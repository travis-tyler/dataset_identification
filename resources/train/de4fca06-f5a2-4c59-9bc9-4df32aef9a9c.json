[{"section_title": "", "text": "In this study, I use data from California to estimate the returns to a community college education for students who do not complete postsecondary credentials. I find strong, positive returns to completed credits in career and technical education (CTE) fields that are closely linked to employment sectors that are not credential-intensive, such as public safety, skilled blue collar trade and technical work, and accounting and bookkeeping, among others. In these sectors, students are able to convert the human capital acquired in their coursework into returns that far exceed the cost of the coursework itself, making some non-completing educational pathways a rational means of securing earnings gains. This finding is consistent with emerging research on skills-builder students and other segments of the community college student population who exhibit coherent patterns of course-taking and enrollment that typically do not result in a credential. These results are not without caveat, however, as I also find that the returns to credits are less consistent for Black and Asian students than they are for White and Hispanic students, and less consistent for female students than they are for male students, indicating the need for further investigation as well as attention to context in applying the results. The \"college completion agenda\"-focusing on increasing the rate at which U.S. citizens complete postsecondary credentials (Lumina Foundation, 2012), particularly segments of the citizenry that historically have been underrepresented in higher education (Lumina Foundation, 2013)-is the dominant reformist paradigm through which community colleges in the U.S. are viewed today (e.g., McPhail, 2011;National Center for Education Statistics, 2011). Following from this focus on completion, the relatively low rate of credential attainment among community college students, which is a little more than half that of students who begin at public four-year institutions (Radford, Berkner, Wheeless, & Sheherd, 2010), has been characterized as symptomatic of the need for major reforms in these institutions. The completion agenda has been expressed in a variety of forms and arenas, perhaps most notably in President Obama's 2009 address before a joint session of the U.S. Congress, calling for the U.S. to retake the international lead in the proportion of citizens who hold college degrees by the year 2020 (Kanter, 2011;The White House, 2009). Prior to this address, however, several major foundations, including the Bill & Melinda Gates Foundation and the Lumina Foundation, had set national goals and associated funding priorities concerning substantial increases in the number of U.S. citizens who complete postsecondary credentials (Russell, 2011). Subsequent to the President's address, a number of national organizations, such as the American Association of Community Colleges and the National Governors Association, issued calls to action concerning increasing college graduation rates among their constituencies (McPhail, 2011;National Governors Association, 2010). The completion agenda paradigm is inextricably linked to and reinforced by longstanding efforts to develop and implement widely accepted standards of postsecondary institutional accountability (Walters, 2012). These efforts have focused largely on institutions' responsibilities with respect to student success, which, for open access institutions like community colleges, is a consequential departure from the historical focus on student enrollment (Bahr & Gross, 2016;Dougherty & Hong, 2006). As it pertains to community colleges, the central challenge of these efforts is identifying measures that capture the full range of institutional activities, including preparing students to transfer to four-year institutions, workforce development, and community education (Bahr, 2013). In the face of this challenge, policymakers often have defaulted to readily measureable outcomes that capture only a portion of the community college mission, and the most common of these is graduation rate (Bautsch & Williams, 2010;Dowd & Tong, 2007). Of course, efforts to develop frameworks for institutional accountability are not the original source of attention to community college graduation rates. A wide range of stakeholders have been concerned with graduation rates for some time, perhaps best exemplified in the \"Student Right-to-Know Act\" of 1990 (Public Law 101-542), which required postsecondary institutions that receive Title IV funds (federal student financial aid) to disclose their graduation rates. However, the explicit linkage between institutional performance and institutional funding evident in many accountability frameworks has increased the consequences to institutions of being judged \"low performers\" on unidimensional metrics like graduation rate (Bahr, 2013;Walters, 2012). From this paradigmatic and policy context, a renewed interest in the labor market value of community college degrees and certificates has arisen. In recent years, careful investigations of the returns to community college credentials have been conducted in a number of states, such as California (Bahr, 2016;Stevens, Kurlaender, & Grosz, 2015), Kentucky (Jepsen, Troske, & Coomes, 2014), Michigan (Bahr, Dynarski, Jacob, Kreisman, Sosa, & Wiederspan, 2015), North Carolina (Liu, Belfield, & Trimble, 2014;Xu & Trimble, 2015), Virginia (Jaggars & Xu, 2015;Xu & Trimble, 2015), Tennessee (Carruthers & Sanford, 2015), and Washington (Dadgar & Trimble, 2014). There is no doubt that a chief goal of community colleges is providing educational pathways to postsecondary credentials. Moreover, the current national attention on college completion and institutional performance with respect to graduation rates makes investigations of the labor market value of those credentials especially salient. Nevertheless, the singular focus of much of the current research on the labor market returns to credentials reinforces an arguably inaccurate perspective that the only worthwhile educational outcome for community college students is a degree or certificate. Yet, two decades ago, Kane and Rouse's (1995) foundational study of the returns to a community college education demonstrated that the return in earnings to an associate degree did not differ significantly from the return to an equivalent number of course credits without an associate degree. Drawing on this finding, the authors argued that, \"studies that focus solely on the returns to an associate degree present an incomplete picture of the returns to a community college education\" (p. 602). Although the growth since that time in the number of certificates awarded by community colleges Bosworth, 2010;Carnevale, Rose, & Hanson, n.d.) might lead one to substitute the phrase \"community college credential\" for \"associate degree,\" Kane and Rouse's argument remains clear: a community college education takes many economically beneficial forms, and only some of these forms result in a postsecondary credential. Grubb (1995) verified Kane and Rouse's conclusion and extended this line of inquiry, demonstrating a significant return in hourly wages and annual earnings to vocational course credits for male community college students who did not complete a postsecondary credential, and a significant return to academic course credits for female community college students who did not complete a postsecondary credential. Likewise, Leigh and Gill (1997) found that community college students who did not complete a credential experienced a significant return in wages and earnings. Eight years later, Marcotte, Bailey, Borkoski, and Keinzl (2005) provided further evidence, finding a significant return to years of community college education among students who did not earn a certificate or associate degree. Even stronger evidence was provided by Jacobson, LaLonde, and Sullivan's (2005) finding among displaced workers of a sizeable, positive return to completed credits in a broad category of community college coursework that included health fields, technically oriented vocational fields, and academic math and science fields. In sum, the accumulated evidence confirms Kane and Rouse's (1999) argument that even students who do not complete postsecondary credentials typically experience a positive labor market return to their community college education, though how this return varies across the diverse terrain of the curriculum remains to be determined. Recent work (e.g., Bahr, 2010Bahr, , 2011Bahr & Booth, 2012Crosta, 2013) has begun to shed light on the large fraction of students in community colleges who do not complete credentials or transfer to four-year institutions, often called non-completing students. Bahr and Booth's (2015) analysis of students' course-taking patterns indicated that about one in six students in California's community colleges are highly successful non-completers, enrolling in just a few courses over a short period of time, succeeding in these courses at an exceptionally high rate, and then departing from the institution, almost always without completing a postsecondary credential or transferring to a four-year institution. In early investigations, Bahr labeled these students drop-ins (Bahr, 2010(Bahr, , 2011 but subsequently renamed them skillsbuilders (Bahr & Booth, 2012) when further analyses demonstrated that they exhibit organized course-taking patterns and tend to concentrate their course-taking in a fairly narrow range of fields, frequently career and technical education (CTE) fields (Booth & Bahr, 2013). In other words, skills-builder students, who elsewhere have been referred to as retoolers (Mullin, 2010), appear to be strategic about their course-taking, pursuing seemingly coherent non-completing pathways through community colleges. Thus, in contradiction to popular notions, students who leave community college without a credential have not necessarily failed to achieve their goals or dropped out (Leigh & Gill, 1997). Despite the evidence of coherent non-completing pathways in community colleges and emerging interest at the state level in incorporating these pathways into accountability frameworks (e.g., Booth, Fuller, & van Ommeren, 2015), most of the recent efforts to quantify the labor market returns to a community college education have focused narrowly on the returns to credentials (e.g., Dadgar & Trimble, 2014;Xu & Trimble, 2015). This works measures the value of these credentials against the unquantified value acquired by community college students who do not complete a credential, who, in turn, are presumed incorrectly to be a relatively homogenous group (Grubb, 2002a). That is, students who complete \"some community college\" are the ambiguous comparison group against which the returns to a given community college credential are assessed, much as \"some college\" is treated as an intrinsically meaningful category of educational attainment in reports of various levels of educational attainment both above and below that offered by community colleges (e.g., Baum, Ma, & Payea, 2013;Webber, 2014). As a result, we still have only the barest information about the labor market returns to educational pathways through community colleges that do not result in a credential. Of the limited research on the returns to non-completing community college students, most has used course credits as a measure of the amount of education received by students and, of necessity, has consolidated credits into an undifferentiated mass (e.g., Jepsen et al., 2014;Kane & Rouse, 1995;Liu et al., 2014) or into broad categories of limited utility (e.g., Grubb, 1995). For example, Jacobson et al. (2005) collapsed students' credits into just two categories, the first of which included math, science, health, and technical trades and professions, while the second included all other subjects. Other studies have focused on the returns to years of community college education (e.g., Marcotte et al., 2005), and these are comparable to studies that consolidated credits into an undifferentiated mass. Yet, students complete coursework in specific fields of study, and one would expect that returns to course credits would vary greatly by the field in which they are completed, just as do the returns to credentials. Hence, a comprehensive understanding of the returns to a community college education requires the same careful attention to coursework completed by students that has been applied in recent studies to the credentials awarded to students. In this study, I extend recent work on the labor market returns to a community college education, using a comparable student-level fixed effects approach and panel data from California to investigate the returns to students who do not complete credentials. My investigation is informed by two theoretical concepts-human capital and signaling (Weiss, 1995). Human capital theory argues that education and training are investments in workers that result in greater productivity and, hence, greater earnings. The theory of the signaling value of credentials contends that a portion of the return to postsecondary credentials is independent of the accumulated human capital that these credentials represent (Weiss, 1995). This is a result of information asymmetry in the relationship between employer and prospective employee: prospective employees know more about their own skills and potential productivity than do employers. Given this asymmetry, a postsecondary credential serves as a signal to employers about an employee's likely productivity, reducing an employer's risk in the hiring decision. Evidence generally supports this theory, indicating that postsecondary credentials have a labor market return that, on average, is somewhat greater than an equivalent number of years of education without a credential (e.g., Arkes, 1999;Jaeger & Page, 1996). The objective of this study is to quantify the labor market returns to human capital acquired by community college students in their coursework, independent of the labor market signaling value of credentials awarded to students as a result of this coursework. I operationalize the accumulation of human capital as completed course credits in each of 24 fields of study. The rationale for using course credits as a proxy for human capital accumulation is detailed by Garriga and Keightley (2007). However, analyzing the returns to credits among non-completing students alone is insufficient because labor market opportunities while attending college likely influence students' decisions about remaining in college to complete a credential. Instead, I use a sample composed of both completing and non-completing students, and I estimate the effects of credentials and credits simultaneously, which allows me to parse the estimated returns to credits from the signaling value of credentials. The data used in this study allow me to observe all four levels of community college credentials awarded in California-low-credit awards, short-term certificates, long-term certificates, and associate degrees-in each of the same 24 fields of study in which completed course credits are observed. I expect to find that, after controlling for the effects of credentials on earnings, there is a positive return to credits in fields of study with clear links to the labor market, particularly the CTE fields in which strong and consistent returns to credentials have been observed in prior work. In California, these fields of study include engineering & industrial technologies, health, law, and public & protective services (Bahr, 2016). In other words, I expect that students reap significant returns to the credits that they complete in these fields, whether or not they complete a credential. Underlying this expectation is the supposition that, in fields of study that are closely associated with labor market opportunities, the returns to community college credentials are primarily a result of the human capital acquired in coursework, and signaling plays a relatively smaller role. Therefore, the returns that students experience should correspond to the coursework that they complete in these fields. I draw on administrative data provided by the Chancellor's Office of California Community Colleges. The data maintained by the Chancellor's Office address all students who enroll in the California Community College (CCC) system and include transcripts, demographics, the award of credentials, application for and receipt of financial aid, and the like. These data also includes information on enrollment by CCC students in other postsecondary institutions outside the CCC system, which is derived from a match with the National Student Clearinghouse, as well as students' quarterly earnings derived from a match with the state's unemployment insurance (UI) database. For the purposes of this study, I focused on all first-time college students who began their postsecondary education at one of the semester-system colleges of the CCC system in the six-year period between the fall term of 2002 and the summer term of 2008, and who additionally reported a valid social security number at college entry. Semester-system colleges account for more than 97 percent of all colleges in the CCC system. Consequently, the 1,877,360 students who met the initial criteria for inclusion in this study constitute the vast majority of first-time students with valid social security numbers who entered the CCC system in the specified period. I observed the course-taking of these students in the CCC system and their enrollment in other postsecondary institutions outside the CCC system through the end of 2013. I observed their quarterly earnings, as reported in the state UI database, from 10 quarters prior to entering the CCC system through the fourth quarter of 2013. I selected from this initial sample the 86 percent of students who were between the ages of 18 and 50 years at college entry and, of these, the 69 percent of students who had at least one non-zero quarterly earnings record in the 10 quarters prior to college entry and at least one nonzero quarterly earnings records during or after enrollment in the CCC system. The final analytical sample includes 1,115,386 students, or about three-fifths (59 percent) of the initial sample. This analytical sample also was employed in Bahr's (2016) study of the labor market returns to community college credentials. I arranged the data for this analysis in a student-quarter format in which a unique observation is defined by the combination of a student identifier, calendar year, and quarter within the year. As noted, earnings reported to the UI system were observed for each student in each quarter, beginning 10 quarters prior to a student's entry into the CCC system and continuing through 2013Q4. Because students in the analytical cohort entered the CCC system at different points in time, however, the length of time that earnings were observed varied across the analytical sample, from a minimum of 32 quarters to a maximum of 55 quarters, or 8 to approximately 14 years. In total, the 1,115,386 students in the sample contributed 49,331,548 quarterly observations. Once the data were arranged in this format, I dropped all quarters in which students' earnings were missing. In UI data, missing earnings information most often indicates zero earnings in that quarter but also can indicate employment in a sector not covered by the UI system (e.g., self-employment, military employment), employment outside of the state, or employment involving direct cash exchange (Feldbaum & Harmon, 2012). Dropping these records reduced the number of quarterly observations to 30,877,882, with an average of 28 quarterly earnings records per student. In line with the bulk of the recent work in this area, I employ a student-level fixed effects linear regression model with robust (clustered) standard errors, estimated with Stata's xtreg, fe vce(cluster) command. The preferred model is presented below as Model 1. The dependent variable, represented by Earnings it , is the earnings of individual i in quarter t, conditional on being employed in quarter t, adjusted for inflation using the CPI-U and set to 2013Q4-equivalent dollars. After adjustment for inflation, I recoded quarterly earnings that exceeded the 99.9th percentile of earnings across all quarters ($71,180) to be equal to the 99.9th percentile to reduce the effect of the most extreme values on the estimates. As discussed earlier, the primary theoretical constructs of interest in this study are human capital and signaling. Human capital is represented by Cumulative Credits, which addresses the cumulative number of course credits completed by individual i in each of k fields of study as of the end of the prior quarter (t -1) in any of the semester-based colleges of the CCC system. The superscript p indicates that Model 1 includes both the identity and square of credits to accommodate the likelihood of nonlinear relationships with earnings (e.g., diminishing returns to credits), as found in some prior work (e.g., Jacobson et al., 2005;Liu et al., 2014). Student who did not complete any credits in a given field of study were assigned a value of zero in all quarters for the variables (identity and square) representing that field. Treating completed credits as a leading indicator of earnings, denoted by \"(t -1)\" enforces the logical assumption that a change in a student's cumulative number of credits affects the student's earnings in the quarter after the coursework was completed, rather than in the quarter in which the coursework was taken. Twenty-four broad fields of study are defined by the CCC Taxonomy of Programs (TOP; Chancellor's Office, 2009), and each comprises a number of narrower subfields, which in turn occasionally contain still narrower branches of coursework. In this analysis, I estimate returns to credits in all of the 24 fields, but I do not report estimates for one of these, namely military studies. Only 158 of the 1,115,386 students in this analysis completed any credits in military studies, and none of these students completed a community college credential in this field. In the course of my analysis, I also estimate returns to credits by subfield of study. Students in the sample completed credits in more than 200 different subfields. For the purposes of the analysis, I collapsed subfields in which fewer than 3,000 credits were completed by the analytical cohort into existing \"other\" or \"general\" subfields within the same parent field (e.g., the \"other health occupations\" subfield within the broader \"health\" field of study; the \"general law\" subfield within the broader \"law\" field of study), resulting in a final set of 189 subfields. Much of the prior work on the returns to community college credentials has assumed that returns are constant over time, which has been demonstrated to be inaccurate (Bahr, 2016;Jaggars & Xu, 2015). For example, the effect on earnings of some awards is small initially but grows later, while the effect of other awards grows quickly at first but declines later. Here, I control for the labor market return to community college credentials using Bahr's (2016) approach, estimating the effects of credentials on the rate of change in students' earnings. In Model 1, the term Time Since Credential Award indicates the number of quarters that have passed since individual i received a postsecondary credential of level j in field of study k, measured at time t. The levels of credentials include low-credit awards (< 6 credits), short-term certificates (6 to 29 credits), long-term certificates (> 29 credits), and associate degrees (> 59 credits). For each combination of level and field, the variable representing that credential was assigned a value of zero in all quarters up to and including the quarter in which the credential was awarded, a value of one in the first quarter after the award of the credential, a value of two in the second quarter after the award, and so on. Students who never received a credential of a given level and field have a zero assigned for this variable in all quarters. The superscript p again indicates that, for each combination of level and field, both the identity and square of time since award were included in the model. Similar to the measures of community college credential awards, Model 1 includes variables representing the number of quarters that have elapsed since a student's final quarter of enrollment in four-year institutions (Time Since Four Year) and less-than-four-year institutions (Time Since Other PSI). These capture the average effect of education received in these types of institutions on the rate of change in students' earnings, and again both the identity and square are included to accommodate nonlinearities. However, information on credential awards from institutions outside of the CCC system was not available. Consequently, estimates represent the average effects of four-year and less-than-four-year education for both students who were awarded credentials by these types of institutions and students who enrolled but were not awarded credentials. The effect of being enrolled in college in a given quarter on students' earnings in that quarter are accounted for by Course Credit Load, Enroll Four Year, and Enroll Other PSI. The first of these represents the number of course credits attempted by individual i in the CCC system in quarter t. As before, both the identity and square are included. Although the CCC system database includes information on enrollment in institutions outside of the CCC system, it does not include information on course credit load in these institutions. Therefore, Enroll Four Year and Enroll Other PSI are simple dichotomous indicators of enrollment in the present quarter t in a four-year postsecondary institution or a lessthan-four-year postsecondary institution other than a college in the CCC system. Another potentially important factor in students' earnings in a given quarter is the amount of financial aid that they have received, hence Model 1 controls for the dollar value of f types of Financial Aid received by individual i in quarter t while enrolled in the CCC system. The f types of aid include grants and scholarships (combined), loans, work-study, and tuition waivers, each entered as a separate variable because funds from different sources may have different effects on students' decisions about employment and earnings. Information about financial aid in postsecondary institutions outside of the CCC system was not available. The underlying trend in earnings is accounted for by Time. This is a naturally ordered enumeration of quarters from 10 quarters prior to college entry through the fourth quarter of 2013, with every student's first quarter in the CCC system assigned a value of eleven. The superscript r indicates the inclusion of the identity, square, and cube of time to accommodate multiple points of inflection in the earnings trend. The variables representing time were interacted with s time-invariant Student Characteristics and a dummy variable to represent each of the possible q quarters of first entry into the CCC system (Quarter of College Entry). The student characteristics include sex, race/ethnicity, age at college entry (eight categories), citizenship status, and academic goal at college entry (seven categories). The interaction of time with each of these time-invariant variables allows the earnings trend to vary across demographic groups, academic goals, and the quarter of college entry. Finally, the individual fixed effects (\u03c1 i ) control for observed and unobserved timeinvariant differences between individuals that are correlated with earnings. The term \u03b5 it is the error for individual i in quarter t. This study has several limitations that should be noted. First, like nearly all of the recent work on the returns to a community college education, this study relies on earnings data drawn from state UI records. As noted earlier, UI data exclude certain employment sectors. These exclusions have meaningful implications for analyses like this one that disaggregate returns by field of study because some fields of study are more prone to lead to employment in these noncovered sectors. For example, cosmetology, construction, and real estate-three subfields of study offered in the CCC system-have relatively high rates of self-employment (Hipple, 2010). Estimates of returns to education in the parent fields in which these subfields are located are subject to bias in proportion to the share of credits and credentials represented by these subfields. Second, this study focuses on quarterly earnings, which is one among many important aspects of the labor market returns to postsecondary education. Others include hourly wages, employment status (i.e., employed versus unemployed), continuity of employment over time, the number of jobs held by an individual in a given period, and employment fringe benefits like employer-funded healthcare and retirement Grubb, 2002a). In addition, there are many non-economic returns to education that also are not addressed in this study, such as improved health outcomes, civic engagement, and reduced involvement in criminal activities (Baum, 2014;. Third, Model 1 estimates the effects of credentials on the rate of change in students' earnings, allowing these effects to vary over time, which is an important advancement over much of the recent research on the returns to a community college education. However, Model 1 does not make the same allowance for the estimated effects of credits on students' earnings, instead assuming that the effects on a student's earnings trajectory of completing coursework in a given field are constant over time. This is a result of the fact that credits are measured in a cumulative manner unlike the award of a credential, which is a change in a discrete state. Thus, the estimated returns to credits in this study represent the average returns over time, as opposed to the specific returns at a particular point in time. Fourth, this study does not differentiate between coursework that was completed with a high level of mastery of content and coursework that was completed with a low level of mastery. A course grade of \"D\" or above typically results in the award of credits, but courses completed with an \"A\" or a \"B\" clearly demonstrate a greater level of mastery than do courses completed with a \"C\" or a \"D.\" Given that course credits serve as a proxy for human capital in this study, the effects of human capital on earnings likely are underestimated in this study due to dilution with low-mastery credits. Future research may consider interacting completed credits in each course with the numeric rank of the grade achieved in the course, replacing cumulative course credits with cumulative course grade points. This approach may allow finer distinctions between levels of human capital accumulation in each field of study. Finally, as noted earlier, most of the recent work on the labor market returns to a community college education has focused on credentials. Furthermore, most of this work has defined the comparison group against which the returns to credentials are measured as community college students who did not complete a credential, as opposed to students who did not attend college at all. Of necessity, the comparison group against which the returns to a community college education are measured in this study also is composed of community college students. However, this study's account of credits completed in each of 24 fields allows the comparison group to be defined much more precisely as the hypothetical students who earned zero credits but who were otherwise comparable to students who completed credits in a given field. Nevertheless, the estimated returns to credits likely differ in unmeasured ways from what would be observed if the comparison group were composed of individuals who have not enrolled in college. In Table 1, I present estimates of the returns to community college credits from Model 1, which, as discussed earlier, controls statistically for the effects of credentials on earnings. These estimates may be understood as the average effects of credits completed by a student who is not subsequently awarded a credential. They are \"average\" effects in the sense that they are measured over persons but also in the sense that they are measured over time, as opposed to being measured at a particular point in time following the completion of the coursework. For ease of interpretation, I provide for each field of study the predicted returns to three, six, and nine credits, which correspond to one, two, and three typical three-credit courses. These predictions indicate the net quarterly earnings gain or loss (in 2013Q4 dollars) of a student who completed the specified number of credits in the specified field, relative to a student who did not complete any credits in that field, after removing the effects of postsecondary credentials on earnings. A positive prediction indicates that students who complete credits in that field earn more, on average, than do students who do not complete credits in any field, while a negative prediction indicates that students who complete credits earn less, on average. In this study, I hypothesized positive returns to community college credits in fields with clear links to the labor market, as demonstrated by the returns to credentials in these fields. Bahr's (2016) analysis of the returns to community college credentials in California revealed consistent, positive earnings gains across levels of credentials in four CTE fields: engineering & industrial technologies, health, law, and public & protective services. Studies of other states likewise have found significant returns to community college credentials in these fields (e.g., Dadgar & Trimble, 2014;Liu et al., 2014). The results presented in Table 1 partially support my hypothesis. Returns to credits in engineering & industrial technologies and public & protective services are strong and positive. The average return to six credits in the former is $400 quarterly ($1,600 annually), while the return to six credits in the latter is $488 quarterly ($1,952 annually). Given that the cost of two three-credit courses in a California community college is a mere $276, these returns are large indeed. Returns to credits in health and law, however, seem to contradict the hypothesis. The return to six credits in health is just $29 quarterly, while the return to credits in law does not differ significantly from zero. In addition to the findings regarding these four fields of study, two other CTE fields evidence strong, positive returns to credits. The return to six credits in business & management is $202 quarterly ($808 annually), while the return in information technology is $131 quarterly ($524 annually).  Table 1 provides the most detailed analysis to date of the returns to cumulative completed credits, disaggregating credits into 24 fields of study of which 23 are reported. However, even this high level of detail masks potentially important variation within fields of study. To explore this matter, I re-estimated Model 1, disaggregating completed credits by 189 subfields of study. I then calculated the predicted returns to three, six, and nine credits in each of the subfields, relative to completing zero credits in the subfield, and present these predictions in Within each of the six focal CTE fields, returns vary widely by subfield. Positive returns to six completed credits are observed in 7 of the 12 subfields of business & management, including general business & commerce ($215 quarterly), accounting ($275), banking & finance ($167), business administration ($165), business management ($163), international business & trade ($63), and the miscellaneous \"other business & management\" subfield ($1,107). Negative returns to six credits are observed in real estate (-$180 quarterly) and office technology/office computer applications (-$104). As noted earlier, there is a high rate of self-employment in the real estate sector, and, consequently, the observed returns to credits in this subfield likely are not fully reflective of the returns actually experienced by students. In information technology, three of the seven subfields have positive returns to six credits, including computer science ($292 quarterly), computer software development ($415), and computer infrastructure & support ($199). None of the subfields evidences a negative return to credits. Of the 19 subfields of engineering & industrial technology, 10 have positive returns to six credits, ranging from $4,920 quarterly in chemical technology to $243 quarterly in environmental control technology. Five subfields have negative returns to six credits, ranging from -$49 quarterly in automotive technology to -$656 quarterly in electro-mechanical technology. In public & protective services, all of the subfields have significant returns to credits. Returns to six credits are positive in four of the subfields: public administration ($1,432 quarterly), administration of justice ($667), fire technology ($280), and legal & community interpretation ($97). Returns to six credits are negative in human services (-$81 quarterly) and the miscellaneous \"other public & protective services\" (-$596). In Table 1, the average return to credits in health was positive but trivial. The field of health has an unusually large number of subfields, and the range of returns to credits evident across these subfields in Table 2 is equally large. Among the 21 (of 27) subfields in which statistically significant returns to credits are observed, quarterly returns to six credits range from $932 in the surgical technician subfield and $577 in the paramedic subfield to -$900 in the occupational therapy technology subfield and -$1,177 in the physical therapist assistant subfield. Finally, in Table 1, the return to credits in law was found to not differ significantly from zero. In Table 2, one observes that the return to six credits in the paralegal subfield is statistically insignificant, but the return to six credits in the general law subfield is positive ($130 quarterly). A question that one might ask about these findings is whether the human capital acquired in community college coursework plays a greater or lesser role in the labor market returns of men relative to women and of one racial/ethnic group relative to another. To examine how the returns to credits vary by gender and race/ethnicity, I re-estimated Model 1 on eight subsets of the larger analytical sample. These subsets were defined by the intersection of gender and race/ethnicity, focusing on the four largest racial/ethnic groups in the CCC system. To simplify comparisons of the returns to credits across demographic groups, I present in Table 3 only the predicted return to six credits (versus zero credits) in each field. Full regression results are available upon request. Marked differences in the returns to credits are observed across the demographic groups. Black students (both men and women) and Asian men receive little or no return to credits in business & management. Similarly, Black students (both men and women), Hispanic women, and Asian women receive no return to credits in information technology. Asian men and White and Black women receive limited or no returns to credits in engineering & industrial technologies. Six of the eight groups receive positive returns to credits in public & protective services, excluding Asian students (both men and women), for whom the returns are minimal or zero. Across the board, however, the magnitude of returns to public & protective services are considerably larger for men than they are for women. Finally, in health and law-the two fields in which little or no returns to credits were observed in the full sample-returns range from negligible to strongly negative across the demographic groups with the notable exception of Asian women, for whom returns in both fields of study are positive and of meaningful size. Taken as a whole, it appears that non-completing pathways in these CTE fields are a more viable option for White and Hispanic students than they are Black and Asian students. In addition, such pathways appear to be more viable for male students than they are for female students. I executed several tests of the sensitivity of the results to adjustments in the analytical sample to address questions that could be raised about the validity of the findings. In each case, I re-estimated Model 1, excluding one or more segments of the full analytical sample. I then calculated the predicted return to six credits (relative to zero credits) in each field of study. The results are presented in Table 4, alongside the parallel predictions for the full sample (Model 1, replicated from Table 1). Substantive differences between the results for the full sample and the results for any of the reduced samples could indicate a threat to the validity of the findings of this study. First, the analytical sample employed in this study includes both completing and noncompleting students, and, of the non-completing students, about 18 percent did not earn any community college credits. It is likely that such students were similarly represented in the analytical samples of much of the recent work on this subject, but most prior studies focused exclusively on the returns to community college credentials, pooling non-completing students into a single comparison group. The study presented here represents a significant advancement over prior work insofar as it differentiates the field-specific returns to credits from the fieldspecific returns to credentials, thereby providing estimates of the returns to non-completing pathways. However, the focus on isolating the returns to credits from the returns to credentials may lead to greater sensitivity to unmeasured differences between students who complete credits and those who do not. To explore this possibility, I re-estimated Model 1, excluding students who completed zero credits in the CCC system. The results are presented as Model 2. A second question concerns whether the returns to credits among students who are not awarded credentials are different from the returns to credits among students who are awarded credentials. One may imagine that bias could arise if common support (Caliendo & Kopeinig, 2005) across completing and non-completing students is weak. For example, if the only students who completed a large number of credits in a given field were those who earned a credential in that field, then differentiating the return to the credential from the return to credits becomes problematic. The return to credits among non-completing students may be inflated by the return experienced by students who were awarded credentials. On a similar note, it could be that the most employable students are disproportionately likely to elect to leave college prior to completing a credential. The individual fixed effects approach used in this study controls for all time-invariant differences between students, but it does not account for unmeasured differences that change over time. One would expect that students' understanding of their capabilities and talents often would evolve while in college, independent of their course-taking, possibly influencing their employability and potential earnings in ways that cannot be accounted for with individual fixed effects. To examine these concerns, I re-estimated Model 1, excluding all students who completed community college credentials and all students who transferred out of the CCC system, whether to a four-year institution or a less-than-four-year institution. The results are presented as Model 3. Third, it is possible that low pre-college earnings among the youngest students in the sample, many of whom were enrolled in high school during some or all of the 10 quarters before beginning college, may inflate the estimated returns to credits. Model 4 addresses this question by excluding all students who were less than 20 years of age when they entered college. Finally, one could argue that depressed earnings experienced by displaced workers immediately prior to beginning college (i.e., Ashenfelter dip) could elevate the observed returns to credits. Model 5 tests this proposition by excluding the two quarters of earnings information immediately prior to each student's entry into the CCC system. It also excludes all students who, after dropping these two quarters of earnings information, had no record of earnings prior to college. Few substantive differences are observed between Model 1 (the full sample) and Models 2, 3, 4, and 5. Through varying somewhat in magnitude, returns to credits in business & management, information technology, engineering & industrial technologies, and public & protective services remain strong and positive across models. This fortifies confidence in the validity of the findings of this study. Among the few differences across models, the most noteworthy occur in the fields of health and law. In Model 1, the effect of six credits in health is positive but approaching zero ($29 quarterly). Among students 20 to 50 years of age (Model 4), the return to six credits in health is considerably stronger ($89 quarterly) though still modest when compared to the other CTE fields of interest here. In Model 1, the return to six credits in law does not differ significantly from zero, but, among non-completing students who never transferred (Model 3), the return is positive ($109 quarterly). In contrast, the return to six credits in law is nearly the opposite (-$99 quarterly) in Model 2, which excludes students who completed zero credits. Students who do not complete credentials constitute the majority of community college students (National Center for Education Statistics, 2011;Shapiro et al., 2013). The members of this group are far from homogenous with respect to the ways that they use the community college, as demonstrated in research on students' course-taking behaviors and enrollment patterns (Bahr, 2010(Bahr, , 2011Crosta, 2013). Yet, heretofore, our understanding of the labor market returns to a community college education for non-completing students has been remarkably superficial. In this study, I estimated the effects on earnings of credits completed in 24 fields of study, while controlling statistically for the returns to postsecondary credentials and other variables that influence the earnings of community college students. I hypothesized positive returns to credits in four CTE fields in which strong links to the labor market have been demonstrated in prior work: engineering & industrial technologies, health, law, and public & protective services (Bahr, 2016). I found strong, positive returns to credits in engineering & industrial technologies and public & protective services, but little or no return to credits in health and law. In addition, I found strong returns to credits in two other CTE fields of study, specifically business & management and information technology. This is an interesting finding because Bahr's (2016) analysis of returns to community college credentials in California indicated that only associate degrees in these fields provide positive earnings gains; neither short-nor longterm certificates provide gains. Yet, the positive return to credits indicates that students are able to convert the human capital acquired in their coursework in these fields into an earnings advantage. Furthermore, it suggests that employers value the skills acquired in coursework more than they do the postsecondary certificates (Bahr, 2016). In considering the similarities and differences in the employment sectors served by these six fields of study, one observes that healthcare and legal services are credential-intensive sectors, while the blue collar occupations linked to a community college education in engineering & industrial technologies are not (Bureau of Labor Statistics [BLS], 2016). The protective services field of employment (e.g., law enforcement, firefighting) occupies a middle ground between the blue collar and healthcare fields but remains considerably less credential-intensive than is healthcare. Thus, while the skills and knowledge (the human capital) acquired in coursework in engineering & industrial technologies and public & protective services appear to be sufficient to advance an individual's earnings, a credential is needed to accomplish the same in health or law. The strong returns to credits in business & management, though not hypothesized, may be explained in part by the fact that the largest subfield of study in business & management is accounting, making up just under one-third (29.5 percent) of all credits completed by students in the field. In turn, the majority of jobs in accounting, bookkeeping, auditing, and clerking do not require a college degree (BLS, 2016), much like the employment sectors linked to engineering & industrial technologies and public & protective services. The return to credits in information technology also was not hypothesized, and the reason for this return is less clear than are the returns to credits in other fields because many jobs in information technology require a college degree (BLS, 2016). One possible explanation for the positive return to credits and the null return to short-and long-term certificates in information technology is that students are training for and finding work in subsectors of information technology that less frequently require a college degree, such as network administration and computer user support (BLS, 2016). Consistent with this explanation, I found a positive return to credits in the subfield of computer infrastructure & support. Yet, stronger returns to credits were found in the subfields of computer science and computer software development, the latter of which is unequivocally a degree-intensive employment sector. Thus, additional explanation is required. One possibility in that regard is that students who already are employed in information technology jobs are taking courses to broaden or update their skills, garnering opportunities for advancement and greater earnings. Future research, however, should investigate closely how and under what circumstances students are using coursework in information technology to strengthen their labor market position. Looking beyond the individual fields of study, it appears that the returns to credits are positive and oftentimes strong in CTE fields that are closely linked to sectors of the labor market that are not credential-intensive. That is, in employment sectors in which the signaling value of postsecondary credentials plays a smaller role, students are able to convert the human capital acquired in their community college coursework into meaningful earnings gains. This finding contradicts common notions about the interchangeability of the words success and graduation (or completion). Assertions that \"[d]ropping in for a couple of courses at the local campus rarely makes much of difference for long-term student success\" (Bosworth, 2010, p. 1) clearly are misleading. Though enrolling in a random mix of community college courses is unlikely to result in earnings gains, a strategic selection of courses in CTE fields appears to be a potentially rational means of advancing one's earning potential. Thus, there is much to be gained from a community college education, even one that does not result in a credential. Furthermore, the methodological decision to exclude from the analysis student-quarters in which no earnings were reported (which, in many cases, indicates zero earnings), while logical and consistent with recent prior work, likely contributes to the underestimation of the returns to credits in this study. Belfield and Bailey (2011) explain that, \"[i]f community college attendance increases the probability of employment (as seems likely if attendance increases productivity), then the earnings gains should be adjusted upward to account for the higher probability of being employed\" (p. 49). By excluding records of zero earnings, I ignored the influence of a community college education on students' transitions from unemployed status to employed status, which, by definition, increases earnings. Consequently, the estimated returns to credits in this study reflect only the returns to employed students, understating the labor market return to non-completing community college pathways. Balancing this conclusion, however, is the finding that the returns to credits are not the same for all demographic groups. White and Hispanic students appear to have more success converting credits into earnings than do Black and Asian students, and male students have somewhat more success than do female students. Undetermined at this point, though, is whether the demographic differences in returns to credits are driven in part by demographic differences in the subfields of study in which those credits are earned. For example, the administration of justice subfield has the second strongest return to credits in the public & protective services field, and one would imagine that credits in this subfield are completed disproportionately by male students in correspondence to the disproportionate representation of men in employment related to law enforcement. It seems likely that the positive returns to CTE credits observed in this study are driven in part by the role of community college coursework in obtaining job-related state licenses and professional certificates (Booth, 2014;Grubb, 2002aGrubb, , 2002b. These third-party certifications may be serving as the means to access or advance in some employment sectors, much as postsecondary credentials do in other employment sectors. To illustrate, California regulates employment in the operation of water and wastewater treatment plants through state licensing systems (Educational Points, 1982;Eligibility Criteria for Taking a Water Treatment Operator Examination, 2001). Receiving or advancing a license requires the successful completion of a state test, and qualifying to take the test requires the completion of coursework in directly related fields of study. A college degree, however, is not required. In community colleges, the relevant coursework falls within the engineering & industrial technologies field of study and serves simultaneously to satisfy the credit requirements of the license and equip students with the knowledge that they need to succeed on the state exams. Indeed, the return to six credits in the subfield of water & wastewater technology is a sizeable $1,339 quarterly. Hence, in these employment sectors, the state license takes the place of a postsecondary credential and likely serves as the mediator between credits and earnings gains. It is important to note, though, that the likelihood that the returns to credits in these fields are driven partially by licensing and certification requirements does not alter the interpretation of the findings as evidence for the returns to human capital acquired in community college coursework. As Belfield and Bailey (2011) argue, \"if the licensing or certification system is demanded by consumers as a way to guarantee quality of service, then these earnings gains are still real (rather than reflecting a restrictive practice in the labor market)\" (p. 54). Nevertheless, much more research is needed on the relationships between community college coursework and third-party certifications, particularly with respect to non-completing pathways through community colleges. In addition to the finding of this study regarding the returns to non-completing pathways in community colleges, it is exceedingly clear that the gross categorizations of credits used in prior work (e.g., Grubb, 1995;Kane & Rouse, 1995;Liu et al., 2014;Marcotte et al., 2005;Jacobson et al., 2005) assume a uniformity in the returns to coursework that does not align with reality. Here, I have demonstrated that the returns to credits vary greatly by field of study, and disaggregating further by 189 subfields revealed even greater variability within fields. Moreover, even the precise measurement of subfield used in this study likely masks markedly different returns to particular course-taking pathways within those subfields, requiring further investigation in future research. For example, returns to credits in manufacturing & industrial technology (a subfield of the broader engineering & industrial technologies field) are strong and positive, but this subfield includes courses as diverse in subject as computer numerical control (CNC) machining, blueprint reading, firearms manufacturing and repair, hazardous materials safety, iron working, sheet metal working, and radiographic examination and testing. Undoubtedly, the human capital acquired in some of these courses has greater labor market value than that acquired in others. Likewise, even within a particular body of coursework, the human capital acquired in an introductory CNC machining course, for example, likely has less labor market value than that acquired in an advanced course in the programming of the logic controllers that govern the CNC machining process. Even more, there likely are important interactive qualities of community college coursework: combinations of courses from different fields of study that realize a return that is greater than the sum of their individual returns. These, too, should be investigated in future research. Future research also should explore how the labor market returns to coursework in each field and subfield vary geographically. It seems likely that the returns to coursework in some fields are dependent on local or regional labor market conditions, specifically the opportunity structure for individuals with particular types of knowledge and training. For example, a large fraction of the credits completed by the analytical sample in the high-return subfield of chemical technology were completed at just one college that has strong ties to the local energy production industry (e.g., oil, natural gas). The labor market returns to course credits in chemical technology at the few other colleges in the CCC system that offer such coursework probably are different from the return experienced by students at this one college. Thus, future research would benefit from sensitivity to geographic variability in the returns to the various non-completing pathways through the community college. Finally, the data used in this study would not support inquiry into any potential disjuncture between students' actual level attainment with respect to credentials and the attainment that they report to prospective employers. One can place a high level of confidence in the accuracy of the administrative data used in this study with respect to students' actual attainment in the community college system, but these data provide no information about what students report to prospective employers about their attainment. Consequently, the estimates of the labor market returns to course credits in this study are based on the assumption of no systematic discrepancy between students' actual attainment and the information held by prospective employers about students' attainment. In that regard, Attewell and Domina (2011), using data from National Education Longitudinal Study of 1988 (NELS88), found that students in that survey were especially prone to report \"fake\" associate degrees and certificates. For example, about one-third (35 percent) of students who reported that they had received an associate degree in fact had not received this degree (Attewell & Domina, 2011, p. 62). Although reporting a fake degree in the NELS88 survey does not necessarily mean that a student is reporting a fake degree to employers, the magnitude of inaccuracy in students' reporting provides a reason to question the assumption of no systematic error. Balancing this concern, however, is the reassurance that a majority of the students who reported a fake credential in NELS88 had completed nearly enough credits to be awarded the credential. Still, it remains that systematic error in reporting educational attainment to employers could inflate inaccurately the estimated returns to course credits in this study by attributing to the credits the labor market value of the credential. Hence, future research should explore the accuracy of students' job market claims regarding educational attainment, as well as the impact of any discrepancies between claims and reality on the observed returns to a community college education."}]