[{"section_title": "Abstract", "text": "Recently, multi-atlas segmentation (MAS) "}, {"section_title": "Introduction", "text": "Multiple-atlas segmentation (MAS) has recently gained popularity for labeling the anatomical structures of a target image [1, 2, 10, 11, 13] . It segments an unknown target image by transferring the labels from a population of annotated exemplars (i.e., atlases) to the target image domain, where the transformation is usually derived from image registration. In atlas-based segmentation, we assume that if two anatomical structures have similar shape and location, they should bear the same label (or tissue type). Since a population of atlases encompasses large anatomical variability, MAS has a greater chance of finding appropriate atlases to Figure 1 . Overview of our method. Training: TR1) computation of Dice ratio (DR) between segmented atlases, TR2) computation of pairwise features from key regions between each pair of atlases, and TR3) learning of relationships between pairwise features and ground truth DR. Testing: TS1) linear alignment of target image to the common space, TS2) computation of pairwise features between target image and all the atlases, TS3) prediction of the segmentation performance using the learned model and, TS4) selection of atlases with the highest scores to be used for multi-atlas segmentation.\nlabel an underlying target image than single atlas-based segmentation. To this end, selection of the best atlases that contribute to achieve high segmentation performance is critical before applying any state-of-the-art MAS method.\nMost common approaches for atlas selection are based on image similarity measurements such as sum of squared differences (SSD) or normalized mutual information (NMI) [1] . More advanced methods use the distance in the manifold, instead of in the Euclidean space [13, 5] . The drawback of these methods is that they are driven by image similarity which is not necessarily correlated with final segmentation accuracy. More critically, many of them require the images to be non-rigidly registered in order to compute their distance, which is computationally demanding.\nIn order to overcome these limitations, we propose a supervised learning approach to model the relationships between a pair of images (i.e. atlas and target images) and the relevance of their contribution to segmentation. Figure 1 shows an overview of the approach. As input, our method receives a set of atlases linearly aligned to a common space, e.g., a template image. In the training stage, we first compute the relevance score between each pair of atlases, using one of the atlas as the target image and the other as the atlas. We define the relevance score as the Dice ratio (DR) obtained by using the atlas image to segment the target image (TR1 in Figure 1 ). Next, we identify a number of key regions in the entire image domain, in order to obtain efficient representations (TR2.a). Then, we extract HOG features [4] to describe the anatomical characteristics in these key regions and compute their squared differences in order to get the pairwise features between each pair of images (TR2.b). After that, we employ SVM-Rank [8] to learn the latent relationship between the pairwise HOG features and the relevance segmentation score (TR3). In the testing stage, we first linearly align the to-be-segmented target image to the atlas domain (TS1). Next, we extract selected HOG features from the key regions and compute the pairwise feature vectors between the target image and each atlas (TS2). Finally, we evaluate their eventual segmentation performance using the learned SVM-Rank model (TS3) and select the best atlases to be used for MAS according to the predicted scores (TS4).\nAs opposed to heuristics such as image similarity, selection by our method is directly related to the segmentation performance. Our learning-based atlas selection method can boost the performance of current state-of-theart MAS methods. As we show in the experiments, significant improvement is achieved on ANDI and LONI LPBA40 datasets, after we equip the majority voting [10] , local weighted voting [2] , and non-local patch-based MAS [11] methods with our atlas selection approach.\nThe overview of the paper is as follows: in Section 2 we describe the proposed method, in Section 3 we detail experimental evaluation and present the results, and in Section 4 we give some concluding remarks."}, {"section_title": "Method", "text": "Consider a set of atlases composed of intensity images A = {A i , i \u2208 I} with I = {1, . . . , N} as index set, and their corresponding label images L = {L i , i \u2208 I} obtained by expert annotation. We assume that all atlases have been linearly aligned to a common space, e.g., a template image. For each voxel in the atlas domain x \u2208 \u03a9 i , A i (x) indicates the intensity value at location x, and label L i (x) \u2208 {0, 1} indicates whether the structure of interest is present at location x or not. As we will explain later, our method is straightforward to apply to the case of multiple labels.\nGiven a target image T , multiple-atlas segmentation aims to locate the anatomical structure in the target image by transferring the label information from the atlases to the target image domain. It consists of two steps: First, spatial correspondence between atlases and target image is obtained by non-rigid registration. In this way, we obtain a set of registered atlases\u00c3 = \u00c3 i , i \u2208 I and their label imagesL = L i , i \u2208 I . Next, a label fusion procedure is often used to determine the label on each target image point based on the label information from the registered atlases L. Many label fusion strategies have been developed. To name a few, majority voting (MV) [10] assigns to each target voxel the label that most frequently appears among the corresponding atlas voxels. Local weighted voting (LWV) [2] weights the contribution of each atlas according to the image patch similarity. Non-local weighted voting (NLWV) [11] introduces the idea of non-local average by performing neighborhood search for similar patches, which gives some extra robustness to possible mis-alignments.\nAtlas-selection is an important step affecting the accuracy of MAS. On one hand, using small subsets of atlases may produce less accurate segmentations since some relevant information from other atlases may be left out. On the other hand, using large subsets of atlases may undermine the segmentation performance because of the high amount of irrelevant information introduced. Given a target image T , the most common strategies are to select the K most similar atlases to T , according to image similarity measurements such as normalized mutual information (NMI) [1] . Even though similarity-based selection performs significantly better than random selection, it is still loosely related to the final score which is the relevance of an atlas A i for segmenting the target image T . Given the target image T and a set of atlases A and L, the process of MAS can be represented asL\nwhereL T is the estimated segmentation for target image T , and A S , L S , with S \u2286 I, is the subset of selected atlases. Dice ratio (DR) is widely used to measure the degree of overlap between the target structure and the deformed atlas structure. It is defined as\nwhere vol (\u00b7) denotes volume. Supposing that we know the labels for the target image, this scoring function induces a selection of the best K atlases for target image T , denoted as S T , so that,\nwhere the cardinality of the set is equal to K, denoted as\nThis scoring function presents two problems to be used for atlas selection in our method: (1) the target labels L T are unknown, and (2) the deformed atlas labels to the target spaceL i are also unknown since one of our goals is to avoid computationally expensive non-rigid registration before the atlas selection step. Figure 2 demonstrates the superiority of using DR, rather than NMI, to select the best atlases for MAS, where black and blue curves show segmentation performances (assessed by the Dice ratio) by increasing the number of the best atlases selected by equation (2) and NMI, respectively. This shows the potentially large room for improvement of the atlas selection strategy targeted at equation (2) with respect to the widely used criterion based on simple image similarity. (2)), respectively. Here we show the results of applying LWV to segment the left hippocampus in the ADNI dataset.\nOur aim is to learn a scoring function f that correlates pairwise appearance information of a target image and each unregistered atlas image with segmentation performance in terms of DR. To make our learning approach tractable, we use a linear model for mapping the pairwise representation obtained by the feature extraction process to our final score f , in the following way\nwhere \u03a6 (\u00b7, \u00b7) is the feature vector derived from a pair of images and w is the weighting vector where each element measures the contribution of a particular pairwise feature in predicting the segmentation score. In the next two sections, we describe the process of learning the weights w and compute the pairwise features \u03a6(\u00b7, \u00b7), respectively."}, {"section_title": "Learning the Relationships between Pairwise", "text": "Appearance and Segmentation Score\nIn this section we focus on the computation of the weights w while assuming that we have the pairwise features between images (which we will explain in section 2.2).\nConsider an atlas in the training set as the target A t , t \u2208 I, and the rest as the atlases A i , i = t. According to equation (3), we focus on the separation between the set of the best K atlases S t and the rest {I \\ {S t , t}}. That is, we want to find the weights w that fulfill the following relationships\nIt is worth noting that \u03a6(A t , A j ) denotes the features extracted from a pair of linearly aligned intensity images without applying any non-rigid registration between them. This type of problem, in which we seek to fulfill certain order relationships between pairs of elements A i , A j with respect to a given reference A t , is known as learning to rank and there exist several algorithms in the literature aimed at solving it. We use SVM-Rank 1 [8] because it has superior performance than other methods [3] . To this end, we compute a set of constraints for each target A t , constraining the pairs of atlases A i , A j so that the i-th atlas should be ranked higher than the j-th atlas according to ground-truth DR. Consider S t as the ground-truth selection of the best K atlases for target A t , as defined in equation (3) . The set of constraints for target A t according to ground-truth selection is now defined as follows,\nwhere (i, j) \u2208 r t means that the i-th atlas should be ranked higher than the j-th atlas for the segmentation of target A t . Using SVM-Rank, we pose this problem as a constrained optimization problem in which we aim to find the weights w that maximize the margin between the scores of the relevant and non-relevant atlases. More specifically,\nwhere the objective function represents a trade-off between a regularization term and margin size, controlled by the parameter \u03b7; and the margin is dynamically set to 1 \u2212 \u03be t,i,j where \u03be t,i,j is the slack variable controlling the amount of margin violation regarding each triplet A t , A i , A j . As part of the training process, we need to perform (N \u2212 1)\n2 pairwise non-rigid registrations between the atlases in order to compute the constraints of equation (6)."}, {"section_title": "Pairwise Feature Computation", "text": "As mentioned in equation 4, our relevance score f is a function of the pairwise representation features between a target T and an atlas A i . In order to find the compact and accurate representation to describe the connection between T and A i , the calculation of \u03a6 (T, A i ) consists of three steps, namely, (1) key region detection, (2) pairwise HOG computation, and (3) feature selection, as detailed below. It is worth noting that we compute the pairwise features only after linear registration, both in the training and testing stages. However, the Dice ratio in the training stage (sec 2.1) is computed based on the non-rigid registration results, which essentially reflect the goal of our approach which is to predict the segmentation score based only on the rigid registration results.\nKey Region Detection: In MAS, the segmentation label at each target point is decided based on the labels of the aligned atlases at that point. Regions with high label variability, such as label boundaries, are the source of most variability in segmentation results. Therefore, we use the appearance in these regions as cues to predict segmentation performance. Since we already know the label information in the training set, we can obtain the set of boundary locations B (L i ) \u2282 \u03a9 i , from label image L i . We define the set of sensible locations as the union of boundary locations in all the training set, B = i B (L i ). Figure 3 shows an example structure, its boundary and the union of the boundaries from all pre-registered atlases.\nPairwise HOG Computation: We use HOG features to obtain the appearance descriptors of the key regions, although other features can also be applied here. HOG computes a bi-dimensional histogram of gradient occurrences along spatial and orientation bins. Spatial bins constitute a division of the image into a grid of 3D cells (since we use 3D images) whereas orientation bins constitute a division of the orientation range (1 . . . 360) into intervals. Discretization into bins provides robustness to both displacement and orientation errors after linear alignment. We construct a feature vector \u03b8 summarizing the HOG values at bins within a distance \u03c1 of the nearest boundary point in B. We use the locations of the bin centers in order to compute the distance to the boundary region. Overlaid on the intensity image, tain a vector \u03b8 containing a number M of selected HOG features in the boundary region. We use the squared difference between the features from the individual images in order to compute the pool of pairwise features between each atlas and a target image, as follows:\n, where j denotes the j-th feature and t, i denote the indices of the target and atlas images, A t , A i , respectively. In the following, we describe how to select the final set of compact features \u03a6 (A t , A i ) that will be used both for training and testing.\nFeature Selection: In order to select a compact set of features, we sort the pool of features \u0398 according to the maximum-relevance minimum-redundancy criterion (MRmR) [9] . This criterion encourages the selection of features that are highly correlated with the target score while maintaining a low redundancy. After sorting, we obtain a sequence \nwhere\nis a vector composed of the j-th pairwise feature from all target-atlas pairs, and \u03a8 = DR(Lt,Li),\u2200t,i is a vector of ground-truth DR between all target-atlas pairs. As relevance function Rel (\u00b7), we use the absolute value of the Spearman's rank correlation coefficient which measures the correlation between the ranks induced by the features and the ground-truth score.\nAs redundancy function Red (\u00b7), we use the absolute value of the Pearson correlation coefficient which measures the correlation between pairs of features. This formula encourages features correlated with the target score and penalizes features correlated with already chosen features. We finally select a compact set of m features with the highest MRmR. We found that m = 1000 was enough in our experiments."}, {"section_title": "Experiments and Results", "text": "We have conducted experiments in the ADNI 2 and LONI-LPBA40 3 datasets. ADNI dataset contains the segmentations of the left (L) and right (R) hippocampi, which have been obtained by a commercial brain mapping tool [6] . LONI-LPBA40 dataset is provided by the Laboratory of Neuro Imaging (LONI) at UCLA and contains 40 brain images, each with 56 manually-labeled ROIs. We regard these segmentations as the ground truth.\nWe use FLIRT [7] in order to linearly align all atlases to a template image prior to feature extraction. We use non-rigid registration by diffeomorphic demons [12] both for MAS and ground-truth DR computation. We apply the following label fusion methods: MV, LWV and NLWV.\nWe compare selection by our method (HOG+SVMRank) to selection by NMI. As baseline method, we use the negative sum of squared differences of the raw HOG features, \u0398 (HOG). This is represented by the scoring function\n, where \u03b8 T and \u03b8 A i are the pool of M HOG features within the boundary regions obtained from target image T and atlas image A i , respectively. This corresponds to the similarity measurement originally used between HOG descriptors. All the methods have been applied to each structure independently. For NMI, we have used a rectangular image region containing the structure of interest. We conduct 5-fold cross-validation experiments in all the methods.\n2 http://www.adni-info.org/ 3 http://www.loni.ucla.edu/Atlases/LPBA40"}, {"section_title": "Parameter Setting", "text": "HOG features have two parameters, namely, the number of orientation bins O and cell size C (in voxels) of the spatial bins. We have found our method not to be very sensitive to the values of these parameters. Due to different sizes of the structures, setting these parameters to a fixed value may cause larger structures to generate an unnecessarily high number of features. In order to trim the number of features to a manageable size, we adaptively fix the HOG parameters C, O in order to get a reasonable number of features M = 10\n4 . Specifically, we start with initial values C = 5, O = 9 and and iteratively augment the cell size C and decrease number of orientation bins O until the number of features is less than M . We set \u03c1 = 0, thus selecting only features within the boundary region."}, {"section_title": "ADNI Results", "text": "For the ADNI dataset, we use 66 randomly selected individuals containing the segmentations of the left and right hippocampus in order to test the segmentation accuracy of different atlas selection methods. The atlas selection methods compared include: NMI-based method, the baseline method (HOG), and our proposed method (HOG+SVMRank). Segmentation accuracy is assessed by the Dice ratio. Figures 4, 5 and 6 show the average segmentation results in both hippocampi obtained by different selection methods using the label fusion methods MV, LWV and NLWV, respectively. Vertical axis shows the segmentation accuracy averaged over all queries in the 5 folds, and horizontal axis shows the number of atlases used. Regarding the different atlas selection methods, best results by our method are \u223c 2% better than best results by NMI for MV label fusion and \u223c 1% for both LWV and NLWV label fusions. Best results for NMI selection in all the label fusion modalities are achieved when using K 25 best atlases. Comparable results by our method are obtained using as few as K 7 best atlases, thus representing a considerable save in computation time on deploying both nonrigid image registration and label fusion.\nResults of the baseline method (green curves in Figures  4-6 ) clearly demonstrate that: (1) HOG features are more useful than image intensity in selecting the best atlases; and (2) our learning procedure for atlas selection can substantially improve the segmentation results by providing atlases which are more correlated with segmentation performance.\nIt is worth mentioning the decrease in performance experienced by MV after selecting a few best atlases. This is because, contrarily to other methods, in MV all atlases have the same importance for predicting the final label. This causes a negative impact as less significant atlases are progressively added after a few best atlases. On the other hand, weighted voting methods use patch similarity measurements in order to filter out poor contributions. Their behavior when using large number of atlases depends on their internal parameters and the number of atlases used, but their performance is more stable than MV.\nIn order to demonstrate that our scoring function targeted at the ground-truth Dice ratio generalizes well to other performance measurements, we compute the average surface distance errors (in mm) by the different atlas selection methods when using K = 23 atlases to segment the left and right hippocampi. The average surface distance errors obtained by HOG+SVMRank vs NMI are 0.4084 vs. 0.4693 (MV) ; 0.3728 vs. 0.4036 (LWV) ; and 0.3608 vs. 0.3819 (NLWV), respectively."}, {"section_title": "LONI Results", "text": "The LONI dataset contains 40 subjects with 56 manually labeled structures. We use the subset of L and R structures located in the cortical area in order to test different atlas selection methods. The structures used are: frontal gyrus, pre-central gyrus, orbitofrontal gyrus, post-central gyrus, parietal gyrus, occipital gyrus, temporal gyrus and parahippocampal gyrus. Figure 9 . Label fusion with non-local weighted voting NMI in 9, 11 and 10 out of the 16 structures for MV, LWV and NLWV label fusions, respectively. This compares favorably to the baseline method which only obtains significant improvement with respect to NMI in 2, 4 and 3 out of the 16 structures for MV, LWV and NLWV label fusions, respectively. The most significant improvement of our method with respect to the others has been obtained in the orbitofrontal, occipital and temporal gyri. In the precentral and postcentral gyri, the baseline method obtains similar results to the proposed method, suggesting that the learning part is not having any impact. In the parietal gyrus, however, neither the baseline or the proposed method gets any improvement with respect to NMI.\nConfirming what we observed in ADNI, the baseline method obtains intermediate results between NMI and the proposed method. Regarding the computational saving, the average proportion of atlases needed by our method in order to meet the best results by NMI are 40%, 64% and 42% for MV, LWV and NLWV label fusion, respectively."}, {"section_title": "Conclusion", "text": "We have presented a method aimed at selecting relevant atlases for multiple atlas segmentation. Our relevance score is related to the expected Dice ratio after non-rigid registration of an atlas and a target image. This measure is more related to segmentation accuracy than simple image similarity. We use a learning-based method in order to map the image features before non-rigid registration to our relevance score. In this way, we avoid the need for using the costly non-rigid registration prior to the selection step. Our method presents improvements with respect to NMI-based selection of \u223c 2% for MV label fusion and \u223c 1% for LWV and NLWV label fusions. Our method obtained significant improvement with respect to the NMI-based method in 11 and 10 out of the 16 structures from LONI, for LWV and NLWV label fusions, respectively. Selection by our method requires a third part of the atlases required by the NMIbased method in order to meet its best results. This considerably reduces the computational time required."}]