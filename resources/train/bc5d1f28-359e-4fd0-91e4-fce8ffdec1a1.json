[{"section_title": "Abstract", "text": "Abstract. Feature learning with high dimensional neuroimaging features has been explored for the applications on neurodegenerative diseases. Low-dimensional biomarkers, such as mental status test scores, gene variations, and protein changes in plasma and cerebrospinal fluid level, are essential in clinical diagnosis of neurological disorders, because they could be simple and effective for the clinicians to assess the disorder's progression and severity. Rather than only using the lowdimensional biomarkers as inputs for decision making systems, we believe that such low-dimensional biomarkers can be used for enhancing the feature learning pipeline. In this study, we proposed a novel feature representation learning framework, Multi-Phase Feature Representation (MPFR), with low-dimensional biomarkers embedded. MPFR learns high-level neuroimaging features by extracting the associations between the low-dimensional biomarkers and the high-dimensional neuroimaging features with a deep neural network. We validated the proposed framework using the Mini-Mental-State-Examination (MMSE) scores as a low-dimensional biomarker and multi-modal neuroimaging data as the high-dimensional neuroimaging features from the ADNI baseline cohort. The proposed approach outperformed the original neural network in both binary and ternary Alzheimer's disease classification tasks."}, {"section_title": "Introduction", "text": "To aid the clinical decision making, feature learning methods have been applied on learning the correlations between the high dimensional features extracted from neuroimaging data recently [1, 2, 3] . Low-dimensional biomarkers, such as the Mini-Mental-State-Examination (MMSE) and the cerebrospinal fluid measurements (CSF), are known as supportive diagnostic tools for clinic diagnosis of brain diseases, accompanied with the high-dimensional neuroimaging biomarkers, such as Magnetic Resonance Image (MRI) and Poistron Emission Tomography (PET). However unlike the application of high-dimensional neuroimaging biomarkers [4, 5, 6, 7, 8, 9, 10, 11, 12] , they have not been sufficiently explored in current machine learning based feature representation methods. There have been studies using the low-dimensional biomarkers, such as CSF, as input features for machine learner [13] . However, low-dimensional biomarkers might not be equally sensitive to the cognitive impairment as high-dimensional biomarkers and can be easily overwhelmed when they are fed into the machine learner together. Whereas, other studies attempted to predict low-dimensional clinic assessments, such as Alzheimer's Disease Assessment Scale-Cognitive Subscale (ADAS-Cog), by building the joint regression models with inputs selected from both highdimensional and low-dimensional biomarkers [14, 15] . However, these methods require the subjects to have paired clinical scores and imaging data, which may lead to shrinkage of training dataset, because of the extra expense on data collection.\nIn an attempt to solve the above-mentioned problems, we proposed a MultiPhase Feature Representation (MPFR) framework that have low-dimensional biomarkers embedded in the feature representation learning rather than directly using them as features. MPFR learns the features by assessing the associations between the low-dimensional biomarkers and the high-dimensional biomarkers based on a deep neural network consisting of stacked auto-encoders (SAE), linear regression and softmax regression. The feature representation network is optimised to estimate the low-dimensional biomarkers before it is finally used for classification. The prominent advantage of the proposed framework is the separation of different training phases. Thus, it does not require every training instance to be attached with a diagnostic label nor low-dimensional biomarkers. In addition, the low-dimensional biomarkers will not be overwhelmed by the high-dimensional biomarkers. We validated the proposed framework with the performance of Alzheimer's Disease (AD) diagnosis with 3 groups from the ADNI cohort and selected the MMSE scores as the low-dimensional biomarkers for feature learning. We modelled the AD diagnosis as a classification problem with 3 classes, including Normal Control (NC), Mild Cognitive Impairment (MCI) and AD. These learnt features revealed the associations between MMSE and the neuroimaging patterns and outperformed the features extracted by the state-of-the-art methods as well as conventional deep-learning-based methods without MPFR in both binary and ternary classification tasks."}, {"section_title": "Multi-Phase Feature Representation", "text": "There are three phases of MPFR framework, as shown in Fig. 1 . Phase A depicts the unsupervised layer-wised pre-training of the feature representation network which learns a manifold to reconstruct the features at the previous layer. The parameters of the auto-encoders learned by Phase A are unfolded and stacked in Phase B. In Phase B, the feature representation network is enhanced by training to output the low-dimensional features. The outputs of Phase B are the low-dimensional biomarkers estimated with the extracted high-level features. In Phase C, after replacing the output layer with softmax regression, the entire structure is finally fine-tuned for the purpose of classification. The learnt features in Phase C are expected to be more sensitive to the training labels since the hidden layers could learn high-level disorder-specific features."}, {"section_title": "Phase A: Pre-Training Stacked Auto-encoders (SAE) with Neuroimaging Biomarkers", "text": "The biomarkers extracted from brain images, such as MRI and PET, are initially used as the inputs for the feature representation learner. They are fed into a multi-layered neural network with non-linear activation function. Each hidden layer of the neural net is seen as a higher level of representation of the previous layer. To obtain high-level features that can represent the original inputs, we used stacked autoencoders (SAE) to form the hidden layers of the neural network. The feature representations can be computed by feed-forwarding the activation signals with sigmoid function S(x) = 1 1+e \u2212x . The parameters of each auto-encoder are optimised to reconstruct the previous input a l\u22121 . The optimisation criterion is to minimise the representation loss:\nwhere h(W, b, x) is the reconstruction yielded from the auto-encoder; x is the input vector of the auto-encoder; W and b are the weight and bias parameters to be trained; the second term is the weight decay to control over-fitting. Gradient descent based algorithms, such as L-BFGS algorithm [16] , can be applied to train auto-encoders, following the greedy layer-wised training strategy by training each hidden layer at once (Phase A in Fig. 1 ) [17] . To fully extract the synergy between different image modalities, we zero-masked a small proportion of feature parameters from one single modality randomly when training the first hidden layer [18] ."}, {"section_title": "Phase B: Feature Representation Optimisation with Low-Dimensional Biomarkers", "text": "Before using the pre-trained network for the classification, the hidden layers are firstly fine-tuned to estimate continuous low-dimensional biomarkers. The network is also expected to extract the correlations between image biomarkers and the low-dimensional biomarkers. For example, if MMSE is chosen to be estimated, the features provided by the fine-tuned feature representation network can be sensitive to the cognitive status of subjects as well as the risk of being diagnosed as AD. However, by observing (a) and (b) in Fig. 2 , it is also obvious that neuroimaging data are expected to be more sensitive to the cognitive impairment. Linear regression is used to estimate the low-dimensional biomarkers. One output layer with linear activation filter is stacked on the top of the pre-trained SAE (Phase B in Fig. 1) . The prediction can be demonstrated as\nwhere h(W, a (l) ) is the vector of the estimated low-dimensional biomarkers; a\nis the l-th layer of high-level features obtained from the pre-trained SAE; W and b are the parameters that can be optimised by jointly propagating the error gradients. Since Phase B is designed for augmenting the feature learning network, early stopping is applied in Phase B training to control the over-fitting on the low-dimensional biomarkers in the training set."}, {"section_title": "Phase C: Classification with AD Labels", "text": "The trained linear regression layer is replaced with a softmax regression output layer (Phase C in Fig. 1 ). The softmax layer uses a different activation function, which might introduce non-linearity different from the sigmoid function in SAE:\nwhere a is the feature vector obtained by the fine-tuned SAE. Y is assigned to possible stages of a particular disease, such as NC, MCI and AD of AD progression. The prediction P (Y = i|x) with the highest probability is chosen as the final decision. The network is then fine-tuned by back-propagating the classification loss with the pre-labelled training subjects as a supervised classification neural network."}, {"section_title": "Experiments", "text": ""}, {"section_title": "Data Acquisition and Feature Extraction", "text": "The dataset used in this study was acquired from the ADNI database [20] . We selected 331 subjects from the ADNI baseline cohort, including 77 NC-, 169 MCI- are slices and MAPER whole brain mask models from ADNI baseline cohort, generated using 3D Slicer 4.3.1 [19] . The neuroimaging data contains more information than MMSE. Some sophisticated features, such as ventricle sizes and atrophy, cannot be captured by MMSE, but can be shown in neuroimaging data.\nand 85 AD-subjects. For each subject, an FDG-PET image and a T1-weighted volume acquired on a 1.5 Tesla MR scanner were retrieved. All the 3D MRI and PET data were registered following the ADNI image correction protocols [20, 21] . The PET images were align to the corresponding MRI image using FSL FLIRT [22] . The MRI images were then non-linearly registered to the ICBM 152 template [23] with 83 functional regions using the Image Registration Toolkit (IRTK) [24] . The outputted registration coefficients of MRI images were used to aligned PET images into the ICBM 152 template. Finally, all registered MRI and PET image were mapped to brain functional regions using the multi-atlas propagation with MAPER approach [25] . Three types of features were extracted from each of the brain regions, including the grey matter volume [25, 26, 27] , solidity [10, 28, 29] features from MRI data, and the cerebral metabolic rate of glucose consumption (CMRGlc) from PET data [7, 30] . Elastic Net [31, 32, 33] was applied to choose the most predictive dimensions of features. 85 feature parameters were eventually selected for each subject evaluated in this study."}, {"section_title": "Performance Evaluation", "text": "The performance on AD diagnosis of the proposed MPFR framework was compared to the state-of-the-art work-flow with multi-kernel SVM (MKSVM) [13] and the conventional deep learning method without embedding MPFR. We chose MMSE scores of patients in the training set to evaluate MPFR in this study, because the variation between the NC/MCI groups and the AD group is obvious ( Fig. 2-a) . All of the experiments were evaluated with the same features extracted from MRI images and PET images. MKSVM was implemented using LIBSVM library with the radial basis function (RBF) kernel [34] . We applied the 'one against all' approach to allow MKSVM to perform the trinary classification problem [35] . The proposed deep learning framework was implemented on Matlab 2013b. The approximated random search strategy was applied to choose the hyper-parameters [36] .\nWe used 10-fold cross-validation to evaluate different learning structures. For each fold of cross validation, about 90% subjects were collected for training (including the pre-training, feature optimisation and classification training) and the rest subjects were used for testing. In the experiments of the MPFR framework, the MMSE scores of the testing set were neglected."}, {"section_title": "Results", "text": "The examination of the high-level features is displayed in Fig 3. Comparing the features learnt with 2 different phases, it is clear that the Phase A only extracted features that represented the neuroimaging data. After Phase B, some dimensions of the learnt features showed variations along the progression of AD.\nIn Phase B, by comparing the different AD stages, most of high-level features at layer 1 tend to vary according to the severity of AD. Whereas only few dimensions of high-level features at layer 2 showed remarkable variance. It is reasonable to assume that after the Phase B of MPFR, the higher layers may tend to extract more abstract patterns by flatting the local variations. The performance of the binary classification between NC and AD is displayed in Table 1 . The proposed method outperformed the conventional SAE in both precisions of classifying NC and AD. It also achieved the highest overall accuracy (90.11%) and specificity (93.98%) among the other two methods. The higher sensitivity achieved by MKSVM (89.09%) can be attributed to the limitation on the quantity of the available training data. Parametric models such as SAE and the proposed method tend to have higher standard deviation than non-parametric models like SVM. However, it is notable that the proposed method performed lower standard deviation than SAE. Table 2 shows the performance of trinery classification, including NC, MCI and AD, which was designed for evaluating the effects on the early detection of AD. The proposed method outperformed the conventional SAE and MKSVM in the overall accuracy (59.19%) and the overall sensitivity (50.98%). It is reasonable to convince that the enhancements of classification performance, comparing to the conventional SAE, were primarily benefited from the robust high-level features learnt with MPFR. "}, {"section_title": "Conclusions", "text": "In this study, we presented a novel framework, the Multi-Phase Feature Representation (MPFR), for the feature representation of neuroimaging data. It differs between the conventional deep learning architecture by learning features to output low-dimensional biomarkers before the deep network is fine-tuned with classification labels. The preliminary results showed that MPFR framework outperformed SAE as well as the state-of-the-art classification method (Multi-Kernel SVM) and had a great potential to embed other low-dimensional biomarkers in feature representation learning without constraining the size of available training data."}]