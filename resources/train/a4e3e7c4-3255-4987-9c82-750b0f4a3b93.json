[{"section_title": "Abstract", "text": "We study possible relations between Alzheimer's disease progression and the structure of the connectome which is white matter connecting different regions of the brain. Regression models in covariates including age, gender, and disease status for the extent of white matter connecting each pair of regions of the brain are proposed. Subject inhomogeneity is also incorporated in the model through random effects with an unknown distribution. As there is a large number of pairs of regions, we also adopt a dimension reduction technique through graphon (Lov\u00e1sz and Szegedy (2006)) functions, which reduces the functions of pairs of regions to functions of regions. The connecting graphon functions are considered unknown but assumed smoothness allows putting priors of low complexity on these functions. We pursue a nonparametric Bayesian approach by assigning a Dirichlet process scale mixture of zero to mean normal prior on the distributions of the random effects and finite random series of tensor products of B-splines priors on the underlying graphon functions. Markov chain Monte Carlo techniques, for drawing samples for the posterior distributions, are developed. The proposed Bayesian method overwhelmingly outperforms a competing method based on ANCOVA models in the simulation setup. The proposed Bayesian approach is applied on a dataset of 100 subjects and 83 brain regions and key regions implicated in the changing connectome are identified."}, {"section_title": "", "text": "1. Introduction. Alzheimer's disease (AD) is a neurodegenerative disorder that affects approximately 5 million people in the US and 30 million people worldwide, with incidence increasing with age. There is no available treatment which modifies the disease once symptoms of cognitive impairment or dementia are clinically apparent (Ferri et al., 2005) . Current thought is that detecting pathologic changes in the brain before the development of clinical symptoms will allow for successful treatment. It has been observed that the white matter connections between regions of the brain that are vital for brain's functioning are affected in Alzheimer's disease. In particular, the changes in white matter are correlated with amyloid plaque burden, which is one of the pathological hallmarks of the AD and has been shown to become elevated years before the onset of clinical symptoms (Prescott et al., 2014) . It may be that these structural connections are part of the anatomic substrate underlying cognition. In this paper, we model changes in the brain connectome caused by the onset of the disease using a graphical structure.\nOur study is performed using data obtained by Alzheimer's Disease Neuroimaging Initiative (ADNI \u2212 adni.loni.usc.edu). Using T1-weighted magnetic resonance (MR) images from ADNI, the cortex of the brain is divided into several regions using a standard anatomic atlas. These regions are connected by white matter fibers, identified using diffusion tensor imaging (DTI) MR. The data used in this study were from the ADNI 2 study and included all subjects with diffusion-weighted imaging as of November 2012. Readers can be referred to the Materials and Methods section of Prescott et al. (2014) for details of MR image acquisition and processing. The graphical representation of these white matter connections between cortical regions is referred to as the connectome. It is thought that some of these connections between brain regions become weakened over time due to the AD. Some other factors like age or sex might also affect the connectome, as well as subject-specific random effects. We model the connectome using graph-theoretic metrics, accounting for patients' specific effects and implement a Bayesian analysis.\nHere, we consider a connectome with 83 cortical regions in the brain. Mathematically, the connectome can be viewed as a graph (V, E), where V denotes the set of nodes or vertices standing for brain regions and E for the edges between pairs of vertices whenever present. As in a graphical model, edges are marked with certain measurements. In our context, the measurements consist of observing the presence or absence of white matter fibers connecting two regions, the number of white matter fiber and the mean length of white matter fibers between them. Our aim is to identify the significant pairs of regions corresponding to different covariates in the connectome. The aspects of the presence of a connection, the number of connections and the mean length are modeled respectively by a binary regression model with a probit link, a Poisson regression model with an exponential link and a normal regression model. Interactions of covariates with pairs of regions are considered. Because the number of region-pairs is prohibitively high, it leads to a very high dimensional regression model if a naive approach is taken. Hence we use a dimension reduction technique that introduces a latent variable for each region and expresses functions of region-pairs in terms of a single smooth unknown function of each pair of latent variables as in a graphon model (Lov\u00e1sz and Szegedy (2006) ). If (a jk : j, k = 1, . . . , J) is an array of parameters, then we model a jk = g(u j , u k ), where u 1 , . . . , u J are latent variables and g is a function of two arguments. Symmetry of the matrix ((a jk )) is respected if g is symmetric in its arguments. The original motivation for this representation is that if a jk , j, k = 1, . . . , J are random variables such that the matrix ((a jk )) is distributionally invariant under permutations of rows and columns, then a jk = g(u j , u k ) for some latent variables u 1 , . . . , u J that can be assumed to be uniformly distributed and for a function g, to be called a graphon function. In the present context, if the parameters a jk , j, k = 1, . . . , J are treated as random, then such row and column wise exchangeability conditions are natural non-informativeness conditions. Given the graphon function, thus the strength of connections is determined by only 83 latent variables linked with each region instead of being 83 2 = 3486 making huge computational savings. The graphon function is also treated as an unknown without any specific parametric form and is nonparametrically estimated from the data. More specifically, we put a finite random series prior based on tensor products of B-splines, where the coefficients are given appropriate prior distributions. Finite random series priors are widely used in the literature to construct priors on various functions and are systematically studied, for instance, in Shen and Ghosal (2015) , but it seems to have not been used before for putting prior distributions on graphon functions. The assumed smoothness of the graphon function helps keep the number of basis function required for the basis expansion relatively small. This is because to approximate a function in [0, 1] d of smoothness index f by a finite series within accuracy , one needs to use only O( \u2212d/f ) many elements of standard bases like polynomials, B-splines or wavelets, that is fewer functions are needed for smoother functions. The proposed Bayesian procedure can be shown to lead to consistent posterior, in the setting where the number regions remain fixed but the number of subjects increases to infinity. The result goes beyond the particular application we are addressing in the present paper. Although the proof uses the standard hypothesis testing and prior positivity of Kullback-Leibler neighborhoods approach developed by Schwartz, our major technical contribution is the construction of exponentially consistent tests for random effects in a Poisson regression model, along with weakening conditions on the predictor variables to include a larger variety of applications. Details on posterior consistency are shown in the supplementary material.\nThe rest of the paper is organized as follows. In the next section, we describe the details of modeling the connectome dataset from ADNI. In Section 3, we describe the prior construction and develop posterior computing techniques. A simulation study comparing the proposed Bayesian procedure with ANCOVA-based ones is conducted in Section 4. The real data on connectome from ADNI is analyzed in Section 5. Finally Section 6 ends with some concluding remarks.\n2. Data description and modeling. Data used in the preparation of this article were obtained from the Alzheimers Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimers disease (AD). Here, we examine if the connectome can be used as a biomarker. In the ADNI dataset on connectome, the brain is divided into J = 83 regions. For each pair of brain regions, the number of white matter fibers between them and their average lengths is obtained. The data is obtained for n = 100 subjects, for whom information regarding disease prognosis, sex and age are also available. For many edges, the mean lengths are not defined where there are no white matter fibers. There are three disease prognosis states, Alzheimer (AD), mild cognitive impairment (MCI) and no cognitive impairment (NC).\nExcept for age, the other two covariates, sex and disease prognosis, are categorical. Since disease prognosis has three possible states, we introduce dummy variables Z MCI and Z AD respectively standing for the onset of MCI and AD, setting NC at the baseline. Similarly, the dummy variable Z M indicating male gender is introduced setting females at the baseline. Let Z = (Z MCI , Z AD , Z M , Age) stand for the whole vector of covariates and Z i stand for its value for the ith subject. Let N ijk stand for the number of white matter fiber connecting brain regions j and k in the ith subject, and L ijk the mean length of such fibers, provided that N ijk \u2265 1. In ADNI dataset, there were no missing values in N ijk or L ijk . Some of the covariates were missing. Any categorical missing covariate (i.e. disease state or sex) value is replaced by its mode and for the continuous covariate age, missing values are replaced by the mean age over all subjects. It seems natural to consider a Poisson model for the counts of fibers connecting two regions in a subject. However, as shown in Figure 1 , the proportions of connected edges among individuals are between 10% to 30%. Thus, the abundance of zero connections makes the Poisson model somewhat inappropriate. We overcome the problem by considering a zero-inflated Poisson model, by boosting the probability of zero through a binary latent variable \u039e ijk with parameter \u03a6(\u03c0 ijk ), where \u03a6 stands for the standard normal distribution function and \u03c0 ijk is a real-valued parameter. If \u039e ijk = 0, then N ijk is set at zero, while if \u039e ijk = 1, the number of connections N ijk is assumed to be Poisson distributed with some positive mean e \u03bb ijk . Note that in our formulation \u039e ijk is not completely identifiable since the value N ijk = 0 is compatible with both possible values of \u039e ijk . If N ijk \u2265 1, we assume that the mean fiber length, in the logarithmic scale, is normally distributed with some mean \u00b5 ijk , and variance \u03c3 2 /N ijk for some unknown \u03c3 > 0. The heuristic justification of the choice of the variance \u03c3 2 /N ijk stems from the fact that L ijk is an average of N ijk (independent) variables and should be approximately normal with variance inversely proportional to the number N ijk of averaging variables. Since fiber lengths are positive, the model seems to fit the data better in the logarithmic scale, and the heuristics for the choice of the variance extends to the logarithmic scale by the delta method, at least when N ijk is large. Thus we can represent the data generating process as\nA simple analysis of covariance (ANCOVA)-type model can be formulated to describe linear effects of the covariates Z i on each unrestricted parameter \u03c0 ijk , \u03bb ijk and \u00b5 ijk for each pair of brain regions (j, k):\nwhere ((\u00b5 0 )) j,k , ((\u03c0 0 )) j,k and ((\u03bb 0 )) j,k are baseline values of \u00b5 ijk , \u03c0 ijk and \u03bb ijk respectively for covariate value Z i = 0. Let\nbe regression coefficients for the average length, connection probability and number of connections respectively and ((.)) j,k denote (j, k) th element of a matrix, and \u03b7 i = (\u03b7 1i , \u03b7 2i , \u03b7 3i ) , i = 1, . . . , n, be independent random effects of the ith subject distributed according to an unknown common distribution. It may be noted that the normal distribution function \u03a6 and the exponential function are used respectively as link functions for binary and Poisson regression. For the latter, the exponential link is almost a universal choice, while for binary regression both logistic and probit (i.e. \u03a6) links are commonly used and usually give similar results. Our preference for the probit link is due to its computational advantage in a Gibbs sampling scheme for Bayesian computation, through a data-augmentation technique (see Albert and Chib (1993) ).\nFor a preliminary analysis, we fit the model using a generalized heteroscedastic ANCOVA, ignoring the zero-inflation aspect and the random effects in the model. The model thus has 3 \u00d7 83 2 = 10458 parameters and 34860 observations of mean length and number of white matter fibers corresponding to 100 subjects and 3486 potential edges between different brain regions. We observed that for several edges (j, k), the maximum likelihood method failed to give estimates of either \u00b5 0,jk or \u03c7 jk . For the Poisson regression, the glm function in R did not converge for several pairs (j, k). This is due to too few observations. Thus it suggests using a dimension reduction of the parameter space through further modeling if we want to conduct an edge-wise analysis. The dimension reduction also helps with computation and gives easy interpretability of the results.\nSince the parameters are indexed by edges, a substantial reduction of dimension will be possible if these can be viewed as arising from some latent characteristics of nodes through some fixed but unknown function. This can be motivated from exchangeability considerations. In the absence of initial information about connections between regions, exchangeability seems to be an appealing assumption. By a well known representation theorem of exchangeable random graphs (c.f. Aldous (1981) , Hoover (1979) ), a function of edge (j, k) can then be represented as f (\u03be i , \u03be j ) where \u03be i , for each node i is a latent variable independently and identically distributed and f is a fixed function, called a graphon, irrespective of the size of the network. Assuming that the function f is sufficiently smooth, a basis expansion can approximate it using only a fewer terms. Thus the graphon technique in our context will be able to reduce a parameter array of size 83 2 = 3486 to only a parameter vector of size 83 + K, where K is the number of parameters used to approximate the unknown smooth graphon function. Typically a modest number of terms suffices for well-behaved functions using standard bases such as B-splines or polynomials. As a result, a substantial dimension reduction is possible through the graphon technique. This leads to modeling the arrays of baseline values and regression coefficient as\nwhere, with an abuse of notations, \u00b5, \u03c0, \u03bb, \u03c7 MCI , \u03c7 AD , \u03c7 M , \u03c7 Age , \u03b2 MCI , \u03b2 AD , \u03b2 M , \u03b2 Age , \u03bb MCI , \u03bb AD , \u03bb M and \u03bb Age are smooth functions on the unit square [0, 1] 2 and symmetric in their arguments, and \u03be 1 , . . . , \u03be J and \u03b4 1 , . . . , \u03b4 J are latent variables taking values in the unit interval. The reason for choosing two separate sets of latent variables \u03be and \u03b4 is to distinguish between fixed and main effects.\n3. Prior specification and posterior computation.\n3.1. Prior specification. To proceed with a nonparametric Bayesian analysis, we put prior distributions on the smooth functions appearing in the graphon representation through basis expansion in tensor products of Bsplines, and on the coefficients of the basis expansion. The coefficients can be arranged in the form of a square matrix. The symmetry of the matrices of coefficients ensures symmetry of the resulting functions in its arguments as required by graphon functions. Given other sets of parameters and values of the random effects, (independent) normal prior on the coefficients of the tensor products of B-splines will lead to conjugacy in the normal regression model for the length, allowing a simple and fast posterior updating rule. In the binary regression model for the connection probability, normal prior still leads to conjugacy using the data augmentation technique of Albert and Chib (1993) . Since no conjugacy is possible for the Poisson regression for the number of connections, Metropolis-Hastings algorithm is applied. Alternatively, adaptive rejection sampling can be applied to obtain posterior updates. On the distribution G of the random effects, we put a Dirichlet process scale mixture of zero mean normal prior (see Chapter 5 of Ghosal and van der Vaart (2017) and West (1987) for scale mixture of normal). The histogram plot of Figure 1 as well as Figure 1 from the supplementary materials motivate us that the distributions of random effects are symmetric but non-normal.\nMore specifically, the prior can be completely described by the following set of relations:\n(i) Graphon functions:\nand for l = MCI, AD, M,\nwhere \u03b8 t,mm = \u03b8 t,m m for all t = 1, 2, 3, and \u03b3 tl,mm = \u03b3 t,m m for all t = 1, 2, 3, l = MCI, AD, M, and that (a) graphon coefficients: For some chosen a > 0,\n(b) latent variables:\nhere Un stands for the uniform distribution.\n(ii) Random effects distribution: For t = 1, 2, 3 and i = 1, . . . , n,\nwhere DP stands for the Dirichlet process, IG for the inverse-gamma distribution and the precision parameter \u03b1 t of the Dirichlet process is given a gamma prior \u03b1 t \u223c Ga(c 1 , c 2 ). (iii) Error variance:\n3.2. Posterior updating. Introduce a latent variable I j the indicator of the Un(0,1) component of the distribution of \u03b4 j , j = 1, . . . , J. Now the conditional log-likelihood is given by\nwhere C involes only hyperparameters a, M, K, b 1 , b 2 , c 1 , c 2 , d 1 , d 2 , q and the observations, but not the parameters of the model. Detailed calculations of all the posterior updates are shown in the supplementary material.\n3.3. Tuning. In the above Metropolis-Hastings steps, we need to tune s 3 , s 31 , s 32 , s 33 , B 1 , B 2 and s 3\u03b7 (these are defined in the supplementary material) to achieve acceptance rates in the range of 25% to 45%. We automatically adjust for the variance of the normal proposal distribution and the shape parameter of proposal beta distribution to maintain an acceptance rate in the range of 25% to 45% after every 500 iterations. The standard deviations are reduced (respectively, increased) to increase (respectively, to reduce) the acceptance rate of the Metropolis-Hastings moves. On the other hand, B 1 and B 2 are increased (respectively, reduced) to increase (respectively, to reduce) the acceptance rate of the corresponding parameters. If U j = 0.5, update will be same as the current value. So, the distribution of U j should have a high concentration at 0.5 to make a local move from the current state. A higher value of B will induce a proposed move in the close vicinity of the original position while a smaller value will lead to a proposed move to a farther location. Tuning the values of B 1 and B 2 can help maintain a desirable proportion of accepted moves. The number of B-spline basis functions (K) is tuned via a grid search over a sequence of values in the range 7-20. For each possible values of K, we generate 10 sets of latent variables. For each set of latent variables, we can fit a simple linear regression to estimates the B-spine coefficients and calculate average the Akaike Information Criterion (AIC) over all the sets of latent variables. Based on these AIC values, we pick the K with the lowest AIC value or the smallest value after which there is not much improvement in the AIC."}, {"section_title": "Simulation.", "text": "In this section, we study the performance of the proposed Bayesian method in comparison with ANCOVA. For computational simplicity, we do not consider the random effects in the data generating process as well as in the model, that is, we consider the following analog of (1):\nWe consider n = 50, 100, 200, 500, 1000, 2000 subjects for data generation with J = 20 nodes.\nData generation:\nThe true matrices are generated as follows with l,jk = (e l,jk + e l,kj )/2 and e jk \u223cN(0, ( \u221a 0.05) 2 ) for l = 1, . . . , 15,\nIf \u039e ijk is generated as zero, the edge (j, k) of i th individual will be missing. The generated data based on these functions have similar missingness compared to the real data. We add the error component along with the functional values to deviate it a little bit from an exact functional form. We have performed 50 replications for each case. We collect 5000 MCMC samples after burning in 5000 initial samples to draw the inference.\nChoice of the hyperparameters: We choose the hyperparameters a = 10, M = 10, b 1 = b 2 = 0.1 and c 1 = c 2 = 10 in (5). We take 7 B-spline basis functions based on the AIC values over a grid of possible number of Bspline basis functions. For all the simulated datasets, it always produces the optimal number as 7 as the number of nodes is fixed at 20.\nFor the ANCOVA based estimation, we use the weighted least squares technique for the normal model and the generalized linear regression for a Poisson regression model with the exponential link function.\nWe present a comparative plot of squared bias, variance, and MSE of the estimates across different sample sizes in Figure 3 for small sample sizes and Figure 4 for large sample sizes. For the largest sample size 2000, Table 1 contains bias square and variance values for both of the two methods. The bias square and variances of the estimated matrices are calculated after averaging over bias square and variances of the individual entries. In the case of ANCOVA, there are several missing values in the estimates of these matrices. Thus the bias square and variances cannot be calculated at those entries. Thus these are calculated by averaging over only the available ones.\nIn Figure 2 , we see that the proposed Bayesian method identifies the true structure for most of the cases. For some cases, it captures the structure but the color levels are different. Usually, the differences are very small as can be observed in Table 1 . But for ANCOVA, even for a sample size as large as 2000, it could not capture the true structures. Figure 3 suggests that bias squares and variances of ANCOVA estimates are not decreasing as sample size increases for small sizes. But there is another factor here in case of small sample sizes. As sample size increases the number of missing values in the estimate goes down. Thus more parameters could be estimated. For larger sample sizes also more parameters become estimable as sample size increases, but this change is not huge. Thus for larger sample sizes, bias square and variance of the ANCOVA estimates are decreasing. From Figure 4 , we can also conclude that the proposed Bayesian method performs much better than ANCOVA by a huge margin for sample sizes as large as 500, 1000 or 2000. This is evident from the Table 1 where bias square values are around 40 times better and variances are 300 times better for the Bayesian estimates than ANCOVA. It may be recalled that estimation by the Bayesian method is consistent."}, {"section_title": "Real data analysis.", "text": "We analyze a real dataset of 100 individuals, collected from ADNI. A demographic summary of the data is provided in Table 2 . In disease categories, we have fewer female than male. The baseline subject is a female subject of the average age of 73.9 with no cognitive impairment. In Figure 5 , we show that a total number of connected edges and the total length of the fibers vary with gender, disease state, and age. We can see that these distributions are different between male and female. Also, the individuals with Alzheimer's disease seem to have more short-range connections. 5.1. Modeling. As described in the Section 3, we first generate 10 sets of latent variables for \u03be and \u03b4. Then we model the graphon functions with 7 to 20 B-spline basis functions and calculate AIC values using standard R packages for linear and generalized linear regressions given each set of latent variables. After that, we take the average of the AIC values for each case of a number of B-spline basis functions. After comparing these average AIC values, 13 B-spline basis functions are considered for the graphon functions in estimation for the real data. Other hyperparameters are kept the same as the simulation i.e. a = 10, M = 10, b 1 = b 2 = 0.1 and c 1 = c 2 = 10. We collect total 10000 MCMC samples. Out of those 5000 are postburn samples are collected after burning in the first 5000 samples. We perform a test of significance for each edge by checking if zero is included in the 95% credible region, constructed from the postburn samples. After that, we rank those by calculating the probability of greater than zero or less than zero depending on whether zero is in the left tail or right tail of the empirical distribution, constructed from the postburn samples. This can be used as an alternative for the p-value in frequentist setup. If this comparison is inconclusive, that is we get zero as the probability, we then compare the lengths of the credible sets. Shorter the length, more significant is that edge. This is because a shorter length would suggest more concentration of the posterior distribution around the posterior mean. All of the estimated effects of the covariates for the top ten significant edges are negative for the connection probability i.e. the probit regression part of the model as in Table 5 to 8 in the supplementary material. For the number of connection, the estimated effects corresponding to AD, gender, and age are mostly negative in their corresponding top ten edges. Some estimated effects corresponding to MCI are also negative. These results can be found in Table 9 to 12 in the supplementary materials. For edge-length, all the estimated effects corresponding to gender and age are negative among the top ten significant edges in Table  3 to 4 in the supplementary materials. Some estimated effects of MCI and AD are negative in their corresponding top ten significant edges as in the first two tables of the supplementary materials.\nSignificant edges are plotted for each parameter of interest. The circles are the different regions and their names are mentioned in the legend. These plots are in 6, 7 and 8. We find that for each part of the model i.e. mean connection length, a number of connections and the binary variable signifying the presence or absence of connection, there are separate sets of regions that have the most number of significant edges, connected with them. In supplementary materials part, there are tables, containing top 10 significant edges for each covariate.\nThere are some regions that have many connected edges in these plots like insula, pallidum, inferior temporal, parsorbital, precentral, posterior cingulate, superior temporal, superior parietal, middle temporal, paracentral, caudal middle frontal etc. These regions seem to be the most significant ones as these have many connected significant edges. In some of the previous studies on Alzheimer's disease, they were mentioned. Some of those are mentioned in Section 6. 6. Conclusions and discussion. We study the effects of some common measurable covariates on the human brain connectome. Our work extends statistical inference on graph structure from the two sample problem (Tang et al. (2017) ) to a more general regression modeling framework. We propose regression models to explain the extent of connections between different cortical brain regions. In this setup, traditional techniques of separately regressing connections, between each pair of regions and the covariates are not appropriate due to missingness at several edges of the connectome. We solve this problem by using graphon functions to reduce the dimension of the parameter space through a fewer number of fundamental parameters and develop a Bayesian method to estimate those. Subject inhomogeneity is incorporated through random effects and the distributions of the random effects are estimated by using Dirichlet process scale mixture of normal (DPSMN) prior. Figure 2 suggests that our Bayesian method identifies the true structure for all the cases in the simulation setting. ANCOVA could not capture the true structures even when the sample size is as large as 2000. Figure 3 suggests that the small sample performance of ANCOVA is poor. The variance of the ANCOVA estimate is the key issue here. Even for large sample sizes, we conclude that the proposed Bayesian method performs better than ANCOVA as shown in Figure 4 .\nThe regions that have many connected edges are summarized here. We also cite next to each region's name previous literature that studied those regions in the context of Alzheimer's disease or dementia and found significant. These regions are insula (Bonthius, Solodkin and Van Hoesen, 2005) , precuneus (Karas et al., 2007; Klaassens et al., 2017) , pallidum (Leh\u00e9ricy et al., 1991) , inferior temporal (Scheff et al., 2011), parsorbital (McLimans and Willette, 2016) , precentral (Canu et al., 2011) , posteriorcingulate (Leech and Sharp, 2013) , superior temporal (Gao et al., 2018) , superior parietal (Migliaccio et al., 2015) , middle temporal (Jack et al., 1998) , paracentral (Karavasilis et al., 2017) and caudal middle frontal (Bakkour et al., 2013) .\nThe greater magnitude of the negative effect on a number of white matter fiber connections between regions for AD subjects than for MCI subjects suggests that white matter connectivity is progressively degraded by lost connections across the clinical spectrum of dementia. In the current analysis, the most significant relationships between a number of white matter connections and MCI or AD status are among widely distributed regions of the brain. In particular, they include connections between regions in the right hemisphere and left hemisphere. They also predominantly involve the frontal, temporal and parietal lobes, and the cingulate cortex. These regions are generally involved with the widespread damage associated with the AD.\nThe preferential loss of \"long-range\" fibers (i.e., fibers between the cerebral hemispheres) in these widely distributed regions corresponds with prior work which has demonstrated that long-range connections become degraded with progression along the AD spectrum, leaving highly connected and shortrange \"hub\" networks relatively intact until late in the disease course (Gao et al., 2014; Sanz-Arigita et al., 2010) ."}]