[{"section_title": "1", "text": ""}, {"section_title": "Introduction", "text": "This report provides a first look at selected findings from the 2004/09 Beginning Postsecondary Students Longitudinal Study (BPS:04/09). It is based on data describing a nationally representative sample of undergraduates who entered postsecondary education for the first time during the 2003-04 academic year. BPS:04/09 covers the experiences of these first-time beginners over a period of 6 academic years, from 2003-04 to 2008-09, and provides information about the rates at which students completed degrees or certificates, transferred to other institutions, and left postsecondary education without attaining degrees or certificates."}, {"section_title": "The BPS:04/09 Data Collection", "text": "The first-time beginning students in the BPS:04/09 study were identified in the 2003-04 National Postsecondary Student Aid Study (NPSAS:04). NPSAS:04 is a nationally representative sample of about 90,000 undergraduate, graduate, and firstprofessional students in about 1,600 postsecondary institutions in the 50 states, the District of Columbia, and Puerto Rico who are eligible to participate in federal Title IV student aid programs. Approximately 19,000 respondents were identified in the NPSAS:04 survey as first-time beginning postsecondary students and became the sample for the BPS:04/09 longitudinal study. While the NPSAS:04 study sample represents the approximately 19 million undergraduates enrolled in 2003-04, the BPS:04/09 study sample represents the approximately 4 million undergraduates who were first-time postsecondary beginners in 2003-04. The first-time beginners in the BPS:04/09 study were interviewed three times: in 2004, at the end of their first year in postsecondary education; in 2006, 3 years after they had started in postsecondary education; and in 2009, 6 years after they had started. In 2004, they were interviewed about a variety of subjects, including their academic and social experiences during the first year, their work while enrolled, their education plans and long-term goals, their demographic characteristics, and their family responsibilities and background. Between March and September of 2006 they were interviewed again, with a focus on their enrollment patterns since 2004, including any transfers, stopout periods, attendance intensity, and completion of certificates and degrees. Those who were no longer enrolled were asked about their employment experiences. The third-year survey is called BPS:04/06, and the results of both the 2004 and the 2006 interviews have been published in a previous report INTRODUCTION (Berkner and Choy 2008). 1 The 2009 interview, conducted between February and October of 2009, focused on the degree completion of those still enrolled after 2006, graduate school enrollment of those who had completed bachelor's degrees, and employment of those no longer enrolled. The BPS:04/09 study draws on many sources of data. Information about the beginning postsecondary students during their first year comes from NPSAS:04, which includes a student interview, institutional records, federal financial aid applications, and federal student loan and Pell Grant records. Data on 2003-04 beginning postsecondary students in 2006 and 2009 are primarily based on the follow-up student interviews. However, both the 2006 and 2009 studies integrate students' enrollment records from the National Student Clearinghouse and data from the same federal databases used in the base year; the 2006 study also contains information from college admissions test agencies, and the 2009 study includes college transcript data from July 1, 2003, through June 30, 2009. In all three study years (2004, 2006, and 2009), student interviews were distributed as web-based questionnaires that were either self-administered or conducted via telephone with a trained interviewer. In 2009, about 15,000 students completed the interview, resulting in a weighted interview response rate of 82 percent. National Student Clearinghouse data or transcript data provided information on another 1,500 cases, resulting in an overall weighted response rate of 89 percent. For more information, a glossary describing the variables used in the tables is provided in appendix A. The technical notes in appendix B supply additional information about response rates, the methodology of the data collection, file preparation, and analysis. Descriptive reports and public access datasets for BPS studies are also available on the NCES website (http://nces.ed.gov/datalab)."}, {"section_title": "The Organization of the Tables in This Report", "text": "The first three tables present information on students' attainment and persistence anywhere between 2003 and 2009. These tables show the percentage of students who attained various degrees, regardless of where they completed them, and the percentage of students who had not attained a degree but were still enrolled in some type of postsecondary institution, whether or not that institution was their original institution. Thus, the analysis of attainment and persistence in the first three tables is based on the students' perspective. Table 1 shows the results for all first-time  INTRODUCTION   3   beginners, table 2 includes only those who began at a public 2-year college, and table  3 includes only those who began at a 4-year institution.   Tables 4-6 provide data on students' attainment and retention at the first institution attended between 2003 and 2009. More specifically, these tables show the percentage of students who either completed a degree at their first institution or were still enrolled at their first institution 6 years after entering. The analysis of attainment and retention in tables 4-6 is thus from the first institution's perspective. Tables 4-6 are parallel to tables 1-3 in that table 4 includes results for all first-time beginners, table 5 only includes those who began at a public 2-year college, and table 6 only includes those who began at a 4-year institution."}, {"section_title": "THIS PAGE INTENTIONALLY LEFT BLANK", "text": ""}, {"section_title": "5", "text": ""}, {"section_title": "Selected Findings", "text": "Attainment and persistence at any institution within 6 years  \u2022 Among 2003-04 beginning students, about 9 percent had received a certificate, 9 percent had received an associate's degree, and 31 percent had received a bachelor's degree within 6 years from any institution (table 1). Another 15 percent had not yet received a degree but were currently enrolled at some institution (7 percent at a 4-year institution and 8 percent at a lessthan-4-year institution), while an additional 35 percent had not received a degree and were not enrolled at any institution. \u2022 Among 2003-04 beginning students who first enrolled in a public 2-year institution, about 8 percent had received a certificate, 14 percent had received an associate's degree, and 12 percent had received a bachelor's degree within 6 years from any institution (table 2). Another 20 percent had not yet received a degree but were currently enrolled somewhere (7 percent at a 4year institution and 13 percent at a less-than-4-year institution) and 46 percent had not received a degree and were not enrolled at any institution. \u2022 Among 2003-04 beginning students who first enrolled in a 4-year institution, 58 percent had received a bachelor's degree, 5 percent had received an associate's degree, and 2 percent had received a certificate within 6 years from any institution (table 3). An additional 12 percent had not yet received a degree but were currently enrolled somewhere (9 percent at a 4year institution and 3 percent at a less-than-4-year institution) and 24 percent had not received a degree and were not enrolled at any institution."}, {"section_title": "Attainment and persistence at first institution within 6 years (2004-09)", "text": "\u2022 In contrast to the above bullets that presented students' attainment and persistence rates at any institution, the following bullets highlight students' attainment and persistence rates just at their first postsecondary institution. Specifically, among 2003-04 beginning students, about 8 percent had received a certificate, 9 percent had received an associate's degree, and 22 percent had received a bachelor's degree within 6 years from the first institution that they attended (table 4). Students who had not yet attained a degree from their first institution by the spring of 2009 were currently enrolled at their first institution (6 percent), had left their first institution but had transferred to another institution (27 percent), or had left their first institution and had not enrolled anywhere else (28 percent). \u2022 Among 2003-04 beginning students who first enrolled in a public 2-year institution, 6 percent had received a certificate and 15 percent had received an associate's degree at their first institution within 6 years (table 5). Students who had not yet attained a degree from their first institution by the spring of 2009 were currently enrolled at their first institution (9 percent), had left their first institution but transferred to another institution (32 percent), or had left their first institution and had not enrolled elsewhere (37 percent). \u2022 Among 2003-04 beginning students who first enrolled in a 4-year institution, about 50 percent had received a bachelor's degree, 3 percent had received an associate's degree, and about 1 percent had received a certificate at their first institution within 6 years (table 6). Students who had not yet received a degree from their first institution by spring of 2009 were currently enrolled at their first institution (5 percent), had left their first institution but transferred to another institution (25 percent), or had left their first institution and had not enrolled anywhere else (17 percent). TABLES 7 Table 1.-ALL BEGINNING STUDENTS: ATTAINMENT AND PERSISTENCE AT ANY INSTITUTION: Six-year  Table 1.-attainment and persistence rates at any institution among all beginning students, by first institution type,  Table 1.-enrollment patterns, degree program, degree expectations, and demographics: 2004-09   Attained a degree from  Did not attain a degree from  any institution by spring 2009\u00b9  any institution by spring  High middle ($60,000-91,999) 3.9 ! 9.8 45.5 8.0 5.7 27.1 Highest ($92,000 or more) 2.4 7.1 58.6 6.8 5.6 19.4 ! Interpret data with caution (estimates are unstable). Relative standard error is greater than 0.3 but less than 0.5. \u2021 Reporting standards not met. 1 These columns include some students who attained a degree and continued to be enrolled. Table 1.-ALL BEGINNING STUDENTS: ATTAINMENT AND PERSISTENCE AT ANY INSTITUTION: Six-year  Table 1.-attainment and persistence rates at any institution among all beginning students, by first institution type,  Table 1.-enrollment patterns, degree program, degree expectations, and demographics: 2004-09-Continued   Enrolled   Status in spring 2009 3 Results include only students who knew their parents' highest level of education.  Table 2.-STUDENTS BEGINNING AT 2-YEAR PUBLIC COLLEGES: ATTAINMENT AND PERSISTENCE AT ANY  Table 2.-INSTITUTION: Six-year attainment and persistence rates at any institution among students  Table 2.-beginning at 2-year public colleges, by enrollment patterns, degree program, degree expectations,  Table 2 Table 2.-STUDENTS BEGINNING AT 2-YEAR PUBLIC COLLEGES: ATTAINMENT AND PERSISTENCE AT ANY  Table 2.-INSTITUTION: Six-year attainment and persistence rates at any institution among students  Table 2.-beginning at 2-year public colleges, by enrollment patterns, degree program, degree expectations,  Table 2     ! Interpret data with caution (estimates are unstable). Relative standard error is greater than 0.3 but less than 0.5. \u2021 Reporting standards not met. 1 These columns include some students who attained a degree and continued to be enrolled. Table 5.-INSTITUTION: Six-year attainment and retention rates at first institution among students beginning Table 5.-at 2-year public colleges, by enrollment patterns, degree program, degree expectations, and  Table 6.-STUDENTS BEGINNING AT 4-YEAR COLLEGES: ATTAINMENT AND RETENTION AT FIRST INSTITUTION: Table 6.-Six-year attainment and retention rates at first institution among students beginning at 4-year colleges, Table 6.-by first institution type, enrollment patterns, degree program, degree expectations, and demographics:   Table 6.-Six-year attainment and retention rates at first institution among students beginning at 4-year colleges, Table 6.-by first institution type, enrollment patterns, degree program, degree expectations, and demographics: No degree from first institution, The respondent had not attained a degree or certificate left first institution, never at the first institution and had left this institution and enrolled in another institution never enrolled at another institution by spring 2009."}, {"section_title": "Table 5.-STUDENTS BEGINNING AT 2-YEAR PUBLIC COLLEGES: ATTAINMENT AND RETENTION AT FIRST", "text": "Attendance intensity through June 2009 ENINPT6Y Indicates the respondent's pattern of full-time, part-time, or mixed full-time and part-time attendance intensity in the months enrolled at all postsecondary institutions between July 2003 and June 2009. Full-time attendance generally means enrollment in 12 or more credit hours per term or 24 credit hours per academic year. Students enrolled full time in an academic year except for the summer months (in which they may have been enrolled part time) were considered to be enrolled always full time. Always full-time Mixed Always part-time BPS:04/06/09 panel weight WTB000 The BPS:04/06/09 panel weight was used to produce the tables in this report. This is the longitudinal study weight that is used for the analysis of the beginning students for whom sufficient survey data was available to be included as sample members in all three years of the BPS interviews (2004, 2006, and 2009)."}, {"section_title": "Degree program, 2003-04", "text": "UGDEG Indicates the undergraduate student's degree program during the 2003-04 academic year. Based primarily on the 2004 interview question \"What degree were you working on at [the National Postsecondary Student Aid Study (NPSAS) sample school]?\" For non-respondents, the degree program reported by the NPSAS institution or reported by the student in the federal financial aid application was used. This variable was edited to ensure that the degree program students reported was actually offered by their institution. Thus students who reported working on a bachelor's degree at a 2-year college were classified as in an associate's degree program and students who reported working on a bachelor's degree or an associate's degree at a less-than-2-year college were classified as in a certificate program."}, {"section_title": "No degree", "text": "The student was not enrolled in a certificate or degree program.\nThe student did not ever expect to complete a degree."}, {"section_title": "Certificate", "text": "The student was enrolled in a certificate program below an associate's degree. Bachelor's degree The student was enrolled in a bachelor's degree program. Dependency status, 2003-04 DEPEND Indicates the student's dependency status for federal financial aid and whether the student had any dependents of his or her own in 2003-04. Students were considered to be financially independent of their parents for federal financial aid purposes in 2003-04 if they were age 24 or older on December 31, 2003 or if they met any of the following criteria: were married; had legal dependents; were veterans of the U.S. armed forces or on active duty; were orphans or wards of the court; or were enrolled in a graduate or professional degree program (beyond the bachelor's degree) in 2003-04. All other students under 24 were considered to be dependent unless they could document that they were receiving no parental support and were determined to be independent by a financial aid officer using professional judgment.\nThe highest level of education the student ever expected to complete was a certificate. Associate's degree The highest level of education the student ever expected to complete was an associate's degree. Bachelor's degree The highest level of education the student ever expected to complete was a bachelor's degree."}, {"section_title": "Dependent Independent", "text": "Dependent student family income level, 2002 DEPINC Indicates the total income of dependent students' parents in 2002. This variable is based on amounts reported in the financial aid application, estimates by students in the student interview, and stochastic imputation. Prior calendar year income is reported in the financial aid application and is used in determining the expected family contribution (EFC) in need analysis. The low and high categories used here are approximately the lowest and highest 25 percent of the income range for all dependent students' families. Lowest (Less than $32,000) Low middle ($32,000-59,999) High middle ($60,000-91,999) Highest ($92,000 or more) Doctorate-granting status of first institution FSECDOC Indicates whether the first 4-year institution the student attended did or did not grant doctorates. Less-than-4-year institutions are not included in this variable."}, {"section_title": "Doctorate Non-doctorate", "text": ""}, {"section_title": "Variable", "text": "Highest degree ever expected to complete, 2003-04 HIGHLVEX When asked in 2003-04, the highest level of education that the student ever expected to complete."}, {"section_title": "Advanced degree", "text": "The highest level of education the student ever expected to complete was a post-bachelor's or postmaster's certificate, a master's degree, a doctoral degree, or a first-professional degree. Highest education of parents, 2003-04 PAREDUC When asked in 2003-04, the highest level of education completed by the student's mother or father, whoever had the highest level. Students who did not know their parents' education level (2.7 percent) are not included in the categories presented in this report."}, {"section_title": "High school or less", "text": "Student's parents earned a high school diploma or equivalent or did not complete high school. Some postsecondary Student's parents attended some postsecondary education, but did not earn a bachelor's degree. Bachelor's degree or higher Student's parents attained a bachelor's or advanced degree. Race/ethnicity RACE Indicates the student's race/ethnicity with Hispanic or Latino origin as a separate category. Race/ethnicity data were collected separately and combined for reporting purposes. All of the race categories exclude Hispanic origin unless specified."}, {"section_title": "White", "text": "A person having origins in any of the original peoples of Europe, North Africa, or the Middle East. Recent high school graduate FALLHSFT Recent high school graduates were students who graduated from high school with a regular diploma in 2003 or early 2004. This variable was aggregated to the following categories in this report:"}, {"section_title": "Yes", "text": "The student graduated from high school with a regular diploma in 2003 or early 2004."}, {"section_title": "No", "text": "The student did not have a regular high school diploma or graduated prior to 2003. Variable"}, {"section_title": "Sex", "text": ""}, {"section_title": "GENDER Male Female", "text": "Transfer status TFNUM6Y Indicates the number of transfers between institutions as of June 2009. A transfer occurs when the respondent leaves one institution (the origin) and enrolls at another institution (the destination) for four or more months. Students who co-enrolled in a second institution without leaving the first institution are not considered to be transfers. This transfer definition does not consider whether course credits were accepted by the destination institution. This variable was aggregated to the following categories in this report:"}, {"section_title": "Never transferred", "text": "The respondent never transferred to another institution."}, {"section_title": "Transferred", "text": "The respondent transferred to another institution at least once. Type of associate's degree UGDEGAA Indicates the student's type of associate's degree program during the 2003-04 academic year. This variable is based on the 2004 student interview or the type of program reported by the institution attended. Students who reported working on a bachelor's degree at a 2-year college were placed in the general education/transfer category."}, {"section_title": "Occupational or technical", "text": "The student was working on an applied associate's degree in occupational or technical programs that are generally terminal degrees."}, {"section_title": "General education/transfer", "text": "The student was working on an academic associate's degree in general education or in preparation for transfer to a 4-year institution. Type of first institution FSECTOR Indicates the level and control of the first institution attended by the student in 2003-04, based on the classification in the 2003 Integrated Postsecondary Education Data System (IPEDS) Institutional Characteristics file. Control concerns the source of revenue and control of operations (public, private nonprofit, for-profit), and level concerns the highest degree or award offered by the institution in any program. Four-year institutions award at least a bachelor's degree; 2-year institutions award at least an associate's degree; less-than-2-year institutions award certificates or other credentials in vocational programs lasting less than 2 years. In most cases, the first institution attended in 2003-04 is also the institution at which the student was sampled for NPSAS:04. However, if the student was enrolled at another institution for more than 3 months in 2003-04 prior to enrolling at the NPSAS sample institution, the prior institution was classified as the first institution attended. Private nonprofit lessthan-2-year institutions were included in the overall totals and totals for less-than-2-year institutions, but the sample size was too small to show them as a separate category. BPS is unique in that it focuses exclusively on a nationally representative sample of students who are enrolled in postsecondary education for the first time (collectively referred to as first-time beginners or FTBs). Study eligibility is determined by a student's first postsecondary enrollment date rather than age-related determinants such as the student's high school graduation year. As such, BPS includes nontraditional students from a variety of backgrounds. In addition, BPS collects data on sample members' complete postsecondary enrollment history during the period between the base year study and the final follow-up, making it distinct from typical within-institution retention and attainment studies that do not track students as they move between schools. BPS:04 is the third cohort of FTBs to be tracked by NCES since 1990. It follows first-time beginners identified in the 2003-04 National Postsecondary Student Aid Study (NPSAS:04) through two follow-up data collections conducted during the third and sixth years after the base year study. 1 BPS:04/09 is the second follow-up data collection of the BPS:04 cohort. As with previous BPS studies, BPS:04/09 includes a multi-mode student interview component that collects information on students' education and employment since their first enrollment in postsecondary education. For the first time in the BPS series B-2 APPENDIX B-TECHNICAL NOTES AND METHODOLOGY of studies, BPS:04/09 includes a transcript component that provides researchers with additional institution-and student-level data for analysis."}, {"section_title": "Data Sources for BPS:04/09", "text": "BPS:04/09 includes some data that were originally collected for NPSAS:04 and BPS:04/06. Data were obtained from the following sources: \u2022 Student interview: Data collected directly from sampled students via web, telephone, and field interviews. \u2022 Student records: Data from institutional financial aid and registrar records at the institutions currently attended. These data were entered at the institution by institution personnel or field data collectors using a computer-assisted data entry (CADE) program or directly downloaded to a data file. \u2022 SAT: Student SAT data from the College Board. \u2022 ACT: Student ACT data from ACT. \u2022 National Student Clearinghouse (NSC): A central repository and single point of contact for the collection of postsecondary enrollment, degree, and certificate records on behalf of participating postsecondary institutions. \u2022 Student transcript: Student enrollment and achievement data collected from postsecondary institutions as part of the BPS:04/09 Postsecondary Education Transcript Study (BPS:04/09 PETS). \u2022 College catalogue: Institutional-and course-level data collected from postsecondary institution materials as part of BPS:04/09 PETS.  "}, {"section_title": "Sample Design", "text": "Four key components determined the sample makeup for BPS:04/09: the definition of the NPSAS institution and respondent universes; the NPSAS institution-and student-level base year sample selections; the definition of the BPS:04/06 sample; and the updating of the BPS:04/06 panel for the BPS:04/09 wave. Each of these pieces is discussed in detail below."}, {"section_title": "Base-Year Study (NPSAS:04)", "text": "To be eligible for inclusion in the BPS:04 cohort, students must have been part of the student universe at an institution included in the NPSAS:04 institution universe. The definition of each universe is presented below."}, {"section_title": "Institution Universe for NPSAS:04", "text": "To be eligible for the NPSAS:04 sample, institutions were required to have met five criteria during the 2003-04 academic year. They must have \u2022 been eligible to distribute Title IV funds; \u2022 offered an educational program designed for persons who have completed a high school education; \u2022 offered at least one academic, occupational, or vocational program of study lasting at least 3 months or 300 clock hours; \u2022 offered courses that were open to persons other than the employees or members of the company or group (e.g., union) that administers the institution; and \u2022 been located in the 50 states, the District of Columbia, or Puerto Rico. These conditions are consistent with previous NPSAS studies with two exceptions: First, prior to NPSAS:2000, institutions were not required to be eligible to distribute Title IV funds to be eligible for selection, 2 and second, previous NPSAS studies excluded institutions that offered only correspondence courses. 3"}, {"section_title": "Student Universe for NPSAS:04", "text": "Students eligible for NPSAS:04 were those who were enrolled in eligible institutions as defined above, and who satisfied both of the following eligibility requirements: \u2022 they were enrolled in either an academic program, at least one course for credit that could be applied toward fulfilling the requirements for an academic degree, or an occupational or vocational program that required at least 3 months or 300 clock hours of instruction to receive a degree, certificate, or other formal award; and \u2022 they were not concurrently or solely enrolled in high school, or in a General Educational Development (GED) or other high school completion program."}, {"section_title": "Institution Sample for NPSAS:04", "text": "The institution sampling frame for NPSAS:04 was constructed from the 2000-01 and 2001-02 Integrated Postsecondary Education Data System (IPEDS) Institutional Characteristics (IC) file, header files, and the 2000 and 2001 Fall Enrollment files. The sample of institutions was refreshed using the 2002-03 IPEDS to ensure that newly formed institutions were included in the sampling frame and IPEDS records for NPSAS-ineligible institutions were removed. Additionally, the IPEDS files were cleaned to remove any cases with missing enrollment data and those with an unusually large or small enrollment. 4"}, {"section_title": "APPENDIX B-TECHNICAL NOTES AND METHODOLOGY B-5", "text": "After cleaning, the sample of institutions was selected from the sampling frame defined above. 5 To allow for state-level analysis of the effects of tuition and student aid policies, three types of institutions-public 2-year institutions, public 4-year institutions, and private nonprofit 4-year institutions-were oversampled in 12 states. Oversampled institutions came from California, Connecticut, Delaware, Georgia, Illinois, Indiana, Minnesota, Nebraska, New York, Oregon, Tennessee, and Texas. These states were chosen because their institutions expressed an interest in, and a willingness to support, NPSAS participation. Table B-2 describes the NPSAS:04 institution sample by institution type, as defined by institution control (e.g., private nonprofit) and institution level (e.g., 2-year). The number of sampled institutions was 1,670, of which 1,630 were confirmed eligible to participate. 6 Of the 1,630 eligible institutions, 1,360 (84 percent) provided student enrollment lists. 5 A direct, unclustered sample of institutions has been used for each NPSAS cohort since NPSAS:96. Prior to NPSAS:96, a clustered sample of institutions was selected for the study. 6 Among the ineligible institutions, 10 closed after the sampling frame was defined, 10 failed to meet one or more of the NPSAS criteria for institution eligibility and the remaining 10 had enrollment lists that were combined with eligible institutions because of an affiliation between the campuses."}, {"section_title": "B-6", "text": "APPENDIX B-TECHNICAL NOTES AND METHODOLOGY"}, {"section_title": "Student Sample for NPSAS:04", "text": "The NPSAS:04 student sampling design was based on fixed type sampling rates rather than fixed type sample sizes. This approach ensured that the probabilities of selection were equal across student type within institution type. 7 Specifically, the sampling design used \u2022 two classifications for undergraduates (one for FTBs and one for all other undergraduates); \u2022 one classification for first-professional students; and \u2022 three classifications for graduate students (master's, doctoral, and \"other\"). 8 The identification of an adequate number of FTBs for the NPSAS:04 sample was critical in preparing the sample that would be used for BPS:04/06 and BPS:04/09. For the NPSAS:04 sampling frame, students who were identified as likely FTBs were classified as potential FTBs. To clarify important distinctions within the potential FTB group, two sub-groups of potential FTBs were also defined. Students who were enrolled in a postsecondary institution during the NPSAS year (July 1, 2003, through June 30, 2004) for the first time after completing high school requirements were considered pure FTBs. Those NPSAS-eligible students who had enrolled for at least one postsecondary course before the 2003-04 NPSAS year, but never completed that course, were considered effective FTBs. Prior NPSAS experience showed that postsecondary institutions are sometimes unable to accurately identify their FTBs. Therefore, it was necessary to compensate for potential misclassifications in the sampling design. For this reason, the falsepositive and false-negative FTB rates observed in NPSAS:96 were used to set appropriate FTB sampling rates for NPSAS:04. 9 A total of 109,210 students were selected for the NPSAS:04 student sample. This sample included 49,410 potential FTBs, 47,680 non-FTB or \"other\" undergraduate students, and 12,120 graduate and first-professional students. Various sources were used to verify eligibility of the NPSAS:04 student sample including institutional records, the NPSAS:04 student interview, and record matching against several administrative databases (e.g., the U.S. Department of Education's Central Processing System). Of the 109,210 sampled students, 101,010 were found to be eligible for the NPSAS:04 study. The variety of data sources used in NPSAS:04 made it possible to obtain some key data elements regardless of whether the respondent completed the interview portion of the study. As such, sample members with incomplete interview data but data on these key elements are still classified as study respondents. At least the minimum amount of data was obtained for ninety percent of the eligible sample members. Table B-3 shows numbers of NPSAS:04 sampled and eligible students as well as response rates by institution type and student type. "}, {"section_title": "First Follow-Up Study (BPS:04/06)", "text": "The primary task of the BPS:04/06 sample definition process was to confirm or reject a potential respondent's initial FTB classification. To construct the frame for the BPS:04/06 sample, multiple data elements such as a student's year of high school graduation, undergraduate class level, and loan receipt dates were used to estimate a student's likelihood of being an FTB during the NPSAS year. Using the NPSAS:04 and BPS:04/06 data sources discussed above, a set of decision rules was developed to identify the cases most likely to be FTBs. In addition to the primary FTB classification, this approach produced three additional FTB categories based on the source of the FTB sample member. The resulting BPS:04/06 sample included 23,090 FTBs identified as follows: 1. FTBs. In total, 24,990 students responding to the NPSAS:04 student interview indicated that they were FTBs during the 2003-04 academic year. Approximately 3,820 students were excluded from the BPS:04/06 sample when multiple data sources confirmed that they could not have been FTBs during the NPSAS year. Of the 21,170 included in the BPS:04/06 sample, 19,800 had other data that strongly supported their FTB status. The remaining potential false positives were re-screened during the BPS:04/06 interview to confirm their status. 2. Other Undergraduates. Based on either CPS data or high school graduation dates, 1,420 students that were not originally classified as FTBs and were part of the NPSAS:04 group of 28,610 \"other\" undergraduates, were later identified as potential FTBs. These potential false negatives were included in the BPS:04/06 sample and re-screened during the BPS:04/06 interview to verify their status. 3. Study respondent likely FTBs. Approximately 8,860 students did not respond to the NPSAS:04 student interview but were classified as NPSAS:04 study respondents and potential FTBs based on their student records, CPS and loan data. To improve nonresponse bias reduction 460 of these 8,860 students were included in the BPS:04/06 sample. Two factors, whether the student was matched with contact information from external data sources and the likelihood of being an FTB, were used to sample the 460 students most likely to be located and eligible for the study. 4. Study nonrespondent likely FTBs. Seven hundred twenty NPSAS:04 sample members were potential FTBs based on information from their student records or CPS, but did not respond to the student interview and did not have sufficient data to be classified as study respondents. Of these 720 students, a subsample of approximately 40 were included in the BPS:04/06 sample based on the same APPENDIX B-TECHNICAL NOTES AND METHODOLOGY B-9 criteria (likelihood of eligibility and of being located) as the subsample in group 3."}, {"section_title": "Second Follow-up Study (BPS:04/09)", "text": "The BPS:04/06 starting sample consisted of 23,090 students. At the conclusion of the BPS:04/06 data collection, ineligible cases were removed from the sample based on the following criteria: \u2022 responses to eligibility questions in the BPS:04/06 student interview; \u2022 logistic modeling done to predict the eligibility status of BPS:04/06 interview nonrespondents; and \u2022 reviews of sample member eligibility information against updated National Student Clearinghouse and National Student Loan Database System data. As a result of these procedures, the total BPS:04/09 sample was cleaned to remove the ineligible cases and thereby reduced to 18,640 cases. Table B-4 shows the sample distribution of the BPS:04/09 sample by prior round response status (i.e., whether the student responded to the NPSAS:04 interview and the BPS:04/06 interview). "}, {"section_title": "BPS:04/09 Study Respondent Definition", "text": "A BPS:04/09 study respondent is defined as any sample member who was determined to be eligible for the study, was not deceased at the time of the BPS:04/09 data collection, and had the requisite valid data from any source to construct his or her enrollment history. In addition to the BPS:04/09 student interview, student-level data for BPS:04/09 were collected from a variety of administrative sources, including the National Student Loan Data System and the National Student Clearinghouse Tracker files. Data from these sources supplemented interview data and allowed enrollment histories and persistence and attainment variables to be constructed for a proportion of interview nonrespondents. Of the 18,640 cases who were eligible at the conclusion of BPS:04/06 and were included in the BPS:04/09 data collection, 105 were deceased and therefore ineligible and 15,160 were BPS:04/09 interview respondents. An additional 1,520 were BPS:04/09 interview nonrespondents but had enough data from other sources to be classified as BPS:04/09 study respondents. Therefore, there were a total of 18,540 eligible BPS:04/09 sample members of which 16,680 qualified as study respondents. A sample member was considered a BPS:04/09 panel respondent if they were a NPSAS:04 study respondent and had sufficient interview or additional data from BPS:04/06 and BPS:04/09. Of the 18,640 cases included in the BPS:04/09 data collection, 16,120 were panel respondents. This report analyzes only those sample members classified as panel respondents."}, {"section_title": "Perturbation", "text": "To protect the confidentiality of NCES data that contain information about specific individuals and to minimize disclosure risks, BPS:04/09 data were subject to perturbation procedures. Perturbation procedures, which have been approved by the NCES Disclosure Review Board, preserve the central tendency estimates but may result in slight increases in nonsampling errors. "}, {"section_title": "Imputation", "text": "All variables with missing data used in this report, as well as those included in the related PowerStats data, have been imputed. BPS:04/09 study respondents who did not complete the interview as well as BPS:04/09 interview respondents with some missing items required imputation of their BPS:04/09 data. The following types of imputations were done: \u2022 Missing BPS:04/09 interview enrollment data were imputed with data obtained from the National Student Clearinghouse data or the student's transcripts. \u2022 BPS:04/09 first follow-up interview data were imputed for cases with completed interviews with some missing items, abbreviated interviews with some missing sections, and cases that did not have a BPS interview. Two types of imputation methodologies were used for the BPS:04/09 data. The first imputation methodology was deterministic imputation. That is, if a logical relationship existed between variables such that a specific value should be assigned to the missing value, then the missing value was assigned the logical value. The second imputation methodology was stochastic imputation. When required, the stochastic imputation approach was applied after the deterministic methodology. For each variable, the stochastic imputation procedure employed a two-step process. First, the dataset was partitioned into imputation classes of homogenous respondents, with homogeneity based on the variable to be imputed. All imputations were processed independently within each imputation class. Second, a weighted sequential hot-deck process was implemented, 10 whereby missing data were replaced with valid data from donor records in the imputation class. Variables requiring imputation were imputed either independently or simultaneously with other variables. This determination was based on the variable's levels of missingness, pattern of missingness, and subject matter considerations. Variables with the least amount of missing data were imputed first, followed by variables with greater amounts of missing data. Once data for a variable had been imputed, that variable was then a candidate for imputation classes for subsequent imputations."}, {"section_title": "B-12 APPENDIX B-TECHNICAL NOTES AND METHODOLOGY", "text": "The combined file of BPS:04/09 study respondents (interview respondents and nonrespondents) was used for imputations. Classification and Regression Tree (CART) analysis was used to identify the imputation classes based on the variables that were most closely related to the variable being imputed. CART (Breiman et al. 1984) is similar to the Chi-Square Automatic Interaction Detection (CHAID) (Kass 1980) procedure that was used for the imputation procedures in NPSAS:04. CART, however, is a nonparametric approach to forming imputation classes. This step produced a number of imputation classes that contain sets of donors used to impute recipients belonging to that class. Next, the imputation classes were used as inputs to a SAS macro that implemented the weighted sequential hot-deck procedure. Data were sorted within each imputation class to increase the chance of obtaining a close match between donor and recipient. The weighted, sequential nature of the hot-deck process derives from its incorporation of the sample weight in the donor selection process and its adaptation of the sequential sample selection method discussed in Chromy (1979). As described in Cox (1980, p. 721), \"This algorithm is designed so that means and proportions, estimated using the imputation-based dataset, will be equal in expectation to the weighted mean or proportion estimated using respondent data only.\" 11 In some cases, further intervention was needed to ensure accuracy and consistency of imputation, as determined by preexisting edit rules. Weighting BPS:04/09 weights compensate for unit nonresponse during the BPS:04/09 data collection. Because the BPS:04/09 sample is a subset of the BPS:04/06 sample and the BPS:04/06 sample is a subset of the NPAS:04 sample, the BPS:04/09 weights were derived from the BPS:04/06 and NPSAS:04 weights. The BPS:04/09 panel analysis weight, which was used for the analyses in this report, was obtained by adjusting the BPS:04/06 analysis weight for cases that were not identified as study respondents for all three data collections (NPSAS:04, BPS:04/06, and BPS:04/09). The SUDAAN procedure PROC WTADJUST was used to implement this adjustment. This nonresponse adjusted weight was then raked to match enrollment and aid totals obtained using 2003 IPEDS counts and weighted NPSAS:04 data. A weight for analyzing cases who were classified as study respondents for BPS:04/09 was developed using similar procedures.  "}, {"section_title": "Quality of Estimates", "text": ""}, {"section_title": "Unit Response Rates and Bias Analysis", "text": "The bias in an estimated mean based on respondents, R y , is the difference between this mean and the target parameter, \u03c0 (i.e., the mean that would be estimated if a complete census of the target population was conducted and everyone responded). This bias can be expressed as follows: The estimated mean based on nonrespondents, , can be computed if data for the particular variable are available for most of the nonrespondents. The true target parameter, \u03c0, can be estimated for these variables as follows: where \u03b7 is the weighted unit (or item) nonresponse rate. For the variables that are from the frame, rather than from the sample, \u03c0 can be estimated without sampling error. The bias can then be estimated as follows: or equivalently: This formula shows that the estimate of the nonresponse bias is the difference between the mean for respondents and nonrespondents multiplied by the weighted nonresponse rate. Nonresponse bias could come from a variety of sources, including failure of the institution to provide lists for NPSAS:04, student nonresponse to BPS:04/09, and item nonresponse to the BPS:04/09 interview."}, {"section_title": "Institution-Level Bias Analysis", "text": "An institution respondent is defined as any sample institution for which \u2022 a student list was received that was sufficient for selecting a sample; or \u2022 a sample of students was selected from an NSLDS file of Stafford loan and Pell grant recipients in cases where such a student file was believed to include at least 85 percent of the student population. In total, 1,360 of the 1,630 eligible NPSAS:04 sample institutions were respondents. The weighted response rates by type of institution range from 70 percent for public 4-year non-doctorate-granting institutions to 93 percent for private nonprofit lessthan-4-year institutions and are below 85 percent for six of the nine types of institutions. A nonresponse bias analysis was conducted for all institutions and for the six types of institutions with a weighted response rate below 85 percent. The nonresponse bias was estimated for variables known (i.e., non-missing) for most respondents and nonrespondents. The following IPEDS variables were used: 13 \u2022 type of institution; 14 \u2022 Carnegie classification; \u2022 degree of urbanization; \u2022 Bureau of Economic Analysis Code (OBE) region; \u2022 historically Black college or university indicator; \u2022 percentage of students receiving federal grant aid; \u2022 percentage of students receiving state/local grant aid; \u2022 percentage of students receiving institutional grant aid; \u2022 percentage of students receiving student loan aid; \u2022 percentage of students enrolled: Hispanic; \u2022 percentage of students enrolled: Asian or Pacific Islander; \u2022 percentage of students enrolled: Black, non-Hispanic; \u2022 total undergraduate enrollment; \u2022 male undergraduate enrollment; \u2022 female undergraduate enrollment; \u2022 total graduate/first-professional enrollment; \u2022 male graduate/first-professional enrollment; and \u2022 female graduate/first-professional enrollment. The nonresponse bias analyses consisted of three steps. First, the nonresponse bias was estimated for the institution-level variables listed above and tests were performed to determine if the amount of bias was significantly different from zero at the p < .05 level. Second, nonresponse adjustments designed to reduce or eliminate nonresponse bias were computed, and the variables listed above were included in the nonresponse models. Third, after weights were computed, the residual bias was estimated for the variables listed above and statistical tests were performed to determine whether the remaining nonresponse bias was significantly different from zero at the p < .05 level. 13 For the continuous variables, categories were formed based on quartiles or logical breaks. 14 Type of institution was used only in the nonresponse bias analysis for all institutions. APPENDIX B-TECHNICAL NOTES AND METHODOLOGY"}, {"section_title": "B-17", "text": "As shown in table B-6, the institution weighting adjustments eliminated some, but not all, bias. For all types of institutions combined, prior to the nonresponse adjustment, about 6 percent of the variables showed statistically significant bias due to institution nonresponse. The variables with significant bias were type of institution, degree of urbanization, OBE region, and graduate/first-professional enrollment. After the nonresponse weight adjustment, none of these variables had a statistically significant bias. Before weighting, 6 percent of the variable categories of public less-than-2-year institutions and 7 percent of the variable categories of public 2-year institutions were significantly biased. For these types of institutions, three variables had a statistically significant bias before weight adjustment. These variables were (1) OBE region, (2) the percentage of students enrolled who are Black non-Hispanic, and (3) the percentage of institutional grant aid. After the weighting adjustment, no significant bias remained in any variables for these types of institutions. None of the private nonprofit 4-year doctorate granting institution variables showed statistically significant bias either before or after the nonresponse adjustment. For the other types of institutions, the percentage of variable categories with significant bias decreased after weight adjustments, but was not completely eliminated. For public 4-year non-doctorate-granting institutions, there were five B-18 APPENDIX B-TECHNICAL NOTES AND METHODOLOGY variables with statistically significant bias prior to the nonresponse adjustment. These variables were (1) whether the institution is a historically Black college or institution, (2) total undergraduate enrollment, (3) total graduate/first-professional enrollment, (4) male graduate/first-professional enrollment, and (5) female graduate/firstprofessional enrollment; after the nonresponse adjustment, the bias was reduced for these variables but was still statistically significant for the total graduate/firstprofessional enrollment and female graduate/first-professional enrollment variables. For private nonprofit 4-year non-doctorate-granting institutions, OBE region had statistically significant bias prior to nonresponse adjustment, but this bias was reduced and was no longer statistically significant after nonresponse adjustment. One level of variable for this type of institution, the percentage receiving student loan aid, had statistically significant bias after the nonresponse adjustment, but was not statistically significant before the adjustment. For private for-profit less-than-2-year institutions, the percentage receiving student loans and total undergraduate enrollment variables showed statistically significant biases prior to the nonresponse weight adjustment. After the adjustment, bias for the total undergraduate enrollment variable was reduced and no longer significant, but the bias for the percentage receiving student loans variable was still statistically significant. Further details on the institution-level bias analysis can be found in the 2004 National Postsecondary Student Aid Study (NPSAS:04) Full-Scale Methodology Report (Cominole et al. 2006)."}, {"section_title": "Student-Level Bias Analysis", "text": "Of the 18,540 eligible students in the BPS:04/09 sample, 16,120 had sufficient data from either the NPSAS:04, BPS:04/06, BPS:04/09 interviews or other sources to be considered panel respondents. Unweighted and weighted response rates were 87 percent and 86 percent, respectively. Student-level nonresponse bias analyses examined the bias before and after the study nonresponse weight adjustment by comparing key characteristics of respondents and nonrespondents. Nonresponse bias was estimated for the following variables: \u2022 type of institution; \u2022 region; \u2022 CPS match (yes/no); \u2022 Applied for federal aid (yes/no) APPENDIX B-TECHNICAL NOTES AND METHODOLOGY B-19 \u2022 Pell grant recipient (yes/no); \u2022 Pell grant amount; \u2022 Stafford loan recipient (yes/no); \u2022 Stafford loan amount; \u2022 institution undergraduate enrollment; \u2022 age at NPSAS:04; \u2022 high school graduation year; \u2022 student dependency status and income NPSAS:04; \u2022 race/ethnicity; \u2022 gender; \u2022 marital status at NPSAS:04; and \u2022 citizenship status at NPAS:04. The nonresponse bias analyses were conducted for the entire sample and each of the institutional strata. As shown in table B-7, when considering the entire sample the bias was significant for more than two-thirds of the variable categories. After weight adjustments, the bias was significant for less than 6 percent of the variable categories, and was reduced across all types of institutions.     Bias analyses were repeated for each of the institutional sectors. Table B-8 summarizes the weighted BPS:04/09 panel response rate, the mean and median bias before and after weight adjustment, and the percent of variable categories with statistically significant bias. In general, the weight adjustments were successful in reducing the bias overall and within each of the institutional sectors."}, {"section_title": "Item-Level Bias Analysis", "text": "Additional bias analyses focused on interview items with weighted response rates less than 85 percent. Item response rates (RRI) are calculated as the ratio of the number of respondents for whom an in-scope response was obtained (I x for item x) to the number of respondents who are asked to answer that item. The number asked to answer an item is the number of unit-level respondents (I) minus the number of respondents with a valid skip item for item x (V x ). The item response rate is calculated as: When an abbreviated questionnaire is used to convert refusals, the eliminated questions are treated as item nonresponse (U.S. Department of Education 2002). A student is considered an item respondent for an analytic variable if the student has data for that variable from any source, including logical edits. Item response rates for most of the items in this report were greater than 85 percent; however, one variable, the income of dependent students' parents at NPSAS:04, was imputed for about 30 percent of the BPS:04/09 panel respondents. Dependent student parental income (DEPINC) was collected in the NPSAS:04 student interview but was also available from other non-interview sources. Students responding via the interview gave a categorical response to the income item, but non-interview income data could be continuous in nature. Students with no family income information and students with only the interview response data had a continuous value of income imputed for DEPINC. Those respondents are considered nonrespondents to the DEPINC item for this analysis. The set of variables and procedures used for the DEPINC item nonresponse analysis are the same as those used for the student-level bias analysis presented earlier in this section. Table B-9 shows the percentage of variable categories for which DEPINC had statistically significant bias prior to imputation. The bias due to item nonresponse for DEPINC was statistically significant for 79 percent of the variable categories examined. The amount of bias varied by type of institution and ranged from 18 percent for students in public less-than-2-year institutions to 62 percent for students in public 2-year institutions. The median relative bias was 12 percent overall APPENDIX B-TECHNICAL NOTES AND METHODOLOGY B-25 and varied from 4 percent for private for-profit 2-year-or-more institutions to 28 percent for public less-than-2-year institutions.  A by-product of imputation is the reduction or elimination of item-level nonresponse bias. While item-level bias before imputation is measurable, after imputation it is not. As a result, how well an imputation procedure worked in reducing bias cannot be directly evaluated. Instead, the before-and after-imputation item estimates are compared to determine whether the imputation significantly changed the biased estimates, thus suggesting a reduction in bias. 15 As shown in table B-9, there are significant differences between estimates computed before and after imputation of DEPINC for all but private nonprofit less-than-4-year institutions and private forprofit 2-year-or-more institutions, suggesting that imputation has reduced the bias due to item nonresponse."}, {"section_title": "Standard Errors", "text": "To facilitate computation of standard errors for both linear and nonlinear statistics, a vector of bootstrap sample weights was added to the analysis file. These weights are \u03b8 \u03b8 \u03b8\u02c6 is the estimate based on the b-th replicate weight (where b = 1 to the number of replicates) and B is the total number of sets of replicate weights. A total of B = 200 replicates are used for BPS:04/09. Once the replicate weights are provided, this estimate can be produced by most survey software packages (e.g., SUDAAN, STATA, or WesVar). The replicate weights were produced using a methodology and computer software developed by Kaufman (2004). This methodology allows for finite population correction factors at two stages of sampling. The NPSAS:04, BPS:04/06, and BPS:04/09 application of the method incorporated the finite population correction factor at the first stage only, where sampling fractions were generally high. At the first stage of sampling, the sampling fractions ranged from 0.06 to 1.00, and the sampling rates were greater than 0.8 in approximately half of the strata. The finite population correction factors for the first stage strata ranged from 0 to 0.97. At the second stage, where the sampling fraction was generally low, the finite population correction factor was set to 1.00."}, {"section_title": "Cautions for Analysts", "text": ""}, {"section_title": "Sources of Error", "text": "The estimates in this report are subject to sampling and nonsampling errors. Nonsampling errors are due to a number of sources, including but not limited to nonresponse, coding and data entry errors, misspecification of composite variables, and inaccurate imputations. In a study like BPS:04/09, there are multiple sources of data for some variables (e.g., CPS, National Student Clearinghouse, student interviews and transcripts) and reporting differences can occur in each. Data B-28 APPENDIX B-TECHNICAL NOTES AND METHODOLOGY swapping and other forms of perturbation, implemented to protect respondent confidentiality, can also lead to inconsistencies. Sampling errors exist in all sample-based datasets, including BPS:04/09. Estimates calculated from a sample will differ from estimates calculated from other samples even if all the samples used the same sample design and methods. The standard error is a measure of the precision of the estimate. In this tabulation, each estimate's standard error was calculated using bootstrap replication procedures and can be produced using the BPS PowerStats software."}, {"section_title": "Comparing BPS:04/09 Estimates to Prior BPS Estimates", "text": "Comparison of results with prior rounds of BPS requires compensation for three changes in the design of the base-year NPSAS survey over time and also for a change in how nonrespondents are handled in the BPS:04/09 data file. First, as discussed above, prior to NPSAS:04 institutions that only offered correspondence courses were not eligible for the NPSAS. NPSAS:04 included such institutions if they were eligible to distribute Title IV student aid. Second, for NPSAS:2000, the survey was restricted for the first time to institutions participating in Title IV student aid programs. According to the NPSAS:96 DAS, only about 1 percent of sampled undergraduates were attending an institution not eligible to participate in Title IV aid programs. When students attending non-Title IV-eligible institutions were excluded from the NPSAS:96 sample, the percentage of undergraduates who received financial aid increased by less than 1 percent. This small change primarily affects comparisons of students enrolled in less-than-2-year and private for-profit institutions. When using the DAS from prior BPS studies for comparison to the BPS:04 cohort, analysts may want to filter cases in the prior studies (BPS:90 and BPS:96) based on whether the student was sampled from an institution that was eligible to participate in Title IV aid programs (T4ELIG). Finally, beginning with NPSAS:90, a design change was made to improve NPSAS full-year estimates. NPSAS:90 sampled students were enrolled at four discrete points in time: summer (August), fall (October), winter (February), and spring (June). Since implementation of NPSAS in 1993, institutions have been asked to provide one list that represents students enrolled at any time during the respective financial aid award year. In NPSAS:90, those students who were initially sampled in the fall could have been enrolled for the full academic year. APPENDIX B-TECHNICAL NOTES AND METHODOLOGY"}, {"section_title": "B-29", "text": "The BPS:04/09 analysis file contains all BPS sample members who either responded to the student interview or had enrollment data available from another source (such as the National Student Clearinghouse or student loan files). Enrollment data make up about half of the BPS interview, and it was desirable to use information available from other sources in addition to the self-report data. As described above, BPS:04/09 sample members with information from either the student interview or enrollment data from another source were classified as study respondents; data items not available from other sources were imputed for sample members who were study respondents but did not have other sources of information. BPS:04/06 also made use of data from other sources, including the National Student Clearinghouse, but the BPS:04/06 dataset contains data items and a positive analysis weight for all sample members who were determined to be eligible; this includes nonrespondents as well as respondents to the BPS:04/06 data collection. Nonrespondents to the BPS:04/06 interview appear on the data file with imputed data for all variables. In previous rounds of BPS, the nonrespondents appeared on the file but did not have data items and had a value of zero for the analysis weight."}, {"section_title": "PowerStats", "text": "The estimates presented in this report were produced using PowerStats, a web-based software application that enables users to generate tables for most of the postsecondary surveys conducted by NCES. PowerStats produces the design-adjusted standard errors necessary for testing the statistical significance of differences in the estimates. PowerStats also contains a detailed description of how each variable was created, and includes question wording for items coming directly from an interview. With PowerStats, users can replicate or expand upon the tables presented in this report. The output from PowerStats includes the table estimates (e.g., percentages or means), the proper standard errors, 16 and weighted sample sizes for the estimates. If the number of valid cases is too small to produce a reliable estimate (fewer than 30 cases), PowerStats prints the double dagger symbol ( \u2021) instead of the estimate. In addition to tables, PowerStats users may conduct linear or logistic regressions. Many options are available for output with the regression results. For a description of all the options available, users should access the PowerStats website at 16 The BPS samples are not simple random samples; therefore, simple random sample techniques for estimating sampling error cannot be applied to these data. The PowerStats takes into account the complexity of the sampling procedures and calculates standard errors appropriate for such samples. The method for computing sampling errors used by PowerStats involves approximating the estimator by replication of the sampled population. The procedure used is a bootstrap technique."}]