[{"section_title": "Table of Contents", "text": ""}, {"section_title": "List of Figures", "text": ""}, {"section_title": "List of Tables", "text": ""}, {"section_title": "Endorsement Disclaimer", "text": "Mention of a commercial company or product does not constitute an endorsement by NOAA. Use of information from this publication for publicity or advertising purposes concerning proprietary products or the tests of such products is not authorized. "}, {"section_title": "Acronyms and Abbreviations", "text": ""}, {"section_title": "AOOS", "text": ""}, {"section_title": "Definitions of Selected Terms", "text": "This manual contains several terms whose meanings are critical to those using the manual. These terms are included in the following table to ensure that the meanings are clearly defined."}, {"section_title": "Codable Instructions", "text": "Codable instructions are specific guidance that can be used by a software programmer to design, construct, and implement a test. These instructions also include examples with sample thresholds."}, {"section_title": "Data Record", "text": "A data record is one or more messages that form a coherent, logical, and complete observation."}, {"section_title": "Datum", "text": "For marine applications, datum is a base elevation used as a reference from which to reckon heights or depths. It is called a tidal datum when defined in terms of a certain phase of the tide (Gill et al. 2001)."}, {"section_title": "Leveling", "text": "Leveling is the determination of the elevation differences between bench marks, to extend vertical control and monitor the stability of the water level measurement gauge. The quality of leveling is a function of the procedures used, the sensitivity of the leveling instruments, the precision and accuracy of the rod, the attention given by surveyors, and the refinement of the computations (Gill et al. 2001). Message A message is a standalone data transmission. A data record can be composed of multiple messages."}, {"section_title": "Operator", "text": "Operators are individuals or entities who are responsible for collecting and providing data. Quality Assurance (QA) QA involves processes that are employed with hardware to support the generation of high quality data (section 2.0 and appendix A). Quality Control (QC) QC involves follow-on steps that support the delivery of high quality data and requires both automation and human intervention (section 3.0)."}, {"section_title": "Real Time", "text": "Real time means that: data are delivered without delay for immediate use; time series extends only backwards in time, where the next data point is not available; and there may be delays ranging from a few seconds to a few hours or even days, depending upon the variable (section 1.0)."}, {"section_title": "Threshold", "text": "Thresholds are limits that are defined by the operator."}, {"section_title": "Background and Introduction", "text": "The U.S. Integrated Ocean Observing System (IOOS) has a vested interest in collecting high quality data for the 26 core variables (U.S. IOOS 2010) measured on a national scale. In response to this interest, U.S. IOOS continues to establish written, authoritative procedures for the quality control (QC) of real-time data through the Quality Assurance/Quality Control of Real-Time Oceanographic Data (QARTOD) program, addressing each variable as funding permits. This water level (WL) manual is the fifth in a series of guidance documents that address QC of real-time data of each core variable. Please refer to http://www.ioos.noaa.gov/qartod/for the following documents. This manual is a living document that reflects the state-of-the-art QC testing procedures for water level observations. It is written for the experienced operator but also provides examples for those who are just entering the field."}, {"section_title": "Purpose/Constraints/Applications", "text": "The following sections describe the purpose of this manual, as well as the constraints that operators may encounter when performing QC of WL data and specific applications of those data."}, {"section_title": "Purpose", "text": "The purpose of this manual is to provide guidance to the U.S. IOOS and the WL community at large for the real-time QC of WL measurements using an agreed-upon, documented, and implemented standard process. This manual is also a deliverable to the U.S. IOOS Regional Associations and the ocean observing community and represents a contribution to a collection of core variable QC documents. WL observations covered by these test procedures are collected in oceans and lakes in real time or near-real time. These tests draw from existing expertise in programs such as the National Oceanic and Atmospheric Administration National Ocean Service (NOAA/NOS) National Water Level Observation Network (NWLON), the University of Hawaii Sea Level Center, and the Global Sea Level Observing System (GLOSS). The Global Climate Observing System recognizes GLOSS as one of the international operational activities that provides essential sea level climate data. The GLOSS Global Core Network is comprised of 290 globally distributed sea level stations (GLOSS 2012). This manual differs from existing QC procedures for WL in that its focus is on real-time data. It presents a series of 11 tests that operators can incorporate into practices and procedures for QC of WL measurements. These tests apply only to the in-situ, real-time measurement of WL as observed by sensors deployed on fixed platforms and not to remotely sensed WL measurements (e.g., satellite observations).   -OPS). A balance must be struck between the time-sensitive needs of real-time observing systems and the degree of rigor that has been applied to non-real-time systems by operators with decades of QC experience. High quality marine observations require sustained quality assurance (QA) and QC practices to ensure credibility and value to operators and data users. QA practices involve processes that are employed with hardware to support the generation of high quality data, such as a sufficiently accurate, precise, and reliable sensor with adequate resolution. Other QA practices include: sensor calibration; calibration checks and/or in-situ verification, including post-deployment calibration; proper deployment considerations, such as measures for corrosion control and anti-fouling; solid data communications; adequate maintenance intervals; and creation of a robust quality control process. Post-deployment calibration (instrument verification after recovery) issues are not part of the scope of this manual. Although QC and QA are interrelated and both are important to the process, QA is not the focus of this manual. However, QA considerations are briefly addressed in appendix A. QC involves follow-on steps that support the delivery of high quality data and requires both automation and human intervention. QC practices include such things as format, checksum, timely arrival of data, threshold checks (minimum/maximum rate of change), neighbor checks, climatology checks, model comparisons, signal/noise ratios, verification of user satisfaction, and generation of data flags (Bushnell 2005). The process of ensuring data quality is not always straightforward. QA/QC procedures may be specific to a sensor technology or even to a particular manufacturer's model, so the establishment of a methodology that is applicable to every sensor is challenging."}, {"section_title": "Constraints", "text": ""}, {"section_title": "Datums and Leveling Considerations", "text": "Observed water levels are reported relative to another vertical elevation that serves as a reference point or datum (Gill et al. 2001). Vertical datums can be a local station datum (relative only to some fixed hardware point or arbitrary value), a tidal datum (such as mean lower low water), a gravimetric datum (such as the North American Vertical Datum of 1988 [NAVD88], based on an equipotential gravity surface commonly called the geoid), or a geodetic datum (the fundamental datum for GPS satellites and based on a mathematical model of the earth called an ellipsoid). To monitor station stability and provide continuity when replacing a WL station, several nearby bench marks are typically installed, and the local station datum and tidal datum elevations are determined relative to them (Hicks 1987). The number of bench marks deployed depends upon the application of the operator, and as many as ten can be called for when the WL station is used for the most demanding applications, such as longterm sea level changes. Three stable bench marks are required to demonstrate stability, and more bench marks are typically required as the duration of station operation increases. Some operators consider the bench marks the most important part of a WL station, as they preserve the tidal datums established by the station long after it is gone. For more detailed information about datums, bench marks, and geodetic leveling, see http://tidesandcurrents.noaa.gov/pub.html#Benchmarks,%20Leveling%20and%20Geodetic%20References. While datums and leveling are beyond the scope of this manual, their importance must be noted, as they are critical to the successful use of the WL data. Gradual station subsidence or rise, datum determinations, and leveling precision are not issues that can be addressed through real-time QC, but they are vitally important to the QA of the observing system and its corresponding data. It is especially critical for operators to correctly convey the datum in use to users and to include this important metadata with every water level observation."}, {"section_title": "Data Processing Methodology", "text": "The type of sensor system used to collect WL data and the system used to process and transmit the WL measurements determine which QC algorithms are used. In-situ systems with sufficient on-board processing power within the sensor may process the original (raw) data and produce derived products, such as water density or speed of sound. Many sensors may sample at high-rate or burst mode (e.g., 1 Hz). These samples are used to produce the actual real-time value transmitted (e.g., 6-minute value). Statistical information about the high rate sample distributions can also be used and transmitted as real-time QC parameters (e.g., sample standard deviations and outliers). If ample transmission capability is available, the entire original data stream may be transmitted ashore and subsequently quality controlled from there. Therefore, because operators have different data processing methodologies, three levels of QC are proposed: required, strongly recommended, and suggested."}, {"section_title": "Traceability to Accepted Standards", "text": "To ensure that WL sensors produce accurate data, rigorous calibrations and calibration checks must be performed in addition to QC checks. Most operators rely upon manufacturer calibrations and conduct calibration checks only before deployment. These calibration checks are critical to ensuring that the manufacturer calibration is still valid. Manufacturers describe how to conduct these calibration checks in their user manuals, which are currently considered QA and further addressed in appendix A. Calibrations and calibration checks must be traceable to accepted standards. The National Institute of Standards and Technology (NIST) (http://www.nist.gov/index.html), a provider of internationally accepted standards, is often the source for accepted standards. Calibration activities must be tailored to match data use and resources. Calibration cost and effort increase dramatically as accuracy requirements increase. Fundamental NIST standards such as length, temperature, and pressure will suffice when conducting calibration checks on most WL sensors."}, {"section_title": "Sensor Deployment Considerations and Hardware Limitations", "text": "WL sensors can be deployed in several ways. Most sensors are fixed to platforms that are designed to ensure minimal vertical or horizontal movement, and they observe the water level from at or above the surface. Pressure sensors may be directly submerged or configured within a bubbler system to observe the back pressure. GPS buoys, which measure water elevation derived from a GPS antenna position, are under development; this technology should improve as GPS accuracy and real-time processing capability improve. While outside the scope of the real-time tests described in this manual, QA is critical to data quality. Sensors require attention to proper QA measures both before and after the deployment. Operators must follow the manufacturer's recommendations for factory calibration schedules and proper sensor maintenance. The following sections describe the sensor technologies that are most often used, with a brief note about their attributes and shortcomings."}, {"section_title": "Microwave", "text": "Microwave altimeters have become popular within the past decade as this technology has evolved. While free of many of the drawbacks of other WL sensors, microwave technology brings new modes of failure, for example, unknown performance in the presence of large waves, the inability to measure water levels in the presence of ice, and surprise occasional problems such as a bee's nest in the sensor horn.  "}, {"section_title": "Acoustic", "text": "Acoustic altimeters typically use a sounding tube but can also operate in open air. They are sensitive to variations in the speed of sound caused by temperature changes and temperature gradients along the sound path. Sounding tubes may become obstructed with biota or ice, causing errors in the measurements. Effects of waves and currents have been partially mitigated using protective wells and orifice configurations (which may be expensive to install and maintain, depending on the project).  "}, {"section_title": "Float/Stilling Wells", "text": "Floats deployed in stilling wells are an old and proven technology. These systems can be fortified to operate in the presence of ice, but they are expensive to install. Intakes can become clogged with sediment, and the mechanisms used to transfer the float elevation to sensors (e.g., shaft-angle encoders) can have unique failure modes. Stilling wells in tidal areas are known to cause significant error in WL observations in the presence of high waves and currents. Figure 2-3 shows a typical NOS/CO-OPS Great Lakes installation of dual shaftangle encoders and their respective floats deployed in the stilling well, also referred to as the sump. Sumps are large stilling wells that have an intake valve used to dampen wave action that might be transferred through the intake pipe to the sump. "}, {"section_title": "Pressure Sensors", "text": "Pressure sensors can be immune to ice, but pressure readings must be adjusted for variations in barometric pressure and water density in real time as part of the conversion to derived real-time water level measurements. Pressure sensors can be vented to the atmosphere to automatically account for variations in atmospheric pressure; however, water density variations still must be accounted for. Sensor drift can be an issue for lowquality sensors, and moisture damage in the air tube is a common failure mode. Allowance for gravity variations must also be made at each installation site. Figure 2-4 provides a generalized schematic of a typical pressure sensor installation as used by the U.S. Geological Survey (USGS) and many others. The back pressure observed by a sensor that is not submerged yields a much more robust system. Figure 2-5 shows a typical NOS/CO-OPS backup pressure sensor orifice installation, which includes the use of parallel plates to reduce draw-down in the presence of currents.  "}, {"section_title": "Lasers", "text": "Infrared laser altimeters reflect well from the sea surface, and sensor performance has improved while costs have decreased. However, performance in fog and heavy rain may not be optimum. The sensors are also affected by high waves and ice or other obstructions in the laser path.  "}, {"section_title": "GPS Buoys", "text": "The accuracy of elevations derived by GPS continues to improve as enhancements are made to national and international global navigation satellite systems (GNSS). The location of the GPS sensor reference point must be calibrated to reflect the water level on the buoy. The on-board processing system must use a tilt-motion sensor to account for wave action. Mooring configurations must be designed to mitigate effects of high currents. Water density variations and bio-fouling can also create biases. GPS data processing is complicated for real-time application and may require shore-based systems for real-time kinematic deployments. Technology-specific QC checks based upon GNSS parameters, such as Positional Dilution of Precision, number of satellites in view, and ephemeris update rates, will be added as this capability evolves. Figure 2-7 shows a GPS buoy on the deck of a small vessel getting ready for deployment. This particular buoy does not provide real-time water level data and requires post-processing of the GPS data. However, real-time information is obtained on buoy performance and operational status. These systems are presently undergoing evaluation by multiple offices within NOAA/NOS. "}, {"section_title": "Applications of WL Data", "text": "Real-time water levels are important for a wide variety of applications, including: Hydrographic and shoreline mapping surveys Safe navigation and vessel transit -draft/air gap Safe vessel docking and close-in maneuvering Commercial fishing Recreational boating Storm surge/inundation/evacuation Tsunami detection Operation of coastal engineering structures Input into operational nowcast/forecast system (models) runs Understanding the impacts of sea level rise and inundation on coastal habitat Other applications, such as monthly and annual mean water levels, do not require real-time QC but benefit from it through early detection of WL station issues."}, {"section_title": "Quality Control", "text": "The real-time QC of WL observations can be extremely challenging. Events such as storm surge, tsunamis, and strong winds can affect water levels and must be considered when determining acceptable data thresholds. Human involvement is therefore important to ensure that solid scientific principles are applied to data evaluation to ensure that good data are not discarded and bad data are not distributed (e.g., selection of appropriate thresholds and examination of data flagged as questionable). To conduct real-time QC on WL observations, the first pre-requisite is to understand the science and context within which the measurements are being conducted. For example and as was discussed in section 2.2.4, sensors can be deployed in a number of ways. Each deployment method imposes the need for specific QC methods, with different interpretations of 'real time.' Real-time WL data should have two main attributes: accurate time and accurate elevation relative to a known reference. This manual focuses specifically on real-time data. For example, for real-time QC, gradual calibration changes or system responses (sensor drift) cannot be detected or corrected. Drift correction for WL measurements during post-processing is difficult even if a valid post-recovery calibration could be obtained. Drift is often caused by bio-fouling, silting/sediment clogging, etc. and affects different systems in different ways (e.g., a sensor's response will be affected by the added mass of bio-fouling). Another example is the ability of some data providers to backfill data gaps. In both of these examples, the observations are not considered to be real time for purposes of QC checks. (However, in some sophisticated 24/7 QC operations, real-time dissemination may be switched from one sensor to another based on real-time QC flags.)"}, {"section_title": "QC Flags", "text": "Data are evaluated using QC tests, and the results of those tests are recorded by inserting flags in the data files. Table 3-1 provides the set of flags and associated descriptions adopted by the International Oceanographic Data and Information Exchange in 2013 and subsequently by U.S. IOOS. Additional flags may be incorporated to provide more detailed information to assist with troubleshooting. For example, an observation may fail the water level min/max test and be flagged as having failed. If the data failed the water level min/max by exceeding the upper limit, a \"failed high\" flag may indicate that the values were higher than the expected range. Such detailed flags primarily support maintenance efforts and are presently beyond U.S. IOOS requirements for QC of real-time data. However, all flags must be identified and defined in the metadata. Further post processing of the data may yield different conclusions from those reached during initial assessments. Flags set in real time should not be changed, ensuring that historical documentation is preserved. Results from post processing should generate another set of flags corresponding to a revised version of the data. Observations are time ordered, and the most recent observation is n0, preceded by a value at n-1, and so on backwards in time. The focus of the real-time QC is primarily on observations n0, n-1, and n-2. "}, {"section_title": "Flag Description", "text": ""}, {"section_title": "Pass=1", "text": "Data have passed critical real-time QC tests and are deemed adequate for use as preliminary data.\nApplies for test pass condition. N/A Test Exception: None. Test specifications to be established locally by operator. Examples: N_DEV = 3, TIM_DEV = 25. Some operators use station-specific values, ranging from about 0.02 meter/6-minute sample, to about 0.50 meter/6-minute sample."}, {"section_title": "Not Evaluated=2", "text": "Data have not been QC-tested, or the information on quality is not available."}, {"section_title": "Suspect or Of High Interest=3", "text": "Data are considered to be either suspect or of high interest to data providers and users. They are flagged suspect to draw further attention to them by operators."}, {"section_title": "Fail=4", "text": "Data are considered to have failed one or more critical real-time QC checks. If they are disseminated at all, it should be readily apparent that they are not of acceptable quality.\nReported value is outside of sensor span.  Test that data point falls within seasonal expectations. This test is a variation on the gross range check, where the gross range Season_MAX and Season_MIN are adjusted monthly, seasonally, or at some other operator-selected time period (TIM_TST). Expertise of the local operator is required to determine reasonable seasonal averages. Longer time series permit more refined identification of appropriate thresholds. Data point n-1 exceeds a selected threshold relative to adjacent data points.\nNo fail flag is identified for this test. N/A\nWhen the five most recent observations are equal, T n is flagged fail. For i=1,REP_CNT_FAIL, If WL n -WL n-i <EPS , flag = 4"}, {"section_title": "Missing Data=9", "text": "Data are missing; used as a placeholder."}, {"section_title": "Test Hierarchy", "text": "This section outlines eleven real-time QC tests that are required, recommended, or suggested for WL measurements. Operators should also consider that some of these tests can be carried out within the instrument, where thresholds can be defined in configuration files. Although more tests may imply a more robust QC effort, there are many reasons operators could use to justify not conducting some tests. In those cases, operators need only to document reasons these tests do not apply to their observations. Such flexibility is needed to support the U.S. IOOS effort, since the number of tests conducted and the justification for not applying some tests are useful for evaluating an operator's skill levels. Tests are listed in table 3-2 and are divided into three groups: those that are required, strongly recommended, or suggested. However, for some critical real-time applications with high risk operations, it may be advisable to invoke all groups. "}, {"section_title": "QC Test Descriptions", "text": "A variety of tests can be performed on the sensor measurements to evaluate data quality. Testing the timely arrival and integrity of the data transmission itself is a first step. If the data are corrupted during transmission, further testing may be irrelevant. The checks defined in these eleven tests evaluate data through various comparisons to other data and to the expected conditions in the given environment. The tests listed in this section presume a time-ordered series of observations and denote the most recent observation as previously described. Some effort will be needed to select the best thresholds, which are determined at the operator level and may require multiple iterations of trial and error before final selections are made. A successful QC effort is highly dependent upon selection of the proper thresholds, which should not be determined arbitrarily but can be based on historical knowledge or statistics derived from recently acquired data. Although this manual provides some guidance for selecting thresholds based on input from various operators, it is assumed that operators have the necessary expertise as well as a sincere interest in selecting the proper thresholds to maximize the value of their QC effort. Operators should openly provide thresholds as metadata for user support. Elevation thresholds chosen may be dependent upon the real-time application, (e.g., chart datum or inundation threshold level). This shared information will help U.S. IOOS to document standardized thresholds that will be included in future releases of this manual."}, {"section_title": "Applications of QC Tests to WL Sensors", "text": "These eleven tests require operators to select a variety of thresholds. Examples are provided in the following test tables; however, operators are in the best position to determine the appropriate thresholds for their operations. Some tests rely on multiple data points most recently received to determine the quality of the latest data point. When this series of data points reveals that the entire group fails, the most recent data point is flagged, but the previous flags are not changed. This action supports the view that historical flags are generally not altered. The first example is in Test 8, the Flat Line Test, where this scenario will become clearer. The exception to the rule occurs for Test 6 Spike Check, where the most recent point must be flagged as \"2 Not Evaluated\" until the next point arrives and the spike check can be performed. For additional information regarding flags, see the Manual for the Use of Real-Time Oceanographic Data Quality Control Flags (U.S. IOOS 2014) posted on the U.S. IOOS QARTOD website."}, {"section_title": "Test 1 -Timing/Gap Test (Required)", "text": "Check for arrival of data. Test determines that the most recent data point has been measured and received within the expected time window (TIM_INC) and has the correct time stamp (TIM_STMP). Note: For those systems that do not update at regular intervals, a large value for TIM_STMP can be assigned. The gap check is not a solution for all timing errors. Data could be measured or received earlier than expected. This test does not address all clock drift/jump issues. Data point exceeds sensor or operator-selected min/max."}, {"section_title": "Flags", "text": "\n\n\n\n\n\n"}, {"section_title": "Condition", "text": "All sensors have a limited output range, and this can form the most rudimentary gross range check. No values less than a minimum value or greater than the maximum value the sensor can output (SENSOR_MIN, SENSOR_MAX) are acceptable. Additionally, the operator can select a smaller span (USER_MIN, USER_MAX) based upon local knowledge or a desire to draw attention to extreme values.\nThis check has the potential to be the most useful test when a nearby second sensor is determined to have a similar response. Ideally, redundant sensors utilizing different technology would be co-located and alternately serviced at different intervals. This close neighbor would provide the ultimate QC check, but cost may prohibit such a deployment in most cases. However, there are few instances where a second sensor is sufficiently proximate to provide a useful QC check. WL observations are more readily compared to adjacent sites then many non-conservative observations (such as dissolved oxygen, for example), and this test should not be overlooked where it may have application. This test is the same as Test 9, Multi-Variate Check -comparison to other variables where the second variable is the second sensor. The selected thresholds depend entirely upon the relationship between the two sensors as determined by the local knowledge of the operator. In the instructions and examples below, data from one site (WL1) are compared to a second site (WL2). The standard deviation for each site (SD1, SD2) is calculated over the period (TIM_DEV) and multiplied as appropriate (N_WL1_DEV for site WL1) to calculate the rate of change threshold. Note that an operator could also choose to use the same threshold for each site, since the sites are presumed to be similar. A unique and highly valuable version of the neighbor check is the surrogate use of WL forecasts. These 'virtual neighbor' constructs offer a QC check that is also presumed to be similar-again, within user-selected thresholds. \n"}, {"section_title": "NOTE:", "text": "Operators may choose to flag as suspect values that exceed the calibration span but not the hardware limits (e.g., a value that sensor is not capable of producing).\nIn a more complex case, more than one secondary rate of change test can be conducted. Wave height or current speed are possible secondary candidates and could be checked for anomalous rate of change values. In this case, a knowledgeable operator may elect to assign a pass flag to a high rate of change observation when any one of the secondary variables also exhibits a high rate of change. Such tests border on modeling, should be carefully considered, and may be beyond the scope of this effort. The QARTOD WL committee recognized the high value in full co-variance testing but also noted the challenges. Such testing remains a research project not yet ready for operational implementation."}, {"section_title": "Condition Codable Instructions", "text": "\nThis check is for single-value spikes, specifically the value at point n-1. Spikes consisting of more than one data point are difficult to capture, but their onset may be flagged by the rate of change test. The spike test consists of two operator-selected thresholds, THRSHLD_LOW and THRSHLD_HIGH. Adjacent data points (n -2 and n 0 ) are averaged to form a spike reference (SPK_REF). The absolute value of the spike is tested to capture positive and negative spikes. Large spikes are easier to identify as outliers and flag as failures. Smaller spikes may be real and are only flagged suspect. The thresholds may be fixed values or dynamically established (for example, a multiple of the standard deviation over an operator-selected period). This test inspects the time series for a time rate of change that exceeds a threshold value identified by the operator. WL values can change substantially over short periods in some locations, hindering the value of this test. A balance must be found between a threshold set too low, which triggers too many false alarms, and one set too high, making the test ineffective. Test implementation can be challenging. Upon failure, it is unknown which point is bad. Further, upon failing a data point, it remains to be determined how the next iteration can be handled. The following suggest two ways to select the thresholds: 1) The rate of change between WL n-1 and WL n must be less than three standard deviations (3*SD). The SD of the WL time series is computed over the previous 25-hour period (operator-selected value) to accommodate cyclical diurnal and other tidal fluctuations. The local operator determines both the number of SDs (N_DEV) and the period over which the SDs are calculated (TIM_DEV). 2) The rate of change between WL n-1 and WL n must be less than 0.1 meter +2SD.\n\n"}, {"section_title": "Suspect=3", "text": "The rate of change exceeds the selected threshold. If |WL n -WL n-1 |>N_DEV*SD, flag = 3\nIt is possible but unlikely that the present observation and the two previous observations would be equal. When the three most recent observations are equal, T n is flagged suspect. "}, {"section_title": "Test 8 -Flat Line Test (Strongly Recommended)", "text": "Invariant value. When some sensors and/or data collection platforms fail, the result can be a continuously repeated observation of the same value. This test compares the present observation n to a number (REP_CNT_FAIL or REP_CNT_SUSPECT) of previous observations. Observation n is flagged if it has the same value as previous observations within a tolerance value, EPS, to allow for numerical round-off error. Note that historical flags are not changed."}, {"section_title": "Test 10 -Attenuated Signal Test (Suggested)", "text": "A test for inadequate variation of the time series. A common sensor failure mode can provide a data series that is nearly but not exactly a flat line (e.g., if a well orifice becomes wrapped in debris). This test inspects for an SD value or a range variation (MAX-MIN) value that fails to exceed threshold values (MIN_VAR_WARN, MIN_VAR_FAIL) over a selected time period (TST_TIM). Comparison to nearby sensors."}, {"section_title": "Summary", "text": "The QC tests in this WL manual have been compiled using the guidance provided by all QARTOD workshops (QARTOD 2003(QARTOD -2009. Test suggestions came from operators with extensive experience. Wherever possible, redundant tests have been merged. In some instances, tests have been simplified and are less rigorous than those offered by established providers of WL data. A balance must be struck between the time-sensitive needs of real-time observing systems and the degree of rigor that has been applied to non-realtime systems by operators with decades of QC experience. The eleven data QC tests identified in this manual apply to WL observations from a variety of sensor types and platforms that may be used in U.S. IOOS. Since several existing programs such as NWLON and GLOSS have already developed QC tests that are similar to the U.S. IOOS QARTOD tests in this manual, the QARTOD WL committee's objective is for the QC tests of these programs to comply with U.S. IOOS QARTOD requirements and recommendations. The individual tests are described and include codable instructions, output conditions, example thresholds, and exceptions (if any). Selection of the proper thresholds is critical to a successful QC effort. Thresholds can be based on historical knowledge or statistics derived from more recently acquired data and should not be determined arbitrarily. This manual provides some guidance for selecting thresholds based on input from various operators, but also notes that operators need the subject matter expertise in selecting the proper thresholds to maximize the value of their QC effort. Future QARTOD manuals will address standard QC test procedures and best practices for all types of common as well as uncommon platforms and sensors for all the U.S. IOOS core variables. Some test procedures may even take place within the sensor package. Significant components of metadata will reside in the sensor and be transmitted either on demand or automatically along with the data stream. Users may also reference metadata through Uniform Resource Locators to simplify the identification of which QC steps have been applied to data. However, QARTOD QC test procedures in this manual address only real-time, in-situ observations made by sensors on fixed platforms or GPS buoys. The tests do not include post processing, which is not conducted real time but may be useful for ecosystem-based management, or delayed mode, which is required for climate studies. Each QC manual is envisioned as a dynamic document and will be posted on the QARTOD website at www.ioos.noaa.gov/qartod/. This process allows for QC manual updates as technology development occurs for both upgrades of existing sensors and new sensors."}, {"section_title": "Quality Assurance Appendix A.", "text": "A major pre-requisite for establishing quality control standards for WL measurements is a strong quality assurance program. Remember the mantra that good QC requires good QA, and good QA requires good scientists, engineers, and technicians. A good QA effort continuously seeks to ensure that end data products are of high value and strives to prove they are free of error. Operators should seek out partnering opportunities to inter-compare systems by colocation of differing sensors, thereby demonstrating high quality by both to the extent that there is agreement and providing a robust measure of observation accuracy by the level of disagreement. Operators should also, if possible, retain an alternate sensor or technology from a second vendor for similar in-house checks. The lists in the following sections suggest ways to ensure QA by using specific procedures and techniques. Operators should also follow instructions provided by the sensor manufacturer."}, {"section_title": "A.1 Sensor Calibration Considerations", "text": "Observations must be traceable to one or more accepted standards through a calibration performed by the manufacturer and/or the operator. If the calibration is conducted by the manufacturer, the operator must also conduct some form of an acceptable calibration check. NIST provides a wealth of information on standards and calibrations for many variables, including time, temperature, and pressure. Virtually all manufacturers provide calibrations traceable to NIST standards as part of their standard product services. An often overlooked calibration or calibration check can be performed by choosing a consensus standard. For example, deriving the same answer (within acceptable levels of data precision or data uncertainty) from four different sensors of four different vendors, preferably utilizing several different technologies, constitutes an acceptable check. Because of the trend towards corporate conglomeration, those wishing to employ a consensus standard should ensure that the different vendors are truly independent."}, {"section_title": "A.2 Sensor Comparison", "text": "An effective QA effort continuously strives to ensure that end data products are of high value and to prove they are free of error. Operators should seek out partnering opportunities to inter-compare systems by colocating differing sensors. Agreement of multiple systems would provide a robust observation, while disagreement may offer a measure of data uncertainty. If possible, operators should retain an alternate sensor or technology from a second vendor for similar in-house checks. For resource-constrained operators, however, it may not be possible to spend the time and funds needed to procure and maintain two systems. For those who do so and get two different results, the use of alternate sensors or technologies provide several important messages: a) a measure of corporate capabilities; b) a reason to investigate, understand the different results, and take corrective action; and c) increased understanding that when variables are measured with different technologies, different answers can be correct, and they must be understood in order to properly report results. For those who succeed, the additional sensors provide a highly robust demonstration of capability. Such efforts form the basis of a strong QA/QC effort. Further, it provides the operator with an expanded supply source, permitting less reliance upon a single vendor and providing competition that is often required by procurement offices."}, {"section_title": "A.5 QA Levels for Best Practices", "text": "A wide variety of techniques are used by operators to assure that sensors are properly calibrated and operating within specifications. While all operators must conduct some form of validation, there is no need to force operators to adhere to one single method. A balance exists between available resources, level of proficiency of the operator, and target data reproducibility requirements. The various techniques span a range of validation levels and form a natural hierarchy that can be used to establish levels of certification for operators (table A-1). The lists in the following sections suggest ways to ensure QA by using specific procedures and techniques. "}, {"section_title": "Better Process", "text": "Good process, plus an overlapping operational period during sensor swap-out to demonstrate continuity of observations."}, {"section_title": "Best Process", "text": "Better process, and follow a well-documented protocol or alternative sensors to validate in-situ deployments. Or, the better process employing manufacturer conducted pre-and post-calibrations."}, {"section_title": "A.6 Additional Sources of QA Information", "text": "WL sensor operators also have access to other sources of QA practices and information about a variety of instruments. For example, the Alliance for Coastal Technologies (ACT) serves as an unbiased, third party test bed for evaluating sensors and platforms for use in coastal and ocean environments. ACT conducts instrument performance demonstrations and verifications so that effective existing technologies can be recognized and promising new technologies can become available to support coastal science, resource management, and ocean observing systems (ACT 2012). The NOAA Ocean Systems Test and Evaluation Program (OSTEP) also conducts independent tests and evaluations on emerging technology as well as new sensor models. Both ACT and OSTEP publish findings that can provide information about QA, calibration, and other aspects of sensor functionality. The following list provides links to additional resources on QA practices. Manufacturer specifications and supporting Web pages/documents QARTOD -http://www.ioos.noaa.gov/qartod/ ACT -http://www.act-us.info/ CO-OPS -http://tidesandcurrents.noaa.gov/pub.html under the heading Manuals and Standards World Ocean Circulation Experiment http://woce.nodc.noaa.gov/wdiu/ National Data Buoy Center http://www.ndbc.noaa.gov/"}]