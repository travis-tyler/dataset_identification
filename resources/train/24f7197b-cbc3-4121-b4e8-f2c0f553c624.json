[{"section_title": "Abstract", "text": "Deep learning (DL) is a family of machine learning methods that has gained considerable attention in the scientific community, breaking benchmark records in areas such as speech and visual recognition. DL differs from conventional machine learning methods by virtue of its ability to learn the optimal representation from the raw data through consecutive nonlinear transformations, achieving increasingly higher levels of abstraction and complexity. Given its ability to detect abstract and complex patterns, DL has been applied in neuroimaging studies of psychiatric and neurological disorders, which are characterised by subtle and diffuse alterations. Here we introduce the underlying concepts of DL and review studies that have used this approach to classify brain-based disorders. The results of these studies indicate that DL could be a powerful tool in the current search for biomarkers of psychiatric and neurologic disease. We conclude our review by discussing the main promises and challenges of using DL to elucidate brain-based disorders, as well as possible directions for future research."}, {"section_title": "Introduction", "text": "In the last two decades, neuroimaging studies of psychiatric and neurological patients have relied on mass-univariate analytical techniques (e.g. statistical parametric mapping). These studies typically compared patients with a diagnosis of interest against disease-free individuals and reported neuroanatomical or neurofunctional differences at group level. The simplicity and interpretability of this approach have led to significant advances in our understanding of the neurobiology of psychiatric and neurological disorders. Mass-univariate analytical techniques, however, suffer from at least two significant limitations. First, statistical inferences are drawn from multiple independent comparisons (i.e. one for each voxel) based on the assumption that different brain regions act independently. This assumption, however, is not in line with our current understanding of brain function in health and disease (Fox et al., 2005; Biswal et al., 2010) ; for example, several psychiatric and neurological symptoms are best explained by network-level changes in structure and function rather than focal alternations (Mulders et al., 2015; Kennedy and Courchesne, 2008; Sheffield and Barch, 2016) . Second, mass-univariate techniques can be used to detect differences between groups but do not allow statistical inferences at the level of the individual. In contrast, a clinician has to make diagnostic and treatment decisions about the person in front of them. These two limitations may have contributed to the limited translational impact of neuroimaging findings in everyday clinical practice so far.\nIn an attempt to overcome these limitations, the neuroimaging community has developed a growing interest in machine learning (ML), an area of artificial intelligence that aims to develop algorithms that discover trends and patterns in existing data and use this information to make predictions on new data. This is achieved through the use of computational statistics and mathematical optimization (Hastie et al., 2001) . ML methods are multivariate and therefore take the inter-correlation between voxels into account, thereby overcoming the first limitation of mass-univariate analytical techniques. In addition, ML methods allow statistical inferences at single subject level and therefore could be used to inform diagnostic and prognostic decisions of individual patients, thereby overcoming the second limitation of mass-univariate analytical techniques (Arbabshirani et al., 2016) . ML methods can be divided into two broad categories: supervised and unsupervised learning. In supervised ML, one seeks to develop a function which maps two or more sets of observations to predefined categories or values. In contrast, unsupervised methods seek to determine how the data are organized without using any a priori information supplied by the operator; here the main objective is to discover unknown structure in the data (Hastie et al., 2001 ).\nOver the past decade, several ML methods have been applied to neuroimaging data from psychiatric and neurological patients with varying degrees of success (Arbabshirani et al., 2016; Wolfers et al., 2015) . The most popular amongst these methods is Support Vector Machine (SVM), a supervised technique that works by estimating an optimal hyperplane that best separates two classes. When these classes are not linearly separable, SVM uses external functions (kernels) that map the original data into a new feature space where the data become linearly separable (Pereira et al., 2009; Vapnik, 1995) . Despite its popularity, SVM has been criticised for not performing well on raw data and requiring the expert use of design techniques to extract the less redundant and more informative features (a step known as \"feature selection\") (LeCun et al., 2015; Plis et al., 2014) . These features, rather than the original data, are then used for classification. While SVM remains a very popular technique within the neuroimaging community, an alternative family of ML methods known as deep learning (DL) (Bengio, 2009 ) is gaining considerable attention in the wider scientific community (Arbabshirani et al., 2016; Calhoun and Sui, 2016; LeCun et al., 2015) . Deep learning methods are a type of representation-learning methods, which means that they can automatically identify the optimal representation from the raw data without requiring prior feature selection. This is achieved through the use of a hierarchical structure with different levels of complexity, which involves the application of consecutive nonlinear transformations to the raw data. These transformations result in increasingly higher levels of abstraction, where higher-level features are more invariant to the noise present in the input data than lower level ones (LeCun et al., 2015) . Inspired by how the human brain processes information, the building blocks of DL neural networks \u2212 known as \"artificial neurons\" \u2212 are loosely modelled after biological neurons. Artificial neurons are organized in layers. A deep neural network consists of an input layer, two or more hidden layers and an output layer. The input layer comprises the data inputted into the model (e.g. voxel intensity); the hidden layers learn and store increasingly more abstract features of the data; these features are then fed to the output layer that assigns the observations to classes (e.g. controls vs. patients). Learning is achieved through an iterative process of adjustment of the interconnections between the artificial neurons within the network, much like in the human brain (Bengio, 2009 ). An essential aspect of DL that differentiates it from other ML methods is that the features are not manually engineered; instead, they are learned from the data, resulting in a more objective and less bias-prone process. Besides, the ability to achieve higher orders of abstraction and complexity relative to other ML methods such as SVM makes DL better suited for detecting complex, scattered and subtle patterns in the data (Plis et al., 2014) .\nFrom a historical perspective, the use of DL in scientific research can be traced back to the perceptron (i.e. the original version of the artificial neuron), which many researchers refer to as the first ML algorithm (McCulloch and Pitts, 1943) . After several setbacks, the pioneering work of Warren McCulloch and Walter Pitts resulted in the development of what is now known as artificial neural networks. However, such networks were able to handle a limited number of hidden layers. It was only in the 2000s that researchers developed a new approach for training artificial neural networks that allowed the inclusion of several hidden layers resulting in greater levels of complexity (Hinton et al., 2006) . This breakthrough led to the development of a new family of ML methods \u2212 known as deep learning \u2212 which has been shown to outperform previous state-of-the-art classification methods in areas such as speech recognition, computer vision and natural language processing (Krizhevsky et al., 2012; Le et al., 2012) .\nThe use of DL could be particularly useful in the investigation of psychiatric and neurological disorders, which tend to be associated with subtle and diffuse neuroanatomical and neurofunctional abnormalities. Since high-level features can be more robust against noise in the input data, deep architectures may be more suitable to identify diagnostic and prognostic biomarkers than conventional ML methods. DL techniques might also provide an ideal tool to investigate the multi-faceted nature of psychiatric and neurological disorders since cross-modality relationships (e.g. neuroimaging and genetics) are likely to occur at an even deeper level (Plis et al., 2014) . In addition to these conceptual differences, the use of DL to investigate psychiatric and neurological disorders has the practical advantage of not requiring manual feature selection (LeCun et al., 2015) . Therefore, it is unsurprising that an increasing number of neuroimaging studies are using DL to elucidate the neural correlates of these disorders (e.g. Payan and Montana, 2015; Plis et al., 2014; Kim et al., 2016) .\nGiven the insurgence of interest in DL within the field of neuroimaging, this review aims to give a brief overview of DL and potential applications to the investigation of brain-based disorders. In the first part of the review, we outline the underlying concepts of DL. To achieve this, we will use one of the simplest DL structures, i.e. the multilayer perceptron, to illustrate the steps of training and testing. This will be followed by a brief description of the most common DL architectures used in the field of neuroimaging, including stacked autoencoders, deep belief networks and convolutional neural networks. The second part of this article aims to summarise the studies that have applied DL to neuroimaging data to investigate psychiatric and neurological disorders. Finally, in the third part of the review, we discuss the main themes that have emerged from our review of the existing literature, and make a number of suggestions for future research directions."}, {"section_title": "Overview", "text": "Deep learning refers to the training and testing of multi-layered neural networks that are capable of learning complex structures and achieve high levels of abstraction. There are two main types of DL models which differ with respect to how the information is propagated through the network. In feedforward networks, the information is propagated through the network in just one direction, from the input to the output layer. Recurrent networks, in contrast, contain feedback connections that allow the information from past inputs to affect the current output. These connections enable the information to persist within the neural network, akin to a form of memory, and this allows the models to process sequential data, such as speech and language, in a natural way.\nThe implementation of DL in the context of supervised classification problems involves two main steps. In the first step, the so-called training phase, a subset of the available data known as the training set is used to optimize the network's parameters to perform the desired task (classification). In the second step, the socalled testing phase, the remainder subset which is known as the test set is used to assess whether the trained model can blind-predict the class of new observations. When the amount of available data is limited, it is also possible to run the training and testing phases several times on different training and test splits of the original data and then estimate the average performance of the model \u2212 an approach known as cross-validation. The two phases of training and testing are not a specific feature of DL but are used in conventional ML methods.\nIn this section, we will discuss the use of feedforward DL for classification problems. We will start with the multilayer perceptron (MLP), the simplest deep neural network (DNN) architecture, to illustrate three important aspects of deep learning \u2212 network structure, training and testing. We will then describe more complex networks, including stacked autoencoders and deep belief networks. Finally, we will describe the increasingly popular convolutional neural networks (CNN), an important adaptation of the MLP that has come to be considered the state-of-the-art for computer vision.\n2.1. Multilayer perceptron 2.1.1. Network structure\nMLPs are organized in a layer-wise structure where each layer stores increasingly more abstract representations of the data (Fig. 1) . The first layer is the input layer where the data is entered into the model. In neuroimaging, the data can be represented as a one-dimensional vector with each value corresponding to the intensity of one voxel. The last layer is the output layer which, in the context of classification, yields the probability of a given subject belonging to one group or the other. The layers between the input and output layers are called hidden layers, with the number of hidden layers representing the depth of the network. Each layer comprises a set of artificial neurons or \"nodes\" (Fig. 1a) in which each neuron is fully connected to all neurons in the previous layer (Fig. 1b) . Each connection is associated with a weight value, which reflects the strength and direction (excitatory or inhibitory) of each neuron input, much like a synapse between two biological neurons.\nUnlike SVM, which relies on expert designed transformations to handle nonlinearly separable classes, the structure of neural networks itself allows the transformation of the input space. The consecutive layers perform a cascade of nonlinear transformations that distort the input space allowing the data to become more easily separable (Fig. 2) . The optimal number of layers and nodes within each layer are not estimated as part of the learning process itself but are defined a priori. These a priori parameters, which are not optimized during the training, are called hyperparameters. It should be noted that the development of algorithms to find optimum values of these hyperparameters is an active area of research, and that at present there are no fixed rules (Bergstra et al., 2011; Gelbart et al., 2014) ."}, {"section_title": "Training", "text": "Traditionally, neural networks can learn through a gradient descent-based algorithm. The gradient descent algorithm aims to find the values of the network weights that best minimise the error (difference) between the estimated and true outputs. Since MLPs can have several layers, in order to adjust all the weights along the hidden layers, it is necessary to propagate this error backward (from the output to the input layer). This propagation procedure is called backpropagation, and allows the network to estimate how much the weights from the lower layers need to be changed by the gradient descent algorithm. Initially, when a neural network is trained, Each input x i has an associated weight w i . The sum of all weighted inputs, x i w i , is then passed through a nonlinear activation function f, to transform the preactivation level of the neuron to an output y j . For simplicity, the bias terms have been omitted. The output y j then serves as input to a node in the next layer. Several activation functions are available, which differ with respect to how they map a pre-activation level to an output value. The most commonly activation functions used are the rectifier function (where neurons that use it are called rectified linear unit (ReLU)), the hyperbolic tangent function, the sigmoid function and the softmax function. The latter is commonly used in the output layer as it can compute the probability of multiclass labels. (b) Example of a feedforward multilayer neural network (also referred to as multilayer perceptron) with two classes, in which the nodes in one layer are connected to all neurons in the next layer (fully connected network). For each neuron j in the first hidden layer, a nonlinear function is applied to the weighted sum of the inputs. The result of this transformation (y j ) serves as input for the second hidden layer. The information is propagated through the network up to the output layer, where the softmax function yields the probability of a given observation belonging to each class. the weights are set at random. When the training set is presented to the network, this forward propagates the data through the nonlinear transformation along the layers. The estimated output is then compared to the true output, and the error is propagated from the output towards the input, allowing the gradient descent algorithm to adjust the weights as required. The process continues iteratively until the error has reached its minimum value. The backpropagation algorithm does not work well with the original models of DNNs that were based on sigmoid and hyperbolic tangent nonlinearities.\nIn these models, the information of the error becomes increasingly smaller as it propagates backward from the output to the input layer, to a point where initial layers do not get useful feedback on how to adjust their weights \u2212 an issue known as the vanishing gradient problem. Therefore, initially, the use of backpropagation yielded poor solutions for networks with three or more hidden layers (Schmidhuber, 2015) . In 2006, however, Hinton and colleagues put forward the idea of \"greedy layerwise training\", which consists of two steps: 1) an unsupervised step, where each layer is trained individually and 2) a supervised step, where the previously trained layers are stacked, one additional layer is added to perform the classification (the output layer), and the whole network parameters are fine-tuned (Hinton et al., 2006) . This breakthrough led to the fast-growing interest in deep learning and enabled the development of at least two types of pre-trained networks that have shown promising results: stacked autoencoders and deep belief networks. It should be noted that these methods are not actual classifiers themselves; instead, they are networks that are pre-trained to learn useful patterns in the data and then fed to a real classifier at the final layer. These two types of networks and their unique characteristics are described in Section 2.2 and 2.3."}, {"section_title": "Testing", "text": "The performance of a deep neural network can be evaluated by several performance measures, such as sensitivity, specificity, accuracy and F-score. Sensitivity refers to the proportion of true positives correctly identified (e.g. the proportion of subjects that were predicted as patient and are true patients), and specificity refers to true negatives correctly identified (e.g. the proportion of subjects that were predicted as healthy controls and are true healthy controls). The accuracy of a classifier represents the overall proportion of correct classifications. The statistical significance of this overall accuracy can be tested using parametric tests such as permutation testing, which measures how likely the observed accuracy would be obtained by chance. Metrics such as F-score and balanced accuracy, which take into account each group's sample size, are particularly useful in cases where classes are unbalanced. The F-score is a measure that combines precision or positive predictive value (proportion of individuals classified as cases were actually cases) and sensitivity (proportion of true cases correctly classified as such). Balanced accuracy, on the other hand, corresponds to the average accuracy obtained on either class (Brodersen et al., 2010) ."}, {"section_title": "Risk of overfitting and possible strategies", "text": "Due to the use of multiple nonlinear transformations, deep networks are highly complex models that involve the estimation of a very large number of parameters. This can lead to the model learning particular fluctuations in the training data that are irrelevant In its shallow structure, an autoencoder is comprised of an input layer, that represents the original data (e.g., pixels in an image), one hidden layer that represents the transformed data, and an output layer that reconstructs the original input data. (b) Stacked autoencoder. Two simple autoencoders are stacked with a 2-class softmax classifier as the final layer. From each simple autoencoder, the output layer is discarded, and the hidden layer is used as the input layer for next autoencoder."}, {"section_title": "Fig. 4.", "text": "Generic structure of a CNN. For illustrative purpose, this example only has one layer of each type; a real-world CNN, however, would have several convolutional and pooling layers (usually interpolated) and one fully-connected layer. (a) Input layer. In its simplest way, the data is inputted into the network in such a way that each pixel corresponds to one node in the input layer. (b) Convolutional layer. A 3 \u00d7 3 filter or kernel (in green) is used to multiply the spatially corresponding 3 \u00d7 3 nodes in the image. The resulting weighted sum is then passed through a nonlinear function to derive the output value of one node in the feature map. The repetition of this same operation across all possible receptive fields results in one complete feature map. The same procedure with different kernels (in orange and blue) will result in separate complete feature maps. (c) Pooling layer. The size of each feature map can be reduced by taking the maximum value (or average) from a receptive field in the previous layer. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) for the purpose of classification \u2212 an issue known as \"overfitting\". When this happens, the model will perform very well on the training data but will not be able to replicate its performance on unseen data (Srivastava et al., 2014) . The risk of overfitting is particularly high in the context of neuroimaging, where the number of data points (e.g. number of voxels) for a subject is much larger than the total number of subjects, resulting in high-dimensional data (Arbabshirani et al., 2016) . However, there are a number of strategies that can be used to minimise the risk of overfitting, collectively known as \"regularization\". A first strategy involves the use of weight decays (e.g., L1 and L2 norms) to penalise models with very high weights. It has been observed that extreme (very low or very high) weight values in a ML model are symptomatic of the model trying to learn the regularities of the data perfectly (Moody et al., 1995) . By forcing weights to remain low, the network becomes less dependent on the training data and is able to better generalise to unseen data (Nowlan and Hinton, 1992) . A second strategy, known as dropout, consists of temporarily removing a random number of nodes and their respective incoming and outgoing connections from the network during training. This means that the contribution of dropped-out neurons to the activation of downstream neurons is temporally removed on the forward pass and that any weight updates are not applied to these neurons on the backward pass. The aim of dropout is to extract different sets of features that can independently produce a useful output, thereby allowing higher levels of generalizability (Srivastava et al., 2014) ."}, {"section_title": "Autoencoders", "text": "Autoencoders are a special case of feedforward networks which comprise of two main components. The first component, i.e. the \"encoder\", learns to generate a latent representation of the input data, whereas the second component, i.e. the \"decoder\", learns to use these learned latent representations to reconstruct the input data as close as possible to the original ( Fig. 3a) (Vincent et al., 2010) .\nSince an autoencoder does not make use of labels, its training is an unsupervised learning process. In its shallow structure, an autoencoder is comprised of three layers: an input layer, one hidden layer and an output layer. The training to perform the input-copying task can be useful to extract meaningful features of the input data. This automatic feature extraction can be performed using an error function (or loss function) that encourages the model encoder to have specific characteristics, such as sparsity of the representation (sparse autoencoders) and robustness to noise (denoising autoencoders). Since autoencoders are automatic features extractors, they can also be stacked to create a deep structure to increase the level of abstraction of learned features. In this case, the network is pre-trained, i.e. each layer is treated as a shallow autoencoder, generating latent representations of the input data. These latent representations are then used as input for the subsequent layers before the full network is fine-tuned using standard supervised learning ( Fig. 3b) (Larochelle et al., 2007) ."}, {"section_title": "Deep belief networks", "text": "Deep belief networks (DBNs), proposed by Hinton et al. (2006) , are technically the first DL models. Similar to stacked autoencoders, DBNs are comprised of stacked shallow feature extractors, known as restricted Boltzmann machines (RBMs). An RBM is composed by only two layers: a visible layer and a hidden layer. Just like autoencoders, RBMs also aim to learn and extract useful features from the data. However, RBMs differ from autoencoders with regards to their training processes. RBMs can be interpreted as a stochastic neural network. Therefore, instead of using deterministic functions and the reconstruction error (like the autoencoders), the RBM uses the maximum-likelihood estimation to find a stochastic representation of the input in its hidden layer (latent features). To do this, RBMs are usually trained using a gradient descent algorithm, with the likelihood gradient being performed by an approximation algorithm known as contrastive divergence (Hinton et al., 2006) . Here the input data, stored in the visible layer, are propagated to the hidden layer as in a feedforward network, and the resulting sum of the weighted inputs provides a measure of the neuron activation probability. The activation of hidden neurons can be thought of as the network's internal representation of the data, which is then propagated back to the visible layer in an attempt to reconstruct the input data from the network's internal representation. The network, therefore, learns by adjusting the weights based on the discrepancy between the true and reconstructed data. Similarly to autoencoders, RBMs can be stacked to create a deep network, where the hidden layer representation of one RBM serves as input layer for the following RBM, and the network can learn higher-level features from lower-level ones to arrive at an abstract representation of the data. Furthermore, the neural network corresponding to a trained DBN can be augmented by adding an output layer, where units represent the labels corresponding to the input sample. This results in a standard neural network for classification that can be further trained using supervised learning algorithms."}, {"section_title": "Convolutional neural networks", "text": "Convolutional neural networks (CNNs) are a special type of feedforward neural networks that were initially designed to process images, and as such are biologically-inspired by the visual cortex (LeCun et al., 1998) . In addition to the input and output layers, CNN can comprise of three types of layers: a convolutional layer, a pooling layer, and a fully-connected layer (Fig. 4) .\nThe convolutional layer is organized in several feature maps. Every neuron in a feature map is connected to a fixed set of neurons in a local region of the previous layer -the receptive field -in such a way that the whole image is covered (\"local connectivity\"). Within the same feature map, the connections between each neuron and the corresponding receptive field share the same weights, whereas different feature maps use different sets of weights (\"weight sharing\"). As a result of this architecture, a feature map can be thought of as a \"feature detector\" that scans the whole image for the same pattern. This pattern is usually known as the kernel. Kernels in a CNN are learned during the training process, as opposed to in SVM, where they are defined a priori. In a network with several convolutional layers, each layer codes for increasingly more abstract features (e.g. lines \u2192 edges \u2192 eyes \u2192 face). The pooling layer simply reduces the number of neurons of the previous convolutional layer. The fully-connected layers are similar to the hidden layers from the conventional MLP where the neurons are connected to all neurons from the previous layer. All combined, the properties of CNN (local connectivity, weight sharing and pooling) result in a significant reduction in the number of parameters, which in turn decreases the likelihood of overfitting, and alleviates computational processing."}, {"section_title": "Review of DL studies of psychiatric or neurological disorders", "text": "In order to identify previous applications of DL in neuroimaging studies of psychiatric or neurological disorders, a search was conducted on 1st August 2016 across several databases (PubMed, IEEE Xplore, Scopus and ArXiv) using the following search terms: (\"deep learning\" OR \"deep architecture\" OR \"artificial neural network\" OR \"autoencoder\" OR \"convolutional neural network\" OR \"deep belief network\") AND (neurology OR neurological OR psychiatry OR psychiatric OR diagnosis OR prediction OR prognosis OR outcome) AND (neuroimaging OR MRI OR \"Magnetic Resonance Imaging\" OR \"fMRI\" OR \"functional Magnetic Resonance Imaging\" OR PET OR \"Positron emission tomography\"). This review did not include EEG studies, although there is some evidence that DL can also be used with this type of data, particularly in epilepsy (Page et al., 2014) . The initial search yielded a total of 172 articles. As the next step, we screened and cross-referenced these articles for studies that had applied a deep learning model to neuroimaging data to investigate a psychiatric or neurologic condition; this identified a total of 25 articles which were relevant to our review. We organized these articles as follows: i) diagnostic studies, which aimed to classify patients from healthy controls, ii) studies on conversion to illness, which used baseline scans from individuals identified as being at high risk of developing a psychiatric or neurologic disorder to predict subsequent transition to the illness, and finally iii) studies predicting treatment response, which used baseline scans from individuals with a neurological or psychiatric diagnosis to predict * Sample sizes for the fine-tuning stage only (pre-training included an additional 386 samples). ** F-score. *** Range of accuracies obtain from the different datasets used; HC, healthy controls; SZ, schizophrenia, FEP, first episode psychosis; ADHD, attention deficit/hyperactive disorder; ADHD-C, attention-deficit/hyperactive disorder combine subtype; ADHD-I, attention-deficit/hyperactive disorder inattentive subtype; ADHD-H, attentiondeficit/hyperactive disorder hyperactive subtype; SCA2, spinocerebellar ataxia type 2; SCA6, spinocerebellar ataxia type 6; AT, ataxia-telangiectasia; TLE, temporal lobe epilepsy; AD, Alzheimer's disease; MCI, mild cognitive impairment; CC, cingulate cortex; VC, visual cortex, PFC, pre-frontal cortex; SSC, somatosensory cortex; sMRI, structural MRI; rsfMRI, resting-state functional MRI; CT, computed tomography; PET, Positron emission tomography; DTI, diffusion tensor imaging; CSF, cerebrospinal fluid; MMSE, mini mental state examination; ADASCog, Alzheimer's Disease Assessment Scale's cognitive subscale; AE, autoencoder, SAE, stacked autoencoder; FCC, fully-connected cascade; DBN, deep belief network, DBaN, deep Bayesian network; CNN, convolutional neural network; DAE, deep autoencoder; DBM, deep Boltzman machine; DW-S2 MTL, deep weighted subclass-based sparse multi-task learning; MLP, multilayer perceptron; nr, not reported. subsequent treatment response. These studies are summarised in Tables 1, 2 and 3 which provide the following information: sample size; type of data used as input; whether a whole brain (WB) or region of interest (ROI) approach was used; whether the information inputted into the model comprised of voxel or region-level features; whether feature selection was or was not used before inputting the data into the model; general type of DL architecture; diagnostic groups being investigated; and accuracy. Whenever performed, we also report the accuracies obtained for multiclass classifications, which involve discriminating between more than two classes (e.g. healthy controls vs. mild cognitive impairment vs. Alzheimer's disease)."}, {"section_title": "Diagnostic studies", "text": "Studies using DL to classify psychiatric or neurological patients from healthy individuals have used a range of neuroimaging modalities including structural MRI (sMRI), resting-state fMRI (rsfMRI), positron emission tomography (PET) and a combination of different modalities (multimodal studies) (see Table 1 ). From Table 1 it can be seen that the vast majority of these studies were carried out in Alzheimer's disease (AD) and its prodromal stage, mild cognitive impairment (MCI). In addition, a smaller number of studies examined psychosis, attention deficit/hyperactivity disorder (ADHD), cerebellar ataxia and temporal lobe epilepsy (TLE). Within each diagnostic category, we first give an overview of the studies that have used a single neuroimaging modality, followed by studies that employed a multimodal approach and, finally, studies that have combined neuroimaging and clinical data within a single classifier."}, {"section_title": "Mild Cognitive Impairment and Alzheimer Dementia", "text": "In one of the first studies using DL in AD and MCI, Gupta et al. (2013) argued that, since (i) natural images and brain imaging have similar, and therefore interchangeable, low-level features (e.g. lines and corners) and (ii) natural images, contrary to neuroimaging, are abundant, then natural images could be used to learn low level features which could then be used to identify lesions along the surface and ventricles of the brain. This process, whereby the features learned in one set of data are used to solve a problem in another set of data, is known as \"transfer learning\". Based on this premise, the authors pre-trained a sparse autoencoder to learn features from natural images, which were then applied to structural MRI data via a CNN, achieving a classification accuracy of 94.7% for AD versus controls, 86.4% for MCI versus controls and 88.1% for AD versus MCI. Consistent with the authors' hypothesis, this method outperformed the one where the learned features were extracted from the neuroimaging data (93.8%, 83.3% and 86.3% for the same comparisons, respectively). However, a few years later and using a similar approach, Payan and Montana (2015) found comparable classification accuracies using features that were learned from the structural MRI data itself. This could potentially be explained by the fact that Payan and Montana (2015) used a much larger sample, as well as by the fact that authors used 3D brain images, as opposed to 2D, which possibly contain more useful patterns for classification. Indeed, Payan and Montana (2015) reported that, in general, the models based on 3D outperformed those based on 2D brain images (AD vs. HC (2D/3D) = 95.4%/95.4%; AD vs. MCI (2D/3D) = 82.2%/86.8%; MCI vs. HC (2D/3D) = 90.1%/92.1%). The best accuracy (97.6%) from single modality studies came from Hosseini-Asl et al. (2016) , who also used transfer learning. Instead of extracting features from natural images and then fine-tuning the model on Alzheimer's patients and controls, as seen in Gupta et al. (2013); Hosseini-Asl et al. (2016) used one Alzheimer's dataset for pre-training and another independent Alzheimer's dataset to fine-tune the model. By performing the pre-training on an Alzheimer's dataset, this approach allowed for the network to extract generic features related to AD biomarkers, such as the ventricular size, hippocampus shape, and cortical thickness as opposed to more generic low-level features as in Gupta et al. (2013) . By using two independent samples during the complete learning process, the final learned features for classification are much less dataset-specific, and should therefore be more generalizable. The final model's architecture was also deeper than in previous studies, which probably also contributed to the high accuracy. Taken collectively, these studies suggest that the application of DL to structural MRI data allows the classification of individuals with AD and MCI with high levels of accuracy. Consistent with the increasing popularity of CNN models, studies that have applied either CNN or a combination of AE and CNN have shown better performances compared to those using only AE, although it should be noted that the former group of studies tended to have larger samples than the latter group. In addition, and similar to the trend reported in computer vision competitions and research, the best performances were obtained by the deepest CNN models.\nStudies of AD and MCI using resting-state imaging have also achieved promising results. For example, Han et al. (2015) designed a hierarchical convolutional sparse autoencoder (HCSAE), which essentially extracts the most discriminating features from the resting-state data and encodes them in a convolutional manner. This particular arrangement allows for the extraction of the most useful information while conserving abundant detail. The final model classified AD and controls with an 80.0% accuracy and significantly outperformed SVM, which only yielded an accuracy of 50% (Fig. 4) . While this is a promising result, the model assumed that functional networks were statistic over time \u2212 an assumption which underlies the vast majority of ML applications to restingstate neuroimaging data. However, recent studies have shown that the network-level functional organization of the brain is dynamic rather than static (Hutchison et al., 2013) . Suk et al. (2016) have addressed this issue by developing an approach which classifies people with MCI and healthy controls using a deep autoencoder to extract hierarchical nonlinear relations among brain regions, whilst modelling the inherent functional dynamics of resting-state data. This was also one of the few studies in which the same DL model was tested against and surpassed other competing models in two independent datasets (72.6% for dataset 1 and 80.0% for dataset 2), thus providing evidence of replicability, a crucial feature for diagnostic tools. In line with the studies using structural imaging, the best performance for the classification of AD patients with restingstate data was also obtained by a CNN model with an accuracy of 96.9% (Sarraf and Tofighi, 2016) . These studies provide initial evidence that brain activity at resting state can be useful in identifying MCI and AD patients. We note that, compared to the performances obtained from structural data, DL models applied to functional data seem to perform worse. This discrepancy could be explained by the substantial difference in sample size between the two types of studies \u2212 while the smallest study using structural data included 140 subjects (Hosseini-Asl et al., 2016) the largest study using functional data included 62 subjects (Suk et al., 2016) .\nWith regards to multimodal studies, Liu et al. (2014) applied a stacked autoencoder (SAE) to structural and PET data and successfully distinguished AD and MCI from controls with an accuracy of 87.8% and 76.9%, respectively. Using a very similar dataset, the same team (Liu et al., 2015a ) achieved a better performance by designing a model where the hidden layers were able to infer the correlations between sMRI and PET, thus better capturing the synergy between the two modalities. This model classified AD and MCI against controls with an accuracy of 91.4% and 82.1%, respectively. Interestingly, the application of the same model to a structural data alone resulted in less impressive accuracies of 82.6% and 72% for AD and MCI, respectively. This discrepancy suggests that the integration of structural and functional data may improve classification accuracy. However, this conclusion should be drawn with great caution since that the authors did not report classification accuracy for PET data alone.\nFinally, four studies have tried combining neuroimaging data with clinical information to build a more robust classification model. For example, Suk and Shen (2013) used a SAE to extract latent features from neuroimaging data (sMRI, PET and CSF), which were then used to predict clinical data (measured using the MiniMental State Examination -MMSE -and Alzheimer's Disease Assessment Scale's cognitive subscale -ADAS-cog) and class labels. As the final step, the resulting learned features were used to classify AD and MCI from healthy individuals with an accuracy of 95.9% and 85.0%, respectively. Notably, two more studies Suk et al., 2015a ) that have used the same exact sample (taken from the publicly available dataset ADNI; Alzheimer's Disease Neuroimaging Initiative) and the same types of data (sMRI, PET, CSF, MMSE and ADAS-cog) have also reported high accuracies for both AD and MCI despite using different implementations of DL. In general, studies combining clinical with neuroimaging data have, in general, reported higher accuracies than studies using single modality or multiple neuroimaging modalities. This is in line with previous studies using conventional ML methods (e.g. Willette et al., 2014; Moradi et al., 2015; Zhang and Shen, 2012) and highlights the usefulness of adding clinical information in the classification of AD and its prodromal phase."}, {"section_title": "Attention-deficit/hyperactive disorder", "text": "With regards to attention-deficit/hyperactivity disorder (ADHD), all five studies included here have used resting-state neuroimaging data. For example, Deshpande et al. (2015) applied a fully connected cascade artificial neural network -a variation of the multilayer perceptron -to functional connectivity from ADHD and healthy controls. The model successfully distinguished between the inattentive and combined subtypes from healthy controls with an accuracy of 90% for both comparisons, while the two subtypes were discriminated with an accuracy of 95%. Connections between frontal areas and the cerebellum were identified as the most discriminating features. There is also evidence that healthy children and children diagnosed with three different ADHD subtypes (inattentive, hyperactive and combined) can be distinguished in one single model using a multiclass approach, without the need to perform binary classifications between healthy controls and each ADHD subtypes. This evidence comes from three studies that have used data from different sites taken from the ADHD-200 consortium, a data-sharing platform aimed at understanding the neural basis of ADHD (Milham et al., 2012) . attempted to discriminate between healthy controls and ADHD subtypes (inattentive, hyperactive and combined) using data acquired from three different sites. Rather than looking at the whole brain, the authors first parcellated the brain and trained different DBNs for each brain area to examine which part of the brain best discriminated ADHD (regardless of subtypes) from healthy controls. A 4-way DBN was then performed for the each best discriminating area -prefrontal (PFC), cingulate (CC) and visual (VC) cortex -in each one of the three datasets separately (dataset 1: PFC = 37.4%, CC = 37.1%, VC = 34.4%; dataset 2: PFC = 54.0%, CC = 54.0%, VC = 51.2%; dataset 3: PFC = 71.8%, CC = 72.7%, VC = 68.8%). partially replicated these findings by applying the same DL approach to functional measures of the prefrontal cortex; this allowed a 4-way classification accuracy of 44.4%, 55.6% and 80.9% in three independent samples from the ADHD-200 consortium. Finally, Hao et al. (2015) identified the most discriminating areas -prefrontal, cingulate, somatosensory and visual cortex -and then combined them within a single model. The resulting input data were put through a deep Bayesian network (DBaN), where a DBN was used to reduce the dimensionality of the data and a Bayesian network was used to extract the relationships between the data. The resulting model achieved a 4-way classification accuracy of 48.8%, 54.0% and 72.7% for three independent samples also taken from the ADHD-200 consortium. These three studies suggest that DL can be used to solve multiclass classifications problems, as all performances were well above chance level (25% for a classification with 4 classes). In addition, these studies suggest that DL can extract meaningful information from patterns of brain functioning to classify ADHD from controls and, more notably, to differentiate between ADHD subtypes. Nevertheless, we note that all four studies conducted in ADHD had unbalanced sample sizes between classes. For example, in , there were just between 2 and 5 children in the Inattentive subtype within each site, while the number of healthy children ranged from 69 to 110 per site. Similarly, each site in did not include any participants on at least one ADHD subtype which may have introduced a bias in the 4-way classification performed across all sites. With the exception of Hao et al. (2015) which reported sensitivity and specificity, all studies assessed model performance by estimating the overall accuracy. This metric is simply the proportion of participants correctly identified, and therefore does not take the unbalance between classes into account; this means that it is possible to have a good overall accuracy even if several participants from a class are misclassified (or even if all participants from a class are misclassified if the sample size for that class is very small compared to the total sample size). Therefore, given the highly imbalanced sample sizes, the possibility that the performances reported in these studies are inflated cannot be ruled out. This possibility is supported by the observation of much lower sensitivities (43.9%, 22.9% and 55.6% for each site) than specificities (68.8%, 87.7% and 83.0%), in Hao et al. (2015) ."}, {"section_title": "Psychosis", "text": "With respect to psychosis, two studies have been performed with promising results. Using structural MRI data from four independent studies, Plis et al. (2014) applied a DBN to the original pre-processed images obtaining an impressive F-score of 91%. While this was a highly promising result, the patients group included both first episode and chronic schizophrenia patients, which could have diluted the models' performance. More recently, Kim et al. (2016) extracted functional connectivity patterns obtained from resting-state functional MRI of individuals diagnosed with schizophrenia and healthy controls and performed a series of experiments with an SAE-based model, in which different hyperparameters were tested. The proposed model consisted of an SAE with weight sparsity control, i.e. only a random selection of neurons in a given layer was activated, that classified schizophrenia patients and controls with an accuracy of 85.5%, outperforming SVM by a margin of 8.1%. Consistent with the literature on brain functional abnormalities in schizophrenia (K\u00fchn and J\u00fcrgen, 2013; van der Meer et al., 2010) , the most relevant features for the classification were the functional connectivity between the thalamus and the cerebellum, the frontal and temporal areas and between the precuneus/posterior cingulate cortex and the striatum. Despite this encouraging result, the sample sizes for each class were modest (50 for each group) and, therefore, it is not clear how well these findings will generalise to a different sample. Nevertheless, both studies suggest that DL can effectively classify psychosis patients on the basis of neuroanatomical and neurofunctional information. Despite the evidence that structural and functional data provide complementary information on the neural basis of psychosis (Cabral et al., 2016; Radua et al., 2012; Schultz et al., 2012) , to date there have been no DL studies using a multimodal approach in psychosis. In addition, despite the evidence that psychosis, similar to AD, is preceded by a prodromal stage (Yung et al., 2005) , there have been no studies applying DL to neuroimaging data to classify individuals at high risk of developing psychosis from healthy controls or distinguishing between high risk individuals who will and will not develop the illness."}, {"section_title": "Temporal lobe epilepsy", "text": "One study examined the potential of DL to classify healthy individuals and patients diagnosed with temporal lobe epilepsy (TLE) from diffusion-weighted images (DWI) (Munsell et al., 2015) . A stacked autoencoder was used to extract meaningful features from patients' connectome while SVM was chosen as the classifier. Deep learning was suggested as an attractive ML alternative because it is capable of encoding latent, nonlinear relationships in high dimension data. This combination yielded a relatively modest accuracy of 69%. In addition, this model was outperformed by another approach where features were extracted using a well-known linear automated method (ElasticNet) instead, which achieved an accuracy of 80%. This discrepancy in favour of the second model could potentially be explained by the absence of any form of regularizers in the first model. Given the high complexity resulting from the numerous parameters to be estimated, DL models are more prone to overfitting (high performance on the training data while performing poorly on unseen data) than conventional ML approaches. One standard solution, that the authors did not use, is to address this issue is by tuning the level of model complexity and penalizing highly intricate ones in order to have better generalizing models."}, {"section_title": "Cerebellar ataxia", "text": "One study was conducted in cerebellar ataxia (CA), a neurodegenerative disorder that affects mainly the cerebellum, with multiple genetics variations each with its characteristic pattern of anatomical degeneration. Yang et al. (2014) applied a stacked AE to T1-weighted images of the cerebellum taken from healthy controls and individuals suffering from three CA subtypes: spinocerebellar ataxia type 2 (SCA2), spinocerebellar ataxia type 6 (SCA6) or ataxiatelangiectasia (AT). The proposed method classified the four groups with an accuracy of 86.3%, an impressive result for a 4-way classification. However, the confusion matrix reported by the authors indicates that no case with the SCA2 subtype was correctly classified. Because the sample size of this group (only four participants) contributed very little for the total sample size (80), it is still possible to misclassify all its cases and achieve a low error rate. In such cases, a high accuracy can be misleading, as it may reflect an overestimation of the algorithm's performance (Arbabshirani et al., 2016) . Balanced accuracy, for example, is a potentially useful alternative as it calculates the average of correct predictions of each class individually (Alberg et al., 2004) .\nIn short, since the first study published in 2013, there is already preliminary evidence that DL allows the accurate classification of a range of neurologic and psychiatric disorders, by extracting discriminating features from either single or multimodal imaging as well as other types of data such as clinical and cognitive information."}, {"section_title": "Conversion to illness", "text": ""}, {"section_title": "From Mild Cognitive Impairment to Alzheimer Dementia", "text": "A total of 8 studies have attempted to predict transition to illness using neuroimaging data, and all of them have focussed on the transition from MCI to AD (Table 2) . With one exception (Liu et al., 2015a) , all studies used a multimodality approach, with three of them also including clinical measures in the prognostic model. The highest accuracy (83.3%), was achieved by a model which included sMRI, PET, CSF and two clinical measures: the MMSE and the ADAS-cog (Suk et al., 2015a) . Interestingly, the lowest performance (57.4%) resulted from a model which used the same input data (sMRI, PET, CSF, MMSE and ADASCog) and a similar sample size . However, the two studies differed on the DL approach, with the former employing a semi-supervised approach with a multilayer perceptron pretrained using a stacked sparse autoencoder, and the latter using a pure supervised approach.\nThese findings highlight the potential impact of the DL architecture on performance, although we cannot exclude the contribution of other sample-specific factors to the results (e.g. recruitment criteria). Overall, this initial sample of studies suggests that individuals diagnosed with MCI who later convert to dementia can be identified using cutting-edge DL methods. Although, in general, accuracies are not as high as when classifying AD or MCI from healthy controls, this is not surprising since brain differences as well as clinical and cognitive symptoms between those identified as being at risk who do and do not develop a disorder are likely to be subtle. In addition to these encouraging results, the suitability of DL to multiclass classification means this analytical approach can easily be employed to examine the biomarkers of different stages of the illness. Four studies have taken advantage of this by conducting 4-way classifications to discriminate between no eminent risk of AD (healthy controls), individuals in the prodromal stage who did not (MCI-C) and did develop dementia (MCI-C) and established Alzheimer's (AD). Accuracies ranged from 46.3% to 53.8%. By using a deep Boltzmann machine to extract features from structural MRI and PET images, Liu et al. (2015a) classified the four groups with an overall accuracy of 53.8%. Suk et al. (2015b) examined the replicability of a DL approach known as deep weighted subclass-based sparse multi-task learning (DW-S2 MTL) in two different datasets, considering both binary and multi-way comparisons. The proposed model, specifically designed to mitigate the effect of less useful features for classification, showed a comparable performance for both binary (74.2% vs. 73.9%) and 4-way (53.7% vs. 47.8%) classifications, thus suggesting good replicability. Taken collectively, these studies provide initial evidence that DL methods could be used to discriminate amongst different stages of illness \u2212 a common challenge in standard clinical settings."}, {"section_title": "Treatment outcome", "text": "Prediction of response to treatment is a research area of high clinical interest. In several psychiatric and neurological disorders, a better understanding of why some patients benefit from a certain treatment whereas others do not, could help clinicians make more-effective treatment decisions and improve long-term clinical outcomes (Mechelli et al., 2015) . However, so far, only one study has used DL to predict clinical response to treatment (Table 3) . Munsell et al. (2015) attempted to develop an algorithm that distinguished between patients with TLE who did and did not benefit from surgical treatment. This was implemented using a stacked autoencoder to extract meaningful features from the connectome of patients who were then classified using SVM. This model, however, yielded a low accuracy of 57%. For comparison, the author investigated another option where features were extracted with an alternative linear approach instead of an autoencoder. This second model resulted in a higher accuracy of 70%. Again, this discrepancy in favour of the second model could potentially be explained by the absence of any form of regularizers in the first model. This model comprised 4 layers, resulting in a high number of weights to be estimated which, together with a modest sample size (41 patients without seizures and 29 with seizures after treatment), might have resulted in overfiting."}, {"section_title": "How does DL compare to a traditional machine learning approach?", "text": "A total of twenty-five studies included in this review compared a DL model against a kernel-based model (SVM or MKL) in order to elucidate how DL compares to a more conventional ML approach. The results of these comparisons are shown in Fig. 5 . It can be seen that, for the majority of studies, DL showed improved performance compared to SVM. Given the small sample of studies, it is difficult to identify specific characteristics of the studies associated with greater or smaller improvement in performance following the implementation of DL. However, a margin favouring DL studies appears to be more evident in studies that have integrated different modalities with cognitive and/or clinical data (Fig. 6 ). This anecdotal observation is consistent with the notion that DL is a powerful tool for detecting abstract relations within the data, especially between different types of data that are likely to be associated in complex ways, such as neuroimaging and clinical/cognitive information (Plis et al., 2014) .\nSince DL requires a large number of observations to learn increasingly complex patterns compared to conventional ML methods, one would expect to find a greater difference between the two methods as sample size increases. However, the effect of sample size on the difference in performance is unclear, possibly due to the small number of studies currently available. There is a minority of studies where SVM/MKL matched or even outperformed the proposed DL model. Amongst these, Munsell et al. (2015) reported the largest margin favouring SVM. However, this article had one of the smallest sample sizes (118 for the diagnostic comparison and 70 for the treatment outcome comparison) while employing one of the deepest networks with 5 layers. Notably, out of all the studies comparing the two approaches, Munsell et al. (2015) was the only one that did not make any formal attempt to prevent overfitting of the DL model, for example through the use of regularization. We note that susceptibility to overfitting becomes more pronounced when deeper and thus more complex networks are used, as in the study by Munsell et al. (2015) , due to the higher number of weights to be estimated (Srivastava et al., 2014) . Therefore, we speculate that the use of small sample sizes, coupled with the high-dimensionality of the data (i.e. when the number of variables highly exceeds the number of participants), may have increased the risk of overfitting in this study."}, {"section_title": "Discussion", "text": "ML has been gaining considerable attention in the neuroimaging community due to its advantages over traditional analytical methods based on mass-univariate statistics. In particular, ML methods take the inter-correlation between regions into account, while mass-univariate methods operate under the assumption that different regions act independently. In addition, ML methods can be used to make inferences at the single-subject level \u2212 a critical difference with mass-univariate analytical methods that are only sensitive to differences at group-level. DL is a type of ML which is increasingly used in neuroimaging after leading to major scientific advances in the areas of speech recognition, computer vision and natural language processing by significantly outperforming other state-of-the-art classification methods (Krizhevsky et al., 2012; Le et al., 2012) . There are two main characteristics that distinguish DL from conventional ML methods: first, DL is capable of learning features from the raw data without the requirement for a priori feature selection, resulting in a more objective or less bias-prone process; second, DL uses a hierarchy of nonlinear transformations, which make this approach ideally suited for detecting complex, scattered and subtle patterns in the data. Given its ability to detect abstract patterns from the data, DL can be considered a promising tool in neuroimaging, as most brain-based disorders are characterised by a scattered and diffused pattern of neuroanatomical and neurofunctional alterations (Plis et al., 2014) . In previous sections of this review, we have described the most common DL architectures and have provided an overview of the studies that have applied DL to neuroimaging data to investigate psychiatric and neurological disorders. In this final section, we discuss the main themes that have emerged from the review of these studies. These will include (i) Results of studies comparing DL and kernel-based models. The graph shows the accuracies (F-score for Plis et al., 2014) for DL models (blue), kernel-based models (red) and the difference between the two (green). HC, healthy controls; ADHD, attention deficit and hyperactive disorder; AD, Alzheimer's disease; MCI, mild cognitive impairment; MCI-NC, mild cognitive impairment non-converters; MCI-C, mild cognitive impairment converters; SZ, schizophrenia; TLE, temporal lobe epilepsy; TLEs, temporal lobe epilepsy with seizures after treatment; TLEns, temporal lobe epilepsy without seizures after treatment. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) consistencies and inconsistencies in the existing literature (ii) the promise of CNNs, (iii) the issue of multiclass classification, (iv) how DL performs compared with conventional ML methods, (v) interpretability of DL in neuroimaging, (vi) the challenge of overfitting and (vii) technical expertise and computational requirements. We conclude by discussing possible directions for future research."}, {"section_title": "Main conclusions from the existing literature", "text": "The majority of published studies have been conducted in patients with MCI and/or AD; this may be explained by the availability of ADNI, a very large open-source dataset including thousands of patients, to the neuroimaging community (Mueller et al., 2005a (Mueller et al., , 2005b . However, studies have also been conducted in other disorders including ADHD, psychosis, TLE and cerebellar ataxia. Taken collectively, the findings published so far suggest that DL can be applied to neuroimaging data, including both structural and functional modalities, to classify diagnostic groups from healthy individuals. Indeed, the performance of the classifiers has been consistently high, with several studies reporting accuracies above 95% for binary classifications between patients and controls (Deshpande et al., 2015; Hosseini-Asl et al., 2016; Payan and Montana, 2015; Sarraf and Tofighi, 2016; Suk and Shen, 2013; Suk et al., 2015a; Suk et al., 2015b) . Nevertheless, the application of a supervised model for diagnostic classification is arguably circular: since diagnostic labels in the training and testing datasets are predetermined through clinical examination, logic dictates that a perfect performance from an ML algorithm will simply mimic clinical assessment. Being able to predict a future diagnosis, or anticipate who will and will not benefit from a certain treatment, are questions of greater translational value in clinical practice. A total of 8 studies have applied DL to neuroimaging data acquired from individuals with MCI to predict subsequent transition to AD with promising results. For example, Suk et al. (2015a) successfully predicted conversion from MCI to AD with 83.3% accuracy, after combining structural MRI and PET data. However, no studies have yet examined transition to illness in other psychiatric disorders with a prodromal phase, such as psychosis, even though we know that it is possible to distinguish between converters and non-converters using conventional ML (Zarogianni et al., 2013; Pettersson-Yeo et al., 2013; Valli et al., 2016) . To our knowledge only one study has used DL to predict treatment outcome. Munsell et al. (2015) achieved an accuracy of 57% when classifying TLE patients who did and did not suffer from seizures after surgical intervention. As discussed earlier, however, this modest result could potentially be explained by the absence of formal strategies to avoid overfitting of the DL model. DL is a very flexible approach, meaning that is it possible to combine different architectures and manipulate a range of hyperparameters within the same model. In addition, the vast majority of existing studies have been published in the last 2 years, and therefore the field of DL applied to neuroimaging of brain-disorders should be considered still at a very early stage. Possibly as a result of this combination of flexibility and novelty, the methodology of the studies reviewed in this article varied considerably. For example, some studies employed a whole-brain approach whereas others focussed on a subset of regions of interest; some studies used the raw data without any form of feature selection whereas others performed a number of transformations on the data to select relevant features; and different studies used different DL architectures. Such methodological variability means that, at present, the reliability and replicability of the existing results remain unclear."}, {"section_title": "The promise of convolutional neural networks", "text": "CNNs are a particular type of feedforward neural network inspired by how the human visual cortex process information. Over the past decade, CNNs have been breaking records in computer vision across several competitions, making this approach a very promising one (Krizhevsky et al., 2012) . Consistent with this, our review has shown that CNNs have generated the most encouraging results in the context of neuroimaging. In its raw form, neuroimaging data comprises millions of voxels. Considering the current computational resources available, putting all voxel intensities through a fully connected network would lead to an unfeasible number of weights to be estimated. Two intrinsic properties of CNNs -weight sharing and local connectivity -result in a significantly reduced number of weights, making it computationally possible to run the network at the voxel-level. Although in neuroimaging CNNs have only been used to examine MCI and AD patients, the accuracies of the studies published so far have been consistently high (i.e. \u226595% for AD and \u226586% for MCI versus controls). High accuracies have been observed with different modalities including structural MRI (Gupta et al., 2013; Hosseini-Asl et al., 2016; Payan and Montana, 2015) , resting-state fMRI (Sarraf and Tofighi, 2016) and CT imaging (Gao and Hui, 2016) , as well as with small (Gao and Hui, 2016; Sarraf and Tofighi, 2016) and large (Gupta et al., 2013; Hosseini-Asl et al., 2016; Payan and Montana, 2015) sample sizes. Hosseini-Asl et al. (2016) used an alternative and interesting approach which involved pre-training a CNN in one Alzheimer's dataset (CADDementia) and then finetuning and testing it in another dataset from the same diagnostic group (ADNI). The results were very promising for both 2-way and 3-way classifications (HC vs. AD; HC vs. MCI; AD vs. MCI; and HC vs. AD vs. MCI) , although it should be noted that the ADNI sample was of modest size. Taken together, these results are in line with the successful performances of CNN-based models reported in other scientific areas, and highlight CNNs as a promising tool in neuroimaging."}, {"section_title": "From binary to multiclass classifications", "text": "In the context of neuroimaging, the vast majority of conventional ML studies have relied on binary classifications involving the comparison between a group of patients and a group of healthy controls (Orr\u00f9 et al., 2012; Wolfers et al., 2015) . This can be explained by the fact that these studies have typically employed SVM, which was originally designed for binary classification problems (Hsu and Lin, 2002) . However, the real challenge for clinicians is not to differentiate between patients and controls but to develop biomarkers which could be used to choose amongst alternative diagnoses or different stages of illness progression. Looking forward, therefore, ML models will need to be able to discriminate amongst several possible alternatives in order to inform real-world clinical decision making. Many approaches have been proposed to enable SVM to handle multiclass classification problems (Fei and Liu, 2006; Hsu and Lin, 2002) . However, this is still an active research area (Kumar and Gopal, 2011) and none of the proposed approaches have been tested in the context of neuroimaging. Most neuroimaging studies using SVM addressed the multiclass problem by performing several binary classifications (for example, AD vs. HC, MCI vs. HC and AD vs. MCI) or one-against-all classifications (for example, AD vs. MCI & HC and MCI vs. AD & HC) . DL however, requires less technical effort to perform multiclass comparisons, and therefore could provide a solution to this issue. This is mainly due to the use of the so-called softmax function in the output layer, which can be considered an extension of the binary logistic regression to several classes. Here the output reflects the probability of belonging to each class, which is a more intuitive index of class membership than some of the most sophisticated indices being developed for SVM multiclass solutions (Fei and Liu, 2006) . In light of its suitability for multiclass classification, a number of studies have used DL to carry out 3 or 4-way classifications between different disorder subtypes or different stages of illness. For example, three of these studies were able to classify children into healthy controls and three ADHD subtypes (inattentive, hyperactive and combined) (Hao et al., 2015; . Notably, there is also preliminary evidence for the use of DL to distinguish between individuals at no imminent risk of dementia, those identified at risk who will and will not develop dementia, and those with established Alzheimer's disease (Liu et al., 2015a; Liu et al., 2014; Suk et al., 2015b) . These are encouraging findings, as they highlight how DL could help bridge the existing gap between neuroimaging findings and real-world clinical practice."}, {"section_title": "Is deep learning superior to conventional machine learning?", "text": "Despite the success of DL in several scientific areas, the superiority of this analytical approach in neuroimaging is yet to be demonstrated. On the one hand, DL has been described as a potentially more powerful approach than conventional shallow ML, as it is capable of learning highly intricate and abstract patterns from the data, which can particularly useful in the case of brain-based disorders (Plis et al., 2014) . On the other hand, given that neuroimaging data is very high-dimensional, the nonlinear approach of DL might not be advantageous as there are not enough data points to extract meaningful nonlinear patterns from the data, whereas the linear approach employed in conventional shallow ML might be more appropriate. Here we tried to clarify this issue by systematically examining the difference in performance between DL and conventional shallow ML in studies which used both approaches. A total of twenty-five studies reported classification accuracy for both DL and conventional shallow ML, with the latter being a kernel-based method, either SVM or MKL. For the majority of these studies DL performed better than conventional shallow ML as shown in Fig. 5 , and in some cases the difference was by a reasonable margin (e.g. Han et al., 2015; Plis et al., 2014; Suk and Chen, 2013) .\nFrom the available evidence, it is not clear whether DL tends to perform better under specific circumstances, for example depending on the modality type or the sample size. However, our systematic review provides anecdotal evidence that studies combining imaging and non-imaging data tend to have a larger margin in favour of DL (see Fig. 6 ). This is consistent with the notion that the association between brain abnormalities and cognitive symptoms, for example, is likely to exist at a deep and abstract level, and as such can be captured more effectively by DL methods than traditional shallow ML methods (Plis et al., 2014) .\nWe know that the application of traditional shallow ML methods to neuroimaging data leads to higher and more stable accuracies as the sample size increases (Nieuwenhuis et al., 2012) . One would expect this to be especially true for DL: since a deep model is inherently more complex than conventional shallow ML models, larger sample sizes should be needed to compensate for the greater number of parameters to be estimated and to take full advantage of DL's ability to detect highly intricate and abstract patterns in the data. We were therefore expecting to see an increase in the margin by which DL outperforms kernel-based methods as sample sizes increase. Such increase however was not observed, as the pattern of difference in performance did not seem to vary systematically with sample size; one possibility is that larger sample sizes than those used in the existing literature would be required to detect increases in the margin by which DL outperforms kernel-based methods.\nIn conclusion, our review suggests that, overall, DL performs better than conventional shallow ML. In light of the increasing interest in DL, however, we cannot exclude a publication bias which favoured studies showing the superiority of this new analytical approach relative to conventional shallow ML methods (Boulesteix et al., 2013) . As the number of studies applying DL to neuroimaging data increases, a thorough assessment of publication bias would be useful to establish the reliability of this initial trend in favour of DL."}, {"section_title": "Interpretability of DL in neuroimaging", "text": "Despite having demonstrated state-of-the-art performances across several fields, DL has been under scrutiny for its lack of transparency during the learning and testing processes (Alain and Bengio, 2016; Lou et al., 2012; Yosinski et al., 2015) . For example, deep neural networks have been referred to as a \"black box\" in contrast with other techniques, such as logistic regression, which are less complex and more intuitive. Such lack of transparency has important implications for the interpretability of the results when DL is applied to neuroimaging data. Due to the multiple nonlinearities, it can be challenging to trace the consecutive layers of weights back to the original brain image in order to identify which features (e.g. regions) are providing the greatest contribution to classification (Suk et al., 2015a) . This information however would be useful in the context of clinical neuroimaging where the aim is not only to detect but also localise abnormalities. A first potential issue is that a model with an excellent performance may be using irrelevant features (e.g. orientation of the images, imaging artefacts), as oppose to clinically meaningful information (e.g. regional grey matter, connectivity between different brain regions), to classify participants. A second potential issue is that an accurate model which provides no information about the underlying neuroanatomical or neurofunctional alterations would be of limited clinical utility, for example with respect to treatment development and optimization.\nDespite its complex inner workings which make the visualization and interpretation of the weights challenging, DL can be used in a way which enables transparency. This is illustrated by several neuroimaging studies included in this review that did report the most important features (e.g., Deshpande et al., 2015; Kim et al., 2016; Liu et al., 2014; Suk et al., 2016) . However, these studies used a variety of approaches to isolate the most informative features, and at present there is no standard and intuitive method for visualizing weights or interpreting latent feature representations (Suk et al., 2015a) . This has motivated several attempts to develop new and intuitive ways of enhancing the interpretability of DL within the recent literature (e.g., Gr\u00fcn et al., 2016; Samek et al., 2015; Simonyan et al., 2013; Yosinski et al., 2015; Zeiler and Fergus, 2014) . There are two main methodological approaches to address this issue, including input modification methods and deconvolution methods. Input modification methods are visualization techniques that involve the systematic modification of the input and the measurement of any resulting changes in the output as well as in the activation of the artificial neurons in the intermediate layers of the network. An example of these methods is the so-called occlusion method (Zeiler and Fergus, 2013) which involves covering portions of the input image up to find the areas of the input data that influence the probability of the output classes. In contrast, deconvolution methods aim to determine the contribution of one or more features of the input data to the output. This involves selecting an activation of interest in an output neuron and then computing the contribution of each neuron in the next lower layers to this activation. Here a number of strategies are available to model the nonlinearities present across the layers, for example, deconvnet (Zeiler and Fergus, 2013) and guided backpropagation (Springenberg et al., 2014) ."}, {"section_title": "The challenge of overfitting", "text": "Overfitting is arguably one of the main challenges in ML. Given their inherent complexity, DL networks are particularly prone to overfitting, i.e., learning irrelevant fluctuations in the data that limit generalizability. Not surprisingly, different approaches to address this issue, known as regularization strategies, have been developed and are now present in most DL algorithms. In section 2.1.4 we described some of the most commonly used regularization strategies applied to modern DL, namely weight decays and dropout. As expected, several studies reviewed here have used some form of regularization. The majority (e.g., Hosseini-Asl et al., 2016; Kim et al., 2016; Liu et al., 2015a ) have employed the L1 or L2 norms, which prevent overfitting by penalizing very low or very high weight values. At least one study employed dropout, where a random number of nodes and respective connections are temporarily removed to extract different sets of features that can independently produce a useful output. The importance of regularization strategies in DL could potentially account for the fact that Munsell and colleagues, who trained 4-and 5-hidden layer models (for inferring diagnostic and treatment outcome, respectively) without using any form of regularization, reported such low performance for DL (Munsell et al., 2015) .\nAn additional approach for minimising the risk of overfitting involves reducing the dimensionality of the data before inputting them into the model. A possible way of achieving this is by extracting region-or patch-level features (as opposed to using voxel-level data). Using different types of features (whether voxel, patch or region) can have implications for how detailed the information inputted into the model is (for example, voxel-level features are very detailed, and also very noisy; region-level features on the other hand, ignore more localized patterns and are less sensitivity to noise). Another option to reduce dimensionality is feature selection. Feature selection is common in conventional ML, where linear methods such as principal component analysis, independent component analysis or elastic net, are used to select the most discriminating features that are then fed to a classifier. However, the use of conventional feature selection methods prior to a DL model seems counterintuitive, since one of the main advantages of DL is the ability to learn, through a purely data-driven method, the most useful features for classification. Several studies reported in this review have attempted to reduce the dimensionality of the data by extracting region-or patch-level features, using feature selection, or combining the two approaches. We note, however, that all CNN-based models were applied to voxel-level data without being preceded by any form of feature selection and yet reported consistently high performances on unseen data. This suggests that DL, and CNN-models and particular, can perform well with neuroimaging data without the requirement to downsize or even preprocess the data. For example, Hosseini-Asl et al. (2016) achieved high levels of accuracy after applying a CNN to voxel-level data without any preprocessing or even skull stripping of the images. This finding has potential implications for the development of clinical tools, as it suggests that it might be possible to apply DL to raw neuroimaging data, thereby saving time as well as technical resources."}, {"section_title": "Technical expertise and computational requirements", "text": "The studies reviewed in this article employed a wide range of DL architectures and hyperparameters. Such flexibility is what makes DL a very powerful tool but comes at a potentially high cost. The number of layers, the number of nodes within each layer and the activation function of each node are only a few examples of a long list of variables one has to consider when designing and optimizing a DL model. Automated optimization strategies are not yet widely available, making optimisation a manual process that requires a great deal of technical expertise and is potentially prone to subjective bias. Since the number of parameters to be estimated is very large, the computational requirements of DL are also more demanding than those of conventional ML methods. For example, Kim et al. (2016) reported that the estimation of a DL model with three hidden layers took 100 times longer than the estimation of a standard SVM model (\u223c3.3 days vs. 0.8 h). However, with the fast-growing availability of graphical processing units (GPUs), the application of DL to neuroimaging data is likely to become less and less time-consuming in the future."}, {"section_title": "Conclusions and future directions", "text": "While still in its initial stages, the application of DL in neuroimaging has shown promising results and has the potential of leading to fundamental advances in the search for imaging-based biomarkers of psychiatric and neurologic disorders. Nevertheless, several improvements will be required before the full potential of DL in neuroimaging can be achieved. Firstly, given the complexity of DL models, we need to move away from studies with small to modest sample sizes in favour of much larger cohorts. A possible way of achieving this is through multi-centre collaborations, in which data is collected using the same recruitment criteria and scanning protocols across sites. A further way of increasing the sample size is through multi-site data sharing initiatives, such as ADNI for Alzheimer's disease and ADHD-200 for ADHD. Secondly, the integration of CNN and recurrent neural networks (i.e. networks that allow the processing of data with sequential inputs such as videos or speech) is likely to lead to significant advances in DL in the next few years (Donahue et al., 2015) . In neuroimaging, this integration could be particularly useful for analysing fMRI data, as it would allow the detection of intricate spatial patterns while simultaneously modelling the temporal component of the BOLD signal. Thirdly, we anticipate that an increasing number of neuroimaging studies will make use of transfer learning, which involves using previously learned features from a large sample of similar enough images. This could help tackle the curse of dimensionality \u2212 a common problem in neuroimaging studies of brain disorders (Gupta et al., 2013; Hosseini-Asl et al., 2016) . Evidence from vision science, where deeper models such as VGG net (Simonyan and Zisserman, 2014) , residuals networks and Inception-v4 (Szegedy et al., 2016) are achieving the highest performances, suggests that transfer learning could be particularly useful when deeper models are employed. Fourthly, we suggest that the so-called augmentation technique -which it is commonly used in computer vision -could be useful in the context of neuroimaging. This technique involves increasing the sample size by applying transformations to the data (e.g., rotation, shear, scaling), and then train a model that is invariant to such transformations. The use of augmentation could also address the issue of modest sample sizes and lead to a decrease in prepossessing time (because steps such as rotation may become redundant). Finally, the use of DL to predict continuous scores is another interesting area for further research with potential clinical applicability, following the encouraging results obtained using conventional ML methods (e.g. Gong et al., 2014; Stonnington et al., 2010; Tognin et al., 2014) . So far, only one study has used DL to predict clinical scores from structural MRI scans in patients with Alzheimer's disease (Brosch and Tam, 2013) .\nIn conclusion, the capacity of DL models to learn complex and abstract representations through nonlinear transformations, makes this a promising approach to single subject prediction in neuroimaging. While there are still important challenges to overcome, the findings reviewed here provide preliminary evidence supporting the potential role of DL in the future development of diagnostic and prognostic biomarkers of psychiatric and neurologic disorders."}]