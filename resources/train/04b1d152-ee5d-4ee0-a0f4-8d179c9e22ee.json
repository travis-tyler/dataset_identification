[{"section_title": "", "text": "\u2022 Roughly 40 percent of combined acreage of corn, soybean, wheat, and cotton were in no-till/ strip-till in 2010-11 (89 million acres per year), with adoption rates higher for some crops (e.g., soybeans) and some regions (e.g., the Southern Seaboard). (See figure.) \u2022 Fifty-six percent of all land used for corn, soybeans, wheat, and cotton was on farms that used no-till/strip-till on at least part of their cropland in 2010-11: 23 percent of land was on farms that used no-till/strip-till on all land in these crops while 33 percent was on farms that used a mix of no-till, strip-till, and other tillage practices. \u2022 Fall application of nitrogen (applying nitrogen in the fall before spring planting, which leaves the nitrogen vulnerable to runoff) accounted for 20 percent of nitrogen applied to corn in 2010 (29 percent of acres). Cotton producers applied only 7 percent (on 14 percent of acres) in the fall of 2007. A report summary from the Economic Research Service"}, {"section_title": "Summary", "text": "\u2022 Split application of nitrogen fertilizer (applying at least part of the total nitrogen after planting when crop needs are highest and risk of runoff is lower) accounted for 59 percent of nitrogen applied to cotton in 2007 (64 percent of acres). In 2010, corn farmers applied 22 percent of nitrogen fertilizer (on 31 percent of acres) after planting. \u2022 Farmer-reported nitrogen rates are higher than benchmark application rates (based on estimated plant uptake and designed to minimize nitrogen losses to the environment) for 36 percent of corn acres, 19 percent of cotton acres, 22 percent of spring wheat acres, and 25 percent of winter wheat acres. \u2022 Using multiple nutrient-management practices has greater potential to reduce the loss of nitrogen than using a single practice. Only 24 percent of cotton acres and 6 percent of corn acres combined four nutrientmanagement practices: (1) no application in the fall, (2) some application after planting, (3) nitrogen application at rates below a \"benchmark,\" and (4) fertilizers incorporated or injected below the soil surface. \u2022 Cover crops were in use on less than 2 percent of total cropland (for all crops) during 2010-11 (6.8 million acres), with adoption rates higher in some regions (e.g., the Southern Seaboard and the Mississippi Portal). Although the benefits of cover crops and no-till/strip-till are enhanced when these practices are used on the same fields, the low cover crop adoption rate suggests that these benefits are realized on few acres."}, {"section_title": "How Was the Study Conducted?", "text": "All the data presented are from the Agricultural Resource Management Survey (ARMS), a joint enterprise of USDA's National Agricultural Statistics Service and the Economic Research Service. Data on tillage and cover crops are from a special section of the farm-level portion of the 2010 and 2011 surveys. Farmers were asked to report the acreage of corn, soybean, wheat, and cotton where no-till/strip-till were used and the acreage of all cropland that had cover crops in the survey year. While previous studies suggest that many farms use no-till/strip-till on only a part of their cropland, the 2010-11 ARMS data provide a broad, national perspective on adoption at the farm level. Data from the crop-specific, field-level portion of the ARMS survey were used to report on nitrogen-management practices for corn, wheat, and cotton producers. While the field-level surveys do not provide a farm-level picture of nitrogen management practices, the field-specific data provide extensive detail on application rates, timing, and methods. Conservation-practice adoption rates are estimated using farm-level and field-level surveys and presented by crop, region, farm type, commodity specialization, land tenure, and operator education. www.ers.usda.gov "}, {"section_title": "Introduction", "text": "Conservation-practice adoption can reduce the adverse environmental effects of agricultural production. Adoption of no-till, strip-till, nutrient management, and cover crops, for example, can provide a suite of environmental (off-farm) benefits including improved water quality through reduced sediment and nutrient loads. Increasingly, it is also recognized that conservation practice adoption can provide on-farm benefits. While the benefit of controlling soil erosion to preserve soil depth has been recognized since the Dust Bowl, conservation practices can also help change the physical, biological, and chemical properties of the soil. Continuous use of no-till or strip-till, for example, can increase soil organic carbon and available water capacity, reduce soil compaction, improve soil aggregate size and stability, and increase porosity (USDA/NRCS, 1996)-changes that may enhance soil health. 1 These benefits are amplified when no-till/strip-till is used with cover crops (USDA/NRCS, 1996;Snapp et al., 2005). Good nutrient management (use of appropriate application rates, methods, and timing) minimizes runoff, leaching, and nitrous oxide emissions (a potent greenhouse gas) and makes nutrients available when they are most beneficial to crops. Cover crops also help improve nutrient management by either conserving nitrogen for grain crops, or utilizing excess nutrients-the benefits will depend on the cover crop choice. High-residue cover crops add carbon, retain nitrogen, increase nutrient use efficiency, and reduce nutrient leaching into groundwater (USDA/NRCS, 2014a). The off-and on-farm value of these practices may increase with an increase in the frequency of extreme weather events that are expected with climate change (Michalak et al., 2013;Lin, 2011;Diaz and Rosenberg, 2008). The practices discussed in this report are frequently supported by USDA conservation programs and are likely to be critical in meeting climate change adaptation goals under the USDA Climate Change Adaptation Plan (USDA/OCE, 2014). This mix of off-and on-farm benefits is typical of agricultural conservation practices. While farmers and other landowners have incentives to maintain the productivity of their land, society seeks to improve environmental quality through publicly funded conservation programs and policies. The extent to which specific practices have been adopted may be useful to conservation-program design and administration. Practices that are widely adopted may not require financial assistance, at least in some regions or among some groups of producers who already believe that the benefits of adoption outweigh the costs. For practices that are beneficial but not yet in widespread use, financial and technical assistance can encourage early adopters, who may be instrumental in demonstrating the conservation value and potential profitability of these practices to other farmers. There is also increasing recognition among researchers and the general public of the importance of the overall level of conservation effort (or stewardship) on U.S. farms. Producers who have adopted multiple conservation practices and implemented them throughout their farm may be taking advantage of complementarity among practices. While doing so, they are addressing a wide range of environmental issues, including the soil-quality benefits of adopting both no-till and cover crops, or the water-quality benefit of adopting both no-till and nutrient management. While data on tillage and cover crop adoption are also available from the crop-specific, field-level (phase 2) portion of ARMS, the whole-farm (phase 3) data offer several advantages. First, the farmlevel data cover the four most important crops (corn, soybeans, wheat, and cotton) in a single year, thereby capturing a \"snapshot\" of these practices across the landscape rather than capturing different crops in different years as in the field-level survey (phase 2). The farm-level (phase 3) sample size is also larger, making it possible to obtain reliable results at State or regional levels (particularly for practices that are not yet widely adopted). While the phase 3 data for 2010-11 provide a total of 17,060 observations, the field-level surveys for corn (2010), cotton 2007, and wheat (2009) provide a total of 4,916 observations (each survey is focused on States that account for 90-95 percent of the target crop). Finally, the farm-level data show the extent of practice adoption within farms (rather than on single fields), at least for those acres planted to the four most widely grown crops (see appendix 2, \"The Agricultural Resource Management Survey\")."}, {"section_title": "Tillage Practices", "text": "Conservation tillage systems traditionally have been defined as tillage systems that leave at least 30 percent of residue on the soil surface after planting (conventional tillage systems leave less than 30 percent crop residue). In a no-till system, farmers plant directly into the undisturbed residue of the previous crop without tillage, except for nutrient injection. In a strip-till system for row crops, seeds are planted into a narrow strip (e.g., 6-8 inches) that has been tilled where fertilizer may have also been injected or placed. While tillage has long been used to control weeds, speed the decay of crop residues that may harbor insects or disease, and ease planting operations, farmers have increasingly adopted production systems that require less tillage and leave significant amounts of crop residue on the soil surface. When compared with conventional or other conservation tillage methods, no-till/strip-till production can reduce soil erosion and sediment loss to water and wind (this in turn mitigates sediment loading in bodies of water), increase soil carbon sequestration, and improve the physical, chemical, and biological properties of the soil in a number of ways including increased water-hold capacity, higher soil organic matter content, and reduced soil compaction (Derpsch et al., 2010;USDA/NRCS, 2014a). Maintaining greater residue on the surface reduces soil temperature, maintains soil moisture, and protects the soil from excessive sunlight and wind (Karlen et al., 2009). Many of these benefits may be enhanced if used in conjunction with other practices, particularly cover crops (USDA/ NRCS, 1996;Snapp et al., 2005). However, since it requires more than 5 years of adoption for no-till fields to reach their full soil tilth, porosity, and organic matter potential (Toliver et al., 2012), many of these benefits will be realized only when no-till is practiced continuously over a period of years. 4 Many farmers who use no-till use it on only a portion of their crop acreage, suggesting that no-till is not necessarily used continuously on these farms. Farmers who use no-till often rotate tillage practices along with crops (see Robertson et al., 2014). Farmers may use no-till/strip-till on crops that are thought to be well suited for the practices (e.g., soybeans) and use conventional tillage or other conservation tillage methods for crops where no-till/strip-till management is perceived as more risky (e.g., corn) (Reimer et al., 2012). Some farmers may also vary tillage based on field characteristics. For example, farmers may use no-till or strip-till on highly erodible land to control soil erosion (from wind or rainfall) (Prokopy et al., 2008). Although not specifically required, tillage practices are often part of conservation plans that must be in use to meet eligibility requirements (conservation compliance) for most Federal agricultural programs, including commodity programs and (after 2014) crop-insurance premium subsidies. Weather may also play a role as farmers may use no-till/ strip-till to conserve soil moisture when water reserves are low but are deterred from using the practice when springtime weather is wet (Ding et al., 2009). In 2010-11, no-till and strip-till were widely used-although not predominantly-on U.S. farms. We consider the four most widely grown crops: corn, cotton, soybeans, and wheat, which accounted for 225 million acres in 2010 and 242 million acres in 2011. Overall, 44 percent of about 980,000 corn, soybean, wheat, and cotton farmers represented by the 2010 and 2011 surveys used no-till/strip-till on at least one of these crops. No-till/strip-till accounted for 39 percent of total acreage in these crops including 31 percent of corn, 46 percent of soybeans, 33 percent of cotton, and 43 percent of wheat ( fig. 1). Regional 5 adoption rates for corn no-till/strip-till were highest in the Prairie Gateway (64 percent) and lowest in the Fruitful Rim (14 percent) (table 1). For soybeans, no-till/strip-till adoption rates were highest in the Prairie Gateway (72 percent) and lowest in the Northern Great Plains (32 percent) and the Mississippi Portal (32 percent). For wheat, adoption was highest in the Northern Great Plains (63 percent) and lowest in the Fruitful Rim (21 percent). For all four crops combined, these practices were most widely used in the Southern Seaboard (64 percent of acres) and Eastern Uplands (56 percent) ( fig. 2 and table 1). Corn, soybean, wheat, and cotton farmers were least likely to use no-till or strip-till in the Fruitful Rim (19 percent). The tillage estimates from the 2010-11 farm-level survey are for no-till and strip-till, so they are not directly comparable to other estimates of no-till acreages. Horowitz, et al. (2010) report estimates of no-till acreage for 2003-07, based on the field-level portion of the ARMS. More recent data, also based on field-level surveys, were obtained from ARMS results and are available online (http:// www.ers.usda.gov/data-products/arms-farm-financial-and-crop-production-practices/tailoredreports-crop-production-practices.aspx) ( fig. 3). In general, the field-level estimates of no-till acreage are lower than our estimates of no-till/strip-till for 2010-11. These differences could reflect both the change in no-till acreage over time and the level of strip-till use. No-till/strip-till adoption in 2010-11 is 8 percentage points higher than no-till adoption in corn in 2010, 11.9 percentage points higher than 2007 cotton, and 4 percentage points higher than 2009 wheat. For soybeans, 2010-11 adoption of no-till/strip-till based on the farm-level ARMS is 46 percent, which is roughly equal to no-till adoption in the 2006 field-level survey (45 percent) and 6 percentage points higher than no-till adoption in the 2012 field-level survey (40 percent).   As already noted, many farmers use no-till or strip-till on only a part of the land they have in crop production. Farmers who use no-till or strip-till on all of the acres they planted in all four crops are defined as \"full adopters.\" That is, no-till or strip-till is used on every acre planted to corn, soybeans, wheat, or cotton. Farmers who use no-till or strip-till on only a part of the acres in these four crops are defined as \"partial adopters.\" Partial adopters have the equipment and expertise (at least for some crops) to use no-till/strip-till but choose to till other portions of their cropland. To the extent that \"start-up\" costs of no-till and strip-till (e.g., new planting equipment) or lack of experience are barriers to no-till and strip-till adoption, these farmers may be well positioned to expand these practices to a larger share of cropland acreage. If some crops or some fields are not well suited to no-till or striptill, however, partial adopters may feel that expanding these practices would not be profitable. During 2010-11, roughly 23 percent of land in corn, soybeans, wheat, and cotton was on a farm where no-till or strip-till was used on every acre (full adopters). Another 33 percent of acreage devoted to the four major crops was located on farms where a mix of no-till, strip-till, and other tillage practices 6 were 6 Here other tillage practices refer to all tillage practices except for no-till or strip-till (conventional tillage, reduced tillage, and conservation tillage (mulch-till and ridge-till)).  No-till or strip-till use on corn, soybeans, wheat, and cotton acres by farm resource region in the   used (partial adopters). Partial adopters used no-till/strip-till on roughly half of their cropland (15 percent of the four major crops) and other tillage practices on remaining cropland (18 percent of four major crops). The data suggest that 56 percent of all land used for corn, soybeans, wheat, and cotton in 2010-11 was located on farms that used no-till/strip-till on at least some portion of land used for these crops. On a regional basis, the proportion of these crops on farms that used no-till/strip-till in 2010-11 (for at least some of these acres) varies from 76 percent in the Southern Seaboard to 23 percent in the Fruitful Rim ( fig. 4). For all other regions, at least 47 percent of acreage for all four crops was on farms that used no-till/strip-till on some of their acres, including 63 percent of acres in the Prairie Gateway and 70 percent in the Eastern Uplands. We note that the Southern Seaboard and Eastern Uplands regions represent a relatively small part of corn, soybean, wheat, and cotton acres. Nonetheless, in the Prairie Gateway, Northern Great Plains, and Heartland regions-which account for 72 percent of corn, soybean, wheat, and cotton acreage-56 percent or more of these crop acres were on farms that used no-till or strip-till to some extent. Many farmers who use no-till or strip-till apply that practice to all of their acreage for an individual crop, regardless of tillage practices on other crops ( fig. 5). These producers account for 25 percent of corn acres, 37 percent of soybean acres, and 39 percent of wheat acres. However, the fact that a farmer puts all of one crop into no-till or strip-till does not mean that he or she will apply that practice to other crops. Only 23 percent of acres in all four crops were located on farms that adopted no-till/strip-till on 100 percent of their acres. This is consistent with the idea that the choice of tillage system can be a crop-specific decision. That may be because some crops are better adapted to no-till/strip-till than others. For example, there is evidence to suggest that no-till production reduces corn yields (by delaying planting, particularly where there is cool, wet springtime weather) but has no effect on soybean yields (Wilhelm and Wortmann, 2004).  Finally, partial adopters appear to differ in the ways they allocate land between no-till/strip-till and other tillage systems. Just under 20 percent of corn, cotton, soybeans, and wheat producers (accounting for 33 percent of land in these crops) use no-till/strip-till and other tillage systems on only part of the land they planted to these crops in 2010-11. More than one-third of partial adopters (about 8 percent of farmers) adopted tillage systems exclusively by crop during 2010-11. On these farms, no-till/strip-till was used exclusively on some crops but not used at all on others ( fig. 6). For example, a corn and soybean producer who always uses no-till/strip-till on soybeans but never on corn would fall in this category. A smaller share of partial adopters (about 3 percent of all farmers) allocated some land in each crop to no-till/strip-till and some land in each crop to other tillage practices. A corn and soybean producer who uses no-till/strip-till on some corn and soybeans, but not on all of either crop, would fall in this category. For example, a producer who has agreed to use no-till or strip-till on highly erodible cropland as part of a soil conservation system to comply with 1 The fourth category (not shown) is other tillage practices on nonadopter farms. Notes: \"Other tillage practices\" refers to all tillage practices except for no-till or strip-till (conventional tillage, reduced tillage, mulch till, and ridge till) Cropland acreage is the total acreage in corn, soybeans, wheat, and cotton for 2010 and 2011. For the Northern Great Plains, the estimate of crop acres on farms that use only no-till/strip-till has a coefficient of variation (CV) of 51. Estimates for the Northern Crescent are omitted due to the unreliability of the statistics. Source: USDA, Economic Research Service and USDA, National Agricultural Statistics Service, Agricultural Resource Management Survey, 2010-11."}, {"section_title": "Figure 4", "text": "Percent of acres on farms adopting no-till/strip-till on all or part of corn, soybean, wheat, and cotton acres, by farm resource region in the continental United States, 2010 Highly Erodible Land Conservation (HELC), but uses tillage on non-highly erodible cropland, could fall in this category. Finally, just under half of partial adopters do not appear to fit into either of these patterns: no-till/strip-till is used on all land in some crops while land in other crops is split between no-till/strip-till and other tillage systems. The Heartland has the largest share of partial adopters ( fig. 6), with an equal share of producers who adopted by crop (11 percent) and who adopted fully on some crops but partially other others (11 percent), while only 3 percent adopted on part of each crop. A similar pattern is seen in the Prairie Gateway: 9 percent of farmers adopted by crop and 9 percent adopted fully on some crops but partially other others, while less than 4 percent adopted on part of each crop. The Eastern Uplands is the only region that deviates from the national pattern, with the largest share of producers adopting on part of each crop. While the tillage data suggest clear differences in no-till/strip-till adoption across regions (table 1), there are fewer significant differences across farmer characteristics. Appendix table A1 shows that, in general, adoption rates are similar across different levels of education, although corn producers who graduated from college applied no-till/strip-till to a larger proportion of land than farmers who completed high school but did not go to college. The opposite is true of cotton producers-college graduates applied no-till/strip-till to a smaller proportion of acres than do high school graduates. Appendix table A2 reveals there are not significant differences in no-till/strip-till adoption by farm typology (which aggregates farm size, sales, and operator primary occupation). Appendix table A3 shows that full tenants (farmers who own all of the land they farm) were less likely to use no-till/strip-till in 2010-11, although the difference is statistically significant only for soybeans. Finally, appendix table A4 shows that farmers specializing in grain production were more likely than other farmers to use no-till/strip-till.  . The Basin and Range shows 3.6 percent of farms making no-till/strip-till decisions based on field characteristics. There are too few observations of those who make no-till/strip-till decisions based on crop or crop and field characteristics to be disclosed. The Northern Crescent shows 5.3 percent of farms making tillage decisions based on crop characteristics. Statistically reliable estimates of farms that make tillage decisions based on field characteristics or crop and field characteristics are unavailable. The Fruitful Rim shows 2 percent of farms making no-till/strip-till decisions based on field characteristics. There are too few observations of those who make no-till/strip-till decisions based on crop and field characteristics to be disclosed. Also, statistically reliable results for those who make tillage decisions based on crop characteristics are unavailable. 1 For the Northern Great Plains, the estimate of farms that make tillage decisions based on field decisions has a coefficient of variation (CV) of 52. The CV is the ratio of the standard error to the estimate and is sometimes referred to as the \"relative standard error.\" The estimate of farms that make no-till/strip-till decisions based on crop and field characteristics has a CV of 57. 2 For the Eastern Uplands, the estimate of farms that make no-till/strip-till decisions based on crop characteristics has a CV of 56. The estimate of farms that make no-till/strip-till decisions based on field characteristics has a CV of 65. 3 The Southern Seaboard has a CV of 52 for the estimate of farms that base no-till/strip-till decisions on field characteristics. Source: USDA, Economic Research Service and USDA, National Agricultural Statistics Service, Agricultural Resource Management Survey, 2010-11."}, {"section_title": "Figure 6", "text": "Percent of farms, by farm resource region, where no-till/strip-till is adopted by crop, on part of each crop, or fully for some crops and partially on other crops, 2010-11 "}, {"section_title": "Nitrogen Management", "text": "The goal of nitrogen management is to reduce loss of fertilizer or manure nitrogen to water or air. Nitrate nitrogen-the form used by plants-is water soluble and can be lost with surface or subsurface flow. Nitrogen can be carried long distances, particularly in large rivers, and can cause water quality problems hundreds of miles from the source. The zone of hypoxic (oxygen-depleted) water in the Gulf of Mexico is largely due to nitrogen runoff from farms in the Mississippi River valley, hundreds of miles north of the Gulf (Rabotyagov et al., 2010). Nitrogen can also be lost to the atmosphere in the form of nitrous oxide (N 2 O), a powerful greenhouse gas with potency 310 times that of carbon dioxide (CO 2 ). Nitrogen management involves applying nitrogen fertilizer and manure: (1) in amounts that are agronomical for the crop being grown and field conditions (e.g., soil and climate); (2) at the time corresponding with crop nitrogen needs, which vary over the crop growing season; and (3) using methods that reduce loss due to runoff (e.g., injection or incorporation below the soil surface). In corn production, for example, crop nitrogen demand is low in the early vegetative stages of growth but starts to rise rapidly 30 to 40 days after planting. Applying nitrogen in the fall months before planting in the spring leaves nitrogen vulnerable to loss through the winter and early spring. Postplanting or \"side dress\" application, on the other hand, makes nitrogen available when it is needed for plant growth and development, while minimizing nitrogen runoff. Our analysis focuses on the application of commercial nitrogen on acres that do not receive manure. The application of commercial fertilizer can be more carefully calibrated than the application of manure, which can vary in terms of nutrient content and is more difficult to precisely apply. Although manure is an important source of nitrogen in corn production-17 percent of corn acres received manure in 2010-our analysis presents a view of nitrogen management in corn that complements the previous work of Ribaudo, Livingston, and Williamson (2012) 7 . For cotton and wheat, our data are more recent than those used by Ribaudo et al. (2011) and manure application is far less important. Only 3 percent of cotton and winter wheat acreage received manure in 2007 and 2009, respectively, while only 1 percent of spring wheat acres received manure in 2009 (table 2). Most corn, cotton, and wheat acres received nitrogen fertilizer. For example, in each region where corn is grown, more than 90 percent of corn acres received nitrogen fertilizer. The proportion of acres varies across regions for cotton and winter wheat. Nitrogen was applied on 99 percent of cotton acres in the Mississippi Portal and on 84 percent of acres in the Prairie Gateway. The Prairie Gateway also has the lowest share of winter wheat acres receiving nitrogen fertilizer (76 percent). In the Northern Great Plains, where 84 percent of spring wheat is grown, nitrogen was applied on 94 percent of acres. Average nitrogen application rates (for acres that received nitrogen) vary across regions because crop mixes, driven by soils and climatic conditions, vary. As a rule, rates are generally higher for 7 Ribaudo et al. (2011) provides an indepth look at nitrogen management in eight major crops in 2006. A followup publication (Ribaudo et al., 2012) looks at trends in nitrogen management 2001 to 2010 for corn. They found, as we did, that 83 percent of corn acres treated with nitrogen did not receive manure. Our results differ from those reported by Ribaudo et al. (2012) because we do not consider manure and we use different criteria for determining maximum agronomic rates of nitrogen application. Our criteria, which are based on the USDA/NRCS Conservation Effects Assessment Program (CEAP) criteria, are explained in the text. In addition to being an important source of nitrogen, we recognize that manure helps build soil organic matter and is often a source of excess nutrient that is vulnerable to runoff."}, {"section_title": "13", "text": ""}, {"section_title": "Conservation-Practice Adoption Rates Vary Widely by Crop and Region, EIB-147", "text": "Economic Research Service/USDA   2007, 2009, and 2010. corn than for cotton or wheat (table 3), and nitrogen is not typically applied to soybeans. Nitrogen application rates in corn vary from 118 pounds (lbs) per acre in the Fruitful Rim to 155 lbs per acre in the Heartland and 153 lbs per acre in the Southern Seaboard. Region-average cotton nitrogen application rates range from 82 lbs per acre in the relatively arid Prairie Gateway to 110 lbs per acre in the Mississippi Portal, where rainfall is more abundant. (Increased water availability is generally Table 3 Expected versus observed yield for corn (2010), cotton 2007 2007, 2009, and 2010. correlated with increased nitrogen use to achieve higher yields (Sheriff, 2005).) In the Fruitful Rim, where a substantial portion of cotton is grown under irrigation, rates average 109 lbs per acre. Spring wheat application rates vary from 74 lbs per acre in the Northern Great Plains to 100 lbs per acre in the Fruitful Rim. Winter wheat application rates vary from 52 lbs per acre in the Prairie Gateway to 101 lbs per acre in the Heartland. Agronomic nitrogen application rates are those where only as much as plants can use is applied, thus improving nitrogen use efficiency. Efficient use of nitrogen minimizes the share of nitrogen lost to the environment (Ribaudo et al., 2011). Agronomic nitrogen rates depend on the crop, crop rotation, expected yield, weather, timing of application, soil, and other conditions. 8 Therefore, determining agronomic rates can be challenging. We define a maximum agronomic or \"benchmark\" rate based on procedures outlined in the USDA/NRCS Conservation Effects Assessment Project (CEAP) cropland reports. 9 For corn and wheat, our benchmark nitrogen application rate is 1.4 and 1.6 times expected removal, respectively, less a nitrogen credit of 40 lbs per acre for fields where soybeans were grown in the previous year (Gerwing and Gelderman, 2005;Penn State Extension, 2015). Expected removal is based on expected crop yields (as stated by the producer), 10 multiplied by removal coefficients of 0.8 lbs per bushel for corn, 1.39 lbs per bushel of spring wheat, and 1.13 lbs per bushel of winter wheat (Lander et al., 1998). Approximately 64 percent of corn acres and 38 percent of wheat acres followed soybeans. For cotton, our benchmark rate is equal to 60 lbs of nitrogen per bale of expected yield, less a nitrogen credit of 40 lbs per acre for fields where soybeans were grown in the previous crop year. Only 2 percent of cotton acres were in soybeans in the previous crop year. We compared our benchmark to reported nitrogen application rates at the field level. On average, nitrogen application rates were lower than the benchmark rates: corn farmers reported using 148 lbs per acre while the benchmark rate is 166 lbs per acre; cotton farmers reported using 94 lbs per acre while the estimated benchmark rate is 117 lbs per acre; spring wheat farmers reported using 77 lbs per acre while the benchmark rate is 99 lbs per acre; winter wheat farmers reported using 61 lbs per acre while the benchmark rate is 85 lbs per acre (table 3). With the exception of winter wheat grown in the Heartland and Eastern Uplands, all regions show average benchmark rates above average reported rates. These averages mask considerable heterogeneity in application rates relative to the benchmark. Figure 7 shows the distribution of the difference between nitrogen application rates reported by producers and our benchmark application rates (based on expected yields). Estimates less than zero indicate that a farmer used less than the benchmark rate of nitrogen, while estimates above zero indicate that a farmer used more than the benchmark rate. The distribution of differences between reported and benchmark nitrogen application rates vary for each crop. This further illustrates the importance of crop-related considerations (such as region, climate, soils, and crop mix) when designing nutrient management plans that maximize  Nitrogen application rates relative to benchmark rates on corn (2010), cotton 2007 nitrogen use efficiency. The largest differences were -10 lbs per acre for corn, -25 lbs per acre for cotton, -10 lbs per acre for spring wheat, and -20 lbs per acre for winter wheat. Nitrogen is applied at more than the benchmark rate on 36 percent of corn acres by an average rate of 39 lbs per acre; on 19 percent of cotton acres by an average rate of 40 lbs per acre; on 22 percent of spring wheat acres by an average rate of 30 lbs per acre; and on 25 percent of winter wheat acres by an average rate of 24 lbs per acre. While figure 7 shows that nitrogen is applied below the benchmark rate on just under 70 percent of corn, cotton, and wheat acres, nitrogen applications over the benchmark rates are estimated to be about 2 million tons for corn, 0.3 million tons for wheat, and 0.1 million tons for cotton. Farmers spent approximately $965 million on corn, cotton, and wheat nitrogen applications over benchmarks. 11 Risk aversion (e.g., decreasing the variability in yields), input substitutability (e.g., increased precipitation), opportunity costs (e.g., the cost of other inputs), and perceptions of agronomic advice (e.g., farmers not believing that extension service recommendations are appropriate for their fields) can entice farmers to apply more nitrogen than is agronomically optimal (Sheriff, 2005). In terms of nitrogen application timing, fall nitrogen application occurs during the fall months before the crop is planted, spring application occurs in the spring months before planting or at planting, and after-planting application occurs while the crop is growing. The appropriate timing of nitrogen applications depends on the crop being grown and whether previously applied nutrients were lost (say, to weather events). Cotton farmers applied a majority of nitrogen-59 percent-after planting ( fig. 8). Winter wheat producers applied 45 percent of nitrogen after planting. Corn farmers applied 22 percent of nitrogen after planting, while spring wheat farmers applied 5 percent after planting. Farmers applied a significant share of nitrogen in the fall for corn (20 percent) and spring 11 Cost estimates use over-application quantities and annual ammonia nitrate prices (see USDA/ERS, 2014b).   Economic Research Service/USDA wheat (21 percent). Corn, cotton, and winter wheat producers applied larger proportions of nitrogen after planting than in the fall before planting. Nitrogen application timing also varies widely by region. In corn, there are large regional differences in the share of nitrogen applied after planting, ranging from 10 percent in the Northern Great Plains to 59 percent in the Southern Seaboard and 40 percent in the Eastern Uplands (table 2). Cotton farmers in the Southern Seaboard applied roughly 70 percent of nitrogen after planting while farmers in the Fruitful Rim applied roughly 60 percent of nitrogen after planting. In the Southern Seaboard, where the weather is relatively warm and wet, farmers may be timing nitrogen applications to avoid loss due to runoff, leaching, or volatilization to the atmosphere. Spring wheat farmers in the Northern Great Plains-the largest spring wheat region-applied just under one-quarter of nitrogen in the fall in advance of planting. This is far more than the proportion of nitrogen applied in the fall by spring wheat producers in the Fruitful Rim (10 percent) and Basin and Range (7 percent). Cotton farmers in the Fruitful Rim applied 20 percent of their nitrogen in the fall; this is more than twice the proportion of nitrogen applied in the fall by farmers in the Prairie Gateway (8 percent) and five times what is applied in the Southern Seaboard (4 percent) and Mississippi Portal (4 percent). Corn producers in the Heartland applied a considerable share of nitrogen in the fall (24 percent), while those in the Eastern Uplands and Southern Seaboard applied 2 percent and 1 percent, respectively. Finally, we consider the proportion of acres on farms that met four nitrogen management criteria: no fall application of nitrogen, at least some post-plant application of nitrogen, nitrogen application rates no larger than the benchmark rate, and nitrogen either injected or incorporated below the soil surface. We also consider the extent to which farmers met all four nitrogen management criteria and used no-till in the same field. For cotton, 24 percent of acres receiving nitrogen fertilizer were on farms that met all four nitrogen application criteria; 1 percent of these met these criteria and used no-till. In corn, 6 percent met all four nitrogen criteria; 2 percent also used no-till. For spring wheat, 2 percent of treated acres met all four criteria and no farmers reported using these practices while also using no-till. Farmers planting winter wheat met three of the four nitrogen criteria (all except fall application) on 10 percent of treated acres; 4 percent met all these criteria and used no-till."}, {"section_title": "Cover Crops", "text": "Cover crops are thought to play a major role in improving soil health by keeping the soil \"covered\" when an economic crop is not growing. These crops are included in crop rotations, but are typically not harvested. Cover crops reduce soil erosion, trap nitrogen and other nutrients that might otherwise be lost to the environment, increase biomass, reduce weeds, loosen the soil to reduce compaction, and improve water infiltration to capture and store a larger share of spring rainfall. These benefits may also be realized more quickly if adopted with no-till/strip-till systems (USDA/NRCS, 1996;Snapp et al., 2005). Because the 2010-11 phase 3 ARMS asks respondents to report cover crop use between harvested crops, estimates do not include fallow fields on which farmers sometimes plant cover crops to aid with soil erosion or for animal feed production. Nor are cover crops linked to specific harvested crops. Therefore, the cover crop proportions provided are relative to all planted acres (as opposed to only corn, soybeans, cotton, and wheat acres). Approximately 4 percent of farmers adopted cover crops on some portion of their fields. Cover crops were used on 1.7 percent of cropland (6.8 million acres) in 2010-11 ( fig. 9). Cover crop adoption was highest in the Southern Seaboard (5.7 percent) and lowest in the Heartland (0.6 percent) and Basin and Range (0.6 percent). That the northern regions had the lowest rate of adoption is not surprising since it is difficult to establish cover crops in cooler regions with shorter growing seasons (Wilson et al., 2014). From the perspective of whole-farm adoption, 8.6 percent of cropland was located on farms that used cover crops on a portion of their land and less than 0.3 percent of farms adopt on all cropland. Therefore, only 3.3 percent of those who used cover crops do so on all of their cropland acreage. Data limitations preclude examining the extent to which cover crops are being used in conjunction with notill/strip-till and nutrient management practices. However, the limited cover crop use suggests that the benefits received from multi-practice adoption are being realized on few acres.  A study of Indiana farmers found that operators are reluctant to adopt cover crops because of concern that cover crops may delay spring planting and because they are relatively difficult to understand and use (Reimer et al., 2012). In addition to limited time after harvest, farmers viewed seed cost, labor, increased management, and cover crop choice as major impediments to adoption (Reimer et al., 2012;Singer and Nusser, 2007). 12 Campaigns promoting adoption could consider incorporating extension services and others who are successful with the practice as these are preferred sources of information (Reimer et al., 2012)."}, {"section_title": "Conclusion", "text": "During 2010-11, we estimate that no-till/strip-till was used on 39 percent of combined corn, soybean, wheat, and cotton acreage. Using farm-level data, we estimate that 23 percent of these acres were located on farms where no-till/strip-till was used on all corn, soybean, wheat, and cotton land. The remaining 15 percent of no-till/strip-till acres were located on farms where no-till/ strip-till was used on only a part of the acres. These results imply that a majority of 2010-11 corn, soybean, wheat, and cotton acres (56 percent) were located on farms that were already equipped for and had experience with no-till/strip-till. Remaining land in these four crops (44 percent) was located on farms that did not use no-till or strip-till in 2010-11. While our analysis does not explain \"partial\" adoption, we hypothesize that both crop and field characteristics play a role. More broadly, we hypothesize that regional differences in no-till/strip-till adoption reflect both differences in crop grown and in climate, soils, and topography-factors that have already been shown to affect no-till adoption (Ogle et al., 2012;Toliver et al., 2012). Given that the benefits of no-till/strip-till multiply when used continuously and that almost onequarter of all land in corn, soybean, wheat, and cotton was tilled but was located on a farm that used no-till or strip-till, questions remain regarding the type of incentive (if any) may encourage these producers to extend no-till/strip to all the acres in their farm. A closely related question is: How do partial adopters differ from full adopters and nonadopters in terms of factors known to affect no-till/ strip-till adoption? This information could help identify potential barriers to full adoption on farms that currently use no-till/strip-till on only a part of their cropland. Unfortunately, many of the fieldspecific attributes known to affect no-till/strip-till adoption (e.g., land erodibility and soil permeability) are not available in the farm-level phase 3 ARMS. Further research using both farm-and field-level data may provide insight that is valuable in identifying opportunities to encourage (target incentives) no-till and strip-till adoption. In the management of nitrogen fertilizer, a substantial share of producers applied fertilizer after planting-applications that more closely coincide with plant needs than applications made prior to planting. For corn and cotton, the most nitrogen intensive of the four major crops, 22 percent and 59 percent of nitrogen was applied after planting, respectively. Nonetheless, fertilizer continued to be applied in the fall before planting for corn and cotton. Some producers also applied nitrogen at rates that exceeded the benchmark rates. Overapplication has substantial environmental and onfarm cost since excess nitrogen deteriorates water quality and creates greenhouse gas emissions, and it represents large opportunity costs for farm enterprises. Only 6 percent of corn acres and 24 percent of cotton acres meet four criteria for the management of nitrogen: no fall application, overall application rate at or below the benchmark, at least some nitrogen applied after planting, and fertilizer incorporated or injected below the soil surface. Using no-till/strip-till in conjunction with good nutrient management reduces nutrient runoff and nitrous oxide emissions, providing benefits to the field and reducing negative externalities from crop production. While best management practices are used individually by farmers, simultaneous adoption on all crop acres is rare. Combining no-till/strip-till, nutrient management, and cover crops on the same field provides multiple benefits, reducing the adverse environmental effect of crop production and improving soil health. However, successful applications require knowledge of how these practices are best integrated with specific crops, climate, and soil conditions. Future research is needed to determine the factors influencing sustained and combined adoption of soil best-management practices. Despite the many advantages attributed to cover crops, the rate of adoption is still quite low. Surveys suggest that many farmers still have reservations about the utility of cover crops on their own farm. Research into the on-farm effects (e.g., yield effects) of cover crops could show the extent to which farmers themselves could benefit. Incentive payments may encourage adoption of best management practices and, if successful, provide a demonstration effect that encourages adoption by other farmers. The Environmental Quality Incentives Program (EQIP), for example, provides payments over a 3-year period to help cover the cost of transitioning to no-till/strip-till, nutrient management (through written nutrient management plans), and cover crop adoption. Between 2009 and 2012, EQIP funded roughly 3.7 million acres of no-till/striptill, 6.5 million acres of nutrient management, and 1.7 million acres of cover crops (USDA/NRCS, 2013). The Conservation Stewardship program also supports these practices with payments spanning 5 years. States also support best-management practices: Maryland offers producers as much as $90 per acre for using cover crops (Maryland Department of Agriculture). These incentives prompted farmers to sign up more than 641,000 acres for the 2014-15 cover crop program-roughly half of the 1.28 million acres of harvested cropland in Maryland (USDA/NASS, 2014). Recent research shows that (1) incentive payments are critical in encouraging producers to prepare written nutrient management plans, and (2) producers who receive nutrient management payments are unlikely to apply fertilizer in the fall before planting corn (Claassen et al., 2014). Results are less conclusive regarding the effect of nutrient-management payments on nitrogen application rates or the proportion of nitrogen applied after planting. Nonetheless, the ARMS data show that most producers do not have written nutrient management plans. This implies that many farmers practice postplanting nitrogen application without the benefit of an incentive payment: only 7 percent of 2010 corn acres, 4 percent of 2007 cotton acres, and 4 percent of wheat acres have a written conservation plan for nutrient management (USDA/ERS, 2014a). More research may help clarify the role of nutrient-management incentives in the adoption of specific nutrient-management practices. Given that nutrient management practices vary widely across farms, it is likely that careful targeting of nutrient management payments-focusing support for nutrient management on farms and practices where improvements are most needed-will be important in maximizing the environmental benefits of conservation programs. Programs that introduce farmers to best management practices and provide technical assistance and support for a few years may be important to sustained adoption since farmers who observe positive results on other farms are more likely to adopt (Reimer et al., 2012). Economic Research Service/USDA  "}]