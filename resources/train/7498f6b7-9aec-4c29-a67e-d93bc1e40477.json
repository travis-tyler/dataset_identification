[{"section_title": "Abstract", "text": "The analysis of the brain from a connectivity perspective is unveiling novel insights into brain structure and function. Discovery is, however, hindered by the prior knowledge used to make hypotheses. On the other hand, exploratory data analysis is made complex by the high dimensionality of data. Indeed, in order to assess the effect of pathological states on brain networks, neuroscientists are often required to evaluate experimental effects in case-control studies, with hundreds of thousand connections.\nIn this paper, we propose an approach to identify the multivariate relationships in brain connections that characterise two distinct groups, hence permitting the investigators to immediately discover sub-networks that contain information about the differences between experimental groups. In particular, we are interested in data discovery related to connectomics, where the connections that characterize differences between two groups of subjects are found, rather than maximizing accuracy in classification since this does not guarantee reliable interpretation of specific differences between groups. In practice, our method exploits recent machine learning techniques employing sparsity to deal with weighted networks describing the whole-brain macro connectivity. We evaluated our technique on functional and structural connectomes from human and mice brain data. In our experiments, we automatically identified disease-relevant connections in datasets with unsupervised and anatomy driven parcellation approaches using high-dimensional datasets."}, {"section_title": "Introduction", "text": "The analysis of brain networks, or connectomes, is a recent and exciting advancement in magnetic resonance imaging (MRI) which promises to identify new phenotypes for healthy, diseased or ageing brains (Sporns (2011)) . A connectome is a mathematical description of the brain, which is conceived as a network, where brain areas (nodes) are connected by links (edges) (Sporns (2010) ), and connections can be either given by white matter tracts between pairs of brain regions, or by an index of correlation of functional activity (Richiardi et al. (2011) ). This allows for analysing the brain as a complex system of dynamically interacting components without explicitly relying on local activation or brain morphology."}, {"section_title": "Case-control studies and connectomics", "text": "Experiments with connectomes are typically designed by comparing a studied group with a control group in order to identify brain-network topological biomarkers relevant to the studied group (Rubinov and Sporns (2010) ). Indeed, inter-group differences in some of these topological measures have been discovered for various neuropsychiatric disorders (Bullmore and Sporns (2009) ), like Alzheimer's disease (Stam et al. (2009) ), multiple sclerosis (He et al. (2009) ), schizophrenia (Lynall et al. (2010) ; Cocchi et al. (2014) ), stroke (Grefkes and Fink (2011) ; Bonilha et al. (2014) ), major depression (Zeng et al. (2014) ), autism spectrum disorder (Crimi et al. (2017) ), etc. All these approaches use topological measures with statistical tests to assess their discrimination power in a univariate analysis framework. Alternatively, in a multi-variate framework, machine learning methods have been proposed to differentiate groups of subjects using topological measures (e.g., Iturria-Medina et al. (2011) ). Surveys on graph-topological metrics using functional magnetic resonance imaging (fMRI) data and related clinical applications using structural features are given respectively in Varoquaux and Craddock (2013) and Griffa et al. (2013) ."}, {"section_title": "Local differences between connectomes", "text": "The main drawback of the aforementioned approaches is the limited interpretability of graph statistics as they miss the local characterization of the groups in terms of differences in the connectivity, but rather employ global statistics which are difficult to be translated into clinical settings for local analysis. A method which allows insights on local connectivity patterns in case-control studies relies on network-based statistics (NBS) . In this approach, the connectivity between pairs of brain regions is tested for significance using univariate statistics for functional ) and anatomical ) connectivity disturbances. Simpson et al. (2013) extended the NBS method using a permutation test based on Jaccard index at node level. While, Chen et al. (2015) enhanced NBS regulating the topological structures comprised. With the same aim, trying to identify discriminating regions between groups, Mastrovito et al. (2018) ; Ng et al. (2016) and Gaonkar and Davatzikos (2013) proposed to analyse the weights resulting from trained support vector machines (SVM). In particular, in Ng et al. (2016) a projection of covariance estimates onto a common tangent space was carried out to reduce the statistical dependencies between elements, and these estimates were used in a SVM framework. Then, both in Gaonkar and Davatzikos (2013) and Ng et al. (2016) meaningful weights were found through t-tests. While in Mastrovito et al. (2018) recursive feature elimination (RFE) is employed to keep features which are relevant for the classification starting from the whole set of features. Preliminary results showed that more advanced machine learning approaches based on SVM coupled with Riemannian/Grassmannian geometry can be used to discriminate groups of connectomes 2 (Dodero et al. (2015) ). Searching for a more specific and localized information, van den Heuvel and Sporns (2011) proposed a sub-graph level analysis, with a specific emphasis on the potential functional importance of highly connected hubs (\"rich-clubs\"). Although the focus on rich-clubs is insightful, this method could leave out subtle differences between case-control groups which are not present in highly connected hubs. Lastly, despite NBS and its extensions have been shown to outperforms other methods in comprehensive comparisons (Kim et al. (2014) ), the identification of graph sub-networks is a pre-requisite which can limit the detected connections and the t-tests are carried out in a univariate manner. Moreover, the choice of related statistics can influence considerably the results (Baggio et al. (2018) )."}, {"section_title": "Relation to previous methods", "text": "In this context, we are interested in data discovery related to connectomics, where the connections that characterize differences between two groups of subjects are found, and where maximizing accuracy does not guarantee reliable interpretation since similar accuracies can be obtained from distinct sets of features (Rondina et al. (2014) ). To overcome the limitations of the univariate approaches which perform statistical tests on single connections mentioned in the previous subsection -and in particular to the most commonly used NBS (Zalesky et al. (2010) ) -we use a multivariate bootstrap-like approach followed by a stability selection step. Therefore, we propose a fully data driven method to identify relevant brain sub-networks in experiments with case-control design. Our approach aims at creating an hypothesis generation tool for connectomes investigations. The method is supposed to work equally well with functional and structural MRI data, and no prior knowledge about the type of connectivity is required, only examples of brain connectivity matrices of two groups are needed.\nA similar method proposed by McMenamin and Pessoa (2015) implemented a two-layer dimensionality reduction technique based on principal component analysis (PCA), followed by quadratic discriminant analysis to identify clusters with altered connectivity at voxel level. However, when PCA was used for feature selection, the eigenvalues of the covariance matrix were used regardless the prior knowledge on the groups to be discriminated, and in doing so the resulting features may not be those which were really meaningful in terms of discrimination between groups. Conversely, our method directly performs a sparse version of linear discriminant analysis (LDA) that, by design, tries to optimize the feature selection step aiming at discriminating the groups. This allows the proposed method to be more specific in terms of identified discriminating connections. Furthermore, sparse models follow a feature selection agenda to subselect among existing variables, whereas PCA dimensionality reduction follows a feature engineering agenda to generate a set of new variables. A feature selection by sparse model is indeed similar to the RFE used by Mastrovito et al. (2018) . However, the stability of RFE approach depends heavily on the type of used model for feature ranking at each iteration, and as shown empirically, using regularized ridge regression jointly to stability selection criteria can provide more stable results in terms of stability selection of features if used combined with a stability criterion, as this combination yields finite sample familywise error control and dramatically improves feature selection (Meinshausen and B\u00fchlmann (2010) ; Ye et al. (2012) ). More specifically, our model is based on an ensemble of sparse linear discriminant models allowing to find the networks' elements (a set of edges) able to consistently distinguish two groups, in the attempt to minimize the subset of selected connectivity features and simultaneously maximize the difference between the groups, jointly using the selected features (Clemmensen et al. (2011) ). Essentially, the system acts as a filter removing the elements that are not useful to discriminate between the groups. First by enforcing sparsity at individual level. Then, by performing a second stage of feature filtering 3 across the dataset to assure stability selection. It is acknowledged that such a feature selection can be applied to arbitrary high-dimensional, multivariate datasets. Nevertheless, recent studies showed that sparsity based approach can be particularly useful in graph/connectome analysis as they can highlight significant connections when prior knowledge is missing (Deligianni et al. (2013) ; Xie and He (2012) ; Coloigner et al. (2017) ; Kim et al. (2014) ).\nOther methods have already used sparsity to estimate relevant connections (Huang et al. (2010) ; Lee et al. (2011) ; Gramfort et al. (2013) ). However, these methods did not focus on finding the discriminant connections between groups while performing the sparse selection. They use sparsity to reduce the number of connections regardless on the inter-class discrimination."}, {"section_title": "Paper overview", "text": "Owing to the sparsity principle driving the learning method combined with the statistical robustness of ensemble methods, our multivariate approach can scale up with the number of analysed connections, even when employing a limited number of whole-brain connectivity matrices. By virtue of being multivariate, this approach can identify brain sub-networks whose edges combination can characterize the differences between the connectomes but taken independently cannot. Moreover, the method does not have to rely on covariance matrices. It just needs an index describing the strength of connectivity between the areas in terms of correlation, similarity, dissimilarity or other metrics. For example, in case of structural connectivity the matrix can be determined counting the number of connections between the areas.\nWe validated the approach on three real datasets. In a first experiment, we used the structural connectivity, based on the tractography extracted from diffusion tensor imaging (DTI). Specifically, we compared a group of acallosal BTBR mice (a well-characterized model of autism) with a group of control normocallosal and normosocial C57BL/6J mice (Sforazzini et al. (2014a) ; Squillace et al. (2014) ). Performing this experiment with a simple and well known connectivity dysfunction, without the use of any prior anatomical parcellation to avoid any prior bias, we empirically validated the approach, which was able to retrieve the expected dissimilarity between the two groups.\nA further experiment was conducted on structural connectivity matrices from a publicly available dataset of patients affected by Azheimer's disease, where connectivity is also defined by tractography. The final experiment was carried out on a large functional dataset of attention deficit hyperactivity disorder (ADHD) children compared to typically developing (TD) children. In all cases, our method successfully detected inter group differences relevant to the medical condition investigated. Those results are compared to the results obtained by using NBS. NBS and MLA select discriminative features in different ways. NBS performs univariate t-tests among the features while MLA performs a sparse multivariate regression. Nevertheless, NBS is the commonly used algorithm for this type of analysis and considered the state-of-art."}, {"section_title": "Methods and Data", "text": "This section first describes the two types of data used to test the proposed method: a mice dataset with high dimensionality, and two publicly available human datasets. Afterwards the pre-processing and the proposed computational model for discriminating patterns in whole-brain analysis are described. 4"}, {"section_title": "Data Mouse Structural Connectivity Data", "text": "The mice cohort was composed of two groups of 22-26 weeks old male subjects (n=16): BTBR T+tf/J mice (n=8) which share analogies to all diagnostic symptoms of autism and characteristic functional and structural features of the brain (Ren et al. (2007) ; Dodero et al. (2013) ; Fenlon et al. (2015) ), and C57BL/6J mice (n=8) which are characterised by normal sociability and represent the control group. The animal preparation protocol is described in Sforazzini et al. (2014b) and Dodero et al. (2013) . Figure . 1 depicts an example of the expected difference between the BTBR and C57BL/6J mice groups. In particular, BTBR mice lack the corpus callosum differently from the C57BL/6J mice.\nBriefly, brains were imaged inside intact skulls to avoid post-extraction deformations. Ex-vivo high-resolution DTI and T2-weighted images were acquired on paraformaldehyde-fixed specimens with a 7 Tesla Bruker Pharmascan MRI scanner (Billerica, MA, USA). T2-weighted MR anatomical images were acquired using a RARE sequence with the following imaging parameters: TR/TE = 550/33 ms, RARE factor = 8, echo spacing 11 ms, and a voxel size of 90 \u00b5m isotropic. DTI volumes were acquired using 4 scans at b0 and 81 scans with different gradient directions (b=1262 s/mm 2 ), with resolution 130 \u00d7 130 \u00b5m 2 , using a 4-shot EPI sequence with TR/TE = 5500/26 ms. Anatomical and DTI sequences were acquired sequentially at the same centre with the same scanner. This dataset is freely distributed 2 . This dataset is used to show that the algorithm is able to identify difference between the groups which are expected to be found as a proof of concept."}, {"section_title": "Human Structural Connectivity Alzheimer Data", "text": "The himan experiments have been performed on the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset publicly available 3 . Only baseline scans were used to avoid confounding factors as advanced brain atrophy and treatment in the Alzheimer patients. This cohort comprised 51 Alzheimer patients (age: 76.5 \u00b1 7.4 years), and 49 normal elderly subjects (77.0\u00b15.1) matched by age. The used data were DTI, and T1-Weighted obtained by using a GE Signa scanner 3T (General Electric, Milwaukee, WI, USA). The T1-weighted scans were acquired at with voxel size = 1.2 \u00d7 1.0 \u00d7 1.0 mm 3 TR = 6.984 ms; TE = 2.848 ms; flip angle=11 \u2022 ). DTI were acquired at voxel size = 1.4 \u00d7 1.4 \u00d7 2.7 mm 3 , scan time = 9 min, and 46 volumes (5 T2-weighted images with no diffusion sensitization b0 and 41 diffusion-weighted images b=1000 s/mm 2 ). For each subject, DTI and T1 have been acquired and co-registered."}, {"section_title": "Human Functional Connectivity ADHD Data", "text": "Functional connectivity was also investigated on a larger resting-state fMRI dataset comprising ADHD and TD subjects (Castellanos et al. (2008) ). In particular, we used the publicly available New York University Child Center dataset 4 , which is the main cohort of this study. The dataset comprised 95 ADHD subjects (67 male and 28 female, mean age 11.4 \u00b1 2.7) which were either inattentive, or hyperactive or both, and 92 healthy TD (45 male and 47 female, mean age 12.4 \u00b1 3.1) which represents the control group.\nThe fMRI volumes were acquired with a Siemens Allegra 3T, with TR/TE 2000/15 ms and voxel size 3 \u00d7 3 \u00d7 3mm 3 . This dataset is used as a real case study where NBS is not useful in proving local connectivity differences."}, {"section_title": "Methods", "text": ""}, {"section_title": "Mouse Dataset Processing and Encoding", "text": "Deterministic tractography was performed on the DTI volumes after eddy current corrections, by using the Fiber Assignment by Continuous Tracking (FACT) algorithm (Mori et al. (1999) ). Fibres were reconstructed in the original volumes following the 2nd-order Runge-Kutta integration scheme (Lazar et al. (2003) ) starting from the centre of each voxel and following the main direction of the tensor. The tracking was stopped when the fibre made a sharp turn (> 35 \u2022 ) or entered a voxel with fractional anisotropy (FA) < 0.15.\nTo allow inter-subject comparisons, registration matrices to a common space were computed for each subject by using affine transformation (12 degrees of freedom). The obtained registration matrices were then applied to the endpoints of each fibre. This allowed the tractography algorithm to work on the original volume space without warping the tensors.\nTo enable a purely data-driven inter-group comparisons without the use of anatomical priors, the brain volumes were split into 3D cubes of size 1 \u00d7 1 \u00d7 1mm 3 , without considering any atlas. Each cube was a node in the graph and the connectivity matrix was built counting the fibres starting and ending into two distinct cube elements of the grid, avoiding the inclusion of u-fibers. This resulted in defining 42,704 edges.\nThe advantage of this approach was that the result of the proposed analysis method was nearly independent from the size of parcellation. Indeed, not considering the anatomy nor the physiology of the brain might result in bundles of fibers split into \"sub-bundles\" connecting adjacent cubes. However, if there is a difference between the two groups it is retrieved for all sub-bundles, hence the overall bundles are then reconstructed. Yet the choice of using a fine grid or an atlas is arbitrary."}, {"section_title": "Alzheimer Dataset Processing and Encoding", "text": "Tractographies for all subjects have been generated processing the DTI data with a deterministic Euler approach, stemming from 2,000,000 seed-points and stopping in case of FA smaller than 0.25. Tracts shorter than 3cm were discarded during the connectome construction. Structural connectivity matrices were constructed by counting the number of fibers connecting two regions of interest (ROIs) of the registered Harvard-Oxford atlas (Makris et al. (2006) ). This atlas defines 96 ROIs, it is freely available with several brainimage analysis platforms, and it has been used in several structural studies including Alzheimer (e.g. inDagley et al. (2017)). The Harvard-Oxford atlas is a probabilistic atlas. However, we used the version where each voxel is associated to the ROI with highest probability."}, {"section_title": "ADHD Dataset Preprocessing and Encoding", "text": "This dataset has been pre-processed as described in Colby et al. (2012) , and the final connectivity matrices are publicly available. In brief, resting-state fMRI data were preprocessed following these steps: Removal of first 4 EPI volumes, slice timing correction, motion correction, and then applying the regressors for WM, CSF, motion time courses and a low order polynomial detrending. A band-pass filter of 0.009 < f < 0.08 Hz was also applied. Lastly, the data were blurred using a 6-mm Full Width at Half Maximum Gaussian filter. The functional region of interests were obtained using the method described in Craddock et al. (2012) for 200 areas. 6\nMulti-link Analysis (MLA)\nThe interpretation of differences in brain networks is not always straightforward given individual variability and the high dimensionality of data (Sporns (2012) ). Moreover, the internal structure of the brain connectivity with cross-relationships and dependencies in the feature space (the edges) may prevent a full retrieval of groups' differences using univariate analysis. Machine learning and dimensionality reduction techniques are designed to solve these issues, and hence these methods are a natural choice for addressing this discrimination task. We propose a twostage feature selection process. At the first stage a classifier reinforcing sparsity is employed to select discriminant features, then only features which are consistent across dataset are kept according to a stability selection criterion.\nAn approach simultaneously implementing both techniques in a common sparse framework is sparse logistic regression, which has been already used to select relevant voxels for decoding fMRI activity patterns (Yamashita et al. (2008) ; Ryali et al. (2010) ). Alternatively, in case of Gaussian-distributed data, the well known linear discriminant analysis has been extended to the sparse case with the sparse discriminant analysis (SDA) model (Clemmensen et al. (2011) ; Witten and Tibshirani (2011) ). In particular, the method by Clemmensen et al. (2011) implements the elastic net regression with the 1 -norm on the feature weights that indirectly sets the number of selected features. In all our experiments we resorted to this SDA model with the assumption that data in each group have a Gaussian distribution.\nFor all the experiments, the connectivity matrices are vectorized and ordered as rows in a n \u00d7 p data-matrix X, with n being the number of observations and p their dimensionality. The corresponding classification of objects is encoded into the n \u00d7 K indicator matrix Y, where each cell Y ik indicates whether observation i belongs to class k. The SDA proposed by Clemmensen et al. (2011) then finds the discriminant vectors \u03b2 k for each class k and the vector of scores \u03b8 k by the convex optimization given by the following regularized linear discriminant formulation\nwhere \u2126 is an arbitrary positive definite matrix, which allows to calculate a smooth discriminant vectors \u03b2 k even if the number of samples is smaller than the number of features (n p). In our experiments we used \u2126 = I which makes the formulation an elastic net problem. The nonnegative parameters \u03b7 and \u03b3 control respectively the 1 and 2 regularization.\nThe advantage of the proposed sparse method is its capability of managing high-dimensional data thanks to the 2 regularization. Moreover, the 1 regularization term allows the model to select a small subset of features for the linear discrimination. This might result in a loss of predictive power while however reducing the over-fitting problem. In contrast, the 2 penalty term enjoys the grouping effect property, i.e., it works keeping small and comparable the weights of correlated predictors (Zou and Hastie (2005) ). Moreover, 2 penalty term is much better at minimizing the prediction error than 1 regularization. As a result, their combination allows to determine a good trade-off between an optimal classifier and a minimal selection of relevant predictors.\nAlthough it is acknowledged that this type of model can be affected by the choice of \u03b7 which represents the advantage and limitation of the method, indeed we noticed that the algorithm was satisfactorily discriminating the two classes on a wide range of \u03b7 values. In this work we 7 were mostly interested on discriminant features rather than finding an optimal classification. However, the results are shown using the values which allow better accuracy estimated in a nested cross-validation manner to produce a jackknife-like classification. In practice a nested leaveone-out procedure was employed. For 1000 iterations, a sample was removed from the training dataset and used as test-set to find the optimal value within a range, then the performances were evaluated on another sample also removed prior the optimization from the training set and used as validation. In presence of a plateau of identical optimal values, the value generating less connections was taken. The parameter \u03b3 was not optimized for the same reason and it was fixed as 10 \u22126 to guarantee a minimal regularization. Lastly, the parameter \u03b7 can also be reformulated as the desired number of variables selected by the model. In the following we will refer to this number as \u03b1 instead of \u03b7. We address the reader to Zou and Hastie (2005) for a description of the relation between \u03b7 and \u03b1, and further details on the algorithm are given in the Appendix. Although this model is very powerful in determining small and good subset of features allowing to linearly discriminate the classes, it suffers from a stability problem (Meinshausen and Buhlmann (2010) ), i.e., small changes in the data can drastically change the result of a single run. To cope with this stability issue, in order to improve the robustness of SDA, we have introduced a second stage exploiting the ensemble of low-stability algorithms to produce a more stable feature selection. In practice, we perform further feature selection to ensure that the features are stable across subjects.\nIn the specific case, the SDA classifier was trained with a nested leave-one-out approach. This ended up in an ensemble of models each one with a subset of \"relevant\" features (connections), selected so to maximize the discrimination between the two groups. Then we refine this ensemble of models by occurrence validation, where only features which were frequently selected during cross-validation were retained, i.e., features occurring in less than a pre-defined percentage of runs were discarded. In all our experiments reported below this threshold was determined as half the number of subjects in the corresponding dataset. In this way, we ensure stability selection of the features (Meinshausen and B\u00fchlmann (2010) ). The weights of the selected features \u03b2 k were then used to evaluate their importance, namely, the higher the weight, the more important the feature is."}, {"section_title": "Results", "text": "In this section we report the results for the experiments with high-dimensional structural connectivity with murine data, and two datasets of human structural and functional connectivity collected to study respectively Alzheimer's and ADHD."}, {"section_title": "Mice Structural Connectivity Data", "text": "In order to prove the discriminative power of our approach, we tested its ability to correctly distinguish the structural connectomes of two groups of mice (C57BL/6J and BTBR) characterized by previously described white matter alterations, i.e., the presence/absence of the two major neocortical intra-hemispheric tracts: the corpus callosum and the dorsal hippocampal commissure (Sforazzini et al. (2014b) ). Being the structural alteration in the BTBR mice well known, this dataset is used to validate the proposed method. Indeed, the BTBR mice model represents a ground truth of expected differences between the two groups. Over and above, more than the discrimination between the groups, we are interested in empirically assessing the ability of our approach to correctly identify white matter tracts differences in the two groups. 8\nIndeed, by using the proposed algorithm, the model correctly classified all samples in a crossvalidation schema, and structural differences -as the lack of corpus callus -were found as expected from literature. The mean misclassification varying the parameter \u03b1 resulting by the cross-validation is shown in Figure .2 (a) .\nTo this aim the proposed approach returns a statistics of the relevance of features, by counting the amount of occurrences of the features selected by the ensemble of models. Figure .2(b) shows the occurrence of the detected features for the experiment with mice structural connectomes, some of which are present in all the runs, indicating a strong relevance for the problem at hand. Interestingly, the edges identified by the algorithm showed the expected characteristic features of the BTBR strain, including the agenesis of the corpus callosum and the presence of rostral-caudal rearrangement of white matter. Figure . 3 shows how our algorithm (MLA) and NBS identify the parts of the corpus callosum which are known to be missing. This experiment confirms that our new approach and NBS are able to identify the acallosal connections in the BTBR models.\nThe whole analysis from raw DTI data to tracts selection of the 10 subjects, by using Matlab Mathworks 2014, took less than 40 minutes on a 2.6 GHz machine with 4GB of RAM. However, the five rounds of MLA analysis required only less than 1 sec (with 1 parameter \u03b1 = 110 estimated by nested cross-validation which also gave 100% accuracy)."}, {"section_title": "Human Structural and Functional Data", "text": "We tested the algorithm also on a publicly available dataset based on human MRI recorded from patients with Alzheimer against normal elderly subjects, and ADHD against TD subjects. The Alzheimer dataset was in particular used to investigate the influence of the regularization parameter regarding the features which are obtained by using the proposed method and NBS. In practice, to test which features are detected by the proposed method and not by the NBS and vice-versa varying \u03b1.\nThe NBS algorithm with threshold equivalent to p-value =0.05 detected 14 connections which used in nested cross-validation classification task produced 65% accuracy. As shown in Figure  . 4, by increasing the \u03b1 parameter, the number of included features by MLA and not by NBS increases and the opposite decreases with a break-even-point at \u03b1 = 15. Interestingly, the best classification score with the features detected by the MLA was optimal for the \u03b1 values of 31 where MLA was including more features than the NBS algorithm and producing 80% accuracy. It has to be noted that with the second stage of feature selection the number of retained features by MLA can be slightly less than the parameter \u03b1. Moreover, it is worthwhile to mention that generally features were symmetric. Namely, the connection from a ROI a to a ROI b and viceversa from a ROI b to a ROI a were detected. The resulting features produced by using the MLA when \u03b1 = 31 are depicted in Figure . 5. Here, NBS produced 14 connections, which interestingly were all included in those found by the proposed algorithm. The identified connections were mostly ipsilateral connections within the two temporal lobes.\nIn the experiment with the ADHD data, the cross-validation found the optimal value for the the MLA algorithm as \u03b1 = 9, which highlighted 7 discriminant connections across the groups with an accuracy of 66%, but the NBS with threshold equivalent to p-value = 0.05 did not produce any significant value. This might be due to the fact that the first key step of NBS is to identify candidate subnetworks which are then tested for their relevance using permutation testing. These candidate subnetworks are only selected if the nodes are explicitly connected between each others. Connectomes derived from data with high dimensional parcellations (as the used dataset with 200 areas) are more likely to have areas that are not connected, either because of low signal or for over parcellation. This is a problem for methods expecting a connected graph, like NBS, 9 but it is not for our approach that does not have any prior on the types of connectivity expected. The connections among the areas detected by the proposed algorithm are also reported graphically in Figure .5 and .6 respectively for the Alzheimer and ADHD experiment. Connections set to zero by MLA are not depicted. The Alzheimer and ADHD samples analysis took respectively less than 1 second and about 30 seconds on 2.6 GHz machine with 4GB of RAM. "}, {"section_title": "Discussion", "text": "The proposed method performs a global multivariate analysis characterizing local differences between networks. As this method is based on sparsity principles, it is particularly suited for those experiments with high-dimensional data and small sample size. Moreover, the analysis based on multivariate statistics allows to retrieve sub-networks based on feature dependencies. The limitation of NBS in detecting univariate differences is visible in the experiment with human functional data. In fact, the proposed algorithm detects some connections which are very often selected by the ensemble of learners, as seen in the histogram in Figure . 2, but if considered with the univariate analysis, some edges are discarded as producing non-significant p-values (e.g., the features detected by using the ADHD data). Nevertheless, both MLA and NBS gave similar results for the mice data experiment confirming the initial hypothesis given by the anatomical differences.\nThe stability of the selected features is an important characteristic of the algorithm. As assessed empirically, by increasing the value of \u03b1, only new features are added without removing 10 (Zalesky et al. (2010) ) are reported. \"Not detected\" (N.D.) means not significant difference between the two areas. ADHD= Attention-Deficit/Hyperactivity Disorder, TD= Typically developed. For this experiment, no statistically significant features were obtained by the NBS algorithm using the t-test threshold corresponding to p-value = 0.05."}, {"section_title": "p-value #", "text": "Region 1 the previous ones, and satisfying accuracy is achieved for a large range of values as shown in Figure .2 (a) . Nevertheless, the parameter \u03b1 does not need to be set automatically, but actually it represents the strength and limitation of the method. In fact, despite in the reported experiments the used \u03b1 was estimated by cross-validation, the sensitivity of the algorithm can be manually adjusted trough this single parameter which allows the neuroscientists to decide how strong the class characterisation should be and it is directly related to the number of connections shown. A similar user-guided approach with methods based on sparsity has been previously described (Huang et al. (2010) ; Lee et al. (2011) ). When MLA was applied to the acallosal BTBR mice, a mouse model of autism (Sforazzini et al. (2014a) ; Squillace et al. (2014) ), as shown in Figure  . 3, the tracts detected as discriminant were those with altered white matter connectivity in BTBR mice with respect to control mice. These results are in line with previous results in literature, including the lack of corpus callosum and hippocampal commissure (Wahlsten et al. (2003) ; Ren et al. (2007) ; Fenlon et al. (2015) ), and increased intra-hemispheric ipsilateral connectivity (Dodero et al. (2013) ; Meyer and R\u00f6richt (1998) ), also observed in human patients with autism spectrum disorder (ASD) (Frazier and Hardan (2009); Casanova et al. (2011) ). This demonstrates that the algorithm is able to identify the known differences between groups. Similar results were obtained with the structural dataset on Alzheimer. Altered brain connectivity both at the microstructural and macrocircuitry levels has been described in this disorder due to the amyloid plaques (Sheline et al. (2010) ). As depicted in Figure . 5, we found widespread connectivity temporal and para-hippocampal differences in patients with Alzheimer compared to healthy elderly subjects. This is inline with several studies about functional connectivity which highlighted decreased functional connectivity between the temporal gyrus and neighbouring regions (e.g. Huang et al. (2010) ; Supekar et al. (2008) ). While pathways between the hippocampus, the parahippocampal gyrus and neocortical regions are considered to be the first affected in Alzheimer's patients (de LaCoste and White (1993) ; Allen et al. (2007)). Neurodegeneration and loss of connectivity between frontal areas, the insula and within the areas of the frontal gyrus has been also documented (Seeley et al. (2009) ). The found connection between the cuneal cortex left and the frontal opercolum right were possible through fibers bifurcating from the corpus callous. Studies have been shown that in particular the functional activities at the cuneal cortex is reduced with the progress of Alzheimer Zhang et al. (2010) , this can explain visual field defects seen in some patients Berisha et al. (2007) .\nRegarding the discriminant connections detected by the MLA algorithm for the ADHD dataset, among the detected areas using \u03b1 = 9, there were the connections between the Frontal Pole and the Cingulate Gyrus, and the Frontal Pole and Angular Gyrus, which are the main Functional hubs of the default mode network (DMN). The DMN is known to be altered in ADHD subjects (Colby et al. (2012) ; Uytun et al. (2016) ). As it has been hypothesized that ADHD subjects may have diminished ability to inhibit the default processing of the DMN (Fassbender et al. (2009) ). The other detected connections could be explained as dorsal medial and medial temporal systems still related to the DMN (Andrews-Hanna et al. (2014) .\nThe connectivity differences for the human dataset, shown in Figure .5 and .6, and reported in Table1 and 2 were those detected by MLA, where some of them were gone miss by NBS. This shows that different approaches -one based on sparsity and one based on family-wise error ratecan produce similar results but the proposed method can find more features than the NBS. NBS and MLA select discriminative features in different ways. NBS performs univariate t-tests among the features while MLA performs a sparse multivariate regression. It is acknowledged that the methods achieve different objectives. However, it has been shown that sparse model jointly to stability selection criteria introduced in the second stage of the proposed method can lead to more robust results than false discovery rate and family-wise error rate based model Hofner et al. (2015) . Moreover, without a ground truth, MLA can be preferred for exploratory purposes as it can provide more insights (more detected features) to neuroscientists looking for case-control differences."}, {"section_title": "Conclusions", "text": "In this manuscript, a fully automated method to characterise brain connectivity in case-control studies was reported. The method based on a sparse learning classification, has been tested on structural and functional connectivity data. The approach is able to identify brain areas of interests that can be further analysed with standard seed based approaches or through histological white matter validation.\nThe algorithm successfully highlighted some known structural white matter differences in acallosal mice, and identified previously reported structural and functional connections in human Alzheimer's and ADHD patients with respect to control subjects. The developed software is freely distributed as a Matlab toolbox at the url https://www.iit.it/code/multi-link-analysis. Our approach can help highlighting differences in connectional features, and in generating hypotheses that can complement univariate techniques. Higher values indicate connections that characterize the differences between BTBR and control mice in the classifiers within our ensemble framework. This information is used to automatically select a sub-set of \"relevant\" features. Namely, the most frequent features highlighted by the histogram are kept.\n(a) (b) (c) (d) Figure . 3: Graphical representation of the most significant features charactering the structural connectome of the two populations: the axial views of a randomly selected subject from the C57BL/6J control population (a) using our algorithm (\u03b1 = 110) and (b) the NBS algorithm using as a threshold p-value 0.05. While (c) and (d) are the axial views and of a randomly selected subject from the BTBR population respectively for our algorithm and NBS. As expected BTBR mice show a lack of corpus callosum and hippocampal commissure and an increased intra-hemispheric ipsilateral connectivity. The depicted discriminant features detected by the proposed algorithm can be increased varying the \u03b1 parameter according to the user taste. Table 2 ."}]