[{"section_title": "INTRODUCTION", "text": "Research on the diagnosis and treatment of the new type of coronavirus (COVID-19), which first appeared in Wuhan Province of China in December 2019 and brought life to almost a standstill all over the world, has gained great momentum. The main reason why this dangerous virus brings life to a halt in the world is its very high contagious feature. Deaths occur when the disease turns into pneumonia (10). People can be contagious before they develop symptoms, making it difficult to control the spread of the virus. Development of any vaccine can take at least 12 months according to the research conducted until the writing of this paper (27). Currently, there are no effective antiviral drugs (29). COVID-19 disease caused by coronavirus has been declared a pandemic by the World Health Organization (WHO) as of March 11. According to the Johns Hopkins Coronavirus Research Center, as of July 10, 2020, the total number of confirmed COVID-19 cases worldwide was 12,294,117 and the total number of active cases 4,976,653. As of the same date, the number of deaths due to COVID-19 disease was 555,531. These statistics reveal that this novel coronavirus can be deadly, with a 4.94% case fatality rate. Distribution of COVID-19 deaths reported worldwide, as of July 10, 2020 by the European Centre for Disease Prevention and Control can be seen in Supplemental Fig. S1; all Supplemental material is available at (https://doi.org/10.6084/m9.figshare.12957488.v1).\nLooking at the current medical technological advances, COVID-19 disease diagnosis is typically based on swabs from the nose and throat (22). The definitive diagnosis is made after pathological examinations. The major disadvantages of this procedure are that it is time consuming and susceptible to sampling error and therefore inefficient. These tests are known as reverse-transcription polymerase chain reactions (RT-PCR), and it is confirmed that the sensitivity of the tests is not high enough for early detection (19). It is possible to increase the diagnostic capabilities of physicians and reduce the time spent for accurate diagnosis with the aid of computer-assisted automatic detection and diagnosis systems. The purpose of these systems is to help experts make quick and accurate decisions. Automatic detection of COVID-19 disease from medical images is a critical component of the new generation of computer-assisted diagnostic (CAD) technologies and has emerged as an important area in recent years. X-rays are a widely used imaging method for the detection, classification, and analysis of diseases caused by viruses. The motivation of this study is the early diagnosis of COVID-19 disease by using a fully automatic, deep convolutional neural network (CNN), whose hyperparameters are determined using Grid Search. The design of a reliable and robust CAD system is proposed using the highest possible number of COVID-19 X-ray images in the literature.\nThere are quite a few studies about the detection of COVID-19 disease using CNN because it is a new type of disease. Ozturk et al. (22) used a deep CNN model for binary classification [COVID-19(+) versus COVID-19(\u2212)(\u2212)] and multiclassification (COVID-19(+) vs. normal vs, pneumonia). With their 17 convolutional layered CNN architecture, they achieved 98.08% success for binary classification and 87.02% success for multiple classification. Although the accuracy rate they obtained is not bad, the number of images they used is not high enough, namely 127 X-ray images for COVID-19, 500 X-ray images for normal, and 500 X-ray images for pneumonia. Another study about detection of COVID-19 disease is by Loey et al. (20), who proposed the deep transfer learning-based generative adversarial network (GAN) model. Their objective was to collect all possible COVID-19 X-ray images. They achieved collection of 307 X-ray images for each of four different classes. They obtained an overall accuracy rate of 85.2% for multiclassification [COVID-19(+) vs. normal vs. pneumonia]. Although they tried to collect the highest number of COVID-19 X-ray images, they were able to collect only 307 images. Another study that is worth examining is in Ref. 19. In this study, the researchers proposed a fully automatic CNN framework to detect COVID-19 disease. They obtained a 96% overall accuracy rate for the detection COVID-19 disease using 1,296 COVID-19 CT images from six different hospitals. Togacar et al. (29) presented a COVID-19 disease detection study using the MobileNetV2 deep learning model. They obtained a 99.27% overall accuracy rate for the COVID-19(+), normal, and pneumonia multiclassification. They used 295 COVID-19, 65 normal, and 458 pneumonia X-ray images. They achieved a satisfactory result, but the number of images they used was still not high enough. There are other studies about usage of deep learning techniques for COVID-19 disease detection (2, 4). Researchers who are interested in more studies in the literature can investigate those papers.\nThe goal of this study is to present two novel and fully automatic deep CNN models whose hyperparameters are automatically determined by Grid Search for COVID-19 detection and virus classification using the largest possible number of X-ray images of COVID-19 that exist in the literature. The rest of this paper is organized as follows. The following section, proposed cnn models, presents the proposed method. All the steps about the proposed architectures for each task can be found in this section. In experimental results and discussion, experimental results are discussed, and these results are compared with the state-of-art methods The final section offers conclusions of the paper."}, {"section_title": "Hyperparameter tuning using Grid Search. :::  ::: PROPOSED CNN MODELS", "text": "Along with deep learning, studies in machine learning evolved from feature engineering to architectural engineering. In previous studies, researchers mostly created the best feature sets to represent a problem in order to solve the problem; that is, they were working on extracting attributes and selecting those with the highest representational capability among them (13, 36). The development of deep learning approaches included how to design a multilayered artificial neural network: how many layers it consists of, how many neurons it contains, which optimization algorithm or activation function will be more important in problem solving. Solving problems with deep learning has become equivalent to designing the multilayered network structure in the best and optimum way. In this architectural engineering, the most frequently used tools after the researcher's intuition were hyperparameters. While designing machine learning models from data, the algorithms or techniques used in the model bring along some parameters that the designer should decide on. The parameters that vary according to the problem and data set and which are left to the person who designed the model are called hyperparameters. Choosing the most appropriate hyperparameter group is one of the important problems to be tackled. The choice of hyperparameters generally varies depending on the intuition of the designer, the experiences obtained from previous problems, the reflection of the applications in different fields to our own problem, current trends, and the design dependency within the model (25). The selection of such hyperparameters is a tedious and time-consuming process. However, recently, different techniques have been introduced to choose the most suitable hyperparameter group for the solution of a problem (11, 14).\nWhile making the model design, the first choices we make for hyperparameters generally do not lead us to the correct results. Hyperparameters are changed in an iterative way; the success of the model is observed, and the most suitable hyperparameter group is tried to be selected for the model. In addition, there are methods that automate this selection job. Some of the hyperparameters are in a position to take an infinite number of values. However, we can determine ranges for the values that hyperparameters can take by using the preliminary information we have about the problem. Value lists are created for hyperparameters by selecting certain key points from these ranges.\nIn the hyperparameter selection process with Grid Search, the network is trained for the combinations of all values in the specified range, and the best combination is selected as the hyperparameter group according to the observed conditions (25, 36). To decide the configuration values, trends in Grid Search should be observed. It should not focus only on the best-performing result; all results in the Grid Search should be reviewed. In other words, fixed parameters or intervals should be observed by observing the relationships and trends among the parameters. Since training deep networks is a lengthy process, a subset of the data set can be worked out for hyperparameter selection, thus saving time. The purpose of this process is not to find the most suitable values for hyperparameters but to create a general opinion. Thus, the range of hyperparameters is determined.\nGrid Search is used to find the optimal hyperparameters of a model that result in the most \u201caccurate\u201d predictions. The optimal hyperparameter values are set and tuned before the learning process is started, since hyperparameters have big effects on the result of the learning process (5, 6). In all tasks of this study, a stochastic gradient descent momentum (SGDM) optimizer is used to update the network parameters (weights and biases) to minimize the loss function by taking small steps at each iteration in the direction of the negative gradient of the loss. CNN and Grid Search were implemented on Matlab\u2019s 2019a software environment with the help of Machine Learning Toolbox. A grid search function for deep learning in Matlab has been created for four hyperparameters (learning, rate, minibatch size, momentum, and \u21132 regularization). The created function has been designed considering \u201cfitness function value,\u201d which has the following formula in Eq. 1:\nThe hyperparameters that give the minimum fval value are accepted as the optimum hyperparameters and are given as output of the parameter optimization process. The algorithm of Grid Search optimizer used in the hyperparameter optimization of the CNN models in this study can be summarized as follows.\nIn this study, a limited range of hyperparameters has been chosen to optimize, because when choosing a grid search method for optimizing hyperparameters, the number of hyperparameters to be optimized should be taken into account, as well as the value ranges for these parameters. However, since the optimization of these hyperparameters requires high computation time, it is not practically meaningful to evaluate all possible probabilities specified for wide parameter value ranges in the experiments to be carried out and to use grid search method. That is why a limited range of each hyperparameter is adopted in this paper. If the selected hyperparameter subset and value ranges form a small search space, the grid search method can be used to obtain successful results. However, when the space begins to expand, random search, metaheuristic algorithms or reinforcement learning algorithms may be preferred. Therefore, using metaheuristic methods (such as genetic algorithms, particle swarm optimization, and differential evolution) for hyperparameter optimization will be more efficient in practical terms. Hyperparameters that needed to be optimized for CNN models in this study are learning rate, minibatch size, momentum, and \u21132 (ridge regression) regularization, because these are among the most important fine-adjustment hyperparameters for the accuracy and success of the classification task. The optimal hyperparameters that were obtained for Task 1 and Task 2 using the Grid Search optimizer algorithm above are shown in Table 3 and Table 4, respectively."}, {"section_title": "Performance evaluation metrics. :::  ::: PROPOSED CNN MODELS", "text": "After the classification algorithm is performed, the performance of the classification must be evaluated. This is done in a variety of ways in previous studies in the literature (16). To check the performance of the classification algorithm, the confusion matrix is used in this paper. Confusion matrix provides helpful information regarding the actual image labels and predicted image labels proposed by the classification method. Different aspects of the classification performance can be assessed using this valuable information. Confusion matrix has diagonal values that show true positives (TP). TP is the number of samples classified as true when it is actually true. True false (TF) is the number of samples classified as false when it is actually false. False positives (FP) is the number of samples classified as positive when it is actually false. False negatives (FN) is the number of samples classified as negative when it is actually true. The most used performance evaluation metrics are accuracy, specifity, sensitivity, and area of receiver operation characteristic curve (curve (area under the curve, AUC). Accuracy is by far the most preferred one (16). In this study, training, validation, and test data sets are randomly assigned for multiple independent iterations to comprehensively test the CNN model. The performance measures, such as accuracy, AUC, sensitivity, specificity, and precision are evaluated on test data sets in this paper. These metrics can be computed using Eqs. 2\u20135, respectively."}, {"section_title": "Data set. :::  ::: EXPERIMENTAL RESULTS AND DISCUSSION", "text": "Since the COVID-19 virus is a new virus and appeared very recently, finding a data set is a huge problem. One of the main contributions of this study to the literature is that a wide variety of data sets have been used. Most data sets that are available in the literature have been found meticulously and used in this study. The first data set is called COVID-19 Image Data Collection by Joseph Paul Cohen, Paul Morrison, and Lan Dao and contains 542 frontal chest X-ray images from 262 people from 26 countries (8). This is a public open data set of chest X-ray images of patients who are positive or suspected of COVID-19 or other viral and bacterial pneumonias (MERS, SARS, and ARDS). The second data set that is used in this study has been created by Paul Money (21) and consists of 5,863 X-ray images and two categories: pneumonia and normal. The third data set used in this study is known as ChestX-ray8 by Wang et al. (35) and consists of 108,948 frontal view chest X-ray images of 32,717 patients. This data set is used to increase the number of pneumonia images. The fourth data set used in this study is the COVID-19 Radiography Database, created by a research team from Qatar University (23). This is a database of chest X-ray images for COVID-19-positive cases along with normal and viral pneumonia images; 219 COVID-19-positive images, 1,341 normal images, and 1,345 viral pneumonia images are currently available. The last data set is by Kermany et al. (18) and was added to the data set to increase the number of pneumonia and COVID-19 chest X-ray images. A total of 1,524 COVID-19 images, 1,527 pneumonia images, and 1,524 normal images were collected for this study. All the data sets used in this study are publicly available, and corresponding websites are given in this paper. Figure 3 shows some of the chest X-ray images with and without COVID-19 from the datastore prepared."}, {"section_title": "Experiment platform and time consumption. :::  ::: EXPERIMENTAL RESULTS AND DISCUSSION", "text": "The hardware and software environments used in this study iares as follows:"}, {"section_title": "Results and discussion. :::  ::: EXPERIMENTAL RESULTS AND DISCUSSION", "text": "Each CNN model is trained separately by splitting the data into training, validation, and testing sets. The training set is used to train the network, and then the testing set is used for testing the model and parameter optimization processes. Training, validation, and testing data sets are randomly separated. A total of 3,048 images, with a training subset of 1,828, validation subset of 610, and testing subset of 610 images (60, 20, and 20%) is used for Task 1; 305 images are randomly excluded from the data set of each class, and they are used for test purposes to prevent a biased data set assignment effect on the CNN and to comprehensively test the CNN model. Figure 4 shows how to feed an image with COVID-19 to a CNN and demonstrates the activations of various layers of the network. After the CNN model is trained, displaying the activations of network layers gives a lot of clues about the features that the deep neural network learns. To discover the features and parameters that the network learns, these activations can be investigated by comparing areas of activation with the original image. CNN uses the first convolutional layer to learn how to detect features like color and edges. More complicated features are detected by deeper convolutional layers, and subsequent convolutional layers of the CNN build up their features by combining features learned by the earlier convolutional layers. For instance, activations of the first convolutional layer in Fig. 4A shows that simple features like color and edges are learned, since this is an earlier layer, whereas channels in the second convolutional layer (Fig. 4B), which is a deeper layer, learns complex features like patchy or ground-glass opacities due to COVID-19. Hence, researchers can find out what the network has learned by identifying features in this way. The proposed CNN architecture for Task 1 can be seen in Fig. 1. This architecture has two convolutional layers that perform convolutions with learnable layers. CNN learns important features, generally with one feature per channel. Every layer of CNN includes many two-dimensional arrays named \u201cchannels.\u201d The first convolutional layer has 96 channels, as shown in Fig. 4A, while the second convolutional layer has 256 channels; 96 of these channels are shown in Fig. 4B.\nEvery single image in the grid of activations (Fig. 4A) corresponds to the output of each channel in the first convolutional layer. White pixels display strong positive activations, while black pixels display strong negative activations. Gray pixels, on the other hand, represent a channel that is not activated as strongly on the input image. The position of a pixel in the activation of a channel corresponds to the same position in the original image. Figure 5 (left) is an image with COVID-19, whereas Fig. 5 (right) is an image with no COVID-19 and is added to compare with the COVID-19 image. Figure 5A (left) shows activation in a specific channel of first convolutional layer for Task 1. White pixels in the channel of Fig. 5B (left) show that this channel is strongly activated at COVID-19. It is seen from the activations that the first convolutional layer is able to activate on COVID-19. Even if the network has never been told to learn about COVID-19, it has learned that COVID-19 has useful features to distinguish between classes of images. Here, a very superior feature of the CNN emerges. In this study, learning to identify COVID-19 helps to distinguish between a COVID-19(+) and a COVID-19(\u2212) image.\nCNN in Task 1 classifies the images into COVID-19(+)and COVID-19(\u2212) images using features that are learned by the network itself during the training process. What the CNN learns during training is sometimes unclear; however, the high-level combinations of the features can be visualized: 96 features learned by CNN in the first convolutional layer are visualized in Fig. 6A, and 256 features learned in the second convolutional layer (Fig. 6AB) are visualized in Fig. 6. CNN architecture for Task 1 has two 2-D convolutional layers. Low-level features are learned in the earlier convolutional layer (Fig. 6A), since they have small receptive field size, whereas deeper layers (Fig. 6B) of the network have larger receptive field size and learn more complicated features. By investigating the channels in Fig. 6A, it can be seen that the filters at this first convolutional layer activate on edges and color, which allows the network to construct more complex features in the second convolutional layer (Fig. 6B).\nCNN architecture for Task 1 has one fully connected layer. The fully connected layers are toward the end of the network and learn high-level combinations of the features learned by the earlier layers. The output image classes are the images generated from the final fully connected layer. Features of fully connected layer for Task 1 and detailed images of fully connected layers that strongly activate the classes for Task 1 are shown in Supplemental Fig. S2 (https://doi.org/10.6084/m9.figshare.12957482.v1).\nAverage accuracy and loss plots for the task of COVID-19(+) image vs COVID-19(\u2212) image (Task 1) are shown in Fig. 7. The proposed CNN model achieves an overall average classification accuracy of 98.92% after 456 iterations for Task 1. This result indicates the ability of the architecture for COVID-19 disease detection. As can clearly be seen from Fig. 7, almost 100% accuracy is obtained after 210 iterations.\nAfter the classification process, the performance of the models should be assessed in various ways. In this study, confusion matrix is used to evaluate the comparison performance. Confusion matrix provides precious information about the predicted and actual classes obtained by the proposed architectures. The performance of the study is assessed from different aspects. Performance of the architecture is evaluated using accuracy, specificity, sensitivity, and precision metrics using Eqs. 2\u20135. Five independent iterations are performed. Classification performance for the task is evaluated for each independent iteration, and the average classification performance of the model is calculated. Performance metrics are calculated using the results from the confusion matrix, and the corresponding results are shown in Table 5. Average accuracy of 98.92% is obtained to classify COVID-19(+) and COVID-19(\u2212) in Task 1. The ROC curve is used as another method to quantify the performance of the architectures. The average value of the AUC of the ROC curve is found to be 0.9957 for Task 1. Confusion matrix results and ROC curves of each independent iteration for Task 1 are shown in Supplemental Fig. S3 (https://doi.org/10.6084/m9.figshare.13100048.v1). It is important to note that the performance measures, such as accuracy, AUC, sensitivity, specificity, and precision, are evaluated on test data sets.\nFour sample validation images with predicted labels and the predicted probabilities of the images having those labels for Task 1 are shown in Supplemental Fig. S4 (https://doi.org/10.6084/m9.figshare.12957485.v1). A total of 4,575 images, with a training subset of 2,745, validation subset of 915, and testing subset of 915 images (60, 20, and 20%, respectively) is used for Task 2; 305 images are randomly excluded from the data set of each class and used for test purposes to prevent a biased data set assignment effect on the CNN and to comprehensively test the CNN model. Five independent iterations are performed. Classification performance for the task is evaluated for each independent iteration, and the average classification performance of the model is calculated. Average accuracy and loss plots for Task 2 are shown in Fig. 8. The proposed CNN model achieves an overall average classification accuracy of 98.27% after 342 iterations for Task 2. This result indicates the ability of the architecture for COVID-19 disease classification. As can clearly be seen from Fig. 8, almost 100% accuracy is obtained after 100 iterations.\nPerformance of the architecture is evaluated using accuracy, specificity, sensitivity, and precision metrics using Eqs. 2\u20135. These metrics are calculated using the results from the confusion matrix and are shown in Table 5. Confusion matrix results and ROC curves of each independent iteration for Task 2 are shown in Supplemental Fig. S5 (https://doi.org/10.6084/m9.figshare.13100084.v1). The average value of the AUC of the ROC curve is found to be 0.9979 for Task 2. It is important to note that the performance measures, such as accuracy, AUC, sensitivity, specificity, and precision, are evaluated on test data sets."}, {"section_title": "Comparison with state-of-the-art methods. :::  ::: EXPERIMENTAL RESULTS AND DISCUSSION", "text": "This section is devoted to the comparison of the proposed method with state-of-the-art methods. Table 6 shows a detailed comparison of the results found using the proposed method with the results of the state-of-the-art methods. The number of COVID-19 disease detection studies using deep learning methods is not high due to the lack of COVID-19 X-ray images in the literature. Togacar et al. (29) used existing deep learning models such as MobileNetV2 and SqueezeNet to detect COVID-19 disease. They created a combined data set comprised of three classes: normal, pneumonia, and COVID-19. They used 295 COVID-19 images, 65 normal X-ray images, and 458 pneumonia images in total to train their deep learning model, and that number of data set is obviously quite small to train a deep learning model successfully. With this data set, they obtained a classification accuracy of 99.27% for Task 2. There was no study for Task 1. Lin et al. (19) proposed a three-dimensional deep learning model for COVID-19 detection. They called their model COVID-19 Detection Model Neural Network (COVNet), which actually consists of ResNet50 as the backbone. They collected 1,296 COVID-19 CT images, 1,325 normal CT images, and 1,735 pneumonia CT images from six different hospitals. They obtained a classification accuracy of 96% for Task 1 and there was no study for Task 2. Ozturk et al. (22) used the DarkCovidnet deep learning model to classify X-ray images as COVID-19 and No Findings (Task 1) and as COVID-19, pneumonia, and normal (Task 2). They obtained an overall accuracy of 98.08% for Task 1 and 87.02% for Task 2. The number of images they used was 127 COVID-19 X-ray images, 500 normal X-ray images, and 500 pneumonia X-ray images. Loey et al. (20) aimed to create the largest possible number of X-ray images for COVID-19 that exists in the literature. They collected 307 images for four different types of classes. The classes are COVID-19, normal, pneumonia bacterial, and pneumonia viral. Loey et al. (20) used pretrained models (Alexnet, Googlenet, and Resnet18) with deep transfer learning to detect COVID-19 disease and to multiclassify between COVID-19, normal, pneumonia bacterial, and pneumonia viral. They obtained a classification accuracy of 85.2% for Task 2 and 99.9% for Task 1. Although the classification rate they obtained for Task 1 seems to be high, the number of images they used is still not enough for successful deep learning training. Apostolopoulos et al. (4) adopted a procedure based on transfer learning for detection COVID-19 detection from X-ray images. They collected 224 COVID-19 X-ray images, 504 normal X-rays, and 714 pneumonia X-rays. They obtained a classification accuracy of 96.78% for Task 2 and there was not a study for Task 1.\nWhen the above-mentioned and existing studies in the literature are carefully examined, the contributions of the study proposed in this paper can be summarized as follows.\nHyperparameters are indispensable for deep learning algorithms and are highly effective on performance. The deep learning model is almost equivalent to choosing the most suitable hyperparameter group. However, pairs of parameters are not always sought for the best performance. In such cases, how to proceed, which hyperparameters will be changed, to what extent, which hyperparameters are in correlation with each other should be investigated, trends should be determined and presented in studies. Recently, hyperparameter groups that have given the best performance are given in studies involving deep learning studies. In some studies, even these parameter pairs are not fully given; the choice of hyperparameters and how they achieve success are not discussed. This weakens the analysis value and importance of the study. In the deep learning studies, we proposed the selection of hyperparameters at certain intervals instead of the intuitive hyperparameter selection method, and detailed analysis of how the model performance and working time are affected by the hyperparameter change in these intervals, and discussion of the hyperparameter groups that are correlated with each other, are analyzed in relation to the hyperparameters. It is imperative that a parameter analysis section be present in all studies. In our opinion, it is essential to establish such a standard in such an area where we can no longer keep up with the pace."}, {"section_title": "CONCLUSIONS", "text": "In this paper, two novel and fully automatic studies using deep convolutional neural networks are presented for COVID-19 detection and virus classification. Two novel, powerful, and robust CNN architectures are designed and proposed for two different classification tasks using publicly available data sets. The hyperparameters of both CNN architectures are automatically determined using the Grid Search Optimizer method. Detection of COVID-19 disease is achieved with high accuracy, such as 98.92%. Moreover, classification of chest X-ray images into normal, pneumonia, and COVID-19 is obtained with satisfying accuracy of 98.27%. Experimental results on large clinical data sets show the effectiveness of the proposed architectures. The results of Task 1 and Task 2 indicate that, to the best of the author\u2019s knowledge, state-of-the-art classification performance is achieved using a large clinical data set without data augmentation. One of the main contributions of this study to the literature is that a wide variety of data sets have been used. It aims to create the largest possible number of X-ray images of COVID-19 that exist in the literature until the writing of this research. A total of 1,524 COVID-19 images, 1,527 pneumonia images, and 1,524 normal images were collected and used for this research. It is believed that, thanks to their simplicity and flexibility, the models proposed in this paper can be readily used in practice to help physicians in diagnosing the COVID-19 disease."}, {"section_title": "DISCLOSURES", "text": "No conflicts of interest, financial or otherwise, are declared by the author."}, {"section_title": "AUTHOR CONTRIBUTIONS", "text": "E.I. conceived and designed research; performed experiments; analyzed data; interpreted results of experiments; prepared figures; drafted manuscript; edited and revised manuscript; approved final version of manuscript."}]