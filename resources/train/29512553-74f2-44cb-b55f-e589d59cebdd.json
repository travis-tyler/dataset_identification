[{"section_title": "Abstract", "text": "This article studies non-parametric panel data models with multidimensional, unobserved individual effects when the number of time periods is fixed. I focus on models where the unobservables have a factor structure and enter an unknown structural function non-additively. The setup allows the individual effects to impact outcomes differently in different time periods and it allows for heterogeneous marginal effects. I provide sufficient conditions for point identification of all parameters of the model. Furthermore, I present a non-parametric sieve maximum likelihood estimator as well as flexible semiparametric and parametric estimators. Monte Carlo experiments demonstrate that the estimators perform well in finite samples. Finally, in an empirical application, I use these estimators to investigate the relationship between teaching practice and student achievement. The results differ considerably from those obtained with commonly used panel data methods."}, {"section_title": "INTRODUCTION", "text": "A standard linear fixed effects panel data model allows for a scalar unobserved individual effect, which may be correlated with explanatory variables. Consequently, by making use of panel data, a researcher may allow for endogeneity without the need for an instrumental variable. However, a scalar unobserved individual effect, which enters additively, imposes two important restrictions. To illustrate these restrictions, suppose that the observed outcome Y it denotes the test score of student i in test t. Here the researcher could either observe the same student taking tests in different time periods or, as in many empirical applications, the researcher could observe several subject specific tests for the same student.\n1 In these applications the individual effect typically represents unobserved ability of student i and the explanatory variables include student and teacher characteristics. Since the individual effect is a scalar and constant across t, the first main restriction is that if one student has a higher individual effect than another student with the same observed characteristics, then the student with the higher individual effect also has a higher expected test outcome in all tests. Hence, it is not possible that student i has abilities such that she is better in mathematics, while student j is better in English. The second main restriction is that the model does not allow for interactions between individual effects and explanatory variables. Therefore, in the previous example, the linear fixed effects model implicitly assumes that the effect of a teacher characteristic on test scores does not depend on students' abilities.\nTo allow for these empirically relevant features, in this article I study panel data models with multidimensional individual effects and marginal effects that may depend on these individual effects. Specifically, I consider models based on Y it = g t X it ,\u03bb i F t +U it , i = 1,...,n, t = 1,...,T ,\nwhere Y it is a scalar outcome variable, g t is an unknown structural function, X it \u2208 R d x is a vector of explanatory variables, \u03bb i \u2208 R R and F t \u2208 R R are unobserved vectors, and U it is an unobserved random variable. The explanatory variables X i = (X i1 ,...,X iT ) may be continuous or discrete and X i may depend on the individual effects \u03bb i . In the previous example, \u03bb i accounts for different dimensions of unobserved abilities of student i and F t is the importance of the abilities for test t. Hence, both the returns to the various abilities and the relative importance of each ability on the outcome can change across tests. Thus, some students may have higher expected outcomes in mathematics, while others may have higher expected outcomes in English, without changes in covariates. Furthermore, since the structural functions are unknown, the model allows for a flexible relationship between Y it and X it , and the effect of X it on Y it may depend on \u03bb i . A semiparametric special case of the model, which is covered by the results in this paper, is \u03b1 t (Y it ) = X it \u03b2 t +\u03bb i F t +U it where \u03b1 t is an unknown strictly increasing transformation of Y it . Such a model is particularly appealing when Y it are test scores, because test scores do not have a natural metric and any increasing transformation of them preserves the same ranking of students (see Cunha and Heckman, 2008) . Thus, next to estimating the slope coefficients, a researcher can allow for an unknown transformation of the test scores. Other special cases of (1) include a linear factor model, where g t is linear, as well as the standard linear fixed effects model with both scalar individual effects and time dummies. Notice that while a linear factor model allows for multiple individual effects, it does not allow for heterogeneous marginal effects. The models studied in this article are appealing in a variety of empirical applications where unobserved heterogeneity is not believed to be one dimensional and time homogeneous, and a researcher wants to allow for a flexible relationship between Y it , X it , and the unobservables. Examples include estimating the returns to education or the effect of union membership on wages (where \u03bb i represents different unobserved abilities and F t their price at time t), estimating production functions (where \u03bb i can capture different unobserved firm specific effects), and cross country regressions (where F t denotes common shocks and \u03bb i the heterogeneous impacts on country i)."}, {"section_title": "2", "text": "This article presents sufficient conditions for point identification of all parameters of models based on outcome Equation (1) when T is fixed and the number of cross-sectional units is large. In the previous example, where T represents the number of tests, I therefore only require a small number of tests for each student. The identified parameters include the structural functions g t , the number of individual effects R, the vectors F t , and the distribution of the individual effects conditional on the covariates.\n3 Identification of these parameters immediately 1826 REVIEW OF ECONOMIC STUDIES implies identification of economically interesting features such as average and quantile structural functions. Although T is fixed, I require that T \u2265 2R+1 so that for a given T only models with at most (T \u22121)/2 factors are point identified, which is also a standard condition in linear factor models. The main result in the article is for continuously distributed outcomes, where my assumptions are natural extensions of those in a linear factor model, but the identification arguments are substantially different. As in the linear model, the assumptions rule out lagged dependent variables as regressors. However, I discuss extensions to allow for lagged dependent variables as regressors, as well as discretely distributed outcomes, in the Supplementary Appendix (see Remark 3). I then show that a non-parametric sieve maximum likelihood estimator estimates all parameters consistently. Since the estimator requires estimating objects which might be high dimensional in applications, such as the density of \u03bb i | X i , this paper also provides a flexible semiparametric estimator, where I reduce the dimensionality of the estimation problem by assuming a location and scale model for the conditional distributions. I provide conditions under which the finite dimensional parameters are \u221a n consistent and asymptotically normally distributed, and I also describe an easy to implement fully parametric estimator.\nIn an empirical application, I study the relationship between teaching practice and student achievement, where Y it are different mathematics and science test scores for each student i. The main regressors are measures of traditional and modern teaching practice for each class a student attends, constructed from a student questionnaire. Traditional and modern teaching practices are associated with lectures/memorizing and group work/explanations, respectively. I estimate marginal effects of teaching practice, on mathematics and science test scores, for different levels of students' abilities and find that the semiparametric two factor model yields substantially different conclusions than a linear fixed effects model.\nMany recent papers in the non-parametric panel data literature are related to the models I consider. First, several papers make use of some form of time homogeneity to achieve identification, do not restrict the dependence of U it over t or the distribution of \u03bb i | X i , and achieve identification of average or quantile effects. Papers in this category include Graham and Powell (2012) , Hoderlein and White (2012) and Chernozhukov et al. (2013) . 4 Chamberlain (1992) analyses common parameters in random coefficient models. Arellano and Bonhomme (2012) extend his analysis and restrict the dependence of U it over t to obtain identification of the variance and the distribution of the random coefficients. While all of these papers allow for multiple individual effects and heterogeneous marginal effects, the time homogeneity assumptions imply that the ranking of individuals based on E[Y it | X i ,\u03bb i ] cannot change over t without a change in X it . Contrarily, compared to those papers, (1) makes stronger assumptions on the dimension of \u03bb i , assumes that \u03bb i affects Y it through an index, and requires independence of U it over t for identification (see Section 2.2 for more details). It therefore rules out random coefficients for example. Thus, (1) is most useful if one believes that \u03bb i has a different effect on Y it for different t and is willing to put some structure on the unobservables. Bester and Hansen (2009) do not impose time homogeneity and instead restrict the distribution of \u03bb i | X i . Altonji and Matzkin (2005) require an external variable, which they construct in panels by restricting the distribution of \u03bb i | X i . Wilhelm (2015) analyses a non-parametric panel data model with measurement error and an additive scalar individual effect. Evdokimov (2010 Evdokimov ( , 2011 assumes that U it is independent over t and he uses identification arguments that are related to those in the measurement error 4. Scalar additive or multiplicative time effects are allowed in some of these papers.\nliterature. He provides identification results in non-separable models with a scalar heterogeneity term as well as a novel conditional deconvolution estimator."}, {"section_title": "5", "text": "I also make use of measurement error type arguments instead of relying on time homogeneity or restricting the distribution of \u03bb i | X i . Specifically, I build on the work of Hu (2008) , Hu and Schennach (2008) and Cunha et al. (2010) . Hu and Schennach (2008) study a nonparametric measurement error model with instruments. The connection to (1) is that \u03bb i can be seen as unobserved regressors, a subset of the outcomes represents observed and mismeasured regressors, and another subset of outcomes serves as instruments. Cunha et al. (2010) apply results in Hu and Schennach (2008) to a measurement model of the general form Y it = g t (\u03bb i ,U it ). Compared to the general model, I use a more restrictive outcome equation to reduce the dimensionality of the estimation problem, which may be appealing in empirical applications. As a consequence, two main identifying assumptions in Cunha et al. (2010) cannot be used in my setting, which changes important arguments in the identification proofs. In particular, one of their main identifying assumption fixes a measure of location of the distribution of a subset of outcomes given \u03bb i . 6 In my model, such an assumption would impose very strong restrictions on g t . Instead, I use the relation between Y it and \u03bb i delivered by (1), combined with arguments from linear factor models and single index models. Moreover, Cunha et al. (2010) impose an assumption on the conditional distribution of the outcomes, which does not hold with my factor structure and T = 2R+1.\n7 I instead show that interchangeability of outcomes can be used to obtain identification with T = 2R+1. These results require stronger independence assumptions compared to Cunha et al. (2010) , but some of these assumptions also serve as sufficient conditions for their completeness assumptions and are used to identify average and quantile structural functions. Finally, I consider extensions to allow for an unknown R and lagged dependent variables as regressors.\nThis article is also related to a vast literature on linear factor models, which are well understood and can deal with multiple unobserved individual effects.\n8 Non-linear models of the form Y it = g(X it )+\u03bb i F t +U it have been studied by Su and Jin (2012) and Huang (2013) when n,T \u2192\u221e. A drawback of additively separable models is that they impose homogeneous marginal effects. The analysis in these papers is tailored to additively separable models. For example, estimation in Bai (2009) is based on the method of principal components.\nThe remainder of the article is organized as follows. Section 2 outlines the identification arguments. Section 3 discusses different ways to estimate the model. Sections 4 and 5 contain the empirical application and Monte Carlo simulation results, respectively. Finally, Section 6 concludes. The proofs of the main results are in the Appendix. Additional material is in a Supplementary Appendix with Section numbers S.1, S.2, etc.. Notation: To simplify the notation, I drop the subscript i from all random variables in the remainder of the article and write the outcome equation as Y t = g t X t ,\u03bb F t +U t . For each t, let 5. Many of these papers also assume some form of strict exogeneity for their main results (Assumption N4). Exceptions are Altonji and Matzkin (2005) , who instead assume an exchangeability condition, and Chernozhukov et al. (2013) .\n6. See their Assumption (v) of Theorem 2. Hu and Schennach (2008) fix a measure of location of the distribution of the measurement error.\n7. See their Assumption (iv) of Theorem 2. The assumption holds with a factor structure when T \u2265 3R and can also hold with T = 2R+1 if the unobservables do not have a factor structure.\n8. The theoretical literature on linear factor models includes Heckman and Scheinkman (1987) , Holtz-Eakin et al. (1988) , Ahn et al. (2001) , Bai and Ng (2002) , Bai (2003) , Andrews (2005) , Pesaran (2006) , Bonhomme and Robin (2008) , Bai (2009) , Ahn et al. (2013) , Bai (2013) , and Moon and Weidner (2015) . Factor models have also been used in applications related to the one in this paper, including Carneiro et al. (2003) , Heckman et al. (2006) , Cunha and Heckman (2008) "}, {"section_title": "REVIEW OF ECONOMIC STUDIES", "text": "X t \u2286 R K and Y t \u2286 R be the supports of X t and Y t , respectively. Let \u2286 R R be the support of \u03bb. Define X = (X 1 ,...,X T ) and define Y and U analogously. Let X and Y be the supports of X and Y , respectively. The conditional pdf of any random variable W | V is denoted by f W |V (w;v) and the marginal pdf by f W (w).\n\nFinally suppose that f X (x) > 0 for all x \u2208 X 1 \u00d7...\u00d7X T . Then the previous arguments imply that g t is identified for all x t \u2208 X t and t < R+2. Next take any x \u2208 X . Since F t is identified and g t is identified for all x t \u2208 X t and t < R+2, the arguments above imply that f Y ,\u03bb|X (y,v;x) is then identified for all y \u2208 Y, v \u2208 by switching the roles of (Y 1 ,...,Y R ) and (Y R+2 ,...,Y 2R+2 ) in the proof. Consequently, g t and the distribution of (U,\u03bb) | X = x are identified for all x \u2208 X ."}, {"section_title": "IDENTIFICATION", "text": "In this section, I assume that R is known. I consider identification of the number of factors in Section S.1.1 of the Supplementary Appendix. Before discussing the general model, I provide intuition for the main result by showing identification of a linear model, where the main arguments go back to Madansky (1964) and are very similar to those of Heckman and Scheinkman (1987) ."}, {"section_title": "Preliminaries: linear factor models", "text": "I consider a linear factor model with T = 5 and R = 2, where X t is a scalar and\nI make the following assumptions.\nAssumption L1. F 4 = 1 0 and F 5 = 0 1 . \nAssumption L1 is a normalization needed because for any R\u00d7R invertible matrix H it holds that \u03bb F t = \u03bb HH \u22121 F t = (H \u03bb) (H \u22121 F t ) =\u03bb F t . Thus, the factors and loadings are only identified up to a rotation and R 2 restrictions are needed to identify a certain rotation. I impose them by assuming that a submatrix of the matrix of factors is the identity matrix, which often gives the individual effects an intuitive interpretation. For example, when the outcomes are test scores, \u03bb 1 and \u03bb 2 can then be interpreted as the abilities, which affect test 4 and 5, respectively. Assumption L2 is a strict exogeneity assumption. Assumption L3 implies that U t and \u03bb are uncorrelated and that U t is uncorrelated across t, conditional on X. Assumptions L4 and L5 ensure that the covariance matrix of any two pairs of outcomes has full rank and imply that each outcome is affected by a different linear combination of \u03bb. Assumption L6 describes the variation in X t over t needed to identify \u03b2 t .\nAssumption L1 implies that\nPlugging these expressions for \u03bb into Equation (2) when t = 3 and rearranging yields To identify the distribution of (U,\u03bb) | X, stronger assumptions are needed. In particular, we could assume that U t is independent over t and independent of \u03bb and then use arguments related to the extension of Kotlarski's Lemma in Evdokimov and White (2012) .\nThe arguments can easily be extended to the case where R > 2 and T > 5. However, the previous arguments highlight that it is necessary to have T \u2265 2R+1. 10 We need R+1 outcomes to difference out \u03bb and then another R outcomes, which can be used as instruments."}, {"section_title": "Assumptions and definitions", "text": "I now return to the general model. One assumption I impose is that the structural functions g t are strictly increasing in the second argument, which is common in non-additive models (see for example Matzkin (2003) or Evdokimov (2010) ). In the application \u03bb F t +U t could be interpreted as the skills needed for test t and the assumption then says that more skills increase the test scores."}, {"section_title": "Define the inverse function", "text": "Although T \u2265 2R+1 is needed, to simplify the notation I assume that T = 2R+1. The extension to a larger T is straightforward as discussed below. Moreover, this section focuses on the continuous case. Therefore, I make the following two assumptions. Assumption N1. R is known and T = 2R+1.\nAll marginal and conditional densities are bounded.\nLet h t (y t ,x t ) denote the derivative of h t with respect to y t . The next assumption imposes monotonicity and a normalization on h t .\n9. These arguments differ from Ahn et al. (2013) , who study a linear factor model for fixed T , because I allow \u03b2 t to be time varying and I use outcomes as instruments once the individual effects are differences out.\n10. It can be shown that without additional assumptions to the ones presented here, the slope coefficients \u03b2 t are not point identified if T < 2R+1. To better understand the normalizations, notice that a special case without covariates is \u03b1 t + \u03b2 t Y t = \u03bb F t +U t . Since the right-hand side is not observed, one can divide both sides by a constant for each t and still satisfy all assumptions. Thus, \u03b2 t is not identified for any t and N3(ii) normalizes them to 1. Similarly, \u03b1 t is not identified for R periods, because the mean of \u03bb is unknown, and N3(ii) normalizes them to \u2212\u0233 t for t = R+2,...,2R+1. As stated in Theorem 2, economically interesting quantities, such as average and quantile structural functions, are invariant to these normalizations (as well the ones in N4 and N6).\nAssumptions N4-N7 can be seen as the non-parametric analogs of L2-L5. Assumption N4 implies that the regressors are strictly exogenous with respect to U t , which rules out for example that X t contains lagged dependent variables. A median normalization is more convenient in non-linear models than the zero mean assumption used in the linear model. Assumption N5 strengthens L3. Although the unobservables \u03bb F t +U t are correlated over t, any dependence is due to \u03bb. Autoregressive U t are thus ruled out. A similar assumption is needed in the linear model to identify the distribution of (U,\u03bb) | X. Note that the assumptions do not require that U t and X t are independent and permit heteroskedasticity. Independence can be relaxed if T > 2R+1 because the proof only requires that 2R+1 outcomes are independent conditional on (X,\u03bb). Hence, one could allow for MA(1) disturbances if T \u2265 4R+1 and similarly for a more complicated dependence structure for larger T . Assumption N6 generalizes L1 and L4. Assumption N7 is just as L5 and rules out that some element of \u03bb is a linear combination of the other elements. Furthermore, all constant elements of \u03bb, and thus time trends, are absorbed by the function h t .\nAssumption N8 is an additional assumption needed due to the non-parametric nature of the model. A non-vanishing characteristic function holds for many standard distributions such as the normal family, the t-distribution, or the gamma distribution, but not for all distributions, for instance the uniform distribution. The purpose of the assumption is to guarantee that a nonparametric analog of the rank condition holds, known as completeness, which implies a strong dependence between two vectors of outcomes, similar as in the linear model (see Lemma 1 in the Appendix)."}, {"section_title": "Identification outline and main results", "text": "I now outline the main identification arguments and state and discuss the formal results. The first step is to notice that independence of\nThe expression for f Y |X (y;x) has a similar structure as in the measurement error model of Hu and Schennach (2008) . Here we can interpret \u03bb as unobserved regressors. By Assumption N6, we can solve for \u03bb in terms of any R outcomes, the corresponding X t , and U t . Thus, a set of R outcomes, here Z 3 , can be interpreted as observed, but mismeasured regressors. The instruments needed for identification are then another set of R outcomes, Z 1 , as before.\nThe results of Hu and Schennach (2008) do not immediately apply to (4) for two main reasons. First, since Z 2 is of lower dimension than \u03bb and since I assume a factor structure for the unobservables, one of their identification conditions is violated.\n11 I solve this problem by rotating the outcomes contained in Z 1 and Z 2 , which is analogous to rotating the outcomes that serve as instruments in the linear model. 12 This additional step and arguments as in Hu and Schennach (2008) then imply identification of f Y ,\u03bb|X up to a one-to-one transformation of \u03bb. Second, to pin down this transformation, Hu and Schennach (2008) and Cunha et al. (2010) impose a normalization of the form (f Z 3 |\u03bb (\u00b7|\u03bb)) = \u03bb, where is a known functional, such as E(Z 3 | \u03bb) = \u03bb in a classical measurement error model. However, in the factor model discussed here, I show that such a normalization imposes very strong restrictions on the structural functions and that all parameters are identified without an additional normalization of \u03bb. 13 To do so, I use arguments from linear factor models and single index models to point identify all parameters of the model. Important assumptions used in this step are the factor structure, independence, monotonicity, the normalizations of g t , and the moments conditions. These arguments then not only uniquely determine f Y ,\u03bb|X , but also g t and F t . To obtain these results I require stronger independence assumptions compared to Cunha et al. (2010) , but some of these assumptions also serve as sufficient conditions for their completeness assumptions and are used to identify average and quantile structural functions. These arguments lead to the following theorem. The proof is in the appendix. Theorem 1. Suppose Assumptions N1 -N8 hold. Then F t , the functions g t , and the distribution of (U,\u03bb) | X = x are identified for all x \u2208X . If in addition f X (x) > 0 for all x \u2208 X 1 \u00d7...\u00d7X T , then g t and the distribution of (U,\u03bb) | X = x are identified for all x \u2208 X . 11. Specifically, Assumption 4 in Hu and Schennach (2008) or, translated to the panel setting, Assumption (iv) or Theorem 2 in Cunha et al. (2010) .\n12. For this particular step, I require Hu and Schennach (2008) .\n13. Only an unknown transformation of \u03bb is pinned down by the eigenfunctions. For example, Assumptions N3(i), N4, and\nIn the completely non-parametric setting of Hu and Schennach (2008) and Cunha et al. (2010) , this assumption is much less restrictive and is truly a normalization if a monotonicity condition holds. Shiu and Hu (2013) . Lagged dependent variables have the advantage of being modeled in the system."}, {"section_title": "which might suggest that identification could be based on moment conditions. While such an approach might lead to identification of h t under similar assumptions, my approach also yields identification of the distribution of (\u03bb,U) | X and thus, average and quantile structural functions, which require knowledge of the distribution of the unobservables and are invariant to the normalizing assumptions (see Section 2.4).", "text": ""}, {"section_title": "Remark 3. The Supplementary Appendix contains extensions of the identification results to identification of the number of factors (Section S.1.1 in Supplementary Appendix), lagged dependent variables as regressors (Section S.1.4 in Supplementary Appendix), and discrete outcomes (Section 1.1.5 in Supplementary Appendix). Incorporating predetermined regressors other than lagged dependent variables requires modeling their dependence, similar as in", "text": ""}, {"section_title": "Objects invariant to normalizations", "text": "This section describes economically interesting objects, namely average and quantile structural functions, which are invariant to the normalization assumptions N3(ii), N4, and N6. Define C t \u2261 \u03bb F t and let Q \u03b1 [C t ] and Q \u03b1 [U t ] be the \u03b1-quantile of C t and U t , respectively. Letx t \u2208 X t and define the quantile structural functions\nas well as the average structural functions t (x t ) = g t (x t ,e)dF C t +U t (e). The functions s t,\u03b1 (x t ) ands t (x t ) are analogous to the average and quantile structural functions in Blundell and Powell (2003) and Imbens and Newey (2009) . Here the unobservables consist of two parts, C t and U t , and C t often has a specific interpretation in applications, such as the abilities needed for a certain test. The function s t,\u03b1 1 ,\u03b1 2 (x t ) allows the two unobservables to be evaluated at different quantiles. Therefore, one could set U t to its median value of 0 and investigate how the outcomes vary with C t . Moreover, let x \u2208 X and define the conditional versions of these functions as\nAverage and quantile structural functions can be used to answer important policy questions. For example suppose X t is class size and the outcomes are test scores. Thens t (25)-s t (20) is the expected effect of a change in class size from 20 to 25 on the test score for a randomly selected student. The conditional versions t (25,x)-s t (20,x) is the expected effect for a randomly selected student from a class of size x. The quantile effects have similar interpretations, but are evaluated at quantiles of unobservables, rather than averaging over them. The following result shows identification of these functions without the normalizations. "}, {"section_title": "ESTIMATION", "text": "This section discusses estimation when R is known. Section S.2.3 in the Supplementary Appendix shows how to test the null hypothesis that the model has R factors against the alternative that it has more than R factors, and how to consistently estimate the number of factors.\nFirst notice that, by Assumptions N3 and N5, the density of Y | X can be written as\nI use this expression to suggest estimation based on the maximum likelihood method. Although I show that a completely non-parametric estimator is consistent, such an estimator might not be attractive in applications due to the potentially high dimensionality of the estimation problem. For example, the function f \u03bb|X (v;x) has R+Td x arguments, which implies a slow rate of convergence, and consequently imprecise estimators in finite samples. 14 Hence, I also suggest a more practical semiparametric estimator, where I reduce the dimensionality by assuming a location and scale model for the conditional distributions."}, {"section_title": "Fully non-parametric estimator", "text": "I follow well known results, such as Chen (2007), and prove consistency of a nonparametric maximum likelihood estimator. I briefly outline the main assumptions below and provide the details in the Supplementary Appendix. Next to the identification conditions, the main assumptions for estimation include smoothness restrictions on the unknown functions. Specifically, I assume that the unknown functions lie in a weighted H\u00f6lder space, which allows the functions to be unbounded and have unbounded derivatives. I denote the parameter space by and the consistency norm by \u00b7 s , which is a weighted sup norm.\n15\n14. In addition, the model nests deconvolution problems which can have a logarithmic rate of convergence. For related setups see Fan (1991) , Delaigle et al. (2008), and Evdokimov (2010) .\n15. This combination of the consistency norm and the parameter space ensures that is compact under \u00b7 s . As discussed in Section S.2.1 in Supplementary Appendix, a weighted sup norm implies consistency in the regular unweighted sup norm over any compact subset of the support."}, {"section_title": "REVIEW OF ECONOMIC STUDIES denote the true value of the parameters by \u03b8", "text": "Then the log-likelihood evaluated at \u03b8 0 and the ith observation is\nNow let n be a finite dimensional sieve space of , which depends on the sample size n and has the property that \u03b8 0 can be approximated arbitrary well by some element in n when n is large enough (see Assumption E4 in the Supplementary Appendix for the formal statement). For example, h t could be approximated by a polynomial function, where the order of the polynomial grows with the sample size. The estimator of \u03b8 0 is\u03b8 \u2208 n which satisfies\nOnce the sieve space is specified, estimation is equivalent to a parametric maximum likelihood estimator. 16 For the estimator to be consistent it is crucial that the parameter space reflects all identification assumptions to ensure that \u03b8 0 is the unique maximizer of\n. Notice that the likelihood already incorporates independence of U 1 ,...,U T ,\u03bb. Moreover, the normalizations in Assumptions N3(ii), N4, and N6 as well as monotonicity of h t are straightforward to impose (see Section 5 for details). The remaining two assumptions, N7 and N8, do not have to be imposed in the optimization problem. The reason is that even without imposing the assumptions, a maximizer of E [l(\u03b8,W i )] corresponds to the true density of Y | X. By Lemma 1 this density implies certain completeness conditions, which can only hold if the covariance matrix of \u03bb | X has full rank. Moreover, given Assumption N1-N7, completeness is sufficient for identification and therefore \u03b8 0 is the unique maximizer of E [l(\u03b8,W i )]. Other implementation issues, including specific sieve spaces, are discussed in Sections 4 and 5 (the application and Monte Carlo simulations, respectively) in more detail.\nThe following result is shown in the appendix which, given the assumptions, follows from Theorem 3.1 in combination with Condition 3.5M in Chen (2007) ."}, {"section_title": "Theorem 3. Let Assumptions N1-N8 and Assumptions E7-E9 in the Supplementary Appendix hold. Let Assumption N9 in the Supplementary Appendix hold for all x", "text": "\u2208 X . Then \u03b8 \u2212\u03b8 0 s p \u2192 0."}, {"section_title": "Remark 5. It is well known that if the individual fixed effects are estimated as parameters, then the maximum likelihood estimator is generally not consistent in non-linear panel data models when T is fixed (i.e. the incidental parameters problem). I circumvents this problem by not treating the fixed effects as parameters, but instead estimating the distribution of \u03bb. The assumptions then imply that the number of parameters grows slowly with the sample size, as opposed to being of the same order as the sample size. However, I assume that \u03bb has a smooth density, which is not required when the fixed effects are treated as parameters (but in this case the estimator would not be consistent). I therefore rule out for example that \u03bb is discretely distributed, but I neither impose parametric assumptions on its distribution, nor on the dependence between \u03bb and X.", "text": "16. The definition ensures that the estimator is always well defined. If the solution to the sample optimization problem is unique, then one can simply use\u03b8 "}, {"section_title": "Semiparametric estimator", "text": "I now outline a semiparametric estimator, which I use in the application. First, I reduce the dimensionality of the estimation problem by making additional assumptions on the conditional distribution of \u03bb | X. In particular, I assume that \u03bb = \u03bc(X,\u03b2 1 )+ (X,\u03b2 2 )\u03b5, where \u03b5 is independent of X. The main advantage of this approach is that the likelihood now depends on the density of \u03b5 as well as \u03b2 1 and \u03b2 2 instead of the high dimensional function f \u03bb|X . Furthermore, I assume that U t is independent of X, but the density f U t is unknown. Alternatively, one could model the dependence between U t and X to allow for heteroskedasticity. The structural functions can be parametric, semiparametric, or non-parametric depending on the application. To accommodate all cases, I assume that h t (Y t ,X t ) = m(Y t ,X t ,\u03b1 t ,\u03b2 3t ), where \u03b2 3t is a finite dimensional parameter, \u03b1 t is an unknown function, and m is a known function. As an example, in Sections 4 and 5,\nDefine the finite dimensional parameter vector\n..,f U T ) denote all unknown functions, and define \u03b8 0 \u2261 (\u03b1 0 ,\u03b2 0 ). Now in addition to the various finite dimensional parameters, several low dimensional functions, namely T one-dimensional densities, one R-dimensional density, and the functions \u03b1 t have to be estimated. The estimator\u03b8 = (\u03b1,\u03b2) is again computed using sieves and maximizing the log-likelihood function. This is computationally almost identical to the estimator described in the previous section, except that now there are less sieve terms and more finite dimensional parameters to maximize over. Next to improved rates of convergence due to the reduced dimensionality, another major advantage of the semiparametric estimator is that \u03b2 0 can be estimated at the \u221a n rate and the estimator is asymptotically normally distributed. Thus, one can easily conduct inference. These results are shown in the following theorem."}, {"section_title": "Theorem 4. Let Assumptions E2 and E8-E18 in the Supplementary Appendix hold. Then", "text": "The proof is very similar to the ones in Ai and Chen (2003) and Carroll et al. (2010) among others. Ackerberg et al. (2012) provide a consistent estimator of the covariance matrix and discuss its implementation in a more general setting."}, {"section_title": "Parametric estimator", "text": "Finally, given the previous results, it is straightforward to estimate the model completely parametrically. In this case the densities f U t and f \u03bb|X and the functions h t are assumed to be known up to finite dimensional parameters. For example, one could assume that \u03bb and U t are normally distributed, where the mean and the covariance of \u03bb is a parametric function of X and the variance of U t is a constant. Consistency and asymptotic normality then follows from standard arguments, such as those in Newey and McFadden (1994) ."}, {"section_title": "APPLICATION", "text": "This section investigates the relationship between teaching practice and student achievement using test scores from the Trends in International Mathematics and Science Study (TIMSS)."}, {"section_title": "Data and background", "text": "The TIMSS is an international assessment of mathematics and science knowledge of fourth and eighth-grade students. I make use of the 2007 sample of eighth-grade students in the U.S. This sample consists of 7,377 students. Each student attends a math and an integrated science class with different teachers in each class for most students. I exclude students which cannot be linked to their teachers, students in classes with less than five students, and observations with missing values in covariates (defined below).\nThe TIMSS contains test scores for different cognitive domains of the tests, which are mathematics applying, knowing, and reasoning, as well as science applying, knowing, and reasoning.\n17 I use these six test scores as the dependent variables Y it , where i denotes a student and t denotes a test. Hence, T = 6 which allows me to estimate a factor model with two factors. The main regressors are measures of modern and traditional teaching practice. Intuitively, modern teaching practice is associated with group work and reasoning, while traditional teaching practice is based on lectures and memorizing. To construct these, I follow Bietenbeck (2014) and use students' answers about frequencies of certain class activities. I number the response as 0 for never, 0.25 for some lessons, 0.5 to about half of the lessons, and 1 for every or almost every lesson, so that the numbers correspond approximately to the fraction of time the activities are performed in class. The teaching measures of student i are the class means of these responses, excluding the student's own response."}, {"section_title": "18", "text": "Various educational organizations have generally advocated for a greater use of modern teaching practices and a shift away from traditional teaching methods (see Zemelman et al. (2012) for a \"consensus on best practice\" and a list of sources, including among many others, the National Research Council and the National Board of Professional Teaching Standards). However, despite these policy recommendations, the empirical evidence on the relationship between teaching practice and test scores is not conclusive and varies depending on the data set, test scores, and methods used. For example, Schwerdt and Wuppermann (2011) make use of the 2003 TIMSS data and find positive effects of traditional teaching practice. Bietenbeck (2014) documents a positive effect of traditional and modern teaching practice on applying/knowing and reasoning test scores, respectively. Using Spanish data, Hidalgo-Cabrillana and Lopez-Mayany (2015) find a positive effect of modern teaching practice on math and reading test scores and, with teaching measures constructed from students' responses, a negative effect of traditional teaching practice. Lavy (2016) finds evidence of positive effects of both modern and traditional teaching practices on test scores using data from Israel. All of these studies at most allow for an additive student individual effect. Since math includes sections on number, geometry, algebra, data, and chance and science includes biology, chemistry, earth science, and physics, it is not clear a priori that the two subjects require the same skills.\n19 I show below that the conclusions in the models I estimate change considerably once more general heterogeneity is allowed for. Moreover, while 17. \"Knowing\" measures knowledge of facts, concepts, and procedures. \"Applying\" focuses on the ability of students to solve routine problems. \"Reasoning\" covers unfamiliar situations, complex contexts, and multi-step problems.\n18. The questions used to construct the teaching practice measures are listed in Table S .2 in the Supplementary Appendix. Bietenbeck (2014) contains much more details on their construction and the background literature.\n19. For example, a physics \"knowing\" question asks what happens to an iron nail with an insulated wire coiled around it, which is connected to a battery, when current flows through the wire (answer: the nail will become a magnet). An algebra \"knowing\" question asks what et al. (2012) generally advocate for modern teaching practices in all subjects, best teaching practices vary across subjects. For instance, they write that \"we now know that problem solving can be a means to build mathematical knowledge\" (p. 170). It is thus not obvious that the same teaching practice dominates in both subjects and I therefore also allow for different effects of teaching practices across test scores."}, {"section_title": "20", "text": "The outcome equation of the general model is Y t = g t (X t ,\u03bb F t +U t ) and thus, Y t is an unknown function of X t . Hence, if X t is discrete, a completely non-parametric estimator allows for a different function for each point of support of the covariates, and a researcher can study the differences of the estimated functions for different values of X t . A major downside of this generality is that there might be very few observations once all discrete covariates are controlled for. To keep the non-parametric idea of the estimator, in this application I restrict myself to students between the age of 13.5 and 15.5 and English as their first language, which leaves 1,739 male and 1,787 female students in 169 schools with 235 math and 265 science teachers. 21 I then estimate the model separately for male and female students to illustrate how discrete covariates can be incorporated non-parametrically, and how gender heterogeneity can be studied with the non-parametric estimator. Similarly, the general model allows for a completely non-parametric function of all additional covariates, including teaching practices, but estimating functions of many dimensions implies a slow rate of convergence and poor finite sample properties. I therefore estimate a flexible semiparametric model, similar to the one in the Monte Carlo simulations, which allows among others for an unknown transformation of the test scores."}, {"section_title": "Model and implementation", "text": "The results reported in this article are based on the outcome equation\nwhere t = 1,2,3 are the math scores (applying, knowing, reasoning) and t = 4,5,6 are the science scores (applying, knowing, reasoning). The scalars X mod t and X trad t are the modern and traditional teaching practice measures. The vector Z t includes the other covariates, namely the class size, hours spent in class, teacher experience, whether a teacher is certified in the field, and the gender of the teacher. I set \u03bb = \u03bc(X trad ,X mod ,\u03b8)+\u03b5, where \u03b5 \u22a5 \u22a5 X trad ,X mod ,Z and \u03bc is a linear function of X mod and X trad , and U \u22a5 \u22a5 (\u03bb,X trad ,X mod ,Z)."}, {"section_title": "22", "text": "I estimate marginal effects, evaluated at the median value of the observables and different quantiles of \u03bb F t . 23 There are twelve marginal effects I consider, namely the effect of traditional teaching on Y t and the effect of modern teaching on Y t for t = 1,...,6, which correspond to the derivative of the quantile structural function, s t,q, 1 2 (x t ), discussed in Section 2.4. With the 20. Other settings where estimated effects differ considerably between math and science include the effects of degrees/coursework and the gender of the teacher on student achievement, respectively (see Wayne and Youngs (2003) and Dee (2007) ).\n21. I obtain qualitatively similar results for a smaller sample, with 897 male and 973 female students, which is restricted to schools with an enrollment between 100 and 600 students, where parents' involvement is not reported to be very low, and where less than 75% of the students receive free lunch.\n22. With this assumption, \u03bb become correlated random effects instead of fixed effects. The results with a quadratic \u03bc are almost identical.\n23. Estimation results based on the average structural functions,s t (x t ), and averaged over the covariates, are very similar. \n. In a linear model these marginal effect are simply the slope coefficients \u03b2 trad t and \u03b2 mod t , and therefore do not depend on the skill level. I show results for the linear fixed effects estimator (FE), three parametric models, and a semiparametric estimator. All parametric models assume that a t (\u00b7) is linear and that \u03b5 and U t are normally distributed. I consider a one factor model where F t = 1 for all t, a one factor model with time varying factors, and a two factor model to illustrate what is driving the differences between the fixed effects estimates and the semiparametric estimates. In addition, I present results for a linear fixed effects model, where the slope coefficients are identical across subjects, which is the specification of Bietenbeck (2014) .\nFor the semiparametric estimator I estimate among others six one-dimensional functions \u03b1 t , six one-dimensional functions f U t , the two-dimensional pdf of \u03b5, and twelve slope coefficients for teaching practices. The outcome equation is only non-parametric in Y t because a more flexible specification with higher dimensional functions would be very imprecise with the limited sample size. While this specification is relatively simple, it keeps all important features of the model, namely the two factors and heterogeneous marginal effects, and that the results do not depend on the particular metric of the test scores. The linearity in X trad t and X mod t also has the advantage that marginal effects are non-zero if and only if the slope coefficients are nonzero. Since the estimated slope coefficients are asymptotically normally distributed, we can find significance of estimated marginal effects by testing H 0 : \u03b2 trad t = 0, even in the semiparametric model, which would not be possible with a completely non-parametric function. Finally, although the model is semiparametric, the structural functions are non-parametrically identified under Assumptions N1-N8 and weak support conditions on the teaching practice measures, as discussed in Section S.1.3 in Supplementary Appendix. To calculate the standard errors for the parametric and semiparametric likelihood based estimators I use the estimated outer product form of the covariance matrix as suggested by Ackerberg et al. (2012) . For the linear fixed effects model I use standard GMM-type standard errors. I defer specific implementation issues, such as the choices of basis functions and how the constraints are imposed, to Section 5 as well as Section S.3 in the Supplementary Appendix. Table 1 shows the estimated marginal effects for the sample of 1,739 boys. 24 The results from the linear fixed effects models suggest a positive relationship between X trad t and knowing and applying test scores as well as a positive relationship between X mod t and reasoning scores. In the unrestricted model, the slope coefficients are similar for math and science and thus, restricting the slope coefficients to be the same across subjects yields similar results. I standardized Y t and the teaching practice measures to have a standard deviation of 1. Hence, a one standard deviation increase of X trad 2 is associated with a 0.078 standard deviation increase of Y 2 in the unrestricted fixed effects model. The marginal effects for a parametric one factor model with F t = 1, where \u03b1 t is linear and all unobservables are normally distributed, are very similar to the fixed effects model, 24 . For each student and test, the TIMSS contains five imputed values because students generally did not answer the same set of questions. My results are based on the first imputed values for each student and test, but the results with the others are similar. which is not surprising because they are based on the same outcome equation. However, in the fixed effects model, U t is not assumed to be independent over t and the relation between \u03bb and X is not modeled. Independence might be hard to justify here because all three math (and similarly science) test scores are obtained from the same overall test. Nonetheless, the two models yield very similar conclusions. Allowing F t to vary produces different marginal effects, which now suggest that traditional teaching practices are associated with better test scores in both subjects. The math subjects have more weight on the first skill, while science subjects have more weight on the second skill. Two numbers are exactly 0 and two are exactly 1, which corresponds to a particular normalization. That is, \u03bb 1 can be interpreted as the skills needed for math applying and \u03bb 2 are the skills for science knowing. Hence, the skills needed in other subjects are linear combinations of these two skills. The estimated correlation is around 68%. Notice that identification would fail if two factors, next to F 12 and F 51 , were zero. Using the results in Chen et al. (2011) , I can test whether any combination of two factors are 0 and I reject each such null at least at the 10% level. I also reject the one factor model in favour of the two factor model at 1840 REVIEW OF ECONOMIC STUDIES and for different quantiles of \u03bb F 1 ). 25 The results suggest that marginal effects are larger for small values of teaching practices and larger for students with low abilities, because the smaller q, the larger the function values. Hence, changes in teaching practices seem to have a larger impact on low ability students. These conclusions generally also hold for the other ten marginal effects as shown in Table 2 . This table displays derivatives of the quantile structural functions for different quantiles of \u03bb F t (high skills is the 95% quantile, medium the 50% quantile, and low skills the 5% quantile) and evaluated at the median values of the covariates. Similar as in Figure 1 , the marginal effects are usually largest in absolute value for students with low abilities."}, {"section_title": "Results", "text": "25. Using quantiles of \u03bb F t +U t yields similar results and even more heterogeneity due to the presence of the additional random variable U t . To better understand the differences between the fixed effects and the two factor model, suppose \u03b1 t is linear and suppress Z t . Then differencing two outcomes for t \u2208{1,2,3} and s \u2208 {4,5,6} yields\ndifferencing might not eliminate the bias, and the direction of the bias depends on the correlation between \u03bb and the regressors. The signs of the marginal effect changes in two cases, namely the effect of X mod t on math and X trad s on science, respectively. In the two factor model, X mod t is positively correlated with the first skill (representing applying-math) and negatively correlated with the second skill (representing knowing-science). Hence, the fixed effects model leads to a positive bias of the effect of X mod t on math, which explains the first sign change. Similarly, X trad s is negatively correlated with the first skill and positively correlated with the second skill, leading to a positive bias of the effect of X trad s on science. These correlations could either be due to teachers adapting their teaching style to the skills of the students or due to students selecting certain teachers based on their skills. Therefore, a linear fixed effects model can lead to very different conclusions compared to a model that allows for richer heterogeneity."}, {"section_title": "MONTE CARLO SIMULATIONS", "text": "In this section, I investigate the finite sample properties of the estimators in a setting that is calibrated to mimic the data in the empirical application. Again I let I assume that U t \u223c N 0,\u03c3 2 t , where \u03c3 = (0.16 0.22 0.53 0.21 0.21 0.31) are again the point estimates in the application. Finally, I choose \u03b1 t (Y t ) = (Y t +c t ) a t /s t , where a t , c t , and s t are chosen to mimic the non-parametrically estimated transformations in the application and to ensure that \u03b1 t (Y t ) satisfies the normalization \u03b1 t (0) = 1. Here a t > 1 for all t, which implies that \u03b1 t (Y t ) is convex, just as the estimated functions in the empirical application.\nI use five different estimators, which I also used in the empirical application, namely a linear fixed effects estimator (FE), three parametric estimators, and a semiparametric estimator. Again, all parametric estimators assume that a t (\u00b7) is linear and that \u03b5 and U t are normally distributed. The parametric estimators include a one factor model where F t = 1 for all t, a one factor model with time varying factors, and a two factor model. For the semiparametric estimator I nonparametrically estimate \u03b1 t , f U t , and the two-dimensional pdf of \u03b5 next to the finite dimensional parameters. To implement the semiparametric estimator, I approximate f U t (u) by a Hermite polynomial of degree 4, which implies that\nwhere \u03c6(u) denotes the standard normal pdf. While the theoretical arguments would allow setting \u03c3 t = 1 for all t, choosing \u03c3 t to be an estimated standard deviation of U t improves the finite sample properties (see Gallant and Nychka (1987) and Newey and Powell (2003) for related arguments). I set \u03c3 t to the estimated standard deviation obtained from a parametric model. Notice that the estimated density is positive by construction. Moreover, since\nboth the constraint that the density integrates to 1 (with z =\u221e) and the median 0 restriction (with z = 0) are quadratic constraints in d jt . Similarly, I write \u03bb = \u03bc(X trad ,X mod ,\u03b8)+ 1/2\u03b5 , I set to the estimated covariance matrix from a parametric model, and I approximate the density of\u03b5 by The sum includes all basis functions of the form e j\u22121\n2 \u03c6(e 1 )\u03c6(e 2 ) with j +k \u2264 4 and j,k \u2265 1."}, {"section_title": "27", "text": "Notice that without the scale and location model, the density of \u03bb | X trad ,X mod would be a sixdimensional function, which would lead to imprecise estimates with a sample size of 1739. I approximate \u03b1 t (Y t ) with polynomials of order 4, that is\nThe coefficient in front of Y t is 1 to impose the scale normalization \u03b1 t (0) = 1 and to ensure that the semiparametric model nests the linear model. The location normalizations are easy to impose by setting \u03b3 t = 0 for two periods, or by imposing M[\u03bb j ]=0 for j = 1,2. I use the latter restriction to facilitate comparison with a parametric model, where \u03bb is normally distributed and M[\u03bb j ]=0. I approximate the integral in the likelihood using Gauss-Hermite quadrature. With these choices, estimating the parameters amounts to maximizing a non-linear function subject to quadratic constraints. In Section S.3 of the Supplementary Appendix, I provide details on the convergence behavior in the simulations and the application.\nI investigate finite sample properties of estimated marginal effects, evaluated at the median value of the observables and unobservables, as well as coverage rates of confidence intervals for the slope coefficients. 28 The marginal effects are analogous to those in Table 1 are described in Equation (6). The results are based on 1,000 Monte Carlo simulations. Table 3 shows the true 27. For a given number of parameters, this specification typically leads to a better approximation of the function than a tensor product (Judd, 1998) .\n28. While the marginal effects are invariant to the normalizations, the slope coefficients depend on the scale normalizations. Hence, imposing the true normalizations is crucial for obtaining correct coverage. In the application, I marginal effects as well as the median of the estimated marginal effects and the median squared error (MSE) in parenthesis. 29 The fixed effects estimator and the one factor model with F t = 1 perform very similar and have large biases and MSEs. Time varying F t only help reducing the biases for t = 1,2,3. Both the parametric and the semiparametric two factor models perform very well and very similar, both in terms of the median estimated marginal effect and the MSE. The parametric model is misspecified because it assumes a linear transformation, but this seems to be a good approximation for marginal effects at the median. However, at different quantiles, the model predicts the same marginal effects, which will lead to a bias. Table 4 shows coverage rates of confidence intervals for the estimated slope coefficients. As expected, all one factor models have poor coverage rates. Contrarily, both two factor models have coverage rates close to 95% for all slope coefficients."}, {"section_title": "CONCLUSION", "text": "This article studies a class of non-parametric panel data models with multidimensional, unobserved individual effects, which can impact outcomes Y t differently for different t. These models are appealing in a variety of empirical applications where unobserved heterogeneity is not believed to be one dimensional and time homogeneous, and a researcher wants to allow for a flexible relationship between Y t , X t , and the unobservables. In microeconomic applications, researchers routinely use panel data to control for \"abilities\" using a fixed effects approach. The methods presented here allow researchers to specify much more general and realistic unobserved heterogeneity by exploiting rich enough data sets. For example, in an empirical application, I investigate the relationship between teaching practice and math and science test scores. As opposed to a standard linear fixed effects model, I allow students to have two unobserved individual effects, which can have different impacts on different tests. Hence, some students can have abilities such that they are better in math, while others can be better in science. The am interested in testing H 0 : \u03b2 trad t = 0, which is invariant to the normalizations and thus, coverage rates of confidence intervals for the (possibly scaled) slope coefficients are of interest.\n29. I use the median and the median squared error to make the results less dependent on outliers.\nresults from this model differ considerably from the ones obtained with a linear fixed effects model, which has also been used in related contexts, such as studying the relationship between student achievement and the gender of the teacher, teacher credentials, or teaching practice, respectively. Since one-dimensional heterogeneity appears to be very restrictive in this context and the conclusions from the two factor model are substantially different, specifying the most realistic model is crucial and might warrant a more in depth analysis, possibly with an even richer data set. Moreover, the models allow for heterogeneous marginal effects and thus, the effects of teaching practices on test scores can depend on students' abilities. I find that the marginal effects of a change in teaching practice on test scores are larger for students with low abilities. Next to microeconomic applications and the examples mentioned in the introduction, the models can for example also be useful in empirical asset pricing, where the return of firm i in time t, denoted by Y it , can then depend on characteristics X it and a small number of factors. The non-parametric approach reduces concerns about functional form misspecification (Fama and French, 2008) . I present non-parametric point identification conditions for all parameters of the models, which include the structural functions, the number of factors, the factors themselves, and the distributions of the unobservables, \u03bb and U t , conditional on the regressors. I also provide a nonparametric maximum likelihood estimator, which allows estimating the parameters consistently, as well as flexible semiparametric and parametric estimators.\nOne restriction of the models is that, other than lagged dependent variables studied in Section S.1.4 in Supplementary Appendix, the regressors are strictly exogenous. It would therefore be useful to incorporate predetermined regressors, which might require modeling their dependence. Furthermore, while Section S.2.3 in the Supplementary Appendix suggests an approach to estimate the number of factors consistently, providing an estimator with desirable finite sample properties, similar to the ones proposed by Bai and Ng (2002) in linear factor models, is another open problem. Finally, it would be interesting to extend the analysis to a large n and large T framework, where so far the existing models do not allow for interactions between covariates and unobservables. Proof. Condition on X \u2208 X and suppress X. Since Z 3 and Z K 1 are independent conditional on \u03bb,\nIt follows that for any bounded function m such that\nConditional on X = x we can write Z 3 = g(x,\u03bb+V ), where V = (U R+2 ,...,U 2R+1 ) and g : \nand L R bnd ( ) analogously. Now condition on X = x, where x \u2208 X such that x t =x t for all t = R+2,...,2R+1, let z 2 \u2208 R be a fixed constant, and define\nThe operator L 1,2,3 is a mapping from L R bnd (Z 1 ) to L R bnd for a fixed value z 2 . Changing the value of z 2 gives a different mapping. With these definitions it follows from Assumption N5 that for any m \u2208 L R bnd (Z 1 )\n. These equalities hold for all functions m \u2208 L R bnd (Z 1 ) and thus we can write\nBy Lemma 1, L 3,\u03bb is invertible and the inverse can be applied from the left. Hu and Schennach (2008) and Lemma 1 above imply that L 1,3 has a right inverse which is densely defined on L R bnd . Therefore,\n3,\u03bb . The operator on the left-hand side depends on the population distribution of the observables only. Hence, it can be considered known. Hu and Schennach (2008) deal with the same type of operator equality in a measurement error setup. They show that the operator on the left-hand side is bounded and its domain can therefore be extended to L R bnd . They also show that the right-hand side is an eigenvalue-eigenfunction decomposition of the known operator L 1,2,3 L \u22121 1,3 . The eigenfunctions are f Z 3 |\u03bb,X (z 3 ;v,x) with corresponding eigenvalues f Z 2 |\u03bb,X (z 2 ;v,x). Each v indexes an eigenfunction and an eigenvalue. The eigenfunctions are functions of z 3 , while x and z 2 are fixed. Hu and Schennach (2008) show that this decomposition is unique up to three features: \nThese conditions are very similar to conditions for non-uniqueness of an eigendecomposition of a square matrix. While for matrices the order of the columns of the matrix that contains the eigenvectors is not fixed, with operators any one-toone transformation of \u03bb leads to an eigendecomposition with the same eigenvalues and eigenfunctions (but in a different order). I show next that the assumptions fix the scaling and the ordering and that all eigenvalues are unique. It then follows that there are unique operators L 3,\u03bb and\nFirst, the scale of the eigenfunctions is fixed because the eigenfunctions we are interested in are densities and therefore have to integrate to 1. Second, two different eigenfunctions share the same eigenvalue if there exists v and w with v = w such that f Z 2 |\u03bb,X (z 2 ;v,x) = f Z 2 |\u03bb,X (z 2 ;w,x). Following Hu and Schennach (2008) , while this could happen for a fixed z 2 , changing z 2 leads to a different eigendecomposition with identical eigenfunctions. Therefore, combining all these eigendecompositions, eigenvalue degeneracy only occurs if two eigenfunctions share the same eigenvalue for all z 2 \u2208 Z 2 , which means that f Z 2 |\u03bb,X (z 2 ;v,x) = f Z 2 |\u03bb,X (z 2 ;w,x) for all z 2 \u2208 Z 2 . Recall that Z 2 = Y R+1 \u2208 R, while \u03bb \u2208 R R . Given the structure of the model, we get f Z 2 |\u03bb,X (z 2 ;v,x) = f Z 2 |\u03bb,X (z 2 ;w,x) for all z 2 \u2208 Z 2 if v F R+1 = w F R+1 , which is clearly possible if R > 1. Hu and Schennach (2008) rule out this situation in their Assumption 4, but an analog of this assumption does not hold here if R > 1. Hence, compared to Hu and Schennach (2008) , additional arguments are needed to solve the eigenvalue degeneracy problem. To do so, notice that, similar as in the linear model, we can rotate the outcomes in Z 1 and Z 2 . Specifically, let K \u2261{k 1 ,k 2 ,...,k R } be a set of any R integers between 1 and R+1 with k 1 < k 2 < ... < k R and let\nFor example, if R = 2 and T = 5, then we could take K ={2,3} and k R+1 = 1 and thus, Z K 1 = (Y 2 ,Y 3 ) and Z K 2 = Y 1 . Let Z K 1 be the support of Z K 1 and, analogously to before, define the operators\n. Then using identical arguments to before, it can be shown that for all sets K\nIt follows that L K 1,2,3 (L K 1,3 ) \u22121 has the same eigenfunctions for all K. Hence, by considering the eigendecomposition for all K, the eigenvalue degeneracy issue now only occurs if two or more eigenfunctions share the same eigenvalue for all operators, which is a similar idea to varying z 2 above. In terms of Y t , this means that eigenvalue degeneracy arises if for v = w it holds that f Yt |\u03bb (y t ;v) = f Yt |\u03bb (y t ;w) for all y t \u2208 Y t and all t = 1,...,R+1. However, Assumptions N3(i), N4, and N6 imply that M[Y t | \u03bb = v]=g t (v F t ), that g t are strictly increasing functions, and that the matrix (F 1 ... F R ) has full rank. Hence f Yt |\u03bb (y t ;v) = f Yt |\u03bb (y t ;w) for all y t \u2208 Y t and all t = 1,...,R+1 implies that v (F 1 ... F R ) = w (F 1 ... F R ), which in turn implies that v = w.\nThird, I show that there is a unique ordering of the eigenfunctions which coincides with L 3,\u03bb . Generally, the problem is that while the sets of eigenfunctions and eigenvalues are uniquely determined, these sets do not uniquely define the distribution of \u03bb | X. In particular, let\u03bb = B (\u03bb,x) , where B(\u00b7,x) is a one-to-one transformation of \u03bb, which may depend on x. Then f Z 3 |\u03bb,X (\u00b7;v,x) = f Z 3 |B(\u03bb,x),X (\u00b7;B(v,x),x) and hence each eigenfunction could belong to f Z 3 |\u03bb,X (\u00b7;\u1e7d,x) for som\u1ebd v. 30 To solve the ordering issue, Hu and Schennach (2008) and Cunha et al. (2010) assume that there exists a known function such that (f Z 3 |\u03bb,X (\u00b7;\u03bb,x)) = \u03bb (see Assumption 5 in Hu and Schennach (2008) ). Notice that in the factor model discussed in this article, the assumptions already imply M(Y R+1+r | \u03bb = v,X = x) = g R+1+r (x,v r ). Hence, it might be tempting to impose the \"normalization\" g R+1+r (x,\u03bb r ) = \u03bb r so that M(Z 3 | \u03bb,X = x) = \u03bb. However, as shown below, here the distribution of Y | \u03bb is identified without such an additional \"normalization\" of \u03bb. Thus, imposing this \"normalization\" is only consistent with the model if g R+1+r is linear in the second argument for all r = 1,...,R, which is a strong assumption. Now to show that there is a unique ordering, first notice that both\u03bb = B(\u03bb,x) and \u03bb have to be consistent with the model. In particular, for\u03bb there has to exist strictly increasing and differentiable functionsg t (with inversesh t ) such that M(Y R+1+r |\u03bb =\u1e7d,X = x) =g R+1+r (x R+1+r ,\u1e7d r ) for all r = 1,...,R.\nIn particular, the conditional median of Y R+1+r only depends on the r'th element of\u1e7d r . Since it follows that g R+1+r (x R+1+r ,v r ) =g R+1+r (x R+1+r ,B r (v,x)). Moreover, sinceg R+1+r is strictly increasing and differentiable, it has to hold that B r (\u00b7,x) is differentiable. Since the left-hand side only depends on v r , it follows that 30. To see why B(\u00b7,x) has to be one-to-one, notice that since the set of eigenfunctions is uniquely determined, for each v and w, there has to exist B (v,x) and B(w,x) such that f Z 3 |\u03bb,X (\u00b7;v,x) = f Z 3 |\u03bb,X (\u00b7;B(v,x),x) and f Z 3 |\u03bb,X (\u00b7;w,x) = f Z 3 |\u03bb,X (\u00b7;B(w,x),x). But as shown above, if v = w, then f Z 3 |\u03bb,X (\u00b7;v,x) = f Z 3 |\u03bb,X (\u00b7;w,x) which immediately implies that f Z 3 |\u03bb,X (\u00b7;B(v,x),x) = f Z 3 |\u03bb,X (\u00b7;B(w,x),x), and thus B (v,x) = B(w,x) . Fts for all r,s = 1,...,R. Hence, again g t is identified up to scale which is fixed. Therefore, g t and F t are identified."}, {"section_title": "A.3. Proof of Theorem 2", "text": "First fixx \u2208 X and\u0233 on the support of Y | X =x and define d t = 31. When R > 1, it can be shown that B(\u03bb,x) = \u03bb using only median independence and not full independence. Hence, even without independence of U t and \u03bb, imposing a \"normalization\" of the form (f Z 3 |\u03bb (\u00b7;\u03bb)) = \u03bb is not without loss of generality.\nSimilarly, since P C t +\u0168 t < e | X = x = P C t +U t < ed t +b F t +c t | X = x it follows that "}]