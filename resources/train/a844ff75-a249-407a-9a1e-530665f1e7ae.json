[{"section_title": "Abstract", "text": "In this paper, we introduce the use of a personalized Gaussian Process model (pGP) to predict the key metrics of Alzheimer's Disease progression (MMSE, ADAS-Cog13, CDRSB and CS) based on each patient's previous visits. We start by learning a population-level model using multi-modal data from previously seen patients using the base Gaussian Process (GP) regression. Then, this model is adapted sequentially over time to a new patient using domain adaptive GPs to form the patient's pGP. We show that this new approach, together with an auto-regressive formulation, leads to significant improvements in forecasting future clinical status and cognitive scores for target patients when compared to modeling the population with traditional GPs."}, {"section_title": "", "text": ": Personalized GPs. The population model is first trained using all past visits data of N patients (x T R , y T R ), where the time difference between two visits is 6 months. The model personalization to the target patient (N + 1) is then achieved by sequentially adapting the model predictions of the future metrics yt+1 (using the posterior distribution of GPs -fGP ), informed by the visits data up to time step t. The shaded fields in the output represent the time points for which no visit data is available for a given patient.\nin available data per patient, inherent per-person differences, and the slowly changing nature of the disease, accurate prediction of AD progression is a significant and difficult challenge.\nMost existing approaches focus on modeling patients based on their clinical status (CS), i.e. the clinical diagnosis categorizing them into one of the 3 main stages of AD (CN, MCI, AD). CS is often modeled based on commonly used cognitive measures, e.g., the mini mental state examination (MMSE) [10] , the Washington University Clinical Dementia Rating Sum of Boxes score (CDRSB) [15] , and the AD Assessment Scale-Cognitive subtest (ADAS-Cog13) [27] . Modeling of these surrogate measures of disease progression has been explored in a number of works [5, 7, 8, 12, 13, 17, 19, 29, 30, 35] . However, the majority of these focus on modeling biomarkers at the population level; for instance, estimating typical trajectories of markers over the full course of the disease to estimate current disease progress and progression rate [29, 30] . Guerrero et al. [13] used mixed effects modeling to derive global and individual biomarker trajectories for a training population, which was later used to instantiate subject-specific models for unseen patients. Some of the modeling techniques [13, 29, 30] require cohorts with known disease onset and are thus prone to bias due to the uncertainty of the conversion time. While Schmidt-Richberg et al. [29, 30] make no parametric assumption on the model shape, their approach relies on the population-only model; while Guerrero et al. [13] estimate parametrized individualized models, based on the subpopulations similarities, to derive patient-tailored predictive models. While the latter approach is personalized, its parametric models are limited in their modeling power as they may not be able to fully represent the underlying multi-modal distribution of the highly heterogeneous patient data.\nGaussian Process (GP) models have been shown to provide powerful probabilistic predictions for clinical analyses by using a non-parametric regression approach [16, 21, 22, 36] . For example, Ziegler et al. [36] proposed a GP-based generative model allowing individualized predictions in patients at risk of developing dementia. Similarly, Hyun et al. [16] , Lorenzi et al. [21] used GPs for spatiotemporal modeling to delineate the developmental trajectories of brain structure and function in AD patients. While these methods exploit individual data to tune target models to specific patients, they do not provide a principled way of adapting the population model -informed by the data of all training subjects -to target new patients over time using data from their most recent clinical visits.\nIn this work, we introduce a personalized Gaussian Process model (pGP) to predict the key metrics of the AD progression (MMSE, ADAS-Cog13, CDRSB and CS) based on each patient's previous visits.\nHere, a patient's visit refers to the data collected at a single time point sample during the ADNI study (see Appendix D.3.). Specifically, in the pGP model, we start by learning a population model using multi-modal data of previously seen patients using the base GP regression [26] . Then, this model is adapted sequentially over time to a new patient using the notion of domain adaptive GPs [9, 20] . The key to our approach is a novel adaptation strategy for personalizing the GP population model (see Fig.1 ). We show this new approach leads to significant improvements in the prediction performance of the future clinical status and cognitive scores for target patients when compared to the population model. \n., x t } contains the input features up to visit t and y (s) ns = {y 2 , .., y t+1 } the corresponding target labels for the future visit t + 1. The total number of visits is denoted by T . For notational convenience, we drop dependence on n s , and use {x (s) t , y (s) t+1 } t=1:T \u22121 as data pairs for learning the (population) prediction model. Since some patients missed certain visits and not all biomarkers were recorded at every visit, we fill in their missing values using their nearest available past visit, i.e., no data of future visits is used.\nPopulation-level GP. We first build the population-level model using data of training subjects {X (s) , Y (s) }. We formulate the predictions as a regression problem, where the goal is to predict patient's future outputs y (s) t+1 from data of previous visits, x (s) t and y (s) t . To this end, we use the auto-regressive GP [3] , which we denote as GP(AR). This model tries to learn the following mapping function: y\nwhere\nadditive Gaussian noise. Following the framework of GPs [26] , we place a prior on the functions f (s) . This gives rise to the joint prior p(Y (s)\nare computed using radial basis function (RBF)isotropic kernel. The kernel parameters \u03b8 were chosen to minimize the negative log-marginal likelihood: \u2212 log p(Y \nwhere k (s) * = k (s) (X (s) , x \nPersonalized GP (pGP). We extend the approach of domain adaptive GPs (DA-GP) [9, 20] to personalize the population GP model to target patients. This is achieved by sequentially adapting the GP posterior for the test patient using the data of his/her past visits, to predict the future output metrics y (p) t+1 . This is achieved by using the obtained posterior distribution of the source (population) data and data of the target patient up to visit t, to obtain a prior for the GP of the future data for the patient:\nFinally, this prior is used to correct the posterior distribution derived above to account for the previously seen data of the target patient. Formally, the conditional prior on the target patient data (given the source data) is given by applying Eqs. t }, the correct form of the adapted posterior after observing the target patient data at visit t is:\nwith V (p|s)\nEqs. (4) (5) show that final prediction in the pGP is the combination of the original prediction based on the source data only, plus a correction term 1 . The latter shifts the mean toward the distribution of the target patient and improves the model's confidence by reducing its predictive variance. Table 1 : Comparison of the population and personalized (p) models, and their auto-regressive (AR) variants."}, {"section_title": "Results", "text": "Data used in this study were collected from the ADNI database (adni.loni.usc.edu). We downloaded the standard dataset processed for the TADPOLE Challenge [1] ; this dataset represents 1,737 unique patients and was created from the ADNIMERGE spreadsheet, to which regional MRI (volumes, cortical thickness, surface area), PET (FDG, AV45, AV1451), DTI (regional means of standard indices) and cerebrospinal fluid (CSF) biomarkers were added. From this data, we constructed a multi-modal feature set consisting of six modalities: demographics (6 features), genetics (3 features), cognitive tests (9 features), CSF (3 features), MRI (366 features)(see Appendix D.1), and DTI (229 features). Due to sparseness, we excluded PET data entirely. For our experiments, we then selected a cohort of 100 patients with more than 10 visits and missing no more than 82.5% of the features (see Appendix D.2.1-2).\nTo evaluate performance, we ran a 10-fold patient-independent cross-validation. All the input features were z-normalized, and we then applied principal component analysis to reduce the effects of noise in the data, preserving 95% of variance. As performance metrics, we report the mean (\u00b1 SD) of the 10folds, and in terms of commonly used metrics: mean absolute error (MAE) and intra-class correlation (ICC(3,1) [31] . The latter ranges from 0-1, and is used to measure the (absolute) agreement between the model predictions and the ground-truth for target scores. For CS, we also compute the models accuracy (ACC) on three target labels (0-CN,1-MCI,2-AD). We report the results obtained using the population-level GPs, and their personalized versions (pGPs). Specifically, we compare the standard GPs and auto-regressive GPs -GP(AR) -the latter using also target scores as input features, but from previous visits of target patients. All GP models were trained to predict four target outputs, using the shared covariance function and the kernel parameters tuned on training data using GP toolbox [26] . Table 1 shows the results. First, we see that GP(AR) significantly improves the prediction performance compared to standard GP (no past scores of the patients are used in the input). Thus, it appears that when learning the model's covariance function, including temporal changes in target scores significantly improves prediction results. The predictions by the personalized models (pGP/pGP(AR)) were obtained by first applying the population models (GP/GP(AR)), then correcting their predictions using the personalized adaption strategy introduced in Sec.2. The result is that both personalized models outperform the population models by a large margin: All improvements are statistically significant based on a paired t-test with equal variances and p < 0.01. We also note significant improvements in accuracy: 24% and 5% on average. Fig.2 (See Appendix B) shows the confusion matrices for AR-models. We see pGP(AR) reduces the confusion between AD and MCI by 7.5% across all patients, in addition to better predicting these two classes. Lastly, we show the improvements in the performance per patient, due to the model personalization, in Fig.3 (See Appendix B)."}, {"section_title": "Conclusion", "text": "Timely diagnosis of AD is a challenging yet important problem whose solution could have significant impact on the success of diagnoses and disease-modifying treatments, especially in the earlier stages of the disease. This paper has proposed personalizing GP models (pGPs), and has tested two version of pGPs on a cohort of 100 patients from the ADNI dataset, showing significant improvements over population-level GP models. In the future, we plan to investigate how the sub-group similarities can be exploited to build patients' profiles, which can later be used to build local personalized models.\nWe also plan to tackle the prediction of a longer time horizon, instead of one-visit-ahead, as done in this work. Extending this framework will help enable the prediction of changes in AD-related scores as early as possible; this capability is of great importance to both clinicians and those at risk of AD since it is critical to the early identification of at-risk patients, the construction of informative clinical trials, and the timely detection of AD progression.\n[33] N. Toschi, A. Duggento, and M. Guerrisi. Predictive disease modeling for personalized and preventative medicine, 2016. URL http://www.biomedicineandprevention.com/ system/files/009_Predictive%20disease%20modeling%20for%20personalized% 20and%20preventive%20medicine.pdf.\n[ Using clinical status (CS) as an indicator, we define patient conversion from one stage of Alzheimer's Disease to another stage as the event when a patient's CS at current visit at time t is different than his/her CS at the previous visit t \u2212 1, \u2200t \u2208 V , where |V | = n, and V is the set of all visits that a patient attends. The total number of possible visits that a patient may attend is denoted, V possible , and |V possible | = 22. Note that it is possible that |V | < 22, since |V | < |V possible |, i.e. the total number of visits a patient attends is not necessarily equal to the total number of possible visits, V possible . Table 2 shows the frequency of patient conversions along the spectrum of AD progression, as measured by change in clinical status from one visit to the next. This information reflects the total number of conversions as observed across the 100 patients selected for use in our experiments. The transition types denoted with asterisks (CN \u2192 MCI, MCI \u2192 AD) indicate key transition types associated with the progression of AD."}, {"section_title": "B Observed Change in Cognitive Scores", "text": "When considering the progression of AD, we are concerned with two patterns of clinical status conversion:\n1. when a cognitively normal (CN) patient converts to MCI (CN \u2192 MCI)\n2. when an MCI patient converts to AD (MCI \u2192 AD).\nThese two scenarios represent the instances in which a patient's clinical status progresses further along the spectrum of Alzheimer's disease, with decreasing cognitive function.\nIn the figure below, we show the confusion matrices for predicting the future clinical status of the patients.\nGP(AR) pGP(AR) Analyzing the changes that occur when a patient undergoes conversion from one stage of AD to another is an important step toward understanding, characterizing, and profiling patients at each stage of the disease. In addition, it is necessary to compute the mean change in value (of metrics we wish to predict) that occurs when a patient undergoes a conversion and compare this mean delta with the MAE of our models; if the mean delta value is greater than the MAE obtained by our models, then we cannot assert that our models -or any model -accurately account for this mean change in value in cases when a patient changes clinical status.\nIn this work, conversion is measured from one visit to the next. At the time t of each conversion, we compute the change in cognitive score of the patient by calculating the absolute difference in cognitive score recorded at visit t \u2212 1 and the cognitive score recorded at visit t. For example, if a patient is diagnosed as MCI at the visit at time t, and the patient was diagnosed as CN at his/her previous visit at time t \u2212 1, then we compute the absolute difference in cognitive scores recorded at the visits at time t \u2212 1 and t. If a patient does not have cognitive scores recorded at the visit at t \u2212 1 and at t, then we do not calculate the absolute difference and do not consider this example.\nAfter computing all of the changes in value for each type of cognitive score (MMSE, CDRSB, ADAS-Cog13), we compute the mean and standard deviation of the change in cognitive score for each of the three cognitive tests. We define this value of the change in cognitive score as the delta (\u2206) of the cognitive score. Table 3 : Comparison of the mean change in cognitive score observed when patients convert to subsequent stages of AD. Mean and standard deviation were computed using data from the 100-patient cohort used in this work.\nIn Table 3 shown above, we report the mean (\u00b1SD) of the delta (\u2206) value of each of 3 types of cognitive scores (ADAS-Cog13, CDRSB, MMSE) which our model tries to predict. The mean (\u00b1SD) is computed using data from all 100 patients. In the first row of C Individual Performance Fig.3 show the individual performance for each patient, and for each output metric. As can be noted from the plots (a-d), the pGP(AR) achieves a lower MAE error than the GP(AR) on more than 80% of all 100 patients across all four predicted metrics (MMSE, ADAS-Cog13, CDRSB, and CS). The relative performance improvements of the pGP(AR) compared to the GP(AR) are most readily evident in plot (a), when the models are used to predict MMSE. In plot (a), it is clear that that pGP(AR) achieves significant improvement in performance in comparison to the GP(AR); the MAE obtained by the pGP(AR) is much lower than that obtained by the GP(AR) for the majority of patients. The pGP(AR) also performs quite well in comparison to the GP(AR) when predicting CS (plot (d)). However, we note that the pGP(AR) and GP(AR) have more comparable performance when predicting ADAS-Cog13 and CDRSB (plots (c-d)). One possible explanation as to why the pGP(AR) is able to outperform the GP(AR) significantly when predicting MMSE, and yields more comparable performance results when predicting ADAS-Cog13 and CDRSB, may be due to the construction of cognitive tests and the inherent subjectivity of tests such as ADAS-Cog and its variants, as has often been noted in literature [24] . Model-wise, we would like to emphasize that while both pGP(AR) and GP(AR) have seen the data of all visits from training patients, during inference the population-level model takes as input only the last visit. By contrast, the pGP(AR) actively updates and leverages its Bayesian framework to incorporate all the previous visit data of a test patient into its inference machinery. Evidently, this temporal personalization using the whole history of a test patient is critical for reducing the estimation error for the majority of the patients used in this work, as can be seen from Fig.3 ."}, {"section_title": "D Data Preprocessing", "text": ""}, {"section_title": "D.1 Feature Selection", "text": "Data used in this work was obtained from the ADNI database. Since its inception, ADNI has conducted three separate phases of study (ADNI-1, ADNI-GO, and ADNI-2) and recruited over 1,500 individuals, aged between 55-90 years, to participate in the study. As of November 2017, ADNI has begun a fourth phase of study called ADNI-3. Data collected from this phase of the study is not yet available in the ADNI database.\nThe ADNI study aims to analyze biomarkers from cognitive tests, blood tests, tests of CSF, and MRI/DTI/PET imaging in order to understand and characterize the progression of Alzheimer's disease. Thus, ADNI collects data samples for a myriad of these biomarkers and stores them in the ADNI database.\nIn our work, we start by collecting a multi-modal dataset from the ADNI database, comprised of biomarkers across 7 different modalities: 3. MRI 4. DTI 5. PET 6. Demographics 7. Genetics Below, we provide a summary of each of the seven modalities, including information regarding the corresponding biomarkers available within each modality, and which biomarkers we selected to include in our feature set:"}, {"section_title": "Cognitive tests 2. CSF", "text": ""}, {"section_title": "Cognitive tests", "text": "Patients in the ADNI study were administered numerous cognitive tests (neuropsychological tests administered by a clinical expert) in order to diagnose AD progression. In the dataset collected from ADNI, we focus on data from 9 main cognitive tests (including subtypes). These include the following: 1) CDR Sum of Boxes (CDRSB), 2) ADAS-Cog11, 3) ADAS-Cog13, 4) MMSE, 5) RAVLT-immediate subtype, 6) RAVLT-learning subtype, 7) RAVLT-forgetting subtype, 8) RAVLTpercent forgetting subtype, and 9) FAQ.\nWe use all nine cognitive tests as features. We also predict CDRSB, ADAS-Cog13, and MMSE."}, {"section_title": "CSF", "text": "Cerebrospinal fluid (CSF) measurements are important for dementia research because they can be used to detect some of the earliest signs of AD. Analyzing the concentration of abnormal proteins such as amyloid-beta, tau, and phosphorylated tau provide strong evidence of progression of AD. ADNI provides three measures of CSF biomarkers: 1) amyloid-beta levels, 2) tau levels, and 3) phosphorylated tau levels. These measurements are not associated with a specific part of the brain [1] .\nWe use these 3 CSF-based biomarkers in our feature set."}, {"section_title": "MRI", "text": "Magnetic resonance imaging (MRI) biomarkers can be used to measure damage to nerve cells.\nSpecifically, MRI-based biomarkers can be used to quantify atrophy and structural brain integrity by measuring the volume of gray matter (GM) and white matter (WM) of the brain. [1] TADPOLE datasets include three main types of structural MRI markers of atrophy: 1) ROI volumes 2) ROI cortical thicknesses 3) ROI surface areas, where an ROI (region of interest) is a 3D sub-region of the brain such as the inferior temporal lobe. These structural MRI markers were computed using an image analysis software called Freesurfer using two pipelines: cross-sectional (each subject visit is independent) or longitudinal (uses information from all the visits of a subject [1] .\nFrom the provided MRI measurements, 18 measurements were null for all 1,737 patients We exclude these measurements from our feature set. In addition to the MRI volumetric features, we also used the manifold features from [14] . Using this set of MRI measurements, we obtain a total of 366 MRI-based features."}, {"section_title": "DTI", "text": "Diffusion tensor imaging (DTI) measures the degeneration of white matter in the brain. In ADNI, DTI is a relatively recent imaging modality, and thus not all subjects have DTI scans. Three types of DTI ROI measurements were provided by ADNI: 1) mean diffusivity, 2) axial diffusivity, and 3) radial diffusivity. DTI measures are recorded for various voxels in the brain. [1] .\nWe obtain 229 DTI-based features using the DTI-based biomarkers provided for various brain ROIs of ADNI subjects."}, {"section_title": "PET", "text": "Positron Emission Tomography (PET) imaging can be used to measure amyloid beta protein as well as to measure damage to nerve cells. In ADNI, three different types of PET measurements are provided: 1) AV45 PET ROI averages, 2) AV1451 PET ROI averages, and FG PET ROI averages. AV45 PET ROI measures amyloid-beta load in the brain, where amyloid-beta is a protein that misfolds, thus leading to AD. AV1451 PET ROI measures tau load in the brain; when tau load is abnormal, it causes damage to neurons, leading to AD. FDG-PET ROI measures cell metabolism, which is useful because AD-affected cells exhibit reduced metabolism [1] .\nDue to sparseness, we do not include PET measurements in our feature set, as the majority of measurements were missing across all patients."}, {"section_title": "Demographics", "text": "In addition to the above cognitive tests and quantitative biomarkers, ADNI provides demographic information for each patient. We use the following six types of demographic information as input features: 1) age, 2) gender, 3) ethnicity, 4) race, 5) years of education, and 6) marital status."}, {"section_title": "Genetics", "text": "The alipoprotein E4 variant (APOE E4) is a gene that is the largest known risk factor for AD. Patients with APOE E4 have a high risk of developing AD. Each patient in ADNI underwent ApoE genotyping tests to determine if they have the APOE E4 gene present. In addition, each ApoE genotyping classifies patients into one of two genetypes (APGEN1 or APGEN2) based on their alleles [1] . These three pieces of genetic information are used as genetic-based features in our feature set.\nAfter collecting data from ADNI, we performed additional data preprocessing steps in order to address missing values, select the features to use in our feature set, and to select the training set of patients.\nAs an initial step in handling missing or null values in the data from ADNI, we replaced all missing or null entries with a dummy value of \u221299999999, and convert all values to numeric format. After analyzing each modality and the percentage of missing values, we obtain a multi-modal feature set of 616 features. In our model, we then address the remaining missing values by using previous values to fill in the missing ones. No future data that we aim to predict is used to fill in the missing values.\nWe describe the steps to select the training set of patients in the following section."}, {"section_title": "D.2 Patient Subset Selection Criteria", "text": "From our database of 1,737 patients, we selected a subset of patients to form the patient cohort used in our experiments. We selected patients to include in the cohort if they met the following two criteria:\n1. the patient attended more than 10 separate visits (i.e. 11 or more) during the 120-month period from which ADNI data was collected to our dataset 2. the patient is missing no more than 82.5% of feature values Using these two criteria, we selected a subset of 100 patients. The application of these two criteria are described below, in Appendix D.2.1-2. The IDs of the 100 patients selected can be found at the end of this document (in Appendix D.4)."}, {"section_title": "D.2.1 Visit History Criteria", "text": "We used the frequency of each patient's visits as criteria to select a subset of patients in order to obtain a subset of patients for which sufficient data samples had been collected. As described in Appendix D.3, the majority of patients did not attend all 22 possible visits during the ADNI study. Out of 1,737 patients, only 267 patients attended more than 10 separate visits (i.e. at least approximately 50% of all 22 possible visits). We selected this subset of 267 patients with at least more than 10 points in time at which data was collected using the hypothesis that the resulting dataset would not be too sparse such that imputation or filling in of missing values would be erroneous. Using this subset of 267 patients, we then selected our final cohort of 100 patients by computing the percentage of missing feature values available for each patient. This process is described in more detail in the following section, Appendix D.2.2."}, {"section_title": "D.2.2 Handling Missing Features", "text": "From the subset of 267 patients selected as described in Appendix D.2.1, we then selected the subset of patients who were missing at most 82.5% of feature data. In other words, a patient profile must contain at least 17.5% of feature data, i.e. the profile must not be missing more than 82.5% of feature data. For instance, if the elements in the table, containing the features of target patient for all the visits, had values \u221299999999, these were counted as the missing feature data for that patient. This high percentage of the missing data is not surprising since, for the majority of the patients, high dimensional modality data such MRI, PET and DTI, were not often present. Also, the latter two are relatively new imagining techniques, and only a few subjects in the TADPOLE dataset have undertaken these images [1] ."}, {"section_title": "D.3 Patient Visit Data Collection", "text": "In the dataset used in this work, quantitative measurements for participants of the ADNI study were collected at clinical visits in six-month increments, on average. Time points were collected at various time points over the duration of 120 months, with samples collected for each patient from at most 22 different time points. Each patient in the study has a data sample from at least one time point (i.e. clinical visit). The maximum number of samples collected per patient corresponds to the maximum number of clinical visits a patient attended over the course of the ADNI study. Thus, each patient has data collected from at most 22 visits. Because patient participate in the ADNI study at varying time points and frequency, the maximum number of samples per patient (for the subset of patient considered here) is 19. The average number of time point samples per patient (i.e. number of visits attended per patient) is 7.334.\nPatients who attended less than 5 visits fall into the lower quartile (25th quartile); patients who attended 9 or more visits fall into the upper quartile (75th percentile). The maximum possible number of visits a single patient may have attended is 22. However, no patient attended all 22 possible visits. Thus, we observe that the maximum number of visits a single patient in our dataset attended was 19. Each patient attended a minimum of one visit. We note that 276 or 15.88% of all 1, 737 patients attended more than 10 visits. Assuming a normal distribution with \u00b5 = 7.334 and \u03c3 = 4.033, patients with more than 10 visits fall into the 81st percentile. "}, {"section_title": "D.4 Cohort Patient IDs", "text": "Below is a list of the IDs of each of the 100 patients selected for use in the experiments performed in this work: "}]