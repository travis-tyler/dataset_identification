[{"section_title": "Introduction", "text": ""}, {"section_title": "J o u r n a l P r e -p r o o f", "text": "Multiple Sclerosis (MS) is the most widespread autoimmune neuroinflammatory disease in young adults with 2.2 million cases reported worldwide [1] . The disease is mainly characterized by inflammation, demyelination and neurodegeneration in the central nervous system and often leads to substantial disability in patients [2] . The current quasi-standard for diagnosing MS, the\nMcDonald criteria, relies on clinical presentation and the presence of lesions visible in conventional T2-weighted brain magnetic resonance imaging (MRI) data [3] . Most common in clinical practice are fluid-suppressed T2-weighted image sequences (e.g. fluid-attenuated inversion recovery sequence [FLAIR] ), which are sensitive towards MS-relevant white matter lesions, but also relatively unspecific with respect to underlying disease processes [4] . Several other imaging markers have been described including global brain atrophy, thalamic atrophy, cortical lesions, altered structural and functional connectivity or central vein signs [5] [6] [7] [8] [9] [10] [11] [12] , of which some are captured in conventional MRI and others require advanced MRI techniques such as diffusion weighted imaging or functional MRI.\nIn the last decade, a lot of research effort has been put on the automatic (i.e. data-driven) detection of neurological diseases based on neuroimaging data including MRI [13, 14] . Early approaches combined parameter-based machine learning algorithms, such as support vector machines, with carefully extracted features known or hypothesized to be relevant in the respective disease. In MS research, features ranging from T2 lesion characteristics to atrophy to local intensity patterns or multi-scale information extracted from MRI data have been used in combination with standard machine learning analyses to either diagnose MS or predict disease progression [15] [16] [17] [18] [19] [20] [21] . While choosing features based on expert criteria reflects the current state of knowledge, it does not allow for finding new and potentially unexpected hidden data properties, which might also help in characterizing a certain disease. Deep learning techniques fill a gap here and allow for utilizing hierarchical information directly from raw or minimally processed data [22] . By being specifically tailored to image data, in particular convolutional neural networks (CNNs) have led to major breakthroughs in medical imaging [23] [24] [25] [26] . In neuroimaging, most CNN analyses so far focused on Alzheimer's disease [27] , but there are also some recent studies in MS. Given the importance of lesions in diagnosing MS and monitoring disease progression, most J o u r n a l P r e -p r o o f\nDespite their potential, deep learning methods are criticized for being non-transparent (such as a 'black box') due to the difficulty to retrace the classification decision in light of huge parameter spaces and highly non-linear interactions [33] . This is especially problematic in medical applications since understanding and explaining neural network decisions is required for clinical integration, error tracking or knowledge discovery. Explaining neural network decisions is an open research area in computer science and a number of suggestions have been made in recent years. Different directions for explanations include visualizing features [34] , generating images that maximally activate a certain neuron [35] and creating heatmaps based on the input images indicating the relevance of each voxel for the final classification decision [36] [37] [38] . Heatmaps are in particular valuable in the medical context, since they allow for an easy and intuitive investigation of what the respective classifier found to be important directly in the input data. Besides understanding diagnostic decisions for individual patients, heatmaps might be useful in validating CNN models. Recently, we have shown the potential of transparent CNN applications for knowledge discovery in Alzheimer's disease [39, 40] .\nThe objective of the current study was to investigate whether a transparency approach can uncover decision processes in MRI-based diagnosis of MS, a disease with well-defined imaging markers, thereby supporting future clinical implementation and verification of machine learning-based diagnosis systems. We present a transparent CNN framework (see Figure 1 ) for the MRI-based diagnosis of MS relying on layer-wise relevance propagation (LRP, [37, 41] ) -a heatmap method that has been shown to outperform previous approaches in terms of explainability and disease-specific evidence [40, 41] . Since the data set was rather small ( = 147 n ), we investigated the effect of pre-training the CNN on data from the Alzheimer's Disease\nNeuroimaging Initiative (ADNI, = 921 n ). Using LRP, individual heatmaps were generated for each subject and analyzed with respect to well-established imaging features in MS (e.g. white matter lesions or thalamic atrophy). By showing that LRP in combination with a naive CNN model (i.e. a model independent of MS-specific knowledge) indeed helps in uncovering relevant imaging features, we conclude that this framework is not only useful in justifying individual diagnostic decisions but also to validate CNN models (especially in light of small sample sizes).\nFigure 1: Illustration of the transparent CNN framework. In the training phase, the CNN model learns a non-linear relationship between the MRI data and the binary diagnostic labels (MS J o u r n a l P r e -p r o o f yes/no). Optionally, the CNN models are pre-trained on a substitute data set or lesions are filled in the MRI data. The learned CNN model is then tested on new subjects to predict the diagnostic label. By supplementing this label with a LRP heatmap, which indicates the relevance of each voxel for the respective label, this framework allows us to understand (at least to some extent) the classification decision in individual subjects. Additionally, the validity of the CNN models can be assessed by matching highlighted brain areas with domain knowledge."}, {"section_title": "Materials and methods", "text": ""}, {"section_title": "Subjects", "text": "In the present study, we retrospectively analyzed data collected by FP from Charit\u00e9 - "}, {"section_title": "MRI acquisition and preprocessing", "text": "All MRI data were acquired on the same 3 T scanner (Tim Trio Siemens, Erlangen, Germany) using a volumetric high-resolution T1 weighted magnetization prepared rapid acquisition gradient echo (MPRAGE) sequence (TR = 1900 ms, TE = 2.55 ms, TI = 900 ms, FOV=240x240 mm 2 , matrix 240x240, 176 slices, voxel size: 1 mm isotropic) as well as a volumetric high-resolution fluid-attenuated inversion recovery sequence (FLAIR, TR = 6000 ms, TE = 388 ms, TI = 2100 ms;\nFOV=256x256 mm 2 , voxel size: 1 mm isotropic). All MR images were bias field corrected using non-parametric non-uniform intensity normalization [44] , changed to a robust field of view and linearly oriented to MNI space using FMRIB software tools [45] . The FLAIR images were then co-registered to the MPRAGE images using a spline interpolation with FSL FLIRT [46] . Lesion segmentation was done semi-automatically on FLAIR using the lesion prediction algorithm [47] as "}, {"section_title": "ADNI data for pre-training", "text": "Data used for pre-training were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database 5 . We have used subjects from ADNI phase 1 who were included in one of two standard MRI collections [52] . We only selected MRI data of Alzheimer's disease (AD) patients and cognitive normal subjects, in total 921 MRI scans from 389 subjects (covering one to three time points). Follow-up acquisitions can be interpreted as a form of data augmentation used to increase the variance within the training data base. Demographical information can be found in Table 2 . The MRI scans were acquired with 1.5 Tesla scanners at multiple sites and had already undergone gradient non-linearity, intensity inhomogeneity and phantom-based distortion correction. T1-weighted MPRAGE scans were downloaded and warped to MNI space with ANTs [53] . As for the MS data, the initial scan volumes were down-sampled to 96x114x96 voxels and standardized. "}, {"section_title": "AD patients", "text": ""}, {"section_title": "Classification and visualization analyses", "text": "Based on the preprocessed FLAIR data, we first trained several CNN models (with and without pre-training, with and without lesion-filling) to discriminate MS patients and healthy controls and then explained the model's decisions for individual subjects in the test data using LRP. For the J o u r n a l P r e -p r o o f CNN models, we evaluated the effect of transfer learning by (1) training the model solely on MS data and (2) pre-training the model on ADNI data and fine-tuning it on MS data. To examine whether our pre-trained network can also learn from only normal-appearing brain matter (NABM),\ni.e. regions without hyperintense lesions, we retrained the network on lesion-filled FLAIR data. As baseline analyses, we included a support vector machine to classify based on (1) lesion volume and (2) preprocessed FLAIR data. Prior to training, the MS data set was randomly split into two sets:\n(1) a set for training and hyperparameter optimization (85 %) and (2) a holdout set used only for final model evaluation (15 %). The code for all models and also the lesion filling algorithm is available at https://github.com/derEitel/explainableMS. In the following subsections, we specify our parameter settings for CNNs, transfer learning and visualization techniques (in particular LRP)."}, {"section_title": "Convolutional neural networks", "text": "In this study, we used a 3D CNN architecture consisting of four convolutional layers followed by exponential linear units (ELUs) activation functions and four max-pooling layers applied after the first, second and fourth ELU activation. For each convolutional layer, we learned 64 filters with a kernel size of 3x3x3. Finally, a linear layer with an output shape of 1 and a sigmoid activation returns the classification score. To improve generalization, the model has been regularized using a dropout on the outputs of each max-pooling layer ( = 0.3 p ), L2-regularization ( = 0.01 \uf06c ) using the weights of the third and fourth convolutional layer, and finally early-stopping the training after the validation loss has not improved for 10/15 epochs during pre-training/fine-tuning. We trained all models using the Adam optimizer [54] . Hyperparameters (including learning rate, L2\nregularization and dropout probability) were optimized on 85% of the training data, leaving 15%\nfor validation. After finding suitable hyperparameters, the model performance was tested out-of-sample on the holdout set. To increase robustness, all CNN experiments were repeated 10 times on the same data split, and thus reported metrics are an average over all 10 trials. We report balanced accuracy as a mean between sensitivity and specificity as well as area under the receiver operating characteristic curve (AUC). All code was implemented using Keras [55] with the TensorFlow [56] backend. 6 J o u r n a l P r e -p r o o f"}, {"section_title": "Transfer learning", "text": "Due to the small sample size of the MS data set, we employed the principle of transfer learning [57] [58] [59] , which has been shown to improve performance in medical imaging including MRI data [60] [61] [62] [63] [64] . We pre-trained our CNN model on ADNI MRI data to separate AD patients and healthy controls, and fine-tuned it on the MS data set to separate MS patients and healthy controls. Since the ADNI data set contains multiple scans for several subjects we ensured that validation and testing was done on disjoint subject sets. The average balanced accuracy over all trials was 78.47%. For further analysis, we selected a model from the 10 trials based on its performance, and then picked its training checkpoint with the best validation accuracy of 82.50%. Fine-tuning on the MS data set uses the same model architecture, which is initialized with the weights and biases of the selected pre-trained model instead of randomly distributed values. We allow all layers to re-learn because we transferred a CNN model between rather different tasks and data sets, in particular (1) across diseases (AD to MS) and (2) across MRI sequences (MPRAGE to FLAIR) exhibiting different magnetic field strengths (1.5 and 3 Tesla). Additionally, the data was augmented during fine-tuning, such that during the creation of each mini-batch each image was flipped along the sagittal axis with a probability of 50% and randomly translated between -2 and 2 pixels within the axial plane. We found optimal initial learning rates to be 0.001 in the pre-training and 0.0005 with a 0.002 decay in the fine-tuning phase."}, {"section_title": "Visualization", "text": "Deep learning methods are often criticized for their lack of interpretability and over the last years much research has focused on improving the interpretability of neural networks [33, 65, 66] . While some work has focused on understanding class representations and functions of individual neurons, others have developed methods to generate heatmaps based on the input data that indicate the importance or relevance of each pixel or voxel for the final classification decision [37, 38, 67] .\nThe latter approach is in particular promising in the medical field since it allows for explaining in a fast and intuitive way individual classification decisions without the need for delving deeply into the network structure [40] . Generally, it is distinguished between local and global attribution methods [68] . Whereas local attribution methods represent how a change in a specific voxel would impact the network's output and solely rely on the network's gradient (e.g. sensitivity analysis\nJ o u r n a l P r e -p r o o f resulting in image-specific saliency maps), global attribution methods adjust the relevance of the presence of a feature globally by weighting it with the entire input and thus are more suitable for explanation. In the present study, we used LRP, which has been shown to be a powerful global attribution method [37, 41, 66] . It uses the classification score () fx directly (and not the gradient as in most other visualization methods) and propagates it through the network using the following\nHere, the relevance from layer j R is propagated to its previous layer i R . The term \uf065 is set to a small value (in this study: 0.001) to avoid division by 0. By using both the activation x as well as the weights w connecting layers i and j , LRP assigns a larger share to neurons that are more strongly activated and to connections which have been reinforced during training [69] . By decomposing the classification score () fx rather than the gradient and conserving the classification score during backpropagation, LRP overcomes the flaws of sensitivity analysis [69] and has been shown to provide evidence for AD in individual subjects [40] . Recently, it has been shown that LRP can be formulated in the same mathematical framework as other global attribution methods including gradient*input [70] , integrated gradients [71] and DeepLIFT [70] and are equivalent under certain assumptions [68] .\nIn this study, we produced individual LRP heatmaps for every subject in the holdout set.\nWe have used the iNNvestigate implementation of LRP [72] . 7 For comparison, we produced heatmaps using gradient*input as an alternative global attribution method.\nAfter the CNN models have been trained, we used LRP to generate an individual heatmap for each subject in the holdout data set indicating the relevance of each voxel for the respective classification decision. In Figure 2 In Figure 3 , we show average heatmaps for all correctly classified MS patients (top) and all correctly classified healthy controls (bottom) in the holdout set. In accordance with the heatmaps of the individual subjects in Figure 2 , posterior periventricular white matter regions have a strong positive relevance for the MS diagnosis. This is true for both MS patients and healthy controls, but the effect is less pronounced for healthy controls. The reversed effect can be seen for clusters exhibiting negative relevance in white matter areas in the corpus callosum and close to occipital and parietal lobe. Over all voxels healthy controls typically obtain a negative relevance sum (mean\u00b1std: -1.05e-6 \u00b1 0.0013) as opposed to a positive relevance sum in MS patients (3.07e-06 \u00b1 0.0014). Notably, the total relevance attributed to lesion areas was on average 5.15% (on MS patients 9.71%) compared to a lesion coverage of only 0.41% in the training data set. In Figure 4 , we show that the sum of voxels containing lesions (referred to as lesion sum) and LRP relevance sum are significantly correlated for training and hold-out data.\nIn Figure 5 , we depict the region-wise LRP relevance for MS diagnosis, separately for MS patients and healthy controls. In the Neuromorphometrics atlas (see Figure 5a ), most relevance is J o u r n a l P r e -p r o o f and fornix. Notably, these areas are generally characterized by a high lesion density, which is also present in this MS data set (see supplementary Figures 4 and 5) . Negative relevance has been found in the superior and anterior corona radiata. Generally, the relevance for MS patients is higher in white matter than in gray matter areas. Moreover, the differences between MS patients and healthy controls are more pronounced in white matter areas.\nThe qualitative and quantitative analysis using another global attribution method, namely gradient*input, produced highly similar results as shown in supplementary Figures 6 and 7. or MS data to a CNN pre-trained on ADNI and fine-tuned on MS. As it can be seen, the fine-tuned model led to the most concise regions of positive and negative relevance. Please note that we averaged here the heatmaps over all (not only the correctly classified) MS patients in the holdout set and that the heatmap values here are not normalized to a fixed range but shown with respect to the minimum value of the untrained model.\nTo assess the contribution of normal-appearing brain matter, we compared the relevance maps between the CNN models trained on the original FLAIR data and the lesion-filled FLAIR data (for the performance see Table 3 ). In Figure 7 , we depict the relevance for the 10 top-scored white matter regions, separately for both models. In general one can see that the relevance shifts from a distribution more evenly spread among multiple areas to a distribution with a prominent peak and otherwise low shares of relevance. Notably, relevance is shifted away from areas with large amounts of lesions such as posterior corona radiata, posterior thalamic radiata as well as tapetum towards mainly the corpus callosum and regions with very few lesions like fornix and external capsule (see supplementary Figure 4 for distribution of white matter lesions). normal-appearing brain matter). We calculated the relevance sum of both models (averaged over subjects) and show the 10 areas with the highest score."}, {"section_title": "Evaluation of heatmaps", "text": "Besides qualitatively comparing individual heatmaps, we compared average heatmaps of MS patients and healthy controls. We evaluated the importance of different brain regions by computing the average relevance for each brain area in the (1) Neuromorphometrics atlas 8 [73] mostly containing gray matter regions and the (2) JHU DTI-based white-matter atlas 9 [74] J o u r n a l P r e -p r o o f \nwhere lm is the individual lesion mask and hm \uf02b the individual positive relevance. for the preprocessed FLAIR volumes an optional prior dimensionality reduction step via principal component analysis was performed."}, {"section_title": "Baseline analyses", "text": ""}, {"section_title": "Results", "text": ""}, {"section_title": "Classification performance", "text": "In Table 3 , we depict the performance for the different classification models. As expected FLAIR Table 3 : Performance (in %) for the different models on the holdout data set. Values are averages over 10 trials. Pre-train., pre-training; Class., classifier; Bal. acc., balanced accuracy; Sens., sensitivity; Spec., specificity; AUC, area under the curve of the receiver operating characteristic; les. fill., lesions filled."}, {"section_title": "Discussion", "text": ""}, {"section_title": "Summary", "text": "J o u r n a l P r e -p r o o f combination with LRP, we could demonstrate the capacity of our framework to learn significant MS-relevant information from conventional MRI data. Notably, a pre-trained CNN was able to identify MS patients with an accuracy similar to a classical machine learning analysis, in which the FLAIR lesion load was used as input. This is quite remarkable, because the CNN model was considered to be naive by not being provided with any prior information on MS-relevant features such as hyperintense lesions. The subsequent visualization analysis, using heatmaps generated by LRP, revealed that the CNN model indeed uses (posterior) white matter lesions as primary information source. In addition, other information, e.g. in normal-appearing white and gray matter (e.g. the thalamus) have been found useful by the CNN model."}, {"section_title": "Related work", "text": "Compared to other neurological diseases, in particular AD, only a few MS studies exist that employ machine learning methods outside the scope of lesion segmentation. We think that the main reasons are (1) [15, 16, 77] and (4) predict conversion from clinically isolated syndrome to MS [21, 78] . Deep learning architectures have so far been implemented for lesion segmentation [28] [29] [30] , predicting MS based on binary lesion masks [32] , modelling brain and lesion variability [79] and finding differences in normal-appearing brain matter based on T1-weighted and myelin images [80] . To the best of our best knowledge, the present study is the first study employing CNNs and advanced visualization techniques for diagnosing MS based on the clinically most relevant MRI sequence (i.e. FLAIR).\nIt is generally recognized that, especially in the medical field, it is very important that classification decisions are reasonably explained even in light of high accuracies (which are no guarantee for a -from a human perspective -sensible discrimination strategy [66, 81] ). Although a number of methods exist that generate individual heatmaps [34, 38, 67, 82] , we focused here on the LRP method [37, 65, 66] which has a solid theoretical framework and has been extensively validated (see e.g. [41, 66, 69] ). Very recently, LRP has shown to be very helpful for explaining Journal Pre-proof J o u r n a l P r e -p r o o f cognitive states or AD diagnosis in deep neural networks trained on either functional or structural MRI data [40, 83] . To the best of our knowledge, these are the only applications of LRP in the neuroimaging field. In the present study, we demonstrated that LRP is capable of identifying reasonable areas supporting a MS diagnosis in addition to features needing further clinical validation. Those areas have been shown to be robust using gradient*input as a different visualization method. By this, we have shown that those heatmaps can be very valuable in explaining decisions of neural networks trained on small sample sizes and to verify whether an algorithm has learned something meaningful (i.e. matching domain knowledge) or just spotted biases or artifacts in the data (see also [38, 66] ). CNNs learn to identify relevant areas beyond lesions. The CNN model primarily focuses on lesions, but relevance has also been attributed to gray matter areas such as the thalamus, which is known to be affected in MS from earliest disease stages [6, 85] . To further investigate what the CNN model learns beyond lesions, we repeated the analysis on lesion filled FLAIR data."}, {"section_title": "Key findings", "text": "J o u r n a l P r e -p r o o f\nAs expected, the balanced accuracy as well as AUC decreased (by almost 17 and 6 percentage points respectively) and relevance has shifted away from regions which typically contain hyperintense lesions. The region that was assigned most relevance after lesion removal was the corpus callosum. While the corpus callosum is generally susceptible to demyelinating lesions [86] [87] [88] the literature also suggests further biomarkers such as axonal loss and diffuse atrophy [88, 89] or narrow T2 hyperintense bands along the callosal-septal interface [87] . The fornix, even though it contains a very small amount of lesions (see supplementary Figure 4 and [90] ), is assigned positive relevance with lesions and an increased relevance without lesions. It has been\nshown that lower fractional anisotropy in the fornix is exhibited in MS subjects in comparison to healthy controls [91, 92] . Additionally, external capsule and superior cerebellar peduncle receive only positive relevance after lesion removal, which were found to be affected in MS patients [93, 94] . These results are generally in line with other machine learning studies finding differences in normal-appearing brain matter in MS patients [17, 18, 80] . It would be very interesting to further investigate whether our findings correlate with underlying pathological mechanisms only demonstrable by advanced MRI sequences such as diffusion weighted imaging or magnetization transfer imaging.\nTransfer learning improves learning across diseases and MRI sequences. In recent years, transfer learning has been successfully employed in brain lesion segmentation [62] and AD classification [60, 63, 95] . The latter studies used either autoencoders trained on MRI data or natural images [60, 95] or used one AD data set for pre-training and another AD data set for fine-tuning [63] . In the present study, we have shown that transfer learning can also help in learning (1) across diseases (AD to MS) and (2) across MRI sequences (MPRAGE to FLAIR) exhibiting different magnetic field strengths (1.5 and 3 Tesla). We demonstrated that not only the balanced accuracy increases drastically (about 16 percentage points), but also that LRP leads to much more focused heatmaps concentrating on (posterior) periventricular lesion areas. Given that our pre-trained model performed similar to a classical machine learning analysis using FLAIR lesion load as a classical biomarker in MS, we believe that larger data sets might allow for outperforming models based on lesion masks in the future. Additionally, we are convinced that our approach -given a reasonable data basis -might also be very useful in answering more complex questions such as predicting disease progression.\nJ o u r n a l P r e -p r o o f"}, {"section_title": "Limitations", "text": "The main limitation of this study is the limited sample size. Although a sample size of = 147 n is comparable with other deep learning studies in the neuroimaging field [27] , it is generally considered to be too low to learn robust representations from the data and to generalize to other data sets. To partly alleviate this problem, we pre-trained our network on ADNI data ( = 921 n ) and fine-tuned it on the MS data. By visualizing the average heatmaps for MS patients, we show in addition to a balanced accuracy of 87.04 % that the CNN captures MS-relevant information by focusing on posterior ventricular regions usually characterized by a high rate of MS lesion incidences. Nevertheless, future studies should verify our results in larger data sets, preferably coming from different sites. Another limitation, related to the first one, is that we were limited in the choice of architecture used for the CNN analysis. Very deep networks with a high capacity easily overfit on data sets with less than hundreds or thousands of samples per class. Furthermore, since we use volumetric data the additional dimension as compared to 2D images causes each layer to consume substantially more GPU memory, which makes it a strongly limiting factor in architecture design. However, we found a relatively simple CNN architecture to be successful together with several regularization methods (drop out, L2-regularization and early stopping).\nMoreover, by registering the MRI data only linearly to MNI space, the regions contained in both atlases only roughly correspond to individual anatomical locations. On the other hand, non-linear registration can lead to strong deformations, in particular in patients, and we show here that our CNN model can also operate on a more native level (in accordance with [96] ). To be able to make more specific anatomical claims in individual subjects, future studies might use individual atlases.\nAnd finally, heatmaps do neither allow to determine the underlying pathological mechanism (e.g.\natrophy, demyelination or axonal loss) resulting in assigning a voxel to be relevant or to assess interactions between voxels. For this, one would have to take a deeper look into the specific filters that have been learned throughout the training process in combination with MR sequences more sensitive for certain tissue damage (e.g. diffusion weighted or myelin imaging). Nevertheless, we still believe that heatmaps can be very helpful in supplementing individual disease diagnoses by providing a simple and intuitive explanation."}, {"section_title": "Conclusion", "text": "J o u r n a l P r e -p r o o f\nIn conclusion, we have shown that our framework helps in uncovering CNN decisions for diagnosing MS based on FLAIR data using LRP. In particular, we demonstrated that (1) CNN models pre-trained on AD data are capable of successfully separating MS patients and controls on a typically sized neuroimaging cohort and (2) LRP is not only very valuable in explaining individual network's decisions, but also in generally helping to assess whether CNN models have learned significant features. Notably, our CNN models focus on hyperintense lesions as primary information source, but also incorporates information from lesion location and normal-appearing brain areas. We see a high potential in the combination of CNNs, transfer learning and LRP heatmaps and are convinced that our framework might not only be helpful in other disease decoding studies, but also for answering more complex questions such as predicting disease progression or treatment response in individual subjects."}, {"section_title": "Funding", "text": "We acknowledge support from the German Research Foundation (DFG, 389563835), the Manfred and Ursula-M\u00fcller Stiftung and Charit\u00e9 -Universit\u00e4tsmedizin Berlin (Rahel-Hirsch scholarship and Open Access Publication Fund)."}, {"section_title": "7.", "text": "J o u r n a l P r e -p r o o f segmentation with a cascaded 3D convolutional neural network approach, NeuroImage "}]