[{"section_title": "Abstract", "text": "Abstract-In the field of Computational Anatomy, biological form (including our focus, neuroanatomy) is studied quantitatively through the action of the diffeomorphism group on example anatomies -a technique called diffeomorphometry. Here we design an algorithm within this framework to pass from dense objects common in neuromaging studies (binary segmentations, structural images) to a sparse representation defined on the surface boundaries of anatomical structures, and embedded into the low dimensional coordinates of a parametric model. Our main new contribution is to introduce an expanded group action to simultaneously deform surfaces through direct mapping of points, as well as images through functional composition with the inverse. This allows us to index the diffeomorphisms with respect to two-dimensional surface geometries like subcortical gray matter structures, but explicitly map onto cost functions determined by noisy 3-dimensional measurements. We consider models generated from empirical covariance of training data, as well as bandlimited (Laplace-Beltrami eigenfunction) models when no such data is available. We show applications to noisy or anomalous segmentations, and other typical problems in neuroimaging studies. We reproduce statistical results detecting changes in Alzheimer's disease, despite dimensionality reduction. Lastly we apply our algorithm to the common problem of segmenting subcortical structures from T1 MR images."}, {"section_title": "INTRODUCTION", "text": "T HE Computational Anatomy project has been the study of shape and form via the infinite dimensional diffeomorphism group, one-to-one smooth transformations between anatomical coordinate systems [1] , [2] , [3] , [4] , [5] , [6] , [7] , [8] , [9] , [10] , [11] , [12] , [13] . For comparison of coordinate systems we have been constructing geodesic positioning systems [14] , defining diffeomorphic correspondences ' which transfers information from one anatomy to another and provides both geodesic coordinates as well as metric length between coordinate systems of the shapes. The Riemanian metric at the basis of diffeomorphometry has now been examined in multiple settings of smooth submanifolds including curves, surfaces and volumes [14] , [15] , [16] , [17] , [18] , [19] . We construct the geodesic positioning via the design of optimal control strategies flowing information from one anatomical coordinate system onto another. The flows of the coordinates t 7 ! ' t act to transfer the image information, with the controls, the vector fields t 7 ! v t , acting as the push. They are related via the dynamics of the system _ ' \u00bc v '. The fact that the geodesic paths are encoded by the initial vector field in the tangent at the identity provides us with geodesic coordinates.\nFor the study of neuroanatomy we have been focussing on shapes formed by the submanifolds, the subcortical and gyral structures in R 3 . As we have demonstrated, the registration information which is supported on the interior to homogeneously colored subvolumes is ill-posed. The deformation is only uniquely determined normal to the level lines of the observed imagery. This is the normality condition described in [16] . This implies that only the discontinuity of the MR imagery supports registration information about the template coordinate system being mapped. At 1 mm resolution the boundaries of the subcortical structures are informative about the anatomical phenotype as seen through the MR modality. We can view the proper solution of the mapping problem at 1 mm scale as interpolating the discriminating registration information onto the boundaries of the level sets.\nThe natural probabilistic representations of the anatomical phenotype is therefore singular and supported on the boundaries of the subvolumes. So on the one hand, powerful parametric models for representing subcortical anatomical variation as observed in MRI as geometric dense subvolumes are models of the statistical variation of the boundaries of the substructures [20] , [21] , [22] , [23] . These are generated empirically via statistical characterization of 1,000s of diffeomorphic mappings in empirical populations. On the other hand, most of the available large scale programs including -FreeSurfer [24] , SPM [25] , FSL [26] , MRIStudio [27] to name some -for analyzing brains generate dense subvolume segmentations as outputs. Many of the large scale studies publish dense segmentations of structures, as well, examples being the ADNI and BIOCARD dementia studies, and PREDICT a Huntington's disease study. In the first two cases the temporal lobe structures including amygdala, hippocampus and entorhinal cortex (ERC); in the latter it is the basal ganglia and motor areas.\nThis paper focusses on a method of going directly from parametric bases representing the statistical randomness of shape on the brain submanifolds to dense segmentations representing the interiors of shapes. We call this reduction of the high dimensional dense segmentation to a parametric representation parametric diffeomorphometry. This method also solves the problem associated to filtering noise from the segmentations, since it solves the Bayes problem of parametric mapping based on a robust prior distribution which accommodates anatomical variation but is of reasonable dimension. It is parametric diffeomorphometry because it replaces the high dimensional geodesic coordinates in the tangent space at the identity used for shooting the geodesic connection of one coordinate system to another, to a basis representation supported on the shapes. This as well turns the high dimensionality of dense imagery such as segmentation into parameters upon which statistics can be performed directly. The subcortical structures occupying order O (10 6 ) dimensions in our MRI (1/3 of the brain), are encoded via roughly O(10 2 ) dimensions via the basis. Our method generalizes the notion of parametrizing the tangent space at the identity in a sum of sparse features, such as control points in Durrleman [28] vertices of discrete surfaces and curves in Glaunes et al. [29] , [30] or originally labelled landmark matching in Joshi [31] or Vaillant et al. [32] , so that the state is finite dimensional rather than the dimension of the diffeomorphism themselves. Instead of representation of the original state via singular points, here we use the geometries of the subcortical surfaces themselves to define a singular representation. Upon this, complete orthonormal bases are defined using empirical statistics or Laplace-Beltrami eigenfunctions. A significant departure from our previous surface based work, is that we extend the state also to include the dense image which is transported, allowing us to define the matching term between the dense interior of the shape as it is transported and the target segmentation. This extends the approach of [33] from point clouds to surface structures with volumes forming the state. This solves the problem originally tackled by Qiu et al. [34] of doing shape analysis and large deformation diffeomorphic metric mapping (LDDMM) supported on substructures, but allowing us to perform the mapping directly onto segmentations rather than target surface meshes. In the setting proposed here, there is no triangulation step of the dense segmentations, and then subsequent surface mapping onto the subvolumes. This solves the high dimensionality problem of doing direct volume mapping as in Beg et al. [35] onto dense segmentations, while avoiding estimating a high dimensional nuisance parameter: the values of v over the homogeneous interiors of the shapes. The prior distribution providing the efficient encoding of the subcortical structures is directly brought to bear in associating coordinates to the target segmentations.\nWe show the application of this methodology for embedding essentially the infinite dimensional segmentations which are now commonly available in the community to parametric geodesic coordinates of structures from three commonly available datasets. These data sets include ADNI [36] and PREDICT-HD [37] , with parcellations performed with FreeSurfer and University of Iowa's quality controlled neural network technologies respectively, which are used to illustrate segmentations of subcortical structures which are now commonly available in large studies. We also include the BIOCARD [38] study of cognitive decline in preclinical normals. We focus on BIOCARD with its three temporal lobe structures analyzing hippocampus, amygdala, and entorhinal cortex segmentations, because we can carry out a complete statistical analysis demonstrating use of geodesic coordinate via our parametric basis representation for statistical hypothesis testing on the etiology of the disease. We analyze the use of the geodesic coordinates coupled to the prior distribution as providing automated methods for quality control, i.e. for outlier rejection and detection of common problems which occur in large neuroanatomical studies. In particular, we show example segmentations from the ADNI and PREDICT datasets that exhibit strong artifacts, demonstrating the robustness of this approach. The BIOCARD and grayscale image datasets analyzed consist of more carefully controlled data, and demonstrate typical performance."}, {"section_title": "GEODESIC POSITIONING RELATIVE TO SUBMANIFOLDS OF NEURO-ANATOMY", "text": "For purposes of computing the geodesic coordinates we generate our minimizing length geodesics as variational minimizers along the path of the Lagrangian or kinetic energy L\u00f0';\n, paralleling the computation of geodesic to a least-action principle. For this we take pairs of diffeomorphisms in the group G, the identity and any other element \u00f0id; g\u00de 2 G \u00c2 G, and construct flows which connect them via the least-action inf _ '\u00bcv';' 0 \u00bcid;' 1 \u00bcg\nWe can represent the norm and inner product in V , a space of smooth vector fields, explicitly via L a matrix differential operator defining the linear form m \u00bc Lv dual to the vector field, and defining the norm kvk 2 V \u00bc \u00f0Lvjv\u00de and inner-product between v; w 2 V according to\nWhen Lv\u00f0dx\u00de \u00bc m\u00f0x\u00dedx has a vector density m, then\nWe call m \u00bc Lv the \"Eulerian momentum\" and L : V ! V \u00c3 . We impose more structure on this V -space by defining it to be a reproducing Kernel Hilbert space with kernel K\u00f0\u00c1; \u00c1\u00de the Green's function of L. Throughout we define L implicitly by choosing K to be a shift invariant Gaussian with 4 mm standard deviation times the identity matrix. It is a Hermitian positive definite highpass operator which enforces smoothness. Note that with this choice of kernel, L is not a classical differential operator, but acts on all (an infinite number of) derivatives.\nGeodesic positioning and coordinates arise from the operation of finding optimizing geodesics associated to the least-action principle of (1) \nConversely, geodesic coordinates are given by the mapping from the group to vector field which generates it (assuming uniqueness), denoted Log id \u00f0\u00c1\u00de : G ! V . The Riemannian logarithm is given by the vector field v at t \u00bc 0 satisfying geodesic connection to g of (1):"}, {"section_title": "The Inexact Matching Problem", "text": "We now introduce the geodesic positioning problem for inexact matching of coordinate systems. We represent subcortical structures in the brain as submanifolds M & R 3 , concentrating our statistical models as singular representations supported on the neuroanatomical structures. Our goal is to transfer the basis coordinates encoding variability of the population supported on the template structures onto the dense MRI image volumes as represented via their segmentations. The left two panels of Fig. 1 depicts the subcortical templates over which the basis is defined. The right top shows four typical segmentations which are available from the ADNI and PREDICT-HD studies depicting thalamus, amygdala, putamen, and hippocampus. The right bottom shows corresponding triangulated meshes which have been rendered demonstrating the meshes are no better in quality. Notice the several appendages protruding from the surfaces.\nThe goal is to calculate geodesic coordinates of the dense segmentations. Our procedure embeds the finite-dimensional basis as a coordinate system on these segmentations. The resulting deformed template has an associated lowdimensional coordinate encoding.\nWe want to match the interior of the parameterized template shape with the target segmentations based on force coming from the boundaries of the subcortical structures. We fix, in the following, a set U of parameters and a measure h so that \u00f0U; h\u00de is a measure space. We can think of the state of our system to be made up of both the surface local coordinate mappings, M \u00bc f\u00f0U\u00de for f : U ! R 3 , as well as a collection of C 2 f1; 2; 3; . . .g dense images concatenated into a single vector valued function with C components I : V & R 3 ! R C , the images vanishing on the boundary of V. A typical situation is when U is a Euclidean subset U & R 2 , h is Lebesgue's measure, and f is a surface parametrization. In place of an open subset, U can be another surface (e.g., the unit sphere), allowing for the parametrization of genus-zero closed surfaces. Another important practical example is when U is a finite set, say f1; . . . ; Mg, with h the counting measure, in which case a function f : U ! R 3 is another way for representing a finite point set ff\u00f01\u00de; . . . ; f\u00f0M\u00deg & R 3 . This latter example is useful in particular when the considered objects are triangulated meshes, since we have used vertex representations as our surfaces in brain and cardiac studies [34] , [39] , [40] , [41] , [42] , [43] , [44] , [45] . When considering multiple shapes at the same time, U is typically a disjoint union of sets, each of these sets parameterizing a surface. Generally, C corresponds to the number of subcortical structures being studied, each component of the image vector being a binary segmentation for one structure. For our grayscale image matching example, C \u00bc 1. We therefore include in the dynamical system the flow of the submanifolds and the template image t 7 ! \u00f0f t \u00bc ' t f 0 ; I t \u00bc I 0 ' \u00c01 t \u00de, the state becoming q t \u00bc \u00f0f t ; I t \u00de. The control is the vector fields t 7 ! v t 2 V with system dynamics\nwhere\n@ @z \u00de T operator places partial derivatives along rows, and the second term denotes matrix multiplication between DI\u00f0x\u00de and v\u00f0x\u00de at each x and takes values in R C . The notation here assumes images are differentiable, although since our implementation uses discrete derivatives Fig. 1 . The problem of associating geodesic coordinates to subcortical templates, to represent the dense segmentations, is depicted here. Left: Depiction of subcortical manifolds representing amygdala, caudate, hippocampus, putamen, thalamus and ventricles. Second from left: sections through the MRI depicting the outlines of the surfaces striking the subvolume. Right: Segmentations (top) and corresponding isosurfaces (bottom) of amygdala, thalamus, hippocampus, putamen structures from the ADNI dementia study (columns 1,2) and PREDICT-HD Huntington's disease study (columns 3,4).\nthis assumption is not necessary. The manifold flows in the direction of the velocity field, and the imagery follows the optical flow equation.\nWe force the flow so as to minimize the matching cost of the template I 0 under the geodesic, to a target J :\nC , where each of the C target images contains a noisy observation of a corresponding segmentation (or J is a corresponding grayscale image and C \u00bc 1). We take as an endpoint matching term the integrated squared error (L2 norm) of the C segmentation images according to\nwith\nis the cth component of the deformed atlas (target) image vector, and s"}, {"section_title": "2", "text": "Ic is a positive scalar determining the relative weight of the cth image in the cost function.\nWe solve the matching problem with an optimal control approach, the diffeomorphisms and vector fields are used as controls that push the forms (submanifolds or images) . The optimal control minimizes the running cost or kinetic energy\n, and the target image J contributes to the cost function through the endpoint matching term E\u00f0\u00c1\u00de, which is assumed smoothly varying in its argument as is the case for integrated square error defined above. (3) with smooth endpoint cost E\u00f0\u00c1\u00de, the variational problem becomes\nSolving this problem gives the geodesic coordinates of anatomical shapes."}, {"section_title": "Controlling Flows with Singular Geodesic Coordinates", "text": "We notice that the coordinates for geodesic positions are high-dimensional objects v 0 2 V . We reduce dimension and build robustness using PCA and computation of LaplaceBeltrami bases [46] which are supported on the gyral and subcortical structures via two-dimensional local charts\nWe control the behaviour of the geodesic positioning by considering a subset of geodesic flows, this subset of flows forms our prior model for Bayesian estimation of the geodesic positioning and generation of coordinates of the noisy segmentation. The initial vector fields for the geodesic are singular in the background space of R 3 , supported over the manifolds via a prior parametric model which is of the form\nfor some vector valued function (or more generally measure) p 0 : U ! R 3 . In other words the surface at time 0, f 0 \u00f0u\u00de, has a vector field supported on it, p 0 \u00f0u\u00de, as illustrated in Fig. 2 left. For this reason we refer to p 0 as the singular geodesic coordinates. We obtain a smooth velocity field v 0 , supported everywhere in space, by convolving p 0 dh with the reproducing kernel Hilbert space kernel K\u00f0\u00c1; \u00c1\u00de, as illustrated in Fig. 2 right. We will use the shorthand notation v 0 \u00bc K \u00c1f p 0 as well as\n: R U K\u00f0f\u00f0\u00c1\u00de; f\u00f0u\u00de\u00dep 0 \u00f0u\u00dedh\u00f0u\u00de ; (10)\nwhere \u00c3 refers to a vector transpose (column to row). \nwhere Dv \u00c3 t refers to the transpose of the 3 \u00c2 3 Jacobian matrix of v t , r 1 K returns the gradient of the kernel in R 3 with respect to its first argument, as a column vector.\nThe constraint gives us our Constrained Variational Problem supported over the subset of geodesics.\nassociated to constraint (9) , with Exp satisfying (3) and smooth endpoint E\u00f0\u00c1\u00de, the control problem becomes arg min\nSolving this problem gives the geodesic coordinates of anatomical shapes, constrained to anatomical submanifolds."}, {"section_title": "The MAP Estimation Problem for Parametric Diffeomorphometry", "text": "Our random orbit model is at hand. We need only generate random realizations of the initial vector fields parametrized by the p 0 field, inducing a prior distribution on geodesic flows. We focus our empirical statistical modelling on the geodesic by statistically modelling the function p 0 : U ! R 3 , through a low dimensional prior distribution, by expanding p 0 through a mean b 0 and N basis functions fb n ; n \u00bc 1; . . . ; Ng,\nWe consider the coefficients fa n g solving the control problem as the parametrization of the anatomical shape. The resulting procedure for mapping surfaces onto dense image segmentations is to reduce dimension by moving the vector field v 0 which is supported on all of 3D space to the singular function p 0 supported on the submanifolds as well as to model the p 0 field as an element in a Hilbert space spanned via a low-dimensional basis.\nTo build our prior distribution, we use the matching technology to generate a large number of empirical maps on p 0 , and then use principal component analysis (PCA) to calculate statistics on the empirically observed random variables. Our Gaussian model is induced by taking a n Gaussian, zero-mean and finite trace so that\nan finite where E\u00bd\u00c1 denotes expectation. Then p 0 \u00f0\u00c1\u00de is a Gaussian random field, mean b 0 and induced covariance operator S p 0 p 0 : U \u00c2 U ! R 3\u00c23 supported over the manifolds reconstructed from the PCA basis\nwhere \u00c3 refers to the vector transpose, implying the covariance is a 3 \u00c2 3 matrix for each pair u; u 0 . In turn this implies the vector fields v 0 \u00f0\u00c1\u00de \u00bc K \u00c1f p 0 2 V are Gaussian with mean field, and covariance operator\nwhere with some abuse of notation we define the linear operator\n. This gives us our Random Orbit Model. Statement 3 (Random Subcortical Orbit Model). We induce our random orbit model according to the geodesic equations\nDrawing Gaussian random field p 0 with mean and covariance m p 0 ; S p 0 p 0 , the geodesic solutions of (17) given by\nBy constraining the random orbit of geodesics supported over the subcortical structures in a PCA basis, we can state the MAP problem."}, {"section_title": "Statement 4 (MAP Estimation). Our MAP estimator takes the form", "text": "In this work we consider basis functions determined through PCA as in [20] , [21] with parameters a as Gaussian variates. Since our basis is chosen to be orthonormal in the space\nWe have also considered the inclusion of bases such as the eigenfunctions of the Laplace-Beltrami operator [46] . We trained on the order of 1,000 surfaces, performing diffeomorphic surface mapping from a template M onto the targets with inital velocity defined as in (9) [29] . We performed PCA on the functions p 0 corresponding to each target, generating a basis representation of the anatomical surfaces. Shown in Fig. 3 are examples of temporal lobe structures defined through geodesic positioning Exp id \u00f0v 0 \u00de \u00c1 M within this model, revealing the generative nature of our prior distribution. The surfaces are laid out spatially according to the first 2 basis functions, with the mean shape in the center."}, {"section_title": "Solution via Adjoint Method", "text": "We consider the problem of minimizing the cost function, with the state q \u00bc \u00f0' f; I ' \u00c01 \u00de, not including the prior:\nwith dynamics written in matrix form\nOur approach is to enforce the dynamics using Lagrange multipliers. \nnent for each of the C images being matched), and p \u00f0u\u00de 2 R 3 , and augmented cost function\nwhere\nExtremizing with respect to p; q, with perturbations \u00f0q; p\u00de ! \u00f0q; p\u00de \u00fe d\u00f0q; p\u00de, q 0 fixed, gives the necessary conditions for an optimizer, with linear dynamics for and boundary conditions:\nWe may solve these equations using the adjoint algorithm as in [14] , [20] , [21] , [47] , [48] , [49] , [50] . For the parametric case the perturbations are spanned by the basis according to p 0 ! p 0 \u00fe b n da n , n \u00bc 1; . . . ; N giving us a new Eqn. (25) satisfying\nWe summarize these results in Algorithm 1. Our specific implementation, where anatomical manifolds are discretized as triangulated meshes, is discussed in the appendix. Because we choose to work with eigenfunctions, the covariance is diagonalized and each entry in the matrix inverse is taken separately by fractional inverse giving the update in step (6) . Equation (24) \nThe discrete implementation is shown in the Appendix."}, {"section_title": "EXPERIMENTS", "text": "We first apply our algorithm, with I 0 and J as a set of segmentations, to an analysis of the temporal lobe structures hippocampus, amygdala, and entorhinal cortex, in populations of patients being studied for neurodegenerative disease. The ADNI data set is also being examined in the temporal lobe and contains amygdala and hippocampus only, with segmentation coming from the automated segmentation methods. The PREDICT-HD data set allows us to focus on motor structures and includes hippocampus but not amygdala. We build a model by performing PCA on the surface mappings of left side structures from the BIOCARD dataset as described in [21] . Templates from which the mappings are performed are constructed using surface template estimation from the population of structures as in Ma [51] . The template is mapped via surface mapping onto each element in the population, from which covariances are empirically generated. We choose the first 47 eigenfunctions of the covariance for our basis functions fb n g, accounting for 95 percent of the covariance's trace. We have observed that this cutoff is near the saturation point for mapping quality metrics as a function of dimension. In fact, our deformed template vertices are on average within 0.4 mm of those obtained with 160 dimensions which is well past the saturation point. This distance should be considered in the context of a typical 1 mm resolution for our applications, and an average distance of 1.4 mm between vertices on the same face of our triangulated surfaces.\nFor each of the three datasets, a template segmentation image I 0 was constructed for each structure at the same resolution as the target segmentations. This corresponds to 0:97 \u00c2 0:97 \u00c2 2 mm (with low resolution in the anteriorposterior direction) for the BIOCARD dataset, and 1 \u00c2 1 \u00c2 1 mm for the other datasets. The template surfaces contouring hippocampus, amygdala, and entorhinal cortex, are depicted in the center of Fig. 3 .\nLast we apply our algorithm with I 0 and J as grayscale T1 MR images. Our goal is to simultaneously identify parametric geodesic coordinates of each subcortical motor structure (caudate, putamen, globus pallidus, as well as the thalamus), from the T1 image data directly. To this end we include a dataset obtained as part of a study of children with attention deficit disorder and autism spectrum disorder [52] . Patients have a mean age of 10.2 yrs, and T1-weighted 3D-volume MPRAGE coronal images were acquired from a Philips 3T Achieva MRI scanner (Best, the Netherlands) using an eight-channel head coil (TR = 7.99 ms, TE = 3.76 ms, Flip angle = 8\n, voxel size = 1 mm isotropic). Eight subcortical structures were segmented manually. Triangulated atlas surfaces, f 0 , were constructed from the manual segmentations. We use the 30 smoothest (corresponding to the smallest eigenvalues) Laplace-Beltrami eigenfunctions per structure as a basis for dimensionality reduction, since we do not have training data for PCA. We take b 0 \u00bc 0 and s 2 an given by the reciprocal of one plus the magnitude squared of the eigenvalue of b n . For typical triangulated surfaces with about 1,000 vertices, this is a 100-fold reduction in the dimensionality of the problem. As compared to the full 256 \u00c2 200 \u00c2 256 image this is a roughly 10,000-fold reduction in the dimensionality of the problem."}, {"section_title": "Parametrization of Target Segmentations", "text": "For each subject we rigidly align the set of left temporal lobe binary segmentations to the template's space using trilinear interpolation. For the BIOCARD dataset we use manually placed landmarks to calculate this rigid transform, while for the other datasets we use unlabelled segmentation data only.\nWe apply our implementation of Algorithm 1 using the available segmentations as image data, with s 1 \u00de, where I is the template image, f is the template surface. Fig. 4 shows examples from the PREDICT-HD dataset of the overlap of the interior segmentation of the template hippocampus I 0 ' \u00c01 1 superimposed on the target. The target segmentation is shown in yellow with the deformed hippocampus shown in blue. The region where they overlap is shown in white. The target image contains noisy components (appendages or leaks on the lateral aspect of the hippocampal body, a typical unwanted artifact in this dataset), which are filtered out by the finite dimensional representation of the shape in the geodesic coordinates of the PCA basis.\nFor another pair of examples, this time from the ADNI study and including hippocampus and amygdala, Fig. 5 shows the segmentation data I 1 as isosurfaces. The target image contains noisy components (blobs, disconnected parts, a typical unwanted artifact in this dataset produced by FreeSurfer) which are filtered out by the finite dimensional representation the shape in the geodesic coordinates of the PCA basis. The other aspect of the state, the surfaces f 1 , are shown with the first two components of their geodesic coding (bottom). Here the deformed atlas hippocampus/amygdala is shown in blue/red, and the target in yellow/cyan.\nFor the BIOCARD dataset we performed mappings onto the entorhinal cortex as well. One example from the BIO-CARD dataset is shown in Fig. 6 . The top left depicts the overlap of the template I 1 with the target J. In addition to the color scheme described, green depicts the deformed template entorhinal cortex, while magenta depicts the target entorhinal cortex. White depicts agreement, while other colors (RGB sums of template and target) depict misclassification errors. The middle left shows isosurfaces of I 1 compared to isosurfaces of the target J. The deformed template surfaces f 1 and first two parameters of their encoding are shown at the bottom left.\nTo examine the effect of the 47-dimensional prior distribution, we mapped the template onto the greater than 300 scans in all 110 subjects. To examine accuracy we computed the volume of each structure and the closeness of the mapped surfaces onto each of the three structures. Shown in the right of Fig. 6 are the comparisons between volumes generated by the finite-dimensional basis and the original triangulation of the quality-controlled segmentations used for studying the disease already published in [23] . If these are identical then every sample will lay exactly on the black line. The greatest discrepancies occurs for the entorhinal cortex which is a very thin laminar structure, often only two voxels in laminar thickness at the original resolution, and generally not reliably characterized by volume. To view these discrepancies in context we calculated the variability which can be expected by examining volumes calculated from the dense voxel segmentation, versus calculated from the triangulated surface. We see for amygdala and hippocampus that the error is on the order of the noise of the boundary, roughly 2-4 percent. For entorhinal cortex we see a slight increase in discrepancy."}, {"section_title": "Outlier Detection: Overlapping Segmentations, Poor Alignment, Extreme Shape", "text": "In large studies being able to detect large discrepancies between the mapping and the target is important. Having a prior distribution allows us to test the resulting solution against the prior for outliers. The three kinds of errors which the algorithm accommodates is overlap of structures, poor initial rigid alignment, and highly distorted shapes.\nTo study resolution of inconsistent segmentations, we use the BIOCARD dataset. Since each structure was labelled individually, there are cases where anatomical definitions overlap. We choose three examples where the amygdala and hippocampus segmentations overlap with a Dice score of 0.096, 0.072, 0.062 (roughly a 5-10 percent overlap). The average overlap for the population was 0.0044, meaning that these examples overlap more than 10 times the average. Shown in the top row of Fig. 7 are these examples. Notice that instead of a clear boundary between the yellow hippocampus, and the cyan amygdala, there exists a large zone colored green. This region corresponds to voxels which have been identified as belonging to both the hippocampus and the amygdala. The segmentations generated by the algorithm shown in the bottom row do not overlap (beyond the linear interpolation applied when generating these slices). The algorithm assigns unique labels to each voxel for three example cases, including those in the green zone. The boundary identified between the two structures will be the most likely, given our prior model for the shape of our temporal lobe structures. Fig. 8 shows examples of misregistered target segmentations depicted via isosurfaces of deformed templates I 1 and targets J which are overlayed with transparency. The misorientation becomes apparent by noticing that the body of the target hippcampus is curved the \"wrong\" way relative to the template. The deformed template surfaces, f 1 are shown in the bottom row, together with the first two dimensions of their coordinates, which are seen to take extreme values. In these examples, the registration is incorrectly rotated around the anterior-posterior axis by about 180 degrees. The segmentation performance is quite poor, but these cases represent quality control errors in the analysis of a large population. The prior as represented by the value of the cost\nsignals these outliers. Examining a set of 10 correctly registered cases and 5 misregistered cases leads to a signal to noise ratio of 2.81 between the two groups. Fig. 9 shows two extreme segmentation examples taken from the PREDICT-HD dataset. Again we use\nas a signal to separate 8 normal from 5 extreme surfaces, leading to a signal to noise ratio of 1.83. "}, {"section_title": "Statistical Analysis Pipeline", "text": "We have been using LDDMM as part of statistical analyses of large populations by quality controlling poor segmentations and triangulating them, before applying surface mapping and performing statistics. In this section we apply the parametric representation of the coordinates of the temporal lobe structures to the BIOCARD segmentations, removing the extra steps of triangulation and surface mapping. We compare the use of geodesic coordinates of the basis representation to previously published results on local (log Jacobian of ' 1 at each vertex) and volume measures [23] . The BIOCARD dataset [23] consists of the three temporal lobe structures associated to 342 brain MRI scans, consisting of 110 unique patients at up to five timepoints. They are divided into three groups: 11 clinical subjects who were diagnosed with Alzheimer's disease (AD) at the time of their last MR scan, 19 preclinical subjects who were not diagnosed with AD at the time of their last MR scan but were later diagnosed with AD, and 80 controls who did not develop AD. The temporal lobe structures were segmented and quality controlled, and a template surface generated, using procedures described in [23] .\nWe performed statistical analyses comparing the amygdala, entorhinal cortex and hippocampus subvolumes between the two groups (controls versus preclinical AD), modelling the local shape markers via linear and mixed effects. The model previously used in Younes et al. [42] takes the absolute volume and atrophy rate of the linear model as a function of age as different between the two groups. The mixed effects as used by Bernal-Rusiel et al. [53] corresponds to representing the noise in the measuring shape marker as corresponding to two different processes, one associated to the time series within a subject, and the second noise associated to the cross-sectional variation from subject to subject. The analysis includes age, gender and log intracranial volumes (calculated using coronal SPGR scans in Freesurfer 5.1.0) as covariates, and computes statistics at each vertex of the triangulated template surface returning p-values corrected for multiple comparisons using permutation testing [54] . The analysis uses a mixed linear effects model for each vertex v, scan j and subject s. For this, each subject's left and right structures (controls and patients) has been registered to the template, resulting in the computation of a normalized deformation marker measuring how much expansion/atrophy at vertex v of the template surface in registering it to subject s for scan j. The raw expansion/ atrophy measure is defined as the logarithm of the local expansion/reduction in surface area around the vertex, interpreted mathematically as a log-Jacobian on the template surface. This measure is then normalized for variations due to gender and intracranial volume by fitting a linear regression model that predicts the former by the latter, and taking the residual. This normalization is group independent.\nWe model the group variables g\u00f0s\u00de as equalling 1 if subject s belongs to the preclinical AD group and zero if the subject belongs to the control group. Our deformation marker model is given by the equation\nfor field of markers \u00f0\u00c1\u00de (either vertex or volume), MRI scan i \u00bc 1; . . . of subject s at age a. represents the noise, and is modeled as \u00bc n \u00fe h where n is a \"random effect\" that measures between-subject variation and h measures withinsubject variation. Both processes are assumed to be centered Gaussian, with variance rs The joint test statistic is computed from Eqn. (30) with familywise error rate calculated by evaluating the maximum S \u00c3 \u00bc : maxS\u00f0\u00c1\u00de over the field of statistics. The maximum value is compared to those obtained by performing the same computation a large number of times, with group labels randomly assigned to subjects. The p-value is given by the fraction of times the values of S computed after permuting the labels is larger than that obtained with the true groups. The p-values that were observed via the linear effects modeling of deformation markers are provided. The volume statistics shown provides p-values for the same linear effects model, also evaluated via permutations, in which the y is replaced by the structure volume, for which no multiple testing correction is required.\nTo demonstrate the validity of using the PCA basis, we performed the statistics using the original procedure already published and generated filtered surfaces based on fitting all of the subjects multiple images with the deformed templates f 1 . From these surfaces, the identical procedure described above was run. Shown in Table 1 are a comparison of these results.\nThe first two columns in the table show volume and vertex results from the already published methodology. We see for the preclinical subjects only the vertex measures are signalling in the entorhinal cortex. Shown in the right two columns are p-values generated identically but from the filtered surfaces generated using the parametric basis mappings. We see almost identical results. It appears as if the volumes in ERC are on the border of discriminating. As well the vertex measures are virtually identical in p-value (.03625 versus .0291)."}, {"section_title": "Grayscale Image Matching", "text": "We choose a set of five skullstripped T1 images for this study. After intensity normalization and linear alignment (rigid motion and scale), each of the five atlases were mapped pairwise to the remaining four. Laplace Beltrami eigenfunctions and eigenvalues for dimensionality reduction and regularization were computed separately for each template.\nData for one example is shown in the figures below. Left side of Fig. 10 shows the deformed atlas as well as the target T1 images, in coronal and axial views. By design, the procedure produces an alignment which is good in the neighbourhood of the subcortical structures, but poor in regions distant to them. Notice that the resolution of this dataset results in blurring of tissue boundaries on the order of 2 to 3 voxels.\nThe matching quality can be observed more readily by considering the alignment of gold-standard manual segmentations. The deformed atlas surfaces f 1 , as well as isosurfaces of the manual segmentations for both template and target, are shown in Fig. 11 . For more detail, the manual segmentations are shown as slices through image data in Fig. 10 right. Based on the gold standard segmentations we determine accuracy using the Dice coefficient. The results for each structure, averaged across each atlas and target, are left/ right caudate: 0.85/0.84, globus pallidus: 0.84/0.82, putamen: 0.87/0.88, thalamus: 0.92/0.92. The performance is greater than 0.8 for each structure examined, comparable to state of the art."}, {"section_title": "CONCLUSION", "text": "Active contours or snakes as first introduced by Kass et al. [55] is a a common tool in computer vision for edge detection, shape modelling, segmentation and visual tracking to name but a few applications [56] , [57] . Originally models assumed explicit parametrizations, where the deformation of an initially parametrized curve is computed by minimizing an energy functional composed of a smoothing term and a term that forces the curve towards the boundary where there is a considerable change in the image intensity. Intrinsic approaches for parametrization-free deformable methods emerged using level sets to allow evolving curves to automatically merge or split [58] , [59] , [60] , work which was later extended to deal with two-dimensional surfaces [61] , [62] . Region-based and region plus edge-based based methods have been developed in 2-D [63] , [64] , [65] , [66] , [67] , [68] , [69] , [70] , [71] , [72] , [73] and 3-D [74] , [75] , [76] , [77] , [78] . However, such approaches do not ensure that the evolving contour maintains important properties over time, like being simple, for example.\nThe general framework presented here departs significantly in that the equations of evolution are bound up with the notion that the shape is an element in a bigger metric space of shapes under flows of diffeomorphisms. This requires the vector fields satisfying the metric to have an associated number of derivatives inherited from the fact that the vector fields are in the reproducing kernel Hilbert space, and the evolution of the shape is geodesic under that metric. The focus on the indexing with respect to the submanifold boundaries implies the Hamiltonian methods of reduction which have emerged over the past five years in CA play a central role [48] , [50] .\nThe parametric embedding of diffeomorphisms results from the representation of the vector fields as a superposition of Green's kernels centered on the surface locations defined by the state in the Hamiltonian system, whose role is played by the surface flowing under the diffeomorphism. This gives an extremely parsimonious representation and one for which the Gaussian random field modelling is extremely efficient.\nOne of our contributions is to extend the actions to states including both surface and volumes. This has allowed us to demonstrate, that for structures such as subcortical structures in the brain, efficient low-dimensional representations are obtained via Hilbert space representations based on PCA and Laplace Beltrami functions which are supported on the subcortical surface domains. This should be contrasted to other sparse methods based on point-clouds which are not as efficient for representing the local geometry of closed surface subcortical structures. To demonstrate this point, we have included an explicit result showing accuracy of mappings using only rigid alignment (6 parameters), an approach with 16 control points (48 dimensions), and our 47 dimensional prior. Control points were randomly initialized on the cortical surfaces in proportion to their surface area (4 on amygdala, 8 on hippocampus, 4 on entorhinal cortex), and forced to repel one another until they reach equilibrium, covering the entire structure as seen in Fig 12 left . We calculate the distribution of surface to surface distances between deformed template isosurfaces and target segmentation isosurfaces, for 6 examples from BIO-CARD. The 95th percentile distances for amygdala are 2.2 mm (rigid) 1.5 mm (control points) and 1.1 mm (surface basis expansion), for hippocampus they are 2.3, 1.6, and 1.1 mm respectively, and for entorhinal cortex they are 4.3, 1.7, and 0.98 mm respectively. This shows higher performance with our method in every case. Additionally, the cumulative distribution function (CDF) of surface to surface distances for entorhinal cortex is shown in Fig. 12 right to emphasize the consistency of our method. For example, the 95 percentile distance for the worst case for the surface method is 1.1 mm, but for the worst control point case it is 2.4 mm, an unacceptable level of error for a structure that is only 3 mm thick.\nThis notion of exploration of embedding of the diffeomorphic flow in a basis supported over the initial shape manifold has been explored as well in several other papers now [20] , [21] . The significant departure here is to introduce an image action which combines both surface evolution and extrinsic volume evolution, allowing for a parametric decomposition of the connected subregions supported over their boundaries, while matching volume interiors. This does not assume surface to surface matching, which makes the procedure extremely robust and efficient. In this sense this circles us back to the inside-outside methods referenced above, in this topological setting that has been explored deeply by the Computational Anatomy community."}, {"section_title": "APPENDIX DISCRETE IMPLEMENTATION", "text": "We implement our algorithm using M as the set of M vertex points in a triangulated surface, i.e. U is the index set f1; . . . ; Mg. We specify f by the points f m for m 2 U. The quantities p m ; fm and pm are similarly defined. The nth basis function of our model, b n , will take a value b nm in R 3 at each vertex f m . We discretize time to into 10 equal steps, Dt \u00bc 0:1, and update f; p; f ; p using Euler's method. In this scenario the velocity field, as written in (9) \nFor numerical and computational reasons, we approach the evolution of image data indirectly. Rather than solving for _ I \u00bc \u00c0DIv and _ qI \u00bc \u00c0div\u00f0v qI \u00de, we introduce the diffeomorphisms ' \u00c01 0t (and ' \u00c01 1t ), which transform the images from the start point (and resp. endpoint) to time t. We compute them using semi-Lagrangian advection [79] , with an Euler integration scheme and linear interpolation:\nWe use this to explicitly solve for I and\nwhere spatial derivatives are calculated by centered difference. The boundary condition at t \u00bc 0 necessary for an optimal solution, as in (27) , for each n \u00bc f1; . . . ; Ng is written as\nWe solve the optimizing equations (33), (34), (36) , and (37) through Algorithm 2.\nAlgorithm 2. Discrete Implementation of Parametric Geodesic Coordinates 1) Initialize coefficients a 2) Calculate co-state p 0 \u00bc b 0 \u00fe P N n\u00bc1 b n a n ; 3) Given p 0 solve the dynamical system forward using (32) "}]