[{"section_title": "Introduction", "text": "Interpersonal communication relies on verbal conversation, but also on non-verbal cues such as facial emotional expressions. Interpreting facial expressions is crucial to recognition of the mental state of others and to successful social interaction. In Alzheimer's disease (AD), these skills are impaired [1] [2] [3] , and this impairment can lead to compromised communication and increased caregiver burden. AD is characterized at the early stages by an episodic memory decline, but other cognitive domains, like executive function and social cognition, may also be impaired [3, 4] .\nPrevious work yielded inconsistent results concerning AD patients' abilities to recognize emotions on faces. Most of the relevant studies report specific impairments for sadness, anger and fear [2, 5, 6] . However, only a few studies [3, [7] [8] [9] [10] investigated this ability at early stages corresponding to mild cognitive impairment (MCI) or prodromal and mild dementia stages of AD. MCI is a transitional state between normal ageing and dementia, where patients present some deficits of cognition with relatively preserved activities of daily living and autonomy [11] . AD at the MCI or mild dementia stage is characterized by episodic memory impairment, cognitive decline to various degrees, and entorhinal cortex and hippocampal atrophy [12] , as well as amygdala atrophy [13, 14] . As early atrophy occurs in brain regions crucial for emotion processing, it might be linked to social disinvestment and behavioural symptoms, early social cognition impairment, and emotion recognition impairment.\nEmotions can be classified into three categories: basic emotions (happiness, surprise, sadness, fear, anger, and disgust), motivational states, and social emotions [15] . Facial emotional expressions usually reflect someone's emotional state and are part of social communication. Fast early perceptual processing of emotional facial expressions involves the thalamus, amygdala, superior colliculus, and striate cortex [16] . Detailed perception and conceptualization of the emotion signaled by the face engages the striate cortex, fusiform face area, superior temporal gyrus (STG), amygdala, orbitofrontal cortex (OFC), basal ganglia, hypothalamus, insula and brainstem [17, 18] . As part of multiple specialized networks, the amygdala is particularly important for the recognition of fear [19] , the anterior insula for disgust [20] [21] [22] , the ventral striatum and the OFC for anger [23] , and the amygdala along with the supplementary motor area for the recognition of happiness [24, 25] .\nThe aim of this study was to better specify the early emotion recognition deficits at mild stages of AD and to disentangle their neuroanatomical correlates. We performed facial emotional expression recognition testing in patients diagnosed with AD at the MCI or mild dementia stage, as well as in healthy controls. Only the patient group had 3D structural magnetic resonance (MR) brain imaging. The patients and controls underwent tests to assess their ability to recognize facial expressions of anger, fear, disgust and happiness. Volumes of individual brain regions were obtained by processing the 3D T1-weighted images with MAPER (multiatlas propagation with enhanced registration) [14, 26] . Correlations between cognitive performance and regional volumes were assessed. Competing Interests: Prof. Hammers is the inventor of the atlases used in this paper. Maximum probability maps based on these atlases have been licensed to industry via Imperial Innovations plc. The other authors have declared that no competing interests exist. This does not alter the authors' adherence to PLOS ONE policies on sharing data and materials."}, {"section_title": "Material and Methods", "text": "This study is part of the PACO (personnalit\u00e9 Alzheimer comportement-personality, Alzheimer's disease, and behaviour) programme (Clinical Trial number 01297140), a national collaborative programme evaluating patients diagnosed with AD at the MCI or mild dementia stages. PACO prospectively explores the role of personality and social clue recognition abilities in the occurrence of behavioural disorders later in the disease course."}, {"section_title": "Participants", "text": "Thirty-nine patients diagnosed with AD at the amnestic MCI stage [11] (n = 15) or the mild dementia stage [27] (n = 24) and 39 healthy control subjects took part in this study. All participants were diagnosed by a board-qualified neurologist with extensive experience in neurodegenerative diseases. Patients were diagnosed either with mild stage dementia according to the Clinical Dementia Rating (CDR) 1 & 2 [28] , or with prodromal AD. Patients with prodromal AD, corresponding to amnestic mild cognitive impairment (aMCI) [29] had a clinical dementia rating criteria of 0.5 as set out in the Pr\u00e9AL study and the revised NINCDS-ADRDA diagnostic criteria suggested for research purposes [30] . Patients scored 20/30 or higher on the Mini Mental State Examination (MMSE [31] ); control subjects scored 28/30 or higher.\nFurther inclusion criteria were age (> 50 years), sufficient visual, auditory and French language skills to complete the clinical evaluations, and the availability of a caregiver able to report on patient personality and behaviour. Patients had no progressive or poorly managed psychiatric pathology, were not taking any antipsychotic or psychotropic medication unless chronically and at stable doses, had no evidence for non-AD related disease and were not depressed. All patients enrolled in the PACO program so far who had MR data available were included in the present study.\nInclusion required written consent from both the patient and a caregiver who was closely involved with the patient. In compliance with French law, the study protocol, inclusion criteria, and consent procedure were reviewed and approved by the responsible regional ethics committee (Comit\u00e9 de Protection des Personnes South-East III) and the Agence Nationale de S\u00e9curit\u00e9 du M\u00e9dicament et des Produits de Sant\u00e9. Participation was not remunerated.\nParticipants' demographical data are presented in Table 1 ."}, {"section_title": "Behavioural tasks", "text": "For the two cognitive tasks described below, photographs of faces and answer options were displayed on a computer screen. The tasks were not timed, but participants were asked to answer \nGender recognition performance. As expected, no significant difference was found between the patient and the control groups for any of the conditions on the gender recognition task (patients: 74% in average, controls: 79% in average) (Fig 2A) .\nEmotion recognition performance. On average, patients performed below controls on emotion recognition (57% vs 69%, p<10 \u221210 ). The two groups showed similar performance on the recognition of neutral expressions (p>0.05). When averaging the five degrees of morphing for each emotion, we found the patient group to be significantly impaired in the recognition of anger (mean performance: 48% vs. 64%, p<10 ), disgust (mean performance: 60% vs 68%, p = 0.049), and happiness (mean performance: 75% vs 84%, p<10 \u22124 ) (Fig 2B) .\nDetailed analysis of individual emotions by degree of morphing intensity. Analysis of individual emotions revealed a variable pattern (Fig 2C to 2F) . In comparison to the control group, the patient group was impaired in anger recognition with morphing intensities of 40-100% (from p<0.02 to p<10 ) and 100% (p<10"}, {"section_title": "Facial gender recognition task", "text": "This task measures the ability to discriminate the gender from face images in order to rule out deficits of attention, vision, or face structural encoding. As a control task, it ensured that any deficits observed in the facial emotional expression recognition task were specifically due to an impaired ability to recognize emotions. Photographic images of males and females were morphed with a gender-neutral face to create a gender continuum. The neutral face was obtained by averaging 20 male and 20 female faces. For each male and each female face, a range of six intensity levels of sex features (0%, 20%, 40%, 60%, 80% and 100%) was obtained by computer graphical manipulation [3] . Ninety-six items using 16 different models (eight women) were randomly presented, and participants were asked to determine whether the face was more feminine or masculine."}, {"section_title": "Facial emotional expression recognition task", "text": "This task evaluates the recognition of four basic emotions: happiness, anger, disgust, and fear [3] . Photographs of facial expressions were morphed with photographs of neutral expressions to create images representing varying degrees (20, 40 , 60, 80, or 100%) of the emotional expression. Twenty items for each emotion and 16 neutral faces were presented in random order. Participants were asked to select the label that best described the emotional expression, i.e. \"anger\", \"fear\", \"disgust\", \"happiness\", or \"neutral\".\nWe used various morphing degrees as we hypothesized that early-stage disease might only affect recognition of the subtlest facial emotional expressions (20% of intensity for instance), while recognition of more distinct expressions might still be intact.\nThe unprocessed results spreadsheet of the behavioural tests is provided as a supplement (S1 File)."}, {"section_title": "Structural MR image processing", "text": "MR image acquisition. Cranial MR scanning was performed at the time of diagnosis or no later than three months after the cognitive tasks, and only on patients. All sequences (3D T1, axial T2, T2\n\u00c3 and FLAIR) were acquired at 1.5 Tesla Philips Achieva scanners at university hospitals in Lyon and Saint-Etienne. A research engineer set up the exact same MR imaging protocol on both sites to ensure that acquisition parameters were identical at both participating hospitals. For volumetric analyses, 1 mm isotropic 3D T1 sequences without contrast injection were performed. Since our control group did not undergo MR scanning, we used healthy subjects who participated in the Alzheimer's Disease Neuroimaging Initative (ADNI) as a control group to compare the brain volumes of our patient group. The 3D structural MR images from the ADNI database were segmented using the same procedures as for the patient group. We selected a group of controls with the same age distribution and gender proportions. We only selected controls who scored 28 or more at the MMSE, and whose MR images were acquired on a 1.5 Tesla scanner. From 254 ADNI subjects matching these criteria, we randomly selected 70 for our control group. Two of the controls were removed on an additional exclusion criterion of having one or more brain regions whose volumes were smaller than the mean of the control group by more than three standard deviations.\nData used in the preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial MR imaging, positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of MCI and early AD.\nImage preprocessing. T1-weighted MR images were preprocessed with FSL FAST to correct for intensity variations due to field inhomogeneity, and to obtain masks of the brain and the intracranial space. We first applied pincram, a multi-atlas procedure for brain masking [33] , with parameters chosen so as to rapidly obtain a coarse, generous brain label. This label was applied to the original image, resulting in a masked version which was subjected to bias correction with FSL FAST.\nCorrected images were processed with pincram to label the intracranial space. Pincram requires atlas data (T1-weighted images with reference labels). A suitable atlas for intracranial masking was obtained by selecting subjects from the IXI cohort (n = 29, http://braindevelopment.org/) with intracranial masks obtained through reverse brain masking [34] . In a subset of the resulting pincram extractions of the PACO images (n = 18), we observed segmentation errors (partial exclusion of gyral crowns and partial inclusion of meninges). We therefore generated new atlases for pincram using PACO images where the extraction was rated successful on visual review (n = 21). These secondary PACO-customized atlases were then applied to all PACO images. No underinclusion problems were subsequently detected on visual review. The resulting brain masks included most of the peripheral cerebrospinal fluid (CSF), even in subjects with substantial brain atrophy. They were thus suitable for estimating the intracranial volume. However, the region anterior to the brainstem was frequently included in the mask, leading to mesiotemporal overestimations. Tighter masks labeling the brain rather than the intracranial space were thus additionally required.\nTo obtain accurate regional brain labels for the 39 PACO subjects, the images were pincram-extracted using the Hammers atlases [26, 35] . These atlases were generated by manual labeling of 83 brain regions in 30 T1-weighted cranial images of adults. With this extraction, most of the peripheral CSF was excluded from the label and the mask followed the gyral surface with high accuracy. However, for eight subjects, the procedure resulted in substantial over-or underinclusions. In seven of these cases, we reverted to the masks obtained with the PACO-customized atlases. In one subject, a suitable image could not be recovered because of substantial differences in the acquisition parameters. This subject was finally excluded.\nMAPER processing to segment brains into regions of interest. MAPER [36] was used to segment the PACO brain images into multiple regions (Fig 1) . MAPER has been shown to yield robust results, even for subjects with ventriculomegaly, which occurs frequently in MCI and mild AD, and yields accurate segmentations for images obtained in multicenter settings [14] . MAPER uses input in the form of multi-subject, multi-region input atlases. Here, we used the Hammers atlases (thirty subjects, manually segmented into 83 regions according to strict protocols) [26, 35] . Tissue classification information is incorporated into the image registration process. A grey matter mask based on FSL FAST tissue classification was applied to the 83 regions, except for pure grey matter regions, i.e. the basal ganglia and the amygdala. Regional volumes obtained were normalize through division by the intracranial volume. Selected regions of interest were additionally analyzed volumetrically without this normalization.\nEvery segmented brain image was visually checked, especially in the regions of interest. In addition, the regions with the smallest and largest volumes were visually checked on the corresponding image to ensure that their segmentation was accurate.\nPreprocessed MR images as subjected to analysis, along with segmentation results, are publicly available [37] ."}, {"section_title": "Statistical analysis", "text": "The variables of interest showed no difference in variance (tested using Fisher variance test) and were normally distributed (tested using the Shapiro test). Thus, they were suitable for parametric analyses.\nDemographical and cognition variables were analyzed using two-tailed Student's t-tests or Wilcoxon tests when comparing the patient group (MCI and mild AD) with the control group. The groups were well matched for sex, but differed significantly in age (patients were older, p<10-5) and education level (patients had lower education level, p<10-5). To take this difference into account, analysis of covariance (ANCOVA) was applied with age, sex, and education level as a covariate. Correlations between performance on the emotion recognition task and volumes of brain regions were examined using Pearson analysis. We studied correlations based on our regions of interest, and corrected for multiple comparisons using Benjamini & Hochberg's method [38] . Nine bilateral regions were investigated for anger recognition (putamen, posterior STG, fusiform gyrus, anterior cingulate gyrus (ACG), precentral gyrus, anterior orbital gyrus, inferior frontal gyrus (IFG), gyrus parahippocampalis, lingual gyrus), seven bilateral regions for disgust (insula, caudate nucleus, putamen, pallidum, IFG, posterior STG, ACG), ten bilateral regions for fear recognition (amygdala, hippocampus, posterior STG, fusiform gyrus, ACG, thalamus, anterior orbital gyrus, IFG, medial orbital gyrus, lateral orbital gyrus) and seven bilateral regions for happiness recognition (amygdala, fusiform gyrus, insula, ACG, anterior orbital gyrus, lingual gyrus, medial orbital gyrus). All statistical analyses were performed using R (http://www.r-project.org). The threshold for statistical significance was set at p<0.05.\nPreviously, Perrin et al. [39] had manually segmented the amygdala of ten of our patients using a different protocol to that used for the Hammers atlases. Their measurements of "}, {"section_title": "Results", "text": ""}, {"section_title": "\u22122", "text": "). Covariance with demographical data. Analysis including all participants revealed that global emotion recognition performance deteriorated with age (r = \u22120.42). Age was negatively correlated with recognition of anger (r = \u22120.38), fear (r = \u22120.30), and happiness (r = \u22120.30).\nStructural imaging findings. Regional segmentation succeeded on every region, except for the cerebellum, which appeared to be slightly underestimated in some subjects. Using MAPER, we segmented 76 regional volumes corresponding to the 83 regions without the cerebellum and ventricles, and considered our regions of interest defined prior to the segmentation. Shapiro tests indicated that the volumes of the regions of interest were normally distributed."}, {"section_title": "Neuroanatomical correlates", "text": "Correlations with emotion recognition performance. In the following analysis, the impaired recognition (IR) condition corresponds to the patients' average emotion recognition performance at morphing degrees where they performed significantly below controls. For instance, anger IR corresponds to the patients' average performance on anger recognition with morphing degrees of 40, 60, 80, and 100%.\nWe investigated correlations between brain regional volume and performance and corrected for multiple comparisons as described in the Methods section (Table 2) . Fear performance was negatively correlated with the right and left amygdala volumes for varying degrees of morphing (Fig 3C and 3D ). Disgust (with 20% of morphing) was negatively correlated with the volume of the left pallidum (Fig 3A) . Happiness recognition was negatively correlated with the volume of the left fusiform gyrus (Fig 3B) . No significant correlations were revealed with anger recognition when correcting for multiple comparisons. However, without this level of correction, negative correlations between anger recognition and the right lingual gyrus volume were seen (average of morphing degrees and IR: both r = \u22120.42, p = 0.008).\nAn overall analysis of the 76 regions without correction for multiple comparisons revealed that most of the volumes of brain regions were negatively correlated with performance on the emotion recognition tasks (cf. Supporting Information). The negative correlations between fear recognition (100% of morphing) and amygdala volumes remained significant after Benjamini-Hochberg correction for 76 comparisons.\nThe correlations between fear IR performance and the amygdala volumes were compared to those derived from the manually determined amygdala volumes [38] after normalization of the latter by intracranial volume (n = 10). These manually determined volumes were also ). To exclude the possibility that the correlations were an artifact of normalization by intracranial volume, we repeated the analysis with non-normalized volumes and obtained very similar results (data not shown).\nComparison between MCI and AD. We repeated the correlation analysis of the previous subsection after having grouped the patients by diagnosis (Table 3) . Even when analyzed separately, the two groups showed the correlation (albeit with lower significance, as was to be expected due to the sample size reduction).\nCorrelations between regions of interest. These exploratory correlations were performed considering the uncorrected comparison results (Supporting Information). The regional volumes which were positively correlated with the recognition of an emotion were also positively correlated among themselves (average r = 0.28, p<10 \u22126 ). Similarly, the regional volumes that were negatively correlated with the recognition of an emotion were positively correlated among themselves (average r = 0.28, p<10 \u22126 ). Regional volumes positively correlated with the recognition of an emotion were only weakly correlated with the regions negatively correlated with the recognition of the same emotion (average: r = 0.12, p<10"}, {"section_title": "\u22126", "text": "). (Fig 4A to 4D) shows the correlation coefficients between emotion recognition performance, regional volumes positively correlated with the recognition of emotions, and regional volumes negatively correlated with the recognition of emotions. When plotting the 76 regions of interest in random order, no clear pattern of correlation is evident (Fig 4E) .\nRegion volume comparison with healthy controls. To exclude the possibility that our patient group was unusual with regard to the region volumes we determined, we compared measurements on selected regions (right and left amygdala, left fusiform, left pallidum, and hippocampus left and right mean) with those obtained on the control group selected from the ADNI database. The volumes were significantly smaller in patients than in controls, except for the fusiform and the pallidum. The fusiform was smaller, but not significantly so. The pallidum was larger by 13%; however pallidum measurements tend to be inaccurate with MAPER [14] . All other structures were approximately 25% smaller. These findings are consistent with moderate atrophy as expected in a patient group."}, {"section_title": "Discussion", "text": "This study revealed specific impairments in facial emotion expression recognition in patients with AD at the MCI or mild dementia stages, whereas recognition of other facial features like gender remains unimpaired. This is consistent with a selective impairment of recognition of Table 3 . Correlations between emotion recognition performance and regional volumes, separated by diagnosis (AD/MCI). facial features relying on temporal and frontal neural networks. Features that are invariant to emotion, like those identifying gender, are still recognized, as this ability depends on posterior occipital areas that are fully or largely preserved during early stages of AD [12] . We found correlations between emotion recognition performance and the volumes of the expected brain structures. However, a new finding was that emotion recognition performance was negatively correlated with most of the grey matter volumes of regions of interest. In particular, fear recognition performance was negatively correlated with the amygdala volumes, whether these were measured automatically or manually. These unexpected results mean that larger regional volumes are associated with lower performance. We had initially hypothesized that the most atrophied regions would be associated with the most impaired cognitive functions."}, {"section_title": "Emotion impairment in mild stages of AD", "text": "Recognition of emotion is impaired in mild stages of AD. We found that emotion recognition was impaired during mild stages of AD. Previous reports on early AD identified distinct deficits in episodic memory and milder deficits of executive, language and visual functions [4] . Some epidemiological studies have highlighted unexpected signs at very early stages of AD such as impaired semantic abilities [4] , and this may help to understand and characterize clinical presentation at the predementia stage. Demonstrating early changes in social cognition in AD may be essential for understanding the social disinvestment observed in the first stages of the disease.\nUnlike Spoletini et al. [8] , who found that amnestic MCI patients were only impaired in the recognition of low-intensity fearful faces, we found that patients were impaired in the recognition of each of several different emotions (anger, fear, happiness, and, to a lesser degree, disgust). Such results were also shown by Bediou et al. [3] .\nDisgust recognition is selectively preserved. Disgust recognition appeared to be selectively preserved, except at the morphing degree of 40%. This is congruent with the study by Henry et al. [5] and may be explained by the relative preservation of the basal ganglia in AD [40] , despite significant atrophy of the insula, the two structures previously found to play a role in disgust recognition [41] . Bediou et al. had found that disgust recognition was preserved in MCI but not in mild AD, which is partially consistent with our results [3] .\nThe impairment is specific to emotion recognition. Patients were neither impaired on gender recognition, nor on neutral expression recognition. Thus, their ability to recognize facial features invariant to emotion was preserved, as well as their visual and attention skills. Our results indicate that in MCI and mild AD, emotion recognition is impaired specifically, rather than as a consequence of global cognitive dysfunction."}, {"section_title": "Neuroanatomical correlates of emotion recognition", "text": "The correlations between emotion recognition performance and regional volumes revealed networks encompassing the regions for which involvement was predicted, even though the direction of the correlation was unexpected. Our findings showing negative correlations between the amygdala volumes and the recognition of fear 100% were confirmed by the manual segmentation of the amygdala [39] and persisted even after correction for multiple comparisons. To our knowledge, previous studies have not investigated the neuroanatomical correlates of emotion recognition in the mild stages of AD in such detail.\nThe total emotion recognition score was negatively correlated with the amygdala volume (bilaterally) and the left hippocampal volume, and was positively correlated with the left anterior cingulate gyrus and the right medial orbital gyrus volumes. These four regions are activated in subjects looking at emotionally expressive faces [17] . Regional involvement was entirely consistent with our hypotheses: anger recognition correlated with the OFC volume as well as the ventral striatum volume, fear recognition with the amygdala volume, and happiness recognition with the fusiform gyrus volume.\nWe did not find the expected correlation between the insula volume and disgust recognition. Disgust recognition is processed in the ventral anterior subregion of the insula. The 83-region Hammers atlases currently label the insula as a whole, which may explain the absence of a correlation in our study."}, {"section_title": "Hypotheses to explain negative correlations", "text": "Contrary to our expectations, we only found negative correlations between emotion recognition performance and grey matter volumes of a priori specified regions of interest. Some hypotheses are presented below to explain why patients with larger volumes may show reduced performance.\nThe traditional interpretation of atrophy of these regions leading to impaired cognitive abilities is regularly found correct in later stages of Alzheimer's disease [6] , when e.g. hippocampus volume is positively correlated with memory performance [42, 43] .\nAmyloid plaque bulk hypothesis. A study by Bussi\u00e8re et al. [44] estimated the volume occupied by amyloid deposits in the hippocampus, the entorhinal cortex, and area 9 of the frontal cortex. On average, the \u03b2-amyloid volume represented 7.3% of the regional volume, with values ranging from 0% to 34.8% [44] . Moreover, patients who had received anti-\u03b2 amyloid treatment with AN1792 to eradicate amyloid plaques showed decreased regional volumes. Evidently, amyloid plaques occupy space and increase regional volumes. At early stages of the disease, the amount of amyloid deposits is thus correlated with some cognitive impairment, in particular memory, and hippocampal atrophy [45] . In order to validate this hypothesis, one might use positron emission tomography with an amyloid tracer to estimate regional \u03b2-amyloid burden.\nNeuroinflammation hypothesis. In mild AD, amyloid plaques are associated with an inflammatory response involving an increased presence of activated complement proteins, cytokines, and activated microglia and astrocytes. Neuroinflammation occurs mostly in the frontal neocortex and limbic system, and precedes cerebral atrophy. The volume occupied by microglia and macrophages increases with the severity of the dementia [46] .\nIt is therefore possible that the regions with the largest volumes are those with the highest degree of neuroinflammation. This hypothesis could be tested by assessing the severity of neuroinflammation by positron emission tomography with markers for activated microglia, e.g.\n[11C]PK11195.\nAs neuroinflammation may be correlated with \u03b2-amyloid burden [47] , the neuroinflammation and amyloid hypotheses both predict increased regional volume to be correlated with cognitive impairment [48] .\nHypercompensation hypothesis. In MCI, functional compensatory mechanisms [49] involving up-regulation of neurotransmitter receptors [50] or enzymes [51] can occur. For instance, increased hippocampal activation was reported in the MCI stage of AD compared to controls [52] . Structural compensation with neuronal hypertrophy in neurodegenerative diseases has also been suggested [53] . The most functionally impaired regions may be structurally compensating the most.\nOur findings also point out the fact that, with MCI patients, structural MRI might not inform properly about the impairments encountered by the patients. Indeed, at the first stages of AD, neuronal death might be underestimated on MR scans since processes like inflammation or amyloid deposits might contribute to relative preservation of some brain region volumes. A complementary method such as PET with selective ligands may help to disentangle these pathological mechanisms."}, {"section_title": "Emotion recognition network", "text": "Structural co-variance is increasingly recognized as relevant for studying brain function in health and disease [54] . We found evidence for structural co-variance in emotion recognition networks in our study. Fig 4 illustrates that regions for which the correlation with emotion recognition has the same direction are positively correlated amongst themselves, whereas no clear correlations were seen when considering all regions of interest in random order. This may indicate that regional involvement in each kind of emotion recognition follows distinct patterns, which supports the locationist view that postulates unique regional networks for each emotion [17] .\nLimitations and perspectives. The patient group consisted of a mixed population of MCI and AD at mild stage, even if the MCI patients included were typical of the form converting into AD. Moreover, controls did not undergo MRI, which prevented volume comparisons between the two groups. MAPER has previously been shown to robustly identify signature structural differences between healthy controls and MCI and AD patients [14] .\nIn future studies, structural connectivity using DTI between the regions of interest could be explored. The functional overactivation hypothesis could be explored with functional MRI, the \u03b2-amyloid burden with amyloid PET, or the neuroinflammation hypothesis with activated microglia PET.\nSupporting Information S1 File. Results of neuropsychological testing (unprocessed). Column A is an identifying number n that connects the patients (upper set of 39 data rows) with their imaging data files [37] via the filename (pattern cn.nii.gz). (XLS) S1 Table. Correlations between emotion recognition performance and regional volumes in the patient group. R: right, L: left. IR: impaired recognition. r: Pearson correlation coefficient. Green = negative correlations, red = positive correlations.\n\u00c3 p<0.05, \u00c3\u00c3 p<10-2, \u00c3\u00c3\u00c3 p<10-3. Literature: Region hypothesized to be involved in task a priori. These correlations were not corrected for multiple comparisons; compare with Table 2 in the main article.\nAcknowledgments PACO is financed by the National Hospital-Based Clinical Research Program (PHRC). We would like to thank all study participants and their carers for their time.\nOne part of the data used in preparation of this article was obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ ADNI_Acknowledgement_List.pdf. Data collection and sharing for this project was funded by the Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, "}]