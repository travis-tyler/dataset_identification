[{"section_title": "", "text": "Participation in the modern U.S. economy requires that most workers have education and training beyond high school, with over 60 percent of all jobs and 80 percent of middle-class jobs requiring some level of postsecondary education (Carnevale, Jayasundera, and Hanson 2012;Carnevale, Smith, and Strohl 2013). The growth in jobs that require postsecondary education has accelerated since 1992 (Carnevale, Jayasundera, and Hanson 2012) and has led some analysts to suggest that a 2-year degree is the minimum educational requirement to achieve self-sufficiency (Carnevale, Gulish, and Strohl 2018). In response to these and other demands, some nonprofit organizations, including Complete College America and Achieving the Dream, have launched initiatives to encourage students to complete a postsecondary credential, and the Lumina Foundation has set Goal 2025: to increase the number of American adults with degrees, certificates, or other credentials to 60 percent by the year 2025. These initiatives have often paid special attention to students pursuing subbaccalaureate degrees (certificates or associate's degrees), as students seeking these degrees often come from groups that are traditionally underrepresented in postsecondary education (Radford et al. 2016). Numerous studies have provided evidence of the economic benefits of a postsecondary credential, including a subbaccalaureate credential (Baum, Ma, and Payea 2013;Carnevale, Rose, and Cheah 2011;Rosenbaum, Stephan, and Rosenbaum 2010;Zaback, Carlson, and Crellin 2012). Completing a subbaccalaureate degree or certificate is positively associated not only with employment but also with earnings (Hout 2012;Xu and Trimble 2016;Stevens, Kurlaender, and Grosz 2015). In particular, financial benefits accrue to students who complete certificates and associate's degrees compared with those who have no education beyond a high school diploma (Minaya and Scott-Clayton 2017). In light of the heightened attention to subbaccalaureate students' success, several critical questions remain: How do postsecondary students who enroll in certificate and associate's degree programs fare in both completion and employment outcomes? This report draws upon data from the 2012/14 Beginning Postsecondary Students Longitudinal Study (BPS:12/14) to describe the enrollment patterns, 3-year completion rates, and early labor market experiences of students who began in certificate or associate's degree programs in 2011-12. It is important to note that these labor market outcomes do not describe the outcomes of all subbaccalaureate completers, but only the subset of students who complete within 3 years and transition relatively quickly from a certificate or associate's degree program into the labor market. Students with shorter time-tocompletion tend to borrow less for education (Chen and Wiederspan 2014) and experience lower opportunity costs associated with staying enrolled and delaying entry into the workforce (King 2002). To provide context for understanding the completion rates and labor market experiences of certificate and associate's degree students, this report begins by examining the institutions they first attended, the programs in which they initially enrolled, and their enrollment intensity during their time in college (i.e., full-time, part-time, or a mix of full-and part-time enrollment). Throughout the report, the term control and level of institution refers to whether an institution is public, private nonprofit, or private for-profit (institution control) and the institution's highest program offering (institution level). The term subbaccalaureate students refers to first-time students who began in either a certificate or an associate's degree program. Additional explanations regarding enrollment intensity and program completion are located in the Technical Notes under Variables Used. All comparisons of estimates were tested for statistical significance using the Student's t statistic, and all differences cited are statistically significant at the p < .05 level unless otherwise specified. 1 The findings contained in this report are purely descriptive and should not be interpreted as implying causal relationships. 1 What control and level of institution did subbaccalaureate students first attend, what fields of study did they first pursue, and what was their enrollment intensity during their first 3 years?"}, {"section_title": "STUDY QUESTIONS", "text": "Among 2011-12 first-time postsecondary students enrolled in a certificate program, 64 percent first attended a private for-profit institution, such as a technical institute, and 24 percent first attended a public 2-year institution, usually a community college (figure 1). Among 2011-12 first-time postsecondary students who enrolled in an associate's degree program, 82 percent first attended a public 2-year institution, and 11 percent first attended a private for-profit institution. Health care was the most common field of study among certificate students overall (43 percent), followed by personal and consumer services (23 percent) and manufacturing, construction, repair, and transportation programs (16 percent) (table 1). The most common certificate field for females was health care, enrolling 57 percent of female certificate students compared with 18 percent of male certificate students. Personal and consumer services enrolled 30 percent of female certificate students compared with 9 percent of male certificate student. Manufacturing, construction, repair, and transportation was the most common certificate field for males, with 46 percent of male certificate students enrolled in this field compared with only 1 percent of female certificate students. ! Interpret data with caution. The coefficient of variation for this estimate is between 30 and 50 percent. \u2021 Reporting standards not met. The coefficient of variation for this estimate is 50 percent or greater. NOTE: All other institutions includes public less-than-2-year and private nonprofit less-than-4-year institutions. Estimates pertain to individuals who were first-time postsecondary students in 2011-12 at Title IV eligible postsecondary institutions in the 50 states and the District of Columbia. Details may not sum to totals because of rounding. SOURCE: U.S. Department of Education, National Center for Education Statistics, 2012/14 Beginning Postsecondary Students Longitudinal Study (BPS:12/14). No field of study predominated among 2011-12 associate's degree students overall, though patterns emerged when looking at students by sex. For female associate's degree students, health care was the most common program, constituting 28 percent of enrollments. The most common associate's degree field for males was general studies and other fields, with 19 percent of enrollments. When comparing male and female associate's degree students, males enrolled in four fields of study at higher rates than females did: engineering and engineering technology, computer and information sciences, business, and military technology and protective services. Female associate's degree students enrolled in three fields at higher rates than males did: health care, social sciences and humanities, and other applied fields.   2 What percentage of subbaccalaureate students earned a credential within 3 years, and how did completion rates vary by control and level of institution first attended, field of study, and enrollment intensity? Timely completion of a postsecondary credential is important given the opportunity costs associated with postsecondary education (Archibald and Feldman 2011)  Students who started at public 2-year institutions had lower rates of completion than their counterparts at private for-profit institutions. Among certificate students who started at public 2-year institutions, 35 percent completed a credential within 3 years, compared with 58 percent of their peers who started at private for-profit institutions. Among associate's degree students who started at public 2-year institutions, 16 percent completed a credential after 3 years, compared with 34 percent of those who started at private for-profit institutions. Completion rates for certificate and associate's degree students also varied with the field of study in which they first enrolled. Over half of certificate students in two fieldsmanufacturing, construction, repair, and transportation (59 percent) and health care (58 percent)-completed a credential by 2014 (table 3). 5 These completion rates were higher than the completion rates of students in other programs. Among certificate students, those studying manufacturing, construction, repair, and transportation had higher completion rates (59 percent) than students in computer and information sciences (30 percent), business (28 percent), and other applied fields (25 percent). Associate's degree students studying manufacturing, construction, repair, and transportation had higher completion rates (38 percent) than their peers in all other fields. Consistent with past research (Ginder, Kelly-Reid, and Mann 2017, table 6), completion rates for both certificate and associate's degree students varied by enrollment intensity, with higher completion rates for students who always attended full time or had mixed enrollment, compared with those who always attended part time (figure 3). Similarly, among associate's degree students, completion rates were highest among those who always attended full time (27 percent), lower for those with mixed enrollment (19 percent), and lowest for those who always attended part time (4 percent).  3 How did labor market outcomes differ between subbaccalaureate completers and noncompleters? This section compares labor market outcomes for subbaccalaureate completers and noncompleters who were no longer enrolled in school. 6 Employment and salary information were collected only for students who were not enrolled in postsecondary education in 2014 and did not plan to reenroll in a degree or certificate program during the subsequent academic year. 7"}, {"section_title": "Employment-to-Population Ratio", "text": "Three years after starting postsecondary education, 72 percent of certificate completers were employed, compared with 59 percent among certificate noncompleters (table A-4). Associate's degree completers also had a higher employment-topopulation ratio 8 (77 percent) than noncompleters (70 percent)."}, {"section_title": "Salary. Employed certificate completers", "text": "and noncompleters had median annual salaries of $20,000, and there were no statistically significant differences in median salary between employed certificate completers and noncompleters by sex (table 4). Employed associate's degree completers had a higher median annual salary ($22,000) than did associate's degree noncompleters ($19,000). Male associate's degree completers had a higher median annual salary ($26,000) than did female associate's degree completers ($19,500   Radford, A.W., Wu, J., Cataldi, E.F., Wilson, D., and Hill, J. (2016). Persistence and Attainment of -12 First-Time Postsecondary Students After 3 Years (NCES 2016. U.S. Department of Education. Washington, DC: National Center for Education Statistics. 9 The target population of students was limited to those who took at least one course for credit that could be applied toward an academic degree or those enrolled in an occupational or vocational program requiring at least 3 months or 300 clock hours of instruction to receive a degree, certificate, or other formal award. The target population excluded students who were also enrolled in high school or a high school completion (e.g., GED preparation) program. \"Title IV institutions\" refers to institutions eligible to participate in federal financial aid programs under Title IV of the Higher Education Act. The target population of institutions was limited to those institutions that offered an educational program designed for persons who have completed secondary education; offered at least one academic, occupational, or vocational program of study lasting at least 3 months or 300 clock hours; offered courses that were open to more than the employees or members of the company or group (e.g., union) that administered the institution; were located in one of the 50 states and the District of Columbia; were not a U.S. service academy institution; and had signed the Title IV participation agreement with the U.S. Department of Education. Students in Puerto Rico were excluded from the analysis in this Statistics in Brief. More detailed information about the BPS data collections and survey methodology are available in the following reports: 2012/14 Beginning Postsecondary Students Longitudinal Study (BPS:12/14) Data File Documentation (https://nces.ed.gov/pubsearch/ pubsinfo.asp?pubid=2016062)."}, {"section_title": "Sources of Error", "text": "Two broad categories of error occur in estimates generated from surveys: sampling errors and nonsampling errors. Sampling errors occur when observations are based on samples rather than on entire populations. The standard error of a sample statistic is a measure of the variation due to sampling and indicates the precision of the statistic. The complex sampling design used in BPS must be taken into account when calculating variance estimates, including standard errors. NCES's web-based software application, PowerStats, was used to generate the estimates in this report; PowerStats uses the balanced repeated replication and jackknife II methods to adjust variance estimation for BPS's complex sample design (Wolter 2007). Nonsampling errors can be attributed to several sources: incomplete information about all respondents (e.g., some students or institutions refused to participate or students participated but answered only certain items); differences among respondents in question interpretation; inability or unwillingness of respondents to give correct information; mistakes in recording or coding data; and other errors of collecting, processing, and imputing missing data. In the design, conduct, and data processing of NCES surveys, efforts are made to minimize the effects of nonsampling errors. Throughout the report, the term control and level of institution refers to whether the institution is public, private nonprofit, or private for-profit (institution control) and the institution's highest program offering (institution level). The term always full-time refers to students who carried at least 12 semester or quarter hours per term at the undergraduate level or 9 credit hours per term at the graduate level; 24 semester hours or 36 quarter hours per academic year for programs of less than one academic year; or 24 clock hours per week for programs using clock hours for all months enrolled between July 2011 and June 2014. Students who are always part-time are students who carried less than full-time credit hours for all months enrolled between July 2011 and June 2014. Students with mixed enrollment are students who carried a mix of full-time and part-time enrollment for all months enrolled between July 2011 and June 2014. The term subbaccalaureate students refers to first-time students who began in either a certificate or associate's degree program. Certificate students and associate's degree students refer to first-time postsecondary students who began in a certificate or associate's degree program, respectively. Question 2 examines the completion rates of these students, looking at the rate at which students who began in each type of program earn any credential. For instance, students who started in an associate's degree program and completed a certificate after 3 years are considered completers in Question 2 because they attained a credential. Question 3 examines the outcomes for completers and noncompleters, with completers being defined based on their initial program and highest completion level. Specifically, certificate completers refers to students who began in a certificate program and whose highest award within 3 years was a certificate, and associate's degree completers refers to students who began in an associate's degree program and whose highest award within 3 years was an associate's degree. Certificate noncompleters and associate's degree noncompleters refer to students who began in a certificate or associate's degree program, respectively, and who had not completed any credential within 3 years. For question 3, both completers and noncompleters are restricted to students who were no longer enrolled 3 years after they began. This is because employment questions were asked only of unenrolled students at the time of the 2014 interview. Some subbaccalaureate students had transferred to a baccalaureate program by 2014. For example, 9 percent of associate's degree students and 1 percent of certificate students had transferred to a public 4-year institution"}, {"section_title": "VARIABLES USED", "text": "The variables used in this Statistics in Brief are listed below. Visit the NCES DataLab website at https://nces.ed.gov/datalab to view detailed information on question wording for variables coming directly from an interview, how variables were constructed, and the data collection source for each variable. The program files that generated the statistics presented in this Statistics in Brief can be found at https://nces.ed.gov/pubsearch/pubsinfo.asp?pubid=2020035. as of 2014 (Ifill et al. 2016, table 2.3-B). These students are distributed across the three categories of students analyzed in Question 2. Subbaccalaureate students who transferred to a baccalaureate program were likely to be enrolled in 2014; therefore, they were excluded from the analysis for Question 3. Some subbaccalaureate students who transferred to a baccalaureate program but were no longer enrolled in 2014 were captured in the analysis for Question 3; analyzing these students separately is not feasible due to small sample sizes."}, {"section_title": "Response Rates and Nonresponse Bias Analysis", "text": "NCES Statistical Standard 4-4-1 states that \"[a]ny survey stage of data collection with a unit or item response rate less than 85 percent must be evaluated for the potential magnitude of nonresponse bias before the data or any analysis using the data may be released\" (Seastrom 2014 1 Respondents before poststratification adjustment were weighted using the base weight, adjusted for nonresponse. Respondents after poststratification adjustment were weighted using the base weight, adjusted for nonresponse and poststratification. 2 The full sample was weighted using the base weight. Respondents after poststratification adjustment were weighted using the base weight, adjusted for nonresponse and poststratification. NOTE: Relative bias and significance were calculated on respondents versus the full sample. Relative bias is defined as the ratio of estimated bias to the weighted mean of the full sample. Variable categories with fewer than 30 nonrespondents were suppressed for calculations in this table. SOURCE: Ifill, N., Radford, A.W., Wu, J., Cataldi, E.F., Wilson, D., and Hill, J. (2016). whether the student was an institutional aid recipient; whether the student was a state aid recipient; students' major; and whether the student was a grant aid recipient. Within each category of institution control and level, nonresponse weight adjustments reduced the estimated bias. For example, the mean estimated relative bias of estimates based on students who attended public 2-year institutions had a value of 6 before nonresponse weight adjustments were made and a value of 4 after those adjustments. In addition, whereas 29 percent of examined variable categories had estimates with significant bias before these adjustments, only 3 percent did afterwards. Poststratification adjustments also had effects on the bias estimates. The difference between respondents' means before and after poststratification ranged from 1 to 6, and the differences between the full sample estimates and those of respondents after poststratification did not exceed 5. 10 At the item level, only one variable used in this report, JOBST14, had a response rate below 85 percent (79 percent) and required a nonresponse bias analysis. Nonresponse bias analysis was conducted for this variable to determine whether respondents and nonrespondents differed on institution and student characteristics. Institution characteristics included the following: control and level; Office of Business Economics region; enrollment (categorized); percentage of full-time students who received any grant aid; and the rate at which full-time students graduated within 150 percent of normal time to completion. Student characteristics included the following: whether the student filed a FAFSA, received federal aid, received a Pell Grant, received a Direct Loan, received state aid, received institutional aid, amount received in Direct Loans (categorized), amount received in Pell Grants (categorized), age (categorized), and major field of study. This analysis was conducted on students who began in certificate or associate's degree programs because this report focuses on subbaccalaureate students. The nonresponse bias analysis indicated that respondents differed from nonrespondents on 5 percent of the characteristics analyzed, indicating that there could be bias in these estimates (exhibit 3). Any bias due to nonresponse, however, is based upon responses prior to stochastic imputation in which missing data were replaced with valid data from the records of donor cases that matched the recipients on selected demographic, enrollment, institution, and financial aid-related variables (Krotki, Black, and Creel 2005). The potential for bias can be tempered by imputation. Imputation procedures are designed specifically to identify as imputation donors cases with characteristics similar to those of the respondents whose data are missing; therefore, imputation is assumed to reduce bias. Although the level of item-level bias before imputation is measurable, the same measurement cannot be made after imputation, so the magnitude of any change in item-level bias cannot be determined. However, the item estimates before and after imputation were compared to determine whether the imputation changed the estimate; such change serves as an indication of a possible reduction in bias. For JOBST14, the proportion of employed students was estimated before and after imputation. The estimated difference in this proportion was tested for statistical significance at the 5 percent level. A significant difference in the proportion after imputation implies a reduction in bias due to imputation. A nonsignificant difference suggests that imputation might not have reduced bias, that the sample size was too small to detect a significant difference, or that there was little bias to be reduced. The difference between the proportions for JOBST14 was statistically significant, indicating that the nonresponse bias was reduced through imputation. For more detailed information on nonresponse bias analysis and an overview of the survey methodology, see 2012/14 Beginning Postsecondary Students Longitudinal Study (BPS:12/14) Data File Documentation (https://nces.ed.gov/pubsearch/ pubsinfo.asp?pubid=2016062)."}, {"section_title": "Statistical Procedures", "text": "Comparisons of means and proportions were tested using Student's t statistic. Differences between estimates were tested against the probability of a Type I error 11 or significance level. The statistical significance of each comparison was determined by calculating the Student's t value for the difference between each pair of estimates and comparing the t value with published tables of significance levels for two-tailed hypothesis testing. 12 Student's t values were computed to test differences between independent estimates using the following formula: where E 1 and E 2 are the estimates to be compared and se 1 and se 2 are their corresponding standard errors. There are hazards in reporting statistical tests for each comparison. First, comparisons based on large t statistics may appear to merit special attention. This can be misleading because the magnitude of the t statistic is related not only to the observed differences in estimates but also to the number of respondents in the specific categories used for comparison. Hence, a small difference compared across a large number of respondents would produce a large (and thus possibly statistically significant) t statistic. A second hazard in reporting statistical tests is the possibility that one can report a \"false positive\" or Type I error. Statistical tests are designed to limit the risk of this type of error using a value denoted by alpha. The alpha level of .05 was selected for findings in this report and ensures that a difference of a certain magnitude or larger would be produced when there was no actual difference between the quantities in the underlying population no more than 1 time out of 20. 13 When analysts test hypotheses that show alpha values at the .05 level or smaller, they reject the null hypothesis that there is no difference between the two quantities. Failing to reject a null hypothesis (i.e., detect a difference), however, does not imply that the values are the same or equivalent. ! Interpret data with caution. The coefficient of variation for this estimate is between 30 and 50 percent. NOTE: Completed credential includes students who began in a certificate program or in an associate's degree program and completed any credential within 3 years. No credential completed, enrolled includes students who began in a certificate program or in an associate's degree program and who had not completed a credential and were still enrolled after 3 years. No credential completed, not enrolled includes students who began in a certificate program or in an associate's degree program who had not completed a credential and were not enrolled after 3 years. Full-time status is based on 12 credit hours unless the awarding institution employs a different standard. Estimates pertain to individuals who were first-time postsecondary students in 2011-12 at Title IV eligible postsecondary institutions in the 50 states and the District of Columbia. Detail may not sum to totals because of rounding. SOURCE: U.S. Department of Education, National Center for Education Statistics, 2012/14 Beginning Postsecondary Students Longitudinal Study (BPS:12/14). "}]