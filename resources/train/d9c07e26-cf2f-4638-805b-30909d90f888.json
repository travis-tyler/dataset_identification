[{"section_title": "Abstract", "text": "Probably not. Frequency distributions of intensification and dissipation developed from synthetic openocean tropical cyclone data show no evidence of significant departures from exponential distributions, though there is some evidence for a fat tail of dissipation rates. This suggests that no special factors govern high intensification rates and that tropical cyclone intensification and dissipation are controlled by statistically random environmental and internal variability."}, {"section_title": "Introduction", "text": "The specter of a sudden intensification of a tropical cyclone just before striking a populous region stimulates a strong interest in understanding and forecasting such an event. For example, a NASA-sponsored field experiment, Genesis and Rapid Intensification Processes (Braun et al. 2013, p. 346) , was partially devoted to the problem of rapid intensification (RI).\n1 One of the experimental questions was ''what environmental (e.g., vertical wind shear, upper-level outflow jets, low-to mid-level moisture, upper-level troughs), oceanic (e.g., warm ocean eddies), and inner-core (e.g., convective bursts, mesovortices) factors govern RI?'' In posing and attempting to answer questions such as these, it is important to distinguish between the random occurrence of favorable factors, on the one hand, and the operation of special physical processes, on the other. For example, if RI is often accompanied by an unusual configuration of upper-tropospheric flow, then the identification of such an unusual condition should aid in the forecasting of RI. At the other extreme, if RI were purely a product of chaotic internal variability, its predictability on the time scales of forecast interest might be quite small.\nOne possible way of detecting the operation of special factors in RI is to look for departures of intensity change probability distributions from canonical distributions (such as a normal distribution). If qualitatively unusual environmental factors are at play, one would expect to find such departures. Kaplan et al. (2010) used historical (''best track'') data to construct such distributions for the North Atlantic and eastern North Pacific regions, as a means of identifying useful thresholds for the definition of RI. Here we expand on that earlier work by augmenting historical tropical cyclone data with a large database of synthetic tropical cyclone events and focusing on the tails of the distributions, where the most rapid intensification and dissipation occur. We find no evidence for a fat tail in the distributions of intensification rates, though there is some evidence for such a tail in dissipation rates."}, {"section_title": "Data and methods", "text": ""}, {"section_title": "a. Observations", "text": "To estimate observed intensity change rates, we use tropical cyclone data compiled by NOAA's National Hurricane Center (NHC) for the North Atlantic and eastern North Pacific regions, and from the U.S. Navy's Joint Typhoon Warning Center (JTWC) for all other regions. We obtained this data from the IBTrACS archive (Knapp et al. 2010) . Peak 1-min wind speeds at 10-m altitude, given in 5-kt increments [1 kt (nautical mile per hour) 5 0.5144 m s 21 ], are reported every 6 h, and we calculate intensity change rates simply as differences over each 6-h interval. To avoid the effect of increased rates of dissipation over land, we tabulate intensity change only if the storm was over open-ocean water at the beginning and end of the 6-h interval, as detected using 1 /48 resolution bathymetry.\nThis historical compilation of tropical cyclone data is based on observations of highly disparate type, frequency, and quality. Estimates based on observations from specially equipped hurricane reconnaissance aircraft are widely regarded as the highest-quality estimates, especially after about 1970, when standards for instrument design, wind-to-pressure conversions, and other factors became more uniform, at least in the North Atlantic region (Landsea 1993) . Many but by no means all North Atlantic tropical cyclones have been surveyed by aircraft since 1944, and a reasonable fraction of western North Pacific storms were surveyed between 1945 and 1987. Other intensity data are based on ship reports, observations on land, including islands, and since the 1970s, observations from satellites. Most contemporary satellite-based intensity estimates are based on the Dvorak technique (Velden et al. 2006) , in which intensity is estimated from image patterns and infraredderived cloud-top temperatures. Satellite-based storm intensities are usually within roughly 10 kt of aircraft reconnaissance-based estimates, at least since 1989 (Knaff et al. 2010) . Some discussion of the effect of Dvorak-type techniques on tropical cyclone intensity estimation can be found in Schreck et al. (2014) .\nGiven the general quality of tropical cyclone observations in various basins at different times, we focus on North Atlantic and western North Pacific data from 1970 to 2013, and data from other basins from 1980 to 2013. The starting year of 1980 is a compromise between the late 1980s, when application of the Dvorak technique is thought to have become robust (Knaff et al. 2010) , and the desire for a longer record."}, {"section_title": "b. Synthetic tropical cyclone events", "text": "We also analyze intensity change statistics for synthetic tropical cyclone events generated by downscaling NCEP-NCAR reanalyses for the period 1980-2010 using the technique described by Emanuel et al. (2008) . Broadly, the time-varying state of the atmosphere and sea surface temperature provided by the reanalysis is seeded randomly in space and time with small-amplitude, warm-core cyclones, whose tracks are then calculated using a betaand-advection model (Marks 1992) driven by the reanalysis winds. The intensity of each vortex is calculated using the Coupled Hurricane Intensity Predictions System (CHIPS; Emanuel et al. 2004) , which accounts for the effects of environmental wind shear, potential intensity, and upper-ocean mixing. The vast majority of the initial warmcore vortices die away and are discarded; the remaining storms constitute a synthetic climatology of tropical cyclone events. Detailed comparisons between such climatologies and observed tropical cyclones are provided in Emanuel et al. (2008) and elsewhere. For the purposes of this study, 12 400 synthetic tropical cyclones were generated for each of the North Atlantic, eastern North Pacific, and western North Pacific basins and for the Southern Hemisphere, and 3100 events are generated for the north Indian Ocean. Standard quantities such as the maximum 1-min surface wind speed at 10-m altitude are recorded every 2 h.\nIn addition to their plentitude, the main advantages of the synthetic events compared to observed tropical cyclones are more frequent sampling, no quantization of intensity, and the absence of observation errors. On the other hand, they are modeled events and as such may differ from real events for any number of reasons.\nComparison of observed and modeled intensity change statistics can serve as a check on both datasets."}, {"section_title": "Results", "text": "To better compare observed to synthetic tropical cyclone intensity rates, we degrade the synthetic event data to more nearly resemble the observational data, by subsampling the 2-h record every 6 h and by rounding the intensities to the nearest 5 kt. We then calculate the probability density of intensity changes, binned in increments of 5 kt (6 h)"}, {"section_title": "21", "text": ". Figure 1a shows the common logarithm of the probability densities of the intensity rates calculated from the observed and synthetic tropical cyclone data for the North Atlantic region for storms of hurricane intensity (.65 kt). The data on either side of zero intensity change tend to fall on straight lines, indicating that the probability densities are nearly exponentially distributed.\nThere are almost two orders of magnitude more synthetic data than observations, so we might ask how much of the difference between the two distributions shown in Fig. 1 is owing to sampling error. To answer this question, we randomly subsample the synthetic data at the same rate as the observed data, and do this 1000 times, calculating the probability densities of the intensity changes of each subsample. Then for each intensity change bin, we find the 5th and 95th percentile of intensity change for that bin; these are shown by the green lines in Fig. 1a . Thus, there is a 10% probability that the observed distribution will lie outside the green lines owing to sampling error alone. With the possible exception of the large number of observed dissipation rates of around 4 kt (h)\n, it would be\ndifficult to reject the hypothesis that the differences between the two distributions are owing to the relatively small number of samples of the observed distribution. The two distributions are compared again in Fig. 1b , but in this case we use every 2-h synthetic track datum, and the intensities are not rounded. As expected, the slope of the probability density decay is shallower since higher-frequency intensity variations are being sampled. If intensity itself is bounded by, say, V max , then measured intensity change rates must be bounded above by V max /Dt, where Dt is the sampling interval. The effects of this can be seen in the difference between the tails of the synthetic (red) distributions in Figs. 1a and 1b.\nNote in Fig. 1b that the probability distribution of the synthetic rates departs noticeably from exponential in the high decay rate tail, suggesting that decay rates (but not intensification rates) may be fat tailed. Since data for events over land have been omitted, perhaps this is a reflection of high decay rates over cold water. Yet when the synthetic intensity data are confined to cases in which the potential intensity exceeds 100 kt, there is no discernible change in the high dissipation tail of the distribution (the fat tail remains). Kowch (2013) examined historical intensity data confined to warm water (sea surface temperatures of 278C and larger) and found that within the resolution of that data there were no significant departures from exponential distributions.\nThe distributions shown for hurricane-strength events in Fig. 1 are extended to all intensities of tropical storm strength (35 kt) and higher in Fig. 2 . Here there is some FIG. 1 . Common logarithms of the probability densities of open-ocean tropical cyclone intensity change rates in the North Atlantic region from 3504 observations (blue) and from 316 950 synthetic samples (red) of hurricane-intensity storms. Green lines or dots indicate the 5th and 95th percentiles of 1000 subsamples of the synthetic tracks data at the rate of the observed data for each intensity change bin. All distributions are bounded below by 10 25 . (a) The synthetic data are subsampled every 6 h and rounded to 5 kt to match the best track data and (b) the intensity changes are calculated over 2-h intervals and the intensities are not rounded. Fig. 1 , but including all intensities of tropical storm strength or larger."}, {"section_title": "FIG. 2. As in", "text": "evidence that the synthetic intensity change rates are significantly less than observed rates in the range from 24 to 15 kt (h) 21 . This may indicate inferior performance of the CHIPS model at low intensities and/or observational biases. For example, it is less likely that storms of less than hurricane strength will have been sampled by reconnaissance aircraft. But here again there is no evidence for a significant departure from an exponential distribution of intensification rates, though some evidence remains for a fat tail of high dissipation rates.\nThe best track and synthetic intensity change distributions are shown for the other four basins in Fig. 3 . Agreement between best track and synthetic distributions is best in the western North Pacific and poorest in the eastern North Pacific. The number of observed events in the north Indian Ocean is too small to make any meaningful comparisons. These distributions, which include all intensities of tropical storm strength and greater, show some change of slope around the nominal rapid intensification threshold of 1.25 kt h 21 . Separate tallies (not shown) of data points less than and greater than nominal hurricane strength show that intensification rates smaller than this threshold are dominated by the weaker events and that the rapid intensification probabilities are almost entirely dominated by hurricane strength intensities. In no case is there substantial evidence for a superexponential fat tail of intensification rates. The synthetic intensity change probability distributions of hurricane strength intensities are compared across each of the five basins in Fig. 4 . Curiously, the North Atlantic and eastern North Pacific intensification distributions fall into one class, while the distributions in the other three basins fall into a second class. In this second class, the distributions are skewed positive while in the first class, the intensification and dissipation halves of the distributions are more symmetric. We "}, {"section_title": "Summary", "text": "Based on the evidence presented here, rapid intensification of tropical cyclones is part of a continuum of intensity change that shows no propensity toward a fat tail, implying that no special processes are responsible for intensification rates above some threshold. Instead, intensification rates appear to be governed by environmental and/or internal processes that are randomly distributed. There is some evidence, however, for a significant departure from exponential of dissipation rates at the high-rate tail, suggesting that some special processes may be at work in rapid weakening (aside from landfall, which we have excluded from the present analysis). These conclusions are based on an analysis of both historical (best track) events and a much larger number of synthetic tropical cyclones. Both types of events have distinct advantages and disadvantages, but results based on them are mutually consistent and lend some confidence to our conclusions."}]