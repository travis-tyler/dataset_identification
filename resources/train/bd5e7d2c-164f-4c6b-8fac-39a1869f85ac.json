[{"section_title": "", "text": "perspectives on school climates, as well as teacher instructional effectiveness captured by the Measures of Effective Teaching Study (MET), are used in the Baltimore school leader effectiveness evaluation (Kane & Staiger, 2012). Given such prevalence of survey measures in education, these measures have to depict an accurate portrayal of differences across schools and over time."}, {"section_title": "Validity and Reliability", "text": "The psychometric considerations of survey research are well developed and widely discussed in the literatures of psychology and are primarily clustered around the concepts of validity and reliability; however, there is little attention paid to the temporal effects of the survey timing on participants' responses. Validity refers to \"the degree to which evidence and theory support the interpretations of test scores entailed by the proposed uses of tests,\" while reliability refers to \"the degree to which an assessment tool produces stable and consistent results\" (American Educational Research Association, American Psychological Association, National Council on Measurement in Education, 1999). In particular, the \"internal consistency\" or \"item homogeneity,\" which denotes \"the reliability of a scale based on the degree of within-scale item inter-correlation,\" has been long used in psychometric testing (Crobanch, 1951). One factor typically omitted from the psychometric testing pertains to the exogenous temporal variation, even though some psychometric papers directly address this feature (Buhyoff & Wellman, 1979;Kitamura, Shima, Sugawara, Toda, 1999;Cole & Stewart, 2002;Young, Blodgett, & Reardon, 2003;Murray, 2003). Our study aims to contribute to the literature by examining how the survey timing in terms of day of week, season, and proximity to high-stakes exam is systematically related to teachers' responses regarding their perceptions of students' poverty and behavior, their control in the classroom, student behavior, and their principal's leadership support. The study is organized as follows: Section 1 presents the literature review, while Section 2 and Section 3 provide identification strategies and research methodology, respectively. Section 4 highlights our main findings and Section 5 discusses the findings and possible directions for further research."}, {"section_title": "Literature Review", "text": "Several scholarly streams of thought in the literature focus on the instability of survey responses. Previous research on the instability of survey responses has empirically investigated specific factors such as survey mode and monetary rewards affecting survey responses while attempting to hold all other potential variables constant. We incorporate our hypothesis of the temporal variations in the perceptions of teachers with the methodological issues in the instability of survey responses. For simplicity, the related literatures are categorized under two general classifications: (1) antecedents and consequences of temporal variations, and (2) the seasonal variation in teacher perceptions."}, {"section_title": "Antecedents and Consequences of Temporal Variations", "text": "Researchers have long recognized the psychological antecedents and consequences of human behaviors with respect to temporal variation. The literatures in psychology have shown distinct patterns in human behavior associated with temperature and other weather variables such as hours of sunlight, duration of daylight, humidity, and air pressure. Suicides, for example, are more likely to happen in spring and summer than in winter (Chew & McCleary, 1995;Ajdacic-Gross et al., 2006). This is in line with a positive effect of seasonal oscillations on crime rates. Warmer temperatures affect the rates of violent behaviors such as robbery (DeFronzo, 1984;Anderson & Anderson, 1984), homicide (Michael & Zumpe, 1983a, 1983bMcDowall & Curtis, 2014;Morken & Linaker, 2000), and sexual assault (Perry & Simpson, 1987;McLean, 2007). In particular, significant variations in violent incidents were observed May through June and October through November (Morken & Linaker, 2000). Violent behavior also peaked on Sundays and Mondays (Sisti, Rocchi, & Preti, 2012;Rastogi et al., 2013). These temporal variations of crime revealed variations of crime opportunities (Carlsmith & Anderson, 1979) or emotional changes (Hipp, Bauer, Curran, & Bollen, 2004) related to personality disorders and moral responsibilities, which are defined as Seasonal Affective Disorder (SAD), which is a cyclic illness characterized by recurrent episodes of depression in fall and winter months alternating with periods of normal or mild moods in summer and spring months (Rosenthal, 1987, p. 57). There is also compelling evidence of a link between seasonal depression and seasonal variations in stock returns (Kamstra, Kramer, & Levi, 2003) and consumption expenditures (Barrow & McGranahan, 2000). Thus, various aspects of human behavior are significantly influenced by temporal variations. Organizations also exhibit a predictable ebb and flow of behavior over time. Tax firms have substantial demands on their time and resources during the first half of the year and comparably more flexibility in the third quarter. Hotels, restaurants, and other organizations tied to tourism oscillate between periods of frenetic chaos and relative calm across days, weeks, and years (Baxter & King, 1999). Schools operate on a particularly well-known and established cycle: Annual schooling is regularly punctuated with breaks in the winter and spring, with a longer (typically 3 month) hiatus during the summer. The statewide standardized, high-stakes accountability tests that often inform and dictate school reform efforts are typically offered in early spring. Recent research has shown that effective human-resource management strategies in education are tied tightly to the school calendar (Drake et al., 2014). The school cycle can dictate how a teacher copes with the demands of the job, and this may be particularly evident among new teachers (Weiss, 1999). During the early weeks of school, teachers establish routines and instructional norms, while also scheduling meetings with parents, administrators, and other teachers. As the school year progresses collaborative interactions may drop, instructional demands accumulate, and evaluations begin. In late winter and spring, teacher burnout increases (Brouwers & Tomic, 2000), in part because teachers cast doubt on their professional abilities, which is related with low self-efficacy (Fernet, Guay, Sen\u00e9cal, & Austin, 2012). At the end of the school year, teachers focus more on summative assessment and evaluation of student learning (Carson, 2006). Thus, we see that both organizations and people are subject to systematic temporal fluctuations, and these fluctuations may be of particular note within schools."}, {"section_title": "Seasonal Variation in Teacher Responses", "text": "A seasonal perspective on learning outcomes has been discussed since Hayns (1978Hayns ( , 1987 found a notably larger achievement gap during the summer months rather than the rest of school year. The author explained this gap by addressing non-school factors developed during the summer break. The subsequent literatures in the seasonality of learning outcomes have since expanded substantially but most have retained a narrow focus on summer learning gains or losses (Cooper, Nye, Charlton, Lindsay, & Greathouse, 1996;Entwistle & Alexander, 1992, 1994Alexandar, Entwisle, & Olson, 2001). We have found that inquiry regarding the temporal effects of teachers' perceptions of leadership support and student behaviors is comparatively limited. This study contributes to the literature by examining seasonal effects on the perceptions of teachers regarding students' poverty and behavior, their control in the classroom, and the principal leadership across the school year. This paper discusses survey-based research, practice, and policies by identifying and quantifying biases related to temporal variations of the timing of survey administration."}, {"section_title": "Identification Strategies", "text": ""}, {"section_title": "Data Description", "text": "The SASS is administered to a sample of elementary and secondary schools representative of national and state levels. These surveys, sponsored by the Institute of Education Sciences, were first administrated in the 1987-88 school year and have been re-administered with minor changes six other times over the past 25 years. The survey questionnaires represent a wide range of topics from teacher demand, teacher and principal characteristics, general conditions in schools, principals' and teachers' perceptions of school climate and problems in their schools, teacher compensation, district hiring, and retention practices to basic characteristics of the student population. SASS information is obtained through four questionnaires: The school questionnaire, the teacher questionnaire, the principal questionnaire, and the school district questionnaire. Among them, we focus on four factors: teachers' perceptions of students' poverty, student behavior, teacher control in the classroom, and teachers' perceptions of leadership support using the responses from the teacher questionnaire. The sample of this study consists of 2007-08 SASS, which is the most recent available for analysis. It is composed of 38,240 teachers of 7,931 schools in 4,613 districts across the United States. 1 We restricted the sample to fulltime teachers. The SASS administrators send out a framework questionnaire to schools once schools have been selected for sampling. The questionnaire asks schools for information on teachers in order to create a sampling frame for the selection of teachers within the school. The framework questionnaire is submitted to the SASS administrators whereas the teacher questionnaires are delivered to a volunteer survey coordinator for each school. The coordinator distributes the questionnaires to selected teachers. The teachers ensure anonymity and confidentiality of their information. The responses are submitted to the SASS administrators, including information regarding the beginning and completion dates of the survey."}, {"section_title": "Conceptualizing Temporal Variation in Schools", "text": "Schools are organizations that maintain a regular and predictable schedule in accordance with the school district policy and procedures. The common academic year calendars are established for each semester while a detailed curriculum and instruction are designed on a weekly basis. The workload burdens on teachers vary across the days of week based on the intensity of the daily curriculum and instruction. In addition, the tempo and pulse of the school year from late August to early June provides an opportunity for researchers to study how perceptual measures relate to a specific season or time of year. For instance, teachers may be more likely to perceive student poverty as a serious problem in winter rather than in spring because the student poverty rates can be more easily revealed by students' clothing. When exploring the role of temporal variations in survey measures, we identified three aspects of time that may be most relevant. First, we consider the role that day of the week may play, hypothesizing, for example, that responses on Fridays may be systematically different from responses collected on Tuesdays. Our second perspective of time looks across the entire school year from October 2 to June. Lastly, we consider temporal variations surrounding high-stakes exams, which typically take place during a 3-week window in the spring. This hypothesis demonstrates the challenges and stresses that teachers encounter when preparing their students for high-stakes exams (Kruger, Waddle, & Struzziero, 2007), suggesting that school supports, teacher perspectives, and organizational practices in the weeks leading up to the exams may differ from the weeks following the exam. As we conceptualize variation in perceptual data over time we identify two sources of variation that may be of interest to researchers and policy makers: \"substantive variation\" (owing to systematic variation in the substantive construct of interest) and \"endogenous variation\" (owing to systematic variation in temporal factors related to respondent perception but unrelated to the underlying construct). As an example of the first, when examining student behavior over the course of the school year, we may find that students behave differently during the initial weeks of school as compared to later in the year after classroom norms and routines have been established. As an example of the second, we might envision a scenario where systematic, external pressures (the approaching high-stakes state exams, for example) cause the teacher to perceive student behavior to be more (or less) orderly than the \"true\" measure of student behavior. Two plausible hypotheses facilitate an inquiry into these temporal variations in schools. The first suggests that people's perspectives are sensitive to personal, professional, or environmental influences. Under this hypothesis, we may expect to observe structural variations in survey responses over time, even when the underlying construct we are measuring remains constant. To investigate the prevalence of perceptual change within schools we selected two measures that we expect to remain constant over time: student poverty and teachers' classroom control. The logic here is that any systematic changes in the perception of these factors are likely not related to the underlying construct, but rather are related to external, time-relevant factors. A second hypothesis suggests that organizational factors within schools change over the course of the school year, and they do so in common, predictable ways. To investigate this second hypothesis we selected two measures that might vary systematically over time: teachers' perceptions of student behavior and teachers' perceptions of leadership support. The four measures we selected are discussed in greater detail below."}, {"section_title": "Teachers' Perceptions", "text": "Student poverty. This item captures the extent to which teachers perceive student poverty to be a problem in the school. The perceptions of teachers are coded as an ordered categorical variable with four responses: \"serious problem\" (1), \"moderate problem\" (2), \"minor problem\" (3), and \"not a problem\" (4). To easily interpret the results, the poverty scale has been recoded such that student poverty is regarded as a serious problem as the scale increases. Although student poverty varies between and within schools over multiple years, we have found no research to suggest systematic variation in student poverty during the school year. If student poverty is a time-invariant or a more flexible construct that varies only stochastically relative to the school year, any systematic variation in this measure can reasonably be attributed to perceptual variation. More detailed information on this measure is presented in Table A.3 of Appendix A. Control in the classroom. To measure teachers' control in the classroom, we use a set of items that solicited teachers' perspectives of control over six processes: selecting textbooks and other instructional materials; selecting content, topics, and skills to be taught; selecting teaching techniques; evaluating and grading students; disciplining students; and determining the amount of homework to be assigned. The perceptions of teachers regarding their control in the classroom are coded as an ordered categorical variable with four responses: \"no control\" (1), \"minor control\" (2), \"moderate control\" (3), and \"a great deal of control\" (4). The Cronbach's alpha is 0.72, which is on par with the accepted reliability standard of 0.70 (Hair, Anderson, Tatham, & Black, 1995;Nunnally, 1978). As with student poverty, we expect teacher control in the classroom to vary between schools (Weiss, 1993) as well as within schools over multiple years; however, we have little reason to believe these measures of classroom control vary within schools over a single school year. Table A.4 of Appendix A presents the related statistics. Leadership support. We use three items to measure teachers' perceptions of leadership support. The perceptions of teachers on leadership support are coded as an ordered categorical variable with four responses: \"strongly agree\" (1), \"somewhat agree\" (2), \"somewhat disagree\" (3), and \"strongly disagree\" (4). To easily interpret the results, we recoded the scales in opposite direction. The Cronbach's alpha is 0.728. Teachers' perceptions of leadership support are tied to factors such as teacher efficacy and retention (Boyd et al, 2011). We hypothesize that leadership support is a construct that may evolve over the course of the school year as the demands on the principals' time changes and the principals' relationship with teachers, particularly newly hired teachers, develops. The relevant statistics are viewed in Table A.5 of Appendix A. Student behavior. Our final perceptual measure pertains to teachers' perspectives of student behavior, asking teachers to document the extent to which tardiness, absenteeism, and classcutting are problematic in their school. The perceptions of teachers regarding student behavior are coded as an ordered categorical variable with four responses: \"serious problem\" (1), \"moderate problem\" (2), \"minor problem\" (3), and \"not a problem\" (4). The scales are recoded in opposite direction for a consistent interpretation. The Cronbach's alpha is 0.839. Teachers' perceptions of student behavior in winter and summer are also significantly different from fall (p = 0.000 < 0.001). In contrast, perceptions of student behavior are not significantly different before and after a high-stakes exam (p = 0.194> 0.1). While we were unable to document any prior work that empirically identifies temporal trends in student behavior, anecdotal evidence suggests that tardiness, absenteeism, and class-cutting are likely to become more prevalent as the school year progresses. Data verification. To examine how survey measures differ before and after high-stakes exams, we searched the state testing dates for each state in the 2007-08 school year by utilizing the Internet Archives Wayback Machine. We restrict our subsample for the temporal variations in terms of the proximity to high-stakes exams to the state comprehensive assessments in Grades 2-8. That means high school teachers are excluded in our analysis. The dates of the testing windows obtained from each state's department of education websites were matched with information provided by the Council of Chief State School Officers (CCSS). A large portion of responses were submitted between late October and December before the winter break in the entire sample, whereas the average testing window for spring exams is between March 10th and April 1st, 2008. We included only states offering a high-stakes exam during fall semester when the majority of SASS participants submitted their responses and excluded Oregon because of its wide range of testing window (Table A.2 of Appendix A). In the state test sample, the average testing window for fall exams is between November 29th and December 18th, 2007 ( Figure 1)."}, {"section_title": "Figure 1. Distribution of Response Dates: Full Sample (Left) and Fall Testing (Right) Sample", "text": "Note: A kernel density plot shows the distribution of teacher survey dates across the school year. There are two important considerations to be aware of here. First, we were unable to find the state test dates in North Carolina and thus North Carolina was dropped from the model. Second, the state test dates in the 2007-08 school year for Indiana, Iowa, North Dakota, New Hampshire, Rhode Island, Utah, Virginia, and Wisconsin could not be ascertained, so we assigned the testing dates based on the test windows of these states in years before and after."}, {"section_title": "Methodology", "text": "This study addresses the effects of the survey timing on the teachers' perceptions of their students (behavior and poverty), their principal, and their classroom. Regression analysis is used to explore the relationship between temporal variation in responses with respect to day of week, season, and proximity to high-stakes exams and the perceptions of teachers regarding students' poverty and behavior, their classroom control, and the principal leadership. This section outlines the methods we applied to discuss three phenomena of temporal variations: variations pertaining to day of week, variations across the entire school year, and variations before and after a statewide exam. When examining each of these three aspects of temporal variations, we use the four perceptual measures previously outlined: student poverty, classroom control, leadership support, and student behavior. To facilitate interpretation of our findings, we standardize the scores for each teachers' perception to have within-sample mean 0 and variance 1 after taking mean values over the respective sets of scales (Heckman, Stixrud, & Urzua, 2006). We use several aspects of the survey administration process to strengthen our identification strategy. To facilitate the data collection process, the SASS begins the survey administration in September and staggers the deployment of its remaining surveys across the school year. Although this staggered timing is not random, it is not purposefully related to factors such as geography, urbanicity, or school quality. Further variation in timing manifests within schools, as the schools are given surveys for all selected teachers within a school at the same time, yet some teachers take longer than others to complete the survey. We take advantage of both within and between-school variation in the survey timing to estimate the impact of timing on survey responses. When exploring the role of temporal variations across the school year in terms of day of week, season, and proximity to high-stakes exams, we use several approaches to mitigate biases that may result from endogenous relationships between response time and teacher characteristics. We first control for observable characteristics at the school and teacher levels, because teachers who promptly complete their survey may have systematically different views from those of their peers who wait to complete the survey. A second strategy for limiting endogenous variation focuses on an examination of temporal variation using only the teachers from each school who responded first. The logic of this approach is that \"first responders\" might be systematically different from their colleagues who respond later, and an examination of response patterns among first responders will yield a cleaner estimate of temporal variation. In a third approach, we use the date the first responder submitted the survey as an instrument for completion date for all other teachers within the school. This approach is based on the assumption that the completion date of the first responders will be related to the completion date of other teachers in the school, but unrelated to unobserved factors that may be correlated with later responses; first responders are not included in this analysis. To conduct instrumental variable (IV) estimations, the instruments should be uncorrelated with errors but partially correlated with the endogenous treatment variable once the other explanatory variables are controlled. The R-squared and the adjusted R-squared values of the first-stage regression are around 0.882 for estimations in the seasonal variations, ruling out potential concerns regarding weak instrument bias (Stock & Yogo, 2005). The F-statistics of for the seasonal variation IV analyses exceed 600, considerably larger than the minimum rule of thumb value of 10. We use these various approaches to examine the four survey scales identified above, including two that are expected to exhibit substantive variation-leadership support and student behavior-and two that exhibit perceptual variation: perceptions of poverty and classroom control."}, {"section_title": "Analytical Approach", "text": "As indicated, we examine three sources of temporal variation: day of week, season, and before and after high-stakes state exams. For each scenario, the dependent variables are four measures of teachers' perceptions: their instructional challenges related to poverty, classroom control, leadership support, and student behavior (see Table A.1 in Appendix A). For many of our models we present results with and without school and teacher control variables. Models without control variables may be of interest to practitioners who use raw, unadjusted survey means, while researchers who frequently integrate control variables may have greater interest in the covariate adjusted regression estimates. School control variables include urbanicity dummies (city, suburb, town, and rural), total enrollment in school, program type dummies (regular, special program emphasis, special education, vocational education, and alternative program), the percentage of students with an individual education program (IEP) and limited English proficiency (LEP), charter school dummy, regional dummies (Northeast, Midwest, South, and West), and school level dummies (primary, middle, high, and combined). Teacher control variables include Hispanic ethnic origin dummy, racial dummies (White, Black, Asian, Pacific Islander, and American Indian), total years of teaching experience and its squared, gender dummy, educational dummies for highest degree earned (associate's degree or no college degree, bachelor's degree, master's degree, educational specialist or certificate of advanced graduate studies, and doctoral degree), union dummy, and dummies for grades of students. A descriptive overview of the full sample and the restricted test sample are presented in Table A.7 and Table  A.8 of Appendix A. To analyze the impact of daily variation on teachers' perceptions, we estimate four equations of the form shown below (one for each of the teacher perception variables). We denote , as the perceptions of teacher i in school j. The model for Scenario 1, day of the week, is specified below: where , are six dummy variables for day of week, with reference to Friday. and are the school and teacher control variables, respectively, as outlined in the previous paragraph. Similarly, the IV models for Scenario 2, investigating variation across the school year are below: , , , where , are dummies for spring and winter seasons, in reference to fall. These variables do not pertain to seasons directly but instead represent periods of time that may be most pertinent to schools: a fall period running from September through December, a winter period from January to March, and a spring period from March to June. , is operationalized as the number of days from September 1, 2007; in the same way , our excluded instrument, is the number of days since September first for the first respondent in each school. Thus, we are using the response time from the first responders in each school to create an exogenous estimate of the response time for all other individuals in the school. The models for Scenario 3, investigating how proximity to state exams may influence survey response patterns, are shown below: where , is 1 if a teacher i responds to the survey before the state exam and 0 after the state exam. The variable TimePrior indicates the number of days before or after the testing window that a survey was completed. As with Scenario 1, we present results for a base model and a covariate-adjusted model."}, {"section_title": "Findings", "text": "The findings from our regression analyses show that temporal variation may introduce unwanted biases into survey responses. We find evidence that teachers' perceptions are sensitive to temporal variation, even when the underlying construct of interest remains constant. We also find evidence that these constructs themselves-commonly used in formative constructs and increasingly used in high-stakes evaluations-show some systematic variation over time. This section outlines the evidence supporting these findings, drawing from the regression models outlined above."}, {"section_title": "Weekly Variation", "text": "Scenario 1 investigates whether the responding day of week affects the survey responses. Our findings are presented graphically in Figure 2, which depicts the predicted values from the covariate-adjusted model. When we examine the two measures used to examine perceptual changes (poverty and classroom control), we see little variation across days, although teachers were more likely to report poverty to be an instructional barrier on Mondays rather than on Fridays. When we examine the two measures intended to measure changes in constructsleadership support and student behavior-we see that teachers are more likely to view principals as supportive on Sundays and Tuesdays (relative to Fridays), and student behavior is reported to be lower on Mondays. Full results are presented in Table B.1 of Appendix B. Similar trends among the coefficients are noted when the sample is reduced to only first responders (see Table  B.2 of Appendix B); however, the 75% reduction in sample size erases much of the statistical significance. In sum, these results suggest that surveys completed on Mondays may yield lower ratings of perceptions regarding students, and surveys completed on Fridays may yield lower ratings of perceptions regarding school leadership. "}, {"section_title": "Seasonal Variation", "text": "In the second set of our analyses, we examine variation in survey responses across the school year. The findings from the IV estimations of the covariate-adjusted models are presented in Figure 3. The top two panels represent the two constructs we hypothesized to be constant across the school year: teachers' perceptions of poverty related problems and classroom control. The lower two panels represent the two constructs we predicted may vary across the school year. Teachers' perceptions of instructional challenges related to poverty, as well as the aspects of classroom control, do not demonstrate significant change across the school year in any of the five models we specified (see Table B.3 in Appendix B). The consistency of predicted values for student poverty-related challenges and classroom control suggests that teachers' perspectives are not strongly influenced by seasonality. This, in turn, implies that any measurable changes that occur across the school year are likely attributable to changes in the underlying construct of interest. The two constructs in the bottom panel of Figure 3, leadership support and student behavior, show notable variation across the school year. Teachers' perceptions of leadership support is greatest at the start of the school year, declines through March before dropping sharply at the end of the school year. This result is evident in the base model, the model with school and teacher covariates, and the model with covariates that limited the sample to first-responders. Although the same pattern is evident graphically when using predicted values, temporal variation in leadership support is not significant in the IV models. Teachers' perceptions of student behavior problems surrounding truancy, tardiness, and absenteeism increase at a modest, though consistent, rate throughout the course of the school year. In particular, teachers are more likely to negatively perceive student behavior in spring season (Table B.6 of Appendix B). These findings are robust across all model specifications. Our final inquiry investigated the extent to which the pressures of high-stakes testing may substantially change perspectives and behaviors within schools. Figure 4 presents the min-max range of predicted values for each day generated from our covariate controlled models across each of our four survey measures. The x-axis shows the number of days before and after the exam period. For the three survey measures of student poverty-related challenges, leadership support, and student behavior, the covariate-controlled models yielded null results, suggesting that measures collected before or after testing are not significantly different. In contrast, teachers who responded to the survey prior to the high-stakes test are somewhat more likely to report greater classroom control (Table B.7 of Appendix B). These results are substantively unchanged when we limit the sample to first responders.  "}, {"section_title": "Discussion and Further Research", "text": "The findings from this research are threefold. First, teachers' report stronger leadership support and more challenging student behaviors early in the week. Second, substantive constructs appear to change predictably over the course of the school year, particularly declines in student behavior and, to a lesser extent, in leadership support. Third, despite the publicity given to the pressures arising around high-stakes state exams, we find little evidence that responses before the exam are systematically different than those before. This last point comes with the caveat that responses to low-stakes surveys, such as the SASS may differ from responses to high-stakes surveys. For state and district-level practitioners these findings imply that reasonable latitude may be given to schools to choose survey dates that best complement local schedules, such as professional development days. Under such conditions, small timing differences in survey administration should not bias comparisons among schools. Although this paper focused on the method of data collection rather than the survey constructs directly, school leaders may seek to modify their practice in response to the above findings. Specifically these findings suggest that teacher perceptions of leadership support lags as the year progresses. Perhaps this is in response to greater responsibilities for both teachers and principals later in the year. If this were true, principals may be more likely to attend to other demands and their support may flag. It may be that levels of principal support remain fairly constant over time, yet teachers feel more stress later in the year and need principals to ramp up their support accordingly. The above findings may also highlight a shifting of the principals' role within an accountability framework. Early in the year principals may adopt the role of coach or mentor as they work with teachers to build instructional capacity. As the year progresses, principals' role may shift to that of evaluator as they engage with teachers in a more summative manner (e.g., formal observations of classroom teaching). This shift from coach to evaluator may push some teachers to see principals as less supportive during the spring than in the fall. The decline in perceived leadership support may also arise as a result of the accumulation of stress and challenges encountered throughout the school year. With summer is traditionally viewed as a period of rest and renewal for teachers it is reasonable for teachers to begin the year positive and optimistic and to have this positivity wane when faced with mounting adversity. This may be the case even in the absence of any discernable differences in leadership behaviors. Whether the decline lies in actual changes in leadership support or is strictly an artifice of perception, the message for school leaders is clear: teachers need more support as the school year progresses. Focused support of new and novice teachers during late spring may be a particularly strong investment on the part of school leaders as these teachers are more likely to leave the school or profession. Although this research was not designed to provide a comprehensive portrayal of all perceptions elicited by teachers, it does provide some direction to leaders as to where their support may be needed. As teachers report student behavior to be more problematic as the year progresses, principals can focus a portion of their efforts to maintain clear and consistent behavioral expectations for students. Especially in elementary schools, the establishment of behavioral norms and values is a priority early in the school year. Principals can support teachers by ensuring that this focus remains strong through the winter and spring months as well. As novice teachers report greater challenges with classroom management, school leaders may want to develop strategies to ensure early career teachers have the supports they need to limit behavioral challenges and focus on instruction. The research we have presented here suggests that it is important for principals to maintain these behavioral supports through the end of the school year. Researchers engaged in survey research may also benefit from these findings. Following the watershed research on the summer learning loss, several studies have structured their research design to collect data including achievement testing at the beginning of the school year and conclude in the late spring, such as the Early Childhood Longitudinal Study, Kindergarten cohort. For designs with a treatment and control group, any seasonal changes would be equally manifest in the control condition and are not a concern. However, studies investigating a given policy or intervention that lack a control or comparison group may wrongly attribute fall-tospring differences to program effects rather than seasonal change. We see three limitations to our study. First, the findings apply only to the measures included here; other constructs operationalized through other measures may experience more or less seasonal change. We see this possibility as a fruitful line of subsequent inquiry. Second, most teachers responded to surveys during the fall semester while most state exams were conducted in spring. This causes a notable reduction in sample size and subsequent reduction in precision. The last limitation arises because the testing window period varies across states, making it difficult to precisely identify teachers' perceptions before and after the state exam. In any future work, district-level exam dates should be integrated to better estimate how high-stakes exams may impact measures of climate, leadership, and efficacy.     Note: All data weighted using adjusted the balanced repeated replication (BRR) weights and the standard deviation are presented in parentheses. Note: All data weighted using adjusted the balanced repeated replication (BRR) weights and the standard deviation are presented in parentheses."}, {"section_title": "Appendix A", "text": ""}]