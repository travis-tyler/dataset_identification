[{"section_title": "Abstract", "text": "ABSTRACT In this paper, we present a two-stage ensemble-based approach to localize the anatomical structure of interest from magnetic resonance imaging (MRI) scans. We combine a Hough voting method with a convolutional neural network to automatically localize brain anatomical structures such as the hippocampus. The hippocampus is one of the regions that can be affected by the Alzheimer's disease, and this region is known to be related to memory loss. The structural changes of the hippocampus are important biomarkers for dementia. To analyze the structural changes, accurate localization plays a vital role. Furthermore, for segmentation and registration of anatomical structures, exact localization is desired. Our proposed models use a deep convolutional neural network (CNN) to calculate displacement vectors by exploiting the Hough voting strategy from multiple 3-viewpoint patch samples. The displacement vectors are added to the sample position to estimate the target position. To efficiently learn from samples, we employed a local and global strategy. The multiple global models were trained using randomly selected 3-viewpoint patches from the whole MRI scan. The results from global models are aggregated to obtain global predictions. Similarly, we trained multiple local models, extracting patches from the vicinity of the hippocampus location and assembling them to obtain a local prediction. The proposed models exploit the Alzheimer's disease neuroimaging initiative (ADNI) MRI dataset and the Gwangju Alzheimer's and related dementia (GARD) cohort MRI dataset for training, validating and testing. The average prediction error using the proposed two-stage ensemble Hough convolutional neural network (Hough-CNN) models are 2.32 and 2.25 mm for the left and right hippocampi, respectively, for 65 test MRIs from the GARD cohort dataset. Similarly, for the ADNI MRI dataset, the average prediction error for the left and right hippocampi are 2.31 and 2.04 mm, respectively, for 56 MRI scans.\nINDEX TERMS Ensemble Hough-CNN, hippocampus, displacement vector, MRI, Hough voting."}, {"section_title": "I. INTRODUCTION", "text": "A broad range of research works on medical imaging has been conducted in recent years. Brain magnetic resonance imaging (MRI) is one of the most studied fields in medical image analysis [1] - [4] . The hippocampus is a crucial structure of the human brain's limbic system [2] . It is believed that the hippocampus plays a vital role in the learning process and memory management of daily life\nThe associate editor coordinating the review of this manuscript and approving it for publication was Baozhen Yao. activities [2] .Furthermore, the hippocampus' shape, structure, and size are the prime biomarker for Alzheimer's disease detection [1] , [2] , [7] , [31] .\nHippocampus localization and segmentation have received attention from different research communities [1] - [4] . Although several methods [1] - [3] , [5] have been proposed to localize and segment the hippocampus, it is still a challenging research area due to the nature of the anatomical structure of the hippocampus. The volume of the hippocampus on each side of the brain is approximately 3.0 to 3.5 cm 3 in the adult brain [6] . The hippocampus has faint edges and overlapping intensities [1] with its neighboring structures, which makes the segmentation more difficult. Therefore, prior knowledge describing the accurate location of the hippocampus can help the segmentation process by confining the region of interest and possibly providing segmentation seeding points.\nIn this work, we propose a joint approach of Hough voting [8] - [10] and a convolutional neural network (CNN) [11] to automatically localize the right and left hippocampi in MRI scans. We used the CNN as a feature extractor due to its ability to learn features from input data. Hough voting [8] , [12] and a CNN are utilized to determine the displacement vectors from the random sample points to the target location inside the given volumetric MRI.\nOur approach consisted of a two-stage learning process [13] to exactly estimate the location of the hippocampus. The graphical overview of our proposed approach is shown in Fig. 1 . We designed multiple global and local models. Those models are then aggregated together in both phases. The global model learned the feature map from the whole MRI scan and predicted the apparent location of the hippocampus. The local model was trained to learn the features map in the vicinity of manually marked hippocampus locations. In the testing phase, we jointly utilized the ensemble global and local models. The detailed ensemble architecture of our proposed two-stage Hough CNN in the test phase is shown in Fig. 1(c) . From the prediction of the ensemble global model, we took samples for the ensemble local model for final predictions. The ensemble local model's predicted displacement vectors are transformed into image pixel positions by adding to the center of the generated samples for the local model, which was ultimately placed inside our anatomical structure of interest. This simple strategy offers a good localization model for the right and left hippocampi in MRI scans.\nWe propose a two-stage ensemble Hough-CNN based on a Hough voting strategy similar to [14] . Although a Hough-CNN was proposed in [14] , their studies focused on segmenting multiple regions of interest using semiautomatic and manually annotated regions with the Hough-CNN. In this study, we performed a two-stage ensemble operation to predict the hippocampus location on both sides of the brain from MRI scans. This approach is robust for various anatomical shapes and appearances. Left and right hippocampi locations in 351 MRI scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and 326 MRI scans from the Gwangju Alzheimer's and Related Dementia (GARD) cohort datasets,(from National Research Center for Dementia (NRCD), Gwangju, Republic of Korea), are manually annotated. In contrast to previous works, we fully evaluated the proposed two-stage ensemble network against the manually annotated ground-truths to obtain quantitative results for the localization network. The ensemble Hough-CNN offers a fully automatic localization scheme, and it is superior to the other previous approaches [1] , [2] .\nThe rest of the paper is arranged in the following manner. In section 2, we review the hippocampus localization-related research works as well as multiple landmark detection of brain regions of interest and highlight the limitations of existing works. Our proposed methodology, consisting of patch and label generation, network architecture and training, and localization procedure is explained in section 3. In section 4, we discuss the evaluation process, dataset and results. A summary of the evaluation is covered in section 5."}, {"section_title": "II. RELATED WORKS", "text": "A number of methods have been proposed to localize brain structures, and they can be categorized into manual localization, spatial relation-based localization, atlas-based localization, statistical shape model-based approaches as well as deep learning-based detection strategies. Manual localization methods of brain structures mainly depend upon the expertise of special operators such as a radiologist [15] , [16] , which can consume a large amount of experts' expensive time. On the other hand, the spatial relation-based method exploits a set of predefined rules such as fuzzy sets [17] , [18] . The atlas-based method provides automatic localization but it requires an atlas to extrapolate information to the target dataset using co-registration procedures [19] , [20] . Although this method can accurately localize the target position automatically, it generally consumes a great deal of computation time and data. Therefore, researchers have moved to new approaches, such as statistical shape model-based approaches, which are capable of predicting shape variability in the training population. This method discerns all the shapes that exist in the training data and parameterizes the mean approximate shape [21] . Using the mean shape, the statistical shape model-based approaches localize the approximate position of the anatomy of interest.\nAchuthan et al. [1] introduced a pairwise nonrigid coherent point drift registration-based method to localize the hippocampus from 40 manually delineated hippocampus volumes [22] . In this method, they utilized the strength of pairwise non-rigid coherent point drift registration. The proposed assembly based coherent drift method offers the prediction of a root mean square distance value that is below 3.5 mm from the ground truth position [1] . In contrast, Siadat et al. [2] proposed a knowledge-based localization of the hippocampus in brain MRI scans. This method follows the statistical roadmap approach to localize any landmark in brain MRI scans such as the hippocampus.\nDeep learning-based detection strategies have achieved many breakthroughs in different disciplines using computer vision and machine learning-based algorithms [13] , [24] , [42] . Gall et al. [8] proposed Hough forests to detect an object, such as pedestrian detection, from highly unconstrained images and video frames. A Hough forest consists of random decision trees where the decision trees are determined from the input data. The local appearances of input data are mapped to the leaves of decision trees in the Hough forest and each leaf is considered to be a probabilistic vote in the Hough space. Therefore, a set of leaves in the Hough forest acts like an implicit appearance codebook that can be improved for Hough-based detection [8] , [26] - [28] . Gall et al. [8] improved the general Hough transform [23] and amalgamated it with other methods, such as the Implicit Shape Model [16] and local appearance codebooks to perform the object detection. Milletari et al. [14] developed a Hough convolutional neural network (Hough-CNN) based approach to segment 26 anatomical structure of interest in brain MRI and CT scans.The regions of interest were annotated using manual and semiautomatic approaches from the Hough-CNN (FSL First [25] ). A multiscale deep reinforcement learning-based landmark detection strategy was developed by Ghesu et al. [24] .\nHough votes refer to a collection of evidences in a Hough space where each evidence corresponds to a product set of different locations, scale, aspects. The maximum peak in the sum of all Hough votes points to an instance of an object [8] . The CNN models calculate the displacement vectors pointing to the hippocampus location based on the estimated instances from Hough votes in the Hough space domain, thus the Hough-CNN is formed. In this research study, we concentrated on automatic localization using a two-stage ensemble Hough-CNN to fully evaluate the accuracy of the Hough-CNN localization approach. "}, {"section_title": "III. PROPOSED TWO-STAGE ENSEMBLE HOUGH-CNN", "text": "If we can calculate displacement vectors from any certain point, then by using random image pixel index as a center, we can generate multiple random samples with corresponding displacement vectors from the sampled pixel to the anatomical structure of interest [8] , [29] . The anatomical context around the ground truth point in the training MRI dataset can be used to learn the displacement vectors pointing to the target location. One can use the random forest [8] , [30] , [41] and deep CNN to determine the displacement vectors from input image features. For multiple samples from the same MRI, the trained model predicts multiple displacement vectors that can be added to with corresponding random points, and then averaged to return an estimated point that is designed to be placed inside the anatomical structure of interest. Multiple global networks are trained using the whole MRI scan. Similarly, multiple local networks are trained to discern local information around the hippocampus. The global and local networks are amalgamated to form the two-stage ensemble and obtain the final estimation of a region of interest. Using a two-stage ensemble Hough CNN, we have accurately localized the right and left hippocampi in an MRI scan."}, {"section_title": "A. PATCH AND LABEL GENERATION", "text": "Let us consider a given volumetric MRI, M XYZ : Z 3 \u2192 N [24] , and the hippocampus as the anatomy of interest. The challenge is to learn the displacement vectors from any random point to the hippocampus location.\nFrom 3D MR imaging space, 2D patches are extracted considering uniformly distributed random points inside a MRI scan. To simplify the challenge of interpreting the 3D data space from a large MRI volume shown in Fig. 2 , we extracted a 2D slice to represent how the data distribution is chosen to train the network. 2D slices of a sagittal, coronal, and axial view of an MRI scan are shown in Fig. 3 and Fig. 4 . In each 2D slice, the sample points are uniformly distributed. We took multiple patches to cover all the information that exists in each slice for the global model. Two different sizes of patches are considered for the global and local networks. Uniformly distributed random sample points from the whole MRI are used to extract patches except in the boundary region. A 2D representation of a 3D MRI region considered to generate patches for the global model (GH-CNN). Subsequently, 96\u00d796 patches are extracted for the GH-CNN. These patches are downscaled to 32\u00d732 and then merge those 3-plane view 2D patches into 3-channel 32\u00d732 patches."}, {"section_title": "FIGURE 4.", "text": "Uniformly distributed random sample points in the vicinity of the hippocampus are used to extract patches. A 2D representation of a 3D 8\u00d78\u00d78 cubic region is selected to generate patches for the local model. The 32\u00d732 patches are extracted from MRI scans and then merged into 32\u00d732\u00d73. These merged patches are used as an input to the local model.\nWe performed a normalization operation on each patch using the standard normal distribution.\nIn MRI M XYZ , the sample generation process for the global network is depicted in Fig. 2 . The blue dots are the centers of the sample patches.\nThe 96\u00d796 patches are extracted from the whole MRI for global networks. The two red dots with a cross are the target left and right hippocampi in the training MRIs. The differences between the blue dots and red dots define the target displacement vectors. The target displacement vectors are calculated with the patches, which are utilized as a label while we train the global and local networks. For the global model, we did not take any sample point near the boundary region of the MRI.\nUsing the blue dots inside the red circles as a center, as shown in Fig. 2 , the patches are extracted from the MRI scans. These extracted patches are used to train the local models. The patch centers follow 8\u00d78\u00d78 cubic regions from the target left and right hippocampi locations (red circles). The generated patches have a dimension of 32\u00d732. Then, the 2D 32\u00d732 patches are merged into 3-channel 32\u00d732 patches. These merged patches are used as input to the local models. Multiple patches are extracted from each MRI scan. We depicted the patch extraction process in Fig. 3 and Fig. 4 . The extracted multiple patches are used to train, validate, and test the proposed model to estimate the hippocampus location. "}, {"section_title": "B. NETWORK ARCHITECTURE AND TRAINING", "text": "Different network design approaches [32] - [36] , [42] are proposed to analyze multiple regions in the brain. Our network design topology follows the ensemble [37] based Hough-CNN with a two-phase learning policy [13] , [14] , [34] . We propose a global Hough convolutional neural network (GH-CNN) and local Hough convolutional neural network (LH-CNN). The GH-CNN consists of 6 convolutional layers along with 3 fully connected layers. All convolutional blocks have the same kernel size (3\u00d73) with a relu [38] activation function. However, the number of filters are different in different convolutional blocks. Three max-pooling layers are used to design the GH-CNN. A batch normalization [39] layer is added after each block of the convolutional layer and fully connected layer. The GH-CNN is shown in Fig. 1 (a) (GH-CNN) and the detail network architectures are shown in Table 1 and Table 2 .\nThe LH-CNN is a little different than the GH-CNN. The LH-CNN consists of 4 convolutional layers with 3 fully connected layers for the ADNI dataset. For the GARD cohort dataset, the LH-CNN has 5 convolutional layers and the rest of the network structure is the same as the ADNI dataset. All convolutional blocks have the same kernel size (3\u00d73) with a relu [38] activation function. Different numbers of filters are utilized in each convolutional block. Two max-pooling layers are used in the LH-CNN. In addition, batch normalization layers are concatenated after each convolutional layer and a fully connected layer. The LH-CNN is shown in Fig. 1  (b) (LH-CNN) . The detailed architecture of the LH-CNN is shown in Table 1 and Table 2 .\nThe GH-CNN and LH-CNN are trained using two different types of patches. Because of GPU memory constrained, the 96\u00d796\u00d73 patches are downscaled to 32\u00d732\u00d73 to train the GH-CNN. On the other hand, 32\u00d732\u00d73 patches are extracted from the vicinity of the hippocampus region, and they are used to train the LH-CNN. The detailed sample extraction procedures are explained in the patch generation section. All the parameters of the Adam optimizer [40] are kept as the default except for the learning rate. Different learning rates (1e-5 to 1e-2) are considered to train different models of the GH-CNN and LH-CNN. The training times of the LH-CNN and GH-CNN range from 6 to 14 hours for each model."}, {"section_title": "C. LOSS FUNCTION", "text": "To train the GH-CNN and LH-CNN, the mean square error is considered as a loss function.\nwhere k is the number of patches generated from each MRI and q is the total number of MRIs used for training. (X j , Y j , Z j ) are the target displacement vectors and (X j , Y j , Z j ) are the predicted displacement vectors. Two representative training and validation curves of the global and local model are shown in Fig. 5 and Fig. 6 , respectively. The 5-fold cross validation result of the global and local models are shown in Appendix A. "}, {"section_title": "D. LOCALIZATION PROCEDURE", "text": "We combine three GH-CNN models with three LH-CNN models and form a two-stage ensemble Hough-CNN. Three GH-CNN models estimate the global displacement vectors separately from the multiple patches extracted from the same MRI scan. After that, we calculate the average displacement vectors. This average result is added to the sampled reference points previously used to extract the global models' samples. This result is the predicted locations for the hippocampus by the global models.\nWe use global predicted locations to generate patches for the local model. After extracting patches from the MRI scan around the global prediction regions, we perform the same operations again. However, this time, we use the local models instead of global models. An ensemble of three LH-CNNs estimate the displacement vectors separately from the sampled patch positions.\nWe calculate the average displacement vectors that were estimated previously by the three LH-CNN models. These average displacement vectors from the LH-CNN models are added to the global models' predicted locations. The obtained results are the final predicted hippocampus locations in the target test MRI scans for each patch. We repeat this procedure for multiple patches. The averaged result is the final voxel location of the target test MRI scans. Using these voxel locations, we display the 3-plane view of the hippocampus for the target MRI scans.\nConsider that the GH-CNN predicted global displacement vectors are V (u,v,w) \u2208 R 3 and the random samples' center was R (X ,Y ,Z ) \u2208 N 3 . Now the global models' predicted hippocampus locations, G (X ,X ,Z ) are \nHere, X, Y, and Z are the center of the samples; u, v, and w are the displacement vectors in the 3D MR image space. We used these global predicted hippocampus locations as random points to extract patches from the same test MRI scan again. Then, these patches are utilized as input to the LH-CNN. Now, consider that LH-CNN predicted local displacement vectors are U (u,v,w) \u2208 R 3 . In this case, the random reference points are the global predicted hippocampi locations, G (X ,Y ,Z ) . Therefore, the local models' predicted hippocampus location, H (X ,Y ,Z ) are\nHere, k denotes the number of patches generated from each MRI scan. The whole process is depicted in Fig. 7 . The detailed localization process is explained in Algorithm 1.\nWe have tested these models with the ADNI MRI dataset and the GARD cohort dataset. For data separation in the ADNI MRI dataset, we considered the patient ID. From 8 patients, 56 MRI scans are used to test the model. The prediction errors (Euclidian distance) for the left and right hippocampi are shown in Table 3 . In the test phase, the predicted VOLUME 7, 2019 FIGURE 7. Left hippocampus localization using the ensemble Hough-CNN. This is a testing phase view of two stage ensemble Hough-CNN. In this phase, three view patches (axial, coronal, and sagittal) are used as an input to the individual model to estimate the displacement vectors (votes) for each patch. The averaged values of global displacement vectors (GDV) are added to random reference sampled points that results in ensemble hippocampus positions G (X ,Y ,Z ) . Now, using G (X ,Y ,Z ) , the second sets of random samples are generated from the same MRI scans, and utilized those samples as an input to the ensemble LH-CNN. The ensemble LH-CNN's averaged local displacement vectors (LDV) are concatenated with\nDividing the L (X ,Y ,Z ) by the number of patches extracted from each MRI scans, we can obtain the estimated hippocampus location, H (X ,Y ,Z ) . We have displayed the left hippocampus here. Similarly, we locate the right hippocampus. left and right hippocampi locations are shown in Fig. 8 to Fig. 11 in Appendix B for the ADNI MRI dataset.\nSimilarly, we performed the same test on the GARD cohort dataset of 65 MRI scans. The prediction errors (Euclidian distance) for the left and right hippocampi are shown in Table 4 . The predicted voxel locations are displayed in Fig. 12 to Fig. 15 in Appendix B."}, {"section_title": "IV. EVALUATION RESULT", "text": "In the test phase, we utilized both the GH-CNN and LH-CNN together to determine the hippocampus location in the test MRI and evaluate the error for the ADNI and GARD cohort datasets."}, {"section_title": "A. DATA SETS", "text": "We exploited two datasets in this research paper. The ANDI 1 and GARD cohort MRI datasets were used to train, validate and test the GH-CNN and LH-CNN. The ADNI dataset consists of 351 MRI scans with three classes (AD, MCI, and NC). There are 60 patient scans available in the ADNI dataset. From 351 MRI scans, 343 MRI scans are considered for training (228) (42 patients), validation (59) (10 patients) and testing (56) (8 patients). We used the patient ID to separate the dataset into the training, validation and testing sets. In the ANDI dataset, most of the scan dimensions are 256\u00d7256\u00d7170 with 1 mm 3 sized voxels. We also used the GARD cohort dataset, which contains 326 MRI scans of 326 patients. The GARD cohort dataset is divided into four classes (ADD, aAD, MCI, and NC). The GARD cohort dataset is divided into the training, validation, and testing set according to their patient identification number. Most of the MRI scans in the GARD cohort dataset have a dimension of 312\u00d7212\u00d7220 with 1 mm 3 sized voxels.\n1 Data collection and sharing for this project was funded by the Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http : //adni.loni.usc.edu/wp \u2212 content/uploads/how_to_apply/ADNI _Acknowledgement_ List.pdf"}, {"section_title": "B. PREDICTION ERROR CALCULATION", "text": "In the ADNI and GARD cohort MRI datasets, each MRI's pixel to pixel distance is approximately 1 mm. Therefore, in 3D MRI, the differences between target locations of the hippocampus and the ensemble Hough-CNN estimated locations of the hippocampus are the prediction errors in VOLUME 7, 2019 Euclidian space. an acceptable average RMS error of 2.24 mm between approximated hippocampus locations and the ground truth.\nThe training, validating and testing operations have been performed with an HP Workstation Intel Xeon Processor "}, {"section_title": "V. CONCLUSION", "text": "In this paper, we presented a joint approach consisting of Hough voting and deep CNN for accurate real time 3D anatomical structure localization in an MRI scan. For exact anatomical structure localization in an MRI scan, we combined Hough voting with a deep CNN. A deep CNN extracts feature maps from input sample images to vote for the center of the samples to calculate the displacement vectors pointing to the target structure. We introduced a two-stage ensemble learning strategy. In the primary phase, the GH-CNN learns all the information about the given training data and predicts the global displacement vectors near the region of anatomical interest. In the final phase, the LH-CNN learns the distinguishable features to predict local displacement vectors pointing towards the target location in the vicinity of the anatomical structure of interest.\nIn the testing phase, we utilized the global displacement vectors from random image pixel locations to extract samples for the LH-CNN. The local models used the predicted locations from the global models and estimated displacement vectors pointing to the target locations for each sample taken from the MRI scans. We used the random sample positions with their corresponding predicted displacement vectors to obtain the hippocampus locations from MRI scans.\nIn this work, we used the ADNI MRI dataset with 60 patients and GARD cohort dataset with 326 patients. Using our proposed approach, we accurately localized the left and right hippocampi. The average prediction error of the proposed approach of the ensemble Hough-CNN model in the test set was 2.31 mm for the left hippocampus and 2.04 mm for the right hippocampus in the 3D MRI space for the 56 MRI scan from the ADNI dataset. Similarly, for the 65 test MRI scans from the GARD cohort dataset, the average prediction error was 2.32 mm and 2.25 mm for left and right hippocampi, respectively. "}]