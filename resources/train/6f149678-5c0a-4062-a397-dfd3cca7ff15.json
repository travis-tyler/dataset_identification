[{"section_title": "", "text": "Perhaps Mathews should acquaint himself with Eric Hanushek's recent research on this very topic. Hanushek and his colleagues (Jamison, Jamison, and Woessman) used student performance on twelve standardized international tests in math and science as a measure of \"cognitive skills\" among those entering the workforce. They analyzed these data for 50 countries from 1960 to 2000. The countries included 30 democracies with market economies and relatively high levels of economic development and 20 countries with lower levels of economic development. Though the analysis was complicated, Hanushek's key finding was simple: The level of cognitive skills of a nation's students has a large effect on its subsequent economic growth rate. He also found that more years of schooling, previously thought to be the major advantage that other countries had over the U.S., only boosted the economy when it was tied with student learning. In other words, \"It is not enough simply to spend more time in school; something has to be learned there.\" Differences among countries' growth in their gross domestic products could be attributed, in part, to higher levels of cognitive skill as measured on international tests. In fact, the researchers estimate that a highly skilled workforce can raise economic growth by about two-thirds 1 For instance, for the TIMSS, countries are required to sample students in the upper of the two grades that contain the largest number of 9-and 13-year olds. In the U.S. and most countries, this corresponds to grades 4 and 8. Countries not satisfying one or more guidelines for sample participation are clearly noted in international reports. of a percentage point every year. Upon first blush, this doesn't sound all that impressive, but consider that a one percent higher growth rate sustained over 50 years yields incomes that are 64 percent higher. So, then, a relationship exists between increased student achievement on international measures and a healthy economy. But not so fast, say challengers in the \"defend-public-education-at-all-costs\" camp. They'd likely point out (Hanushek does) that the U.S. has never done particularly well on international assessments; we're as average as they come. Still, our GDP growth rate has been higher than average over the past 100 years. The authors, then, pose a reasonable question: If cognitive skills, as measured by international results, are so important to economic growth, how can we explain what's happened in the U.S.? The short answer, according to Hanushek and colleagues, is we have other educational and economic advantages. Educationally, the manner in which we expanded our education system over the 20th century -opening secondary schools at record numbers -is credited with stimulating economic growth, as are our renowned U.S. colleges and universities. Economically, the researchers extol our freer labor markets, reduced government regulation of firms, less powerful trade unions, and lower tax rates as growth boosters. Lest we be content to rest on our laurels, though, the analysts close with this warning: Although the strengths of the U.S. economy and its higher-education system offer some hope for the future, the situation at the K-12 level should spark concerns about the long-term outlook for the U.S. economy, which could eventually have an impact on the higher-education system as well\u2026Other countries are doing more to secure property rights and open their economies, which will enable them to make better use of their human capital. Most obviously, the historic advantage of the U.S. in school attainment has come to an end, as half of the OECD countries now exceed the U.S. in the average number of years of education their citizens receive. Those trends could easily accelerate in the coming decades. Simply put, we're living on borrowed time. Can we really afford to ignore what can only be described as our students' very ordinary performance on international exams? Sure, Americans score above average on some measures, but when it comes to comparisons with our economic peers, we fall pretty short. Isn't it possible that time is running out in terms of maintaining our economic edge? In the pages that follow, we present recent results from the most important and widely used international assessments of student performance. They include the Trends in International Mathematics and Science Study (TIMSS), the Progress in International Reading Literacy Study (PIRLS), The Programme for International Student Assessment (PISA), and the Civic Education Study (CIVED). We also consider high school and college graduation rates, and list the top three performers, our \"medal winners,\" in 58 discreet \"events.\" Unlike in the athletic Olympics, U.S. performance in the \"Education Olympics\" is, shall we say, uninspiring. Our strong performance in civics, in fact, avoids a complete medal shutout for the old red, white, and blue. Contrast this with our performance in the 2008 Summer Olympics in Beijing where the United States took home 110 medals (36 gold, 38 silver, 36 bronze medals), more than any other nation. 2 We've also sprinkled throughout our report some interesting sidebar blurbs about the top performing nations (according to our medal counts), since we're naturally curious about how education looks in these countries and what we might learn from them. We don't draw conclusions from these blurbs; they're intended to raise questions more than provide answers. Likewise, our report is not meant to be exhaustive or comprehensive, but user-friendly, suggestive, and even illuminating."}, {"section_title": "Executive Summary", "text": "Fact: The United States trails many of its economic peers on international measures that assess students' reading, mathematics, and science performance. Some people are deeply alarmed by that fact; others think there's no need to overreact. This report lays out the international evidence, in one pithy PDF file, so that you can judge for yourself whether there's cause for a nationwide shot in the arm or not. In recent weeks, we at the Thomas B. Fordham Institute have hosted a friendly international competition called the \"Education Olympics.\" We know the U.S. typically kicks some Olympic derriere every four years when the international competitions roll around. In fact, in the last ten summer or winter Olympic games, the U.S. has been among the top five medal winners. The games in Beijing were no exception. We led the overall total medal count with 110, making it the fourth straight Olympics that the U.S. has come home with the most medals. Our performance across the globe in education, however, is in stark contrast to the exhilarating athletic victories forged overseas. While the physical prowess of our athletes enables the U.S. to lug home buckets of shiny medals, our academic dexterity needs some serious sweat-onyour-brow training. This report presents the international data in a way that mirrors our Education Olympics web-event. In addition to compiling the overall results from several international assessments, we've laid out \"chunks\" of data (which we call \"events\") that highlight student performance on sub-tests or by sub-groups (such as males and females). We've awarded gold, silver, and bronze medals to those countries achieving at the highest levels. Some analysts won't like the fact that we've ranked these nations (see more about this in Chapter 1). Still, we hope that they (and you) will take the standings in the Olympic spirit in which they're bestowed -and not as statistical precision. We examine results from four well-known and generally respected international measures: The Programme for International Student Assessment (PISA). This one covers math and 1. science (like TIMSS), but also evaluates reading literacy and students' ability to apply what they've learned to real-world situations. It's administered to fifteen-year-olds every three years. We're examining data from both the 2003 and 2006 PISA administrations. The Trends in International Mathematics and Science Study (TIMSS). This assessment 2. addresses the knowledge and skills that students have acquired by grade four and eight in math and science. 3 It's administered every four years and we report on the latest year, 2003. [Results from the 2007 administration are not yet available.] The Progress in International Reading Literacy Study (PIRLS). This exam covers trends in 3. primary school reading. It's administered every five years and assesses the reading comprehension of students in their fourth year of schooling. We're reporting on the latest year, 2006. The Civic Education Study (CIVED). This exam is an international assessment of the civic 4. knowledge and skills of 14-year olds (eighth and ninth graders). It also examines student attitudes towards democracy and citizenship and willingness to participate in civic activities. We're examining the results from 1999, the last year it was administered. In addition, we examine two other indicators: 1) upper secondary (what Americans call high school) graduation rates and 2) the percentage of a country's college-going population that receives bachelor's degrees (international data on this are from 2004). 4 Drawing from these assessments and indicators, we developed 58 events, each focused on student performance on sub-tests or for sub-groups. Each event was an opportunity to win a gold, silver, or bronze medal; we had a few ties, which resulted in a total of 190 medals. The top three \"medal winners\" across all events are Finland (35 medals), Hong Kong (33), and Singapore (16) (see Table i). The United States wins just one medal: a gold for its performance on the Civic Education exam. That gives the U.S. a 20th place finish -below Cyprus, Poland, Slovenia, and the Russian Federation, among others. 56 4 Includes graduates of any age for the year 2004 divided by the number of persons at the typical age of graduation for respective countries (generally between ages 22-24). 5 All of the nations in Table 1 typically participate in the athletic Olympics, with the exception of Macao-China. 6 Chinese Taipei is commonly known as Taiwan. In terms of specific events, U.S. performance is lagging overall. But a few events are particularly depressing. Our fifteen-year-olds finish 30th out of 41 countries in their problem solving abilities (according to PISA 2003 results) and 31st out of 57 countries in their ability to explain various phenomena in scientific terms (PISA 2006 results). The U.S. places 38th out of 57 countries in terms of getting these same youngsters over PISA's most basic achievement level in science. And our low high school graduation rate lands us in eighteenth place out of 24 countries (according to 2004 OECD data). "}, {"section_title": "Tally Of Medal Winners", "text": "This chapter presents a summary of the \"events\" comprising our Education Olympics web competition (www.edolympics.net). For clarity, we've clustered them together by the assessment from which they were drawn. The events include medal winners from PISA 2003, TIMSS 2003, PIRLS 2006, and CIVED 1999 assessments, as well as two additional indicators (high school graduation rates and the percentage of a country's college-going population obtaining bachelor's degrees). Note this important caveat: When we examine results from international assessments, we must keep in mind that they are sample studies. In other words, the average scores of the student populations tested are only estimates of what the scores would have been if all the students in the country within the targeted population had been tested. Because they are estimates, a margin of error is involved. Consequently, when one country's estimated score is higher than another's (or higher than the international average), we cannot say with certainty that this difference in scores would have been identical had all students been tested. To surmount this analytic hurdle, researchers typically establish levels of statistical significance and say that one country is higher or lower than another (or than the international average) only when the difference is statistically significant. So, when the data are presented, nations are typically grouped into broad bands according to whether their performance is higher than, not significantly different from, or lower than that of the U.S. (see tables in Chapter 2 for this type of display). To rank countries without using these criteria is potentially misleading. We acknowledge this; a score of 564 for one country and a score of 565 for another doesn't necessarily mean that the latter country is ranked higher than the former. Yet we do rank in this report. We wanted our Education Olympics to mirror the real Olympics and we needed individual standings. And we don't intend this report to be a full-fledged scholarly analysis of international data; there are plenty of those (see our References page). So we ask that you view these rankings in the manner in which we've intended -as a user-friendly snapshot, not a bullet-proof statistical exercise. That said, Table 1 presents the total medal count by country. Nations winning no medals are not included here but are listed in the appendix (see Table A-1). The rankings are determined by the number of medals awarded to each nation. There are a total of 58 medal events and 77 participating nations. Keep in mind that all 77 nations did not participate in every assessment (see Chapter 2 for participation data), so the rankings are partly a product of how active countries choose to be in these several international assessments in various years.  Our first set of \"events\" is drawn from the PISA exam which tests fifteen-year-old students in mathematics, science, and reading literacy. The events listed in Table 2 show those nations with the most students performing at the top level on PISA (based on 2006 results). In other words, these events look at how many of each nation's students are among the \"best and brightest\" in the world. The events are divided into overall science performance by gender and by test subsection.  Table 3 show those nations with the fewest students performing at the lowest level on PISA in science (based on 2006 results) -which is a good thing. Naturally, some of the same countries that appear in Table 2 also appear in Table 3. The events are divided by overall performance in science by gender and by test subsection.  Table 4 show those nations that have the highest average scores on the problemsolving section of PISA (based on 2003 results). 7 These are the countries whose students do best when it comes to reasoning, deciding, and troubleshooting problems. PISA situates these problems in various contexts, such as personal life, work or leisure, and community settings. The events are divided by overall performance and by gender."}, {"section_title": "Events in", "text": "Events in Table 5 show those nations that have the highest average scores on the reading literacy section of PISA (based on 2003 results). These are the nations whose students do the best in terms of understanding and using written information for a variety of purposes. PISA uses multiple sources to assess literacy skills including narrative, descriptive, and expository writing, as well as charts, tables, and maps. Events are divided by overall combined performance and by gender. 7 Problem solving is assessed separately from math and science in PISA.   Table 6 show those nations that have the highest average scores on the mathematics literacy section of PISA (based on 2003 and 2006 results). [Overall score is from 2006. Male/ female scores from 2006 were not readily available, so those are from 2003.] These are the countries whose students do the best at formulating, solving, and interpreting math problems. PISA typically situates these problems in real-world settings such as those encountered when shopping, travelling, cooking, or handling personal finances. Events are divided by overall performance and by gender. Events in Table 7 show those nations that have the highest average scores on the science literacy section of PISA (based on 2006 results). These are the countries whose students do exceptionally well at retaining scientific facts and terms, understanding fundamental scientific concepts, and recognizing the limits of scientific knowledge. Events are divided by overall performance, performance by gender, and performance of first-generation immigrant students.  Events in Table 8 show those nations that have the highest average scores on the PISA subtest that measures students' ability to explain phenomena scientifically. These are the countries, for example, whose students do very well applying their knowledge of science to a given situation. Event results (drawn from 2006 PISA) are divided by overall performance and gender. Events in Table 9 show those nations that have the highest average scores on the PISA subtest that measures students' ability to identify scientific issues. These are the countries whose students do well, for example, knowing and recognizing what types of questions can be investigated scientifically. Event results (drawn from 2006 PISA) are divided by overall performance and gender.  Events in Table 10 show those nations that have the highest average scores on the PISA subtest that measures students' ability to use scientific evidence. In other words, these are the countries whose students are best able to make sense of scientific findings, distinguishing between real evidence and false claim. Event results (drawn from 2006 PISA) are divided by overall performance and gender.  Our second set of \"events\" is drawn from the TIMSS, which tests students in grade four and eight in mathematics and science. 8 Events in Table 11 show those nations that have the highest average scores in fourth-grade math (based on 2003 results). These are the countries whose youngsters do best overall in the subject, as well as in specific math areas like patterns and relationships, data, geometry, measurement, and numbers. Events are divided by overall performance, performance by gender, and performance by test subsection. Events in Table 12 show those nations with the highest average scores in eighth-grade math (based on 2003 results). These are the countries whose adolescents do best overall in the subject, as well in the specific math areas like algebra and geometry. Events are divided by overall performance, performance by gender, and performance by test subsection. Our third set of \"events\" is drawn from the PIRLS, which tests students in reading comprehension in their fourth year of schooling. Events in Table 13 show those nations that have the highest average scores on PIRLS overall and by subtest (based on 2006 results). These are the countries whose students did exceptionally well with various comprehension skills, such as retrieving and focusing on specific ideas, making simple and complex inferences, and examining and evaluating text features. Events from the Civic Education Study (CIVED) Our fourth set of \"events\" is drawn from the Civic Education Study. This assessment tests fourteen-year-olds on their civic knowledge and skills, as well as attitudes towards citizenship. It was last administered in 1999. Events in Table 14 show those nations with the highest average scores. Events include overall scores, as well as by content and skill areas. Students in these countries did well, for example, identifying key features of democracies and understanding political articles and political cartoons. "}, {"section_title": "Events from Other Data Sources", "text": "Our final set of \"events\" involves academic completion rates. The results are based upon 2004 data from the Organisation for Economic Cooperation and Development (OECD). The event in Table 15 shows those nations that have the greatest percentage of their total upper secondary education population (high school students) graduating. The event in Table 16 shows those nations that have the greatest percentage of their total college-going population receiving bachelor's degrees (at any age) for the year 2004. A complete list with the U.S. performance on all 58 medal events can be found in the appendix (Table A-2).  "}, {"section_title": "International Assessments and Results", "text": "This chapter provides a brief description of the international assessments reported in Chapter 1. We also include the nations that participated in each assessment for the year(s) examined and summary achievement data by country. Unlike the medal events in Chapter 1, however, we report international data in this section consistent with how it's reported by the National Center for Education Statistics (NCES) and the Organisation for Economic Co-operation and Development (OECD)."}, {"section_title": "PISA", "text": "The Programme for International Student Assessment (PISA) is an internationally standardized assessment that was jointly developed by participating countries and administered to fifteen-year-olds in schools. The test is carried out and overseen by the OECD. The assessment essentially asks what can students do with the mathematics and science that they have learned? It measures students' ability to apply what they have learned to real-world situations and to communicate solutions to others. Unlike the TIMSS, PISA is not tied to curriculum or schooling per se. Rather, it \"move[s] beyond the school-based approach towards the use of knowledge in everyday tasks and challenges.\" 9 The three primary domains assessed are mathematical literacy, scientific literacy, and problem solving. Like the TIMSS, the countries choosing to participate vary each time PISA is administered. The testing cycle is every three years and the tests are typically administered to between 4,500 and 10,000 students in each country. We present data from both the 2003 and 2006 (the latest) administration of PISA. Forty-one countries participated in 2003 and 57 countries did so in 2006. In all PISA cycles, the domains of reading, mathematical, and science literacy are assessed. The main focus of PISA 2003 was mathematical literacy and problem solving. For PISA 2006, the focus was on scientific literacy. Tables 17 and 18 present the average scores for PISA 2006 math literacy and science literacy. As shown in Table 17, 31 nations have statistically higher math averages than the United States, including Finland, Canada, Denmark, and Iceland. Plus, the U.S. average of 474 is lower than the OECD average of 498. The picture for science (Table 18) is much the same. Twenty-two nations have statistically higher science averages than the U.S. The U.S. average (489) is below the OECD average (500). 9 PISA 2003 Assessment Framework, OECD, pg. 10.     Chapter 2: International Assessments and Results"}, {"section_title": "(cont'd)", "text": "Tables 19 and 20 present the average scores for PISA 2003 reading literacy and problem solving. As shown in Table 19, twelve nations score statistically higher than the U.S. in reading literacy. These include Finland, Canada, Sweden, and Belgium. The U.S. average (495) is barely above the international average (494). Twenty-six nations score statistically higher than the U.S. in terms of their problem solving prowess ( Table 20). These include France, Germany, Ireland, and Poland. The U.S. average (477) is below the OECD average (500).    Average is higher than U.S. Average Average is not measurably different from U.S. Average Average is lower than U.S. Average\nIn short, the United States consistently underperforms internationally on the PISA math, science, reading, and problem solving measures. And, unlike on the TIMSS and PIRLS measures, we typically score below the international average. Both our economic peers (such as Japan, France, and the United Kingdom) and our non-economic competitors (such as Slovenia, Latvia, and Lithuania) significantly outperform us in one or more of these areas. \nTables 23 and 24 present the average scale scores for eighth-grade math and science. In math, nine nations score significantly higher than the U.S., though our 504 average is higher than the international average (466). The story is similar for eighth-grade science (Table 24) where seven nations have statistically higher averages, though our average (527) is again higher than the international average (473).  Botswana, Bulgaria, Chile, Egypt, Estonia, Ghana, Indonesia, Israel, Jordan, Republic of Korea, Lebanon, Republic of Macedonia, Malaysia, Palestinian National Authority, Romania, Saudi Arabia, Serbia, Slovak Republic, South Africa, Sweden    Average is lower than U.S. Average\nIn short, the U.S. trails on TIMMS many (but not all) other nations which are considered our economic peers (or rivals, some would say). Many will point out, however, that we score above the international average on the TIMSS measures. And while that's true, it's important to remember that averages are drastically lowered by developing nations (such as Ghana, Egypt, South Africa, and Botswana). The Thomas B. Fordham Institute"}, {"section_title": "TIMSS", "text": "The Trends in International Mathematics and Science Study (TIMSS) is an international study that addresses the knowledge and skills that students have acquired by grades four and eight in mathematics and science. The test is administered every four years with variation in the grade and age levels tested. The countries choosing to participate may also be different for different administrations of the test. The year for which we report, 2003, is the third (and latest) comparison of mathematics and science achievement carried out since 1995 by the International Association for the Evaluation of Educational Achievement (IEA), an international organization of national research institutions and governmental research agencies. 10 For the 2003 administration, 25 countries participated at grade four and 45 countries participated at grade eight. TIMSS can be used to track changes in achievement over time. Unlike PISA, it is closely linked to the curricula of the participating countries, providing an indication of the degree to which students have learned concepts in mathematics and science they have encountered in school. TIMSS also includes survey data and classroom video data which measure what is taught and how in a sample of countries. Tables 21 and 22 present the average scale scores for fourth-grade math and science. As shown in Table 21, eleven nations have statistically higher math averages than the U.S.; however, the U.S. average of 518 is above the international average of 495. One of our best performances is in fourth-grade math (Table 22). Only three nations score statistically higher than the U.S. (Singapore, Chinese Taipei, and Japan). Our 536 average is higher than the 489 international average.    Botswana, Bulgaria, Chile, Egypt, Estonia, Ghana, Indonesia, Israel, Jordan, Republic of Korea, Lebanon, Republic of Macedonia, Malaysia, Palestinian National Authority, Romania, Saudi Arabia, Serbia, Slovak Republic, South Africa, Sweden.  Average is lower than U.S. Average"}, {"section_title": "PIRLS", "text": "The Progress in International Reading Literacy Study (PIRLS) is an international assessment of trends in primary school reading. It is administered every five years and assesses the reading comprehension of students in their fourth year of schooling. In 2006, PIRLS was conducted in 40 countries. (Considering Belgium's two education systems and Canada's five participating provinces, that makes for 45 participants.) The sample included a nationally representative sample of fourth-grade students in the United States. The PIRLS assessment measures student performance on a combined reading literacy scale and on literary and informational subscales. The former uses narrative fiction to assess students' abilities to read and understand literature. The latter uses a variety of informational texts to assess students' abilities to acquire and use information while reading. PIRLS 2006 also gathered information about classrooms and schools via student, teacher, and principal questionnaires. Table 25 presents the average combined literacy scores for fourth-grade students. As shown, ten nations (or provinces) score statistically higher than the U.S., including Hong Kong, Sweden, and Italy. The U.S. literacy average of 540, however, is higher than the international average of 500. Once again, the U.S. trails some of our economic peers, this time in reading literacy. But we also outperform some of them, including New Zealand, France, and Norway. "}, {"section_title": "Civic Education Study (CIVED)", "text": "The Civic Education Study is an international assessment of the civic knowledge and skills of fourteen-year-olds (eighth and ninth graders) in 28 countries. It also examines student attitudes toward democracy and citizenship and willingness to participate in civic activities. The assessment is not designed to measure knowledge of a particular country's government but measures knowledge and understanding of key civic principles that are universal across democracies. Like TIMSS, the assessment is carried out by the International Association for the Evaluation of Educational Achievement (IEA), an international organization of national research institutions and governmental research agencies. The 1999 Civic Education Study was the first IEA study in this subject area since 1971. Roughly 90,000 fourteen-year-old students from 28 countries participated, as well as thousands of their teachers and principals (through separate questionnaires). To our knowledge, there are no present plans to re-administer the CIVED. In the United States, the assessment was administered to 2,811 students in 124 public and private schools at the beginning of ninth grade. Table 26 presents the average scores by country for the CIVED 1999 assessment. As shown, no countries have significantly higher average scores than the U.S. and our average score (106) is higher than the international average (100). The performance of the U.S. on CIVED is heartening and could be cited as evidence of our international agility. But keep this in mind, too: fewer nations participate in CIVED than the other international assessments. There's also less variation in the scores. The \"democratic\" content, too, naturally favors nations like the U.S. Finally, CIVED doesn't have the track record that the other international measures have established. "}, {"section_title": "Other Measures", "text": "In addition to the PISA, TIMSS, PIRLS, and CIVED data, we include limited 2004 data from the Organisation for Economic Cooperation and Development (OECD). Specifically, we examine academic completion rates (i.e., high school graduation rates and percentage of a country's college-going population receiving bachelor's degrees). Tables 27 and 28 present these data. As shown (Table 27), Norway, Germany, and Korea have the highest upper secondary (what we call high school in the U.S.) graduation rates. The U.S. rate (75.4) falls below the OECD international average (81.1). In addition, Finland, at 55.2 percent, has the greatest percentage of its college-going population receiving bachelor's degrees in 2004 at any age ( Table 28). The U.S. percentage is 33.3.   "}]