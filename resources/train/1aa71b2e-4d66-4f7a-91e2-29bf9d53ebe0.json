[{"section_title": "Abstract", "text": "Multivariate pattern analysis techniques have been increasingly used over the past decade to derive highly sensitive and specific biomarkers of diseases on an individual basis. The driving assumption behind the vast majority of the existing methodologies is that a single imaging pattern can distinguish between healthy and diseased populations, or between two subgroups of patients (e.g., progressors vs. non-progressors). This assumption effectively ignores the ample evidence for the heterogeneous nature of brain diseases. Neurodegenerative, neuropsychiatric and neurodevelopmental disorders are largely characterized by high clinical heterogeneity, which likely stems in part from underlying neuroanatomical heterogeneity of various pathologies. Detecting and characterizing heterogeneity may deepen our understanding of disease mechanisms and lead to patientspecific treatments. However, few approaches tackle disease subtype discovery in a principled machine learning framework. To address this challenge, we present a novel non-linear learning algorithm for simultaneous binary classification and subtype identification, termed HYDRA (Heterogeneity through Discriminative Analysis). Neuroanatomical subtypes are effectively captured by multiple linear hyperplanes, which form a convex polytope that separates two groups (e.g., healthy controls from pathologic samples); each face of this polytope effectively defines a disease subtype. We validated HYDRA on simulated and clinical data. In the latter case, we applied the proposed method independently to the imaging and genetic datasets of the Alzheimer's Disease Neuroimaging Initiative (ADNI 1) study. The imaging dataset consisted of T1-weighted volumetric magnetic resonance images of 123 AD patients and 177 controls. The genetic dataset consisted of single nucleotide polymorphism information of 103 AD patients and 139 controls. We identified 3 reproducible subtypes of atrophy in AD relative to controls: (1) diffuse and extensive atrophy, (2) precuneus and extensive temporal lobe atrophy, as well some prefrontal atrophy, (3) atrophy pattern very much confined to the hippocampus and the medial temporal lobe. The genetics dataset yielded two subtypes of AD characterized mainly by the presence/absence of the apolipoprotein E (APOE) \u03b54 genotype, but also involving differential presence of risk alleles of CD2AP, SPON1 and LOC39095 SNPs that were associated with differences in the respective patterns of brain atrophy, especially in the precuneus. The results demonstrate the potential of the proposed approach to map disease heterogeneity in neuroimaging and genetic studies."}, {"section_title": "Introduction", "text": "Automated analysis of spatially aligned medical images has become the main framework for studying the anatomy and function of the human brain. This is typically performed by either employing voxelbased (VBA) or multivariate pattern analysis (MVPA) techniques.\nVBA complements region of interest (ROI) volumetry by providing a comprehensive assessment of anatomical differences throughout the brain, while not being limited by a priori regional hypotheses. VBA typically performs mass-univariate statistical tests on either tissue composition or deformation fields, aiming to reveal regional anatomical or shape differences (Ashburner et al., 1998; Goldszal et al., 1998; Ashburner and Friston, 2000; Davatzikos et al., 2001; Chung et al., 2001; Fox et al., 2001; Job et al., 2002; Kubicki et al., 2002; Chung et al., 2003; Studholme et al., 2004; Bernasconi et al., 2004; Giuliani et al., 2005; Job et al., 2005; Meda et al., 2008; Ashburner, 2009) . However, voxel-wise methods often suffer from low statistical power and more importantly, ignore multivariate relationships in the data.\nOn the other hand, MVPA techniques have gained significant attention due to their ability to capture complex relationships of imaging signals among brain regions. This property allows to better characterize group differences and could potentially lead to improved diagnosis and personalized prognosis. As a consequence, machine learning methods have been used with increased success to derive highly sensitive and specific biomarkers of diseases on individual basis (Mour\u00e3o Miranda et al., 2005; Kl\u00f6ppel et al., 2008; Davatzikos et al., 2008; Vemuri et al., 2008; Duchesne et al., 2008; Sabuncu et al., 2009; McEvoy et al., 2009; Ecker et al., 2010; Hinrichs et al., 2011; Cuingnet et al., 2011) .\nA common assumption behind both VBA and MVPA methods is that there is a single pattern that distinguishes the two contrasted groups. In other words, most computational neuroimaging analyses assume a single unifying pathophysiological process and perform a monistic analysis to identify it. However, this approach ignores the heterogeneous nature of diseases, which is supported by ample evidence. Typical examples of brain disorders that are characterized by a heterogeneous clinical presentation include both neurodevelopmental and neurodegenerative disorders: autism spectrum disorder (ASD) comprises neurodevelopmental disorders characterized by deficits in social communication and repetitive behaviors (Geschwind and Levitt, 2007; Jeste and Geschwind, 2014) ; schizophrenia and Parkinson's disease can be subdivided into distinct groups by separating its symptomatology to discrete symptom domains (Buchanan and Carpenter, 1994; Graham and Sagar, 1999; Koutsouleris et al., 2008; Nenadic et al., 2010; Zhang et al., 2015; Lewis et al., 2005 ); Alzheimer's disease (AD) can be separated into three subtypes on the basis of the distribution of neurofibrillary tangles (Murray et al., 2011) ; and mild cognitive impairment (MCI) may be further classified based on the type of specific cognitive impairment (Huang et al., 2003; Whitwell et al., 2007) .\nDisentangling disease heterogeneity may significantly contribute to our understanding and lead to a more accurate diagnosis, prognosis and targeted treatment. However, few research efforts have been focused on revealing the inherent disease heterogeneity. These approaches can be categorized into two distinct classes. The first class assumes an a priori subdivision of the diseased samples into coherent groups, based on independent (e.g., clinical) criteria, and opts to identify group-level anatomical or functional differences using univariate statistical methods (Huang et al., 2003; Koutsouleris et al., 2008; Nenadic et al., 2010; Whitwell et al., 2012; Zhang et al., 2015) . As a consequence, multivariate relationships in the data are ignored. Moreover, and more importantly, these methods depend on an a priori disease subtype definition, which may be either difficult to obtain (e.g., from autopsy near the date of imaging), or noisy and non-specific (e.g., cognitive or clinical evaluations). Methods belonging to the second class apply multivariate clustering (typically driven by all image elements) directly to the diseased population towards segregating subsets of distinct anatomical subtypes (Graham and Sagar, 1999; Whitwell et al., 2007; Lewis et al., 2005; Noh et al., 2014) . Such an approach aims to cluster brain anatomies instead of pathological patterns. Thus, it has the potential risk of estimating clusters that reflect normal inter-individual variability, some of which is due to sex, age and other confounds, instead of highlighting disease heterogeneity.\nIn order to tackle the aforementioned limitations, it is necessary to develop a principled machine learning approach that is able to simultaneously identify a class of pathological samples and separate them into coherent subgroups based on multivariate pathological patterns. To the best of our knowledge, one approach has been previously proposed in this direction (Filipovych et al., 2012) . That work tackled disease subtype discovery by simultaneously solving classification and clustering in a semi-supervised maximum margin framework. It jointly estimated two hyperplanes, one that separates the diseased population from the healthy one, and another hyperplane that splits the estimated diseased population into two groups. Thus, only one linear classifier was used to separate patients from controls, thereby limiting its ability to capture heterogeneous pathologic processes. Moreover, it arbitrarily assumed that exactly two disease subgroups exist, rather than attempting to determine the number of subtypes from the data.\nHere, we propose a novel non-linear semi-supervised 2 machine learning algorithm for integrated binary classification and subpopulation clustering aiming to reveal heterogeneity through discriminant analysis (HYDRA). To the best of our knowledge, ours is the first algorithm to deal with anatomical/genetic heterogeneity in a supervisedclustering fashion with arbitrary number of clusters. The proposed approach is motivated by recent machine learning methods that derive non-linear classifiers through the use of multiple-hyperplanes (Fu et al., 2010; Gu and Han, 2013; Varol and Davatzikos, 2014; Kantchelian et al., 2014; Tak\u00e1cs, 2009; Osadchy et al., 2015) . Classification is performed through the separation of healthy controls from pathological samples by a convex polytope that is formed by combining multiple linear max-margin classifiers. Heterogeneity is disentangled by implicitly clustering pathologic samples through their association to single linear sub-classifiers. Multiple dimensions of heterogeneity may be captured by varying the number of estimated hyperplanes (faces of the polytope). This is in contrast to non-linear kernel classification methods which may accurately fit to heterogeneous data in terms of disease prediction, but do not provide any explicit clustering information that can be used to determine subtypes of pathology. HYDRA is a hybrid between unsupervised clustering and supervised classification methods; it can simultaneously fit maximum margin classification boundaries and elucidate disease subtypes, which is not possible with neither unsupervised clustering methods nor non-linear kernel classifiers.\nNote that a preliminary version of this work was presented in (Varol et al., 2015) . The current paper extends our previous work in multiple ways: (i) A more sophisticated initialization scheme based on determinental point processes is employed (Sec. Appendix A.1); (ii) the sensitivity to initialization due to the non-convexity of the objective function has been improved by using multiple initializations and consensus strategies (Sec. Appendix A.4); (iii) a symmetric version of the algorithm is developed towards accounting for the heterogeneity of the healthy controls and avoiding over-learning (Section 2.4); (iv) a detailed description of the proposed methodology is provided; (v) we extensively evaluate our method, HYDRA, by using additional (imaging and genetic) datasets and comparing it to unsupervised clustering and non-linear classification methods.\nThe remainder of this paper is organized as follows. In Section 2, we detail the proposed approach. Next, we experimentally validate our method using synthetic (Section 3) and clinical (Section 4) data. We discuss the results in Section 5, while Section 6 concludes the paper with our final remarks."}, {"section_title": "Method", "text": "In high dimensional spaces, the modeling capacity of linear support vector machines (SVMs) is theoretically rich enough to discriminate between two homogeneous classes. However, while two classes are linearly separable with high probability, the resulting margin may be small. This case arises, for example, when one class is generated by a multimodal distribution that models a heterogeneous process (see Fig. 1a ). This may be remedied by the use of non-linear classifiers, allowing for larger margins and thus, better generalization. However, while kernel methods, such as Gaussian radial basis function (GRBF) kernel SVM, provide non-linearity, they lack interpretability when aiming to characterize heterogeneity.\nHere, we take advantage of the previous intuition to design a novel machine learning technique that will provide larger margins while being able to elucidate heterogeneity. We introduce non-linearity using multiple linear classifiers that form locally linear hyperplanes whose linear segments separate the clusters of negative samples from the positive class (see Fig. 1b ). In this way, subjects are explicitly clustered by being assigned to different hyperplanes, giving rise to interpretable directions of variability that may be useful in discovering heterogeneity.\nSuppose that our dataset consists of n binary labelled d-dimensional data points \u00f0D \u00bc \u00f0x i ; y i \u00de n i\u00bc1 ; x i \u2208\u211d d and y i \u2208f\u22121; 1g\u00de . Without loss of generality, we assign the negative class to the pathological population whose heterogeneity we seek to reveal. Let us note that while there may be heterogeneity in the healthy population, we focus here on revealing disease heterogeneity. Our aim is twofold. First, we aim to estimate k hyperplanes that form a convex polytope that separates the two classes with a large margin. Second, we aim to assign each pathological sample to the hyperplane that best separates it from the normal controls. The main idea is that samples that belong to different pathological subgroups will be assigned to different hyperplanes, each of which reflects a respective pathological process (see Fig. 1c ). Towards fulfilling the aforementioned aims, we introduce the proposed approach by extending standard linear maximum margin classifiers."}, {"section_title": "Large margin classification", "text": "For completeness, let us briefly introduce standard linear maximum margin classifiers. Maximum margin classifiers aim to estimate a hyperplane that separates the two classes by a half space, while ensuring that the distance (or margin) from the decision boundary for each sample is maximized. More formally, suppose that the set F comprises the set of all linear classifiers w such that for the given dataset D all samples are correctly classified, or \u2200i , y i (w\nThe goal is to find the classifier w belonging to the set F that maximizes the margin between classes. The margin is defined as the orthogonal distance between the two hyperplanes:\nwhere the set of points u, v that satisfy the equations, represent points from both classes with active constraints. Notice that setting u \u00bc \u2212 w satisfies the previous equations. Since u, v are parallel, the orthogonal distance between the hyperplanes is simply ku\u2212vk 2 \u00bc 2 kwk 2 , which is the margin for SVM (Vapnik, 2000) .\nThe optimal classifier is estimated by solving an optimization problem. However, instead of maximizing the margin, its inverse \u00f0 kwk 2 2 2 \u00de is typically minimized subject to the separability constraints. This results in the well known SVM objective:\nsubject to\nwhere \u03be = (\u03be 1 , \u2026 , \u03be n ). The second term of the objective \u00f0C\u2211 n i\u00bc1 \u03be i \u00de accounts for slack when classes are non-separable."}, {"section_title": "Convex polytope classification", "text": "Standard SVMs assume that there is a single pattern (encoded by the estimated hyperplane) that distinguishes the two classes. However, this assumption is violated in the case of heterogeneity. We aim to model heterogeneity by utilising multiple linear hyperplanes, each one corresponding to a different pathological pattern. By combining multiple linear classifiers in a piecewise fashion, we extend linear max-margin classifiers to the non-linear case. Thus, we consider the extended hypothesis class that consists of the set of sets of K hyperplanes, generalizing the geometry of the classifier to that of a convex polytope (Tak\u00e1cs, 2009 ). Due to the interior/exterior asymmetry of the polytope, it is necessary to confine one class to its interior while restricting the other class to its exterior. Without loss of generality, we confine the positive class to the interior of the polytope. Thus, the search space F K is defined as\nIn other words, F K comprises all sets of K classifiers such that all classifiers correctly classify all members of the positive class, while for every negative sample, there is at least one classifier that correctly classifies it.\nThe latter gives rise to an assignment problem, where samples that have been affected by the same pathological process are assigned to the same hyperplane. This can also be seen as a clustering task since samples that have been assigned to the same hyperplane can be equivalently considered as clustered together. Thus, if\nn \u2212 \u00d7K denotes the binary matrix that describes the assignment of the i-th negative class sample (n \u2212 in number) to the j-th face of the polytope, then the search space becomes:\nGiven the assignment S \u2212 , there are K margins; each one corresponding to one face of the polytope. Analogous to the SVM formulation, the margin for the j-th face of the polytope is 2 kw j k 2 . However, due to the piecewise nature of the convex polytope, there are multiple notions of margin for the surface of the polytope. In this work, aiming to keep the problem tractable, we maximize the average margin across all the faces of the polytope:\n. Thus, for a given dataset D and assignment S \u2212 for the negative class, the objective becomes:\nNote that, given the assignments, the objective and the constraints are separable into K-independent subproblems. Each subproblem is analogous to the SVM formulation after adding the slack terms \u03be i,j , or\nwhere C is a penalty parameter on the training error. If we now use the definition of the slack terms as \u03be i ,j = max{0,1-y i (w j T x i + b j )}, and consider all hyperplanes ({W,b} \u225c{w j , b j } j =1 K ) at the same time, we get:\nSo far, we have assumed that the assignment matrix S \u2212 is known.\nHowever, this is not the case in practice and S \u2212 has to be estimated too.\nAttempting to solve for both {W, b} and S \u2212 results in a non-convex objective function which is combinatorially difficult to optimize. Furthermore, optimization for the binary assignment S \u2212 is itself nonconvex since it constitutes an integer programming task. To make the problem tractable, we take two steps. First, we relax the binary assignment (s i , j \u2208 {0, 1}) to a soft assignment (\n. Given this relaxation, the objective becomes block-wise convex with respect to the groups of variables {W, b} and {S \u2212 }. We then use this relaxed objective function to obtain locally optimal solutions by iteratively solving for {W, b} and {S \u2212 }. The details of the iterative optimization are given in Appendix A."}, {"section_title": "Prediction", "text": "Once the polytope classifier {W, b} is trained, predicting the class y \u204e of a new instance x \u204e is straightforward:\nIn other words, if x \u204e is in the interior of the polytope defined by the estimated hyperplanes ({W,b}), then it is classified as positive by all classifiers corresponding to the faces of the polytope (w j T x \u204e +b j N 0), resulting in an overall positive class prediction (y \u204e = + 1). Otherwise, if x \u204e is in the exterior of the polytope, then it is classified as negative by at least one classifier corresponding to a face of the polytope (w j T x \u204e + b j b 0), resulting in an overall negative class prediction (y \u204e = -1). Analogously, the prediction score is simply the minimum of the prediction scores of all classifiers corresponding to the faces of the polytope: ( min\nMoreover, a new sample may be assigned to the existing clusters by computing the assignment index s \u204e,j using Eq. (A.1)."}, {"section_title": "HYDRA algorithm", "text": "Given the solutions of {W, b} and S \u2212 outlined in Sec. Appendix A.2\nand Sec. Appendix A.3, we solve for the maximum margin convex polytope in an iterative fashion. This is the main workhorse behind the proposed framework that aims to elucidate heterogeneity through discriminative analysis (HYDRA) and is outlined in Algorithm 1. However, due to the non-convex nature of the problem, it is necessary to take additional steps to ensure the high quality of the solution. Our approach towards enhancing the quality of the solution is twofold. First, particular care is taken to initialize the iterative algorithm in such a way that clustering solutions that exhibit diseaserelated diversity are promoted. This is made possible by employing determinental point processes (DPP) (Kulesza and Taskar, 2012) to sample diverse directions of pathology, which can subsequently be used to estimate the initial clustering assignments (see Appendix A.1 for details).\nSecond, acknowledging the fact that, in non-convex settings, the estimated solution may vary greatly depending on the initialization, we employ a multi-initialization strategy that is coupled with a fusion step. Multiple runs of the Algorithm 1 are performed using different initializations generated by the previously described DPP sampling process, as well as different subsets of the population. The estimated clusters constitute hypotheses that capture perturbations of the underlying group topography. These clustering hypotheses are aggregated by taking into account the consensus of the respective solutions, producing the final clustering result that is free of noisy perturbations and emphasizes the underlying group structure (see Appendix A.4 for details). "}, {"section_title": "Symmetric HYDRA algorithm", "text": "The algorithm that we have so far outlined is asymmetric. The patients lie on the exterior of the polytope while the controls are constrained on the interior of the polytope. This property may result in over-fitting when classifying. This can be remedied by symmetrizing the algorithm. One can run the Algorithm 1 twice, once using the actual labels Y and once using the negated labels: -Y. ] to make predictions using the following formula:\nwhere both classifiers are taken into account.\nNote that the symmetric model does not affect the clustering of the patients since the two runs of Algorithm 1 are independent of each other. The difference is that the symmetric model provides two clusterings, one for the patients and one for the controls."}, {"section_title": "Experiments using simulated data", "text": "We first validated the proposed method using synthetic data. We used a two-dimensional toy dataset to provide insight into the workings of the proposed approach. Then, we quantitatively validated the proposed approach against common clustering and classification approaches in a simulated dataset where heterogeneity has been introduced. We evaluated the ability of HYDRA to distinguish between two classes and demonstrated its potential to reveal relevant subgroups.\nLet us note that for all experiments, the classification was performed using the symmetric version of HYDRA, while the clustering of the negative class was used to reveal disease heterogeneity. The final clustering was the consensus result of twenty repetitions. The primal formulation was employed when tackling low-dimensional data, while the dual formulation was preferred in the case of high-dimensional data (see Appendix B.1 for the dual formulation)."}, {"section_title": "Toy example", "text": "To illustrate the behavior of our method, we generated a synthetic two-dimensional dataset with thousand instances (see Fig. 2 ). The first half of the samples were drawn from a unimodal distribution, simulating the healthy control population (denoted by magenta squares). The other half consisted of a crescent-shaped cluster of points, corresponding to the heterogeneous disease group (denoted by rhombuses colored using different variants of blue). To provide a more comprehensive setting, we additionally considered two different separability cases between the two populations. In the first case (see Fig. 2a ), the two classes overlapped highly, resulting in low separability. In the second case (see Fig. 2d ), the two groups did not overlap and were separated by a significant margin, thus increasing separability.\nTo further clarify the advantages of the proposed framework, we compared the performance of HYDRA (using two hyperplanes, K =2) against the performance of standard linear SVM. The results of the experiments are shown in Fig. 2 . There are two important observations to make. First, the introduced non-linearity in HYDRA allows for improved separability between the two groups in both scenarios (see Figs. 2b, c, e and f) . This increase is more important in the case of lowseparability between classes (see Figs. 2b and c), where the linear SVM was not able to fully separate them. In the case of high separability, the hyperplane that was estimated by the linear SVM effectively separated positive from negative samples. However, it did so by a relatively small margin (see Fig. 2b ). On the other hand, HYDRA harnessed the non-linear structure of the data and separated them with a high margin that led to improved generalization performance (see Fig. 2f ).\nSecond, and most importantly, HYDRA separated the negative class into two subgroups that differ from the positive class in two distinct directions. This clustering is directly related to the hyperplanes that separate the two classes. As a consequence, the obtained clustering is obtained in a supervised fashion and thus, it is driven by discriminating patterns that capture disease heterogeneity. This is in contrast to standard clustering techniques that group together samples based on appearance, which is not necessarily related to disease variability."}, {"section_title": "Simulated high-dimensional heterogeneous data", "text": "Despite ample evidence of disease heterogeneity, the lack of labeled ground-truth poses a fundamental obstacle in validating the proposed approach. Thus, to overcome these limitations, we construct a simulated validation setting that allows for quantitative comparisons with other algorithms.\nAiming to replicate the common high-dimensional low sample size regime that is prevalent in neuroimaging studies, we generated a synthetic dataset with three hundred instances (or subjects) that are sampled as images with features on a 64 \u00d7 64 grid. The positive class (healthy group) was generated by randomly sampling 150 samples from a multivariate unimodal Gaussian distribution with zero mean and unit variance (N \u00f00; 1\u00de). The negative class (disease group) was generated by drawing 150 samples from a tri-modal distribution, where each mode simulates a different focus of disease progression (see Fig. 3a ). Each focal effect had a radius of 10 pixels, with a variance of 0.5 units. To simulate the effect of disease progression, an age effect was simulated. This was generated by adding unit variance random noise to simulate progression. Therefore, there were three distinct focal effects in each subgroup, the subgroup specific effect with variance 1.5 units and the non-specific effects with unit variance. Additionally, 10% of the labels were mislabeled to simulate misdiagnosis and label noise."}, {"section_title": "Validation measures", "text": "HYDRA is in principle an exploratory analysis tool, aiming to reveal disease heterogeneity. However, it operates by simultaneously (c) Similarly, the groups that were obtained using K-means (K=3) are reported. Note that the groups estimated by HYDRA capture distinct focal effects that align well with the simulated ones, while the ones estimated by K-means mix the focal effects and recapitulate different stages of disease progression.\nperforming classification and clustering. Thus, it is of interest to understand how well the proposed method accomplishes each step.\nTo validate the classification performance, we computed the area under the receiver operating characteristic curve (AUC) (Bradley, 1997) . The AUC statistic summarizes the quality of the performance of a binary classifier. It is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one. Thus, an AUC equal to one indicates a perfect classifier. We calculated a distribution of AUC values by performing 100 realizations of 10-fold cross-validation. During each iteration, the data were partitioned into ten folds. Each fold was successively used as a test set while the remaining folds were used to train the method. The optimal parameter C of the method was estimated by performing a grid search over C\u2208 {2 -5 , \u2026 ,2 3 } using an internal round of 10-fold cross-validation. The clustering performance of our approach was assessed by taking into account the stability of the obtained results. The adjusted Rand index (ARI) (Hubert and Arabie, 1985) was used to quantify the similarity between different clustering results. This index is corrected for grouping by chance, resulting in a more conservative estimation of the overlap. A value equal to one indicates a perfect clustering. We calculated the ARI in a cross-validated fashion, following the previously described cross-validation scheme. However, in our calculations, we took into account only the clustering stability between training folds. Any pair of training folds shared 80% of the subjects, allowing us to compute how consistently the common subjects were placed in the same clusters despite the variations due to the~10% difference in the sample composition across folds. In detail, given the optimal C value that was estimated during the inner-fold cross-validation, we trained the model, yielding a clustering of the negative subjects in the training set. This procedure was repeated for all realizations of the 10-fold cross-validation, yielding a set of clusterings of the negative subjects of the respective training sets. Finally, we computed the average pairwise ARI between the estimated clusterings.\nLet us note that the classification accuracy and the clustering stability are only surrogate measures that allow us to elucidate the underpinnings of the proposed method. HYDRA does not directly target increased classification accuracy, but instead it focuses on detecting disease subgroups. Moreover, while clustering stability is desirable, it does not necessarily imply that the estimated clusters correspond to the underlying heterogeneity. Quantitatively evaluating the relevance of the clustering to the intrinsic heterogeneity is in general not feasible. However, in this simulated scenario, the ground truth was available by default. Thus, we calculated the ARI between the estimated clusters and the simulated ones. Moreover, to further assess the performance, we conducted group analysis between the estimated subgroups and the positive class. The derived p-value maps allow for the visualization of the estimated clusters and their comparison to the generated ones."}, {"section_title": "Comparison with existing methods", "text": "To further validate HYDRA, we compared it to common classification and clustering approaches.\nAs far as classification is concerned, we first compared our method against linear SVMs. In fact, our method is a generalization of the linear SVM framework. By setting the parameter K equal to one, our method reduces to a linear SVM classifier. Parameter selection (i.e., fixing C value) was performed using the same strategy as the one for the proposed framework.\nMoreover, because HYDRA establishes a non-linear separation boundary between the two classes, we contrasted its performance against the GRBF kernel SVM. The free parameters were determined through a nested cross-validation strategy. A grid search was performed over the parameter space defined by the regularization parameter C (C \u2208 {2 Verifying that HYDRA achieves comparable accuracy with commonly used classifiers, thus retaining discriminative power, is important because discrimination is inextricably tied to the cluster definition. However, the main focus of the method is on discovering clusters in the abnormal cohort. To validate the clustering potential of our framework, we included the performance of the K-means clustering (Lloyd, 1982) (20 replicates were used). We also examined the potential of the approach that performs classification on top of the clustering results. In particular, we first used K-means to cluster samples from one class and then trained a linear SVM for each cluster. This procedure was performed for both the negative and positive classes. The out of sample prediction was obtained using Eq. (2). This approach (Gu and Han, 2013 ) is termed here K-means/SVM. Similar to the previous cases, nested crossvalidation was performed for selecting the C parameter. Note also that we run K-means and HYDRA for the same value of the parameter K that varied from one to nine (K\u2208 {1, \u2026 , 9})."}, {"section_title": "Results", "text": "The results of the cross-validated classification accuracy are reported in Fig. 4a . We note that the classification results depend on the value of the parameter K. The high dimension and low sample size setting allowed linear SVM to separate the two classes with high accuracy. However, the non-linearity that is introduced by Gaussian SVM, as well as by HYDRA and K-means/SVM, resulted in a slight improvement in the classification performance (see also Table 1 ). We should underline that a statistically significant improvement of the performance was observed only for HYDRA results (p-value for t-test comparison between K = 3 HYDRA results and linear SVM equals to 0.016). Lastly, we observe that the classification accuracy that was obtained by HYDRA peaks at K = 3 and relatively decreases for higher values of K. This indicates that HYDRA was able to correctly estimate the intrinsic dimensionality of the pathological class.\nAs far as the clustering reproducibility is concerned, we note a significant difference between HYDRA and K-means (see Fig. 4b ). Note that K-means obtained the highest reproducibility, yet the estimated clusters did not reflect the simulated focal effects. K-means consistently grouped the data into two clusters, while HYDRA segregated the data with higher stability into three subgroups (see also Table 1 ). The importance of this difference was further emphasized by the fact that K-means results were significantly different from the HYDRA clustering. HYDRA clusters overlapped highly with the simulated ones while K-means results did not match the generated subgroups (see Table 1 ). This is because K-means, being blind to class information, was driven by global patterns that were confounded by the variations stemming from covariate effects rather than relevant heterogeneity. On the contrary, HYDRA was able to identify the heterogeneous groups by exploiting patterns that encode directions along which the two groups differ.\nTo further appraise the differences between the two methods, we report in Figs. 3b and c the group differences between the positive class and the three subgroups K-means and HYDRA estimated, respectively. By visually comparing them to the group differences for the simulated groups (see Fig. 3a ), we observe that HYDRA recovered the three modes of differences with high certainty. Contrarily, K-means captured global effects that reflect the overall progression of the simulated pathology (note the relevant increase of the group differences in Fig. 3c ), instead of teasing out distinct pathological directions.\nOur synthetic validation setting provides two key insights. First, while all methods were able to successfully separate the two groups, only HYDRA was able to distinguish between pathological subgroups. Thus, to effectively disentangle disease heterogeneity, one should focus on discriminating patterns rather than global image appearance. Second, and most importantly, analyzing the clustering stability allows for the estimation of the intrinsic dimensionality of the pathological group. Therefore, we adopt hereafter this popular approach (Ben-Hur et al., 2002; Lange et al., 2004) to perform model selection."}, {"section_title": "Experiments using clinical data", "text": "Having shown interest in the proposed approach using synthetic data, we next applied our method to data from the Alzheimer's Disease Neuroimaging Initiative 3 (ADNI). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator, Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment and early Alzheimer's disease. 4 Here, our goal was to investigate both the anatomical and the genetic heterogeneity in Alzheimer's disease."}, {"section_title": "Visualization of heterogeneity", "text": ""}, {"section_title": "Anatomical heterogeneity", "text": "To visualize the neuroanatomical heterogeneity of both the anatomically and genetically defined disease clusters, voxel-based analyses (VBA) were performed between the controls and patient groups.\nTo perform VBA, MRI scans were first pre-processed using previously validated and published techniques (Goldszal et al., 1998) . The preprocessing pipeline includes: (1) alignment to the anterior and posterior commissures plane; (2) skull-stripping (Doshi et al., 2013) ; (3) N3 bias correction (Sled et al., 1998) ; (4) tissue segmentation into gray matter (GM), white matter, cerebrospinal fluid and ventricles using MICO (Li et al., 2014) ; (5) deformable mapping (Ou et al., 2011) to a standardized template space (Kabani et al., 1998) ; (6) formation of regional volumetric maps called RAVENS maps (Davatzikos et al., 2001) , generated to enable analyses of volume data rather than raw structural data; (7) the RAVENS were normalized by individual intracranial volume to adjust for global differences in intracranial size, and smoothed for incorporation of neighborhood information using an 8-mm full-width at half-maximum Gaussian filter.\nThe GM RAVENS were used for all VBA experiments, where a general linear model (GLM) was applied voxel-wise to estimate the disease effect on the voxel value using age and sex as covariates. False discovery rate (FDR) correction for multiple comparisons was used for all voxelbased analyses. Only results surviving the statistical threshold at q b 0.05 are shown."}, {"section_title": "Genetic heterogeneity", "text": "In addition to anatomical heterogeneity, the genetic differences between the subgroups of AD were assessed by performing ANOVA on genetic markers, followed by a Bonferroni test for multiple comparisons. Only results surviving the statistical threshold at q b 0.05 are reported. Both the classification accuracy and the cluster stability were maximized at K = 3 for HYDRA, agreeing with the intrinsic dimensionality of the heterogeneous group. The classification accuracy obtained by K-means/SVM remained relatively stable for different values of K. However, the clustering stability was maximized for K=2, demonstrating that higher reproducibility does not necessarily imply successful heterogeneity detection."}, {"section_title": "Anatomical heterogeneity of Alzheimer's disease Participants and MRI data preprocessing", "text": "The first dataset comprises MRI scans that were made available by the ADNI study.\n5 T1-weighted MRI volumetric scans were obtained at 1.5 T for 123 AD patients and 177 normal controls (CN) (see demographic information given in Table 2) . A low-level representation was extracted by automatically partitioning the MRI scans of all participants into 153 ROIs spanning the entire brain. The ROI segmentation was performed by applying a new multi-atlas label fusion method (Doshi et al., 2016) . The derived ROIs were used as features for all clustering and classification methods.\nCorrection for age and sex effects. To remove age and sex related differences between patient groups while retaining disease-associated neuroanatomical variation, the strategy outlined in (Dukart et al., 2011) was used. Within each cross-validation training fold, we calculated voxel-level \u03b2-coefficients for age and sex in control subjects' ROIs using partial correlation analysis. Then, all subjects were residualized using these coefficients to correct for age and sex effects not attributable to disease related factors."}, {"section_title": "Evaluation of results for structural MRI AD data", "text": "Classification results are reported in Fig. 5a . The standard linear SVM achieved a highly accurate classification performance (AUC for K =1 is greater than 0.9), which emphasizes the high separability between AD patients and healthy controls. Similar to linear SVM, HYDRA was able to separate the two groups with high accuracy but, contrary to the simulated case, it did not improve on the results of linear SVM. This is most likely because the data were already linearly separable. However, the classification performance of the proposed method remained relatively stable for different values of K (no statistically significant differences between the results were found), demonstrating that HYDRA was able to retain the important discriminative information that is necessary for disease subtype clustering. Furthermore, the stable AUC at K \u2265 2 may indicate a possible plateau in the AD vs. control classification rate (Cuingnet et al., 2011) . Lastly, we should emphasize that HYDRA aims to increase the margin with K, which is indeed achieved (see Supplementary material). This has two important implications: (i) that there is heterogeneity in the data; and (ii) that HYDRA successfully harnesses this heterogeneity to improve the margin.\nThe clustering stability results are presented in Fig. 5b , while the AUC and ARI values for the HYDRA model at K = 1 , 2 , 3 are given in Table 3 . The stability analysis suggests that three clusters are appropriate for capturing the intrinsic dimensionality for representing the disease heterogeneity. At finer levels (higher values of K), these three clusters are partitioned into smaller clusters, giving rise to a hierarchical structure (see Supplementary material). This observed hierarchy provides further evidence that the data has an inherent structure that HYDRA effectively reveals.\nOptimal clustering is visualized through the use of VBA (see Fig. 6B , C and D). The commonly performed voxel-wise group difference analysis between all healthy subjects and all patients (see Fig. 6A ) provides the necessary baseline for comparison. It should be noted that the statistical significance of the group comparisons between the controls and the subgroups of AD may be biased due to sample splitting. Thus, these comparisons should serve a qualitative visualization function, rather than a quantitative one. For this reason, we do not state the statistical significance levels for these differences.\nWe observe that at the K = 3 cluster level (see Fig. 6 ) the estimated subgroups are associated with distinct patterns of structural brain alterations: (i) diffuse atrophy subtype (see Fig. 6B ) exhibiting a typical AD pattern, similar to the one that is found by commonly applied monistic VBA (see Fig. 6A ). This subtype was characterized by atrophy in nearly all cortical regions and increased lesion load in the periventricular white matter; (ii) lateral parietal/temporal subtype (see Fig. 6C ) in which bilateral parietal lobe, bilateral temporal cortex, bilateral 5 http://adni.loni.usc.edu/data-samples/mri/. Table 1  Table summarizing the results for the simulated dataset. Cross-validated classification accuracy is reported for Gaussian SVM, linear SVM, HYDRA and K-means/SVM. Cross-validated cluster stability and overlap with the ground truth are reported for HYDRA and K-means. * denotes the value of the parameter K that was chosen based on the cluster stability analysis. All models achieved comparable classification performance in terms of AUC. However, HYDRA was able to correctly identify the ground truth clusters. Note that while K-means achieved the highest reproducibility, it estimated clusters that did not correspond to the generated focal effects. dorsolateral frontal lobe, precuneus were mainly involved, and few periventricular white matter lesions were present; (iii) medial temporal dominant subtype (see Fig. 6D ) involving predominantly bilateral medial temporal cortex. The estimated subgroups were associated with distinct demographic, cognitive and cerebrospinal fluid (CSF) biomarker characteristics. The first subgroup comprised 24% of AD subjects. It included relatively more male participants (21 males, 8 females) of relatively increased age (78.9 \u00b1 5.75). Members of this group achieved a Mini Mental State Examination (MMSE 6 ) score of 23.97 \u00b1 1.97, while the frequency of APOE \u03b54 allele carriers was 72.4%. In addition, this group had the highest CSF Amyloid-beta 1 to 42 peptide (A\u03b2) concentration, 157.3 pg/mL, and the lowest CSF total tau (t-tau) and CSF tau phosphorylated at threonine 181 (p-tau) concentrations, 97.3 pg/mL and 31.2 pg/mL, respectively, on average compared to the other subgroups. The second subgroup was the largest one, consisting of 51% of AD subjects, 60.32% of whom are APOE \u03b54 carriers. Both sexes were nearly equally represented (31 males and 32 females), having a mean age of 73.7 years (\u00b1 7.63 standard deviation). Its members performed relatively worse in terms of MMSE (23.16 \u00b1 1.99). The average CSF p-tau concentration for this group was the highest compared to the other subgroups at 44.9 pg/mL.\nThe last subgroup included the 25% of AD patients. Contrary to the previous subgroup, it was dominated by females (9 males and 22 females) of relatively younger age (72.62\u00b16.85) with a rather higher frequency of APOE \u03b54 allele carriers (74.19%). MMSE performance of this subgroup was 24.06 \u00b1 1.34. The CSF A\u03b2 concentration was the lowest for this group at 127.9 pg/mL while the CSF t-tau concentration was the highest at 139.4 pg/mL, on average, compared to the other subgroups.\nComparing the genetic profiles of these three subgroups of AD yielded further insight on the differences between the pathologies exhibited by each subgroup. One-way ANOVA was performed for each of the single nucleotide polymorphisms (SNPs) identified in two recent genome wide association studies that reported loci associated with AD (Lambert et al., 2013) and cognitive decline (Sherva et al., 2014 ) (see Appendix C). Three SNPs were statistically significantly different: rs10948363, which is related to gene CD2AP; rs11023139, which is related to gene SPON1; and rs7245858, which is related to gene LOC390956.\nFor SNP rs10948363, which is related to the gene CD2AP, 58% of the first subgroup and 74% of the third subgroup were carriers of the minor G allele, while 39% of the second subgroup were carriers of this risky allele.\nFor SNP rs11023139, which is related to the gene SPON1, 29% of the first subgroup were carriers of the minor A allele, while 2% of the second subgroup and 11% of the third subgroup were carriers of this allele.\nLastly, for SNP rs7245858, which is related to gene LOC39095, 23% of the first subgroup were carriers of the minor A allele, while 2% of the second subgroup and 4% of the third subgroups were carriers of this allele."}, {"section_title": "Genetic heterogeneity of Alzheimer's disease", "text": ""}, {"section_title": "Genotype data", "text": "The second dataset comprises genotypes for 103 AD patients and 139 normal controls (see demographic information in Table 4 ), obtained from the ADNI study.\n7 ADNI genotyping is performed using the Human610-Quad Bead-Chip (Illumina, Inc., San Diego, CA), which results in a set of 620,901 single nucleotide polymorphisms (SNPs) and copy number variation markers (for details, see (Saykin et al., 2010) ). Due to the weak or spurious signal in most of the genome, we opted to only use SNP loci that were associated with Alzheimer's disease or cognitive decline in recent large-scale genome-wide association studies (Lambert et al., 2013; Sherva et al., 2014) . This resulted in a reduced set 6 MMSE is a quantified clinical assessment for dementia (Folstein et al., 1975) 7 http://adni.loni.usc.edu/data-samples/genetic-data/. of 66 SNPs (see table in Appendix C) that were represented through the use of two binary variables encoding the presence of major-major or major-minor alleles, thus raising the total number of features to 132."}, {"section_title": "Evaluation of results for genotype AD data", "text": "Classification results are reported in Fig. 7a . The standard linear SVM discriminated fairly between healthy controls and AD patients (AUC for K =1 equals 0.72). Compared to the result that was obtained using imaging features, this highlights the difficulties associated with disease classification in the genotype domain. HYDRA was able to separate the two groups with a similar accuracy for K = 2 (AUC equals to 0.70). The classification accuracy dropped for higher values of K. However, the difference between the results for K = 1 and K = 2 was statistically insignificant (p =0.10).\nThe clustering stability results are presented in Fig. 7b , while the AUC and ARI values for the HYDRA model at K = 1 , 2 , 3 are given in Table 3 . The stability analysis suggested that two clusters are appropriate for capturing the intrinsic dimensionality for representing the genetic heterogeneity associated with AD. Similar to the anatomically driven clustering results, these two clusters are successively partitioned to smaller clusters for higher values of K (see Supplementary material), showing a hierarchical organization. This suggests that the data has structure that HYDRA reveals. Table 3  Table summarizing the classification and clustering performance of HYDRA for the experiments using structural MRI and genetic data, respectively. Results are reported for three values of the parameter K. The optimal value of the parameter K that was estimated by performing model selection based on clustering stability is denoted by *. The bold values indicate the maxima of the corresponding measures for each dataset. The differences in AUC were statistically insignificant between K=1 and K=3 for MRI data (two-tailed t-test p-value equals to 0.115) and between K=1 and K=2 for genetic data (two-tailed t-test p-value equals to 0.102). This suggests that the discriminative signal was preserved, allowing for clinically relevant clusters to be found."}, {"section_title": "Experiment", "text": "Classification The optimal genotype clustering is visualized by contrasting the imaging phenotypes of the estimated subgroups against the healthy control population through VBA (see Figs. 8A and B) .\nWe observe that at the K = 2 cluster level, the estimated subgroups were associated with distinct patterns of structural brain alterations: (i) increased temporal lobe atrophy subtype (see Fig. 8A ) including posterior medial cortex atrophy and increased white matter lesion load; (ii) increased superior frontal lobe atrophy subtype (see Fig. 8B ) including temporal lobe atrophy and periventricular white matter lesions.\nThe first subgroup exhibited reduced GM volumes in the hippocampus and entorhinal cortex (Fig. 8A) , while the second subgroup exhibited reduced GM volumes in the superior frontal lobe (Fig. 8B) . The difference between the brain images in the two subgroups are visualized in Fig. 8C .\nThe sex and age composition of the two estimated subgroups was similar for both cases. The proportion of the females in the first subgroup was 48.52%, while for the second, it was 45.71% (see also Table 4 ). The average age of the first subgroup was 74.5 years, while it was 76.2 years for the other subgroup.\nIn addition to anatomical differences, the two subgroups exhibited significantly different levels of APOE \u03b54 allele and CSF biomarkers. While the first subgroup was composed of 98% APOE \u03b54 carriers, only 14% of the second subgroup were APOE \u03b54 carriers. Also, the first group had lower A\u03b2 concentration, 133.6 pg/mL, and higher t-tau and p-tau concentrations, 129.5 pg/mL and 42.5 pg/mL, respectively, on average compared to the second subgroup.\nFurther analysis of the genetic differences between the two subgroups yielded two additional loci of interest. While 32% of the first subgroup were carriers of the risk-related A allele of the SNP rs6656401 (related to gene CR1) 49% of the second subgroup was composed of carriers of this allele.\nThe second locus that differed between the two subgroups was the SNP rs6733839, which is related to gene BIN1. While 72.06% of the first subgroup consisted of risk-related C allele carriers of rs6733839, 85.71% of the second group comprised carriers of this allele.\nHowever, similar to voxel-based analysis of the differences between the subgroups of AD patients, these statistical findings should be approached with care as there might be bias due to sample splitting. The statistical power needed to make a definite statement about the genetic differences between the subtypes of AD may require a much higher sample size."}, {"section_title": "Discussion and conclusion", "text": ""}, {"section_title": "Synopsis", "text": "In this paper, we presented HYDRA, a method for disentangling heterogeneity in a principled semi-supervised machine learning framework. HYDRA aims to generalize the basic assumption of computational neuroimaging studies from a single separating pattern to many patterns, thus addressing one of the major challenges that characterizes many studies, namely the presence of heterogeneity. HYDRA attempts to find patterns associated with the underlying disease process, or more generally with the difference between two groups. These different patterns could potentially identify different dimensions of the underlying disease process and hence lead to diagnostic subcategories.\nThe proposed approach seamlessly integrates clustering and discrimination in a coherent framework by solving for a non-linear classifier that bears common geometric properties with convex polytopes. Discrimination is achieved by constraining one class in the interior of the polytope, while at the same time maximizing the margin between examples and class boundary. On the other hand, clustering is performed by associating disease samples to different faces of the polytope, and hence to different disease processes. Thus, each face of the polytope informs us about the distinct foci of disease effects that distinguish the patients from the healthy control subjects. This coupling between clustering and classification allows for segregating patients based on disease patterns rather than global anatomy.\nIn our experiments, we demonstrated the ability of the proposed approach to discern disease foci in both synthetic and clinical datasets without undermining its predictive power. Moreover, our method is endowed with improved generalization performance due to its maximum margin property of the method and the low complexity of the model (compared to standard non-linear classifiers, e.g., Gaussian kernel SVM). The latter allows it to efficiently handle small sample size high dimensionality data that are commonly encountered in neuroimaging studies by exploiting the dual model representation and operating in the inner product space."}, {"section_title": "Model selection", "text": "Choosing an appropriate number of hyperplanes, or corresponding disease subtypes, is a important and difficult model selection question. The difficulty is underlined by the fact that there is no ground truth available against which one may test a clustering result. However, we presented a strategy based on examining the clustering stability (Ben-Hur et al., 2002; Lange et al., 2004) . The basic premise behind this strategy is that as one gets closer to the intrinsic dimensionality of the pathological group, the clustering algorithm should obtain similar results for different datasets generated by sampling the initial population. The group structure should remain relatively stable accounting for the fact that the datasets have been generated by the same factors."}, {"section_title": "Anatomical heterogeneity of AD", "text": "Applying the proposed framework to structural imaging data from ADNI, resulted in the definition of three AD subgroups. Our results largely agree with a recent study employing surface-based morphometry to study AD heterogeneity based on cortical thickness (Noh et al., 2014) and bear similarity to the subtypes that were recently identified in a pathologic study based on the distribution and density of neurofibrilllary tangles (Murray et al., 2011) . The first subgroup is similar to the diffuse atrophy subtype reported in (Noh et al., 2014) and the typical AD group in (Murray et al., 2011) . The second subgroup is comparable to the parietal dominant in (Noh et al., 2014) and the first subtype in (Murray et al., 2011) . The third subgroup maps to the medial temporal subtype of (Noh et al., 2014) and the third group of (Murray et al., 2011) .\nThe agreement of the results, despite the differences in the design of the studies, emphasizes the fact that AD should be considered as a neuroanatomically heterogeneous disease, characterized by multiple pathological dimensions. Among the pathological dimensions revealed in this study, only the first one (Fig. 6B ) bore important resemblance with a typical AD pattern involving signature AD regions, while the other two (Figs. 6B and C) exhibited distinct pathological patterns. These dimensions may reflect distinct pathways leading to AD, associated with distinct disease processes that may constitute potential therapeutic targets.\nAiming to further elucidate the recovered pathological dimension of AD, we found that the anatomically defined clusters exhibit significant differences in their genotypes, demographic characteristics and CSF biomarker distributions.\nThe first subgroup comprised more male participants of relatively older age. A total of 72.4% of its members were APOE \u03b54 allele carriers, while SNPs rs11023139 and rs7245858 were carried relatively more by members of this subgroup than members of the other two; 29% of the first subgroup were carriers of the minor A allele for rs11023139 and 23% of the first subgroup were carriers of the minor A allele for rs7245858 (see Evaluation of results for structural MRI AD data). This subgroup was characterized by the most widespread pattern of atrophy, yet the most normal CSF biomarker levels. Moreover, the cognitive performance of its members was comparable to the one of the rest of the subgroups. The older age of the group, the relatively more normal levels of CSF biomarkers as well as the protective nature of rs11023139, which has been associated with a slower rate of cognitive decline (Sherva et al., 2014) , suggest a protracted disease progression. The possible long disease progression may have allowed for compensatory mechanisms to develop resulting in a cognitive performance that is comparable to the other groups despite the extended atrophy.\nThe second subgroup was the largest one (comprising 51% of AD subjects), with nearly equal sex proportions. However, it comprised proportionally fewer APOE \u03b54 carriers (60.32%), fewer carriers of the risky allele of SNP rs10948363 (39%), and almost no carriers of the minor A allele of SNP rs10948363 (2%) and SNP rs7245858 (2%). This was the group whose members performed worse in terms of MMSE.\nThe third subgroup included predominantly females of relatively younger age. Most of the patients (74.19%) were APOE \u03b54 allele carriers, while 74% of them were also carriers of the minor G allele of the SNP rs10948363, whose corresponding gene is CD2AP. CD2AP is a scaffolding protein that is involved in cytoskeletal reorganization and intracellular trafficking (Dustin et al., 1998) and has been previously associated with late onset AD (Naj et al., 2011) . Moreover, a direct link between CD2AP and amyloid \u03b2 toxic effects has been noted in yeast, nematodes and rat cortical neurons after study of the role of several genes in amyloid \u03b2 and tau pathways (Treusch et al., 2011) . This along with the fact that this group exhibits the most abnormal levels of CSF t-tau and A\u03b2 concentration may explain why members of this group are diagnosed as AD, despite being of younger age and exhibiting more focal atrophy. The sex difference in the population of this subgroup may result from the gender difference in the AD-promoting effect of the APOE genotype (Payami et al., 1996) . Given that APOE \u03b54 preferably affects medial temporal lobe structures, women may have a more vulnerable medial temporal cortex than men, giving rise to this specific subtype."}, {"section_title": "Genetic heterogeneity of AD", "text": "Applying the proposed framework to genetic data from ADNI, resulted in the identification of two AD subgroups. These groups were essentially dichotomized based on the presence of APOE \u03b54 allele (98% of the members of the first subgroup carry it, while only 14% of the second subgroup do). However, the two groups exhibit additional genetic differences, as well as anatomical differences and distinct distributions of CSF biomarkers.\nGenetic differences were found for the SNP rs6656401 (related to gene CR1) and the SNP rs6733839 (related to gene BIN1). Genetic variations at CR1 have been associated with the risk of cerebral amyloid angiopathy and decreased entorhinal cortex volume (Biffi et al., 2012; Bralten et al., 2011) . Increased expression of the BIN1 gene has been recently implicated with modulating tau pathology (Chapuis et al., 2013) , while BIN1 has also been associated with entorhinal and temporal pole cortex thickness (Biffi et al., 2012) .\nAnatomical differences were mainly found in hippocampal and entorhinal cortex, where the first group was characterized by significantly more atrophy. The anatomical differences between the subgroups may be explained by the genetic variations. APOE \u03b54 has been related to increased atrophy in hippocampus (Hashimoto et al., 2001; Honea et al., 2009) , entorhinal (Juottonen et al., 1998) and medial frontal cortex (Fennema-Notestine et al., 2011) . Given that, the first subgroup is expected to exhibit more atrophy in these areas.\nThe two groups were characterized by differences in the distribution of the CSF biomarkers. This difference was more significant for the CSF A\u03b2, which was significantly reduced in the first group. This difference may also be attributed to the effect of APOE \u03b54, which has been previously associated with reduced levels of CSF A\u03b2 and t-tau (Prince et al., 2004; Sunderland et al., 2004) .\nWhile the dominant presence of APOE \u03b54 in the first subgroup provides the means to interpret the anatomical and CSF biomarker differences between the two subgroups, the relatively higher expression of the SNPs related to CR1 and BIN1 genes in the second subgroup (where APOE \u03b54 allele is less expressed) may be an indication that these genes may be part of an alternative pathway for AD pathogenesis in the absence of APOE \u03b54 expression. The atrophy exhibited by the second subgroup in the entorhinal cortex seen in Fig. 8B ) may be a product of CR1 expression since APOE \u03b54 is largely absent in this subgroup. While this hypothesis remains to be validated, this underlines the value of data-driven, multivariate, exploratory techniques in forming new hypotheses."}, {"section_title": "Limitations and future work", "text": "There are some limitations to this work. First, the lack of ground truth for the clinical datasets does not allow us to quantitatively validate the proposed method. However, on the one hand, when AD patients were clustered based on imaging information, the identified patterns of abnormality aligned well with findings based on neuropathology reported in Murray et al. (2011) and the subtypes defined based on cortical thickness in Noh et al. (2014) . Moreover, the anatomically defined subgroups also exhibited genetic differences, which provides additional evidence for the validity of the obtained clustering. On the other hand, when clustering based on genetic information, we identified subpopulations that exhibited meaningful anatomical differences. In summary, our results were consistent with the existing picture of pathological neurodegeneration and the function of the related SNPs.\nNevertheless, the sample size that is necessary for drawing reliable conclusions about the full extent of heterogeneity of AD may be higher than what was analyzed. In general, we were able to demonstrate the presence of heterogeneity in AD given the ADNI dataset. However, to be able to elucidate disease heterogeneity and map the distinct pathological processes that drive it, a wider sampling of the patient population probed in a multi-parametric fashion may be required.\nAnother limitation of this work is that the diseased population was studied by using either structural imaging data or genetic information. While this demonstrates the ability of the proposed framework to handle both imaging and non-imaging data, including additional information (e.g., amyloid PET imaging, tau imaging, cerebrospinal fluid biomarkers) would be beneficial in better characterizing the dimensions and extent of heterogeneity. Nonetheless, HYDRA cannot currently handle multiple sources of information. This could be made possible by extending HYDRA through the adoption of multiple kernel techniques (Bach et al., 2004) . Different kernels could be employed to encode different sources of information, allowing for their seamless integration. This extension could make HYDRA even more general, allowing its application to other exploratory problems, such as characterization of the breast cancer heterogeneity and the analysis of abnormal tissue subtypes, without being limited to the clustering of brain images.\nWe should note that the estimation of the subpopulations may be influenced by confounding variations due to age and sex differences. In its current form, our method does not explicitly take into account this case. Instead, we circumvent this by performing univariate covariate correction prior to feeding the data to our method. In order to tackle this shortcoming, we are currently working on extending the proposed method by explicitly modelling the effect of covariates within a unified clustering framework. However, the effect of the covariates also renders prohibitive the usage of the classification model to interpret the weight vectors of the hyperplanes (as explained in Haufe et al. (2014) ). We circumvent this by performing voxel-wise group analysis between the inferred patient clusters. However, the interpretation of the group comparison results should be made with care since the significance of the comparison may be biased due to the sample splitting. The voxel-based comparisons should serve only as a qualitative tool and not as a quantitative one. Furthermore, to avoid the circularity of assessing group differences using the same Fig. 8 . Comparison between group differences obtained using commonly applied monistic analysis and the results that were obtained using our method for heterogeneity detection in genetic data. The voxel-based analysis was performed using GM RAVENS. Color maps indicate the scale for the t-statistic. Images are displayed in radiological convention. Axial views of the VBA results obtained from GM group comparisons of (A) CN vs. first AD subgroup; (B) CN vs. second AD subgroup; and (C) first AD subgroup vs. second AD subgroup are shown. For (A) and (B), colder colors indicate relative GM volume increases (CN b AD subgroups), while warmer colors correspond to relative GM volume decreases (CN N AD subgroups). Similarly for (C), warmer colors indicate relative GM volume increases (first AD subgroup b second AD subgroup), while colder colors correspond to relative GM volume decreases (first AD subgroup N second AD subgroup). Both groups exhibit atrophy in the temporal lobe and posterior medial cortex while white matter lesions are present in the periventricular area. However, the first AD subgroup, which mainly comprises APOE \u03b54 carriers, is characterized by significantly more hippocampus and entorhinal cortex atrophy and less superior frontal lobe atrophy.\nfeatures that the groups are clustered by, we have assessed group differences using features that have not been used in the clustering. Namely, we have assessed the genetic and demographic differences between the anatomic subtypes of AD and the anatomic and demographic differences between the genetic subtypes of AD.\nA possible extension of our method is towards handling regression and longitudinal studies. This could allow us to elucidate the complex nature of spatiotemporal disease dynamics as well as to reveal varying paths of normal progression. Lastly, it is straightforward to derive a one-class version of HYDRA, analogous to the work of Sato et al. (2009) , to detect and subtype outliers among controls. This could potentially shed light on the heterogenous nature of healthy phenotypes."}, {"section_title": "Conclusion", "text": "HYDRA aims to separate two groups by deriving a non-linear classification boundary that is constructed by using multiple linear hyperplanes. The constructed polytope allows for the revealing heterogeneity by assigning subgroups of patients to different hyperplanes. HYDRA is general; it can handle imaging and non-imaging data and can find applications in exploratory analyses other than clustering of brain images. We evaluated the performance of the method in simulated data, providing insight into its workings. Furthermore, we applied HYDRA to structural imaging and genetic dataset from ADNI, revealing disease subtypes that are consistent with the existing picture of pathological neurodegeneration and the function of the related SNPs. These results demonstrate the potential of our approach in teasing out heterogeneity."}, {"section_title": "Acknowledgments", "text": "This work was partially supported by the National Institutes of Health (grant number R01-AG014971). The authors would like to express their appreciation to the anonymous reviewers for their constructive comments."}, {"section_title": "Appendix A. Optimization", "text": "Similar to other clustering methods, the HYDRA algorithm requires an initialization step followed by iterations of assignment and convex polytope solutions. To make the clustering robust, we further find the consensus of the clustering results obtained in multiple runs of HYDRA. Here, we detail the techniques used for each of these steps. Initialization is found in Appendix A.1, assignment step is found in Appendix A.2, convex polytope solution is in Appendix A.3 and consensus is found in Appendix A.4.\nAs mentioned in the main text, HYDRA is geometrically asymmetric, requiring one of the groups to lie inside the polytope. We provide the solution for the symmetric version of HYDRA in the Symmetric HYDRA algorithm section.\nLastly, HYDRA can be solved in the dual domain if sample size is relatively lower than the dimensionality. The dual solution is in Appendix B.1."}, {"section_title": "A.1. Initialization", "text": "Due to the non-convex nature of the maximum margin polytope problem, the initialization is crucial in directing the iterative algorithm towards favorable solutions. Since we are interested in elucidating discriminative patterns between controls and patients, simply initializing by clustering the patients may not be sufficient. This is because standard clustering may group patients by following global patterns, such as the brain volume, or even more subtle patterns that nonetheless reflect normal inter-individual variability and not variability in the disease process. On the contrary, patients should be assigned to initial clusters by considering their difference map with respect to controls. In other words, since we aim to explore different directions of deviation from normal anatomy without concern for magnitude of that deviation, we initially group patients into clusters based on the regions in which they differ from the controls and not the magnitude of their difference. To achieve this, we initialize the assignments of patients into clusters by sampling K unit length hyperplanes obtained by considering the space of all pairwise differences between patients and controls. We choose K unique hyperplanes by applying determinental point processes (DPP) (Kulesza and Taskar, 2012) . DPP is a sampling technique that aims to obtain samples that are as diverse as possible. This type of sampling ensures that the differences we sample reflect unique biomarkers instead of repeated biomarkers with varying magnitudes. This is crucial in preventing clustering patients into groups that are not related to variability in the disease process. The steps of the initialization algorithm are given in Algorithm 2. \u2022 Obtain m hyperplanes by taking the difference between members of the same pair:\nm by determinental point processes (Kulesza and Taskar, 2012) \u2022 Set rows of S \u2212 such that s i , argmin j w j\nA.2. Assignment step solution For {W, b} fixed, the problem of estimating S \u2212 is an assignment problem that can be cast as a linear program (LP). The LP problem has infinite solutions when the loss function max{0, 1 + w j T x i + b j } is equal to 0 for multiple classifiers j and for the same sample i. In this case, we choose the solution that is proportional to the margin:\n\u00f0A:1\u00de\nwhere 1(\u00b7) is the indicator function. Let us note here that the obtained clustering is inherently different from the result that is obtained by standard clustering techniques. Instead of grouping together samples based on the similarity of their appearance, we aggregate here samples that are best separated by the same classifier. Thus, the inferred clustering is driven by discrimination. The more pronounced the pathology is, the easier it is to disentangle the underlying heterogeneity in the imaging profiles."}, {"section_title": "A.3. Convex polytope solution", "text": "For S \u2212 fixed, the solution to {W, b} can be obtained using K calls to a modified version of LIBSVM (Chang and Lin, 2011) 8 that allows for adaptive sample weightings. The adaptive weight c i,j of sample i for the classifier j is calculated as In case the dataset is highly unbalanced (i.e., one of the classes is over-represented) samples in each class can be further weighted by their inverse relative proportion within the training set."}, {"section_title": "A.4. Consensus solution", "text": "While DPP initialization serves as the first step in avoiding poor locally optimal solutions, consensus clustering serves as the second layer to eliminate unstable clusterings that may arise due to the nonconvexity of the objective function. In noisy, or high dimensional data, the clustering obtained via Algorithm 1 may depend greatly on the initialization. To decrease this dependency and obtain stable clustering results that characterize the disease heterogeneity, we opt for a multiinitialization strategy, endowed by a fusion step. First, multiple runs of Algorithm 1 result in a number of clustering hypotheses. Then, we aim to fuse the respective hypotheses by harnessing the wisdom of the crowd to obtain an aggregate clustering. Consensus is achieved by grouping together samples that co-occur (i.e., they are assigned to the same clustering) across different clustering hypotheses. In practice, we first compute a co-occurrence matrix of the subjects based on each clustering result and then perform spectral clustering using it."}, {"section_title": "A.4.1. Co-occurrence matrix", "text": "Given P clusterings {S \u2212 p } p = 1 P obtained by running Algorithm 1 P times, the co-occurence matrix A is given by In other words, each il-th entry of the matrix enumerates the number of cases that the i-th and l-th sample were assigned to the same cluster."}, {"section_title": "A.4.2. Spectral clustering", "text": "The consensus clustering involves the calculation of the Laplacian matrix from the co-occurrence matrix A and the computation of the K eigenvectors ([v 1 \u2026 v k ]) that correspond to the K smallest eigenvalues (\u03bb 1 \u2264 \u2026 \u2264 \u03bb K ). Then, the aggregate clustering of subjects is obtained by running K-means in the obtained subspace. The implementation of consensus clustering is outlined in Algorithm 3. It should be noted that the consensus clustering presented herein is analogous to spectral clustering (Ng et al., 2002) . The SNPs used as features is given in Table C .5. Two features were extracted from each subject for each SNP: the presence of the major-major and the major-minor alleles. Minor allele frequency (MAF) column in Table C .5 denotes the likelihood of observing the rare minor allele in the population! Genetic features used for control vs. AD classification/clustering using HYDRA SNPs associated with cognitive decline identified in (Sherva et al., 2014 "}]