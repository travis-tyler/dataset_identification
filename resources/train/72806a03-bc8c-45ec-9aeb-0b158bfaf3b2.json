[{"section_title": "Relationship of This Report to the Federal Resource Management and Ecosystem Services Guidebook", "text": "The online Federal Resource Management and Ecosystem Services Guidebook (nespguidebook.com) is designed to increase consistency in the use of ecosystem services in federal decision making. This working paper identifies data and modeling resources available at a national level for common ecosystem services to enhance the consistency and credibility of ecosystem services assessments for use in methods like those presented in the guidebook."}, {"section_title": "SUMMARY", "text": "Resource managers face increasingly complex decisions as they attempt to manage for the longterm sustainability and the health of natural resources. Incorporating ecosystem services into decision processes provides a means for increasing public engagement and generating more transparent consideration of tradeoffs that may help to garner participation and buy-in from communities and avoid unintended consequences. A 2015 White House memorandum from the Council on Environmental Quality, Office of Management and Budget, and Office of Science Technology and Policy acknowledged these benefits and asked all federal agencies to incorporate ecosystem services into their decision making. This working paper, which has been expanded since its initial publication in November 2016, describes the ecological and social data and models available for quantifying the production and value of many ecosystem services across the United States. To achieve nationwide inclusion of ecosystem services, federal agencies will need to continue to build out and provide support for this essential informational infrastructure."}, {"section_title": "INTRODUCTION", "text": "Resource managers face increasingly complex decisions as they attempt to manage for the long-term sustainability and health of natural resources. They must address large spatial scale and long-term ecosystem dynamics, climate-related stressors (extreme heat and weather events, pest outbreaks, etc.), population growth and urbanization, the spread of invasive species, and dwindling public resources (Burke 2013). Growing threats, pressures, and uses of our lands and waters appear to be increasing the likelihood of significant tradeoffs in resource management decisions, affecting what benefits are provided and who receives them or loses them. For example, increasing energy infrastructure for solar and wind throughout the United States is resulting in damage to fragile habitats (e.g., Kuvlesky et al. 2007), impacts to species and majestic views, and in some cases important pollinators (Kunz et al. 2009) but at the same time are providing a clean source of energy to millions of people (U.S. EIA 2015). Better and more transparent ways to assess these difficult tradeoffs among easily monetized benefits (energy) and less easily expressed benefits (recreational and spiritual benefits and intrinsic values of species, habitats, and wide open spaces) are needed. Although the public depends on and derives substantial benefit from how natural resources are managed (health, happiness, money), these connections are not always apparent to them. Ecosystem services assessments provide a means for increasing public engagement and generating more transparent consideration of tradeoffs in resource management decisions that may help to garner greater support and participation from both public and private beneficiaries, hopefully reducing conflict and enhancing financial support. Incorporating ecosystem services into decision processes may also result in better integration of the less easily quantified and monetized benefits resulting in more sustainable and better ecological and social outcomes. Recent policies and guidance at the federal level reflect a growing interest in ecosystem service approaches to natural resource planning and management that culminated in a 2015 White House memorandum from the Council on Environmental Quality, Office of Management and Budget, and Office of Science Technology and Policy, asking all federal agencies to incorporate ecosystem services into their decision making. \u2022 Early use of ecosystem services valuation in the federal government occurred under the Natural Resources Damages Act in response to the Valdez oil spill (U.S. EPA 2016). \u2022 Greater use of these approaches was sparked in part by the 1998 President's Council of Advisors on Science and Technology (PCAST) report \"Teaming with Life: Investing in Science to Understand and Use America's Living Capital\" (PCAST 1998). \u2022 The 2008 Farm Bill called for federal agencies to explore ecosystem services and their potential application in environmental markets, resulting in the establishment at the U.S. Department of Agriculture (USDA) of an Office of Ecosystem Services and Markets that same year (Lucero & Doudrick 2008). \u2022 In 2010, a large-scale appointee-level interagency dialogue on ecosystem services brought together all federal agencies with natural resource jurisdictions, with a focus on markets and payment for ecosystem services. Similar interagency dialogues have continued since then. \u2022 In 2011 PCAST issued its report on \"Sustaining Environmental Capital: Protecting Society and the Economy,\" which asserts the critical importance of both the environment and the economy to societal well-being and emphasizes the need for agencies to develop consistent ecosystem service valuation techniques across federal agencies (PCAST 2011). \u2022 The U.S. Forest Service's (USFS) 2012 Planning Rule requires that planning activities consider ecosystem services, as part of an integrated resource management focus (USDA 2012). The agency is moving quickly to phase in implementation of the rule, with many forest plans already under way. \u2022 In 2013, the White House Council on Environmental Quality released new Principles and Requirements for Federal Investments in Water Resources, which shape water resource project decisions across a number of federal agencies and include specific guidance on using an ecosystem services framework for project evaluation (White House 2013). \u2022 A number of other agencies, including the Bureau of Land Management (BLM), the U.S. Fish and Wildlife Service (FWS), the U.S. Geological Survey (USGS), the U.S. Army Corps of Engineers (USACE), and the National Oceanic and Atmospheric Administration (NOAA), are also exploring ways to implement ecosystem services approaches by assessing and testing methods for identifying and valuing ecosystem services and applying this information in a natural resources decision-making context. \u2022 In 2014 the National Ecosystem Services Partnership launched an online guidebook (NESP 2016) on the integration of ecosystem services assessment into federal natural resource planning and management. \u2022 In 2015, the White House released a policy memorandum  asking agencies to incorporate ecosystem services into federal decision making and calls for further guidance to be released in 2016. The White House also released a report (Burke et al. 2015) that provided an ecosystem assessment of research needs for coastal green infrastructure. These federal initiatives are a move toward wider recognition of the multiple ways in which society depends on natural resources and a move away from evaluations that focus narrowly on a limited subset of benefits. In general this shift involves moving from a narrow focus on high-profile user groups to a view that also recognizes benefits that flow to the general public and society. Environmental nongovernmental organizations like the Nature Conservancy and World Wildlife Fund, as well as the land trust community, including the Land Trust Alliance and Trust for Public Land, are also building a broader consideration of ecosystem services and benefits to people into their decisions and communications. Corporations are also exploring how ecosystem services can inform their supply chains, infrastructure, and operations (Waage and Kester 2014). Federal agencies need two things to achieve nationwide adoption of ecosystem services approaches that support use by private and nonprofit partners: (1) credible, consistent, and practical methods that clearly improve decision processes and outcomes and that can be incorporated into planning and management processes (NESP 2016;Olander et al. 2015;Van Wensem et al. 2016); and (2) ecological and social data and models that explain the relationships between management and the production and value of services. This working paper focuses on this second requirement."}, {"section_title": "Ecological production functions", "text": "Ecological production functions are relationships that: \u2022 can be measured or modeled; \u2022 estimate the effects of changes in the structure, function, and dynamics of an ecosystem on outputs that are directly relevant to people; \u2022 can take many forms, from conceptual relationships established through expert opinion to complex simulation models; and \u2022 are often a series of statistical relationships connecting ecosystem condition to outputs. The data and modeling needs for an ecosystem services assessment include (1) the ecological data describing the status and trends of the resources being managed and affected, (2) the models that describe the effects of different management alternatives on the target and nontarget resources (the ecological production function), and (3) the social data on resource use and appreciation and, where available, value transfer models to assess the values and preferences associated with different outcomes on human wellbeing ( Figure 1-1 with an example in Figure 1-2). The data and models for more traditional ecosystem services like timber, fishing, hunting, and hiking and management actions like timber, fishery, recreational access and trails, and fire management are more readily available. New data collection and research are likely needed to build the data and models for the less-often-quantified services related to air and water quality, viewsheds, disease risk (mosquito-borne, air or water quality-influenced, or exerciserelated) and intrinsic biodiversity or cultural services, as well as a better understanding of how people value all of these services."}, {"section_title": "Figure 1--1. Needs for an ecosystem services assessment", "text": "Note: Data and models needed in ecosystem services assessments include ecological data, social data, value data, ecological production functions, and, where necessary, benefit transfer functions."}, {"section_title": "Figure 1--2. Ecosystem services causal chain illustrating the types of data and models that are needed", "text": "Note: Example of ecosystem services causal chain conceptual diagram linking the management of mechanical thinning of forests to changes in exposure to smoke and incidence of illness. Data to calibrate and test models that show the relationship between thinning and smoke produced, as well as those that show the relationships among smoke, exposures, and health impacts, are all needed. This requires data on the forest fuel load (size and type) as well as the location and number of people at potential risk of smoke exposure. To date, ecosystem services applications to planning and management have been scattered and often oneoff, with different approaches and tools used and with locally specific or locally calibrated data. While this has resulted in significant learning, it has not resulted in a consistent and commonly used set of approaches, data, or models that have been deemed credible by experts. If ecosystem services approaches are going to be widely applied across the country by federal agencies and other resource managers, a move toward more consistent, common, and accredited data, models, and tools is likely needed. A common infrastructure (whether centralized or networked) could supply essential data and models and, in doing so, greatly enhance consistency and credibility while reducing costs and effort associated with current assessments. There are efforts under way by the federal government to build needed data and modeling infrastructure, such as the EnviroAtlas (www.epa.gov/enviroatlas), which is part of a larger data effort called EcoInforma (www.data.gov/ecosystems/ecoinforma/), and an online searchable ecological production function library (Bruins et al. 2012) that is under development. This working paper discusses the current state of data and models and points to supporting infrastructure to maintain and update them where such infrastructure is known. Where particular needs are recognized they are noted, including new data, modeling, and infrastructural support. Sections 2 and 3 describe the ecological data and ecological production functions available and needed. Section 4 focuses on use and value data or functions (Figure 1-1). The working paper covers a handful of common services that are likely to be widely relevant in resource management decisions including services related to biodiversity, water supply, water quality, recreation, and risk reduction (climate, fire, flood, and coastal inundation). A fundamental need that underlies the idea of nationwide infrastructure is that the data and models are sufficiently scalable and transferable so they can work across multiple scales, geographies, and management challenges. Given this need we focus much of the discussion on nationally or widely available data and models."}, {"section_title": "ECOLOGICAL DATA AND MODELS FOR ECOSYSTEM SERVICES ASSESSMENTS", "text": "The ecological data needed for ecosystem services assessments include the quantity, quality, and location of ecological systems or flows that produce ecosystem services. These data provide the baseline ecological status and trends from which we will model and predict changes due to management (Figure 2-1). Also needed are ecological production function models that will trace the ecological changes resulting from management through a system resulting in a predicted change in the ecological flow or system. Figure 2--1. Ecological and social data and models Note: The difference in ecosystem function, services, and benefits between the baseline scenario and what is changed due to a management action in the second scenario will provide an estimate of the outcomes due to the expected or suggested action. The arrows represent a series of assumptions or models that connect a change in ecosystem function to changes in ecosystem services supply to changes in social benefits."}, {"section_title": "Land Use and Land Cover Change Data", "text": "Simply stated, many ecosystems' goods and services can be estimated from information on land use and land use patterns. Both proximal (e.g., local harvesting of game) and distal (e.g., sequestration of carbon in a far-off forest or upstream stream buffer management) land use patterns have a significant impact on the flow of services from an ecosystem to a particular community or group of beneficiaries. Even ecosystem services derived from an aquatic system are significantly impacted by land use. Land use data can provide the foundation for ecosystem services assessments and are typically used in conjunction with many other data sources to arrive at an ecosystem services endpoint. Historically, land use data have been largely unavailable, and it has become common practice to use land cover as a proxy for land use. While the terms \"land cover\" and \"land use\" are often used interchangeably or even lumped together as one entity (i.e., land cover/land use), there are noteworthy distinctions that are particularly relevant for the topic of ecosystem services. Land cover is defined as the observed biophysical cover on the earth's surface, whereas land use is characterized by the arrangements, activities, and inputs of people to produce, change, or maintain a land cover. For example, grassland is a cover type, but rangeland is a use (Theobald 2014). The use of land use or land cover data alone or in combination with additional qualitative and quantitative data has become an important part of methods to assess ecosystem service provision (Pickard et al. 2015, Burkhard et al. 2009Burkhard et al. 2012;. A land use map for the United States has recently been developed (Theobald 2014) and may prove to be of significant help in ecosystem services assessments. Land cover data resolution is an important concept for an ecosystem services assessment and refers not only to the area on the ground represented by each data point or pixel (spatial resolution) but also to the specificity of the classes of land cover (thematic resolution) represented by the data. Temporal resolution is another important attribute. In the simplest of classification schemes, there may only be a few classes, such as impervious surface, tree cover, grass, and water, and in the most complex of systems, there may be hundreds of classes representing different ecosystem types. The requirements for spatial resolution and specificity of classes will depend on decision context, including scale, the ecosystem good or service being measured, the level of accuracy required, and the setting (e.g., urban, rural, agricultural, forest). If one is trying to measure, for example, the approximate quantities of carbon stored or sequestered in forests across the United States, then a coarse land cover data set with perhaps only two classes of forests may suffice. If one is trying to quantify carbon storage or sequestration more precisely across the United States, then a more finely resolved product with information about types of forests would be more appropriate. If a community is interested in knowing how much automobile emissions are being mitigated by roadside tree buffers, then obviously a much finer spatially resolved land cover data set is required in addition to perhaps more information about tree species. Likewise, fine spatial and thematic resolution land cover data may be required to measure pollination as a service. Temporal resolution is important for investigating changes over time and predicting future conditions. Several sources of existing national land cover data exist for the conterminous United States with perhaps the best known being the National Land Cover Database (NLCD; MRLC 2015), a 30-meter-resolution, 16-class product developed by the Multi-Resolution Land Characteristics Consortium (MRLC) every five years, most recently in 2011. NLCD will be moving to an annual product in the future. NLCD maps land cover to 16 different land cover classes. Other nationally available land cover databases that can be used in addition to NLCD include: \u2022 USDA's National Cropland Data Layer, a 30-meter-resolution annual product with specificity in types of crops across the United States; \u2022 USGS Gap Analysis Program (GAP), the U.S. interagency Landscape Fire and Resource Planning (LANDFIRE) program, and the USGS and ESRI Global Ecosystems mapping product, all of which map ecosystems at a 30-meter resolution with hundreds of ecosystem classes; and \u2022 NOAA's Coastal Change Analysis Program (C-CAP) Land Cover, available now for coastal areas at a 30-meter resolution, more finely resolved wetland classes than NLCD. NOAA will be producing a 1-meter product in the future. Much more spatially resolved land cover data are necessary for many ecosystem services assessments where finely resolved landscape features are particularly important. Coarse scale data oversimplify land cover patterns in highly fragmented environments like urban environments and riparian corridors. Ecosystem services assessments in urban areas also require spatial detail because it is important to know where the forests and other natural land cover types are in relation to where people are living and working, roadways, and other infrastructure. The Environmental Protection Agency (EPA) and the USFS are developing 1-meter land cover data for many communities across the United States that are being used in ecosystem services assessments (www.epa.gov/enviroatlas and http://gis.w3.uvm.edu/utc).The demand for high-resolution land cover data is beginning to result in investment in regional 1-meter land cover products, with a recent example being the Chesapeake and Delaware Bay watersheds. The NLCD is completed every five years and thus allows for a historical land cover change analysis, which is important for evaluating ecosystem services changes over time. For future ecosystem services projections, the USGS has produced Forecasting Scenarios of Land-Use Change (FORE-SCE; Sohl and Sayler 2008), land cover projections out to the year 2100 with a spatial resolution of 250 meters, and about the same number of classification classes as NLCD. USGS has also released backward-looking products going back to 1938 (Sohl et al. 2016), while the EPA has produced the Integrated Climate and Land-Use Scenarios (ICLUS) report, which explores future changes in human population, housing density, and impervious surface for the United States. The accuracy of land cover data varies across the different products and is something with which a user should become familiar. Typically land cover products with more classes will have a much lower accuracy for each class than will a land cover product with fewer classes."}, {"section_title": "Terrestrial and Freshwater Biodiversity", "text": "Biodiversity is the variety of life and the ecological processes and interactions that characterize ecosystems on earth. That variety is commonly characterized at multiple levels of ecological organization, from genetic diversity within organisms to species diversity within natural communities, to community diversity within landscapes or regions. Since it supports the core benefits that people derive from their environment, biodiversity is fundamental for the provision of many ecosystem services. Many services related to outdoor recreation and nature appreciation or existence are tied directly to a given place's biodiversity. In practical terms, biodiversity information applicable to ecosystem service assessment includes data that describe and locate biodiversity on land and in water. It also includes information on biodiversity's response to human alterations that affect primary ecological processes. These ecological processes and their continued function determine the impacts on biodiversity and the sustainability of continued flows for related services. These data and models can be organized in terms of species and communities in terrestrial or aquatic environments."}, {"section_title": "Data Sources: Status and Trends Species: What We Have", "text": "Species are one common starting point for addressing biodiversity. In the United States, NatureServe is a primary source of information on the taxonomy, description, distribution, and relative at-risk status that would be needed to address the services they might provide. NatureServe has data available on several web portals including NatureServe Explorer and Landscope America (www.landscope.org). NatureServe Explorer includes information on nearly 60,000 species in the United States, with taxonomy, generalized distribution, life history, and at-risk status. Because Natural Heritage programs originated as field inventories for species considered to be at some risk of extinction, species information is best developed for that subset of all species. For many at-risk species, additional information on how to document local occurrences and their viability, as well as their conservation management and monitoring, is summarized. NatureServe compiles detailed location information from Natural Heritage programs in all 50 U.S. states, the Navajo Nation, and all of the Canadian provinces for species of conservation concern, including legally listed species. Over one million locations have been documented in this cumulative database since systematic inventories began in the 1970s. Programs apply specific rules for delineating locations so they provide a high-confidence prediction of occurrence for each species. Given data sensitivity, access to documented field locations for at-risk species are not posted publicly but are available under license or by subscription (www.natureserve.org/conservation-tools/natureserve-surveyor) with NatureServe (2016b) or individual Natural Heritage programs. Another major source of data for species assessment in the United States is the USGS through two sources. The first is their national Gap Analysis Program (GAP; http://gapanalysis.usgs.gov), which has downloadable spatial data showing the range and distribution of almost all vertebrate species in the United States. The program has existed for over 20 years and over the last few years has focused on creating access to relatively consistent nationwide information for vertebrates. Habitat relationships for each species have been documented by GAP for subsequent use in distribution mapping. It should be emphasized that GAP models are aimed at predicting species distributions, reflecting potential range rather than more narrowly defined habitat associations. GAP data are also available on the new EPA EnviroAtlas (http://enviroatlas.epa.gov/enviroatlas), designed to provide access to national data on ecosystem services. Another portal for location data in the United States is the new Biodiversity Information Serving Our Nation (BISON) resource (http://bison.usgs.ornl.gov), which has detailed specimen data from as many sources as could be identified, along with selected observations of species. BISON is the U.S. node of the Global Biodiversity Information Facility (GBIF, www.gbif.org) and therefore hosts essentially all records of species occurrences available for the country, including those data sets mentioned here specifically. From a practical standpoint, addressing terrestrial, freshwater, and marine species separately makes sense, since most services-focused ecosystem analyses would need to be different for each of these groups of species. However, currently, as described previously, most species information is organized primarily by the type of information provided and then by taxonomy. The National Resource Conservation Service (NRCS) PLANTS Database (http://plants.usda.gov), with its generalized distribution data, is widely used for plant taxonomy in the United States. The database and portal provide straightforward downloads and are largely up to date but provide no information on distribution trends over time. The most extensive network of species data for any specific group of taxa has been compiled for birds by the Cornell Lab of Ornithology, available on a series of portals including eBird (www.ebird.org), All About Birds (www.allaboutbirds.org), and the subscription-based Birds of North America (http://bna.birds.cornell.edu). The National Science Foundation-supported eBird, an example of the power of citizen science, provides detailed information on most bird observations, allowing for an analysis of their distribution and, when combined with the almost 50 years of data from the Breeding Birds Survey, allows for detailed analysis of their distribution and trends (Sauer et al. 2014), much of the critical information needed for ecological analysis. However, many birds are strongly associated with freshwater aquatic habitats and others with marine habitats, and the available databases and sites are designed to provide information on an individual species basis without identifying their associated habitats. NatureServe and the network has developed a partnership with iNaturalist (www.inaturalist.org) to develop similar information for all amphibians, reptiles, and mammals and many groups of freshwater fish and invertebrates. Other sources of species observation data include DataONE and the National Phenology Network. DataONE provides the distributed framework (composed of Member Nodes and Coordinating Nodes), sound management, and robust technologies that enable long-term preservation of diverse multiscale, multidiscipline, and multinational observational data (DataONE 2016). The U.S.A. National Phenology Network aims to detect and analyze trends in biodiversity by focusing on phenology in plant and animal species (USANPN 2016). The U.S. FWS and state fish and wildlife agencies have extensive data on species, especially those that are important for hunters and fishers. Seasonal habitat use areas and migration corridors are most commonly developed for wildlife management but vary considerably in their level of development and public accessibility. Watchable wildlife areas have also been designated throughout much of the United States (Watchable Wildlife 2011), and this information may be used to document major wildlife-related recreation sites. Information associated with the response of a given species to human alteration is found in several forms from NatureServe. A relative score (called an element occurrence or EO rank) for quality of a given location or occurrence is based on the application of ecological criteria by field biologists. These scores are A-D, where an \"A\" EO rank indicates a very high-quality occurrence, while a \"D\" rank indicates severely degraded ecological conditions and presumed limited viability. Ideally, these criteria (as opposed to the resulting score) would be of use in production functions because they could characterize the common responses of the species to human alterations that affect primary and supporting ecological processes. The criteria used to assign ranks to occurrences focus on the likelihood of long-term persistence as affected by population size (or habitat area), habitat condition, and spatial context. That is, while these factors might contribute to ecological production functions as influenced by management activities, actual production functions have not been estimated. NatureServe Conservation Status ranks use information on distribution, EO rank, and trends in threats to determine the relative extinction risk rangewide (called a global or G-rank) or within a given subnation (S-rank). For at-risk species, an information source parallel to the NatureServe Conservation Status rank is the International Union for Conservation of Nature (IUCN) and their Red List of Threatened Species (www.iucnredlist.org). This site provides various search options to access information on common threats and protective management or policy responses. For analysis of species, a significant need is for relatively detailed maps showing locations where species with high existence values, particularly species with regulatory requirements (listed or at risk), occur or may occur. Currently available data, such as NatureServe occurrences, remain an essential source, but their completeness and currency require ongoing investment in systematic field inventory. Also, the U.S. FWS has maps showing areas of defined critical habitat or other recovery plan areas, such as those defined as late-successional reserves (LSRs) for the northern spotted owl and marbled murrelet. For a limited number of listed or regulated species, probability-based distribution maps showing the likelihood of species' occurrence are available. There is a need for integrated maps that combine probability of occurrences (and/or habitat quality) with any designated critical habitat (reflecting plans for recovery). For more common vertebrates and vascular plants, integrating observations and collection data into distribution databases that showed the last observation within an area, most suitably a 12-digit hydrologic unit code (HUC), could be readily accomplished and could provide important information for species distributions and trends. Research on trends in the distribution and status of species requires this baseline knowledge. These data can be built on over time through field monitoring and remote sensing of changing landscape conditions. This remains a substantial unmet need."}, {"section_title": "Vertebrate Models", "text": "Production function models for vertebrates assess how management or resource use affects species, so information on critical corridors and seasonal habitat need to be established and monitored. These data need to consistently characterize, map, and document the relative quality of these critical habitat components. Currently, these data are developed in limited form, often by state wildlife agencies and wildlife researchers, and so there are no established sources where these data have been consolidated. Invertebrates, Plants, Fungi, and Other Taxa BISON and the GBIF do a good job integrating observation and collection data; however, they are generally only searchable on a species-by-species basis. For assessing species existence in a location, a standard set of geographies used in analysis, such as watersheds, could be identified, so that species lists for these geographies could readily be generated, significantly improving agencies' ability to use the information. Natural Heritage programs commonly maintain lists of at-risk species by county or other local political jurisdiction. Another need is to attribute these species to marine vs. freshwater vs. terrestrial ecosystems, so one can better determine how management will affect the systems in which they reside. For both, assessing species as to their relative tolerance for intensive human uses (timberlands, farmlands, rangelands, etc.) would greatly assist in ecosystem service-related analysis to help predict changes."}, {"section_title": "Natural Communities: What We Have", "text": "Natural communities provide a range of cultural, spiritual, and recreational services. Seeing a unique or colorful plant or any large native animal or walking through a majestic old-growth forest or across alpine tundra can be inspiring. Natural communities are characterized by the diversity of landscapes and regions and are chronicled most extensively for terrestrial environments of the United States. NatureServe Explorer (http://explorer.natureserve.org) and, in collaboration with the Ecological Society of America, the U.S. National Vegetation Classification (www.usnvc.org), describe vegetation-based natural communities. Maps of vegetation-based natural communities are available at national and regional scales from sources such as the USGS GAP, NatureServe, and the interagency LANDFIRE program (www.landfire.gov). In each of these efforts, natural communities are described at multiple levels of thematic detail, so that few or many map types may be displayed, depending on user needs. Both the USFS and National Park Service have active vegetation inventory programs targeted to the lands they manage. Wetlands (i.e., swamps, bogs, marshes, riparian zones, and shallow ponds), while also included in these previously mentioned sources, are the primary focus of the National Wetlands Inventory (NWI; www.fws.gov/wetlands). NWI is an ongoing effort to map locations and trends in wetland extent nationwide. They include relatively few wetland types but do provide an extensive national map resource suitable for many applications. Wetland condition assessments (e.g., NatureServe 2016a) aim to characterize the functional values and ecological integrity associated with a wetland, given the potential altering effects of land and water uses (U.S EPA 2016c). The U.S. EPA has supported extensive wetland and freshwater aquatic condition assessments; the latter measure the composition of aquatic species to indicate the degree to which physical or chemical alterations have affected ecological functions. Compared with the terrestrial environment, there has been much less emphasis on freshwater natural community classification and description. Freshwater natural communities are typically described in terms of their physical characteristics (e.g., water temperature, chemistry, and dynamic flow properties) and animal species (e.g., invertebrates and fish). The Nature Conservancy (2015) has contributed much to mapping and assessing freshwater communities throughout the United States. USGS maintains maps of hydrography, depicting streams, rivers, and lakes. These data are readily available in the National Hydrological Dataset (NHD, http://nhd.usgs.gov) so that freshwater communities can be represented in generalized form, although the NHD is uneven in its development across the country and needs significant investments in many areas to provide the improvements needed to represent hydrology well enough to inform most water-related services."}, {"section_title": "Natural Communities: What We Need", "text": "As noted above, classification and description of aquatic communities are far less developed than those of terrestrial communities, although new efforts are underway (Artz 2016). Mapping the location of aquatic communities, once they are classified and described, is most advanced for surface waters. Least developed of all are natural communities, both terrestrial and aquatic, associated with caves. Natural isolation in caves is well known to result in narrow endemism of both terrestrial and aquatic species, but the classification, description, and inventory of cave ecosystems remains very limited. Finally, the relative at-risk status of natural communities, like that for species, could provide an additional measure of irreplaceability for the existence value of biodiversity. Documenting at-risk status for natural communities lags behind efforts for species. However, recent international initiatives, with pilot efforts in the United States, include the IUCN Red List of Ecosystems. The IUCN approach documents rangewide trends in conversion and human alteration to a given ecosystem type in order to gauge its at-risk status as critically endangered, endangered, vulnerable, near threatened, or least concern. As pilot efforts are completed, new investment in documenting the at-risk status of all terrestrial and aquatic ecosystem types should provide an important contribution to ecosystem service assessments."}, {"section_title": "Predictive Models", "text": "Predictive models of species, habitats, or natural communities can be used to reflect both the existence values of important features across the landscape and the attributes that directly define services, such as carbon sequestration, flood amelioration, and pollinator availability. And most predictive models are tied to spatial data that can reflect changes over time, so that changes in service provisions based on investments, mitigation, restoration, or other activities can be measured. With respect to recreational species, fish and wildlife agencies have detailed models reflecting important habitat attributes, such as big game winter range or upland game bird breeding habitats. They also have detailed information on available wildlife numbers, allowing them to set hunting and fishing limits that maintain viable populations. However, the link between the production functions in the terrestrial and aquatic habitats or landscape and the numbers of fish and wildlife available for food and recreation is generally available locally and only for a limited number of species (salmon, deer, elk, etc.).\nThe economic value to agriculture from a change in abundance of wild pollinators depends on four factors: (1) the distance of pollinator habitats from crop fields, (2) the extent to which those crops are dependent on pollinators, (3) the response of crop yields to the additional pollination, and (4) crop price (Iovanna et al. 2017). Isolating the effect of pollinators on yields requires care, because pollination is only one of many important inputs to crops that determine yield (Iovanna et al. 2017). The InVEST Model of Crop Pollination is a commonly used tool to predict changes in supply of native pollinators within range of a target agricultural field at a landscape scale. Data inputs include land use/land cover, relative availability of nesting and foraging resources on each land cover type, and pollinator species/guild attributes (Lonsdorf et al. 2009;Wolny 2012). The model is typically used on landscape scales, at which data can be gathered in a consistent manner (e.g., Kennedy et al. 2013;Ricketts and Lonsdorf 2013). Broader-scale assessments require much more intensive data compilation efforts, and they may require expert sources of data when consistent datasets aren't available (Koh et al. 2016). Efforts are under way to modify the InVEST landscape model to inform farm-scale decisions that reflect evaluation of integrated use of managed bees and wild bees to support crop pollination (Integrated Crop Pollination Project 2017). The InVEST Crop Pollination model is designed to account for the diminishing impact of pollinators on crop fields with increasing distance from pollinator habitat and the diminishing change in marginal relative value with increasing pollinator abundance. In other words, where few pollinators exist, the addition of new pollinator habitat can make a large impact, but where pollinators are already plentiful, new habitat will make less of a difference (Iovanna et al. 2017). Insect pollinators are only valuable to those crops that depend in some way on pollinator services, so the InVEST Crop Pollination model accounts for the pollinator-dependence of crops in the landscape (Klein et al. 2007) (Iovanna et al. 2017). Output maps include pollinator abundance over the entire landscape, pollinator abundance on farms, and relative pollinator service value of each cell (Wolny 2012). The InVEST model provides only relative indices of pollinator abundance and value. To relate these relative indices to actual monetary values, the user must obtain prices for each pollinator-dependent crop within the area of interest. Crop prices can be found at the USDA Agricultural Marketing Service (AMS) Market News website (USDA Agricultural Marketing Service 2017), and U.S. futures market prices, at the CME Group site (CME Group 2017). Currently, the best way to model the relationship between floral diversity and managed honeybee health is to rate the floral resources of a landscape using a managed-bee ArcGIS tool (Lonsdorf and Davis 2016). This model applies the same assumptions as the InVEST pollinator model, namely that floral resources within the foraging area are directly related to honeybee colony health. The model parameters needed to describe habitat quality can be informed by recent empirical studies (e.g., Otto et al. 2016;Smart et al. 2016a,b). Output from the model is a raster map showing the quality of floral resources at point, over the spring-fall growing season. This output can be ground truthed using honey production data. Gallant et al. (2014) developed a complex analysis for predicting conditions that might support hives using multiple sources of land cover to determine where apiaries of 100 or more colonies could be supported. The supplemental materials of this paper include data on crops that benefit from or require insect pollinators, including the percentage of yield due to insect pollination. Ricketts et al. 2008 http://dx.doi.org/10.11 11/j.1461 --0248.2008.01157.x This synthesizes results from 23 studies estimating the relationship between pollination services and distance to natural habitats. Pollinator richness and visitation rates to crops exponentially decline with increasing distance from natural habitat; evidence indicates an overall decline in fruit and seed set. This model builds on the assumption that floral resources are directly related to health of a honeybee colony, and it ground truths the estimates using available honey production data.\nEcosystem services typically consider the multiple benefits water in streams provide to society, as direct human water use and consumption is only one benefit. Neither abundant, polluted water nor clean, scarce water is able to meet societal water-supply needs. Understanding how climate and human alterations to the landscape affect streamflow is an active area of research. Some studies have used empirical models to compare streamflow changes between nearby natural (unaltered) and human-modified basins (e.g., Vogel et al. 2011;Arrigoni et al. 2010;Hodgkins et al. 2007). Changes in streamflow in natural basins are attributed to climate and natural disturbance processes, and differences in the human-modified basins can be attributed to human influences, in terms of both direct withdrawals and indirect landscape impacts. Indirect impacts include changes in land cover, which can often have mixed impacts on water supply. For example, more forest cover can result in more evapotranspiration and less overall water supply, as well as changes in the timing of runoff, groundwater reacharge, and water quality (e.g., Kim 2012), though these are not strict relationships and they depend on watershed geology, ecology, and climate. Agricultural changes in land cover have been documented to have mixed impacts depending on type of crop, the land cover agriculture is replacing, and the drainage system used (Schilling et al. 2008). Urbanization, one of the dominant factors in altering streamflow, often results in increased streamflow after rain events due to increased impervious surface, but it can also result in an overall decrease in streamflow as groundwater recharge is reduced (Hodgkins et al. 2007;Dewalle et al. 2000). Moving beyond a paired catchment approach, empirical analysis can be combined with physically based models (such as the Soil and Water Assessment Tool, SWAT) to determine if human activities are responsible for major changes in streamflow within a specific watershed (e.g., Kim 2012;Claessens et al. 2006). A third approach has been to quantify the relative contribution of climate and direct human modifications on mean annual streamflow using Budyko curves, which rely on the interdependence between mean annual evaporation and potential evaporation (influenced by land cover) for a watershed's precipitation regime (e.g., Patterson et al. 2013;Wang and Hejazi 2011). All three approaches can be applied and will provide different results given the location and time period of observation (i.e., trends from 1960 to 1990 may be different from trends from 1980 to 2010; McCabe and Wolock 2002). Furthermore, it is very hard to separate the effects of land use change on water supply available because watersheds are dynamic, depending on a unique combination of climate, land use, and water use that can change over time. Therefore, a given increase in urbanization may have very different relationships to changes in streamflow depending on other factors in the watershed. Water-based recreation-particularly swimming, fishing, and boating-requires relatively high-quality water in order for these activities to be safe and aesthetically enjoyable. Water quality for freshwater recreation is a particularly multifaceted and challenging suite of ecosystem services for which to develop nationally standardized data, models, and valuation approaches. Before water quality and its effect on associated recreational values can be valued, physical changes in water quality must be quantified; water quantity may matter as well, as it affects pollutant concentrations and the seasonality of any water-quality problems (Young 2005). Phosphorus is generally the limiting nutrient in freshwater systems, so its quantification will be particularly important; however, other pollutants may also impair water quality and affect recreational users. The U.S. EPA's Impaired Waters, Assessed Waters, and Total Maximum Daily Load (TMDL) database (http://water.epa.gov/scitech/datait/tools/waters/data/downloads.cfm) provides spatial information on water-quality impairment, including the degree of pollution and the specific pollutants of concern in a given watershed. Water quality for freshwater recreation as an ecosystem service can be valued in at least three different ways: (1) by quantifying baseline water quality, recreational use, and value (placing value on the water resource used by recreationists, i.e., a particular river reach, lake, or reservoir, and making assumptions about potential substitutes and other considerations, such as the relationship between water quality and recreation demand); (2) by quantifying the current contribution of upstream ecosystems in improving water quality, recreational use, and associated values for downstream recreational sites (placing economic value on the upstream ecosystems that improve water quality, i.e., the value of upstream wetlands or riparian buffers in improving water quality, which requires a simulation of water quality with and without ecosystems that can filter pollutants); and/or (3) by quantifying how proposed future management changes (e.g., land use/land cover, agricultural practices) may improve or degrade downstream water quality, recreational use, and associated values (placing economic value on the water resource and/or upstream ecosystems that improve water quality, which requires a simulation of current water quality and potential future improvements or degradation brought on by land use or management changes). Each of these requires different types of information on ecosystems and the services they provide. Many national sources of water quality data exist, including data from the U.S. Geological Survey (USGS) (http://water.usgs.gov/owq/data.html), such as the National Water-Quality Assessment (NAWQA, http://water.usgs.gov/nawqa/) and National Water Information System (NWIS, http://nwis.waterdata.usgs.gov/nwis) programs. The U.S. EPA's National Lake Assessment and National Rivers and Streams Assessment provide data on lake and stream water quality, respectively (http://water.epa.gov/type/lakes/lakessurvey_index.cfm, http://water.epa.gov/type/rsl/monitoring/riverssurvey), and their National Pollutant Discharge Elimination (NPDES) program database provides additional data on point source pollution (https://ofmpub.epa.gov/apex/aps/f?p=GPWI:HOME::::::). The U.S. EPA's EnviroAtlas also provides a number of potential model inputs for \"Clean and Plentiful Water.\" Results are aggregated at the HUC-12 level, which is unlikely to provide the needed spatial resolution for modeling; however, the original preaggregation data used for the EnviroAtlas can be obtained for use in modeling. The USGS's Reservoir Sedimentation Database (RESSED, http://water.usgs.gov/osw/ressed) provides data on sediment delivery to reservoirs and may be helpful for quantifying the costs of sedimentation. Emerging efforts such as the National Ecological Observatory Network (NEON) may also provide useful data on water quality that could support the quantification and valuation of this service in the coming years (www.neonscience.org).\nVarious models have been used to quantify water quality; for a more complete review than is possible here, see Wang et al. (2013) and Olander et al. (2014). Selected models that have been used to assess water quality include dedicated hydrologic models such as the Soil and Water Assessment Tool (SWAT, Arnold and Fohrer 2005;Francesconi et al. 2016) and more generalized ecosystem service models such as Integrated Valuation of Ecosystem Services and Tradeoffs (InVEST) or ARtificial Intelligence for Ecosystem Services (ARIES, Vigerstol and Aukema 2011). The USGS Spatially Referenced Regression on Watershed attributes (SPARROW) model has been used at the national and regional scales to track nitrogen, phosphorus, suspended sediment, and organic carbon (http://water.usgs.gov/nawqa/sparrow). Another USGS model, the Load Estimator (LOADEST), can be used to quantify more diverse pollutants but is more data intensive (http://water.usgs.gov/software/loadest). The U.S. Department of Agriculture (USDA) has been working with the APEX (Agricultural Policy/Environmental eXtender)-based Nutrient Tracking Tool to evaluate the effects of agricultural (both animal and crop production) management on nitrogen, phosphorus, and sediment loadings from farms (Saleh et al. 2011). More generalized, less data-intensive models are more likely to be useful for regional-and national-scale assessments than data-intensive models (like SWAT) whose nationwide application would be resource intensive. However, data-intensive models can be very useful for case studies and for analyzing the accuracy of more generalized models (e.g., Dennedy-Frank et al. 2016). Ecosystem service models like InVEST and ARIES use approaches including the Universal Soil Loss Equation (USLE), 1 other deterministic or probabilistic methods to quantify sediment retention as an ecosystem service, and nutrient export and retention approaches to quantify nutrient regulation (Kareiva et al. 2011;. Such models are easier to parameterize and run when data and model coefficients are accessible and transparent; recent work to catalog model coefficients for use with InVEST sediment and nutrient models (www.naturalcapitalproject.org/database.html) and to automate data and model selection in ARIES are examples of steps forward to make these tools more useful for regional-and national-scale assessments. For most models, basic tradeoffs exist between spatial and temporal resolution data sets, and not all models are yet capable of modeling at fine (i.e., subannual) temporal resolution, as adequate calibration data may be difficult to obtain. \nWhile there are clearly myriad connections between biophysical ocean data and society's well-being, only a subset of this information is directly applicable and in a form that supports comprehensive ecosystem services assessments. Models of fisheries production function that link biophysical data, population abundance, and projected catch have been extensively used for decades to manage commercial and recreational fisheries (see Age Structured Assessment Program and A Stock Production Model Incorporating Covariates, for example, among other methods in the NOAA Fisheries Toolbox). NOAA is also currently piloting a new fisheries management model that analyzes how different management regulations (e.g., closed areas) affect fishers' welfare. Outside of fisheries, NOAA has developed ecosystem service production functions on a more limited, project-by-project basis depending on the management context. In addition, the InVEST toolkit incorporates a wide variety of data sets to assess several other marine ecosystem services (carbon sequestration, coastal protection, marine aquaculture, marine water quality, and wave energy) and is flexible to the amount and type of data available. However, other than in fisheries, there is generally a dearth of linked biophysical and socioeconomic data needed to construct production functions used in ecosystem services assessments. \nThe other approach to estimating carbon storage and sequestration is model driven. General algorithms based on empirical (and data-driven) evidence are used to recreate carbon pools as well as fluxes across a system that can vary in depth and scale. For instance, the Forest Vegetation Simulator (FVS), an individual tree growth and yield model (Dixon 2002), estimates carbon storage and sequestration capacity on a stand to landscape scale including all relevant forest ecosystem pools such as aboveground and belowground live biomass, detrital pools, and organic soil carbon. Extensions of FVS can further provide estimates under various climate change assumptions as well as on carbon pools and fluxes of biomass harvests including forest product fate assumptions. FVS, coupled with fire models such as FlamMap (USDA 2016b) and advanced vegetation and fire behavior modeling, can encompass highly disruptive stochastic events in their estimates (Finney 2006). For agriculture, carbon storage and sequestration models focus on the plant-soil nutrient cycling such as the CENTURY model and the user-friendly adaptation of this tool, COMET-Farm (Finney 2006). A variety of hybrid approaches rely more on the data-or model-driven approach. For instance, FIA data coupled with FVS modeling efforts are frequently used to estimate and monitor carbon storage and sequestration capacity of forests at a variety of scales (e.g., Nunery and Keeton 2010;MacLean et al. 2014;Gunn et al. 2014). If the goal is to assess general greenhouse gas implications of land use scenarios, it is important to consider that a change in vegetation cover and soil dynamics is not restricted to carbon or CO 2 release. The inclusion of non-CO 2 GHG-relevant emissions (other reactive gases and biogenic aerosols and factors such as methane or atmospheric particles), surface albedo, evapotranspiration, or complex greenhouse gas decay functions can alter model results significantly. We identify six major fields of uncertainty in several components of current approaches to estimate carbon storage and sequestration: (i) The identification of baselines against which a given scenario can be assessed is a major step in carbon storage and sequestration estimates and frequently a focus of scientific debate. In particular, defining and predicting an alternative future in the absence of a proposed policy or practice (i.e., a counterfactual baseline) is inherently uncertain (e.g., Buchholz et al. 2014). (ii) Spatial and (iii) temporal boundaries frequently drive outcomes and can range from a stand-level to ecoregion-level analysis including wildfire dynamics or from a few decades to thousands of years. (iv) The inclusion of behavioral effects and leakage frequently extends outcome uncertainty significantly. (v) In the case of GHG impact analysis, a lack of scientific consensus on metrics complicates a comparison of study outcomes. Last, (vi) the mineral soil is one of the largest terrestrial carbon pools. The response of this slow-acting carbon pool to altered aboveground conditions is largely unknown. "}, {"section_title": "Natural Communities", "text": "Since patterns in vegetation or aquatic fauna reflect their environmental settings and natural disturbance processes, they form a practical focus for modeling production functions related to the existence value of these communities and a proxy for related species existence and other biodiversity-based ecosystem services. Most common forms of human alteration to natural communities are from land conversion (for agriculture, urban, and industrial land uses), degradation from overuse by forestry or grazing, displacement of native species diversity by invasive species, and disruption of natural dynamic processes like river flooding or natural wildfire. Land use and remote sensing data can track these patterns and trends across land and water (e.g., U.S. EPA 2001; Leu et al. 2008;Theobald 2013), providing a source for analysis of ecosystem service provision. Conceptual \"state and transition\" models have been developed to predict and track the effects of wildfire, wildlife, forestry, or rangeland management on natural community types and landscapes. These can provide ecological production functions for assessing how ecosystem services provided by the natural community change. Models of natural wildfire regimes are available through the LANDFIRE program for all major upland vegetation types in the United States. Not only are there quantitative descriptions of fire frequency, intensity, and successional pathways, but maps are produced for fuels, topography, recent fire events, and fire regime alteration. Fire regime alteration expresses the departure from expected vegetation conditions resulting from fire suppression or effects of invasive plant species. Similarly, the NRCS maintains more-specific state and transition models connected to soil type maps for use in rangeland and forest management. These models, called \"ecological site descriptions,\" are currently most developed in the western states, but initiatives aim to advance their development nationwide (USDA NRCS 2016). Many federal and state agencies rely on models to evaluate how management decisions affect ecosystem outputs. Increasingly, state and transition models, such as those mentioned above, are linked to climate variables and subsequently applied using climate change projections for upcoming decades. These models may provide an indication of the magnitude and direction of change in dynamic processes (fire, species invasion, and hydrology). More complex process models, such as Landis (Landis-II 2016), are used to evaluate ecosystem outputs and tree species distributions in light of management actions and climate change. All of these can provide detailed information that can directly inform environmental outputs such as wood products, carbon sequestration, wildlife abundance, and fire risk, but currently the detailed models informing specific local or watershed outputs exist in only a few parts of the United States. Although considerable information exists for understanding how natural communities are affected by human uses, much effort is needed to integrate existing information into predictive models and to do so across terrestrial and aquatic environments. This knowledge would be greatly enhanced by the systematic establishment of reference locations specifically aimed at measuring responses to human alteration, so that comparative analysis of field observations can better support inferences regarding the effects of land or water uses on key ecological processes. This type of information may be gleaned from Long-Term Ecological Research (LTER) sites and the developing National Ecological Observatory Networ k (NEON), but these networks aim for very intensive research in a small range of locations. The U.S. EPA (2016b) National Wetland Condition Assessment represents one broader effort to establish reference locations (currently around 1,200) for national reporting on trends in wetlands. NatureServe network programs have established as many as 60,000 locations, mostly east of the Rocky Mountains, where natural communities have been described and assessed. Much related information also exists throughout conservation lands where ecological management and restoration has been implemented and monitored. A coordinated effort to integrate and augment this information could form the foundation for modeling production functions of numerous biodiversity-related ecosystem services. An Example of Infrastructure Data from the U.S. Forest Service Often, additional data on infrastructure that interacts with ecosystems and the flow of services will be needed for assessment. This can be useful for both the ecological assessment of ecosystem service supply and quantifying accessibility of services, which is important for understanding potential importance to people. We provide an example here from the USFS. The USFS collects and maintains spatially referenced (geographic information system, GIS) data on the built environment (infrastructure) under its jurisdiction. Publicly available data can be found at http://data.fs.usda.gov/geodata/edw/datasets.php and include information on three types of infrastructure: (1) National Forest System trails, (2) National Forest System roads, and (3) National Forest System recreational facilities. These GIS data are in the process of development and are not yet comprehensive. First, basic trail data are available for public use and distribution describing the characteristics of more than 5,000 USFS trails (spanning roughly 10,000 trail miles). These data may include basic trail characteristics such as trail number, trail name, trail length, trail surface (native material, imported material, snow), typical range of trail grade (in percent), trail width, and whether motorized, bicycle, or stock use of the trail is authorized. Second, the USFS maintains publicly available data on more than 75,000 National Forest Service roads (spanning nearly 100,000 miles). For each road segment, these data include road name, road surface (paved, gravel, dirt), and suitability for various types of vehicles. Third, the USFS collects and maintains publicly available data on selected recreational sites and facilities. These data are sparse and are currently unavailable for many recreation sites. Characteristics of the data may include the recreation area name and type. "}, {"section_title": "Pollination", "text": "Pollinators are essential to our food system and are important inputs to our farming economy (Potts et al. 2010). Roughly two-thirds of the world's most important crop plants benefit from bees and other pollinators (Klein et al. 2007). In the United States, bees are estimated to contribute 11% of agricultural gross domestic product (Lautenbach et al. 2012). Of this overall contribution, at least 20% (equivalent to $3.07 billion) is provided by wild pollinators (Losey and Vaughn 2006). Pollinators help to maintain the livelihoods of farmers who depend on them. Pollination services can stem from wild pollinators as well as from managed colonies of insects. Many farmers use managed honeybees (Apis mellifera) to ensure crop pollination, but there is increasing evidence that wild bees play an important role as well (Garibaldi et al. 2013). There are roughly 4,000 species of bees in the United States, but only a relative few are important crop pollinators (Kleijn et al. 2015 ). Honeybees and native bees can complement each other in providing pollination to crops (Brittain et al. 2013;Greenleaf 2006), and crops appear to benefit from native bee pollination even when honeybees are abundant (Garibaldi et al. 2013). Both managed and wild populations of bees are declining in the United States due to a mix of parasites, diseases, habitat loss, and pesticides (Potts et al. 2010;Bartemeus et al. 2013;Colla et al. 2012). In the United States, the number of honeybee hives has declined steadily over the last 50 years (Ellis et al. 2010 "}, {"section_title": "Data Sources", "text": "The data described here pertain to insect pollinators, but data on other animal pollinators could be incorporated. Pollinator presence can be loosely approximated on the basis of land cover type; land cover classes determined to be pollinator habitat (such as grassland, forest, or wetland) can act as a proxy for pollinator presence. This relatively simple way to account for the likely abundance of pollinators does not, however, allow for any description of population sizes or pollinator diversity. The National Land Cover Dataset (NLCD) is a widely used dataset with distinct land cover classifications that can be used to estimate the presence and amounts of pollinator habitat. (A full list of land classification datasets that could also be used as pollinator habitat proxies can be found in the \"Land Use and Land Cover Change Data\" section.) There has been a recent increase in research regarding the linkages between land cover and pollinator health. For wild pollinators, important reviews include papers on loss of pollinator habitat quantity or quality (Brown and Paxton 2009;Koh et al. 2016), bee abundance and landscape composition (Viana et al. 2012;Kennedy et al. 2013), and disturbance effects on wild bees (Potts et al. 2010;Winfree et al. 2010). For honey bees, research also demonstrates a clear association between land use and honey bee colony survival (Smart et al. 2016a;Paudel et al. 2015), individual bee physiology (Smart et al. 2016b), diet (Requier et al. 2015), and large-scale habitat suitability (Gallant et al. 2014;Otto et al. 2016) (Iovanna et al. 2017). It is important to assess pollinator services in relation to the location of crops that benefit from or require pollinators. The USDA Cropland data layers are national-scale raster coverages that distinguish among crop cover types and thus allow for identification of the location of pollinator-dependent crops. Other datasets provide lists of pollinator crops that benefit from or depend on pollinators and also indicate the fraction of production attributed to insect pollination (Calderone 2012;Klein et al. 2007). Additional useful data sources include the USGS Pollinator Library, which documents and continually updates information on forbs that are utilized by pollinating insects across broad U.S. geographic regions (USGS 2016). Data on honey bee forage species, by region, can be found in the Bee Forage Regions database from NASA (NASA 2017). Regionally appropriate seed mixes for establishing pollinatorfriendly wildflower strips are available from the USDA National Conservation Research Service (USDA National Conservation Research Service). The National Agricultural Statistics Service (NASS) houses data on honey production, prices, inventory, and sales as well data on honey bee colonies, colony sales, and colony collapse due to a variety of causes (USDA National Agricultural Statistics Service 2017)."}, {"section_title": "Fresh--Water Supply", "text": "Fresh-water supply or water-quantity data describe different types of water resources: surface water that is flowing (streams, rivers) or in lakes and reservoirs, and groundwater stored in aquifers. The quantity of surface water available in a region is largely a function of climate and water-use patterns. The type of human water use defines the demand for a given quantity, quality, and timing of water. Climate, as well as hydrology and upstream water use, defines the amount and timing of water delivered into a basin. In many instances, infrastructure, such as reservoirs and canals, tunnels, and pumping stations that divert water for inter-basin transfers, has been constructed to redistribute the amount of water available over time and space. Reservoirs change the natural variation of streamflow (the amount and timing of water in a stream), which can negatively affect downstream ecosystems (e.g., Pearsall et al. 2005;Doyle et al. 2003). Some reservoirs have attempted to change their water operations to mimic a more natural flow regime while meeting societal needs (e.g., for John H. Kerr Reservoir, see Pearsall et al. 2005; for Glen Canyon Dam, see Stevens et al. 2001)."}, {"section_title": "Data Sources: Status and Trends", "text": "The main source of national water-supply data is through the USGS, which manages a network of streamgages throughout the United States (http://waterdata.usgs.gov/nwis). Stream gages collect continuous stage (height of river) and discharge (flow through the river) at a single point, which is often averaged to a daily time step. Some stream gages collect additional data including turbidity, water temperature, and other water quality parameters. Stream gages have operated over different time ranges, with some gages recording for over 100 years and others for only a few years. These data can be used directly to explore ecosystem service questions on streams where gages are located and can be extrapolated to the contributing upstream watershed by helping to calibrate hydrologic models that serve to assess ecosystem services. The USGS provides spatial delineations of river basins using a hydrologic unit code (HUC), a spatial watershed cataloging system. The smallest resolution provided is a HUC 12, which can range from less than ten to a few hundred square miles (https://water.usgs.gov/GIS/huc.html). USGS is currently developing the National Hydrology Database Plus-High Resolution (NHDPlus HR) that provides highresolution spatial data on streams, lakes, and catchments (https://nhd.usgs.gov/Catchments can be smaller than a mile and aggregated to larger catchments that drain to an outlet point. The data include catchment characteristics, flow direction, and flow volume estimates. Although it provides high-resolution spatial data, the attribute data are static and do not capture the temporal variation in water quantity or quality. The USGS has a more limited groundwater data network that contains information regarding depth to water level and the aquifer each well is screened in or pumped from. The USGS groundwater resources program (http://water.usgs.gov/ogw/gwrp/) has studied and published reports and toolkits to assess the quantity, quality, and recharge rates of several aquifers, as well as their baseflow to streams. Coarse-scale national assessments of water yield and availability exist (e.g., Brown et al. 2016) that may be useful for generalized assessments of larger river basins at coarse temporal scales. However, such analyses lack the spatiotemporal resolution needed for fine-grained analysis across smaller spatial and/or temporal extents. Information on human management of streams is less consistently gathered and available. Most watersheds in the United States have reservoirs that impact the amount and timing of water available. The National Inventory of Dams provides a database of reservoirs, construction years, owners, locations, and storage volumes (http://geo.usace.army.mil/pgis/f?p=397:1:0). However, information regarding how the reservoir is operated, how decisions are made regarding how much water is stored in the reservoir, and how much is released at any given time must be gathered on an individual basis. Finally, water-use data can help quantify demand for and use of water. USGS compiles a water-use report every five years, which aggregates state-level water-use data, describing the quantity of surface and groundwater used by different beneficiary groups (e.g., domestic, agricultural, industrial, electric power generation) at the state and country level (https://water.usgs.gov/watuse/). Additionally, Tidwell et al. (2014) developed a national database of water use and cost for western U.S. HUC-8 watersheds that could provide useful data on the economic value of water resources."}, {"section_title": "Marine and Coastal Systems: Ecological Data and Models", "text": "The potential for the ocean to provide benefits to society depends on what stressors affect marine systems and to what extent that impact can be mitigated. Each service depends on a unique suite of ecological processes, supported by biophysical structure and function. Managing for these services requires, first, an understanding of what controls these ecological processes and how they interact with one another to eventually produce services that society cares about, that is, ecosystem services production functions (Tallis et al. 2008). Only after a sufficient understanding of these processes is acquired can it then be considered how management interventions might positively affect service provision. This may include the analysis of how alternative management actions provide different types and quantities of benefits based on how they affect ecological processes, including those not initially considered significant. The ecosystem services approach provides decision-support information for managers trying to maximize the benefits of their actions given different costs, priorities, constraints, risks, and knowledge gaps. The ocean presents a particularly challenging ecosystem to map the stock and flow of ecosystem services, \"where ecosystem boundaries are fluid, habitats are often poorly spatially defined and knowledge of ecosystem function emphasizes both context dependency and complex scaling from local to global processes\" (Townsend et al. 2014). International, national, regional, state, county, and local authorities share responsibilities that sometimes overlap but always involve linked ecosystem processes that cross jurisdictional boundaries (Crowder et al. 2006;Ekstrom et al. 2009). Therefore, using ecosystem services information to manage the ocean requires not only the right data and models but also having the institutional structures in place to facilitate the application of ecosystem-based management approaches. NOAA collects a wide array of information to support its fisheries management mandates, representing one of the best sources available of marine ecosystem services-relevant data. The agency and its partners collect information on the status of fish populations not only through stock assessment surveys and by analyzing fishermen's catch data but also by collecting a wide range of physical and chemical variables such as water density, sea surface temperature, salinity, nutrients, and oxygen, as well as food habits data by analyzing wildlife stomach contents. NOAA also uses a variety of derived information sources, such as the position of currents and depth of temperature stratification in the water column. All of this information is then incorporated into ecosystem-linked stock assessments, multispecies models, and ecosystem models in order to inform NOAA's fisheries management policies. Filling data gaps (e.g., the contribution of certain marine taxa to food webs are poorly understood) and increasing survey standardization (e.g., nutrients) remain priority needs to gain a more complete picture of marine ecosystem structure and function. In addition to supporting fisheries management, NOAA collects biophysical data for many other mission areas. These include information on marine life to support Endangered Species Act listings, marine mammals protected by the Marine Mammal Protection Act, and other species that are ecologically and/or culturally significant; ecological forecasts to help society predict and prepare for impacts from events such as harmful algal blooms and flooding from storms; the movement and location of marine debris that can harm marine life and end up on beaches; data on ocean bathymetry, currents, and tides to support ships' safe navigation; and monitoring of important ecological areas and resources, including corals and the habitats within National Marine Sanctuaries."}, {"section_title": "Ecosystem Services in Cities and Urban Areas: Data Sources and Predictive Models", "text": "Urbanization and development are important drivers of land use and land cover change (Eigenbrod et al. 2011;, which in turn alter biodiversity and the delivery of urban ecosystem services critical to the health and well-being of over 80% of the U.S. population (U.S. Census Seto et al. 2013;McPhearson et al. 2016). Many ecosystem services such as drinking water, urban heat island mitigation, noise reduction, recreation, and mental and physical health benefits of urban green space can only be locally produced within and around cities (G\u00f3mez-Baggethun et al. 2013). Urban ecosystem services have been most widely assessed for urban street trees and forests (Nowak et al. 2013) through the iTree modeling suite developed by the USDA Forest Service. The iTree economic valuation tool for urban ecosystem services focuses on services associated with urban trees. Recently developed urban ecosystem services assessment and nonmonetary valuation methods enable examination of tradeoffs among multiple urban ecosystem services provided not only by urban forests but also by other types of urban green infrastructure ) and serviceproviding areas (Andersson et al. 2015). Still, monetary valuation models for urban ecosystem services have not been developed explicitly for cities that allow analysis of tradeoffs and/or identify mismatches in supply and demand for multiple urban ecosystem services. Though iTree-based studies rely on field measurements of urban trees, most urban ecosystem services assessment and valuation studies depend primarily on existing land use and land cover data available through various data portals including the NLCD. Urban areas require relatively high-resolution data (30m x 30m or less) for both social and ecological assessment and valuation since urban areas are well known to be extremely heterogeneous with social-ecological change occurring across fine spatial scales. In multiple cities 1-meter-resolution land cover data is becoming increasingly available. The EnviroAtlas Community Component provides information derived from these 1-meter land cover data summarized by census block groups for 16 cities, with 10 others currently in progress and 24 planned additions by 2019 (U.S. EPA 2016a). For example,  use 1-meter-resolution land cover data derived from light detection and ranging (LiDAR) and other data sources as well as land use data to assess storm-water runoff mitigation, urban heat island mitigation (cooling), carbon storage, air pollution removal, and recreation for all urban green infrastructure in New York City. Researchers were then able to examine how different valuation rankings affected the total services produced per unit area. Data at the parcel or lot scales, which is widely available for U.S. cities (Hamstead et al. 2015;McPhearson et al. 2016), can also be useful.  Note: Nonmonetary valuation of five urban ecosystem services, storm water runoff mitigation, urban heat island mitigation (cooling), carbon storage, air pollution removal, and recreation, generated by green infrastructure in New York City."}, {"section_title": "DATA AND MODELS FOR ECOSYSTEM SERVICES THAT REGULATE AND REDUCE RISKS", "text": "The \"ecosystem services\" of natural hazard protection or regulation in general depend on the presence and condition of natural systems such as mangroves or dunes but emphasize the fact that \"the outcome of a natural hazard becomes a natural disaster as the result of the interaction of human or ecosystem vulnerability and the extent and severity of the damage to the human group or ecosystem receiving it\" (Guenni et al. 2005)."}, {"section_title": "Climate Stability through Carbon Storage and Sequestration", "text": "Data: Status and Trends Enhancing climate stability through carbon storage and sequestration and reduced emissions of greenhouse gases are services that ecosystems can provide to people. There are several approaches for estimating vegetation-based carbon storage and sequestration capacities for the United States varying in precision and effort. Data-driven approaches rely on existing data sets that contain field measurements. The associated effort with such data sets frequently restricts their use to landscape-level assessments and can have low resolution (though some are 30-meter resolution). Examples include the Forest Inventory and Analysis (FIA) database of the USFS, soil databases such as the State Soil Geographic (STATSGO) Data Base, or remote sensing-based inventories such as LANDFIRE or the National Biomass and Carbon Dataset for the year 2000. Field measurements over time can be compared, and historic sequestration rates can be computed based on these data sets with implications to current and future developments in storage and sequestration. A subcategory of data set-based approaches relies on the use of estimation equations and lookup tables or default factors that can be applied to a given unique ecological unit (e.g., ecological sections and subsections; USDA 2007) based on typical conditions of the immediate surrounding landscape. Examples include carbon storage estimates for forest ecosystem and related human activities as provided by Smith et al. (2006)."}, {"section_title": "Wildfire Risk Regulation", "text": "The vegetation of North America has been shaped by recurring fires over millions of years. Fire remains the primary natural disturbance influencing the plant and animal communities of most western forests today. The wildfire risk regulation ecosystem service varies with respect to the degree to which each ecosystem is fire adapted. In general, the frequency and mosaic patterns of intensity are shaped by the underlying terrain and climate; however, human influence has long been a factor in this relationship as well. In some forest types, new forest structures and fire regimes, shaped by past management efforts and exacerbated by climate changes, are leading to what many view as uncharacteristically severe wildfires. The consequences of these forest structures and fire regimes are most serious in forest types that were historically characterized by frequent but low-severity fire, many of which are found in low elevations and are often close to human settlements (Noss et al. 2006). Fire-adapted systems require occasional fire to remove dead and desiccant vegetation and debris, along with some live vegetation, maintaining diversity of vegetation composition, age, and size structure. These features of a constantly refreshing landscape allow it to sustain habitat, watershed protection, and other ecosystem services as well as limiting negative air quality. Documents such as the interagency Quadrennial Fire and Fuels Reports (QFFR 2005(QFFR , 2009(QFFR , 2014 and books released in recent years such as Mapping Wildfire Hazards and Risks (Sampson et al. 2000) and The Economics of Forest Disturbances (Holmes et al. 2008) all document substantial progress in understanding and modeling the ecosystem service of wildfire regulation. Under the Millennium Ecosystem Assessment (2005) framework, wildfire risk reduction is considered one of several regulating services that can be managed to provide several constituents of well-being, including security from disasters and access to clean air, while concurrently providing material for shelter as a byproduct of risk reduction treatments. Using this typology, the primary service that the wildland environment provides is some level of protection or resilience from damaging fire events that are regularly ignited by lightning and people (both intentionally and accidentally). These fires (1) affect people in negative ways with primary effects (e.g., burnt structures, forage, timber), secondary effects (e.g., debris flows and flooding in recently burnt areas), and indirect effects (e.g., smoke-induced health problems); (2) affect the supply of many other ecosystem services both positively and negatively (Venn and Calkin 2011); and (3) cost municipal, state, and federal taxpayers money to prevent, extinguish, and rehabilitate. All three of these types of impacts can theoretically be valued, and ideally a national picture based on a schematic (e.g., Kline, 2004, pg. 7) could be developed that adequately addresses the complexity arising from the variable intensities, scales, and frequency of fire through time in U.S. fire regimes, including: \u2022 Benefits: maintenance and resilience of vegetation patterns and associated soil/nutrient/hydrologic flows (intermediate services) that all change through time, affecting a number of final provisioning and regulating services such as timber, forage, and wildlife (e.g., big game) availability, the quantity and quality of water (including flows and floods), scenery, recreation, and carbon sequestration; \u2022 Damages: risk of loss of structures (private and public) and other built capital and cultural/historical sites, as well as risks to human health and safety (in part via impacts to air); and \u2022 Expenditures (management actions): private and public funds spent on (i) prevention/hazard reduction treatments, (ii) suppression, (iii) rehabilitation/reconstruction. Since a devastating series of forest fires swept through Idaho, Montana, and Washington in 1910, five years after the establishment of the Forest Service, the relative influence people have had on fire has grown, as attempts are made to suppress nearly all wildfires. With population growth and habitation in fire-prone areas, unmanaged wildfire causes far more unwanted consequences than desirable effects. Nationally, roughly 97% of all reported ignitions are suppressed as small fires each year, which confounds our ability to describe pure ecosystem resilience to fire. Recognition of how fire's important ecosystem role has diminished led to efforts to increase its function using prescribed burning and, in limited cases, wildfire use under its various monikers. More recently, thinning followed by burning has been proposed as a preparation mechanism to allow naturally ignited fires back onto the landscape under conditions where naturally ignited fire can restore forest health and provide more cost-effective and enduring resilience to damaging events."}, {"section_title": "Fire Modeling Considerations", "text": "Wildfires typically grow from ignitions based on interactions of the wildland fire behavior triangle (National Park Service n.d.), where dynamic weather and fuel conditions interact with topography to determine fire spread and resultant fire effects. In reality, several other social factors influence the fire behavior triangle, directly affecting not only the spatial fuel arrangements' temporal trajectory but also fire impacts through preventative mitigation (constructing homes and fences with flame-resistant materials, installing sprinklers, foaming structures), suppression actions (building fire lines, applying suppressants to fire, conducting burnouts to eliminate potential fuels), and rehabilitation efforts. Estimating the changing ecosystem service values resulting from natural trends, anthropocentric activities designed to reduce wildfire risk, or the combination of the two is best accomplished by estimating incremental avoided costs. Untangling the interaction of factors yielding avoided costs, namely preventative vegetation changes and suppression actions, is very site specific. Even at a small scale it is hard to do systematically as circumstances change as a result of fuel conditions, resource availability, and evolving perceptions of risk informed by near real-time information technology. In reality, maximization, let alone full understanding of the following production function for the subsequent ecosystem service, is nearly impossible: where X is wildland fire potential given dynamic climatic, vegetative, and weather processes; Y is trajectories of mitigating impacts from preventative actions by home owners; Z is trajectories of mitigating impacts from hazardous fuel treatment; Q is wildfire suppression actions; and P is rehabilitation efforts. Although efforts like the Forest Service's Fuel Treatment Effectiveness Monitoring Program evaluate if hazardous fuel treatments affected fire behavior or facilitated suppression efforts, no data collection efforts currently aim to empirically evaluate all factors for a comprehensive analysis of the interacting components. However, given that current wildfire modeling helps demonstrate the logic representing best available science for several components and incorporation of choice modeling of social factors (e.g., Wibbenmeyer et al. 2013) in addition to the current and alternate fuel conditions, one can estimate the value of different levels of wildfire risk management. Despite the complexity of wildfire risk regulation, important subsets of ecosystem services have strong potential for which nationally standardized data, models, and valuation approaches can be developed. Before marginal impacts can be evaluated, a conceptual framework must be accepted that reconciles the mechanisms through which wildfire risk reduction affects expected values in different directions at different times; for a discussion of evolving thought on how to analyze net value change through time see Gebert et al. (2008). Mercer et al.'s (2008) work is one example of an approach to revealing the tradeoffs of fuel management, suppression, and expected damages. Specifically, the common task required in most evaluations is defining baseline wildfire risk trajectories of expected losses and expected benefits. These are best ascertained by using multiple conditional fire intensity probabilities, which can be changed to reduce the vulnerability of homes and property conditions and to transition from net negative to net positive impacts on other ecosystem components. An essential requirement of a useful conceptual model is the ability to handle the temporal aspect of risk reduction associated with various mitigation actions that can alter risk both at different times and for different durations. Incorporating fluctuating insurance coverage and dynamic property valuation into this portrayal of risk must be done carefully yet parsimoniously to realistically assess changes in fire expectations based on modeling."}, {"section_title": "Predictive Models Ecological Fire Modeling vs. Fire Behavior Modeling", "text": "Given that fire as a disturbance interacts with both live and dead vegetation in multiple states of flammability, it can be valuable to include expected patterns of transition due to vegetative succession as well as the influence of insects and disease, windthrow, hurricanes, and other common wildland disturbances that affect fuel loading. The recent decade has demonstrated the magnitude of these interactions and makes modeling fire in the context of other ecological processes appealing. While some models are deterministic in nature in that they project change through time steps in a preprogrammed manner, other ecological process models that employ statistical probabilities of disturbances and are run multiple times to develop ranges of future conditions or probability surfaces of conditions and disturbance levels are more suited for this task. These models are used to gain an understanding of the amount of change expected but are not generally capable of suggesting how any specific part of the modeled area is likely to change. In other words, deterministic models like the Fire and Fuels Extension to the Forest Vegetation Simulator (FFE-FVS; www.fs.fed.us/fmsc/fvs) tend to be better at showing expectations under defined scenarios, and models like FireBGCv2 (USDA 2016a) tend to be better at showing how the composition of a landscape's fuels might change through the future. Fire behavior models are used to determine what type of fire is expected under specified fuel and weather conditions. Most of these models are built on foundational BEHAVE (Andrews 1986) fire behavior modeling logic, with variants used to address multiple management questions. Many U.S. analysts use FARSITE to model how an ignition will likely evolve as a fire from a specified point, given the fuel and weather conditions input to the model (e.g., www.fire.org/downloads/farsite/WebHelp/usersguide/ug1_introduction.htm). FlamMap, a derivative of FARSITE, can be used to model the type of fire that would be expected were an entire area to burn under one or more specified sets of weather conditions (Finney 2006). If there are concerns about the avenues through which fire will likely spread the fastest, the minimum travel time (MTT) component of the Treatment Optimization Model (TOM) software can be used (Finney 2006). When a fire breaks out and managers want to understand the probability of spread in different directions, FSPro is used to compute a probability surface associated with a range of possible weather for a specified duration (http://wfdss.usgs.gov/wfdss_help/WFDSSHelp_FSPro_Ref.html). The Large Fire Simulator (FSim) is useful for estimating annual burn probabilities and conditional fire intensities across an entire landscape (www.firelab.org/project/wildfire-hazard-potential). Although numerous other modeling tools have been developed, those noted above are the most commonly used wildfire behavior modeling tools in the United States, and all rely on the same inputs describing physical and fuels characteristics, with the more complicated questions requiring a move from static weather conditions to a distribution of several weather variables and ignition probabilities. One helpful development is that a coarse scale assessment process called LANDFIRE has mapped topographic and fuel conditions across the entire United States and continues to update them on a regularly scheduled basis. While many analysts choose to modify or substitute for these wall-to-wall layers, there is data available nationally. Given that some fuels information is available everywhere, the next task is to meaningfully carve the nation into modeling units at scales that show the marginal changes in hazards under unmanaged or various potential management scenarios. These should be developed thoughtfully to ensure the areas align with planning jurisdictions and common fire regimes with current Fire Planning Units or something similar."}, {"section_title": "Property Risk Models-From Types of Structures to Area--Wide Assessments", "text": "All of these fire behavior tools help address the hazard but do not completely diagnose risk. Finney (2005) describes fire risk as the combination of fire probabilities and fire effects. In the case of wildfire, the beneficiaries' perspective can be used to bound the assessment of the changes in the expected levels of ecosystem services. Perhaps the most obvious beneficiaries are those whose lives and safety are affected, which is difficult to assess. While most residents and firefighters evacuate from wildfire areas before they are injured or killed, the fuel conditions and fire line intensity do impact how fire is fought. Beyond the risk of life and injury, estimating risk to private property and other ecosystem service values that can be affected by wildfire is another substantial challenge. Jack Cohen's (1995) post-incident investigation work has been key in modeling the expected amount of destruction to property if fire interacts with residential dwellings. His Structure Ignition Assessment Model (SIAM) was built to explore how changes in structural materials (especially the choice of roofing materials) and surrounding vegetation change a structure's vulnerability to fire. Stockmann et al. (2010)  (2) delineating the WUI; (3) estimating and assigning conditional burn probabilities to structures on individual residential properties; (4) simulating vegetative succession for a greenhouse gas emission scenario; (5) estimating the probabilities that pixels in the WUI burn and the conditional probabilities of residential losses for each WUI property given residential parcels burn; and (6) assigning monetary values to residential properties and aesthetic property value losses due to wildfire. The intent is not only to quantify current and future financial risk but also to clarify the degree to which all involved agents (homeowners, developers, municipal zoning authorities, and land/fire management agencies) can modify this risk (Prato et al. 2014). Wildland Fire Decision Support System efforts such as the Rapid Assessment of Values at Risk (RAVAR; Calkin et al. 2011) were attempts to determine the most sensitive human assets to wildfire. RAVAR went beyond residences and commercial structures, commonly found in state revenue department cadastral databases, to other elements of human security and well-being and is designed to enhance both real-time fire management strategy and long-term wildfire risk reduction planning. The good news is that many of the modeling efforts conducted to assess how land and fire management activities might be able to maintain or reduce wildfire risk are designed as GIS processes, where the analyst artificially modifies fuel conditions as a speculative response to hypothetical treatments to detect how much change is possible and the new trajectory of risk following treatments. For example, the ArcFuels (2016) extension in Esri ArcMap software uses a logic process that identifies valuable natural and infrastructure assets and iteratively explores how treatments could modify risk to each asset (also using some assumptions regarding suppression). Thompson et al. (2013) showed how ArcFuels and FSim can provide a before-and-after look at wildfire risk when a community has collectively provided a set of undesirable fire encounters. The USFS is currently combining this approach with the stratified cost index to compare investments in 10-year fuel treatment plans with expected suppression cost savings to analyze financial tradeoffs in the context of the multiple objectives for its landscape-level fuel treatments."}, {"section_title": "Gaps and Challenges", "text": "Financial property loss is not the only wildfire impact to people. Efforts such as STARFire (Manley et al. 2010) are attempts to plan with information regarding the suite of expected impacts, including damage to vulnerable assets and avoided costs, as well as positive impacts to other resources to compute estimated marginal net costs/benefits. A complement or possible alternative to this type of modeling is to ask people to value the suite of ecosystem services associated with wildfire risk reduction using the contingent valuation method. Loomis and Gonzalez-Caban (2008) summarize various studies that have estimated the value to specified populations of residents of reducing wildfire risk by specific amounts in clearly delineated areas. Although the contingent valuation methodology has recognized limitations and is expensive, the potential exists to borrow from representative situations and use the benefit transfer approach to apply generalized dollar values. Even if they are used only as relative values, this approach may help managers who are comfortable using these elicited value estimates in their decisions. Despite significant advances in wildfire modeling and valuation several gaps in our knowledge remain and require attention. The primary challenge is to standardize how the counterfactual representation of wildfire events and their probability is portrayed in the absence of preventative treatments, suppression, and rehabilitation activities. The marginal difference between real outcomes and this alternate portrayal is the basis for evaluating changes in ecosystem conditions and the flow of ecosystem services. The Fire Regime Condition Class (FRCC) is one useful modeling approach that addresses this counterfactual situation, by classifying the degree of departure from expected fire regimes across the United States. Although FRCC is criticized for various reasons, it offers one way to estimate current ecosystem resilience to fire, displays how suppression has changed this resilience across the nation, and highlights the relative benefits of treatments or desirable fires and of returning to more appropriate fire regimes. Another challenge is the changing climate and its influence on fire behavior. Seasoned fire managers describe growth in the upper end of fire behavior observations, and the lack of these conditions in the historic record means there is limited predictive power outside the range of inputs used in forecasting, requiring a move from inference to extrapolation. Like all ecosystem services, fire risk regulation is part of an interconnected web of benefits, and we currently struggle to express those relationships sufficiently to represent tradeoffs that will occur or even what we expect to come from management actions. The troubling inadequacies of legacy dogma and associated analysis systems in recognizing fire's role in maintaining ecosystem balance (which collectively provides myriad related ecosystem services) expands to be even more problematic when we consider that impacts may change from negative to positive or vice versa through time (see Kline 2004 for discussion of dynamic complexities of benefits linked to fuel treatments). In other words, short-term damage often yields long-term hazard reduction or ecosystem service enhancement in the same vicinity. As a terrestrial and aquatic example, fire often eventually leads to increased density of ungulate forage and recruitment of woody debris, as standing trees are converted to fallen logs and transported downslope into creeks, where they increase shade and reduce stream temperatures in fire-adapted ecosystems. While many scientists have addressed the string of temporal reactions in the environment such as these, a gap still exists for how to abstract from local understanding to regional or national understanding of fire's place in the web of services. Moving from appropriate representations of this wildfire risk regulation to useful analyses of benefits will require a great deal of work. Just consider even a limited set of familiar ecosystem services such as timber, forage, or other protected provisioning values. A lack of documented information about specific public and private forest management plans for a baseline makes assessments, which are often done with poor information describing consumer and producer surpluses, extremely speculative. Expanding from this basic analysis to consider all of the confounding interactions of these additional ecosystem service variables seems to make accurate with-or-without cost-benefit analyses prohibitive. Although FIRECLIM, the newest generation of Forest Plan revision in the Sierra Nevada Mountains (Thompson et al. 2016), and other cooperative efforts seem to tackle the complexity of wildfire risk regulation, they require a large team to complete the analysis for even part of one state. While this cutting-edge approach could likely be replicated across the country to estimate a large portion of wildfire risk reduction ecosystem service values, it is likely too onerous for forest planning teams to complete on their own. This gap complicates how this type of learning can be factored into fire and land management planning, prioritizing activities such as harvesting and using prescribed fire or fire suppression strategies. Working together, federal agencies and partners can develop and document the conceptual framework and plans to address key data and modeling gaps associated with the ecosystem service of wildfire risk regulation. Perhaps the best vehicle to solidify and communicate that vision is the next iteration of the QFFR and the upcoming Cohesive Wildfire Management Strategy revision. www.fs.fed.us/rm/wfdss_rav ar Designed to enhance both real--time fire management strategy and long--term wildfire risk reduction planning by going beyond structures to other elements of human well--being Esri ArcMap --ArcFuels www.arcfuels.org Uses a logic process that identifies valuable natural and infrastructure assets and iteratively explores how treatments could modify risk to each asset Flooding Data Sources: Hydrology and Risk to People Two main types of data are needed to evaluate the flood risk management benefits of ecosystems: (1) hydraulic data-maximum depth, arrival time, and duration across a range of flows for each structure location or damageable element in the study area-and (2) damageable elements data-value and depth damage relationships for every damageable structure or element within the study area, either individually represented with stage-damage relationships or aggregated into a single stage-damage relationship. A comprehensive hydraulic current conditions (without-project) data set for the entire United States does not exist. However, numerous hydraulic studies have been done on a local and even regional scale, but they would have to be gathered from a patchwork of sources: reclamation districts, local flood control agencies, cities, counties, state water resource agencies, Federal Emergency Management Agency (FEMA), USACE, and others. One of the best sources of data may be the Corps Water Management System (CWMS) National Deployment; this data set is limited to watersheds with existing corps projects. The National Structure Inventory describes a screening-level structure inventory for the entire United States (https://data.femadata.com/FIMA/NSI_2010). This inventory contains adequate information on structures to derive damage functions, values, and populations."}, {"section_title": "Predictive Modeling", "text": "To account for flood risk reduction, it is necessary to have with-and without-project conditions. Comparison of these two project conditions allows calculation of benefits generated by the project. The with-project condition should reflect a change in the hydraulic or structure data. This requires some sort of hydraulic modeling that can account for changes to the floodplain caused by the project (levees, channel improvements, reservoirs, etc.). The damageable elements within the floodplain may also change as a result of the alternatives being analyzed (e.g., relocations and raising structures for nonstructural measures or buyouts to make room for the levee structure). With-project hydraulic data must be generated for individual projects, with the analysis tailored specifically to each project. When assessing the hydrological and ecological impacts of a change in management, it is necessary to analyze incremental changes in ecosystems and those functions resulting from the management change, any of which can magnify or impede structural and nonstructural changes throughout the floodplain. To do this, the with-project hydraulic model must be capable of evaluating changes in vegetation, sediment loading, flow retention, and other geospatial and hydrological features as well as ecological habitat. It is necessary to be able to evaluate the impacts that structural changes have on the survivability of ecological habitats over time. This requires the ability to incorporate a feedback loop between ecological and hydrologic models over multiple years because the changes in the ecology of an area may affect flood mitigation in a particular area downstream or upstream and may even interact directly with the structural measures' ability to provide continued flood mitigation. For example, the addition of a wetland may attenuate flood hydrographs, which in turn reduces scour, erosion, and sedimentation. This ecosystem feature may provide increasing benefits across time. Finally, to adequately evaluate the life cycle of a project alternative in a systems context, a comprehensive modeling framework is required. One option is to research the application of the Hydrologic Engineering Center Watershed Analysis Tool (HEC-WAT) with the flood risk analysis compute option, using Hydrological Modeling System (HEC-HMS), Reservoir System Simulation (HEC-ResSim), River Analysis System (HEC-RAS), Ecosystem Functions Model (HEC-EFM or EFM-Sim), and Flood Impact Analysis (HEC-FIA). Everything from the biophysical makeup of the system (habitat) to hydrodynamics and socioeconomic conditions must be considered to effectively measure storm protection services. As a starting point, an assessment of the hydrodynamics of the system of interest is necessary. There are a number of models, such as those cited above; the Sea, Lake, and Overland Surges from Hurricanes model (www.nhc.noaa.gov/surge/slosh.php); and the ADvanced CIRCulation (ADCIRC) model (www.adcirc.org). As an example, ADCIRC can be used to generate storm surge scenarios that can then lead to an estimation of the impact on society. ADCIRC is a physics-based hydrodynamic model that uses a computational mesh to solve shallow water equations for a number of applications, including coastal storm surge and flooding. Users are able to simulate storm event surges for a defined region. Some have found value in combining with ADCIRC the Simulating Waves Nearshore wave modeling software (http://swanmodel.sourceforge.net), which computes random short-crested, wind-generated waves in coastal regions and inland waters (Dietrich et al. 2011). Storm surge grids generated by ADCIRC can then be modified to inundation grids, which measure impact on coastal communities. To assess the physical and economic impact of coastal flooding, FEMA developed Hazus-MH (hereafter Hazus), a geographic information system (GIS)-based modeling tool that estimates physical, economic, and social impacts of natural disasters such as floods, earthquakes, and hurricanes (www.fema.gov/hazus). Hazus uses internal databases concerning hazards, buildings, facilities, transportation systems, vehicles, lifeline utilities, hazardous materials, and agricultural products (FEMA 2013). The effect of flooding events, for example, is then measured in dollar losses of buildings, monetary losses of vehicles, and displacement of households. It is also important to consider changes in the landscape over time. Human impacts in the form of coastal development and physical changes to the natural environment as a result of sea level rise require additional computational steps to effectively account for storm surge impacts. The USGS has recently released a report that catalogs the relevant tools to model and visualize sea level rise impacts on coastal environments (Doyle et al. 2015). "}, {"section_title": "SOCIAL AND ECONOMIC DATA AND MODELS FOR ECOSYSTEM SERVICES", "text": ""}, {"section_title": "Sociocultural Context", "text": "The flow of ecosystem service benefits is always mediated by social systems. Every human use of nature has a sociocultural context: relatively enduring relationships and understandings among individuals and groups that shape both the ends and means of actions affecting ecosystems. This context can determine the nature of the ecosystem benefits received, their value, who shares these benefits, and who does not. Humans do not experience their environment as an external and objective reality. Rather, \"nature is seen by humans through a screen of beliefs, knowledge, and purposes, and it is in terms of their images of nature, rather than of the actual structure of nature, that they act\" (Rappaport 1979, 97). Such \"images of nature\" are not universal but to a great extent vary from society to society. While for many societies pigs are a valuable source of meat, for Islam and Judaism the pig is considered to be an unclean animal, not to be eaten (Douglas 1966). Given this cultural premise, for these religious communities, pigs provide no provisioning service. The use of wood for heating and cooking might seem a simple example of a provisioning service, needing little in the way of sociocultural context to be understood, but this is not the case. In an analysis of fuel wood use in the Peruvian Andes, Keely Maxwell uses anthropological and ecological methods to describe the Andean fuelscape or energy landscape. \"Fuelscapes are shaped by ecological characteristics, historic settlement patterns and property rights, gendered and intergenerational divisions in household labor, and state conservation policies\" (Maxwell 2011, 465). Rights to fuel wood are determined by multiple factors. For fuel from planted trees, these include \"community residency, house and field ownership, and the degree of human labor in tree planting and harvest-a complex mix of ownership and usufruct rights.\" Trees in the uncultivated monte are a common pool resource, with rights to fuel conveyed by membership in a nearby community (Maxwell 2011, 472). Different situations require greater or lesser attention to the sociocultural context of ecosystem services provision and value. The analytic skills involved-understanding how social systems mediate the human experience of the environment and the consequences of environmental change-are basic to several disciplines, including environmental anthropology, environmental sociology, and human geography."}, {"section_title": "Sociodemographic Data", "text": "Ecosystem services, like other market services, are used and appreciated by different population sectors in varying rates. A prime example of this is outdoor recreation. Survey data and economic modeling efforts consistently show differential participation rates for outdoor recreation across a host of demographic variables including sex, age, race, ethnicity, income, and population density (Bockstael et al. 1987;Bowker and Leeworthy 1998;Bowker et al. 2006;FHWAR 2006FHWAR , 2011. Modeling and mapping the impacts of management decisions (and actions) on ecosystem services requires an understanding of the spatially explicit supply and demand of these services. Sociodemographic factors that vary spatially provide insight into the demand side of this equation. Demand for use services can be modeled using per capita rates of use or participation and multiplying by population present in a given spatial unit (pixel, county, watershed, etc.). While many different sociodemographic factors may influence these rates, only those sociodemographic factors that display geographic variability are relevant for spatial representation of demand. Many demographic variables such as age and sex may not vary substantially at the spatial scale of analysis, in which case average participation rates (e.g., across all ages and sexes) will serve to represent demand spatially. However, when sociodemographic factors are both determinants of participation or use levels and vary spatially, it is important to use them in assessing spatial demand. The U.S. Census (2010) provides the most accurate demographic data available for the United States. These data are aggregated into census block spatial units to protect the privacy of census respondents. Spatial mapping of ecosystem service demand frequently requires finer-scale demographic information. The U.S. EPA developed a dasymetric population map of the continental United States for EnviroAtlas. This map combines the U.S. Census blocks with landcover data (NLCD 2011) using a simple model to allocate the summarized census block populations down to 30m x 30m gridded raster cells. The dasymetric population data can also be reaggregated into any spatial unit, a method that sometimes has a distinct advantage over using the census blocks, which vary greatly in size depending on population density. The dasymetric population map is publicly available through the EnviroAtlas website (www.epa.gov/enviroatlas). The EnviroAtlas dasymetric population map can be combined with other types of demographic data from the U.S. Census (2010). Current work explores the application of census block-level demographic proportions to the dasymetric map to segment the market for the purpose of estimating spatially explicit demand for outdoor recreation services (Mazzotta et al. 2014). Fine-scale mapping of demographic variables in this manner can never provide 100% accuracy because it is impossible to accurately spatially allocate those demographic variables within a census unit. These methods merely provide approximated geographic representations of predictor variables on which economic models may be built. The final products derived from these methods must be maps of ecosystem service demand aggregated to a summary unit (i.e., county) where spatial errors are smoothly distributed. "}, {"section_title": "Use and Benefit Transfer Data and Models", "text": "Ecosystem services assessments require information on how many people use, appreciate, or are affected by a change in service provision. Various resources that collect some of this data are described below."}, {"section_title": "Wildlife Resource Valuation", "text": "Various types of economic value are derived from wildlife resources, including use values for wildlifebased recreation activities, as well as passive use values held for the preservation of wildlife species and their habitats. The first practical application of the contingent valuation method was implemented by Davis (1963) to monetize the value of big game hunting in Maine, and since then there have been dozens of studies valuing wildlife-based recreation activities. Many of these studies quantify per-person peractivity day values; for instance, 659 such value estimates for hunting and 324 for wildlife viewing are reported in a database of recreation use values developed at Oregon State University, which has compiled studies conducted in the United States and Canada from 1958 to 2006 (see http://recvaluation.forestry.oregonstate.edu). The Benefit Transfer Toolkit being developed by USGS includes updated databases for hunting and wildlife viewing, compiling data from new or previously overlooked valuation studies conducted in the United States through 2014 (see https://my.usgs.gov/benefit-transfer). Many of the value estimates included in these databases are based on The National Survey of Fishing, Hunting, and Wildlife-Associated Recreation conducted by the U.S. FWS and U.S. Census Bureau, which often includes contingent valuation questions to capture net economic values of wildlife-related recreation activities by state (see Hay 1988;Waddington et al. 1994;Boyle, Roach, et al. 1998;Aiken and la Rouche 2003). Continuing to collect these data regularly can help facilitate benefit transfers. Meta-regression models based on this existing literature can often be used for benefit function transfers. For instance,  estimates such a model for recreational hunting values. USGS's Benefit Transfer Toolkit includes an updated version of this hunting model and also includes meta-regression models of per-person per-day values for wildlife viewing and fishing. It is important to note that existing benefit-per-unit estimates need to be tied to an estimate of quantity, such as hunter or viewer days. Thus, at the area of interest for applying benefit transfer values, collecting data on visitor use of public lands is an extremely important service that agencies can provide to help facilitate benefit transfers of wildlifebased recreation values. In addition to the economic value held for wildlife-based recreation activities, many people derive passive-use values, such as existence and bequest values, from the preservation of wildlife species, particularly threatened, endangered, and rare species. Beginning in the 1980s, primary studies quantifying the total economic value held for rare and endangered species were published; Loomis and White (1996) conducted a meta-analysis of such studies. An updated summary and meta-analysis by Richardson and Loomis (2009) summarizes the results of 31 studies that have used stated preference methods to quantify the economic value of approximately 29 fish and wildlife species in the United States. In addition to the differences in the types of species these studies value, they differ in other significant ways. For instance, some studies are based on surveys of visitors at a specific site, while others survey households in a particular city or state, and still others survey households across the entire United States. A metaregression model based on these existing studies is also provided in Richardson and Loomis (2009), who find that variables such as the type of species being valued, the change in the size of the species population being valued, whether a species is a \"charismatic megafauna\" or not, the year the study was conducted, and various methodological attributes of the study significantly influence willingness-to-pay values. The information provided in Richardson and Loomis (2009) can be used for unit value transfers, average value transfers by species type, and function transfers based on the meta-regression model provided. In addition to those studies conducted in the United States, many have valued rare or endangered species in other countries, such as Australia (Wilson and Tisdell 2007;Jakobsson and Dragun 2001), Sweden (Boman and Bostedt 1999;Ericsson et al. 2007), England (White et al. 1997;White et al. 2001), China (Kontoleon and Swanson 2003), Sri Lanka (Bandara and Tisdell 2005), Greece (Langford et al. 2001), and Spain (Ojea and Loureiro 2007). The majority of existing studies quantifying total economic values for wildlife species have focused on valuing often large gains in the population of a species (e.g., a 50% gain) or the avoidance of large losses in populations. More research is needed on valuing smaller changes in populations, as many projects affect only a limited area of habitat. Transferring values or functions from the existing literature typically requires an understanding of how the population of the species being evaluated is expected to change with project impacts or a management action. Often, an agency can model how management actions will result in changes to species' habitats, but it is important to have models, data, or professional judgments that can be used to translate habitat changes into estimates of population changes that can be tied to a measure of economic value. Additionally, existing estimates of economic value are often reported on a per-household basis for a specific geographic extent, making it important to understand the possible extent of the affected market when transferring values (see Loomis 2000 for empirical analysis of this issue). It can be challenging to conduct benefit transfers of passive-use values, and the limited number of studies quantifying economic values for threatened, endangered, and rare species adds to the difficulty of identifying a representative study in the existing literature. While function transfers based on metaregression models can alleviate some of these concerns, there is a considerable need for additional primary studies quantifying the total economic value of wildlife. Endangered species that may be affected by major management actions, such as the Florida panther, as well as unique species that spur controversial resource allocation issues, such as wild horses and burros on BLM and USFS lands, could be targeted for future research. Information on hunting and fishing uses are widely gathered but currently not standardized in ways that would allow them to be used for regional or multistate analysis. Both the BLM and the USFS permit the collection of nontimber products, including mushroom collection, Christmas tree cutting, native plant collecting, and other uses that, if included in their agency databases (e.g., the Natural Resource Information System), could provide data for service-related analysis. Similarly, while watchable wildlife areas have been designated throughout much of the United States, information on the amount and kinds of uses are not standardized or readily available. It also may be possible to analyze eBird observations to spatially attribute recreational bird viewing. The EnviroAtlas identified four types of outdoor recreation with the minimum data sets necessary to construct national maps of demand. These four types of outdoor recreation are big game hunting, freshwater fishing, migratory bird hunting, and bird watching. The base data set required to estimate recreation demand is derived from national survey data, namely the National Survey of Fishing, Hunting, and Wildlife-Associated Recreation (FHWAR). Data from the FHWAR must be aggregated into the sociodemographic groups identified as spatially heterogeneous determinants of recreation participation. We narrowed this list to two variables of interest including rural/urban status and a combination of race and ethnicity. Figure 4-1 shows the variability of participation rates across these variables."}, {"section_title": "Figure 4--1. National outdoor recreation participation rates across four market segments (EnviroAtlas, Mazzotta 2014)", "text": "Participation rates may also vary geographically. For example, hunting participation rates tend to be higher in the northern Midwest than in New England. For this reason, the country is first divided into 10 regions based on climate and agricultural similarities (USDA 1998); the region-specific participation rates are then calculated for each of the four market segments. This gives a total of 40 unique participation rates for each type of outdoor recreation. The EnviroAtlas dasymetric population map can be combined with other types of demographic data from the U.S. Census (2010) to generate maps of the market segments identified above. The four market segment maps are then divided into the 10 regions, and the regional participation rates are applied. This creates a map estimating the number of participants within a market segment. Because participants may choose to recreate in different locations throughout the year, we convert the number of participants to the number of recreational days demanded by multiplying by the weighted mean number of days of annual participation. These maps are then added together to create a surface of recreation demand. An urban example map for the Chicago area is shown in Figure 4-2A. The issue with these maps is that they only represent demand for outdoor recreation in the locations where the participants live. The majority of outdoor recreation occurs away from the home. Much of the economics literature focusing on recreation centers on the development of complex travel distance and site selection models (Parsons, 2013). A much simpler method uses available survey data to approximate participants' willingness to travel for recreational purposes, pulling travel distance data for the four types of recreation from the National Visitor Use and Monitoring Survey (USDA, 2009) database. The data can be separated by urban versus rural status based on prior observations in differing willingness to travel across this variable (Bowker et al. 2006). A gamma probability density function (pdf) is then fit to the urban and rural data and these pdfs used to generate a two-dimensional probability surface approximating an individual's willingness to travel for a given type of recreation. The two-dimensional probability surfaces are then applied to the urban and rural maps of the days demanded. The result is a smoothed surface of recreational demand. This map better represents where recreation would likely occur if environmental conditions are amenable.  A -Big game hunting days demanded in situ, or where hunters live. B -Big game hunting days demanded dispersed across the landscape using the two-dimensional travel distance probability surface. EnviroAtlas is currently working to complete these final maps of recreational demand for big game hunting, bird watching, freshwater fishing, and migratory bird hunting. A more thorough scientific manuscript is currently in progress documenting this method's specifics. The completed maps will be publicly available through the EnviroAtlas website soon (or by request at www.epa.gov/enviroatlas/forms/contact-enviroatlas). Case Study: These methods were used in a recent study to assess the economic impact of mountaintop removal mining on recreational fisheries in West Virginia (Mazzotta et al. 2014). This study modeled the impacts of different mining scenarios on fish populations. Our maps of freshwater fishing demand were overlaid with the modeled fish maps to quantify changes in the supply of recreational fishing. A map of days of recreational fishing demanded can allow changes in fish populations in specific streams to be quantified in terms of the recreational ecosystem service provided. The Mazotta study takes this a step further by applying benefit transfer to monetize the impact of the mining scenario on the recreational fishery."}, {"section_title": "Valuation", "text": "Recreation plays an important role in public land use, and federal agencies have long expressed the need for recreation value estimates to incorporate in planning and project evaluation. Throughout the 1970s and 1980s, the U.S. Water Resources Council and USFS published administratively approved recreation value estimates based on a combination of existing studies, expert judgment, and political screening (Rosenberger and Loomis 2003). Over the following decades, four comprehensive literature reviews of studies valuing recreation were conducted for the USFS by Sorg and Loomis (1984), Walsh et al. (1988), MacNair (1993, and Loomis et al. (1999). This information was then compiled by Rosenberger and Loomis (2001), who summarized the results of 163 recreation valuation studies conducted from 1967 to 1998 in the United States and Canada. These studies comprise 760 value estimates across 21 different recreation activities, varying in geographic scale. For instance, while some focus on recreation activities at specific sites, others value recreation activities at broader geographic scales, such as at the state or national level. The information provided in Rosenberger and Loomis (2001) can be used for various types of benefit transfers, including unit value transfers, transfers of average values across recreation activities and geographic regions, and benefit function transfers based on an estimated meta-regression model. An updated report, released by Loomis (2005), compiles studies and value estimates through the year 2003, resulting in 1,239 value estimates for 30 different outdoor recreation activities on national forests and other public lands. Average per-person per-day values by recreation activity and census region are also provided in Loomis (2005). Not only do these facilitate average value transfers, but they can be used to identify major gaps in the existing literature across recreation activities and regions. For instance, only one existing valuation study was identified for recreation activities such as backpacking and horseback riding. If agencies expressed a need for value estimates for these activities, primary research could be targeted there. A comprehensive online database of recreation use values held for a wide variety of recreation activities has been developed at Oregon State University by Randall Rosenberger (http://recvaluation.forestry.oregonstate.edu). This database provides detailed information about recreation valuation studies conducted in the United States and Canada from 1958 through 2006, resulting in 2,703 per-person per-activity day value estimates. The Benefit Transfer Toolkit being developed by USGS includes updated databases for a subset of these recreation activities, compiling value estimates from new or previously overlooked studies conducted in the United States through 2014 (https://my.usgs.gov/benefit-transfer). The Toolkit also provides average values by region. These databases are easily accessible and provide a convenient source of information for value transfers. Additional sources of data for benefit transfers include databases of value estimates for specific recreation types, such as coastal-based recreation (see www.oceaneconomics.org/nonmarket/valEstim.asp and www.marineecosystemservices.org/explore), and meta-regression models for various types of recreation (for instance, Johnston et al. 2006;Brander et al. 2007;Neher et al. 2013; https://my.usgs.gov/benefit-transfer). Benefit transfers of recreation values require knowledge of changes in recreation use, an estimate of quantity that can be tied to an appropriate measure of economic value. Due to the fact that existing studies frequently report welfare estimates in per-person per-day units, it is often necessary for resource specialists, planners, or managers to be able to estimate this quantity change, based on data or professional judgment. While this presents a challenge for agencies that do not consistently collect visitor use data, especially by recreation activity, these data are a necessary component of incorporating information on recreation values into planning efforts, making it increasingly important for agencies to continue to improve on visitor use data collection efforts. Many federal and state agencies frequently lack the necessary resources to conduct primary valuation studies. Fortunately, recreation on public lands has been studied quite extensively in the nonmarket valuation literature by academic economists. Benefit transfer thus provides a reasonable approach to incorporating recreation use values into planning efforts and decision making. However, considerable gaps in the valuation literature do exist for certain types of recreation, such as activities involving cultural sites and those in certain geographic locations. Databases of existing value estimates will likely continue to be updated and expanded on and can be used to identify gaps in the literature where primary studies can be targeted. In addition, focusing primary research on recreation activities that spur controversial resource tradeoffs, such as off-highway vehicle use, could benefit agencies that need to evaluate competing recreation values to make informed decisions regarding resource allocation and use. It is also important for original valuation studies to report detailed information to facilitate more accurate transfers. Finally, while many agencies lack the resources to conduct primary studies, incorporating valuation questions into regularly administered visitor satisfaction surveys can provide a low-cost approach to obtaining information for use in future transfers, especially if a random sample of visitors is surveyed. Models were estimated using 58 different park unit survey data sets; WTP estimates for these 58 park surveys were used within a meta--regression analysis model to predict average and total WTP for NPS recreational visitation system--wide"}, {"section_title": "Forest--Based Recreation", "text": "Several benefit transfer studies have been conducted to support the USFS's outdoor recreation planning efforts. These studies trace back to 1980 when the USFS began publishing recreation values (per-person per-activity day estimates) under the auspices of the Resources Planning Act (Rosenberger and Loomis 2001;Loomis 2005). Although early estimates of forest-based recreation values were derived from a limited number of empirical studies and relied on substantial expert judgment, more recent benefit transfer studies have used an expanded set of primary studies (based on travel cost, contingent valuation, and choice-based methods) to conduct statistical meta-analyses. Because hundreds of observations are available to estimate these models, they have a much stronger scientific foundation than earlier estimates. Explanatory variables used in meta-analyses of forest-based recreation in the United States include whether or not the primary study was conducted on USFS land (and, if so, the USFS region), the type of recreational site (e.g., forest, lake, river), and the primary recreational activity (e.g., hiking, snowmobiling, big game hunting; Shrestha and Loomis 2003). By including an indicator for studies conducted on USFS land, multiple-use values for various types of outdoor recreation on National Forests have been be obtained. In addition to studies conducted in the United States, meta-analysis has been used to explain travel cost estimates of forest recreation values based on observations gathered from nine European countries (Zanderson and Tol 2009). The authors included several auxiliary variables in the analyses to consider the influence of socioeconomic variables and site-specific characteristics on forest recreation values. Site attributes and measures of national economic and population variables played a significant role in explaining forest recreation values. Meta-analysis has also been used to explain the variation in estimates of forest values based on contingent valuation studies of forest management programs conducted around the globe (Asia, Europe, Latin America, the Middle East, the United States; Barrio and Loureiro 2010). In these studies, management to enhance forest recreation was found to provide a significant contribution to total forest value. Site and national socioeconomic characteristics were also found to be important in explaining willingness to pay for forest management programs.  Shrestha and Loomis 2003 Test of convergent validity of meta--analytic benefit transfer tested using out--of--sample studies A meta--analysis of forest recreation values in Europe Zandersen and Tol 2009 Uses meta--analysis to explain variation in forest recreation values in Europe based on 26 studies in nine countries Meta--Analysis of Contingent Valuation Forest Studies Barrio and Loureiro 2010 Uses meta--analysis to explain the variation in values obtained using the contingent valuation method based on 35 studies conducted across several countries and forest types Water Supply Use Data The USGS collects county-level water use data across the United States every five years by different sectors: municipal, private, industry, mining, electricity, commercial, agriculture, and so on. The water use data report withdrawals (water removed from the system and returned back to the system farther downstream) and consumption (water permanently lost to the system). The USGS provides a lowresolution spatial and temporal snapshot of information, the best available at a national scale (http://water.usgs.gov/watuse). Each state has different requirements regarding when water withdrawals must be reported (e.g., in North Carolina, agricultural users must report withdrawals of more than 1 million gallons per day, while nonagricultural users must report withdrawals exceeding 100,000 gallons per day). North Carolina is one of the few states that has a centralized database of local government-owned water utilities that report their water source and the amount of water withdrawn and discharged on a monthly basis (www.ncwater.org/water_supply_planning/Local_Water_Supply_Plan). Otherwise this data needs to be estimated based on demographic information. The USDA Forest Service's Forests to Faucets project uses GIS to model and map the continental United States land areas most important to surface drinking water and the role forests play in protecting these areas. This project uses the EPA's Safe Drinking Water Information System (SDWIS) to identify locations and number of people served by surface water intakes to develop a drinking water protection index. This index shows which areas have the highest potential to affect water quality through the input of sediments and contaminants from the land, while taking the number of water users into account (Weidner and Todd 2011). While the number of users is incorporated into the water protection index, the type of water use is not differentiated. In the western United States, water allocation laws have created a more extensive system of tracking and allocating water use (see next section on Western Water). Each state or water management district within a state (if a state has one) manages watersheds differently and has different management priorities. Water and demand management practices can be roughly divided between the eastern and western United States. Eastern U.S. management is based on riparianism and the assumption that there will be enough water available to meet all reasonable demands. Western U.S. management is based on the doctrine of prior appropriation and that there is not enough water available, so all water must be allocated among different users. These states have a framework for managing water supply among users. Individual states are responsible for establishing the framework for water demand and management, with wide variation in the degree of regulation (Gerlak 2005). As water shortages have been experienced in the eastern United States, more states are moving toward a form of regulated riparianism where they are starting to require water permits for withdrawals over a certain magnitude (e.g., in North Carolina, as described; MacDonnell 2009; Dellapenna 2002). Most states have different regulations for managing surface water compared to groundwater, and these rules may vary within states depending on endangered species, groundwater overwithdrawal or recharge rates, reservoir operations, and so on. Water utilities are risk averse and track the service population, water use, water supply, peak demand, and other factors to ensure they have enough supply to meet demand (Lemos 2008). This data is often available in utility annual reports, particularly for larger water utilities. Reservoirs are owned by national, state, private, and public entities. Some reservoirs are run-of-the-river and do not have an operational component. Other reservoirs, such as federally owned flood control dams, hydroelectric dams, and water supply dams, have a water-control manual that describes how the reservoir is managed and operated. Operational rules vary between reservoirs, but once known, they can be modeled. Ecological or environmental flows are often defined as the minimum streamflow that can maintain ecological integrity. Ecological flows have been implemented for some reservoirs (minimum release) and by some states. It is an area of current research on the best way to determine the ecological flow of streams (e.g., Richter et al. 1996;Poff et al. 2010) given limited data availability and the difficulty of determining how much the change in flow is due to climate versus human alterations. Where ecoflows are established, they can provide a boundary for assessing availability of water for different services and beneficiaries-separating availability for consumption (irrigation, drinking water, etc.) from water for ecosystem functions (recreation, etc.). Continued research on teasing out how much water supply is changing due to climate versus human impacts and what management practices (land cover type, reservoirs, etc.) are contributing to the greatest shifts in streamflow quantity and timing requires having better data, particularly the temporal resolution, on the human side of the equation (land cover change, withdrawals, discharges). As part of the federal Clean Water Act, the EPA has put in place a permitting system (National Pollutant Discharge Elimination System) that limits the maximum discharge an individual wastewater facility plant can handle on a daily basis. The EPA collects this data, and facilities can be searched through their website (www.epa.gov/enviro). While this data is useful, more accurate models could be developed using the actual discharge (as this likely changes by season). Currently, the only way to get this information is from individual facilities or state governments that collect it. A similar situation exists for withdrawals, for which a plant's maximum capacity can be obtained but not necessarily how much of the plant's capacity is being used on a daily basis. Water utilities plan their water supply around meeting the peak, not average, daily demand. Having a standardized collection method and management of human modification data would enable cumulative impacts to be assessed. NLCD updates every five years or so. Population, climate events, and so on change or occur on a much shorter timescale. We can model and estimate, but there is a mismatch between water supply data that is collected at a specific point (minute to minute, hourly, daily, monthly, etc.) and land cover change (every five years), water use (every five years at the county scale), and population. Regarding the last, there is a census block every 10 years and municipal/county estimates every year (this is also residential, but daily water demand might be different as people travel from suburbs to city center-which could be in a different basin). Our ability to pull apart what is human use and what is climate would be better with better use data. Traditionally, water policy has dealt with issues of quantity and quality separately; however, these should be integrated and addressed together. Plentiful, polluted water, just as scarce, clean water, do not constitute a sufficient water supply to meet demand. Maps land areas most important to surface drinking water, the role forests play in protecting these areas, and the extent to which these forests are threatened by development, insects and disease, and fire Social Preference, Valuation or Benefit Transfer: An Example of Western U.S. Water Efforts to model water use and/or demand in the western United States have been the subject of considerable interest, particularly as population growth and economic development have increasingly strained water supplies in many western regions. Data on water use and demand are a foundational part of these analyses but can be difficult to acquire at the desired spatial and temporal resolution, particularly over long time periods. While individual organizations (e.g., water utilities, irrigation districts) often have records of water use, which could then be translated into demand relationships (with varying levels of difficulty), this data can be difficult to acquire, even in the rare instances that it exists in a convenient form. Long-term and comprehensive national-level data on water use is maintained by the USGS (www.usgs.gov) but is often available only at the state level and at annual intervals. In many cases, state agencies are the most complete and accessible sources of water use data, with California's Department of Water Resources offering perhaps the most well-refined database (www.water.ca.gov/waterdatalibrary). Turning water use data into a demand relationship often requires, at a minimum, additional information on the (marginal) price of water and the price elasticity of demand. Centralized databases with information on water prices are uncommon, but price information can often be gleaned from the websites of water utilities (urban) or irrigation districts (agricultural), although the myriad pricing schemes used (e.g., increasing block rates) can complicate estimates of demand functions. Perhaps the quickest and most straightforward manner of gaining a rough estimate of a demand function is via the \"point expansion\" approach that has been used by many and described clearly by Griffin (2006). A considerable body of literature has been developed for estimating water demands in various sectors, including agricultural (Howitt et al. 2012;Young and Loomis 2014), urban (Howe and Linaweaver 1967;Nieswiadomy 1992;Whittington et al. 1990;Young and Loomis 2014), hydropower (Young and Loomis 2014), flood control (White 1964;Young and Loomis 2014), recreation (Freeman 2003), and ecosystem services (Freeman 2003;Young and Loomis 2014). And, while each situation has its idiosyncrasies, a general sense of demand behavior in each of these sectors can be gleaned from these research efforts. There is also a long history of combining data on water use and models to develop strategies for managing water, with most of these focusing on water quantity (Harou et al. 2009), as opposed to water quality. One of the most advanced is the CALVIN model (https://watershed.ucdavis.edu/shed/lund/CALVIN) developed by researchers at the University of California, Davis, as a means of examining California-wide water resource management strategies (Jenkins et al. 2004). There is also a broad range of regional/watershed models that have been developed for investigating improved water management throughout the western United States; however, in most cases these models were developed for a specific application and, consequently, are often designed solely for the researcher who developed it. As a result, these models are often poorly documented and maintained, an issue that the water resource systems modeling community needs to address. Water Quality: Economic Benefits of Water Quality Changes There is an extensive literature devoted to the estimation of economic benefits of water quality change, and methods for estimating these values are well developed (Young and Loomis 2014;see Freeman et al. 2014 for a methodological summary of economic valuation methods in general). These values are often (though not always) expressed in terms of individuals' or groups' willingness to pay (WTP) for specified changes in water quality within particular areas. 2 Although methods for valuing the benefits of water quality improvements are well developed, and the literature now includes hundreds (if not thousands) of studies addressing values of water for different beneficiary groups, it is not straightforward to develop widely applicable and transferable estimates of water quality value. Water quality benefits often vary considerably across sites, even for similar or identical chemical changes. Among the primary reasons are the many ways that water quality improvements benefit different groups of users and nonusers and heterogeneity in both beneficiaries and values over different areas. Water quality has multiple characteristics that pose challenges for WTP estimation (Griffiths et al. 2012;Griffiths and Wheeler 2005). Water quality can vary spatially and temporally, for example, headwater versus downstream. There are also many interrelated ways that water can change (e.g., pollutant concentrations, dissolved oxygen, pH, temperature, clarity, color), each with potentially distinct implications for use and nonuse benefits realized by different groups (Bergstrom et al. 2001;Van Houtven et al. 2014;Young and Loomis 2014). Moreover, water quality benefits are often realized through direct and indirect effects on other ecosystem services valued by different user/nonuser beneficiaries (Blamey et al. 2002;Boyd and Krupnick 2013;Boyd et al. 2016;Johnston and Russell 2011). Water quality changes provide different benefits (in terms of both type and quantity) for many different beneficiary groups, including but not limited to agricultural users (Ward and Michelsen 2002), nearby homeowners (Leggett and Bockstael 2000;Poor et al. 2007), the general public, including users and nonusers (Johnston et al. 2005;Johnston et al. 2003;Johnston et al. 2015;Van Houtven et al. 2007), recreational users (Bockstael et al. 1989;Lipton 2004;Lipton and Hicks 1999;Peters et al. 1995), and others. Hence, the estimation of water quality benefits requires one to first specify the causal chain through which specific types of water quality changes benefit or harm specific beneficiary groups. These causal chains (or conceptual means-ends diagrams) specify whose benefits are being considered (i.e., the beneficiary group) and the channels through which benefits are realized. Valuation methods (and benefit transfers) must similarly adapt to these differences. Different valuation methods are required to measure different types of ecosystem service values related to water quality improvements; no single valuation method can measure all possible values (Holland et al. 2010;Johnston et al. 2002). Stated preference methods provide the only means to measure total use and nonuse WTP for water quality change, although revealed preference methods may be capable of measuring total values of certain beneficiary groups when values are linked solely to observable uses (Freeman et al. 2014). 3 In general, the results of stated and revealed preference methods are not directly comparable, as these approaches measure different components of total value (Johnston et al. 2002). An additional challenge in comparing water quality values estimated by different stated and revealed preference studies is that different metrics may be used to quantify water quality change within different contexts. Moreover, different types of water quality measures are applicable to different types of valuation applications (Boyd et al. 2016). A common simplification in stated preference analysis is to convey policy effects using a single water quality index (WQI) that combines information on multiple physical and chemical water quality parameters (Abbasi 2012; Carson and Mitchell 1993;Vaughan 1986;Van Houtven et al. 2014). An additional simplification used along with (or instead of) WQIs is the characterization of water quality using use criteria such as swimmable or boatable (Smith et al. 1986;Viscusi et al. 2008). However, many other measures of water quality are possible (e.g., clarity, specific quality parameters such as dissolved oxygen, temperature, probability of adverse events such as harmful algal blooms), and these are not always comparable across studies. Moreover, as noted, the most relevant measures of water quality often differ across beneficiary groups (Boyd et al. 2016). These complications aside, there have been a number of recent efforts to generalize the insights provided by the water quality valuation literature and to generate reduced form functions that could be used to predict certain types of water quality benefits (often total WTP including both use and nonuse components) across unstudied sites. For example, meta-analysis has been used to evaluate systematic influences of study, economic, resource, and population attributes on measures of nonmarket willingness to pay (WTP) for environmental quality improvements (including water quality change), and to generate parameterized functions for use in benefit transfer (Bergstrom and Taylor 2006;Boyle et al. 2013;Johnston and Rosenberger 2010;Johnston et al. 2015;Nelson and Kennedy 2009). Within metaregression models used for such purposes, the dependent variable is most often a comparable mean or median welfare measure (e.g., WTP) drawn from existing primary valuation studies. Independent moderator variables represent observable factors hypothesized to explain variation in this welfare measure across observations. Meta-regression models have been used to estimate benefit functions for changes in both the quantity and quality of many different types of nonmarket goods, including changes in water quality (Johnston et al. 2003(Johnston et al. , 2005(Johnston et al. , 2016Bergstrom et al. 2001;Van Houtven et al. 2007). Benefit transfers from these functions-typically predicting mean per household WTP-have been used to support multiple benefit cost analyses of environmental regulations affecting U.S. water quality (e.g., U.S. EPA 2010U.S. EPA , 2012U.S. EPA , 2013U.S. EPA , 2015. In principle, such approaches are well suited for large-scale applications, as they provide a means to tailor value forecasts to specific conditions. Despite the potential use of meta-analysis to support benefit transfers in this area, applications also face empirical and theoretical challenges, involving such issues as selection biases in the published literature (Rosenberger and Johnston 2009), difficulties reconciling and combining the information provided by prior studies Bergstrom and Taylor 2006;Johnston and Moeltner 2014), and econometric modeling (Nelson and Kennedy 2009). Moreover, any benefit transfer-including those applying meta-analysis-involves generalization errors not present when using primary studies for valuation (Rosenberger and Stanley 2006). Hence, the development of broadly applicable meta-analytic value functions for water quality (or using other means such as structural benefit transfer;  is not a trivial undertaking. Simpler forms of benefit transfer for water quality benefits, such as single-site benefit function transfer, are only suitable when study sites (where the primary study was conducted) and policy sites (where the value is needed) are similar across all relevant dimensions (Johnston and Rosenberger 2010;Johnston et al. 2015). Discussions of the advantages and disadvantages of different types of benefit transfers are provided by Johnston et al. (2015). In practical terms, the capacity exists to conduct meta-analytic and other types of benefit function transfers for some types of water quality improvements in water bodies and watersheds nationwide. The best-developed capacity is for transfers of total WTP (including use and nonuse values) for water quality improvements quantified using a standard WQI. Similarly robust transfers can be conducted for use thresholds that can be linked to a WQI (e.g., the value of obtaining swimmable water). While these methods are relatively well developed, transfers of this type are only suitable in cases where approximate values are required. Rosenberger (2015) finds that benefit function transfers (over all types of resources) generate errors that average 65%, with a median of 35%. Where more precise values are warranted, primary studies are required (Allen and Loomis 2008). Other types of values, such as amenity values of water quality or clarity captured by hedonic property value models, are likely to be more context specific and difficult to transfer with accuracy. There are also fewer directly comparable studies of such values in the literature that can be used to support benefit transfers or meta-analysis. As a result, researchers have not yet developed robust meta-analyses or other benefit functions enabling these values to be forecast for different sites. Similar limitations apply to recreational benefits such as the value of clean water for different types of recreation-although the number of studies in this area could in principle be used to support development of robust meta-analyses. In general, the capacity for benefit transfers is more defensible and robust for cases in which benefits can be directly linked to standardized scales that are commonly used across the valuation literature, such as WQIs or water quality ladders, or uses that can be linked to these scales. As values become more idiosyncratic across sites or are linked to less commonly used measures of water quality, benefit transfer becomes less defensible."}, {"section_title": "Example of Economic Valuation Data and Models for Freshwater Recreation", "text": "The economic valuation of water quality for freshwater recreation can use several different methods. Cost-based approaches are often used to value avoided cost of removing sediment or nutrients from waterways, as in the case of water treatment costs for nutrient removal or reservoir dredging costs. These approaches can be valid and useful if they represent a realistic, least-cost estimate for water-quality improvement, though they lack a connection to economic welfare theory (i.e., they do not measure producer and/or consumer surplus), and are used to estimate changes in the value of water quality more generally rather than the explicit value of freshwater recreation. Contingent valuation, travel cost, and related approaches have frequently been used to estimate both current recreational values and potential future values under scenarios for water-quality improvement or decline (e.g., Breece 2006, Johnston and. Because of the time and expense associated with conducting new primary studies, value-transfer approaches may also be useful for valuing water quality for freshwater recreation as an ecosystem service, as long as best practices for value transfer are carefully followed. Numerous attributes could theoretically influence economic values for recreation, though not all of these are likely to be statistically significant. Accounting for these attributes in valuation or value transfer approaches is important. These attributes include the type of recreational activity (e.g., fishing, boating, swimming), attributes related to ecosystem service supply (e.g., type of water body, land ownership-i.e., Forest Service, NPS, USACE), and attributes related to recreation demand (e.g., per capita income, congestion, substitute sites; Rosenberger and Loomis (2001), http://recvaluation.forestry.oregonstate.edu). Existing value transfer tools (e.g., http://dare.agsci.colostate.edu/outreach/tools;  and databases (http://recvaluation.forestry.oregonstate.edu, https://my.usgs.gov/benefit-transfer/) may be particularly helpful for this purpose."}, {"section_title": "Coastal and Marine Services Use Data", "text": "The most comprehensive survey of recreational use of our coastal and marine resources is the National Survey of Fishing, Hunting, and Wildlife-Associated Recreation, which is produced by the U.S. FWS and the U.S. Census Bureau. The geographic coverage (every state; marine and terrestrial) and time series (every five years since 1991) provides consistent measurements of use and impact. However, applying it to regions smaller than the state level can be challenging. Additionally NOAA publishes recreational catch statistics through the Marine Recreational Information Program. Valuation Armed with only biophysical data, managers may know enough about the societal context in which they are working to conduct an ecosystem services assessment without socioeconomic values and to improve management outcomes. Alternatively, depending on the drivers, managers may primarily care about the biophysical outcome (e.g., amount of hectares restored or protected) and not necessarily the benefits humans derive from it (recreational, aesthetic, existence, etc.). Explicitly accounting for how human wellbeing is influenced by changes in environmental conditions helps avoid assumptions, unintended consequences, and missed opportunities to discover optimal solutions. There are several contexts within which researchers derive marine ecosystem service values, producing different information depending on the intended use. Because NOAA, as well as regional and state fisheries management organizations, are mandated to collect market data, the value of commercial fisheries is the most readily available marine ecosystem services information. Before passing new fisheries regulations, for instance, NOAA analyzes how the changes may alter the benefits fishers receive from a given day at sea. Most marine ecosystem services values, however, are derived from passive use (e.g., existence and aesthetics), which requires the use of nonmarket valuation techniques. Unlike with commercial fisheries, there is no market that can be analyzed to derive valuation information from these services. Other economic information associated with services is collected-e.g., the economic impact of National Marine Sanctuaries-but these may only be used as proxies for the value that society derives from healthy marine ecosystems. Over the past two decades, NOAA has supported several dozen nonmarket valuation studies (many of which are included in an inventory of studies described here), including many through its Sea Grant College program. A majority of these studies derive values associated with either beach recreation or recreational fisheries, as both of these activities are enjoyed by millions of people annually. Other services valued include scuba diving, the continued existence of endangered species, flood protection, and water quality. There are several approaches to capturing the value of ecosystem services using nonmarket methods (U.S. EPA 2009;NRC 2004NRC , 2012. Besides directly valuing services (e.g., the amount people are willing to pay to scuba dive in a particular location-see Parsons and Thur 2008), some valuations focus on a particular area (e.g., a state park-see Wallmo and Edwards's 2007 Technical Memorandum, which conducts a valuation on Marine Protected Areas) so the services being valued are implied in the value of the area rather than explicitly considered. Others derive values for services based on people's preferences for the outcome of how different alternative management actions affect a resource (e.g., how wide a beach should be constructed through nourishment-see Pendleton et al. 2012). Another approach is to analyze the loss of value when a resource or service is negatively affected (e.g., through the degradation of habitat or natural resources-see Petrolia and Kim 2011). Benefit transfer approaches are also used to derive marine ecosystem services values. Such approaches are used when an original nonmarket valuation study is not justified given the manager's informational needs and there exists a value or values from other studies that can be applied to a separate but relatively similar context. At NOAA, these approaches are most commonly used to assess damages to recreation and other ecosystem services from oil spills and other toxic discharges. In general, benefit transfer approaches are more commonly used when the primary focus is on assessing the biophysical changes driven by an environmental impact or a management action and is seen as an expeditious way of incorporating socioeconomic information. Most of NOAA's ecosystem services work, however, has focused on the socioeconomic part of the equation, so primary studies are justified. There is certainly potential to use benefit transfer in broader ocean and coastal management contexts, particularly where there are strong drivers to quickly and cost-effectively calculate valuation information. In these cases, it is nonetheless critical that best practices for using benefit transfer approaches are used (described elsewhere). Besides those studies that explicitly support mandates-including fisheries market values, damage assessments from oil spills, and cost-benefit analyses to support National Environmental Policy Act analyses-there are two main drivers for social scientists to conduct or apply ecosystem service valuations in the marine and terrestrial environment. The first driver is to compel decision makers and the public of the importance of conservation, environmental regulations, the support of recreational activities, and so on. Rarely do these studies link to biophysical production functions because they have a communication focus and do not require such rigorous ecological data. The second driver is to provide decision-support information by, for example, evaluating how different regulations affect the value of recreational fishing. In neither of these contexts are biophysical and socioeconomic information consistently linked to each other within a holistic analysis. Part of the reason is that many ecosystem services, particularly recreational ones, can be enhanced without changing ecological processes (e.g., more mooring buoys are provided for fishing boats). In other cases, valuations are not linked to biophysical production-functions simply because the research questions being asked by social scientists seemingly do not require this information. When social science surveys pose hypothetical alternative restoration actions, for instance, they may not be concerned with the efficacy of the restoration method. Instead, the assumption is that a certain level of restoration is achieved, and the focus is on how it affects societal outcomes. The reverse holds true for biophysical scientists who fail to draw strong linkages with human well-being. The ecological processes they are analyzing are done through the lens of assessing the change in ecological outcome. The strength of the ecosystem services approach laid out in this working paper is that biophysical and socioeconomic information are explicitly linked, providing a more complete, robust picture of the management context that includes the ultimate societal outcomes of alternative management actions. Urban Social Preference and Value Data Most cities have much of the required data to perform ecosystem services evaluations, especially as highresolution land cover data become more widely available (e.g., U.S. National Agriculture Imaging Program (NAIP) data, though raw data will still need to be converted to land cover). Urban land cover and land use data make assessment and valuation of urban services possible, especially for provisioning and regulation services. For cultural services, however, social use and preference data is much less available. Cultural ecosystem services have the potential to contribute some of the highest values in urban ecosystem valuation studies, especially when physical and mental health benefits of urban green space are included. Studies of urban systems within the field of urban ecology (Grimm et al. 2000;Pickett et al. 2011) highlight the importance of human activity, values, perceptions, and norms and how they interact with ecological processes to affect ecosystem structure, functioning, and services (e.g., Andersson et al. 2007;Grove et al. 2006). Since human decisions and preferences strongly shape urban space, preferences are not necessarily primarily decided by knowledge (McNie 2007). People bring various material, moral, spiritual, aesthetic, and other values to bear on the urban environment, and their values can affect their attitudes and actions toward ecosystems and the services they provide (Ernston 2013; G\u00f3mez-Baggethun and Barton 2013), which makes valuation challenging in urban areas without substantial social use and preference data. Still, social-demographic indicators derived from U.S. Census data and local land use data have been used to understand social need for urban ecosystem services (McPhearson, Auch, et al. 2013;McPhearson, Kremer, et al. 2013), and social networking data from Twitter, Flickr, Foursquare, and others is increasingly used to examine social preferences for green areas and services (Bertrand et al. 2013;Wood et al. 2013). Research to develop robust decision support tools for examining tradeoffs and synergies among multiple services produced in urban and periurban areas is ongoing. However, new tool development is in process with the expectation that in the very near term modeling suites that build on but go beyond iTree will soon be available. For example, an Urban InVEST model is currently in development through a partnership with the Natural Capital Project, the New School, and Stockholm Resilience Center with prototypes for multiple services being tested in Minneapolis and New York City. Additionally, the ARIES modeling tool in development could provide similar capability for urban areas . The main barriers to scientifically robust metrics for monetary valuation of urban ecosystem services include both social and ecological data availability, especially at the high spatial resolution needed to advance planning and management in urban contexts. Increasing the scientific rigor of existing and newly developed models will be important, especially to take into account the built and technical infrastructure in cities. For example, reliable calculations for air pollution removal by urban green infrastructure depends on wind speed, building height, amount of vehicle traffic, and road width, all of which need to be incorporated in modeling efforts. Still, urban ecosystem services assessment and valuation is moving forward quickly (G\u00f3mez-Baggethun and Barton 2013; Larondelle and Haase 2013;Haase et al. 2012Haase et al. , 2014 especially for understanding how urban ecosystems contribute to urban heat island reduction, noise mitigation, recreation, stormwater absorption, and carbon storage and sequestration. Remaining challenges and areas for future research include gathering social preference data both from social media and through traditional social science methods. Additional research is especially needed to understand the social inequality in access to urban green spaces driven by mismatches between the spatial distribution of the supply of and the demand for ecosystem services, especially in underserved areas of the city (Haase et al. 2014;Kremer, Hamstead, Haase, et al. 2016). For example, a recent effort to map the social need for ecosystem services around vacant lots in NYC found that low-income, highpopulation-density areas of the city also tend to have decreased access to green space where many ecosystem services are produced (Kremer et al. 2013;McPhearson, Kremer, et al. 2013). Finally, ecosystem protection in cities will rely on increasing efforts by park and natural area managers to focus on management outcomes that seek to maximize ecosystem functioning for services, which could be an abrupt shift from existing or past management goals (Schewenius et al. 2014). Federal mechanisms regulate and influence how cities manage some of their most important ecosystem services, including water supply and stormwater quality, among others (McPhearson et al. 2014), which demonstrates a unique opportunity for federal-level urban planning, management, and design incentives to increase socially just production of urban ecosystem services critical for the health and well-being of urban residents. "}, {"section_title": "Climate Stability", "text": "The economic valuation of climate-stabilizing (e.g., sequestration of carbon) or -destabilizing actions (greenhouse gas emissions) is determined by the severity of future climate change and its associated impacts. A large research effort has gone into establishing the causal links between atmospheric CO 2 concentrations and climate change. Through the investigations discussed previously, links can then be established between changes in the climate and the potential future damages (from sea level rise, changes in precipitation patterns, and so on) associated with a lack of climate stability. Economic models then take these damages, or the benefits associated with avoiding them, and monetize them to attempt to assign an overall economic value to the ecosystem services being affected by climate change. A broad summary measure of this type is the social cost of carbon, or SC-CO 2 (Interagency Working Group on Social Cost of Carbon 2015). The SC-CO 2 measure developed by the Interagency Working Group (IAWG) is intended to be a comprehensive estimate covering all damages associated with climate change, although as noted in the IPCC Fifth Assessment Report (IPCC 2014), the models used to estimate the economic consequences of emissions do not include all physical, ecological, and economic impacts associated with climate change. However, the models used by the IAWG to estimate monetized damages from an incremental increase in emissions do include a range of impacts such as net changes in agricultural productivity, human health, property damages, and the value of ecosystem services (where possible). Typically, information from the ecological data and models discussed in the foregoing are expressed as \"damage functions\" that can be incorporated in economic models, which overlay these ecological inputs with assumptions about human economic behavior. Several types of economic models are used to assess policy or programmatic scenarios that affect emissions and climate stabilization: sector-specific models that focus on a narrow slice of the economy, broader macroeconomic models that can cover all interactions among businesses and households within a region or globally but do not explicitly model ecosystem services and atmospheric chemistry, and integrated assessment models that combine modeling of economic behavior and its associated emissions with information on the interactions among emissions, climate change, and the physical world. Sector-specific economic models are helpful in providing detailed estimates of potential costs of climate change within one or more sectors of the economy. For example, the Forestry and Agricultural Sector Optimization Model with Greenhouse Gases (FASOM-GHG) can estimate how changes in temperature, precipitation, and land use may interact with agricultural markets and domestic or global policies to affect U.S. food production and trade, along with the emissions associated with agricultural production (Adams et al. 2005). Similarly, the Global Timber Model (Sohngen et al. 2001) is a dynamic model of ecological change and economic change that can capture the impact of climate change on world timber markets. Unlike detailed sector-specific models that can express relatively precise relationships between climate and economic outcomes, broader macroeconomic models express relationships among climate stability, ecosystem services, and the economy through more general damage functions derived from the results of ecological models. The models then attempt to quantify changes in the economy for a specific climate change scenario or mitigation policy. For instance, the Intertemporal General Equilibrium Model (IGEM) of the U.S. economy was used to estimate climate change impacts on agriculture, forestry, energy demand, water supplies, coastal protection, and the labor supply through changes in air quality and health (Jorgenson et al. 2004). Other work has modeled the economic effects of individual impacts of climate stabilization on ecosystem services (see, for example, Bosello et al. 2006, who use the GTAP-E model to look at human health, and Hinkel et al. 2013 on coastal flood damage and adaptation costs associated with sea-level rise). To develop the broadest measures of the monetized impacts of climate change, such as the SC-CO 2 , integrated assessment models (IAM) are typically employed. Because of their scope, they are less reliant on prespecified damage functions than the narrower macroeconomic models and can estimate some types of emissions damages directly. The Global Change Assessment Model (GCAM), developed at the Joint Global Change Research Institute and used by the U.S. EPA, among others, has representations of the economy, energy sectors, land use, and water that are linked to a climate model. The IAWG that developed the SC-CO 2 measures used by U.S. federal government agencies relied on three IAMs: DICE (Nordhaus and Boyer, 2000), PAGE (Hope, 2006), and FUND (Tol 2002a(Tol , 2002b. Similar to GCAM, these three models translate emissions into changes in atmospheric greenhouse concentrations, the atmospheric concentrations into changes in temperature, and finally the changes in temperature into economic damages. This type of structure allows the IAMs to explore climate change, mitigation policies, and interactions among the physical and economic components of the model. www.fund--model.org IAM used to perform cost--benefit analyses of emissions reduction policies through linking simple models of the economy, population, sea levels, and other impacts Policy Analysis of the Greenhouse Effect (PAGE) http://climatecolab.o rg/wiki/--/wiki/page/PAGE IAM that projects future increases in temperature, economic costs of damages caused by climate change, costs of mitigation policies, and potential costs of adaptation measures"}, {"section_title": "DATA AND MODELING INFRASTRUCTURE", "text": "Given the historic memo  released by the Executive Offices of the President in October of 2015 and the resulting momentum within the largest resource management agencies in the United States (USDA, Department of the Interior, NOAA, USACE), there is tremendous opportunity to advance the use of ecosystem services in federal decision making. In the next two to five years it will be critical to put the data and modeling foundations in place so ecosystem services information can be put into practice. Implementing, operationalizing, and institutionalizing ecosystem services will require efforts to address remaining challenges including those around data and modeling. These include (1) missing data and models (ecological and economic), (2) uncertainty about what data and models are acceptable (good enough), (3) uncertain precision of results, and (4) the time required to assess ecosystem services. Building a robust and sustainable data and modeling infrastructure could help address all of these challenges. Further, the rapid growth of terrestrial sensor networks, drone-based mapping and monitoring, satellite remote sensing, and crowdsourced data increasingly open the door to data mining, machine learning, and other inductive \"big data\" modeling approaches that have thus far seen relatively limited application in the field of ecosystem services (Hey et al. 2009. These methods, which use algorithms to identify patterns and relationships from data, differ from deductive ecological production function approaches but may work well in cases where data from traditional field experiments are sparse but sensor-based data are abundant or where ecological production function relationships are unknown or perform poorly. These techniques require further work on semantics and the use of data services (ideally Open Geospatial Consortium, OGC) that are seeing increasing use in environmental modeling (Peckham et al. 2013. They are also receiving attention from federal agencies such as USGS (www2.usgs.gov/cdi/participate.html) and the Interagency Steering Committee on Multimedia Environmental Modeling (ISCMEM, www.nrc.gov/docs/ML1328/ML13281A407.pdf). Combined with cloud-based modeling, these approaches hold promise to greatly advance the integration of data and models in service of faster, better, cheaper ecosystem service modeling in service of decision making."}, {"section_title": "Current Federal Efforts", "text": "A number of efforts are under way to develop pieces of a data and modeling infrastructure. \u2022 EcoINFORMA: This data portal is part of data.gov. It is aimed at expanding the availability and interoperability of federal and nonfederal biodiversity, ecosystems, and ecosystem services information by collecting, organizing, and serving existing data. It currently includes three resource hubs: BISON, EnviroAtlas, and Multi-Resolution Land Characteristics Consortium (MRLC), which serves data from the NLCD. www.data.gov/ecosystems/ecoinforma \u2022 BISON: This database and mapping interface focuses on species occurrence data collected from numerous research institutions including museums, journals, botanical gardens, herbariums, federal agencies, universities, and many others. http://bison.usgs.ornl.gov/#home \u2022 EnviroAtlas: The Atlas is a geospatial mapping tool with national data (including only the continental United States at present). It currently generates maps at a HUC-12 scale for the national data but includes some high-resolution data for a growing number of cities. While the EPA has put forth a heroic effort in pulling this resource together it has a few limitations. First, at this time the national data is at a resolution too coarse for many services. Second, it only provides partial information for some services. And third, it will need a long-term home and funding as the EPA Office of Research and Development (ORD) operates by developing research and tools but is not set up to fund and manage them long term. www.epa.gov/enviroatlas \u2022 Ecological Production Function Library: This nascent effort to design a well-organized and searchable database of ecological production function models has identified a real need. This initial effort needs to be shared with other federal agencies and users to get feedback on how to align it with data and to make it credible and functional for users, so that its use will be supported by experts. A coordinated effort with capacity from multiple agencies will be needed to populate the library with a wide range of existing models that agencies, universities, and other researcher organizations have developed. Like other products by the EPA's ORD, it will need a long-term home and funding. https://cfpub.epa.gov/si/si_public_record_report.cfm?dirEntryId=241148 \u2022 Benefit Transfer Toolkit: A benefit transfer toolkit was developed for fish, wildlife, wetlands, and open space . This version of the toolkit (available at http://dare.agsci.colostate.edu/outreach/tools) can be credibly applied by knowledgable economists and continues to be used for benefit transfers. Discussion about continuing to update and expand this type of tool led USGS to develop a new web-based version (https://my.usgs.gov/benefit-transfer). This version of the toolkit includes updated value estimates and new meta-regression models and will ultimately include additional ecosystem services and mapping features. In addition, two other initiatives are being developed within the USGS: an Environmental Capital Dashboard (www.fort.usgs.gov/science-tasks/111148), which is collecting and developing pilot studies, and a National Capital Accounting program (http://powellcenter.usgs.gov/viewproject/57741607e4b07657d1a9910c), which will collate national data to assess status and trends over time. Although these are a good start, they lack strong approaches for gathering new economic and social data and are not sustainably resourced or well coordinated given the nature of federal funding and programs. Thus it is necessary to ramp up efforts to address remaining challenges in building and maintaining national data and modeling infrastructure and assuring the data can accurately inform social and economic outcomes. Challenges A number of important issues will need to be addressed in building a robust national data and modeling infrastructure. Ecological Data and Models Building, collecting, and maintaining the broad category of ecological models and the data that are required to allow them to operate for ecosystem services assessment provide significant challenges related to the variable spatial and temporal scale of information needed to inform decisions (Schimel et al. 1997). Most existing monitoring systems and national inventories are established to address national-scale questions and therefore are set up to provide information to feed national models and analyses (e.g., whether in the United States forests are stable or lands producing timber are increasing or decreasing; Oswalt et al. 2012). As a result, the information generated may be too coarse to be useful to apply to many of the subregional plans (regional highway plans, national forest plans, BLM district plans, watershed plans), which actually influence funding allocation for infrastructure, restoration, mitigation, or conservation, while most of the detailed monitoring, mapping, and data collection for on-the-ground projects are too detailed and expensive to practically develop at the scale of these plans. Similar scale issues exist for much of the aquatic and hydrologic data in the country. Other problems relate to the use of ecological data that can only approximate the types of services being analyzed in the models. Land cover is often used as the only available proxy for myriad services that it can only approximate . Available methods allow for the development of spatial data attributes that might better inform the indicators that can feed economic or social models. An example is the use of imputed plot data for forests (Ohmann and Gregory 2002), which can provide information on forest structure and composition, rather than just informing whether some type of forest is present; this data is much more likely to be relevant to models of ecosystem service outputs. Wetlands, streams, estuaries, grasslands, and shrub-steppe ecosystems all have similar disconnects between what is measured and the services the ecosystems provide. The final data-related challenge relates to the difficulty in keeping appropriate data up to date, to reflect current services at the time of the analysis. Data is usually collected at different times in different locations and aggregations, such as national wetlands assessments and land cover maps that get updated every five years and take a year or two more before they are publicly available. The 2011 National Land Cover Data (NLCD) was released in 2015 and will be used until the 2016 update is available, possibly in 2019 or 2020. NLCD is working to analyze change (Jin et al. 2013). Creating data that can be continuously updated and tied to ongoing inventories of water, vegetation, and species is a reachable goal and is critical to measuring ecosystem service outputs and change over time. There are a number of ways the agencies can move forward to improve data and modeling. They can focus efforts on key data sets that underlie assessment of many services in the United States. For example, the hydrological base information (the National Hydrography Database, NHD) needs to be high resolution (Hi-RES) all over the country and needs to convey common attributes so that models of water output, availability, flow patterns, and aquatic habitat can be developed across watersheds throughout the United States. At this time there is no national support for creating even data across the country because work is done and supported on a state-by-state basis. Similarly, soils and surficial geology are data layers that could significantly improve model outputs from ecosystems to services. Developing these data layers across the country on even a moderate (1:100,000) scale would be valuable for modeling many services. The Soil Survey Geographic Database (SSURGO 1:24,000) mapping was to be completed for the conterminous United States 20 years ago. While agricultural areas continue to be updated, forested areas are incomplete, particularly in western states, in spite of the role of forest soils in erosion and soil formation (SSURGO 2015). In addition, agencies are the primary source of research and research funding focused on resource management, which generates the data for ecological production function models that underlie ecosystem services assessments. These data, when collected from studies that range in geographic, spatial, and temporal scale, are the basis for meta-analyses and the generation of generalized functions and models that can be more widely used. Agencies can request or require that critical data from the individual studies they conduct or support be made available, setting reporting requirements and metrics. They can ask for data to be provided to a repository or made available in a standard electronic format. Such steps are necessary as individual studies often do not report or even collect all the data that would be useful for a meta-analysis."}, {"section_title": "Economic Data and Models", "text": "Currently the federal government's efforts to capture \"traditional\" socioeconomic data and information is significant. Examples of these are the Census (www.census.gov) and additional products such as the American Community Survey (www.census.gov/programs-surveys/acs/), American Housing Survey (www.census.gov/programs-surveys/ahs.html), and Economic Census (www.census.gov/econ/census). Price indices (www.bls.gov/ppi) and labor numbers produced by the Bureau of Labor Statistics (www.bls.gov) provide an essential foundation in the production of values for ecosystem services and, in particular, when employing a robust benefit transfer approach such as functional transfer. However, there still exist significant gaps in \"nontraditional\" socioeconomic data that can enhance the development and uptake of benefit transfer models. By design, primary valuation studies are required input for benefit transfer models. These studies can be significantly more expensive and take longer than transfer valuations (Wilson and Hoehn 2006), and so there is a desire to default to benefit transfer. There exists a significant problem, especially in the coastal and marine environments, of a lack of primary valuation studies of acceptable rigor that can be used in a transfer analysis in any meaningful way, especially for policy application. With increased demand for ecosystem services valuation work to be done, how do we service that need with limited resources? In order to meet the growing demand and support the appropriate use of benefit transfer models there is a need to build an intellectual infrastructure that would do the following: Support primary valuation studies that can be used in benefit transfer analysis: There is a need to grow the number of studies (n), especially for underrepresented services (e.g., water quality, aesthetics) and habitats (e.g., seagrass, prairie pothole) in a manner that is useful in benefit transfer. Loomis and Rosenberger (2006) provide general criteria necessary for valid benefit transfer but, more importantly, discuss how the design and reporting out of primary studies can increase their usefulness, including: \u2022 Policy-relevant study designs (e.g., commodity, welfare measure, and market area comparability); \u2022 Full and consistent reporting (e.g., what was valued, market area, welfare measures); \u2022 Information repositories. These important suggestions, as well as others, could be institutionalized within agency studies and as requirements for grantees and contractors conducting primary valuation studies. Primary valuation methods like contingent valuation, a stated preference approach, requires public surveys. Given federal rules, public surveys done by the agencies or with public funding require Office of Management and Budget (OMB) approval, which can at times be difficult and time-consuming to obtain (OMB 2006a(OMB , 2006b. When this occurs, primary valuation studies are not the tool of choice, pushing agencies to use benefit transfer methods when data may be poor and/or only available for a limited number of benefits. The OMB, which depends heavily on cost-benefit analyses when making decisions, currently has some concern with the use of stated-preference-type surveys, as do some federal agencies. Such surveys have been done poorly at times and can be difficult to do well but in many cases are the only option for assessing nonuse values. Concerns over stated preference have further hampered the use of such primary valuation methods for federal studies."}, {"section_title": "Development and deployment of benefit transfer tools and best practices:", "text": "As demand for ecosystem services valuation increases in federal agency operations, benefit transfer analysis will be called on to fill some of this need. Given the issues identified above, along with a shortage of benefit transfer practitioners, an effort to develop robust benefit transfer tools that are transparent is warranted. A multiagency effort in this area could leverage expertise and resources within the federal family and develop buy-in early on. Additionally, the coordinated effort among the agencies would help begin to meet goals of the Office for Management and Budget and Council on Environmental Quality with regard to ecosystem services integration."}, {"section_title": "Data and Model Infrastructure", "text": "The list of questions and challenges to be addressed is long. While there are some initial conversations and efforts under way, the level of effort and resources committed to building and sustaining the necessary data and model infrastructure will likely need to be much greater. Here is a list of questions that need to be addressed. \u2022 Is there a minimum set of data and models sufficient to support most applications (sufficiently credible)? \u2022 National versus state/local databases? Will it be in multiple places for redundancy? How can it be made both accessible and secure? How can federal agencies address barriers created by internet security? \u2022 How will data and models be made available? User queries via web services? Will disaggregated data be made available? If so, how can security and privacy be insured? Can the example of the U.S. Research Data Centers that manage the use of disaggregated U.S. Census data be used? \u2022 Where will data and models be stored? \u2022 How will data and models be curated? Who will curate the resource? \u2022 How will data and models be quality assured? How will data and models be updated over time? How will different data sets be aligned (e.g., semantic modeling)? Will other efforts be needed to build consistency in reporting and data and model structure? \u2022 Are there mechanisms that would allow the government to have sustained funding and sufficient expertise and capacity for this? Would it make sense to do this as a public-private partnership? Are there other data models that could be used as examples (e.g., MRLC consortium that supports the NLCD data products)? \u2022 How will these activities be managed and funded over time? \u2022 Do the data and models need to be freely available or can they be fee-for-service?"}]