[{"section_title": "", "text": "aging and predicting adverse outcomes when compared to the traditional use of specific molecular biomarkers. Application of pattern recognition and machine learning as a tool for analyzing medical images may provide much needed insight into tissue changes occurring with aging, and further, connect these changes with their metabolic and functional consequences. Changes in body composition, both in the relative quantities of different tissue and their cellular and matrix content, occur with aging in all living organisms. Humans undergo an overall decline in lean body mass, mostly represented by muscle, and an increase in fat mass that occurs even in individuals who maintain the same weight over long time periods. In addition to global, quantitative changes, there are also qualitative changes that affect the characteristics and regional distribution of fat and muscle. For example, aging men show fat accumulates preferentially within and around the abdomen rather than in the subcutaneous tissue of the limbs and chest. CT and MRI images collected in large epidemiological studies have described tissue-specific changes in density and texture that may be correlated with adverse physiological changes and predict disease outcomes (1,2). Based on these studies, researchers have suggested that measures of body composition should be included in any attempt to characterize phenotypic aging (1,2). A problem with this approach found in CT and MRI images characterizing body composition is the large variability in overall fat content and its regional distribution between individuals. Indeed, no previous studies have used body images to identify characteristics from multiple tissues that in aggregate correlate with chronological age, nor has this approach been validated in independent samples or in subsamples randomly selected from the original study population. Several previous studies used CT and MRI to find agerelated differences in brain (3), bone (4), kidney (5) and fat distribution in skeletal muscle (6). All these studies were able to find statistically significant differences in morphology correlated with age, but they involved relatively a small number of participants, and used manual steps or semimanual classification in the analysis pipeline. Thus, until now it remained unclear whether information from body images alone can be used to detect changes in body composition and discern phenotypic age in a fully objective and automated way. We present an automated analysis framework for abdominal CT scans that uses machine learning to eliminate potential bias from manual image processing steps, uses a much larger data set of over 1200 images, and achieves higher age discrimination accuracy than previous studies. Abdominal CT scans are especially well suited for examining changes in adipose tissue. The characteristic low radiodensity of adipose tissue allows for its easy isolation from other tissues, making it possible to directly compare age-related changes in fat distribution and texture to those in other tissues in the abdomen. Supervised learning is ideal for comparing groups of images with substantial individual differences and a large variety of possible changes between groups (7). We used supervised learning to train classifiers to distinguish between abdominal CT scans of subjects grouped by age, and used classification accuracy as a surrogate measure of the aging signal in abdominal tissues. We compared several different classification techniques used separately and in an ensemble classifier to ensure that our results are independent of the analysis technique used. We focused our study on age-related changes occurring later in life, thus our \"Younger\" cohort was 50-70 y.o., and our \"Older\" cohort was 80-99 y.o, with male and female participants being considered separately. We demonstrated that aging signal could be detected in unmodified scans and that this could be substantially improved with contrast enhancement. We explored differential aging by quantifying the contribution of aging signal from three constituent tissue groups: Adipose Tissue (AT), soft tissues (ST) and bones. We found that AT had the greatest age-related change of the three tissues in both males and females, followed by ST and bones. We also found that males had consistently greater age related change than females in all three abdominal tissues."}, {"section_title": "Materials and Methods", "text": "Our institutional review board approved this retrospective study and waived the requirement for informed consent."}, {"section_title": "Study population", "text": "CT scans were from participants in the Baltimore Longitudinal Study of Aging (BLSA) ranging from 30 to 99 years old. Fig. 1 shows the age distribution for male and female participants. Of the 1092 participants with CT scans (544 males and 548 females), we assigned participants into two groups based on their age at the time of exam: \"Younger\", age 50-70; and \"Older\", age 80-99 (see Table I). We did not further refine or sub-select the BLSA population other than by age, so the demographics inherent in the BLSA (race, income, genetic diversity, BMI, etc.) are reflected in our sub-population. Each of the participants had scans from 1 to 6 visits, such that the total number of scans was 1967."}, {"section_title": "From raw scans to Hounsfield units", "text": "CT images were collected with a Siemens Somatom Sensation 10 CT scanner. The scans were performed with a 500 \u00d7 500 mm field of view, 512 \u00d7 512 image matrix, and 10-mm slice thickness. Pixel planes used for processing were single-slice CT scans acquired at the L4-L5 vertebrae on the lumbar column. A standard calibration procedure using phantoms in the scanner's bed was performed, so that intensity of the reconstructed pixels was based on the Hounsfield scale. We used shifted Hounsfield units (SHU) where a range in pixel values from 1 to 2000 corresponds to a range of -1000 to 1000 HU."}, {"section_title": "Automated processing", "text": "The data processing was based on conventional pattern recognition as previously described (8). Two basic stages of data flow were image pre-processing and feature computation followed by cross-validation experiments (see Results) using three statistical classifiers (next section). Image preprocessing (see in Fig. 2) had a biomedical rationale and consisted of several steps: trunk masking (to remove background), rigid-body registration, tissue masking and contrast enhancement. We masked the trunk area by setting a global threshold below the lowest tissue value, choosing the largest connected component (the trunk) and discarding smaller components (including the scanner bed, phantoms, etc.: Fig. 2, panels 1-2, (9)). We implemented a simplified rigid-body registration procedure that includes translation and rotation ( Fig. 2, panels 2-3). First, cropping the subject's trunk as above, resulted in the translation transform. The rotational alignment was largely provided by the physical alignment to the scanner's bed, requiring no more than two degrees of additional rotation correction. Due to the relatively small correction required, we used one based on the secondorder moments of the binary mask of the trunk (10). Thus, the angle correction was calculated using the binary mask, and then it was applied to the original scan. Tissue masking was used to define sub-regions of the trunk corresponding to specific tissues. The range of pixel values comprising the mask was defined as a segment in the Hounsfield scale. We used contrast-limited adaptive histogram equalization (CLAHE, (11)) for intensity enhancement. In this approach, the raw scan pixel plane is first split into several tiles (we used 16 tiles), local histogram equalization takes place for each tile, and then interpolation is used at tile boundaries. Importantly, the CLAHE enhancement was performed separately on the whole image, independently of tissue masking (Fig. 2, panels 4-6). We applied the tissue mask to the enhanced scan to select the target tissue. Additionally, the pixels outside the mask were set to the average pixel value of the whole trunk area (Fig. 4B). We used the general image features we previously described (8,12,13) to provide a large set of numerical image descriptors for each image. The feature library consists of twelve different algorithms, including features based on histograms from polynomial coefficients (Chebyshev and Chebyshev-Fourier types), coefficients of Zernike polynomials, features derived from Radon transforms, Gabor filters, multi-scale histograms, textures (Tamura and Haralick), edge statistics, and object statistics based on the direct and inverted Otsu threshold. As described before, these image features were also extracted from transforms of the original image, consisting of the fast Fourier transform, Chebyshev transform, and wavelet transform (symlets5, level-1 details), as well as two compound transforms: Fourier of Chebyshev and Fourier of wavelet. The CHARM descriptors have been a dependable tool for quantitative analysis of diverse biological and biomedical applications (8,12,13). The multipurpose nature of the CHARM features allows to avoid biasing the classifier with any pre-conceived notions of the biology responsible for the observed changes. This also allows asking open-ended questions and design assays without a-priori knowledge of underlying mechanism or biology, which is of primary utility when the biology is not well understood."}, {"section_title": "Statistical classifiers", "text": "We employed three statistical classifiers, WND5 (7, 8, 12, 13) (referred to subsequently as WND) and two support vector machine (SVM) classifiers (14)(15)(16). When categorizing a given test sample, WND goes over the training data class-by-class and selects the class where the average similarity between all of its training samples and the test sample is largest. In WND, similarity is defined as the inverse-exponential distance in weighted feature space, with the exponent set to 5. Fisher scores were used as weights for the feature space dimensions as before. We have used WND for a variety of pattern recognition applications (8,12,13,17) and we use it here due to its consistent performance. Compared to other classifiers, WND operates in a comparatively high-dimensional space, and it was set to use the top 600 Fisher-weighted features for this study. SVM converts data into an artificial high-dimensional space and constructs support vectors to build a decision boundary, which is a unique hyperplane maximizing the margin of separation between different classes. The SVM algorithm is based on Cover's theorem stating that data cast in a high-dimensional space non-linearly are more likely to be linearly separable than in the original lower-dimensional space. The design implements very efficient use of this high-dimensional space: during training/testing only pair-wise dot products are used in contrast to explicit use of large vectors in computations. As a specific implementation of the SVM algorithm in our experiments, we used libSVM (14) with the RBF kernel. To be computationally efficient, SVM requires a greater reduction in the dimensionality of the original feature space compared to WND. We used two techniques, both based on the concept of mutual information. The minimal-redundancy maximal relevance (mRMR) (15) algorithm forces inter-class features to be maximally distant (e.g. minimally redundant) while maximizing their relevance to the targets. The conditional mutual information minimization (CMIM, (16)) method operates on similar principles, favoring individually informative and pair-wise weakly dependent features. We set both algorithms to pick the best 30 features from the training sets for use in SVM classifiers."}, {"section_title": "Classifier evaluation", "text": "Classifiers were evaluated using non-exhaustive two-fold cross-validation with 100 randomized splits into training and testing sets. For cross-validation purposes, the presence of multiple scans per participant required that scans from one participant are not used for both training and testing sets. In each split, we randomly selected participants for training and then selected one of their visits at random for the training samples. This resulted in a very close number of training samples for both genders: 420 (e.g. 210 per-class) samples for male participants and 396 (198 per-class) samples for female participants in each randomized split. The remaining scans were then used to test the resulting classifier. Classifier performance is reported as the overall classification accuracy (CA), which is the fraction of all samples that were called correctly. To avoid overfitting, we used the recursive feature addition, where the features were pre-ranked as described in the previous section. Cross-validation strategy precluded from selection bias. Additionally, we reported per-class accuracies allowing for supplemental analysis of classification errors. We tested three classification schemes consisting of two classifiers and three feature selection methods (Fisher/WND, mRMR/SVM, and CMIM/SVM). We also defined an ensemble classifier based on the majority vote of the three for each test sample."}, {"section_title": "Results", "text": ""}, {"section_title": "Aging signal in raw scans and signal enhancement", "text": "Raw scans of whole abdominal areas (labeled Torso) were analyzed first (See Table II). Preprocessing was limited to cropping the raw scans to exclude the area outside of the abdomen. Classification of this raw data resulted in an ensemble CA of 0.688 for male subjects and 0.635 for female subjects. Next, we performed image normalization and enhancement (CLAHE pre-processing; see Materials and Methods). We observed that CLAHE enhancement (See Fig. 3) resulted in a significant classification improvement compared to the raw scans, even without rotation correction (not shown). After applying rotation correction, classification improved further but to a much lesser extent than the improvement from contrast enhancement. The CLAHEenhanced, rotationally corrected images of the whole torso resulted in an ensemble CA of 0.759 for males and 0.718 for females (Table II)."}, {"section_title": "Where is the aging signal?", "text": "The Hounsfield scale can be broadly split up into ranges of radiodensity corresponding to bones (1100 -2000 in shifted Hounsfield units, SHU), adipose tissues (ATs, 850 to 950 SHU), and soft tissues (STs, 1030 to 1060 SHU) (See Figure 4). Bones have a broad range of radiodensities and hence take up a large proportion of the upper range of the Hounsfield scale. Adipose tissues occupy a much smaller portion of the lower range of the Hounsfield scale, while soft-tissues, despite having the largest variety of tissue types, capture a relatively narrow range in the middle of this scale (18). In order to mask these three types of tissue using Hounsfield ranges, we divided the cumulative histogram of Hounsfield units into quartiles, and merged the middle two quartiles to define the three types of tissue (see Fig. 4, panel A). The resulting boundaries (in SHU) were 720-938 for the first segment, 939-1070 for the second segment, and all values above 1071 for the last segment. The three segments largely corresponded to ATs, STs, and Bone tissue ranges. We compared discrimination between the two age cohorts in all three tissue segments (Bones, STs, ATs) and in the whole torso (labeled Torso), using three different classifiers and an ensemble classifier based on the three classifier votes. The results are shown in Table  III, where each cell contains two sub-compartments: overall classification accuracy (CA) in the upper sub-cell and per-class CAs in the lower sub-cell for the Younger and Older classes respectively. The ensemble classifier always reported either the highest overall CA, or was within 0.5% of the highest CA (See Table III). This classifier also had closer and more consistent agreement between the per-class accuracies for Younger and Older subjects. The CAs reported by each of the four classifiers for the different tissues were much more consistent between classifiers than they were between tissues, indicating that different tissues change with age to different extents, and that this is independent of the classification technique used. Thus, the CAs are an indication of the non-uniform aging signal present in different tissues. In males, the highest aging signal was observed for ATs (0.785, see Table III and Fig. 5), while in females, Torso (0.718) was higher than ATs (0.707). In both males and females, the lowest aging signal was observed in Bones (0.647 and 0.644, respectively). Males had higher aging signals than females in every tissue, with the largest gender difference in ATs (0.078 or 10%) and lowest for Bones (0.003 or 0.5%)."}, {"section_title": "Discussion", "text": "As indicated in the introduction, the difficulty with characterizing phenotypic aging through direct body composition is in large variability of data within the same age cohort. Large within-class variability requires adequate sampling to capture data variance. In the crossvalidation experiments, we trained classifiers on about 400 unique participant-scans to capture the variance and to avoid overfitting to phenotype. The aging signal in the raw abdominal scans was 0.688 for males and 0.635 for females, which is relatively low compared to a noise level of 0.5. We speculated that the signal strength in raw scans was somewhat compromised by decreased efficiency of feature algorithms on low-contrast images (Fig. 3, columns 1,2). As expected, contrast enhancement resulted in an increased classification signal of 0.759 for males and 0.718 for females. There are several sources of noise in the scan data: variations in subject size, z-section of subjects, and other distortions that are impossible to normalize for. Additionally, only the chronological age of the subjects is known, while it is the unknown physiological age of the subject that affects the observations. In this context, an accuracy of 0.759 should be considered relatively high, and is higher than the age discrimination values reported in previous imaging studies."}, {"section_title": "Adipose tissue: highest aging signal", "text": "Out of the three constituent tissue types (ATs, STs, and Bones) considered, adipose tissue had the largest aging signal in both genders (see Table III and Fig. 5), which is consistent with AT as an aging biomarker. From a pattern recognition perspective this is surprising since AT has a narrow dynamic range as well as (at least by visual inspection) limited variation in texture. This is in contrast to bones, which have the largest dynamic range of the three tissues and a much larger variation in texture, but have little detectable aging signal in either gender. The accuracies we observed are thus reversed from what one may expect from very basic assumptions. We speculate that the reason for the high aging signal observed in AT may be the ageassociated transition of AT from subcutaneous to visceral fat, and probably a change in density and texture that occurs in the visceral fat with aging (19)(20)(21)(22)(23). Additionally, the two genders showed substantially different classification accuracies for AT (0.785 in males vs. 0.707 in females), a difference of almost 10%. We speculate that this is due to the difference in the distribution of AT in males vs. females (24). In males, AT typically accumulates in the abdominal area, and abdominal scans are well suited to capture the transition from subcutaneous to visceral fat. In contrast, females have multiple depositions of AT and a more complicated process of fat redistribution during aging that is not necessarily optimally represented in abdominal scans. Thus, the redistribution of AT between subcutaneous and visceral fat may explain the high aging signal in this tissue, while the specific concentration of fat in the abdomen of males vs. a more dispersed distribution in females may explain why the aging signal is substantially higher in males than in females."}, {"section_title": "Soft tissue", "text": "Soft tissue is composed of a variety of tissues largely characterized by their water content (neither bone nor fat). Soft tissue occupies a relatively large percentage of the torso (\u223c40%), has (by manual observation) a variety of textures and shapes, but also has the narrowest radiodensity range of the three tissues. The observed aging signal (per Table III) was relatively high at 0.700 in males and 0.678 in females. It is possible that muscle is a significant contributor to this aging signal, as myosteatosis is a known marker of aging as well as age-related insulin resistance and hyperinsulinemia (25,26). However, muscle is not the only component of soft tissue, and is not the main tissue with this range of radiodensities within the abdomen. To our knowledge, ST has not been previously described as an aging marker, and our results indicate that these tissues warrant further study."}, {"section_title": "Bones: smallest aging signal", "text": "As noted above, age discrimination for Bones was the lowest out of the four data sets considered in both genders: 0.647 (males) and 0.644 (females), while the gender difference between the two was in the third digit of their values. Bone tissue is a well-known age marker, and bone loss is a hallmark of the aging process. Bone tissue is also well suited for CT studies because its density spans across half of the Hounsfield scale. Based on these considerations, we would have expected to detect a substantial aging signal in bone. Bone aging is also known to be distinct in the two genders. Bone density with aging decreases in males gradually, while in females bone loss accelerates after mid-life (19,27,28). We would expect to detect these differences. Although the aging signal we detected is significantly higher than noise, it is of low magnitude and shows no differences between males and females. A set of contributing factors may explain our observations. First, in much of the research on bone density loss, the study subject is the femur (29,30), a weight-bearing bone whose density loss is directly related to functional decline. In this study, the bones consisted of highly variable fragments of lower ribs and the L4 lumbar vertebra. Although the bone in the vertebrae is known to be sensitive to osteoporosis as it consists mostly of trabecular bone, the specific parts of the vertebra and ribs that were captured in the scans was highly variable from sample to sample because they came in and out of view with small changes in body position (See Fig. 4, panel B). These types of abdominal sections are simply not optimal for studying bone structure. Lastly, both the older and younger female cohorts in our dataset consist of post-menopausal women, which may be past the stage of accelerated bone loss, where changes are smaller and more comparable to those in men. We suggest that studies addressing changes in bone would be better performed on scans of the thigh and/or calf."}, {"section_title": "Where classification errors occur", "text": "The per-class accuracy (Table III, values in brackets) allowed for analysis of common misclassification measures, miss rate (e.g. frequency of 'Y' misclassified as 'O') and fall-out (frequency of 'O' misclassified as 'Y'). These rates can be calculated as complementary to the known per-class accuracy given binary classification problem. For example, the per-class accuracies [0.770 0.747] (Males: ensemble, Torso) give miss rate and fall-out as 0.230 and 0.253, respectively. The per-class misclassifications were rather uniform for male participants (the largest difference is 0.03 for ATs). For female participants, the differences between fall-out and miss values were low (less than 0.02) for ATs and Bones, but were higher for Torso (0.16) and for STs (0.12). Here 'O' cohort showed higher misclassification rate, which could be attributed to a greater dispersion of morphology within older participants, given heterogeneous nature of this tissue group (more receptive to age diversion in the constituent tissues)."}, {"section_title": "Conclusions", "text": "We present a framework for automated processing of CT scans to evaluate the relative aging signals in tissues present in abdominal sections. The method relies on supervised machine learning and low-level generic image descriptors. Using three different classifiers and ensemble classification we demonstrate that robust aging signals exist in the morphological patterns of contrast-enhanced abdominal CT scans. The analysis showed that aging signal was higher overall in males than in females. In males, the strongest aging signal was observed in adipose tissue, while in females, adipose tissue was a close second to the signal in the whole torso. This was the first aging study based exclusively on image data from the BLSA and is by far the largest aging study based on images thus far conducted in humans. Scheme for generating intensity range data for experiments with tissue-specific scan areas. 1: original scan, 2: background pixels removed, rotation normalizing, 3: clipped, 4: CLAHE adjusted trunk, 5: tissue-specific mask, 6: CLAHE-adjusted and masked image.  Panel A: analysis of different quantiles over CT scans of all male subjects resulted in three intensity ranges roughly corresponding to adipose tissue, soft tissues and bones. Panel B illustrates segmentation of the whole intensity range according to the selected ranges shown above. Rows 1-3 present Fats, STs, and Bones ranges, respectively. Four male subjects shown correspond to obese 67 y.o. 1  Per-tissue signal contributions by the ensemble classifier.  "}]