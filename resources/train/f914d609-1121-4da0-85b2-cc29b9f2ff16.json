[{"section_title": "Abstract", "text": "Graph Convolutional Networks (GCNs) have made significant advances in semi-supervised learning, especially for classification tasks. However, existing GCN based methods have two main drawbacks. First, to increase the receptive field and improve the representation capability of GCNs, larger kernels or deeper network architectures are used, which greatly increases the computational complexity and the number of parameters. Second, methods working on higher order graphs computed directly from adjacency matrices may alter the relationship between graph nodes, particularly for weighted graphs. In addition, the direct construction of higher-order graphs introduces redundant information, which may result in lower network performance. To address the above weaknesses, in this paper, we propose a new method of multi-hop convolutional network on weighted graphs. The proposed method consists of multiple convolutional branches, where each branch extracts node representation from a k-hop graph with small kernels. Such design systematically aggregates multi-scale contextual information without adding redundant information. Furthermore, to efficiently combine the extracted information from the multihop branches, an adaptive weight computation (AWC) layer is proposed. We demonstrate the superiority of our MultiHop in six publicly available datasets, including three citation network datasets and three medical image datasets. The experimental results show that our proposed MultiHop method achieves the highest classification accuracy and outperforms the state-of-theart methods. The source code of this work have been released on GitHub (https://github.com/ahukui/Multi-hop-Convolutionson-Weighted-Graphs)."}, {"section_title": "I. INTRODUCTION", "text": "D EEP leaning methods exhibit promising performance in many fields [1] , such as computer vision [2] , [3] , natural language processing (NLP), and medical image computing [4] . In addition to the success of deep convolutional neural networks (CNNs) in grid-structured data analysis, there is an increased interest in applying deep learning, especially Graph Convolutional Networks (GCNs), to arbitrarily structured data like social network, knowledge graphs and chemical molecules [5] - [7] . For instance, Hamilton et al. [8] proposed a general inductive framework called GraphSAGE to efficiently generate node embedding by sampling and aggregating features from a node's local neighborhood for node-classification tasks. Velickovic et al. [9] The source code of this work is available at the GitHub repository (GATs), leveraging masked self-attentional layers for performing node classification of graph-structured data. Monti et al. [10] proposed a novel matrix completion architecture for recommendation systems by combining a multi-graph CNN and a recurrent neural network. GCNs have also started to make an impact in the domain of medical imaging. Before that, the conventional medical image based disease prediction or classification solely relies on the information from images and the relationship and similarity between subjects indicated by non-imaging features have been largely ignored. To efficiently exploit the wealth of both imaging and non-imaging information, for example age, health history, etc., for improving the accuracy of disease prediction, efforts of using GCNs have been made. For example, Parisot et al. [11] introduced GCN for population based disease prediction, which treats a patient population as a sparse graph. Vertices of the graph are associated with image-based feature vectors and the edges encode phenotypic information. To analyze the impact and relevance of the neighborhood definitions on the task of disease prediction, Kazi et al. [12] incorporated a novel weighting layer into the GCNs, which automatically learns the weight of each meta-data entry with respect to its relevance to the prediction task. Furthermore, inspired by the success of the inception architecture in CNNs, Kazi et al. [13] proposed a novel InceptionGCN model, which leverages spectral convolutions with different kernel sizes and chooses optimal features to solve the disease prediction problem.\nAlthough the above methods have improved the efficiency of GCNs in learning node representation and hence the accuracy of node classification, the structure of the constructed graphs limits the information extraction to be in local neighborhoods, similar to a fixed kernel is used for a CNN. A main reason is because the features of every node can only be learned from its neighbors at a fixed number of hops away. To overcome this challenge, many researchers try to employ bigger kernel size for GCN filter [13] , or design deeper GCNs [14] , or mix feature representations of neighbors at various distances for constructing special graph structures. For example, Abu-El-Haija et al. [15] proposed MixHop that can learn a general class of neighborhood mixing relationships by repeatedly mixing feature representations of neighbors at various distances, where nodes receive latent representations from first-degree neighbors and further N -degree neighbors at every message passing step. However, utilizing bigger kernel size, increasing the depth of GCNs significantly or employing higher-order graph convolutional network would increase the computational complexity of the convolution operator and the number of parameters. For the higher-order graph convolutional networks, such as [15] , which construct the higherorder graph by directly multiplying the adjacency matrix many times. Although this operation is easily and effective in higherorder graph constructing, the constructed higher-order graph always bring redundant information. Besides, this operation also ignored the weight of graph and changed the original relationship between the nodes. For example, as shown in the top row of Figure 1 , for the weighted graph, the operation of multiplying the adjacency matrix reassigned higher weight to those indirect connected nodes, which changes the predefined relationship between nodes. And the connections constructed by higher-order graph (3-order) already exist in the lowerorder graph (1-order), which also brings many redundant information.\nTo tackle the above-mentioned challenges, in this paper, a novel Multi-hop Graph Convolutional Network (MultiHop) is proposed for classification tasks on graphs datasets, particularly for the weighted graph. The proposed MultiHop consists of multiple graph convolution branches. Each branch captures the node representation from its neighbors with a different hop, for systematically aggregating multi-scale contextual information without adding redundant information. Different from the higher-order graph constructed by multiplying the adjacency matrix, the higher-order graph used in our model are computed by both the hop and weight between each node and avoid problem of relationship be changed and information redundantly as shown in the bottom row of Figure 1 . Compared with utilizing bigger kernel size or designing deeper network architecture, our proposed MultiHop significantly reduces the number of trained parameters and the computational complexity. Specifically, to adaptively fuse the node representations learned from multi-branch, an adaptive weight computation (AWC) layer is designed. The AWC layer works together with multi-branch, which receives the learned node representations and adaptively computes the weight of node representations from different branches. MultiHop then fuses the features together for getting the final node representations. In certain sense, the proposed MultiHop to GCN may be analogous to the successful dilated convolutions [16] to CNNs.\nIn this paper, extensive experiments were performed on two categories of datasets, three publicly disease prediction datasets -ABIDE [17] , TADPOLE [18] and Chest X-rays [19] and three citation network datasets -Citeseer, Cora and Pubmed [20] , are used to evaluate our proposed methods. The results corroborate the effectiveness of our proposed MultiHop, which outperforms state-of-the-art methods.\nIn the rest of the paper, we first give a short overview the spectral graph convolutional networks (GCNs). Then we will present our proposed the Multi-Hop GCN in detail, which is followed by the experimental results and discussions."}, {"section_title": "II. SPECTRAL GRAPH CONVOLUTIONAL NETWORKS", "text": "In this section, we briefly review the mathematical background of spectral graph convolution network employed in our work. Let G(V, E) represents an undirected graph with can be factored as L = U \u039bU T , where U is the matrix of eigenvectors ordered by eigenvalues and \u039b is the diagonal matrix of eigenvalues. Accordingly, for a graph signal x \u2208 R N which is the feature vector for every nodes of a graph. Giving a filter g \u03b8 = diag(\u03b8) which is a diagonal matrix filled with learnable parameters \u03b8 \u2208 R N in the Fourier domain. The spectral graph convolution operator on x can be defined as:\nwhere U T x is the graph Fourier transform of x. Based on the definition of spectral graph convolution, Bruna et al. [21] first proposed the spectral convolution neural network (Spectral CNN on graphs). They define a spectral convolution layer as:\nwhere H i \u2208 R N \u00d7M and H i+1 \u2208 R N \u00d7M are the input and output of Spectral CNN layer, which also are the feature descriptions (where N denotes the number of nodes and M indicates the dimensionality of node features), \u03c3 denotes a nonlinear activation function, such as the ReLU(\u00b7) = max(0, \u00b7). However, since multiplication with the eigenvector matrix U is O(N 2 ) and computing the eigendecomposition of L in the first place might be prohibitively expensive for large graphs, which make Spectral CNN compute expensive. To circumvent this challenge, Defferrard et al. [22] proposed ChebNet which defines a filter as Chebyshev polynomials of the diagonal matrix of eigenvalues.\nThe g \u03b8 can be well-approximated by a truncated expansion in terms of Chebyshev polynomials T k (\u039b) up to K th order:"}, {"section_title": "GCN layer", "text": "Adaptive weight computation Dot operator Based on this, the convolution of a graph signal x with the defined filter g \u03b8 is\nFrom this equation, we can note that which can reduce the computation complexity of spectral graph convolution to O(|E|) linear in the number of edges.\nTo further alleviate the problem of overfitting on local neighborhood structures for graphs with very wide node degree distributions, Kipf et al. [23] proposed a first-order approximation of ChebNet. They limited the layer-wise convolution operation to k = 1. And therefore the ChebNet becomes a linear function on the graph Laplacian spectrum. Furthermore, in this linear formulation of a GCN, they further approximate \u03bb max \u2248 2, Under these approximations, Eq.14 is simplified as\nTo further constrain the number of parameters, address overfitting and minimize the number of operations per layer, such as matrix multiplications, they further assumed \u03b8 = \u03b8 0 = \u2212\u03b8 1 . Therefor, Eq.5 can be written as:\nIn order to avoid numerical instabilities and exploding or vanishing gradients bring by stacking multiple layers,\nAccordingly, for a graph X \u2208 R N \u00d7C where N denotes the number of nodes and C indicates the dimension of node features, the definition of graph convolution layer is:\nwhere \u0398 \u2208 R C\u00d7F is a matrix of filter parameters, H i+1 \u2208 R N \u00d7F is the convoluted matrix, H 0 = X and F denotes the number of filters.\nIII. MULTI-HOP GCN In this section, we first give an overview of the our Multi-Hop and then discuss each component in detail."}, {"section_title": "A. Overall Framework", "text": "The objective of our MultiHop is to learn a classifier, which can classify each node of a graph G(V, E) into different categories. Figure 2 gives an overview of the proposed MultiHop. As shown in Figure 2 , our proposed MultiHop consists of two major components: feature extraction and feature fusion. The feature extraction component aims to learn feature representations of each node within its neighborhood defined by various hops. Multi-branch graph convolution layers are designed to achieve the feature extraction. The feature fusion component adaptively computes the weights of learned feature representations by our specifically designed AWC layer. The representation of each node from different branches are then aggregated together using the computed weights to obtain the final node representation for classification. Details of the proposed method are presented in the following sections."}, {"section_title": "B. Affinity Graph Construction", "text": "The construction of an affinity graph G(V, E) is crucial to accurately model the interactions between the subjects. A graph G consists of |V| =N nodes connected by the weighted edges E \u2208 R N \u00d7N . Mathematically, E can be defined as\nwhere W \u2208 R N \u00d7N is the weight matrix, A \u2208 R N \u00d7N is adjacency matrix, and \u2022 denotes the Hadamard product.\nFor medical image datasets with no prior defined graphs, to efficiently exploit the wealth of both imaging and non-imaging information, both information sources are used to define a weighted graph G in our work. The patients are set as nodes V with their corresponding node feature vectors extracted from image data. The graph's adjacency matrix A is computed by the non-imaging measures M \u2208 R n (e.g. gender, age or other meta-information) as where\nand M t (i) and M t (j) are the value of the t th non-imaging measurement for nodes i and j, respectively. \u03b2 is a threshold for the element similarity.\nThe weight matrix W is computed by the similarities between the feature vectors extracted from imaging data. i.e.,\nwhere \u03c1 is the correlation distance between nodes i and j, and \u03c3 is the width of the used convolution kernel. For those datasets with pre-defined adjacency matrix A \u2208 R N \u00d7N , such as citation network datasets including Citeseer, Cora and Pubmed, we just need to compute the weight matrix W \u2208 R N \u00d7N based on the similarities between node features.\nBy changing the connection of affinity graph E, we can construct various hop graphs E k . The details are described in Figure 3 and Algorithm 1. First, for each node i in graph E we search the shortest path from i to its k hop distance away node i k by depth first search algorithm (DFS). Then, we statistic the weight of each path and select the path with the maximum weight as the new wight for E k (i, i k ). To avoid change the relationship between nodes, we use the value of hop k to assign a small value for the graph with huge hop. Figure 1 is an example of various hop graphs E k produced by our proposed method."}, {"section_title": "C. Multi-branch GCN", "text": "GCNs are commonly implemented by using many graph convolutional layers in a sequence manner with a constant kernel size [11] . For a single graph convolutional layer in GCN, it only can learn the features of each node from its neighbors within a fixed number of hops. Applying GCN with fewer layers on the whole graph might not capture the semantic and comparable feature from the whole graph. In order to enlarge the receptive field, the network has to be deep or employs big kernels, for example the work in [13] . However, such design of GCNs may significantly increase the computational complexity of the convolution operation and the number of parameters, which may lead to overfitting and decrease the network performance.\nTo overcome the above challenges and enlarge the learning field of each node, in this paper, we utilize various hop graphs with weighted edges to directly represent the relationship between nodes. Inside the various hop graphs, each node can directly connect with farther neighbors, which enables each node can directly learn the node representation from its neighbors with greater distances by the spectral convolutions with a small kernel. To learn the node representations from above hop graphs, we employ multiple branches in our MultiHop with each branch aggregating the representations of node from unique hop graph respectively as shown in Figure 2 . Compared with those models utilizing larger kernel size or deeper architecture for increasing the receptive fields of convolutional filters, our proposed model is more effective and directly in learning the representations of node from large receptive field with fewer training parameters."}, {"section_title": "D. Adaptive Weight Computation", "text": "To adaptively fuse the node representations learned from the multiple branches, inspired by the work of Velickovic et al. [9] , we propose a novel adaptive weight computation (AWC) layer. The input of AWC layer is a set of node features {H 1 i , H 2 i , ..., H k i } from the ith graph convolution layer, H k i \u2208 R N \u00d7C is the nodes represents learned by the kth branch, N is the number of nodes and C is the number of classes. The AWC layer computes the weight coefficients {w 1 , w 2 , ..., w k } of node features, w i \u2208 R N , and outputs a fusing node representation H i . The above process is accomplished through a single-layer feed-forward neural network, parameterized by a shared weight vector \u03b1 \u2208 R C . Formally, the weights are computed by"}, {"section_title": "1-hop 2-hop", "text": "and the final feature is\nThrough the above AWC layer, our MultiHop GCN can adaptively aggregate the representations of each node learned from multiple branches. It enables the capture of both local and global structural information from 1 to k-hop neighbors."}, {"section_title": "IV. EXPERIMENTS AND RESULTS", "text": ""}, {"section_title": "A. Datasets and Implementation Details", "text": "In our work, six publicly available datasets belonging to two categories (medical image datasets and citation network datasets) are used for evaluating the proposed methods. The data description and implementation details are presented as follows.\n1) Dataset 1 -ABIDE:: The Autism Brain Imaging Data Exchange (ABIDE) database [17] is a collaboration of different international imaging sites that have aggregated and are openly sharing neuroimaging data from 539 individuals suffering from ASD and 573 age-matched typical controls (TC; 764 years). These 1112 datasets are composed of structural and resting state functional magnetic resonance imaging (R-fMRI) datasets along with an extensive array of phenotypic information for Autism spectrum disorders (ASD) studies. For fair comparison, we choose the same set of 871 subjects used by [11] , [13] , which are divided into normal (468) and ASD diseased (403) subjects. We also follow the same preprocessing step as performed in [11] , [13] . The pre-processing consists of skull striping, slice timing correction, motion correction, global mean intensity normalisation, nuisance signal regression, band-pass filtering (0.01-0.1Hz) and registration of the functional MRI images to MNI152 standard anatomical space. We follow the same graph construction step as in the baseline method [11] . Two non-imaging measures, gender and acquisition site, are used for constructing the graph. The 200 most discriminating features from each subject are selected by a ridge classifier as subject's features. For the element similarity threshold \u03b2, we set \u03b2 = 0 for the two nonimaging elements. A MultiHop network with two branches is constructed for this datasets. Each branch has two graph convolutional layers. The filter number of the two layers are 16 and 2, respectively.\n2) Dataset 2 -TADPOLE:: This dataset [18] is derived from the Alzheimers Disease Neuroimaging Initiative (ADNI) database (adni.lonu.usc.edu), which consists of 557 patients with 354 multi-modal features per patient. There are total three classes existence, Cognitively Normal (CN), Mild Cognitive Impairments (MCI) or Alzheimers Disease (AD). Our goal on the TADPOLE database is to predict the class of each patient. To provide a fair evaluation for TADPOLE, in the experiment, we follow the same pre-processing step as performed in the work of [13] . Four demographics are selected (age, gender, APOE status and FDG PET) for graph construction. We also set threshold \u03b2 = 2 for age and \u03b2 = 0 for the rest of the three demographics. The features are extracted from MR and PET imaging, cognitive tests, CSF and clinical assessments. A MultiHop network with four branches is designed. Each branch has two graph convolution layers with 16 and 3 filters, respectively.\n3) Dataset 3 -CXR:: In this CXR dataset [19] , the Chest X-rays are from out-patient clinics and captured as part of the daily routine using Philips DR Digital Diagnose systems. The dataset consists of x-ray images from 662 subjects, which are divided into 326 normal and 336 abnormal x-rays showing various manifestations of tuberculosis. Each subject contains two non-imaging elements (gender, age). In our experiment, a pre-trained ResNet [24] is employed to extract the feature representations (each feature vector with length of 2048) of all CXR images. The gender and age are used for graph construction, and we set the element similarity threshold \u03b2 = 5 for age and \u03b2 = 0 for gender. Figure 4 shows the affinity graph of part of the CXR dataset. The structure of the network is the same as the one used for the ABIDE dataset. 4) Datasets 4-6 -Citation Network Datasets:: We also evaluate the effectiveness of our proposed model following the experimental setup in [20] using three citation network datasets -Citeseer, Cora and Pubmed, which belong to the second category. The nodes with sparse bag-of-words feature vectors represent document and the edges denote citation links between documents. Table I summarizes the dataset statistics. Our experiments on the citation network datasets follow the setup presented in [20] . Differently, to prove the effectiveness of our MultiHop in weighted graph, in our experiment, we use the similarity between the feature vectors at every node to weight the adjacency matrix of graph. Since the feature vectors of Citeseer and Core are binary and sparse, we employed L1 distance to compute the weight matrix. The network architecture consists of three branches. Each branch has two graph convolution layers. The number of filter in the first layer is 16. The number of filter in the second layer equals to the number of categories. For the Pubmed dataset, each publication is described by a TF/IDF weighted word vector from a dictionary consisting of 500 unique words. The correlation distance is employed to evaluate the similarity. The network architecture has two branches and each branch has two graph convolution layers with 8 and 3 filters, respectively."}, {"section_title": "B. Implementation Details", "text": "The proposed method is implemented using the open-source deep learning library Keras [30] . Each model is trained endto-end with Adam optimizer. L 2 regularization with weight of 0.0005 and dropout in input and hidden layers with rate of 0.5 are also be used. The activation function is ELU [31] . For medical image datasets, early stopping is utilized, and the spectral graph convolutional layer employed in our model is approximated by the order K = 3 Chebyshev polynomials [22] . For a graph signal x, convolution with a filter g \u03b8 approximated by Chebyshev polynomials is defined as\nwhere filter g \u03b8 = diag(\u03b8) is a diagonal matrix filled with learnable parameters \u03b8 \u2208 R N in the Fourier domain,\u039b = 2 \u03bbmax \u039b \u2212 I N , and \u039b is the diagonal matrix of eigenvalues for the normalized graph Laplacian matrix I N \u2212D \u2212 1 2 AD \u2212 1 2 . The Chebyshev polynomials are defined recursively by T k (x) = 2xT k\u22121 (x) \u2212 T k\u22122 (x) with T 0 (x) = 1 and T 1 (x) = 1.\nFor the citation network datasets, the graph convolutional layers used in our model are approximated by first-order Chebyshev polynomial [23] , which is defined as\nwhere \u0398 \u2208 R C\u00d7F is a matrix of filter parameters, H i+1 \u2208 R N \u00d7F and H i are the output and input of layer and F denotes the number of filters,\u00c3 = I N + A andD ii = j\u00c3 ij .\nDuring training, we first train our model about 2000 epochs with an initial learning rate of 0.005, and then train the model about 1000 epochs with the learning rate of 0.001. Since we note that the citation datasets are sensitive to the initialization, we ran all the models 100 times. After ranking the networks by using validation accuracy, we finally report the average test accuracy of the top 50 runs."}, {"section_title": "C. Experimental Results", "text": "In this section, we first compare our proposed MultiHop method against several state-of-the-art GCN based methods. Then we evaluate the effectiveness of multi-branch strategy and AWC layer through ablation studies. After that, we further visualize the various hop graphs to investigate feature learning.\nComparison with state-of-the-art GCN methods: To evaluate the performance of our proposed MultiHop, we compare the results against several state-of-the-art methods based on GCN. Table II and Table III list the performances of our proposed MultiHop and other state-of-the-art GCN methods under two categories of available datasets. From Table II , we can note that our MultiHop outperforms other state-of-the-art GCN methods and performed the best on the medical image datasets, which indicates that our MultiHop are generalized and robust to the medical image datasets. It's notable that we used mixed graph for every medical image datasets for creating various hop graphs. Particularly, under the same mixed graph, our model outperforms GCN [11] , InceptionGCN by an average margin of 2.18%, 3.34% for ABIDE dataset, 9.78%, 7.47% for TADPOLE dataset, 2.73%, 0.6% for CXR dataset, which proved the effectiveness of our MultiHop. The node classification accuracy on citation network datasets are shown in Table III . Compared with other GCN based methods, the proposed MultiHop obtained significantly better performance on both Citeseer and Cora datasets, and very similar performance to MixHop on Pubmed dataset.\nEffectiveness of multi-branch and AWC layer: In our experiments, we compare the performances of our MultiHop under different number of branches and three different types of fusing strategies: sum, max-pooling and our proposed AWC layer. The sum operation directly adds all of features learned from multi-branch together, and the max-pooling operation selects the max one from all of features learned by multibranch. Table IV shows the results of our MultiHop with different number of branch and fusing strategies on TADPOLE datasets, respectively. As it can be seen from Table IV , compared with sum and max-pooling, our MultiHop with AWC layer can obtain better performance with the number of branch increasing, which proves that the effectiveness of AWC layer in adaptive computing weight. Apart from the evaluation criterion of accuracy, we also perform statistical comparison of the results using paired t-test with a confidence interval of 0.95 for showing the effectiveness of our proposed AWC layer. Our MultiHop with AWC layer is compared to model with sum and max-pooling layer for statistical significance, and all the p values are also given in corresponding Table IV . It can be seen that our MultiHop with AWC layer significantly outperforms  TABLE II  MEAN ACCURACIES OF THE STRATIFIED 10-FOLD CROSS VALIDATION ON THE MEDICAL IMAGE DATASETS. \"MIXED\" INDICATES THAT THE AFFINITY  GRAPH IS CONSTRUCTED BY AVERAGING ALL THE GRAPHS BUILT WITH DIFFERENT MEASURES. \"BEST\" DENOTES THAT THE BEST PERFORMANCE   OBTAINED UNDER THE AFFINITY GRAPH CONSTRUCTED WITH A PARTICULAR NON-IMAGING the other fusing strategy with p < 0.05, which clearly demonstrates that AWC layer is effective in improving the performance of classification. We also compare three different types of fusing strategies on ABIDE and CXR datasets, the classification results are listed in Table V . Compared with sum and max-pooling, the AWC layer significantly improves the performance of model, which further prove that AWC layer are effective in improving the performance of model."}, {"section_title": "Contribution of various hop graphs:", "text": "To demonstrate the information from various hop graphs can improve the performance of model, we use individual graph with different hops to train the MultiHop which only has one branch. The experiments are carried on TADPOLE dataset, 20% data be random selected for test and the rest are used for training. The experiment results from four individual graphs are show in Figure 5 . From top row of Figure 5 , we can note that parts of wrongly predicted nodes on 1-hop graph can be reassigned a true label in other graphs, which indicates that the features from the neighbors at different distances are meaningful. We also employ t-SNE [32] to visualize the distribution of the node representation learned by each hop graph as shown in bottom row of Figure 5 . We can note that the feature learned by our MultiHop is distinguished, which prove that our MultiHop can make those hop graphs complement each other for improving the accuracy of classification."}, {"section_title": "V. CONCLUSION", "text": "In this paper, we analyzed the disadvantages of existing GCNs methods on semi-supervised learning. For the methods used bigger kernels or deeper network architectures, which increase the computational complexity and the number of parameters, and for the methods employed higher order graph convolutional networks, which ignore the weight of graph and change the original relationship between the nodes and always bring redundant information. To address the two problems, in this paper, we presented a novel Multi-hop Graph Convolutional Network (MultiHop) for classification tasks on graphs datasets, particularly for the weighted graph. The proposed MultiHop can capture the node representation from various order graphs by multi-branch. To aggregate the lower-order and higher-order neighborhood information in an adaptive manner, an adaptive weight computing layer also be proposed. Extensive experiments were conducted to demonstrate the effectiveness of the proposed method. Our proposed MultiHop achieves superior results compared with other state-of-the-art methods. "}]