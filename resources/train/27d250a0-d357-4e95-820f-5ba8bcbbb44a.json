[{"section_title": "Abstract", "text": "Increasing effort in neuroimaging has been dedicated to early diagnosis of Alzheimer's disease (AD) based on structural magnetic resonance imaging (MRI) data. Most existing studies have been focusing on binary classification problems, e.g., distinguishing AD patients from normal control (NC) elderly or mild cognitive impairment (MCI) individuals from NC elderly. However, identifying individuals with AD and MCI, especially MCI individuals who will convert to AD (progressive MCI, pMCI), in a single setting, is needed to early diagnose AD. In this paper, we propose a data-driven, deep ordinal ranking model for distinguishing NC, stable MCI (sMCI), pMCI, and AD at an individual subject level, taking into account the inherent ordinal severity of brain degeneration caused by normal aging, MCI, and AD, rather than formulating the classification as a traditional multi-category classification problem. The proposed deep ordinal ranking model focuses on the hippocampal morphology of individuals and learns informative and discriminative features automatically. We experimented with baseline MRI scans of 1776 subjects obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) 1, ADNI GO, and ADNI 2. Our deep learning model was trained based on the ADNI 1 data and validated on the independent cohort of ADNI GO and ADNI 2. Our results indicate that the proposed method can achieve better performance than traditional multi-category classification techniques using shape and radiomics features from structural MRI data. Our method might accelerate the development of personalized AD diagnostic systems with targeted interventions.\n3"}, {"section_title": "Introduction", "text": "Alzheimer's disease (AD) is the most prevalent neurodegenerative disorder. As a major public health issue, this disease results in tremendous neurologic disability, emotional suffering, and financial difficulty for patients, their families, and the society at large. Mild cognitive impairment (MCI) as a prodromal stage to AD, characterized by gradual neurodegeneration, is considered at a significantly higher risk to develop AD, with a conversion rate of 10-15% per year (Grundman et al., 2004) . Although clinical criteria for MCI and early AD have been developed to formalize assessment of the gradual progression of cognitive and other symptoms in early AD, currently it is difficult to predict which individuals who meet criteria for MCI will ultimately progress to AD. Neuroimaging has been playing an increasingly important role for clinical AD diagnostics. As the search for effective therapies to slow the progression of AD intensifies, there is a need for better diagnostic and prognostic tools to identify individuals at high risk to progress to AD.\nTo aid AD diagnosis and distinguish MCI patients with higher risk of conversion to AD (progressive MCI, pMCI) from stable MCI individuals (sMCI), machine learning techniques have been proposed to build classifiers upon imaging data and clinical measures (Davatzikos et al., 2008; Fan et al., 2008a; Fan et al., 2008b; Misra et al., 2009; Desikan et al., 2010; Filipovych et al., 2011; Moradi et al., 2015; de Vos et al., 2016; Hu et al., 2016; Rathore et al., 2017) , and identified prominent structural differences between pMCI and sMCI subjects at medial temporal lobe (MTL), including regions such as hippocampus and entorhinal cortex.\nMost existing classification studies of AD have been focusing on two-category classification problems, e.g., distinguishing AD patients from cognitively normal control (NC) elderly, MCI from NC, or pMCI from sMCI. However, the early diagnosis of AD is essentially a multi-category classification problem, i.e., we need to identify individuals with AD, pMCI, and sMCI in a single setting. The multi-category classification problem associated with early\nThe hippocampus is one of the first brain structures affected by AD and undergoes severe structural changes (Braak and Braak, 1991) . The structural variation between the hippocampus of AD patients and healthy subjects has been studied intensively (Qiu et al., 2008; Teng et al., 2015; Tsao et al., 2017) (Li et al., 2007; Chupin et al., 2009; Gerardin et al., 2009; Costafreda et al., 2011; Devanand et al., 2012; Ben Ahmed et al., 2015; de Vos et al., 2016; Hu et al., 2016; Sorensen et al., 2016; Aderghal et al., 2017; Tsao et al., 2017) . Several studies have specifically focused on the hippocampus for early diagnosis of AD and build predictive models upon anatomical features including volume and shape based measures, and image intensity texture features Devanand et al., 2012; Ben Ahmed et al., 2015; de Vos et al., 2016; Hu et al., 2016; Aderghal et al., 2017; Tsao et al., 2017) . Particularly, promising performance of hippocampus shape (Li et al., 2007; Gerardin et al., 2009; Costafreda et al., 2011) , texture features (Sorensen et al., 2016) , and 2D convolutional neural networks (CNNs) based features (Aderghal et al., 2017) has been demonstrated in AD prediction.\nHowever, most of the hippocampus focused pattern classification studies have been relying on the two-category classification techniques.\nTo achieve early prediction of AD based on the hippocampal MRI data, we develop an ordinal ranking based deep learning method, referred to as Deep Ordinal Ranking hereafter, to simultaneously learn reproducible and discriminative features from the hippocampal MRI data and classify AD, pMCI, sMCI, and NC subjects, by making the best of inherent ordinal severity of the brain degeneration at AD's different stages. Since deep convolutional neural networks (CNNs) based feature learning is potentially able to capture complex relationship between imaging data and the ordinal severity of the brain degeneration of AD, we adopt the CNNs to learn informative features from structural MRI data by optimizing a multi-output logistic regression model which encodes the ranking information of different stages of AD. We have evaluated the proposed method based on a large cohort of subjects from Alzheimer's Disease Neuroimaging Initiative (ADNI), including ADNI 1, ADNI GO, and ADNI 2. We compared the Deep Ordinal Ranking method with the state-of-the-art methods with multi-category classification capability. Experimental results have demonstrated that the proposed method could achieve improved prediction performance."}, {"section_title": "Materials and Methods", "text": ""}, {"section_title": "Image dataset", "text": "The data used in this study were obtained from the ADNI cohort (http://adni.loni.usc.edu), consisting of baseline MRI scans of 1776 subjects from ADNI 1, ADNI Go and ADNI 2. The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial MRI, positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of MCI and early AD. For up-to-date information, see www.adni-info.org. We used MRI data (total n=817 scans, with 228 NC, 236 sMCI, 161 pMCI, and 192 AD patients) from ADNI 1 to train the proposed classification model. Then we validated the Deep Ordinal Ranking method with independent data (total n=959 scans with 311 NC, 395 sMCI, 94 pMCI and 158 AD patients) from the cohorts ADNI GO and ADNI 2.\nMCI subjects that converted to AD from 0.5 to 3 years from the baseline scan were defined as pMCI, otherwise they were considered as sMCI. The characteristics of the cohorts included in this study are summarized in table 1. "}, {"section_title": "Hippocampus extraction", "text": "T1 MRI scans of all the subjects were registered to the MNI space using affine registration and resampled with a spatial resolution of 1 \u00d7 1 \u00d7 1 mm 3 . Left and right hippocampus regions were then segmented from the T1 images for each subject using the local label learning (LLL) (Hao et al., 2014) algorithm with 100 hippocampus atlases obtained from a preliminary release of the EADC-ADNI harmonized segmentation protocol project (www.hippocampal-protocol.net) (Boccardi et al., 2015) . A 3D bounding box of size 29 \u00d7 21 \u00d7 55 was adopted to extract hippocampus regions from the T1 image using the segmentation label of left and right hippocampus for each subject. These hippocampus regions, referred to as hippocampal MRI images hereafter, were used as the input to the proposed deep ordinal ranking model."}, {"section_title": "Ordinal ranking", "text": "To make the best of the ordinal severity of the brain degeneration rendered by normal aging, MCI, and AD, we propose an ordinal ranking method within an ordinal regression framework by transferring the ordinal ranking problem into a set of binary \"larger than\" problems (Fan, 2011) .\nParticularly, NC, sMCI, pMCI and AD are labeled using an ordinal order \u2208 {1,2,3,4} , corresponding to their severity of the brain degeneration. Three binary \"larger than\" problems associated with the ordinal ranking problem are the brain degeneration \"larger than normal aging?\" ( > 1), \"larger than sMCI?\" ( > 2), and \"larger than pMCI\"( > 3). The binary \"larger than\" problems are solved separately and then the binary codes obtained are fused to obtain the final multi-category classification label.\nGiven training data {( , ), = 1,2, \u2026 , } , where represents the feature vector for subject and \u2208 {1,2,3,4} represents its associated category label, the 4-category label could be transformed into a binary label for each binary \"larger than\" problem. For the -th binary problem ( > ), its positively labeled training dataset + and negatively labeled training dataset \u2212 could be constructed as\nBased on the training dataset, a binary classifier could be trained using any pattern classification techniques, such as support vector machine (SVM) (Cortes and Vapnik, 1995) and random forests (RF) (Tin Kam, 1998) . Once all the three binary classifiers are obtained, the ordinal ranking rule is constructed as\nwhere \u27e6\u2022\u27e7 is 1 if the inner condition is true and 0 otherwise."}, {"section_title": "Deep ordinal ranking", "text": "Given the imaging data of hippocampus of each subject, different kinds of feature representations could be extracted, such as shape representation and radiomic characterization of image texture measures within the hippocampus regions (Rathore et al., 2017) . Although these representations have been investigated and achieved promising performance, as handcrafted features they might be not optimal and less discriminative for the AD diagnosis.\nThe success of deep learning techniques in pattern recognition (Goodfellow et al., 2016) in recent years have witnessed promising performance in learning imaging features for a variety of pattern recognition tasks (Gulshan et al., 2016; Nie et al., 2016; Esteva et al., 2017) . In these studies, convolutional neural networks (CNNs) are widely adopted to learn informative imaging features by optimizing a pattern recognition cost function. Ordinal regression based on CNNs has also been adopted for age estimation, and achieved better performance than state-of-theart alternative techniques (Niu et al., 2016) . Therefore, we propose a deep ordinal model for AD The network architecture of the proposed deep learning model is illustrated in Fig. 1a .\nThe Deep Ordinal Ranking model contains one convolutional layer (Conv), followed by three residual blocks (ResBlock), one fully connected layer (FC), and an output layer for the ordinal ranking (FC2). Rectified linear units (ReLU) is used as a nonlinear activation function for the convolutional and fully connected layers, batch normalization (BN) is adopted to accelerate deep network training (Ioffe and Szegedy, 2015) , and max pooling layers are adopted to obtain features at multiple scales. The residual network structure, as illustrated in Fig. 1b , has been adopted widely since its invention (He et al., 2016) and achieved promising performance in many challenging pattern recognition tasks. Several studies have also demonstrated that the residual connection would accelerate the convergence and improve the performance of the CNNs (Szegedy et al., 2017) . The left and right hippocampus regions are adopted as twostream inputs to the deep model, which are gradually convolved by multiple 3D kernels within the subsequent Conv layer and ResBlock layers. The high-level feature representations of each hippocampus region are then flatten and connected to the FC layers, whose output are concatenated and fed into the output layer.\nTo learn imaging features informative for the ordinal ranking with binary \"larger than\"\nclassification problems, we formulate the ordinal ranking as a multi-label classification problem.\nIn our study, the four-category label of each subject \u2208 {1,2,3,4} is transformed into a 3-bit binary label encoding its status corresponding to the 3 binary \"larger than\" problems, i.e., the brain degeneration \"larger than normal aging?\", \"larger than sMCI?\", and \"larger than pMCI?\".\nFor example, one AD patient will be labeled as [1,1,1] in the deep ordinal ranking setting while labeled as [0,0,0,1] in the regular four-category classification setting. The output layer has three nodes corresponding to the three binary \"larger than\" problems in the Deep Ordinal Ranking model. Sigmoid cross entropy loss is adopted to optimize the deep learning model."}, {"section_title": "Data augmentation", "text": "To boost the deep learning model's performance and robustness to image alignment and hippocampus segmentation errors, data augmentation is adopted to generate more training data (Goodfellow et al., 2016) . Particularly, augmented image data were generated using image translation and non-rigid deformable image registration techniques. In particular, each hippocampus image along with its corresponding hippocampus masks in the training dataset was translated by 2 voxels along 26 directions of 3D image space separately, yielding augmented images that account for translation invariance for training the deep learning model. A non-rigid deformable image registration method, namely ANTs (Avants et al., 2011) , was adopted with its default parameter setting to register one hippocampal MRI image, referred to as moving image, to another of the same side (left to left and right to right) within the same disease category (NC to NC, sMCI to sMCI, pMCI to pMCI, and AD to AD), and the resulting deformation field was used to deform the moving hippocampus image and its hippocampus label to generate deformed hippocampus image and label. In total, 21242 spatial translated images, and 84824 non-rigid registered images were generated as the augmented dataset for training the deep learning model."}, {"section_title": "Validation and comparisons", "text": "We evaluated the proposed method and compared it with state-of-the-art alternative methods based on the same training and validation datasets."}, {"section_title": "State-of-the-art alternative methods under comparison", "text": "We \uf0b7 Shallow classifier: Random forests (RF) (Tin Kam, 1998 ) is adopted to construct classifier using shape and radiomics representation respectively. Its inherent feature selection and decision ensemble techniques lead to robust classification and better generalization. Moreover, RF can handle multi-category classification naturally.\n\uf0b7 Deep classifier: CNNs with the architecture shown in Fig. 1 is adopted for the prediction tasks based on the learned features in the data-driven way."}, {"section_title": "\uf0b7 Classification strategy.", "text": "\uf0b7 Regular multi-category classification: the early diagnosis of AD is formulated as a 4-category classification problem, RF using shape representation, RF using radiomics representation, and CNNs with 4-category output are evaluated in this study. For the CNNs, the network architecture is the same as that in Fig.1 except that the output layer is replaced with 4-node output layer for regular multi-category classification.\n\uf0b7 Ordinal ranking classification: for the shallow classifier, 3 \"larger than\" binary classifiers are constructed using RF based on shape and radiomics representation respectively. For the deep classifier, the proposed deep ordinal ranking model as illustrated in Fig.1 is adopted. Note that the same network architecture and parameter configuration is adopted for deep classifier under both regular multicategory and ordinal ranking setting except the differences of the output layer.\nIn addition to the 4-category classification, we have also performed a binary classification to distinguish AD patients from NC elderly based on shape, radiomics, and deep CNNs representation as baseline experiments, in order to investigate the discriminative power of hippocampal representation for AD diagnosis.\nThe performance of the classification is evaluated with the following metrics: (1) normalized confusion matrix, (2) adjusted classification accuracy, (3) receiver operating characteristic curve (ROC), and area under ROC (AUC). A normalized confusion matrix illustrates not only the sensitivity and specificity for the multi-category classification results, but also the pattern of misclassification reflecting the severity of different stages of AD disease.\nAdjusted classification accuracy is calculated as the mean sensitivity value of the 4 categories, which takes the imbalance of sample sizes of different categories into consideration. For the binary AD versus NC prediction, ROC and AUC are adopted for the evaluation."}, {"section_title": "Experimental settings", "text": "The deep learning model's network architecture is illustrated by Fig. 1 , with 1 Conv layer, 3\nResBlocks, 1 FC layer, and an output layer. In particular, the Conv layer contains 64 kernels, while the ResBlock 1, 2, and 3 contains 64, 128, and 128 kernels respectively. The kernel size for all the kernels is 3 \u00d7 3 \u00d7 3. A stride of 2 and kernel size of 2 is used for the max pooling layer.\nThe fully connected layer FC1 contains 256 nodes, which extract a 256-dimensional features for left and right hippocampus respectively. The two 256-dimensional feature vector is concatenated and fed to FC2 with 3 output nodes for the deep ordinal ranking model (4 output nodes for the deep multi-category classification model). A dropout operation with a ratio of 0.5 is applied before the features fed into the last FC layer.\nThe deep learning model was optimized using stochastic gradient descent (SGD) algorithm (Boyd and Vandenberghe, 2004) , the momentum was set to 0.9, and the base learning rate was set to 5 \u00d7 10 \u22125 . The learning rate was updated using a stepwise policy, which drops the learning rate by a factor of 0.1 after every 40000 steps. The maximum iteration of the training procedure was set to 120000. Batch size of 32 was adopted to update weights in the model. The deep learning models was implemented using Caffe (Jia et al., 2014) , and trained on a Nividia Titan X (Pascal) graphics processing unit (GPU).\nFor the RF based on shape representation and radiomics representation, 1000 decision trees were adopted, and the minimum leaf size of the tree was set to 5. Sample weight for each training image was set to the ratio between total number of training images and the number of images within the same category, and the training images were sampled with replacement during the training procedure. The built-in RF implementation TreeBagger in Matlab (R2013a) was adopted to train the model, and default values were used for other parameters."}, {"section_title": "Results", "text": "The distributions of hippocampus volumes of different groups are illustrated in Fig. 2 . These plots indicated that AD patients and NC elderly could be roughly separated based on their hippocampus volumes. However, the hippocampus volumes of MCI individuals scatter inbetween the AD group and NC group, demonstrating the complexity of distinguishing between the 4 groups based on the hippocampus volume only. In fact, that might be impossible.\nTwo experiments were conducted to evaluate the performance of the Deep Ordinal Ranking model. We first performed a binary classification task for distinguishing the AD patients from the NC individuals using the shape representation, radiomics representation, and deep representation respectively with a two-fold purpose. On one hand, we would like to check the power of hippocampus based representation for the AD diagnosis, on the other hand, we would like to investigate if the deep representation learned based on the deep CNNs is more discriminative for the prediction task. We then performed the 4-category prediction based on the 3 kinds of hippocampus representation under regular multi-category classification and ordinal ranking setting, to investigate if improved prediction performance could be achieved by the Deep Ordinal Ranking model. It is worth noting that all the prediction models were trained using the ADNI I dataset, and validated using the ADNI Go & 2 dataset. The results of 4-category prediction are illustrated in Fig. 4 and Fig. 5. Fig. 4 shows the adjusted accuracy for the prediction. It could be observed that the CNNs model obtained better performance than the RF method using shape and radiomics representations, and the performance under the ordinal ranking setting were generally better than their counterparts under the conventional multi-category classification setting. The best performance was obtained by the Deep Ordinal Ranking model, and the adjusted accuracy was 0.465. Fig. 5 illustrates the confusion matrices of all the 6 prediction models. Generally speaking, the AD group and NC group were separated pretty well by all the models, our Deep Ordinal Ranking model captured the progressive patterns of the AD better than other models, as the larger coefficients of the confusion matrix located at the nearby positions along the diagonal of the matrix, indicating that misclassified subjects were assigned to adjacent categories in the progression spectrum, instead of the distant categories. Instead of formulating the AD diagnosis as binary classification that accounts for 2 out 4 stages of AD progression, or as regular multi-category classification ignoring the progressive property of adjacent stages, we formulate the diagnosis task under an ordinal ranking framework. The ordinal ranking framework can naturally consider the severity degrees of brain degeneration along with the disease progression. Under regular multi-category classification setting, one subject might be misclassified into one arbitrary category. However, larger penalty would be introduced to the prediction model under the ordinal ranking setting if one pMCI individual is assigned to the NC instead of sMCI, as NC is more distant from pMCI on the ordinal list. This has also been demonstrated in Fig. 4 and 5. All the prediction models under ordinal ranking setting outperformed their multi-category counterparts, and the pattern of the prediction results followed the disease progression better, as shown in Fig. 5f in particular, most of the incorrectly assigned individuals were located at adjacent categories of their true category.\nAlthough the proposed deep ordinal ranking model has achieved promising performance for AD diagnosis, further effort is needed in following aspects. First, the current study focused on the hippocampus in AD diagnosis, and obtained similar classification performance as those methods based on the whole brain information (Liu et al., 2015b) . It is expected to obtain improved classification performance to extract informative features from the whole brain MRI data. Second, hyper-parameters of the deep ordinal ranking model need further optimization, including network architecture, convolutional filter size, learning rate, batch size, number of filters per convolution layer, and so on (Goodfellow et al., 2016) . Currently, we set these parameters considering GPU memory. However, Bayesian optimization methods could be used to tune our models (Snoek et al., 2012) , and better performance could be obtained. Moreover, the definition of pMCI category might influence the performance of the diagnosis. Conversion to AD within 2 or 3 years are generally used for the identification of pMCI in the literature.\nHowever, other settings need to be considered."}, {"section_title": "Conclusion", "text": "In this paper, we have presented a deep ordinal ranking model for classifying AD's different stages using structural imaging data focusing on the hippocampus, built on CNNs and ordinal ranking techniques. The comparison with the traditional multi-category classification methods based on the ADNI dataset has demonstrated that our method could achieve promising performance, indicating that the utilization of inherent ordinal severity of brain degeneration associated with AD's different stages could help achieve improved classification performance.\nMoreover, the deep learning features of the hippocampus also outperformed hand-crafted imaging features, i.e., shape and radiomics features. Benefiting from the flexible architecture of proposed deep model, the performance of our method might be further improved if multimodality information is taken into account, e.g., PET imaging and CSF biomarkers (Liu et al., 2015a) . Besides classification, our proposed method is also a better fit for regression studies of AD associated clinical score estimation than simple metric regression, since most of the clinical score measures, e.g., mini mental state examination (MMSE), are not continuous variables."}]