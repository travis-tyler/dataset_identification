[{"section_title": "Abstract", "text": "Early detection is a crucial goal in the study of Alzheimer's Disease (AD). In this work, we describe several techniques to boost the performance of 3D convolutional neural networks trained to detect AD using structural brain MRI scans. Specifically, we provide evidence that (1) instance normalization outperforms batch normalization, (2) early spatial downsampling negatively affects performance, (3) widening the model brings consistent gains while increasing the depth does not, and (4) incorporating age information yields moderate improvement. Together, these insights yield an increment of approximately 14% in test accuracy over existing models when distinguishing between patients with AD, mild cognitive impairment, and controls in the ADNI dataset. Similar performance is achieved on an independent dataset. We make our code and models publicly available at"}, {"section_title": "Introduction", "text": "Alzheimer's disease (AD) is the leading cause of dementia, and the 6th leading cause of death in the U.S. (National Center for Health Statistics (2017)). Unfortunately, all clinical trials to reverse AD have failed so far (Servick (2019) ). It is hypothesized that clinical trials need to target patients at earlier stages before significant brain atrophies. But diagnosing the disease at an early stage is challenging. The current method for early detection relies on PET imaging, which is invasive and very costly. Various studies show that AD-related brain degeneration begins years before the clinical onset of symptoms (Jagust (2018) ). This suggests that early detection of AD might be possible from standard structural brain imaging scans. Unfortunately, both clinical and also research-grade detection accuracies remain low.\nIn this paper we focus on learning to differentiate between cognitively normal aging (CN), mild cognitive impairment (MCI), and Alzheimer's disease (AD), using structural brain MRI (T1-weighted scans). We propose a 3D convolutional neural network (CNN) architecture that achieves state-of-the-art performance for this task. The key novel components of the architecture are (1) instance normalization, an alternative to batch normalization introduced originally in the context of style transfer (Ulyanov et al. (2016) ; Huang and Belongie (2017) ), (2) the use of small-sized kernels in the first layer to avoid downsampling, (3) wide architectures with large numbers of filters and relatively few layers, (4) providing the age of the patient to the network through an embedding inspired by a recent technique from natural language processing (Vaswani et al. (2017) ).\nSection 3 describes the data and our preprocessing scheme. Our methodology is then presented in Section 4. In Section 5 we report ablation experiments on the test set to isolate the effect of the different elements in our model, as well as additional analysis of the results. Code to reproduce our main results is publicly available at https://github.com/NYUMedML/ CNN_design_for_AD."}, {"section_title": "Related Work", "text": "An important task in automatic diagnostics of AD is to distinguish patients with different degrees of mental impairment from MRI scans. Initial works applied simple classifiers such as support vector machines on features obtained from volumetric measurements of the hippocampus (Gerardin et al. (2009) ) and other brain areas (Plant et al. (2010) ).\nMore recently, several deep-learning approaches have been applied to this task. Gupta et al. (2013) used pretraining based on a sparse autoencoder to perform classification on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset (ADNI). Hon and Khan (2017) applied state-of-the-art architectures such as VGG (Simonyan and Zisserman (2014) ) and Inception Net ) on the OASIS dataset (Marcus et al. (2010) ), selecting the most informative slices in the 3D scans based on image entropy. Valliani and Soni (2017) , showed that a ResNet (He et al. (2016) ) pretrained on ImageNet (Deng et al. (2009) ) outperformed a baseline 2D CNN. Hosseini-Asl et al. (2016) evaluated a 3D CNN architecture on ADNI and data from the CADDementia challenge (Bron et al. (2015) ). Cheng et al. (2017) proposed a more computationally-efficient approach based on large 3D patches processed by individual CNNs, which are then combined by an additional CNN to produce the output. Lian et al. (2018) proposed a related hierarchical CNN architecture that automatically identifies significant patches. Siamese networks were applied by Khvostikov et al. (2018) to distinguish regions of interest around the hippocampus fusing data from multiple imaging modalities.\nAs described in a recent survey paper, Wen et al. (2019) , many existing works suffer from data leakage due to flawed data splits, biased transfer learning, or the absence of an independent test set. The authors also report that, in the absence of data leakage, CNNs achieve an accuracy of 72-86% when distinguishing between AD and healthy controls. In a similar spirit, Fung et al. (2019) studied the effect of different data-splitting strategies on classification accuracy. A significant drop in test accuracy (from 84% to 52% for the three-class classification problem considered in the present work) was reported when there was no patient overlap between the training and test sets. B\u00e4ckstr\u00f6m et al. (2018) also studied the effect of splitting strategies and report similar results for two-way classification."}, {"section_title": "Datasets and Preprocessing", "text": ""}, {"section_title": "Datasets", "text": "For this study, we use T1-weighted structural MRI scans from the ADNI dataset (Mueller et al. (2005) ), which have undergone specific image preprocessing steps including multiplanar reconstruction (MPR), Gradwarp, B1 non-uniformity correction, and N3 intensity normalization (ADNI (2008)). In total, we used over 3000 preprocessed scans. According to the ADNI procedures manuals, labels in the ADNI dataset are extracted based on the scores obtained on memory tasks-corrected by education level-and other criteria, some of which are subjective (ADNI (2008)). The labels are AD (mildly demented patients diagnosed with AD), MCI (mildly cognitively-impaired patients in the prodromal phase of AD) and CN (elderly control participants)."}, {"section_title": "Data preprocessing", "text": "Most previous studies use packages such as FSL, Statistical Parametric Mapping (SPM), and FreeSurfer (Fischl (2012) ) to preprocess the data. FSL provides brain extraction and tissue segmentation functionality, while SPM realigns, spatially normalizes, and smooths the scans. FreeSurfer provides a preprocessing stream that includes skull stripping, segmentation, and nonlinear registration. For this study, we used the Clinica software platform developed by ARAMIS Lab, which supports FSL, SPM and FreeSurfer. We first split patients into training, validation and test sets. Then we use Clinica to register the scans to a Dartel template computed exclusively from the training data (Ashburner (2007) ), and normalize them to the Montreal Neurological Institute (MNI) coordinate space (Evans et al. (1993) ). The validation and test data are not used to compute any templates in order to avoid data leakage. The input to the Clinica software is the ADNI scans converted to BIDS format. The output dimensions are 121 \u00d7 145 \u00d7 121 voxels along sagittal, coronal and axial dimensions respectively. Due to preprocessing and registration errors, the final number of scans in our dataset is 2702.\nThe subjects in the dataset are split between training (70%), validation (15%) and test (15%) sets. As mentioned in the previous section, the split is carried out before preprocessing to avoid any data leakage. Data leakage resulting from using the same subjects in the training and test sets has been shown to artificially improve model performance by a large margin (B\u00e4ckstr\u00f6m et al. (2018) ; Fung et al. (2019)). Table 1 shows the demographics of the patients in the training, validation, and test sets. Leandrou et al. (2018) ). The features are informative (AD patients tend to have smaller volumes with respect to healthy controls), but they do not enable accurate classification due to the significant overlap between the three classes. This motivates learning discriminative features automatically. Our proposed methodology achieves this using a deep convolutional neural network, inspired by their success in computer vision. However, it is worth emphasizing that our dataset of interest is very different to the datasets of natural images typically used to benchmark computer vision tasks. In our case, all scans are registered and have very similar structure. In addition, the number of examples is usually orders of magnitude smaller. Therefore, we need to design architectures capable of learning subtle differences from relatively small datasets."}, {"section_title": "Methodology", "text": ""}, {"section_title": "Proposed model", "text": "Our proposed architecture is a 3D CNN model, composed of convolutional, normalization, activation and max-pooling layers. The architecture is described in more detail in Table 2 .\nIn this section, we outline several design choices that significantly boost the performance of the network for the task of differentiating between CN, AD, and MCI patients. Instance normalization. Batch normalization, introduced by Ioffe and Szegedy (2015), has become one of the standard techniques to ease training of deep feed-forward networks. In our proposed model, however, we apply instance normalization, a technique introduced in the context of style transfer (Ulyanov et al. (2016) ; Huang and Belongie (2017) ). In Section 5.3.1, we show that applying instance normalization consistently outperforms batch normalization for our task of interest.\nSmall-sized kernels. In contrast to most standard architectures for image classification, we use small-sized kernels in the first convolutional layer to prevent early spatial downsampling."}, {"section_title": "Block", "text": "Layer Type Output size\n3 Softmax 3 Table 2 : The backbone architecture. k = kernel size, c = number of channels as a multiple of the widening factor f , p = padding size, s = stride and d = dilation. We report results for f equal to 1, 2, 4, and 8 in Section 5. The age encoding, if used, is forward propagated through two linear layers with layer normalization before being added to the output of FC1, see Table 6 in the Appendix for details.\nFor instance, ResNet and AlexNet use relatively large kernel sizes and strides in their first layer, which dramatically reduce the spatial dimension of their inputs. This accelerates the computation and is not usually detrimental in the case of natural-image classification tasks. However, for our task of interest, early downsampling results in significant loss of performance, as we show in Section 5.3.2. Wider network. In our architecture design we favor a wider architecture that is not too deep. In Section 5.3.3, we find that increasing the depth of the model only brings marginal gains, whereas widening the architecture improves performance significantly.\nAge encoding. Brains typically shrink to some degree in healthy aging (Peters (2006) ). This might confuse the model since Alzheimer's disease may have a similar effect (Van Hoesen et al. (1991) ). A simple way to incorporate age in our model is to concatenate the normalized age of the patient to the output of the convolutional layers. However, this seems to result in worse performance. In order to better integrate age information, we encode each age value into a vector and combine the vector with the output of the convolutional layers. See Appendix A for further details."}, {"section_title": "Method", "text": "Accuracy Balanced Acc Micro-AUC Macro-AUC\n57.2 \u00b1 0.5% 56.2 \u00b1 0.8% 75.1 \u00b1 0.4% 74.2 \u00b1 0.5% proposed \u2022 66.9 \u00b1 1.2% 67.9 \u00b1 1.1% 82.0 \u00b1 0.7% 78.5 \u00b1 0.7% proposed \u2022 + Age 68.2 \u00b1 1.1% 70.0 \u00b1 0.8% 82.0 \u00b1 0.2% 80.0 \u00b1 0.5%\nResults on 2D ResNets initialized with or without pretrained weights on Imagenet reported by Valliani and Soni (2017) . 3D ResNet with mild modifications, see Fung et al. (2019) for details. The balanced accuracy is computed using the confusion matrix in the paper. \u2022 The backbone model showed in Table 2 with a widening factor of 8. \nAccuracy Balanced Acc Micro-AUC Macro-AUC No age information 66.9 \u00b1 1.2% 67.9 \u00b1 1.1% 82.0 \u00b1 0.7% 78.5 \u00b1 0.7% Proposed age encoding 68.2 \u00b1 1.1% 70.0 \u00b1 0.8% 82.0 \u00b1 0.2% 80.0 \u00b1 0.5% Baseline age encoding 61.5 \u00b1 1.4% 62.6 \u00b1 1.0% 78.6 \u00b1 1.2% 78.3 \u00b1 1.1% Table 7 : Comparison of different ways of incorporating the age information using the proposed architecture."}, {"section_title": "Experiments and Results", "text": "In this section, we present and interpret the results of our study, which demonstrate the effectiveness of the techniques described in Section 4."}, {"section_title": "Description of computational experiments", "text": "We choose AlexNet and ResNet as baseline 3D CNNs since they are popular in computer vision as well as for our task. Unsurprisingly, given the size of the dataset, all architectures, including ResNet and AlexNet, are able to fit the training set with high balanced accuracy, while the generalization ability varies. We perform data augmentation via Gaussian blurring with \u03c3 uniformly chosen from 0 to 1.5, and random cropping of size 96 \u00d7 96 \u00d7 96. We set the batch size to 4 (for memory considerations) and the learning rate to 0.01. We use stochastic gradient descent with momentum equal to 0.9. We use the same settings for AlexNet and ResNet, except for the batch size which is set to 16 since these architectures use batch normalization. After training, the models with the lowest validation loss are saved and evaluated on the test set to obtain the results reported in Table 3 . We compute the confidence intervals using bootstrapping."}, {"section_title": "Comparison to other methods", "text": "Our primary metric in this work is standard classification accuracy (Acc). As the test set is not necessarily balanced, we also use balanced classification accuracy (Bal-Acc) which is calculated as the average of the recall of each class. We also compute area under the ROC curves (AUCs), which are widely used for measuring the predictive accuracy of binary classification problems. This metric indicates the relationship between the true positive rate and false positive rate when the classification threshold varies. As AUC can only be computed for binary classification, we compute AUCs for all three binary problems of distinguishing between one of the categories and the rest. We also calculate micro and macro averages, denoted as Micro-AUC and Macro-AUC respectively. Table 3 summarizes our results. Our proposed model significantly outperforms previously reported results 1 , as well as the baseline architectures. Incorporating age through the proposed encoding improves performance moderately. We show the ROC curves obtained on the validation and test set in Figure 2 . The model achieves around 90% AUC when distinguishing CN or AD from the other two classes, and 60 \u2212 65% when distinguishing MCI from the other two classes."}, {"section_title": "Ablation studies", "text": "In this section, we perform ablation studies on the techniques described in Section 4 to isolate their individual contributions to the accuracy of the proposed model. The studies were performed on the test set."}, {"section_title": "Instance normalization vs batch normalization", "text": "We compare batch normalization (BN) and instance normalization (IN) on the backbone architecture using different widening factors and on ResNet-18. The results are in Table 4 . More comprehensive evaluations on different widening factors are presented in Table 8 "}, {"section_title": "Early spatial downsampling", "text": "Here we study how the kernel size of the first convolutional layer affects the final classification performance. We compare original kernel sizes 1 \u00d7 1 \u00d7 1 with stride 1, 3 \u00d7 3 \u00d7 3 with stride 2, and 7 \u00d7 7 \u00d7 7 with stride 4. The results are summarized in Figure 3 . The smallest kernel has the best performance. This is a possible explanation for the inferior performance of ResNet and AlexNet for our task. We further check this hypothesis for ResNet, the results show that reducing kernel size for the initial layer is effective for ResNet as well (see details in Appendix C). Figure 3 : Comparison of the performances of different first layer kernel sizes for the backbone architecture in Table 2 . Larger kernel sizes in the first layer result in worse performance."}, {"section_title": "Wider or deeper model?", "text": "In this section we compare the effect of varying width or depth on classification accuracy. The left graph in Figure 4 shows that widening the network architecture leads to better classification performance up until a certain point. This finding is in line with results reported for the ResNet by Zagoruyko and Komodakis (2016) . We increase the depth of our backbone network by adding convolutional blocks (convolutional layers + instance normalization + ReLU activation). It should be noted that the size of the representation output from the final convolutional block might decrease when the network becomes deeper. To control for the effects of the representation size when making the architecture deeper, convolutional layers in each block are set to have kernel size of 3 \u00d7 3 \u00d7 3, stride of 1 and padding of 1. Increasing depth only achieves small gains in accuracy. We also observe that deeper networks are often slower and more difficult to train when compared to wider networks."}, {"section_title": "Impact of dataset size", "text": "In Figure 5 , we report the performance of the proposed model for datasets of different sizes (obtained by randomly subsampling the data). We observe that increasing the size of the dataset results in better performance in all evaluation metrics. Given that the model is trained on a very small dataset compared to regular computer-vision tasks, more data may be needed to exhaust the representation ability of the models. Figure 4 : Performance for different widening factors (left) and numbers of added blocks (right) for backbone architecture in Table 2 . Wider architectures consistently achieve better performance up until a widening factor of x4. Deeper networks only achieve marginal improvement. Figure 5 : Performance of the proposed model evaluated using different subsampling rates. The trend is clear: increasing dataset size improves performance across all evaluation metrics."}, {"section_title": "Width Depth", "text": ""}, {"section_title": "Validation with independent dataset", "text": "We test the generalization capacity of our model on a completely separate dataset, obtained from the Australian Imaging Biomarkers and Lifestyle flagship study of ageing (AIBL) (Ellis et al. (2009) ). We follow the same preprocessing procedures as for the ADNI validation and test set (described in Section 3), being careful to avoid any data leakage. After preprocessing, we obtain 783 CN scans from 461 subjects with average age 73.5, 150 MCI scans from 113 subjects with average age 76.2, and 134 AD scans from 95 subjects with average age 75.4. The results are shown in Table 5 . We apply our proposed architecture without age information, since this information may not be readily available for different datasets. The model achieves a similar performance on this independent dataset as on the ADNI data, which demonstrates that the features learned by the network generalize effectively.\nMethod Accuracy Balanced Acc Micro-AUC Macro-AUC proposed on ADNI 66.9 \u00b1 1.2% 67.9 \u00b1 1.1% 82.0 \u00b1 0.7% 78.5 \u00b1 0.7% proposed on AIBL 63.6 \u00b1 0.7% 65.7 \u00b1 1.1% 90.0 \u00b1 0.6% 82.1 \u00b1 0.7% Table 5 : Comparison of the performance of the proposed model on the ADNI and AIBL datasets.\n6. Analysis"}, {"section_title": "Analysis of wrongly-classified subjects", "text": "We analyze the wrongly-classified validation examples in Figure 6 . Mini-Mental State Exam (MMSE) scores (with value ranges from 0 to 30) are widely used tools for detecting cognitive impairment, assessing severity, and monitoring cognitive changes over time. Lower scores often mean more cognitive impairment. The model's output after the softmax layer (logits) can be viewed as the confidence of the model in predicting a class. The trend in the figure shows that for higher MMSE scores the model becomes more confident in predicting CN, and less confident in predicting AD. Since the criteria to assign labels are subjective, and the boundary between MCI and the other two classes is not always clear, it is possible that some of the classification errors are due to noise in the labels. "}, {"section_title": "Opening the black box", "text": "In order to visualize the features learned by the model, we compute saliency maps consisting of the magnitude of the gradient of the target class score with respect to the input (Simonyan et al. (2013) ). Figure 7 shows examples of these saliency maps for randomly selected scans in the validation set belonging to each class. It also shows aggregated maps that combine saliency maps from all scans in the validation set. These results reveal some interesting aspects of the proposed model: the model focuses on gray-matter regions around the hippocampus and the ventricles, which is consistent with existing biomarkers (Risacher and Saykin (2013)), as well as on some additional regions. A detailed study of these regions lies beyond the scope of this work, but is an intriguing direction for future research."}, {"section_title": "Axial 50th", "text": "Axial 26th "}, {"section_title": "Conclusion", "text": "In this paper, we develop a novel 3D CNN architecture to perform three-way classification between patients with Alzheimer's disease, patients with mild cognitive impairment, and healthy controls. Our architecture combines different elements (instance normalization, wider layers, and an encoding of the patient's age) to achieve a significant gain in classification accuracy, demonstrated on completely held-out data and on an independent dataset."}, {"section_title": "Appendix A. Age encodings", "text": "To compute the age encoding vector, we first fix the age values range from 0 to 120 years old, and round all possible age values to 0.5 decimal places. In total, we get 240 possible age values. Inspired by the positional encoding in the transformer model (Vaswani et al. (2017) ), we use sinusoidal functions to implement the encoding. We define AE (age) \u2208 R d model to be the age encoding function defined as:\nAE (age,2i) = sin(age/10000 2i/d model )\nAE (age,2i+1) = cos(age/10000 2i/d model )\nwhere age is one of the 240 possible age values,and i = 0, 1, 2, . . . , d model /2\u22121 is the dimension and d model is the size of the encodings. We further transform the age encodings using a few fully connected layers to match the scales and sizes with the visual representation. The architecture for the transformation is showed in Table 6 ."}, {"section_title": "Layer Output size", "text": "Linear 512 LayerNorm 512 Linear 1024 We compare this method with a simple baseline. In the baseline, we directly concatenate normalized age (with range from 0 to 1) to the learned representation obtained from the convolutional layers. The results are in Table 7 . Our proposed encoding results in improved performance, whereas the baseline encoding results in worse performance."}, {"section_title": "Appendix B. Instance Normalization vs Batch Normalization", "text": "In "}]