[{"section_title": "Abstract", "text": "To acquire larger samples for answering complex questions in neuroscience, researchers have increasingly turned to multi-site neuroimaging studies. However, these studies are hindered by differences in images acquired across different scanners, so-called scanner effects, in the raw images and derived measurements. These effects have been shown to bias comparison between scanners, mask biologically meaningful associations, and even introduce spurious associations. To address this, the field has focused on harmonizing data via removing the scanner differences in mean and variance of measurements. Contemporaneously with the increase in popularity of multi-center imaging, the use of multivariate pattern analysis (MVPA), which refers to machine learning and multivariate statistical techniques for group comparisons or predictive modeling, has also become commonplace. These approaches have been shown to provide improved sensitivity, specificity, and power due to their modeling the joint relationship across measurements in the brain. In this work, we demonstrate that these currently available methods for removing site effects are inherently insufficient for MVPA. This stems from the fact that no currently available harmonization approach has addressed how correlations between measurements can vary across sites. Using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, we show that considerable differences in covariance exist across sites, and that the state-of-the-art harmonization techniques do not address this issue. We also propose a novel methodology that harmonizes covariance of multivariate image measurements across sites and demonstrate its improved performance in data harmonization, which further facilitates more power for detection of clinically relevant associations. * Equal contribution \u2020 Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at:"}, {"section_title": "Introduction", "text": "The need for larger samples in human subjects research have led to a growing number of multi-site studies that aggregate data across different locations and scanners. This trend is especially prevalent in neuroimaging research where the reliability and generalizabilty of findings from the conventional single-site studies are often limited by the amount of resources, types of scanners, and the ability to reach representative patient populations. Several collaborative studies have been formed to address such issues (Mueller et al., 2005; Sudlow et al., 2015; Trivedi et al., 2016; Van Essen et al., 2013) . The larger samples obtained through these efforts promotes greater power to detect significant associations as well as better generalizability of results across diverse populations. However, these study designs also introduce heterogeneity in equipment and data preprocessing steps that, if not appropriately addressed, may impact study findings.\nSeveral researchers have determined that variability driven by site, often called site effects, reduce the reliability of derived measurements and can introduce bias. In the field of neuroimaging, investigators are mainly concerned with scanner effects, which are induced by differences in the scanners used for data acquisition. Neuroimaging measurements have been repeatedly shown to be affected by scanner manufacturer, model, magnetic field strength, head coil, voxel size, and acquisition parameters (Han et al., 2006; Kruggel et al., 2010; Reig et al., 2009; Wonderlick et al., 2009) . Even in scanners of the exact same model and manufacturer, differences still exist for certain neuroimaging biomarkers (Takao et al., 2011) .\nPreviously, neuroimaging analyses primarily involved mass univariate testing which treated features as independent. Under this paradigm, the impact of site effects is mainly through changes in the mean and variance of measurements. Recently, researchers have increasingly used entire sets of features as patterns for prediction algorithms in a framework called multivariate pattern analysis (MVPA). This approach has become a powerful tool in diverse research topics including pain perception (Smith et al., 2017) , neural representations (Haxby et al., 2014) , and psychiatric illnesses (Koutsouleris et al., 2014) . One of the major benefits of this approach is the ability to leverage the associations between brain features in order to better characterize a phenotype of interest (O'Toole et al., 2007) . As a result, site effects on the covariance of measurements are likely to impact findings substantially. In fact, a recent investigation showed that MVPA was able to detect site with high accuracy and that the detection of sex depended heavily on the sites of training and test data (Glocker et al., 2019) .\nThe main statistical harmonization techniques employed in neuroimaging have generally corrected for differences across sites in mean and variance, but not covariance (Fortin et al., 2016 (Fortin et al., , 2018 Rao et al., 2017; Yamashita et al., 2019) Increasingly, the ComBat model (Johnson et al., 2007) has become the state-of-art harmonization techniques in neuroimaging and have been successfully applied to structural and functional measures (Bartlett et al., 2018; Fortin et al., 2017 Fortin et al., , 2018 Marek et al., 2019; Yu et al., 2018) . However, this model also does not address potential site effects in covariance. Recently, another stream of data-driven harmonization methods have aimed to apply machine learning algorithms such as generative adversarial network (GAN) or distance-based methods to unify distributions of measurements across sites, but these methods shift the original data distributions inexplicitly and have not been tested for their potential influence on MVPA (Nguyen et al., 2018; Zhou et al., 2018) .\nIn this paper, we examine if site effects influence MVPA results. In particular, we study the cortical thickness measurements derived from images in the Alzheimer's Disease Neuroimaging Initiative (ADNI) and demonstrate the existence of scanner effects in covariance of structural imaging measures. We then propose a novel harmonization method, Correcting Covariance Batch Effects (CovBat), inspired by the work of Johnson et al. (2007) , that removes scanner effects in mean, variance, and covariance. We then apply CovBat and show that within-site correlation matrices are successfully harmonized. Furthermore, we find that machine learning methods are unable to distinguish scanner manufacturer after our proposed harmonization is applied, and that the harmonized data facilitate more accurate prediction of disease group. We also assess the performance of the proposed method in simulated data, and again find that the method mitigates scanner effects and improves detection of meaningful associations. Our results demonstrate the need to consider covariance in harmonization methods, and suggest a novel procedure that can be applied to better harmonize data from multi-site imaging studies."}, {"section_title": "Site Identified Despite Existing Harmonization", "text": "We first examine a subset of the ADNI dataset to determine if covariance among cortical thickness measurements differs across scanners. Our data were obtained from the ADNI-1 database which contained magnetization-prepared gradient echo (MP-RAGE) from Siemens and Philips scanners or a similar works-in-progress MP-RAGE sequence for General Electric (GE) scanners (Jack et al., 2010) . All of these scans were collected at a magnetic field strength of 1.5 Telsa and there were a total of 90 scanners across 58 locations. The T1 images were processed using the ANTs cross-sectional cortical thickness pipeline (Tustison et al., 2019) . Lastly, the cortical thickness measures were derived from the pre-processed images as the average thickness in 62 cortical regions, 31 in each hemisphere, defined through the Desikan-Killiany Atlas (Klein & Tourville, 2012) .\nTo investigate the potential impact of site differences in covariance using MVPA, we conducted an experiment to predict scanner manufacturer labels using data harmonized with existing methods. In particular, we use a Monte Carlo split-sample experiment including data acquired on any scanner used to image three or more subjects. This sample consists of 505 subjects across 64 scanners, with 213 subjects acquired on scanners manufactured by Siemens, 70 by Philips, and 222 by GE. Using the 62 cortical thickness values as inputs, we i) randomly split the sample into 50% training data and 50% testing data; ii) train a random forests algorithm to recognize if a scanner was manufacturered by Siemens, and iii) assess predictive performance on the testing data. We train it using data harmonized via the existing ComBat method and our proposed method CovBat. For all tests, we accounted for the possibility that scanner could be detected through the covariates age, sex, and disease status by residualizing out those variables. We repeat steps (i)-(iii) 100 times and report the area under the receiver operating characteristic curve (AUC) values. Figure 1 shows that Siemens scanners are highly identifiable based on unharmonized cortical thickness measurements (AUC 0.89 \u00b1 0.02) and still detected after ComBat is applied (0.66 \u00b1 0.03). After our method, chances of distinguishing Siemens scanners are close to random (AUC 0.53 \u00b1 0.03). "}, {"section_title": "Combatting Batch Effects", "text": "The current standard in harmonization of neuroimaging measures is a method called ComBat developed by Johnson et al. (2007) and first applied to neuroimaging data by Fortin et al. (2017) . This method seeks to remove the mean and variance scanner effects in the data in an empirical Bayes framework. Let y ij = (y ij1 , y ij2 , . . . , y ijp ) , i = 1, . . . , M , j = 1, . . . , n i denote the p \u00d7 1 vectors of observed data where p is the number of features. Our goal is to harmonize these vectors across the M scanners indexed by i. ComBat assumes that the features indexed by v follow\nwhere \u03b1 ijv is the intercept, x ij is the vector of covariates, \u03b2 v is the vector of regression coefficients, \u03b3 iv is the mean scanner effect, and \u03b4 iv is the variance scanner effect. The errors e ijv are assumed to follow e ijv \u223c N (0, \u03c3 2 v ). ComBat then uses empirical Bayes point estimates \u03b3 iv as \u03b3 * iv and \u03b4 iv as \u03b4 * iv and residualizes with respect to these estimates to obtain"}, {"section_title": "Correcting Covariance Batch Effects", "text": "We propose the CovBat algorithm by accounting for the joint distribution of the ComBatadjusted observations as follows:\nStep 1. We first perform ComBat to remove the mean and variance shifts in the marginal distributions of the cortical thickness measures and additionally residualize with respect to the covariates to obtain ComBat-adjusted residuals e ij = (e ij1 , e ij2 , . . . , e ijp ) where\nStep 2. The e ComBat ij are assumed to have mean 0; their covariance matrices which we denote by \u03a3 i , however, may differ across scanners. We thus perform principal components analysis (PCA) on the full dataset to obtain the full-data covariance matrix as \u03a3 = p k=1 \u03bb k \u03c6 k \u03c6 T k . The ComBat-adjusted residuals can then be expressed as e ComBat ij = p k=1 \u03be ijk \u03c6 k , where the \u03bb k are the eigenvalues of \u03a3, \u03c6 k are the principal components obtained as the eigenvectors of \u03a3, \u03be ijk are the principal component scores, and K < p is chosen to capture the majority of the variation in the observations. After applying this decomposition, the site-specific covariance matrices can be approximated in the full data eigenspace as\nwhere \u03bb ik are site-specific eigenvalues. This model assumes that the covariance site effect is contained within the \u03bb ik , which can be approximated as the sample variance of the principal component scores \u03be ijk .\nStep 3. Thus, we posit:\nwhere ijk \u223c N (0, \u03c4 2 k ) and \u00b5 ik , \u03c1 ik are the center and scale parameters corresponding to each principal component indexed by k. Note that this is analogous to the ComBat model, applied to each of the k principal component scores instead of the original measures. After imposing a prior on each parameter, we can then estimate each of the k pairs of center and scale parameters by finding the values that bring each site's mean and variance in scores to the pooled mean and variance. We then remove the site effect in the scores by residualizing via\n. Finally, we obtain CovBat-adjusted residuals by projecting the adjusted scores back into the residual space via e CovBat\nWe then add the intercepts and covariates effects estimated in Step 1 to obtain CovBat-adjusted observations"}, {"section_title": "Harmonization Evaluation", "text": "We focus our evaluation framework on removal of scanner effects in covariance rather than mean and variance which have been shown to be addressed by ComBat in previous papers (Fortin et al., 2017 (Fortin et al., , 2018 . Hence, we propose tests that directly assess harmonization of correlation matrices across sites. Furthermore, we assess the degree to which residual scanner effects can affect comparison between sites and clinically meaningful associations.\nTo assess scanner effects in covariance, we examine the correlation matrices before and after harmonization. Additionally, we quantify the similarity of correlation matrices between scanners by looking at the pairwise Frobenius norms. For this measure, lower values indicate greater harmonization in covariance.\nWe also evaluate if the harmonization procedures affect the results of MVPA using the neuroimaging measures as patterns. Similar to the earlier experiments in Section 4 for classifying scanner, we i) randomly split the subjects into 50% training set and 50% validation set; ii) train a random forests algorithm to detect a binary clinical covariate, and iii) assess predictive performance on the validation set via AUC. We train separate models for unharmonized, ComBat-harmonized, and CovBat-harmonized data where both harmonization methods are performed including age, sex, and diagnosis status as covariates. We perform these steps (i)-(iii) 100 times and again report the AUC values. For these experiments, higher AUC would indicate greater ability to recover biologically meaningful associations."}, {"section_title": "CovBat Reduces Covariance Scanner Effect", "text": "We apply CovBat to observations from the three sites with the largest number of subjects. Site A collected images on a Siemens Symphony 1.5T scanner while sites B and C both acquired images on GE Signa Excite 1.5T. The demographics for these subjects are shown in Table 2 . Note that demographic variables differ across sites so we residualize each cortical thickness measure on age, sex, and diagnosis status to obtain the correlation structure independent of these clinical covariates. Figure 2 shows the correlation matrices for each site using the residualized cortical measures both before and after CovBat. The differences between the correlation matrices are striking. Especially notable are the increased positive correlations across most pairs of cortical regions in site A and the weakened right-left correlations in site C visible as the diagonal line in the top-left and bottom-right quadrants. Visually, the correlation structures are considerably more similar across sites after CovBat; Sites A and B are almost indistinguishable after this adjustment.\nWe also compare with harmonization via ComBat, and report our quantitative results for ComBat-adjusted as well as CovBat-adjusted correlation matrices in Table 1 . A tuning parameter of the CovBat model is the desired proportion of variance explained in the dimension reduction space, which we selected at 80% (26 PCs). To ensure that our results do not depend strongly on the choice of tuning parameter, we also report the minimum and maximum of the pairwise Frobenius norms after applying CovBat with percent variation explained ranging from 50% (10 PCs) to 99% (53 PCs). We report the results of this sensitivity analysis in parentheses. We find that ComBat adjustment does not harmonize the correlation matrices whereas CovBat adjustment shows large reductions in the between-scanner distances. "}, {"section_title": "Original ComBat", "text": ""}, {"section_title": "CovBat Recovers Biological Associations", "text": "It is well-known that cortical thickness differs substantially by sex and Alzheimer's disease status (Lerch et al., 2005; Sowell et al., 2007) . To assess whether CovBat maintains biological associations of interest, we perform two MVPA experiments using random forests to classify healthy versus Alzheimer's disease (AD) and to differentiate patients by sex. Figure 3 shows that detection of these biological differences is considerably improved by either harmonization method, but the proposed CovBat approach shows an even greater performance improvement. For detection of AD, the mean AUC increases from 0.74 (\u00b10.03) in raw data to 0.78 (\u00b10.03) in ComBat-harmonized data to 0.79 (\u00b10.03) in CovBat-harmonized data. Similarly, the mean AUC for detection of sex increased from 0.66 (\u00b10.03) to 0.69 (\u00b10.03) to 0.70 (\u00b10.03). These findings suggest that CovBat not only provides thorough removal of scanner effects, but also helps to recover clinical associations. "}, {"section_title": "Findings Replicated in Simulations", "text": "To test our harmonization method, we create simulated datasets based on a modified version of the ComBat model which includes site effects in covariance. Essentially, we impose mean and variance site effects on a ground truth multivariate normal distribution and additionally modify the covariance matrix of this distribution by site. To achieve the latter, we add high-rank site-specific matrices to the underlying true covariance matrix to ensure that the site effect can be corrected through adjustment in PC scores, but also requires harmonization of a sufficiently high number of PCs. To test detection of a simulated covariate, we impose that distribution of the outcome measures depends on the presence of a binary covariate drawn from a Bernoulli distribution. Our simulations consisted of three sites each with 100 simulated subjects with a binary covariate drawn from a Bernoulli(0.25) distribution. We have the covariate associated with a decrease in the mean of the cortical thickness values for 15 ROIs in both hemispheres. Additional details are available in SI Appendix S.2."}, {"section_title": "Covariate Effect on Mean", "text": "In the first scenario where the covariate does not influence the covariance, we anticipate that harmonization of mean and variance is sufficient to remove any confounding of site effect with the association of interest. We also anticipate that detection of site via MVPA should be improved by harmonization of covariance. We perform experiments to test these hypotheses under the same paradigm as the MVPA experiments implemented on the ADNI dataset and report the results in Figure 4 . The results show that both ComBat (AUC 0.59 \u00b1 0.04) and CovBat (0.54 \u00b1 0.04) underperform the raw data (0.63 \u00b1 0.05) for detection of the simulated covariate, which could be attributable to imperfect residualization on the covariate prior to mean harmonization. As for detection of site, we find that Site 1 is almost perfectly detected in the raw data (AUC 0.9991 \u00b1 0.001), obscured after ComBat (0.58 \u00b1 0.05) and almost impossible to detect after CovBat (0.53 \u00b1 0.03)."}, {"section_title": "Covariate Effect on Covariance", "text": "In the second simulation scenario, we study the impact of an additional covariate effect on variance and covariance that is guaranteed to be confounded with the site effects. To achieve this, we allowed the covariate effect on covariance to be proportional to a chosen site's covariance shift (see SI Appendix S.2 for details). This scenario represents a situation where detection of the covariate using MVPA would be highly influenced by the presence of site effects. This is because without harmonization of covariance, subjects in the chosen site would be mistaken for subjects with the covariate. Consequently, we expect that ComBat alone would be insufficient to recover the covariate association and that CovBat would outperform on this metric. We again anticipate that detection of site should be further improved by CovBat. The results of the MVPA experiments are shown in Figure 4 . As anticipated, we observe that the mean AUC using the raw data is the lowest (0.85 \u00b1 0.03), ComBat shows some performance increase, (0.85 \u00b1 0.04), and CovBat performs the best (0.88mean \u00b1 0.02). Detection of site also follows our predictions such that Site 1 is almost perfectly detected in the raw data (AUC 0.9987 \u00b1 0.001), difficult to detect after ComBat (0.59 \u00b1 0.05) and near impossible to detect after CovBat (0.53 \u00b1 0.03)."}, {"section_title": "Discussion", "text": "The growing number of multi-site studies across diverse fields has urged the development of harmonization methods that are generalizable, but also account for field-specific challenges. In neuroimaging research, the rise of MVPA has established an unmet need for harmonization of covariance. We demonstrated that strong scanner effects in covariance exist and could influence downstream MVPA experiments, which remain after performing the state-of-the-art harmonization. We then proposed a novel method demonstrated to be effective in removing site differences in covariance and improving the detection of biological associations via MVPA. Simulation studies further replicated these observations, and suggest that the improvement in covariate detection could be linked to confounding between site effect and covariate effect on the covariance between multivariate measurements. This finding suggests that future work could aim to control for covariate effects on variance and covariance so that harmonization does not remove desired properties of the data. "}, {"section_title": "Supporting Information Appendix (SI)", "text": ""}, {"section_title": "Details of ADNI dataset", "text": "All data for this paper are obtained from ADNI (http://adni.loni.usc.edu/ and processed using the ANTs longitudinal cortical thickness pipeline (Tustison et al., 2018) with code available on GitHub (https://github.com/ntustison/CrossLong). We briefly summarize the steps involved. First, raw MP-RAGE or the equivalent sequence for GE scanners are downloaded from the ADNI-1 database. The images are first processed using the ANTs cross-sectional cortical thickness pipeline (Tustison et al., 2014) , which involves N4 bias correction, brain extraction, Atropos n-tissue segmentation, and registration-based cortical thickness estimation. Then, a single-subject template is created for each individual using all of their repeated scans, and the template is subsequently used in rigid registration of the subject's images. For our analyses, we only use the cortical thickness values of the baseline scans.\nWe define site based on information contained within the Digital Imaging and Communications in Medicine (DICOM) files for each scan. Specifically, subjects are considered to be in the same site if they share the same location of scan, scanner manufacturer, scanner model, head coil, and magnetic field strength. In total, this definition yields 142 distinct sites of which 78 had less than three subjects and were removed from analyses.\nThis subsample of 505 subjects have a mean age of 75.3 (SD 6.70) and is comprised of 278 (55%) males, 115 (22.8%) Alzheimer's disease (AD) patients, 239 (47.3%) late mild cognitive impairment (LMCI), and 151 (29.9%) cognitively normal (CN) individuals. For the subsample comprised of the three largest sites in the dataset, their demographics are listed in Table 2 . Since the correlations between cortical thickness values are of primary interest in our study, we display the correlation matrices annotated with the 62 regions of interest (ROIs) in Figure 5 . "}, {"section_title": "Simulation Design", "text": "Let y ij , i = 1, 2, 3, j = 1, . . . , 100 be vectors of length 62 representing the simulated outcome for cortical thickness values in 62 regions. The y ij are generated using the following model: where \u03b3 i = (\u03b3 1 , \u03b3 2 , . . . , \u03b3 62 ) are vectors of region-specific mean shift drawn from i.i.d. standard normal distributions and \u03b4 i = (\u03b4 1 , \u03b4 2 , . . . , \u03b4 62 ) are vectors of region-specific scale shifts drawn from i.i.d. site-specific inverse gamma distributions with chosen parameters. For our simulations, we chose to sufficiently distinguish the site-specific scaling factors by assuming \u03b4 1v \u223c Inverse Gamma(2, 0.5), \u03b4 2v \u223c Inverse Gamma(3, 1), and \u03b4 3v \u223c Inverse Gamma(4, 2) for v = 1, 2, . . . , 62. The error terms e ij \u223c N(0, \u03a3 + \u2126 i + \u03bax ij \u03a8) where \u03a3 is the sample covariance matrix of Site B from Section 6, x ij is a single binary covariate, \u03ba is a chosen constant, \u2126 i are site-specific covariance shift matrices, and \u03a8 is a chosen covariance shift matrix which can be similar to any of the \u2126 i . To ensure that the covariance matrices are positive semi-definite, we set the negative eigenvalues equal to a small constant, 10 \u221212 . This method for inducing covariance site effects ensures flexibility in the direction, complexity, and confounding of the effect. In the first simulation setting, we assume that the covariate only affects the mean of the measurements. We choose \u03b2 = \u22120.5 for 15 regions of interest in both the left and right hemispheres to impose that about half of the ROIs are negatively associated with the covariate. We also choose \u03ba = 0 to ensure that each site-specific covariance matrix only depends on the underlying true covariance matrix \u03a3 and the chosen \u2126 i matrices. The covariance matrices across sites are shown in Figure 6 with associated pairwise Frobenius norms listed in Table 3 Table 3 : Pairwise Frobenius norms between site-specific correlation matrices for simulations with no effect of covariate on covariance Figure 6 : Correlation matrices following harmonization for simulations with no effect of covariate on covariance\nIn the second simulation setting, we assume that the covariate affects not only mean, but also variance and covariance. To achieve this, we use the same \u03b2 value as above but choose \u03ba = \u22120.5 and \u03a8 to be equal to \u2126 2 to force confounding of site and covariate effects on covariance. The simulation findings are shown to be consistent with findings from the ADNI data application. To better illustrate the effects of harmonization, we plot the stratified covariance matrices for subjects whose binary covariate equals 0 or 1, before and after CovBat in Figure 7 . We observe that CovBat harmonization leads to better differentiation between the two subject groups. Meanwhile the differences across sites are much smaller after CovBat as evident in Figure 8 and "}, {"section_title": "ADNI Acknowledgements", "text": "The majority of the data used in this paper are derived from the ADNI study. Data collection and sharing for this project was funded by the Alzheimer's Disease Neuroimaging "}]