[{"section_title": "", "text": "Finally, we would also like to thank those members of the staff of the National Center for Education Statistics who have worked closely with us on this project: Jeffrey A. Owings, Chief of the Longitudinal and Household Studies Branch, who served as the Project Officer for the base year study from its inception; and Anne Hafner, the Project Officer for the first follow-up of NELS:88, for her assistance in the development of the composite variables. Thanks go also to Ralph Lee, Jerry West, Teresita Kopka, and Peggy Quinn.  The student constitutes the basic t nit of analysis in the NELS:88 design. All other data sets, including the parent, teacher, and school, are intended primarily to supplement the student data, (Additional information about the NELS:88 base year sample design is provided in Chapter III and in the NELS:88 Base Year Sample Design Report.)2 Even though data for each respondent population can be analyzed separately, only the student and school data sets constltute fully representative national samples. While in various respects the parent data set resembles a representative or probability sample of the parents of (eligible) eighth graders in the United States in the spring of 1988, several features of the NELS:88 parent component depart from the strict requirements of a probability sample. For example: some unknown number of parents had more than one eighth grader and therefore more than one chance of selection into the sample; also, the parent respondent was self-selected, and only one parent or guardian could participate. Finally, parents of student nonparticipants have been systematically excluded from the parent data file. Thus, only if the student completed the student questionnaire was a completed parent questionnaire included on the public release tape. (Restriction of parent eligibility to parents of participating students was also a feature of the HS&B parent survey.) Again, the primary purpose of the parent data file is to provide student-related contextual information that can be linked to individual records on the NELS:88 student file. While parent data may be weighted for separate analyses, a separate weight adjusted for parent nonresponse was not included on either the student or parent data files. A close approximation of weighted parent values can be computed by applying the base year student weight to parent responses. (An explanation of how to produce population estimates using the parent file student weights appears in Chapter VII.) In the pages that follow, the parent component user's manual provides guidance and complete documentation to the parent public release data tape for the base year of NELS:88. This manual also provides background information about the purposes of NELS:88, and about its survey instruments, sample design, and data collection and processing procedures."}, {"section_title": "1.3", "text": ""}, {"section_title": "Organization of the Data User's Manuals", "text": "Four manuals have been produced for the NELS:88 base year study, one to accompany each of the four public release data tapes--the student, parent, teacher, and school manuals. Each is designed to provide the user with general information and documentation, as well as information and documentation for use with a specific public release data tape. Thus, a user can consult any one of the manuals and find that many of the same topics are covered. This redundancy was deliberately built into each manual in order to minimize the user's need to consult more than one manual and because some analysts might be interested in one particular data tape but not the others. 1.4 Overview"}, {"section_title": "NCES's National Education Longitudinal Studies Program", "text": "The U.S. Department of Education's National Center for Education Statistics (NCES) is mandated to \"collect and disseminate statistics and other data related to education in the United States\" and to \"conduct and publish reports on specific analyses of the meaning and significance of such 2 Spencer, Frankel, Ingels, Rasinski, and Tourangeau, NELS :88 Base Year Sample Design Report (see note 1)."}, {"section_title": "2", "text": "Base Year: Parent Component Data File User's Manual statistics\" (Education Amendments of 1974-Public Law 93-380, Title V, Section 501, amending Part A of the General Education Provisions Act). Consistent with this mandate and in response to the need for policy-relevant, time-series data on nationally representative samples of elementary and secondary students, NCES instituted the National Education Longitudinal Studies (NELS) program, a continuing long-term project. The general aim of the NELS program is to study the educational, vocational, and personal development of students at various grade levels, and the personal, familial, social, institutional, and cultural factors that may affect that development. The NELS program currently consists of three major studies: the National Longitudinal Study of the High School Class of 1972 (NLS-72); High School and Beyond (HS&B); and the National Education Longitudinal Study of 1988 (NELS:88). Taken together, these studies represent the educational experience of youth from three decades --the 1970s, 1980s, and 1990s. Figure 1-1 illustrates the increasing number of issues that have become part of NCES's Na-tional Education Longitudinal Studies research agenda. A brief description of these studies is followed by a review of NELS:88."}, {"section_title": "The National Longitudinal Study of the 1970s: NLS-72", "text": "The first of the NELS projects, the National Longitudinal Study of the High School Class of 1972 (NLS-72), began in the spring of 1972 with a survey of a national probability sample of 19,001 seniors from 1,061 public, secular private, and church-affiliated high schools. The sample was designed to be representative of the approximately three million high school seniors in more than 17,000 schools in the spring of 1972. Each sample member was asked to complete a student questionnaire and a 69-minute test battery. School administrators were also asked to supply survey data on each student, as well as information about the schools' programs, resources, and grading systems. Five follow-ups, conducted in 1973, 1974, 1976, 1979, and 1986, have been completed. At the time of the first follow-up, an additional 4,450 students from the class of 1972 were added to the sample. Through intensive locating and tracking efforts, 13,912 of the 1972 base year respondents and 17,928 participants in the expanded first follow-up sample responded to the fourth follow-up in 1979. The fifth follow-up included 12,841 participants from a subsample of 14,489 respondents who participated in the base year or one of the subsequent follow-ups. In addition to background information, the NLS-72 base year and follow-up surveys collected data on respondents' educational activities, such as schools attended, grades received, and degree of satisfaction with their educational institutions. Participants were also asked about work experiences, periods of unemployment, job satisfaction, military service, marital status, and children. Attitudinal information on self-concept, goals, participation in political activities, and ratings of their high schools are other topics for which respondents have supplied information.   1.4.3 High School and Beyond of the 1980s: HS&B"}, {"section_title": "13", "text": "The next major longitudinal study sponsored by NCES was High School and Beyond (HS&B). HS&B was initiated in order to capture changes that had occurred in education-related and more general social conditions, in federal and state programs, and in the needs and characteristics of students since the time of the earlier survey. Such changes have been particularly prominent over the last decade and are clearly continuing. Thus, HS&B was designed to maintain the flow of education data to policymakers at all levels who need to base their decisions on information that is reliable, relevant, and current. Base year data collection was conducted by NORC in the spring of 1980. Students were selected using a two-stage probability sample with schools as the first-stage units and students within schools as the second-stage units. There were 1,015 public, private, and church-affiliated secondary schools in the sample and a total of 58,270 participating students. Unlike NLS-72, HS&B included cohorts of both tenth graders and twelfth graders. Since the base year data collection in 1980, three follow-ups of the HS&B cohorts have been completed, one in the spring of 1982, one in the spring of 1984, and the last in the spring of 1986. The four NELS survey cohorts (NLS-72 seniors, the HS&B seniors and sophomores, and NELS:88 eighth graders) are displayed in Figure 1-2 according to their initial and subsequent survey years and their modal age at the time of each survey. As illustrated, NLS-72 seniors were first surveyed in 1972 at age eighteen and have been resurveyed five times since, with the last survey occurring in 1986 when these young adults were about thirty two years of age. The HS&B cohorts have been surveyed at points in time that would permit as much comparison as possible with the time points selected for NLS-72. NELS:88 is also designed to fit into this larger analytical scheme. By beginning with a cross-section of 1988 eighth graders, following a substantial subsample of these students in 1990 and thereafter, and freshening the 1990 and 1992 samples, NELS:88 will provide a point of comparison with the high school classes of 1980 and 1982, and the high school class of 1972 (NLS-72). To facilitate cross-cohort comparisons, many of the content areas contained in the HS&B base year survey will be repeated in the first follow-up of NELS:88.\nFrankel, M., Inference from Survey Samples: An Empirical Investigation (Ann Arbor: Institute for Social Research, 1971)."}, {"section_title": "The National Education Longitudinal Study of 1988: Overview", "text": "The base year of the National Education Longitudinal Study of 1988 (NELS:88) represents the first stage of a major longitudinal effort designed to provide trend data about critical transitions experienced by students as they leave elementary school and progress through high school and into college or their careers. A 1988 eighth grade cohort will be followed at two-year intervals as this group passes through high school and into postsecondary education. Policy-relevant data about educational processes and outcomes will be collected over time, especially as it pertains to student learning, early and late predictors of dropping out, and school effects on students' access to programs and equal opportunity to learn. Base Year: Parent Component Data File User's Manual 1.5.1 NELS:88 Study Objectives NELS:88's objectives are more comprehensive than those of any education longitudinal study to date. Its major features include the planned integration of student, parent, teacher, and school studies; the initial concentration on eighth grade student cohorts with planned follow-up at two year intervals; the inclusion of supplementary components to support analyses of geographically or demographically distinct subgroups; and the design linkages to previous longitudinal studies and other current studies. Underlying these various features is a central theme that education in America must be understood as a lifelong process enmeshed in a complex social context. Several priorities have guided the research objectives of NELS:88. First, since the primary research objectives of this study are longitudinal in nature, survey items have been selected for their usefulness in predicting or explaining future outcomes as measured in later survey waves. Second, the priority for base year questionnaires was to obtain valuable cross-sectional data, wherever this objective proved consistent with the longitudinal requirements of the survey. Third, the study provides data for the analysis of point estimates of student achievement that may be cross-sectionally related to factors such as school type, programs, family characteristics, and the like."}, {"section_title": "CA -", "text": "Of equal importance are the policy objectives that NELS:88 is designed to serve. The study is intended to produce a comprehensive data set for the development and evaluation of educational policy at all governmental levels. Part of its aim is to inform decision makers, education practitioners, and parents about the changes in the operation of the educational system across time, and the effects of various elements of the system on the lives of the individuals who pass through it. Specifically, NELS:88 focuses on a number of interrelated policy issues, including: identification of school attributes associated with achievement; the transition of different groups from eighth grade to secondary school; the influence of ability grouping on future educational experiences and achievements; determinants of dropping out of th.. educational system; and changes in educational practices over time. One of the unique features of the NELS:88 study is the extensive attention it gives to the role of parents. It gathers data on the effect of parents' attitudes and behaviors on educational choices, the correlates of active parental involvement in the school, parental guidance, and the parents' role in the educational success of their children. Figure 1-3 provides a guide to the linkage between the NELS:88 questionnaire items and some of the key policy issues related to school research."}, {"section_title": "Base Year Study Design", "text": "Four study components constitute the base year design: surveys and tests of students, and surveys of parents, school administrators, and teachers. A student questionnaire gathered information about basic background variables and a range of other topics including schoolwork, aspirations, and social relationships. Students also completed a series of curriculum-based cognitive tests that used item overlapping methods to measure ability and its growth between eighth and twelfth grades in four achievement areas---reading, mathematics, science, and social studies (history /government). One parent of each student was asked to respond to a parent survey intended to gauge parental aspirations for children, family willingness to commit resources to children's education, the home educational support system, and other family characteristics relevant to achievement. Selected teachers (in two of the four subject test areas) of each sampled student completed a teacher questionnaire designed to collect data about school and teacher characteristics, evaluations of the selected students, course content, and classroom teaching practices. Finally, a school administrator questionnaire was completed by school principals. It was used to gather descriptive information about the school's teaching staff, the school J9 Oo   Base Year: Parent Component Data File User's Manual"}, {"section_title": "II. Data Collection Instruments", "text": "The data collection instruments for the NELS:88 base year study consisted of four separate questionnaires and a battery of eighth grade tests. All four NELS:88 questionnaires were designed to provide continuity and consistency with earlier education longitudinal studies. Where appropriate, NELS:88 drew from NLS-72, HS&B, and other current NCES studies--in particular, the National Assessment of Educational Progress (NAEP) and the Schools and Staffing Study --in order to ensure a common standard of measurement that would permit comparisons and maximize the utility of NELS:88 data. Figure 2-1 provides a comparative overview of the specific content areas covered by each of the NELS:88 base year questionnaires. A brief description of the contents of the data collection instruments used in the NELS:88 base year follows."}, {"section_title": "2.1", "text": ""}, {"section_title": "Student Questionnaire and Eighth Grade Tests", "text": "A 45-minute self-administered student questionnaire was completed by eighth grade students in the classrooms of their schools. The student questionnaire was designed to collect information about a wide range of topics, including the student's and parents' background, language use, family background, perceptions of self, plans for the future, jobs and household chores, school life, school work, and school activities. Students also completed a series of cognitive tests, which were administered in a single group session. The combined tests included 116 items to be completed in 85 minutes. The eighth grade tests .ire described briefly below: Reading (21 items, 21 minutes): consists of five short passages followed by comprehension and interpretation questions. Mathematics (40 items, 30 minutes): consists of quantitative comparisons and other questions assessing mathematical knowledge. Science (25 items, 20 minutes): questions assessing science knowledge and scientific reasoning ability. History/Government (30 items, 14 minutes): questions assessing knowledge of U.S. history, civics, and government. NORC's subcontractor, the Educational Testing Service (ETS), developed the cognitive test battery. In order to facilitate comparisons with test data from other national studies, NELS:88 borrowed or adapted a number of test items from NAEP and from earlier education longitudinal studies. Properties of the tests and the test item reliabilities are discussed in ETS's report, Psychometric Report for the NELS:88 Base Year Test Battery,4 which can be obtained from NCES.  "}, {"section_title": "Parent Questionnaire", "text": "A self-administered 30-minute questionnaire was completed by one of the student's parents on about the same date that the student questionnaire and eighth grade tests were administered. The instructions in the questionnaire and accompanying letter directed the most knowledgeable parent (or guardian) to complete the questionnaire. The most knowledgeable parent was defined as the parent who knows the most about the student's educational activities and related behaviors. In accordance with this definition, the respondent was self-selected. The parent questionnaire was designed to collect information from parents about factors that influence educational attainment and participation. The questions focused on family background and socioeconomic characteristics, and on the character of the home educational support system. These data will allow analysis of the effect on student educational outcomes of parental behaviors concerning student course selection, long-range educational planning, participation in school activities and nonschool extracurricular activities, and the establishment of discipline at home. In addition, the parent instrument collected data related to parental behaviors and circumstances with which the student may not be familiar, such as parental education and occupation, and contained more sensitive items relating to income and religious affiliation. The questionnaire also included a section that gathered information to be used in locating the respondent for subsequent follow-ups. English-and Spanish-language versions of the questionnaire were made available to parents. The object of the parent questionnaire was to provide data that could be used primarily in the analysis of student behaviors and outcomes, and only secondarily as a data set by itself. Parent questionnaires were administered to one parent of each student in the core sample."}, {"section_title": "2.3", "text": "Teacher Questionnaire A self-administered teacher questionnaire was completed by selected teachers responsible for instructing sampled students in two of the four test subjects (mathematics, science, reading, and social studies).5 It is important to note that the teacher survey was designed primarily to obtain student-level data, as reported by teachers, pertaining to specific eighth grade students and the courses in which they were enrolled. Although some teacher-level data were collected, the primary emphasis was on information that may help account for the subsequent educational development of the sampled students. Issues that received principal consideration included the quality, equality, and diversity of educational opportunity, and the effect of these factors upon individual development and educational and career outcomes. The teacher questionnaire was designed to collect information in three areas: teachers' perceptions of the sampled students' classroom performances and personal characteristics; curriculum content of areas that they teach; and teachers' background and activities. Teachers were asked to respond to the questionnaire items in relation to a specific list of sampled eighth grade students enrolled in their classes. The contents of these three sections are described on the following page. Base Year: Parent Component Data File User's Manual Part I, Student Information, asked the teachers to indicate which of the sampled students they had in their classes during the 1987-88 academic year, and for those students enrolled in their class(es), to indicate whether or not the student had various school-related problems and handicaps. Part H, Class Information, required teachers to respond to a series of course-related questions regarding a distinct set of classes they had been identified as teaching to one or more of the sampled students. Subsections of items within this segment of the questionnaire applied to the four specific curriculum areas (i.e., mathematics, science, English, and social studies), enabling teachers to respond to these subsections as appropriate. Part III, Teacher Background and Activities, requested teachers to provide general background information about themselves and their school. NORC's subcontractor, Westat, prepared the teacher questionnaire under the direction of NORC and NCES."}, {"section_title": "2.4", "text": ""}, {"section_title": "School Administrator Questionnaire", "text": "A self-administered 40-minute school administrator questionnaire was completed by the school principal, headmaster, or other knowledgeable school administrator designated by the principal. The questionnaire was designed to collect information about school, student, and teacher characteristics; school policies and practices; the school's grading and testing structure; school programs and facilities; parent involvement in the school; and school climate. The primary purpose of the school administrator questionnaire was to gather general descriptive information about the educational setting and environment associated with the individual students who were selected for participation in NELS:88. The school information describes the over all academic climate in terms of enrollments and educational offerings, as well as specific school policies. The information obtained through the school administrator questionnaire provides supplemental information to that provided by the student questionnaire so that student outcome and achievement data can be considered in terms of the educational setting. School-level data will provide a basis for distinguishing patterns among eighth grade schools as they relate to the transition of students to the tenth grade and beyond. NORC and its subcontractor, Westat, collaborated in designing the instrument. Base Year: Parent Component Data File User's Manual"}, {"section_title": "III. Sample Design and Implementation", "text": "This chapter describes the design and procedures used for selecting schools and students into the NELS:88 base year sample. It provides information on the calculation of sample weights and the relative efficiency of the sample design. The chapter also provides information about procedures used to adjust sample weights for nonresponse and about the effect of nonresponsc on estimates. A detailed description of the sample design and its implementation is available in the NELS :88 Base Year Sample Design Report.6"}, {"section_title": "Base Year Sample Design", "text": "The base year survey employed a two-stage, stratified sample design, with schools as the firststage unit and students within schools as the second-stage unit. Within each stratum, schools were selected with probabilities proportional to their estimated eighth grade enrollment. In addition, schools were oversampled in certain special strata. Within each school approximately 26 students were randomly selected (typically, 24 regularly sampled students and 2 OBEMLA-supplement Hispanic and Asian/Pacific Islander oversampled students). In schools with fewer than 24 eighth graders, all eligible students were selected. From a national frame of about 39,000 schools with eighth grades, a total of 1,734 schools was selected, of which 1,057 schools participated. Thus, the target sample size of 1,032 schools was achieved and in fact surpassed. In designing a sampling frame for a survey one can use either an explicit or an implicit list of the elements to be sampled. For NELS:88, the creation of an explicit list of all eighth grade students in the U.S. would have been an impossible task. NORC therefore elected to use an implicit list of students, by using a list of public and private schools in the U.S. It was imperative that the list of schools be as complete and accurate as possible, and that as many of the schools as possible have data on the variables to be used in the stratification of the sampling frame. Investigation of various sources indicated that the most readily available source for a complete and accurate frame was the data base compiled by Quality Education Data, Inc. (QED) of Denver, Colorado. This data base includes both public and private parochial and nonparochial schools. QED performs annual, late-summer updates by telephoning each public school district, each Catholic diocese, and all private schools on its records. In addition, QED receives a constant flow of current information from agencies such as the National Catholic Educational Association (NCEA), the Council of American Private Education (CAPE), the Association of Christian Schools, and the like, concerning school openings and closings, enrollments, and so forth. The QED records were successfully employed in the five NELS:88 field test states, and proved highly accurate. The number of schools with eighth grades not included in their lists is estimated to be small. The QED list contained information about whether a school was urban, suburban, or rural. NORC used this information for stratification purposes. The QED list did not contain information about the racial/ethnic composition of public schools usable for the NELS:88 sampling frame. Racial/ethnic composition data were obtained from Westat, Inc. in its capacity as an NORC subcontractor for the NELS:88 base year study. As part of their work on the National Assessment of Educational Base Year: Parent Component Data File User's Manual Progress (NAEP), Westat had obtained data from the Office of Civil Rights (OCR) and from other sources (e.g., district personnel) that identified those schools with a minority enrollment of greater than 19 percent. The schools for which the OCR data were available tended to be large schools in large SMSAs; Westat also obtained the black and Hispanic percentages directly from district personnel in selected districts that, according to the QED information, enrolled large proportions of black or Hispanic students. In all cases, data on percent black and Hispanic were compiled only for schools in the primary sampling units of the Year-17 NAEP survey. In all, less than half of the eighth graders in the NELS:88 frame came from schools for which such minority enrollment data were available. However, this procedure allowed the explicit stratification and allocation of schools with very large percentages of black or Hispanic students. Stratification information on whether a school was public, Catholic (private), or other private was obtained from the QED list and lists of private schools."}, {"section_title": "Exclusions from the Sample", "text": "Exclusion of students. The study excluded certain kinds of students: specifically, mentally handicapped students and students not proficient in English, for whom the NELS:88 tests would be unsuitable; and students having physical or emotional problems that would make participation in the survey unwise or unduly difficult. Data were obtained on the numbers of students excluded as a result of these restrictions to facilitate inferences to the larger populations that include such persons. Seven ineligibility categories were employed at the time of student sample selection: A. attends this school only on a part-time basis, primary enrollment at another school. (Each eighth grade student was to have one and only one first-stage [that is, school-level] chance of selection into the NELS:88 sample.) B. physical disability precludes filling out questionnaires and taking tests."}, {"section_title": "C.", "text": "mental disability precludes filling out questionnaires and taking tests. has transferred out of the school since roster was compiled. G. is deceased. In cases D, F, and G, the student was no longer at the school. In cases A, B, C, and E, the student, though still enrolled at the school, was excluded from the sample. The exclusion of part-time students (category A) has no implications for estimation. However, exclusion of cases covered by categories B, C, and E may have implications for estimates drawn from the base year sample and subsequent study waves. Details are presented in the NELS:88 Base Year Sample Design Report.7 Figure 3-1 gives the number and percentage of excluded and non-excluded students who fall into these three categories. Exclusion of schools. Just as certain students were considered to be ineligible, so too certain kinds of schools were ineligible for selection. The eligible populations of schools are restricted to \"regular\" schools in the U.S., private as well as public. Excluded from the sample are Bureau of Indian Affairs (BIA) schools, special education schools for the handicapped, area vocational schools that do not enroll students directly, and schools for dependents of U.S. personnel overseas. (Of course, students who are educated at home or in private tutorial settings, and those who have dropped out of school prior to reaching eighth grade, also fall outside the NELS:88 base year sample.) These exclusions have implications for national inferences based on NELS:88 data, although their impact on such estimates generally is quite small. Information from various sources suggests that approximately 10 percent of American Indian school children attend schools that are affiliated with BIA, including schools directly operated by BIA and those operated by American Indian communities under contract to BIA. Other sources suggest that less than 10,000 eighth graders attend Department of Defense Dependent Schools (DODDS) serving dependents of U.S. personnel overseas. The NELS:88 core sample was designed to minimize overlap with the NAEP sample for the 1987-68 school year. To accomplish this goal, the selection of the NELS:88 schools involved a twophase process. The first phase was the NAEP selection. Any schools that were not selected for NAEP were eligible for NELS:88 selection and any schools that were selected for NAEP were not eligible for NELS:88 selection. In principle, then, no school was eligible for selection in both surveys. Exceptions to this principle could have occurred in practice because not all of the schools originally selected for NAEP agreed to participate, and therefore substitute schools were selected. While NORC was able to eliminate the originally selected NAEP schools from the NELS:88 sample, it was not able to screen out NAEP substitute schools. Additional sample selections within superstrata were made for schools that refused to participate in the survey. No addition,) selections were made for students who, for whatever reason, failed to participate. Each school (and student) was assigned a weight equal to the number of schools (or students) in the universes they represented. The derivation of student case weights is discussed below. Use of weights properly projects estimates (within sampling error) to the population of eighth grade students who meet the NELS:88 eligibility criterion in United States schools in 1987-1988 (that is, about 95 percent of all eighth graders), and for subgroups within that population. The current weights give estimates reasonably close to those from other data sources. Table 4.4-1 in Chapter IV reviews sample selection and sample realization."}, {"section_title": "3.2", "text": ""}, {"section_title": "Calculation of Sample Weights", "text": "The general purpose of the weighting scheme is to compensate for unequal probabilities of selection into the base year sample and to adjust for the fact that not all individuals selected into the sample actually participated. The weights are based on the inverse of the probabilities of selection into the sample and on nonresponse adjustment factors computed within weighting cells. For the base year survey two different weights have been calculated to adjust for the fact that not all sample members have data for all instruments. The weight BYQWT applies to 24,599 student questionnaires (and is also used in conjunction with parent data),8 while BYADMWT applies to the 1,035 school administrator questionnaires. These weights project to the population of approximately 8 Sec section 3.3 for a discussion of the parent questionnaire weighting and gencralizability."}, {"section_title": "22", "text": "Base Year: Parent Component Data File User's Manual 3,008,080 eligible eighth graders in 22,790 public, 6,946 Catholic, and 9,037 other private schools in 1988. The weighting procedures consisted of two basic stages: Stage 1. Calculation of a preliminary base year weight based on the inverse of the product of the probabilities of selection for the base year sample. Stage 2. Adjustment of this preliminary weight to compensate for \"unit\" nonresponse, that is, for noncompletion of an entire school questionnaire or student questionnaire. The unit varied depending upon the weight being adjusted. The nonresponse-adjusted school weight was derived as the product of the school's stage 1 weight times a nonresponse adjustment factor intended to adjust for the fact that some of the sampled schools did not return a completed questionnaire. The stage 1 weight for students was based upon the inverse of the probability that the student's school was selected into the sample multiplied by the inverse of the probability that the student was sampled within the school. The nonresponse-adjusted student weight was derived as the product of the student's stage 1 weight times a nonresponse adjustment factor intended to adjust for the fact that some of the sampled students did not participate, that is, did not return a completed questionnaire. Statistical properties of the weights are presented in Table 3.2-1. Each school appearing on the NELS:88 school file, and each student appearing on the NELS:88 student file, has a value for a final weight variable. The weight represents the probability of selection into the sample plus a factor that adjusts for nonresponse. Thus, the weight ser, es the purpose of allowing a particular case to represent other nonsampled cases within its sampling stratum, and to represent nonresponding cases similar to it in various respects. Because separate final student and school weights have been provided, the construc6on of each will be considered separately in the following discussion. The final school weight, BYADMWT, was derived using a multistage process. First, an initial weight was attached to each school record in a file containing records for all eligible schools in the NELS:88 sample. The initial weight represented the inverse of the school's selection probability. A logistic regression procedure was used to estimate (in terms of a probability of nonresponding) the degree to which each of the responding schools resembled a nonresponding school. This estimated probability of nonresponse was the first adjustment factor applied to a school's weight. Next, a polishing procedure further adjusted the weights to sum to known population totals within strata. Estimating the nonresponse probability for each of the responding schools was possible because key background information on almost all of the nonresponding schools was available. The final result of these procedures was a final weight for each of the responding schools adjusted to compensate for nonresponse. For the purpose of adjusting the school weight, a nonresponding school was considered to be school for which both school administrator questionnaire data and student quest:onnaire data were unavailable. The final student weight, BYQWT, was also derived using a multistage process. A design weight for each eligible student on a participating school's sample roster represented the student's probability of selection within the school. A student-level nonresponse adjustment factor was calculated by forming weighting cells based upon the combination of certain levels of variables representing school type, region, ethnicity, and gender. For each student, the product of a nonresponse adjusted preliminary school weight and the student's design weight was formed. (The preliminary school weight was slightly different from BYADMWT. BYADMWT was adjusted to account for the fact that the 17 schools for which school administrator questionnaire data were available, but student questionnaire data were missing, were treated as missing in the school file. The preliminary school weight eliminated this step in the adjustment process. Thus, it is appropriate for application to the 1,052 schools with student questionnaire data available). This product was summed for participating and nonparticipating students within weighting cells. The ratio of the sums for participating and nonparticipating students was considered to be a participating student's propensity for nonparticipation and was used as the nonresponse adjustment factor for each student's design weight."}, {"section_title": "3.3", "text": "A Note About the Parent Survey: Weighting and Generalizability Because of the success in obtaining a parent questionnaire for such a high percentage of students, a separate weight adjusted for parent nonresponse was not included on either the student or parent data files. A very close approximation of weighted parent values can be computed by applying the base year student weight, BYQWT, to parent responses. Note that because this is a student-based weight, the associated parent data will be missing for the 1,948 cases for which there is a student questionnaire, but no parent questionnaire. In using the parent data, it is necessary to keep in mind the qualified sense in which the parent survey is representative of eighth grade parents in the United States in the spring of 1988. First, because some types of schools and some students were excluded or considered ineligible, there is a class of parents of eighth graders who had no chance of selection. Second, some extremely small number of parents had more than one chance of selection into the sample. This most often occurred in the case of parents of twins, or parents with children near in age, one of whom was out of the normal grade sequence. Third, orphans with an institutional guardianship arrangement constitute another rare population. Fourth, an important limit to the generalizability of the data is the fact that for purposes of the 24 43 Base Year: Parent Component Data File User's Manual public release tape, parents of nonparticipants have been excluded, even though parent questionnaires were frequently obtained for this group. Finally, the NELS:88 parent survey obtained data from only one parent or guardian of each child, though a majority of NELS:88 eighth graders lived in two-parent homes. The parent respondent was self-selected rather than randomly selected, and a broad definition of parent or guardian was applied. In some cases a grandparent or other relative who filled the role of parent, or a foster parent or other guardian, completed the parent questionnaire. These qualifications should be kept in mind when generalizing findings from the NELS:88 parent data."}, {"section_title": "3.4", "text": ""}, {"section_title": "School and Item Nonresponse Analyses", "text": "Although the sample design yields, in theory, a sample that mirrors the population within sampling error, in practice, nonresponse can introduce distortions. In the NELS:88 base year survey there were two stages of sample selection and therefore two stages of potential nonresponse. During the base year survey, schools were asked to permit the selection of eighth grade students from school rosters and to hold survey and makeup days for the collection of student data. Not all of the selected schools agreed to take part in the study. In addition, not all of the individual students selected for the sample within cooperating schools (or the teachers or parents linked to these students) provided the data sought from them. During the base year survey, shortened versions of the NELS:88 school administrator questionnaire were sent to nonresponding schools in the pool of original selections. Almost all of these schools provided data. These data provide a basis for assessing the impact of school-level nonresponse on base year estimates. The analysis suggests that school-level nonresponse introduces a negligible amount of bias into the estimates. However, the amount of bias is slightly higher than for the High School and Beyond survey.9 The school non-response analysis suggests that, to the extent that schools can be characterized by different types of students, the impact of nonresponding schools on the quality of the student sample is small. The effect of student-level nonresponse within the responding schools was not assessed. Full details of the school nonresponse analysis are presented in the NELS:88 Base Year Sample Design Report. 10 An analysis of student questionnaire item nonresponse was also undertaken. The percentages of multiple responses, missing responses, and where applica-le, \"don't know\" responses were calculated for each of the questions in the stue mit questionnaire. The analysis was conducted after data cleaning had taken place. This means that a response to an item could have come from the eighth grade respondent or from the logic-driven machine cleaning process. Nonresponse reflects the failure of both of these sources to provide a response. Nonresponse rates for each item were examined by item type, topic, and position it the questionnaire. The average item nonresponse rate in the student questionnaire was 4.7 percent. Average item nonresponse for the parent survey was slightly higher than for the student (7.46). A full report of the item nonresponse analyses can be found in the NELS:88 Base Year Sample Design Report.11 As documented in Chapter VII, there were cases when 9 Frankel, M., Kohnke, L., Buonanno, D., and Tourangeau, R., High School and Beyond Base Year (1980) Sample Design Report (Chicago: NORC, 1981)."}, {"section_title": "10", "text": "Spencer, Frankel, Inge ls, Rasinski, and Tourangeau, NELS:88 Base Year Sample Design Report (sec note 1)."}, {"section_title": "11", "text": "Spencer, Frankel, Inge ls, Rasinski, and Tourangeau, NELS :88 Base Year Sample Design Report (see note 1)."}, {"section_title": "44", "text": "Base Year: Parent Component Data File User's Manual information not provided by the school administrator or the student was obtained from other sources. One example is when information from the QED data file, used to create the sample frame, was also used to fill in missing information about the grade range of the school. Similarly, information on the student's sex and race were obtained from the school rosters when they were missing from the student questionnaire. A full description of these substitutions appears in Chapter VII and Appendix D. In addition, as explained above, certain responses were imputed logically, as the result of machine cleaning. In general, however, there were no other attempts at imputing data for missing values. Data users are therefore cautioned that nonresponse bias may be a problem for items with high nonresponse."}, {"section_title": "Standard Errors and Design Effects", "text": "Statistical estimates calculated using NELS:88 survey data are subject to sampling variability. Because the sample design involved stratification, disproportionate sampling of certain strata, and clustered (i.e. multi -stage) probability sampling, the calculation of exact standard errors for survey estimates can be difficult and expensive. Popular statistical analysis packages such as SPSS (Statistical Program for the Social Sciences) or SAS (Statistical Analysis System) do not calculate standard errors by taking into account complex sample designs. Because of the complex design of the NELS:88 sample (described in detail in the NELS :88 Base Year Sample Design Report),12 standard errors generated by SPSS and SAS will usually underestimate the sampling variability of statistical estimates such as population means, percentages, and more complex statistics such as correlations and regression coefficients. Several procedures are available for calculating precise estimates of sampling errors for complex samples. Procedures such as Taylor series approximations, Balanced Repeated Replication (BRR), and Jackknife Repeated Replication (JRR) produce similar results.13 Consequently, it is largely a matter of convenience which approach is taken. For this report, the Taylor Series procedure was used to calculate the standard errors. The impact of departures from simple random sampling on the precision of sample estimates is often measured by the design effect. For any statistical estimator (for example, a mean or a proportion), the design effect is the ratio of the estimate of the variance of a statistic derived from consideration of the sample design to that obtained from the formula for simple random samples. Standard errors and design effects were selected for 30 means and proportions based on the NELS:88 student, parent, and school data. The 30 variables from the student questionnaire were selected to overlap as much as possible with those variables examined in High School and Beyond. The remaining variables from the student questionnaire and from the parent and school questionnaires were selected randomly. We calculated the standard errors and design effects for each statistic both for the sample as a whole and for selected subgroups. For both the student and parent analyses, the subgroups were based on the student's sex, race and ethnicity, school type (public, Catholic, and other private), and socioeconomic status (lowest quartile, middle two quartiles, and highest quartile). For the school analysis, the subgroups were based on two levels of school type (public and combined private) and eighth grade enrollment (at or below the median and above the median). 12 Spencer, Frankel, Ingels, Rasinski, and Tourangeau, NELS:88 Base Year Sample Design Report (see note 1)."}, {"section_title": "45", "text": "Base Year: Parent Component Data File User's Manual Design effects for questions selected from the student, parent, and school questionnaires are presented in Tables 3.5-1 through 33-3. On the whole, the design effects indicate that the NELS:88 sample was slightly more efficient than the High School and Beyond sample. For means and proportions based on student questionnaire data for all students (see Table 3.5 -1), the average design effect in the NELS:88 survey was 2.54; the comparable figure was 2.88 for the High School and Beyond sophomore cohort and 2.69 for the senior cohort. Tables 3.5-4 through 3.5-6 show that this difference is also apparent for subgroup estimates. The High School and Beyond Sample Design Report 14 presents design effects for ten subgroups defined similarly to those in Table 3.5-4. For eight of the ten subgroups, the NELS:88 design effects are smaller on the average than those for both the High School and Beyond sophomore and senior cohorts. The increased efficiency is especially marked for students attending Catholic schools. In NELS:88, the average design effect is 2.70; in High School and Beyond, it was 3.60 for the sophomores and 3.58 for the seniors. The smaller design effects in the NELS:88 may reflect the somewhat smaller cluster size used in the later survey. The High School and Beyond base year sample design called for 36 sophomore and 36 senior selections from each school; the NELS:88 sample called for the selection of only 24 students from each school. Clustering tends to increase the variability of survey estimates, because the observations within a cluster are similar and therefore add less information than independently selected observations. The design effects for the estimates based on parent questionnaire data (see Table 3.5-2) are similar to those for the student questionnaires. For estimates applying to all students, the mean design effect was 2.48 for the parent data and 2.54 for the student data. For all but one of the subgroups, the average design effect for the student items is about the same as, or larger than, the average design effect for parent items. This suggests that the homogeneity of student responses within clusters is about the same as, or greater than, the homogeneity of parent responses within the domain clusters. Given the students' shared school experiences, in general, and the uniform questionnaire administration procedures, in particular, this is not surprising. For private schools, the design effect for the parent items is considerably larger than the design effect for the student items. This suggests that parents within a particular private school gave strikingly similar responses to the 30 NELS:88 items used in the design effect analysis. The design effects for the school questionnaire data (see Table 3.5-3) reflect only the impact of stratification and unequal selection probabilities; the sample of schools was not clustered. As a result, the design effects for estimates based on the school data tend to be small compared to those for estimates based on the student and parent data. The mean design effect for estimates concerning all schools is 1.82. Tables 3.5-4 through 3.5-6 give the mean design effects (DEFF5) and mean root design effects (DEFTs) for each data set and subgroup. A detailed presentation of design effects for individual items for the total sample and for various subsamples is presented in the NELS :88 Base Year Sample Design Report.15 14 Frankel, Kohnke, Buonanno, and Tourangeau, 11S ILB Base Year (1980) Sample Design Report (see note 9)."}, {"section_title": "15", "text": "Spencer, Frankel, Ingels, Rasinski, and Tourangeau, NELS:88 Base Year Sample Design Report (see note 1).    a One purpose of these tables is to show the relative efficiency of each of the surveys. This comparability is facilitated by choosing comparable domains within which to compare the student and parent surveys. Thus, parent survey design effects were computed using the student's sex and the student's race as subgroups. As in the student survey, the sex and race composites were used to obtain domain categories."}, {"section_title": "46", "text": "Note: Each mean is based on 30 questionnaire items. "}, {"section_title": "Design Effects and Approximate Standard Errors", "text": "Researchers who do not have access to software for computing accurate estimates of standard errors can use the mean design effects presented in Tables 3.5-4, 3.5-5, and 3.5-6 to approximate the standard errors of statistics based on the NELS:88 data. Design-corrected standard errors for a proportion can be estimated from the standard error computed using the formula for the standard error of a proportion based on a simple random sample and the appropriate mean root design effect (DEFT): where p is the weighted proportion of respondents giving a particular response, n is the size of the sample, and DEFT is the mean root design effect. Similarly, the standard error of a mean can be estimated from the weighted variance of the individual scores and the appropriate mean DEFT: where Var is the sample variance, n is the size of the sample, and DEFT is the mean root design effect. Tables 3.5-4, 3.5-5, and 3.5-6 make it clear that the design effects and root design effects vary considerably by subgroup. It is therefore impertant to use the mean DEFT for the relevant subgroup in calculating approximate standard errors for subgroup statistics. Standard error estimates may be needed for subgroups that are not tabulated here. One rule of thumb may be useful in such situations: design effects will generally be smaller for groups that arc formed by subdividing the subgroups listed in the tables. (This is because smaller subgroups will be less affected by clustering than larger subgroups.) Estimates for Hispanic males, for example, will generally have smaller design effects than the corresponding estimates for all Hispanics or all males. For this reason, it will usually be conservative to use the subgroup mean DEFT to approximate standard errors for estimates concerning a portion of the subgroup. This rule applies only when the variable used to subdivide a subgroup crosscuts schools. Sex is one such variable, since most schools include students of both sexes. It will not reduce the average cluster size to form groups that are baged on subsets of schools. Standard errors may also be needed for other types of estimates than the simple means and proportions that are the basis for the results presented here. A second rule of thumb can be used to estimate approximate standard errors for comparisons between subgroups. If the subgroups crosscut schools, then the design effect for the difference between the subgroup means will be somewhat smaller than the design effect for the individual means; consequently, the variance of the difference estimate will be less than the sum of the variances of the two subgroup means from which it is derived: in which Var(b-a) refers to the variance of the estimated difference between the subgroup means, and Var(a) and Var(b) refer to the variances of the two subgroup means. It follows from equation 3that Var(a) + Var(b) can be used in place of Var(b-a) with conservative results. Base Year: Parent Component Data File User's Manual A final rule of thumb is M.'. more complex estimators show smaller design effects than simple estimators.16 Thus, correlation and regression coefficients tend to have smaller design effects than subgroup comparisons, and subgroup comparisons have smaller design effects than means. This implies that it will be conservative to use the mean root design effects presented here in calculating approximate standard errors for complex statistics, such as multiple regression coefficients. The procedure for calculating such approximate standard errors is the same as with simpler estimates: first, a standard error is calculated using the formula for data from a simple random sample; then, the simple random sample standard error is multiplied by the appropriate mean root design effect."}, {"section_title": "16", "text": "Kish, L., and Frankel M., \"Inference from Complex Samples,\" Journal of the Royal Statistical Society: Series B (Methodological), 36, 2-37 (1974 "}, {"section_title": "Overview", "text": "The NELS:88 base year study collected data from students, parents, teachers, and school administrators. Self-administered questionnaires and tests represented the principal mode of data collection. For the NCES-sponsored core sample, the number of completed instruments and completion rates based on sample eligibility for each instrument are listed in Table 4-  aPercentage of cases for which a student questionnaire was obtained for which a cognitive test was also obtained. bIndicates a coverage rate. See section 4.4. Although more parents, teachers, and school administrators participated, the above completion rates reflect the number of records in the public use data file, where parent, teacher, and school administrator data were excluded for the students who did not participate."}, {"section_title": "4.2", "text": ""}, {"section_title": "Pre-Data Collection Activities", "text": "Before the data collection effort could begin, it was first necessary to secure from the administrator of each sampled school a commitment to participate in the study. Several levels of cooperation were sought before school administrators were approached. The first level involved contacting key educational organizations. The Committee on Evaluation Information Systems (CEIS)17 of the Council for Chief State School Officers was asked to provide its approval of the project. Contact was also made with the National Catholic Education Association (NCEA) and the National Association of Independent Schools (NAIS) in order to inform them of the study and to solicit their endorsements. For public schools the next step involved contacting the Chief State School Officer (usually the state Superintendent of Schools) of each state to explain the objectives of the study and the data collection procedures (especially those for protecting individual and institutional confidentiality). Once approval was obtained at the state level, contact was made with District Superintendents and, Base Year: Parent Component Data File User's Manual upon receipt of district approval, contact was made with the school principals. Wherever selected private schools were organized into an administrative hierarchy (for example, Catholic school dioceses), approval was obtained at the higher level before the school principal or headmaster was approached. Within each cooperating school, principals were asked to designate a school coordinator who would serve as a liaison between the NORC staff, the school administrator, and the selected students, teachers, and parents. The school coordinator (often a guidance counselor or senior teacher, but sometimes the principal or assistant principal) handled all requests for data and materials as well as all logistical arrangements for data collection on the school premises. Included among these responsibilities was annotating the list of sampled students to identify students whose physical or learning handicaps or linguistic disabilities would preclude participation in the survey. Coordinators were asked to classify all eligible students as Hispanic, Asian-Pacific Islander, or \"core\" (neither Hispanic nor Asian-Pacific Islander), and to distribute parental permission forms to sampled students. School administrators were also requested to collect audiological data for eligible hearing-impaired students participating in Individualized Educational Programs (IEPs)."}, {"section_title": "Base Year Data Collection", "text": "Student questionnaires and tests were administered in group sessions to roughly twenty-five students in each of the schools in the core sample and augmentation samples. Telephone interviews were conducted for a small number of students who were unable to participate in the group-administered sessions. Parents who initially refused to grant permission for their child to participate in the study, but who later consented when contacted by an NORC representative, usually allowed their child to complete a questionnaire by telephone. Given the mode of administration, test data were not collected for these students. The parent, teacher, and school administrator questionnaires consisted of self-administered instruments that were normally received in the schools and then delivered to the intended recipient via the school coordinator, NORC representative, or, in the case of the parent, the student."}, {"section_title": "Student Survey and Eighth Grade Tests", "text": "NORC organized an Orientation Day for 158 schools that requested it or for schools that were deemed likely to particularly benefit from it.18 The Orientation Day was usually arranged one or two weeks prior to the administration of the student questionnaire and tests. During these sessions, sampled students were informed about the objectives of the NELS:88 study, its voluntary nature, and the measures to be used to ensure respondent confidentiality. Students were also briefed about the tasks and procedures that would be followed in administering the questionnaire and tests. A check was made during this time to confirm that all required parental permission forms had been obtained. Base year student data were collected from students19 in the core and augmentation sample schools between February 1 and June 30, 1988. Selected eighth graders within each school were 18 Orientation days were originally planned for all schools. However, the NELS:88 base year field test indicated that orientation days for eighth grade students would not significantly affect participation rates in most schools. Sec Ingels, S. J., et al., National Education Longitudinal Study of 1988: Field Test Report (Chicago: NORC, 1987; ERIC ED 289-897). Base Year: Parent Component Data File User's Manual gathered in a group session on the scheduled Survey Day. Two NORC field staff members, a \"team leader\" and a clerical assistant, were responsible for overseeing the administration of the questionnaires and tests during the planned session. Actual survey administration, which was usually conducted in a school classroom or library, consisted of several steps. A check was made to confirm that parental permission forms had been obtained for all selected students. Students in each session were instructed to first complete the self-administered student questionnaire, starting with the background and identification section. A ten-minute break followed, during which time NORC field staff reviewed the questionnaires for completeness (i.e., checking for missing or multiple-response critical items). Upon completion of the questionnaires, an 85 minute battery of cognitive tests was administered. The tests consisted of four timed sections devoted to mathematics, reading, science, and social studies (history/government). Once the test battery was completed, an attempt was made to retrieve missing (or inappropriately marked) questionnaire items before the student left the classroom.\" At the close of the session, NORC representatives packaged all completed student questionnaires and tests and mailed them to NORC for processing. Teacher and school administrator questionnaires were also collected, but were mailed to Westat for processing. Arrangements were made to conduct make-up sessions for students who were scheduled, but unable to attend the first Survey Day. If fewer than five students were scheduled for a make-up day, the school coordinator was asked to handle the arrangements and oversee its administration.21 When five or more students were scheduled, or in instances where the school coordinator was unavailable to conduct a make-up day, NORC representatives arranged a return visit to the school."}, {"section_title": "Parent Survey", "text": "A self-administered questionnaire was hand-delivered by the student to his or her home with a written request that it be \"completed by the parent or guardian who is most familiar with the student's current school situation and educational plans.\" One parent of each sampled student in the core sample was included in the parent survey. The parent questionnaires were received by parents on one of two dates: the Orientation Day or on Survey Day. Students who attended Orientation Day received parent questionnaire packets to take home. The packet was addressed to \"The Parent of [Eighth Grade Student].\" Although parents were encouraged to complete the questionnaires for return by Survey Day, they were also given the option of mailing the document directly to NORC. A prepaid envelope was included in the parent questionnaire packet for this purpose. A similar procedure was followed for students who attended Base Year: Parent Component Data File User's Manual Survey Day. About 40 percent of parent questionnaires were returned through the schools or directly without further intervention by NORC. A mixed mode follow-up design was used in pursuing parents who failed to return a completed questionnaire several weeks after the questionnaire should have been received. (The locator section in the student questionnaire usually provided the necessary information for reaching the parent during the follow-up effort.) Parents first received a telephone prompt from an NORC central office interviewer, encouraging them to complete and return the questionnaire promptly.22 The telephone prompt accounted for an additional 20 percent of the completed cases. If a case was still outstanding two weeks after a telephone prompt it was transferred to an NORC field interviewer for follow-up. Field interviewers were instructed to attempt to complete the case by telephone administration. Failing that, the interviewer was instructed to make a personal visit to the respondent's home in an attempt to conduct a face-to-face interview. A special effort was made to ensure a high completion rate for parents of the OBEMLA (Hispanic and Asian/Pacific Islander) oversampled students. One of these efforts involved having a Spanish-language parent questionnaire and a Spanish-speaking interviewer available to conduct the telephone follow-ups. If an interviewer reached a Spanish-speaking household during the telephone prompting she or he would transfer the call to a Spanish-speaking interviewer. The bilingual interviewer would ascertain if the parent preferred to complete the questionnaire in Spanish or English. If a Spanish questionnaire was preferred, that version was mailed to the parent. During the follow-up field period, households that had been identified as Spanish-speaking during the prompting stage were assigned to Spanish-speaking interviewers who could administer the Spanish-language instrument if necessary. 23 Approximately 575 Spanish-language parent questionnaires were completed. While a native language version of the questionnaire was not available for Asian and Pacific Islander parents, other special procedures were used to ensure a high completion rate for this group. NORC contracted with Arts, Research, and Curriculum Associates, an educational consulting firm specializing in concerns of Asian and Pacific Islander ethnic groups, to develop a multi-language prompting letter (written in Chinese, Korean, Tagalog, Vietnamese, and English). The letter stressed the importance of the NELS:88 study and encouraged parent participation. The letter also asked parents to obtain assistance with the English language parent questionnaire, if necessary. Within two weeks after the letter and a copy of the parent questionnaire were sent to the parents of Asian/Pacific Islander students, an employee of that organization (who had signed the NORC confidentiality pledge and was, in effect, an NORC interviewer), and who could speak to the parent in his or her native language, telephoned the household. During that contact, the interviewer stressed the importance of the study and encouraged the respondent to participate. These special efforts proved quite effective in increasing completion rates for parents in both groups, bringing the final weighted completion rates to 88.35 percent for Hispanic parents and 90.76 percent for Asian and Pacific Islander parents. Base Year: Parent Component Data File User's Manual"}, {"section_title": "Teacher Survey", "text": "A self-administered teacher questionnaire was distributed to selected eighth grade teachers of the sampled students. Teachers were selected on a preassigned basis in two of four subject areasmathematics, science, English, social studies. Each school was randomly assigned to one of the following combinations of curriculum areas: mathematics and English, mathematics and social studies, science and English, and science and social studies. Thus, at any given school, each sampled student's current teacher(s) in each of the two designated subject areas was selected to receive a teacher questionnaire. This selection procedure was designed to ensure representation of mathematics or science curriculum and English or social studies in all schools. (Combinations of English and social studies as well as science and mathematics were excluded by the design.) The design also achieved balanced representation of the four curriculum area combinations across the school variables of control (that is, public, Catholic, and other private), level (elementary, middle, junior-senior high school), geographical stratum, and school size. Finally, using this design, the number of teacher respondents was expected to vary depending on the size and structure of the eighth grade at a particular school. It was anticipated that small schools with a self-contained eighth grade could have as few as one or two eligible teachers, while larger, departmentalized schools would typically have seven to ten teacher respondents. An average of five teachers pei school participated in the teacher survey. As part of a larger mailing--; school coordinators received the teacher questionnaires about two weeks before the scheduled Survey Day. The packet contained a cover letter, teacher questionnaire, and a study brochure. School coordinators were responsible for delivering the materials to the selected teachers and requesting that they complete and return the questionnaire prior to the scheduled Survey Day. School coordinators were also responsible for collecting the completed questionnaires so that they could be picked up by the NORC representative on Survey Day. Telephone follow-up activities for teachers who did not return a completed questionnaire were conducted by NORC's subcontractor, Westat. In order to prepare the school package, as well as meet the study objective of linking teacher data to individual students, several key pieces of information had to be acquired and processed before the teacher survey could proceed. The information required included: A school file that contained information about the participating school, including the school's ID number, name, address, and telephone number. The file also contained the name and title of the school coordinator, the scheduled survey date, and key school characteristics (such as size and control). This information was used to produce school coordinator mailing labels and to ensure that the survey materials were sent before the school's scheduled Survey Day. The file was transmitted electronically from NORC to Westat as soon as a school agreed to participate in the study. A student file that contained the names and ID numbers of selected students for a participating school. This file was also transmitted electronically from NORC to Westat as soon as it was available. A class schedule form completed by the school coordinator. Once NORC completed the student sampling for a school, the school coordinator was asked to complete a class schedule form. Using this form, coordinators recorded informationdbout the classes each sampled student attended in the two curriculum areas preassigned to the school. This form identified the teachers and classes to be included in the survey. This information was used to produce the teacher labels and list of each teacher's sampled classes. The class schedule form served two purposes. The first was to identify the teachers who taught classes in the designated curriculum areas to one or more of the sampled students included in the study. Each teacher listed on the class schedule form by the school coordinator was asked to complete a teacher questionnaire. The second purpose of the class schedule form was to identify, by teacher, the specific class each student attended for each assigned subject area. This information was used to produce a list of classes for which each teacher respondent provided descriptive information in Part Ii of the questionnaire. The class schedule form, then, provided the mechanism to link teacher ratings of students and descriptions of curriculum and practices to individual students. School coord;natoms were instructed to return their completed forms to Westat. Once a completed class schedule form was received at Westat, it was checked for completeness and discrepancies. If any crucial items were missing or errors were detected, the school coordinator was contacted by telephone and the relevant information was obtained or clarified. If a class schedule form was not returned to Westat within two weeks, a prompting telephone call was made to the school coordinator. Although the questionnaire administration schedule allowed approximately two weeks for teachers to return the completed questionnaires to school coordinators for return to Westat, in some cases materials were not received at the school sufficiently in advance of Survey Day to maintain this schedule. When school and/or student files were received too late to allow the timely completion of the class schedule form request packages, the packages were express mailed to the schools. Trained telephone interviewers then contacted the school coordinators and helped them complete the class schedule form by telephone. Sim ilarly, overnight express mailings were used to ensure the arrival of questionnaire packages prior to Survey Day. Coordinators were asked to encourage teacher respondents to have completed questionnaires ready for NORC field staff. When time did not permit the arrival and/or return of completed questionnaires on the desired time schedule, school coordinators were given the necessary materials to mail questionnaires directly to Westat following the completion of Survey Day activities. In general, these administrative exceptions were handled on a case-by-case basis."}, {"section_title": "School Survey", "text": "For the school survey, the school administrator (principal or headmaster) was asked to complete a school administrator questionnaire before the scheduled Survey Day. About two weeks before the Survey Day, school coordinators received a school administrator questionnaire packet that contained a cover letter, the school administrator questionnaire, and a study brochure. School coordinators were responsible for delivering the materials to the school administrator. They were also instructed to collect the completed questionnaire on or before Survey Day so that it could be picked up by the NORC representative. After that date, school administrators could mail their completed questionnaires directly to Westat in prepaid business reply envelopes provided for this purpose. Follow-up activities for administrators who did not return a completed questionnaire were conducted by Westat. "}, {"section_title": "Dam Collection Results", "text": "Tables 4.4-1 through 4.4-3 summarize the data collection results for the NELS:88 base year study. Table 4.4-1 reviews the school sample selections and sample realization. The final sample was approximately equal to the original target number of schools. Just under 70 percent of the original selections cooperated. In order to achieve overall numerical targets in each stratum, replacement schools were drawn from the same stratum into the sample when those originally selected refused to participate. The tables that follow (Table 4.4-2 and Table 4.4-3) present two sets of completion statistics for the four study components that constitute the NELS:88 core sample. The statistics are presented according to the sampling stratification variables. Table 4.4-2 displays weighted and unweighted completion rates based on the overall study/ sample design in which the participating student constitutes the basic unit of analysis. For purposes of this table, the completion rate was calculated as the ratio of the number of completed interviews divided by the number of in-scope sample members. Note that the student population is, in the strictest sense, the sole independent sample, and that the other populations, for example parent and teacher, arc defined in relation to participating students. Because the parent or teacher of a base year student nonparticipant was defined as out-of-scope (even though they may have completed questionnaires), these out-of-scope respondents have been subtracted from both the numerator and the denominator in the response rate calculation. Given this definition of response rate, weighted completion rates exceed 93 percent for each class of respondents as well as for the teacher ratings of students. In the case of teacher ratings, the statistics given represent more strictly a coverage rate than a teacher response rate. Note that reports were sought from two teachers of each student. The teacher ratings statistics in Table 4.4-2 depict the percentage of base year participating students for whom observations were obtained from one or more teachers. Table 4.4-3, in contrast, presents the weighted and unweighted completion rates for each survey based on the initial sample selections--that is, the response rate denominator includes base year nonparticipants, even though the parents and teachers of base year nonparticipant respondents were defined as out-of-scope. Utilizing this definition, the completion rates decrease by several points to around the 90 percent mark. Because in both instances ineligible (or out-of-scope) schools and students were removed from the sample prior to data collection, completion rates are computed directly by simply dividing the number of participating respondents/schools by the number of selections. As in figure 4.4-2, the teacher survey represents a coverage rate, rather than a teacher response rate.  "}, {"section_title": "62", "text": ""}, {"section_title": "Data Control and Preparation", "text": "This chapter describes the procedures used to transform responses from the parent questionnaire into a computer data file. These procedures include editing completed questionnaires for missing information, retrieving the missing information, monitoring the receipt of completed questionnaires, preparing the questionnaires for data entry, and preparing the documents for archival storage. To efficiently accommodate the large number of respondents and the many variables constituting the 1TELS:S8 parent survey, most of the questions in the parent questionnaire used response formats suitable for optical mark reading, in the same manner as the student questionnaire and eighth grade tests."}, {"section_title": "5.1", "text": ""}, {"section_title": "Monitoring and Receipt Control", "text": "As described in Chapter IV, a completed parent questionnaire could reach NORC through various routes. When questionnaires were received at NORC, receipt control clerks checked each for completeness and assigned a disposition code to the corresponding parent indicating if the questionnaire had been sent to NORC through the school, directly by the parent, or through an interviewer. In the latter case, a further distinction was made between interviews that were conducted over the telephone and those that were conducted in person. Receipt control clerks then entered this disposition code into NORC's Survey Management System (SMS), a microcomputer-based system that replaced the NORC Automated Survey System (NASS) used on earlier studies. At the time of entry, the SMS generated and automatically entered the date that data for each case was received. An NORC coder checked to make sure that the parent had correctly filled in the preassigned identification number. Overall, 62 percent of received questionnaires were mailed directly to NORC, 19 percent returned through the school, 17 percent were completed by telephone interviewers, and 2 percent were completed in personal interviews."}, {"section_title": "5.2", "text": ""}, {"section_title": "Inhouse Editing and Coding", "text": "After a questionnaire was logged into the SMS, it was sent to an editing shop where 26 critical items were checked and flagged when missing. As in the student questionnaire, critical items were those that were of particular interest to policy analysts, judged to have important policy relevance, or provided information which could be used in locating the student in subsequent follow-up studies. A complete listing of critical items appears in Appendix B. Questionnaires in which responses to one or more of the critical items were missing, undecipherable, or had multiple categories marked when only one was required were sent to the telephone retrieval shop. NORC interviewers in the retrieval shop called the respondent and attempted to elicit a response to the missing critical item(s). If, after prompting, thc respondent indicated that he or she had chosen not to answer that item, the interviewer marked a \"no retrieval\" response for the item. (This was indicated by filling in an oval to the left of the critical item.) The \"no retrieval\" responses were used during the machine editing process to assign a \"refused\" reserve code to the critical items. Overall, 43 percent of parent questionnaires required critical item retrieval."}, {"section_title": "5.3", "text": ""}, {"section_title": "Data Entry and Archival Storage", "text": "When editing, coding, and inhouse retrieval were completed, questionnaires were separated into two parts, each of which received different treatment with respect to data entry and archiving. First, a section of the parent questionnaire that asked parents to provide identifying information and 46 6 Data File User's Manual information about the high school their eighth grader would be most likely to attend was removed from each questionnaire and filed. This information will be used to locate students for the NELS:88 first follow-up in 1990. The data entry for the remaining part of the each questionnaire, which contained parents' responses to the majority of the questions, was completed through an optical mark reading procedure. Optical mark reading was conducted by NORC's subcontractor, Questar Data Systems, Inc., which received the questionnaires in batches for processing. Questar also arranged to have questionnaires photographed onto microfilm. Once the questionnaires were scanned and photographed they were destroyed and the rolls of microfilmed questionnaires were returned to NORC for archival storage. Base Year: Parent Component Data File User's Manual"}, {"section_title": "VI. Data Processing", "text": "Data processing activities span the entire length of the NELS:88 base year parent survey, beginning with drawing the sample, continuing with receipt control and machine editing, and ending with the preparation of public use data tapes and user documentation."}, {"section_title": "6.1", "text": ""}, {"section_title": "Student and Parent Locator Data Base", "text": "The locator database contains the most up-to-date name and address information available for each student. These data were constructed from both the sample file and from locating information provided by the student, and so contain the data required to trace a student through the school or district. Locating information was provided in Part I of the student questionnaire, including the student's name and address, his or her parents' names and address(es), and the name, address, and relationship of another person likely to stay informed of the respondent's whereabouts. Part I of the student questionnaire also requested information regarding respondent birth date, sex, parent occupation, and the sector (e.g., public, private) of the high school he or she expected to attend. These data are included in the public use data tapes. Additional locating information was provided in the parent questionnaire in a section titled \"Information for Future Follow-Up.\" Requested information included the parent's name and address, as well as the name and address of another relative and of a family friend, both of whom would be likely to stay informed of the parent's whereabouts. To ensure confidentiality, all identifying information is stored on secure files that are separate from the questionnaire data."}, {"section_title": "6.2", "text": ""}, {"section_title": "Receipt Control Procedures", "text": "The NORC Survey Management System (SMS) was used to track survey activities. This system h ses a record for each student that contains the school ID, the respondent ID number, student and parent disposition codes, and other information. Data control disposition codes in the SMS files were used to track completion rates of the sample during the data collection. At the end of the data collection period the SMS file was merged with the scanned data to search for any discrepancies in IDs or final status. In most cases, it was possible to resolve such discrepancies by referring to the microfilm of the documents."}, {"section_title": "Storage and Protection of Completed Instruments and Records", "text": "Whenever questionnaires were not being processed, they were filed in locked cabinets. After data retrieval and editing, the locator pages containing the respondent's name and ID were data-entered into the student locator data base, then detached and filed in a locked cabinet, in a locked room. From this point on, the respondent's name and address could no longer be associated with his or her responses to the questionnaire. Questionnaires were stored in locked file cabinets in locked rooms until they were transmitted to the scanning subcontractor, who observed identical security and confidentiality protection safeguards. The optical scanning subcontractor for the NELS:88 base year was Questar Data Systems, Inc."}, {"section_title": "Optical Scanning", "text": "With the exception of the locator section, NORC used the optical mark read (OMR) method of data conversion for the parent questionnaire. (Key-to-disk equipment at NORC was used to convert 48 7i Base Year: Parent Component Data File User's Manual the locator section to machine readable form.) The materials were optically scanned using equipment that read darkened ovals or marks on the page. The scanning subcontractor conducted extensive tests and checks of the machine's ability to correctly read the darkened ovals. Adjustments were made to the marksense threshold as required. To check the accuracy of data conversion, the scanning programs were tested in two ways: through use of dummy questionnaires specifically designed to detect scanning errors, and by running a substantial number of real documents through the system. Final data were compared item by item to hardcopy questionnaires, and procedures were modified until accuracy was attained."}, {"section_title": "Machine Editing", "text": "Conventions for editing, coding, error resolution, and documentation adhered as closely as possible to the procedures and standards previously established for HS&B and NLS-72. After the scanning contractor completed data conversion and supplied NORC with a raw data tape, the combination of machine editing and visual inspection of the output began. The tasks performed included: resolving inconsistencies between filter and dependent questions, supplying the appropriate missing data codes for questions left blank, and detecting illegal codes and converting them to missing data codes. Variable frequencies were inspected before and after these steps to verify the correctness of the automated processes. Inconsistencies between filter and dependent questions were resolved in the machine editing process. In most instances, dependent questions that conflicted with the skip instructions of a filter question contained data that, although possibly valid, were superfluous. For instance, respondents sometimes indicated \"no\" to the filter item and then continued to answer \"no\" to subsequent dependent questions. If a value was given to a filter question indicating that the respondent should have skipped the subsequent question(s), those questions were set to a value of legitimate skip even if the respondent answered some or all of these questions. If a multiple response or no answer was given to a filter question that was not a legitimate skip, it was assigned an appropriate reserve code (\"6\", \"7\", or \"8\", and all subsequent questions that might have been skipped were processed as if the respondent should have answered them. After improperly answered questions were converted to blanks, the parent data were passed through a second step in the editing progran; that supplied the appropriate reserve codes for blank questions. Where a value was not provided Ly the respondent, a reserve code fills the field. These codes are as follows: 6 = MULTIPLE RESPONSE 7 = REFUSED (if a critical item is missing and the retrieval oval is checked) 8 = MISSING 9 = LEGITIMATE SKIP If the field is longer than one column, the right-hand column contains one of the above codes and the rest of the columns are filled with \"9\"s. Each critical item has an associated \"retrieval oval.\" The retrieval oval was marked if an attempt was made to retrieve data from a respondent. These flags then were used to set corresponding blank data to REFUSED. Although retrieval variables were present in the questionnaire, they are not present in the data since their purpose was to determine correct reserve codes. Any critical item that was blank, not a legitimate skip, and whose retrieval oval flag was checked was coded as \"7\" (refused). A critical item that was blank, not a legitimate skip, and whose respective retrieval flag was not checked was coded as \"8\" (missing). If a filter was coded \"7\" (refused), all subsequent questions that might have been skipped were processed as if the respondent should have answered them. Filters that were coded \"6\" (multiple response) or \"8\" (missing) were handled the same way. Detection of out-of-range codes was completed during scanning for all questions except those permitting an open-ended response. The two-digit occupation codes for the manually coded, openended questions were checked manually to validate all codes. The frequency with which responses were recoded to legitimate skip for each skip pattern was closely monitored. Frequency distributions of responses before and after editing were inspected. All filter questions and their respective dependent items were displayed in condensed crosstabulations so that staff could verify the correctness of the recoding."}, {"section_title": "6.5", "text": ""}, {"section_title": "Data File Preparation", "text": "Composite variables were constructed for students; the composites included on the parent tape are a subset of those on the student file. The conventions used to assign SAS and SPSS variable names are as consistent as possible with HS&B and NLS-72. In those two surveys, variable names were assigned according to the survey wave and the question number. A similar system was developed for NELS:88. For example, BYP85G, is from the base year parent survey, question 85, part G. Most composite variables were constructed using responses from two or more questionnaire items. In some cases, composites were constructed from variables from different databases. Others were constructed by recoding a variable and a very few were simply copied from a different data source to this file for the user's convenience. Composite variables may be valid throughout the survey (e.g. SEX) or they may be specific to this particular survey wave. The names of the latter begin with BY for base year. Hence, BYFAMSIZ categorizes the base year family size. Weights are similarly labeled: BYQWT for the selection weight for student questionnaire completion adjusted for nonresponse during the base year, and so on. Composite variables, such as SEX, RACE, or G8ENROL, which will remain valid throughout the survey waves, have names that will remain unchanged. The only reserve code used for composite variables is that of missing data. For one-column variables that is an 8, for variables greater than one column, the leftmost columns are filled with \"9\"s (9....8). This reserve code is used when the sources for data are either item nonresponse or nonparticipation in all or part of the components of the study. Appendix D contains explanations of the conditions under which specific composite variables were assigned a missing code. "}, {"section_title": "VII. Guide to the Data Files and Codebook", "text": "The NELS:88 public use data files are available on four separate tapes, one for each study component: the student survey, the parent survey, the teacher survey, and the school administrator survey. The tape for the parent survey component contains a data file for 22,651 participating parents of the 24,599 participating students from 1,052 schools, including the OBEMLA student oversamples. Data records are present for parents who completed the parent questionnaire and whose child completed the student questionnaire. As indicated earlier, the parent data can be used alone Or merged with the student, teacher, or school files. Since multiple instruments were used to gather data from students, parents, teachers, and school administrators, the analyst must use the proper participation flags and weights to produce accurate statistics. Therefore, before describing the data files, several suggestions are offered that should be helpful to the analyst. These are followed by a complete description of the content and organization of the parent data file and a guide to the associated codebook. The primary purpose of the NELS:88 base year sample of parent-respondents was to provide information about student-related characteristics, parental practices, and family or home characteristics which can be linked to individual student-level records. At the student level, analysis and reporting activities will focus on the effects of parent and home characteristics on various student outcomes and responses. Because of the success in obtaining a parent questionnaire for such a high percentage of students, a separate weight adjusted for parent nonresponse was not included on either the parent or student data files. For a reasonable approximation of weighted parent values, analysts can apply the student weight BYQWT to parent responses. Note that because this is a student-based weight, the associated parent data will be missing for the 1,948 cases for which there is a student questionnaire, but no parent questionnaire. A student weight and several flags are provided (see section 7.1) in order that analyses of parent data can be conducted. Analysts intending to use the data other than as contextual data for student analysis must note that the respondents to the parent questionnaire do not constitute a statistical or representative sample of eighth grade parents (see section 3.3). These weights do not reflect the unequal chances of selection for parents because no adjustment is made for the fact that some parents had mire than one eighth grader while other parents were selected from one or two parent households. Additionally, no distinction between parent or guardian is reflected in the flags although the first question in the questionnaire provides detail on the relationship between the student and the parent or guardian respondent. In the section on the data file, the reader should pay particular attention to the composite variables, which have been specially constructed to streamline substantive analyses. Since researchers often need to control for education level, family income, educational aspirations, socioeconomic status, and the like, a set of classification variables has been carefully constructed that can be used for this purpose. Complete specifications used to create these composite variables can be found in Appendix D. Should the analyst choose to create alternatives, he or she is, of course, free to do so. One of the first steps to take before running statistical analyses is to select the proper participation flags and weight. There are four participation flags (BY indicates base year) which define subsets of the parent respondents. They include: which is 1 if the student completed the cognitive tests and 0 if he or she did not. which is 1 if the student had at least one teacher questionnaire completed and 0 if he or she did not. which is 1 to indicate that a Spanish-language questionnaire was used to gather the parent data, and is 0 if the Spanish-language questionnaire was not used. which is 1 if the student had on file an Individualized Education Program and was reported to the Department of Education as belonging to one of the following handicap categories: deaf, hard of hearing, deaf-blind, or multiple handicap (only if hard of hearing was included as one of his or her impairments); and the student is currently mainstreamed with regular hearing eighth grade students for English or mathematics classes. It is 0 if the above criteria were not satisfied. These flags should be used to select the subset of respondents the analyst intends to examine. When the user combines these with the appropriate weight, he or she can produce population mates. There is one student weight, BYQWT, which can be used with the flags to estimate the population of a subset of students or parents. For example, if data from all parents whose children completed the test are desired, BYTXPAFG should be used to select them. (Even if the analyst is running unweighted statistics, the participation flags should be used). To compute a weighted estimate of the proportion of parents in the base year who completed the questionnaire in Spanish and who stated that English is spoken in the home (Question 22B), for example, one would take the following steps: (1) use the base year flag BYSPANFG to select the 575 cases that completed the questionnaire in Spanish; (2) invoke the appropriate weight, BYQWT; and (3) run frequencies for the variable BYP22B. The appropriate participation flag(s) and/or weight should be used if unweighted and weighted analyses are to be performed correctly. See Appendix F for specific examples using the Statistical Analysis System (SAS). Although sampling weights are discussed in detail in Chapter III, a few words are warranted here. The NELS:88 data files are designed to be used as weighted data sets in all analyses. The complexity of the sample design of the base year virtually ensures inaccurate results if the data are analyzed on an unweighted basis. Clustering, multistage selection, and disproportionate sampling all contribute potential bias and various degrees of unreliability, which can be avoided by using the weights provided to analyze specific subsets of the sample. NCES has responded to numerous questions over the years having to do with statistical analyses of data from earlier longitudinal education studies and now routinely recommends the procedures outlined in Appendix F, using SAS with NELS:88 data. SPSS-X can also be used, and the data file contains the appropriate control cards for this package. Analysts should contact their own support facilities to obtain the information necessary to create an SPSS-X system file from a SAS system file and vice versa."}, {"section_title": "7.2", "text": ""}, {"section_title": "Content and Organization of the Data Files", "text": "The parent raw data file consists of 22,651 records. (Nonparticipating parents are not included on the base year data tape of a longitudinal study). Each record is organized as shownin the record layout that appears as Appendix C. The variables on the record are grouped into logical sets as discussed below. For the sake of brevity, each item of data is referred to by its SAS (SPSS-X) variable name as defined in the control cards provided with the data file. The parent data tape contains four related files. They are: 1. The raw data file, with items in the following order for each respondent: SAS system file"}, {"section_title": "Identification Codes", "text": "The first variable on the raw data file, STILID, is a unique but randomized seven-digit student identification code, which consists of a five-digit school ID, followed by a two-digit student code. Both sets of numbers have been randomly assigned to maintain confidentiality. Since there is a single parent respondent for each student, that parent respondent is identified by the corresponding student ID. If a parent has more than one child in the student survey, there is a parent record for each child. The first field of the teacher identification is the student ID. The school ID is embedded in the first five digits of each component ID. See Figure 7-1."}, {"section_title": "Parent Questionnaire Information", "text": "Information from the parent questionnaire is presented in the same order as the questions. Variables are identified by their SAS (SPSS-X) name. All variable names begin with BYP for Base Year Parent, followed by the question number. For example, BYP20A is question 20, part A, from the base year parent questionnaire. Teacher 2 J Note: Each student was rated by teachers in two subjects. For some students, both ratings were made by the same teacher. Base Year: Parent Component Data File User's Manual"}, {"section_title": "Sampling Weights", "text": "Because of the success in obtaining a parent questionnaire for such a high percentage of students, the student weight BYQWT can also be applied to provide a reasonable approximation of weighted parent statistics. See section 3.3 for the use of this weight. Note that, because this is a student based weight, the associated parent data will be missing for the 1,948 cases for which there is a student questionnaire, but no parent questionnaire. BYQWT is calculated from the design weight for the student (RAWWT), adjusted for the fact that some of the selected students did not complete the questionnaire. RAWWT is the reciprocal of the conditional selection probability within school for the student, given that the school was selected into the ,..iase year sample, multiplied by his or her school's design weight (SCHWT). Used in conjunction with the appropriate flag, it can compute population estimates for a corresponding subset of parent respondents. BYQWT is included on both the student and parent data tapes. BYADMWT is the overall design weight for schools (SCHWT) adjusted for the fact that some of the school administrators of the participating schools did not complete a school questionnaire. BYADMWT is included on the school data tape."}, {"section_title": "Composite Variables", "text": "All composite variables reflect student data. The composite variables included on the parent tape are a subset of those on the student tape. Most composite variables were constructed using responses from two or more questionnaire items. In some cases, composites were constructed from numerous variables or from variables from different data bases. Others were constructed by recoding a variable. A very few were simply copied from a different data source to the file for the user's convenience. All of the composite variables are described in detail in Appendix D, where they are listed along with flags and weight in the order in which they appear on the tape. Most of the composite variables can be used as classification variables or independent variables in data analysis. For this reason, composite variables may be referred to as classification variables in this or other NCES documents. Composites of school-level characteristics provide information about the respondent's child's school. G8TYPE classifies the type of school by the grades spanned. G8CTRL classifies the school into one of four categories, public, Catholic, other religious private, and other non-religious private. The information for G8CTRL was taken primarily from school data file after combining types of Catholic schools. BYSCENRL categorizes the school enrollment and G8ENROL categorizes the eighth grade enrollment as reported by the school. G8URBAN classifies urbanicity; this classification was taken directly from the QED (Quality Education Data) file, for the student's school. G8REGON indicates in which of the four U.S. Census regions the school is located. G8MINOR reflects by category the percentage of minority students in the eighth grade reported by the school. G8LUNCH reports by category the percentage of students in that student's school who receive free or reduced-price lunches. It was calculated from responses to the school questionnaire. For some respondent's children, a school administrator questionnaire is not available. In these cases data for G8TYPE, G8CTRL, BYSCENRL, and G8ENROL were (if available) taken from the QED (Quality Education Data) file. Base Year: Parent Component Data File User's Manual Some composites of school-level characteristics can be considered demographic information, such as school region (G8REGON) and urbanicity of the respondent's school (G8URBAN). Other composite and special variables. Many of the composite variables constructed were student demographic characteristics. SEX, RACE, HISP, API, BIRTHMO, and BIRTHYR are all examples. The SEX variable was taken first from the Student Questionnaire. If this source was missing or not available, then the sex variable from school rosters was used. Any records with this variable still missing had sex imputed from the student's name, or if that could not be done unambiguously, the value for SEX was randomly assigned. RACE also was constructed from several sources of information. The first source was the student self-report. Secondly, if the student information was missing or inconsistent with that of the parent, data from the parent questionnaire were used (see Appendix D). HISP (Hispanic subgroup), API (Asian and Pacific Island subgroup), BIRTHMO, and BIRTHYR were taken directly from the student questionnaire. Socioeconomic status can be determined from BYSES and BYSESQ. The parent questionnaire was the primary source used to construct this composite, averaging the nonmissing values of five standardized components: father's and mother's educational levels, father's and mother's occupations, and family income. For cases without parent data (8.1 percent), student data were used. The first four components from the student data are the same as the components used from parent data and a ranking of material possessions was substituted for family income. BYSESQ is simply the BYSES quartile to which the respondent belongs. Family variables include the language spoken in the home (BYHMLANG). The primary source for this composite was the student questionnaire; otherwise, parent questionnaire data were used. BYFCOMP, which categorizes the family makeup, is taken from the student questionnaire only. Additional family characteristics are available with family size (BYFAMSIZ) taken first from the student questionnaire and second from the parent questionnaire, and the highest level of education reported for either of the student's parents (BYPARED). To construct BYPARED, student data were used whenever parent data were either missing or not available. Four psychological scales for the respondent's child, designed to be as comparable as possible with those on HS&B and NLS-72, were constructed from various attitude items. These scales are intended to measure locus-of-control (BYLOCUSI and BYLOCUS2) and self-concept (BYCNCPT1 and BYCi'CPT2). BYLOCUSI and BYCNCPT1 represent only the scale items that correspond closely to NLS-72 and HS&B items. BYLOCUS2 and BYCNCPT2 represent all NELS:88 scale items. Each composite scale is the average of the standardized scores of the questionnaire items of which it is composed. For each scale a textile ranking was calculated. These variables are named: BYLOCUIT, BYLOCU2T, BYCNCP1T, and BYCNCP2T. A measure of reliability, coefficient alpha,24 was calculated for each of these scales. The values are: BYLOCUSI =. .5750, BYLOCUS2 = .6802, BYCNCPT1 = .7355, and BYCNCPT2 = .7867. For a list of the component items, the construction procedures, and the wording of the items in both NELS:88 and HS&B, see Appendix D. It is important to note that while the items are comparable, they are not always identical. Educational variables include variables constructed from the results of cognitive 'gists given to students, as well as from student questionnaire responses. Quartile results are reported f )r each of 24 Cronbach, L. J., \"Coefficient Alpha and the Internal Structure of Tests,\" Psychometrika, 16, 197-334 (1951)."}, {"section_title": "so", "text": "Base Year: Parent Component Data File User's Manual the base year cognitive tests given in the four areas of reading, mathematics, science, and social studies (history/government). The variables are BYTXRQ (base year test reading quartile), BYTXMQ (base year test mathematics quartile), BYTXSQ (base year test science quartile), and BYTXHQ (base year test history quartile). In addition, the quartile of a standardized test composite for reading and math (BYTXQURT) is reported. Seven ratings are reported that characterize the student's proficiency in reading and mathematics. These variable names begin with BYTX for base year test, followed by R for reading or M for mathematics. The variables are: reading proficiency level 1 reading proficiency level 2 overall reading proficiency mathematics proficiency level 1 mathematics proficiency level 2 mathematics proficiency level 3 overall mathematics proficiency A description of the proficiency levels and an interpretation of the overall proficiency ratings are in Appendix D. Additional variables providing greater detail on student cognitive test performance are found on the student data tape. BYGRADS is an average, with all non-missing elements equally weighted, of student self-reports for grades over the four subject areas. The source is student questionnaire item 81. BYGRADSQ is the quartile distribution of BYGRADS. BYPSEPLN characterizes the postsecondary education plans of the student and was taken directly from the aspirations stated by the student in response to BYS45. BYHOMEWK categorizes the total amount of time the student reported spending on homework a week. BYLEP specifies whether the student has Limited English Proficiency. It was constructed from the student self-evaluations and the teacher evaluations for proficiency in using the English language. BYLM was constructed from teacher and student reports and specifies whether the student is classified as Language Minority (from a home in which a language other than English is typically spoken). NOMSECT is the classification of the school the student expects to attend for tenth grade. The classifications were taken directly from the student data file, coded, and matched to the QED (Quality Education Data) files. HEARIMP indicates if the student was reported to have a hearing impairment either by the parent or by the project staff as part of the survey activity. Also, the student was classified as hearingimpaired if reported as such to the Department of Education and currently mainstreamed with regular hearing eighth grade students for English or mathematics classes. This variable is less strictly defined than BYIEPFLG. Base Year: Parent Component Data File User's Manual HANDPAST was constructed from responses on the parent questionnaire and indicates whether the student has ever participated in a program for the handicapped --that is, for persons with emotional, mental, learning, or other disabilities. BYHANDPR reflects responses on the parent questionnaire and indicates whether the student is currently participating in a program for the orthopedically handicapped or learning-disabled. BYHAND'1'R was constructed from responses on the teacher questionnaire(s) and indicates whether at least one teacher reports a handicap that interferes with school performance."}, {"section_title": "7.3", "text": ""}, {"section_title": "Guide to the Codebook", "text": "The codebook provides a comprehensive description of the parent data file. For each variable on the tape, the codebook provides a summary of the related information. The question number and wording, the variable's tape position and format, and the responses to the item, along with their unweighted frequency and percent and weighted percent, are shown. See Figure 7-2 for an example. Each portion of the example is numbered. These numbers can be used to reference the associated explanation in the text following the figure. Finally, it is worth pointing out that in general, there were no attempts at imputing data for missing parent responses. Because of this, item nonresponse may be a problem, especially for items with high item nonresponse. These topics are discussed in the item nonresponse section 3.4 and in the NELS :88 Base Year Sample Design Report.25 (2) Tape Pos. 247-247 (3) Format: Il Explanations: (1) Question number: For variables taken directly from questionnaires, this is the question number in the original document. Composite variables and other items such as flags and weights have variable names that represent their content. (2) Tape position: This item gives the starting and ending tape position for each variable on the data tape. (3) Variable format: This item indicates the type of variable, its width, and the number of positions following the decimal point, if any. (4) SAS and SPSS-X variable name: Each variable on the data tape is identified by a unique SAS and SPSS-X variable name. Data indicators (such as flags and status codes) and composite variables are given mnemonics that help identify them, for example, G8REGON for \"Grade 8 in what US Census Region\" and BYSES for \"base year socioeconomic status composite.\" For all variables the user should be careful always to refer to the variable by its SAS (SPSS-X) name in any computing procedures, rather than by its question number. (5) SAS (SPSS-X) variable label: A short variable label appears after the variable name. This label is the same as that which appears on the SAS (SPSS-X) data definition cards included on the tape. (6) Original question wording: This reproduces the exact question wording as it appeared in the questionnaire."}, {"section_title": "S9", "text": "Base Year: Parent Component Data File User's Manual 7Response categories: This item provides either the original response categories (in the case of questionnaire items) or the recoded or constructed response categories (for composite variables and data indicators, such as flags). For display in the tables, some continuous variables have been recoded to collapse all valid values into a single response category. This allows the codebook tables to show the frequency counts, unweighted percentages, and adjusted weighted percentages for continuous variables without printing each distinct value that the variable can take. These value labels are not the same as those on the SAS (SPSS-X) data definition cards. Condensed value labels that do not cause truncation problems are provided with the data definition cards. (8) Response codes: This item provides the actual numerical codes that appear on the data tape in the tape position specified (except for continuous variables, where the actual values that appear on the tape have been recoded to produce the frequency counts and percentages). Certain codes, discussed below, are reserved to indicate missing data, legitimate skip, and so forth. (9) Frequency counts: This item shows the unweighted frequency counts for all records that were processed, including records that have missing data codes, legitimate skips, and so forth. (10) Unweighted percentage frequencies: This column displays the frequency counts of item 9 as percentages. All records that were processed are included. (11) Weighted \"valid cases\" percentage frequencies: This column displays the weighted frequencies for those cases that are \"valid,\" that is, excluding those records that have been assigned reserved codes. (12) Reserved codes: In this data set certain codes, termed \"reserved codes,\" have been chosen always to stand for certain situations. NORC and Westat have different values for reserve code 6. The student and parent surveys use NORC's convention of 6 = multiple response as shown below. The school and teacher surveys use Westat's code of 6 = don't know. Reserve codes 7, 8, and 9 are identical for all study components. These reserve codes and their interpretations are: 6 = multiple response . . more than one response where only one response was called for 7 = refusal respondent refused to answer an item or refused to resolve a multiple response where only one was called for, either at the time of the questionnaire administration or at telephone follow-up 8 = missing data data that should be present for this respondent is missing, but respondent did not necessarily refuse to provide data 9 = legitimate skip ... . because of responses to preceding filter questions, data for this item should not be present for this respondent; that is, the value is legitimately missing These reserved codes correspond identically to those used in NLS-72 and in the HS&B study. The codes as listed above apply to variables with single-column data fields. For variables with fields greater than one column, the leftmost columns arc filled with 9s (e.g., 96,996,9996 3. We are asking you these questions in order to gather information about what happens to students as they move through high school and make decisions about postsecondary education and work. 4. Your responses will be merged with those of others, and the answers you give will never be identified as yours.  On the cover of this questionnaire, you will find the name of an eighth grader. Please check the cover to make certain that the child named on the cover is one for whom you or your spouse or partner are responsible. The questionnaire should be completed by the parent or guardian who is most familiar with the student's current school situation and educational plans. If you are the appropriate person, please fill out the questionnaire and return it in the postage-paid envelope provided. If neither you nor your spouse or partner are the appropriate person, please call Lee Howard collect at (312) 702-8998, to discuss the best way to get the questionnaire to the appropriate person. IMPORTANT: PLEASE READ CAREFULLY BEFORE BEGINNING THE QUESTIONNAIRE."}, {"section_title": "GENERAL INSTRUCTIONS", "text": "For any particular eighth grader, it is important that we know which individuals are referred to as the child's parents/guardians in the answers you are providing. To help us, we ask that, just for the purposes of this .survey. you use the following guidelines: TWO PARENTS OR GUARDIANS IN THE HOUSEHOLD 1. if you are the child's parent (biological or adoptive) and you are married to the child's other parent (biological or adoptive), answer all questions concerning YOUR SPOUSE/PARTNER with reference to your spouse. 2. If you are the child's parent (biological or adoptive) and you are now married to or living with someone other than the child's other parent (biological or adoptive), answer all questions concerning YOUR SPOUSE/PARTNER with reference to your current partner (not your ex-spouse). 3. If you are a grandparent of the child and you are living with one of the biological parents of the child, answer all questions concerning YOUR SPOUSE/PARTNER with reference to that biological parent  1930-1939 1940-1944 1945-194; 1950-1;54 1955-1959 1960 or later 9. In what year we your spouse/partner born? REMINDER: Use \"spouse/partner\" definition from page G. Does not apply. I do not (MARK ONE) have a spouse/partner 1929 or earlier 1930-1939 1940-1944 1945-1949 1950-1954 1955-1959 1960  (MARK ONE) None Less than $1,000 S 1.000 to $ 3.000 S 3.001 to S 6.000 S 6.001 to $10.000 $10,001 to $15.000 More than S15.000 84C. About how much money do you expect to have set aside ter your eighth grader's future education by the time he or she finishes high school? (MARK ONE) None Less than $1,000 $ 1.000 to $ 3,000 S 3,001 to $ 6.000 $ 6.001 to S10,000 S10.001 to S15.000 More than S15.000 84D. Do you expect this amount to cover the total cost of his or her education? "}, {"section_title": "E", "text": "The study you are taking part in seeks to measure changes over time in matters related to your child's education. For this reason, we may try to contact you again in the future. Since people move around a great deal, in this section we are asking you for information that will make it possible for us to locate you easily. Please be assured that any information you give us concerning either a relative or a close family friend will be used only to inquire how we might find you. Each weight, flag, and composite variable is defined below and shown in the order in which it appears on the data tape. See Chapter III for a detailed discussion of weights and Chapter VII for a brief discussion of flags and composite variables. Composites have been constructed using all four components of NELS:88. Variable names indicate from which file values were taken: BYS for base year student, BYP for base year parent, BYT for base year teacher, and BYSC for base year school."}, {"section_title": "Weight", "text": "Because of the success in obtaining a parent questionnaire for such a high percentage of students, a separate weight adjusted for parent nonresponse was not included on either the parent or the student data files. For a reasonable approximation of weighted parent values, analysts can apply the weight BYQWT to parent responses. Note that because this is a student-based weight, the associated parent data will be missing for the 1,948 cases for which there is a student questionnaire, but no parent questionnaire. BYQWT is calculated from the design weight (RAWWT) for the student, adjusted for the fact that some selected students did not complete the student questionnaire. RAWWT is the reciprocal of the conditional selection probability for the student, given that the school was selected into the base year sample, multiplied by his or her school's design weight."}, {"section_title": "Flags", "text": "The following flags indicate the completion or not of specified instruments. A value of I specifies that the instrument was completed, 0 that it was not. The first three flags, BYTXPAFG, BYTEPAFG, and BYIEPFLG, reflect the status of the respondent's child. These flags also appear on the student data file. BYTXPAFG indicates if the respondent's child completed the cognitive tests. Since students are included on the student file for whom a parent questionnaire was not completed, this flag is interpreted differently on the student file. The values for BYTXPAFG are: 1 = Student completed the tests and had a parent questionnaire completed 0 = Did not complete the tests and have a parent questionnaire completed BYTEPAFG indicates if at least one teacher completed a questionnaire for the respondent's child. Since students arc included on the student file for whom a parent questionnaire was not completed, this flag is interpreted differently on the student file. "}, {"section_title": "Student Composites", "text": "G8TYPE classifies the type of school by the grades spanned. It was coded using school data first. After the unique patterns of grade spans were determined, they were collapsed, creating the following categories. For example, G8TYPE = 1 includes schools that start with either pre-kindergarten, kindergarten, or grade 1 and that end with grade 8. The responses to BYSC1A-N were compared to established patterns to determine the appropriate grade span category. If G8TYPE was missing, then it was coded using the QED (Quality Education Data) file as a second source. The values for G8TYPE are: 1= P or K or 1 through 8 2 = P or K or 1 through 12 3 = 6 or 7 or 8 through 12 4 = 3 or 4 or 5 through 8 5 = 6 through 8 6 = 7 through 8 7 = 7 through 9/8 through 9 8 = Missing G8CTRL classifies the type of school into public, Catholic, or other private as reported by the school. The classification was collapsed from BYSC4. A few non-Catholic privates were contacted to confirm their designation. The values for G8CTRL are: Base Year: Parent Component Data File User's Manual BYSCENRL categorizes the entire school enrollment as reported by the school. The values were created by collapsing the data from BYSC2 into categories. Missing data were then imputed from the actual enrollment reported on the QED file. The values for BYSCENRL are: 1 = 1-199 students 2 = 200-399 3 = 400-599 4 = 600-799 5 = 800-999 6 = 1,000-1,199 7 = 1,200+ G8ENROL categorizes the eighth grade enrollment as reported by the school. The values were created by collapsing the data from BYSC3 into categories. Missing data were then imputed from the QED file for eighth grade schools. The values for G8ENROL are: G8REGON indicates in which of the four U.S. Census regions the school is located. It was created by recoding the sampled state of the eighth grade school into the four Census Bureau regions. In rare instances, this value was set to missing for confidentiality reasons. Base Year: Parent Component Data File User's Manual G8MINOR reflects the percentage of minority students in the eighth grade reported by the school. It was constructed by adding nonreserve code values of BYSCI3A -D and categorizing the result. If the school questionnaire was missing or if BYSC13A-D were missing, G8MINOR was set to missing. The values for G8MINOR are: 0 = None 1 = 1-5% 2 = 6-10% 3 = 11-20% 4 = 21-40% 5 = 41-60% 6 = 61-90% 7 = 91-100% 8 = Missing G8LUNCH categorizes the percentage of free or reduced price lunch at the school calculated from the school questionnaire. It was constructed by dividing BYSC16A by BYSC2, multiplying by 100, rounding to the nearest whole number and coding the result. If the school questionnaire was missing or if BYSC16A was missing, G8LUNCH was set to missing. The value for G8LUNCH are: NOMSECT is the classification of the school the student expects to attend for tenth grade. The student response to BYS13 was assigned a Permanent Identification Number from the QED (Quality Education Data) directory. This link to the QED data was then used to assign a value of public, Catholic, or other private to the first nominated tenth grade school. The values for NOMSECT are: 1 = Public school 2 = Catholic school 3 = Other private school 8 = Missing, the student did not answer BYS13 or the school nominated could not be linked to data from QED SEX of the student respondent was taken first from the \"Your Background\" (BYS12) section of the student questionnaire. If this source was missing or not available, then the value of the 4 re; Crosstabulations of students' self-categorization with parents' self-categorization indicated that roughly 60 percent of the 924 students who said they were American Indian or Alaskan Native had parents who classified themselves as \"white, not Hispanic.\" While parent-student ethnicity reports logically need not match--the one parent or step-parent interviewed represents, after all, only a part of the child's racial-ethnic background --empirically, one would not expect so large a discrepancy if the race-ethnicity item were working well. One hypothesis was that students were confused by the \"white, not of Hispanic origin\" category and were drawn to the \"American\" in American Indian. This hypothesis was tested by calling a random sample of students' parents and asking the parents to verify the race/ethnicity of the child. , The parent was not told how the child had actually responded. The parent was asked to use the eighth grader, rather than self, as the reference point. One hundred parents were interviewed about the race and ethnic background of their child. Ninety-three of the parents said their child was \"white, not of Hispanic origin.\" Six parents said that their child was \"American Indian or Alaskan Native,\" and one parent indicated that the child was \"black, not of Hispanic origin.\" In the base year field test, race/ethnicity and parent occupation were found to be among the most difficult questions for eighth graders to answer. On the basis of these findings, it was decided to recode the 625 students who responded \"American Indian or Alaskan Native\" and whose parent responded \"white, not Hispanic\" to BYP10 to \"white, not Hispanic\" for this composite. BYS31A was left unchanged so that the analyst has access to the actual respondent data. The values for RACE are: 1 = Asian or Pacific Islander 2 = Hispanic, regardless of race 3 = Black, not of Hispanic origin 4 = White, not of Hispanic origin 5 = American Indian or Alaskan Native 8 = Missing, BYS31A was not answered HISP characterizes the Hispanic subgroup to which the student belongs. If BYS31A was equal to 1, 3, 4, or 5, then this variable was coded \"0.\" If BYS31A was either 2 or a reserve code, then the value for BYS31C was checked. If BYS31C contained a valid value (not a reserve code) of 1-4, then that value was assigned to HISP; otherwise this variable was coded \"8.\" Base Year: Parent Component Data File User's Manual The values for HISP are: 0 = non-Hispanic 1 = Mexican, Mexican-American, Chicano 2 = Cuban 3 = Puerto Rican 4 = Other Hispanic 8 =Missing API specifics to which Asian or Pacific Island group the student belongs. If BYS31A was equal to 2, 3, 4, or 5, then this variable was coded \"00.\" If BYS31A was either 1 or a reserve code, then the value for BYS31B was checked. If BYS31B contained a valid value (not a reserve code) of 01-10, then that value was assigned to API; otherwise this variable was coded \"98.\" Note that groups 01-06 only were oversampled for inclusion in the OBEMLA supplement. The values for API are: HEARIMPI classifies the student as either hearing-impaired or not. It was constructed by initializing HEARIMP to 0 and then setting it to 1 if either of the following criteria were met: 1. If the student had on file an Individualized Education Program and was reported to the Department of Education as belonging to one of the following handicap categories: deaf, hard-of-hearing, deaf-blind, or multiple handicap (only if hard-of-hearing was included as one of his or her impairments); AND the student is currently mainstreamed with regular hearing eighth grade students for English or mathematics classes (BYIEPFLG = 1)."}, {"section_title": "2.", "text": "If in the course of drawing up the roster of students for the school or in administering the instruments, project staff determined that any student satisfied only one of the requirements listed above, BYIEPFLG was set to 0 and that student was listed as part-eligible. This part-eligible list was used to set HEARIMP to 1.\nYou may have to delete at least one third of the label cards given in this file because of SAS system limitations which are present at many computer installations."}, {"section_title": "1", "text": "Note that the frequency of reported impairment or handicap is influenced by the eligibility criteria and participation patterns, which tended to eliminate more severely impaired or handicapped students. Please see section 3.1.1 for details."}, {"section_title": "130", "text": "Base Year: Parent Component Data File User's Manual 3. If the parent reported a problem (BYP47B = 1 or BYP47C .-. 1 or BYP48B = 1 or BYP48C = 1). Please note that if HEARIMP is set to 1 because of satisfying criterion 3, the student may have been impaired in the past without necessarily being so in the present. The values for HEARIMP are: 0 = Not reported as hearing-impaired 1 = Hearing-impaired HANDPAST2 was constructed from responses on the parent questionnaire and indicates whether the student has ever participated in a program for the handicapped. The values for HANDPAST are: 0 = Not past handicap program recipient (BYP48A through BYP48J are 0) 1= Past handicap program recipient (if any BYP48A through BYP48J = 1) 8 = Missing, no parent questionnaire, or BYP48A through BYP48J are missing BYHANDPR3 was constructed from responses on the parent questionnaire and indicates whether the student is currently participating in a program for the orthopedically handicapped or learning disabled. The values for BYHANDPR are: 0 = Not current program participant (BYP49C and BYP49D are 0) 1 = Current program recipient for orthopedically handicapped or learning disabilities (BYP49C or BYP49D = 1) 8 = Missing, no parent questionnaire or BYP49C and BYP49D are missing BYHANDTR4 was constructed from responses on the teacher questionnaire(s) and indicates whether at least one teacher reports a handicap that interferes with school performance. The values for BYHANDTR are: 0 = Neither teacher reported any handicaps interfering with school performance (BYT1_10 is 0) 1 = Either teacher reports a handicap (BYT1_10 is 1) 8 = Missing, no teacher questionnaire or BYT1_10 is missing BIRTHMO for student was taken directly from BYS11 of the student questionnaire. Its range is 1-12 with 98 indicating missing. BIRTHYR for student was coded from BYS11 of the student questionnaire. All values less than 72 were set to 72 and all values greater than 75 were set to 75. 72 = 1972 or before 73 = 1973 74 = 1974 75 = 1975 or after 98 = Missing BYLOCUS1 for student was designed to be as comparable as possible with HS&B and NLS-72 data. Locus of control items are all in student question 44. They are BYS44B, BYS44C, BYS44F, BYS44G, BYS44K, and BYS44M. Three of these items are comparable to HS&B and NLS-72 items. They are BYS44C, BYS44F, and BYS44G. It is important to note that while comparable, they are not always identical. For the user's convenience, the NELS:88 items appear below along with the HS&B and NLS-72 items, which appear in parentheses. BYS44C: In my life, good luck is more important than hard work for success. (Good luck is more important than hard work for success.) BYS44F: Every time I try to get ahead, something or somebody stops me. (Text identical.) BYS44G: My plans hardly ever work out, so planning only makes me unhappy. (Planning only makes a person unhappy, since plans hardly ever work out anyway.) NO COMPARABLE NELS:88 ITEM. (People who accept their condition in life are happier than those who try to change things.) Each of the above three items was standardized separately to a mean of zero and a standard deviation of 1 using BYQWT. All nonmissing components were averaged. Any student mi ,sing all components was assigned a missing value (8). The actual range for BYLOCUSI is -3.01 through 1.52, from low to high control; 99.98 indicates missing. BYLOCUlT is the tertile into which BYLOCUSI falls. It was constructed by recoding BY-LOCUS1 into three categories (low, medium, and high), based on the weighted, BYQWT, marginal distribution. The values for BYLOCUIT are: 1 = Tertile I Low 2 = Tertile 2 Medium 3 = Tertile 3 High 8 = Missing BYLOCUS2 for student is the composite of the locus of control items in student question 44. They are BYS44B, BYS44C, BYS44F, BYS44G, BYS44K, and BYS44M. BYS44K is a reverse scoring item so the values were reversed before performing computations. Each of these 6 items was standardized separately to a mean of zero and a standard deviation of 1 using BYQWT. All nonmissing components were averaged. Any student missing all components was assigned a missing value (8)."}, {"section_title": "1:12", "text": "3ase Year: Parent Component Data File User's Manual The actual range for BYLOCUS2 is -3.01 through 1.52, from low to high control; 99.98 indicates missing. BYLOCU2T is the tertile into which BYLOCUS2 falls. It was constructed by recoding BY-LOCUS2 into three categories (low, medium, and high), based on the weighted, BYQWT, marginal distribution. The values for BYLOCU2T are: 1 = Terti le 1 Low 2 = Tertile 2 Medium 3 = Tertile 3 High 8 = Missing BYCNCPT1 for student was designed to be as comparable as possible with HS&B and NLS-72 data. Self-concept items are all in student question 44. They are BYS44A, BYS44D, BYS44E, BYS44H, BYS44I, BYS44.1, and BYS44L. Four of these items are comparable to HS&B and NLS-72 items. They are BYS44A, BYS44D, BYS44E, and BYS44H. These same four items are all reverse scoring items so the values were reversed before performing computations. It is important to note that while comparable, they are not always identical. For the user's convenience, the NELS:88 items appear below along with the HS&B and NLS-72 items, which appear in parentheses. Each of the above four items was standardized separately to a mean of zero and a standard deviation of 1 using BYQWT. All nonmissing components were averaged. Any student missing all components was assigned a missing value (8). The actual range for BYCNCPT1 is -3.61 through 1.15, from low to high esteem; 99.98 indicates missing. BYCNCP1T is the tertile into which BYCNCPTI falls. It was constructed by recoding BY-CNCPT1 into three categories (low, medium, and high), based on the weighted, BYQWT, marginal distribution. The values for BYCNCP1T are: Base Year: Parent Component Data File User's Manual BYCNCPT2 for student is the composite of the self-concept items in student question 44. They are BYS44A, BYS44D, BYS44E, BYS44H, BYS44I, BYS44D, and BYS44L. BYS44A, BYS44D, BYS44E, and BYS44H are reverse scoring items so the values were reversed before performing computations. Each of the above seven items was standardized separately to a mean of zero and a standard deviation of 1 using BYQWT. All nonmissing components were averaged. Any student missing all components was assigned a missing value (8). The actual range for BYCNCPT2 is -3.61 through 1.25, from low to high esteem; 99.98 indicates missing. BYCNCP2T is the tertile into which BYCNCPT2 falls. It was constructed by recoding BY-CNCPT2 into three categories (low, medium, and high), based on the weighted, BYQWT, marginal distribution. The values for BYCNCP2T are: 1 = Tertile 1 Low 2 = Tertile 2 Medium 3 = Tertile 3 High 8 = Missing BYSES for student was constructed using the following parent questionnaire data: father's educational level, mother's educational level, father's occupation, mother's occupation, and family income (data coming from BYP30, BYP31, BYP34B, BYP37B, and BYP80). Educational-level data were recoded as for the composite BYPARED (with the exception of category \"7,\" which was coded as missing for BYSES calculations; see BYPARED). Occupational data were recoded using the Duncan SEI scale as used in HS&B. Each nonmissing component (after any necessary recoding) was standardized to a mean of 0 and a standard deviation of 1. Nonmissing standardized components were averaged yielding the BYSEScomposite. The parent data were used to construct BYSES if at least one component was not missing. For cases where all pa. nt data components were missing (8.1 percent of the participants), student data were used to compute the BYSES. The first your components from the student data are the same as the components used from parent data (i.e., educational-level data, BYS34A & BYS34B, similarly recoded; occupational data, BYS4B and BYS7B of student questionnaire part one, also recoded). The fifth component for BYSES from the student data consisted of summing the non-missing household items listed at BYS3A-P (after recoding \"Not Have Item\" from \"2\" to \"0\"), calculating a simple mean of these items, and then standardizing this mean. If eight or more BYS35A-P were nonmissing this component was computed; otherwise it was set to missing. All components coming from student data were standardized. Nonmissing standardized components were averaged, yielding the BYSES composite for those cases where parent data were either missing or not available. The student data were used to construct BYSES if all components based on parent data were missing and at least one component based on student data was not missing. Otherwise BYSES was set to missing. The actual range for BYSES is -2.97 through 2.56, with 99.998 indicating missing. BYSESQ is the quartile into which BYSES falls. It was constructed by recoding BYSES into quartiles based on the weighted, BYQWT, marginal distribution. BYPARED characterizes the level of education attained by either of the parents of the student. It was constructed using parent questionnaire data (BYP30 and BYP31). Student data (BYS34A and BYS34B) were used whenever parent data were either missing or not available. If both parent and student data were missing, BYPARED was assigned a value of missing. Highest valid value for a given source became BYPARED. The following table shows the relatiGnships between what was reported on the parent and student questionnaires and the value assigned to the variable BYPARED. Greater than high school and less than 4-year degree Missing BYFAMSIZ reports the student's estimated family size. It was computed using both the parent and student questionnaires. If all of BYS8A-I were reserved codes, then BYFAMSIZ was coded as missing. Otherwise the number was 1 for the respondent plus an estimate for the number of siblings (detailed below) plus the number of family members other than siblings as marked in items BYS8A-D and BYS8G-I. (This procedure counts only 1 person each for BYS8G-I, even if more than one person in each category lives in the household.) The first reference used for the number of siblings is BYP3B. If that is a reserve code, then BYS32 is used instead. If neither BYP3B nor BYS32 listed any siblings, then one sibling is counted for each item marked in BYS8E and BYS8F as a final source. All values for BYFAMSIZ which are greater than 9 were set to 10, creating the end value of 10 which means 10 or more. The values for BYFAMSIZ are: BYHMLANG characterizes primary language use in the home by differentiating between English or non-English languages and whether that language was the only language or the dominant among several spoken. The classification is made from the student questionnaire data. If no language other than English is spoken (BYS21 = 2), the student is English Only; if the language usually spoken is English (BYS22 = 1) but another language is used (BYS23 = 2 to 96), the student is English Dominant. If another language is usually used (BYS22 = 2 to 13), then the student is assigned to Non-English Only when no other language is spoken in the home (BYS23 = 0) or to Non-English Dominant if there is another language used in the home (BYS23 = I to 96). When the language use cannot be determined from the student questionnaire, data from the parent questionnaire is used to construct the variable. If no language other than English is spoken (BYP22A = 2), the student is English Only; if the language usually spoken is English (BYP23 = 1) but another language is also used (BYP22A = 1), the student is English Dominant. If another language is usually used (BYP22A = 1 and BYP23A > 1), then the student is assigned to Non-English Only if English is not spoken in the home (BYP22B = 2) or to Non-English Dominant if English is also spoken (BYP22B = 1). If language use cannot be determined from either the student or the parent questionnaire, the value is coded missing. The values for BYHMLANG are: 1 = Non-English Only 2 = Non-English Dominant 3 = English Dominant 4 = English Only 8 = Missing BYPSEPLN characterizes the postsecondary school plans of the student and was taken directly from BYS45. The values for BYPSEPLN are: 01 = Won't finish high school 02 = Will graduate from high school but won't go further 03 = Will go to vocational, trade, or business school after high school 04 = Will attend college 05 = Will graduate from college 06 = Will attend a higher level of school after graduating from college 93 = Missing Base Year: Parent Component Data File User's Manual BYHOMEWK categorizes the number of hours per week spent doing homework as reported by the student respondent. It was computed as follows. BYS79A through BYS79E were recoded so that: None = 0 Less than 1 hour = .5 1=1,2=2,3=3 4-6 = 5 7-9 = 8 10 or more = 10. The nonmissing recoded values were summed across subjects and assigned to one of the categories below. If any subjects were missing, then BYHOMEWK was set to missing. The values for BYHOMEWK are: 01 = None 02 = 50 to 1.99 hours 03 = 2.00 to 2.99 04 = 3.00 to 5.49 05 = 5.50 to 10.49 06 = 10.50 to 12.99 07 = 13.00 to 20.99 08 = 21.00 or more 98 = Missing BYLEP5 specifies whether the student has Limited English Proficiency. It was constructed from the student self-evaluation and the to her evaluations for proficiency in using the English language. BYLEP was set to 1 if the student responded to any of BYS27A, BYS27B, BYS27C, or BYS27D with 4 (\"Not very well\"), or if either teacher marked yes to BYT1_12, which asks if the student is a Limited English Proficiency student. If both the student responses to BYS27A-D and the teacher response to BYT1_12 were missing, BYLEP was set to missing. It was 0 otherwise. Section 3.1.1 includes details of exclusions from the sample that must be considered when using this flag in analysis. The values for BYLEP are: 0 = The student is not reported to be Limited English Proficiency 1 = The student is self-reported as Limited English Proficiency or so reported by one of his or her teacbrs 8 = Missing 5 Note that the frequency of reported English language limitations is influenced by the eligibility criteria and participation patterns, which tended to eliminate those with more severe English deficiencies. Please see section 3.1.1 for more information."}, {"section_title": "7,1", "text": "Base Year: Parent Component Data File User's Manual BYLM6 specifies whether the student is classified as Language Minority (from a home in which a language other than English is typically spoken). If either teacher answered yes to BYT1_11, or if the student response to BYS22 indicates a language other than English is usually spoken in the home (values 2-13), the student is classified as Language Minority. If both the student response to BYS22 and his or her teachers' responses to BYT1_11 were missing, the value for BYLM was set to missing. It was 0 otherwise. The values for BYLM are: 0 = The student is not classified Language Minority 1 = The student is classified Language Minority 8 = Missing BYGRADS is an average, with all nonmissing elements equally weighted, of the self-reports for grades over the four subject areas (English, mathematics, science, and social studies). The source is student questionnaire item 81. It was computed by converting the response categories in BYS81A through BYS81D to a five-point scale (mostly As = 4, Bs = 3, Cs = 2, Ds = 1, mostly below D = .5, else set 8) and taking the mean of all nonmissing values of these four variables equally weighted. The mean was rounded to one decimal place. The range for BYGRADS is 0.5-4.0 with 9.8 indicating missing. BYGRADSQ is the quartile distribution of BYGRADS. It was constructed by recoding BY-GRADS into quartiles based on the weighted, using BYQWT, marginal distribution. The values for BYGRADSQ are: "}, {"section_title": "Test Results", "text": "The following composites are all based upon the cognitive tests that were given to participating students. Quartile results (1 = low) are reported for each of the base year tests in the four areas of reading, mathematics, science, and social science (history/ government) as well as for a standardized test composite score for reading and mathematics. The student data file has more detailed results including number right, number wrong, number not attempted, formula score, standardized score, IRT (Item Response Theory)-estimated number right and IRT-estimated formula score for each test, as well as full scores for the standardized test Two overall ratings are reported that characterize the student's proficiency in reading and mathematics. Proficiency calculations use a refinement of the student weight (BYQWT) that adjusts for the fact that not all students who completed the questionnaire completed the cognitive tests. These variable names begin with BYTX for base year test, followed by R for reading or M for mathematics. The variables and their values are: The values for BYTXRPRO, overall reading proficiency, are: In addition to the core sample and survey described in the main text, several other supplemental components were undertaken and data files generated under the auspices of the NELS:88 base year study. These include: several state augmentations; a supplement of hearing-impaired students, funded by Gallaudet University; a supplement of Christian schools that are members of the Christian Schools International organization, funded by the Barnabas Foundation; the NELS:88 Enhancement Survey of Middle Grades Practices, funded by the Office of Educational Research and Improvement (OERI), through the Johns Hopkins University Center for Research on Elementary and Middle Schools (CREMS); the collection of transcripts for the base year teacher sample, sponsored by the National Science Foundation; and the production of a modularized version of the NELS:88 data in IBM-compatible format on floppy diskettes, sponsored by a grant from the National Science Foundation and the U.S. Department of Education. These auxiliary data files greatly expand and enrich the analytic uses of the public use data sets. The NCES-sponsored core sample of 1,052 participating schools and 24,599 participating students was increased to 1,242 participating schools and 28,397 participating students, respectively, as a result of the state augmentations and Christian schools supplements. Data for the state augmentations and all supplements discussed below do not appear on the NCES public release tapes for NELS:88."}, {"section_title": "Christian Schools Supplement", "text": "A sample of Christian schools that are members of the Christian Schools International (CSI) organization was drawn to supplement NELS:88. The sample was selected from CSI schools with probability proportional to eighth grade size. Two disproportionately large school units were doublesampled. Of the initially contacted 58 schools, 41 schools agreed to participate. (Due to the doublesampling of the two schools, the number of sampling units was 43.) Students, parents, teachers, and school administrators were surveyed. Students completed both the cognitive test battery and the questionnaire during the Survey Days held in their schools."}, {"section_title": "State Augmentations and Supplements", "text": "In an effort to enhance the statistical precision of their state samples, four states sponsored sample augmentations by adding schools and students in their states. Three of these states also sponsored instrument supplements in the form of additional questions pertaining to policy issues of interest to their states."}, {"section_title": "Survey of NELS:88 Base Year Dropouts", "text": "Seven months after completion of in-school data collection (in January 1989), the small number of dropouts from the base year core sample were surveyed. These were students who were eligible to participate at the time that the school roster was annotated to indicate eligibility by the school coordinator. They were drawn into the sample but then dropped out between the time of sampling and their school's Survey Day. Students who drop out of school subsequent to their base year Survey Day will be captured in the NELS:88 first follow-up. A student was designated a \"dropout\" when several conditions were met: the student had been absent from the school for at least twenty consecutive days, the absence was not excused, and it was the opinion of the school coordinator that the child would not return to school. According to this definition, chronic truants who had not taken legal action to leave school (or could not take such action owing to their age) could also be designated dropouts. In identifying the dropouts, significant definitional problems were encountered as plans for the dropout survey progressed. On Survey Day, school coordinators identified 96 absent sample members as dropouts. However, the following autumn, it was learned that most of these students were not dropouts at all, but had transferred to other schools. Thus, during the five to seven month period following the Survey Day, when NORC staff were engaged in locating and interviewing the dropouts in the sample, it was frequently the case that students who had been originally classified as 1987-1988 school year dropouts had to be reclassified based on new information that became available. For the purposes of this survey, we attempted to collect data from all students who were dropouts or truants as of their base year Survey Day. The sample of eligible base year dropouts, whose status was verified, contained 29 dropouts and one parent of each child. The locating task was made more difficult by the fact that, unlike those who had completed the questionnaires on Survey Day, these children had not provided any locating information. The locating information was first sought at the child's former school. If the school was not able to provide a valid current address, calls were made to directory assistance and to selected former classmates of the child. Field interviewers were able to locate 26 of the 29 students. Of the 26 locatable children, 25 participated; of the 26 locatable parents, all 26 participated. The response rate was 86 percent for the dropouts and 90 percent for their parents. Although the sample is small, it is a national probability sample of eighth grade dropouts. In the NELS:88 first follow-up, these dropouts will be surveyed again in spring 1990. The instruments for the dropouts differed only slightly from those used for the core sample of students. Both the base year student and base year parent questionnaires were modified in order to reflect the later administration date and changed school status of the children. Certain questions were reworded to reflect the appropriate point of reference. For example, \"since the beginning of this school year\" was changed to \"when you were in eighth grade.\" Questions about school situation were deleted as no longer directly relevant to the situation of the dropout when they referred to such things as high school attendance plans and courses in which the student was currently enrolled. Student cognitive tests were not administered, nor was teacher information collected for the dropouts. The data collection procedures also differed from those used in the main study. Both student/dropout and parent questionnaires were completed by telephone interviews or, for the significant number of respondents without telephones, in personal interviews by NORC field staff. Locating and data collection were conducted between November. 1988 and January, 1989."}, {"section_title": "CREMS NELS:88 Enhancement Survey of Middle Grades Practices", "text": "The Survey of Middle Grades Practices enhances the NELS:88 base year school questionnaire by collecting new information to monitor middle grades reform in the schools attended by NELS:88 eighth graders. The questionnaire for this supplemental survey was designed by the Center for Research on Elementary and Middle Schools (CREMS) of the Johns Hopkins University and the data collection was conducted by NORC. The school principals who provided base year information in the NELS:88 school questionnaire were asked to participate in this enhancement survey between late October 1988 and February 2   143Base Year: Parent Component Data File User's Manual 1989. The enhancement survey augments the information in the base year school questionnaire with details on school and classroom characteristics and practices, including school organization, guidance and advisory practices, rewards for and evaluatic s of student performance, curriculum and instructional practices, transition to high school, middle grade programs, parent involvement, and team teaching. Included in the enhancement survey is an alternative version of an item on classroom organization. This item from the CREMS data has been appended to the base year school file. It should be noted that the original question on the organization of classroom instruction (see school codebook, BYSC18) was asked during the 1987-1988 school year, while the correction item was asked during and references the 1988-1989 school year. The unweighted completion rate for the enhancement survey was 98.63 percent."}, {"section_title": "Collection of NELS:88 Teacher Transcripts", "text": "In order to assess teacher qualifications in science and mathematics, NELS:88 participating teachers were asked for permission to obtain copies of their college transcript records. The National Science Foundation will use the transcripts to conduct research on college coursetaking patterns of teachers in order to assess and improve teacher education and training programs. Under a grant from the NSF, Westat began collecting the college transcripts in the fall of 1988. Based on the NELS:88 design, a total of 1,881 mathematics and science teachers (or the total number of those who gave permission to obtain their college transcripts) are participating in the Transcript Study, requiring transcript collection and follow-up efforts at registrars' offices at approximately 1,200 postsecondary institutions. Two data files will be developed to facilitate the analysis of the relationship between transcript-based measures of teacher qualifications and teacher characteristics and practices. One file will link the teacher transcript measures with applicable teacher and school survey data sets from NELS:88. The second file will link the teacher transcript measures to NELS:88 student questionnaire and cognitive test data."}, {"section_title": "Modularized Version of NELS:88 Data for Floppy Diskettes", "text": "An education longitudinal analysis group at the University of Chicago, sponsored by the National Science Foundation and the U.S. Department of Education, will produce a modularized version of the NELS:88 base year data for floppy diskettes. The modularized version of the data will be appropriate for modern IBM-compatible computing environments and it will make the data easily and more economically accessible for research and policy-related use by a wider audience. The modularized NELS:88 data will be made available by NCES."}, {"section_title": "Past Studies and Data Files Related to NELS:88 Available from NCES", "text": "Data from the earlier NCES longitudinal studies--NLS-72 and HS&B--may also be of some interest to users of the NELS:88 data. These data sets will be of special interest in later waves of NELS:88, when cross-cohort comparisons will be possible (for example, comparisons of the NELS:88 1990 sophomores and the HS&B 1980 sophomores; comparison of the 1992 NELS:88 seniors and the HS&B sophomore and senior cohorts in 1982and 1980, and NLS-72 seniors in 1972. In addition to the core survc .; for HS&B and NLS-72, briefly described earlier, records studies have been undertaken, including the collection of the high school transcripts of the sophomore co-Base Year: Parent Component Data File User's Manual hort and the collection of postsecondary education transcripts and financial aid data for the seniors. Data files for these studies and other HS&B data, such as parent surveys, school surveys, teacher comments, etc., are described below. Users manuals or other forms of documentation are available from NCES for all the data files. These auxiliary data files greatly expand the analytic potential of the core data sets, and researchers are encouraged to become familiar with them."}, {"section_title": "HS&B Base Year Files", "text": "The Language File contains information on each student who during the base year reported some non-English language experience either during childhood or at the time of the survey. This file contains 11,303 records (sophomores and seniors combined), with 42 variables for each student. The Parent File contains questionnaire responses from the parents of about 3,600 sophomores and 3,600 seniors who are on the Student File. Each record on the Parent File contains a total of 307 variables. Data on this file include parents' aspirations and plans for their children's postsecondary education. The Twin and Sibling File contains base year responses from sampled twins and triplets; data on non-sampled twins and triplets of sample members; and data from siblings in the sample. This file (2,718 records) includes all of the variables that are on the HS&B student file, plus two additional variables (family ID and SETTYPEtype of twin or sibling). The Sophomore Teacher File contains responses from 14,103 teachers on 18,291 students from 616 schools. The Senior Teacher File contains responses from 13,683 teachers on 17,056 students from 611 schools. At each grade level, teachers had the opportunity to answer questions about HS&B-sampled students who had been in their classes. The typical student in the sample was rated by an average of four different teachers. Preliminary analyses by NCES indicate that the files contain approximately 76,000 teacher observations of sophomores and about 67,000 teacher observations of seniors. The Friends File contains identification numbers of students in the HS&B sample who were named as friends of other HS&B-sampled students. Each record contains the IDs of sampled students and IDs of up to three friends. Linkages among friends can be used to investigate the sociometry of friendship structures, including reciprocity of choices among students in the sample, and to trace friendship networks."}, {"section_title": "Merged HS&B Base Year, First, Second and Third Follow-Up Files", "text": "The First Follow-Up Sophomore File contains responses from 29,737 students and includes both base year and first follow-up data. This file includes information on school, family, work experiences, educational and occupational aspirations, personal values, and test scores of sample participants. Students arc also classified in terms of high school status as of 1982 (that is, dropout, same school, transfer, or early graduate). The First Follow-Up Senior File contains responses from 11,995 individuals and includes both base year and first follow-up data. This file includes information from respondents concerning their high school and postsecondary experiences and their work experiences. The Second Follow-Up Sophomore File has all base year, first follow-up, and second follow-up data for 14,825 members of the sophomore cohort. Data cover work experience, postsecond-Base Year: Parent Component Data File User's Manual ary schooling, earnings, periods of unemployment, and so forth, for the sophomore cohort, who by this time had been out of high school for two years. The Second Follow-Up Senior File encompasses all base year, first follow-up, and second follow-up data for the 11,995 individuals who constitute this follow-up sample. Data cover work experience, postsecondary schooling, earnings, periods of unemployment, and so forth, for the senior cohort, who by this time had been out of high school for four years. The Third Follow-Up Sophomore File includes all base year, first follow-up, second followup, and third follow-up data for the 14,825 members of the sophomore cohort. Data cover marriage and family formation, work experience, postsecondary schooling and interest in graduate degree programs, earnings, periods of unemployment, and alcohol consumption for this cohort, who by 1986 had been out of high school for four years. The Third Follow-Up Senior File includes all base year, first follow-up, second follow-up, and third follow-up data for the 11,995 individuals who constitute this follow-up sample. Data cover marriage and family formation, work experience, postsecondary schooling and interest in graduate degree programs, earnings, periods of unemployment, and alcohol consumption for the senior cohort, who by 1986 had been out of high school for six years."}, {"section_title": "Other HS&B Files", "text": "The High School Transcript File describes the coursetaking behavior of 15,941 sophomores of 1980 throughout their four years of high school. Data include a six-digit course number for each course taken, along with course credit, course grade, and year taken. Other items of information, such as grade point average, days absent, and standardized test scores, are also contained on the file. The Offerings and Enrollments File contains school information, course offerings, and enrollment data for 957 schools. Each course offered by a school is identified by a six-digit course number. Other information, such as credit offered by the school, is also contained on each record. The Updated School File contains base year data (966 completed questionnaires) and first follow-up data (956 completed questionnaires) from the 1,015 participating schools in the HS&B sample. First follow-up data were requested only from those schools that were still in existence in the spring of 1982 and had members of the 1980 sophomore cohort currently enrolled. Each high school is represented by a single record that includes 230 data elements from the base year school questionnaire, if available, along with other information from the sampling files (e.g., stratum codes, case weights). The Postsecondary Education Transcript File for the HS&B seniors contains transcript data on dates of attendance, fields of study, degrees earned, and the titles, grades, and credits of every course attempted at each school attended, coded into hierarchical files with the student as the highest level of aggregation. Although no survey forms were used, detailed procedures were developed for extracting and processing information from the postsecondary school transcripts that were collected for all members of the 1980 senior cohort who reported attending any form of postsecondary schooling in the first or second follow-up surveys. (Over 7,000 individuals reported over 11,000 instances of school attendance.) The HS&B HEGIS and PSVD File contains the postsecondary school codes for schools HS&B respondents reported attending in the first and second follow-ups. In addition, the file provides data on institutional characteristics, such as type of institution, highest degree offered, enrollment, admissions requirements, tuition, and so forth. This file permits analysts to link HS&B questionnaire data with institutional data for postsecondary schools attended by respondents."}, {"section_title": "NLS-72 Files", "text": "The NLS-72 Base Year Through Fourth Follow-Up (1979) File contains data from the base year through fourth follow-up for over 23,000 respondents. Data include school experiences and test results during the base year and subsequent activities related to work, postsecondary schooling, military service, family formation, and goals and aspirations. The NLS-72 Fifth Follow-Up File consists of the results of the fifth follow-up survey, carried out in 1986, when sample members were about thirty-two years old. Data include work experience going back to 1979, postsecondary schooling, extensive family formation history, periods of unemployment, goals and aspirations, and selected attitudes. Records in this file can be linked through student ID to those in the NLS-72 Base Year Through Fourth Follow-Up (1979). The NLS-72 Teacher Supplement File contains the responses of the portion of the fifth follow-up NLS-72 sample who had obtained teacher certification and/or had teaching experience. Data include certification history, subjects taught, years of experience, attitudes toward teaching as a career, and subsequent work experiences of those who had left teaching. These data can be linked through the respondent ID to the NLS-72 Fifth Follow-Up File and to the NLS-72 Base Year Through Fourth Follow-Up File. The Postsecondary Education Transcript Study of the NLS-72 Sample contains transcript data on dates of attendance, fields of study, degrees earned, and the titles, grades, and credits of every course attempted at each school attended, coded into hierarchical files with the student as the highest level of aggregation. Although no survey forms were used, detailed procedures were developed for extracting and processing information from the postsecondary school transcripts that were collected in 1984 for all members of the NLS-72 cohort who reported attending any form of postsecondary schooling in any of the first through fourth follow-up surveys. (Over 14,000 individuals reported over 24,000 instances of school attendance)."}, {"section_title": "I 7", "text": "Base Year: Parent Component Data File User's Manual Guidelines for Using SAS with NELS:88 Parent Data The files provided on the public release tape include SAS cards and a SAS system file. The SAS system file includes: 1) Base Year Questionnaire Data 2) Base Year Flags, Weight, and Composites NCES and NORC strongly suggest that all SAS users be aware of the potential problem areas when using the parent data files via SAS. 1. SAS users should use the '(KEEP=...)' and '(DROP =...)' options in the 'SET...;' statement and/or in the 'DATA...;' statement when creating working data files so that unwanted variables are not included in the files. It is faster (but not essential) for variables in the '(KEEP=...)' statement to be listed in the same order as they occur in the main system file. Remember also that the '(KEEP=...)' option does not reorder the variables in the new data set."}, {"section_title": "3.", "text": "The large number of VALUE cards in the PROC FORMAT section requires that a special DD statement be placed just after the //EXEC SAS card to increase the capacity of the format library during a SAS run: //LIBRARY DD SPACE= (TRK,(25,25,60)) This may not be possible at some computer installations, so it may be necessary to delete some values."}, {"section_title": "4.", "text": "When working with large files, it may be necessary to override the default work space with the following DD card: //WORK DD UNIT=SYSCR,SPACE= (CYL,(40,40)) Place the //WORK DD card just after the //EXEC SAS card (or after the //LIBRARY DD card, if that is included as well)."}, {"section_title": "5.", "text": "The formats given in the PROC FORMAT step here are not permanently associated with each variable. Whenever they are needed for a procedure, it is necessary to include them in this PROC FORMAT step before the procedure that will use them, as shown in the following example: //EXEC SAS,OPTIONS=INOCRAPHICS',REGION=1280K //LIBRARY DD SPACE= (TRK,(25,25,60) VALUE FBYP41V 1 = \"YES\" 2 = \"NO\" 6 = \"MULTIPLE RESPONSE\" 7 = \"REFUSAL\" 8 = \"MISSING\" 9 = \"LEGITIMATE SKIP\"; VALUE FBYP52A 1 = \"VERY IMPORTANT\" 2 = \"SOMEWHAT IMPORTANT\" 3 = \"NOT VERY IMPORTANT\" 4 = \"NOT AT ALL IMPORTANT\" 6 = \"MULTIPLE RESPONSE\" = \"REFUSAL\" 8 = \"MISSING\" 9 = \"LEGITIMATE SKIP\"; PROC FREQ DATA=IN01.PAQ; FORMAT BYP41 FBYP41V. BYP52A FBYP52A.; TABLES BYP41*BYP52A; TITLE \"8TH GRADR SKIP GRADE BY HOW IMP CHILD COMPLETE SCH FASTER\"; At the end of the formats given in this file, there is a frequency procedure and a means procedure (in comment form) which contain FORMAT...; statements for every variable for which there is a format. These FORMAT...; statements will save users a lot of time because they can be used in any SAS procedure. When users create their own formats they should keep in mind that a format for a character variable must have a format name beginning with '$', and that format names must not end in a digit."}, {"section_title": "6.", "text": "For very large files, the user may encounter problems when sorting. Various options may be added to the //EXEC SAS card to circumvent these problems. A suggested example is given below (consult the SAS manual for descriptions of these options): It is suggested that the user include the LENGTH statement when creating new variables, in order to save space and computer memory. 8. For many tabulations, PROC TABULATE produces the most readable output. The SAS user may use the format statements (provided) for classification variables to produce the row values of tables from PROC TABULATE. Base Year: Parent Component Data File User's Manual 9. Output from SAS can be downloaded to personal computers for production of final reports. NCES has a program available for taking into account the sample design when computing standard errors. The program, known as CTAB, is a Taylor series based routine which uses an ASCII file to compute standard errors for crossclassifications. The program also produces labeled tabular output suitable for use in publications. CTAB is available for use on microcomputers, and can be obtained through NCES."}, {"section_title": "10.", "text": "Use the NCES-and NORC-defined composite and classification variables whenever possible to simplify programming. These classification variables were carefully constructed and for many of them, sources of data from outside the parent questionnaire were merged into the parent data to construct the variables."}, {"section_title": "11.", "text": "SAS and SPSS-X system files now can be converted at many computer installations. Contact your own facility to obtain the information necessary to create an SPSS-X file from SAS and vice-versa.        Dalaog,r,mea= grader ever skip grad. because of:  What grade(s) did he or she skip? (MARK ALL THAT APPLY) 1.7% 85.1% RESERVED CODES: ----------------MISSING        100.0% 3.0% 93.7% 3.3%  6.2% (MISS) TOTALS: 22661 100.0% 100.0%            1.6% $20,000 or more 14 284 1.3% 1.6% RESERVED CODES: BEST COPY AVAILABLE   61.2% 71.7% ----------------"}, {"section_title": "Formal 11", "text": "We haven't thought about this The student had on file an Individualized Education Program and was reported to the Department of Education as belonging to one of the following handicap categories: deaf, hard of hearing, deaf-blind, or multipin handicap (only if herd of hearing was incluied as one of his or her impairments); AND the student is currently mainstreamed with regular hearing eighth grade students for English or mathematics ci NOTE: This variable was Ts:coded by NCES in accordance with the confidentiality provisions of PL100-297  This variable was recoded by NCES in accordance with the confidentiality provisions of PL100-297 (1988). Question CSTYPE ---------------Tape Pee. "}]