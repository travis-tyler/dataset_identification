[{"section_title": "", "text": "."}, {"section_title": "NATIONAL CENTER FOR EDUCATION STATISTICS", "text": "User's Manual The four NELS program cohorts (NLS-72 seniors, the HS&B sophomores and seniors, and NELS:88 eighth graders) are displayed in Figure 1-2 according to their initial and subsequent survey years and their modal age at the time of each survey. As illustrated, NLS-72 seniors were first surveyed in 1972 at age eighteen and have been resurveyed five times since, with the last sun ey occurring in 1986, when these respondents were about thirty-two years of age. The HS&B cohorts have been surveyed at points in time that would permit as much comparison as possible with the time points selected for NLS-72. NELS:88 is also designed to fit into this larger analytical scheme. The NELS:88 first followup sophomore class of 1990 parallels the HS&B sophomore class of 1980; similarly, the second follow-up senior class of 1992 will parallel the 1980 and 1982 HS&B, and 1972 NLS-72 senior classes."}, {"section_title": "National Education Longitudinal Study of 1988: Overview", "text": "The base year of the National Education Longitudinal Study of 1988 (NELS:88) represents the first stage of a major longitudinal effort designed to provide trend data about critical transitions experienced by students as they leave elementary school and progress through high school and into postsecondary institutions or the work force. The 1988 eighth-grade cohort is being followed at two-year intervals. Policy-relevant data about educational processes and outcomes will be collected over time, especially as it pertains to student learning, early and late predictors of dropping out, and school effects on students' access to programs and equal opportunity to learn. The first follow-up in 1990 constitutes the first opportunity for longitudinal measurements from the 1988 baseline. It also provides a comparison point to high school sophomores ten years before, as studied in HS&B. The study aptures the population of early dropouts (those who leave school prior the end of tenth grade), while monitoring the transition of the student population into secondary schooling. The second follow-up took place early in 1992, when most sample members were in the second term of their senior year. The second follow-up provides a culminating measurement of learning in the course of secondary school, and also collects information that will facilitate investigation of the transition into the labor force and postsecondary education after high school. Because the NELS:88 sample was freshened to represent the high school class of 1992, trend comparisons can be made to the high school classes of 1972 and 1980 that were studied in NLS-72 and HS&B. The NELS:88 second follow-up returned to students who were identified as dropouts in 1990, and identified and surveyed additional students who had left school since the prior wave. The third follow-up will take place in 1994, when most sample members will have left high school. The primary goals of the 1994 round will be to provide for trend comparisons with NLS-72 and HS&B, to address issues of employment and postsecondary access and choice, and to ascertain how many dropouts have returned to school and by what route. A fourth follow-up is tentatively scheduled for 1996.  NELS:88s objectives are more :omprehensive than those of any education longitudinal study conducted to date. Its major features include the planned integration of student, dropout, parent, teacher, and school studies; the initial concentration on an eighth-grade student cohort with planned follow-up at two-year intervals; the inclusion of supplementary components to support analyses of geographically or demographically distinct subgroups; and the design linkages to previous longitudinal studies and other current studies. Multiple research and policy objectives are addressed through the NELS:88 design. The study is intended to produce a general purpose data set for the development and evaluation of educational policy at all governmental levels. Part of its aim is to inform de:isionmakers, education practitioners, and parents about the changes in the operation of the educational system over time, and the effects of various elements of the system on the lives of the individuals who pass through it. Specifically, NELS:88 focuses on a number of interrelated policy issues, including: identification of school attributes associated with achievement; the transition of different types of students from eighth grade to secondary school; the influence of ability grouping on future educational experiences and achievements; determinants of dropping out of the educational system; and changes in educational practices over time. One of the unique features of NELS:88 is the extensive attention it gives to the role of parents. It gathers data on the effect of parents' attitudes and behaviors on educational choices, the correlates of active parental involvement in the school, parental guidance, and the parent's role in the educational success of their children. Guides to the linkage between NELS:88 first follow-up questionnaire items and some of the key policy issues related to education research are provided in Figure 1-3."}, {"section_title": "First Follow-Up Core Study and Sample Design", "text": "Three study components were carried over from the base year of NELS:88, and constituted the main first follow-up design: surveys and tests of students, and surveys of school administrators and teachers. In addition, three new components--dropouts, Base Year Ineligible Study, and School Effects Augmentation--were initiated in the first follow-up, and a freshened sample was added to the student component. A student questionnaire gathered information about basic background variables and a range of other topics including school work, aspirations, and social relationships. Students also completed a series of curriculum-based cognitive tests that used item overlapping methods to measure educational achievement and cognitive growth between eighth and tenth grades in four subject areas--reading, mathematics, science, and social studies (history/government). If a student was a first-time participant of NELS:88, he or she also completed a new student supplement, containing questions on basic demographic information which were asked in the base year but not repeated in the first follow-up. Selected teachers (in two of the four subject areas) completed a teacher questionnaire designed to collect data about school and teacher characteristics, evaluations of the selected students, course content, and classroom teaching practices. Finally, a school administrator questionnaire was completed by school principals. It gathered descriptive information about the school's teaching staff, the school climate, characteristics of the student body, and school policies and program offerings. "}, {"section_title": "III. Sample Design", "text": "This chapter describes the procedures used for selecting teachers into the NELS:88 first follow-up sample. It is important to remember that teachers entered into the sample only by virtue of teaching one or two of four selected courses (mathematics, science, English, history) to one or more of the first followup sample members in the spring term of the 1989-90 school year. Although the sampling design does not involve the selection of teachers, this chapter does provide background information to familiarize the reader with student sampling procedures. in addition to discussing the identification of first follow-up teachers and subject substitution procedures, as well as nonsampling sources of measurement error."}, {"section_title": "3.1", "text": "First Follow-Up Sample Design' There were three basic objectives for the NELS:88 first follow-up sample design. First, the sample was to include approximately 21,500 students who were in the eighth-grade sample in 1988 (including base year nonrespondents). This longitudinal cohort was to be distributed across 1,500 schools. Second, the sample was to constitute a valid probability sample of all students currently enrolled in the tenth grade in the 1989-1990 school year. This entailed freshening the sample with students who were tenth graders in 1990 but not in the eighth grade during the 1987-1988 school year.' Third, the first follow-up was to include a sample of students who had been deemed ineligible for base year data collection (because physical, mental, or linguistic barriers prevented them from participating) so that those able to take part could be added to the first follow-up student sample, and demographic and school enrollment information could be obtained for them. Since teacher data were not collected for these base year ineligible sample members, sampling procedures for this group will not be discussed here."}, {"section_title": "Longitudinal Cohort (1988 eighth graders)", "text": "Including nonrespondents, the NELS:88 base year sample comprised 26,432 students. Of these, 96 were deemed out of scope for the 1990 first follow-up; included in this category were students who had died or moved out of the United States. Among the remaining 26,336 students, 348 were found to have dropped out of school, and were selected into the first follow-up with certainty (probability equal to one). Base year students attending school in 1989 were subsampled with probabilities related to the number of other base year students attending the same school. On the basis of information obtained during the spring and summer of 1989, it was determined that the pool of 25,988 students were distributed among 3,967 schools.' As had been anticipated, the distribution of these students among schools was highly skewed. It was found that approximately 23 1. If the student who was examined was enrolled in the eighth grade in the U.S. in 1988, then the freshening process terminated. If the designated student was not enrolled in the eighth grade in the U.S. in 1988, then that student was selected into the freshened sample."}, {"section_title": "2.", "text": "Whenever a student was added to the freshened sample in step 1, the next student on the roster was examined and step 1 was repeated. The sequence of steps I and 2 was repeated (adding more students to the freshened sample) until a student who was in the eighth grade in the U.S. in 1988 was reached on the roster. At a given first follow-up school, the freshening process could yield zero, one, or more than one new sample member. Altogether, 1,229 new students were added to the tenth-grade sample--on average, just less than one student per school. Some of these freshened students were removed from the sample when the populations of transfer students and potential dropouts were subsampled as a cost-saving measure. Freshened students were dropped in the subsampling process either because they themselves were not included in the subsample, or because the base year student to whom they were linked was not included. Some 1,043 students selected through the freshening procedure remained in the final first follow-up sample. It should be noted that the school sample from which school contextual data (teacher and school administrator questionnaires) was collected is not identical to the school sample as used for freshening. Freshening took place at all schools at which there were NELS:88 sample members as of the first day of the 1989-90 school year, regardless of whether that site was the phase 1 origin school (that is, one of the 1,468 clusters containing, in total, 21,126 in-school sample members selected after phase 1 tracing) or the destination school of a transfer from a selected phase 1 school. The school sample for purposes of collecting contextual data from principals and teachers, on the other hand, comprised the 1,330 schools that represent selected clusters (as traced in phase 1) at which (1) NELS:88 sample members were sill present in the 1989-90 school year, and (2) provided at least one completed student questionnaire. 1\u00b0For exact selection probabilities, see the NELS:88 First Follow-Up Student Component Data User's Manual. FI: Teacher Component Data File User's Manual\nA course file with one record per course (in this case, only the course-related information, Part II of the questionnaire, can be meaningfully analyzed.)"}, {"section_title": "Selection of Teachers", "text": "In the base year, NELS:88 schools were randomly assigned a combination of two subject areas; math-English, math-history, science-English, or science history. (The subject combinations math-science and English-history were not used in the base year.) All of the sample members in each school were then assigned that school's subject combination. Teachers were selected based on whether they taught one of these subjects to one or more of the sample members. In the first follow-up, however, the subject areas in which teacher contextual data would be gathered for each student were largely preassigned, in that base year retained sample members were assigned the same subject combinations as in the base year. The rationale for maintaining the base year subject wherever possible was maximization of comparable longitudinal data. Thus, if a sample member was assigned the subject combination of mathematics-English in the base year, his or her mathematics and English teachers, as of the spring of 1990, were asked to complete a teacher questionnaire for the first follow-up. Freshened students who were not enrolled in the eighth grade in the base year, and hence, not assigned a subject combination previously, were assigned the subject combination of their base year \"linked\" partner. Once the student sample was selected, teachers ,'ere identified through a teacher-class-student matrix called the Class Schedule Form, a school-level form which provided a record of each sample member in the school and his or her subject combination. The assignment of subject matter pails to schools ensured that data were collected from two teachers of each student (assuming that the same teacher did not teach both subjects and that both the student's teachers chose to participate in the study). Occasionally, a student was enrolled in more than one spring-term class in a particular subject (for example, U.S. History and Western European History). In this instance, the course in which the student had spent the most class time between the start of school and survey day was chosen; if this nile was not sufficient to eliminate all but one of the candidate classes, the class that involved the most advanced subject matter was selected. Other cases were encountered in which there was more than one teacher for a designated class (for example, team teaching arrangements). In these cases, the teacher with the greatest assigned responsibility was chosen to complete the teacher questionnaire. In two instances it was necessary to apply subject substitution rules. First, if a given sample member was not enrolled in one or both of his or her preassigned subject areas, subjects were substituted. Second, in certain schools with large clusters of NELS:88 students, some subject substitution was sometimes instituted to reduce the burden of teachers who had eight or more students to rate. The procedures for subject substitution varied somewhat for these two cases. Figure 3-1 provides an illustration of subject substitution for high-burden teachers and for students not enrolled in a preassigned subject. The decision rules for subject substitution attempted to maximize the number of students with two teacher reports, while maintaining when possible the pairing of mathematics or science with English or history. Thus, science was substituted for math (or the inverse was applied); likewise, English and history could be substituted for each other. However, when these subject choices were unavailable, the remaining subject was substituted. This meant that combinations such as mathematics and science or history and English were, unlike the base year, allowable in the first follow-up. In addition, some first follow-up students had only one eligible teacher; if a student was enrolled in only one of the four subject areas, only one teacher report was sought. Since subject combinations were assigned at the school level in the base year, teacher data for each base year school reflect only one of the four possible subject pairings. Because a 1990 tenth-grade Analysis of survey error is important in understanding the potential bias in making inferences from an obtained sample to a population. Both sampling and nonsampling error contribute to total survey error. Because the first follow-up teacher sample was not representative of the population of tenth-grade teachers in 1989-90, analyses of sampling error were not performed. However, the teacher data were reviewed for overall consistency and levels of item nonresponse. When like or similar first follow-up teacher questionnaire items were compared, they generally exhibited a high degree of internal consistency. Most inconsistencies could be removed by machine editing of the data. However, some small inconsistencies do remain in the edited data. These problematic variables are discussed below. Because, for cost reasons, planned retrieval of missing or ambiguous or inconsistent critical data for the teacher survey did not take place in the first follow-up, there is somewhat more inconsistency in the data than otherwise would have been the case. In \"Part II: Class Information\" of the teacher questionnaire, one source of high nonresponse stems from disuse of the \"other\" category. As shown in the following table, surprisingly, the same items exhibited high nonresponse across the four different class information sections. Item 16g is the last subitem on the questionnaire page out of a list of subitems respondents were asked to answer. Items 12d and 18i, are the last \"other\" subitem on the page out of a list of subitems respondents were asked to answer. It appears that respondents had difficulty seeing these last items, and the problem was exacerbated when the last subitem was an \"other\" response. Under this latter circumstance, responses were omitted both because some respondents did not see the subitem or believed they had answered all subitems and other respondents discounted the \"other\" response category. Same-subject pairings pertain to situations in which either (a) different teachers instructed the sample member in the same subject but different courses, or (b) the same teacher instructed the sample member in two different courses of the same subject matter. F1: Teacher Component Data File User's Manual Other problematic variables are items that ask about specific courses teachers instruct. These are items 20-21 for the history questionnaire (U.S. History and Western Civilization or World History), 20-25 for the math questionnaire (Algebra I, Algebra II and Geometry), and items 21-26 for the science questionnaire (Biology and Chemistry). (The English questionnaire did not inquire about specific English courses taught.) For all subject matter questionnaires, nonresponse increased slightly, but noticeably from the general class information items (2)(3)(4)(5)(6)(7)(8)(9)(10)(11)(12)(13)(14)(15)(16)(17)(18)(19) to these class specific items. The increase was most noticeable in the history questionnaire where the average nonresponse on items 20-21 doubled to 17 percent from the average of 9.6 percent on items 2-19. The most logical explanation for this increase is that the format for these items did not allow for respondents to indicate they did not teach the specific course queried. A review of response frequencies suggests that teacher respondents engage in a fairly stable pattern of nonresponding. For most of the high nonresponse items in \"Part 3: Teacher Background and Activities,\" based on teachers' pattern of responding, it appears that when a situation does not apply, teachers simply skip the item altogether rather than indicate \"no\" or \"not applicable\" if such a response category is even present. Items high in nonresponses due to this cause are: F1T310A1 through F1T310G2--major and minor fields of undergraduate study: Because some colleges or universities do not offer a minor field of study, for item F1T310A2-F IT310G2, minor field of undergraduate study, item nonresponse jumps to 28.8 percent from 6.7 percent for item F1T310A I -F I T310G1 , major field of undergraduate study. F1'F311A1 through F1T311G2major and minor fields of graduate study: For FIT311A1-FIT311G1, major field of graduate study, item nonresponse is 9.8 percent but for F1T311A2-F1T311G2, minor field of graduate study, item nonresponse is 46.4 percent. A graduate program is less likely than an undergraduate program to offer a minor. F1T3 1411 number of courses taken in graduate school for most frequently taught subject: For one-half of teacher respondents, those who did not receive a graduate degree, item 14B is not applicable. Nonresponse for graduate school courses taken is 23 percent. As a point of comparison nonresponse for undergraduate courses (F1T3_14A) taken is 9.6 percent. Fl: Teacher Component Data File User's Manual F1T3 17A (full-time) and F1T3_1713 (part-time)--other paying jobs in addition to duties at this school: Even when given the opportunity to indicate not applicable--no other full-time job held\", respondents skipped the response option. Nonresponse to item F1T3_17A (\"another full-time job\") is 42.0 percent compared to 23.2 percent for item F1T3_17B (\"another part-time dub \"). F1T3 13course taught most often: Nonresponse for this item is 21 percent. This item in this format did not appear in the first follow-up field test teacher questionnaire, and therefore, could not inform development of the main study instrument. As indicated by the loss of data for approximately 21 percent of respondents who gave a multiple response, many respondents teach more than one course with equal frequency. This item has been reformatted in the second follow-up teacher questionnaire--\"If you have taught more than one course with the same frequency, mark all of those courses.\" One additional source of imperfect consistency discovered during data cleaning involves question 23 in part three of the questionnaire. For this question, teachers were to report both hours and minutes spent on 13 school-related activities outside regular school hours. if one totals the hours and minutes across all 13 activities, 12 percent of the sample spent more than 40 hours on outside activities, 4 percent more than 60 hours and 1 percent more than 100 hours. One person reported that he/she spent 316 hours on outside activities. When a given activity is looked at in isolation, hours and minutes reported may seem plausible, but when one sums across all activities, totals sometimes become too high to be judged as accurately (or even reasonably) estimated. Finally, users are cautioned that teacher reports of student language minority status (first follow-up teacher questionnaire item F1T1_11) should be viewed with extreme caution, if base year results can be generalized to the first follow-up. Analyses of teacher data from the NELS:88 base year suggest that eighth grade teachers often do not know when students come from a home in which a language other than English is spoken--NELS:88 eighth grade teachers tended to seriously underreport such students.' (Presumably, those more adept in English are the more likely to be misidentified). The discrepancy between teacher and student reports was quite large both for Hispanics and Asians. Some 27 percent of Asians were identified by at least one of their two teachers as coming from a family in which a foreign language was spoken. However, 73 percent of the Asian eighth graders indicated that they came from a family in which a non-English language was spoken. For Hispanic eighth graders, 39 percent were identified by at least one of the two surveyed teachers as coming from a languageminority household. However, 76 percent of Hispanic students reported coming from a home in which a non-English language was spoken. (Sometimes--but not often--teachers reported that a student was from a language minority household though the student indicated otherwise. One percent of Asian students and 4 percent of Hispanic were so identified.) Given the fact that high school teachers typically have many more students to teach than do middle grades instructors, there is little reason to suppose that first follow-up teacher reports of student language minority status will be notably more accurate; a thorough comparison of 1990 student and teacher reports has not, however, been conducted as of this date. 12 Bradby, D.S. 1992. Language Characteristics and Academic Achievement: A Look at Asian and Hispanic Eighth Graders in NELS:88. Washington, D.C., National Center for Education Statistics, "}, {"section_title": "IV. Data Collection", "text": "In the spring of 1990, the first follow-up survey gathered a second wave of data from the eighthgrade cohort of 1988, the majority of whom were enrolled in tenth grade, and a first wave of data from freshened students (that is, students who were enrolled in tenth grade in the spring term of 1990, but not enrolled in eighth grade in the base year). Again, as in the base year, two teachers of each sampled student and students' current school principal were asked to complete, respectively, a teacher and school administrator questionnaire. Sample members who had dropped out of school, and remained so at the time of data collection, were administered the dropout questionnaire and cognitive test battery. Self-administered questionnaires remained the principal mode of data collection for all respondent populations. Although the data collection procedures employed in the first follow-up were modeled after those of the base year, the design of the study necessitated several activities that had not been performed previously. First, in order to select the first follow-up sample, an extensive locating effort was undertaken. Second, the base year sample was \"freshened\" to generate a representative sample of the tenth-grade class of 1990. Third, off-campus survey sessions, similar to those used in HS&B, were scheduled to administer the student or dropout questionnaire to sample members who were currently not enrolled in a first follow-up school at the time of data coil action. And fourth, to obtain a more precise estimate of the rate of dropping out for the eighth-grade cohort of 1988, a subsample of first follow-up nonrespondents was further pursued. Overall, data collection activities for the first follow-up survey were executed in four phases which spanned two years (see Figure 4-1). The first and second phases of the study were conducted from January to December of 1989 and involved the pre-data collection activities of securing state, district, diocese, and school permission to conduct the study, \"tracing,\" enrollment verification, and sample freshening. Phase three, conducted from late January to July of 1990, constituted the main data collection effort. Phase four (January to June of 1991) constituted the second data collection effort. Completion rates based on sample eligibility for the NCES-sponsored first follow-up sample, including freshened students, arc presented in Table 4.1-1. 88.5% 88.7% Percentages of cases for which a student/dropout questionnaire was obtained for which a cognitive test was also obtained. Indicates a coverage rate (student participants who have a completed school questionnaire). Coverage rate for student participants who have one or more completed teacher questionnaire.  "}, {"section_title": "Pre-Data Collection Activities", "text": "Pre-data collection activities spanned Phases 1 and 2 of the study. Conducted from January to June of 1989, Phase 1 of the first follow-up survey encompassed the pre-data collection activities of tracing sample members to their 1990 anticipated school of attendance, and securing state, district, and school permission to conduct the study. Phase 2 took place from September to December of 1989. After tracing was completed and the first follow-up student sample was finalized, all first follow-up schools were contacted again in the fall of 1989 to re-verify student enrollment, freshen the core and state augmentation student samples, schedule Survey Day sessions, and for small cluster size schools (i.e., schools with fewer than 11 sample members), secure permission to conduct the study."}, {"section_title": "Tracing", "text": "Since the vast majority of the base year sample would change schools between eighth and tenth grades, an extensive student tracing effort was undertaken. The primary purpose of tracing was to locate and define the first follow-up student sample and its associated schools. As described in Chapter III, selection of the student sample (through which first follow-up schools were selected) was based on sample member clustering, with the objective of selecting approximately 21,500 base year sample members while restricting the number of schools in which survey sessions would be conducted to roughly 1,500. In order to draw the first follow-up sample it was, therefore, necessary to definitively identify sample member clustering within the 3,362 schools to which base year sample members reported they would matriculate. Specifically, tracing was accomplished through sample members' base year reported 1989-1990 school of attendance, and involved contacting schools directly and verifying sample members' enrollment. A second purpose of tracing was to serve as a beginning point for measuring the fluid process of dropping in and out of school. Tracing began in the base year through a student questionnaire item that asked respondents to name, in order of probability, the two schools they were most likely to attend during the 1989-1990 academic year. From March 1 to June 30 of 1989, field interviewers conducted on-site verification of enrollment at 1,662 schools which were nominated by three or more base year sample members as being the school they would most likely attend. If a sample member was not enrolled at his or her first choice school, interviewers contacted, in order of the likelihood of attendance, the sample members' second choice school, the school most frequently named by his or her eighth-grade classmates (called the modal school), if different from the sample members first and second choice schools, and finally, the sample member at home. Of the 24,599 base year respondents, 92 percent (N=22,631) nominated a school that at least three other respondents also nominated. The remaining respondents who reported attending a school that fewer than three base year sample members attended (N=1,968) and base year nonrespondents (N=1,833) were mailed a postage paid return postcard which asked them either to confirm whether the school they had nominated was the school they were actually attending, or to provide the name and address of the school they would be attending in the 1989-90 school year. After 18 weeks of tracing, 99 percent (N=26,211) of the entire base year sample (N=26,432) had been located. Fl: Teacher Component Data File User's Manual"}, {"section_title": "Securing District/Diocese and School Cooperation", "text": "A second activity occurring simultaneously with tracing was contacting and securing the cooperation from schools (as well as their states and districts or dioceses) enrolling 11 or more sample members.' The first step, prior to contacting state and district or diocesan officials, was to gain endorsement of the study from key educational organizations. Approval for the first follow-up survey was requested and obtained from the Education Information Advisory Council (EIAC) of the Council of Chief State School Officers, the National Catholic Education Association (NCEA), and the National Association of Independent Schools (NAIS). Endorsements were received as well from the American Association of School Administrators (AASA), the National Association of Secondary School Principals (NASSP), and the National School Boards Association (NSBA). For public schools, the Chief State School Officer of each state was first contacted, then the District Superintendent of each district that oversaw a school in which a NELS:88 sample member was enrolled was contacted. At both the state and district levels, officials were informed of the study's purpose, data collection procedures, and future tracing activities. The same contacting procedures were follow with private schools if they also were organized into an administrative hierarchy. such as Catholic school dioceses. Table 4.1-2 summarizes the results of district or diocese and school contacting. The final first follow-up core sample was enrolled in 1,109 public and 249 Catholic or other private schools which fell under the jurisdiction of 885 districts and diocese. Of the 885 districts and diocese contacted, 99.2 percent (N=878) agreed to participate in the study. School contacting proved equally successful with 99.2 percent (N=1,347) of the 1,358 eligible first follow -tip schools granting permission for the first follow-up to be conducted in their school."}, {"section_title": "13", "text": "Prior to tracing, a frequency distribution of student cluster sizes showed that approximately 75 percent of the base year respondents attended a school enrolling 11 or more sample members. As part of the sampling strategy, it was deemed, a priori, that these 18,103 students and their associated 856 schools would be sampled with certainty. As such, only principals of schools with student cluster sizes of 11 or more (i.e., certainty schools) were asked during the spring of 1989 to participate in the study. After tracing, and identifying sample member clustering, sample members who were enrolled in schools with cluster sizes ranging from 1 to 10 were the selected. In the fall of 1989, the principal's of selected schools were asked to participate in the study. H: Teacher Component Data File User's Manual Table 4.1-2 Summary of NELS:88 first follow-up district/diocese and school contacting"}, {"section_title": "Pre-Survey Day Activities", "text": "In the fall of 1989, NORC field interviewers personally visited all 1,468 first follow-up core schools identified after subsampling.\" During this visit, interviewers first asked school principals to appoint a school coordinator who would serve as a liaison between the school and NORC, and assist interviewers with such activities as sample freshening, distribution and collection of survey materials, and verification of student enrollment. Principals were also asked to schedule a Survey Day and Make-Up Day date sometime between February 1 and June 30, 1990. During this same visit, interviewers reverified students' enrollment, and gathered additional locating information, such as a new home address or name of new school, for students who were no longer enrolled in the school. Another major activity conducted during this visit was sample freshening. At all schools enrolling a sample member on the first day of the school year, the core sample was augmented to obtain, collectively, a representative sample of the tenth-grade class of 1990. Note that the number of schools in which freshening occurred was not the same as that in which other pre-survey day activities took place. In some cases, a non-sampled school was included in the freshening sample when a core student transferred to it, and a sampled school was excluded if a student transferred out of the school before or after the first day of the school year (only if that student was the only core sample member in that school). In all but approximately onethird of the 1,468 schools (N=544), interviewers were able to set Survey Days, re-verify enrollment and freshen the sample in one visit. For the remaining third, a second visit was needed to complete the fall pre-data collection activities. 14 This number includes School Effects Augmentation (SEA) schools which are also \"core\" sample schools. That is, 248 first follow-up schools in the 30 largest MSAs were selected as SEA schools. In these schools, the first follow-up core sample was augmented to obtain a student sample representative of that particular school. "}, {"section_title": "First Follow-Up Data Collection Activities", "text": "First follow-up data collection followed phase I and 2 activities of tracing and securing cooperation, and was also undertaken in two phases: phase 3 (January to July, 1990) and phase 4 (January to June, 1991). In phase 3, data were collected for all first follow-up components: student, dropout, teacher. and school administrator. In order to derive a more precise dropout rate for the 1988 eighth-grade cohort, a second data collection effort (phase 4) was undertaken in the spring of 1991. At that time, the populations of sample members previously identified as dropouts, and those who potentially may have been dropouts' were subsampled, pursued, and administered either an abbreviated student or dropout questionnaire (depending upon school enrollment status) either over the telephone or in-person. In addition, data were collected for nonresponding teachers and school administrators in phase 4."}, {"section_title": "Student Survey and Cognitive Tests", "text": "In -School Survey Sessions. From January 26 to June 30. 1990, in-school survey sessions or \"Survey Days\" were held in all core schools still enrolling first follow-up sample members. On Survey Day, two NORC field representatives, a \"team leader\" and clerical assistant, supervised sampled students as they completed the survey instruments during a three hour long session. After sampled students were assembled in the Survey Day venue, which was usually a classroom or library, the team leader took attendance and checked for outstanding parental permission forms. Students in each session were then instructed to first complete a self-administered new student supplement, if ''ley received one,'' and a student questionnaire. A ten-minute break followed during which time NORC field staff reviewed participants' questionnaires for completeness (i.e., checked for missing or illegitimate multiple responses to singe-response critical items). Immediately following the break, students were administered an 85-minute a .)-litive test battery. The test consisted of four timed sections covering the subject areas of mathematics, reading, science, and social studies (history/citizenship/geography). Upon completion of the cognitive test battery, a second attempt was made to retrieve missing (or inappropriately marked) questionnaire items before students left the classroom. At the close of Survey Day, NORC field staff made arrangements for a Make-Up Day to be held for first follow-up sample members who did not participate in the survey session. If five or fewer students did not participate, the school coordinator was asked to supervise Make-Up Day.' If more than 5 students were scheduled, or the school coordinator was unavailable to conduct Make-Up Day, the NORC team leader returned to the school to conduct the session. An average in-school participation rate of 96 percent was achieved for the longitudinal (eighth-grade cohort) student sample. Off-Campus Survey Sessions. Off-campus survey sessions were initially planned as a method for surveying dropouts and students who were enrolled in schools that had refused to participate in the study or who had transferred to a school outside the original set of first follow-up schools. However, Fl: Teacher Component Data Fil' Uver's Afanual if a student who had missed both Survey Day and Make-Up Day resided close to the site of an offcampus session, he or she was also invited to attend. Off-campus survey sessions were held from April 1 to July 27, 1990. NORC field staff contacted qualified students by telephone and invited them to take part in an off -campus survey session. Students were reimbursed (up to $20) for travel expenses to and from the survey sites. Sessions were conducted using nrocedures as similar as possible to those of on-campus sessions, and were typically scheduled in a public library or community association meeting room. Field staff scan-edited completed questionnaires during the testing period and attempted to obtain missing or incomplete data before participants left the sites. If a sample member was unable to attend an off-campus group survey session, he or she was surveyed either in-person or over the telephone. Because the off campus sessions typically involved only one to three participants, these administrations were handled by a single survey representative."}, {"section_title": "Dropout Survey and Cognitive Tests", "text": "In the initial data collection period, team leaders administered the dropout questionnaire and cognitive tests to cohort dropouts during off-campus group administration sessions. Team leaders were instructed to procure sites for these sessions that approximated as closely as possible the characteristics necessary for a Survey Day room; off-campus sessions were conducted in public libraries, community centers, and similar locations. In off-campus survey sessions, team leaders followed the same procedures as for in-school sessions. Attendance was taken; permission was checked; in-school scripts and instructions were read; instruments were administered with the precise timing of an in-school session; and critical items were edited and retrieved. Dropouts attending off-campus sessions were reimbursed (up to $20) for travel expenses at the end of the session. This reimbursement was not a payment for participation. If possible, dropouts were invited to the same off-campus sessions as in-school students. In a few cases, however, it was preferable to administer the survey in a sample member's home A home site off -campus administration was held when only one respondent in a particular area was eligible for an off campus administration, the home environment was suitable, and a more desirable site was unavailable or inaccessible to the respondent. Team leaders followed the same procedures as for in-school and central site off-campus administrations. Respondents participating in home administrations did not receive the $20.00 reimbursement for travel expenses. Quality control procedures for the dropout questionnaire were very similar to those employed in Survey Day sessions. During the test administration, the team leader edited the dropout questionnaires, checking that critical items were completed in full. If data were missing, the team leader attempted retrieval at the sample member's work area when he or she had completed a test section. At the end of the testing session, sample members were instructed to close and hand in their test booklets. Any sample members with items yet unretrieved were asked to stay for a few minutes after the session. During phase 4, the initial data collection plan for dropouts was modified slightly. For the phase 4 screening of the 50 percent subsample of nonresponding students, telephone interviewers verified enrollment for all cases. If a sample member was identified as a cohort dropout, he or she was administered an abbreviated version of the dropout questionnaire over the telephone. Conversely, if a sample member was identified as a stopout, he or she was administered an abbreviated student 3t Fl: Teacher Component Data File User's Manual questionnaire. If the sample member was a student, he or she was not surveyed.'8 Since the abbreviated questionnaire gathered primarily objective behavioral information, such as sample member's address, enrollment status, and basic background information (sex, race/ethnicity), interviewers were allowed to conduct a telephone interview with a proxy.' Proxy administrations were used as a \"last-resort\" method of acquiring enrollment data on dropouts. Nonrespondents for whom no telephone number was available were pursued, screened, and surveyed in person. Again, in-person interviews took place with an abbreviated version of the dropout (or student) questionnaire and were conducted with either the sample member or a proxy. The other category of sample members pursued during this time--sample members who were previously identified as dropouts--were surveyed in the same manner as nonresponding students. For both categories of sample members surveyed during phase 4, cognitive tests were not administered given the date of this second effort--some six months to one year after the initial data collection effort. Incentives of up to $20 for completing an abbreviated interview were offered to sample members intervie;,d during this second data collection effort."}, {"section_title": "Teacher Survey", "text": "Pre-data collection activities for the teacher survey occurred during phase 3 of the study and overlapped with student and dropout data collection. Beginning in January, NORC interviewers were instructed to complete a Class Schedule Form (CSF) for every eligible school in their assignment. The purpose of the CSF was to identify specific classes of each sample member, and the teachers who taught those classes. Class schedule forms were completed using both telephone and in-person methods, depending on the student cluster in each school. If there were five or fewer sampled students in a school, the information was collected from the school coordinator over the telephone. If more than five sample members were enrolled in a school, the interviewer completed the CSF at the school. Class schedule forms were completed, and teachers selected on a flow basis, depending on survey day schedules. The first batch of completed forms (for schools with survey days in February) were mailed back to NORC's central office in January and data entered; lists of selected teachers were produced in February. As teachers were being selected for the first group of schools, class schedule forms were being completed by interviewers at the second group of schools, so that there was almost continuous case flow between field interviewers and the central office. Once teachers were selected, approximately two weeks prior to the school's Survey Day, teacher packets were mailed to the school coordinator. Each packet contained a teacher questionnaire, cover letter, and study brochure. Teachers were instructed to complete the questionnaire and return it to the school coordinator on or before the school's Survey Day. If a teacher was unable to return the questionnaire to the school coordinator by the desired date, he or she was instructed to mail the completed questionnaire directly to NORC in the enclosed prepaid envelope. The school coordinator was instructed to collect all completed teacher questionnaires by the date of the school's survey session, so that the NORC representative could mail them along with the completed"}, {"section_title": "18", "text": "For cost reasons, only dropouts and stopouts were interviewed during phase 4."}, {"section_title": "19", "text": "The first follow-up defined proxies as friends, relatives, or acquaintances who could verify dropout status and provide sample member address information. F1: Teacher Component Data File User's Manual student questionnaires. The role of the NORC interviewer was to work with the school coordinator to monitor the completion of the questionnaires and prompt any nonresponding teachers. Any nonresponding teachers remaining at the close of the initial data collection period were pursued during the second data collection effort. In January of 1991, the full version teacher questionnaires were mailed to 2,671 nonrespondents. As in the initial data collection period, the questionnaires were mailed to the school coordinator at the nonresponding teacher's school. Unlike the first data collection attempt, however, school coordinators were not responsible for collecting the questionnaires. In the event that the teacher was no longer at the school, the school coordinator was asked to either call NORC, or return the packet in the prepaid envelope with a note stating that the teacher was no longer there. Follow-up procedures, such as a remail or telephone prompt, were not undertaken. To ensure compai-.. Ality of data across the two data collection periods, teachers were instructed to complete the questionnaire with respect to the first follow-up sample members who were enrolled in a particular class in the spring term of 1989-90 school year."}, {"section_title": "School Administrator Survey", "text": "In the spring of 1990, the chief administrators (or their designees) of all schools with first followup sample members still in attendance were asked to complete a self-administered school administrator questionnaire. Approximately two weeks prior to a school's Survey Day, the school coordinator distributed the school administrator questionnaire along with a cover letter and study brochure to the principal of the school. In the cover letter, the principal was instructed, if possible, to return the completed instrument to the school coordinator on or before Survey Day, at which time the NORC survey representative would collect it. Administrators who were unable to complete their questionnaire by Survey Day were instructed to return it to NORC in the prepaid business envelope that was provided. At the close of the initial data collection period, 77 percent of eligible school administrators had completed a questionnaire. A mixed mode follow-up to collect key items from administrators who failed to return a completed questionnaire was undertaken in the second data collection effort. Specifically, in mid-November of 1990, the original version of the school administrator questionnaire was mailed to 338 nonrespondents. The remail accounted for an additional four percent of the completed cases (N=57). If a case was still outstanding two weeks after the remail, interviewers contacted the school principal by telephone and attempted to complete an abbreviated telephone interview. The telephone follow-up accounted for an additional 250 questionnaires and brought the response rate up to 97 percent. Including both original (self-administered) and abbreviated (telephone interview) versions, 21 percent of the school administrator questionnaires were collected during the second data collection effort."}, {"section_title": "First Follow-Up Data Collection Results", "text": "Tables 4.3-1 and 4.3-2 summarize data collection results for the NELS:88 first follow-up survey. All completion rates have been derived based on eligible sample members only. That is, for these tables, completion rates are calculated as the number of completed interviews divided by the number of in-scope sample members. Also, note that the first follow-up student/dropout sample constitutes the basic unit of analysis and that all other samples--school administrators and teachers--are defined in relation to participating sample members. Fl: Teacher Component Data File User's Manual Unlike the completion rates reported for the base year student and first follow-up dropout components, weighted completion rates for the first follow-up student component, as well as the school and teacher coverage rates, are lower than their corresponding unweighted rates. This is primartiy due to subsampling and the fact that subsampled groups with higher weights participated at a lower rate. Table 4.3-1 presents statistics for the first follow-up full cross-sectional sample, which includes both base year retained and freshened sample members. The statistics are reported with respect to four study components--student, dropout, teacher, and school--and selected sample member and tenth-grade school characteristics. As shown, the weighted teacher questionnaire coverage rate for students who have one or more completed teacher questionnaires is 81 percent. In order to inform users of the full extent of student-teacher data coverage, this coverage rate was calculated based on all student participants (N=18,221), both those eligible and ineligible for the teacher survey. By design, no teacher or school administrator data were collected for students who transferred out of originally selected first follow-up schools. When transfer students are taken out of the denominator (N=17,924), the weighted coverage rate for students with one or more teacher questionnaires is 88.5 percent. The unweighted coverage rate is 88.7 percent. The school administrator survey coverage rate with transfer students excluded is 97.5 percent weighted and 98.0 percent unweighted. Table 4.3-2 displays summary completion rate statistics for panel student members (those who participated in both the base year and first follow-up) by selected student and eighth-grade school characteristics. Both base year and first follow-up teacher questionnaire data were collected for 78 percent of panel students; for almost 99 percent of panel students, either base year or first follow-up teacher data is available.  School questionnaire coverage rate for each student who has completed a BY student questionnaire and IF student questionnaire. h PANEL students only (student who completed a BY and IF student questionnaire). Coverage rate for panel students with one or more completed teacher questionnaires. "}, {"section_title": "Data Preparation and Processing", "text": "This chapter describes the procedures used to transform responses from first follow-up questionnaires into a data file. To efficiently accommodate the large number of documents, the teacher questionnaires were optically scanned. Several procedures were implemented to prepare these documents for optical scanning, including monitoring the receipt of completed questionnaires, editing and coding certain questionnaire items, and preparing the documents for microfilming. For budgetary reasons, retrieval of critical items was not attempted for the teacher component of the first follow-up. Data processing activities spanned the entire length of the NELS:88 first follow-up survey. beginni tracing, securing school cooperation, and teacher selection, through receipt control and machine editing, and ending with the preparation of public release data files and user documentation."}, {"section_title": "5.1", "text": ""}, {"section_title": "Monitoring and Receipt Control", "text": "Tracking and receipt of questionnaire data for all respondent populations was accomplished through the NORC Survey Management System (SMS). The SMS for the teacher component was accessible through the teacher ID. and contained information on the status of each selected teacher's questionnaire. Teacher disposition codes were used to track completion rates of the teacher sample during data collection. Once a teacher questionnaire was returned to NORC, receipt control clerks reviewed the document and assigned, then entered into the SMS, appropriate disposition codes which identified the status of each teacher questionnaire in the sample. At the time of entry, the SMS generated and automatically entered the date that the completed questionnaire for each case was received. . \\t the end of the data collection period, the SMS file of disposition odes was merged with the scanned or keyed data to identify discrepancies in [Ds or final status. In most cases, it was possible to resolve such discrepancies by referring to the hardcopy of the documents."}, {"section_title": "5.2", "text": ""}, {"section_title": "In -house Editing and Coding", "text": "The next step was to edit the teacher locator page for legibility and remove the page from the rest of the questionnaire. Any discrepancies between teacher names were reconciled using a list, produced from the SMS, of teachers and their corresponding IDs. If a different name appeared on the locator pages than on the list of teacher IDs, coding supervisors attempted to resolve the problem, either by correcting a misspelled name, or by determining if the name on the SMS list was incorrect. Questionnaires were then edited and coded for completeness. Some blank questionnaires were considered temporary teacher refusals. Other blank questionnaires, in which the teacher clearly wrote that he or she had never taught either the course or the student specified, were separated, and the teacher disposition code changed to reflect an ineligible status Completed questionnaires were then checked for stray marks and separated by subject area."}, {"section_title": "5.3", "text": ""}, {"section_title": "Data Entry and Archival Storage", "text": "When editing %ti as completed, the respondent locator pages were separated from the rest of the instrument and filed in locked cabinets in a locked and secured room. Data entry for the remaining part of the teacher questionnaire was performed through an optical mark reading procedure. Optical mark reading v. as conducted by NORC's subcontractor, Questar Data Systems, Inc., which received the Fl: Teacher Component Data File User's Manual questionnaires in batches for processing. Questar also arranged to have questionnaires photographed onto microfilm. Once the questionnaires were scanned and photographed, they were destroyed and the rolls of microfilmed questionnaires were returned to NORC for archival storage."}, {"section_title": "Optical Scanning", "text": "With the exception of the teacher locator section, NORC used the optical mark read (OMR) method of data conversion for the first follow-up teacher questionnaires. Teacher materials were optically scanned using equipment that read darkened ovals or marks on the page. The scanning subcontractor conducted extensive tests and checks of the machine's ability to correctly read the darkened ovals. To check the accuracy of data conversion, the scanning programs were tested in two ways: through use of dummy questionnaires specifically designed to detect scanning errors or problems, and by running a substantial number of real documents through the system. Final data from the first batch of questionnaires scanned were carefully checked against the original documents to assure that complete accuracy had been attained."}, {"section_title": "5.5", "text": "Machine Editing Conventions for editing, coding, error resolution, and documentation adhered as closely as possible to the procedures and standards previously established for HS&B and NLS-72. After the scanning contractor completed teacher data conversion and supplied NORC' with a raw data tape, the combination of machine editing and visual inspection of the output began. The tasks performed included: resolving inconsistencies between filter and dependent questions, supplying the appropriate missing data codes for questions left blank, detecting illegal codes and converting them to missing data codes and investigating inconsistencies or contradictions in the data. Variable frequencies and crosstabulations were inspected before and after these steps to verify the correctness and appropriateness of the automated machine editing processes. Inconsistencies between filter and dependent questions were resolved in the machine editing process. In most instances, dependent questions that conflicted with the skip instructions of a filter question contained data that, although possibly valid, were superfluous. For instance, respondents sometimes indicated \"no\" to a filter question and then continued to answer \"no\" to subsequent dependent items. When a filter question indicated that subsequent questions(s), should have been skipped. the subsequent dependent questions were set to a value of legitimate skip with one exception. In the exception, if the dependent questions were answered in a manner that was inconsistent with the filter but consistent within the dependent items, the filter was hack edited (changed) and made consistent with the dependent responses. If a multiple response or no answer was given to a filter question, the question was assigned an appropriate reserve code (\"6\", \"7\" or \"8\") and all subsequent questions that might have been skipped were processed as if the respondent should have answered them. The frequency with which responses were recoded to legitimate skip for each skip pattern was closely monitored. Frequency distributions of responses before and after editing were inspected. All filter questions and their respective dependent items were displayed in crosstabulations so that staff could verify the correctness of the recoding. After improperly answered questions were converted to blanks, the teacher data were passed through a second step in the editing program that supplied the appropriate reserve codes for blank 45 F1: Teacher Component Data File User's Manual questions. Where a value was not provided by the respondent, a reserve code fills the field. These codes are as follows: If the field is longer than one column, the right-hand column contains one of the above codes and the rest of the columns are filled with \"9\"s. Detection of out-of-range codes was completed during scanning or data entry for all questions except those permitting an open-ended response. Questions with multiple response were checked by verifying the data in the questionnaire microfilm."}, {"section_title": "Linking Student, Class, and Teacher Data", "text": "Two primary problems were encounted when teacher class information was linked to students. The first problem occurred when the teacher neglected to provide the student or class identifier. The second type of problem occurred when the teachers erroneously recorded a student or class identifier. Attempts to reconcile or clean missing or erroneously recorded identifier information were handled in the following manner: If there was only one student or class expected for a teacher, any identifier problem was ignored, and the expected identifier was used. If there was more than one student/class expected and no identifiers were provided, it was assumed that the teacher followed the instructions and the data were recorded in the correct column position in the qeustionnaire. That is, the position of the identifier inform n as recorded by the teacher in the teacher questionnaire was used to determine the student/teacher or class/teacher link. (See question 1 in Part I of the teacher questionnaire for instructions on expected position of responses.) If there was more than one student/class expected and erroneous identit -s were provided, student and class data linking problems were handled differently. In the case wher, several students were involved, the questionnaire was reviewed on microfilm and student initials were checked. (Teachers were instructed to record both the student's numerical identifier and initials in each column.) If this did not resolve the problem, all student data for the teacher were inspected and the data were linked or assigned to a student based upon the pattern (column location) of other student data gathered through the questionnaire. For class data, if the identifiers were compared in the aggregate and no pattern could he established, the class data were eliminated."}, {"section_title": "5.6", "text": ""}, {"section_title": "Data File Preparation", "text": "The conventions used to assign SAS and SPSS-X variable names are as consistent as possible with HS&B and NLS-72. In those two surveys, variable names were assigned according to the survey wave, part of the questionnaire, and the question number. A similar system was developed for NELS:88. For example, F I T32, is question 2 from part 3 of the first follow-up teacher questionnaire. Or, for variables in the class rating section, the \"\" in the variable name is replaced by a subject code. Thus, FIT2F7 is question 7 in part 2 of the English version of the teacher questionnaire. "}, {"section_title": "Guide to the Data Files and Codebook", "text": "The NELS:88 public use data files are available on four separate magnetic tapes,' one for each study component: the student survey, the dropout survey, the teacher survey, and the school administrator survey. The tape for the teacher survey component contains a data file based on data from 9,987 teachers, resulting in 27,994 teacher ratings and information for 15,908 of the 18,221 participating students from 1,296 schools, including the OBEMLA student oversamples. As indicated earlier, the teacher data can be used alone or merged with the student, or school files, though use of the teacher files as a stand-alone dataset is not recommended. The NELS:88 first follow-up sample of teacher-respondents does not constitute a statistical or representative sample of tenth grade teachers for analysis and reporting purposes. Rather, the results of this questionnaire are intended to provide information about student-related characteristics, teacher practices, and curriculum exposure which can be linked to nationally representative student-level record data. If the data are used as intended, analysis and reporting activities should focus on the effects of teaching, curriculum, and teacher characteristics on student outcomes. The teacher data file has, therefore, been constructed at the student level. That is, there is a teacher record for every teacher/student pair, with up to two records per student and up to sixteen (16) records per teacher. The student ID is included in the teacher file and can be used to link to the student files. See Section 6.3.1 for details on how IDs can be used to link data files. Since multiple instruments were used to gather data from students, dropouts, teachers, and school administrators, the analyst must use the proper participation flags and weights (on the student/dropout files) to produce accurate statistics. Therefore, before describing the data files, several suggestions are offered that should be helpful to the analyst. These are followed by a complete description of the content and organization of the teacher data file and a guide to the associated codebook."}, {"section_title": "A Note About the Teacher Data File and Codebook", "text": "In reviewing the teacher codebook, data users should keep in mind that the codebook and data file are presented at the level of the student-teacher pairs. Different values will appear when the user examines results at other levels, such as: students with at least one teacher rating, the number of teachers who did the ratings, and course information. The data file is structured at the level of student-teacher pairs because the student participants constitute the basic unit of analysis in the NELS:88 study design. The objective of the teacher survey was to obtain ratings in two predetermined subjects for each student. For most students, the two subjects were taught by two different teachers. In those cases, the student could have two records, that is one from each teacher, or only one record, if one of the two teachers refused to respond, or no records if neither teacher responded. For a small number of students, both courses were taught by the same teacher. In this situation, the teacher was treated as though he or she were two separate individuals. That is, the teacher-subject combination defined a unique teacher ID. In this case, students have two sets of ratings, both were made by the same teacher, but there will be two different teacher IDs. Please also note that most teachers rated a number of students, usually, but not always, in a single subject. Thus a teacher may have multiple teacher-student pair records, depending on the number of students he or she rated."}, {"section_title": "2)", "text": "While the initial release of the data is in tape format, a version of both the restricted and public use data files is currently being prepared in a Compact Disc Read-Only Memory (CD-ROM) format."}, {"section_title": "Teacher Component Data File User's Manual", "text": "The user may wish to view the data from different perspectives. Please keep in mind that neither the respondent teachers nor the courses constitute a valid probability sample. These alternate views are:"}, {"section_title": "1.", "text": "A teacher file containing one record per teacher (of course, the student or course information will not be meaningful in this context)."}, {"section_title": "Packaged Statistical Programs", "text": "The procedures outlined in Appendix C, using SAS or SPSS-X with NELS:88 data, are recommended; the data tape contains the appropriate control cards for both statistical packages. Analysts should contact their own support facilities to obtain the information necessary to create an SPSS-X system file from a SAS system file and vice versa. One of the first steps to take before running statistical analyses is to select the proper participation flags and weights. Relevant flags and weights are found on the student tapes. The NELS:88 data files are designed to be used as weighted datasets in all analyses, with teacher data designed to be linked to student or school files. The complexity of the sample design of NELS:88 virtually ensures inaccurate results if the data are analyzed on an unweighted basis. Clustering, multistage selection, and disproportionate sampling all contribute potential bias and various degrees of unreliability, which can be avoided by using the weights provided to analyze specific subsets of the sample. The appropriate participation flags and weights should be used if analyses are to be performed correctly. See Appendix C for specific examples using Statistical Analysis System (SAS)."}, {"section_title": "6.3", "text": ""}, {"section_title": "Content and Organization of the Data Files", "text": "The teacher raw data file consists of 27,994 records. There is one record for each teacherstudent-subject combination. (Records for nonparticipants are not included on the first follow-up data tape). Each record is organized as shown in the record layout that appears in Appendix E. The variables on the record are grouped into logical sets as discussed below. For the sake of brevity, each item of data is referred to by its SAS (SPSS-X) variable name as defined in the control cards provided with the data file. The teacher data tape contains four related files. They are: The raw data file, with items in the following order for each respondent: "}, {"section_title": "Identification Codes", "text": "The identification information consists of four variables. The first is the seven-digit student identification code. To ensure confidentiality, each sequential number component was mapped to a random number. These random numbers were then concatenated to form the student identification code. The second variable is a five digit school identification code. The school IDs were also randomized. The next variable is a two digit sequential code for the teacher within the school. This teacher code is followed by a one letter code for the subject matter (English, mathematics, history (social studies), science) for the subject-dependent questions. Thus, to uniquely identify teachers, the five digit school ID, plus the two digit teacher code, plus the one letter subject code would be used (positions 8-15). The section ends with a two digit code which identifies the class in which the teacher taught the student. See Figure 6-1 for an illustration of how all data tape IDs are linked."}, {"section_title": "Teacher Questionnaire Information", "text": "Information from the teacher questionnaire is presented in the same order as it appears in the questionnaire. Variables are identified by their SAS (SPSS-X) name. Variable names begin with FIT (First follow-up Teacher) and indicate the part (I, 2, 3 or 4) of the questionnaire and the question number within that part. For example, F1T310C, is question IOC from part 3 (or Part III) of the teacher questionnaire the part on teacher background. In the class rating section where specific subject areas are rated, the \"_\" in the variable name is replaced with the subject code of the specific subject referred to in the question. Thus, FIT2M19A is question 19A from the Math section of part 2. Exceptions to this naming convention are the four variables in the :dentification section: STU _ED (student ID), TEACH, SUBJECT, and CLASS. "}, {"section_title": "Guide to the Codebook", "text": "The codebook provides a comprehensive description of the teacher data file. For each variable on the tape the codebook provides a summary of the related information. The question number and wording, the variable's tape position and format, and the responses to the item along with their unweighted frequency and percent and weighted percent are shown. See Figure 6-2 for an example. Each portion of the example is numbered. These numbers can be used to reference the associated explanation in the text following the figure. As noted in Chapter III, certain responses were imputed logically, as the result of machine cleaning. In general, however, there were no attempts at imputing data for missing values. Because of this, nonresponse bias may be a problem, especially for items with high item nonresponse. (2) Tape Pos. 333-333 (3) Format: II (4) F1T36 (5) EMPLOYMENT STATUS AT THIS SCHOOL/SYSTEM (6) What is your employment status in this school or school system? Explanations: (I) Question number: For variables taken directly from questionnaires, this is the question number in the original document. F.!: Teacher Component Data File User's Manual (2) Tape position: This item gives the starting and ending tape position for each variable ot, the data tape. (3) Variable format: This item indicates the type of variable, its width, and the number of positions following the implicit decimal point, if any. SAS and SPSS-X variable name: Each variable on the data tape is identified by a unique SAS and SPSS-X variable name. For all variables the user should be careful always to refer to the variable by its SAS (SPSS-X) name in any computing procedures, rather than by its question number. SAS (SPSS-X) variable label: A short variable label appears after the variable name. This label is the same as that which appears on the SAS (SPSS-X) data definition cards included on the tape. Original question wording: This reproduces the exact question wording as it appeared in the questionnaire. Response categories: This item provides the original response categories or, in some cases, the recoded categories of the questionnaire items. For display in the tables, some continuous variables have been recoded to collapse all valid values into a single response category. This allows the codebook tables to show the frequency counts, unweighted percentages, and adjusted weighted percentages for continuous variables without printing each distinct value that the variable can take. These value labels are not the same as those on tne SAS (SPSS-X) data definition cards. Condensed value labels that do not cause truncation problems are provided with the data definition cards. Response codes: This item provides the actual numerical codes that appear on the data tape in the tape position specified (except for continuous variables, where the actual values that appear on the tape have been recoded to produce the frequency counts and percentages). Certain codes, discussed below, are reserved to indicate missing data, legitimate skip, and so forth. Frequency counts: This item shows the unweighted frequency counts for all student records that were processed, including records that have missing data codes, legitimate skips, and so forth. Unweighted percentage frequencies: This column displays the frequency counts of item 9 as percentages. All records that were processed are included. Weighted \"valid cases\" percentage frequencies: This column displays the weighted frequencies for those cases that are \"valid,\" that is, excluding those records that have been assigned reserved codes. The teacher file frequencies are run at the student level and weighted frequencies reflect weighted student frequencies through the student questionnaire weight (FIQWT). Reserved codes: In this data set certain codes, termed \"reserved codes,\" have been chosen always to stand for certain situations. These reserve codes and their interpretations are: Fl: Teacher Component Data File User's Manual 6 = multiple response . more than one response where only one response was called for 7 = refusal respondent refused to answer an item at the time of the abbreviated telephone interview 8 = missing data data that should be present for this respondent is missing, but respondent did not necessarily refuse to provide data 9 = legitimate skip . . . because of responses to preceding filter questions, data for this item should not be present for this respondent; that is, the value is legitimately missing These reserved codes correspond identically to those used in NLS-72 and in the HS&B study. The codes as listed above apply to variables with single-column data fields. For variables with fields greater than one column, the leftmost columns are filled with 9s (e.g., 96, 996, 9996). In addition to the survey described in the main text, several other supplemental components were undertaken and data files generated under the auspices of NELS:88. In the base year survey, these included: several state augmentations; a supplement of hearing-impaired students, funded by Gallaudet University; a supplement of Reformed Christian schools that are members of the Christian Schools International organization, funded by the Barnabas Foundation; and the NELS:88 Enhancement Survey of Middle Grades Practices, funded by the Office of Research in the Office of Educational Research and Improvement (0ERI), through the Johns Hopkins University. The first follow-up wave of NELS:88 also included supplemental components: the state augmentations, continued from the base year; the School Effects Augmentation (SEA), supported by funds from the John D. and Catherine T. MacArthur Foundation, and by NCES; and the Base Year Ineligible study (BYI), also sponsored by NCES. These auxiliary data files expand and enrich the available analysis data. In the base year, the NCES-sponsored core sample of 1,052 participating schools and 24,599 participating students was increased to 1,242 participating schools and 28,397 participating students, respectively, as a result of the state augmentations and Christian schools supplements. The first follow-up School Effects Augmentation added some 6,400 students to the initial base year retained sample of 21,474 students. Data for the state augmentations and other supplements discussed below do not appear on the NCES public release files for NELS:88."}, {"section_title": "Christian Schools Supplement", "text": "A sample of Christian schools that are members of the Christian Schools International (CSI) organization was drawn to supplement the NELS:88 base year school sample. The sample was selected from CST schools with probability proportional to eighth grade size. Two disproportionately large school units were double-sampled. Of the initially contacted 58 schools, 41 schools agreed to participate. (Due to the double-sampling of the two schools, the number of sampling units was 43.) Students, parents, teachers, and school administrators were surveyed. Students completed both the cognitive test battery and the questionnaire during the Survey Days held in their schools. Base-year data from the Christian School Supplement will be made available on a restricted use basis in the fall of 1992. Individual students in this supplement are being re-surveyed in the NELS:88 second follow-up, as are their parents."}, {"section_title": "State Augmentations and Supplements", "text": "In an effort to enhance the statistical precision of their state samples, four states sponsored sample augmentations in the base year by adding schools and students in their states. Three of these states also sponsored instrument supplements in the form of additional questions pertaining to policy issues of interest to their states. Three of the four states which augmented their samples in the base year continued to provide funds in the first follow-up for following and collecting data for the initial base year state augmentation samples which were retained in the first follow-up, and two states continued to sponsor instrument supplements in the first follow-up. The Survey of Middle Grades Practices enhanced the NELS:88 base year school questionnaire by collecting new information to monitor middle grades reform in the schools attended by NELS:88 eighth graders. The questionnaire for this supplemental survey was designed by staff of the Center for Research on Effective Schooling r Disadvantaged Students (CDS) at Johns Hopkins University (these staff members were, when the supplement was initiated, part of the Center for Research on Elementary and Middle Schools) and the data collection was conducted by NORC. The school principals who provided base year information in the NELS:88 school questionnaire were asked to participate in this enhancement survey between late October 1988 and February 1989. The enhancement survey augmented the information in the base year school questionnaire with additional information on school organization, guidance and advisory periods, rewards and evaluations, curriculum and instructional practices, interdisciplinary teams of teachers, transitions and articulation practices, involvement of parents, and other practices recommended for middle grades reform. The middle grades practices data are linkable to the NELS:88 base year data files, and are available on a restricted use basis only. Included in the enhancement survey was an alternative version of an item on classroom organization. This item from the Hopkins Enhancement Survey data was appended to the base year school file. It should be noted that the original question on the organization of classroom instruction (see base year school codebook, BYSC18, in the NELS:88 Base Year School Component Data File User's Manual) was asked during the 1987-1988 school year, while the correction item was asked during, and references, the 1988-1989 school year."}, {"section_title": "Past Studies and Data Files Related to NELS:88 Available from NCES", "text": "Data from the earlier NCES longitudinal studies--NLS-72 and HS&B--may also be of interest to users of the NELS:88 data. These data sets are of special interest for researchers interested in crosscohort comparisons between the sophomores of NELS:88 first follow-up (1990) and HS&B base year (1980), and, in the future, comparisons of the 1992 NELS:88 seniors and the HS&B sophomore and senior cohorts in 1982and 1980, and NLS-72 seniors in 1972 In addition to the core surveys for HS&B and NLS-72, described in Chapter I, records studies were undertaken, including the collection of the high school transcripts of the sophomore cohort and the collection of postsecondary education transcripts and financial aid data for the seniors. Data files for these studies and other HS&B data, such as parent surveys, school surveys, teacher comments, etc., are described below. Users manuals or other forms of documentation are available from NCES for all the data files. These auxiliary data files greatly expand the analytic capabilities of the core data sets, and researchers are encouraged to become familiar with them."}, {"section_title": "HS&I.; Base Year Files", "text": "The Language File contains information on each student who, during the base year, reported some non-English language experience either during childhood or at the time of the survey. This file contains 11,303 records (sophomores and seniors combined), with 42 variables for each student. The Parent File contains questionnaire responses from the parents of about 3,600 sophomores and 3,600 seniors who are on the Student File. Each record on the Parent File contains a total of 307 variables. Data on this file include parents' aspirations and plans for their children's postsecondary education."}, {"section_title": "Fl: Teacher Component Data File User's Manual", "text": "The Twin and Sibling File contains base year responses from sampled twins and triplets data on non-sampled twins and triplets of sample members; and data from siblings in the sample. t.is file (2,718 records) includes all of the variables that are on the HS&B student file, plus two additional variables (family ID and SETTYPE--type of twin or sibling). The HS&B teacher's comment files may be of particular interest to users of the NELS:88 teacher data. The Sophomore Teacher File contains responses from 14,103 teachers on 18,291 students from 616 schools. The Senior Teacher File contains responses from 13,683 teachers on 17,056 students from 611 schools. At each grade level, teachers had the opportunity to answer questions about HS&B-sampled students who had been in their classes. A response of Yes, No, or Don't Know was sought for the following seven student-specific evaluations: (1) will probably go to college; (2) is working up to potential; (3) seems popular with others; (4) has talked with me outside of class about school work or plans; (5) seems to dislike school; (6) has the kind of self-discipline to hold a job; (7) has or may have a physical or emotional handicap that is affecting his or her school work. The typical student in the sample was rated by an average of four different teachers. The files contain approximately 76,000 teacher observations of sophomores and about 67,000 teacher observations of seniors. The Friends File contains identification numbers of students in the HS&B sample who were named as friends of other HS&B-sampled students. Each record contains the IDs of sampled students and IDs of up to three friends. Linkages among friends can be used to investigate the sociometry of friendship structure-,, including reciprocity of choices among students in the sample, and to trace friendship networks."}, {"section_title": "Merged HS&B Base Year, First, Second and Third Follow-Up Files", "text": "The First Follow-Up Sophomore File contains responses from 29,737 students and includes both base year and first follow-up data. This file includes information on school, family, work experiences, educational and occupational aspirations, personal values, and test scores of sample participants. Students are also classified in terms of high school status as of 1982 (that is, dropout, same school, transfer, or early graduate). The First Follow-Up Senior File contains responses from 11,995 individuals and includes both base year and first follow-up data. This file includes information from respondents concerning their high school and postsecondary experiences and their work experiences. The Second Follow-Up Sophomore 91e has all base year, first follow-up, and second follow-up data for 14,825 members of the sophomore co wt. Data cover work experience, postsecondary schooling, earnings, periods of unemployment, and so 1 ,th, for the sophomore cohort, who by this time had been out of high school for two years. The Second Follow-Up Senior File encompasses all base year, first follow-up, and second follow-up data for the 11,995 individuals who constitute this follow-up sample. Data cover work experience, postsecondary schooling, earnings, periods of unemployment, and so forth, for the senior cohort, who by this time had been out of high school for four years. The Third Follow-Up Sophomore File includes all base year, first follow-up, second follow-up, and third follow-up data for the 14,825 members of the sophomore cohort. Data cover marriage and family formation, work experience, postsecondary schooling and interest in graduate degree programs, Fl: Teacher Component Data File User's Manual earnings, periods of unemployment, and alcohol consumption for this cohort, who by 1986 had been out of high school for four years. The Third Follow-Up Senior File includes all base year, first follow-up, second follow-up, and third follow-up data for the 11,995 individuals who constitute this follow-up sample. Data cover marriage and family formation, work experience, postsecondary schooling and interes. in graduate degree programs, earnings, periods of unemployment, and alcohol consumption for the senior cohort, who by 1986 had been out of high school for six years."}, {"section_title": "Other HS&B Files", "text": "The High School Transcript File describes the coursetaking behavior of 15,941 sophomores of 1980 throughout their four years of high school. Data include a six-digit course number for each course taken, along with course credit, course grade, and year taken. Other items of information, such as grade point average, days absent, and standardized test scores, are also contained on the file. The Offerings and Enrollments File contains school information, course offerings, and enrollment data for 957 schools. Each course offered by a school is identified by a six-digit course number. Other information, such as credit offered by the school, is also contained on each record. The Updated School File contains base year data (966 completed questionnaires) and first follow-up data (956 completed questionnaires) from the 1,015 participating schools in the HS&B sample. First follow-up data were requested only from those schools that were still in existence in the spring of 1982 and had members of the 1980 sophomore cohort currently enrolled. Each high school is represented by a single record that includes 230 data elements from the base year school questionnaire, if available, along with other information from the sampling files (e.g., stratum codes, case weights). The Postsecondary Education Trasteript File for the HS&B seniors contains transcript data on dates of attendance, fields of study, degrees earned, and the titles, grades, and credits of every course attempted at each school attended, coded into hierarchical files with the student as the highest level of aggregation. Although no survey forms were used, detailed procedures were developed for extracting and processing information from thc postsecondary school transcripts that were colle?ted fcr all members of the 1980 senior cohort who reported attending any form of postsecondary se-tooling in the first or second follow-up surveys. (Over 7,000 individuals reported over 11,000 instances of school attendance.) The Postsecondary Education Transcript File for the HS&B sophomores includes transcript dai a for over 6,000 members of the 1980 sophomore cohort who reported in the follow-up survey that they had attended a postsecondary institution. The data tile created for this study includes detailed information about program enrollments, periods of study, fields of study pursued, specific courses taken, and credits earned as of the third follow-up in 1986. Additional sophomore cohort transcripts data are being collected in the autumn of 1992 as part of the HS&B fourth follow-up study. The Senior Financial Aid File contains financial aid records from postsecondary institutions respondents reported attending and federal records of the Guaranteed Student Loan (GSL) program and of the Pell Grant program. The Sophomore Financial Aid File includes data on postsecondary financial aid experiences for 1980 sophomores who attended a postsecondary institution. Financial aid data were collected from federal records of the Guaranteed Student Loan and Pell Grant programs, and GSL disbursement data 4 L 3 El: Teacher Component Data Fih User's Manual from guarantee agencies participating in the C'Itaranteed Student Loan program. The HS&B REGIS and PSVD File contains the postsecondary school codes for schools HS&B respondents reported attending in the first and second follow-ups. In addition, the file provides data on institutional characteristics, such as type of institution, highest degree offered, enrollment, admissions requirements, tuition, and so forth. This file permits analysts to link HS&B questionnaire data with institutional data for postsecondary schools attended by respondents."}, {"section_title": "NLS-72 Files", "text": "The NLS-72 Base Year Through Fourth Follow-Up (1979) File contains data from the base year through fourth follow-up for over 23,000 respondents. Data include school experiences and test results during the base year and subsequent activities related to work, postsecondary schooling, military service, family formation, and goals and aspirations. The NLS -72 Fifth Follow-Up File consists of the results of the fifth follow-up survey, carried out in 1986, when sample members were about thirty-two years old. Data include work experience going back to 1979, postsecondary schooling, extensive family formation history, periods of unemployment, goals and aspirations, and selected attitudes. Records in this file can be linked through student ID to those in the NLS-72 Base Year Through Fourth Follow-Up (1979). The NLS-72 Teacher Supplement File contains the responses of the portion of the fifth follow-up NLS-72 sample who had obtained teacher certification and/or had teaching experience. Data include certification history, subjects taught, years of experience, attitudes toward teaching as a career, and subsequent work experiences of those who had left teaching. These data can be linked through the respondent ID to the NLS-72 Fifth Follow-Up File and to the NLS-72 Base Year Through Fourth Follow-Up File. The Postsecondary Education Transcript Study of the NLS-72 Sample contains transcript data on dates of attendance, fields of study, degrees earned, and the titles, grades, and credits of every course attempted at each school attended, coded into hierarchical files with the student as the highest level of aggregation. Although no survey forms were used, detailed procedures were developed for extracting and processing information from the postsecondary school transcripts that were collected in 1984 for all members of the NLS-72 cohort who reported attending any form of postsecondary schooling in any of the first through fourth follow-up surveys. (Over 14,000 individuals reported over 24,000 instances of school attendance). The large number of VALUE statements in the PROC FORMAT section requires that a special DD statement be placed just after the // EXEC SAS statement to increase the capacity of the format library during a SAS run: //LIBRARY DD SPACE= (TRK,(25,25,60)) Since this may not be possible at some computer installations, it may be necessary to delete some VALUE statements 4. When working with large files, it may be necessary to override the default work space with the following DD statement: //WORK DD UNIT=SYSCR,SPACE= (CYL,(40,40)) Place the //WORK DD statement just after the // EXEC SAS statement (or after the //LIBRARY DD statement, if that is included as well)."}, {"section_title": "5.", "text": "The formats given in the PROC FORMAT step here are not permanently associated with each variable. Whenever they are needed for a procedure, it is necessary to include them in this PROC FORMAT step before the procedure(s) that will use them. In the following example PROC FORMAT is used first to make a temporary library of formats (sets of value labels). Then PROC FREQ is used to access the First Follow-Up teacher SAS system file and to create a frequency table. The FORMAT statement in PROC FREQ links the variable in the frequency to the appropriate value label stored in the temporary format library. VALUE FlIAV I = \"YES\" 2 = \"NO\" 6 = \"MULTIPLE RESPNSE' 7 = \"REFUSAL\" E = \"MISSING\" 9 = \"LEGITIMATE SKIP'"}, {"section_title": "// EXEC SAS", "text": ""}, {"section_title": "TABLES F1T310D1; TITLE 'BACHELOR'S DEGREE MAJOR IN MATHEMATICS':", "text": "to the end of each SAS card fi;e. there is a frequency procedure which contains FORMAT statements for every variable for which there is a format. These FORMAT statements can be used in any SAS procedure. However, if there are a large number of format links, they must be divided into several format statements to work. (About 90 format links in the format statement were utilized in testing the SAS cards on the University of Chicago mainframe. Whenever variables are needed from several files (e.g , first follow-up school and student), the files may be merged by STU_ID or F1SCH_ID using SAS MERGE statements. A simple one line MERGE statement will put variables from separate files together in a single record for analysis Users are reminded to first sort the files by the variables selected for merging: that is. sort both files either by STU_ID or F1SCH_ID. For very large files, the user may encounter problems when sorting. Various options may be added to the //EXEC SAS card to circumvent these problems. A suggested example is given below (consult the SAS manual for descriptions of these options): It is suggested that the user include the LENGTH statement when creating new variables, in order to save space and computer memory."}, {"section_title": "9.", "text": "For many tabulations, PROC TABULATE produces the most readable output. The SAS user may use the format statements (provided) for classification variables to produce the row values of tabulate tables."}, {"section_title": "10.", "text": "Output from SAS can be downloaded to personal computers for production of final reports. NCES has available a program for taking into account the sample design when computing standard errors. The program, known as CTAB, is a Taylor series based routine that uses an ASCII file to compute standard errors for crossclassifications. The program also produces labeled tabular output suitable for use in publications. CTAB is available for use on microcomputers, and can be obtained through NCES."}, {"section_title": "11.", "text": "Use the NCES-and NORC-defined composite and classification variables whenever possible to simplify programming."}, {"section_title": "12.", "text": "SAS and SPSS-X system files can now be converted at many computer installeons. Contact your own facility to obtain the information necessary to create an SPSS-X file from SAS and vice versa."}, {"section_title": "13.", "text": "There is a peculiarity with version 6.06 of SAS. The symbol \"%\" will not be printed in a variable label if the label is the first thing to be printed on the page. LONGITUDINAL STUDY As a matter of polio/. the Nat n-a :::ii-r 7-i a-:n 5ta'. s cs 3 wow concerned w;th protectihg the privacy of -_.' , -...'...,1 S ,i,'-c; particizate r -111. ."}, {"section_title": "OM", "text": "i ioluntary surveys Vie. ,vast to 'ia. Jo__ 'K --_,,, 7-.3.' 1 Section 406 of trie General EC .cat C\" Pr.:, sons Act _,1_;-'..1SC, '''221e-4 i and Public Law 100-297 alloy., JS `0 asi.. ,D_: 're ibii....=s'.' ors .n '.his Your resoonses will be me-ged p,tr I--.-Fe .-.. :-.--er -es;:criber'_3 an l the answers you give will rie,ie, by -i.,-_--' e ,:: a =,-,-: , 3 5:-1..--1. :4; 5 L . oft."}, {"section_title": "You may skip any questions ! ) _,", "text": ", : a F.. ,,J e i---..oi ,ii, L.:-, -F. r , J st i 417. i_ I.: ant hope you answer as rrian / =1..,=.: The public reporting burden for this collection of information is estimated to average one hour (60 minutes) per response. Send comments regarding this burden estimate, or any other aspect of this collection of information, Make dark marks that fill the oval. Erase cleanly any answer you wish to change. Make no stray markings of any kind."}, {"section_title": "CORRECT MARKS", "text": ""}, {"section_title": "000111", "text": "INCORRECT MARKS C6X00 EXAMPLE: 1. Will marks made with ballpoint or felt-tip pen be properly read?"}, {"section_title": "INTRODUCTION", "text": "This questionnaire is part of a major longitudinal study designed to provide trend data about critical transitions experienced by young people as they develop, attend school, and embark on their careers. Your school has agreed to participate in this study and has allowed us to resurvey those students who were selected as part of a random sample when they were in eighth grade. A list of these sampled students should be attached to the cover of this questionnaire. (If the list is missing. please report the problem to the study coordinator at your school the person who distributed this questionnaire to you.) You have been identified as a teacher of one or more of the sampled students. We are seeking information from you to supplement other study data about these students. This questionnaire has four very different sections: Part I asks you questions about the characteristics and behaviors of the sampled students whom you have in one of your classes this semester/term. Individual students are referred to by \"Student Number.\" as shown in the List of Students attached to the cover of this questionnaire. Part I asks you to write the student's initials below the student's number. If you have more than sixteen students on your list of students, your packet should contain a \"Continuation Booklet\" for use in answering questions about students 17 and above. Part II asks a series of questions about specific, designated classes. The particular class or classes for which information is being requested is indicated on a Class List sheet attached to the cover page of this questionnaire. As you will see, Part II contains room for responses on a maximum of five classes. You may not need all five response columns. Use only as many columns as you need to respond separately for each of the classes listed on the attached class list. In the unlikely event that your class list contains more than five different classes, use your 'Continuation Booklet\" for answering questions about classes numbered 6 and above. Part III requests some general background information about you. Part IV asks a series of questions about your school's climate. Please answer directly on the questionnaire by darkening the appropriate oval or by writing your response in the space provided. We realize that you are very busy; however, we would appreciate it if you would complete the questionnaire and return it to your NELS:88 School Coordinator within the next two weeks (or sooner, if asked by the coordinator). To protect the confidentiality of your responses, we suggest that you return the completed questionnaire in the confidential return envelope provided for this purpose. Thank you very much for your help.            --      13  16 't 9, (4) tr. \u00ae   xA -: . ,,,,, 0 1,         \nThis questionnaire is part of a major longitudinal study d,.-signed to provide trend data about critical transitions experienced by young people as they develop, attend school, and embark on their careers. Your school has agreed to participate in this study and has allowed us to resurvey those students who were selected as part of a random sample when they were in eighth grade. A list of these sampled students should be attached to the cover of this questionnaire. (If the list is missing, please report the problem to the study coordinator at your school the person who distributed this questionnaire to you.) You have been identified as a teacher of one or more of the sampled students. We are seeking information from you to supplement other study data about these students. This questionnaire has four very different sections: Part I asks you questions about the characteristics and behaviors of the sampled students whom you have in one of your classes this semester/term. Individual students are referred to by \"Student Number,\" as shown in the List of Students attached to the cover of this questionnaire. Part I asks you to write the student's initials below the student's number. If you have more than sixteen students on your list of students, your packet should contain a \"Continuation Booklet\" for use in answering questions about students 17 and above. Part II asks a series of questions about specific. designated classes. The particular class or classes for which information is being requested is indicated on a Class List sheet attached to the cover page of this questionnaire. As you will see, Part II contains room for responses on a maximum of five classes. You may not need all five response columns. Use only as many columns as you need to respond separately for each of the classes listed on the attached class list. In the unlikely event that your class list contains more than five different classes, use your \"Continuation Booklet\" for answering questions about classes numbered 6 and above. Part III requests some general background information about you. Part IV asks a series of questions about your school's climate. Please answer directly on the questionnaire by darkening the appropriate oval or by writing your response in the space provided. We realize that you are very busy; however, we would appreciate it if you would complete the questionnaire and return it to your NELS:88 School Coordinator within the next two weeks (or sooner, if asked by the coordinator). To protect the confidentiality of your resporlses, we suggest that you return the completed questionnaire in the confidential return envelope provided for this    1 1   1 1 1 1 1 1 1 1   1 1 1 1   1 1 1  1 1 1 1 1   1       3. Which of the following best 0 describes the \"track-this class is considered to be? (MARK ONEI  This class consists primarily of students with: Avt,tw. Irv 1Imva-i a( hi(,htne,,t Widely (11nd ihg hicynnhi (2) Students Students (3)  Wirl(ly flinhring achthvhinent Iovels."}, {"section_title": "Most of the Time", "text": "Sometimes Rarely Never 0 0 0 0 0 0 0 0 0 0 0 0 i. So that the four independent teacher questionnaires--English, mathematics, science and history--could be optically scanned as a single document, pages 20 through 26, in the English teacher questionnaire booklet, were left blank intentionally. That is, these blank pages were reserved for the other specific subject matter items asked in the mathematics, science and history teacher questionnaires.   \nContinued on next page    e. There is a great deal of cooperative effort among staff members E)0 (a)(a)CE)(10 0 CD 0 0 0 (1) m. The principal usually consults with staff members before he she makes decisions that affect us The level of student drug or alcohol use in this school interferes with my teaching OGDCDOCDCD n. The attitudes and habits students bring to my class greatly reduce their chances for academic success p. I am familiar with the content and specific goals of the courses taught by other teachers in my department q The teachers union (or education association) and the school administration work together to improve the achievement of students in this school I Now 3. Indicate the degree to which each of the following is a problem with students in your school. . When students are successful in achieving intended goals or objectives, it is often attributed to one of the following sources. ww. Which do you believe is the most frequent source of success? (MARK ONE) c If some students in my class are riot doing well I feel that I should change my approach to the subject 0 0 CD 0 CD CE) d By trying a different teaching method. I can significantly affect a student's achievement 00CDGDCDGD e There is really very little I can do to insure that most of my students achieve at a high level CDO)00013) f I am certain t am making a difference in the lives of my students  "}, {"section_title": "USES OF THE DATA", "text": "The data from this survey will be used by educators and by Federal and State policy makers to address important issues facing the Nation's schools: educational standards, curriculum tracking, dropping out of school, the education of the disadvantaged, the needs of language minority students, incentives for attracting students to the study of science and mathematics, and the features of effective schools."}, {"section_title": "CONFIDENTIALITY", "text": "As a matter of policy, the National Center for Education Statistics is concerned with protecting the privacy of individuals who participate in voluntary surveys. We want to let you know that: 1. Section 406 of the General Education Provisions Act (20-USC 1221e -1) and Public Law 100-297 allow us to ask you the questions in this questionnaire. 2. Your responses will be merged with those of other respondents and the answers you give will never be identified as yours. 3. You may skip any questions you do not wish to answer: however. we hope you answer as many questions as you can. -11P-\nAs a matter of policy, the National Center for Education Statistics is concerned with protecting the privacy of individuals who participate in voluntary surveys. We want to let you know that: 1. Section 406 of the General Education Provisions Act (20-USC 1221e -1) and Public Law 100-297 allow us to ask you the questions in this questionnaire. 2. Your responses will be merged with those of other respondents, and the answers you give will never be identified as yours. 3. You may skip any questions you do not wish to answer: however, we hope you answer as many questions as you can. -0-"}, {"section_title": "ID NUMBER", "text": "The public reporting burden for this collection of information is estimated to average one hour (60 minutes Make dark marks that fill the oval. Erase cleanly any answer you wish to change. Make no stray markings of any kind. This questionnaire is part of a major longitudinal study designed to provide trend data about critical transitions experienced by young people as they develop, attend school, and embark on their careers. Your school has agreed to participate in this study and has allowed us to resurvey those students who were selected as part of a random sample when they were in eighth grade. A list of these sampled students should be attached to the cover of this questionnaire. (If the list is missing, please report the problem to the study coordinator at your school the person who distributed this questionnaire to you.) You have been identified as a teacher of one or more of the sampled students. We are seeking information from you to supplement other study data about these students. This questionnaire has four very different sections: Part I asks you questions about the characteristics and behaviors of the sampled students whom you have in one of your classes this semester/term. Individual students are referred to by \"Student Number,\" as shown in the List of Students attached to the cover of this questionnaire. Part I asks you to write the student's initials below the student's number. If ycu have more than sixteen students on your list of students, your packet should contain a \"Continuation Booklet\" for use in answering questions about students 17 and above.\nThe public reporting burden for this collection of information is estimated to average one hour (60 minutes) per response. "}, {"section_title": "4)", "text": "Part II asks a series of questions about specific, designated classes. The particular class or classes for which information is being requested is indicated on a Class List sheet attached to the cover page of this questionnaire. As you will see, Part II contains room for responses on a maximum of five classes. You may not need all five response columns. Use only as many columns as you need to respond separately for each of the classes listed on the attached class list. In the unlikely event that your class list contains more than five different classes, use your \"Continuation Booklet\" for answering questions about classes numbered 6 and above. Part III requests some general background information about you. Part IV asks a series of questions about your school's climate. Please answer directly on the questionnaire by darkening the appropriate oval or by writing your response in the space provided. We realize that you are very busy; however, we would appreciate it if you would complete the questionnaire and return it to your NELS:88 School Coordinator within the next two weeks (or sooner, if asked by the coordinator). To protect the confidentiality of your responses, we suggest that you return the completed questionnaire in the confidential return envelope provided for this purpose. Thank you very much for your help. 111111111tH 11111111111111111111111111111111111111111111111111"}, {"section_title": "PART I: STUDENT INFORMATION", "text": "Please answer the questions n this section for each student listed on the attached Student List Fill in the oval corresponding to the appropriate responses to Questions 1.23 in the first column for the first listed student Continue until you have completed a column for each student listed on the Student List Questions 2-23 apply only to students who are enrolled in the class listed next to their name on the Student List (a \"Yes\" response to    How involved are the parents of this student in his her academic performance\"'      Ar(.1t,'\" ii 1'1001 admi\"\"1\"-      13. Indicate the person or groups who helped determine which particular textbook workbook you use in this 14 Now prepared do you feel to teach the subject matter covered in this course? Approximately how many minutes per week does this class meet regularly (exclude lab penodsr  .. class have lab sessions (e.g., science, math)? 16   ...."}, {"section_title": "CO", "text": ".1 \\C4 VI to The columns refer to the same classes that you identified on page 10, Question 1A.   .. ..       Fl '\"i' ' 0 i 0 3.,C)F9  So that the four independent teacher questionnaires--English, mathematics, science and history--could be optically scanned as a single document, pages 24 through 26, in'the science teacher questionnaire booklet, were left blank intentionally. That is, these blank pages were reserved for the other specific subject ma..:ter items asked in the mathematics, history and English teacher questionnaires. PART TEACHER BACKGROUND AND ACTIVITIES 00 00 00 00 00 00 00 00 CO   24. Indicate the importance you give to each of the following in setting grades for students in your classes (exclude special education students  Rules for student behavior are consistently enforced in this school 0 CD CD CD \u00ae\u00ae ri The principal usually consults with staff members before he she makes decisions that affect us 00 CD 0 GAD 3. Indicate the degree to which each of the following Is a problem with students in you school.  dropping out of school, the education of the disadvantaged, the needs of language minority students, incentives for attracting students to the study of science and mathematics, and the features of effective schools."}, {"section_title": "1111111111111111111H11111111111111111111111911111111111111110111", "text": "Students Students f0 10; (1] (ti.     class have lab sessions (e.g., science, math)? 16   ' <I (') .7) Never,s`-liC:.., z? 42. -- . , . .0 -9 >'\"\u00b0, -; S' Semester,4/Q)  The columns refer to the same classes that you identified on page 10, Question 1A.     6.: (3)"}, {"section_title": "76", "text": ".10 ."}, {"section_title": "1-i)", "text": ".   3- .   g. So that the four independent teacher questionnaires--English, mm mathematics, science and history--could be optically scanned as a single document, pages 20 through 26, in the history teacher questionnaire booklet, were left blank intentionally. That is, these blank pages were reserved for the other specific subject matter items asked in the mathematics, science and English teacher questionnaires."}, {"section_title": "1-", "text": "PART III: TEACHER BACKGROUND AND ACTIVITIES  Yes, summer only (1) Yes. school year only (2)  Yes. during the entire year   Continued on next page 3. Indicate the degree to which each of the following is a problem with students In your school. (MARK ONE ON EACH LINE) e There is really very little I can do to insure that most of my students achieve at a high levEI OCOI:Da\")0\u00ae    and Public Law 100-297 allow us to ask you the questions in this questionnaire 2 You responses will be merged with those of other respondents, and the answers you give will never be identified as yours. Make dark marks that fill the oval. Erase cleanly any answer you wish to change. Make no stray markings of any kind. CORRECT MARKS llICORREC-r MARKS 000  This questionnaire is part of a major longitudinal study designed to provide trend data about critical transitions experienced by young people as they develop, attend school, and embark on their careers. Your school has agreed to participate in this study and has allowed us to resurvey those students who were selected as part of a random sample when they were in eighth grade. A list of these sampled students should be attached to the cover of this questionnaire. (If the list is missing, please report the problem to the study coordinator at your school the person who distributed this questionnaire to you.) You have been identified as a teacher of one or more of the sampled students. We are seeking information from you to supplement other study data about these students. Part I asks you questions about the characteristics and behaviors of the sampled students whom you have in one of your classes this semester/term. Individual students are referred to by \"Student Number,\" as shown in the List of Students attached to the cover of this questionnaire. Part I asks you to write the student's initials below the student's number. If you have more than sixteen students on your list of students, your packet should contain a \"Continuation Booklet\" for use in answering questions about students 17 and above. Part II asks a series of questions about specific, designated classes. The particular class or classes for which information is being requested is indicated on a Class List sheet attached to the cover page of this questionnaire. As you will see, Part II contains room for responses on a maximum of five classes. You may not need all five response columns. Use only as many columns as you need to respond separately for each of the classes listed This questionnaire has four very different sections: on the attached class list. In the unlikely event that your class list contains more than five different classes, use your \"Continuation Booklet\" for answering questions about classes numbered 6 and above. Part III requests some general background information about you. Part IV asks a series of questions about your school's climate. Please answer directly on the questionnaire by darkening the appropriate oval or by writing your response in the space provided. We realize that you are very busy; however, we would appreciate it if you would complete the questionnaire and return it to your NELS:88 School Coordinator within the next two weeks (or sooner, if asked by the coordinator). To protect the confidentiality of your responses, we suggest that you return the completed questionnaire in the confidential return envelope provided for this purpose. Thank you very much for your help.        3. Which of the following best 0 describes the \"track\" this class is considered to be? (MARK ONE) General.."}, {"section_title": "IL", "text": ""}, {"section_title": "N-", "text": ""}, {"section_title": "General.", "text": ""}, {"section_title": "General", "text": "General.       15b. Approximately how many minutes per week does this class have lab sessions (e.g., science, math)?"}, {"section_title": "Vocational technical", "text": "16   .             Of these, how many were spent on the following? 26b. The teacher working with the entire class as a group (e.g., lecture, etc.) 26b. 26c. The teacher working with small groups of students A one pound bag contains 50 percent more tan M&Ms than green ones. Write a mathematical statement that represents the relationship between the tan (t) and green (g) M&Ms, using t and g to stand for the number of tan and green M&Ms. Here are some responses you get from students: Kelly "}, {"section_title": "NOTE:", "text": "So that the four independent teacher questionnaires--English, mathematics, science and history--could be optically scanned as a single document, page 26, in the mathematics teacher questionnaire booklet, was 'eft blank intentionally. That is, this blank page was reserved for the other specific subject matter items asked in the science, history and English teacher questionnaires. PART III: TEACHER BACKGROUND AND ACTIVITIES     24. Indicate the Importance you give to each of the following in setting grades for students in your classes (exclude special education students 3. Indicate the degree to which each of the following is a problem with students in your oc,itool.     PiT:i2E USE Or C'.EP REACINC mA\"EL:A..1, Eng,,,, cc,. how much Kmohptla dc r4:11(Z111,/r.\" \"Pic' \".\".'\"\".   82.5% (MISS) )0TALS: 27994   "}, {"section_title": "(MISS, 25E21", "text": ""}]