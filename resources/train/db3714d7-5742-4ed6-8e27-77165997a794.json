[{"section_title": "", "text": "xii"}, {"section_title": "CONTENTS (continued)", "text": "List of Tables   Table  Page   3 10-1 Crosswalk between round number of data collection, grade, and school year: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 ..  1998-99, 1999-2000, 2001-02, 2003-04, and 2006-07..................................................................... 10-7 10-4 ECLS-K: K-8 longitudinal weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 Examples of research questions and appropriate weights to use: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 xxiv This page is intentionally left blank. xxv"}, {"section_title": "GETTING STARTED", "text": "This chapter highlights key information needed to work with the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K) data and directs users to the appropriate sections of this manual to get started quickly. For additional information about any particular topic, users should go to the indicated section of this manual, hereinafter referred to as the User's Manual. In this chapter, major differences between the eighth-grade data collection and previous rounds are summarized; cautions and caveats about using the data are provided; and basic information about using the Electronic Codebook is summarized. As described in section 1.4 of chapter 1, two files are available for analyzing eighth-grade data: (1) a restricted-use data file containing information collected during the eighth-grade round and recalibrated assessment scores for all rounds and (2) a kindergarten-eighth grade (K-8) full sample public-use data file that has been produced in the place of both an eighth-grade public-use file and a K-8 longitudinal file. As described in chapter 10, the full sample data file can be used for within-year analyses of any round of data collection from kindergarten through eighth grade, and it also can be used for any combination of cross-year analyses. This manual serves as a guide for users of both of these files. Most of the User's Manual chapters apply to both the public-use and the restricted-use data files, but a few sections apply to only one of the two. Exhibit A summarizes the User's Manual sections that do not apply to both files and indicates the data file to which they apply. The user should watch for notices (\u25ba Please note\u2026) at the beginning of sections that indicate if a section does not apply to both data files. In preparing public-use data files, the National Center for Education Statistics (NCES) takes steps to minimize the likelihood that an individual school, teacher, parent, or child 1 participating in the study can be identified. Every effort is made to protect the identity of individual respondents. Some modifications to the data contained in the eighth-grade restricted-use file have been made to the K-8 full sample public-use data file to ensure confidentiality. These modifications do not affect the overall data quality and most researchers should be able to find all data needed for analysis in the public-use data file. Chapter 1, section 1.4.1, provides a general description of the differences between public-use and 1 To be consistent with documentation from earlier rounds of the ECLS-K, this manual refers to student respondents in the eighth-grade round as \"children.\" xxvi restricted-use files. Table 7-16 in chapter 7 contains a list of eighth-grade variables that have been modified. Section 7.10 contains additional information about the \"masking\" process. This chapter applies to users of the K-8 full sample public-use data file"}, {"section_title": "Major Differences in the Eighth-Grade Data Collection and Release", "text": "Although the eighth-grade data collection shares many similarities with earlier rounds, some modifications were made to capture important information relevant to children in eighth grade. The major differences between the eighth-grade data collection and the earlier rounds are summarized below: Parent data were collected in the fall rather than in the spring, as was the method in previous rounds. Because the data were collected at the beginning of the school year, items tapping parent involvement in various school functions were followed by items asking whether parents had yet had an opportunity to be involved in those functions. xxvii New construct areas were added to the parent interview for eighth grade. These new construct areas included the following: expectations of how far child will go in school; -family activities (e.g., working on homework together, going shopping, attending concerts, plays, or movies); -family rules (e.g., rules new to round 7 are about the child maintaining a certain grade point average, doing homework, and hours spent on the computer or playing video games); -parent monitoring (e.g., checking homework, having and enforcing a curfew); xxviii -home ownership, value, and mortgage debt; and savings for post-high school education. The sample of children included on the K-8 longitudinal public-use data file differs from the sample included in prior ECLS-K longitudinal files. In each of the previous ECLS-K longitudinal files, children were included if they had at least one nonzero weight among the weights computed for the rounds included in the longitudinal file. However, the K-8 longitudinal public-use data file included any child who was ever sampled in the base year who had base-year data, and any child sampled in the first-grade year who had at least one round of data in first grade and beyond. In eighth grade, children were assessed in proctored group settings rather than one on one. In earlier rounds, the mathematics, reading, and science assessments were conducted via one-on-one direct assessment. In the eighth grade, however, children were expected to be familiar with proctored testing in school. Thus, groups of ECLS-K sampled children who attended the same school were assessed in a single, proctored group administration. The content changes of the assessment are described in section 2.1.2. Two-level (high versus low) second-stage assessment forms were used, rather than three-level forms used in previous rounds. In the eighth-grade timed assessment session, all children were given separate routing tests in each subject area to determine the level (high versus low) of their second-stage reading, mathematics, and science assessments. Routing children into two, rather than three, second-stage forms facilitated accurate and efficient distribution of the second-stage forms. Results of the spring 2006 field test showed that there was no loss of data by using a two-level second-stage form. Information on the results of the spring 2006 field test can be found in the ECLS-K Methodology Report for the Eighth Grade (NCES 2009-003) (Tourangeau et al. forthcoming). Information on the quality of the eighth-grade assessment data can be found in the ECLS-K Psychometric Report for the Eighth Grade (NCES 2009-002) (Najarian, Pollack, and Sorongon forthcoming). Age-appropriate changes were made to the rating items used to tap children's perceptions of their social skills, interest in school subjects, self-concept, and control they had over their own lives. In the kindergarten and first-grade rounds of the ECLS-K, parents and teachers reported on children's social skills. In the third and fifth grade of the ECLS-K, the children provided information about themselves by completing a short self-description questionnaire that included items from a published instrument appropriate for third-and fifth-graders (Self Description Questionnaire I) (Marsh 1992a). In eighth grade, a new version of the self-description questionnaire was developed using items from a published instrument designed to be used with adolescents (Self Description Questionnaire II) (Marsh 1992b). See sections 2.1. 1, 3.3, and 3.4 for additional information on the eighth-grade self-description questionnaire. In addition, two scales from the student questionnaire adapted from the National Education Longitudinal Study (NELS:88) tapped children's self-concept and their perceptions of how much control they had over their own lives. See sections 3.3 xxix and 3.4 for more information on these scales and the scores that are available for analysis. The procedures for collecting height and weight data were modified. In the previous rounds of the ECLS-K, height and weight data were collected during the one-on-one direct assessment sessions. In the eighth grade, height and weight data were collected during the group assessment sessions. In most cases the groups were small (in many cases there was a single child). However, in some cases, the assessment sessions had several children participating. In the group assessment sessions, children were measured one at a time at a single height and weight station. The average size of the assessment group was three children and ranged from one to nine children per group. See section 5.5.2 or the ECLS-K Eighth-Grade Methodology Report (NCES 2009-003) (Tourangeau et al. forthcoming) for additional information on the height and weight data collection. In eighth grade, children completed self-administered paper and pencil questionnaires about their school experiences, their activities, their perceptions of themselves, and their weight, diet, and level of exercise. This questionnaire was completed during the group assessment session. The Academic Rating Scale (ARS) was replaced with other items tapping children's classroom behavior and performance. English, mathematics, and science teachers were asked to rate children on their respective domain-relevant skills. Teachers also rated children on their effort (e.g., \"Does this student usually work hard for good grades in your class?\"), behavior (e.g., \"Does this student seem to relate well to other students in your class?\"), and attendance (e.g., \"How often is this student absent from your class?\"). Teachers also were asked to report if they had either spoken to a guidance counselor regarding a child's poor performance or if they had recommended children for academic honors or advanced placement. Information on the scaling of these items can be found in section 3.2. Information about children's food consumption was collected through a selfadministered questionnaire. In previous rounds, the assessor read the questionnaire items for the children and recorded their responses. In the eighth-grade round, the food consumption items were included in the self-administered questionnaire completed during the group assessment session. Collection of school record abstracts and school facilities checklists was discontinued. These instruments were discontinued due to cost constraints and low response rates in prior rounds. Items associated with Individualized Education Programs (IEPs) that were collected from school record abstracts in previous rounds were collected in the special education teacher questionnaire (B). xxx"}, {"section_title": "Cautions and Caveats", "text": "Users of previous rounds of the ECLS-K data have frequently asked certain questions. For example, can school-level and teacher-level estimates be made with the ECLS-K data? Or, did the ECLS-K sample whole classrooms? NCES has developed a set of responses to users' most common questions. Please see the NCES website for commonly asked questions and responses: http://nces.ed.gov/ecls. In addition to the frequently asked questions and responses, other aspects of working with the data are important to know, including the following: The sample is not representative of children in eighth grade, classrooms, or schools. The ECLS-K base-year sample is a representative sample of children attending kindergarten during the 1998-99 school year, of schools with kindergartens, and of kindergarten teachers. Because the first-grade sample was freshened with children who had not attended kindergarten in the United States in the previous year, the first-grade sample is representative of children attending first grade in the United States during the 1999-2000 school year. However, it is not representative of schools with first grades or of first-grade teachers. The eighth-grade sample is not representative of children in eighth grade, eighth-grade teachers, or schools with eighth grades. Children who started their schooling in the U.S. after first grade are not represented in the sample. The data should not be used to make statements about eighth-graders, schools with eighth grades, or eighth-grade teachers. Not all sample children were in eighth grade. The eighth-grade data file includes children who were in eighth grade in spring 2007, and others who were either held back (e.g., seventh-graders) or promoted ahead an extra year or more (e.g., ninthgraders). Users should be aware of this fact when using the data and interpreting the findings. Most children in the sample had been in school for at least 9 years (K-8) and some more than 9 years (those who were repeating kindergarten in the base year). A very small number may have been in school less than 9 years (some were part of the freshened sample added in first grade). Child mobility and its consequences. A random subsample of children who transferred from their base-year schools was flagged to be followed in fall-first grade and in subsequent rounds of data collection. Sections 4.3.1,4.4.1,4.5,and 4.6 describe the subsampling of movers. A number of variables on the file can be used to determine if a child moved to a different school between rounds. Section 7.8 describes these variables. Missing data. Users should be certain to recode any missing data properly before conducting analyses. If the user is analyzing data over time, it is especially important to check that all skip patterns are the same across years because some changed between rounds of data collection. Five different possible missing data codes are used xxxi on the file. See section 7.4 for a discussion of the different missing values codes and the circumstances in which they are used. Rescaled scores. The longitudinal scales necessary for measuring gain over time were developed by pooling all rounds of item response data, from fall-kindergarten through spring-eighth grade. Scale scores reported in each successive round were based on all test items present in the assessments up to and including that round. Each time the item pool was expanded, scores were recalibrated for all rounds to make longitudinal comparisons possible. Each recalibration of the scale score represents the estimated number right on a larger and larger set of items. As a result, the scale score for the same child in the same grade changes each time a new set of test items is incorporated and the scale on which the score is based is expanded. Estimates of gains in scale score points should be made using the recalibrated versions for all rounds. It would be inappropriate to compare previously reported scale score means with means based on recalibrated scores in the eighth-grade data file because the set of items on which the score is based has changed. This caveat applies primarily to analyses that report gains in scale score points. The effect of rescaling on previously reported Tscores and proficiency probability scores should be relatively small. However, to the extent that the pooling of test items across rounds represents a redefinition of the construct being measured, slight differences in these statistics may be observed as well. See the ECLS-K Psychometric Report for the Eighth Grade (NCES 2009-002) (Najarian, Pollack, and Sorongon forthcoming) for more information."}, {"section_title": "Use of weights.", "text": "The eighth-grade restricted-use data file contains 5 sets of crosssectional weights and 12 longitudinal (panel) weights. Although a variety of weights exist on the file, there are scenarios for which there may not be a perfect weight. For a discussion of the weights and guidance in selecting an appropriate one, refer to sections 4.8, 9.3.1, and 10.4. Defining special populations. The ECLS-K includes a number of analytic groups of interest that can be identified and studied separately. For example, the eighth-grade data file contains variables that identify children who have a disability diagnosed by a professional (P7DISABL) and those who live in households with incomes below the federal poverty threshold (W8POVRTY). With variables from earlier rounds of data collection, it is possible to identify children who participated in Head Start in the year prior to kindergarten (HSATTEND from the base year and P4HSBEFK asked of new respondents in spring-first grade) and language minority children (WKLANGST), as well as other subgroups. Users who wish to study a specific subpopulation should consult the ECLS-K composite variables (table [7][8][9][10][11][12][13][14][15] or the data collection instruments to identify variables that might help them identify their population of interest. Examining school and classroom effects. Examination of classroom effects is possible with kindergarten and first-grade data because child assessment data were collected at the start and end of each of these grades. When studying the effects of schools and classrooms, it is important to group the subject children in the same classroom and/or same school. Each type of respondent (child, parent, regular teacher, special education teacher, and school) has a unique ID number. These ID numbers can"}, {"section_title": "INTRODUCTION \u25ba", "text": "Please note that this manual will refer to student respondents in the eighth-grade round as \"children\" to be consistent with the terminology used in documentation from earlier rounds of the ECLS-K. This manual provides guidance and documentation for users of the eighth-grade data 2 of the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K). It begins with an overview of the ECLS-K study. Subsequent chapters provide details on the instruments and measures used, the sample design, weighting procedures, response rates, data collection and processing procedures, and the structure of the data file. The ECLS-K focuses on children's early school experiences beginning with kindergarten and ending with eighth grade. It is a multisource, multimethod study that includes interviews with parents, the collection of data from principals and teachers, and student records abstracts, as well as direct child assessments. In the eighth-grade data collection, a student paper-and-pencil questionnaire was added. The ECLS-K was developed under the sponsorship of the U.S. Department of Education, Institute of Education Sciences, National Center for Education Statistics (NCES). Westat conducted this study with assistance provided by Educational Testing Service (ETS) in Princeton, New Jersey. The ECLS-K followed a nationally representative cohort of children from kindergarten into middle school. The base-year data were collected in the fall and spring of the 1998-99 school year when the sampled children were in kindergarten. A total of 21,260 kindergartners throughout the nation participated. Two more waves of data were collected in the fall and spring of the 1999-2000 school year when most, but not all, of the base-year children were in first grade. 3 The fall-first grade data collection was limited to a 30 percent subsample of schools 4 (see exhibit . It was a design enhancement to enable researchers to measure the extent of summer learning loss and the factors that contribute to such loss and to better disentangle school and home effects on children's learning. The spring-first grade data 2 The term \"eighth grade\" is used throughout this document to refer to the data collections that took place in the 2006-07 school year, at which time most of the sampled children-but not all of them-were in eighth grade. 3 Though the majority of base-year children were in first grade during the 1999-2000 school year, about 5 percent of the sampled children were retained in kindergarten and a handful of others were in second grade during the 1999-2000 school year. 4 Approximately 27 percent of the base-year children who were eligible to participate in year 2 attended the 30 percent subsample of schools. 1-2 collection, which included the full sample, was part of the original study design and can be used to measure annual school progress and to describe the first-grade learning environment of children in the study. All children assessed during the base year were eligible to be assessed in the spring-first grade data collection regardless of whether they repeated kindergarten, were promoted to first grade, or were promoted to second grade. In addition, children who were not in kindergarten in the United States during the 1998-99 school year, and therefore did not have a chance to be selected to participate in the base year of the ECLS-K, were added to the spring-first grade sample. 5 Such children include immigrants to the United States who arrived after fall 1998 sampling, children living abroad during the 1998-99 school year, children who were in first grade in 1998-99 and repeated it in 1999-2000, and children who did not attend kindergarten. Their addition allows researchers to make estimates for all first-graders in the United States rather than just for those who attended kindergarten in the United States in the previous year. A fifth wave of data was collected in the spring of the 2001-02 school year when most, but not all, of the sampled children were in third grade. 6 In addition to the school, teacher, parent, and child assessment data collection components, children were asked to complete a short self-description questionnaire, which asked them how they thought and felt about themselves both academically and socially. The spring-third grade data collection can be used to measure school progress and to describe the third-grade learning environment of children in the study. Exhibit 1-1. ECLS-K waves of data collection: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 Data  1 Fall data collection consisted of a 30 percent sample of schools containing approximately 27 percent of the base-year children eligible to participate in year 2. 2 See description of freshened sample in text preceding exhibit 1-1. NOTE: See section 1.3 for a description of the study components. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), spring 2007. 5 Their addition is referred to as \"freshening\" the sample. See chapter 4, section 4.3.2 for more detail on the freshening process. 6 Approximately 89 percent of the children interviewed were in third grade during the 2001-02 school year, 9 percent were in second grade, and less than 1 percent were in fourth grade or higher."}, {"section_title": "1-3", "text": "A sixth wave of data was collected in the spring of the 2003-04 school year when most, but not all, of the sampled children were in fifth grade. 7 In addition to the data collection components used in third grade, children also were asked about their food consumption at school and other places (e.g., home, restaurants) in the week prior to the interview. The spring-fifth grade data collection can be used to measure school progress and to describe the fifth-grade learning environment of children in the study. A seventh wave of data was collected in the spring of the 2006-07 school year when most, but not all, of the sampled children were in eighth grade. 8 In addition to the data collection components used in fifth grade, children were asked to complete a paper-and-pencil questionnaire about their school experiences, their activities, their perceptions of themselves, and their weight, diet, and level of exercise. The spring-eighth grade data collection can be used to measure school progress and to describe the eighth-grade learning environment of children in the study. The sample of children in the eighth-grade round of data collection of the ECLS-K represents the cohort of children who were in kindergarten in 1998-99 or in first grade in 1999-2000. Since the sample was not freshened after the first-grade year with children who did not have a chance to be sampled in kindergarten or first grade (as was done in first grade), estimates from the ECLS-K eighthgrade data are representative of the population cohort rather than all eighth-graders in 2006-07. Comparisons of the weighted population of ECLS-K children enrolled in the eighth grade with the weighted population of eighth-graders reported in the 2006 Current Population Survey 9 suggest that the ECLS-K represents about 80 percent of all U.S. eighth-graders in the 2006-07 school year. 10 Some examples of subpopulations of eighth-graders who are not represented in the ECLS-K in 2006-07 include children who started kindergarten before fall of 1998 and were retained in a later grade, children who immigrated to the United States after first grade, and children who were home-schooled until after first grade. Data were collected from teachers and schools to provide important contextual information about the school environment for the sampled children, but the teachers and schools are not representative of eighth-grade teachers and schools in the country in 2006-07. For this reason, the only weights produced from the study for eighth-grade estimates are for making statements about children, including statements about the teachers and schools of those children. 7 Approximately 90 percent of the children interviewed were in fifth grade during the 2003-04 school year, 9 percent were in fourth grade, and less than 1 percent were in some other grade (e.g., second, third, or sixth grade). 8 Approximately 89 percent of the children interviewed were in eighth grade during the 2006-07 school year, 9 percent were in seventh grade, and less than 2 percent were in some other grade (e.g., such as fifth, sixth, or ninth grade). 9 The Current Population Survey is the monthly survey of households conducted by the Bureau of the Census for the Bureau of Labor Statistics of the U.S. Department of Labor (see http://www.bls.gov/cps/). 10 The estimate of the percent of eighth-graders captured by the ECLS-K was calculated by dividing the sum of the child weight (C7CW0) by the number of eighth-graders according to the 2006 Current Population Survey."}, {"section_title": "1-4", "text": "The ECLS-K has several major objectives and numerous potential applications. The ECLS-K combines (1) a study of achievement in the elementary and middle school years; (2) an assessment of the developmental status of children in the United States at the start of their formal schooling and at key points during elementary and middle school; 3cross-sectional studies of the nature and quality of kindergarten programs in the United States; and (4) a study of the relationship of family, preschool, and school experiences to children's developmental status at school entry and their progress during kindergarten, elementary school, and middle school. The ECLS-K has both descriptive and analytic purposes. It provides descriptive data on children's status at school entry, their transition into school, and their progress into middle school. The ECLS-K also provides a rich dataset that enables researchers to analyze how a wide range of family, school, community, and individual variables affect children's early success in school; to explore school readiness and the relationship between the kindergarten experience and middle school performance; and to record children's academic growth as they move into middle school. The ECLS-K is part of a longitudinal studies program comprising two cohorts-a kindergarten cohort and a birth cohort. The birth cohort (ECLS-B) is following a national sample of children born in the year 2001 from birth to kindergarten. The ECLS-B examines how early learning environments are associated with early cognitive, physical, and socioemotional development and thus prepare children for kindergarten success. Together these cohorts will provide the depth and breadth of data required to more fully describe and understand children's early learning, development, and education experiences."}, {"section_title": "Background", "text": "Efforts to expand and improve early education will benefit from insights gained through analyses of data from the large-scale, nationally representative ECLS-K data and the study's longitudinal design. The ECLS-K database contains information about the types of school programs in which children participate, the services they receive, and repeated measures of the children's cognitive skills and knowledge. The ECLS-K database also contains measures of children's physical health and growth, social development, and emotional well-being, along with information on family background and the educational quality of their home environments."}, {"section_title": "1-5", "text": "As a study of early achievement, the ECLS-K allows researchers to examine how children's progress is associated with such factors as placement in high or low ability groups, receipt of special services or remedial instruction, grade retention, and frequent changes in schools attended because of family moves. Data on these early school experiences were collected as they occurred, with the exception of their experiences before kindergarten, which were collected retrospectively. Collecting this information as the experiences occurred produces a more accurate measurement of antecedent factors and enables inferences to be made about their relationship to later academic progress. The longitudinal nature of the study enables researchers to study children's cognitive, social, and emotional growth and to relate trajectories of change to variations in children's experiences in kindergarten and the early to later grades. The spring-eighth grade data collection can be used to describe the diversity of the children in the study and the classrooms and schools they attended. It can also be used to study children's academic gains in the years following kindergarten. The ECLS-K sample includes substantial numbers of children from various minority groups. Thus, the ECLS-K data present many possibilities for studying cultural and ethnic differences in the educational preferences, home learning practices, and school involvement of families; the developmental patterns and learning styles of children; and the educational resources and opportunities that different groups are afforded in the United States."}, {"section_title": "Conceptual Model", "text": "The design of the ECLS-K was guided by a framework of children's development and schooling that emphasizes the interrelationships between the child and family; the child and school; the family and school; and the family, school, and community. The ECLS-K recognizes the importance of factors that represent the child's health status and socioemotional and intellectual development and incorporates factors from the child's family, community, and school-classroom environments. The conceptual model is presented in exhibit 1-2. The study paid particular attention to the role that parents and families played in helping children adjust to formal school and in supporting their education through the elementary and middle school grades. It also gathered information on how schools prepare for and respond to the diverse backgrounds and experiences of the children and families they serve. 1-7 about children's development at school entry and their experiences both with family members and with others. Information was collected from parents/guardians in each round of data collection. Teachers, like parents, represented a valuable source of information on themselves, the children in their classrooms, and the children's learning environment (i.e., the classroom). Teachers were not only asked to provide information about their own backgrounds, teaching practices, and experience; they were also called on to provide information on the classroom setting for the sampled children they taught and to evaluate each sampled child on a number of critical cognitive and noncognitive dimensions. Special education teachers and service providers of sampled children with disabilities were also asked to provide information on the nature and types of services provided to the child. With the exception of the fall-first grade data collection, teachers completed self-administered questionnaires each time children were assessed. School administrators, or their designees, were asked to provide information on the physical, organizational, and fiscal characteristics of their schools, and on the schools' learning environment and programs. Special attention was paid to the instructional philosophy of the school and its expectations for children. School administrators or their designees were also asked to provide basic information about the school grade level, school type (public or private), length of school year, and attendance recordkeeping practices. Prior to the third-grade data collection, the questions had been part of the school administrator questionnaire. These items were collected in a separate school fact sheet in third grade but were reintegrated into the school administrator questionnaire in the fifth-and eighth-grade data collections. Information was collected from school administrators via self-administered questionnaires during each spring data collection."}, {"section_title": "ECLS-K Data Files", "text": "The ECLS-K data are released in restricted-use and public-use versions. A brief overview of the differences between the restricted-use and public-use data files is provided here, followed by a description of the data files that are currently available."}, {"section_title": "Differences Between ECLS-K Restricted-Use and Public-Use Files", "text": "In preparing public-use data files, NCES takes steps to minimize the likelihood that an individual school, teacher, parent, or child participating in the study can be identified. Every effort is made to protect the identity of individual respondents. This is in compliance with the Privacy Act of 1974, as amended, the E-Government Act of 2002, the Education Sciences Reform Act of 2002, and the 1-8 USA Patriot Act of 2001, which mandate the protection of confidentiality of NCES data that contain individually identifiable information. The process begins with a formal disclosure risk analysis. Variables identified as posing the greatest disclosure risk are altered (e.g., by combining categories), and in some instances, entirely suppressed. The following data modifications account for the differences between public-use and restricted-use data files: Outlier values are top-or bottom-coded; 11 Individual cases for which a particular variable poses an especially high risk of disclosure have the value of that variable altered (usually by no more than 5 to 10 percent for continuous variables) to reduce the risk; Some continuous variables are modified into categorical variables, and categories of certain categorical variables are collapsed; A small number of variables with too few cases and a sparse distribution are suppressed altogether, rather than modified; and A small number of variables are further masked to enhance confidentiality. After modifying individual records that have the greatest risk of disclosure, the disclosure risk analysis is repeated to verify that the risk of disclosure has been reduced to acceptable levels. The 11 To understand top-and bottom-coding, consider a fictitious variable with the following frequency distribution:  [1][2][3][4][5][6][7][8][9] modifications that are implemented to avoid identification of schools, teachers, parents, and children do not affect the overall data quality, and most researchers should be able to find all that they need in the public-use data files. While very few of the variables are suppressed, some users might require the restricted-use data files. Researchers examining certain rare subpopulations, such as children with disabilities, or children with specific non-English home languages or countries of birth, for example, will find that the restricted-use data files contain a few more variables with a wider range of data values. However, in many instances, even though the detailed information on the restricted-use data files may be of interest, the sample sizes will be too small to support these analyses. NCES recommends that researchers who are uncertain of which data release to use first examine the public-use data files to ascertain whether their specific analytic objectives can be met using those data files."}, {"section_title": "Overview of Available Data Files", "text": "Several ECLS-K data files are available for use by analysts. These are described below beginning with the eighth-grade data files."}, {"section_title": "ECLS-K Eighth-Grade", "text": "Restricted-Use Data File. The eighth-grade data are available only as a child-level data file. The file includes all data collected from or about the children and their schools including data from the child assessments and the student, parent, teacher, and school administrator questionnaires. No eighth-grade teacher or school files are released because the sample of teachers and schools is not nationally representative of eighth-grade teachers or schools with eighth grades. Analysts who wish to examine children's experiences in eighth grade and the influence of their classroom or school characteristics on their eighth-grade experiences should use the eighth-grade restricted-use file or the K-8 full sample public-use file described below. The eighth-grade data file can be used not only to analyze data collected in the eighth grade but also to provide weights and variables that can be used in longitudinal data analysis of kindergarten, first, third, fifth, and eighth grades. In addition to the crosssectional weights, cross-year (kindergarten-eighth grade) weights have been added to the eighth-grade data file for those analysts who wish to examine children's learning across school years (see chapter 9). Instructions on how to create a longitudinal file using the base-year, first-grade, third-grade, fifth-grade, and eighth-grade restricteduse data are provided in chapter 9. A public-use data file, however, is available that combines the base-year, first-grade, third-grade, fifth-grade, and eighth-grade publicly released data (see next bullet). Most analysts will find it more convenient to use the already created full sample file described below."}, {"section_title": "1-10", "text": "Kindergarten-Eighth Grade Full Sample Public-Use Data File. This public-use data file combines data from the base, first-, third-, fifth-, and eighth-grade years. It contains both within-year and cross-year weights so that analysts can examine children's growth and development between kindergarten and eighth grade. Unlike the public-use longitudinal files released in previous rounds, this file contains all data for all ECLS-K sample cases that have been publicly released in any of the rounds. Thus, it can be used for within-year (cross-sectional) analyses of any round of data collection and cross-year (longitudinal) analyses of combinations of rounds. See chapter 10 for details on how to use the K-8 full sample public-use file."}, {"section_title": "ECLS-K Fifth-Grade", "text": "Restricted-and Public-Use Data Files. The fifth-grade data are available only as child-level data files. The files include all data collected from or about the children and their schools including data from the child assessments and from their parents, teachers, or schools. No fifth-grade teacher or school files were released because the sample of teachers and schools is not nationally representative of fifth-grade teachers and schools with fifth grades. Analysts who wish to examine children's experiences in fifth grade and the influence of their classroom or school characteristics on their fifth-grade experiences should use the fifth-grade data file or the K-8 full sample public-use data file. The fifth-grade data file can be used not only to analyze data collected in the fifth grade but also to provide weights and variables that can be used in longitudinal data analysis of kindergarten, first, third, and fifth grades. In addition to the cross-sectional weights, cross-year (kindergarten-fifth grade) weights were included in the fifth-grade data file for those analysts who wish to examine children's learning across school years. Instructions on how to create a longitudinal file using the base-year, first-grade, third-grade, and fifth-grade data are provided in chapter 9. However, most analysts will find it more convenient to use the already created K-8 full sample public-use data file described above. For more information on these files, refer to the ECLS-K Combined User's Manual for the ECLS-K Fifth-Grade Data Files and Electronic Codebooks (NCES 2006-032) (Tourangeau et al. 2006). Longitudinal Kindergarten-Fifth Grade (K-Fifth Grade) Public-Use Data File. This public-use data file combines data from the base, first-, third-, and fifth-grade years. This file is now superseded by the K-8 full sample public-use data file."}, {"section_title": "ECLS-K Third-Grade", "text": "Restricted-and Public-Use Data Files. The third-grade data are available only as child-level data files. The files include all data collected from or about the children and their schools including data from the child assessments and from their parents, teachers, and schools. No third-grade teacher or school files were released because the sample of teachers and schools is not nationally representative of third-grade teachers or schools with third grades. Analysts who wish to examine children's experiences in third grade and the influence of their classroom or school characteristics on their third-grade experiences should use the third-grade data file or the K-8 full sample public-use data file. The third-grade data file can be used not only to analyze data collected in the third grade but also to provide weights and variables that can be used in longitudinal data analysis of kindergarten, first grade, and third grade. In addition to the cross-sectional 1-11 weights, cross-year (kindergarten-third grade) weights were included in the thirdgrade data file for those analysts who wish to examine children's learning across school years. Instructions on how to create a longitudinal file using the base-year, first-grade, and third-grade data are provided in chapter 9. However, most analysts will find it more convenient to use the already created K-8 full sample public-use data file described above. For more information on these files, refer to the ECLS-K User's Manual for the ECLS-K Third Grade Public-Use Data File and Electronic Code Book (NCES 2004-001)  . Longitudinal Kindergarten-Third Grade (K-Third Grade) Public-Use Data File. This public-use data file combines data from the base, first-grade, and third-grade years. This file is now superseded by the K-8 full sample public-use data file ECLS-K First-Grade Restricted-and Public-Use Data Files. The first-grade data (fall and spring) are available only as child-level data files. The files include all data collected from or about the children and their schools including data from the child assessments and from their parents, teacher, and schools. Although these data are freshened to be representative of first-graders in the U. S. in 1999-2000, no first-grade teacher or school files are released because the sample of teachers and schools is not nationally representative of first-grade teachers or schools with first grades. Analysts who wish to examine children's experiences in first grade and the influence of their classroom or school characteristics on their first-grade experiences should use the first-grade data file or the K-8 full sample public-use data file. The first-grade data file can be used not only to analyze data collected in the first grade but also to provide weights and variables that can be used in longitudinal data analysis of both kindergarten and first grade. In addition to the cross-sectional weights, cross-year (kindergarten-first grade) weights have been added to the firstgrade data file for those analysts who wish to examine children's learning across school years. However, most analysts will find it more convenient to use the alreadycreated K-8 full sample public-use data file described above. For more information on these files, refer to the ECLS-K User's Manual for the ECLS-K First Grade Public-Use Data Files and Electronic Codebook (NCES 2002-135) (Tourangeau et al. 2002). Longitudinal Kindergarten-First Grade (K-First Grade) Public-Use Data File. This public-use data file combines data from the base and first-grade years. This file has now been superseded by the K-8 full sample public-use data file. ECLS-K Base-Year Data Files. There are three main and four supplementary data files available for the base year. The three main data files are the child-level data file, the teacher-level data file, and the school-level data file. The supplementary files are the teacher salary and benefits file, the special education file, the student records abstract file, and the Head Start Verification Study file. The child file data contains all the data collected from or about the children, including data from the child assessments, and from their teachers, parents, and schools. Analysts who wish to obtain descriptive information about U.S. kindergarten children or their families, or who want to examine relationships involving children and families, children and teachers, or children and schools, should make use of the child 1-12 data file or the K-8 full sample public-use data file. Analysts wishing to obtain descriptive information about the population of kindergarten teachers in the United States, or to study relationships involving teachers as the principal focus of attention, should use the teacher data file. Analysts who want to obtain descriptive information about public and private schools that contain kindergarten classes, or who want to examine relationships among school characteristics, should make use of the school data file. These child-, teacher-, and school-level data files are available in public-use and restricted-use versions. For more information on these files, refer to the ECLS-K Base Year Public-Use Data Files and Electronic Codebook: User's Manual (NCES 2001-029rev) (Tourangeau, Burke et al. 2004). The Salary and Benefits File is at the school level and contains information on the base salary, merit pay, and benefit pay of teachers and principals. The salary and benefits data, when combined with other ECLS-K data, can be used to examine, for example, the relationship between child outcomes and school resource allocation and use. This file is only available as a restricted-use file. For more information about this file, see the ECLS-K Base Year Restricted-Use Salary and Benefits File (NCES 2001-014) (Tourangeau et al. 2001b). The Special Education File is a child-based data file that contains information on 784 children identified as receiving special education or related services in kindergarten. Special education teachers were asked to complete two questionnaires designed to collect information about their professional background and experience and about the nature of the special education program and special education services provided to each of the sampled children receiving services. It is only available as a restricted-use file. For more information about this file, see the ECLS-K Base Year Restricted-Use Special Education Child File (NCES 2001-015) (Tourangeau et al. 2001c). The Student Records Abstract File contains information from school records about children's school enrollment and attendance; Individualized Education Program (IEP) and disability status; and home and school language. The student records abstract form was completed by school staff after the end of the school year. This data file is useful in providing additional predictors and correlates of children's transitions to kindergarten and later progress in school. This file is only available as a restricted-use data file. For more information about this file, see the ECLS-K Base Year Restricted-Use Student Record Abstract File (NCES 2001-016) (Tourangeau et al. 2001d). The Head Start Verification File contains information from Head Start program providers. The purpose of the Head Start Verification Study was twofold: (1) to identify which of the children reported by either their parents or their schools as having attended Head Start the year prior to kindergarten did indeed attend a Head Start program and (2) to evaluate the process of identifying Head Start participation through parent and school reports and provide further information on the actual process of verifying these reports. This file is a restricted-use data file. For more information about this file, see the ECLS-K Base Year Restricted-Use Head Start File (NCES 2001-025) (Tourangeau et al. 2001a). The outcomes of the verification process are also included as data items on the ECLS-K first-grade and kindergartenfirst grade longitudinal files."}, {"section_title": "1-13", "text": "The Census Data and Geocoded Location File contains census tract and ZIP Code tabulation area (ZCTA) codes for ECLS-K children's homes and schools for each round of the ECLS-K up to third grade. It also has about 600 census variables (or census-derived variables) for each census tract and ZCTA including income, race/ethnicity, and many other sociodemographic characteristics. Supporting documentation included on the CD consists of a user's manual, data file record layouts describing the variables on each of the ASCII data files, and SAS code for converting the data files. This file is a restricted-use data file available upon request from the Institute of Education Sciences Security Data Officer."}, {"section_title": "Contents of Manual", "text": "This manual provides documentation for users of the eighth-grade data files (the eighthgrade restricted-use data file and the K-8 full sample public-use data file) of the ECLS-K. Prior to fifth grade, separate manuals were issued for each data file. Please refer to the previous chapter, Getting Started, for a summary of which sections of the manual do not apply to both files and for an overview of the major differences between the eighth-grade round of data collection and previous rounds. The manual contains information about the data collection instruments (chapter 2) and the psychometric properties of these instruments (chapter 3). It describes the ECLS-K sample design and weighting procedures (chapter 4); data collection procedures and response rates (chapter 5); and data processing procedures (chapter 6). In addition, this manual shows the structure of the eighth-grade data file and provides definitions of composite variables (chapter 7); describes how to install and use the Electronic Codebook (chapter 8); and describes how to use and merge the base-year, first-grade, thirdgrade, fifth-grade, and eighth-grade files (chapter 9). Finally, chapter 10 presents information on the kindergarten-eighth grade full sample public-use data file. The Electronic Codebook contains unweighted frequencies for all variables. Because this manual focuses on the eighth-grade data collection, minimal information is provided about the base-year, first-grade, third-grade, or fifth-grade data. Users who wish to learn more about these data collections should refer to the ECLS-K Base Year Public-Use Data Files and Electronic Codebook: User's Manual (NCES 2001-029rev) (Tourangeau, Burke et al. 2004); the User's Manual for the ECLS-K First Grade Public-Use Data Files and Electronic Codebook (NCES 2002-135) (Tourangeau et al. 2002), the User's Manual for the ECLS-K Third Grade Public-Use Data File and Electronic Code Book (NCES 2004-001)  , or the Combined User's Manual for the ECLS-K Fifth-Grade Data Files and Electronic Codebooks (NCES 2006-032) (Tourangeau et al. 2006). Additional information about the ECLS program can be found on the World Wide Web at http://nces.ed.gov/ecls. This page is intentionally left blank. 2-1"}, {"section_title": "DESCRIPTION OF DATA COLLECTION INSTRUMENTS", "text": "This chapter describes the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K) eighth-grade data collection instruments. The ECLS-K eighth-grade data collection instruments consisted of eight questionnaires (student, parent, teacher, special education teacher/service, and school administrator), three achievement tests (reading, mathematics, and science), and one physical measurement record form. The eighth-grade data collection instruments, with the exception of the assessments and the items adapted from the Self Description Questionnaire II (Marsh 1992) 12 in the student questionnaire, are available on the ECLS-K DVD and CD-ROM as appendix A. The assessments and Self Description Questionnaire II items contain copyright-protected materials. For information on the data collection instruments used in any of the past rounds of the ECLS-K, please refer to chapter 2 of the ECLS-K base-year, first-grade, third-grade, fifth-grade, and eighth-grade user's manuals. These can be found on the Web at http://nces.ed.gov/pubsearch."}, {"section_title": "Child Assessments and Questionnaire", "text": "The child assessments were paper-and-pencil assessments administered in small group settings timed and proctored by a trained test administrator in the spring of the 2006-07 school year. Children were assessed with the same assessment regardless of whether they were on grade level (i.e., in eighth grade). As in the previous rounds, the eighth-grade assessments included cognitive and physical (i.e., height and weight) components. In addition, a self-administered student questionnaire was completed during the eighth-grade assessment session. This included an adaptation of the Self Description Questionnaire (SDQ) II (Marsh 1992b)  out of school and their relationships with their friends and parents. Items about children's food consumption were included in the \"Your Diet\" section, with questions about the kinds of food they could 12 The student questionnaire used items adapted with permission from the Self Description Questionnaire (SDQ) II (Marsh, 1992)."}, {"section_title": "2-2", "text": "buy at school and the food that they had eaten in the past week. The entire assessment session was 2 hours in duration. Chapter 3 contains a detailed description of the assessment scores and information on their use and interpretation."}, {"section_title": "Cognitive Assessments", "text": "The ECLS-K eighth-grade direct cognitive assessment battery was designed to assess children's academic achievement in spring of eighth grade, and to provide a means of measuring academic growth since kindergarten entry. A panel of child development, middle school education, and content area experts recommended that the knowledge and skills assessed by the ECLS-K eighth-grade assessments should represent the typical and important academic goals of middle school curricula in English, mathematics, and science. Reading, mathematics, and science were the three cognitive domains assessed in the eighth grade. While the direct cognitive assessments were individually administered at all six previous time points, in spring-eighth grade, groups of ECLS-K sampled children who attended the same school were assessed in a single, proctored group administration. All children were given separate routing assessment forms to determine the level (high/low) of their reading, mathematics, and science assessments. The two-stage cognitive assessment approach was used to maximize the accuracy of measurement and reduce administration time by using the child's responses from a brief first-stage routing form to select the appropriate second-stage level form. 13 For the reading, mathematics, and science routing forms, children read items in a booklet and recorded their responses on an answer form. These answer forms were then scored by the test administrator. Based on the score of the respective routing forms, the test administrator then assigned a high or low second-stage level form of the reading, mathematics, and science assessments. For the second-stage level tests, children read items in the assessment booklet and recorded their responses in the same assessment booklet. The routing tests and the second-stage level tests were timed and took 80 minutes to complete. 13 For additional detail on the eighth-grade cognitive assessments, see the ECLS-K Psychometric Report for the Eighth Grade (NCES 2008-069) (Najarian, Pollack, and Sorongon forthcoming)."}, {"section_title": "2-3", "text": "Accommodations that did not significantly affect the assessment were provided to those children whose Individualized Education Programs (IEPs) required accommodations for assessments. These included allowing for additional time or the presence of a health care aide. Children were excluded from the direct assessment if they had a disability (e.g., blindness or deafness) that could not be accommodated by the ECLS-K direct assessment, if their IEP prevented their participation in assessments, or they required an accommodation not offered by the ECLS-K assessments. Chapter 5, section 5.5.2 has more information on accommodations and exclusions in the ECLS-K. In order to measure growth across time, a longitudinal scale is needed. Therefore, the cognitive assessments were designed to have overlapping items, i.e., items that were included in at least two rounds of data collection. Assessment items in each of the content domains were drawn from assessments used in other large-scale studies of similar-aged youth, such as the National Assessment of Educational Progress (NAEP), the National Education Longitudinal Study of 1988 (NELS:88), and the Education Longitudinal Study of 2002(ELS:2002, the Texas Assessment of Knowledge and Skills (TAKS), as well as previous rounds of the ECLS-K. Items were chosen to extend the longitudinal scales initiated in kindergarten, first grade, third grade, and fifth grade, but were grade-appropriate in terms of content and format. Items were reviewed by content area specialists for appropriateness of content and difficulty, and for relevance to the assessment framework. In addition, items were reviewed for issues related to sensitivity to minorities. Items that passed these content, construct, and sensitivity screenings were field tested in the spring of 2006. For additional detail on the selection of items for the eighth-grade cognitive assessments, see the ECLS-K Psychometric Report for the Eighth Grade (NCES 2009-002) (Najarian, Pollack, and Sorongon forthcoming). Reading. The eighth-grade reading assessment focused on four aspects of reading comprehension skills including forming a general understanding of the text, developing a more complete understanding of what was read, making connections from the text with personal background knowledge, and critically evaluating, comparing and contrasting, and understanding the effect of literary devices or the author's intentions. The kindergarten through eighth-grade proficiency levels included (1) Letter Knowledgeidentifying upper-and lower-case letters of the alphabet by name; (2) Beginning Sounds-associating letters with sounds at the beginning of words; (3) Ending Sounds-associating letters with sounds at the end of words; (4) Sight Words-recognizing common \"sight\" words; (5) Words in Context-reading words in context; (6) Literal Inference-making inferences using cues that were directly stated with key 2-4 words in text; 7Extrapolation-identifying clues used to make inferences; (8) Evaluationdemonstrating understanding of author's craft and making connections between a problem in the narrative and similar life problems; (9) Evaluating Nonfiction-comprehension of biographical and expository text; and 10Evaluating Complex Syntax-evaluating complex syntax and understanding high-level vocabulary. Mathematics. The eighth-grade mathematics assessments addressed the following content strands: number sense, properties, and operations; measurement; geometry and spatial sense; data analysis, statistics, and probability; and pattern, algebra, and functions. The cognitive processes (conceptual, procedural, and problem solving) were assessed in each of the strands. Some of the items drew upon knowledge from more than one strand. For example, an item might require that a child apply knowledge about geometry, measurement, and number operations to answer the question correctly. The kindergarten through eighth-grade mathematics proficiency levels include (1) Numberand Shape-identifying some one-digit numerals, recognizing geometric shapes, and one-to-one counting up to 10 objects; (2) Relative Size-reading all one-digit numerals, counting beyond 10, recognizing a sequence of patterns, and using nonstandard units of length to compare the size of objects; (3) Ordinalityand Sequence-reading two-digit numerals, recognizing the next number in a sequence, identifying the ordinal position of an object, and solving a simple word problem; (4) Addition and Subtraction-solving simple addition and subtraction problems; (5) Multiplication and Division-solving simple multiplication and division problems and recognizing more complex number patterns; (6) Place Value-demonstrating understanding of place value in integers to hundreds' place; (7) Rate and Measurement-using knowledge of measurement and rate to solve word problems; (8) Fractions-solving problems using fractions; and (9) Area and Volume-solving word problems involving area and volume. No new mathematics proficiency level was added at the eighth grade because it was not warranted. Previously defined proficiency levels were sufficiently \"difficult\" to allow for the demonstration of growth in the higher proficiency levels at eighth grade. Science. In the eighth-grade assessment, equal emphasis was placed on life science, earth and space science, and physical science. Similar to the third-and fifth-grade science assessments, children needed to demonstrate understanding of the physical and natural world, draw inferences, and comprehend relationships. In addition, they needed to interpret scientific data, formulate hypotheses, and identify the best plan to investigate a given question. As with the third-and fifth-grade science assessments, no set of proficiency levels was developed. The subject matter content of the science assessment domain was too 2-5 diverse and the items insufficiently ranked or graded to permit the formation of a set of proficiency levels. Instead, a single score was calculated to represent each child's breadth and depth of understanding and knowledge of the world. For additional detail on the development of the eighth-grade cognitive assessments, see the ECLS-K Psychometric Report for the Eighth Grade (NCES 2009-002) (Najarian, Pollack, and Sorongon. forthcoming)."}, {"section_title": "Student Questionnaire", "text": "Children completed the student questionnaire after completing the routing test. The student questionnaire was timed, and children had 20 minutes to complete the questionnaire. They entered their responses to each item into the student questionnaire booklet. Topics covered by the student questionnaire included the following: school experiences-school safety, importance of grades, time spent on homework, peer relationships; activities-participation in school-sponsored and out-of-school activities; social-emotional development-how children thought and felt about themselves both academically and socially; weight and exercise-level of exercise per week, participation in physical education classes; and diet-what kinds of food they could buy at school and the food they had eaten in the past week. The student questionnaire included two scales to measure their socioemotional development. The first was the self-description questionnaire (SDQ), which was used to determine how children thought and felt about themselves both academically and socially. Children rated their perceived competence and interest in reading and mathematics. They also reported on internalizing problem behaviors with which they might struggle. The Internalizing Problems scale included items on sadness, loneliness, and anxiety."}, {"section_title": "2-6", "text": "The SDQ consists of 16 statements. Children rated whether each item was \"not at all true,\" \"a little bit true,\" \"mostly true,\" or \"very true.\" Three subscales were produced from the SDQ items. The scale scores on all SDQ scales represent the mean rating of the items included in the scale. The SDQ Perceived Interest/Competence-Reading subscale includes four items on grades in English and the child's interest in and enjoyment of reading. The SDQ Perceived Interest/Competence-Math subscale includes four items on mathematics grades and the child's interest in and enjoyment of mathematics. The SDQ Internalizing Behavior subscale includes eight items on internalizing problem behaviors such as feeling \"sad a lot of the time,\" feeling lonely, feeling ashamed of mistakes, feeling frustrated, and worrying about school and friendships. The items on the first two subscales of the ECLS-K SDQ were adapted with permission from the Self Description Questionnaire (SDQ) II (Marsh 1992b). The items in the internalizing problem behavior subscale were developed specifically for the ECLS-K and used in the third-and fifth-grade rounds. The second set of scales consisted of the Self-Concept and Locus of Control scales adapted from the National Education Longitudinal Study of 1988 (NELS:88). The Self-Concept scale comes from the Rosenberg Self-Esteem Scale (RSE) (Rosenberg 1965). These scales asked children about their perceptions about themselves and the amount of control they had of their own lives. Items were drawn from the NELS:88 student questionnaire and asked children to indicate the degree to which they agreed with 13 statements about themselves. They chose from the following responses: \"strongly agree,\" \"agree,\" \"disagree,\" or \"strongly disagree\" for each item. As noted earlier, to measure children's food consumption, the student questionnaire included 19 items that asked them about the kinds of food they could buy at school and the food they had eaten in the past week. The first set of questions was about foods that are high in fat, sodium, and/or added sugars (e.g., candy, salty snacks, soft drinks). Children were asked if they could buy these foods at school, and, if so, how often they bought the food in the past week and where they bought the food (vending machine, cafeteria, or somewhere else in school). In the second set of questions, children were asked about whether they ate particular key foods and beverages in the past 7 days, such as milk, sweetened beverages (e.g., soft drinks), fruits and vegetables, and fast food. They were asked to include food they ate at home, at school, at restaurants, or anywhere else."}, {"section_title": "2-7", "text": "The eighth-grade food consumption items were the same as those used at the fifth-grade round. Items tapping food consumption were taken mainly from existing surveys, although some were developed for the ECLS-K. Two main sources for questions were two surveys by the Centers for Disease "}, {"section_title": "Physical Components", "text": "Anthropometric data were collected in all seven rounds of the ECLS-K. The anthropometric data consisted of recording the children's height (in inches to the nearest quarter-inch) and weight (in pounds to the nearest half-pound) to measure their physical growth and development. The Shorr Board vertical stadiometer and a Seca digital scale were used to obtain standing height and weight measurements, which were recorded on a height and weight recording form. Height and weight were measured twice for each child and took approximately 2 minutes to complete. For additional detail on the procedures used to collect height and weight, see the ECLS-K Eighth-Grade Methodology Report (NCES 2009-003) (Tourangeau et al. forthcoming)."}, {"section_title": "Parent Interview", "text": "The eighth-grade parent interview was conducted using a computer-assisted interview (CAI). The parent interview was conducted primarily in English, but provisions were made to interview parents who spoke other languages with bilingual English-Spanish interviewers or interpreters for other languages. Most of the interviews were conducted by telephone, but a small percentage (2.2 percent) were conducted in person. Data collection for the eighth-grade parent interview started in fall 2006. The parent interview lasted on average 46 minutes and contained approximately 300 questions concerning eighth- 14 Information on these CDC surveys is available at http://www.cdc.gov/HealthyYouth/."}, {"section_title": "2-8", "text": "grade school experiences, parent characteristics, and child health. Topics covered in the eighth-grade parent interview included the following: parent involvement in school activities; family structure-demographics, household roster, marital status; home environment and cognitive stimulation-frequency of literacy activities, computer use, television viewing, homework, family routines; child's schooling; critical family processes, such as marital satisfaction and religiosity; parent/child interaction-parent discipline; nonresident parent-contact with child, school involvement, and child support; primary language spoken in home; child's health and well-being-physical functioning, parent ratings of child's strengths and difficulties, 15 services for children with special needs, receipt of prescription for attention and/or hyperactivity disorders, family therapy; parent health and emotional well-being; parental educational expectations for the child; parent education; parent employment; welfare and other public assistance use; food security; and parent income and assets. The order of preference for the respondent to the parent interview was the same as in previous rounds: (1) the respondent from the previous round (if there was one), (2) the child's mother, another parent or guardian, or (4) some other adult household member. In a majority of the cases in the eighth-grade data collection (94 percent), the eighth-grade parent respondent was the same as the 15 These parent interview items (CHQ.900) are from the Strengths and Difficulties Questionnaire (ages 11 -17) copyrighted by Dr. Robert Goodman, Ph. D., of the Psychiatric Institute of London, England. Agencies may use these questions without charge or permission providing the wording is not modified, all questions are retained, and copyright is acknowledged. More information can be found at http://www.sdqinfo.com/ or Appendix V in http://www.cdc.gov/nchs/data/nhis/srvydesc.pdf."}, {"section_title": "2-9", "text": "respondent from the previous round. The child's mother was the respondent in 88 percent of the cases and the child's father in 9 percent. Other adults completed the parent interview in 3 percent of the cases (typically grandparents of the sampled child)."}, {"section_title": "General Education Teacher Questionnaires", "text": "During the spring-eighth grade data collection, one teacher-level background and three child-level subject matter (i.e., English, mathematics, and science) questionnaires were used to collect data from the sampled children's teachers. The self-administered teacher-level background questionnaire covered a variety of topics, including views on teaching and the school, teacher demographic information, teaching experiences, and education and certification information. The English, mathematics, and science teacher questionnaires were each organized in the same manner. Each questionnaire was divided into three sections. The first section included questions that collected data on the child's social skills, class performance, and his or her skills in relevant areas. The English teacher questionnaire asked about the child's skills in written and oral expression. The mathematics teacher questionnaire asked about the child's skills in mathematics, such as problem solving and demonstrating mathematical reasoning. The science teacher questionnaire asked about the child's skills in science, such as designing an experiment to solve a scientific question and writing up and preparing a presentation of scientific data. The second section included questions about characteristics of the children in the classroom. The third section included questions about the instructional practices in the classroom, such as specific instructional activities and curricular focus, and assigned books and textbooks. In this last section, the items specified activities and practices that were relevant to the subject domain (i.e., English, mathematics, or science). Two subject-matter questionnaires were completed for each sampled child. Therefore, data were gathered on each sampled child's skills in the areas of English and mathematics, or in the areas of English and science."}, {"section_title": "2-10", "text": "Topics covered in the spring-eighth grade teacher questionnaires included the following: children's domain-relevant skills (i.e., written and oral expression, science, and mathematics skills); and children's behavior and performance in class. In the first five rounds of data collection, each sampled child's regular classroom teacher (i.e., the teacher who taught the child for the majority of the day) completed the teacher questionnaires. In spring-fifth grade, each sampled child's reading teacher and either a mathematics or science teacher completed questionnaires. This latter approach was also used in spring-eighth grade, in which each sampled child's English teacher and either a mathematics or science teacher completed questionnaires. In some schools, the sampled children were taught reading, mathematics, and science by the same teacher in one classroom. In other schools, different teachers taught these subjects to the sampled children. Each child's selected teacher(s) received a self-administered teacher-level background questionnaire. In addition to the teacher-level questionnaire, each teacher received at least one of the three child-level questionnaires (English, mathematics, or science, based on the subject(s) they taught) specifically about the focal child. All children were assigned to have an English teacher complete questionnaires. In fifth grade, half of the children were randomly assigned to have a mathematics teacher complete questionnaires, and the other half of the children were assigned to have a science teacher complete questionnaires. This assignment made for the mathematics or science teacher questionnaire in 2-11 fifth grade was carried forward in eighth grade so that the same children who had a mathematics teacher questionnaire in fifth grade would have a mathematics teacher questionnaire in eighth grade, and those with a science teacher questionnaire in fifth grade would have a science teacher questionnaire in eighth grade. In cases where the same eighth-grade teacher taught the sampled child English, mathematics, and science, the teacher was asked to complete an English questionnaire and either a mathematics or science questionnaire, depending upon the domain for which the child was sampled."}, {"section_title": "Special Education Teacher Questionnaires", "text": "In the spring-eighth-grade data collection, field supervisors asked the school coordinators to identify the ECLS-K children receiving special education services and the names of their special education service providers. The supervisor then listed special education staff working with each child (e.g., speech pathologists, reading instructors, and audiologists). Field supervisors determined the primary service provider of children receiving special education services from multiple service providers. The primary special education teacher/service provider was defined as follows: the teacher who managed the child's IEP; the teacher who spent the greatest amount of time providing special education services to the child; or the teacher who was most knowledgeable about the child's special needs and use of assistive technologies. Special education teachers of children in the ECLS-K were asked to complete two questionnaires. The questionnaires addressed topics such as the child's disability, IEP goals, the amount and type of services used by sampled children, and communication with parents and general education teachers. Part A of the special education teacher questionnaire was designed to collect information about the special education teacher's professional background and experience, including the following: when the child first had the IEP; likelihood that the child would have an IEP next school year; percentage of IEP goals that were met during this school year; and receipt of special education or related services because of attention deficit/ hyperactivity disorder. The special education teacher was asked to complete part B for each sampled child for whom he or she was the primary service provider."}, {"section_title": "2-13", "text": ""}, {"section_title": "School Administrator Questionnaire", "text": "The principal, administrator, or headmaster at the school attended by the sampled child was asked to complete the school administrator questionnaire in the spring of 2007. This self-administered questionnaire was intended to gather information about the school, student body, teachers, school policies, and characteristics of the administrator. The school administrator questionnaire was divided into seven sections. The first five sections requested mainly factual information about each school and the programs offered at the school. Either a principal or a designee who was able to provide the requested information could complete these sections. The school's principal was asked to complete the remaining two sections concerning his or her background and evaluations of the school climate. If a designee was chosen to do the last two sections, he or she was instructed to answer the background and education questions about the school's principal or headmaster. The school administrator was also asked questions regarding the availability at school of various foods, including those that are healthy and those that are high in fat, sodium, and/or added sugars. Questions were asked about whether children could purchase food or beverages from vending machines at the school or a school store, canteen, or snack bar. School administrators were also asked if the school offered children a la carte lunch or breakfast items that were not sold as part of the National School Lunch or the School Breakfast Program. In addition, questions were asked about whether children could buy particular foods and beverages at school, such as milk, sweetened beverages (e.g., soft drinks), fruits and vegetables, candy, and salty snacks; where these foods could be obtained in the school (e.g., a school store, a vending machine); and how full the cafeteria was at peak meal times. Questions on the availability of foods that were not part of USDA meal programs and on cafeteria crowding were taken from the School Health Policies and Programs Study (SHPPS). The content areas addressed in this questionnaire in spring-eighth grade included the following: school characteristics-type of school, length of school year and start and end dates, school size, average daily attendance, highest and lowest grades; academic course offerings for eighth-graders; child population characteristics-race/ethnicity of children, participation in special services, percent Limited English Proficient (LEP); school facilities and resources; 2-14 community characteristics and school safety; average starting salary of full-time first year teachers; school policies and programs-assessments and testing, free and reduced-price breakfast and lunch; programs for special populations-English as a Second Language (ESL) and bilingual education, special education, gifted and talented; principal characteristics-sex, race/ethnicity, age of principal, experience and education; school governance and climate-goals and objectives for teachers, school functioning and decisionmaking; and availability of different types of foods during school hours. 3-1"}, {"section_title": "ASSESSMENT AND RATING SCALE SCORES USED IN THE ECLS-K", "text": "Several types of scores were used in the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K) to describe children's cognitive and social development during kindergarten through eighth grade. These scores were for the direct cognitive assessment, the teacher ratings of English, mathematics, and science skills, and the self-description questionnaire (SDQ). Descriptions of the scores for each assessment or scale follow, along with variable names, variable descriptions, and descriptive statistics from the ECLS-K data files. 16 Guidelines for when and how to use each cognitive assessment score are also provided in this chapter."}, {"section_title": "Direct Cognitive Assessment", "text": "The eighth-grade direct cognitive assessment contained items in reading, mathematics, and science. In each subject area, children received a 10-item routing test. Performance on the routing items guided the selection and administration of one of two second-stage (high and low) forms in each subject area. The second-stage forms contained items of appropriate difficulty for the level of ability indicated by the routing items. 17 The eighth-grade direct cognitive assessment was built from the framework established in the previous kindergarten through fifth-grade rounds of data collection. The design and administration of the assessment instruments, and the scores derived from them, evolved over time to keep pace with children's growth and the objectives of the study. Changes in the assessments include the following: English language screening: In kindergarten and first grade, children who were identified as coming from a language minority background were administered a language-screening assessment, the Oral Language Development Scale (OLDS), prior to administering the direct cognitive assessments. English language screening was discontinued after spring-first grade because nearly all children in the sample had demonstrated sufficient English proficiency to participate in the full assessment by that time."}, {"section_title": "3-2", "text": "Assessment instruments: The four rounds of data collection in kindergarten and first grade used the same set of assessment instruments in reading, mathematics, and general knowledge. Children were routed to different levels of difficulty within each assessment domain depending on their performance on a short routing test in each subject area. Because children's academic skills in the subsequent rounds could be expected to have advanced beyond the levels covered by the original forms, new sets of assessment instruments were developed for the third grade, fifth grade, and again for the eighth grade. Some of the assessment items were retained across rounds to support the development of longitudinal score scales in each subject area. Science assessment: The kindergarten and first grade (K-1) general knowledge assessment included basic natural science concepts as well as concepts in social studies. For third, fifth, and eighth grades, a science assessment replaced the general knowledge assessment. Thus, the longitudinal scale for measuring gains in science spans only the third-through eighth-grade rounds."}, {"section_title": "Assessment format:", "text": "The format of the eighth-grade assessment was modified from that of prior rounds to accommodate administration differences for the older sample. In all previous rounds, an assessor presented the questions to the child and entered responses into a computer for each individually administered assessment. In third grade and fifth grade, the mathematics assessment included a workbook for the questions that required computations or written responses. The reading assessment in third grade was administered in booklet format instead of on an easel to accommodate the length of the reading passages used in the assessment, while the fifth-grade reading assessment had both a booklet containing the reading passages and an easel for the presentation of questions. The individually administered easel assessments were less appropriate for the older sample in eighth grade. Therefore, the eighth-grade assessments were paper-based and were administered in groups (where possible). The passages and items were in booklet form; an answer sheet was provided for the routing test responses, while responses for the second-stage forms were entered into the assessment booklets. There were two second-stage forms for each domain."}, {"section_title": "Item cluster scores:", "text": "The K-1 assessment scores included a count of the number right on three questions related to familiarity with conventions of print. Additional cluster scores, based on small numbers of reading and science items, were reported for the third-and fifth-grade assessments. There were no cluster scores for the eighth-grade round. Bridge sample: Field test results after spring-first grade suggested that the growth in skills between the first-and third-grade assessments might make measurement of gain problematic. Data were collected for a small \"bridge sample\" of second-graders to support development of longitudinal scales in reading and mathematics. A bridge sample of fourth-graders was not necessary to bridge the gap between the third-and fifth-grade assessments, because field test results showed a sufficient amount of overlap between high achieving third-graders and low achieving fifth-graders. Similarly, a bridge sample was not done to bridge the gap between fifth-and eighthgraders."}, {"section_title": "3-3", "text": "The scores used to describe a child's performance on the direct cognitive assessment include broad-based measures that report performance in each domain as a whole, as well as targeted scores reflecting knowledge of selected content or mastery within a set of hierarchical skill levels. Some of the scores are simple counts of correct answers, while others are based on Item Response Theory (IRT), which uses patterns of correct and incorrect answers to obtain estimates that are comparable across different assessment forms. The different types of scores that are used to describe children's performance on the direct cognitive assessment are described in detail in this chapter. Number-right scores and IRT scale scores measure children's performance on a set of questions with a broad range of difficulty. Standardized scores (T-scores) report children's performance relative to their peers. Criterion-referenced proficiency scores evaluate children's performance with respect to subsets of items that mark specific skills. Tables 3-1 through 3-9 show the types of scores, variable names, descriptions, and summary statistics for the direct cognitive assessment. The name and description for each variable in the tables begin with a \"C,\" indicating that it is a child variable, and a data collection round number: 1 (fallkindergarten), 2 (spring-kindergarten), 3 (fall-first grade), 4 (spring-first grade), 5 (spring-third grade), 6 (spring-fifth grade), or 7 (spring-eighth grade). Weighted means in tables containing only eighth-grade scores use the round 7 cross-sectional weight, C7CW0, to represent population estimates for eighth grade. Weighted estimates in tables containing scores for all earlier rounds are based on C1_7SC0, the round 1-2-3-4-5-6-7 panel weight, while tables containing only scores for science, assessed only in third, fifth, and eighth grades, use C57CW0, the round 5-7 panel weight. Kindergarten through fifth-grade scores in this database differ somewhat from the corresponding scores in the previously released data files because they were re-estimated along with the eighth-grade scores (see section 3.1.2). In addition, all kindergarten through fifth-grade score statistics presented here differed from previous estimates because the panel weight used restricted estimates to children who participated in all seven rounds of data collection (for reading and mathematics scores), or rounds 5, 6, and 7 (science scores). deviations for the routing test number-right scores for the kindergarten and first-grade surveys. Table 3-2   has the same information for the third-grade routing tests, table 3-3 for the fifth-grade routing tests, and   table 3-4 for the eighth-grade routing tests.  1998, spring 1999, fall 1999, and spring 2000. 3-5   "}, {"section_title": "Number-Right Scores", "text": ""}, {"section_title": "Item Response Theory Scale Scores; Standardized Scores (T-Scores)", "text": "Broad-based scores using the full set of assessment items in reading, mathematics, and science were calculated using IRT procedures. The IRT scale scores estimated children's performance on 3-6 the whole set of assessment questions, while standardized scores (T-scores) reported children's performance relative to their peers on the content domains. IRT makes it possible to calculate scores that can be compared regardless of which second-stage form a child takes. IRT uses the pattern of right, wrong, and omitted responses to the items actually administered in an assessment and the difficulty, discriminating ability, and \"guess-ability\" of each item to place each child on a continuous ability scale. The items in the routing tests, plus a core set of items shared among the different second-stage forms and different rounds of data collection, made it possible to establish a common scale. It is then possible to estimate the score the child would have achieved if all of the items in all of the assessment forms had been administered. IRT has several other advantages over raw number-right scoring. By using the overall pattern of right and wrong responses and the characteristics of each item to estimate ability, IRT can compensate for the possibility of a low-ability child guessing several difficult items correctly. If answers on several easy items are wrong, the probability of a correct answer on a difficult item would be quite low. Omitted items are also less likely to cause distortion of scores, as long as enough items have been answered right and wrong to establish a consistent pattern. Unlike raw scoring, which treats omitted items as if they had been answered incorrectly, IRT procedures use the pattern of responses to estimate the probability of correct responses for all assessment questions. Finally, IRT scoring makes possible longitudinal measurement of gain in achievement over time, even though the assessments that are administered are not identical at each point. The common items present in the routing test and in overlapping second-stage forms allow the scores to be placed on the same scale, even as the two-stage design adapts to children's growth over time. As noted earlier, kindergarten and first-grade responses were pooled with third-, fifth-, and eighth-grade data to stabilize the longitudinal estimates. In addition, the maximum values of the scale scores were extended to include the more difficult items administered in the eighth-grade assessments. The scale scores for each round of user files are defined on the basis of performance on all tasks administered up to and including the current round. The re-estimated kindergarten/first-grade, third-grade, fifth-grade, and eighth-grade IRT scores in this database differ from the IRT scores in the kindergarten/first-grade, third-grade, and fifth-grade files previously released. For example, the reading scale score in the fifth-grade file is based on test items used in kindergarten through fifth grade, while the current reading score is an estimate based on an expanded set of items, all of those used in kindergarten through eighth grade. In order to compute meaningful estimates of gains over time, scores for different 3-7 rounds must be based on comparable sets of tasks. As a result, scores for all previous rounds have been re-estimated (or recalibrated) so that comparisons can be made. The IRT scale scores in the database represent estimates of the number of items children would have answered correctly at each point in time if they had taken all of the 212 questions in all of the first-and second-stage reading forms administered in all rounds, the 174 questions in all of the mathematics forms, and the 111 science items. These scores are not integers because they are probabilities of correct answers, summed over all items in the pools. Reading and mathematics gain scores may be obtained by subtracting the re-estimated IRT scale scores at fall-kindergarten from the IRT scale scores at spring-first grade, spring-first grade from spring-third grade, spring-third grade from spring-fifth grade, spring-fifth grade from spring-eighth grade, and so forth. For the science assessment, which was not administered in kindergarten/first grade, gain scores may be computed for third to fifth to eighth grade only. The general knowledge test administered in the earlier rounds is not on the same scale. (Note that scores for different subject areas are not comparable to each other because they are based on different numbers of questions and content that is not necessarily equivalent in difficulty, i.e., it would not be correct to assume that a child is doing better in reading than in mathematics because his or her IRT scale score in reading is higher than in mathematics). See table 3-5 for variable names, descriptions, ranges, weighted means, and standard deviations for the IRT scale scores. Standardized scores (T-scores) provide norm-referenced measurements of achievement, that is, estimates of achievement relative to the population as a whole. A high mean T-score for a particular subgroup indicates that the group's performance is high in comparison to other groups. It does not represent mastery of a particular set of skills, only that the subgroup's mastery level is greater than a comparison group. Similarly, a change in mean T-scores over time reflects a change in the group's status with respect to other groups. In other words, T-scores provide information on status compared with children's peers, while the IRT scale scores and proficiency scores represent status with respect to achievement on a particular criterion set of assessment items. The T-scores provide only an indicator of the extent to which an individual or a subgroup ranks higher or lower than the national average and how much this relative ranking changes over time. The standardized scores reported in the database are transformations of the IRT theta (ability) estimates, rescaled to a mean of 50 and standard deviation of 10 using cross-sectional sample weights for each wave of data. For example, a fifth-grade reading T-score of 45 (C6R4RTSC) represents a reading achievement level that is one-half of a standard deviation lower than the mean for the population represented by the assessed sample of ECLS-K round 6 participants. If the same child had a reading T-score of 50 in eighth grade (C7R4RTSC), this would indicate that the child had made up his or her initial deficit and was reading at a level comparable to the national average. T-scores for earlier rounds have been re-estimated using the ability estimates based on the whole longitudinal item pools."}, {"section_title": "3-8", "text": "Since the T-scores represent status with respect to a peer group rather than with respect to a criterion set of items, the expansion of the item pool should result in only slight changes in the previously reported T-score estimates. In making T-score comparisons across rounds, the re-estimated scores should be used. See table 3-6 for variable names, descriptions, and ranges for the standardized T-scores across all rounds. The K-8 Full Sample Public Use data file includes the IRT theta (ability) scores for each data collection round for each domain (reading, mathematics, general knowledge, science) along with the standard error of measurement (SEM) associated with each theta score. The theta scores represent a child's ability measured at each round along a single continuous scale. The theta scores represent underlying ability (which is normally distributed at all rounds) while the IRT scale scores represent predicted performance on the ECLS-K assessments (which is not normally distributed at all rounds). The theta scores are ideally suited for measuring growth from kindergarten through the eighth grade. The theta score distribution range is approximately -3 to 3."}, {"section_title": "3-9", "text": ""}, {"section_title": "Proficiency Levels", "text": "Proficiency levels provide a means of distinguishing status or gain in specific skills within a content area from the overall achievement measured by the IRT scale scores and T-scores. Clusters of four assessment questions having similar content and difficulty were included at 10 points along the reading and 9 points along the math score scales for the assessments. Clusters of four items provided a more reliable assessment of proficiency than did single items because of the possibility of guessing; it is very unlikely that a child who had not mastered a particular skill would be able to guess enough answers correctly to pass a four-item cluster. The following reading and mathematics proficiency levels were identified in the reading and mathematics assessments for kindergarten through eighth grade. No proficiency scores were computed for the science assessment because the questions did not follow a hierarchical pattern."}, {"section_title": "3-10", "text": ""}, {"section_title": "Reading", "text": "Level 1: Letter recognition: identifying upper-and lower-case letters by name; Level 2: Beginning sounds: associating letters with sounds at the beginning of words; Level 3: Ending sounds: associating letters with sounds at the end of words; Level 4: Sight words: recognizing common \"sight\" words; Level 5: Comprehension of words in context: reading words in context; Level 6: Literal inference: making inferences using cues that are directly stated with key words in text (for example, recognizing the comparison being made in a simile); Level 7: Extrapolation: identifying clues used to make inferences, and using background knowledge combined with cues in a sentence to understand use of homonyms; Level 8: Evaluation: demonstrating understanding of author's craft (how does the author let you know\u2026) and making connections between a problem in the narrative and similar life problems; Level 9: Evaluating nonfiction: critically evaluating, comparing and contrasting, and understanding the effect of features of expository and biographical texts; and Level 10: Evaluating complex syntax: evaluating complex syntax and understanding high-level nuanced vocabulary in biographical text."}, {"section_title": "Mathematics", "text": "Level 1: Number and shape: identifying some one-digit numerals, recognizing geometric shapes, and one-to-one counting of up to 10 objects; Level 2: Relative size: reading all single-digit numerals, counting beyond 10, recognizing a sequence of patterns, and using nonstandard units of length to compare objects; Level 3: Ordinality, sequence: reading two-digit numerals, recognizing the next number in a sequence, identifying the ordinal position of an object, and solving a simple word problem; Level 4: Addition/subtraction: solving simple addition and subtraction problems; Level 5: Multiplication/division: solving simple multiplication and division problems and recognizing more complex number patterns; Level 6: Place value: demonstrating understanding of place value in integers to the hundreds place; Level 7: Rate and measurement: using knowledge of measurement and rate to solve word problems; Level 8: Fractions: demonstrating understanding of the concept of fractional parts; and Level 9: Area and volume: solving word problems involving area and volume, including change of units of measurement. The proficiency levels were assumed to follow a Guttman model, that is, a child passing a particular skill level was expected to have mastered all lower levels; a failure should be consistent with nonmastery at higher levels. Only a very small percentage of children in kindergarten through eighth grade had response patterns that did not follow the Guttman model, that is, a failing score at a lower level followed by a pass on a more difficult item cluster. For the first six rounds of data collection, less than 7 percent of reading response patterns, and about 3 percent of mathematics assessment results, failed to follow the expected hierarchical pattern; in round 7 (grade 8) these figures were 3 percent for mathematics and less than 1 percent for reading. This does not necessarily indicate a different order of learning for these children; since most of the proficiency-level items were multiple-choice, many of these reversals may be due to children guessing. Two types of scores are reported with respect to the proficiency levels: a single indicator of highest level mastered, and a set of IRT-based probability scores, one for each proficiency level. More information on each of these types of scores is provided below. As for the other IRT-based scores (scale scores and T-scores), re-estimated values for earlier rounds should be used when making comparisons of proficiency levels across rounds."}, {"section_title": "Highest Proficiency Level Mastered", "text": "Mastery of a proficiency level was defined as answering correctly at least three of the four questions in a cluster. This definition results in a very low probability of guessing enough right answers by chance, generally less than 2 percent. At least two incorrect or \"don't know\" responses indicated lack of mastery of a cluster. Questions that were answered with an explicit \"I don't know\" were treated as wrong, while omitted items were not counted. Since the ECLS-K direct cognitive assessment was a twostage design (where not all children were administered all items), and since more advanced assessment instruments were administered in third, fifth, and eighth grades, the data did not include all of the assessment items necessary to determine pass/fail for every proficiency level at each round of data collection. The missing information was not missing at random; it depended in part on children being routed to second-stage assessment forms of varying difficulty within each round, and in part on the range of difficulty of the assessments at the different grade levels. In order to avoid bias due to the nonrandomness of the missing proficiency level scores, imputation procedures were undertaken to fill in the missing information. Pass or fail for each proficiency level was based on actual counts of correct or incorrect responses, if they were present. If too few items were administered or answered to determine mastery of a level, a pass/fail score was assigned based on the remaining proficiency scores only if they indicated a pattern that was unambiguous. That is, a \"fail\" was inferred for a missing level if there were easier cluster(s) that had been failed and no higher cluster passed; or a \"pass\" was assumed if harder cluster(s) were passed and no easier one failed. In the case of ambiguous patterns (e.g., pass, missing, fail, where the missing level could legitimately be either a pass or a fail), an additional imputation step was undertaken that relied on information from the children's performance on all of the domain items answered in that round of data collection. IRT-based estimates of the probability of a correct answer were computed for each missing assessment item and used to assign an imputed right or wrong answer. These imputed responses were then aggregated in the same manner as actual responses to determine mastery at each of the missing levels. About 67 percent of the \"highest level\" scores in reading and 80 percent in mathematics were determined on the basis of item response data alone for the kindergarten through fifth-grade rounds. In eighth grade, the scores determined on the basis of item response data dropped to 19 percent for reading and 47 percent for math, a result of the necessary placement of the proficiency level items on either the low or high second-stage form, based on their estimated difficulty levels. The rest utilized IRTbased probabilities for some or all of the missing items, since the \"missingness\" is a consequence of the child's ability or grade level and requires special treatment in order to avoid misleading results. (The ECLS-K Psychometric Report for the Eighth Grade (NCES 2009-002) (Najarian, Pollack, and Sorongon forthcoming) describes this treatment in more detail.) Scores were not imputed for missing levels that included a reversal (e.g., fail, blank, pass) because no resolution of the missing data could result in a consistent hierarchical pattern."}, {"section_title": "3-13", "text": "Scores in the data file represented the highest level of proficiency mastered by each child at each round of data collection, whether this determination was made by actual item responses alone or by a combination of item responses and imputation methods. The highest proficiency level mastered implies that children demonstrated mastery of all lower levels and nonmastery of all higher levels. A zero score indicates nonmastery of the lowest proficiency level. Scores were excluded only if the actual or imputed mastery level data resulted in a reversal pattern as defined above. The highest proficiency level-mastered scores did not necessarily correspond to an interval scale, so in analyzing the data, they should be treated as ordinal. See table 3-7 for variable names, descriptions, and weighted percentages for the highest proficiency level mastered scores. "}, {"section_title": "3-14", "text": ""}, {"section_title": "Proficiency Probability Scores", "text": "Proficiency probability scores were reported for each of the proficiency levels described above, at each round of data collection. The scores estimate the probability of mastery of each level and can take on any value from zero to one. An IRT model was employed to calculate the proficiency probability scores, which indicated the probability that a child would have passed a proficiency level, based on his or her whole set of item responses in the content domain. The item clusters were treated as single items for the purpose of IRT calibration, in order to estimate children's probabilities of mastery of each set of skills. The hierarchical nature of the skill sets justified the use of the IRT model in this way. The proficiency probability scores differed from the highest level scores in that they could be used to measure gains over time, and from the IRT scale scores in that they targeted specific sets of skills. The proficiency probability scores can be averaged to produce estimates of mastery rates within population subgroups. These continuous measures can provide a close look at individuals' status and change over time. Gains in probability of mastery at each proficiency level allow researchers to study not only the amount of gain in total scale score points but also where along the score scale different children made their largest gains in achievement during a particular time interval. For example, subtracting the mathematics level 8 probability at round 6 (C6R4MPB8) from the level 8 probability at round 7 (C7R4MPB8) indicates whether a child advanced in mastery of the particular set of level 8 skills (i.e., fractions) during the time interval between the fifth-and eighth-grade assessments. Thus, children's school experiences can be related to improvements in specific skills. See tables 3-8 and 3-9 for variable names, descriptions, ranges, weighted means, and standard deviations for the proficiency probability scores in reading and mathematics.    The following are some examples of interpretation and use of the proficiency probability scores: Children's skills in making inferences based on cues directly stated in text (literal inference) increased dramatically between first and third grade, from 18 percent, or a mean probability = 0.18 (C4R4RPB6), to 68 percent (C5R4RPB6). Nearly all children, 92 percent, had mastered this skill by eighth grade (C7R4RPB6)."}, {"section_title": "3-15", "text": ""}, {"section_title": "3-17", "text": "In spring-third grade, most children had not yet demonstrated understanding of the author's craft or making connections between a problem in the narrative and similar life problems. Only 25 percent mastered the evaluation level in third grade (C5R4RPB8), with 44 percent demonstrating mastery in fifth grade (C6R4RPB8) and 64 percent in eighth grade (C7R4RPB8). Twenty-six percent of eighth-graders were proficient at critical evaluation of nonfiction (C7R4RPB9), up from only 6 percent in fifth grade (C6R4RPB9)."}, {"section_title": "3-19", "text": "Only percent of eighth-graders were able to evaluate complex syntax and understand high-level vocabulary in a biographical passage (C7R4RPB10). Fourteen percent of children understood interpretation and manipulation of simple fractions (C6R4MPB8) by the spring of fifth grade, and 36 percent by spring of eighth grade (C7R4MPB8). Three percent of fifth-graders could solve word problems involving area and volume (C6R4MPB9), with 16 percent of children demonstrating mastery in eighth grade (C7R4MPB9). Comparisons of subgroups may be made by computing the mean probability for each group at a single point in time, or the mean gain for each group from one time to another. See section 3.1.5 for further discussion of measurement of gain."}, {"section_title": "Choosing the Appropriate Score for Analysis", "text": "Each of the types of scores described earlier measures children's achievement from a slightly different perspective. The choice of the most appropriate score for analysis purposes should be driven by the context in which it is to be used: a measure of overall achievement versus achievement in specific skills; an indicator of status at a single point in time versus growth over time; or a criterion-referenced versus norm-referenced interpretation."}, {"section_title": "Item Response Theory-Based Scores", "text": "The scores derived from the IRT model (IRT scale scores, T-scores, proficiency probabilities) were based on all of the child's responses to a subject area assessment. That is, the pattern of right and wrong answers, as well as the characteristics of the assessment items themselves, were used to estimate a point on an ability continuum, and this ability estimate, theta, then provided the basis for criterion-referenced and norm-referenced scores. As noted earlier, estimates of gains and comparisons of achievement across rounds that make use of the IRT-based scales should use re-estimated values for the 3-20 earlier rounds, not values found on earlier user files, if using eighth-grade scores, or data from prior rounds only, or both (see section 3.1.2). The IRT scale scores are overall, criterion-referenced measures of status at a point in time. They are useful in identifying cross-sectional differences among subgroups in overall achievement level and provide a summary measure of achievement useful for correlational analysis with status variables, such as demographics, school type, or behavioral measures. The IRT scale scores may be used as longitudinal measures of overall growth. However, gains made at different points on the scale have qualitatively different interpretations. For example, children who made gains in recognizing letters and letter sounds are learning very different skills than those who are making the jump from reading words to reading sentences, although the gains in number of scale score points may be the same. Comparison of gain in scale score points is most meaningful for groups that started with similar initial statuses. The standardized scores (T-scores) are also overall measures of status at a point in time, but they are norm-referenced rather than criterion-referenced. They do not answer the question, \"What skills do children have?\" but rather \"How do they compare with their peers?\" The transformation to a familiar metric with a mean of 50 and standard deviation of 10 facilitates comparisons in standard deviation units. T-score means may be used longitudinally to illustrate the increase or decrease in gaps in achievement among subgroups over time. T-scores are not recommended for measuring individual gains over time. The IRT scale scores or proficiency probability scores are used for that purpose. Proficiency probability scores, derived from the overall IRT model, are criterionreferenced measures of proficiency in specific skills. Because proficiency scores each target a particular set of skills, they are ideal for studying the details of achievement, rather than the single summary measure provided by the IRT scale scores and T-scores. They are useful as longitudinal measures of change because they show not only the extent of gains but also where on the achievement scale the gains are taking place. Thus, they can provide information on differences in skills being learned by different groups, as well as the relationships with processes, both in and out of school, that correlate with learning specific skills. For example, high socioeconomic status (SES) kindergarten children showed very little gain in the lowest reading proficiency level, letter recognition, because they were already proficient in this skill at kindergarten entry. At the same time, low-SES children made big gains in basic skills, but most had not yet made major gains in reading words and sentences by the end of kindergarten. Similarly, the best readers in eighth grade may be working on learning to comprehend complex syntax and vocabulary and make evaluative judgments based on reading material, which would show up as large gains in reading levels 8, 9, and 10. Less skilled readers may show their largest gains between fifth and eighth grades at levels 6 or 7, literal inference and extrapolation, catching up with the skill levels achieved by many of their peers in earlier rounds. The proficiency level at which the largest change is taking place is likely to be different for children with different initial status, background, and school setting. Changes in proficiency probabilities over time 3-21 may be used to identify the process variables that are effective in promoting achievement gains in specific skills."}, {"section_title": "Scores Based on Number Right for Subsets of Items (Non-IRT Based Scores)", "text": "The routing test number-right scores do not depend on the assumptions of the IRT model. They were derived from item responses on specific subsets of assessment items, rather than estimates based on patterns of overall performance; therefore the values of these scores reported in user files for earlier rounds were not re-estimated. Highest proficiency level mastered also, in theory, was derived from item responses, although a relatively small number of IRT-based estimates were substituted for missing data. Routing test number-right scores for the eighth-grade reading, mathematics, and science assessments are based on 10 items in each domain. They target specific sets of skills and cover a broad range of difficulty. These scores may be of interest to researchers because they are based on a specific set of assessment items, which was the same for all children who took the assessment. However, because of the limited number of items in the routing tests, it is important to remember that these scores do not represent a comprehensive sample of the relevant domain of knowledge. The primary purpose of the routing tests was selection of appropriate second-stage forms. Highest proficiency level mastered is based on the same sets of items as the proficiency probability scores but consists of a series of dichotomous pass/fail scores, reported as a single highest mastery level. The highest proficiency level mastered should be treated as an ordinal variable. Pass/fail on each of the individual levels in the set is based on whether children were able to answer correctly at least three out of four actual items in each cluster. For about one-third of reading scores and 20 percent of mathematics scores in the earlier rounds, and about 80 percent for reading and 50 percent for mathematics in eighth grade, the item data was supplemented with IRTbased estimates so that the \"highest level\" scores would not have to be reported as missing data. The higher percentages in eighth grade are a result of the necessary placement of proficiency level items on either the low or high second-stage forms, based on their estimated difficulty levels. Therefore, analysis of missing data that is not missing at random (i.e., the \"missingness\" is a consequence of the child's skill level or grade level) requires special treatment in order to avoid misleading results. The ECLS-K Psychometric Report for the Eighth Grade (NCES 2009-002) (Najarian , Pollack, and Sorongon forthcoming) describes this treatment in more detail."}, {"section_title": "Measuring Gains", "text": "This section outlines approaches to measuring gains that rely on multiple criterionreferenced points to identify different patterns of child growth. It describes how analysts might use the year of schooling) can be relatively trivial compared to individual and group differences in where the gains take place. It is more likely that one will see substantial subgroup differences in initial status than in gains, suggesting that the gains being made by individuals at different points on the score scale are 3-23 qualitatively different. Thus analysis of the total IRT scale score without explicitly taking into consideration where the gain takes place tells only part of the story. The ECLS-K design utilized adaptive assessments to maximize the accuracy of measurement and minimize floor and ceiling effects, and then to develop an IRT-based vertical scale with multiple criterion-referenced points along that scale. These points, the 10 reading and 9 mathematics proficiency levels described in section 3.1.3, model critical stages in the development of skills. Criterion-referenced points serve two purposes at the individual level: (1) they provide information about changes in each child's mastery or proficiency at each level, and (2) they provide information about where on the scale the child's gain is taking place. This provides analysts with two options for analyzing achievement gains and relating them to background and process variables. First, gains in probability of proficiency at any level may be aggregated by subgroup and/or correlated with other variables. Second, the location of maximum gain may be identified for each child by comparing the gains in probability for all of the levels and focusing on the skills the child is acquiring during a particular time interval. The probabilities of proficiency at any level may be averaged to estimate the proportion of children mastering the skills marked by that level. For example, the spring-first grade mean for mathematics level 5, \"Multiply/Divide,\" was 0.23, analogous to 23 percent of the first-grade population demonstrating mastery of this set of items. The mean probability at the end of third grade, 0.77, is equivalent to a population mastery rate of 77 percent, with a mastery rate of 93 percent by the end of fifth grade and 98 percent in eighth grade. While most children were making their largest gains between first and third grades at level 5, a small number of children were advancing their skills in solving word problems based on rate and measurement, level 7, and others were still catching up with simple addition and subtraction, level 4. "}, {"section_title": "3-24", "text": "Another approach entails computing differences in probabilities of proficiency between any two selected time points for all of the proficiency levels. The largest difference marks the mastery level where the largest gain for a given child is taking place: the \"locus of maximum gain.\" The locus of maximum gain is likely to vary for different subgroups of children categorized according to variables of interest. Once having identified mutually exclusive groups of children according to the proximity of their gains to each of the critical points on the developmental scale, one can treat the different types of gains as qualitatively different outcome measures to be explained by background and process variables. Each different analytical approach provides a different perspective with respect to understanding children's growth. While comparisons of scale score means may be used to capture information about children at a single point in time, analysis of gain in probability of proficiency is more likely to provide useful information about the contribution of background and process variables to gains in achievement over time. Examples of these approaches can be found in Rock and Pollack (2002a). Another important issue to be considered in analyzing achievement scores and gains is assessment timing: children's age at first assessment, assessment dates, and the time interval between successive assessments. This issue is most relevant in the early years, kindergarten and first grade. It was not possible to apply standard measures of reliability to the \"highest proficiency mastered\" score, for the following reasons. The score is not a set of items replicating the same or similar tasks, so an internal consistency measure such as split-half reliability or alpha coefficient cannot be computed. Nor can the reliability be evaluated based on the variance of repeated estimates of overall ability that was appropriate for the IRT-based scores. The definition of reliability-consistency of measurement under different circumstancessuggested an appropriate way to assess the reliability of the \"highest proficiency level mastered\" score. The score denoting the highest level mastered reduces the series of pass/fail scores on the hierarchical set 3-26 of proficiency levels to a single score. For example, a child demonstrating mastery of the first five reading levels but not the remaining four would be said to have a \"highest proficiency mastered\" score of five. The question to be answered by a reliability estimate is how likely it would be that the same highest level score would be obtained under other circumstances. In this case, the other circumstances available are not a parallel set of items, but two different methods of arriving at the score. A child's highest level mastered could be determined on the basis of actual item response data alone for only about 19 percent of the reading and 47 percent of the mathematics eighth-grade scores, because the clusters of items marking some of the proficiency levels appeared only in some of the test forms. Alternatively, IRT ability estimates and item parameters could be used to generate pass/fail scores, and the composite highest level scores, for these same children. The percent of cases for which these two different methodologies result in identical or adjacent \"highest level mastered\" scores can be considered to be a reliability estimate. The high level of exact-plus-adjacent agreement (albeit slightly lower in eighth grade) between the methods indicates that the IRT approach supports the use of the highest level score sufficiently well for use in aggregate statistics. Tables 3-10 through 3-12 present the reliability statistics for all of the assessment scores in eighth grade.  years 1998-1999, 1999-2000, 2001-02, 2003-04, and 2006- years 1998-1999, 1999-2000, 2001-02, 2003-04, and 2006- School years 1998School years -1999School years , 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 "}, {"section_title": "3-27", "text": ""}, {"section_title": "Validity", "text": "Evidence for the validity of the direct cognitive assessments was derived from several sources. A review of national and state performance standards, comparison with state and commercial assessments, and the judgments of curriculum experts all provided input to test specifications."}, {"section_title": "3-28", "text": "The ECLS-K test specifications were derived from a variety of sources. For the thirdthrough eighth-grade assessments, national and state performance standards in each of the domains were examined. The scope and sequence of materials from state assessments, as well as from major publishers, were also considered. The resulting ECLS-K fourth-and eighth-grade frameworks are similar to the NAEP fourth-and eighth-grade frameworks, with some differences due to ECLS-K formatting and administration constraints. The NAEP fourth-grade frameworks were modified for third and fifth grades (and for the earlier K-1 forms), while the eighth-grade frameworks were used as defined in NAEP. An expert panel of secondary school educators, including curriculum specialists in the subject areas, examined the pool of items. The assessment specifications indicated target percentages for content strands within each of the subject areas. These percentages were matched as closely as possible in developing the field-test assessment item pool as well as in selecting items for the eighth-grade assessment forms. Some compromises in matching target percentages were necessary to satisfy constraints related to other issues, including linking to K-1, third-grade, and fifth-grade scales, avoiding floor and ceiling effects, and fieldtest item performance. This was especially true for the reading assessment, whose structure, (i.e., several questions based on each reading passage, placed an additional constraint on the selection of items to match content strands.)"}, {"section_title": "Indirect Cognitive Assessment", "text": "English, mathematics, and science teachers were asked to rate each sampled child on his or her skills in areas relevant to the subject taught. English teachers were asked about children's skills in written and oral expression. Mathematics teachers were asked about children's skills in mathematics, such as problem solving and demonstrating mathematical reasoning. Science teachers were asked about children's skills in science, such as designing an experiment to solve a scientific question and writing a report and preparing a presentation of scientific data. In earlier grades, teachers also rated children's achievement in a fourth domain: social studies. Teachers rated each child's skills, knowledge, and behaviors as \"Outstanding (5),\" \"Very Good 4,\" \"Good (3),\" \"Fair (2),\" or \"Poor (1).\" If a skill, knowledge, or behavior had not been introduced into the classroom yet, or if the teacher otherwise did not have the opportunity to observe the skill, the teacher was able to code that item as \"Not Applicable/Not Observed.\" In eighth grade, many schools are departmentalized so different teachers may be rating the child on science and mathematical thinking. All children were rated on their English skills by their English teacher. Half of the children were rated on their mathematics skills by their mathematics teacher,"}, {"section_title": "3-29", "text": "and half were rated on their science skills by their science teacher. The differences between the direct and indirect cognitive assessments, and the scores available, are described here."}, {"section_title": "Comparison to Direct Cognitive Assessment", "text": "The teacher ratings overlap and augment the information gathered through the direct cognitive assessment battery. Although the direct and indirect instruments measure children's skills and behaviors within the same broad curricular domains with some intended overlap, several of the constructs they were designed to measure differ in significant ways. Most important, the teacher rating scales include items designed to measure both the process and products of children's learning in school, whereas the direct cognitive battery is more limited. Because of time and space limitations, the direct cognitive battery is less able to measure the process of children's thinking, including how they express their ideas, solve mathematical problems, or investigate scientific phenomena. The language and literacy teacher ratings collect information on children's oral expression and written composition, areas not assessed on the direct measure. These criterion-referenced indirect measures are targeted to the specific grade level of the child and draw upon the daily observations made by teachers of the children in their class."}, {"section_title": "Scores Available for the Teacher Ratings", "text": "IRT analysis using a generalized partial credit model (Muraki 1992) was used to create measures of the reported performance of children on a hierarchy of skills, knowledge, and behavior. The generalized partial credit model, as implemented in the SSI Parscale computer program, uses the pattern of ratings on items to obtain an estimate of the difficulty of each item and to place each child on an interval scale set with a minimum score of one and a maximum score of five. The analysis showed that the reliability of the estimates of the child's ability was very high for all domains (see table 3-13).  items. Children would have a greater than 50 percent probability of receiving ratings of \"5\" on items below their ability level.    The teacher ratings scale was designed to provide information on children's abilities at a given point in time, not necessarily over time. Moreover, these teacher rating scales are placed on a different metric than the ARS scores in previous rounds. Therefore, change scores cannot be calculated between time points."}, {"section_title": "3-30", "text": ""}, {"section_title": "3-32", "text": "The teacher ratings do not represent a systematic national sample of teachers. Each set of teacher ratings is linked to a sampled child, and teachers were asked to rate as many ECLS-K sample children as they had in class."}, {"section_title": "Self-Description Questionnaire", "text": "Beginning in the third-grade data collection in the ECLS-K, children were asked to provide self-assessments of their academic and social skills. For the eighth-grade data collection, children rated Children rated whether each item was \"not at all true,\" \"a little bit true,\" \"mostly true,\" or \"very true.\" Three scales were produced from the eighth-grade SDQ items. The scale scores on all eighthgrade SDQ scales represent the mean rating of the items included in the scale. Children who responded to the eighth-grade SDQ answered virtually all of the questions, so treatment of missing data was not an issue. As with most measures of social-emotional behaviors, the distributions on these scales are skewed (negatively skewed for the positive social behavior scales and positively skewed for the problem behavior scales).    "}, {"section_title": "Self-Concept and Locus of Control Scale Scores", "text": "The Self-Concept and Locus of Control scales were adopted from the National Education Longitudinal Study of 1988 (NELS:88). These scales ask children about their self-perceptions and the amount of control they have over their own lives. Items were drawn from the NELS:88 student questionnaire and asked children to indicate the degree to which they agreed with 13 statements about themselves. Statements reflected perceptions children might have about themselves and about how much control they felt they had over their own lives. Children rated whether they \"strongly agree,\" \"agree,\" \"disagree,\" or \"strongly disagree\" with each item. In order to be as comparable as possible to NELS:88, scale scores were calculated with the same procedures as NELS:88. Some items were positively worded, and some were negatively worded. As"}, {"section_title": "3-35", "text": "a result, scoring for some items was reversed to provide an appropriate score. For the Self-Concept scale, three of the seven items in the scale were reverse scored before performing computations, so that higher scores indicate more positive self-concept: I certainly feel useless at times. At times I think I am no good at all. I feel I do not have much to be proud of. The seven items in the scale were then standardized separately to a mean of zero and a standard deviation of 1. The scale score is an average of the seven standardized scores. For the Locus of Control scale, five items were reverse scored so that higher scores indicate greater perception of control over one's own life: I don't have enough control over the direction my life is taking. In my life, good luck is more important than hard work for success. Every time I try to get ahead, something or somebody stops me. My plans hardly ever work out, so planning only makes me unhappy. Chance and luck are very important for what happens in my life. The six items in the scale were then standardized separately to a mean of zero and a standard deviation of 1. The scale score is an average of the six standardized scores. Children who responded to the Self-Concept and Locus of Control items answered virtually all of the questions, so treatment of missing data was not an issue. Table 3-21 presents the internal consistency reliability estimates of the Self-Concept and Locus of Control scales, as measured by Cronbach's coefficient alpha. The coefficient alpha for both scales is consistent with the findings from the NELS:88 data (alpha Self-Concept = .79, alpha Locus of Control = .68) (Ingels et al. 1990).  4-1"}, {"section_title": "3-36", "text": ""}, {"section_title": "SAMPLE DESIGN AND IMPLEMENTATION", "text": "This chapter describes the sample design of the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), and how it was modified and implemented for each round of data collection. An overview of the sample design is given here and described in more detail in the following sections, followed by a discussion of the types of weights needed for analyses and how they were computed. The ECLS-K employed a multistage probability sample design to select a nationally representative sample of children attending kindergarten in 1998-99. In the base year the primary sampling units (PSUs) were geographic areas consisting of counties or groups of counties. The secondstage units were schools within sampled PSUs. The third-and final-stage units were children within schools. The first-grade data collection targeted base-year respondents, where a case was considered responding if there was a completed child assessment or parent interview in fall-or spring-kindergarten. While all base-year respondents were eligible for the spring-first grade data collection, fall-first grade was limited to a 30 percent subsample. The spring child sample was freshened to include current first-graders who had not been enrolled in kindergarten in 1998-99 and, therefore, had no chance of being included in the ECLS-K base-year kindergarten sample. For both fall-and spring-first grade, only a subsample of children who had transferred from their kindergarten schools was followed. The third-grade data collection targeted base-year respondents and children sampled in first grade through the freshening operation in which the spring-first grade sample was freshened to include first-graders who had not been enrolled in kindergarten in 1998-99 and therefore had no chance of being included in the ECLS-K base-year kindergarten sample. As in the first-grade data collection in which only a subsample of children who had transferred from their kindergarten schools was followed, a subsampling of movers was also used in third grade. In third grade, however, the subsampling rate applied to transferred children was slightly higher; children whose home language was non-English (also known as children belonging to the language minority group) who moved for the first time between kindergarten or first grade and third grade were followed at 100 percent. In other words, children belonging to the language minority group who did not move in first grade but moved in third grade were all followed into their new third-grade schools. The higher subsampling rate allows for the preservation of this group in the 4-2 sample for analytic reasons. Children not in the language minority group continued to be subsampled for follow-up if they moved in third grade. The fifth-grade data collection set differential sampling rates for movers in different categories. It also excluded four special groups of children, irrespective of other subsampling procedures that were implemented. The excluded children were those who became ineligible in an earlier round because they died or moved out of the country; who were subsampled out in previous rounds because they were movers; whose parents emphatically refused to cooperate (hard refusals); and who were eligible for the third-grade data collection but had neither first-grade nor third-grade data. Of the remaining children, those who moved from their original schools during fifth grade or earlier were subsampled for follow-up. Children whose home language was not English (language minority) continued to be a special domain of analytic interest and were subsampled at higher rates. Children were subsampled at different rates depending on the longitudinal data available for those children. The eighth-grade sample included all children eligible after fifth grade regardless of their fifth-grade response status. The ineligible children were those who moved out of the country, were deceased, or moved to another school and were not subsampled for follow-up in fifth grade. There was no subsampling of movers for follow-up as in previous rounds since the vast majority of children were not in the same school from kindergarten to eighth grade (having moved out of elementary schools into middle schools), and subsampling these movers would result in substantial losses in sample size and precision of the estimates for eighth grade."}, {"section_title": "Base-Year Sample", "text": "In the base year, children were selected for the ECLS-K using a multistage probability design. The PSUs were counties or groups of counties selected with probability proportional to size (PPS). The basic PSU measure of size was the number of 5-year-olds, but this was modified to facilitate the oversampling of Asian and Pacific Islanders (APIs) required to meet precision goals. In all, there were income. From each non-SR stratum, two PSUs were selected with PPS without replacement using Durbin's Method (Durbin 1967). Table 4-1 summarizes the characteristics of the ECLS-K PSU sample. Department of Defense (DOD) domestic schools, a 1996 list of schools was obtained directly from the DOD. These schools constitute the original frame. A procedure was implemented to create a freshened frame by identifying kindergarten programs that would be operational at the time of ECLS-K base-year data collection but that were not included in the original frame. These were newly opened schools that were not listed in the CCD and the PSS, as well as schools that were in the CCD and the PSS but did not appear to offer kindergarten programs according to those sources. The selection of schools was systematic, with probability proportional to a weighted measure of size based on the number of kindergartners enrolled. As with the PSU sample, the measure of size was constructed taking into account the desired oversampling of APIs. Public and private schools constituted distinct sampling strata. Within each stratum, schools were sorted to ensure good sample representation across other characteristics. In total, 1,280 schools were sampled from the original frame and 133 from the freshened frame. Of these, 953 were public schools and 460 were private schools."}, {"section_title": "4-4", "text": "The characteristics of the ECLS-K school sample are presented in The third-stage sampling units were children of kindergarten age, selected within each sampled school. The goal of the child sample design was to obtain an approximately self-weighting sample of children and, at the same time, to achieve a minimum required sample size for APIs who were 4-5 the only subgroup that needed to be oversampled to meet the study's precision goals. For each sampled school, the field staff obtained a complete list of kindergartners enrolled. Two independent sampling strata were formed within each school, one containing API children and the second, all other children. Within each stratum, children were selected using equal probability systematic sampling, using a higher rate for the API stratum. 19 In general, the target number of children sampled at any one school was 24. Once the sampled children were identified, parent contact information was obtained from the school. The information was used to locate a parent or guardian and gain parental consent for the child assessment and for the parent interview. Table 4-3 presents characteristics of children sampled and eligible for the base year. During the fall-kindergarten data collection, a census of kindergarten teachers was taken at each school. Each sampled child was linked to his or her kindergarten teacher. In spring-kindergarten, teacher-child linkages were reviewed and updated. If new kindergarten teachers had joined the school, they were added to the census of kindergarten teachers. Special education teachers who taught one or more sampled children were included in the spring-kindergarten data collection. If a sampled child received special education services from such a teacher, the teacher was linked to that child. While the sample of schools was the same for fall-and spring-kindergarten, the child sample was larger in spring than in fall. In spring-kindergarten, 1,426 additional children were sampled from the schools that refused to participate in fall but were converted into respondents in spring. For a detailed description of the base-year sample, see the ECLS-K Base Year Public-Use Data Files and Electronic Codebook: User's Manual (NCES 2001-029rev) (Tourangeau, Burke et al. 2004).  "}, {"section_title": "4-6", "text": ""}, {"section_title": "Fall-First Grade Subsample", "text": "A subsample of ECLS-K base-year PSUs was selected for fall-first grade data collection. All 24 of the SR PSUs were retained. Of the 76 non-self-representing (NSR) PSUs, 38 were retained by sampling one PSU per stratum with equal probability. Base-year schools in the 62 fall-first grade sampled PSUs were stratified by frame source (original public, original private, freshened public, and freshened private as described in section 4.1) and arranged in their original selection order. A 30 percent equal probability subsample of schools was drawn in the 24 SR PSUs, and a 60 percent subsample of schools was drawn in the 38 NSR PSUs. In total, 311 schools that had cooperated in either fall-or spring-kindergarten were selected. The characteristics of the base-year cooperating schools selected for fall-first grade data collection are presented in table 4-4. The fall-first grade data collection consisted of the direct child assessment and the parent interview. Data collection was attempted for every eligible child found still attending the school in which he or she had been sampled during kindergarten and a subset of eligible children who had transferred from the school in which they were originally sampled. \"Eligible\" is defined as a base-year respondent (i.e., a child who had either a fall-or spring-kindergarten child assessment or parent interview or was excluded from assessment because of a disability or because the child belonged in the language minority, not Spanish group). To contain the costs of data collection, a random 50 percent of children were flagged to be followed for fall-first grade data collection in the event that they had transferred."}, {"section_title": "4-8", "text": ""}, {"section_title": "4-9", "text": "Except for children who were repeating kindergarten, all base-year children sampled in schools with a high grade of kindergarten are de facto movers. Since many of these movers may move en masse to the same first-grade school, steps were taken to follow these children at a higher rate. Using the information collected during spring-kindergarten, a list of destination schools was compiled for each such school. The destination school having the most movers was designated as primary, unless no such school had more than three movers. Children who moved en masse into a primary destination school in fall-first grade were treated as \"nonmovers\" and were not subsampled (that is, they continued to be followed and were part of the ECLS-K sample). In this way, movers are defined differently in this chapter (statistical movers) than in chapter 5 (operation movers). As discussed above, a random 50 percent of children were subsampled to be followed if they moved out of the kindergarten school. Prior to sampling, children were stratified into groups of nonmovers, movers with information identifying their new schools, and movers without such identifying information. Sampling was done with equal probability within subsampling strata using the same sampling rate of 0.5 in each substratum. A flag was created for each child indicating whether the child had been sampled to be followed. Table 4-5 shows the characteristics of the children subsampled and eligible for fall-first grade. Region, locale, school affiliation, and school type describe the school the child attended in kindergarten.  72 \u2020 Not applicable. 1 School offers kindergarten and at least another grade between first grade and twelfth grade. NOTE: School characteristics (i.e., region, locale, school affiliation, and school type) describe the school the child attended in kindergarten. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), fall 1999 and spring 2000."}, {"section_title": "4-10", "text": ""}, {"section_title": "4-11", "text": ""}, {"section_title": "Spring-First Grade Sample", "text": "The ECLS-K spring-first grade data collection targeted all base-year respondents (i.e., respondent in fall-or spring-kindergarten). In addition, the spring child sample was freshened to include current first-graders who had not been enrolled in kindergarten in 1998-99 and, therefore, had no chance of being included in the ECLS-K base-year kindergarten sample. While all children still enrolled in their base-year schools were recontacted, only a 50 percent subsample of base-year sampled children who had transferred from their kindergarten school was followed for data collection."}, {"section_title": "Subsampling Movers", "text": "As noted earlier, in spring-first grade all children in a random 50 percent subsample of baseyear schools were flagged to be followed for data collection if they transferred from their base-year school. (This is in contrast to fall-first grade, where a random 50 percent of children in each of the 30 percent of schools subsampled were flagged). In order to maximize the amount of longitudinal data, care was taken during spring-first grade sampling to ensure that any child who had been flagged to be followed in fall-first grade would continue to be so.\nIn spring-first grade, all children in a random 50 percent subsample of base-year schools were flagged to be followed for data collection if they transferred from their base-year school at any point in the future. In order to maximize the amount of longitudinal data, care was taken during spring-first grade sampling to ensure that any child who had been flagged to be followed in fall-first grade would continue to be followed. The spring-first grade sampling procedure for movers is described in section 4.3.1. In spring-third grade, children who were followed in spring-first grade were retained in the sample (i.e., the mover follow-up still targeted the same 50 percent subsample of children in the base-year 4-16 schools). In addition, language minority children who moved between first grade and third grade were followed with certainty as described below."}, {"section_title": "4-12", "text": "In selecting the spring-first grade 50 percent subsample of schools where movers would be flagged for follow-up, the three primary strata were SR PSUs, NSR PSUs that had been selected for fallfirst grade, and NSR PSUs that had not been selected for fall-first grade. Within these major strata, schools were grouped by frame source (original public, original private, freshened public, and freshened private as described in section 4.1). Finally, within each frame source, schools were stratified by whether the school participated in the base-year study and were then arranged in original selection order. Schools that had been part of the 30 percent fall-first grade sample were automatically retained. Then equal probability sampling methods were employed to augment the sample to the desired 50 percent. The net result of these procedures was that every base-year selected school had on average a 50 percent chance of having its ECLS-K transfer children followed during spring-first grade, and any transfer child who had been followed in fall-first grade would still be followed in spring-first grade. Table 4-6 shows the characteristics of the eligible children in the spring-first grade sample, excluding freshened children. Region, locale, school affiliation, and school type describe the school in which the child attended kindergarten.   1 School offers kindergarten and at least another grade between first grade and twelfth grade. NOTE: School characteristics (i.e., region, locale, school affiliation, and school type) describe the school the child attended in kindergarten. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), fall 1999 and spring 2000."}, {"section_title": "4-13", "text": ""}, {"section_title": "Child Freshening", "text": "The spring-first grade child freshening used a half-open interval sampling procedure (Kish 1965). The procedure was implemented in the same 50 percent subsample of ECLS-K base-year schools in which transfer children were flagged for follow-up. Each of these schools was asked to prepare an alphabetized roster of children enrolled in first grade, and the names of ECLS-K kindergarten-sampled children were identified on this list. Beginning with the name of the first kindergarten-sampled child, school records were checked to see whether the child directly below in the sorted list attended kindergarten in the United States in fall 1998. If not, (1) that child was considered to be part of the freshened sample and (2) the record search procedure was repeated for the next listed child, and so forth. When the record search revealed that a child had been enrolled in kindergarten the previous year, that child was not considered part of the freshened sample and the procedure was begun all over again with the second base-year sampled child name, and so on. Note: the child roster was \"circularized\" (i.e., the first name on the roster was considered to follow the last name on the roster in the implementation of the procedure). Child freshening brought 165 first-graders into the ECLS-K sample, which increased the weighted survey estimate of the number of first-graders in the United States by about 2.6 percent. The child freshening procedure was not entirely free of bias. A first-grader would have no chance of being in the ECLS-K first-grade sample if he or she was enrolled in a school where neither the 4-15 child nor any of his or her classmates had attended kindergarten in the United States in the fall of 1998. However, this would be a rare circumstance and is not thought to be an important source of bias. A more significant source of potential bias is nonresponse. One source of nonresponse inherent to the freshening plan was that the procedure only involved children who had not transferred from the school in which they had been sampled during the base year. A more detailed discussion of freshened child nonresponse can be found in section 5.7.2 of the ECLS-K User's Manual for the ECLS-K First Grade Public-Use Data Files and Electronic Codebook (NCES 2002-135) (Tourangeau et al. 2002)."}, {"section_title": "Spring-Third Grade Sample", "text": "The sample of children for spring-third grade consists of all children who were base-year respondents and children who were brought into the sample in spring-first grade through the sample freshening procedure described in section 4.3.2. Sample freshening was not implemented in third grade, hence no new children entered the sample. While all children still enrolled in their base-year schools were recontacted, slightly more than 50 percent of the base-year sampled children who had transferred from their kindergarten school were followed for data collection. This subsample of children was the same 50 percent subsample of base-year movers flagged for following in spring-first grade, with the addition of movers whose home language was not English (language minority children). The two special sampling procedures implemented in spring-third grade are described below."}, {"section_title": "Language Minority Children", "text": "In addition to the subsample of movers to be followed described above, children whose home language was not English and who moved between spring-first grade and spring-third grade were all retained rather than being subsampled at the 50 percent rate. Operationally, this means that children whose home language was not English who were not flagged for follow-up in the previous round had their flags switched from \"not to be followed\" to \"to be followed.\" This mover flag was set in first grade to specify whether a child was to be followed if he or she moved from the kindergarten school at any point in the future. This affects only language minority children who had not moved out of the original sample schools before third grade. If they had moved before third grade, then their flags were not switched and they continued not to be followed. This modification to the mover follow-up procedure provides a larger sample of children whose home language is not English. The mover follow-up activities that originally targeted a 50 percent subsample of children in base-year schools resulted in a 54 percent subsample with the addition of language minority children. Table 4-7 shows the characteristics of eligible children in the spring-third grade sample, excluding freshened children. Region, locale, school affiliation, and school type describe the school at which the child attended kindergarten.   "}, {"section_title": "4-17", "text": ""}, {"section_title": "Spring-Fifth Grade Sample", "text": "In fifth grade, four groups of children were not followed, irrespective of other subsampling procedures that were implemented. They are (1) children who became ineligible in an earlier round (because they died or moved out of the country), (2) children who were subsampled out in previous rounds because they moved out of the original schools and were not subsampled to be followed, children whose parents emphatically refused to cooperate (hard refusals) in any of the data collection rounds since spring-kindergarten, and (4) children eligible for the third-grade data collection for whom there were neither first-grade nor third-grade data. Among the 21,357 children who were eligible for the study after the base year, 5,214 were excluded from the fifth-grade survey, and they are distributed as shown in table 4-8. 1 Characteristics are from the most recent data available for the child (e.g., if a child was not subsampled in third grade and had data from first grade, then the characteristics of the child come from first grade). "}, {"section_title": "4-19", "text": ""}, {"section_title": "4-20", "text": "Of the remaining children, those who moved from their original schools during fifth grade or earlier were subsampled for follow-up. In order to contain the cost of data collection, the rate of subsampling was lower in fifth grade than it had been in previous years. The subsampling rates maximize the amount of longitudinal data available for key analytic groups. Children whose home language is not English (language minority) continued to be a special domain of analytic interest and were subsampled at higher rates. Children were subsampled at different rates depending on the longitudinal data available for those children. For base-year respondents, the sampling rates for following movers were as follows: These rates are different than those used in third grade where movers were subsampled uniformly at a rate of 0.5, and language minority children were followed at 100 percent (unless they were already subsampled out in first grade). The mover follow-up activities that originally targeted a 50 percent subsample of children in base-year schools resulted in a 54 percent subsample with the addition of 4-21 language minority children in third grade. For fifth grade, these mover follow-up activities targeted a 42 percent subsample of movers who were eligible to be fielded in fifth grade and resulted in a 41 percent subsample. Table 4-9 shows the characteristics of eligible children in the spring-fifth grade sample, excluding freshened children. Region, locale, school affiliation, and school type describe the school at which the child attended kindergarten. A new feature of the fifth-grade sample was the subsampling of children for the administration of the mathematics or science questionnaires. While all children retained for the fifth-grade data collection had child-level questionnaires filled out by their reading teachers, half were subsampled to have child-level questionnaires filled out by their mathematics teachers and the other half had child-level questionnaires filled out by their science teachers.   1 School offers kindergarten and at least another grade between first grade and twelfth grade. NOTE: School characteristics (i.e., region, locale, school affiliation, and school type) describe the school the child attended in kindergarten. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECSL-K), spring 2004."}, {"section_title": "4-22", "text": ""}, {"section_title": "4-23", "text": ""}, {"section_title": "Eighth-Grade Sample", "text": "The sample design for eighth grade called for including all 12,129 children eligible after fifth grade (regardless of their fifth-grade response status), and following all movers without any subsampling. In the ECLS-K first-grade to fifth-grade data collections, subsampling of movers was used to reduce data collection costs. The initial sample size was developed taking into account the reduction in sample size and increase in the variability of the weights of the respondents resulting from the subsampling. As the design was extended beyond fifth grade (the initial planning of the ECLS-K did not plan for this extension into eighth grade), a change in the methods of handling movers to avoid subsampling them was needed to achieve the major analytic goals. The vast majority of children were not in the same school from kindergarten to eighth grade (having moved out of elementary schools into middle schools), and subsampling these movers would result in substantial losses in sample size and precision of the estimates for the eighth grade. Table 4-10 shows the characteristics of eligible children in the spring-eighth grade sample, excluding freshened children. Region, locale, school affiliation, and school type describe the school in which the child attended kindergarten."}, {"section_title": "4-24", "text": ""}, {"section_title": "Sample Attrition", "text": "In a longitudinal study, sample attrition due to nonresponse and change in eligibility status is expected. The sample of respondents decreases with each round of data collection. In the case of the ECLS-K, a combination of field and sampling procedures was applied that caused the sample to increase after the fall-kindergarten data collection, but then decrease in each subsequent round. The first procedure was the school-level refusal conversion in spring-kindergarten, resulting in a number of schools that agreed to participate in the study after having refused to do so in the previous round. From these schools, 1,426 children were sampled and added to the initial sample of 21,387 kindergarten children. The second procedure was sample freshening in spring-first grade as described in section 4.3.2. This brought in 165 eligible children to add to the sample of 21,192 base-year respondents who remained eligible after the base year. A base-year responding child was defined as one with at least one direct cognitive test score in fall-or spring-kindergarten or whose parent responded to the family structure section of the parent instrument in fall-or spring-kindergarten. The third procedure-applied in first, third, and fifth grades-required that a subsample of children who moved out of their original sample schools not be followed into their new schools, as described in sections 4.3.1 and 4.4.1, resulting in a decrease in the sample. The fourth and last procedure, applied in fifth grade only, is the exclusion from the data collection of children who were difficult to field, as described in section 4.5, also resulting in a significant decrease in the sample. Table 4-11 shows the sample size for each round of data collection of the ECLS-K, and the response status of the children in each round. Tables 4-12 and 4-13 show the same children separately by the original sample school affiliation (public/private).   1 School offers kindergarten and at least another grade between first grade and twelfth grade. NOTE: School characteristics (i.e., region, locale, school affiliation, and school type) describe the school the child attended in kindergarten. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECSL-K), spring 2007.  of children in the ECLS-K sample, by response status and data collection round: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 Response status  1 1,426 children were sampled from refusal-converted schools. 2 21,192 children remained eligible after the base year. In addition, 165 children were sampled via the sample freshening procedure. 3 5,214 children were excluded from the fifth-grade data collection. They were children who became ineligible in an earlier round, movers not subsampled to be followed in previous rounds, hard-to-field cases such as hard refusals, and children with neither first-grade nor third-grade data. 4 12,129 fifth-grade respondents and eligible respondents were eligible for the eighth-grade data collection. NOTE: Response status is defined in terms of completed child assessment OR completed family structure data of the parent interview. Children who died or moved out of the country were classified as ineligible. Children who moved and were subsampled for follow-up but could not be located were treated as belonging to the unknown eligibility category. A portion of children who moved was subsampled out and not followed into their new schools. The numbers of children in this table are different than in tables 4-3 to 4-7 and table 4-9 since the earlier tables include only eligible children. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), fall 1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007.  1998-99, 1999-2000, 2001-02, 2003-04, and 2006-07 Response status  2 16,638 public school children remained eligible after the base year. In addition, 146 public school children were sampled via the sample freshening procedure. 3 4,013 children from the original sample of public schools were excluded from the fifth-grade data collection. They were children who became ineligible in an earlier round, movers not subsampled to be followed in previous rounds, hard-to-field cases such as hard refusals, and children with neither first-grade nor third-grade data. 4 9,655 fifth-grade respondents and eligible respondents from the original sample of public schools were eligible for the eighth-grade data collection. NOTE: Response status is defined in terms of completed child assessment OR completed family structure data of the parent interview. Children who died or moved out of the country were classified as ineligible. Children who moved and were subsampled for follow-up but could not be located were treated as belonging to the unknown eligibility category. A portion of children who moved was subsampled out and not followed into their new schools. The numbers of children in this table are different than in tables 4-3 to 4-7 and table 4-9 since the earlier tables only include eligible children. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), fall 1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007.  of private school children in the ECLS-K sample, by response status and data collection round: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 Response status  2 4,554 private school children remained eligible after the base year. In addition, 19 private school children were sampled via the sample freshening procedure. 3 1,201 children from the original sample of private schools were excluded from the fifth-grade data collection. They were children who became ineligible in an earlier round, movers not subsampled to be followed in previous rounds, hard-to-field cases such as hard refusals, and children with neither first-grade nor third-grade data. 4 2,474 fifth-grade respondents and eligible respondents from the original sample of private schools were eligible for the eighth-grade data collection. NOTE: Response status is defined in terms of completed child assessment OR completed family structure data of the parent interview. Children who died or moved out of the country were classified as ineligible. Children who moved and were subsampled for follow-up but could not be located were treated as belonging to the unknown eligibility category. A portion of children who moved was subsampled out and not followed into their new schools. The numbers of children in this table are different than in tables 4-3 to 4-7 and table 4-9 since the earlier tables include only eligible children. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), fall 1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007. The number of children who participated in all five years of the ECLS-K data collection (base year, first grade, third grade, fifth grade, and eighth grade) is 8,706 (6,911 in original public schools and 1,795 in original private schools). This represents 41 percent of the base-year respondents or 38 percent of children sampled for the base year."}, {"section_title": "4-25", "text": ""}, {"section_title": "4-26", "text": ""}, {"section_title": "4-27", "text": ""}, {"section_title": "Calculation and Use of Sample Weights", "text": "As in previous years, the ECLS-K data were weighted to compensate for differential probabilities of selection at each sampling stage and to adjust for the effects of nonresponse. In the ECLS-K base year, weights were computed at the child, school, and teacher levels. Estimates using the base-year weights are representative of all kindergarten children, all schools with kindergarten programs and all kindergarten teachers. After the base year, only child-level weights were computed. The use of these weights is essential to produce estimates that are representative of the cohort of children who were in kindergarten in 1998-99 or in first grade in 1999-2000. Since the sample was not freshened after the 4-29 first-grade year with third-, fifth-or eighth-graders who did not have a chance to be sampled in kindergarten or first grade (as was done in first grade), estimates from the ECLS-K third-, fifth-, and Several sets of weights were computed for eighth grade. As in previous years, there are several survey instruments administered to sampled children and their parents, teachers and schools: cognitive and physical assessments for children; student questionnaires (third, fifth and eighth grade only); parent instruments; several types of teacher instruments completed by reading or English, mathematics, science, and special education teachers; and school instruments. The stages of base-year sampling in conjunction with differential nonresponse at each stage and the diversity of survey instruments require that multiple eighth-grade cross-sectional sampling weights be computed for use in analyzing the eighth-grade ECLS-K data, as was the case with previous rounds of data collection. Several combinations of kindergarten through eighth-grade longitudinal weights were also computed. Details on these longitudinal weights are available in chapter 9 and in chapter 10 for users of the K-8 full sample public-use data file. This section describes the different types of eighth-grade cross-sectional weights, how they were calculated, how they should be used, and their statistical characteristics."}, {"section_title": "4-30", "text": ""}, {"section_title": "Types of Cross-Sectional Sample Weights", "text": "As in fifth grade, five sets of cross-sectional weights were computed for children in the eighth-grade sample. These weights are defined as follows: C7CW0 is nonzero if assessment data or student questionnaire data are present (or the child was excluded from direct assessment due to a disability). C7PW0 is nonzero if parent interview data are present. C7CPTE0 is nonzero if assessment data or student questionnaire data are present (or the child was excluded from direct assessment due to a disability), and parent interview data, and teacher-level data from the English teacher are present. C7CPTM0 is nonzero if the child was sampled to have a child-level questionnaire completed by the mathematics teacher, and assessment data or student questionnaire data are present (or the child was excluded from direct assessment due to a disability), and parent interview data, and teacher-level data (either from the English teacher or the mathematics teacher) are present. C7CPTS0 is nonzero if the child was sampled to have a child-level questionnaire completed by the science teacher, and assessment data or student questionnaire data are present (or the child was excluded from direct assessment due to a disability), and parent interview data, and teacher-level data (either from the English teacher or the science teacher) are present. If the child has only subject-specific child-level data from the teacher (English, mathematics, or science) but no data from the teacher-level questionnaire, then the child is considered a nonrespondent for the CPT weights, and hence has none of the CPT weights. Prior to the fifth-grade data collection, only one child-parent-teacher weight was computed based on the presence of the teacher questionnaire B (teacher-level). With the addition beginning in fifth grade of the subject-specific questionnaires filled out by teachers for each child in the ECLS-K sample, and the subsampling of children for the administration of the mathematics and science teacher questionnaires, three child-parent-teacher weights were computed. They are used to analyze direct child assessment data combined with parent interview data and data provided by the subject-specific teacher (child-and/or teacher-level data) with or without school-level data, as described below. Careful consideration should be given to the choice of a weight for a specific analysis since it depends on the type of data analyzed. Each set of weights is appropriate for a different set of data or 4-31 combination of sets of data. Exhibit 4-1 summarizes how the different types of cross-sectional weights should be used. Cross-sectional weights are used to provide estimates for the eighth-grade data collection. Details under \"to be used for analysis of . . .\" provide guidance based on whether the data to be used with the weights were collected through the child assessments, parent interviews, or different types of teacher questionnaire. Exhibit 4-1. ECLS-K eighth-grade cross-sectional weights: School year 2006-07"}, {"section_title": "Weight", "text": "To be used for analysis of ...\nTo be used for analysis of ...\nTo be used for analysis of ..."}, {"section_title": "C7CW0", "text": "child direct assessment or student questionnaire data from spring-eighth grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-eighth grade teacher questionnaire (teacherlevel or child-level), or (c) data from the spring-eighth grade school administrator questionnaire. C7PW0 parent interview data from spring-eighth grade, alone or in combination with (a) springeighth grade child assessment or student questionnaire data, (b) data from any springeighth grade teacher questionnaire (teacher-level or child-level), or (c) data from the spring-eighth grade school administrator questionnaire. Exception: If data from the parent interview AND child assessments AND teacher-level (with or without child-level teacher) questionnaires are used together, then C7CPTE0, C7CPTM0, or C7CPTS0 should be used."}, {"section_title": "C7CPTE0", "text": "child direct assessment or student questionnaire data from spring-eighth grade with spring-eighth grade parent interview data and spring-eighth grade English teacher-level data with or without child-level data from the English teacher, alone or in combination with data from the spring-eighth grade school administrator questionnaire."}, {"section_title": "C7CPTM0", "text": "child direct assessment or student questionnaire data from spring-eighth grade with spring-eighth grade parent interview data and spring-eighth grade English or mathematics teacher-level data with or without child-level data from the mathematics teacher, alone or in combination with data from the spring-eighth grade school administrator questionnaire. This weight is to be used only if the analytic sample is restricted to the subset of children who were sampled to have a mathematics teacher questionnaire. C7CPTS0 child direct assessment or student questionnaire data from spring-eighth grade with spring-eighth grade parent interview data and spring-eighth grade English or science teacher-level data with or without child-level data from the science teacher, alone or in combination with data from the spring-eighth grade school administrator questionnaire. This weight is to be used only if the analytic sample is restricted to the subset of children who were sampled to have a science teacher questionnaire. child's weight. These weights should not be used for estimates solely using direct child assessment data but should be used when analyzing parent and child assessment data together. For example, they should be used when exploring the relationship between home literacy behaviors and children's reading skills. When analyzing child assessment data in conjunction with teacher data and parent data, one of the three child-parent-teacher weights should be used. C7CPTE0 should be used if teacher-level data from the English teacher are analyzed with or without child-level data from the English teacher. Note that the teacher-level questionnaire can be completed by more than one teacher (English and/or mathematics; or, English and/or science). Therefore, C7CPTM0 should be used if teacher-level data from the English or mathematics teacher are analyzed with or without child-level data from the mathematics teacher. Likewise, C7CPTS0 should be used if teacher-level data from the English or science teacher are analyzed with or without child-level data from the science teacher. Weight C7CW0 may be used when analyzing child assessment data in conjunction with English teacher-level data alone. In this case, some data may be missing because some teachers did not complete the questionnaire, but these are the most appropriate weights for this type of analysis. Here are some examples of how the child-parent-teacher weights may be used. C7CPTE0 is used when child direct assessment or student questionnaire data and parent data and English teacher-level data with or without child-level data from English teachers are combined in an analysis; for example, in the analysis of the relationship between parent education, teacher education, and children's reading 4-33 knowledge and skills. If it is the children's mathematics knowledge and skills as reported by the teacher that are analyzed, then C7CPTM0 should be used. Likewise, C7CPTS0 should be used if children's science knowledge and skills as reported by the teacher are combined with direct assessment, parent, and teacher-level data. These weights should not be used for estimates using only direct child assessment data or only parent interview data. Careful consideration should be given to which set of weights is appropriate for the desired analysis. Using the wrong weights will result in more biased or inefficient estimates (because the weighting adjustments were not correctly accounted for in the estimates). For example, if C7CPTE0 were used in an analysis of child-and teacher-level data only, then the resulting estimates will be inefficient compared to estimates using C7CW0. The lower parent response causes C7CPTE0 to result in a smaller sample with positive weights. If using C7CPTE0 with child-level data from the questionnaire filled out by the mathematics teacher, then there will be missing mathematics-related data for approximately half of the children. There may be combinations of data for which no weights were specifically developed, but all analyses should incorporate whichever weight that matches most closely."}, {"section_title": "Weighting Procedures", "text": "Two features of the eighth-grade sample design that are different from previous grades are that (1) only fifth-grade respondents and eligible nonrespondents were included in the eighth-grade sample and (2) children who changed schools between fifth and eighth grade were not subsampled out but were all followed into their new school. However, a feature of the fifth-grade sample whereby children were subsampled for the administration of the mathematics or science questionnaires as discussed in section 4.5 was retained for eighth grade. The mathematics and science teacher questionnaires were administered to the same halves of the sample as was done in fifth grade. This is to allow for longitudinal analyses of data from the mathematics and science teacher questionnaires. The same subsamples of children selected for these two instruments in the fifth grade were maintained for eighth grade, i.e., children who had been assigned to have mathematics teacher questionnaires in fifth grade had mathematics teacher questionnaires in eighth grade, and likewise for the science teacher questionnaire. These features of the design are taken into account in the weighting. The weighting procedures were divided into three main stages.\nThis section presents the statistical procedures used to produce the K-8 longitudinal weights. These procedures are nearly identical to the procedures used for the cross-sectional weights (see chapter 4). The differences are primarily in how eligible respondents are defined, and in how adjustment cells are created. For example, in computing weight C67CW0, a respondent was defined as a child for whom both cross-sectional weights, C6CW0 and C7CW0, are nonzero. A child with a nonzero C67CW0 had both spring-fifth grade and spring-eighth grade scorable cognitive assessment data, or was excluded from the cognitive assessments because he or she was a child with disabilities. Longitudinal weights involving the fall-first grade data collection were computed differently to adjust for the fact that only a subsample of children was included in fall-first grade."}, {"section_title": "4-34", "text": "The starting point for the eighth-grade child weight is the fifth-grade child weight before adjustment for fifth-grade child nonresponse. It includes the following: adjustment of the school base weight for base-year school-level nonresponse; adjustment of the child weights for base-year child-level nonresponse; adjustment of the base-year child weight for subsampling of schools for freshening in first grade (for children sampled in first grade only); adjustment for fifth-grade mover subsampling; and adjustment for fifth-grade unknown eligibility status. Except for the last two adjustments, this starting weight is the same in all rounds of data collection after the base year because the same sample of children (base-year respondents and children sampled in first grade) was eligible for subsequent rounds of data collection. The starting weight was extracted from the first-grade weighting file to be used in eighth grade. The procedures used for computing these weights are described again in section 4.8.3 for completeness. The second stage of weighting was to adjust the initial child weight computed in the first stage for the following: eighth-grade unknown eligibility status; and eighth-grade child-level nonresponse. For the mathematics and science child-parent-teacher weights, an additional adjustment was necessary (before the second-stage adjustment for nonresponse) to adjust for the subsampling of children for whom mathematics or science teacher data questionnaires were administered. The third and last stage was to rake the weights adjusted in the second stage to sample-based control totals. Raking is a multivariate poststratification of the weights, explained in section 4.8.4.2. The computation of the initial child weights is described in section 4.8.3. The subsequent weight adjustments are described in section 4.8.4. Section 4.8.5 describes the different types of weights computed for spring-eighth grade."}, {"section_title": "4-35", "text": "In general, in each adjustment to the weight, the adjustment factor is multiplied by the weight in the prior step to get the adjusted weight. This fact is not repeated in the discussions of the weight adjustments in the following sections; only the computation of the adjustment factor is discussed."}, {"section_title": "Computation of Spring-Eighth Grade Initial Child Weights", "text": "As mentioned earlier, the first stage of weighting was to compute an initial child weight that reflects: (1) the adjustment of the school base weight for base-year school-level nonresponse (school-level weights), (2) the adjustment of the child weights for base-year child-level nonresponse (child-level weights), (3) the adjustment of the base-year child weight for subsampling of schools for freshening in first grade (child-level weights, for children sampled in first grade only), (4) the adjustment for fifth-grade mover subsampling, and 5the adjustment for fifth-grade unknown eligibility status. These weights were already computed for spring-fifth grade. For completeness, they are described below, in section 4.8.3.1 for the school-level weights, and in section 4.8.3.2 for the child-level weights."}, {"section_title": "Base-Year Nonresponse-Adjusted School Weights", "text": "This weight is the same as that computed for the first-grade data collection. It was computed as the school base weight adjusted for base-year school-level nonresponse. The base weight for each school was the inverse of the probability of selecting the PSU (county or group of counties), multiplied by the inverse of the probability of selecting the school within the PSU. For schools selected in the base year through the frame freshening procedure, an additional factor equal to the inverse of the selection probability of the district or diocese was included in the base weight. See section 4.1 for a description of how schools were selected as part of the frame freshening procedure. A base-year responding school was an original sample school with at least one child with a positive C1CW0, C2CW0, C1PW0, or C2PW0 weight. C1CW0 is positive for LM/not Spanish children, children with disabilities, and children with at least one direct cognitive test score in fall-kindergarten. C1PW0 is positive for children whose parents completed the family structure questions of the parent interview in fall-kindergarten. C2CW0 and C2PW0 weights are positive under similar circumstances except for spring-kindergarten. Schools that did not meet this condition are nonrespondents and their weights distributed across responding units (at the school level) in this stage. The base-year school weight 4-36 was adjusted within nonresponse weighting classes created in the base year using the Chi-Squared Automatic Interaction Detector (CHAID) and variables with known values for both respondents and nonrespondents. School characteristics used for constructing nonresponse cells were the school affiliation (public, Catholic, non-Catholic religious, or nonreligious private), the school locale (large city, midsize city, suburb of large city, suburb of midsize city, large town, small town, or rural area), the region where the school was located (Northeast, Midwest, South, or West), and the size classification of the school in terms of school enrollment. Once the weighted nonresponse cells were determined, the nonresponse adjustment factors are the reciprocals of the response rates within the selected nonresponse cells."}, {"section_title": "Base-Year Child Weights", "text": "As mentioned earlier, two groups of children were fielded in spring-third grade: base-year respondents and eligible children who were sampled in first grade as part of the sampling freshening procedure. The base-year child weights for the two groups were the same as those computed for the firstgrade year. A description of them follows. Base-year child weights for base-year respondents. As previously described, a base-year respondent was defined as one with at least one direct cognitive test score in fall-or spring-kindergarten (or who was excluded from assessment because of a disability or because the child belonged in the language minority/not Spanish group), or whose parent responded to the family structure section of the parent instrument in fall-or spring-kindergarten. In terms of weights, a base-year respondent is a sampled child with a positive fall-or spring-kindergarten weight (i.e., C1CW0, C2CW0, C1PW0 or C2PW0 weights). The base-year child weight is the product of the base-year nonresponse-adjusted school weight and the inverse of the within-school selection probability of the child, adjusted for child-level nonresponse. The nonresponse weighting classes included school characteristics from the school nonresponse adjustments such as school affiliation, locale, region, school enrollment class, and child characteristics such as age group, sex, and race/ethnicity. These weighting classes are similar to those used for the original child weights in fall-and spring-kindergarten. For a description of the computation of child weights in fall-and spring-kindergarten, see chapter 4, section 4."}, {"section_title": "of the ECLS-K Base Year", "text": "Public-Use Data Files and Electronic Codebook: User's Manual (NCES 2001-029rev) (Tourangeau, Burke et al. 2004)."}, {"section_title": "4-37", "text": "Base-year child weights for eligible children sampled in first grade. Since each child sampled in first grade was directly linked to a child sampled in kindergarten, the first step was to compute a weight for the children who were sampled in kindergarten that reflected the school freshening subsampling and the school freshening nonresponse (some schools refused to provide information needed for freshening). This weight was then assigned to the child sampled in first grade and further adjusted for nonresponse due to not obtaining the data from the sample of freshened children (i.e., children sampled in first grade). Part 1: School weight adjusted for subsampling of schools for freshening. First the school base-year weight adjusted for school nonresponse (as described in section 4.8.3.1) was adjusted for the subsampling of schools for freshening. Child freshening was done in the same 50 percent subsample of schools that were flagged for following movers in spring-first grade. The school freshening subsampling adjustment factor was computed as follows: 0 if the school was not in the set of schools subsampled for freshening; 21 and the sum of base-year nonresponse-adjusted school weights for all schools over the sum of base-year nonresponse-adjusted school weights for schools subsampled for freshening, if the school was in the set of schools subsampled for freshening. This adjustment was done within cells defined by school affiliation and census region. Part 2: School weight adjusted for freshening nonresponse. The freshening procedure could not be applied in all designated schools because some schools did not provide the information needed for freshening. These schools are considered freshening nonrespondents. The school weight adjusted for freshening subsampling was then adjusted for this type of nonresponse. The school freshening nonresponse adjustment factor was calculated as the sum of weights of the freshening-adjusted school weights for all schools designated for freshening over the sum of weights of the freshening-adjusted school weights for schools that responded to freshening. In both the numerator and denominator of this factor, the school measure of size was incorporated; the school measure of size is relevant because the weights will be used for child-level estimates, not school-level estimates. The nonresponse cells for this adjustment were created using school affiliation and urbanicity. Part 3: Base-year child weight. The school-adjusted weight was multiplied by the inverse of the within-school selection probability of the child in the base year to obtain a base-year child weight. The base-year child weight was then adjusted for base-year child nonresponse because children who did not respond in the base year could not be linked to children in first grade in spring 2000. The adjustment factor was computed as the sum of the base-year child weights of all base-year children over the sum of the base-year child weights of base-year respondents within each nonresponse cell. The nonresponse cells were created using school characteristics such as school affiliation, locale, region, school enrollment class, and child characteristics such as age group, sex, and race/ethnicity. Part 4: Base-year child weight adjusted for movers. Only children who did not move from their original schools were designated as links to children in the freshening procedure. The children who moved and were followed into their new schools were not identified to participate in the freshening process in their new schools. As a result, all the children who moved were considered nonrespondents to the freshening process. Additionally, nonmovers and movers who were not in first grade were not eligible for freshening (e.g., if a child was in kindergarten in spring 2000, he or she would be linked only to other kindergarten children and thus was not eligible for the freshening of first-graders). Adjustment was necessary to account for these two groups of children and was done in two steps. In the first step, adjustment was done for movers whose grade was unknown. A portion of the movers was assumed to be in first grade. In the second step, the weights were adjusted for children who were in first grade but who were not identified to participate in the freshening process because they had moved into a new school. For this two-step adjustment, each child was classified as: (a) mover in first grade, (b) mover in another grade, (c) mover with unknown grade, (d) nonmover in first grade, and (e) nonmover in another grade. The first-step adjustment for movers whose grade was unknown was computed as follows: 0 if the child was a mover with unknown grade (group c); 1 if the child was a nonmover, in first grade or in another grade (group d or e); and the sum of the nonresponse-adjusted base-year child weights (computed in part 3) of all movers (group a, b, or c) over the sum of the nonresponse-adjusted base-year child weights of movers with known grade (group a or b), if the child was a mover with known grade (group a or b)."}, {"section_title": "4-39", "text": "The second-step adjustment for movers who could not be used as links for freshening was computed as follows: 0 if the child was a first-grade mover (group a); 1 if the child was in a grade other than first grade (group b or e); and the sum of the weights adjusted in the first step of part 4 of all first-graders (group a or d) over the sum of the weights adjusted in the first step of part 4 of nonmovers in first grade (group d), if the child was a nonmover in first grade (group d). This two-step adjustment was done within cells defined by school affiliation and census region. The weights thus created for children sampled in kindergarten were then linked to the children who were brought into the sample in first grade through sample freshening. In other words, the weight of the child sampled in first grade was defined at this point to be the weight computed for the child sampled in kindergarten that was responsible for bringing the first-grader into the sample. For the next step in the computation of the spring-first grade child weights, the two groups of children-base-year respondents and children sampled in first grade through sample freshening-were put together, and a common variable and label were used to designate the initial child weight. This is the base-year child weight as computed above for each group of children. Base-year child weights adjusted for fifth-grade mover subsampling and fifth-grade unknown eligibility. First, the base-year child weights were adjusted to reflect the subsampling of movers in fifth grade. In the ECLS-K, a child could move more than once and at different times. For example, a child could move out of his or her original sample school because the school did not have grades higher than kindergarten. Then he or she could move again between first and third grade, first and fifth grade, or third and fifth grade. Once a child was identified as a mover, he or she stayed a mover unless he moved back to the original sample school. For example, a child who moved between kindergarten and third grade, but stayed in that same school between third and fifth grade, was considered a mover for the fifth grade. Each mover in the fifth grade had a flag indicating whether he or she was followed into the new school. These flags were set according to the mover subsampling plan described in section 4.5."}, {"section_title": "4-40", "text": "Children who were excluded from the fifth-grade data collection because they moved out of the original schools and were subsampled out for follow-up in previous rounds had their flag set to \"not followed.\" In fifth grade, children were fielded as described in exhibit 4-2. The base-year child weight was adjusted to reflect the subsampling of fifth-grade movers. The adjustment factor for subsampling movers (who moved before or during fifth grade) was computed as follows: 1 if the child was not a mover; 0 if the child was a mover and the value of the follow flag was 0 (i.e., not to follow); and the sum of initial child weights of children who were movers over the sum of initial child weights of children who were movers and whose follow flags have value 1, if the child was a mover whose follow flag has value 1. For the third category, the adjustment factor was computed within cells created using the following characteristics: whether children were sampled in kindergarten or first grade, and whether they were language minority children. Note that for the computation of the fifth-grade final weights, large mover adjusted weights for 12 children were trimmed by 40 percent, and the excess weight was not redistributed at this step since the total sum of weights was re-established later at the raking step of the fifth-grade final weights. For eighth grade, it was the untrimmed mover-adjusted weight that was used, so that the excess weight was not discarded at this point."}, {"section_title": "4-41", "text": "After the adjustment for subsampling movers, the child weights were adjusted for fifth-grade children whose eligibility was unknown (since subsampled out movers and children of unknown eligibility in fifth grade were not included in the eighth-grade sample). In fifth grade, a portion of children of unknown eligibility was assumed to be ineligible, equal to the proportion of children of known eligibility who were ineligible. To carry out this adjustment, each fifth-grade child was classified as (a) an eligible respondent, (b) an eligible nonrespondent, (c) ineligible (out of the country or deceased) or (d) of unknown eligibility (mover who could not be located). The adjustment factor for children of unknown eligibility) was computed as follows: 0 if the child was of unknown eligibility (group d); and the sum of the mover adjusted weights of all children (any group) over the sum of the mover adjusted weights of children who were eligible respondents, eligible nonrespondents, or ineligible (group a, b, or c), if the child was not of unknown eligibility."}, {"section_title": "4.8.4", "text": "Computation of Spring-Eighth Grade Child Weights"}, {"section_title": "Adjustment for Unknown Eligibility and Nonresponse", "text": "The initial child weights described in section 4.8.3 were adjusted for nonresponse in eighth grade, and raked to sampled-based control totals to obtain the final spring-eighth grade child weights. The eighth-grade initial child weights described in section 4.8.3 were adjusted for eighthgrade nonresponse. As in previous years, the nonresponse adjustment was done in two steps. In the first step, the adjustment was for children whose eligibility was not determined (unknown eligibility). A portion of children of unknown eligibility was assumed to be ineligible, equal to the proportion of children of known eligibility who were ineligible. In the second step, the adjustment was for eligible nonrespondents. To carry out these adjustments, each child was classified as (a) an eligible respondent, The second adjustment factor (for eligible nonrespondents) was computed as follows: 0 if the child was an eligible nonrespondent (group b); and the sum of the weights adjusted in the first step of eligible children (group a or b) over the sum of the weights adjusted in the first step of eligible responding children (group a), if the child was an eligible respondent. In both steps of the adjustment, separate nonresponse classes were created using fifth-grade moving status (all cross-sectional weights); response status of the child assessment and parent interview in the previous rounds (C7CW0 and C7PW0); the race/ethnicity of the child (C7CW0 and C7PW0); whether the child belonged to the language minority group (all cross-sectional weights); the type of household collected from the parent interviews (all cross-sectional weights except C7CW0); and the school affiliation including whether the child was homeschooled (C7CPTE0, C7CPTM0 and C7CPTS0 only). After nonresponse adjustment and prior to raking, very large weights were trimmed but not redistributed because the sum of weights was re-established after raking, described in section 4.8.4.2 below."}, {"section_title": "Raking to Sample-Based Control Totals", "text": "To reduce the variability due to the subsampling of schools and movers in fifth grade, the child weights were then raked to sample-based control totals computed using the initial child weights computed as described in section 4.8.3. The child records included in the file used for computing the control totals are records of fifth-grade respondents, eligible nonrespondents, and ineligible children. Records of fifth-grade ineligibles were part of raking in fifth grade, and needed to be included in the file for computing control totals for eighth grade (even though they were not eligible for eighth grade) in order for the sum of weights to be the estimated number of children who were in kindergarten in 1998-99 or in first grade in 1999-2000."}, {"section_title": "4-43", "text": "In the nonresponse adjustment step, the weights of the eighth-grade nonresponding children were distributed to the eighth-grade responding children while the weights of the eighth-grade ineligible children were not affected. At the end of raking, the weights of the ineligible children are nonzero, but will be set to zero because these children are not included in the analysis of the spring-eighth grade data. The reason for including the ineligible children in the raking step is that these children were included in the sample-based control totals. The raking factor was computed separately within raking cells as the sample-based control total for the raking cell over the sum of the nonresponse-adjusted weights for children in the same cell. Raking cells (also known as raking dimensions) were created using school and child characteristics collected in the base year or first-grade year: school affiliation, census region, urbanicity, sex, age, race/ethnicity, socioeconomic status (SES), language minority status, whether sampled in kindergarten or first grade, and, if sampled in kindergarten, mover status."}, {"section_title": "Additional Adjustment for Child-Parent-Teacher Cross-Sectional Weights", "text": "In all three child-parent-teacher weights described in section 4.8.1, the presence of at least one completed teacher-level questionnaire is the factor that determines whether the child would have a positive child-parent-teacher weight in the two subjects to which he or she was assigned (i.e., English and mathematics, or English and science). A child could have one teacher who taught all subjects, in which case the teacher was asked to fill out both the English questionnaire and the mathematics questionnaire (if the child was selected for mathematics) or science questionnaire (if the child was selected for science). A child could also have different teachers teaching different subjects, in which case the child might have an English teacher filling out the English questionnaire and a mathematics teacher filling out the mathematics questionnaire, and both teachers could have filled out the teacher-level questionnaire. Because of the subsampling, no children had teachers who completed both the mathematics and the science questionnaires.    An additional adjustment is necessary to adjust for the subsampling of children for whom mathematics or science teacher data questionnaires were administered. For the child-parent-mathematics teacher weight, this adjustment (before adjustment for movers and nonresponse adjustments, described in sections 4.8.4.1 and 4.8.4.2, respectively) was computed as follows: 0 if the child was sampled for science rather than mathematics; and the sum of the initial child weights of all children over the sum of the initial child weights of children who were sampled for mathematics questionnaires. Similarly, for the child-parent-science teacher weight, this adjustment was computed as follows: 0 if the child was sampled for mathematics rather than science; and the sum of the initial child weights of all children over the sum of the initial child weights of children who were sampled for science questionnaires."}, {"section_title": "Types of Cross-Sectional Weights and Their Use", "text": "The different types of cross-sectional weights are described in section 4.   "}, {"section_title": "Cross-Sectional Weights To Be Used With Parent Data (C7PW0)", "text": "The weight C7PW0 is to be used with parent interview data. In spring-eighth grade, a respondent was defined as a child for whom the family structure section (FSQ) in that child's parent 4-47 interview for the corresponding round was completed. Note that this weight is at the child level even though the data were collected from the parents; they sum to eighth-grade children, not to the parents of eighth-grade children. The weight C7CPTE0 is to be used for analysis involving all children with child assessment, parent, and teacher-level data. If child-level data from English teachers are included in the analysis, then the same weight C7CPTE0 should be used. A respondent for this type of weight was defined as a child who had scorable cognitive assessment data or student questionnaire data for spring-eighth grade (or was excluded from direct assessment due to a disability), whose parent completed the FSQ section of the parent interview for spring-eighth grade, and who had completed teacher-level data from either the English teacher and/or the mathematics/science teacher."}, {"section_title": "Cross-Sectional Weights To Be Used With a Combination of Child Direct Assessment", "text": ""}, {"section_title": "Data and Parent Interview Data and Teacher Data for Children With Mathematics", "text": "Teacher Questionnaire (C7CPTM0) The weight C7CPTM0 is to be used for analysis involving children who were subsampled to have a mathematics teacher questionnaire and who had child assessment, parent, and child-level data from mathematics teachers (with or without teacher-level data). A respondent for this type of weight was defined as a child who had scorable cognitive assessment data or student questionnaire data for springeighth grade (or was excluded from direct assessment due to a disability), whose parent completed the FSQ section of the parent interview for spring-eighth grade, and who had completed teacher-level data from either the English teacher or the mathematics teacher. If there were mathematics data but no teacherlevel data, then C7CPTM0 is zero, and such a case would not be included in the analysis. See The weight C7CPTS0 is to be used for analysis involving children who were subsampled to have a science teacher questionnaire and who had child assessment, parent, and child-level data from science teachers (with or without teacher-level data). A respondent for this type of weight was defined as a child who had scorable cognitive assessment data or student questionnaire data for spring-eighth grade (or was excluded from direct assessment due to a disability), whose parent completed the FSQ section of the parent interview for spring-eighth grade, and who had completed teacher-level data from either the English teacher or the science teacher. If there were science data but no teacher-level data, then C7CPTS0 is zero, and such a case would not be included in the analysis. See section 4.8.1 for how the child-parentteacher weights were defined."}, {"section_title": "Replicate Weights", "text": "For each weight included in the data file, a set of replicate weights was calculated. Replicate weights are used in the jackknife replication method to estimate the standard errors of survey estimates. All adjustments to the full sample weights were repeated for the replicate weights. For spring-eighth grade, there are 90 replicate weights. Each set of replicate weights has the same prefix in the variable name as the full sample weight. For example, the replicate weights for C7CW0 are C7CW1 through C7CW90. The methods used to compute the replicate weights and how they are used to compute the sampling errors of the estimates are described in section 4.9.3."}, {"section_title": "Characteristics of Cross-Sectional Sample Weights", "text": "The statistical characteristics of the sample weights are presented in table 4-17. For each type of weight, the number of cases with nonzero weights is presented together with the mean weight, the standard deviation, the coefficient of variation (i.e., the standard deviation as a percentage of the mean weight), the minimum weight, the maximum weight, the skewness, the kurtosis, and the sum of weights. The difference in the estimate of the population of children (sum of weights) between rounds of data collection and between types of weight is due a combination of factors, among them: (1) the number of children in previous rounds of data collection who became ineligible in eighth grade (due to death or leaving the country) and 2the adjustment of the weights for the children of unknown eligibility."}, {"section_title": "4-49", "text": ""}, {"section_title": "Variance Estimation", "text": "The precision of the sample estimates derived from a survey can be evaluated by estimating the variances of these estimates. For a complex sample design such as the one employed in the ECLS-K, replication and Taylor Series methods have been developed. These methods take into account the clustered, multistaged characteristics of sampling and the use of differential sampling rates to oversample targeted subpopulations. For the ECLS-K, in which the first-stage self-representing sampling units, (i.e., PSUs) were selected with certainty and the first-stage non-self-representing sampling units were selected with two units per stratum, the paired jackknife replication method (JK2) is recommended. This section describes the JK2 and the Taylor Series estimation methods.\nFor each K-8 full sample weight listed in exhibit 9-1, a set of replicate weights was calculated. Replicate weights are used in the jackknife replication method to estimate the standard errors of survey estimates. Any adjustments done to the full sample weights were repeated for the replicate weights. For longitudinal weights not involving the fall-first grade data, there are 90 replicate weights. For a description of how the replicates were formed, see chapter 4, section 4.8. For the two longitudinal weights involving fall-first grade (C1_7SC0 and C1_7SP0), there are 40 replicate weights. The reason for the smaller number of replicates is that only a subsample of schools was included in the fall-first grade sample. The weights associated with the fall-first grade data do not account for the Durbin method of selecting primary sampling units (PSUs), since it did not apply. Rather, they reflect the fact that only one of the two sampled PSUs in the non-self-representing (NSR) strata was kept in the subsample. To account for this feature, pairs of similar NSR PSUs were collapsed into 19 variance strata. The self-representing (SR) PSUs account for the remaining 21 variance strata."}, {"section_title": "Paired Jackknife Replication Method", "text": "In this method, a survey estimate of interest is calculated from the full sample. Subsamples Replicate weights were created to be used in the calculation of variance estimates. Each replicate weight was calculated using the same adjustment steps as the full sample weight but using only the subsample of cases that constitute each replicate. For the original ECLS-K design in the base year, replicate weights were created taking into account the Durbin method of PSU selection. The Durbin method selects two first-stage units per stratum without replacement, with probability proportional to size and a known joint probability of inclusion (Durbin 1967). In the ECLS-K PSU sample design, there were 24 self-representing (SR) strata and 38 nonself-representing (NSR) strata. Among the 38 NSR strata, 11 strata were identified as Durbin strata 22 and were treated as SR strata for variance estimation. The purpose of the Durbin strata is to allow variances to be estimated as if the first-stage units were selected with replacement. This brings the number of SR PSUs to 46 (24 original SR PSUs and 22 Durbin PSUs from the 11 Durbin strata). The remaining 54 NSR PSUs are in 27 NSR strata; thus 27 replicates were formed, each corresponding to one NSR stratum. For the SR strata, 63 replicates were formed. The 90 replicates will yield about 76 degrees of freedom for calculating confidence intervals for many survey estimates. As stated earlier, the sample of PSUs was divided into 90 replicates or variance strata. The 27 NSR strata formed 27 variance strata of two PSUs each; each PSU formed a variance unit within a 22 For a description of the Durbin method, see the ECLS-K Third Grade Methodology Report (NCES 2005-018) (Tourangeau, Brick, Byrne, et al. 2004)."}, {"section_title": "4-51", "text": "variance stratum. All schools within an NSR PSU were assigned to the same variance unit and variance stratum. Sampled schools in the 46 SR PSUs were grouped into 63 variance strata. In the SR PSUs, schools were directly sampled and constituted PSUs. Public schools were sampled from within PSU while private schools were pooled into one sampling stratum and selected systematically (except in the SR PSUs identified through the Durbin method in which private schools were treated as if they were sampled from within PSU). Schools were sorted by sampling stratum, school affiliation (from the original sample or newly selected as part of freshening), type of frame (for new schools only), and their original order of selection (within stratum). From this sorted list, they were grouped into pairs within each sampling stratum; the last pair in the stratum may be a triplet if the number of schools in the stratum is odd. This operation resulted in a number of ordered preliminary variance strata of two or three units each. The first ordered 63 strata were then numbered sequentially from 1 to 63; the next ordered 63 strata were similarly numbered, and so on until the list was exhausted, thus forming the desired 63 variance strata. In strata with two units, a unit being a PSU in the case of NSR PSUs and a school in the case of SR PSUs, the base weight of the first unit was doubled to form the replicate weight, while the base weight of the second unit was multiplied by zero. In strata with three units, two variance strata were created: in the first variance stratum, the base weight of two of the three units was multiplied by 1.5 to form the replicate weight and the base weight of the last unit was multiplied by zero; in the second variance stratum, the base weight of a different group of two units was multiplied by 1.5, and the base weight of the third unit was multiplied by zero. Multiplying the base weight in a unit by zero is equivalent to dropping one unit as required by the jackknife method. All adjustments to the full sample weights were repeated for the replicate weights. For each full sample weight, there are 90 replicate weights with the same weight prefix. A child sampled in first grade through the freshening process was assigned to the same replicate as the originally sampled child to whom the child was linked. When the child sampled in first grade was assigned a full sample weight (see section 4.8.3.2), he or she was assigned the replicate weights in the same manner. To reflect the variability of the control totals in the sample-based raking, a set of replicate control totals was created. Each replicate was then raked to the corresponding replicate-based control totals. This resulted in each replicate retaining the variability associated with the original sample estimates of the control totals."}, {"section_title": "4-52", "text": "The replicate weights can be used with software such as WesVar (http://www.westat.com/ wesvar/), SUDAAN (SUDAAN Language Manual, Release 9.0 [Research Triangle Institute 2004 or http://www.rti.org/sudaan/], and AM (http://am.air.org)."}, {"section_title": "Taylor Series Method", "text": "The Taylor Series method produces a linear approximation of the survey estimate of interest; then the variance of the linear approximation can be estimated by standard variance formulas (Wolter 1985 For the replication method, the full sample weight, the replicate weights, and the method of replication are required parameters. All analyses of the ECLS-K data should be done using JK2. As an example, to compute spring-eighth grade child-level estimates (e.g., mean reading scores) and their SEs, users need to specify CHILDID in the ID box of the WesVar data file screen, C7CW0 as the full sample weight, C7CW1 to C7CW90 as the replicate weights, and JK2 as the method of replication. and SE SRS can be computed using the formulas below for means and proportions."}, {"section_title": "4-54", "text": "Means: where w i are the sampling weights, n is the number of respondents in the sample, and the sample mean x w is calculated as follows: where p is the weighted estimate of proportion for the characteristic of interest and n is the number of cases in the sample. 23 Common procedures in SAS, SPSS, and Stata assume simple random sampling. Use the SVY procedure (SAS), the Complex Samples module (SPSS), or the SURVEY command (Stata) to account for complex samples."}, {"section_title": "4-57", "text": "In both cases of means and proportions, the SE assuming SRS should be multiplied by DEFT to get the approximate standard error of the estimate under the actual design."}, {"section_title": "4.10.2", "text": "Median Design Effects for the ECLS-K In the ECLS-K, a large number of data items were collected from children, parents, teachers, and schools. Each item has its own design effect that can be estimated from the survey data. Typically, standard errors and design effects are presented for selected items from the study to allow analysts to see the range of standard errors and design effects that can be expected. Another way to produce design effects for analysts' use is to produce median design effects for the same set of selected items, at the overall level and for selected subgroups. Table 4-19 shows estimates, SEs, and design effects for 52 means and proportions that were selected from the ECLS-K eighth-grade child assessment, student questionnaire, parent interview, and child-level teacher questionnaires. It is from this set of selected items that median design effects were computed for subgroups and presented in table 4-20. For each survey item, table 4-19 presents the number of cases for which data are nonmissing, the estimate, the standard error taking into account the actual sample design (Design SE), the standard error assuming SRS (SRS SE), the root design effect (DEFT), and the design effect (DEFF). Standard errors (Design SE) were produced in WesVar using JK2 based on the actual ECLS-K complex design. For each survey item, the variable name as it appears in the ECLS-K fifth-grade Electronic Codebook (ECB) is also provided in the table. For more information on the variables used in this section, refer to chapter 3, which describes the assessment and academic rating scale scores used in the ECLS-K, and chapter 7, which has a detailed discussion of the other variables. The survey items were selected so that there was a mix of items from the various questionnaires. They include the different scale scores from the direct child assessment, Academic Rating Scale scores from the teachers, characteristics of the children as they reported themselves in the student questionnaires, characteristics of the parents, and characteristics of the students as reported by the parents and teachers. In general, the design effects are lower than in previous years. The median design effect is 3.1 (compared with 4.0 in fifth grade). This is due to a smaller sample size that clustered in a smaller 4-58 number of schools; there were fewer middle schools for children to attend when they moved up from elementary schools.  2 SRS SE is the standard error assuming simple random sample. For an explanation of this statistic, see section 4.10. 3 DEFT is the root design effect. For an explanation of DEFT, see section 4.10. 4 DEFF is the design effect. For an explanation of DEFF, see section 4.10. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), spring 2007. Table 4-20 presents the median design effects from the same survey items for subgroups based on school affiliation, child's sex and race/ethnicity, geographic region, level of urbanicity, and the socioeconomic scale quintile of the parents. Design effects are highest for children in the Midwest and lowest for American Indians. American Indians are the smallest group of children, and they are highly clustered. "}, {"section_title": "4-59", "text": ""}, {"section_title": "4-60", "text": ""}, {"section_title": "4-61", "text": "In spring-eighth grade, as in first, third, and fifth grades, design effects are not computed for items from the teacher-level and school administrator's questionnaires since there are no teacher or school weights computed for any of the ECLS-K years after kindergarten. Although SEs and design effects may also be calculated for the teacher and school administrator's questionnaires at the child level, they are quite large compared to those typically found for the ECLS-K data. Design effects for teacher and school items are large because the intraclass correlation is 100 percent for children in the same school and very high for children in the same class; children attending the same school have the same school data, and children in the same class have the same teacher data. This page is intentionally left blank. 5-1"}, {"section_title": "DATA COLLECTION METHODS AND RESPONSE RATES", "text": "The following sections discuss the data collection procedures and response rates in the "}, {"section_title": "Overview of Data Collection Methods", "text": "The The modes of data collection for obtaining consent and conducting the parent interview was telephone and in-person computer-assisted interviewing (CAI) and mailed, hard-copy consent forms; the child assessments were timed and group-administered using hard-copy assessment booklets; selfadministered questionnaires were used to gather information from teachers, school administrators, and children. 5-3"}, {"section_title": "Field Staff Training", "text": "Several in-person training sessions were conducted to prepare staff for the eighth-grade data collection. In spring 2006, field supervisors and interviewers were trained to contact parents to obtain consent and to identify the school their child would attend in the 2006-2007 school year. In fall 2006, two trainings were held: one to train supervisors and interviewers to conduct the parent interview and one to train supervisors to contact original schools and recruit transfer schools. In spring 2007, two trainings on the administration of the direct child assessments were held: one for field supervisors and one for test administrators. The following sections discuss each specific type of training."}, {"section_title": "Obtaining Parent Consent Training", "text": "Field supervisors and interviewers were trained on obtaining parent consent in May 2006. Prior to the May in-person training session, supervisors and interviewers completed 16 hours of home study training that included reading materials and written exercises on the study design and field procedures as well as extensive individual and role-play practice in refusal aversion techniques to better answer respondent questions and address respondent concerns. The home study practice included role plays on answering respondent concerns and questions over the telephone with another interviewer as well as with a field supervisor. Field supervisor training. The topics covered in the field supervisor training included debriefing interviewers on the home study exercises that supervisors completed with interviewers, principles of supervision, establishing and monitoring production goals, field management issues, using the automated Field Management System (FMS), and administrative issues. The FMS was used throughout all phases of data collection to enter information about the sampled children, parents, teachers, and schools and to monitor production on all data collection activities. Field supervisors entered information into the FMS during training presentations, thus acquiring hands-on experience with the FMS and all field procedures prior to data collection. Field supervisor training for the parent consent phase of the study preceded the interviewer training and lasted for one day. Seven field supervisors completed training."}, {"section_title": "5-4", "text": "Interviewer training. The topics covered included an overview of study activities to date, a review of the parent folder that included parent contact information, an introductory script for obtaining consent, the CAI parent consent recording application, interactive lectures and role plays on answering respondent's questions or concerns about the study, and the procedures for recording parents' spoken consent on the telephone. A major goal of this training was to train interviewers to be able to respond immediately, directly, and in a fluid and natural way to respondent concerns in order to build consent response rates. The obtaining parent consent training was 1\u00bd days long. A total of 113 interviewers completed training."}, {"section_title": "Parent Interview Training", "text": "Field supervisors and interviewers were trained on conducting the parent interview in As in the fifth-grade training, advance contact and recruitment training were conducted using the FMS. As noted earlier, the FMS was used during all phases of data collection to enter information about the sampled children, teachers, and schools and to monitor production on all data collection activities. The field supervisors entered information into the FMS during training presentations, thus acquiring hands-on experience with the FMS and all field procedures prior to beginning data collection, in addition to completing role plays and exercises that involved entering information into the FMS. "}, {"section_title": "Spring-Eighth Grade Direct Child Assessment Training", "text": ""}, {"section_title": "2006 Eighth-Grade Data Collection Activities", "text": "Data collection activities in 2006 included obtaining parents' consent for their children to continue participating in the study and the schools they would attend, tracing households with outdated address information, conducting the parent interview, and contacting schools to recruit them into the study and arrange the spring data collection. The following sections discuss each of these data collection activities."}, {"section_title": "Obtaining Parent Consent", "text": "In mid-April 2006, advance packages were mailed to the 11,924 households eligible to participate in this round of the study. The package included a letter to the parents on ECLS-K stationery, a parent consent form that asked permission for continued participation in the study and asked the parent to confirm or provide school contact information for the school their sampled child would be attending in the upcoming school year (2006-07), and a parent newsletter with study results from elementary school years. Three weeks after mailing the parent advance package, a reminder postcard was mailed to all parents. By the second week in May, hard-copy consent forms had been received from 36 percent (4,265) of the eligible households."}, {"section_title": "5-7", "text": "Beginning the second week in May and continuing through the end of December, interviewers telephoned all parents who had not responded to the advance mailing, obtained parent consent, and confirmed or updated school contact information. During this data collection period, parent consent was obtained either by the parent signing and returning the consent form or by recording spoken consent on the interviewer's laptop. Spoken consent was obtained by reading the permission form to the parent and asking her for consent to record her response to the request. If the parent agreed to give spoken consent, the interviewer read a statement from her laptop that identified the parent and child and stated that the parent had given permission to record her spoken consent. All consent recordings were verified by home office staff who listened to the recordings and, when verified, generated a hard-copy parent consent form with a proxy auto-signature of the verifier. For those parents from whom consent was not received and who did not have a telephone, in-person visits to the home were made to obtain their consent. By the end of December 2006, consent had been obtained from approximately 83 percent (9,835) of eligible households."}, {"section_title": "Conducting the Parent Interview", "text": "Parent interview procedures mirrored those of previous rounds of data collection. The parent interview was conducted in the fall and winter of 2006 in order to first obtain parent consent and school information for the sampled child for any outstanding cases. The parent interview was administered, primarily as a CAI telephone interview, from September 2006 through January 2007. For cases with parent consent still needed, interviewers attempted to obtain consent and complete a parent interview during the same call. Slightly over 34 percent of the parent interviews were completed in September, 34 percent in October, 18 percent in November, and over 6 percent in December and January. The parent interview averaged 45 minutes. As in previous rounds of data collection, the parent interview was conducted in person if the respondent did not have a telephone. Table 5-1 presents the number of parent interviews completed by mode and language. In eighth grade, slightly over 2 percent of all completed parent interviews were conducted in person; 9 percent of all completed parent interviews were conducted in a language other than English; and 89.4 percent of the latter were conducted in Spanish. "}, {"section_title": "5-8", "text": ""}, {"section_title": "Fall Preassessment Contact", "text": "Beginning in September 2006, all schools confirmed or identified by parents while obtaining consent were contacted by telephone to prepare for the spring data collection. When children were identified as having transferred to another school, the child's new school (and district, if necessary) was recruited. Advance mailings. In September 2006, an advance package was mailed via Federal Express to all identified schools asking them to prepare for the fall preassessment telephone call. The schools were asked to identify a school staff coordinator to serve as a liaison with the study. (In returning schools, this person was usually the coordinator from previous rounds of data collection.) The advance package contained study findings from previous rounds and an overview of eighth-grade data collection activities. The school coordinators were asked to complete an information form about the ECLS-K sampled children prior to the telephone call."}, {"section_title": "5-9", "text": "Preassessment contact. The fall preassessment contact was made by telephone between September and December 2006. The fall preassessment school contact was successful in meeting two important goals: (1) contacting original sampled schools to set up the spring assessment, and 2 All children who transferred were followed to their new school and not subsampled as in previous years. (Refer to the ECLS-K Fifth-Grade Methodology Report (NCES 2006-037) (Tourangeau, L\u00ea, and Nord 2005) for additional details on how transfer children were subsampled in prior rounds.) If the new school belonged to a district that was new to the study, the district was contacted and recruited before any contact was made with the school. If the district was already cooperating, the new school was contacted and recruited directly. Reviewing information about ECLS-K sampled children. Field supervisors collected information from the school coordinators about the ECLS-K sampled children still enrolled in the school, including the child's current grade; the name and classroom for the child's English teacher and mathematics or science teacher; and whether or not the child had an Individualized Education Plan (IEP)."}, {"section_title": "5-10", "text": "If the child had an IEP, then the name and classroom of the child's special education teacher was collected, along with whether the child required any accommodations to participate in the direct cognitive assessment. The accommodations in the eighth-grade direct cognitive assessment included all of those for the kindergarten, first-grade, third-grade, and fifth-grade direct cognitive assessments, with the addition of large print. Field supervisors contacted the teachers of the ECLS-K children as necessary for any of this information. Contacting families of homeschooled children. As part of obtaining parent consent, the status of homeschooled children who were identified in rounds 1 through 6 was confirmed with their parents and updated as necessary. As parents of these children were contacted to obtain consent, they were asked to confirm that the child was still homeschooled or if the child had enrolled in a school. If the child had enrolled in a school, the new school was contacted and recruited into the study. Parents of children who were still schooled at home were notified about the next round of data collection in the spring. Identifying the key child in classrooms with multiple study children. In fifth grade, the design of the child-level teacher questionnaire was changed to include collecting data about the child's reading class and mathematics or science class. The design of the eighth-grade child-level teacher questionnaire followed this model although English teachers rather that reading teachers were contacted. In elementary schools, children were primarily taught in intact classrooms, and teachers only reported classroom level information once for the classroom. Due to the design change in fifth grade, the teacherchild links were broadened to include the domain (reading, mathematics, or science) as well as information to identify the English, mathematics, or science classroom. In order to reduce data collection burden for teachers who were linked to multiple sampled children in the same class, a \"Key Domain Child\" was identified for each separate subject and class that each teacher taught. The teachers would be asked to report classroom-level information only once in the questionnaire for the key domain child and child-level information for all sampled children in that class. Field supervisors collected the teacher-childdomain-classroom link information about each child and entered the information into the FMS. The information was used to generate the hard-copy teacher questionnaires (see section 5.5.3 for more information on teacher questionnaire data collection). Refer to the ECLS-K Fifth-Grade Methodology Report (NCES 2006-037) (Tourangeau, L\u00ea, and Nord 2005) for additional detail on the Key Child concept. 5-11"}, {"section_title": "Tracing Activities During the Eighth-Grade Data Collection", "text": "In order to ensure that as many of the sampled children as possible were contacted for eighth-grade data collection, tracing activities were ongoing through all phases of data collection. Tracing began in April of 2006 when the parent consent packages were mailed and continued through the spring data collection. If the parent advance package was returned as undeliverable but had new address information, it was remailed to the parent at the new address and the updated address was added the ECLS-K tracking database. If the package was returned as undeliverable with no updated address information, this information was entered into the tracking database and appeared on the parent locating form generated for each case. Interviewers used the parent locating form to attempt to obtain updated telephone numbers and addresses while prompting for consent and conducting the parent interview. Locating efforts included calling all contacts identified on the locating form, using directory assistance and the Internet resources, and in person-visits to the last known address of the case to attempt to collect updated address information from neighbors."}, {"section_title": "Spring-Eighth Grade Data Collection", "text": "All children who were assessed during the base year or for whom a parent interview was completed in the base year were eligible to be assessed in the spring-eighth grade data collection, with four exceptions. They are (1) children who became ineligible in an earlier round (because they died or moved out of the country), (2) children who were subsampled out in previous rounds because they moved out of the original schools and were not subsampled to be followed, (3) children whose parents emphatically refused to cooperate (hard refusals) in any of the data collection rounds since springkindergarten, and (4) children in the eighth-grade sample for whom there were neither third-grade nor fifth-grade data. Eligibility for the study was not dependent on the child's current grade, that is, children were eligible whether they had been promoted to eighth grade or had been retained. Test administrators received school assignments with a set of schools in or around a particular geographic area. An average assignment consisted of 13 schools. Each test administrator was responsible for all data collection activities in his or her assignment; they conducted the direct child assessments and collected all school and teacher questionnaires. A majority of the field staff hired for eighth-grade assessments were continuing from fall school recruiting or had worked on previous rounds"}, {"section_title": "5-12", "text": "of ECLS-K data collection. Any staff hired with no prior experience on the study had experience on the National Assessment of Educational Progress (NAEP) in conducting group assessments."}, {"section_title": "Preassessment School Contact", "text": "Based on the information collected in the fall of 2006, packets of hard-copy teacher and school administrator questionnaires and instructions were assembled and mailed to schools beginning in January 2006, along with letters confirming the scheduled visits to the school. Teachers and school administrators were asked to complete the questionnaires and turn them in to the school coordinator for pickup by test administrators on assessment day. Test administrators conducted preassessment activities by telephone starting in March 2007. The preassessment activities for these schools were similar to those conducted in previous rounds of data collection and included confirming the assessment date, the school's receipt of the hard-copy questionnaires, and arranging for space to conduct the assessments."}, {"section_title": "Conducting the Direct Child Assessments", "text": "The direct child assessments were conducted from March through early June 2007, the same time of year as in prior spring data collections. About 81 percent of the assessments were completed in March and April, about 18 percent were completed in May, and less than one percent were completed in June. In year-round schools, multiple assessment visits to the school were done, as needed, to assess all of the sampled children in each track. The direct child assessments were usually conducted in a school classroom or library. Before conducting the assessments, test administrators set up the room for the assessments. The test administrator followed procedures for meeting the child(ren) at the test area as agreed upon during the preassessment contact with the school. In scheduling schools in the fall, attempts were made to schedule the direct child assessments at about the same point in time between the beginning and the end of the school year, to increase the likelihood that exposure to instruction would be about the same for all children. As noted earlier, the eighth-grade direct child assessments for reading, mathematics, and science were timed, two-stage, group-administered assessments. Test administrators read from a script for each 5-13 component of the assessment. The assessment routing forms were administered first in the following order: reading, mathematics, and science, and were timed for a total of 29 minutes. While the test administrators scored the assessment routing forms and identified and labeled the appropriate secondstage form for each domain, children were given 20 minutes to complete the student questionnaire. The second-stage assessments were administered in the following order: reading, mathematics and science, and were timed for a total of 51 minutes. The assessment session also included measurements of the sampled children's height and weight. The total time to complete all activities in an assessment session averaged slightly less than 2 hours. Participating children received a $15 honorarium. Table 5-2 displays the total number of completed child assessments during spring-eighth grade data collection. All of the assessments were completed in reading: 94.6 percent of assessments were completed with no accommodations required; 4.9 percent completed the assessment with some accommodation, and less than 0.5 percent were excluded from participating in the assessments. The term accommodation in this table is the field operational definition of accommodation, which includes the wearing of glasses and hearing aids. These types of aids were systematically tracked to ensure that every child had the same chance at a successful assessment. With this information, assessors could prompt a child (e.g., to get her glasses before being assessed). \"Excluded\" is a subcategory in this present; the use of a personal assistive device, and large print. Table 5-3 presents the number of children excluded from or requiring an accommodation to the direct child assessment in the spring of eighth grade. "}, {"section_title": "Teacher and School Data Collection", "text": "Data were collected from school administrators, regular classroom teachers, and special education teachers from March through June 2007. The school and teacher questionnaires were mailed to the school coordinators beginning in late January 2007 on a flow basis, depending on the school's scheduled assessment date. Using the teacher-child-domain-classroom linkage information collected in the fall, a packet of questionnaires was assembled for each English, mathematics, science, and special education teacher. The customized teacher questionnaire materials included a cover letter and a $25 check attached to the teacher questionnaire, instruction sheets attached to the child-level questionnaires for each separate class, and a special education instruction sheet attached to the special education questionnaires (if appropriate). A packet of materials was also assembled for the school administrator. Packets were bundled together by school and mailed to the school coordinator for distribution. If the school or teacher and school administrator were not identified in the fall preassessment contact, then the field supervisor gathered the relevant information during the spring preassessment call and mailed the packets."}, {"section_title": "5-15", "text": "All teachers, including special education/service providers, received $25 for completing child-level instruments for sampled children in their classrooms. Teachers completing questionnaires for more than 10 children in their classes received remunerations of up to $55. Over 97 percent of teachers had fewer than 10 ECLS-K children. On assessment day, after collecting completed questionnaires, the test administrator (TA) scanned the questionnaires to ensure that there were no missing critical items. During the field period, the TAs followed up with the school coordinator by making an in-person visit to the school or prompting by telephone to review the status of the incomplete or missing questionnaires."}, {"section_title": "Data Collection Quality Control", "text": "Continuous quality assurance procedures were employed during all data collection activities, with a particular focus on the assessments. The procedures were incorporated throughout all stages of the study (i.e., during instrument development, in the staff training program, and through parent validations). Data collection quality control efforts began with the additional development and testing of redesigned sections of the CAI/CAPI applications and the FMS. As sections of these applications were reprogrammed, extensive testing of the entire system was conducted to verify that the systems were working properly from all perspectives. This testing included review by project design staff, statistical staff, and the programmers themselves. Quality control processes continued with the development of field procedures that maximized cooperation and thereby reduced the potential for nonresponse bias. Quality control activities continued during training and data collection. During assessor training, field staff practiced conducting the parent interview in pairs and practiced multiple exercises on scoring the first stage of each assessment and affixing labels to the second stage of each assessment. When the fieldwork began, field supervisors made telephone calls to parents to validate the interview. The teacher and school questionnaire packages were reviewed for accuracy at 100 percent to ensure the correct questionnaires were sent to the schools for distribution and completion. 5-16"}, {"section_title": "Quality Control on the Child Assessment", "text": "The mode of assessment administration changed in eighth-grade from a one-on-one, CAIwith-easels assessment administration to a group-administered, timed, hard-copy assessment. The hardcopy assessment was a two-stage assessment with a routing assessment for each of three domains, reading, mathematics, and science, and two levels of the second-stage assessment for each domain. TAs had to administer the routing assessment, score the three domains, and identify the appropriate secondstage assessment by domain and affix a label with a child's name and identification number. In the training session, TAs practiced this process multiple times to be able to quickly and accurately score and label assessment forms in the field. All trainees were proficient on the process after completing training. TAs accuracy in identifying the appropriate assessment forms was examined during the field period by comparing the child's' routing test score and the assessment form the TA labeled for the child. TAs identified the appropriate second-stage assessment with over 99 percent accuracy for each assessment domain: 99.2 percent accuracy for the reading assessment; 99.3 percent accuracy for the science assessment; and 99.5 percent accuracy for the mathematics assessment."}, {"section_title": "Validation of Parent Interviews", "text": "Approximately 10 percent of the respondents who completed parent interviews were selected for a short re-interview conducted by a field supervisor (i.e., a \"validation\" interview). The first parent interview completed by an interviewer was always selected for validation. Over the course of the field period, a running count of an interviewer's completed parent interviews was maintained, and each tenth completed parent interview was selected for validation, thus ensuring that 10 percent of each interviewer's cases were selected for validation. The parent validation was approximately 5 minutes long and was conducted by telephone. In spring-eighth grade, a total of 834 parent interviews were validated with 75.8 percent reporting the same answers as in the original interview. Field supervisors used a standardized parent validation script to make validation calls to parents. The script covered the following topics: verification of the child's full name, date of birth, and sex; and seven questions repeated from the parent interview."}, {"section_title": "5-17", "text": "Field supervisors noted if the validation check was completed with no changes, with \"minor\" changes, or with \"major\" changes. \"Minor\" changes include spelling of parent name, child's name, parent's address or telephone number, child's date of birth, or child's gender. \"Major\" changes include any changes to the question responses. responses during the original parent interview and those during the validation may reflect differences in respondent recall, respondent interpretation of the question, or actual change in the data, rather than a validation issue. Feedback from supervisors indicated that two validation items may reflect some of these differences, rather than true validation issues. As a result, the results for major changes may be overreported. 5-19"}, {"section_title": "5-18", "text": ""}, {"section_title": "Spring-Eighth Grade Completion Rates", "text": "Since data were collected from schools, parents, teachers, and children, there were many opportunities for sources to contribute differentially to nonresponse, and this is reflected in the varying completion rates in the tables in this section. These completion rates differ not only by survey instruments, but within each survey instrument they differ also by school and child characteristics. In this section, eighth-grade completion rates are presented for three groups of children: (1) children sampled in kindergarten, 2 In general, completion rates for eighth grade are lower than in previous year. Even though hard-to-field cases 26 from the fifth-grade collection were excluded, the completion rates are lower for three main reasons: (1) the eighth-grade data collection occurred three years after the fifth-grade data collection, making it harder to find respondents, (2) the children were older and could refuse to cooperate at a much higher rate than younger children, and 3the change in the field procedure in which explicit parent consent had to be obtained before the children could be approached. Table 5-5 shows that the completion rates for the child assessment are higher in public schools than in private schools. Within the private school category, the difference in the rates is not as large. Excluding the \"unknown\" category, the complete for the child assessment rates range from 82.7 percent for children in non-Catholic private schools to 97.1 percent for children in schools in small towns. The pattern of completion rates is similar or the parent interviews, ranging from 76.5 percent for children in non-Catholic private schools to 89.2 percent for children in schools in large towns, excluding the \"unknown\" category. The \"unknown\" category includes children who were unlocatable as their whereabouts were unknown. The category \"unknown\" also includes 48 children who were homeschooled and thus had no information concerning schools. Table 5-6 shows that the overall weighted completion rates are 75.3 for the student questionnaire, 73.3 percent for the school administrator questionnaire, and 74.5 for the teacher-level questionnaire. Excluding the \"unknown\" category, the completion rates for the student questionnaire follow the same pattern of the rates for child assessment with the lowest rate for children in non-Catholic schools (82.0 percent) to the highest rate for children who were not in schools in cities or their surrounding areas (in this case 96.2 percent in the rural area outside the Metropolitan Statistical Areas). 25 The categories of school affiliation in the tables in this chapter do not match categories of school affiliation in the tables in chapter 4. This is to allow users to compare completion rates in eighth grade with those in previous years. 26 Hard-to-field cases are the hard-refusal cases and cases that were nonrespondents in both first and third grades as described in section 4.5."}, {"section_title": "5-21", "text": "The pattern of completion rates for the school and teacher instruments is somewhat different. For the school administrator questionnaire, the rates range from 80.4 percent for schools with the highest minority enrollment to 97.0 percent for schools with the lowest minority enrollment. This is a phenomenon observed in previous rounds for the school administrator questionnaire. Table 5-7 shows that the rates for the child-level teacher questionnaires. All three of these subject-specific teacher questionnaires were completed at an overall rate of 72 or 73 percent. Excluding the \"unknown\" category, the completion rates for the child-level teacher questionnaires are as follows: 80.4 percent (large city) to 97.3 percent (small town) for English; 77.2 percent (large city) to 97.3 percent (small town) for mathematics, and 79.2 percent (non-Catholic private or large city) to 93.7 percent (high total enrollment) for science. These rates are not as high as in fifth grade but higher than in third grade, most likely due to the higher incentives employed in fifth grade and carried on to eighth grade.     Tables 5-8 to 5-10 show the completion rates by mover status. Unlike previous years in which only a subsample of movers was followed into their new schools, the eighth-grade data collection followed all movers. The number of movers is larger than the number of nonmovers as children left their elementary schools for middle schools. Because of these changes, the rates are no longer comparable to rates in earlier years. In earlier years, nonmovers responded at a higher rate than movers. This is not the case for eighth grade. Not only the number of nonmovers is much smaller, but they also responded at a lower rate, 73.4 percent compared with 81 percent for movers, in the case of the child assessment. Since all movers were followed and highly successfully located, the difference between the completion rates of located movers and unlocated movers was not as large as shown in previous years. Of those who moved, 97 percent were located. There are cases whose mover status was unknown. These are children whose parents refused consent for their children to be approached for data collection, and the whereabouts of the children were not traced. The parent interview completion rates are 67.8 percent for nonmovers and 76.6 percent for movers. The difference in the rates between located movers and all movers is minimal, again because almost all movers were successfully located. There is the peculiar case of a high completion rate of unlocated movers. Even though children could not be located for the child assessment, a parent interview was conducted by telephone, leading to the 91 percent response rate for this category. The same is true for the cases of children with unknown mover status; 43 cases had parent interviews that apparently did not have information about where their children went to school. The pattern of completion rates by mover status is the same for the student questionnaire and the teacher questionnaires. The school administrator questionnaire is the only one where the completion rate for nonmovers is higher than for movers, a 10 percent difference. This can be explained by the fact that movers were not always assessed in schools so that the school administrator questionnaire could be administered; schools where nonmovers attended had been in the sample for a long time and tend to cooperate more than schools that were new to the sample, had a lower level of commitment to the ECLS-K, and often refused to complete the school administrator questionnaire.  1 Based on ECLS-K survey data and not on data from the sampling frame. 2 English, mathematics, or science assessment was scorable, or child was disabled and could not be assessed, or child had student questionnaire data or height and weight data. 3 Family structure portion of parent interview was completed. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), spring 2007.   Tables 5-11 to 5-13 present child-level weighted and unweighted completion rates for the spring-eighth grade data collection for children who were sampled as part of the kindergarten cohort in the base year, this time broken out by child characteristics. When the \"unknown\" categories are not included, the differences in completion rates by sex and by year of birth are within 2 percentage points, but for race and ethnicity they are more substantial. Table 5-11 shows that the child assessment completion rate was highest for Whites (80.9 percent) and lowest for Asians (59.9 percent), a reverse in the trend of earlier years. The low response rate for Asians persists for other instruments as well. The unweighted sample of Asians is about 8 percent, about the same proportion as in earlier years. Their moving pattern is the same as in previous years; their relative moving rate is about 50 percent higher compared with fifth grade, the same as their minority counterparts (Hispanics and American Indians 27 )."}, {"section_title": "5-22", "text": ""}, {"section_title": "5-23", "text": ""}, {"section_title": "5-29", "text": ""}, {"section_title": "5-33", "text": ""}, {"section_title": "5-34", "text": "Therefore, the drop in the completion rates cannot be attributed to a change in the sample. The highest completion rate is for White, uniform across all instruments. American Indians have a higher completion rate for the parent interview, but the sample size for this group is so small that it should not be compared with Whites. In addition to the child assessment, parent interview, student questionnaire, school administrator questionnaire, and teacher questionnaires (for which completion rates have been summarized in the preceding paragraphs), data were also collected in eighth grade from special education teacher questionnaires for children who had special education teachers. Table 5-14 presents counts of completes and weighted and unweighted completion rates at the overall child level for the special education teacher questionnaires A and B. Although the number of special education teacher questionnaires is small, its completion rates are high, 93.9 percent for part A, which captures teacher information, and 94.7 percent for part B, which relates to children who receive individualized special education services. These rates are not broken down by school and child characteristics because of the small sample sizes. even when they were otherwise followed for data collection. These movers were considered freshening nonrespondents in the child term. prepare an alphabetic roster of children enrolled in first grade. These schools were also requested to identify which children did not attend kindergarten the previous year. Schools did not participate in the freshening process because they either refused or were unable to provide the requested information. Within the schools that agreed to freshen, the freshening completion rate is 99.2 percent, the slight loss due to children who transferred to other schools (the child term). Multiplying these two terms together gives a first component completion rate of 77 percent. Note that the first component rate for spring-eighth grade is not identical to the first component rate for earlier grades because of the exclusion of children in special groups as explained in section 4.7.  6 62 46.9 54.9 School administrator questionnaire 6 62 41.9 53.7 Teacher-level questionnaire 6 63 46.3 55.7 English teacher questionnaire (child level) 6 61 45.1 54.0 Mathematics teacher questionnaire (child level) 6 33 43.7 56.7 Science teacher questionnaire (child level) 6 27 42.0 49.3 Special education part A 6 10 66.3 71.5 Special education part B 6 10 66.3 71.5"}, {"section_title": "5-37", "text": "In the first component, this is the completion rate for freshening. In the second component, this is the completion rate for the survey instruments. The product of the two components is the overall completion rate for the survey instruments. The freshening completes and completion rates for children in schools targeted for freshening. The freshening completes and completion rates for children in schools that agreed to the freshening procedure. English, mathematics, or science assessment was scorable, or child was disabled and could not be assessed. Family structure portion of parent interview was completed. A completed questionnaire was defined as one that was not completely left blank. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-(ECLS-K), spring 2007."}, {"section_title": "5-38", "text": "The second component varies by survey instrument, and is much lower than in previous years. As discussed before, the completion rates dropped in general due to the time gap between the fifthgrade and eighth-grade data collections and the introduction of the explicit parent consent into eighth grade. Also, the number of children sampled is much smaller than in the past, a drop of 40 percent; there were 165 children sampled in first grade in the fifth-grade data collection; there were 100 of such children in the eighth-grade data collection. The rates for the paper-and-pencil instruments range from 54.5 percent for the child-level science teacher questionnaire to 86.1 percent for the special education questionnaire part A or B. The rate for the child assessment, at 60.9 percent, is almost 15 points lower than for the kindergarten sample, and the parent interview, at 51.5 percent, is about 20 points lower. The rates for the school instrument and the teacher instruments are all lower between 14 and 19 points, except for the special education teacher questionnaires where the difference is about 8 percentage points. The final completion rate for each instrument is the product of the two components. Because of the low rates at the first stage, these range from a high of 66.3 percent for the special education questionnaire part A or B to a low of 39.6 percent for the parent interview. grade represent such a small fraction of the total population of children, their inclusion in the computation of the completion rate brings down the rates for all children by less than half a percent relative to the rates for children sampled in kindergarten, even though the completion rates for children sampled in first grade are much lower than the kindergarten rates. The spring-eighth grade overall completion rates for the child assessment and the parent interview are 75 percent and 70.9 percent, respectively."}, {"section_title": "Spring-Eighth Grade Completion Rates-All Children", "text": "The unweighted completion rates are almost always higher than the weighted completion rates, by as much as 13 percent at the overall level. Where there is a large difference, it is due to fifthgrade movers who have larger weights than fifth-grade nonmovers. The weights of the fifth-grade movers had been increased in fifth grade to account for the subsampling of movers in fifth grade. This difference is not as large as in fifth grade, because movers in eighth grade were not subsampled out and no mover adjustment was applied to the weight. The fifth-grade mover adjustment, however, did apply to the eighth grade as explained in chapter 7. Table 5-17 shows the completion rates for the child assessment, the parent interview, the student questionnaire, and the school and teacher instruments for children who have nonzero child weights (C7CW0>0). These are children whose spring-eighth grade English, mathematics, or science assessments were scorable, children who could not be assessed because of disabilities, or children who completed a student questionnaire. These conditioned completion rates are useful to analysts who want to assess the relationship between the different instruments in term of participation. The completion rates from the different instruments are dependent in that if data from one instrument are missing (e.g., parent instrument) it is likely that data from other instruments are also missing. (e.g., school administrator questionnaire). The conditioned completion rate for the child assessment is by definition 100 percent. The rate slightly less than 100 percent, shown when children sampled in kindergarten are combined with children sampled in first grade, is due to the school freshening nonresponse for children sampled in first grade."}, {"section_title": "5-39", "text": "When the completion rates are conditioned on the presence of the child weight, they are at least 17.5 points higher than the unconditional completion rates for all instruments but the special education questionnaires. For these last two instruments, the difference between the number of completes for the conditional and unconditional rates is very small; hence the conditional rates are not affected as much as for the other instruments. For all other instruments, the conditional completion rates are higher by 16.9 points for the parent interview, and as high as 21.2 points for the teacher-level questionnaire. The rate for the student questionnaire is not part of this comparison because almost all children who were assessed also completed the student questionnaire. "}, {"section_title": "5-40", "text": ""}, {"section_title": "Overall Response Rates", "text": "The ECLS-K overall response rate can be computed by the product of the school-level response rate from the base year and the completion rates from each round of data collection after the base year. Table 5-18 presents the overall response rate after data collection for 5 school years: base year, first grade, third grade, fifth grade, and eighth grade, and for each study instrument that is common to all rounds of data collection: child assessment, parent interview, school administrator questionnaire, teacherlevel questionnaires A and B (replaced by one single teacher-level questionnaire in fifth and eighth grade), child-level teacher questionnaire part C (replaced by the reading/English child-level questionnaire in fifth and eighth grade), and the two special education questionnaires A and B. The instrument-specific overall response rates are driven by the school-level response rate in the base year. Since the overall school response rate is low at 74 percent, overall response rates for all instruments cannot be higher than 74 percent. In fact, they range between 62 and 70 percent in the base year, and steadily drop each year until they range only between 17 and 38 percent in eighth grade. Leaving aside the special education questionnaires that were administered to a small selected sample, the instrument with the highest overall response rate by the end of the study in eighth grade is the child assessment, followed by the parent interview. The school and teacher questionnaires have about the same overall response rates. The drop in the overall response rate from year to year is natural in a longitudinal study.   "}, {"section_title": "5-43", "text": ""}, {"section_title": "Nonresponse Bias Analysis", "text": "Estimates from nearly all surveys are potentially subject to bias due to nonresponse. Two aspects of the ECLS-K that increased the concern about nonresponse bias were its longitudinal design and the use of multiple sources for acquiring data about the sampled children. In the ECLS-K, nonresponse occurred in the initial base year of collecting data, and then attrition occurred in subsequent rounds of data collection. As in most longitudinal surveys, nonresponse in the ECLS-K generally increased as the sample aged. The use of multiple sources in the ECLS-K (e.g., direct child assessment, parent interview, teacher interview) provided the opportunity to obtain valuable data about the child, but it also presented multiple chances for nonresponse. For example, even if the child could be assessed, the parent might decline to be interviewed, and estimates using the parent data were subject to nonresponse. forthcoming) includes an examination of the potential for nonresponse bias using three methods: 1comparison of respondents and nonrespondents using the available sample frame, (2) multivariate analysis to identify the characteristics of cases most likely to respond, and 3analysis of attrition bias applicable to longitudinal studies. Nonresponse bias of the estimates from the eighth grade was present but small. In most cases, the use of a mover status category in the fifth-grade nonresponse adjustment weighting helped reduce the bias, and the sample-based raking to the characteristics of the base-year children further reduced the nonresponse bias and variance of the estimates. The proper use of the ECLS-K weights in data analysis will minimize the effect of nonresponse bias. 6-1"}, {"section_title": "DATA PREPARATION", "text": "As described in chapter 5, two types of data collection instruments were used for the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K) data collection in spring-eighth grade: computer-assisted interviews (CAI) and self-administered paper forms (hard copy). The data preparation approach differed with the mode of data collection. The parent interview was conducted using CAI techniques. Editing specifications were built into the computer programs used by interviewers to collect these data. The child assessments and student questionnaires were administered as hard-copy forms and were completed in a group setting. The teacher and school administrator questionnaires were self-administered on hard-copy forms. When the field supervisors returned these forms, coders recorded the receipt of these forms into a project-specific forms tracking system. The forms were then sent to a scanning subcontractor for transfer into an electronic format. After the data were scanned, upcoding was conducted, and the data were reviewed for range and logic consistency. The following sections describe the data preparation activities for both modes of data collection in more detail."}, {"section_title": "Coding and Editing Specifications for Computer-Assisted Interviews (CAI)", "text": "The very nature of designing a computer-assisted interview forces decisions about edit specifications to be made up front. Both acceptable ranges and logic consistency checks were preprogrammed into the electronic questionnaire. The following sections describe the coding and editing that were conducted on the CAI parent interview."}, {"section_title": "Range Specifications", "text": "Within the CAI parent interview instruments, respondent answers were subjected to both \"hard\" and \"soft\" range edits during the interviewing process. A \"soft range\" is one that represents the reasonable expected range of values but does not include all possible values. Responses outside the soft range were confirmed with the respondent and entered a second time. For example, the number of times a child changed from one school to another since spring 2004 had a soft range of 0 to 3. A value outside this range could be entered and confirmed as correct by the interviewer as long as it was within the hard range of values (0 to 5)."}, {"section_title": "6-2", "text": "\"Hard ranges\" are those that have a finite set of parameters for the values that can be entered into the computer, for example, \"0-5 times\" for the number of times the child, in the previous 5 days, ate a breakfast that was not school provided. Out-of-range values for closed-ended questions were not accepted. If the respondent insisted that a response outside the hard range was correct, the assessor or interviewer could enter the information in a comments data file. Data preparation and project staff reviewed these comments. Out-of-range values were accepted and entered into the data file if the comments supported the response. Parent interview items on house value. No hard coding range was specified for items asking about the remaining principal on the house (PAQ020). In 82 cases, the remaining principal on the house (PAQ200) was greater than the house value (PAQ150). For some of these cases, the difference between the principal and value was less than $10,000; however, in other cases the discrepancy seemed unusually high. For example, 48 cases had principal values that exceeded the home value by at least $50,000. Therefore, analysts are advised to scrutinize those cases having remaining principal on the house greater than the house value and use judgment when working with these cases."}, {"section_title": "Consistency Checks (Logical Edits)", "text": "Consistency checks, or logical edits, examine the relationship between and among responses to ensure that they do not conflict with one another or that the response to one item does not make the response to another item unlikely. For example, in the household roster, one could not be recorded as both a sister and male. When a logical error such as this occurred during a session, a message appeared requesting verification of the last response and a resolution of the discrepancy. In some instances, if the verified response still resulted in a logical error, the interviewer recorded the problem either in a comment or on a problem report."}, {"section_title": "Additional Coding", "text": "Additional coding was required for some of the items collected in the CAI instrument. These items included \"Other, specify\" text responses, occupation, and race/ethnicity. Interviewers keyed verbatim responses to these items. Once the data were keyed, staff were trained to code these data using 6-3 coding manuals designed by Westat and the National Center for Education Statistics (NCES) to support the coding process. Review of \"Other, specify\" items. The \"Other, specify\" open-ended parent interview responses were reviewed to determine if they should be coded into one of the existing response categories. During data collection, when a respondent selected an \"other\" response in the parent interview, the interviewer entered the text into a \"specify\" overlay that appeared on the screen. The data preparation staff reviewed these text \"specify\" responses and, where appropriate, coded them into one of the existing response categories. In some cases, the post-data collection \"Other, specify\" text upcoding resulted in a routing question being set to a category that would route to another item that was correctly skipped during the interview. In those cases, the skipped item was set to -9. Users should be aware that in these cases, the values of -9 are due to the post-data collection \"Other, specify\" text upcoding and not due to early termination of the telephone interview. Other cases of which users should be aware in which a value of -9 was set during the postdata collection editing are in twin households where a non-English language was spoken in the home (PLQ020 = 1). There are 12 records on the data file in which PLQ083 = -9 and PLQ090 = -9 for the second child of a set of twins. The Blaise CAPI program did not collect child-level language data for the twins in households speaking any language other than English. As a result, the child-level PLQ variables were set to -9 (Not Ascertained) for the 12 twins. Parent involvement. In the eighth-grade data collection, parent data was collected in the fall rather than in the spring, as was the method in previous rounds. Because the data were collected at the beginning of the school year, items tapping parent involvement (PIQ020) in various school functions were followed by a question asking whether parents had yet had an opportunity to be involved in those functions. When indicated, responses were treated as \"Other, specify\" items and upcoded to \"No opportunity yet\" for PIQ020 in the data set."}, {"section_title": "Parent occupation coding.", "text": "As in the kindergarten, first-grade, third-grade, and fifth-grade data collections, occupations were coded using the Industry and Occupation Coding Manual (NCES Postsecondary Student Aid Study (NPSAS:1990) and contained one to four digits. Analysis of the NPSAS categories revealed that some categories had very small numbers of cases and some categories that are similar had similar participation rates, suggesting that the separate codes could be collapsed without significant loss of information. The NHES industry and occupation code categories use a twodigit code, the highest level of aggregation, to have sufficient numbers of cases to support analysis without collapsing categories. There are 13 industry codes and 22 occupation codes in the NHES coding scheme. If an industry or occupation could not be coded using this manual, the Index of Industries and Cases that could not be coded using the autocoding system were coded manually using a customized coding utility program designed for coding occupations. The customized coding utility program brought up each case for coders to assign the most appropriate codes. In addition to the text strings, other information, such as main duties, highest level of education, and name of the employer, was available for the coders. The coders used this information to ensure that the occupation code assigned to each case was appropriate. Over half the cases (63.2 percent) were manually coded. The cases were then verified. Verification of coding is an important tool for ensuring quality control and extending coder training. As a verification step, two coders independently assigned codes (i.e., a double-blind coding process) to industry and occupation cases. Coders also independently assigned a second code for autocoded cases. A coding supervisor adjudicated disagreements between the initial code and the verification code. The adjudication by the supervisor served to further train coders by presenting concrete examples of appropriate coding. Of the cases that were autocoded, 16.6 percent required adjudication because the verifier disagreed with the autocoding. Of the cases that were manually coded, 28.3 percent required adjudication because the manual coder and the verifier disagreed. After 6-5 coding, verification, and adjudication were completed, all of the data were sorted by job title and code to check the coding one last time for consistency and to catch any coding errors that may have been overlooked. Race/ethnicity coding. The same coding rules used since the kindergarten year were used to code all race/ethnicity variables for children, resident parents, and nonresident parents. (See chapter 7, sections 7.6.1.4 and 7.6.2.9 for details on how the race and ethnicity variables were coded and how the race/ethnicity composite was created.) Partially complete parent interviews. All \"completed\" parent instruments (i.e., had completed all sections of the parent interview) were retained in the final data file. A small number of interviews in eighth grade (199, less than 3 percent) terminated the parent interview after the Family Structure (FSQ) section but before the end of the instrument. These interviews were considered as \"partially complete\" cases and were also included in the data file. All instrument items after the interview termination point were set to -9 for \"Not Ascertained.\" Parent interviews in which the respondent terminated the interview prior to the FSQ section were considered \"incomplete\" and not retained on the data file. Household roster in the parent interview. Several tests were run on the household roster to identify missing or inaccurate information. These tests are the same tests run on the first-grade, thirdgrade, and fifth-grade files. One flag was used to identify cases that were edited for any of the reasons described below. The flag is P7EDIT; the flag was set to \"1\" if the case was edited in the given wave. There were 347 cases requiring edits in eighth grade. There were essentially three general types of roster tests performed to determine which cases required editing. First, the relationship of an individual to the focal child was compared to the individual's listed age and sex. Problems found were corrected on the basis of data from prior data collections wherever possible. Second, households with more than one mother or more than one father were scrutinized for errors. While it is possible to have more than one mother in a household-for example, a household could contain one biological and one foster mother of the focal child-such cases warranted closer inspection. Corrections were made whenever clear errors and a clear resolution existed. The relationship of an individual to both the focal child and the reference person was also examined, as there were cases in which the relationship of an individual to the focal child conflicted with his or her status as 6-6 the spouse/partner of the reference person. For example, in a household containing a child's grandparents but not his or her parents, the grandmother may be designated the \"mother\" figure, and the grandfather thus becomes the \"father\" (for the purposes of some questions in the interview) by virtue of his marriage to the grandmother. These cases were examined but left unchanged. Both the original-and correct (grandfather)-relationship data and the new \"parent-figure\" designation (father) that had been constructed were kept. In addition, the number of household roster errors by the interviewer was counted. For example, a household roster error would occur if an interviewer entered the same sibling into the household roster twice. In that instance, the interviewer would set the duplicate entry to \"no longer in the household,\" and the reason departed would be set to \"roster error.\" In the eighth-grade data, there are 14 cases with these types of errors after the roster tests were run; the cases can be identified by the flag \"P7ERRFLG.\" Teacher responses to key child items. Teachers of sampled children were asked to respond to child-level questionnaires for the reading, mathematics, and science domains. In many cases, teachers had more than one sampled child in a class. The items in the child-level questionnaire that collected information about classroom characteristics were redundant under these circumstances. The key child approach was designed to minimize the burden on the teachers by designating one questionnaire in which the classroom characteristics items were to be completed. See chapter 5, section 5.3.3 for a description of the key child design and procedures. Once the child-level questionnaires were keyed and loaded into the editing system, a review was conducted to identify cases in which teachers reported classroom characteristics on a different questionnaire than the one designated as the key child instrument for the given class. This process involved three steps: the review of missing data for classroom characteristics items within each domain (reading, mathematics, and science) for key child records, a detailed review of all data records in classes with multiple children and missing values for selected classroom characteristics items, and the updating of appropriate records. In the first step, data records for key children in all classrooms with more than one sampled child were selected. Frequency distributions of the classroom items were examined for the level of missing data within each domain. All classroom characteristics items were included in this review. The 6-7 results of this initial review indicated that missingness was largely confined to the items concerning the race composition of the classroom and the percent of instructional time devoted to various subjects. In the second step, all returned instruments were selected for classrooms with multiple children that had missing data for the race and percent of instructional time items. These cases were reviewed to ascertain whether the teacher had mistakenly reported the classroom characteristics items on a questionnaire other than that designated for the key child. In the third step, update specifications were prepared, directing data preparation staff to apply the classroom characteristics data to the key child record for the classroom. Updates were made to 30 English records, 13 mathematics records, and 20 science records as a result of this review. A review was also conducted to identify classrooms with multiple sampled children for which no key child instrument was returned. There were 14 such cases for English, 5 such cases for mathematics, and 10 such cases for science. In some cases, the teacher had reported the classroom characteristic items on a questionnaire other than that designated for the key child, and those data were used for that classroom."}, {"section_title": "Coding and Editing Specifications for Hard-Copy Questionnaires and Assessments", "text": ""}, {"section_title": "Receipt Control", "text": "In order to monitor the almost 96,000 documents that were to be received in the eighth-grade year, the project-specific receipt and document control system developed in the kindergarten year was used, with modifications to track hard-copy questionnaires sent to and received from the scanning subcontractor. The receipt and document control system was initially loaded with the identifying information, such as identification numbers for schools, teachers, and children; the links between teachers and children; and the questionnaires that were expected from each school and teacher for each cooperating school in the sample. As data were collected in the field, field supervisors completed transmittal forms for each school to indicate which questionnaires were being mailed to the home office. Once data collection started, receipt control clerks reviewed the questionnaires returned from the field for accuracy and completeness. The identification number on each form was matched against the 6-8 identification numbers in the tracking system to verify that the appropriate number of forms for each school was returned. When the clerks verified that the correct questionnaires were returned, they were logged into the receipt and document control system. Once forms were logged in, they were sorted by instrument type and ID number. Batch forms were generated and included in the batch to indicate which questionnaires were included in the batch. The child assessment forms, the student questionnaire, the teacher questionnaires, and the school administrator questionnaires were batched and sent to the scanning subcontractor to be scanned into electronic form. When these instruments were returned from the scanning subcontractor, the identification number on each form was matched against the identification numbers in the tracking system to verify that the appropriate number of forms for each batch was returned. When the clerks verified that the correct questionnaires were returned, they were logged into the receipt and document control system. rekeyed by more senior data entry operators at a rate of 100 percent to verify the data entry. The results of the two data entry passes were compared and differences identified. In the case of differences, the hardcopy form was pulled and examined to determine what corrections had to be made to the keyed data. These corrections were rekeyed, resulting in an accuracy rate exceeding 99 percent. The verified batches were then transmitted electronically to Westat's study staff and loaded into the computer system for data editing. When these instruments were returned from the Westat data entry staff, the identification number on each form was also matched against the identification number in the tracking system to verify that the appropriate number of forms for each batch was returned. When the clerks verified that the correct forms were returned, they were logged into the receipt and document control system. The following sections describe the coding and editing processes for hard-copy questionnaires."}, {"section_title": "Coding", "text": ""}, {"section_title": "Coding of Questionnaires", "text": "The hard-copy questionnaires required coding of race/ethnicity for teachers, review of \"Other, specify\" text responses, and a quick visual review of particular questions in each questionnaire."}, {"section_title": "6-9", "text": "The quick visual review was to ensure that the questionnaire values were accurate, complete, and consistent across variables, and that the numbers were converted to the appropriate unit of measurement prior to converting data to an electronic format. The coding staff were trained on the coding procedures and had coding manuals to support the process. This staff also edited the data after scanning and the data were loaded into the system. Senior coders verified coding. Review of \"Other, specify\" items. The \"Other, specify\" text responses were reviewed by the data editing staff and, where appropriate, upcoded into one of the existing response categories. The small number of text responses that remained after upcoding did not fit into any preexisting category."}, {"section_title": "Coding of Reading and Mathematics Assessment Forms", "text": "The "}, {"section_title": "Data Editing", "text": "The data editing process consisted of running range edits for soft and hard ranges, running consistency edits, and reviewing frequencies of the results. Range specifications. Hard-copy range specifications set the parameters for high and low acceptable values for a question. Where values were printed on the forms, these were used as the range parameters. For open-ended questions, such as, \"Counting this school year, how many years have you taught in your current school including part-time teaching?\", high and low ranges were established as acceptable values. Data frequencies were run on the range of values to identify any errors. Values outside the range were identified as errors and were printed on hard copy for a data editor to review. Cases identified with range errors were identified, and the original response was updated. In some cases, range 6-10 violations were retained in the data because the value was checked and found to be the value reported by the teacher or school. These were marked as \"keep as is\" cases. Data frequencies were then rerun and reviewed. This iterative process was repeated until no further range errors were found. Consistency checks (logical edits). By programming logical edits between variables, consistency between variables not involved in a skip pattern was confirmed. For example, in the school administrator questionnaire, the number of children eligible for free breakfast could not exceed the total number of children enrolled in the school. These logical edits were run on the whole database after range edits were complete. The logical edits were run separately for each form. All batches of data were combined into one large data file, and data frequencies were produced. The frequencies were reviewed to ensure the data remained logically consistent within the form. When an inconsistency was found, the case was identified, and the inconsistency was printed on paper for an editor to review. The original value was corrected (or checked and marked \"keep as is\"), and the case was then rerun through the consistency edits. Once the case passed the consistency edits, it was appended back into the main dataset. The frequencies were then rerun and reviewed. This was an iterative process; it was repeated until no further inconsistencies were found. S7LATEST, S7NOFACL, S7NOSTAF, and S7OTHER (i.e., q14). If S7USDABR = 2 (no), respondents were supposed to skip S7BRKSTR, S7BRKEND, S7BRKLOC, S7BRKCLR, S7PRABRK, S7ELIBRK, S7PARBRK, S7ELRPBK, and S7PARPBK (i.e., q15-q18). This skip was enforced in post-collection data editing."}, {"section_title": "School participation in breakfast program (school administrator questionnaire", "text": "Frequency and cross-tabulation review. Frequencies and cross-tabulations were run to determine consistency and accuracy across the various forms and matched against the data in the field management system. If discrepancies could not be explained, no changes were made to the data. 7-1"}, {"section_title": "DATA FILE CONTENTS AND COMPOSITE VARIABLES", "text": "This chapter describes the contents of the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K) eighth-grade data files and focuses largely on the composite variables that have been created. The eighth-grade data file can be used for longitudinal analysis in combination with the files from the base year (kindergarten year), first grade, third grade, and fifth grade. See chapter 9 for details about longitudinal analyses. The composites listed in this chapter refer to those created for eighthgrade only. In most instances, the composite specifications are identical to those created for the previous data collection rounds. Any changes from previous specifications are highlighted in this chapter. For reference, the base-year, first-, third-, and fifth-grade user's manuals are included in appendix C of the eighth-grade electronic codebook (ECB). As noted in chapter 1, there is one child-level eighth-grade data file or catalog on the eighth- including composites, are also stored in the child catalog. The file, named child8r.dat for the restricteduse data file, is stored in the root directory of the CD-ROM as an ASCII file. However, it is strongly recommended that users access the data using the ECB software available on the CD-ROM rather than access the ASCII file directly. Appendix B on the CD-ROM contains the record layout for the child catalog. The eighth-grade restricted-use data file can be used for longitudinal analysis in combination with the files from the base year (kindergarten year), first grade, third grade, and fifth grade. See chapter 9 for details about longitudinal analyses. The child catalog on the K-8 full sample public-use data file is named childk8p.dat. It contains one record for each of the 21,409 children who have data for at least one of the rounds of the ECLS-K (fall-kindergarten, spring-kindergarten, first, third, fifth grade, or eighth grade). As with the eighth grade file, childk8p.dat is stored in the root directory of the CD-ROM as an ASCII file, but it is strongly recommended that users access the data using the ECB software available on the CD-ROM 7-2 rather than access the ASCII file directly. Appendix B on the CD-ROM contains the record layout for the child catalog. See chapter 10 for more information on the K-8 full sample public-use data file. This chapter is divided into 10 sections. Sections 7.1 through 7.5 focus on the conventions used in the study and describe identification variables, the structure of the teacher variables, child assessment flags, missing values, and variable names. Section 7.6 provides details about the creation of composite variables on the eighth-grade data file. Section 7.7 focuses on the methodological variables. Section 7.8 discusses variables used to identify children who changed schools. Section 7.9 contains a table of the composite variables. Finally, section 7.10 describes masked variables."}, {"section_title": "Identification Variables", "text": "The eighth-grade data files (child8r.dat and childk8p.dat) contain a child identification (ID) variable (CHILDID) that uniquely identifies each record. Teachers on the child records are identified with the ID variables J71T_ID (English teacher ID, called the \"reading\" teacher ID in previous rounds) and J72T_ID (mathematics or science teacher ID). The structure of the teacher data in springeighth grade is similar to the data in spring-fifth grade because English/reading and mathematics or science teachers were asked to provide data, rather than one main teacher as was done prior to fifth grade. Information about how to use these data and how they are stored is provided in section 7.2. In addition to teacher identification numbers, there are also identification numbers that indicate a child's particular class (English and mathematics/science). For English, the ID variable name is J71CLASS. For mathematics/science, it is J72CLASS. Schools are identified by the ID variable S7_ID (spring-eighth grade). The ID variable S7_ID indicates the school the child attended at the time of the spring-eighth grade data collection. Schools that joined the ECLS-K in the fifth grade have an \"A\" as the first character. Schools that joined the ECLS-K in the eighth grade have a \"C,\" \"D,\" or \"E\" as the first character. If it was not known where the child was at the beginning or the end of the round, the scheme shown in table 7-1 for assigning ID numbers was used. Section 7.8 provides further details on identifying children who changed schools. Each type of respondent (child, parent, English teacher, mathematics or science teacher, special education teacher, and school) has a unique ID number. The original school ID number (S_ID) is the base for all the subsequent ID numbers as children, parents, and teachers were sampled from schools during the base year. The school ID number is a four-digit number assigned sequentially to sampled schools. The number has a series of ranges: 0001-1299 for originally sampled schools; 2000 series for new schools added to the sample during the first grade sample freshening process; 3000 series for substitute schools that replaced nonresponding original sample schools; and 4000 through 6000 series for transfer schools, which were assigned during processing at the home office. (See chapter 4 for a complete description of the ECLS-K sample.) There is also a 9000 series of S_ID numbers that refers to children who do not attend regular school because they are schooled at home (S_ID numbers 9101 through 9499)."}, {"section_title": "7-3", "text": "There are also several specific 9000 series codes for children who were not located or not followed at the end of a round. The school ID numbers start with 999 for these cases. The child ID number (CHILDID) is a concatenation of the school ID where the child was sampled, a three-digit student number, and the letter \"C.\" For example, 0001010C is the ID number of the tenth child sampled in school 0001. The teacher ID numbers (J71T_ID and J72T_ID) are a concatenation of the school ID where the teacher was sampled, the letter \"T,\" and a two-digit teacher number. In rounds of the study prior to spring-fifth grade, the numbering for the two-digit teacher number started with 01, such that 0001T01 was the ID number for the first teacher sampled in school 0001. In spring-fifth grade, the numbering for the two-digit teacher numbers started with T60 so that teachers could be identified easily. In spring-eighth grade, the two-digit teacher numbers started with E01. Thus, in spring-eighth 7-4 grade 0002E01 is the ID number for the first teacher sampled in school 0002. The parent ID number (PARENTID) is linked to the child ID number and is a concatenation of the four-digit school ID, the three-digit student number, and the letter \"P.\" It is the same number as the child ID with a letter \"P\" instead of a letter \"C\" at the end. For example, 0001010P is the ID number of the parent of the tenth child sampled in school 0001. If twins are sampled, the ID of the first child sampled is used to generate the parent ID. For twins, there are two child-level records with the same parent ID. Children with the same teacher can be identified by finding all children on the child file with the same teacher ID. It should be noted that there is a difference in the variable names between the base-year and the first-, third-, fifth-, and eighth-grade special education teacher IDs. In the base year of the study, information from special education teachers was included in a separate file and was not part of the child or teacher catalogs. The ID number for special education teachers in the base-year special education file was T_ID. In the eighth-grade data file (and the first-, third-, and fifth-grade data files), the special education teacher information is included with the rest of the data, necessitating ID numbers to distinguish special education teachers from regular education teachers. In the eighth-grade file, J71T_ID and J72T_ID are used to identify regular education teachers, and D7T_ID is used to identify special education teachers. If there is no special education teacher, D7T_ID will be missing. If there is a special education teacher, D7T_ID will be filled whether or not the special education teacher responded. In either case, it should be noted that there could be missing data for special education data in the part B questionnaire. It is left to users to determine how they would like to set \"Not Applicable\" versus \"Not Ascertained\" codes for such combinations. Users interested in links to special education services, regardless of whether the source of the information was the starting or ending school, can use the composite variable F7SPECS that is based on information from the FMS system rather than the receipt of particular special education questionnaires."}, {"section_title": "Using Teacher Variables", "text": "In the eighth grade, children were expected to have different teachers for English, mathematics, and science, and the teacher questionnaires were specific to each subject to reflect this. (In fifth grade, there were also separate teacher questionnaires for reading, mathematics, and science; however, in previous rounds there was one teacher questionnaire for all subjects.) For the spring-eighth 7-5 grade data collection, all children were assigned to have an English teacher complete questionnaires. Half the children were assigned to have a mathematics teacher complete questionnaires, and the other half were assigned to have a science teacher complete questionnaires. Thus, each child was linked to a maximum of two teachers: one for English, and one for either mathematics or science. However, a teacher could be linked to any number of children. In addition, although each child was linked for only two subjects, a teacher could be linked for three subjects (e.g., linked to child 1 for English/ mathematics, and linked to child 2 for English/science). There are two types of data collected from teachers, taken from four questionnaires. The first type is data about the teacher's background and topics such as instructional level and time, child characteristics, textbooks, homework assignments, and criteria for grades, collected in the teacher questionnaire (one per each teacher linked to a responding ECLS-K child). The second type is data about the child, as reported by the English, mathematics, and science teacher. As discussed in section 7.1, teachers on the child records are identified with the ID variables J71T_ID (English teacher ID) and J72T_ID (mathematics or science teacher ID). These ID variables indicate the teacher ID that links to the child regardless of whether there were data received from that teacher. To determine whether data were receipted from a teacher, flag variables must be used. These flags are described below."}, {"section_title": "Teacher Flags (J71TQUEX, J72TQUEX, F7MTHSCI, T7SAMTCH)", "text": "There are three teacher flags on the file (J71TQUEX, J72TQUEX, F7MTHSCI) that identify the presence or absence of teacher data and indicate if the data are from the English, mathematics, or science teacher. There is also a flag (T7SAMTCH) that indicates if the teacher linked to the child for English and mathematics/science was the same. In the base year of the study, and in the rounds for first and third grades, there was only one teacher (other than a special education teacher, if applicable) assigned to answer questions about the child, and there were flags corresponding to each of the three teacher questionnaires (parts A, B, and C) given to this teacher. In spring-fifth and eighth grades, the flags also corresponded to different teacher questionnaires but the data were collected from English (referred to as reading in spring-fifth grade), mathematics, and science teachers."}, {"section_title": "7-6", "text": "The flag J71TQUEX indicates whether there were English teacher data collected (0 = False; 1 = True), and the flag J72TQUEX indicates whether there were mathematics or science teacher data collected (0 = False; 1 = True). To determine whether the child was linked to a mathematics or science teacher, the flag F7MTHSCI should be used (1 = Math, 2 = Science). Using the flags J7TQUEX and F7MTHSCI together will indicate the presence or absence of data and whether the data were for mathematics or science. For example, if a user sought to examine science teacher data, he or she would first determine whether mathematics or science teacher data had been collected (J72TQUEX = 1) and, if so, examine data for children who were linked to a science teacher (F7MTHSCI = 2) rather than a mathematics teacher (F7MTHSCI = 1). If the child had science teacher data, the user would look at science questionnaire variables (all of which begin with the prefix N7). Mathematics teacher data (variables beginning with the prefix M7) would be missing for that child. Further information on variable prefixes is in section 7.5. There is also a flag (T7SAMTCH) that indicates if the same teacher was linked to the child for both English and mathematics/science. If the value of the flag is 1 (True), then the teacher linked to the child for English and mathematics/science was the same person. If the value of the flag is 0 (False), then the teachers linked to the child for English and mathematics/science were different."}, {"section_title": "Child Assessment Flags (C7ENGFLG, C7MTHFLG, C7SCIFLG, C7STUDAT)", "text": "There are three flags that indicate the presence or absence of child assessment data. C7ENGFLG indicates the presence or absence of an English assessment; C7MTHFLG indicates the presence or absence of a mathematics assessment; and C7SCIFLG indicates the presence or absence of a science assessment. In addition, there is a flag, C7STUDAT, which indicates the presence or absence of student questionnaire data."}, {"section_title": "Missing Values", "text": "All variables in the ECLS-K data use a standard scheme for missing values. Codes are used to indicate item nonresponse, legitimate skips, and unit nonresponse (see exhibit 7-1)."}, {"section_title": "7-7", "text": "Exhibit 7-1. Missing values codes, School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007. The \"Not Applicable\" code (-1) has two purposes. Its primary purpose is to indicate that a respondent did not answer the question due to skip instructions within the instrument or external reasons that led a respondent not to participate. In the parent interview, where the parent or guardian was a respondent, \"Not Applicable\" is coded for questions that were not asked of the respondent because of a previous answer given. For example, a question about a sibling's age is not asked when the respondent has indicated that the child has no siblings. For the teacher and school data where the instruments are selfadministered, \"Not Applicable\" is coded for questions that the respondent left blank because the written directions instructed them to skip the question due to a certain response on a previous question. Another use of the \"Not Applicable\" code is the circumstance in which it is not known whether a respondent would have answered a question series following a lead question. One example of this use of \"Not Applicable\" is school administrator questionnaire question 13. Question 13 asks whether the school participates in USDA's school breakfast program. If the answer to question 13 is \"Yes,\" the questionnaire skips to question 15 about what time breakfast is served (regardless of whether the breakfast is part of the USDA program). If the answer to question 13 is \"No,\" the questionnaire skips to question 14 about why the school does not participate in USDA's school breakfast program. If question 13 was left blank by the respondent, question 14 is coded \"Not Applicable.\" The \"Refused\" code (-7) indicates that the respondent specifically told the interviewer that he or she would not answer the question. This, along with the \"Don't Know\" code (-8) and the \"Not Ascertained\" code (-9), indicates item nonresponse. The \"Refused\" code rarely appears in the school and teacher data because it indicates that the respondent specifically wrote something on the questionnaire indicating an unwillingness to answer the question. The \"Don't Know\" code (-8) indicates that the respondent specifically told the interviewer that he or she did not know the answer to the question (or in rare cases on the self-administered 7-8 questionnaires, \"I don't know\" was written in for the question). For questions where \"Don't Know\" is one of the options explicitly provided, a \"-8\" will not be coded for those that choose this option; instead the \"Don't Know\" response will be coded as indicated in the value label information for that question. The \"Not Ascertained\" code (-9) indicates that the respondent left a question blank that he or she should have answered. For the school and teacher self-administered questionnaires, this is the primary code for item nonresponse. For data outside the self-administered questionnaires (e.g., direct assessment scores), a \"-9\" means that a value was not ascertained or could not be calculated due to nonresponse. \"System Missing\" appears as a blank when viewing codebook frequencies and in the ASCII data file. System Missing codes (blanks) in the eighth-grade data file indicate that an entire instrument or assessment is missing due to unit nonresponse. (Note that in the first grade, System Missing also indicated that some questions were not asked in the school administrator questionnaire for returning schools but were asked in another form of a questionnaire for new schools. This issue does not apply to the third-, fifth-, or eighth-grade files because only one form of the school administrator questionnaire was used.) An example of System Missing is nonparticipation in the parent interview by a child's parent. In this case, all questions from the parent interview will be blank (system missing). These may be translated to another value when the data are extracted into specific processing packages. For instance, SAS will translate these blanks into periods (\".\") for numeric variables. Depending on the research question being addressed, cases with missing values (e.g., -1, -7, -8, -9, and system missing) may need to be recoded. It is advised that users cross-tabulate all lead questions (e.g., whether the child has ever been evaluated by a professional in response to his or her ability to pay attention or learn) and follow-up questions (e.g., whether there was a diagnosis of a problem from a professional) before proceeding with any recodes or use of the data. Missing values for composite variables were coded using the same general coding rules as those used for other variables. If a particular composite was inappropriate for a given household-as the variable P7MOMID was for a household with no resident mother-that variable was given a value of \"-1\" (Not Applicable). In instances where a variable was appropriate, but complete information to construct the composite was not available, the composite was given a value of -9 (Not Ascertained). The \"Refused\" 7-9 and \"Don't Know\" codes were not used for the composites except in the calculations of the height, weight, and body mass index (BMI) composites for spring-eighth grade. 2 28The ECLS-K eighth-grade restricted-use data file is provided on a CD-ROM and is accessible through an ECB that allows data users to view variable frequencies, tag variables for extraction, and create the SAS, SPSS for Windows, or Stata code needed to create an extract file for analysis. The child data file on the ECB is referred to as a \"catalog.\" Instructions for using the CD-ROM and ECB are provided in chapter 8."}, {"section_title": "Variable Naming Conventions", "text": "Variables were named according to the data source (e.g., parent interview, teacher 28 Children's height and weight measurements were each taken twice to prevent error and provide an accurate reading. Children's BMI was calculated based on height and weight. The rules for using \"Don't Know\" and \"Not Ascertained\" codes for these values was as follows. If both the first and second measurement of height in the child assessment were coded as -8 (Don't Know), then the height composite was coded as -8 (Don't Know). If both the first and second measurements of weight were coded as -8 (Don't Know), the weight composite was coded as -8 (Don't Know). If either the height or weight composites were coded as not ascertained (-9), the BMI composite was coded as not ascertained (-9). If neither the height nor weight composites were coded as not ascertained, and either the height or weight composite was coded as -8 (Don't Know), then the BMI composite was coded as -8 (Don't Know). 7-12"}, {"section_title": "Composite Variables", "text": "To facilitate analysis of the survey data, composite variables were created and added to the child data file. Most composite variables were created using two or more variables, each of which is  Table 7-15 lists all the composite variables for the eighth grade. All basic child demographic variables are presented first, followed by variables for household composition. Imputed variables are listed next, followed by demographics for parents (resident father and mother characteristics are followed by characteristics of nonresident biological parents and nonresident adoptive parents). Teacher, classroom, and school variables are listed last. Once the user identifies the composites of interest, he or she can refer to exhibit 8-8 for instructions on accessing the variables from the ECB. It should be noted that some composite variables in the eighth-grade file have changed from prior rounds. Some changes were due to differences in source variables (e.g., there were changes in the school administrator and teacher questionnaires, and the student records abstract and school facilities checklist were not used in spring-eighth grade), and other changes were due to content area deletions (e.g., there are no longer variables in the parent questionnaire about child care, nor variables in the teacher questionnaires about the percentage of limited-English-proficient children in the English, mathematics, and science classes)."}, {"section_title": "Child Composite Variables", "text": "There are many child-level composite variables on the child catalog. Table 7-15 describes all of the composites. Some of these variables are described in further detail here. 7-13"}, {"section_title": "Child's Age at Assessment (R7AGE)", "text": "The child's age was calculated by determining the number of days between the date when the child completed the ECLS-K direct child assessment and the child's date of birth (R7DOBMM, R7DOBDD, R7DOBYY). The total number of days was then divided by 30 to calculate the age in months. The child assessment date was tested for the appropriate range (March to July 2007). If the assessment date fell outside these ranges, the modal assessment date for the child's school was used."}, {"section_title": "Gender (R7GENDER)", "text": "The eighth-grade gender composite was taken from the fifth-grade gender composite, if it was not missing. If it was missing, the third-grade composite was used. The third-grade gender composite was derived using the gender indicated in the parent interview (INQ.016), child report (AIQ.050), and the FMS. Because of the discrepancies found in the third-grade reports of a child's sex, the most frequently reported gender was used for the child. If there were an equal number of reports for male and female from these sources, the following hierarchy of rules was used: if the data were from the parent interview in previous rounds, then the third-grade gender composite, R5GENDER, was equal to gender from that parent data. Otherwise, gender was updated from the third-grade parent interview question. If the parent interview data were missing, gender was updated from the child report. Otherwise, the third-grade gender composite was equal to the composite GENDER from a previous round (because GENDER in previous rounds incorporated the FMS, this last step meant that the FMS was used as the final source of data). If the third-grade gender composite was missing, R7GENDER was decided based on the most frequently reported gender from all sources of data, across all rounds of data collection. (The composite variable for R7GENDER is on the file but not the source variables). For most of the cases the data were collected in the base year. Gender was not asked in the eighth-grade parent interview."}, {"section_title": "Child's Date of Birth (R7DOBYY, R7DOBMM, and R7DOBDD)", "text": "In the eighth grade, the child's date of birth was derived from the fifth-grade date of birth composites if they were not missing. If the fifth-grade composite was missing, the third-grade composite was used. The third-grade date of birth composites were derived from one of three sources: the parent 7-14 report (CHILDDOB), the child report (AIQ.040), or the FMS. If the child's date of birth had been reported in a parent interview from a previous round, that value was used. Otherwise, the value from the third-grade parent interview was used. If those data were not available or were outside the criteria for inclusion (June 1, 19901, to March 31, 1995, the date of birth from the child interview was used. Finally, if the child report was not available or was outside the criteria for inclusion, the FMS value was used. If the date of birth given was before June 1, 1990, or after March 31, 1995, the data were excluded from the third-grade composite. It should be noted that in the kindergarten and first-grade files, the child date of birth composites (DOBYY, DOBMM, and DOBDD) were created using two rather than three sources of data. The two sources were parent interview data and, in cases in which the parent interview data did not exist or were outside reasonable boundaries, FMS data. In spring-third grade, a third source-the child-was added and used in the creation of the third-grade composite. If the third-grade composite was missing, the eighth-grade composite for date of birth was taken from a previous parent interview. Otherwise, date of birth was taken from the FMS."}, {"section_title": "Race/Ethnicity (W8AMERIN, W8ASIAN, W8PACISL, W8BLACK, W8WHITE, W8HISP, W8MT1RAC, W8RACETH, and R7RACE)", "text": "In spring-eighth grade, the race of the focal child was not collected in the parent interview if a parent interview had been conducted in any of the previous rounds; thus, for these cases, race information is based on information collected in previous parent interviews and the FMS. The composites for the child's race/ethnicity are presented in the ECLS-K files in three ways: (1) as dichotomous variables for each race/ethnicity category (W8AMERIN, W8ASIAN, W8PACISL W8BLACK, W8WHITE, W8HISP, W8MT1RAC) from the parent interview data; (2) as a single race/ethnicity composite taken from the parent interview data (W8RACETH); and (3) as a race/ethnicity composite taken from either the parent data or the FMS, with FMS data used only if parent data were missing (R7RACE). Respondents were allowed to indicate that their child belonged to more than one of the five race categories (White, Black or African American, American Indian or Alaska Native, Asian, Native Hawaiian or other Pacific Islander). From these responses, a series of five dichotomous race variables 7-15 were created that indicated separately whether the child belonged to each of the five specified race groups. In addition, one more dichotomous variable was created for those who had simply indicated that their child was biracial or multiracial without specifying a race. The retention of the dichotomous variables on the file allows users to create different composites as needed. Data were collected on ethnicity as well. Specifically, respondents were asked whether or not their child was Hispanic. Using the six race dichotomous variables and the Hispanic ethnicity variable (e.g., from spring-third grade P5HSP_1 to P5HSP_25, depending on household size), the race/ethnicity composite variables for the child (W8RACETH and R7RACE) were created. The categories were White, non-Hispanic; Black or African American, non-Hispanic; Hispanic, race specified; Hispanic, no race specified; Asian; Native Hawaiian or other Pacific Islander; American Indian or Alaska Native, and more than one race specified, non-Hispanic. The child composites W8RACETH (race/ethnicity) and R7RACE (race/ethnicity) both share these categories; however, FMS data were used to fill in missing parent report data for the variable R7RACE, and only parent report data were used for the variable W8RACETH. A child was classified as Hispanic if a respondent indicated the child's ethnicity was Hispanic regardless of whether a race was identified and what that race was. For W8RACETH, if the child's race/ethnicity information was available from the parent interview composite in a prior data collection (e.g., W5RACETH, W3RACETH, W1RACETH, WKRACETH), the value from the most recent year composite was used and copied forward.2 30 If the data were missing for a child from all of these composites, W8RACETH was -9 (Not Ascertained). For R7RACE, responses from the parent interview composite from fifth grade (R6RACE) were copied forward. If fifth-grade data were missing, responses from the composite from third grade (R5RACE) were used. If the third-grade composite, R5RACE, was missing, then the race variable based on parent interview data in the third grade were used (W3RACETH). If the third-grade composite was missing, the first-grade composite was used (W1RACETH). If the first-grade composite was missing, the race variable based on parent interview data in kindergarten was used (WKRACETH). If the parent interview data were missing, then FMS data from a previous round were used. If previous round FMS data were missing, then FMS data on race from the eighth-grade were used. 30 A number of respondents, both in this and in prior rounds, gave some variant of \"biracial\" as the other-specify response to child race. In previous rounds, these responses had been considered to be uncodeable, and the relevant children were given a value of -9 (Not Ascertained) for WKRACETH and W1RACETH. In spring-third, spring-fifth, and spring-eighth grades, these responses were treated as multiracial, and the relevant children were given a value of 8 (multiracial) for W3RACETH, W5RACETH, or W8RACETH."}, {"section_title": "7-16", "text": "It should be noted that for eighth-, fifth-, and third-grade variables R7RACE, R6RACE, and R5RACE, previous parent interviews were prioritized over the FMS. This is different from the method used to derive the variable RACE in the first grade. In the first grade, the composite RACE was copied forward from previous rounds and FMS data were used if parent reports were not available. Because parent reports were expected to be more accurate than school records, if new information about race was obtained in the third-grade parent interview, it was used rather than previous information obtained from the FMS. Therefore, because the third grade race information is copied into composites in later rounds, the eighth, fifth-, and third-grade variables R7RACE, R6RACE, and R5RACE are different from RACE in previous rounds for a minority of cases."}, {"section_title": "Child's Height (C7HEIGHT)", "text": "To obtain good measurements, each child's height was measured twice. An additional variable was used in spring-eighth grade to allow assessors to add one-fourth, one-half-, and three-fourths inch measurements to the primary height variable recorded in whole inches. For the height composite C7HEIGHT, if the two height values from the instrument (i.e., C7HGT1 and C7HGT2 for spring-eighth grade) were less than 2 inches apart, the average of the two height values was computed and used as the composite value. Otherwise, the value that was closest to 65 inches for boys and 63 inches for girls, which is the 50th percentile score for 14-year-olds, was used as the composite value. The height average was determined by the National Center for Health Statistics (NCHS) in collaboration with the National Center for Chronic Disease Prevention and Health Prevention (NCCDPHP)."}, {"section_title": "Child's Weight (C7WEIGHT)", "text": "Each child's weight was also measured twice. An additional variable was used in springeighth grade to allow assessors to add half-pound measurements to the primary weight variable recorded in whole pounds. For the weight composite (C7WEIGHT), if the two weight values from the instrument (i.e., C7WGT1 and C7WGT2 for spring-eighth grade) were less than 5 pounds apart, the average of the two values was computed and used as the composite value. Otherwise, the value that was closest to 114 pounds for boys and 108 pounds for girls, the median weight for 14-year-olds as determined by NCHS in collaboration with the NCCDPHP, was used as the composite value. services were coded 1 (Yes). This was done even if data for some of the source variables were missing. In spring-fifth and spring-eighth grades, unlike previous rounds, another source variable used to code P7DISABL was CHQ.300 for vision-related problems. If the source variable for the vision diagnosis (CHQ.300) was coded 1 (Yes) and the follow-up question (CHQ.316) was coded NOT \"correctable by glasses\" (i.e., either only \"improvable with glasses\" or \"not correctable with glasses\"), the composite P7DISABL was coded 1 (Yes). Also, in spring-eighth grade, as in spring-fifth grade, the composite P7DISABL was coded 1 (Yes) if the child had vision problems such that the child's best eyesight (CHQ.320) allowed him or her to see large print in books, form and/or color of objects but not detail, shadows, lights, or saw no light or had no light perception. If data for all the source variables were missing, the composite was coded -9 (Not Ascertained). Otherwise, P7DISABL was coded 2 to indicate no reported disability. It should be noted that the spring-third, -fifth, and -eighth grade composites are somewhat different from the composites in previous rounds of the study because questions were added about overall 7-18 behavior and relations to adults and about emotional behavior such as anxiety or depression. Only diagnosed emotional or behavioral problems were included in the composite. These include the following: Unlike the disability composite in fall-kindergarten that included a question about children's coordination in using their arms or legs, the disability composites since spring-first grade have not included that question. The disability composites in spring-fifth and spring-eighth grades are different from other years of the study because they exclude children who have a diagnosis, but the diagnosis was that the child had \"no problem.\" They also exclude children with correctable vision. Any answers that indicate, for children who do not have correctable vision, what a child's best eyesight allows him or her to see are also counted as having a disability. The question about what a child's best eyesight allows him or her to see asks if the child can see large print in books and form and/or color of objects, but not detail; if the child can see shadows and lights; or if the child sees no light or has no light perception. In both spring-fifth and spring-eighth grades, questions asked if the child ever had a disability rather than whether he or she had a disability since the last round of data collection as had been done in earlier rounds of the study. Thus, disabilities that were diagnosed before spring-fifth and spring-eighth grades are included."}, {"section_title": "Family and Household Composite Variables", "text": "Many composites were created to capture information about the sampled children's family and household characteristics. Several of these are described below. All of the family and household composites are listed and described in table 7-15."}, {"section_title": "Number of Siblings (P7NUMSIB)", "text": "The composite P7NUMSIB indicates the total number of siblings (full, step-, adoptive, or foster) with whom the child lived in the household (FSQ.160 and FSQ.170). Siblings were identified through the respondents' stated relationship of the sibling to the focal child. In addition, any child that was reported to be a child of the focal child's parent/guardian was considered a sibling of the focal child. Although round 7 was 3 years later than round 6 in terms of the child's grade level (grade 5 in round 6, and grade 8 in round 7), data collection for parents was in the fall of the year in round 7 rather than in the spring as in other rounds, so there were not 3 full years between data collections. Thus, age was increased by 2 years rather than 3. Age changes were made to increase the ages of all household members other than the focal child and twin (the ages of the focal child, and twin, if applicable, were updated based on birth date). The ages of all household members who were not new to the study in spring-eighth grade (other than the focal child and twin) were increased by the numbers shown in table 7-2. Ages were increased incrementally each round of the study. The numbers in table 7-2 reflect the total number of years added to the first reported age for a household member when the household joined the study. The guidelines for creating these were as follows: (1) half-years could not be included, and (2) the same number of years was added for those who entered the study during the same school year. The numbers were made to err on the side of making persons older rather than younger because this would cause fewer problems with range checks and displays in the parent interview if there was a discrepancy between actual age and imputed age. "}, {"section_title": "7-20", "text": ""}, {"section_title": "Food Security Status", "text": "Food security status of the children's families was assessed based on responses to the 18 food security questions (P7WORRFD through P7NOMONY) in the spring-eighth grade parent interview. The questions measured a wide range of food insecurity and reduced food intake issues. They were combined into a scale using statistical methods based on the Rasch measurement model. "}, {"section_title": "7-21", "text": "When selecting a food security scale for a research application, the likely effects on the measures of the ages of children in the household should be taken into consideration. Young children in U.S. households are generally protected from disrupted diets and reduced food intake to a greater extent than are older children in the same households. The household scale combines adult and child items and, as a result, can reflect, in part, experiences of elder siblings of the sampled child. The Children's Food Security Scale refers to conditions among any/all of the children in the household, so it may also reflect the experiences of elder siblings of the sampled child. Thus, for many research applications, the adult scale may be preferred instead of the household scale or children's scale. In other applications, the household or children's scale may be used with controls for the presence and age of older children in the household. Comparisons of the food security of households over time could also be distorted by the higher probability that the sampled children will be affected by the food insecurity of the household as they grow older. Using the adult scale for such comparisons will avoid this problem. interval-level measure based on the Rasch measurement model and is appropriate for linear models, such as correlation, regression, or analysis of variance. It is on the standard (logistic-unit) metric described in Measuring Children's Food Security in U.S. Households, 1995-99 (for households without children). Valid values range from 1.7 to 11.1, with higher values indicating more severe food deprivation. The scale score is undefined for households that affirmed no adult-referenced items (see discussion of P7FSSCAL above)."}, {"section_title": "Food Security Status: Categorical Measures (P7FSSTAT, P7FSCHST, and P7FSADST)", "text": "P7FSSTAT is a categorical measure of Household Food Security status formed by dividing P7FSSCAL into three ordered categories: food secure, food insecure without hunger, food insecure with hunger. In previous rounds, the third category of \"food insecure with hunger\" was broken into two categories: \"food insecure with hunger (moderate)\" and \"food insecure with hunger (severe).\" In springfifth and spring-eighth grades, these categories have been collapsed into one. P7FSSTAT is appropriate for comparing prevalence rates of food insecurity and hunger across subpopulations and can be used as a categorical variable in associative models. There are few cases in the most severe category, so, for most prevalence reporting purposes, the two categories of food insecure with hunger (moderate and severe) should be collapsed and reported as a single category. When interpreting food security statistics, users should remember that food security status is a household-level characteristic. In most households classified as food insecure with hunger, the children in the household were not hungry. P7FSCHST is a categorical measure of Children's Food Security status that identifies households with hunger among children at some time during the 12 months prior to the survey. This variable is appropriate for comparing prevalence rates of hunger among children across subpopulations. There were few households (n = 39, 0. "}, {"section_title": "7-23", "text": "P7FSADST is a categorical measure of Adults' Food Security status that identifies households as food secure, food insecure without hunger, or food insecure with hunger among adults. This variable is appropriate for comparing prevalence rates of food insecurity and hunger among adults across subpopulations."}, {"section_title": "Food Security Status: Raw Scores (P7FSRAW, P7FSCHRA, and P7FSADRA)", "text": "The Household Food Security raw score, P7FSRAW, is a count of affirmative responses to the 18 items. This is an ordinal-level measure of food insecurity. It is not recommended for direct use in analysis but can be used to identify categories of food insecurity additional to the categorical measures provided in the NCES data file. The Children's Food Security raw score, P7FSCHRA, is a count of affirmative responses to child-referenced items. Responses to items skipped because of screening are assumed to be negative. Families with no valid responses are coded as missing (-9). It ranges from 0 to 8. P7FSADRA is the adult food security raw score, a simple count of the number of household-and adultreferenced food security items affirmed by the parent. It ranges from 0 to 10."}, {"section_title": "Socioeconomic Status (SES) and Poverty (W8DADSCR, W8MOMSCR, W8SESL, W8SESQ5, W8INCCAT, W8POVRTY)", "text": "Socioeconomic status (SES) was computed at the household level using data for the set of parents who completed the parent interview in the fall of eighth grade. The SES variable reflects the socioeconomic status of the household at the time of data collection (fall 2006). The components used to create the SES were as follows: father/male guardian's education; mother/female guardian's education; father/male guardian's occupation; mother/female guardian's occupation; and household income."}, {"section_title": "7-24", "text": "Occupation was recoded to reflect the average of the 1989 General Social Survey (GSS) prestige score. This was computed as the average of the corresponding prestige scores for the 1980 census occupational categories covered by the ECLS-K occupation. Table 7-15 provides details on the prestige score values (W8DADSCR, W8MOMSCR). The variables were collected as follows: Income. The information about income was collected in the fall of eighth grade. Broad-range and detailed-range income questions were asked of all participants. The broad range classifies household income as $25,000 and less per year, or as greater than $25,000. The detailed range classifies household income as shown in table 7-3. Households that were determined to meet the size and income criteria related to poverty shown in table 7-4 were asked to report income to the nearest $1,000. (For simplicity, this is called exact income.) Because not all households were asked to report exact income, the midpoint of the detailed income range was used to compute the SES composite variable. Parent's education. The information about parent's education was collected or updated in spring-eighth grade. Parent's occupation. The information about parent's occupation was collected or updated in spring-eighth grade.   A two-stage procedure was used to impute missing values for parent's education and occupation, while missing values of the detailed income category were imputed in only one step. The procedure used for creating the SES variable was the same as the procedure used for previous rounds of the ECLS-K with the only difference that missing values of income category were all imputed by hot deck and not filled in with data from previous rounds that were at least 3 years old. However, income data from previous rounds were used to sort the records in the imputation cells so that the imputed values are from donors with the closest income values."}, {"section_title": "7-25", "text": "First, if a parent had completed an interview in the kindergarten-, first-, third-, or fifth-grade year, missing values for the fall-eighth grade education and occupation were filled in with values from the 7-26 previous years. The rationale for this approach was that the best source of data for an individual or a household was the data from a previous year. This first imputation stage was implemented as follows: Education level was brought forward from the most recent previous round. This was done only if the same person was the parent figure both in fall-eighth grade and in the earlier round. Occupation was brought forward only if the individual was in the labor force (i.e., was working at a paid job, on vacation from a paid job, or looking for a job). It was also required that the same person be the parent figure both in fall-eighth grade and in the earlier round. NOTE: Prestige scores were not assigned to individuals unless they were in the labor force, regardless of whether they reported an occupation. Second, education and occupation data still missing after this initial step were imputed using a hot-deck methodology. In hot-deck imputation, the value reported by a respondent for a particular item is assigned or \"donated\" to a \"similar\" person who failed to respond to that question. Auxiliary information known for both donors and nonrespondents is used to form groups of persons having similar characteristics. These groups of similar respondents and nonrespondents are called \"imputation cells.\" The imputed value for a case with a missing value is taken from a randomly selected donor among the respondents within the cell. Detailed income category was brought forward from the most recent previous round, but was used only as a sort variable in the hot-deck procedure. All missing values of the detailed income category were imputed by hot deck. By using filled-in values from the previous rounds as a sort variable, the nearest neighbor was selected as donor for the missing value. Imputation cells were defined by respondent characteristics that were the best predictors of the variables to be imputed. These relationships had been determined previously by Chi-Squared Automatic Interaction Detector (CHAID) analyses of the base-year data. Missing values for the education, occupation, and detailed income range variables were imputed by the hot-deck method for all households. Hot-deck imputation was done in a sequential order, separately, by type of household (female single parent, male single parent, and both parents present). For households with both parents present, the mother's and father's variables were imputed separately. Imputed as well as reported values were used to define imputation cells; missing values for donor characteristics were treated as a separate category. No"}, {"section_title": "7-27", "text": "imputed value was used as a donor. No donor was used more than once. The order of hot-deck imputation for all the variables was education, occupation, and income category. Occupation imputation involved two steps. First, the labor force status of the parent was imputed (i.e., whether the parent was employed). Then the parent's occupation was imputed only for those parents whose status was identified as employed either through the parent interview or the first imputation step. The detailed income range was imputed in two steps: first for cases where the broad income range was known and, second, for cases where it was unknown. detailed income range, where the broad income range was known; and detailed income range, where the broad income range was unknown. At this point, all of the missing values had been imputed. However an exact income value was still required to construct the SES composite. The midpoint of the detailed income range was assigned for this purpose to all households. The log of the detailed income range midpoint was then used to compute the SES composite. This value does not vary widely within the levels of the detailed income range, so the midpoint was a reasonable choice. It was used only for the purpose of computing the SES composite and was not retained in the data file. All missing values of the SES components were imputed by the process described above. Tables 7-6 through 7-9 summarize the results.    "}, {"section_title": "7-28", "text": ""}, {"section_title": "7-29", "text": "where m i is the number of nonmissing SES components for the i-th household. W8SESL is the continuous variable for the SES composite that ranges from -2.48 to 2.54. As described, the SES composite is the average of up to five measures, each of which was standardized to have a mean of 0 and a standard 7-30 deviation of 1, hence the negative values. For analyses that require a continuous SES measure, such as multivariate regressions, W8SESL is the variable to use. A categorical SES variable (W8SESQ5) was created that contains the quintile for the value of the composite SES for the child. Quintile 1 represents the lowest SES category and quintile 5 represents the highest SES category. The quintiles were computed at the child level using the fall-eighth grade parent weights. For categorical analyses, use W8SESQ5 and the parent weight. Note that, for households with only one parent present, not all the components were defined. In these cases, SES was computed averaging the available components. The imputed detailed income range variable (W8INCCAT) was also used to create a household-level poverty variable (W8POVRTY). Income was compared to census poverty thresholds for 2006, which vary by household size. Table 7-10 shows the detailed income categories used in the ECLS-K parent interview for determining whether to ask a more detailed question about income to the nearest $1,000. For comparison, the table also shows weighted poverty thresholds from census. 3 31Households whose income fell below the appropriate threshold were classified as poor (see table [7][8][9][10]. For example, if a household contained two members, and the household income was lower than $13,167, then the household was considered to be below the poverty threshold. If either the ECLS-K category or the amount from the detailed question about income would place the household in poverty, the household was flagged as poor. The categorical measure was generally the deciding factor for defining poverty status for the composite because the detailed question about income had a range check that did not allow detailed incomes much beyond the range of the categorical question; however, the range check did allow for incomes that were slightly above the categorical range. Thus, the income ranges and the exact income amounts in the poverty thresholds were not always perfectly aligned. For example, for households of 4 or more, the categorical limit was $15,000-$20,000, but a household with the exact income amount of $20,614 (just outside the categorical limits) would still be included as poor. "}, {"section_title": "Parent Education (W8PARED, W8DADED, and W8MOMED)", "text": "There are three parent education composites on the file. These are W8PARED PEQ.021, verified whether the parent had a high school diploma or its equivalent, such as a GED. If there was no education information to update from spring-fifth grade, respondents were asked for their highest education level in PEQ.020. If this education level was less than the education level reported in a previous round, the higher education level was kept for the spring-eighth grade composite."}, {"section_title": "7-32", "text": "If both parents/guardians resided in the household, W8PARED was the highest value for education level from either the mother/guardian in W8MOMED or the father/guardian in W8DADED. If the household only had one parent or guardian, then W8PARED was equal to either W8MOMED or W8DADED depending on which parent or guardian resided with the child. If the education data for either of the parents were missing3 32 it was imputed, and the composite W8PARED was created based on both the reported and imputed data."}, {"section_title": "Parent Race/Ethnicity (P7HDRACE and P7HMRACE)", "text": "The composites for race/ethnicity for the parents were calculated in the same way as those for the child, except that there is not a variable that supplements parent-reported race/ethnicity with FMS data similar to the variable R7RACE for children. All data on parent race/ethnicity are derived from the parent interview. Race/ethnicity for parents is presented in the spring-eighth grade data file as a categorical race/ethnicity composite (for the father/male guardian it is P7HDRACE, and for the mother/female guardian it is P7HMRACE). Respondents were allowed to indicate that they belonged to more than one of the five race categories (White, Black or African American, American Indian or Alaska Native, Asian, Native Hawaiian or other Pacific Islander). From these responses, a series of five dichotomous race variables were coded that indicated separately whether the respondent belonged to each of the five specified race groups. In addition, one more variable was coded for those who had simply indicated that they were biracial or multiracial without specifying the race.3 33 The dichotomous codes for each of the race variables are not provided on the spring-eighth grade file, but the composite derived from the responses is provided. Parent race/ethnicity was obtained for all parents and spouses of respondent parents but may or may not have been collected for a parent's boyfriend or girlfriend. For example, in a family with a birth mother and stepfather the race/ethnicity of both parents was obtained. However, in a family with a birth mother and her boyfriend, if he was not identified as a spouse or partner of the mother, the race/ethnicity of the mother was obtained but that of the boyfriend was not. 32 Missing data were due to \"Refused\" or \"Don't Know\" answers from respondents. 33 In a previous round of the study, respondents who reported they were \"biracial\" in the \"other\" category were classified as \"uncodeable.\" These responses were reclassified as \"multiracial\" in spring-fifth and spring-eighth grades. "}, {"section_title": "Grade-Level Composite (T7GLVL)", "text": "To create the grade-level composite (T7GLVL), two sources of grade data were used: 1information from the special education teacher part B questionnaire (E7ENRGR (SPB Q2) with answer categories for grades 5-10 and classes that were ungraded) and 2information from the FMS (C_GRADE with answer categories for grades 2-10). Teacher reports were prioritized over the FMS because it was assumed that teachers had the best knowledge of the child's grade and that school records (on which the FMS was based) were more apt to be in error. If the teacher report from E7ENRGR was missing, the FMS variable C_GRADE was used. If both sources of information were missing, then T7GLVL was not ascertained. It should be noted that the ungraded category was renumbered in springeighth grade to incorporate ninth and tenth grades (\"ungraded\" was category 9 in spring-third grade, and is category 13 in spring-eighth grade). In spring-fifth grade, the grade-level composite was created somewhat differently because there were five possible sources of information: (1) the reading teacher questionnaire (Q1 G6GRENRL for grade level); (2) the special education teacher questionnaire, part B (Q2 E7ENRGR for grade level); (3) the child assessment introductory section (AIQ.030 C6INGRAD); (4) the child assessment closing section (ACQ.005 C6FIFTH and ACQ.010 C6GRADE, completed by interviewer); and (5) FMS information about grade level. If conflicts existed among these five sources, the grade level indicated by the majority of the nonmissing sources was used for T6GLVL. If there was not a majority answer for grade level, the grade indicated in a particular source was selected, according to the hierarchy of (1) Classroom reading teacher, G6GRENRL; (2) Special education teacher, E7ENRGR; (3) Assessment 7-34 introduction, C6INGRAD; (4) Assessment closing, C6FIFTH and C6GRADE; and (5) FMS. One exception to this hierarchy was made. Because the FMS and AIQ grade-level information did not allow for ungraded classrooms, the FMS and AIQ information were not considered in any case in which at least one source indicated an \"ungraded\" classroom. It should be noted that in spring-first grade, there was information about grade level from the student record abstract; however, there were no grade-level questions in the child assessment at that time. In both spring-third and spring-fifth grades, grade level was not asked in the student records abstract, but was included as part of the child assessment instead. The spring-eighth grade data collection did not include a student records abstract instrument."}, {"section_title": "School and Class Composite Variables", "text": "Variables on school and class characteristics were constructed from the teacher and school data and the sample frame. Details on how some of the variables were created follow."}, {"section_title": "School Type (S7SCTYP)", "text": "In spring-eighth grade, the questions in the school administrator questionnaire changed, and some variables used in spring-fifth grade were not in the questionnaire. Also, rather than using a single question to determine whether the school was public (as in spring-fifth grade), in spring-eighth grade public schools were defined by three variables (comprehensive public school, public magnet school, or public school of choice). In spring-eighth grade, S7SCTYP was created as follows: If Question 7 in the school administrator questionnaire (which of the following characterizes your school) was answered as a comprehensive public school (not including magnet school or school of choice) (S7REGSKL); a public magnet school (S7MAGSKL); or a public school of choice (open enrollment) (S7CHCESK), the school was coded as \"public.\" Otherwise, if the question was answered as a Catholic school (S7CATHOL), the school was coded as \"Catholic.\" If the question was answered as other private school, religious affiliation (S7OTHREL), the school as coded as \"other religious.\" If the question was answered as private school, no religious affiliation (S7OTHEPRI), then the school was coded as \"other private.\" Homeschooled 7-35 children (those schooled at home instead of at school) were coded as -1. If S7SCTYP could not be coded from the school administrator questionnaire, S6SCTYP, S5SCTYP, S4SCTYP, S3SCTYP, S2KSCTYP, and CS_TYPE2 were used. If those sources were also unavailable, a variable from the school master file was used. If S7SCTYP was missing from all sources, it was coded as -9 (Not Ascertained). As noted above, the school type composite was created somewhat differently in previous rounds. In spring-fifth grade, S6SCTYP was created based on questions 5 (S6PUBLIC) (whether school is public) and 7 (S6CATHOL, S6OTHREL) (type of private school) from the school administrator questionnaire. If the response to question 5 (Is this a public school?) was \"Yes,\" then S6SCTYP was coded \"public.\" If the response to question 7.a. (S6CATHOL) (Is your school a Catholic school?) was \"Yes,\" then the school was coded as \"Catholic.\" Otherwise, if the response to question 7.b. (S6OTHREL) (Is your school private with another religious affiliation?) was \"Yes,\" then S6SCTYP was coded as \"private, other religious.\" Otherwise, because the skip pattern to question 7 was used only if the school was private, if the response to question 7.c. (S6NAISKL, private school accredited by NAIS), question 7.d. (S6OTHPRI, other private), question 7.e. (S6PVTSPD, special education school-primarily serves children with disabilities), or question 7.f. (S6PVTEAR, an early childhood center-school or center includes preschool and/or early elementary grades) was \"Yes,\" then S6SCTYP was coded as \"other private.\" If S6SCTYP could not be coded from the school administrator questionnaire, reports of school type from the same school in previous rounds were used (in spring-third grade, school type was taken from a questionnaire called the school fact sheet, and the variable name was S6SCTYP; in previous rounds, school type had been asked in the school administrator questionnaire, and the variable names were S4SCTYP, S3SCTYP, S2KSCTYP, and CS_TYPE2). If those sources were unavailable, a variable from the school master file was used. If S6SCTYP could not be coded, S6SCTYP was coded as -9 (Not Ascertained). If the child was schooled at home, the composite was coded as -1 (Not Applicable)."}, {"section_title": "Public or Private School (S7PUPRI)", "text": "S7PUPRI is a less detailed version of school type (with only two categories-public and private) and is derived from the school type composite S7SCTYP described above. In spring-eighth grade, and in previous rounds of the study, it was created as follows. If S7SCTYP was 4 (public), then S7PUPRI was coded as \"public\" (1). If S7SCTYP was 1-3 (Catholic, other religious, other private), then S7PUPRI was coded as \"private\" (2). If S7SCTYP was coded as Not Ascertained (-9), then S7PUPRI 7-36 was -9 (Not Ascertained). If S7SCTYP was coded \"Not Applicable,\" then S7PUPRI was coded \"Not public school universe. If these were also missing, the variable was coded -9 (Not Ascertained). If the child was schooled at home, the composites were coded -1 (Not Applicable). The composite was created in the same way in previous rounds of the study; however, the highest category in spring-fifth grade was for 750 or more students. In spring-eighth grade, categories 5 and 6 have been changed to \"750-999 students\" and \"1,000 and above students,\" respectively, to reflect the larger size of middle schools. "}, {"section_title": "Percent Minority Students in the School (S7MINOR)", "text": "The composite variable S7MINOR indicates the percentage of minority students in a school in spring-eighth grade. The composite is based on a question in the school administrator questionnaire (Q11) that was used to ask about the number or percentage of students in the following categories: Asian or Pacific Islander; Hispanic, regardless of race; Black, not of Hispanic origin; White, not of Hispanic origin; American Indian or Alaska Native; and other. The composite was based on the sum of percentages for all categories except White, not of Hispanic origin. In some cases, the composite could not be obtained from the data because of missing data or errors. If the composite could not be derived from the data, percent minority was obtained from the CCD (for public schools) or the PSS (for private schools). If 7-37 these data were missing, the composite was coded -9 (Not Ascertained). If the child was schooled at home, the composite was coded as -1 (Not Applicable). In all rounds of the study since the first grade, school administrators were allowed to report their answers to the student racial composition questions as either numbers or percents, whereas in springkindergarten they were asked to report those answers as percents. All answers recorded as numbers in spring-eighth grade were converted to percentages for the composite variable. The sum of the answers across all categories was allowed to add within +/-5 percent of the reported total. In a few cases, this produced answers slightly over 100 percent. These were topcoded to 100 percent. A flag for each individual race/ethnicity variable indicates whether the answer was reported as a number or a percent.3 34 Because the composite is calculated as a percent, these flags will not be needed by users unless the analyst is interested in examining how answers were reported. If the flags (S7ASNFL, S7HSPFL, S7BLKFL, S7WHTFL, S7INDFL, and S7OTHFL) were equal to 1 for each of the race variables S7ASNPCT, S7HISPPCT, S7BLKPCT, S7WHTPCT, S7INDPCT, S7OTHPCT, these six race/ethnicity variables were reported by the respondent as percentages. It should be noted that the composite for percent minority has been created in the same way since first grade. However, the composites from first grade forward are slightly different from the one used in spring-kindergarten (S2MINOR) because the school administrator questionnaire item that asked about the percent of minority students in the school had different response options. In springkindergarten, the percent of minority students was derived from answers to the school administrator questionnaire by determining the percentage of children who were of either Hispanic or Latino origin (question 14) and the percentage of children who were American Indian or Alaska Native, Asian, Black or African American, or Native Hawaiian or Other Pacific Islander (question 15) to create the percent minority composite. In spring-first, -third,-fifth, and-eighth grades, ethnicity and race were included in the same question. 34 There were also other questions in the school administrator questionnaire that allowed for answers to be recorded as either a number or percent. The flags for these variables are S7ADAFLG (average daily attendance reported as number/percent), S7ASNFLG (question about Asian or Pacific Islander teachers reported as number or percent), S7HSPFLG (question about Hispanic teachers reported as number or percent), S7BLKFLG (question about Black teachers reported as number or percent), S7WHTFLG (question about White teachers reported as number or percent), S7INDFLG (question about American Indian or Native Alaskan teachers reported as number or percent), and S7OTHFLG (question about teachers of other races reported as number or percent). In all cases, the final variables related to these flags are reported as percentages, but the flags indicate how the answers were originally recorded by respondents. 7-38"}, {"section_title": "Highest and Lowest Grade at the School (S7HIGGRD, S7LOWGRD)", "text": "In spring-eighth grade, there were two composite variables that indicate the highest grade level in the school (S7HIGGRD) and the lowest grade level at the school (S7LOWGRD). Both variables were created by first coding answers of ungraded in question 6 of the school administrator questionnaire (What are the lowest and highest grade levels in your school?), and then coding the highest grade in the school and the lowest grade in the school, respectively. In previous rounds of the study, there was a composite for school instructional level (e.g., S6SCLVL) that had categories of less than first grade, primary school, elementary school, and combined school. However, because the study children were by then in schools that might be connected with grades higher than elementary school, the \"combined\" category is less useful than knowing the highest and lowest grade in the school, so the instructional level composite was not created for spring-eighth grade. The school-level composite from past rounds was used, though, if data from the spring-eighth grade school administrator questionnaire were missing about highest and lowest grades. If these data were also missing, a School Master file variable derived from PSS/CCD (not on file) was used for the composites."}, {"section_title": "School Lunch Composites (S7FLCH_I, S7RLCH_I)", "text": "The school lunch composites were computed at the school level for the set of public schools that have at least one child or parent respondent (i.e., the child had nonzero child weight, C7CW0, or nonzero child-level parent weight, C7PW0) in spring-eighth grade. There are two school lunch composites as follows: Percent of children eligible for free school lunch; and Percent of children eligible for reduced-price lunch. The data that are used to create the school lunch composites were collected in the school administrator questionnaire. Specifically, school principals were asked to report on the total enrollment in the school (S7ANUMCH), the number of children in the school who were eligible for free school lunch (S7ELILNC), and the number of children who were eligible for reduced-price school lunch (S7ELIRED). The percent of children eligible for free school lunch is computed as the ratio of S7ELILNC over S7ANUMCH. Likewise, the percent of children eligible for reduced-price school lunch is the ratio of S7ELIRED over S7ANUMCH."}, {"section_title": "7-39", "text": "Not all schools completed the school administrator questionnaire, and among those who did, not all responded to all three questions needed to compute the school lunch composites. Therefore, there were missing values for some of the components of the school lunch composite variables. Prior to fifth grade, if the source variables have missing value, then the composites were filled in with values computed using the most recent CCD if they are not missing from the CCD, or left missing if they are missing from the CCD. In fifth and eighth grades, the composites were computed as they had been in the past, but if they had missing values, they were imputed. The source variables, however, were not imputed. Table 7-11 shows the level of missing data for the school lunch composite variables among the 2,266 public schools that had child or parent respondents in the eighth grade of the ECLS-K. A two-stage procedure was used to impute missing values for each school lunch composite variable. First, if a school had a nonmissing value for the school lunch composite in the kindergarten, first-grade, third-or fifth-grade year, missing values for the spring-eighth grade school lunch composites were filled in with values from the previous years. The rationale for this approach was that the best source of data for a school was the data from a previous year. Second, data still missing after this initial step were imputed using a hot-deck methodology. Imputation cells were created using the Title I status of the school and the school latitude and longitude. In fifth grade, the information used to derive this variable was from S6TT1 (\"whether school received Title I funds\") and S6TT1TA (\"whether Title I funds are targeted or school wide\"), both from the school administrator questionnaire. If these two variables had missing values for fifth grade, then data from third grade or first grade (if third-grade data were also missing) or kindergarten (if third-grade and first-grade data were also missing) were used. If these data were missing from the school administrator questionnaire for all rounds, then the information from the most recent Common Core of Data (CCD 2002-03) was used. In eighth grade, these variables were dropped from the school administrator questionnaire. Consequently, the imputation process used the information from the CCD 2005-06. If these variables were missing from the CCD, then information from the school administrator questionnaire available from 7-40 the most recent round (fifth grade, third grade, first grade or kindergarten) was used. The values from these different sources are for the exact same schools participating in eighth grade and previous rounds. The resolution of cases having missing data is shown for each school lunch composite in   Since children were designated as eligible for either free lunch or reduced-price lunch but not for both services, the two school lunch composites should sum to no more than 100 percent. A very small number of schools (less than 4 percent) had imputed values of the two school lunch composites summing to more than 100 percent. These values came from two sources: (1) from values reported by the school in another year or (2) from the hot-deck imputation. The reporting error has been present in all rounds of the ECLS-K, and the decision was to keep the reported values in the data file. If the erroneous 7-41 values came from the hot-deck imputation, then they were corrected so that the two school lunch composites do not add to more than 100 percent. Dates (S7SCHBDD, S7SCHBMM, S7SCHBYY,   S7SCHEDD, S7SCHEMM, S7SCHEYY)"}, {"section_title": "School Year Start and End", "text": "The composite for school year start and end dates was taken from the school administrator questionnaire (Q3, S7SYRSMM, S7SYRSDD, S7SYRSYY, S7SYREMM, S7SYREDD, S7SYREYY). If those data were missing, the values were taken from the FMS. In spring-fifth and spring-eighth grades, the answers for the starting date, year (S7SCHBYY) and the ending date, year (S7SCHEYY) had already been filled in for the school administrator when he or she received them. It should be noted that in spring-third grade, the question about school year starting and ending dates was in the school fact sheet. Also, in spring-first grade and spring-kindergarten the composites for school year start and end dates were created differently because they were based on different questions. The question was in the student record abstract rather than in the school fact sheet and was based on responses to multiple questions about start and end dates for school terms (e.g., semesters, trimesters). Composite variable names in past rounds started with an \"L\" prefix in spring-third grade (this was the prefix for the school fact sheet), and a \"U\" prefix in spring-first grade and spring-kindergarten (this was the prefix for the student record abstract). If the start and end dates varied for children in the same school, the composite was created by using the school start and end dates reported for the majority of children in a school. 7-42"}, {"section_title": "FMS Composite Variables", "text": "The composite variables created from FMS data follow."}, {"section_title": "Year-Round Schools (F7YRRND)", "text": "This composite was created using data from the FMS. The FMS flag was \"1\" if the child was in a year-round school. The values for the year-round school composite variable are 1 (Year-round school) and 2 (Not year-round school). If the child was schooled at home, the composite was coded as -1 (Not Applicable)."}, {"section_title": "Indicator of Whether Child Received Special Education Services (F7SPECS)", "text": "The composite variable F7SPECS indicates whether or not the child received special education services in the spring of eighth grade, based on the presence or absence of a link to a special education teacher in the FMS. The values are 1 if the child received special education services, 2 if the child did not receive special education services, and -9 if the link was missing between the child and his or her teacher in the FMS."}, {"section_title": "Indicator of Whether Child Has an Individualized Education Plan (IEP) on Record at", "text": ""}, {"section_title": "School (F7RIEP)", "text": "The variable F7RIEP indicates whether or not the child had an IEP or Individualized Family Service Plan (IFSP) on record at his or her school or another school in the spring of eighth grade. This information was recorded on the student work grid in the FMS in spring-eighth grade rather than in the student records abstract as was done in spring-fifth grade. For this reason, the prefix had changed from \"U\" for the student record abstract to \"F\" for the FMS. The values for the variable are 1 (child has an IEP/IFSP on record at his or her school or at another school) and 2 (child does not have an IEP/IFSP on record at his or her school). If the information was missing, F7RIEP was coded as -9 (Not Ascertained). 7-43"}, {"section_title": "Parent Identifiers and Household Composition (P7DADID, P7MOMID, P7HPARNT, P7HDAD, P7HMOM, P7HFAMIL, P7MOMTYP, P7DADTYP)", "text": "The construction of parent identifiers and the household composition variables from the parent interview data was a two-step process. First, individuals identifying themselves as the child's mother/father were located within the household roster, and the type of their relationship to the child (biological, adoptive, foster, step-, partner of parent, or unknown) was established. For households containing more than one father or mother, a hierarchy was used to designate the \"current,\" or residential, parent of each gender. The biological parent, if present, was always the current mother or father. In the absence of a biological parent, the current mother/father designation was assigned to the adoptive, step-, foster/guardian, partner, or \"unknown-type\" parent. If there were more than one father or mother of the same type, the parent with the lower person number on the household roster was selected. Person number refers to the number each household member has on the roster list. Household members are listed in the It should be noted that, because the composite construction identifies only one resident mother or one resident father, same-sex parents are not readily identified in the composites themselves. Two approaches can be used to identify these couples. First, the user should search the relationship variables (P7REL_1, etc.) to identify households in which more than one person is identified as a father/mother to the focal child. Second, since not all same-sex partners identify themselves as \"mother\" or \"father\" to the focal child, the user should also search for households in which the respondent (identified by P7PER_1, etc.) is the child's parent, and the respondent's spouse/partner (identified from P7SPOUSE) is the same sex as the respondent."}, {"section_title": "7-45", "text": "There are two sections in the parent interview that asked questions specific to the parent figure: PEQ, Parent education; and EMQ, Employment. Each of these sections was completed during the parent interview for up to two parents or parent figures. To indicate which household member or members were the subject of each section, \"pointer\" variables that hold the original number of the household member on the household roster were used. To illustrate how the pointer variables work, suppose there is a household with both a mother and a father who were listed third and fourth in the household roster. If household member #3, the mother, was the first person to receive the PEQ education section, then the pointer variable P7EDUP1 will equal \"3.\" The answers to the education questions for the mother will be contained in interview items in this section that end with the suffix \"_1\" (e.g., P7NDEG_1, P7DEGT_1, P7ENR_1, etc.). The suffix \"_1\" indicates that the data are for the first subject of the questions. Similarly, if household member #4, the father, was the second person to receive the PEQ education section, then the pointer variable P7EDUP2 will equal \"4.\" The answers to the education questions for the father will be contained in interview items in this section that end with the suffix \"_2\" (e.g., P7NDEG_2, P7DEGT_2, P7ENR_2, etc.). The suffix \"_2\" indicates that the data are for the second subject of the questions. Table 7-14 identifies the pointer variables. 7-47"}, {"section_title": "7-46", "text": ""}, {"section_title": "Industry and Occupation Codes Used in the ECLS-K", "text": "This section describes the aggregated categories that were used for coding occupation in the ECLS-K."}, {"section_title": "Executive, Administrative, and Managerial Occupations", "text": "This category includes senior-level and middle management occupations and occupations that directly support management. Senior-level managers are persons concerned with policymaking, planning, staffing, directing, and/or controlling activities. Middle managers include persons who plan, organize, or direct and/or control activities at the operational level. Workers in this category are not directly concerned with the fabrication of products or with the provision of services. Other officials and administrators include consultants, library directors, custom house builders, and location managers. Legislators are also included in this category."}, {"section_title": "Engineers, Surveyors, and Architects", "text": "This category includes occupations concerned with applying principles of architecture and engineering in the design and construction of buildings, equipment and processing systems, highways and roads, and land utilization."}, {"section_title": "Natural Scientists and Mathematicians", "text": "This category includes those engaged primarily in the application of scientific principles to research and development. Natural scientists are those in the physical sciences (e.g., chemistry, physics) and the life sciences (e.g., biology, agriculture, medicine). In addition, this category includes those in computer science, mathematics (including statistics), and operations research."}, {"section_title": "Social Scientists, Social Workers, Religious Workers, and Lawyers", "text": "This category includes occupations concerned with the social needs of people and with basic and applied research in the social sciences."}, {"section_title": "Teachers: College, University, and Other Postsecondary Institution; Counselors, Librarians, and Archivists", "text": "This category includes those who teach at higher education institutions and at other postsecondary (after high school) institutions, such as vocational institutes. In addition, vocational and educational counselors, librarians, and archivists are included here."}, {"section_title": "7-48", "text": ""}, {"section_title": "Teachers, except Postsecondary Institution", "text": "This category includes prekindergarten and kindergarten teachers, elementary and secondary teachers, special education teachers, instructional coordinators, and adult education teachers (outside postsecondary)."}, {"section_title": "Physicians, Dentists, and Veterinarians", "text": "This category includes health care professionals who diagnose and treat patients. In addition to physicians, dentists, and veterinarians, this category includes optometrists, podiatrists, and other diagnosing and treating professionals, such as chiropractors, hypnotherapists, and acupuncturists."}, {"section_title": "Registered Nurses, Pharmacists, Dieticians, Therapists, and Physician's Assistants", "text": "This category includes occupations concerned with the maintenance of health, the prevention of illness and the care of the ill through the provision and supervision of nursing care; compounding drugs, planning food service or nutritional programs; providing assistance to physicians; and the provision of therapy and treatment as directed by physicians."}, {"section_title": "Writers, Artists, Entertainers, and Athletes", "text": "This category includes occupations concerned with creating and executing artistic works in a personally interpreted manner by painting, sculpturing, drawing, engraving, etching, and other methods; creating designs for products and interior decorations; designing and illustrating books, magazines, and other publications; writing; still, motion picture, and television photography/filming; producing, directing, staging, acting, dancing, singing in entertainment; and participating in sports and athletics as a competitor or player and administering and directing athletic programs."}, {"section_title": "Health Technologists and Technicians", "text": "This category includes occupations concerned with providing technical assistance in the provision of health care. For example, clinical laboratory technologists and technicians, dental hygienists, radiologic technicians, licensed practical nurses (LPNs), and other health technologists are included here."}, {"section_title": "Technologists and Technicians, except Health", "text": "This category includes those providing technical assistance in engineering and scientific research, development, testing, and related activities, as well as operating and programming technical equipment and systems."}, {"section_title": "Marketing and Sales Occupations", "text": "This category includes occupations involving selling goods or services, purchasing commodities and property for resale, and conducting wholesale or retail business."}, {"section_title": "7-49", "text": ""}, {"section_title": "Administrative Support Occupations, including Clerks", "text": "This category includes occupations involving preparing, transcribing, transferring, systematizing, and preserving written communications and records; collecting accounts; gathering and distributing information; operating office machines and data processing equipment; operating switchboards; distributing mail and messages; and other support and clerical duties such as bank teller, data entry keyer, etc."}, {"section_title": "Service Occupations", "text": "This category includes occupations providing personal and protective services to individuals, and current maintenance and cleaning for building and residences. Some examples include food service, health service (e.g., aides or assistants), cleaning services other than household, and personal services."}, {"section_title": "Agricultural, Forestry, and Fishing Occupations", "text": "This category is concerned with the production, propagation (breeding/growing), gathering, and catching of animals, animal products, and plant products (timber, crop, and ornamental); the provision of services associated with agricultural production; and game farms, fisheries, and wildlife conservation. \"Other agricultural and related occupations\" include occupations concerned with the production and propagation of animals, animal products, plants, and products (crops and ornamental)."}, {"section_title": "Mechanics and Repairers", "text": "Mechanics and repairers are persons who do adjustment, maintenance, part replacement, and repair of tools, equipment, and machines. Installation may be included if it is usually done in conjunction with other duties of the repairers."}, {"section_title": "Construction and Extractive Occupations", "text": "This category includes occupations that normally are performed at a specific site, which will change over time, in contrast to production workers, where the work is usually at a fixed location. Construction workers include those in overall construction, brickmasons, stonemasons, carpenters, electricians, drywall installers, paperhangers and painters, etc. Extractive occupations include oil well drillers, mining machine operators, and so on."}, {"section_title": "Precision Production Occupations", "text": "Precision production includes occupations concerned with performing production tasks that require a high degree of precision or attainment of rigid specification and operating plants or large systems. Included in this category are tool and die makers, pattern and model makers, machinists, jewelers, engravers, and so on. Also included are some food-related workers including butchers and bakers. Plant and system operators include water and sewage, gas, power, chemical, petroleum, and other plant or system operators."}, {"section_title": "7-50", "text": ""}, {"section_title": "Production Working Occupations", "text": "This category includes occupations concerned with setting up, operating, and tending of machines and hand production work, usually in a factory or other fixed place of business."}, {"section_title": "Transportation and Material Moving Occupations", "text": "This category includes occupations concerned with operating and controlling equipment used to facilitate the movement of people or materials and the supervising of those workers."}, {"section_title": "Handlers, Equipment Cleaners, Helpers, and Laborers", "text": "This category includes occupations that involve helping other workers and performing routine nonmachine tasks. A wide variety of helpers, handlers, etc., are included in this category. Examples include construction laborers, freight, stock, and material movers, garage and service station-related occupations, parking lot attendants, and vehicle washers and equipment cleaners."}, {"section_title": "Unemployed, Retired, Disabled, or Unclassified Workers", "text": "This category includes persons who are unemployed, have retired from the work force, or are disabled. It also includes unclassified occupations that do not fit into the categories above (e.g., occupations that are strictly military, such as \"tank crew member\" and \"infantryman\")."}, {"section_title": "Methodological Variables", "text": "To facilitate methodological research, 11 variables are included on the eighth-grade data file. The identifiers for parent interview work area (F7PWKARE), parent interviewer (F7PINTVR), and child assessment work area (F7CWKARE) were extracted from the FMS. Finally, an indicator variable (F7PREFCV, Parent Interview Refusal Conversion) was created to flag cases that had, at any time, refused to respond to the parent interview but later agreed to participate. The values for F7PREFCV are 1=YES (refused but were converted to be a participant) and 2=NO (did not refuse). 7-51"}, {"section_title": "Children Who Changed Schools", "text": "There are several variables in the file that can be used to determine if a child moved to a different school between rounds of data collection."}, {"section_title": "Children Who Changed Schools Between Rounds (R7R6SCHG)", "text": "A variable on the file that will be of interest to users examining school change is R7R6SCHG (school type change between spring-fifth grade and spring-eighth grade). It indicates whether the child changed schools and, if so, the school type of the previous and the new school (e.g., whether the change was from public to private school, private to private school, etc.). R7R6SCHG is created by comparing the school IDs from spring-fifth grade and spring-eighth grade for children who were in the spring-fifth grade data collection. A difference in IDs indicated a change. If there was no difference in IDs, R7R6SCHG was coded 1 (child did not change schools). For children who changed schools, the spring-fifth grade school type variable S6SCTYP was compared to the spring-eighth grade school type variable S7SCTYP. Categories were assigned as appropriate (2 = child transferred from public to public; 3 = child transferred from private to private; 4 = child transferred from public to private; 5 = child transferred from private to public; and 6 = child transferred, other). Category 6 was used for those children who transferred schools, but school type was unknown. Children who were not in the spring-fifth grade data collection were coded -9, \"Not Ascertained,\" on R7R6SCHG. Children who were homeschooled in spring-fifth grade or spring-eighth grade were coded -1, \"Not Applicable,\" for R7R6SCHG. In previous rounds of the study, there was also a variable that indicated whether a student moved to a \"destination school\" (e.g., R6DEST in spring-fifth grade). Destination schools were schools for which it was determined before data collection that at least four ECLS-K children would move into them from a school that ended before a particular grade or a school that had closed. In spring-eighth grade, the majority of students would have moved from elementary to middle/junior high schools, so this variable was less useful and it was not used in spring-eighth grade. \u25ba Please note that the last two columns of table 7-15 in section 7.9 contain information that is filespecific. Information for the restricted-use file is contained in the second to last column while information for the K-8 full sample public-use file is contained in the last column of table 7-15. 7-52 7.9 Composite Table   Table 7-15 describes the composite and derived variables that are on the ECLS-K child catalog. Note that a few of the variables specified in the \"derived from\" column are intermediary variables that were not included in the final data set. An example of an intermediary variable is the child gender variable from parent questionnaires prior to spring-eighth grade, CHILDGEN. If this variable was missing, or had conflicting information across rounds of the study, information about gender was used from the FMS or child report. The variable CHILDGEN is not included in the final dataset, but the composite R7GENDER is included. Other intermediary variables are taken from either the FMS or the school master file and are not included on the data file. The \"derived from\" column also contains the item numbers from the questionnaire, which help in identifying the items used in the creation of these composites. This information allows a user to decide whether to use the composite based on how it was defined. \u25ba Please note that the following section (7.10) applies to the K-8 full sample public-use file. It does not apply to the eighth-grade restricted-use file."}, {"section_title": "Masked Variables", "text": "For some of the variables on the K-8 full sample public-use file, certain categories were modified. The value labels for those masked variables were updated from the restricted-use variables to reflect the new categories that were created during the masking process. There are three types of modifications on the K-8 full sample public-use data file. Outliers are top-or bottom-coded to prevent identification of unique schools, teachers, parents, and children without affecting overall data quality."}, {"section_title": "7-53", "text": "Variables with too few cases and a sparse distribution are suppressed in the public-use data file. The values for these variables were set to -2 and labeled \"suppressed\" in the ECB. Certain continuous variables are modified into categorical variables, and certain categorical variables have their categories collapsed in the public-use data file. While this protects the cases from a disclosure risk, these variables can still be used in all different kinds of analysis such as logistic regression analysis. In addition to these modifications, other procedures were used in both data files (restricteduse and K-8 full sample public-use) to modify data based on the disclosure analysis NCES conducted in order to protect the identity of the respondents and children. Certain schools identified as at risk for disclosure had a 5 to 10 percent noise introduced in those variables that posed a risk for disclosure. Also, for one group of variables values were modified by \"data swapping.\" This process removes a reported value and replaces it with a reported value from a different respondent for a subset of the records. There is a comment field in the variable frequency distribution view screen of the electronic codebook that displays a comment for each masked variable indicating whether the variable from the restricted-use file has been recoded or suppressed in the K-8 full sample public-use file. Variables that were recoded in any way during the data masking process display the comment, \"These data recoded for respondent confidentiality.\" Variables that were suppressed on the K-8 full sample public-use file for protection of the respondent or child from identification display the comment, \"These data suppressed for respondent confidentiality,\" and all values for the variable are set to equal -2 for that variable. All variables from the special education teacher questionnaire part A (i.e., all variables with the prefix D7) and from the special education teacher questionnaire part B (i.e., all variables with the prefix E7) have been suppressed in the eighth-grade public-use file. Included in this group of suppressed variables are all teacher and school identifiers, which have last two characters \"ID\" and prefix D7 or E7.        "}, {"section_title": "7-54", "text": "Continuous Continuous See note at end of table. Family/HH Adult food security scale score. This is a measure of the severity of food insecurity or hunger experienced by adults in the household in the previous 12 months"}, {"section_title": "7-74", "text": "Continuous Continuous"}, {"section_title": "P7FSADST", "text": "Family/HH A categorical measure of adult's food security status that identifies households as food secure, food insecure without hunger, and food insecure with hunger among adults. "}, {"section_title": "0-100", "text": "Recoded to the following: 1=Less than 1%, 2=1% to less than 5%, 3=5% to less than 10%, 4=10% to less than 25%, 5=25% or more 76 M7PBLK Class Percent of Blacks in math class-child-level data M7BLACK (MTH Q12c), M7TOTRA (MTH Q12G) Note: In round 6, M6CLSZ, a composite, was the source variable rather than M6TOTRA. However, for the reasons described above for G7PBLK, the class size variable is no longer a composite in round 7.\nRecoded to the following: 1=Less than 1%, 2=1% to less than 5%, 3=5% to less than 10%, 4=10% to less than 25%, 5=25% or more 77 N7PBLK Class Percent of Blacks in science class-child-level data N7BLACK (SCI Q12c), N7TOTRA (SCI Q13G) Note: In round 6, N6CLSZ, a composite, was the source variable rather than N6TOTRA However, for the reasons described above for G7PBLK, the class size variable is no longer a composite in round 7.\nRecoded to the following: 1=Less than 1%, 2=1% to less than 5%, 3=5% to less than 10%, 4=10% to less than 25%, 5=25% or more 78 G7PHIS Class Percent of Hispanics in English class-childlevel data G7HISP (RDG Q13b), G7TOTRA (RDG Q13G) Note: In round 6, G6CLSZ, a composite, was the source variable rather than G6TOTRA. However, for the reasons described above for G7PBLK, the class size variable is no longer a composite in round 7.\nRecoded to the following: 1=Less than 1%, 2=1% to less than 5%, 3=5% to less than 10%, 4=10% to less than 25%, 5=25% or more 7-77 \nRecoded to the following: 1=Less than 1%, 2=1% to less than 5%, 3=5% to less than 10%, 4=10% to less than 25%, 5=25% or more 80 N7PHIS Class Percent of Hispanics in science class-child-level data N7HISP (SCI Q12b), N7TOTRA (SCI Q13G) Note: In round 6, N6CLSZ, a composite, was the source variable rather than N6TOTRA. However, for the reasons described above for G7PBLK, the class size variable is no longer a composite in round 7.\nRecoded to the following: 1=Less than 1%, 2=1% to less than 5%, 3=5% to less than 10%, 4=10% to less than 25%, 5=25% or more 81 G7PMIN Class Percent of minorities in English class-childlevel data G7ASIAN, G7HISP, G7BLACK, G7AMRIN, G7RACEO (RDG Q13), G7TOTRA (RDG Q13G) Note: In round 6, G6CLSZ, a composite, was the source variable rather than G6TOTRA. However, for the reasons described above for G7PBLK, the class size variable is no longer a composite in round 7.\nRecoded to the following: 1=Less than 10%, 2=10% to less than 25%, 3=25% to less than 50%, 4=50% to less than 75%, 5=75% or more Note: In round 6, M6CLSZ, a composite, was the source variable rather than M6TOTRA. However, for the reasons described above for G7PBLK, the class size variable is no longer a composite in round 7.\nRecoded to the following: 1=Less than 10%, 2=10% to less than 25%, 3=25% to less than 50%, 4=50% to less than 75%, 5=75% or more 7-78    Note: Category 5 is now 750-999 students and category 6 has been added for schools with 1,000 or more students. 1=0-149 students, 2=150-299 students, 3=300-499 students, 4=500-749 students, 5= 750-999 students, 6=1,000 and above students 1=0-149 students, 2=150-299 students, 3=300-499 students, 4=500-749 students, 5= 750-999 students, 6=1,000 and above students 100 S7MINOR School Percentage of minority students in school PMINOR (School Master File variable derived from PSS/CCD, not on file), S7ASNPCT, S7HSPPCT, S7BLKPCT, S7INDPCT, S7OTHPCT (all from SAQ Q11)"}, {"section_title": "Continuous", "text": "Recoded to the following: 1=Less than 10%, 2=10% to less than 25%, 3=25% to less than 50%, 4=50% to less than 75%, 5=75% or more     These functions allow users to access the accompanying catalog and \"view\" the data in various ways by performing customized searches, queries, and extractions. The organization of this document provides a \"start to finish\" approach through the system, beginning with the installation of the ECB, utilizing the ECB's functions, navigating through the catalog, and performing user-specified data extractions. "}, {"section_title": "7-86", "text": ""}, {"section_title": "2.", "text": "Select the Settings menu and then the Control Panel folder icon.\nClick on a command from the dropdown list. The Menu Bar may also be activated and its options selected using the shortcut keys described in section 8.2.7.\nClick on the Go button.\nIn the Search Text Box (shown in exhibit 8-21), type in \"edu\" and then click on the Search button.\nSelect Open from the Taglist pulldown menu.\nSelect the Add option to display a list of previously saved taglists, shown in exhibit 8-27.\nClick on the Save or Save As button above the Working Taglist column. You can also select the Save or Save As options from the Taglist pulldown menu.\nClick on the Save As button above the Working Taglist column. You can also click on the Taglist pulldown menu and select the Save As option.\nClick on the Taglist pulldown menu (exhibit 8-31) and select the Export option.\nClick on the Taglist pulldown menu (exhibit 8-33) and select the Import option. Exhibit 8-33. Pulldown menu to select Taglist Import 3. You will be prompted to save the current Working Taglist if unsaved changes have been made. Save the taglist if desired.\nThe Working Taglist will be replaced by a New taglist.\nAfter a few seconds, the screen shown in exhibit 8-56 appears indicating that the repair and compact of the database was successfully completed. The command for repairing and compacting the database. The Codebook menu contains the command for the following: Viewing the entire codebook based on the working taglist; and Printing the entire codebook based on the working taglist. The Help menu provides access to the detailed online help system. Longitudinal analyses with the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K) can be conducted both \"within school year\" and \"across school years.\" Examples of within-year analyses are those that look at children's growth in cognitive scores between fall and spring of kindergarten or between fall and spring of first grade. Such analyses do not require the combined use of kindergarten and first-grade data. They can be conducted using only the kindergarten base-year files or the first-grade files only. Therefore, within-school year analyses are not discussed in this chapter. Since data were only collected once for third grade, once for fifth grade and once for eighth grade, within-third grade, within-fifth grade, and within-eighth grade longitudinal analyses are not possible. Cross-year analyses, on the other hand, those that combine information from two or more of the kindergarten, firstgrade, third-grade, fifth-grade, or eighth-grade years, are the focus of this chapter. This chapter describes how to combine (or merge) the kindergarten, first-grade, third-grade, fifth-grade, and eighth-grade files to create cross-year files for K-8 longitudinal analyses. The information contained in this chapter applies to users of the base-year, first-grade, third-grade, fifth-grade, and eighth-grade files. Users of the public-use files can consider using the public-use K-8 full sample file briefly described in chapter 1, which combines data from the base year and first, third, fifth, and eighth grades. It contains longitudinal weights so that analysts can examine children's growth and development between kindergarten and eighth grade. Because it contains most of the variables in the restricted-use files, most users will find it more convenient to use the K-8 full sample data file that NCES releases rather than creating their own longitudinal file (see chapter 10). This chapter begins with a discussion of K-8 longitudinal analyses and the types of research questions that can be addressed with cross-year files. All the examples assume that analysts are including eighth-grade data in their analyses. In chapter 10, additional examples of longitudinal research questions are provided, not all of which include eighth-grade data. It then describes the K-8 longitudinal weights 9-2 available on the cross-sectional file and merging procedures for users who wish to create their own longitudinal files."}, {"section_title": "3.", "text": "In the Control Panel window, click on the Display icon.\nThe Variable List will then scroll down automatically to show the selected variable.\nThe new Variable List will include only the variables that have the text \"edu\" in the variable name or the variable description. The catalog-specific topical variable groupings can be found in appendix E on the CD-ROM. Simply find the topic of interest in the Topic column first and then enter in the Search Text Box the matching keywords in the Variable Identifier to narrow the search.\nThe Open Taglist dialog box, shown in exhibit 8-25, appears. 1. Click on the Taglist pulldown menu to display the menu options.\nHighlight the saved taglist whose variables you wish to add to your Working Taglist.\nThe Save Taglist As dialog box appears as shown in exhibit 8-29.\nThe Save Taglist As dialog box appears, shown in exhibit 8-30, with the current taglist name in the Taglist Name field.\nThe Export Working Taglist To dialog box appears (exhibit 8-32).\nClick on the Taglist pulldown menu and select the Delete option.\nThe codebook for the current taglist opens in a new window as shown in exhibit 8-38. 4. Use the buttons described in exhibit 8-39 to navigate through the displayed codebook. Click this button to change to the previous page. Click this button to advance to the next page. Click this button to change the displayed page to the last page. Click this button to discontinue a page change. Click this button to print the codebook. Refer to the procedure below for steps on printing the codebook. Click this button to export the codebook to a different destination and save it as a different file format. Refer to the procedure below for steps on exporting the codebook. Click the dropdown arrow to select a display magnification of the codebook.\nIn any application that supports bitmap images (e.g., Microsoft Paint, Microsoft Word, etc.), paste the saved image."}, {"section_title": "4.", "text": "Select the Settings tab.\nOn the Select Catalog screen (exhibit 8-10), highlight the name of the catalog. (The eighth-grade ECB has only one catalog.) Exhibit 8-10. Select Catalog screen\nThe selected variable is highlighted.\nClick on the Variable Name, Variable Description, or Both Variable Name and Description radio button to specify where to search.\nClick on the OK button.\nEnter the new name for the taglist in the Taglist Name field.\nEnter the new name of the taglist in the Taglist Name field.\nEnter the file name for your taglist.\nThe Import Taglist From dialog box appears (exhibit 8-34).\nThe Delete Taglist selection screen, shown in exhibit 8-35, appears with the taglists listed that may be deleted.\nPrint the image to the printer using the print function of the application that you are using. \nSelect View from the Codebook pulldown menu.\nDo children who adapted easily to a school setting in kindergarten do better in eighth grade than their peers who experienced more difficulty settling into school, or is slow adjustment to kindergarten associated with poorer performance in eighth grade? 5. Are there particular school or classroom characteristics that are associated with larger growth rates in reading and mathematics skills between first grade and eighth grade, between third grade and eighth grade, or between fifth grade and eighth grade? 6. Are kindergartners' reading and mathematics growth over the first 7 years of school associated with their family's poverty status in kindergarten? To study these and similar questions, researchers would use information from two or more rounds of data collection, across the kindergarten, first-, third-, fifth-, and eighth-grade years. 35 For the first question, the researcher would need to examine differences between fall-kindergarten and springeighth grade assessment scores. To do this, one would use fall-kindergarten data with spring-eighth grade data. Similarly, questions 2 and 3 (regarding the relationship between readiness at kindergarten entry-or maternal employment in that time frame-and eighth-grade outcomes) would be examined by using data from the same two time points. Note that for question 3 one would need to include data from the parent interview in the base year. To examine the relationship of children's kindergarten adjustment with their later grade performance, as in question 4, researchers might use data from several rounds (i.e., fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade). For example, one could use variables from fall-kindergarten and spring-kindergarten to measure 35 When creating a longitudinal file to analyze assessment scores, the recalibrated assessments scores contained on the eighth-grade file should be used. Please refer to chapter 3 for more information on the recalibrated scores."}, {"section_title": "5.", "text": "Set the Desktop Area to 800 x 600 pixels with the Desktop Area slidebar. As noted above, the ECB requires approximately 20 MB of available disk space on your hard drive. If 20 MB of space is not available, you may wish to delete unnecessary files from the drive to make space for the ECB.\nClick OK to open the Main ECB screen, shown in exhibit 8-11.\nFollow any prompts. You will be prompted by the InstallShield Wizard to confirm the uninstallation and finish the process.\nThe field ID of the current variable selected is shown on the right of the Go button (exhibit 8-18).\nClick on the Search button to initiate the search.\nClick on the Search button to initiate the search.\nThe new variables are added to your Working Taglist. \nClick on the Save button.\nClick on the Save button.\nClick on the Save button.\nEnter the file name for the taglist you want to import.\nHighlight the taglist that is to be deleted and click on the OK button.\nOnce you have finished viewing the codebook, close the screen by clicking on the Windows \"X\" control located in the top right corner of the window. You may also close the window using the other standard Windows defaults: by clicking on the windows icon in the upper left corner and selecting Close, or by pressing Alt-F4.\nThe entire codebook displays as shown in exhibit 8-44. Note that this view includes ALL variables in the catalog and can span more than 1000 pages depending on the size of the ECB. The page number is in the upper left corner of the window. To print selected pages of the codebook, select Pages from the Printer Dialog box. Enter the pages you want to print and the number of copies you want. Click on the OK button."}, {"section_title": "ECB Features", "text": "The ECB allows a user to do the following: Search the names and labels of variables in the database (called the catalog) to select variables for analysis (see section 8.3,Variable List). Examine the question wording, response categories, and response frequencies for variables the user selects (see section 8.4.9, Viewing Codebook and Variable Information). Create a list of variables to be extracted from the catalog, save the list for later use, print the list as a codebook, or use a predefined list on the ECB (see section 8.4, Working Taglist). Automatically generate SAS, SPSS for Windows, or Stata programs to extract selected variables from the whole dataset or for a subset of the cases that are defined by the user (see section 8.5, Extracting Data From the ECB). The ECB does not create a SAS, SPSS for Windows, or Stata data file. It will prepare the statements that you can use with your own SAS, SPSS for Windows, or Stata software to create your file."}, {"section_title": "8-3", "text": "As noted earlier, the CD-ROM contains an ASCII dataset that the ECB uses to extract specific subdata files. The CD-ROM must be in the drive for the data to be extracted."}, {"section_title": "Installing, Starting, and Exiting the ECB", "text": "The ECB is provided on a CD-ROM and is intended to be installed and run from within the  5. Click on the OK button to start the installation. You will now see several installation screens, some of which will prompt you for a response. Depending on your PC's configuration, you may encounter warning messages during installation. To respond, always keep the newer version of a file being copied and ignore any access violations that occur during file copying. If you are installing multiple ECBs (not different versions of the same ECB) on your PC, you may receive a message warning that Setup is about to replace pre-existing files. To respond, always opt to continue the installation although the default is to cancel the setup. When you get a follow-up message to confirm whether the installation should be continued, press \"Yes\" to continue although the default is \"No.\" 6. The screen shown in exhibit 8-2 indicates that the setup is being prepared. 11. The installation process should take about a minute, depending on the speed of the computer on which the ECB is being installed. Another option for installing the ECB software is to go to the Start menu and go to Settings. Select Control Panel and select Add/Remove Programs from the options. Click on the Install button and follow the directions. Make sure the ECB CD-ROM is in the CD-ROM drive before starting. The program will automatically find the file Setup.exe in the CD-ROM and begin installation. The process will begin at step 5 in the section above. Click \"Yes\" if you are a first-time user. The ECB splash-screen shown in exhibit 8-9 will appear."}, {"section_title": "8-9", "text": "Exhibit 8-9. ECB splash screen"}, {"section_title": "8-10", "text": "Exhibit 8-11. Main ECB screen"}, {"section_title": "6.", "text": "You are now ready to use the functions of the ECB as described in the following sections.\nThe program is designed so that the uninstallation will keep the taglists when the ECB program is uninstalled in order that all the saved taglists will be retained when the ECB is reinstalled. As a result, the uninstallation will not remove the directory where the ECB was located.\nClick the Reset button to return to the top of the original Variable List (Field ID 1) or enter another field ID to scroll to another variable. For field IDs that identify different groups of variables, please refer to appendix E on the CD-ROM for the catalog-specific topical variable groupings. The Go button will not be available in a narrowed or expanded list. After a Narrow Search or an Expand Search, you must reset the Variable List (see section 8.3.1.4) before you can use the Go button.\nThe variables meeting the specified criteria will be displayed in the Variables List column. If no variable names or descriptions in the catalog contain the specified search text, then the message shown in exhibit 8-20 will appear.\nThe variables meeting the specified criteria will be added to the variables already displayed in the Variables List column.\nThe newly assigned taglist name now appears in the Working Taglist header bar. If a name that already exists is entered, you will be prompted to replace the old taglist with the new taglist. Click \"Yes\" only if you wish to replace the old taglist with the new taglist. 1. Complete any changes you wish to make to the existing taglist.\nThe newly assigned taglist name now appears in the Working Taglist header bar. If a name that already exists is entered, you will be prompted to replace the old taglist with the new taglist. Click \"Yes\" only if you wish to replace the old taglist with the new taglist or enter a unique name.\nYou will be prompted to replace the file if the file name you entered already exists. Do so or click on \"No\" to enter a new file name. The Working Taglist will be saved under the filename you enter. \nClick on the Open button. The Working Taglist will be replaced by the new imported taglist.\nA confirmation screen, shown in exhibit 8-36, verifies your intention to delete the taglist."}, {"section_title": "Exiting the ECB", "text": "The ECB can be shut down at any time; however, you will be prompted to save any unsaved information."}, {"section_title": "Title Bar", "text": "The Title Bar, shown below in exhibit 8-14, is the horizontal bar located at the top of the main screen. It will list the name of the program and the catalog that you have opened, and it will indicate that you are in the \"Create Taglist\" mode. "}, {"section_title": "8-13", "text": ""}, {"section_title": "Using Shortcut Keys to Navigate", "text": "The shortcut keys provide a means for selecting menu options and screen buttons without the use of a mouse. These shortcut keys are identified by an underscore under the shortcut letter within the option or button label. The menus that appear on the windows are activated by simultaneously selecting the <ALT> key and the underscored letter. An example of this is the activation of the Taglist Menu by selecting the key combination of <ALT>-<T>. Once the menu is activated and all options are displayed, the options can be selected by then pressing the underscored letter for the desired option or by pressing the arrow keys to move between the options. Not all screens have shortcut keys. They may, however, be used without mouse capability by pressing the <TAB> key. The <TAB> key moves the cursor or highlight through the options and buttons within the windows. When the desired option or button is highlighted, it can be selected by pressing the <ENTER> key."}, {"section_title": "Variable List", "text": "The ECB main screen, shown in exhibit 8-16, comprises two primary lists that each provide functions for reviewing, grouping, and extracting variable data from the opened catalog. These lists  How To Use the Go Button: 1. Type the field ID in the input box on the left of the Go button."}, {"section_title": "8-17", "text": "The \"Field ID\" remains active in a narrowed or expanded list. However, the field IDs indicate the order of the variables in the catalog rather than that in the Variable List. As a result, the field Enter a key character string, word, or phrase in the Enter Narrow Text field. Character strings can include a single alphanumeric character or a sequence of several characters. The search is not case sensitive. The results returned will be all entries that contain that exact sequence of letters, numbers, spaces, and words."}, {"section_title": "Click on the Variable Name, Variable Description, or Both Variable Name and", "text": "Description radio button to specify where to search."}, {"section_title": "8-19", "text": "Exhibit [8][9][10][11][12][13][14][15][16][17][18][19][20]. No Matches Found message"}, {"section_title": "7.", "text": "Repeat the Narrow Search procedure if necessary. Please note that the field ID at the upper right corner of the Variable List reflects the order of the variables in the catalog rather than that in the narrowed Variable List.\nRepeat the Expand Search procedure if necessary. If no variable names or descriptions in the catalog contain the specified search text, then the message shown in exhibit 8-23 will appear. Please note that the field ID at the upper right corner of the Variable List reflects the order of the variables in the catalog rather than that in the expanded Variables List. \nClick on the \"Yes\" button to permanently delete the saved taglist. "}, {"section_title": "Example of Narrowing a Search", "text": "The following example shows you how to narrow the Variable List. In this example, you want to include all the variables from the catalog that measure education. Do the following: 1. In the Variable List, click on the Narrow button."}, {"section_title": "8-20", "text": "Exhibit 8-21. Example of narrowing a search"}, {"section_title": "Expanding Your Variable Search", "text": "The Expand Search function can be used to expand a previously narrowed list of variables Enter a key character string, word, or phrase in the Enter Expand Text field. Character strings can include a single alphanumeric character or a sequence of several characters. The search is not case sensitive. The results returned will be all entries that contain that exact sequence of letters, numbers, spaces, and words."}, {"section_title": "Working Taglist", "text": "The Working Taglist, shown in exhibit 8-24, displays a list of variables that are currently selected or tagged for extraction. All Working Taglists contain a set of variables, called required variables, that will be automatically included in all data files that the user creates. The required variables provide a foundational dataset upon which other variables rely. These required variables cannot be untagged or deleted from the Working Taglist by the user. When a catalog is first opened, the default Working Taglist consists of only the required variables for that catalog. (See appendix E on the CD-ROM for the catalog-specific required variables.) To create a taglist, add the variables you have selected to the required variables."}, {"section_title": "8-23", "text": "Exhibit 8-24. ECB Working Taglist"}, {"section_title": "Opening a Taglist", "text": "The ECB allows you to open a predefined or previously saved taglist and display it in the Working Taglist column. Taglists, however, are saved as part of a particular catalog and can only be opened as part of the associated catalog."}, {"section_title": "8-24", "text": "How To Open a Taglist: 1. Open a catalog."}, {"section_title": "Saving Taglists", "text": "The ECB has the ability to save the newly created or modified taglist displayed in the How To Save a New Taglist: 1. Complete any changes you wish to make to the new taglist."}, {"section_title": "8-29", "text": "Exhibit 8-30. Save Taglist As dialog box (#2)"}, {"section_title": "Exporting Taglists", "text": "Taglists can be saved as external files (*.tlt) for distribution. However, the exported files should be accessed only through the ECBs. Manually modifying the files outside of the ECB software is not recommended. How To Export a Taglist: 1. Add to the Working Taglist all the variables that you would like to export."}, {"section_title": "8-31", "text": "How To Import a Taglist: 1. Save the current Working Taglist before importing new taglist if desired."}, {"section_title": "Using Predefined Taglists", "text": "The ECB provides predefined taglists that address specific topics. These predefined taglists can be added to your Working Taglist or can be opened as a new Working Taglist. Opening these predefined taglists is performed using the same steps as opening a user-saved taglist presented in section 8.4.1. Users can add as many of the predefined taglists as desired to the open Working Taglist. See appendix E on the CD-ROM for listings and descriptions of the catalog-specific predefined taglists."}, {"section_title": "8-32", "text": "Exhibit 8-34. Import Taglist dialog box"}, {"section_title": "Deleting Taglists", "text": "The ECB provides the capability to permanently delete previously saved taglists. Predefined taglists provided with the ECB, however, cannot be deleted through this function. How To Delete a Taglist:"}, {"section_title": "1.", "text": "Close the taglist currently displayed in the Working Taglist column by selecting the New option from the Taglist pulldown menu."}, {"section_title": "Viewing Codebook and Variable Information", "text": "The codebook for a taglist displayed in the Working Taglist column can be created, viewed, and printed from the ECB main screen. The codebook displays several pieces of information about each variable that are described in exhibit 8-37."}, {"section_title": "8-34", "text": "Exhibit 8-37. Codebook information"}, {"section_title": "Field Description", "text": "Question Text The question that was asked of the respondent by the interviewer or that was on the self-administered instruments."}, {"section_title": "Variable Name/ Description", "text": "The name of the variable as it appears in the catalog and a brief description of its content."}, {"section_title": "Record Number", "text": "The row number of the variable within the catalog data file."}, {"section_title": "Format", "text": "The format of the variable. The first character is either \"A\" or \"N\" for alphabetical or numeric. Most variables are numeric except the identifiers-which begin with an \"A.\" The number following the \"A\" or \"N\" is the length of the variable. For numeric variables, the number after the decimal point is the number of decimal places."}, {"section_title": "Comment", "text": "Information to clarify specific information about a variable."}, {"section_title": "Position", "text": "The column number (position) of the variable within the catalog data file."}, {"section_title": "Response", "text": "A brief statement of each response code's meaning."}, {"section_title": "Codes", "text": "The numeric codes specifying each response."}, {"section_title": "Frequency", "text": "The numeric count of respondents providing the corresponding response code. The frequency counts are unweighted."}, {"section_title": "Percent", "text": "The percentage of respondents providing the corresponding response code. The percents are unweighted. How To View the Codebook for Tagged Variables: 1. Complete any changes you wish to make to the displayed taglist. 2. Click on the Codebook pulldown menu and select the View option."}, {"section_title": "NOTE:", "text": "The counter \"1 of 1+\" on the tool bar on top of the screen indicates the current page number and the last page number of the report. Users must navigate to the last page of the report to load 8-36 the entire report. Once the user has viewed the last page of the report, the \"+\" sign will disappear and the correct last page number will show."}, {"section_title": "8.", "text": "When you are done viewing the entire codebook, close the window by clicking on the Windows control \"X\" in the upper right corner of the screen. You will return to the main screen."}, {"section_title": "Extracting Data From the ECB", "text": "Once the variables have been selected (tagged) for extraction and reside in the Working Taglist, the next step is to generate the code through which the statistical analysis software can retrieve and display the results. The ECB provides options for generating the code for analyzing data with the SAS, SPSS for Windows, or Stata statistical analysis programs. To run these programs, you will need the appropriate statistical software and the ECB CD-ROM from which the program can extract data. SPSS users should note that an entire catalog can produce a Frequencies command statement with more than 500 variables. This may produce a warning of \"too many variables,\" and the Frequencies command will not execute. Users may work around this limitation by dividing the Variable List into two or more Frequencies commands. When extracting data to be used with either the SAS, SPSS for Windows, or Stata programs, a dialog box will be presented that allows the user to define the extract population through the Limiting Fields. See exhibit 8-46. The Limiting Fields include various subgroups of respondents that are typically of interest to analysts. These subgroups can be selected or deselected to narrow the data field that is extracted. Also, please note that the ECB extract function allows the user to specify the drive letter of the CD-ROM drive. If you attempt to run the resulting SAS, SPSS, and Stata programs on a workstation with a different CD-ROM drive letter, you must alter the program code accordingly or regenerate the program code using the ECB."}, {"section_title": "8-42", "text": "The SAS, SPSS, or Stata source code generated by the ECB to read in the data may contain code statements that are \"commented\" out (e.g., with * in SAS). These code statements either run descriptive statistics (e.g., frequencies, means, etc.), or associate formats with variables. They are commented out because not all analysts will want them included in the source code. SAS users (prior to SAS, Version 8) should note that, although the ECB will allow dataset names larger than eight characters, the SAS system will reject these names at run-time. "}, {"section_title": "8-49", "text": "If a mistake in defining the criteria is made, and it is not discovered until after writing out or running the extract program, it is very easy to correct if the taglist was saved before exiting the ECB program. Simply restart the ECB and select the appropriate catalog, open the taglist that you saved, define the extract criteria correctly, and write out the extract program again. The program should be reviewed before running it because it may need to be customized."}, {"section_title": "Repairing and Compacting the Database", "text": "Periodically users may wish to repair and compact the database that contains the data of the ECB program. If many taglists are created and deleted on a regular basis, the database will contain lingering references to old taglists that are no longer needed. When the database is repaired and compacted, the ECB program \"cleans house\" and makes the database more efficient. It also decreases the size of the database, so space is conserved. How To Repair and Compact the ECB Database: 1. Select the Tools pulldown menu and select the Repair and Compact Database option."}, {"section_title": "Conducting Longitudinal Analyses", "text": "As described in chapter 1, one of the primary goals of the ECLS-K is to understand how children's early experiences influence their transition into kindergarten and their progression through the "}, {"section_title": "Examples of Research Questions", "text": "A variety of research questions can be examined using the K-8 longitudinal files. The following are some examples: 1. How much do children's reading and mathematics skills increase between the fall of kindergarten and the spring of eighth grade? 2. Do measures of school readiness at the beginning of kindergarten predict children's skill and knowledge levels at the end of eighth grade? 3. What family background characteristics (e.g., family poverty, parent education, maternal employment) are associated with children's later school outcomes?"}, {"section_title": "9-4", "text": "adjustment during kindergarten and then relate those variables to outcomes in the spring of the third, fifth, and eighth grades. C67CW0 is nonzero if assessment data are present for both spring-fifth grade and spring-eighth grade, or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability. C67PW0 is nonzero if parent interview data are present for both spring-fifth grade and spring-eighth grade. C567CW0 is nonzero if assessment data are present for spring-third grade, spring-fifth grade, and spring-eighth grade, or if the child was excluded from direct assessment in all of these three rounds of data collection due to a disability. C567PW0 is nonzero if parent interview data are present for spring-third grade, spring-fifth grade, and spring-eighth grade. C4_7CW0 is nonzero if assessment data are present for spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade, or if the child was excluded from direct assessment in all of these four rounds of data collection due to a disability. C4_7PW0 is nonzero if parent interview data are present for spring-first grade, springthird grade, spring-fifth grade, and spring-eighth grade."}, {"section_title": "9-5", "text": "C2_7FC0 is nonzero if assessment data are present for five rounds of data collection involving the full sample of children (spring-kindergarten, spring-first grade, springthird grade, spring-fifth grade, and spring-eighth grade), or if the child was excluded from direct assessment in all of these five rounds of data collection due to a disability. C2_7FP0 is nonzero if parent interview data are present for five rounds of data collection involving the full sample of children (spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade). C1_7FC0 is nonzero if assessment data are present for six rounds of data collection involving the full sample of children (fall-kindergarten, spring-kindergarten, springfirst grade, spring-third grade, spring-fifth grade, and spring-eighth grade), or if the child was excluded from direct assessment in all of these six rounds of data collection due to a disability. C1_7FP0 is nonzero if parent interview data are present for six rounds of data collections involving the full sample of children (fall-kindergarten, springkindergarten, spring-first grade, spring-third grade, spring-fifth grade, and springeighth grade). C1_7SC0 is nonzero if assessment data are present for all seven rounds of data collection (fall-kindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), or if the child was excluded from direct assessment in all of these seven rounds of data collection due to a disability. C1_7SP0 is nonzero if parent interview data are present for all seven rounds of data collection (fall-kindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade). The use of the K-8 longitudinal weights is described in exhibit 9-1. This exhibit is designed to help users choose appropriate weights for their analysis. First, decide which two or more points in time are the focus of the analysis. The analysis could pertain to two points in time (spring-fifth grade and spring-eighth grade), three points in time (spring-third grade, spring-fifth grade, and spring-eighth grade), four points in time (spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), five points in time (spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and springeighth grade), six points in time (fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), or seven points in time (all seven rounds of data collection). For example, if the analysis uses spring-fifth grade and spring-eighth grade data, then the appropriate weights would be those beginning with C67 (denoting child-level data from round 6, springfifth grade AND round 7, spring-eighth grade). Second, consider the source of the data, which also affects the choice of the weight. In exhibit 9-1, details under \"to be used for analysis of \u2026\" provide guidance based on whether the data were collected through the child assessments, parent interviews, teacher 9-6 questionnaires at the teacher level, or at the child level (English, mathematics, or science teacher questionnaire). For the same example noted earlier, the two weights available are C67CW0 and C67PW0. If parent data from spring-fifth grade and spring-eighth grade are needed for the analysis, then C67PW0 should be used. Base-year longitudinal weights for the analysis of the base-year data (within the kindergarten year) alone are described in the base-year user's manuals. First-grade longitudinal weights for the analysis of the first-grade data (within the first-grade year) alone, and of the combined kindergarten/first-grade data, are described in the first-grade user's manuals. Third-grade longitudinal weights for the analysis of the third-grade data alone, and of the combined kindergarten/first-grade/third-grade data, are described in the third-grade user's manuals. Fifth-grade longitudinal weights for the analysis of the fifth-grade data alone, and of the combined kindergarten/first-grade/third-grade/fifth-grade data, are described in the fifthgrade user's manual. K-8 longitudinal weights are used to produce estimates of differences between two or more rounds of data collection spanning kindergarten, first grade, third grade, fifth grade, and eighth grade. Simple examples involving two rounds of data collection are the differences in children's mean assessment scores between spring-fifth grade and spring-eighth grade using the C67CW0 weight and the change in the total number of persons in the household size using C67PW0. K-8 longitudinal weights are also used to study the characteristics of children who were assessed in two or more rounds of data collection. For example, one can study how family background characteristics of children in kindergarten are related to assessment scores in spring-eighth grade for children who were assessed in spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade. In this case, C4_7PW0 is used to study the characteristics of the children as reported by their parents, and C4_7CW0 is used to estimate the change in assessment scores between spring-first grade and spring-eighth grade. As noted earlier, any longitudinal analysis that uses data from fall-first grade will be limited to a 27 percent subsample of children. There may be combinations of data for which no weights were developed. For further advice on which weights to use when analyzing a complex combination of data, contact NCES at ECLS@ed.gov."}, {"section_title": "9-7", "text": "Exhibit 9-1. ECLS-K: K-8 longitudinal weights, spring-eighth grade: School year 2006-07"}, {"section_title": "C67CW0", "text": "child direct assessment data from BOTH spring-fifth grade and spring-eighth grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-fifth grade or spring-eighth grade teacher questionnaire (teacher-level or childlevel), (c) data from any spring-fifth grade or spring-eighth grade school administrator questionnaire, or (d) data from spring-fifth grade school facilities checklist."}, {"section_title": "C67PW0", "text": "parent interview data from BOTH spring-fifth grade or spring-eighth grade, alone or in combination with (a) spring-fifth grade or spring-eighth grade child assessment data, (b) data from any springfifth grade or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-fifth grade or spring-eighth grade school administrator questionnaire, or (d) data from spring-fifth grade school facilities checklist."}, {"section_title": "C567CW0", "text": "child direct assessment data from THREE rounds of data collection (spring-third grade, spring-fifth grade and spring-eighth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-third grade, spring-fifth grade, or springeighth grade teacher questionnaire (teacher-level or child-level), (c) school administrator questionnaire data from any of these three rounds, or (d) data from any spring-third grade or springfifth grade school facilities checklist."}, {"section_title": "C567PW0", "text": "parent interview data from THREE rounds of data collection (spring-third grade, spring-fifth grade and spring-eighth grade), alone or in combination with (a) child assessment data from any of these three rounds, (b) data from any spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-third grade or spring-fifth grade school facilities checklist."}, {"section_title": "C4_7CW0", "text": "child direct assessment data from FOUR rounds of data collection (spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-first grade, springthird grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or childlevel), (c) data from any spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist."}, {"section_title": "C4_7PW0", "text": "parent interview data from FOUR rounds of data collection (spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth), alone or in combination with (a) child assessment data from any of these four rounds, (b) data from any spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any springfirst grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist."}, {"section_title": "C2_7FC0", "text": "child direct assessment data from FIVE rounds of data collection (spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any springkindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist. See notes at end of exhibit."}, {"section_title": "9-8", "text": "Exhibit 9-1. ECLS-K: K-8 longitudinal weights, spring-eighth grade: School year 2006-07-Continued"}, {"section_title": "C2_7FP0", "text": "parent interview data from FIVE rounds of data collection (spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), alone or in combination with (a) child assessment data from any of these five rounds, (b) data from any spring-kindergarten, springfirst grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist."}, {"section_title": "C1_7FC0", "text": "child direct assessment data from SIX rounds of data collection (fall-kindergarten, springkindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-kindergarten, spring-first grade, spring-third grade, springfifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist."}, {"section_title": "C1_7FP0", "text": "parent interview data from SIX rounds of data collection (fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), alone or in combination with (a) child assessment data from these any of these six rounds, (b) data from any fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any springkindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist."}, {"section_title": "C1_7SC0", "text": "child direct assessment data from ALL SEVEN rounds of data collection (fall-kindergarten, springkindergarten, fall-first grade, spring-first grade, spring-third grade, spring-fifth grade, and springeighth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade or spring-eighth grade school administrator questionnaire, or (d) data from any springkindergarten, spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist."}, {"section_title": "C1_7SP0", "text": "parent interview data from ALL SEVEN rounds of data collection (fall-kindergarten, springkindergarten, fall-first grade, spring-first grade, spring-third grade, spring-fifth grade, and springeighth grade), alone or in combination with (a) child assessment data from any of these seven rounds, (b) data from any fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), 9-9\n2,063 parent interview data are present for all seven rounds of data collection involving the full sample of children (fall-kindergarten, springkindergarten, fall-first grade, springfirst grade, spring-third grade, spring-fifth grade, and spring-eighth grade). parent interview data from ALL SEVEN rounds of data collection (fallkindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), alone or in combination with (a) child assessment data from any of these seven rounds, (b) data from any fallkindergarten, spring-kindergarten, spring-first grade, spring-third grade, springfifth grade, or spring-eighth grade teacher questionnaire (teacher-level or childlevel), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, springthird grade, or spring-fifth grade school facilities checklist. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), fall 1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007. 10-27 K-8 longitudinal weights are used to produce estimates of differences between two or more rounds of data collection spanning kindergarten, first grade, third grade, fifth grade, and eighth grade. Simple examples involving two rounds of data collection are as follows: 1. estimating the differences in children's mean assessment scores between spring-fifth grade and spring-eighth grade using C67CW0; and 2. estimating the difference in Social Rating Scale scores as reported by parents in spring-kindergarten and spring-first grade using C24PW0 (Social Rating Scale scores as reported by parents are not available for fall-first grade, spring-third grade, springfifth grade or spring-eighth grade). K-8 longitudinal weights are also used to study the characteristics of children who were assessed in two or more rounds of data collection. For example, one can study the characteristics of kindergarten children that are associated with the greatest gains in learning in fifth and eighth grades. If the analysis includes data collected from the parents in spring-fifth grade and spring-eighth grade, then C67PW0 can be used in the analysis. However, if the analysis involves only the key characteristics (e.g., race) available for most children and the child assessment data from spring-fifth grade and spring-eighth grade, then C67CW0 can be used to estimate changes in assessment scores between spring-fifth grade and spring-eighth grade. An example in which data from more than two rounds are used is as follows: to examine whether the gains children have made in their reading knowledge and skills during the kindergarten year and from the end of kindergarten to the end of first grade are associated with parents' and teachers' beliefs about kindergarten readiness and parental educational expectations, the weight Y2COMW0 would be appropriate. Exhibit 10-5 shows examples of research questions, the data of the survey components, and the weights to be used for analyses appropriate to these research questions. As noted in the first-grade, third-grade, fifth-grade, and eighth-grade user's manuals, any longitudinal analysis that uses data from fall-first grade will be limited to a 27 percent subsample of children. 37 37 As described in the first grade user's manual, fall-first grade was a design enhancement to enable researchers to study the extent of summer learning losses and gains and the factors associated with them. The fall data collection was limited to children in a 30 percent subsample of schools."}, {"section_title": "Longitudinal Weights Not Involving the Fall-First Grade Data", "text": "In the first stage, the starting point for the K-8 longitudinal weights is the initial child weight that reflected the following: adjustment of the school base weight for base-year school-level nonresponse; adjustment of the child weights for base-year child-level nonresponse; and adjustment of the base-year child weight for subsampling of schools for freshening in first grade (for children sampled in first grade only). The second stage of weighting was to adjust the initial child weight in the first stage for the following: subsampling of movers in data collection rounds prior to eighth grade; and adjustment for longitudinal unknown eligibility status and nonresponse. In the adjustment for subsampling of movers, mover status was created so that it was specific to each panel. For example, for the spring-fifth grade/spring-eighth grade panel (longitudinal weights C67CW0 and C67PW0), a child was a mover if he had been identified as a mover in spring-fifth grade, i.e., in spring-fifth grade he attended a school that was not the school where he had been sampled in kindergarten. As mentioned earlier, all eighth-graders were followed into their new schools if they 9-10 moved between fifth and eighth grade. Therefore the concept of mover in eighth grade does not exist as far as weight computation is concerned. Similarly, for the spring-third grade/spring-fifth grade/springeighth grade panel (longitudinal weights C567CW0 and C567PW0), a child was a mover if he had been identified as a mover in spring-third grade and in spring-fifth grade. The adjustment factor for subsampling movers was computed within cells created using the following characteristics: whether children were sampled in kindergarten or first grade and whether they were language minority children. A small number of children with large weights had their weights trimmed. However, the weights were not redistributed because the total sum of weights was reestablished in the raking procedure that came later. In both steps of the nonresponse adjustment, separate nonresponse classes were created for longitudinal movers and nonmovers using race/ethnicity, school affiliation, combinations of response status of child assessments and parent interviews from previous rounds, and the type of household collected from the parent interviews. The third and last stage was to rake the weights adjusted in the second stage to sample-based control totals. The raking factor was computed separately within raking cells as the sample-based control total for the raking cell over the sum of the nonresponse-adjusted weights for children in the same cell. Raking cells (also known as raking dimensions) were created using school and child characteristics collected in the base-year or first-grade data collection: school affiliation, region, type of locale, sex, age, race/ethnicity, socioeconomic status (SES), language minority status, whether sampled in kindergarten or first grade and, if sampled in kindergarten, mover status."}, {"section_title": "Longitudinal Weights Involving the Fall-First Grade Data", "text": "For the longitudinal weights involving the fall-first grade data collection in which children were part of a subsample of the ECLS-K full sample (i.e., C1_7SC0 and C1_7SP0), the initial weights were from fall-first grade. These were the base-year child-adjusted weights (as described in chapter 4, section 4.8.3.2 for base-year respondents), incorporating the school subsampling factor appropriate for fall-first grade. These weights were also trimmed to reduce the weight of all the children in one private school that had a large school weight."}, {"section_title": "9-11", "text": "The adjustments for subsampling movers and for child nonresponse are identical to those for the other longitudinal weights. The adjustment factor for subsampling movers was computed within cells by whether they belonged in the language minority group. A small number of children with large weights had their weights trimmed. However, the weights were not redistributed because the total sum of weights was reestablished in the raking procedure that came later. In both steps of the nonresponse adjustment, separate nonresponse classes were created for movers and nonmovers using the type of household collected from the parent interviews, school affiliation, and race/ethnicity. The raking dimensions are the same as those for the other longitudinal weights. After the first raking, a small number of children had their weights trimmed; then all the weights were raked again."}, {"section_title": "Characteristics of Longitudinal Weights", "text": "The statistical characteristics of the longitudinal weights are presented in table 9-1. For each weight, the number of cases with nonzero values is presented together with the mean weight, the standard deviation, the coefficient of variation (i.e., the standard deviation as a percentage of the mean weight), the minimum value of the weight, the maximum value of the weight, the skewness, the kurtosis, and the sum of weights. "}, {"section_title": "9-12", "text": "The difference in the estimate of the population of children (sum of weights) between the different panels of children and types of weights results from a combination of factors, among them: (1) the number of base-year respondents who became ineligible (due to death, leaving the country, or being a nonsampled mover) after the base year, (2) the adjustment of the weights for the children of unknown eligibility, and 3 "}, {"section_title": "9-13", "text": "Each replicate weight variable name has the same weight prefix as for the full sample weight variable name. For example, the replicate weights for C1_7FC0 are C1_7FC1 through C1_7FC90; the replicate weights for C1_7SC0 are C1_7SC1 through C1_7SC40. For the replication method using WesVar or AM, the full sample weight, the replicate weights, and the method of replication are required parameters. Variance estimation using the ECLS-K data should be done using the paired jackknife method (JK2). As an example, to compute the mean difference in reading scores between spring-fifth and spring-eighth grade and their standard errors, users need to specify C67CW0 as the full sample weight, C67CW1 to C67CW90 as the replicate weights, and JK2 as the method of replication. For the Taylor Series method using SUDAAN, SAS, Stata, SPSS, or AM, the full sample weight, the sample design, the nesting stratum, and PSU variables are required. For the same example cited earlier, the full sample weight (C67CW0), the stratum variable (C67CSTR), and the PSU variable (C67CPSU) must be specified. The \"with replacement\" sample design option, WR, must also be specified if using SUDAAN. First-stage primary sampling unit within stratum-spring-fifth grade/spring-eighth grade longitudinal C-weights C67PSTR Sampling stratum-spring-fifth grade/spring-eighth grade longitudinal P-weights C67PPSU First-stage primary sampling unit within stratum-spring-fifth grade/spring-eighth grade longitudinal P-weights C567CSTR Sampling stratum-spring-third grade/spring-fifth grade/spring-eighth grade longitudinal Cweights C567CPSU First-stage primary sampling unit within stratum-spring-third grade/spring-fifth grade/springeighth grade longitudinal C-weights C567CSTR Sampling stratum-spring-third grade/spring-fifth grade/spring-eighth grade longitudinal Pweights C567PPSU First-stage primary sampling unit within stratum-spring-third grade/spring-fifth grade/springeighth grade longitudinal P-weights C47FCSTR Sampling stratum-spring-first grade/spring-third grade/spring-fifth grade/spring-eighth grade longitudinal C-weights C47FCPSU First-stage primary sampling unit within stratum-spring-first grade/spring-third grade/springfifth grade/spring-eighth grade longitudinal C-weights C47FPSTR Sampling stratum-spring-first grade/spring-third grade/spring-fifth grade/spring-eighth grade longitudinal P-weights C47FPPSU First-stage primary sampling unit within stratum-spring-first grade/spring-third grade/springfifth grade/spring-eighth grade longitudinal P-weights C27FCSTR Sampling stratum-spring-kindergarten/spring-first grade/spring-third grade/spring-fifth grade/spring-eighth grade longitudinal C-weights C27FCPSU First-stage primary sampling unit within stratum-spring-kindergarten/spring-first grade/springthird grade/spring-fifth grade/spring-eighth grade longitudinal C-weights C27FPSTR Sampling stratum-spring-kindergarten/spring-first grade/spring-third grade/spring-fifth grade/spring-eighth grade longitudinal P-weights C27FPPSU First-stage primary sampling unit within stratum-spring-kindergarten/spring-first grade/springthird grade/spring-fifth grade/spring-eighth grade longitudinal P-weights C17FCSTR Sampling stratum-fall-kindergarten/spring-kindergarten/spring-first grade/spring-third grade/spring-fifth grade/spring-eighth grade longitudinal C-weights C17FCPSU First-stage primary sampling unit within stratum-fall-kindergarten/spring-kindergarten/springfirst grade/spring-third grade/spring-fifth grade/spring-eighth grade longitudinal C-weights C17FPSTR Sampling stratum-fall-kindergarten/spring-kindergarten/spring-first grade/spring-third grade/spring-fifth grade/spring-eighth grade longitudinal P-weights C17FPPSU First-stage primary sampling unit within stratum-fall-kindergarten/spring-kindergarten/springfirst grade/spring-third grade/spring-fifth grade/spring-eighth longitudinal P-weights C17SCSTR Sampling stratum-longitudinal C-weights covering all seven rounds of data collection C17SCPSU First-stage primary sampling unit within stratum-longitudinal C-weights covering all seven rounds of data collection C17SPSTR Sampling stratum-longitudinal P-weights covering all seven rounds of data collection C17SPPSU First-stage primary sampling unit within stratum-longitudinal P-weights covering all seven rounds of data collection based on the ECLS-K child and parent data. For each survey item, the tables present the number of cases, the estimate, the standard error taking into account the actual sample design (Design SE), the standard error assuming SRS (SRS SE), the root design effect (DEFT), and the design effect (DEFF). Standard errors (Design SE) were produced using JK2. Standard errors and design effects are presented in tables 9-3 to 9-8. Data items are from the direct child assessment, the student questionnaire, the parent interview, and the child-level teacher questionnaires. Full sample weights were used to compute the estimates; then the corresponding replicate weights were used to compute standard errors and design effects.  Design SE is the standard error under the ECLS-K sample design. For an explanation of this statistic, see section 4.10. 2 SRS SE is the standard error assuming simple random sample. For an explanation of this statistic, see section 4.10. 3 DEFT is the root design effect. For an explanation of DEFT, see section 4.10. 4 DEFF is the design effect. For an explanation of DEFF, see section 4.10. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), spring 2007.  Design SE is the standard error under the ECLS-K sample design. For an explanation of this statistic, see section 4.10. 2 SRS SE is the standard error assuming simple random sample. For an explanation of this statistic, see section 4.10. 3 DEFT is the root design effect. For an explanation of DEFT, see section 4.10. 4 DEFF is the design effect. For an explanation of DEFF, see section 4.10. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), spring 2007. Table 9-5. ECLS-K, spring-first grade/spring-third grade/spring-fifth grade/spring-eighth grade panel: standard errors and design effects using C4_7CW0-C4_7CW90 and C4_7PW0-C4_7PW90, by selected child and parent variables: School years 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006   Standard errors and design effects were not computed for items from the teacher and school administrator questionnaires since there are no teacher or school weights computed for spring-third grade."}, {"section_title": "9-18", "text": ""}, {"section_title": "9-20", "text": ""}, {"section_title": "9-22", "text": "Although standard errors and design effects may also be calculated for the teacher and school administrator questionnaires at the child level, they are quite large compared to those typically found for the ECLS-K data. Design effects for teacher and school items are large because the intraclass correlation is 100 percent for children in the same school and very high for children in the same class; children attending the same school have the same school data, and children in the same class have the same teacher data. The correlation is not 100 percent for children in the same class because teacher data include not only items about the teacher and the class but also items about the individual children as completed by their teachers. Table 9-9. ECLS-K panel: median design effects for subgroups, kindergarten through eighth grade: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 Spring-fifth/ spring-eighth 9-32 Table 9-9. ECLS-K panel: median design effects for subgroups, kindergarten through eighth grade: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007. Introduction"}, {"section_title": "9-31", "text": "For the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), the kindergarten-eighth grade full sample public-use data file, referred to hereinafter as the K-8 full sample data file, combines data from the base-year (kindergarten), first-grade, third-grade, fifth-grade, and eighth-grade data collections. It was created so that analysts can easily access all data that has been publicly released in any round of data collection between fall-kindergarten and spring-eighth grade. The file can be used to analyze data from any single round of data collection or from any combination of rounds (e.g., cross-year analysis). When using the data from a single round of data collection, analysts can answer questions related to children's status at a point in time. When using data from multiple rounds, analysts can examine children's growth and development within kindergarten, within first grade, and between kindergarten and eighth grade without having to go through the process of merging several different data files. Cross-sectional and longitudinal weights developed for each round of the ECLS-K are included on the data file. Thus, this file can be used to study such topics as children's skills at school entry and their learning across school years, the extent of summer learning or loss between kindergarten and the fall of the following school year, and the home, school, or classroom characteristics that are associated with children's growth in reading, mathematics, and science skills. Users will obtain basic information about the K-8 full sample public-use data file in this chapter. The chapter begins with a description of the individuals included on the file. It then provides an overview of the content of the data file and a description of the cross-sectional and longitudinal weights on the file. Round 7 weights described in chapters 4 and 9 are repeated here as well for the convenience of users of the K-8 full sample data file. 10-2"}, {"section_title": "Individuals Included on the K-8 Full Sample Public-Use Data File", "text": "Unlike previously released longitudinal files that contained only those children with data at particular points in time, the K-8 full sample public-use data file includes all children with ECLS-K data in at least one of the seven rounds of data collection, from fall-kindergarten through spring-eighth grade. In all, the K-8 full sample data file has 21,409 child records. They are as follows: 21,260 base-year respondents, i.e., children who had fall-and/or spring-kindergarten child assessment or parent interview data or who were excluded from assessment because of a disability or because they belonged in the language minority, not Spanish group; in other words, children with at least one nonzero base-year cross-sectional weight (C1CW0, C2CW0, C1PW0, or C2PW0); and 149 children who were sampled in spring-first grade through the sampling freshening process, and who had data for at least one data collection year (i.e., spring of first, third, fifth, or eighth grade). The K-8 full sample data file is a child-level file. All parent, teacher, and school information collected for any particular child from each round of data collection has been attached to that child's record (a more detailed description of the record layout is contained in appendix E on the Electronic Codebook (ECB) for the K-8 full sample data file). For detailed information about response rates in each round of data collection, see chapter 5 of the base-year, first-grade, third-grade, fifth-grade, and eighthgrade user's manuals."}, {"section_title": "Content", "text": "The K-8 full sample data file contains all publicly released data collected from parents, children, teachers, or schools in the base-year (fall and spring), first-grade (fall and spring), spring-third grade, spring-fifth grade, and spring-eighth grade data collections. It includes data from the household rosters, which list all household members, their relationship to the sampled child, and selected other characteristics. This roster information has not been available on the longitudinal files previously released. The K-8 full sample data file also includes the composite variables describing critical household roster-based information, such as the children's family structure and selected characteristics of the family members. See chapter 7 of the base-year, first-grade, third-grade, fifth-grade, and eighth-grade user's manuals for a description of these and other composite variables."}, {"section_title": "10-3", "text": "Similar to the first-, third-, and fifth-grade files, the K-8 full sample data file contains a few base-year variables that were not in the base-year files. They fall into three categories: (1) base-year recalibrated assessment scores, (2) base-year recalibrated Academic Rating Scale (ARS) scores, and (3) new and corrected base-year composites. The direct child assessment scores were recalibrated to obtain gain scores that could be compared across seven waves of data. The ARS scores were recalibrated because an error was identified in the base-year ARS scores. Specifically, the fall and spring base-year ARS scores used slightly different metrics. These scores were recalibrated using a combined calibration of fall-and spring-kindergarten ratings. Therefore, the unit for the corrected fall-and spring-kindergarten scores is the same, though comparisons between fall-and spring-kindergarten scores are not recommended. Although the item stems are similar across grades, the actual items include performance criteria that increase from one grade to the next. Moreover, the ARS score metric is different at each point. Therefore, change scores should not be used to compare eighth-grade ratings with those from earlier rounds. The specifics of the ARS and composite problems are described in the first-grade public-use "}, {"section_title": "K-8 Weights", "text": "Several sets of cross-sectional and longitudinal weights have been computed for children with complete data from each round and different combinations of rounds. All weights on the K-8 full 10-4 sample data file are child-level weights. There are no K-8 longitudinal weights at the school or teacher level since school-and teacher-level weights were not computed for the first-grade, third-grade, fifth-, or eighth-grade years due to lack of representativeness. Detailed descriptions of the ECLS-K cross-sectional weights are included in chapter 4 of the ECLS-K base-year, first-grade, third-grade, fifth-grade, and eighth-grade user's manuals. Detailed descriptions of the ECLS-K longitudinal weights are included in chapter 9 of the first-grade, third-grade, fifth-grade, and eighth-grade user's manuals. Before describing the weights, it is useful to understand the conventions used to name them. The names of the weights indicate the round or rounds of data collection and the component or combination of components (parent, child assessment, teacher) to which they apply. The ECLS-K has seven rounds of data collection, as shown in exhibit 10-1: Exhibit 10-1. Crosswalk between round number of data collection, grade, and school year: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 Round  1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007. ECLS-K variable names are restricted to eight characters; thus, some weights use an underscore to indicate a range of rounds. For example, weight C1_4CW0 applies to cases with assessment data from the first four rounds of data collection (fall-kindergarten, spring-kindergarten, fall first-grade, and spring-first grade) or cases that were excluded from the direct assessment in one or more rounds due to a disability. The letters in the weight names indicate the survey component (see exhibit . Two letters (F and S) are also used in some of the longitudinal weights to indicate whether the weight applies to the full sample (F) or to the fall-first grade subsample (S). These letters appear before P (parent interview) and C (child assessment) in the weight name. For example, C1_6FC0 is used for analysis of child assessment data for the full sample from five rounds (1, 2, 4, 5, and 6). Data from round 3 (the 10-5 subsample) are not included and thus the weight applies to the full sample. Weight C1_6SC0, on the other hand, pertains to assessment data from six rounds including the round 3 subsample, and thus the weight applies only to cases included in the subsample. The letter 'S' is not provided to indicate fall-first grade subsampling when round 3 is specified in the weight name (e.g., C34PW0). Many weights end in W0; the 'W' merely stands for \"weight.\" All analysis weights end in 0 (zero), whereas replicate weights end in 1 through 90. Four longitudinal weights described in exhibit 10-4 do not follow these naming conventions: BYCOMW0, Y2COMW0, C1_4PW0, and C1_4CW0. These weights were named before the naming conventions were put into place. Both C1_4PW0 and C1_4CW0 include the first four rounds of data and thus pertain to cases in the fall-first grade subsample. Child-level information in science teacher questionnaire (fifth and eighth grades) 1 BY Base-year data: information from fall-and spring-kindergarten (e.g., BYCW0, BYPW0, BYCPTW0) 1 When S appears in longitudinal weights, it means that the weight applies only to the panel that includes the fall-first grade subsample. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), fall 1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007. The cross-sectional weights available on the K-8 full sample file ECB are described in exhibit 10-3. The longitudinal weights available on the file are described in exhibit 10-4. In both exhibits, the number of records with nonzero weights is given for each weight so that users can check the count of records that will be included in a particular analysis. The use of the weights is described in the last column of exhibits 10-3 and 10-4. This column is designed to help users choose appropriate weights for their analyses. The K-8 full sample file includes records of children who were base-year respondents but who did not have data for both fall-kindergarten and spring-kindergarten. These records are included because a base-year respondent is defined as a child who had either a fall-or spring-kindergarten child assessment or parent interview or was excluded from assessment because of a disability or because the child belonged in the language minority, not Spanish group; in other words the data file includes records  for children with at least one nonzero base-year cross-sectional weight (C1CW0, C2CW0, C1PW0, or C2PW0) but not necessarily all nonzero base-year cross-sectional weights."}, {"section_title": "How to Use Cross-Sectional Weights", "text": "To use cross-sectional weights, decide which round of data collection you will be using and from which components you will be drawing data (e.g., parent interview, child assessment, or teacher questionnaire). In exhibit 10-3, go to the round of data collection you will be using. The column \"to be used in analysis of\" will help you select the weight that most closely matches the components from which you are drawing data. For example, if you are using third-grade parent interview and child assessment data in your analysis, go to the section of the exhibit labeled \"Spring-third grade.\" The best weight for your purposes is C5PW0. If you are also going to use teacher-level information from the third-grade teacher questionnaire, then you would use C5CPTW0. Detailed descriptions of the ECLS-K crosssectional weights are included in chapter 4 of the ECLS-K base-year, first-grade, third-grade, fifth-grade, and eighth-grade user's manuals."}, {"section_title": "10-7", "text": "Exhibit 10-3. ECLS-K: K-8 cross-sectional weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 child direct assessment data from fall-kindergarten, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity) or (b) data from any fall-kindergarten teacher questionnaire (teacher-level or child-level). C1PW0 18,097 parent interview data are present for fallkindergarten. parent interview data from fall-kindergarten, alone or in combination with (a) fall-kindergarten child assessment data or (b) data from any fallkindergarten teacher questionnaire (teacher-level or child-level). Exception: If data from the parent interview AND child assessments AND teacher-level (with or without child-level teacher) questionnaires are used together, then C1CPTW0 should be used. C1CPTW0 17,124 assessment data are present for fallkindergarten (or if the child was excluded from direct assessment in fall-kindergarten due to a disability), parent interview data are present for fall-kindergarten, and teacher-level questionnaire data are present for fall-kindergarten. child direct assessment data from fall-kindergarten with fall-kindergarten parent interview data and fall-kindergarten teacher-level data with or without child-level data from the teacher. data from spring-kindergarten teacher questionnaire part A, data from fallor spring-kindergarten teacher questionnaire part B, or combination of data from fall-kindergarten or spring-kindergarten teacher questionnaire part A or B. C2CW0"}, {"section_title": "Spring-Kindergarten", "text": "19,967 assessment data are present for springkindergarten, or if the child was excluded from direct assessment in springkindergarten due to a disability. child direct assessment data from spring-kindergarten, alone or combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-kindergarten teacher questionnaire (teacher-level or child-level), or (c) data from the springkindergarten school administrator questionnaire or school facilities checklist. See note at end of exhibit."}, {"section_title": "10-8", "text": "Exhibit 10-3. ECLS-K: K-8 cross-sectional weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 parent interview data from spring-kindergarten, alone or in combination with (a) spring-kindergarten child assessment data, (b) data from any spring-kindergarten teacher questionnaire (teacher-level or child-level), or (c) data from the spring-kindergarten school administrator questionnaire or school facilities checklist. Exception: If data from the parent interview AND child assessments AND teacher-level (with or without child-level teacher) questionnaires are used together, then C2CPTW0 should be used. C2CPTW0 17,454 assessment data are present for springkindergarten (or if the child was excluded from direct assessment in springkindergarten due to a disability), parent interview data are present for springkindergarten, and teacher-level questionnaire data are present for springkindergarten. child direct assessment data from spring-kindergarten with springkindergarten parent interview data and spring-kindergarten teacher-level data with or without child-level data from the teacher, alone or in combination with data from the spring-kindergarten school administrator questionnaire or facilities checklist. Fall-First Grade C3CW0 5,291 assessment data are present for fall-first grade, or if the child was excluded from direct assessment in fall-first grade due to a disability. child direct assessment data from fall-first grade, alone or in combination with a limited set of child characteristics (e.g., age, sex, and race/ethnicity) C3PW0 5,071 parent interview data are present for fallfirst grade. parent interview data from fall-first grade, alone or in combination with fall-first grade child assessment data."}, {"section_title": "Spring-First Grade C4CW0", "text": "16,727 assessment data are present for spring-first grade, or if the child was excluded from direct assessment in spring-first grade due to a disability. child direct assessment data from spring-first grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-first grade teacher questionnaire (teacher-level or child-level), or (c) data from the springfirst grade school administrator questionnaire or school facilities checklist. See note at end of exhibit."}, {"section_title": "10-9", "text": "Exhibit 10-3. ECLS-K: K-8 cross-sectional weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 child direct assessment data from spring-first grade with spring-first grade parent interview data and spring-first grade teacher-level data with or without child-level data from the teacher, alone or in combination with data from the spring-first grade school administrator questionnaire or facilities checklist. Spring-Third Grade C5CW0 14,470 assessment data are present for spring-third grade, or if the child was excluded from direct assessment in spring-third grade due to a disability. child direct assessment data from spring-third grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-third grade teacher questionnaire (teacher-level or child-level), or (c) data from the springthird grade school administrator questionnaire or school facilities checklist. C5PW0 13,489 parent interview data are present for springthird grade. parent interview data from spring-third grade, alone or in combination with (a) spring-third grade child assessment data, (b) data from any spring-third grade teacher questionnaire (teacher-level or child-level), or (c) data from the spring-third grade school administrator questionnaire or school facilities checklist. Exception: If data from the parent interview AND child assessments AND teacher-level (with or without child-level teacher) questionnaires are used together, then C5CPTW0 should be used. See note at end of exhibit."}, {"section_title": "10-10", "text": "Exhibit 10-3. ECLS-K: K-8 cross-sectional weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 child direct assessment data from spring-third grade with spring-third grade parent interview data and spring-third grade teacher-level data with or without child-level data from the teacher, alone or in combination with data from the spring-third grade school administrator questionnaire or facilities checklist. C6CW0 11,346 assessment data are present for spring-fifth grade, or if the child was excluded from direct assessment in spring-fifth grade due to a disability."}, {"section_title": "Spring-Fifth Grade", "text": "child direct assessment data from spring-fifth grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-fifth grade teacher questionnaire (teacher-level or child-level), or (c) data from the springfifth grade school administrator questionnaire or school facilities checklist. C6PW0 10,996 parent interview data are present for springfifth grade. parent interview data from spring-fifth grade, alone or in combination with (a) spring-fifth grade child assessment data, (b) data from any spring-fifth grade teacher questionnaire (teacher-level or child-level), or (c) data from the spring-fifth grade school administrator questionnaire or school facilities checklist. Exception: If data from the parent interview AND child assessments AND teacher-level (with or without child-level teacher) questionnaires are used together, then C6CPTE0, C6CPTM0, or C6CPTS0 should be used. C6CPTR0 10,120 assessment data are present for spring-fifth grade (or the child was excluded from direct assessment in spring-fifth grade due to a disability), parent interview data are present for spring-fifth grade, and teacherlevel from the reading teacher. child direct assessment data from spring-fifth grade with spring-fifth grade parent interview data and spring-fifth grade reading teacher-level data with or without child-level data from the reading teacher, alone or in combination with data from the spring-fifth grade school administrator questionnaire or facilities checklist. See note at end of exhibit."}, {"section_title": "10-11", "text": "Exhibit 10-3. ECLS-K: K-8 cross-sectional weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 child direct assessment data from spring-fifth grade with spring-fifth grade parent interview data and spring-fifth grade reading or mathematics teacher-level data with or without child-level data from the mathematics teacher, alone or in combination with data from the spring-fifth grade school administrator questionnaire or facilities checklist. This weight is to be used only if the analytic sample is restricted to the subset of children who were sampled to have a mathematics teacher questionnaire."}, {"section_title": "C6CPTS0", "text": "5,103 child was sampled to have a child-level questionnaire completed by the science teacher, assessment data are present for spring-fifth grade (or the child was excluded from direct assessment in springfifth grade due to a disability), parent interview data are present for spring-fifth grade, and teacher-level data are present for spring-fifth grade (either from the reading teacher or the science teacher). child direct assessment data from spring-fifth grade with spring-fifth grade parent interview data and spring-fifth grade reading or science teacherlevel data with or without child-level data from the science teacher, alone or in combination with data from the spring-fifth grade school administrator questionnaire or facilities checklist. This weight is to be used only if the analytic sample is restricted to the subset of children who were sampled to have a science teacher questionnaire. Spring-Eighth Grade C7CW0 9,358 assessment data are present for springeighth grade (or if the child was excluded from direct assessment in spring-eighth grade due to a disability), or child questionnaire data are present for springeighth grade. child direct assessment or student questionnaire data from spring-eighth grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-eighth grade teacher questionnaire (teacher-level or child-level), or (c) data from the spring-eighth grade school administrator questionnaire."}, {"section_title": "C7PW0", "text": "8,809 parent interview data are present for springeighth grade. parent interview data from spring-eighth grade, alone or in combination with (a) spring-eighth grade child assessment or student questionnaire data, (b) data from any spring-eighth grade teacher questionnaire (teacherlevel or child-level), or (c) data from the spring-eighth grade school administrator questionnaire. Exception: If data from the parent interview AND child assessments AND teacher-level (with or without child-level teacher) questionnaires are used together, then C7CPTE0, C7CPTM0, or C7CPTS0 should be used. See note at end of exhibit."}, {"section_title": "10-12", "text": "Exhibit 10-3. ECLS-K: K-8 cross-sectional weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 child direct assessment or student questionnaire data from spring-eighth grade with spring-eighth grade parent interview data and spring-eighth grade English teacher-level data with or without child-level data from the English teacher, alone or in combination with data from the spring-eighth grade school administrator questionnaire. C7CPTM0 4,130 child was sampled to have a child-level questionnaire completed by the mathematics teacher and assessment data are present for spring-eighth grade (or the child was excluded from direct assessment in spring-eighth grade due to a disability), or student questionnaire data are present for spring-eighth grade, parent interview data are present for spring-eighth grade, and teacher-level data are present for springeighth grade (either from the English teacher or the mathematics teacher). child direct assessment or student questionnaire data from spring-eighth grade with spring-eighth grade parent interview data and spring-eighth grade English or mathematics teacher-level data with or without childlevel data from the mathematics teacher, alone or in combination with data from the spring-eighth grade school administrator questionnaire This weight is to be used only if the analytic sample is restricted to the subset of children who were sampled to have a mathematics teacher questionnaire."}, {"section_title": "C7CPTS0", "text": "4,164 child was sampled to have a child-level questionnaire completed by the science teacher and assessment data are present for spring-eighth grade (or the child was excluded from direct assessment in springfifth grade due to a disability), or student questionnaire data are present for springeighth grade, parent interview data are present for spring-eighth grade, and teacherlevel data are present for spring-eighth grade (either from the English teacher or the science teacher). child direct assessment or student questionnaire data from spring-eighth grade with spring-eighth grade parent interview data and spring-eighth grade English or science teacher-level data with or without child-level data from the science teacher, alone or in combination with data from the spring-eighth grade school administrator questionnaire. This weight is to be used only if the analytic sample is restricted to the subset of children who were sampled to have a science teacher questionnaire. SOURCE: U.S. Department of Education, National Center for Education Statistics, Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K), fall 1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007. 10-13"}, {"section_title": "How to Use Longitudinal Weights", "text": "First, decide which two or more points in time are the focus of the analysis. The analysis could pertain to two points in time (e.g., spring-kindergarten and fall-first grade, or spring-kindergarten and spring-first grade, or spring-first grade and spring-third grade); three points in time (e.g., spring-first grade, spring-third grade, and spring-fifth grade); four points in time (any four of fall-kindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, spring-fifth grade, and springeighth grade); five points in time (any five of fall-kindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade); six points in time (any six of fall-kindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, springfifth grade, and spring-eighth grade, or seven points in time (all seven rounds of data). In exhibit 10-4, go to the section of the table containing the weights for the HIGHEST grade level that you will be including in your analyses. For example, if the analysis uses spring-kindergarten and fall-first grade data, go to the section of the table labeled \"Fall-first grade.\" The appropriate weight begins with C23 (denoting childlevel data from round 2 AND round 3). If the analysis uses data from spring-kindergarten, spring-first, and spring-third grade, go to the section of exhibit 10-4 labeled \"Spring-third grade.\" The appropriate weight begins with C245 (denoting data from rounds 2, 4, AND 5). If the analysis uses data from springkindergarten, spring-first, spring-third, and spring-fifth grade, go to the section of the exhibit labeled \"Spring-fifth grade.\" The appropriate weight begins with C2_6F. If the analysis uses data from springkindergarten, spring-first, spring-third, spring-fifth grade, and spring-eighth grade, go to the section labeled \"Spring-eighth grade.\" The appropriate weight begins with C2_7F. Second, consider the source of the data, which also affects the choice of the weight. In exhibit 10-4, details under the \"to be used in the analysis of \u2026\" column provide guidance based on whether the data were collected through the child assessments, parent interviews, or teacher questionnaires. If parent data from spring-kindergarten and fall-first grade are needed for the analysis, then C23PW0 should be used, otherwise C23CW0 can be used. Similarly, if an analyst wishes to examine the influence of parent characteristics on gains in assessment scores between kindergarten and third grade, the appropriate weight would be C245PW0, indicating that parent interview data was included. However, if only child or teacher data were used in the analysis, then the appropriate weight to use is C245CW0. Detailed descriptions of the ECLS-K longitudinal weights are included in chapters 4 and 9 of the ECLS-K first-grade, third-grade, fifth-grade, and eighth-grade user's manuals."}, {"section_title": "10-14", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 K-8 longitudinal (cross-year) weights Number of records with nonzero weight Is nonzero if \u2026 To be used for analysis of \u2026 Fall-Kindergarten no longitudinal weights in first round of data collection Spring-Kindergarten BYCW0 18,211 assessment data are present for both fall-kindergarten and springkindergarten, or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability. child direct assessment data from BOTH fall-and spring-kindergarten, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fall-or spring-kindergarten teacher questionnaire (teacher-level or child-level), or (c) data from the springkindergarten school administrator questionnaire or school facilities checklist."}, {"section_title": "BYPW0", "text": "16,906 parent interview data are present for both fall-kindergarten and fall-first grade. parent interview data from BOTH fall-and spring-kindergarten, alone or in combination with (a) fall-or spring-kindergarten child assessment data, (b) data from any fall-or spring-kindergarten teacher questionnaire (teacher-level or childlevel), or (c) data from the spring-kindergarten school administrator questionnaire or school facilities checklist. BYCPTW0 15,420 assessment data are present for both fall-kindergarten and springkindergarten (or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability), parent interview data are present for both fall-kindergarten and springkindergarten grade, and teacher-level questionnaire data are present for both fall-kindergarten and springkindergarten. child direct assessment data from BOTH fall-and spring-kindergarten with parent interview data from BOTH fall-and spring-kindergarten and teacher-level questionnaire data from BOTH fall-and spring-kindergarten, alone or in combination with data from the spring-kindergarten school administrator questionnaire or facilities checklist. See note at end of exhibit."}, {"section_title": "10-15", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998-99, 1999-2000, 2001-02, 2003-04, and 2006 weights Number of records with nonzero weight Is nonzero if \u2026 To be used for analysis of \u2026 Spring-Kindergarten-Continued BYCOMW0 17,060 assessment data are present for both fall-kindergarten and springkindergarten (or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability), AND parent interview data are present for fall-kindergarten, springkindergarten, or both rounds, or teacher-level questionnaire data are present for fall-kindergarten, springkindergarten, or both rounds. child direct assessment data from BOTH fall-and spring-kindergarten in combination with at least one or more rounds (fall-and/or spring-kindergarten) of parent and/or teacher-level questionnaire data. This may or may not be in combination with the spring-kindergarten school administrator questionnaire and facilities checklist data. Exception: Whenever BOTH rounds of parent data are used in the analysis either BYPW0 or BYCPTW0 (described above) should be used. Fall-First Grade C23CW0 5,216 assessment data are present for both spring-kindergarten and fall-first grade, or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability. child direct assessment data from BOTH spring-kindergarten and fall-first grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from the spring-kindergarten teacher questionnaire (teacher-level or child-level), or (c) data from the springkindergarten school administrator questionnaire or school facilities checklist."}, {"section_title": "C23PW0", "text": "4,861 parent interview data are present for both spring-kindergarten and fallfirst grade. parent interview data from BOTH spring-kindergarten or fall-first grade, alone or in combination with (a) spring-kindergarten or fall-first grade child assessment data, (b) data from the spring-kindergarten teacher questionnaire (teacher-level or child-level), or (c) data from the spring-kindergarten school administrator questionnaire or school facilities checklist. C123CW0 4,729 assessment data are present for falland spring-kindergarten and fall-first grade, or if the child was excluded from direct assessment in all three of these rounds of data collection due to a disability. child direct assessment data from THREE rounds of data collection (fallkindergarten, spring-kindergarten and fall-first grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fall-or spring-kindergarten teacher questionnaire (teacher-level or child-level), or (c) data from the spring-kindergarten school administrator questionnaire or school facilities checklist."}, {"section_title": "10-16", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 parent interview data from THREE rounds of data collection (fall-kindergarten, spring-kindergarten and fall-first grade), alone or in combination with (a) child assessment data from any of these three rounds, (b) data from any fallkindergarten or spring-kindergarten teacher questionnaire (teacher-level or childlevel), or (c) data from the spring-kindergarten school administrator questionnaire or school facilities checklist."}, {"section_title": "Spring-First Grade C24CW0", "text": "16,371 assessment data are present for both spring-kindergarten and spring-first grade, or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability. child direct assessment data from BOTH spring-kindergarten and spring-first grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-kindergarten or spring-first grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten or spring-first grade school administrator questionnaire or school facilities checklist. C24PW0 14,938 parent interview data are present for both spring-kindergarten and springfirst grade. parent interview data from BOTH spring-kindergarten or spring-first grade, alone or in combination with (a) spring-kindergarten or spring-first grade child assessment data, (b) data from any spring-kindergarten or spring-first grade teacher questionnaire (teacher-level or child-level), or (c) data from any springkindergarten or spring-first grade school administrator questionnaire or school facilities checklist. C124CW0 15,001 assessment data are present for fallkindergarten and spring-kindergarten and spring-first grade, or if the child was excluded from direct assessment in all three of these rounds of data collection due to a disability. child direct assessment data from THREE rounds of data collection (fallkindergarten, spring-kindergarten and spring-first grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-kindergarten, fall-kindergarten, or spring-first grade teacher questionnaire (teacher-level or child-level), or (c) data from any springkindergarten or spring-first grade school administrator questionnaire or school facilities checklist. C124PW0 13,413 parent interview data are present for fall-kindergarten and springkindergarten and spring-first grade. parent interview data from THREE rounds of data collection (fall-kindergarten, spring-kindergarten, and spring-first grade), alone or in combination with (a) child assessment data from any of these three rounds, (b) data from any springkindergarten, fall-kindergarten, or spring-first grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten or springfirst grade school administrator questionnaire or school facilities checklist. See note at end of exhibit."}, {"section_title": "10-17", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998-99, 1999-2000, 2001-02, 2003-04, and 2006 weights Number of records with nonzero weight Is nonzero if \u2026 To be used for analysis of \u2026 Spring-First Grade-Continued C1_4CW0 4,542 assessment data are present for four rounds of data collection (fallkindergarten, spring-kindergarten, fall-first grade, and spring-first grade), or if the child was excluded from direct assessment in all of these four rounds of data collection due to a disability. child direct assessment data from FOUR rounds of data collection (fallkindergarten, spring-kindergarten, fall-first grade, and spring-first grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fall-kindergarten, spring-kindergarten, or springfirst grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten or spring-first grade school administrator questionnaire or school facilities checklist."}, {"section_title": "C1_4PW0", "text": "4,012 parent interview data are present for four rounds of data collection (fallkindergarten, spring-kindergarten, fall-first grade, and spring-first grade). parent interview data from FOUR rounds of data collection (fall-kindergarten, spring-kindergarten, fall-first grade, and spring-first grade), alone or in combination with (a) child assessment data from any of these four rounds, (b) data from any fall-kindergarten, spring-kindergarten, or spring-first grade teacher questionnaire (teacher-level or child-level), or (c) data from any springkindergarten or spring-first grade school administrator questionnaire or school facilities checklist. C34CW0 5,047 assessment data are present for both fall-first grade and spring-first grade, or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability. child direct assessment data from BOTH fall-and spring-first grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from the spring-first grade teacher questionnaire (teacherlevel or child-level), or (c) data from the spring-first grade school administrator questionnaire or school facilities checklist. C34PW0 4,682 parent interview data are present for both fall-first grade and spring-first grade. parent interview data from BOTH fall-and spring-first grade, alone or in combination with (a) fall-or spring-first grade child assessment data, (b) data from the spring-first grade teacher questionnaire (teacher-level or child-level), or (c) data from the spring-first grade school administrator questionnaire or school facilities checklist. See note at end of exhibit."}, {"section_title": "10-18", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998-99, 1999-2000, 2001-02, 2003-04, and 2006 weights Number of records with nonzero weight Is nonzero if \u2026 To be used for analysis of \u2026 Spring-First Grade-Continued Y2COMW0 13,983 assessment data are present for fallkindergarten and spring-kindergarten and spring-first grade, or if the child was excluded from direct assessment in all three of these rounds of data collection, parent and/or teacher data are present for one or more base-year rounds, and parent and/or teacher data are present for spring-first grade. child direct assessment data from THREE rounds of data collection (fallkindergarten, spring-kindergarten, and spring-first grade), in combination with parent and/or teacher data from spring-first grade, AND parent and/or teacher data from fall-or spring-kindergarten. Spring-Third Grade C45CW0 13,964 assessment data are present for both spring-first grade and spring-third grade, or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability. child direct assessment data from BOTH spring-first grade and spring-third grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-first grade or spring-third grade teacher questionnaire (teacher-level or child-level), or (c) data from any springfirst grade or spring-third grade school administrator questionnaire or school facilities checklist. C45PW0 12,652 parent interview data are present for both spring-first grade and springthird grade. parent interview data from BOTH spring-first grade and spring-third grade, alone or in combination with (a) spring-first grade or spring-third grade child assessment data, (b) data from any spring-first grade or spring-third grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-first grade or spring-third grade school administrator questionnaire or school facilities checklist. C245CW0 13,694 assessment data are present for spring-kindergarten and spring-first grade and spring-third grade, or if the child was excluded from direct assessment in all of these three rounds of data collection due to a disability. child direct assessment data from THREE rounds of data collection (springkindergarten, spring-first grade and spring-third grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-kindergarten, spring-first grade, or spring-third grade teacher questionnaire (teacher-level or child-level), or (c) data from any springkindergarten, spring-first grade, or spring-third grade school administrator questionnaire or school facilities checklist."}, {"section_title": "10-19", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 parent interview data from THREE rounds of data collection (spring-kindergarten, spring-first grade and spring-third grade), alone or in combination with (a) child assessment data from any of these three rounds, (b) data from any springkindergarten, spring-first grade, or spring-third grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten, spring-first grade, or spring-third grade school administrator questionnaire or school facilities checklist. C1_5FC0 12,558 assessment data are present for four rounds of data collection involving the full sample of children (fallkindergarten, spring-kindergarten, spring-first grade, and spring-third grade), or if the child was excluded from direct assessment in all four of these rounds of data collection due to a disability. child direct assessment data from FOUR rounds of data collection (fallkindergarten, spring-kindergarten, spring-first grade, and spring-third grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fall-kindergarten, spring-kindergarten, springfirst grade, or spring-third grade teacher questionnaire (teacher-level or childlevel), or (c) data from any spring-kindergarten, spring-first grade or spring-third grade school administrator questionnaire, or school facilities checklist."}, {"section_title": "C1_5FP0", "text": "10,998 parent interview data are present for four rounds of data collection involving the full sample of children (fall-kindergarten, springkindergarten, spring-first grade, and spring-third grade). parent interview data from FOUR rounds of data collection (fall-kindergarten, spring-kindergarten, spring-first grade, and spring-third grade), alone or in combination with (a) child assessment data from any of these four rounds, (b) data from any fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten, spring-first grade, or spring-third grade school administrator questionnaire or school facilities checklist. C1_5SC0 4,032 assessment data are present for five rounds of data collection (fallkindergarten, spring-kindergarten, fall-first grade, spring-first grade, and spring-third grade), or if the child was excluded from direct assessment in all five rounds of data collection due to a disability. child direct assessment data from FIVE rounds of data collection (fallkindergarten, spring-kindergarten, fall-first grade, spring-first grade and springthird grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fall-kindergarten, springkindergarten, spring-first grade, or spring-third grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten, spring-first grade, or spring-third grade school administrator questionnaire or school facilities checklist. See note at end of exhibit."}, {"section_title": "10-20", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 parent interview data from FIVE rounds of data collection (fall-kindergarten, spring-kindergarten, fall-first grade, spring-first grade, and spring-third grade), alone or in combination with (a) child assessment data from any of these five rounds, (b) data from any fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten, spring-first grade, or spring-third grade school administrator questionnaire or school facilities checklist."}, {"section_title": "Spring-Fifth Grade C56CW0", "text": "11,136 assessment data are present for both spring-third grade and spring-fifth grade, or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability. child direct assessment data from BOTH spring-third grade and spring-fifth grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-third grade or spring-fifth grade teacher questionnaire (teacher-level or child-level), or (c) data from any springthird grade or spring-fifth grade school administrator questionnaire or school facilities checklist. C56PW0 10,079 parent interview data are present for both spring-third grade and springfifth grade. parent interview data from BOTH spring-third grade and spring-fifth grade, alone or in combination with (a) spring-third grade or spring-fifth grade child assessment data, (b) data from any spring-third grade or spring-fifth grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-third grade or spring-fifth grade school administrator questionnaire or school facilities checklist. C456CW0 10,852 assessment data are present for spring-first grade, spring-third grade, and spring-fifth grade, or if the child was excluded from direct assessment in all of these three rounds of data collection due to a disability. child direct assessment data from THREE rounds of data collection (spring-first grade, spring-third grade and spring-fifth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-first grade, spring-third grade, or spring-fifth grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-first grade, spring-third grade, or spring-fifth grade school administrator questionnaire or school facilities checklist. See note at end of exhibit."}, {"section_title": "10-21", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 parent interview data from THREE rounds of data collection (spring-first grade, spring-third grade and spring-fifth grade), alone or in combination with (a) child assessment data from any of these three rounds, (b data from any spring-first grade, spring-third grade, or spring-fifth grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-first grade, spring-third grade, or spring-fifth grade school administrator questionnaire or school facilities checklist. C2_6FC0 10,673 assessment data are present for four rounds of data collection involving the full sample of children (springkindergarten, spring-first grade, spring-third grade, and spring-fifth grade), or if the child was excluded from direct assessment in all four of these rounds of data collection due to a disability. child direct assessment data from FOUR rounds of data collection (springkindergarten, spring-first grade, spring-third grade, and spring-fifth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-kindergarten, spring-first grade, springthird grade, or spring-fifth grade teacher questionnaire (teacher-level or childlevel), or (c) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school administrator questionnaire or school facilities checklist."}, {"section_title": "C2_6FP0", "text": "9,267 parent interview data are present for four rounds of data collection involving the full sample of children (spring-kindergarten, spring-first grade, spring-third grade, and springfifth grade). parent interview data from FOUR rounds of data collection (spring-kindergarten, spring-first grade, spring-third grade, and spring-fifth grade), alone or in combination with (a) child assessment data from any of these four rounds, (b) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school administrator questionnaire or school facilities checklist. C1_6FC0 9,796 assessment data are present for five rounds of data collection involving the full sample of children (fallkindergarten, spring-kindergarten, spring-first grade, spring-third grade, and spring-fifth grade), or if the child was excluded from direct assessment in all five of these rounds of data collection due to a disability. child direct assessment data from FIVE rounds of data collection (fallkindergarten, spring-kindergarten, spring-first grade, spring-third grade, and spring-fifth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fallkindergarten, spring-kindergarten, spring-first grade, spring-third grade, or springfifth grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school administrator questionnaire or school facilities checklist. See note at end of exhibit."}, {"section_title": "10-22", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 parent interview data from FIVE rounds of data collection (fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, and spring-fifth grade), alone or in combination with (a) any child assessment data from these four rounds, (b) data from any fall-kindergarten, spring-kindergarten, spring-first grade, springthird grade, or spring-fifth grade teacher questionnaire (teacher-level or childlevel), or (c) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school administrator questionnaire or school facilities checklist. C1_6SC0 3,000 assessment data are present for six rounds of data collection (fallkindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, and spring-fifth grade), or if the child was excluded from direct assessment in all six rounds of data collection due to a disability. child direct assessment data from SIX rounds of data collection (fall-kindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, and spring-fifth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fallkindergarten, spring-kindergarten, spring-first grade, spring-third grade, or springfifth grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school administrator questionnaire or school facilities checklist."}, {"section_title": "C1_6SP0", "text": "2,566 parent interview data are present for six rounds of data collection (fallkindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, and spring-fifth grade). parent interview data from SIX rounds of data collection (fall-kindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, and spring-fifth grade), alone or in combination with (a) child assessment data from any of these six rounds, (b) ) data from any fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade teacher questionnaire (teacher-level or child-level), or (c) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school administrator questionnaire or school facilities checklist. See note at end of exhibit."}, {"section_title": "10-23", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998-99, 1999-2000, 2001-02, 2003-04, and 2006 weights Number of records with nonzero weight Is nonzero if \u2026 To be used for analysis of \u2026 Spring-Eighth Grade C67CW0 8,960 assessment data are present for both spring-fifth grade and spring-eighth grade, or if the child was excluded from direct assessment in both of these rounds of data collection due to a disability. child direct assessment data from BOTH spring-fifth grade and spring-eighth grade, alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-fifth grade or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-fifth grade or spring-eighth grade school administrator questionnaire, or (d) data from the spring-fifth grade school facilities checklist. C67PW0 8,544 parent interview data are present for both spring-fifth grade and springeighth grade. parent interview data from BOTH spring-fifth grade or spring-eighth grade, alone or in combination with (a) spring-fifth grade or spring-eighth grade child assessment data, (b) data from any spring-fifth grade or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-fifth grade or spring-eighth grade school administrator questionnaire, or (d) data from the spring-fifth grade school facilities checklist. C567CW0 8,827 assessment data are present for spring-third grade, spring-fifth grade, and spring-eighth grade, or if the child was excluded from direct assessment in all of these three rounds of data collection due to a disability. child direct assessment data from THREE rounds of data collection (spring-third grade, spring-fifth grade and spring-eighth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-third grade or spring-fifth grade school facilities checklist. C567PW0 8,070 parent interview data are present for spring-third grade, spring-fifth grade, and spring-eighth grade. parent interview data from THREE rounds of data collection (spring-third grade, spring-fifth grade and spring-eighth grade), alone or in combination with (a) child assessment data from any of these three rounds, (b) data from any spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacherlevel or child-level), (c) data from any spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-third grade or spring-fifth grade school facilities checklist. See note at end of exhibit."}, {"section_title": "10-24", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 parent interview data from FOUR rounds of data collection (spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth), alone or in combination with (a) child assessment data from any of these four rounds, (b) data from any spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist. C2_7FC0 8,503 assessment data are present for five rounds of data collection involving the full sample of children (springkindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), or if the child was excluded from direct assessment in all of these five rounds of data collection due to a disability. child direct assessment data from FIVE rounds of data collection (springkindergarten, spring-first grade, spring-third grade, spring-fifth grade, and springeighth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any spring-kindergarten, springfirst grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist. See note at end of exhibit."}, {"section_title": "10-25", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 parent interview data from FIVE rounds of data collection (spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), alone or in combination with (a) child assessment data from any of these five rounds, (b) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacherlevel or child-level), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, springthird grade, or spring-fifth grade school facilities checklist. C1_7FC0 7,803 assessment data are present for six rounds of data collection involving the full sample of children (fallkindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), or if the child was excluded from direct assessment in all of these six rounds of data collection due to a disability. child direct assessment data from SIX rounds of data collection (fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fallkindergarten, spring-kindergarten, spring-first grade, spring-third grade, springfifth grade, or spring-eighth grade teacher questionnaire (teacher-level or childlevel), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, springthird grade, or spring-fifth grade school facilities checklist. C1_7FP0 6,861 parent interview data are present for six rounds of data collection involving the full sample of children (fall-kindergarten, springkindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade). parent interview data from SIX rounds of data collection (fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), alone or in combination with (a) child assessment data from these any of these six rounds, (b) data from any fall-kindergarten, springkindergarten, spring-first grade, spring-third grade, spring-fifth grade, or springeighth grade teacher questionnaire (teacher-level or child-level), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, spring-third grade, or spring-fifth grade school facilities checklist. See note at end of exhibit."}, {"section_title": "10-26", "text": "Exhibit 10-4. ECLS-K: K-8 longitudinal weights: School years 1998-99, 1999-2000, 2001-02, 2003-04, and 2006 weights Number of records with nonzero weight Is nonzero if \u2026 To be used for analysis of \u2026 Spring-Eighth Grade-Continued C1_7SC0 2,369 assessment data are present for all seven rounds of data collection involving the full sample of children (fall-kindergarten, springkindergarten, fall-first grade, springfirst grade, spring-third grade, spring-fifth grade, and spring-eighth grade), or if the child was excluded from direct assessment in all of these seven rounds of data collection due to a disability. child direct assessment data from ALL SEVEN rounds of data collection (fallkindergarten, spring-kindergarten, fall-first grade, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade) alone or in combination with (a) a limited set of child characteristics (e.g., age, sex, and race/ethnicity), (b) data from any fall-kindergarten, spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade teacher questionnaire (teacherlevel or child-level), (c) data from any spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, or spring-eighth grade school administrator questionnaire, or (d) data from any spring-kindergarten, spring-first grade, springthird grade, or spring-fifth grade school facilities checklist."}, {"section_title": "10-28", "text": "Exhibit 10-5. Examples of research questions and appropriate weights to use: School years 1998School years -99, 1999School years -2000School years , 2001School years -02, 2003School years -04, and 2006 Research  1998, spring 1999, fall 1999, spring 2000, spring 2002, spring 2004, and spring 2007."}, {"section_title": "10-29", "text": "There may be combinations of data for which no weights were developed. For example, there is no specific weight to study changes in children's classroom environments as they move from kindergarten to eighth grade if child assessment or parent data are not used in the analysis. In this example, the data come from the teacher-level teacher's questionnaire (TQA in kindergarten, first grade, and third grade, and teacher-level teacher questionnaire in fifth grade and eighth grade). The preferred weight for this analysis would be C2_7FC0, which is the weight for child direct assessment data from spring-kindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade. Of children on the longitudinal K-8 file with teacher-level data in all five of these rounds (e.g., springkindergarten, spring-first grade, spring-third grade, spring-fifth grade, and spring-eighth grade), 99 percent (6,483) have nonzero C2_7FC0, compared with 90 percent (5,909) with nonzero C1_7FC0 and 25 percent (1,669) with nonzero C1_7SC0, the other two longitudinal weights available for analyses of child data. The preferred weight is the one that will yield the largest number of records for analysis, which in this case is C2_7FC0. Analytically, it can be argued that since the direct assessments are conducted in schools, this weight comes closest to capturing the children in participating schools and thus to capturing the children with relevant school environment data. Similarly, if data from the school administrator questionnaire are used in the analysis of the K-8 longitudinal data, then the same arguments can be used to select the weight. In this case, 27 percent of children in the K-8 file have school administrator questionnaire data from kindergarten, first grade, third grade, fifth grade, and eighth grade; of these, 98 percent have nonzero C2_7FC0 compared with 89 percent with nonzero C1_67FC0 and 25 percent with nonzero C1_7SC0. Therefore, the preferred weight is also C2_7FC0. For further advice on which weights to use when analyzing a complex combination of data, contact NCES at ECLS@ed.gov."}, {"section_title": "Characteristics of Weights", "text": "The statistical characteristics of the cross-sectional and longitudinal weights are presented in table 10-1. The weights are listed by round with the cross-sectional weights listed before the longitudinal ones within each round. For each weight, the number of cases with nonzero values is presented together with the mean weight, the standard deviation, the coefficient of variation (i.e., the standard deviation as a percentage of the mean weight), the minimum value of the weight, the maximum value of the weight, the skewness, the kurtosis, and the sum of weights."}, {"section_title": "10-30", "text": "The difference in the estimate of the population of children (sum of weights) between the different panels of children and types of weights results from a combination of factors, among them: (1) the number of base-year respondents who became ineligible (due to death, leaving the country, or being a nonsampled mover) after the base year; (2) the adjustment of the weights for the children of unknown eligibility; and (3) the difference in the number of records used to construct sample-based control totals. Of the longitudinal weights computed in third grade, fifth grade, and eighth grade, 12 weights (C45CW0, C45PW0, C56CW0, C56PW0, C67CW0, C67PW0, C456CW0, C456PW0, C567CW0, C567PW0, C4_7FC0, and C4_7FP0) involve children sampled in first grade. For these weights, the child records included in the file used for computing the control totals are records of baseyear respondents and records of eligible children sampled in first grade. For all other longitudinal weights, records of children sampled in first grade were not included in the file, causing the sum of weights to be smaller. For information about the development of the longitudinal weights, see chapter 9 of the firstgrade, third-grade, fifth-grade, and eighth-grade user's manuals. 10-31 Table 10-1. Characteristics of child-level K-8 weights: School years 1998K-8 weights: School years -99, 1999K-8 weights: School years -2000K-8 weights: School years , 2001K-8 weights: School years -02, 2003K-8 weights: School years -04, and 2006  10-32 Table 10-1. Characteristics of child-level K-8 weights: School years 1998-99, 1999-2000, 2001-02, 2003-04, and 2006 "}]