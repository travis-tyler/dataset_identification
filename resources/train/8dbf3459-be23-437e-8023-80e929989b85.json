[{"section_title": "Introduction", "text": "Following recent improvements in model resolution and physics, global climate models (GCMs) are now being employed to study how tropical cyclone (TC) frequency and intensity might change in the future (e.g., Sugi et al. 2002;Knutson and Tuleya 2004;Bengtsson et al. 2007;Gualdi et al. 2008;Knutson et al. 2008;Zhao et al. 2009;Bender et al. 2010;Knutson et al. 2010). TCs can be costly events in terms of loss of life and property. Therefore it is important to understand how these storms may be affected by a warmer climate. GCMs have the potential to be valuable tools in this area of research, but before they can be used with confidence to predict future TC attributes, it is necessary to understand how well they represent historical TCs. Specifically, how well do model-generated TCs match observed TCs with respect to intensity, frequency, and spatial distribution? After earlier attempts at resolving TC-like vortices in coarse-resolution GCMs (e.g., Manabe et al. 1970;Haarsma et al. 1993;Bengtsson et al. 1995), enhanced computing capabilities and physical parameterizations have resulted in better representations of tropical cyclones in models (e.g., Vitart et al. 1993;Sugi et al. 2002;Oouchi et al. 2006;Bengtsson et al. 2007;Walsh et al. 2007;LaRow et al. 2008;Zhao et al. 2009). Although these finer-resolution GCMs have been able to generate warm core vortices that resemble TCs, the resolution and physics still fall short in some respects. Most notably, the modeled systems are still unable to attain intensities of observed TCs (e.g., Emanuel et al. 2008;LaRow et al. 2008;Zhao and Held 2010). In fact, Chen et al. (2007) used mesoscale models to demonstrate that a grid spacing of ;1 km may be necessary to resolve hurricane eyewall convection and wind maxima. Despite these shortcomings, recent studies reveal some promise in the ability of GCMs to reproduce global TC statistics such as storm counts and seasonal cycle on the basin scale (e.g., Camargo et al. 2005;Zhao et al. 2009). For example, Zhao et al. (2009) ran a global climate model of 50-km horizontal resolution over the period  and found that the correlation of modeled and observed yearly Atlantic Ocean hurricane counts was greater than 0.8, although correlations were lower in the Pacific and Indian Ocean basins. As resolution and physics continue to improve and new models are developed, intercomparison analyses are needed to provide insight into the model strengths and weaknesses. For example, Camargo et al. (2005) examined genesis location, TC counts, intensity, and storm lifetimes in a statistical analysis of TC-like vortices in three low-resolution GCMs. They found that basinscale global TC statistics match the observed statistics reasonably well, even for these lower-resolution models. With the suite of higher-resolution models, individual modeling groups have presented TC performance statistics for their specific model (e.g., Bengtsson et al. 2007;Gualdi et al. 2008;LaRow et al. 2008;Zhao et al. 2009). However, there remains a need for a uniform framework that can be used to compare the new suite of highresolution models with each other and with observations. We present a spatial lattice framework, first introduced for use in TC studies by Elsner et al. (2012), as a novel approach to model intercomparisons. The model comparison we present demonstrates how the spatial lattice approach may facilitate efficient spatial and statistical comparison of model-generated TCs. Here we employ the spatial lattice to see how well the spatial distribution of actual TCs compares with the distributions generated by two atmospheric GCMs: the Florida State University (FSU) Center for Ocean-Atmospheric Prediction Studies (COAPS) spectral model and the Geophysical Fluid Dynamics Laboratory (GFDL) High-Resolution Atmospheric Model (HiRAM). The methodology applied in this study to compare regional cyclone occurrence between observations and model simulations can be used to compare other models and other storm attributes such as intensity and intensification rate. The paper is organized as follows: observational and model track data are presented in section 2, followed by an explanation of the spatial lattice methodology in section 3. Section 4 examines the spatial distribution of observed and GFDL model TC occurrences using maps, and section 5 quantifies the comparison using a performance diagram. Section 6 compares the spatial distribution of observed and model TC occurrence over the North Atlantic alone using both the GFDL and FSU COAPS models. Comparisons are quantified using relative risk ratios. A summary is given in section 7."}, {"section_title": "Data", "text": ""}, {"section_title": "a. Observational data", "text": "Observational data used in this research come from the International Best Track Archive for Climate Stewardship (IBTrACS; available online at http://www.ncdc. noaa.gov/oa/ibtracs/; Knapp et al. 2010). For analysis purposes, the 6-hourly data have been interpolated to hourly intervals using the method outlined in Elsner and Jagger (2013). Although IBTrACS includes more than a century's worth of track data, we subset the data from the period 1982-2008. This is also the time period over which the models were run. Furthermore, because these data were obtained during the satellite era, the reliability of the observations is quite high. Finally, the period of study also includes the transition from the relatively inactive period in the North Atlantic from 1970-94 to the more recent active period after 1995 (e.g., Elsner et al. 2000;Goldenberg et al. 2001). Regardless of the cause, the apparent nonstationary nature of the North Atlantic TC climatology during this period is worth noting."}, {"section_title": "b. Model data", "text": "Model-derived track data are obtained from experiments performed by the Hurricane Working Group of the U.S. Climate Variability and Predictability Research Program (CLIVAR; http://www.usclivar.org/workinggroups/hurricane). We use data from two different highresolution atmospheric (uncoupled) GCMs. As with the observational data, the modeled track data are provided at 6-hourly intervals and have been interpolated to hourly intervals using the same algorithm as used for the observations. We first use cyclone tracks from the GFDL HiRAM, version 2.2 (Zhao et al. 2009(Zhao et al. , 2012. The model data come from a control simulation forced with monthly prescribed SSTs and sea ice concentrations for each simulated year from the Hadley Centre Global Sea Ice and Sea Surface Temperature (HadISST) dataset (Rayner et al. 2003). The model features a 50-km horizontal resolution and 32 vertical levels. As described by Zhao et al. (2009), TC-like vortices are detected and tracked using an algorithm similar to that used by Vitart et al. (2003). The algorithm searches for a coinciding (within 28 latitude and longitude) relative vorticity maximum at 850 hPa, a sea level pressure minimum, and a maximum in the 300-500-hPa averaged temperature field. The vortex trajectories are considered TC tracks when the modeled maximum surface winds exceed 15.2 m s 21 during at least three (not necessarily consecutive) days (Zhao et al. 2009). We use track data from three realizations of the HiRAM, referred to here as r1, r2, and r3, which differ only in their initial conditions. The initial conditions in different HiRAM runs are obtained from 1 January of different years from an earlier Atmospheric Model Intercomparison Project (AMIP) run. For these long integrations, the initial conditions are completely irrelevant to the solutions since we do not use the first year results. The purpose is to generate different realizations of the simulation. We also use cyclone tracks from the FSU COAPS global spectral model (Cocke and LaRow 2000;LaRow et al. 2008). As with the GFDL HiRAM, the FSU COAPS model is uncoupled with the ocean and is forced with prescribed SSTs from the HadISST dataset. The spectral model has 27 vertical levels and a T126 horizontal resolution, which corresponds to roughly 0.948 of latitude. The simulated TC tracks were obtained using a similar algorithm. Because global track data were not available from this model, FSU COAPS tracks are compared with observations and HiRAM tracks for the North Atlantic basin only. Again, we use tracks from three model runs, r1, r2, and r3."}, {"section_title": "The spatial framework", "text": "First, a global comparison is implemented using track data from observations and GFDL HiRAM. To set up the spatial framework, we consider only those observations that meet or exceed 17 m s 21 , which corresponds to the 43rd percentile for the global IBTrACS dataset. We also set a 17 m s 21 minimum threshold for the modeled storms. Relative to observations, the model is unable to produce storms with intensities greater than 50 m s 21 (category 3 on the Saffir-Simpson scale); however, after the 17 m s 21 threshold is imposed, the average observed wind speed exceeds the average model wind speeds by less than 6 m s 21 for all model runs (see Table 1). It should be noted that the models are much more successful in simulating minimum central pressure. The minimum pressures from the GFDL HiRAM track data are 896.3, 905.4, and 897.0 hPa for runs r1, r2, and r3, respectively. These values compare well with the observed minimum pressure of 878.9 hPa. Therefore, another approach might be to use minimum pressure from the model data to infer wind speeds through some type of pressurewind relationship and then set the 17 m s 21 threshold from the inferred wind speeds. However, because we do not have data for the spatial extent of the modeled storms and would introduce additional uncertainty by using a pressure-wind relationship that does not incorporate storm size, we instead simply set the 17 m s 21 threshold using the raw wind speeds. For the global spatial analysis, the data locations are first projected onto a planar coordinate system using a Mollweide projection (Snyder 1987). The Mollweide projection is used because we want to examine global distributions of TCs in equal areas. The cost of using an equal-area projection is a sacrifice in the accuracy of angles and shapes, which is significant at the borders of the ellipse. To establish the spatial lattice, we first define a common grid of equal area hexagons that cover the global tropical and subtropical region to approximately 708N/S latitude. We choose to use a hexagon lattice because 1) it does not require an areal correction as needed for latitude-longitude grids and 2) relative to rectangles, hexagons are more efficient at capturing the curved nature of TC tracks (Elsner et al. 2012). The use of an areal correction, which would be necessary if we instead relied on latitude-longitude grids, would affect attribute values within the grids. For example, for areally corrected latitude-longitude grids, per-gridcell storm counts will not necessarily be an integer count, thereby making interpretation less intuitive and physical. With an equalarea tessellation, however, counts are preserved as integers. This allows for a more natural and physically meaningful interpretation of the results. We use hexagons of area 7.3 3 10 5 km 2 (slightly larger than the state of Texas) with a diameter, measured from vertex to opposite vertex, of 917 km. The selected area is sufficiently small to capture regional (basin and subbasin) variability. Once the hexagon grid is defined, we populate it with track attribute data from the observational and model datasets. Additional details, justification, and applications for the spatial framework used here can be found in Elsner et al. (2012)."}, {"section_title": "Cyclone counts", "text": "As we are interested in comparing observed and modeled spatial distributions of storms, we calculate cyclone counts within each hexagon. Cyclone counts represent the number of storms that ''passed through'' each hexagon in the spatial grid. One count is assigned for each TC that enters a hexagon. For example, a Counts are obtained by summing the number of unique storm IDs within each hexagon. Therefore if a TC enters, exits, and then reenters a hexagon, that TC is only counted once within the hexagon. Figure 1 illustrates the framework for the year 2005 in the Gulf of Mexico. We sum the number of cyclones contained in each hexagon and store this information in a polygon data frame for further calculations. This procedure is carried out for both observed and modeled data. It should be noted, however, that the hexagons in Fig. 1 have a smaller area of 1.6 3 10 5 km 2 as compared with the hexagons of area 7.3 3 10 5 km 2 used in the global analysis that follows. Using the same spatial lattice to sum TC counts for both observations and model, we can visually compare them with ease. Figure 2 contains a map of cyclone counts for (a) observations and (b) the GFDL HiRAM (r1). Darker reds indicate areas with higher storm frequencies over the 1982-2008 time period. Overall, the maps for observations and the model show a very similar spatial distribution of TCs. In both maps, local maxima in TC counts are present in the eastern and western North Pacific basins as indicated by the darker red hexagons. For observations, 223 out of the 363 hexagons in the lattice have cyclone counts less than 25. Only two hexagons have cyclone counts greater than 200. For the model a total of seven hexagons contain TC counts greater than 200 for HiRAM runs r1, r2, and r3. The largest observed count is 255, while the largest model counts are 295, 258, and 277 for realizations r1, r2, and r3, respectively. As evident in Fig. 2, there is distortion in the country border lines that is not present when we display the hexagon grid. This is a presentation issue that does not affect the actual analysis. The grid from which the cyclone counts are calculated is properly projected, but the polygons are not distorted as the country borders are when mapped. Furthermore, the grids remain the same for observations and model, so comparison still can be made accurately. However, caution should be exercised when interpreting the precise locations of country borders relative to the hexagons, particularly on the map edges. Although per-hexagon TC counts greater than 200 may seem high, they occur in particularly active regions of the eastern and western North Pacific basins. The eastern North Pacific is an especially active basin in terms of the number of storms forming over a given unit of area (Gray 1968;Molinari et al. 2000). This is clearly illustrated by the high-count hexagon (from observations) off of the west coast of Mexico. The high-count hexagon in the western North Pacific occurs roughly within the monsoon trough region, as geographically defined in Harr and Chan (2004). It is estimated that 60%-80% of western North Pacific TCs develop within the monsoon trough (Ritchie and Holland 1999;Harr and Chan 2004), which may help explain the high TC counts in this area. The highest TC count hexagons for the model are similarly located in the eastern and western North Pacific, although the largest counts in the western North Pacific appear to be displaced slightly eastward of the observed maximum. To facilitate further comparison of the observed and modeled TCs, we also create difference maps (Fig. 3). For cyclone count hexagons, this is accomplished by simply subtracting the per-hexagon modeled storm counts from the per-hexagon observed storm counts. Visually, these results agree well with Zhao et al. (2009). Although the overall distributions of observed and modeled TCs are similar, there is a significant area of overprediction (more modeled than observed cyclones) in the western North Pacific, and a small area of underprediction in the eastern North Pacific (fewer modeled than observed cyclones). There is an additional area of underprediction in the South China Sea. In all three model runs, the areas of strongest overprediction (on the order of 75-125 cyclones) exist in the western North Pacific and in the eastern North Pacific. Interestingly, the model also generates too many storms in the South Atlantic, an area in which observed storms have been exceptionally rare (only one storm was observed here in the 1982-2008 time period). Figures 2 and 3 also demonstrate how the spatial lattice framework may provide additional insight into the range of over/underprediction across space."}, {"section_title": "Metrics of spatial performance", "text": "The difference maps allow for a qualitative assessment of model performance in terms of cyclone counts per hexagon. We observe that there are numerous regions in which the model overpredicts the number of TCs (e.g., western North Pacific), while there are other regions in which the model underpredicts (e.g., Gulf of Mexico). Although this is a useful way of assessing subregional model performance in terms of cyclone counts, we are also interested in comparing how well the observed and modeled tracks match spatially over the entire globe. Stated differently, we are interested in knowing whether hexagons that cover areas with observed activity also cover areas with modeled activity. A simple bias calculation provides some insight into this spatial matching aspect of model performance. To calculate the bias, we compare the set of hexagons in which the observed cyclone count is greater than zero with the set of hexagons in which the modeled cyclone count is greater than zero. We then calculate the number of hits, false positives, and false negatives from these sets of hexagons. A hit is defined as a hexagon that contains at least one observed and at least one modeled TC; a false positive is defined as a hexagon that contains at least one modeled TC but does not contain an observed TC; and a false negative is defined as a hexagon that contains at least one observed TC but does not contain a modeled TC. We calculate the bias as defined in Roebber (2009): bias 5 where H is the sum of the hits, FP is the sum of the false positives, and FN is the sum of the false negatives for a grid of hexagons populated with observed and model data. For bias values near 1, there is no bias in the model. In this case, the amount of area covered by modeled tracks is the same as the amount of area covered by observed tracks. If the bias is less than 1, the area covered by observed tracks exceeds the area covered by modeled tracks. The model is in a sense underpredicting the spatial extent of the tracks. Conversely, if the bias is greater than 1, the area covered by modeled tracks exceeds the area covered by observed tracks and the model is overpredicting the spatial extent of the tracks. To obtain an estimate of model bias and its uncertainty relative to our spatial framework, we first generate 100 sets of hexagon lattices. Each lattice is randomly offset very slightly such that the hexagons do not precisely match in space. We then overlay the observed and modeled track data onto each set of hexagons to obtain per-hexagon counts as before. For the model, we use data from the GFDL HiRAM r1 in this section. Hexagons containing at least one observed storm are compared with hexagons containing at least one modeled storm and the bias is then calculated from Eq. (1). These biases are specific to gridcell size. For example, we might expect larger biases from lattices composed of smaller hexagons. To see the effects of grid resolution, we repeat this process for grids with per-hexagon areas of 14.6 3 10 5 , 9.70 3 10 5 , 7.28 3 10 5 (the original grid area), 4.85 3 10 5 , and 3.64 3 10 5 km 2 . The bias calculations, broken down by ocean basin and gridcell area, are presented with 95% confidence intervals (CIs) in Table 2. The CIs are based on the 2.5th and 97.5th percentiles of the 100 bias values. Interestingly, varying gridcell sizes in the range presented here does not statistically significantly affect the biases. In general, there is more overprediction than underprediction, with the most consistent exception being the North Atlantic. The overprediction is especially high in the South Atlantic, where the model produced 14 storms over the  period, but only one was observed. In general, there are more false positives than false negatives, although for most basins besides the South Atlantic the bias values do not fall far from 1, indicating good agreement. From Table 2, we also notice several basins for which the model appears to be unbiased. However, a bias value of 1 is not the perfect summary of model performance. In these cases, the number of false positives may simply balance out the number of false negatives. To gain additional insight to how well the model matches observations within the spatial framework, we also calculate a ''critical success index'' (CSI) (Roebber 2009). The CSI is expressed as Thus, values near 1 indicate very few false negatives or false positives, or a close match between model and observations, while values closer to zero indicate many false negatives, false positives, or both. Hits (H), false positives (FP), and false negatives (FN) are defined as before. As is done for the biases, we similarly calculate the CSI for 100 lattices and for varying gridcell sizes. These calculations, again broken down by ocean basin and gridcell area, are presented with 95% CIs in  Model bias values for the North Atlantic (NA), east Pacific (EP), west Pacific (WP), South Pacific (SP), north Indian (NI), south Indian (SI), South Atlantic (SA), and all basins together (All). The large numbers are median bias values after generating 100 hexagon grids slightly offset from each other in space. The numbers in parentheses represent the 95% confidence intervals. Bias values are provided for varying grid resolutions with per-hexagon areas (10 5 km 2 ) given in the first column. positives, fall below 20% for all grid sizes. Also not entirely unexpected is the slight decrease in CSI that occurs as per-hexagon area decrease; however, these decreases are not statistically significant, as indicated by the overlapping 95% confidence intervals. Roebber (2009) also introduces a way to visually compare the different metrics of performance in a single plot. We adopt this ''performance diagram'' to display the bias, CSI, probability of detection (POD), and success rate (SR) for the GFDL HiRAM track data. The probability of detection is expressed as The success rate is expressed as As displayed in Fig. 4, POD is defined along the vertical axis and SR along the horizontal axis. The straight dashed lines in Fig. 4 are lines of equal bias, while the curved solid lines represent lines of equal CSI. Using this diagram, we can visually assess model performance on the basis of four metrics: bias, CSI, POD, and SR. Figure 4 displays these points (with 95% CIs) for the North Atlantic (NA), eastern North Pacific (EP), western North Pacific (WP), South Pacific (SP), north Indian (NI), south Indian (SI), South Atlantic (SA), and for all basins together (ALL). The values plotted represent the median values following the generation of 100 hexagon grids as is done for the bias and CSI in Tables 2 and 3. The values in Fig. 4 are calculated based on grids with a per-hexagon area of 7.28 3 10 5 km 2 (the same area as is used in the maps in Figs. 2  and 3). Most points in Fig. 4 are clustered in the upper-right portion of the diagram, which indicates a high success rate and probability of detection. It is also clear from Fig. 4 that most points lie above the ''no bias'' line (bias 5 1), although the western North Pacific and northern Indian Ocean fall very near this line. The North Atlantic is the only basin with a bias less than 1, as mentioned previously. The North Atlantic will be addressed further in the following section. Figure 4 also indicates high CSI TABLE 3. Model CSI values (%) for the North Atlantic (NA), east Pacific (EP), west Pacific (WP), South Pacific (SP), north Indian (NI), south Indian (SI), South Atlantic (SA), and all basins together (All). The large numbers are median CSI values after generating 100 hexagon grids slightly offset from each other in space. The numbers in parentheses represent the 95% confidence intervals. CSI values are provided for varying grid resolutions with per-hexagon areas (10 5 km 2 ) given in the first column.  values for most basins, with the clear exception being the South Atlantic. On the basis of these metrics and our spatial lattice approach, the western North Pacific appears to most closely match observations, with a high probability of detection, a high success rate, a bias near 1, and a CSI close to 0.9. It should be mentioned that, as evident in Fig. 3, the western North Pacific represents a large area of model overprediction in terms of the number of storms present compared to observations. However, in terms of the area covered by TC tracks, the model matches observations well over the western North Pacific. For the South Atlantic, the performance diagram indicates significant model overprediction based on a high probability of detection, a low success rate, a very low CSI, and a very high bias. This makes sense as only one TC was observed during this period, but 14 TCs were generated by the GFDL HiRAM, r1. Although the GFDL HiRAM produces few TCs over the South Atlantic relative to other basins, for the period 1982-2008 it nevertheless generates far more TCs than observed. All of the previous calculations are made with a threshold of at least one TC for both model and observations. If we increase the threshold to be at least 15 TCs, for a grid of hexagons with area 7.28 3 10 5 km 2 , the global bias value decreases to 1.01 and the global CSI becomes 83.6% (compared to 1.11 and 74% with a threshold of one TC). For a threshold of 50 TCs, the bias remains at 1.01, but the CSI increases to 90.1%. Finally, for a threshold of at least 200 TCs, the bias still remains near 1.01, but the CSI increases to 98.8%. Therefore, it appears that the areas that generally contain the most observed storms also contain the most modeled storms."}, {"section_title": "Intermodel comparison over the North Atlantic", "text": "We next compare the GFDL HiRAM simulated tracks with those generated from the FSU COAPS spectral model. Because global tracks are not yet available for the FSU COAPS model, we focus our comparison on the North Atlantic basin. Once again, we select only observed cyclone points with intensities exceeding 17 m s 21 , which corresponds to the 33rd percentile of total observed storms over the North Atlantic. As with the HiRAM, a 17 m s 21 wind threshold is also set for the FSU COAPS model. The data are projected onto a planar coordinate system using a Lambert conformal conic projection. As was done for the global comparison, a grid of equal-area hexagons is created, this time for the North Atlantic basin. For the North Atlantic comparison, we use hexagons of area 1.91 3 10 5 km 2 , which are much smaller than the hexagons used for the global comparison (slightly larger than the state of Washington). This allows for a more detailed examination of subregional spatial variability. The hexagons are populated with observations and model data from both the GFDL HiRAM and the FSU COAPS spectral model. Per-hexagon cyclone counts for observations and the first run from each model are shown in Fig. 5. From Fig. 5 it is apparent that there are some discrepancies between the FSU COAPS model and observations. The FSU COAPS model appears to generate more cyclones over the south-central portion of the North Atlantic. Figure 5b also suggests that most of these model-generated cyclones recurve fairly quickly. This is consistent with LaRow et al. 2008, who attribute this to the model's large-scale steering flow during the first half of the hurricane season. The framework also allows us to directly compare the FSU COAPS model with the HiRAM. In contrast to the FSU COAPS model, which tends to generate too many cyclones over the North Atlantic, the GFDL HiRAM does not generate as many cyclones as are observed. The spatial pattern of the HiRAM cyclones is more consistent with observations, although there are fewer modeled cyclones over the Gulf of Mexico and Caribbean Sea than are observed. This latter point is also true of the FSU COAPS model. Further comparison of the FSU COAPS model with observations is implemented using relative ratios. We use the ratios to examine the factor by which the modeled cyclone frequency exceeds the observed frequency. This is accomplished by first dividing the number of cyclones in each hexagon by the total number of cyclones for the entire grid. These ratios are calculated for both model and observations. We then divide the model relative ratio by the observed relative ratio to obtain the factor by which modeled cyclone frequency exceeds observed cyclone frequency. The base-two logarithm of these factors, indicated by the color bar, is shown for the FSU model in Fig. 6a. A value greater than zero indicates an overprediction by the model, while a value less than zero indicates an underprediction. The overprediction region is clearly visible in the center of Fig. 6a. It is also apparent that few modeled cyclones are present over the Gulf of Mexico, at higher latitudes, and near the Cape Verde Islands. Figure 6b provides the same information for the GFDL HiRAM. In general, the GFDL HiRAM agrees better with observations, although once again there is a notable lack of model-generated cyclones in the Gulf of Mexico and Caribbean. Finally, a qualitative comparison between the FSU COAPS and the GFDL HiRAM is made. The results of this model comparison are depicted in Fig. 7. Using the same hexagon lattice as in Figs. 5 and 6, we compare areas in which both models overpredict the number of TCs relative to observations (shown in red), the areas in which the FSU model overpredicts but the GFDL underpredicts (magenta), the areas in which the GFDL overpredicts but the FSU underpredicts (cyan), and finally the areas in which both models underpredict (blue). It is clear from this map that both models underpredict over both the Caribbean and Gulf of Mexico. This is perhaps the result of a lack of model genesis over this subregion, premature recurving of storms generated farther east, or both. In the FSU COAPS model, for example, LaRow et al. (2008) note that a break in the ridge over the central Atlantic during the peak of the hurricane season allows more modeled storms to recurve early rather than continue westward. The possibility of a lack of model genesis over the Gulf of Mexico is also addressed. Figure 8 displays counts for per-hexagon genesis points for observations ( Fig. 8a), FSU COAPS (Fig. 8b), and GFDL HiRAM (Fig. 8c). To  6. Hexagons indicate the factor by which model storm frequency exceeds observed storm frequency for (a) FSU COAPS and (b) GFDL HiRAM. Values greater than 0 (pinks and reds) indicate that modeled storm frequency exceeds observed storm frequency, while values less than 0 (blues) indicate that observed storm frequency exceeds modeled storm frequency. obtain the genesis points, we define ''genesis'' as the first record for each individual storm in the IBTrACS and model datasets. As expected, hexagons with the most observed genesis points are located off the west coast of Africa, throughout the main development region (MDR), and also over the Caribbean and Gulf of Mexico. In contrast to observations, nearly all genesis in the FSU COAPS model occurs over the south-central portion of the basin, well west of Africa and east of the Caribbean and Gulf of Mexico. In fact, the highest per-hexagon genesis count for the FSU COAPS model is 50 storms, significantly higher than the maxima of 13 and 15 for observations and the GFDL, respectively. Very few storms generated by the FSU COAPS model form over the Gulf of Mexico or Caribbean. The distribution of genesis points from the GFDL HiRAM more closely matches observations; however, there is still a noticeable lack of model genesis over the Gulf of Mexico and Caribbean by this model as well. For the GFDL HiRAM, the small number of modeled TCs developing over the Gulf of Mexico and Caribbean may be a result of large model wind shear anomalies, although another possible cause is the general lack of simulated convective activity over this region. This is also true of the FSU COAPS model, which generates higher than observed wind shear over the Gulf of Mexico for the August-October period. The FSU COAPS model also displays a dry precipitation bias in this region. In addition to the underprediction over the Gulf of Mexico and Caribbean, the area of overprediction by the FSU COAPS model is evident in the red and magenta hexagons of Fig. 7. It is also interesting to note that the area of GFDL HiRAM overprediction extends farther north and east across the basin. Although Fig. 7 provides a qualitative assessment of model over-and/or underprediction, the magnitude of the model discrepancy is not apparent. FIG. 7. Hexagons indicate subregions in which there was overprediction by both the FSU and GFDL models (red), overprediction by the FSU model and underprediction by the GFDL (magenta), underprediction by the FSU model and overprediction by the GFDL (cyan), or underprediction by both models (blue). FIG. 8. Per-hexagon counts of genesis points for (a) observations, (b) FSU COAPS, and (c) GFDL HiRAM. ''Genesis'' is defined as the first record for each storm listed in the IBTrACS and model datasets. The darkest shading represents genesis counts greater than 15."}, {"section_title": "Summary", "text": "GCMs are now routinely employed to study how TC frequency may change with a warmer climate. However, before confidence can be placed in future cyclone scenarios, it is necessary to understand how well they reproduce the historical spatial climatology. Using a methodology based on the spatial tessellation of Elsner et al. (2012), this study puts forward a spatial lattice approach to quantitatively compare regional TC activity. Global and regional comparisons are made between actual and simulated TC occurrences using actual TCs from the IBTrACS dataset and GCM-generated TCs from the GFDL HiRAM and FSU COAPS models over the common period 1982-2008. Globally results show that although there are some areas of over-and underprediction, the spatial distribution of TCs generated by the GFDL HiRAM compare well with observations. Difference maps using the spatial lattice highlight the areas in which the model disagrees with observations. The primary mismatch areas are found in the Pacific. Several quantitative metrics of model success are used to examine the ability of the GFDL HiRAM to accurately capture the spatial extent of TC tracks globally and regionally. Again, the model performs fairly well overall, with the primary problem area being the South Atlantic. Additionally, comparisons focusing on the North Atlantic basin are made using both models. Results confirm a large area of overprediction by the FSU COAPS model over the south-central portion of the basin, and a large area of underprediction by both models over the Gulf of Mexico and Caribbean. The underprediction is particularly relevant to projections of future U.S. hurricane activity. As the data become publicly available, this method can be applied to provide a comprehensive model comparison using all model datasets from phase 5 of the Coupled Model Intercomparison Project (CMIP5). All the code used to generate the results of this paper is available online (http://rpubs.com/sestrazz/4591)."}]