[{"section_title": "Abstract", "text": "Effective and accurate diagnosis of Alzheimer's disease (AD), as well as its prodromal stage (i.e., mild cognitive impairment (MCI)), has attracted more and more attentions recently. So far, multiple biomarkers have been shown sensitive to the diagnosis of AD and MCI, i.e., structural MR imaging (MRI) for brain atrophy measurement, functional imaging (e.g., FDG-PET) for hypometabolism quantification, and cerebrospinal fluid (CSF) for quantification of specific proteins. However, most existing research focuses on only a single modality of biomarkers for diagnosis of AD and MCI, although recent studies have shown that different biomarkers may provide complementary information for diagnosis of AD and MCI. In this paper, we propose to combine three modalities of biomarkers, i.e., MRI, FDG-PET, and CSF biomarkers, to discriminate between AD (or MCI) and healthy controls, using a kernel combination method. Specifically, ADNI baseline MRI, FDG-PET, and CSF data from 51 AD patients, 99 MCI patients (including 43 MCI converters who had converted to AD within 18 months and 56 MCI nonconverters who had not converted to AD within 18 months), and 52 healthy controls are used for development and validation of our proposed multimodal classification method. In particular, for each MR or FDG-PET image, 93 volumetric features are extracted from the 93 regions of interest (ROIs), 1 Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (www.loni.ucla.edu/ADNI). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: www.loni.ucla.edu\\ADNI\\Collaboration\\ADNI_Authorship _ list.pdf.\n2 automatically labeled by an atlas warping algorithm. For CSF biomarkers, their original values are directly used as features. Then, a linear support vector machine (SVM) is adopted to evaluate the classification accuracy, using a 10-fold cross-validation. As a result, for classifying AD from healthy controls, we achieve a classification accuracy of 93.2% (with a sensitivity of 93% and a specificity of 93.3%) when combining all three modalities of biomarkers, and only 86.5% when using even the best individual modality of biomarkers. Similarly, for classifying MCI from healthy controls, we achieve a classification accuracy of 76.4% (with a sensitivity of 81.8% and a specificity of 66%) for our combined method, and only 72% even using the best individual modality of biomarkers. Further analysis on MCI sensitivity of our combined method indicates that 91.5% of MCI converters and 73.4% of MCI nonconverters are correctly classified. Moreover, we also evaluate the classification performance when employing a feature selection method to select the most discriminative MR and FDG-PET features. Again, our combined method shows considerably better performance, compared to the case of using an individual modality of biomarkers."}, {"section_title": "Introduction", "text": "Alzheimer's disease (AD) is the most common form of dementia in elderly people worldwide. It is reported that the number of affected people is expected to double in the next 20 years, and 1 in 85 people will be affected by 2050 (Ron et al., 2007) . Thus, accurate diagnosis of AD, especially for its early stage also known as amnestic mild cognitive impairment (MCI), is very important. It is known that AD is related to the structural atrophy, pathological amyloid depositions, and metabolic alterations in the brain Nestor et al., 2004) . At present, several modalities of biomarkers have been proved to be sensitive to AD and MCI, including the brain atrophy measured in magnetic resonance (MR) imaging (de Leon et al., 2007; Du et al., 2007; Fjell et al., 2010; McEvoy et al., 2009) , hypometabolism measured by functional imaging (De Santi et al., 2001; Morris et al., 2001) , and quantification of specific proteins measured through CSF (Bouwman et al., 2007b; Fjell et al., 2010; Mattsson et al., 2009; Shaw et al., 2009 ).\nHowever, most existing pattern classification methods just use one individual modality of biomarkers for diagnosis of AD or MCI, which may affect the overall classification performance. For example, many high-dimensional classification methods use only the structural MRI brain images for classification"}, {"section_title": "A C C E P T E D M A N U S C R I P T ACCEPTED MANUSCRIPT", "text": "3 between AD (or MCI) and healthy controls (Cuingnet et al., 2010; Fan et al., 2008a; Fan et al., 2007; Gerardin et al., 2009; Kloppel et al., 2008; Lao et al., 2004; Magnin et al., 2009; Misra et al., 2009; Oliveira et al., 2010; Westman et al., 2010) . Also, according to the features being extracted from the structural MRI, the existing classification methods can be roughly divided into three categories, using 1)\nvoxel-wise tissue probability (Fan et al., 2007; Kloppel et al., 2008; Lao et al., 2004; Magnin et al., 2009) ,\n2) cortical thickness (Desikan et al., 2009; Lerch et al., 2008; Oliveira et al., 2010; Querbes et al., 2009) , and 3) hippocampal volumes (Gerardin et al., 2009; West et al., 2004) . It was found that most effective features for AD or MCI classification are actually extracted from the atrophic regions, i.e., hippocampus, entorhinal cortex, parahippocampal gyrus, and cingulated, which are consistent with previous findings using group comparison methods (Chetelat et al., 2002; Convit et al., 2000; Fox and Schott, 2004; Jack et al., 1999; Misra et al., 2009 ). In addition to structural MRI, another important modality of biomarkers for AD or MCI detection is fluorodeoxyglucose positron emission tomography (FDG-PET) (Chetelat et al., 2003; Foster et al., 2007; Higdon et al., 2004) . With FDG-PET, some recent studies have reported the reduction of glucose metabolism in parietal, posterior cingulated, and temporal brain regions for AD patients (Diehl et al., 2004; Drzezga et al., 2003) . Besides these neuroimaging techniques, there are also some biological or genetic biomarkers developed for diagnosis of AD or MCI. For example, researchers have found 1) the increased CSF total tau (t-tau) and tau hyperphosphorylated at threonine 181 (p-tau) are related to the neurofibrillary tangle pathology, 2) the decreased amyloid \u03b2 (A\u03b2 42 ) indicates amyloid plaque pathology, and 3) the presence of the apolipoprotein E (APOE) \u03b54 allele can predict cognitive decline or conversion to AD (Bouwman et al., 2007b; de Leon et al., 2007; Fjell et al., 2010; Ji et al., 2001 ).\nActually, different biomarkers provide complementary information, which may be useful for diagnosis of AD or MCI when used together (Apostolova et al., 2010; de Leon et al., 2007; Fjell et al., 2010; Foster et al., 2007; Landau et al., 2010; Walhovd et al., 2010b) . It was reported that FDG-PET and MRI measures are differentially sensitive to memory in health and disease (Walhovd et al., 2010b) . A recent study also\nshows that the morphometric changes in AD and MCI are related to CSF biomarkers, but can also provide complementary information to CSF biomarkers (Fjell et al., 2010) . A more recent study has compared the respective prognostic ability of genetic, CSF, neuroimaging, and cognitive measures obtained in the same participants, indicating that there exists complementary information among these biomarkers which may aid in the future diagnosis of AD and MCI (Landau et al., 2010) . Inspired by these findings, a few studies have used two or more biomarkers simultaneously for detection of AD and MCI, i.e., using MRI and CSF in (Bouwman et al., 2007a; Vemuri et al., 2009) , MRI and cognitive testing in (Geroldi et al., 2006;  M A N U S C R I P T ACCEPTED MANUSCRIPT 4 Visser et al., 2002) , FDG-PET and CSF in (Fellgiebel et al., 2007) , FDG-PET and cognitive testing in (Chetelat et al., 2005) , and MRI, CSF, and FDG-PET in (Walhovd et al., 2010a) .\nAlthough the use of multiple biomarkers yields promising results, the above methods may be limited.\nFirst, only a few manually selected brain regions are generally considered for MRI and PET based classification of AD or MCI. However, the structural and functional features measured from a limited set of pre-defined regions may be not able to reflect the spatial-temporal pattern of structural and physiological abnormalities in their entirety (Fan et al., 2008b) . Second, most above methods are primarily designed to characterize group differences, not for individual classification. Although there exist some methods combining two modalities of biomarkers for individual classification, i.e., using both MRI and PET (Fan et al., 2008b; Hinrichs et al., 2009a; Hinrichs et al., 2009b; Ye et al., 2008) , both MRI and CSF (Davatzikos et al., 2010) , or both MRI and APOE biomarkers (Ye et al., 2008) , there is still few method that combines all three modalities of biomarkers (MRI, PET, and CSF) for classification, which we will show the benefit of combining all three biomarkers for AD or MCI diagnosis in this paper.\nSpecifically, we will combine the measurements from all three biomarkers, i.e., MRI, PET, and CSF, to discriminate between AD and healthy controls, or between MCI and healthy controls. To effectively combine three different biomarkers for classification, we use a simple-while-effective multiple-kernel combination method. This method can be naturally embedded into the conventional SVM classifier without extra steps. Our experimental results show that the combination of different measurements from MRI, PET, and CSF demonstrates much better performance in AD or MCI classification, compared to the case of using even the best individual modality of biomarkers.\n12 and 4 also show that, for AD classification, the differences among accuracy, sensitivity, and specificity are small, while, for MCI classification, it tends to have a higher sensitivity but lower specificity.\n\n14 combination method for AD study (Hinrichs et al., 2009b; Ye et al., 2008) . Specifically, in (Ye et al., 2008) , MRI and APOE data as well as the age and sex information were combined using the existing multiple-kernel learning method. In (Hinrichs et al., 2009b) , MRI and PET data were combined also using the same multiple-kernel learning method. However, both studies aimed only for AD classification, while in this paper we studied for both AD classification and MCI classification. The latter is actually more important than the former for early detection and treatment of AD. More importantly, we combine not only MRI and PET, but also CSF, which was rarely investigated before in the multiple-kernel combination study. Our experimental result shows that each modality (MRI, PET, and CSF) is indispensable for achieving good combination and classification. Also, we use more advanced feature extraction method with atlas warping, compared to those in (Hinrichs et al., 2009b; Ye et al., 2008) . Thus, we can achieve much better performance compared to those reported in (Hinrichs et al., 2009b; Ye et al., 2008) . Even for their new method using baseline MRI, PET, CSF, and additional longitudinal MRI and PET data, biological measures, and cognitive scores (Hinrichs et al., 2010) , its performance is still inferior to our method using only baseline MRI, PET and CSF, as shown in Table 3 .\n15 from different modalities. Then, for a new testing sample, each of these models will have a predication on it, and finally we aggregate all predictions to get the final decision on the new testing sample. This technique is also called ensemble learning, which has been a very popular learning method for decades in the machine learning community (Tan and Gilbert, 2003) .\nWe have compared our kernel combination method with the ensemble learning method for AD (or MCI) classification. Specifically, the ensemble learning method trains 3 SVM classifiers from MRI, PET, and CSF, respectively; and then the majority voting is used to get the final class labels for each new testing sample. The ensemble learning method obtains a classification accuracy of 91.8% for AD classification, and an accuracy of 75.6% for MCI classification, which are slightly inferior to the corresponding classification numbers achieved by our kernel combination method. These results indicate the effectiveness of the ensemble learning method as a useful and general way in improving classification accuracy of individual modalities. It may be even more interesting to investigate adding the mixed kernel from kernel combination into the ensemble or just ensembling different mixed kernels with different weights. However, the full investigation on this topic is beyond the focus of this paper. On the other hand, it is worth noting the disadvantage of the ensemble learning, i.e., the difficulty in interpreting the model since multiple models are used in the ensemble learning. This issue may limit its use in some medical applications where in addition to the accuracy, interpretability is also concerned and important.\n16 among the top-ranked eleven features selected (according to SVM weights) for MCI classification on MRI modality, six features, namely, 'amygdala right', 'hippocampal formation left', 'hippocampal formation right', 'entorhinal cortex left', 'temporal pole left', and 'parahippocampal gyrus left', are identical to those selected by the t-test statistics as shown in Table 4 . Notice that these six brain regions are known to be related to AD and MCI by many studies in the literature (Chetelat et al., 2002; Convit et al., 2000; Fox and Schott, 2004; Jack et al., 1999; Misra et al., 2009) .\n"}, {"section_title": "Methods", "text": "The data used in the preparation of this article were obtained from the Alzheimer's Disease Neuroimaging ADNI is the result of efforts of many coinvestigators from a broad range of academic institutions and private corporations, and subjects have been recruited from over 50 sites across the U.S. and Canada. The initial goal of ADNI was to recruit 800 adults, ages 55 to 90, to participate in the researchapproximately 200 cognitively normal older individuals to be followed for 3 years, 400 people with MCI to be followed for 3 years, and 200 people with early AD to be followed for 2 years (see www.adniinfo.org for up-to-date information). The research protocol was approved by each local institutional review board and written informed consent is obtained from each participant."}, {"section_title": "Subjects", "text": "The ADNI general eligibility criteria are described at www.adni-info.org. Briefly, subjects are between 55-90 years of age, having a study partner able to provide an independent evaluation of functioning.\nSpecific psychoactive medications will be excluded. General inclusion/exclusion criteria are as follows: 1) In this paper, only ADNI subjects with all corresponding MRI, CSF and PET baseline data are included.\nThis yields a total of 202 subjects including 51 AD patients, 99 MCI patients (43 MCI converters who had converted to AD within 18 months and 56 MCI non-converters who had not converted to AD within 18 months), and 52 healthy controls. Table 1 lists the demographics of all these subjects. Subject IDs are given in Supplemental Table 5 ."}, {"section_title": "MRI", "text": "All structural MR scans used in this paper were acquired from 1.5T scanners. Data were collected across a variety of scanners with protocols individualized for each scanner, as defined at www.loni.ucla.edu/ ADNI/Research/Cores/index.shtml. Briefly, raw Digital Imaging and Communications in Medicine "}, {"section_title": "Image analysis", "text": "Image pre-processing is performed for all MR and PET images. First, we do anterior commissure (AC) -posterior commissure (PC) correction on all images, and use the N3 algorithm (Sled et al., 1998) to correct the intensity inhomogeneity. Next, we do skull-stripping on structural MR images using both brain surface extractor (BSE) (Shattuck et al., 2001 ) and brain extraction tool (BET) (Smith, 2002) , followed by manual edition and intensity inhomogeneity correction. After removal of cerebellum, FAST in the FSL package (Zhang et al., 2001 ) is used to segment structural MR images into three different tissues: grey matter (GM), white matter (WM), and cerebrospinal fluid (CSF). After registration using HAMMER (Shen and Davatzikos, 2002) , we obtain the subject-labeled image based on a template with 93 manually labeled ROIs (Kabani et al., 1998) . For each of the 93 ROI regions in the labeled MR image, we compute the volume of GM tissue in that ROI region as a feature. For PET image, we first align it to its respective MR image of the same subject using a rigid transformation, and then compute the average intensity of each ROI region in the PET image as a feature. Therefore, for each subject, we totally obtain 93 features from MRI image, other 93 features from PET image, and 3 features from CSF biomarkers."}, {"section_title": "7", "text": ""}, {"section_title": "Multimodal data fusion and classification", "text": "A general framework based on kernel methods (Scholkopf and Smola, 2002) is presented here to combine multiple biomarkers (MRI, PET, and CSF) for discriminating between AD (or MCI) and healthy controls.\nThis kernel-based method can be easily embedded into the conventional SVM classifier for highdimensional pattern classification, without extra steps. Moreover, unlike other combining methods which can only process one type of data, i.e., numeric data type, our method can combine multiple types of data such as numeric data, string, and graph.\nBefore introducing the kernel combination method, we first briefly review the standard single-kernel SVM algorithm. The main idea of SVM is summarized as follows. First, the linearly nonseparable samples are mapped from their original space to a higher or even infinite dimensional feature space, where they are more likely to be linearly separable than in the original lower-dimensional space, through a kernel-induced implicit mapping function. Then, a maximum margin hyperplane is sought in the higherdimensional space.\nNow we will present the multiple-kernel SVM which can be used to integrate multiple modalities of biomarkers (i.e., MRI, PET and CSF) for individual classification of AD (or MCI) from healthy controls.\nSuppose that we are given n training samples and each of them is of M modalities. Let Multiple-kernel based SVM solves the following primal problem: Similarly as in the conventional SVM, the dual form of multiple-kernel SVM can be represented as below:\nis the kernel function for the two training samples on the m-th modality. The symbol n is the number of training samples.\nFor a new test sample\n, we first denote ( )\nas the kernel between the new test sample and each training sample on the m-th modality. Then, the decision function for the predicted label can be obtained as below:\nIt's easy to know that the multiple-kernel based SVM can be naturally embedded into the conventional\nas a mixed kernel between the multimodal training samples i x and j x , and ( ) x and the test sample x . In fact, our method can be viewed as a way for kernel combination which combines multiple kernels into one kernel.\nIt is worth noting that our formulation of multiple-kernel SVM is similar, but different from, the existing multi-kernel learning methods (Hinrichs et al., 2009b; Lanckriet et al., 2004; Wang et al., 2008) . One key difference is that we do not jointly optimize the weights m \u03b2 s together with other SVM parameters (e.g., \u03b1 ) in an iterative way. Instead, we constrain 1 m m \u03b2 = \u2211 and use a coarse-grid search through crossvalidation on the training samples to find the optimal values. After we obtain the values of m \u03b2 s, we use them to combine multiple kernels into a mixed kernel, and then perform the standard SVM using the mixed kernel. The main advantage of our method is that it can be conveniently solved using the conventional SVM solvers, e.g., LIBSVM (Chang and Lin, 2001 ).\nAs explained above, this kernel combination method can provide a convenient and effective way for fusing various data from different modalities. In our case, we focus on multimodal classification using\nthree modalities, i.e., MRI, PET, and CSF biomarkers. Figure 1 gives a schematic illustration of our multimodal data fusion and classification pipeline.\nA lot of studies have shown that biomarkers from different modalities may contain complementary information for diagnosis of AD (Apostolova et al., 2010; de Leon et al., 2007; Fjell et al., 2010; Foster et al., 2007; Landau et al., 2010; Walhovd et al., 2010b) . Recently, several works on combining different modalities of biomarkers have been reported (Bouwman et al., 2007a; Chetelat et al., 2005; Fan et al., 2008b; Fellgiebel et al., 2007; Geroldi et al., 2006; Vemuri et al., 2009; Visser et al., 2002; Walhovd et al., 2010a) . A common practice in these works is the concatenation of all features (from different modalities) into a longer feature vector. However, this may be not enough for effective combination of features from different modalities. In this paper, we provide an alternative way by using kernel combination to integrate different biomarkers. Compared with the direct feature concatenation method, the kernel combination method has the following advantages: 1) it provides a unified way to combine heterogeneous data when different type of data cannot be directly concatenated; 2) it offers more flexibility by using different weights on biomarkers of different modalities. For instance, we cannot directly concatenate data represented by strings or graphs with numeric data while we can possibly construct separate kernels for string, graphs and numeric data respectively and then fuse them by kernel combination. In our case, since MRI, PET, and CSF are different types of features, the kernel combination provides us a better way to integrate them for guiding the classification.\nIt's worth noting that the kernel combination method has been successfully applied to many other fields, i.e., protein function prediction (Lanckriet et al., 2004) , cancer diagnosis (Yu et al., 2010) , and gene prioritization (De Bie et al., 2007) . Recently, several researches have started to use this powerful kernel"}, {"section_title": "Validation", "text": "To evaluate the performance of different classification methods, we use 10-fold cross-validation strategy to compute the classification accuracy (for measuring the proportion of subjects correctly classified among the whole population), as well as the sensitivity (i.e., the proportion of AD or MCI patients correctly classified) and the specificity (i.e., the proportion of healthy controls correctly classified).\nSpecifically, the whole set of subject samples are equally partitioned into 10 subsets, and each time the subject samples within one subset are successively selected as the testing samples and all remaining subject samples in the other 9 subsets are used for training the multiple-kernel classifier. This process is repeated for 10 times independently to avoid any bias introduced by randomly partitioning dataset in the cross-validation. The SVM classifier is implemented using LIBSVM toolbox (Chang and Lin, 2001) , with a linear kernel and a default value for the parameter C (i.e., C=1). The weights in the multiple-kernel classification method are learned based on the training samples, through a grid search using the range from 0 to 1 at a step size of 0.1. Specifically, in each fold of the 10-fold cross-validation, we perform another 10-fold cross-validation on the training samples to determine the optimal values for the weights.\nAlso, for each feature i f in the training samples, a common feature normalization scheme is adopted, i.e., "}, {"section_title": "Results", "text": ""}, {"section_title": "Multimodal classification based on MRI, PET, and CSF", "text": "We first test the performance of our multimodal classification method in identification of AD (or MCI) from healthy controls, based on MRI, PET, and CSF biomarkers of 202 baseline subjects in ADNI. Table   2 shows the classification rate of our multimodal classification method, compared with the methods using each individual modality only. Note that Table 2 shows only the averaged results of 10 independent experiments, along with the minimal and maximal values given in brackets; and the detailed results can be found in the supplemental Figs. 8-9 for each experiment. Besides, Fig. 2 further plots the\ncorresponding ROC curves of different classification methods for AD or MCI, respectively. As we can see from Table 2 and Fig. 2 , the combined measurements of MRI, PET, and CSF consistently achieve more accurate discrimination between AD (or MCI) patients and healthy controls. Specifically, for classifying AD from healthy controls, our multimodal classification method can achieve a classification accuracy of 93.2%, a sensitivity of 93%, and a specificity of 93.3%, while the best accuracy on individual modality is only 86.5% (when using PET). On the other hand, for classifying MCI from healthy controls, our multimodal classification method achieve a classification accuracy of 76.4%, a sensitivity of 81.8%, and a specificity of 66%, while the best accuracy on individual modality is only 72% (when using MRI).\nIn addition, the area under the ROC curve (AUC) is 0.976 and 0.809 for AD classification and MCI classification respectively with our multimodal classification method (see Fig. 2 ), while the best AUC on individual modality is 0.938 (when using PET) for AD classification, and 0.762 (when using PET) for MCI classification.\nTable 2 also indicates that, for AD classification, there are little differences among accuracy, sensitivity, and specificity of each classification method (totally 5 methods examined), while for MCI classification the differences are relatively large, e.g., relatively large sensitivity, but low specificity, for each method.\nThis characteristic of possessing high sensitivity may be advantageous for diagnosis purpose, because the cost is different for misclassifying an MCI patient into a healthy control (with sensitivity reduced in this case) and misclassifying a healthy control into an MCI patient (with specificity reduced in this case), and the former cost is much higher than the latter. Inspired from this observation, we further divide the MCI cohort into MCI converters who converted to AD within 18 months and the MCI non-converters who had not convert to AD within 18 months, and then compute how many MCI converters and MCI nonconverters are correctly classified as MCI. The results with our multimodal classification method reveal that the 91.5% MCI converters and 73.4% MCI non-converters are correctly classified. It's worth noting that in practice the cost of misclassifying MCI converters is usually much higher than that of misclassifying MCI non-converters. Thus, this characteristic of possessing a higher classification rate for the MCI converters by our method is potentially very useful.\nFor comparison with other multimodal classification methods, we also perform the use of direct feature concatenation as a baseline method for multimodal AD (or MCI) classification. Specifically, for each subject, we first concatenate 93 features from MRI, 93 features from PET, and 3 features from CSF, into a 189 dimensional vector. Remember that each feature has been normalized to have zero mean and unit standard deviation. Then, we perform SVM-based classification on all samples with a 10-fold crossvalidation strategy as described above, and obtain the classification results in the bottom row of Table 2 .\nA C C E P T E D M A N U S C R I P T"}, {"section_title": "ACCEPTED MANUSCRIPT", "text": ""}, {"section_title": "11", "text": "As we can observe from Table 2 , our kernel combination method consistently outperforms the baseline method on each performance measure.\nFurthermore, in Table 3 we compared the proposed method with a recent method proposed in (Hinrichs et al., 2010) . The latter used 114 ADNI subjects (48AD+66HC) for AD classification, and it reported both results of using only imaging modalities (MRI+PET) and all modalities (MRI+PET+CSF+APOE+ Cognitive scores), as included in Table 3 . The proposed method uses a similar number of ADNI subjects,\ni.e., 103 subjects (51AD+52HC), with results given in Table 2 . For comparison, we also include the proposed method's results in Table 3 . As we can observe from Table 3 , the proposed method is superior to Hinrichs et al.'s method in case of using only imaging modality (MRI+PET) or all modalities (MRI+PET+CSF). It's worth noting that, in (Hinrichs et al., 2010) , both baseline and longitudinal data are used for MRI and PET modalities, while the proposed method uses only the baseline data. In the second case, even the additional APOE and cognitive scores were used in Hinrichs et al.'s method, our result is still better. These results further validate the efficacy of the proposed method for multimodal classification."}, {"section_title": "Comparison of different combination schemes", "text": "To investigate the effect of different combining weights, i.e., \u03b2 MRI , \u03b2 CSF , and \u03b2 PET , on the performance of "}, {"section_title": "Classification performance with respect to the number of selected ROI features", "text": "We have shown the effectiveness of our multiple-kernel combination method on using whole-brain ROI features (without feature selection) for AD or MCI classification. Here, we investigate how the performance of our multiple-kernel combination method changes with respect to the number of the selected ROI features. To this end, we first use a paired t-test, respectively, on MRI and PET data of training samples to choose the most discriminative brain regions or features for guiding AD or MCI classification (Gerardin et al., 2009 ). It's worth noting that the feature selection is performed using only the training samples, instead of all samples. Specifically, in each fold of the 10-fold cross-validations, we perform a t-test only on the training samples to select the most discriminative feature subset. Table 4 and Figs. 5-6, most of the selected top regions, e.g., hippocampal, amygdale, entorhinal cortex, uncus, temporal pole and parahippocampal regions, are known to be related to the AD by many studies using group comparison methods (Chetelat et al., 2002; Convit et al., 2000; Fox and Schott, 2004; Jack et al., 1999; Misra et al., 2009 ). For example, hippocampus is a structure highly related to the memory, which is always affected in the AD.\nThen, we test the classification performances of different methods with respect to the different number of brain regions selected for AD (or MCI) classification, with results shown in Fig. 7 . As we can see from For example, Fig. 7 shows that, even only one brain region is selected for MRI and PET images, our multimodal classification method can still achieve a reasonable classification accuracy, compared to the individual-modality based classification methods. Another interesting observation from Fig. 7 is that more brain regions are needed for achieving higher accuracy for MCI classification than AD classification.\nThis indicates that, with the progress of disease, more atrophies are produced in AD, thus a small number of brain regions with relatively large atrophies is sufficient for successful classification of AD."}, {"section_title": "13", "text": ""}, {"section_title": "Discussion", "text": "In this paper, we have proposed a new multimodal data fusion and classification method to automatically discriminate patients with AD (or MCI) from healthy controls, using a kernel combination method. This kernel combination method can be naturally embedded into the conventional SVM and solved efficiently.\nThe results on 202 baseline subjects from ADNI show that our multimodal classification method can consistently and substantially improve the classification performance of the individual-modality based classification methods. Specifically, our method can achieve a high accuracy (93.2%) for AD classification, a relatively high sensitivity (81.8%) for MCI classification, and especially a high sensitivity (91.5%) for classification of MCI converters."}, {"section_title": "Diversity of individual modalities in classification", "text": "As mentioned earlier, a lot of studies have indicated that different modalities contain complementary information for discrimination. Here, we quantitatively measure the discrimination similarity and diversity between any two different modalities, i.e., MRI vs CSF, MRI vs PET, and CSF vs PET, by comparing their individual classification results. Both Jaccard similarity coefficient and Kappa index are used to measure the similarities and diversities, respectively. Small values on both indexes imply a low similarity and a high diversity on the two modalities. For AD classification, the averaged similarities "}, {"section_title": "Data fusion vs ensemble", "text": "In this paper, we combine data from different modalities using kernel combination, which first combines multiple kernel matrices from different modalities into a single kernel matrix and then trains a single SVM model from the combined kernel matrix. Interestingly, we can also combine results from multiple modalities at classification stage. That is, we first train multiple SVM models on multiple kernel matrices"}, {"section_title": "Effect of feature selection", "text": "We test the kernel combination method on two cases, i.e. without and with feature selection. It is worth noting that the main concern of using feature selection in the current study is to validate the effectiveness of the kernel combination on the selected brain regions. Therefore, we adopt a simple feature selection method based on t-test statistics, which has been widely used in the neuroimaging analysis. Figure 7 shows that even a simple feature selection method can potentially select effective features (or regions) for achieving higher classification accuracy than the original methods using all features. We expect that the use of more advanced feature selection methods in the future can lead to further improvement for our multimodal classification.\nOn the other hand, in the current study we adopt a linear SVM as the classifier, which intrinsically uses a feature weighting mechanism, i.e., the absolute values of components in the normal vector of SVM's hyperplane can be regarded as weights on features (Kloppel et al., 2008) . In this way, we can rank the features according to their averaged SVM weights. We find that the top-ranked features are partially identical with those top features obtained from a separate feature selection method we used. For example,"}, {"section_title": "Limitations", "text": "While aiming to develop a multimodal diagnostic tool, the current study is limited by at least two factors.\nFirst, besides MRI, PET, and CSF, there are also other modalities of data, i.e., APOE. However, since not every subject has data on all modalities and the number of subjects with all modalities available is too small for reasonable classification, the current study does not consider APOE for multimodal classification. Second, in the current study, we investigate only the classification between one stage of dementia (either MCI or AD) and healthy controls, and do not test the ability of the classifier to simultaneously discriminate multiple stages of dementia, i.e., multi-class classification of AD, MCI, and healthy controls. Although the conversion from binary-class classification to multi-class classification seems straightforward, with many multi-class classification methods available (Duda et al., 2001) , there may be some problem and this will be our future work."}, {"section_title": "Conclusion", "text": "This study proposes a new multimodal data fusion and classification method based on kernel combination for AD and MCI. Compared with the conventional direct feature concatenation method, our method provides a unified way to combine heterogeneous data, particularly for the case where different types of data cannot be directly concatenated. Moreover, our method offers more flexibility by using different weights for different data modalities. The results on 202 baseline subjects of ADNI show that our multimodal classification method achieves a high accuracy for AD classification and an encouraging accuracy for MCI classification.\nThe current study only considers the baseline data of the subjects in ADNI. In the future, we will use both baseline and longitudinal data to predict the conversion from MCI to AD by finding the spatiotemporal pattern of brain atrophy in multiple modalities. Moreover, we will involve using more modalities of data (i.e., APOE) into our current multimodal classification method. To overcome the limitation of the possible small number of subjects available for training and testing classifier as discussed earlier, we will seek more advanced methods in machine learning which can use missing data for classification, i.e., semisupervised classification. We expect that, by using more samples (with both complete and missing modality information), the semi-supervised method will improve the classification performance further. Table 1 Subject information   Table 2 Comparison of performance of single-modal and multimodal classification methods. Table 3 Comparison of performance of different multimodal classification methods Table 4 Top 11 brain regions detected from MRI and PET modalities for MCI classification A C C E P T E D M A N U S C R I P T ACCEPTED MANUSCRIPT "}, {"section_title": "22", "text": ""}, {"section_title": "List of tables", "text": ""}, {"section_title": "Figure captions", "text": ""}]