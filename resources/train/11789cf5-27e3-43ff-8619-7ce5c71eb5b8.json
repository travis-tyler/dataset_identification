[{"section_title": "", "text": "The International Association for the Evaluation of Educational Achievement (IEA) is an independent nongovernmental nonprofit cooperative of national research institutions and governmental research agencies that originated in Hamburg, Germany in 1958. For over 60 years, IEA has developed and conducted high-quality, large-scale comparative studies in education to support countries' efforts to engage in national strategies for educational monitoring and improvement. IEA continues to promote capacity building and knowledge sharing to foster innovation and quality in education, proudly uniting more than 60 member institutions, with studies conducted in more than 100 countries worldwide. IEA's comprehensive data provide an unparalleled longitudinal resource for researchers, and this series of in-depth peer-reviewed thematic reports can be used to shed light on critical questions concerning educational policies and educational research. The goal is to encourage international dialogue focusing on policy matters and technical evaluation procedures. The resulting debate integrates powerful conceptual frameworks, comprehensive datasets and rigorous analysis, thus Foreword IEA's mission is to enhance knowledge about education systems worldwide, and to provide high-quality data that will support education reform and lead to better teaching and learning in schools. In pursuit of this aim, it conducts, and reports on, major studies of student achievement in literacy, mathematics, science, citizenship, and digital literacy. These studies, most notably TIMSS, PIRLS, ICCS, and ICILS, are well established and have set the benchmark for international comparative studies in education. The studies have generated vast datasets encompassing student achievement, disaggregated in a variety of ways, along with a wealth of contextual information which contains considerable explanatory power. The numerous reports that have emerged from them are a valuable contribution to the corpus of educational research. Valuable though these detailed reports are, IEA's goal of supporting education reform needs something more: deep understanding of education systems and the many factors that bear on student learning advances through in-depth analysis of the global datasets. IEA has long championed such analysis and facilitates scholars and policymakers in conducting secondary analysis of our datasets. So, we provide software such as the International Database Analyzer to encourage the analysis of our datasets, support numerous publications including a peer-reviewed journal-Large-scale Assessment in Education-dedicated to the science of large-scale assessment and publishing articles that draw on large-scale assessment databases, and organize a biennial international research conference to nurture exchanges between researchers working with IEA data. The IEA Research for Education series represents a further effort by IEA to capitalize on our unique datasets, so as to provide powerful information for policymakers and researchers. Each report focuses on a specific topic and is produced by a dedicated team of leading scholars on the theme in question. Teams are selected on the basis of an open call for tenders; there are two such calls a year. Tenders are subject to a thorough review process, as are the reports produced (Full details are available on the IEA website). This sixth volume in the series is concerned with teacher quality and educational outcomes. Regarded as the most vital school resource, teachers are key to understanding the \"black box\" of education. To that end, the current volume examines the v link between teacher effectiveness and student outcomes from several different perspectives. Especially important in this research is understanding whether better teachers can mitigate the known deleterious effect of low socioeconomic status. Literature on the links between social class and achievement abounds; however, questions remain concerning the role of the teacher and teaching quality in this relationship. To begin a study on the importance of teacher effectiveness, the authors draw on data collected over 20 years by the IEA's Trends in International Mathematics and Science Study (TIMSS). Although student outcomes, namely, achievement, figure prominently in this work, the authors use a wide array of contextual information to bring their narrative to life. Inputs, such as teacher experience, teachers' perceptions of their own levels of preparedness, and the degree to which the implemented curriculum is aligned to the educational system's curricular expectations, are modeled as explanations for system-level variation in achievement. The authors further examine whether there are stable patterns over time, educational system, and grade in the investigated relationships. As is the bane of much social science research, particularly the cross-cultural sort, revealing consistent patterns across dozens of heterogeneous countries over time is no mean feat. Rather, the authors found substantial variation in teacher characteristics, behavior, and perceptions, and in the way in which these variables relate to mathematics achievement. Here, the old adage about change being the only constant is appropriate. In spite of an absence of conclusive patterns, this book uses high-quality data to underscore an axiom of international research in education: the local context matters. To ignore this important result is to risk wasting time and effort at the expense of children. As the authors wisely note, \"Simple transference of policy ideas that have enjoyed apparent success in one educational system can yield unexpected (or even disastrous) consequences in another\" (Chap. 8). A key takeaway from this book is that international assessment databases, such as TIMSS, are rich resources for testing these sorts of theories and for understanding whether and when a successful policy initiative in one country can be expected to succeed in other contexts. A second conclusion worth repeating here is that, based on extensive analyses, teachers with similar backgrounds and experiences can be expected to produce different results in the classroom. Again, the local context matters. When teachers are assigned an undue share of responsibility, this shifts emphasis away from society at large and the role that we all play in ensuring high-quality education for the next generation. Future publications in this series will include a novel exploration of student profiles using variables related to motivation, affect, and attitudes about school mathematics, and an in-depth investigation into the nature and extent of students' misconceptions and misunderstandings related to core concepts in mathematics and physics across grades four, eight, and 12."}, {"section_title": "Seamus Hegarty Leslie Rutkowski", "text": "Series editors vi Foreword"}, {"section_title": "Introduction", "text": "While it has become commonplace to argue that high-quality teachers are essential to student learning, unfortunately, there is little clarity about the best means for improving teacher effectiveness, with major consequences for policymakers and researchers alike. Over the last several decades, education reformers have attempted to improve the capacity of the teacher labor force and the quality of instructional content, spawning a voluminous research literature in the process. However, the relationships between measures of teacher effectiveness and student outcomes, whether understood as mean achievement or equity, are inconsistent, and this, in 2 1 The Role of International Assessments in Understanding Teacher \u2026 turn, has raised serious questions about the best approach for achieving policy goals. In this sense, the ambiguity in the research literature has left policymakers with little direction as to the best approaches to reform. In addition, variation across countries in how various measures of teacher quality are related to student outcomes has made cross-country transfer of educational ideas difficult, since without understanding whether (or why) policies work differently in different national contexts, it is hard to know whether (or when) a particular policy should be adopted (Plucker 2014). The central aim of this report was to investigate what international comparative assessments can reveal about the role of teachers in influencing student outcomes. While the bulk of existing research from the United States suggests that teacher credentials have a limited impact on student achievement, it remains unclear whether this finding is more broadly applicable. If the limited impact of teacher credentials in the United States is due to the specifics of the country's teacher preparation system (or educational system more broadly) or statistical issues (for example, more limited variation in how teachers are educated), research would suggest that the United States should seek solutions in other countries. However, if the (weak) relationship holds across educational systems, then policymakers and researchers will have to determine whether formal teacher preparation is an effective lever for improving student outcomes.\nTo date, research into relationships between teacher characteristics and student outcomes has relied on data from only a few countries, or been restricted to analysis of data collected at single point in time, or both. Such limitations have made it difficult to draw general conclusions about whether particular measures of teacher quality (such as, instructional alignment) are systematically associated with higher learning gains, or whether any such gains are due to other factors or the unique circumstances of a given educational system. In this chapter, we take advantage of the measures of teacher quality within the TIMSS framework, and the extensive international data collected by TIMSS over 20 years, to investigate this problem more thoroughly, using a variety of statistical methods. Our aim was twofold: first, to identify whether given teacher-related metrics were generally related to student mean outcomes within and across countries; and second, whether these relationships were sensitive to the statistical method employed or a particular sample (namely, data collected from one cycle of TIMSS). This chapter can be considered to be an extended robustness check on the association between teacher quality and student mathematics performance, comparing particular results to different educational contexts (namely differing national education systems), different years, and different methodological choices. A secondary consideration was the challenge of balancing rigorous quantitative methods with the practical problems of dealing with large-scale datasets. Sophisticated multilevel models with very large sample sizes, such as would be necessary if incorporating all of the TIMSS countries in every cycle into one model, can be computationally quite demanding, even with modern computing power. More sophisticated methods would likely identify more precise and less biased estimates. This chapter presents an exploratory study, aiming to assess whether there were obvious patterns across time and space, preliminary to more detailed research. We begin by assessing how frequently the relationship between measures of teacher effectiveness and student outcomes were statistically significant across countries. As noted in Chap. 2, the existing research literature has failed to identify any consistent relationships between teacher characteristics (experience, education, teacher content knowledge) and student outcomes, but has indicated that student outcomes may be more strongly associated with teacher behaviors (content coverage and time on teaching mathematics). Thus, we aimed to determine whether this was a consistent finding across different educational systems, and how sensitive these findings were to the statistical method used. To do this, we compared the results of a \"full\" model, incorporating teacher-and student-level effects, with those from a model that ignored student clustering within classrooms and classroom-level means. Having considered the effect of the different statistical methods on our findings, we next investigated the stability of these associations across time. Although the country-level averages of teacher quality measures may vary over time, the direction and strength of relationship between teacher and student factors should be more consistent, assuming low measurement error, sufficiently sensitive and reliable instrumentation, and rough institutional stability in a particular educational system. We analyzed the stability of statistical estimates across time, first by comparing multilevel regression coefficients for a given country across multiple years of the TIMSS, and next by conducting a fixed-effect analysis using country-level means. Finally, we assessed the robustness of multilevel model results by comparing a simplified means of calculating standard errors with the more elaborate jackknifing procedure recommended by the various TIMSS user guides. All of the analyses in this chapter use a basic additive model in which student mean achievement in mathematics is predicted by six teacher variables (experience, preparedness, education, alignment, time spent on mathematics, and teacher gender) and three student control variables (books in the home, language spoken in the home, and student gender). The operationalization of these variables has already been discussed in Chap. 3. We applied this model to each education system participating in TIMSS for every cycle of participation, using standard jackknifed standard errors and five plausible values. Education systems that did not include one of the five main teacher variables (experience, education, preparedness, alignment, and time spent on mathematics) were excluded from the analysis. Each education system was analyzed separately by year and grade level. The analysis presented in the main text is summary data combining the results for multiple educational systems. (For detailed country-level results for each statistical model, please consult Appendix B.)\nIn this chapter, we address our second research question, namely what is the relationship between different types of teacher quality and instructional metrics and student achievement? Our study extends the work of , who analyzed the TIMSS 2011 grade four data to explore the relationship between teacher quality variables and student outcomes. The analysis undertaken by  incorporated similar constructs to those explored in Chap. 5 (teacher experience, self-efficacy, and educational preparation), and included receipt of professional development and teacher instructional practices. However,  identified only a modest relationship between instructional quality and student mathematics achievement, and their analysis was limited to grade four data. In this chapter, we explore the extent to which including opportunity to learn variables 64 6 Relationships Between Instructional Alignment, Time \u2026 (time spent on teaching mathematics and content coverage) mediate the influence of instructional quality, using both grade four and grade eight TIMSS data."}, {"section_title": "Linking Teaching Quality to Student Outcomes", "text": "Ever since its foundation in the late 1950s, the International Association for the Evaluation of Educational Achievement (IEA) has focused on providing high-quality impartial comparative data on student learning and contexts, aimed at enabling researchers and policymakers to unpack the \"black box\" of classroom instruction (Schmidt et al. 2018). Beginning with the original pilot study of 12 countries in the late 1960s, and continuing with the First International Mathematics Study (FIMS), the Second International Mathematics Study (SIMS), and the Trends in International Mathematics and Science Study (TIMSS), IEA sponsored studies have attempted to identify the key mechanisms of classroom instruction. Since 1995, successive cycles of TIMSS have collected extensive information about teacher background and practices across countries; such data can therefore potentially be used to address important questions about the role of teachers in influencing student outcomes, and is ideally suited to examining the relationship between teacher quality and student outcomes. The design of TIMSS renders it feasible to focus on the role of teachers. There are two major long-term large-scale international assessments of student mathematics: IEA's TIMSS, and the Programme of International Student Assessment (PISA) run by the Organisation for Economic Cooperation and Development (OECD). Both TIMSS and PISA randomly select a group of representative schools, but whereas the 1.2 Linking Teaching Quality to Student Outcomes 3 PISA study selects a group of 15-year-old students from within those schools without linking them to specific teachers, TIMSS selects intact classrooms and collects extensive information about teacher background and practice. As a consequence, TIMSS data provides a unique opportunity to examine the impact of teachers on a representative sample of students in multiple countries across time. As TIMSS also tests students at two different grades (namely grades four and eight), it is also possible to examine the specific impacts of teacher characteristics and teaching practices on students at two different stages of their learning."}, {"section_title": "Conceptual Framework and Research Questions", "text": "In this study, we took advantage of the design of TIMSS to examine key teacher characteristics (experience, education, and preparedness to teach) and teacher behaviors (instructional time and instructional content) and assessed how these were related to student outcomes using data collected for both grade four and grade eight during the multiple past cycles of TIMSS. We used national curriculum data collected by the TIMSS assessments to assess the relationship between teacher instruction and national curricular standards (e.g., instructional alignment) and educational outcomes. We also focused on the distributional impact of curriculum and instruction on students, with attention paid to overall and socioeconomic status based inequality at the student and country level. We explored the evolution of these associations over time using multiple methods, including regression, fixed effect, and structural equation modeling. We also paid close attention to the methodological complexities involved with using TIMSS data and their impact in examining the relationships between teacher measures and student outcomes. Our primary focus was student learning in mathematics. Although international assessments have also examined reading and science achievement, the research literature on the role of instructional content is much better grounded for mathematics, and hence presents a better example of the impact of schools and teachers on student outcomes because learning of mathematics takes place principally inside the classroom. Whereas students may be well exposed to reading, the use of language, or basic scientific concepts outside school, they tend to have much more limited exposure to mathematical concepts before they enter school (Sparks 2017). We examine teacher effectiveness along multiple dimensions, including both traditional measures (teacher experience and teacher education) and more infrequently employed indicators (instructional time and content, and preparedness to teach). Although others have examined the contribution of these elements to student achievement, to our knowledge, there has been no previous research into the joint effects of these factors using a multi-year, multi-country model. The research outlined in this report is therefore novel in assessing the robustness of these relationships across countries treating each iteration of the TIMSS as a separate sample, thereby testing the replicability and reproducibility of analyses based on only one year of data. Our approach also enabled us to examine whether the significant cross-country variation in some of the observed associations (especially the relationships of teacher experience and teacher education with achievement) was more consistent within countries. Examining trends provides a means to evaluate the success of an education system in strengthening teacher quality, improving coherence, and reducing inequality. This report builds on an initial valuable exploration of these topics undertaken by , in which TIMSS trend data was used to demonstrate considerable national-level curriculum reform (leading to greater instructional coherence), strengthened teacher preparation requirements, a reduction in standard deviations in student performance, but little change in the amount of time devoted to teacher professional development or to mathematics instruction. The conceptual model that we used in this report builds on the work of , who applied a structural equation modeling approach to the TIMSS 2011 data, analyzing each country separately. Their model included teacher observable characteristics (years of experience, college major, and specialization), professional development (participation in broad mathematics instruction professional development, specific mathematics instruction professional development, and collaborative professional development), and teacher preparedness (using preparedness to teach numbers, geometry, and data indices) as direct predictors of student achievement. The relationship of these predictors with student outcomes are mediated by instructional quality, operationalized as a latent variable derived from clarity of instruction, supportive climate, and cognitive activation indicators.  also controlled for student gender and books in the home in their analysis. While our model is based on the Blomeke model, we incorporated several additional components.  noted a weak relationship between instructional quality and student outcomes. As it stands, the Blomeke model addresses the \"how\" without the \"what;\" the weak relationships they observed may be explained by the absence of measures of instructional content (what teachers are teaching) and of how long they spent on this task. Given the strong research base on the effects of opportunity to learn and instructional time on student learning (see Chap. 2), we believed that including such factors as additional mediating variables would influence the estimates of instructional quality and greatly strengthen the model as a whole. We thus also explored the relationship between teacher characteristics, and content coverage and instructional time, which despite obvious plausibility has received little attention in the research literature. Bearing all these considerations in mind, we developed four key questions to guide our research: (1) Are there identifiable trends in teacher quality and instructional metrics over time? (2) What are the relationships between student achievement and different types of teacher quality and instructional metrics? 1.3 Conceptual Framework and Research Questions"}, {"section_title": "5", "text": "(3) How stable are these relationships across time and statistical method? (4) What are the relationships between student equity and teacher quality and instructional metrics? In this report, we aim to address each of these questions in turn. We begin by reviewing the existing research literature on teacher effectiveness in Chap. 2. Next, in Chap. 3, we focus on the variables we used for our analyses and consider some of the methodological issues involved. Turning to our research questions, in Chap. 4, we present descriptive statistics for teacher quality and instructional metrics, establishing changes over time and potential trends in the education-system-level means reported in the TIMSS data. In Chap. 5, we further analyze multiple cycles of the data using ordinary least squares regression, multilevel, and fixed-effect models, while paying close attention to the stability of estimates across time and according to each of the different statistical methods, concentrating on the relationship between teacher quality variables and student outcomes. Expanding on this analysis, in Chap. 6 we present a multilevel structural equation model using TIMSS 2011 data that extends the earlier work of . In Chap. 7, we shift our focus to our final research question regarding issues of educational equity, examining the associations between teacher characteristics and behaviors and differences among students, rather than average outcomes. Finally, we conclude in Chap. 8 with a discussion of the overall research findings, implications for policymakers and researchers, a review of potential limitations of the work, and suggestions for future research. 8 2 A Review of the Literature on Teacher Effectiveness \u2026 results. Chetty et al. (2014) found that students taught by highly effective teachers, as defined by the student growth percentile (SGPs) and value-added measures (VAMs), were more likely to attend college, earn more, live in higher-income neighborhoods, save more money for retirement, and were less likely to have children during their teenage years. This potential of a highly effective teacher to significantly enhance the lives of their students makes it essential that researchers and policymakers properly understand the factors that contribute to a teacher's effectiveness. However, as we will discuss in more detail later in this report, studies have found mixed results regarding the relationships between specific teacher characteristics and student achievement (Wayne and Youngs 2003). In this chapter, we explore these findings, focusing on the three main categories of teacher effectiveness identified and examined in the research literature: namely, teacher experience, teacher knowledge, and teacher behavior. Here we emphasize that much of the existing body of research is based on studies from the United States, and so the applicability of such national research to other contexts remains open to discussion."}, {"section_title": "Teacher Experience", "text": "Teacher experience refers to the number of years that a teacher has worked as a classroom teacher. Many studies show a positive relationship between teacher experiences and student achievement (Wayne and Youngs 2003). For example, using data from 4000 teachers in North Carolina, researchers found that teacher experience was positively related to student achievement in both reading and mathematics (Clotfelter et al. 2006). Rice (2003) found that the relationship between teacher experience and student achievement was most pronounced for students at the secondary level. Additional work in schools in the United States by Wiswall (2013), Papay and Kraft (2015), and Ladd and Sorenson (2017), and a Dutch twin study by Gerritsen et al. (2014), also indicated that teacher experience had a cumulative effect on student outcomes. Meanwhile, other studies have failed to identify consistent and statistically significant associations between student achievement and teacher experience Gustaffsson and Nilson 2016;Hanushek and Luque 2003;Luschei and Chudgar 2011;Wilson and Floden 2003). Some research from the United States has indicated that experience matters very much early on in a teacher's career, but that, in later years, there were little to no additional gains (Boyd et al. 2006;Rivkin et al. 2005;Staiger and Rockoff 2010). In the first few years of a teacher's career, accruing more years of experience seems to be more strongly related to student achievement (Rice 2003). Rockoff (2004) found that, when comparing teacher effectiveness (understood as value-added) to student test scores in reading and mathematics, teacher experience was positively related to student mathematics achievement; however, such positive relationships leveled off after teachers had gained two years of teaching experience. Drawing on data collected from teachers of grades four to eight between 2000 and 2008 within a large urban school district in the United States, Papay and Kraft (2015) confirmed previous research on the benefits experience can add to a novice teacher's career. They found that student outcomes 2.2 Teacher Experience 9 increased most rapidly during their teachers' first few years of employment. They also found some further student gains due to additional years of teaching experience beyond the first five years. The research of Pil and Leana (2009) adds additional nuance; they found that acquiring teacher experience at the same grade level over a number of years, not just teacher experience in general (i.e. at multiple grades), was positively related to student achievement.\n"}, {"section_title": "Teacher Professional Knowledge", "text": "A teacher's professional knowledge refers to their subject-matter knowledge, curricular knowledge, and pedagogical knowledge (Collinson 1999). This professional knowledge is influenced by the undergraduate degrees earned by a teacher, the college attended, graduate studies undertaken, and opportunities to engage with on-the job training, commonly referred to as professional development (Collinson 1999;Rice 2003;Wayne and Youngs 2003). After undertaking in-depth quantitative analyses of the United States' 1993-1994 Schools andStaffing Survey (SASS) and National Assessment of Educational Progress (NAEP) data sets, Darling-Hammond (2000) argued that measures of teacher preparation and certification were by far the strongest correlates of student achievement in reading and mathematics, after controlling for student poverty levels and language status. As with experience, research on the impact of teacher advanced degrees, subject specializations, and certification has been inconclusive, with several studies (Aaronson et al. 2007;Hanushek and Luque 2003;Harris and Sass 2011;Luschei and Chudgar 2011) suggesting weak, inconsistent, or non-significant relationships with student achievement. However, several international studies comparing country means found that teacher degrees (Akiba et al. 2007;Gustaffsson and Nilson 2016;Montt 2011) were related to student outcomes, as did Woessman's (2003) student-level study of multiple countries."}, {"section_title": "Undergraduate Education", "text": "In their meta-analysis of teacher effectiveness, Wayne and Youngs (2003) found three studies that showed some relationship between the quality of the undergraduate institution that a teacher attended and their future students' success in standardized tests. In a thorough review of the research on teacher effectiveness attributes, Rice (2003) found that the selectivity of undergraduate institution and the teacher preparation program may be related to student achievement for students at the high school level and for high-poverty students. In terms of teacher preparation programs, Boyd et al. (2009) found that overall these programs varied in their effectiveness. In their study of 31 teacher preparation programs designed to prepare teachers for the New York City School District, Boyd et al. (2009) drew from data based on document analyses, interviews, surveys of teacher preparation instructors, surveys of participants and graduates, and student value-added scores. They found that if a program was effective in preparing teachers to teach one subject, it tended to also have success in preparing teachers to teach other subjects as well. They also found that teacher preparation programs that focused on the practice of teaching and the classroom, and provided opportunities for teachers to study classroom practices, tended to prepare more effective teachers. Finally, they found that programs that included some sort of final project element (such as a personal research paper, or portfolio presentation) tended to prepare more effective teachers. Beyond the institution a teacher attends, the coursework they choose to take within that program may also be related to their future students' achievement. These associations vary by subject matter. A study by Rice (2003) indicated that, for teachers teaching at the secondary level, subject-specific coursework had a greater impact on their future students' achievement. Similarly Goe (2007) found that, for mathematics, an increase in the amount of coursework undertaken by a trainee teacher was positively related to their future students' achievement. By contrast, the meta-analysis completed by Wayne and Youngs (2003) found that, for history and English teachers, there was no evidence of a relationship between a teacher's undergraduate coursework and their future students' achievement in those subjects."}, {"section_title": "Graduate Education", "text": "In a review of 14 studies, Wilson and Floden (2003) were unable to identify consistent relationships between a teacher's level of education and their students' achievement. Similarly, in their review of data from 4000 teachers in North Carolina, Clotfelter et al. (2006) found that teachers who held a master's degree were associated with lower student achievement. However, specifically in terms of mathematics instruction, teachers with higher degrees and who undertook more coursework during their education seem to be positively related to their students' mathematics achievement (Goe 2007). Likewise, Harris and Sass (2011) found that there was a positive relationship between teachers who had obtained an advanced degree during their teaching career and their students' achievement in middle school mathematics. They did not find any significant relationships between advanced degrees and student achievement in any other subject area. Further, using data from the United States' Early Childhood Longitudinal Study (ECLS-K), Phillips (2010) found that subject-specific graduate degrees in elementary or early-childhood education were positively related to students' reading achievement gains. "}, {"section_title": "Certification Status", "text": "Another possible indicator of teacher effectiveness could be whether or not a teacher holds a teaching certificate. Much of this research has focused on the United States, which uses a variety of certification approaches, with lower grades usually having multi-subject general certifications and higher grades requiring certification in specific subjects. Wayne and Youngs (2003) found no clear relationship between US teachers' certification status and their students' achievement, with the exception of the subject area of mathematics, where students tended have higher test scores when their teachers had a standard mathematics certification. Rice (2003) also found that US teacher certification was related to high school mathematics achievement, and also found that there was some evidence of a relationship between certification status and student achievement in lower grades. Meanwhile, in their study of grade one students, Palardy and Rumberger (2008) also found evidence that students made greater gains in reading ability when taught by fully certified teachers. In a longitudinal study using data from teachers teaching grades four and five and their students in the Houston School District in Texas, Darling-Hammond et al. (2005) found that those teachers who had completed training that resulted in a recognized teaching certificate were more effective that those who had no dedicated teaching qualifications. The study results suggested that teachers without recognized US certification or with non-standard certifications generally had negative effects on student achievement after controlling for student characteristics and prior achievement, as well as the teacher's experience and degrees. The effects of teacher certification on student achievement were generally much stronger than the effects for teacher experience. Conversely, analyzing data from the ECLS-K, Phillips (2010) found that grade one students tended to have lower mathematics achievement gains when they had teachers with standard certification. In sum, the literature the influence of teacher certification remains deeply ambiguous."}, {"section_title": "Professional Development", "text": "Although work by Desimone et al. (2002Desimone et al. ( , 2013 suggested that professional development may influence the quality of instruction, most researchers found that teachers' professional development experiences showed only limited associations with their effectiveness, although middle-and high-school mathematics teachers who undertook more content-focused training may be the exception Harris and Sass 2011). In their meta-analysis of the effects of professional development on student achievement, Blank and De Las Alas (2009) found that 16 studies reported significant and positive relationships between professional development and student achievement. For mathematics, the average effect size of studies using a pre-post assessment design was 0.21 standard deviations. Analyzing the data from six data sets, two from the Beginning Teacher Preparation Survey conducted in Connecticut and Tennessee, and four from the United States National Center for Education Statistics' National Assessment of Educational Progress (NAEP), Wallace (2009) used structural equation modeling to find that professional development had a very small, but occasionally statistically significant effect on student achievement. She found, for example, that for NAEP mathematics data from the year 2000, 1.2 additional hours of professional development per year were related to an increase in average student scores of 0.62 points, and for reading, an additional 1.1 h of professional development were related to an average increase in student scores of 0.24 points. Overall, Wallace (2009) identified professional development had moderate effects on teacher practice and some small effects on student achievement when mediated by teacher practice.\nWe considered three aspects of teachers' participation in professional development. The first was professional development in mathematics (PDM), which measured whether a teacher participated in professional development activities associated with mathematics content, pedagogy/instruction, and curriculum. For each activity, participation was coded as 1, and no participation was coded as 0. The average score for the three activities was used to indicate a teacher's level of participation in professional development for mathematics teaching. The second aspect was professional development in mathematics instruction (PDS), which measured whether a teacher participated in professional development activities associated with integrating information technology into mathematics, mathematics assessment, and addressing individual students' needs. Each activity was scored as before. The average score for these three activities was used to indicate a teacher's participation in mathematics instruction professional development. The third aspect was professional development in collaboration (COL), assessed using five items: (1) \"I am content with my profession as a teacher\", (2) \"I am satisfied with being a teacher at this school\", (3) \"I had more enthusiasm when I began teaching than I have now\", (4) \"I do important work as a teacher\", and (5) \"I plan to continue as a teacher for as long as I can\". Response options were \"agree a lot\", \"agree a little\", \"disagree a little\", and \"disagree a lot\"; they were coded as 1, 2/3, 1/3, and 0, respectively. The average score of these five activities was used to indicate a teacher's participation in professional development in collaboration. Consistency coefficients (i.e., Cronbach's alpha) varied across countries, being between 0.36 and 0.63 for grade four mathematics teachers, and between 0.21 and 0.64 for grade eight mathematics teachers. The low internal consistency coefficients may suggest that the three aspects of professional development do not measure similar constructs."}, {"section_title": "Teacher Content Knowledge", "text": "Of course, characteristics like experience and education may be imperfect proxies for teacher content knowledge; unfortunately, content knowledge is difficult to assess directly. However, there is a growing body of work suggesting that teacher content knowledge may associated with student learning. It should be noted that there is an important distinction between general content knowledge about a subject (CK) and pedagogical content knowledge (PCK) specifically related to teaching that subject, each of which may be independently related to student outcomes (Baumert et al. 2010). Studies from the United States (see for example, Chingos and Peterson 2011;Clotfelter et al. 2006;Constantine et al. 2009;Hill et al. 2005;Shuls and Trivitt 2015) have found some evidence that higher teacher cognitive skills in mathematics are associated with higher student scores. Positive associations between teacher content knowledge and student outcomes were also found in studies based in Germany (Baumert et al. 2010) and Peru (Metzler and Woessman 2012), and in a comparative study using Programme for the International Assessment of Adult Competencies (PIAAC) data undertaken by Hanushek et al. (2018). These findings are not universal, however, other studies from the United States (Blazar 2015; Garet et al. 2016;Rockoff et al. 2011) failed to find a statistically significant association between teacher content knowledge and student learning. The studies we have discussed all used some direct measure of teacher content knowledge. An alternative method of assessing mathematics teacher content knowledge is self-reported teacher preparation to teach mathematics topics. Both TIMSS andIEA's Teacher Education andDevelopment Study in Mathematics (TEDS-M, conducted in 2007-2008) have included many questions, asking teachers to report on their preparedness to teach particular topics. Although Luschei and Chudgar (2011) and Gustafsson and Nilson (2016) found that these items had a 2.3 Teacher Professional Knowledge 13 weak direct relationship to student achievement across countries, other studies have suggested that readiness is related to instructional quality , as well as content knowledge and content preparation (Schmidt et al. 2017), suggesting that instructional quality may have an indirect effect on student learning."}, {"section_title": "Teacher Behaviors and Opportunity to Learn", "text": "Although the impact of teacher characteristics (experience, education, and preparedness to teach) on student outcomes remains an open question, there is much a much more consistent relationship between student achievement and teacher behaviors (instructional time and instructional content), especially behaviors related instructional content. Analyzing TIMSS, Schmidt et al. (2001) found an association between classroom opportunity to learn (OTL), interpreted narrowly as student exposure to instructional content, and student achievement. In a later study using student-level PISA data,  identified a robust relationship between OTL and mathematics literacy across 62 different educational systems. The importance of instructional content has been recognized by national policymakers, and has helped motivate standards-based reform in an effort to improve student achievement, such as the Common Core in the United States (Common Core Standards Initiative 2018). However, we found that there was little research on whether teacher instructional content that aligned with national standards had improved student learning; the only study that we were able to identify found that such alignment had only very weak associations with student mathematics scores (Polikoff and Porter 2014). Student-reported data indicates that instructional time (understood as classroom time on a particular subject) does seem to be related to mathematics achievement (Cattaneo et al. 2016;Lavy 2015;Rivkin and Schiman 2015;Woessman 2003)."}, {"section_title": "Conclusion", "text": "This review of the literature simply brushes the surface of the exceptional body of work on the relationship between student achievement and teacher characteristics and behaviors. Whether analyzing US-based, international, or the (limited) number of comparative studies, the associations between easily measurable teacher characteristics, like experience and education, and student outcomes in mathematics, remains debatable. In contrast, there is more evidence to support the impact of teacher behaviors, such as instructional content and time on task, on student achievement. Our goal was to incorporate all these factors into a comparative model across countries, with the aim of determining what an international cross-national study like TIMSS could reveal about the influence of teachers on student outcomes in mathematics. The analysis that follows draws on the existing body of literature on teacher effectiveness, which identified key teacher factors that may be associated with higher student achievement: teacher experience, teacher professional knowledge (measured by education and self-reported preparation to teach mathematics), and teacher provision of opportunity to learn (time on mathematics and content coverage)."}, {"section_title": "The TIMSS Dataset", "text": "All of the analyses in this report make use of IEA's Trends in International Mathematics and Science Study (TIMSS) data, merging several distinct instruments: student assessments, teacher background surveys, and national background surveys. The design of TIMSS uses a stratified random sampling to select a representative sample of schools at each grade level of the study, and then to sample intact classrooms within those schools. Separate surveys are conducted at grades four and eight. Since the first cycle of TIMSS in 1995, there have been four subsequent iterations at both grades four and eight (in 2003, 2007, 2011, 2015), as well as an additional survey at grade eight undertaken in 1999. The design of TIMSS has a number of important implications for researchers. First, despite continuing over time, the TIMSS is not a true longitudinal sample, but rather a series of cross-sectional studies. Because TIMSS does not sample the same group of students, teachers, or schools across time, many of the most common identification strategies employed by researchers to account for unobserved variables and other biases are not available. All of the relationships between variables should therefore be treated as suggested associations rather than strictly causal. To cope with this limitation, we adopted a multi-model analytical strategy to test for the robustness of statistical results. The aim was to improve confidence in the reliability of analyses by examining the stability of relationships across time, across different aggregations of data, and using different statistical procedures. These approaches are discussed in more detail in later chapters. Second, many features of TIMSS have changed considerably over time. Some of the key variables of interest, such as teacher preparedness to teach mathematics topics, or the mathematics topics expected to be taught according to the national research coordinators, were not included in earlier cycles of TIMSS. The list of topics included in TIMSS has also changed considerably since 1995. For example, although the literature suggests that receipt of professional development could be related to student outcomes (see for example Blank and De Las Alas 2009), the variation in how this construct is incorporated in different cycles of TIMSS is too diverse (in our judgment) to permit its consideration as a variable in multi-year statistical models. 1 Similarly, participating educational systems differ from one cycle of TIMSS to another; they may be present in one cycle of TIMSS but not in another, or may only participate at grade four but not at grade eight. Such variations greatly restrict the available sample when analyzing education-system-level trends (whether means or regression coefficients). For example, Germany did not take part at grade four in 2003, and only participated at grade eight in 1995. Thirdly, the complex sampling design of TIMSS has important implications for statistical modeling and analysis. Because typically only one intact classroom is selected in a given school, it is very difficult to distinguish classroom-from 3.1 The TIMSS Dataset 21 school-level effects. Therefore, for analytical purposes, we ignored school-level effects in our models. Multilevel and classroom-mean models treat each classroom as existing independently, rather than being clustered within schools. Given the acknowledged impact of schools, and the importance of within-school between-classroom heterogeneity, this amounts to an important qualification to any conclusions drawn from our analysis . Readers should understand that TIMSS samples a random population of classrooms meant to reflect an entire education system's population, rather than a straightforward random sample of all students or teachers. As such, strictly speaking, the associations explored in this study should be interpreted as reflecting representative classrooms, rather than all of an educational system's teachers and students. The complex sampling design, which stratifies within blocks of schools, giving different weights to different schools (and hence classrooms), means that standard calculation of standard errors (and hence statistical significance) is inadvisable. Instead, TIMSS requires a jackknifing procedure, which produces more accurate standard error estimates but at the cost of much greater computational burdens (especially for multilevel models). It also introduces problems with subdividing types of classrooms, as we discuss in Chap. 7. The educational systems examined in our analyses are usually referred to as \"countries.\" This is for ease of reading, but it should be noted that there are a number of systems that are not countries as such, but are units with a degree of educational autonomy that have participated in TIMSS following the same standards for sampling and testing. A final word of caution about the analyses in forthcoming chapters. Cross-country comparisons of teacher characteristics and behaviors inevitably raise questions about the consistency of these concepts across different cultural contexts. This is a particular problem for survey results, since along with difficulties in translation, there may be problems related to culturally-specific interpretations; these are some of the inevitable challenges encountered when conducting comparative research."}, {"section_title": "Operationalization of Variables", "text": "The variables in this study are drawn from the TIMSS database (see https://www. iea.nl/data). Additional details can be found in the TIMSS 2015 user guide (Foy 2017) and other TIMSS user guides and technical reports (https://timssandpirls.bc. edu/isc/publications.html). The first three variables that we included in the various statistical models are student control variables that have been associated with student outcomes and/or different learning opportunities, which means that excluding them could result in spurious relationships between teacher quality and student outcomes. These are: student gender, number of books in the home (a common proxy measure of socioeconomic status reflecting both parental education and parental income), and whether the student speaks the language of the test at home . The remaining variables are teacher variables that the research literature and policymakers have to varying degrees treated as measures of teacher effectiveness (as we have already discussed in Chap. 2): namely, education, experience, content knowledge, time on mathematics, and instructional content. We also incorporated an additional teacher-level variable that was included in all iterations of TIMSS, which is teacher gender."}, {"section_title": "Student Gender (Stmale)", "text": "The student gender variable (Stmale) denotes the gender of each student as indicated by the student on the TIMSS survey. Student gender is a dichotomous variable and is captured by the question: \"Are you a girl or boy?\" Higher values indicate a male student. Student gender is included for both grades four and eight for each cycle of TIMSS included in this study (2003, 2007, 2011, and 2015 "}, {"section_title": "Student Language (Lang)", "text": "The student language variable (Lang) denotes the language of each student, as indicated by the frequency of using the language of the test at home. Student language is captured by the question: \"How often do you speak [ (2003, 2007, 2011, and 2015)."}, {"section_title": "Student Estimated Number of Books in the Home (Books)", "text": "The number of books in the home (Books) variable denotes the number range of books, not including magazines, newspapers, or school books, in each student's home as estimated by the student. The variable is captured by the question: \"About how many books are there in your home? (Do not count magazines, newspapers, or your school books.)\" The question has five response categories: (1) None or very few (0-10 books); (2) Enough to fill one shelf (11-25 books); (3) Enough to fill one bookcase (26-100 books); (4) Enough to fill two bookcases (101-200 books); (5) Enough to fill three or more bookcases (more than 200). As part of the TIMSS survey, each of the response categories included an explanatory illustration displaying how each category would likely look. The Books variable is included for both grades four and eight for each cycle of TIMSS included in this study (2003, 2007, 2011, and 2015)."}, {"section_title": "Teacher Experience (Exp)", "text": "The teacher experience (Exp) variable denotes the total number of years the respondent reported teaching. Teacher experience is captured by the question: By the end of this school year, how many years will you have been teaching altogether? This is an open response question, and the years are reported in whole numbers. Teacher experience is included for both grades four and eight for each cycle of TIMSS included in this study (2003, 2007, 2011, and 2015). In our analyses, this variable is left as a simple linear variable in an effort to explore the general impact of teacher experience. However, as noted in Chap. 2, additional study should consider a non-linear relationship and/or distinguish early career teachers."}, {"section_title": "Teacher Gender (Tmale)", "text": "The teacher gender (Tmale) variable denotes the gender of each teacher as indicated by the teacher on the TIMSS survey. Teacher gender is a dichotomous variable and is captured by the question: \"Are you female or male?\" Teacher gender is included for both grades four and eight for each cycle of TIMSS included in this study (2003, 2007, 2011, and 2015). Higher values indicate male teachers. The TIMSS survey coded \"2\" as male and \"1\" and female. For the purposes of this work, the variable has been recoded as \"1\" for male teachers and \"0\" for female teachers."}, {"section_title": "Teacher Feelings of Preparedness (Prepared)", "text": "Teacher feelings of preparedness (Prepared) is an index of teacher reported self-efficacy to teach mathematics. TIMSS includes a series of questions asking teachers the degree to which they feel prepared to teach various mathematics topics. These topics vary across the various cycles of TIMSS, following the structure of topics in that year's mathematics framework for that grade level. For each topic, teachers are asked \"How well prepared do you feel you are to teach the following mathematics topics?\" and can respond on a four-point scale: not applicable (1), very well prepared (2), somewhat prepared (3), and not well prepared (4). For the purposes of this study, we recoded these responses so that 4 = very well prepared, 3 = somewhat prepared, 2 = not very well prepared, and 1 = not applicable. We then averaged the responses across mathematics topics."}, {"section_title": "Teacher Preparation to Teach Mathematics (Mathprep)", "text": "The Mathprep variable denotes mathematics teacher preparation by indicating teachers who majored in a combination of education and mathematics during their post-secondary studies. Mathprep is included for both grades four and eight for each cycle of TIMSS for which component variables of the index were available (2003, 2007, 2011, and 2015). Mathprep was included in the 2011 and 2015 TIMSS cycles, but had to be derived from the 2003 and 2007 data. The TIMSS 2015 user guide for the international database (Foy 2017;Supplement 3, p. 11 for grade four and p. 32 for grade eight) provides detailed information about how to create the variable Mathprep (called ATDM05 at grade four and BTDM05 at grade eight in Foy 2017). Following the coding scheme in the user guide (Foy 2017), the Mathprep variables for the 2003 and 2007 cycles were created similarly using \"if then\" statements to combine two variables for each grade level. For grade four, the first variable denoted the respondent's post-secondary major or main area of study, categorized as: education = primary/elementary, education = secondary, mathematics, science, language of test, and other. The second variable denoted whether the respondent specialized in mathematics. For grade eight, the first variable denoted whether the respondent majored in mathematics during their post-secondary education. The second variable denoted whether the respondent majored in education with a mathematics specialty during their post-secondary education. The \"if then\" statements helped indicate 2003 and 2007 TIMSS respondents who majored in a combination of education and mathematics during their post-secondary studies. There are nuanced differences between the creation of Mathprep for grade four and grade eight because of differences in credentials required to teach mathematics in primary and secondary education. Grade four teachers often have a post-secondary major of primary/elementary education, whereas grade eight teachers often have a post-secondary major in their discipline of interest (such as mathematics). The new variable resulted in five categories for grade four: (1) Respondent did not have formal education beyond upper-secondary; (2) Respondent majored in something other than primary education and/or mathematics; (3) Respondent majored in mathematics but did not major in primary education; (4) Respondent majored in primary education but did not major or specialize in mathematics; and (5) Respondent majored in primary education and majored or specialized in mathematics. Similarly, Mathprep resulted in five categories for grade eight: (1) Respondent did not have formal education beyond upper-secondary; (2) Respondent majored in something other than mathematics and/or mathematics education; (3) Respondent majored in mathematics education but did not major in mathematics; (4) Respondent majored in mathematics but did not major in mathematics education; and (5) Respondent majored in mathematics and mathematics education. After creating the Mathprep variable for 2003 and 2007, the 2011 and  2015 Mathprep variable was reverse coded to match the numeric schema for  Mathprep in 2003 and 2007. This also allowed for those who majored in primary education/mathematics education and also majored in mathematics to be associated with the highest value (5)."}, {"section_title": "Time Spent on Teaching Mathematics (Mathtime)", "text": "The Mathtime variable denotes the amount of time in minutes the respondent reported teaching mathematics to their given class. Mathtime is included for grades four and eight for all years in which the variable was available (2003, 2007, 2011, and 2015). Mathtime was included in TIMSS for years 2003, 2007, and 2015, but in 2011, for both grades four and eight, the Mathtime variable was captured by two variables: one reporting hours (ATBM01A) and the other reporting minutes (ATBM01B). To have consistency across years, we converted the \"hours\" variable into minutes by multiplying it by sixty. Then, we added the now-converted \"hours\" variable to the \"minutes\" variable, resulting in one measure of time spent on teaching mathematics as measured by minutes. This conversion was necessary to have a consistent measure of time spent on teaching mathematics across grade levels and years."}, {"section_title": "Teacher Curricular Alignment (Alignment)", "text": "This variable is an index measuring the degree to which teachers are instructing students in the topics that are intended to be taught at that grade level according to national curricular expectations. The variable was therefore constructed by combining data from two surveys: the TIMSS teacher background survey and the related national background survey. TIMSS teacher respondents were presented with a list of mathematics topics related to the topics contained in the TIMSS framework for that cycle, and asked to mark whether the topic was: (1) mostly taught before this year, (2) mostly taught this year, or (3) not yet taught or just introduced. These responses were then recoded so that \"mostly taught\" is coded as \"1\" and the other two responses as zeros. Next, national and/or provincial administrative leaders in education systems participating in the TIMSS were presented with an identical list of topics and asked to respond at what grade level that topic should be taught by teachers. These responses were recoded as \"1\" for \"0\", with \"1\" indicating that the topic should be taught at the relevant grade level (grades four and eight). The entire matrix of topics in that grade level was then compared with teacher responses. Cells were coded as \"1\" if a given teacher followed national curricular expectations, in other words, if they did teach a topic that should be taught, or did not teach a topic that shouldn't be taught. By contrast, a failure to match with national curricular expectations about a particular topic earned a coding of \"0.\" The percentage of alignment was then calculated, with 1 indicating perfect alignment and 0 indicating perfect non-alignment."}, {"section_title": "Methods", "text": "As mentioned previously, the chapters that follow use a variety of statistical methods, reflecting the study's purposefully multi-model approach. The analytic strategies are discussed briefly here, and are addressed in more detail in the appropriate chapters. Unless mentioned specifically, all analyses employ the procedure for generating jackknifed standard errors and (when considering student outcomes) the calculation and combination of all plausible values, as outlined in the various TIMSS technical reports (see https://timssandpirls.bc.edu/isc/publications.html) and the IEA Database Analyzer (see https://www.iea.nl/data). Chapter 4 presents international averages of country-level means (including participating sub-units) for the predictors used throughout the remaining chapters, including teacher experience, teacher preparedness, teacher education (preparation to teach mathematics), teacher time spent on mathematics, and teacher curricular alignment. Variable means are calculated for each educational system participating in each cycle of TIMSS, and confidence intervals are used to identify statistically significant differences for the same country in different iterations of TIMSS. Chapter 5 presents a number of statistical methods that we used to examine the relationship between teacher characteristics and behaviors and student outcomes. We used a multi-model approach to test the degree to which relationships remained robust across countries, within countries, and across different periods, and we assessed the stability of estimates using different statistical techniques. As a first step, we compared the results for (1) single-level linear regressions (ignoring classroom-level clusters) of individual student outcomes as predicted by teacher variables; (2) two-level linear regression models that cluster students within classrooms using SAS PROC MIXED maximum likelihood statistical software (Singer 1998); and (3) a single-level linear regression of classroom means of student variables with teacher variables. The comparison of these analyses enables the frequency of statistically significant associations between purported measures of teacher effectiveness and student achievement in mathematics to be determined. Additional analyses in Chap. 5 include an examination of the stability of multilevel model regression coefficients within each country across the different cycles of TIMSS, and an exploratory fixed effects regression analysis of changes in country-level means. Whereas the models in Chap. 5 treat each of the teacher-level variables as independent variables, Chap. 6 introduces a model that uses teacher behaviors (time on mathematics and alignment with national curriculum standards) as mediating variables for instructional quality. We used a structural equation modeling (SEM) approach to analyzing the results for each country in a single cycle of TIMSS (namely 2011), permitting the inclusion of additional variables like teacher professional 3.3 Methods 27 development to estimate a latent construct of \"instructional quality.\" A multilevel model clustering students within classrooms using jackknifed standard errors and five plausible values was applied to each educational system. Comparison of the results in Chaps. 5 and 6 demonstrates that a wide range of statistical techniques can be used to assess whether there are temporally and cross-nationally robust associations between measures of teacher effectiveness and student achievement in mathematics. Chapter 7 departs from the focus on mean student outcomes to consider the distributional effects of teacher effectiveness. First within-country equity was measured by standard deviation of pooled country-level student achievement. Country-level fixed effect analysis was used to assess the relationship between teacher effectiveness measures and student variation (measured by standard deviations). Second, the relationship between within-classroom variation in student outcomes and teacher quality was analyzed using averaged classroom-level single-level linear regressions. Finally, differences in teacher effectiveness between higher (top quartile) and low (bottom quartile) SES classrooms, as measured by using the average number of books in the home as a proxy for SES, were examined using Welch's t-tests (which are not sensitive to sample size). This last analysis used an alternative to the jackknifed standard error approach (designed for the entire sample of classrooms) because it examined a sub-sample that is vulnerable to Type I error."}, {"section_title": "Conclusions", "text": "In the research presented in this volume, we use a number of teacher-and student-level variables and empirical approaches to examine the relationship between measures of teacher effectiveness and student outcomes. It should be emphasized that issues with cross-national comparability and the lack of truly representative student and teacher samples imposes some limits on these variables and statistical methods. International large-sample student-level longitudinal data, such as TIMSS, lacks some of the teacher measures now commonly used in the US-based studies, making comparisons with existing research difficult. A number of potentially important control variables (not to mention a means of distinguishing school effects from teacher effects) are unavailable in TIMSS. As a consequence, it is very difficult to construct more robust causal estimates of teacher effects in multiple countries across time. The aim of this study was more modest: to use multiple statistical models to explore whether there is a consistent pattern between measures of teacher quality (both characteristics and behavior) and student outcomes across time and space, and assess whether the ambiguous findings of US-based research were replicated on an international scale.\nWith respect to Research Question 1, \"Are there identifiable trends in teacher quality and instructional metrics over time?\", the results to this chapter indicate that while trends vary from country to country, a focus on a common pool of countries (Table 4.3) suggested substantial change in teacher quality metrics. Specifically, at both grades four and eight, there were broad-based increases in teacher education and teacher experience. There was also an increase in time spent on mathematics in grade four over the cycles of TIMSS that we investigated, and a smaller increase at grade eight. By contrast, teacher self-reported preparedness to teach mathematics has been largely stable since 2007. Alignment of instructional content with national expectations has also stayed at a relatively consistent level at grade four, but alignment has declined since 2003 at grade eight. The most striking finding of this chapter was the very modest degree of alignment between teacher instructional content and national expectations of content coverage in mathematics. Among those educational systems reporting alignment in all four TIMSS cycles that we investigated, the international mean was only 0.55 at grade four and 0.60 at grade eight. At grade four, only two educational systems, Hong Kong and Korea, exhibited instructional alignment \u226570% over the last four cycles of TIMSS. High alignment rates were much more common at grade eight. It was further quite surprising to find that the United States, which has no official national curriculum, scored relatively highly for alignment. Overall, the results suggest that, in many countries, teachers (especially grade four teachers) maintain substantial discretion in what to teach, a conclusion bolstered by the similarly strong variation 4.11 Conclusions 45 in time spent on mathematics. Compared with the much more stable teacher characteristics (experience, feelings of preparedness, and level of formal education) reported in this chapter, the reported variability in teacher behaviors related to opportunity to learn demonstrates the importance of incorporating these factors into studies of effectiveness."}, {"section_title": "Empirical Approach", "text": "In this chapter we present descriptive results for educational systems (or \"countries\") participating all waves of the TIMSS between 1995 and 2015, with additional attention paid to those countries that were part of the TIMSS in every cycle since 2003. The focus of this chapter is on student mathematics achievement and its relation to factors associated with teacher quality, which we assess using both teacher characteristics (experience, self-efficacy, formal preparation, gender) and teacher behaviors (time spent on teaching mathematics, content coverage); student characteristics (gender, socioeconomic status, language spoken in the home) are also considered. Our aim was to lay the foundations for the analyses in the later chapters, as well as identify general patterns in teacher quality across TIMSS countries. Education system (henceforth referred to as country) means were calculated using the IEA Database Analyzer (free to access at www.iea.nl/data), with standard errors generated using a jackknife procedure. Because the TIMSS sampling design recruits a sample of representative classrooms rather than a sample of representative teachers, mean teacher results for each country do not necessarily reflect those of all teachers in a given educational system. Further, teacher-level data are not straightforward means, with each teacher counted equally. Rather, following the TIMSS sampling design, teachers are weighted according to the representativeness of their classrooms, based on the stratified sampling frame in each participating country. In this descriptive analysis, we first examined all the data across cycles 1 and then by education system. In general, between country differences were observed exhaustively across all variables. Within country variation over time was explored to identify patterns and anomalies. Only countries with three or more years of data were included when examining trends within countries over time. To identify significant differences, confidence intervals were calculated for each country and year combination by using standard errors. In some instances, the data were examined across years only to determine if there were any significant changes over time generally. In this chapter, we report summary frequency distributions for country mean values for each year and grade level (complete results are provided in Appendix A, and should be consulted as source data in the discussion of patterns). Where we discuss general patterns, we first reference all participating countries in a given year, rather than the common set of countries that participated every year (see Table 4.1). Because this could introduce bias (given changes in country participation), we also report mean results from a more limited common pool of countries that participated in every cycle of TIMSS from 2003 to 2015 (see Table 4.2) For most variables, this comprises 18 education systems at grade four and 26 education systems at grade eight (see Table 4.3).     \n"}, {"section_title": "31", "text": ""}, {"section_title": "Curricular Alignment", "text": ""}, {"section_title": "Grade Four", "text": "The teacher curricular alignment variable (Alignment) responses indicate that alignment between a country's national expectations of topic coverage and actual instruction ranged between 0.34 and 0.72, where 0.00 reflects no alignment and 1.00 reflects perfect alignment between curriculum and instruction (see Appendix A). This wide range suggests there is variation in curriculum alignment across countries and years, but warrants further exploration. The mean curricular alignment was 0.54, suggesting that on average, teacher instruction was aligned with the national curriculum just over 50% of the time as an average for all TIMSS countries participating in the cycles from 2003 to 2015. For the subset of countries that participated in each year, the mean remained essentially constant (0.56 in both 2003 and 2015). Examining variation in curricular alignment within a country over time provides interesting distinctions between educational systems. In some countries, alignment remained relatively constant between cycles. For example, in England, curricular alignment was 0.58 in 2003, 0.55 in 2007, 0.57 in 2011, and 0.55 in 2015. The overlapping confidence intervals suggest these differences were not significantly different, providing evidence that curriculum alignment in England has remained steady since 2003. In other countries, alignment has changed across cycles. For example, curricular alignment in the United States was 0.68 in 2007, 0.56 in 2011, and 0.62 in 2015 (United States data were not available for this variable prior to 2007). 2 In this case, confidence intervals do not overlap for any cycle, indicating statistically significant differences in curricular alignment within the United States over the various cycles of TIMSS. Differences in curricular alignment within a country over time may be attributable to policy change, but further research would be needed to verify such strong conclusions. In the United States example, most states adopted the Common Core State Standards in the 2010-2011 school year (see http://www.corestandards.org/about-the-standards/development-process/), which may have contributed to the recorded decline in curricular alignment in 2011 (as states and teachers adjusted to the new standards).\nThe teacher preparation to teach mathematics (Mathprep) variable for grade four ranged from 1.00 to 4.93 (see Appendix A). This variable was measured by a five-point scale, where 1.00 corresponds with having no formal preparation to teach mathematics and 5.00 corresponds with having specialized preparation in both primary education and mathematics (namely that a given primary teacher would have been trained for content knowledge (CK), pedagogical content knowledge (PCK), and general pedagogical knowledge appropriate for grade four students). A mean value of 3.67 indicates that, on average, across all cycles and countries, teachers majored in primary education and/or mathematics but did not always have both qualifications. For the pool of 18 educational systems that participated in all four cycles of TIMSS from 2003 to 2015, the mean was 3.59 across years, rising steadily from 3.41 to 3.74. In general, values for teacher preparation to teach mathematics at grade four remained relatively consistent within countries throughout the testing years, with only slight variations within some countries. For example, Quebec's values for this variable were 3. 86, 3.89, 3.95, and 3.95 for the years 2003, 2007, 2011, and 2015, respectively. While these values slightly increased over the years, the differences were not significant, which suggests that there was little change in teacher preparation to teach mathematics at grade four in Quebec. Conversely, as an example an education system that showed significant changes in teacher preparation to teach mathematics at grade four, in Singapore the value went from 3.55 in 2003 to 4.18 in 2015. This significant difference indicates that teachers in Singapore have become better prepared to teach mathematics in grade four. Significant differences in teacher preparation to teach mathematics within countries, as in Singapore, may reflect policy changes that impacted teacher preparation, meriting further exploration. Notably, Italy had consistently low values for teacher preparation to teach mathematics in grade four, of <1.50 for all four cycles of TIMSS. At the opposite end of the spectrum, in the Netherlands, teacher preparation to teach mathematics values were >4.5 for three out of the four TIMSS cycles considered.\nThe large range (from 65.90 to 479.24 min) of teacher reported time spent on teaching mathematics as measured in minutes at grade four (Mathtime) suggests significant variation within counties over time (see Appendix A). For many countries there were differences in time spent on teaching mathematics across the different test cycles. For example, Australia's average teacher time on mathematics started at 260 min in 2003, remained steady in 2007 at 266 min, increased dramatically to 346 min in 2011, and finally decreased to 306 min in 2015. The changes in 2011 and 2015 were both significant, and may reflect the introduction of a national curriculum between 2008 and 2012. Similarly, time on mathematics in the United States started at 245 min in 2003, and subsequently increased to 289 min in 2007, 343 min in 2011, and 359 min in 2015. These increases were all statistically significant, with the largest jump occurring between 2007 and 2011. As mentioned earlier, this increase in the time teachers spent on teaching mathematics in the United States may be attributed to implementation of the Common Core State Standards. There was a general increase in time spent on mathematics in fourth grade among the pool of commonly participating countries (Table 4.3), rising from 242 min in 2003 to 264 min in 2015 (although this was a decrease from a high of 277 min in 2011). The wide within-country variation across years may suggest that time spent teaching mathematics in grade four is not often standardized. However, there were a handful of instances where teacher time on mathematics was consistent within countries over years, such as in Singapore where time spent on mathematics varied only between 325 and 329 min over five testing periods. Countries consistently at the lower end of the grade four time on mathematics spectrum included Chinese Taipei, Norway, and Sweden; countries consistently at the higher end of the grade four time on mathematics spectrum included Portugal, Canada (Quebec), Italy, and the United States Taken together, these findings suggest wide variations in time on mathematics in grade four.\nTeacher feelings of preparedness to teach mathematics (Prepared) were measured on a four-point scale, where higher values indicated teachers felt better prepared to teach mathematics. At grade four, teacher feelings of preparedness ranged from 2.07 to 3.88, with a mean value of 3.24 (see Appendix A). For those countries that participated in each cycle of TIMSS between 2003 and 2015 (Table 4.3), the mean was 3.16 (rising sharply between 2003 and 2007, but remaining stable afterwards). This mean value suggests that generally teachers feel well prepared to teach mathematics. Some recognizable patterns emerge when examining grade four teacher feelings of preparedness within countries over the different testing years. In many countries, the values associated with grade four teacher feelings of preparedness significantly increased between the 2003 and 2007 test cycles, and then remained steady for the remaining test cycles. For example, the grade four teacher feelings of preparedness in Norway were 2.61 in 2003, 3.69 in 2007, 3.51 in 2011, and 3.78 in 2015. Similar increases between 2003 were seen in several other countries, such as Australia, Belgium (Flemish), Canada (Ontario), Canada (Quebec), Hungary, Italy, Morocco, and the United States. This indicates some change around teacher feelings of preparedness occurred between 2003 and 2007. One possible explanation is that TIMSS does not ask about the same mathematics topics in every cycle; there are cycle-to-cycle alterations to the TIMSS framework that mean that the same topics are not asked every time. It is thus possible that differences in mean teacher responses could be partly attributable to the survey instrument rather than the underlying construct.\nThe teacher experience variable captures the total number of years the teacher has been teaching (Exp). At grade four, teacher experience ranged from 7.63 to 27.64 years, with a mean reported value of 16.29 years (see Appendix A). The comparable mean for the restricted sample of eighteen countries was 16.79 years, rising from 15.92 years in 2003 to 17.65 years in 2015, suggesting an increase in teacher experience over time. When looking at teacher experience within countries over years, there were some countries where the amount of reported teacher experience was consistent and some countries that showed significant variation in reported teacher experience. Teacher experience in the United States was fairly consistent, hovering between a mean of 13 and 14 years of experience across the test cycles from 2003 to 2015. However, the 2015 mean value of 13.13 years was significantly lower than the other values. This slight decrease in mean years of teacher experience may coincide with the economic crisis the United States experienced in the late 2000s. During this time, many older teachers opted for retirement options, and this would have systematically driven down mean teacher experience as measured in years. Conversely, mean grade four teacher experience appeared quite variable in Ontario, Canada. While the values for Ontario were similar in 2003 and 2007 (13.11 and 13.15 years, respectively), mean teacher experience dropped to 11.52 years in 2011 and then substantially increased to 14.99 years in 2015. Further research is required to better understand such significant variations. The education systems that consistently reported the lowest number of years of teacher experience at grade four included Kuwait and Singapore; both reported multiple values \u226410 years. Those that consistently reported the highest number of years of teacher experience at grade four included Lithuania and Georgia; both reported multiple values >20 years.\nTeacher gender is a dichotomous variable; a response of 0.00 denotes the teacher is female and a response of 1.00 denotes the teacher is male (Tmale). For grade four, the teacher gender variable ranged between 0.00 and 0.80, with a mean of 0.21 (see Appendix A). This mean value is quite informative because an average close to 0.00 indicates teachers tend to be female, a mean of 0.50 indicates male and female teachers are equally represented, and a mean close to 1.00 indicates teachers tend to be male. The grade four mean of 0.21 (0.20 for the restricted sample), which holds over time, indicates that TIMSS respondents were more likely to be female. In general, teaching tends to be a female-dominated profession in many countries (especially at earlier grades), so these results are not surprising. Between-country findings yielded interesting results related to grade four teacher gender. Most countries' means for this variable were closer to 0.00 across test cycles, indicating that teachers in each of the countries tended to be female. However, a few countries had results that suggested teacher representation was more gender balanced. Denmark, for example, reported teacher gender values of 0.51 in 2007, 0.42 in 2011, and 0.47 in 2015. In Denmark there are almost equal numbers of male and female teachers, which may reflect Denmark's reputation for greater gender equity. In a few countries, the results indicated that teachers were more often male. In Yemen, for example, teacher gender values were 0.74 in 2003, 0.74 in 2007, and 0.78 in 2011; one explanation for this might be that the culture in Yemen supports a more male-dominated workforce, resulting in fewer female employees in general. In general, the within-country analysis uncovered little variation in grade four teacher gender across years. However, a few countries did see decreases in their teacher gender variable over time. For example, Morocco's values for grade four teacher gender were 0.64 in 2003, 0.50 in 2007, 0.50 in 2011, and 0.37 in 2015. The substantial change from 2003 to 2015 implies teachers were more likely to be males in 2003, but, by 2015, teachers were more likely to be female. One possible explanation for this shift is that, over time, it became more socially acceptable for females to hold teaching positions.\nAt grade four, student mathematics performance (Performance) in TIMSS ranged from a point score of 223 to 618, with a mean of 491 (see Appendix A). Examining the international mean over time suggests slight increases in overall performance over time. For example, at grade four, the overall mean student performance was 490 in 2003; by 2015, the mean had increased to 506. For our more restricted sample of countries, the international mean rose from 505 in 2003 to 527 in 2015. Cross-national comparison of grade four student performance within countries showed that some countries demonstrated considerably more variation than others, which may merit deeper investigation. For example, in Armenia, the mean grade four student performance was 455.92 in 2003, 499.51 in 2007, and 452.28 in 2011. These back and forth changes suggest a degree of instability in grade four student performance between test cycles in Armenia. Other countries with considerable variation included Qatar, Yemen, and Kuwait, to name a few. At the same time, Australia saw very little variation in their mean grade four student performance over time, with scores of 499 in 2003, 516 in 2007, 516 in 2011, and 517 in 2015. Other countries exhibiting similar consistency include Belgium (Flemish), New Zealand, and Italy. As has been widely noted in scholarly and popular publications, countries with the highest scores over time are largely located in East Asia, while countries with the lowest scores over time are largely located in West Asia and Africa. As such, geographical and cultural differences may play an important role in student achievement.  "}, {"section_title": "Grade Eight", "text": "In grade eight, there was a larger spread in the values associated with teacher curricular alignment than at grade four, which ranged from 0.25 to 0.88 (see Appendix A). Mean curricular alignment was slightly higher than that at grade four (0.59), meaning that, on average, instruction was aligned with the given national curriculum 59% of the time. For the countries that participated in every cycle of TIMSS from 2003 to 2015, the average curricular alignment declined from 0.66 to 0.58. Examining within country variation over time indicated that although some countries had constant curricular alignment over the years (i.e., Georgia), others showed gradual improvements in curricular alignment. For example, Australia's curricular alignment has steadily improved since 2003, with curricular alignment measuring 0.54 in 2003, 0.55 in 2007, 0.57 in 2011, and 0.59 in 2015; note that the difference between their curricular alignment in 2003 and 2011 was significant. More often than not, curricular alignment demonstrates a more random pattern of variation across cycles, alternating between increases and decreases. For example, in the United States, curricular alignment decreased in 2011 as it did at grade four; again this dip may be attributed to short-term policy changes, and the transition to the new Common Core State Standards. Japan showed the highest average degree of curricular alignment over time; alignment remained consistently above 80% in the 2003,2007,2011, and 2015 cycles of TIMSS.\nThe findings for teacher preparation to teach mathematics in grade eight were very similar to those for grade four, ranging between 1.00 and 4.89 with a mean of 3.69, which suggests that, on average, grade eight teachers majored in mathematics education and/or mathematics, but did not always have both qualifications (see Appendix A). Again, this TIMSS scale presumes that more exhaustive formal preparation in mathematics content and pedagogy indicates better preparation to teach mathematics. The mean for commonly participating countries (Table 4.3) was 3.60, increasing from 3.52 in 2003 to 3.79 in 2015. Throughout the testing years, there was more within country variation in teacher preparation to teach mathematics at grade eight than at grade four. Teacher preparation to teach mathematics in grade eight significantly increased between 2003 and 2015 in some countries (such as Quebec, Canada), and significantly decreased in others (for example, Saudi Arabia), or showed no consistent pattern (for example, England). The greater temporal within-country variation in teacher preparation to teach mathematics in grade eight points to possible between grade differences in teacher preparation requirements. For example, perhaps the requirements around teacher preparation to teach mathematics in grade four are more clearly defined than they are for grade eight. At grade eight, Morocco consistently had low values associated with teacher preparation to teach mathematics (three reporting years with values <2.00), while conversely, Romania had three reporting years with values >4.00. Interestingly, at both grades four and eight, the mean values associated with teacher preparation to teach mathematics increased over time. At grade four, the mean value for teacher preparation to teach mathematics was 3.53 in 2003 and 3.85 in 2015. Again, at grade eight, the mean value was 3.69 in 2003 and 3.88 in 2015. Similar results were found when trends were restricted to only those countries that participated in all four cycles of TIMSS between 2003 and 2015 (an increase of >0.3 for both grades). These increases may point to overall improved teacher preparation to teach mathematics at grades four and eight across countries. One possible explanation for this improvement is that teacher preparation became more of a policy priority over time, resulting in more stringent teacher preparation requirements.\nWhile the range (80.60-350.35 min) of teacher reported time spent on teaching mathematics as measured in minutes in grade eight was not quite as large as grade four, it was still large enough to warrant further exploration (see Appendix A). There was a weaker trend among commonly participating TIMSS countries (Table 4.3) between 2003 and 2015, with the average time spent on teaching mathematics increasing from 212 to 220 min, although, as with grade four, the largest averages were found in 2011. Examining within country variation provides a clearer story about how much time teachers spend teaching mathematics in grade eight. There was still variation in teacher time on mathematics in grade eight, but the variation was not as large as observed for grade four. Recall that Australia's average time on mathematics in grade four ranged from 260 to 346 min over four test cycles. For grade eight, Australia's time spent on teaching mathematics varied between 208 and 220 min over those same four test cycles. Similarly, in the United States, while there were still significant increases in grade eight time spent on mathematics over the test cycles, the increases were not as large as they were in grade four. For example, over four test cycles, the grade four time on mathematics in the United States varied from 245 to 359 min, a sweep of over 100 min; meanwhile, the grade eight time on mathematics in the United States over the same four test cycles ranged only between 226 and 265 min. These differing degrees of variation within countries for time on mathematics at grades four and eight may suggest there are widespread grade-level differences in how much time teachers spend on teaching mathematics. Countries consistently at the lower end of the grade eight time on mathematics spectrum included Cyprus, the Netherlands, Japan, and Sweden; countries consistently at the higher end of the grade eight time on mathematics spectrum included Lebanon, Canada (Ontario), Chile, and the United States.\nFor grade eight, there was a wider range for teacher feelings of preparedness than seen at grade four, with values from 1.06 to 3.91 and an overall mean value of 2.91 (see 4.5 Teacher Preparedness 39 Appendix A). The average of 2.91 may suggest that generally grade eight teachers felt adequately prepared to teach mathematics, but their feelings of preparedness are not as strong as those of the grade four teachers. However, when the pool of education systems was restricted to only those that participated in all cycles of TIMSS between 2003 and 2015, the international mean was 3.17, virtually indistinguishable from that reported for grade four teachers. As with grade four, the values associated with grade eight teacher feelings of preparedness significantly increased between the 2003 and 2007 test cycles, and then remained steady for the remaining test cycles. For example, the grade eight teacher feelings of preparedness in the United States were 2.84 in 2003States were 2.84 in , 3.87 in 2007States were 2.84 in , 3.66 in 2011  At both grades four and eight, the mean values associated with teacher feelings of preparedness displayed large increases between 2003 and 2007, and levelled off in subsequent cycles of TIMSS. For example, at grade four the overall mean value for teacher feelings of preparedness was 2.52 in 2003 and 3.38 in 2007. Similarly, at grade eight the overall mean value was 2.58 in 2003 and 3.58 in 2007. It seems unlikely that teacher feelings of preparedness would change so considerably between two consecutive test cycles, suggesting that these increases may also reflect changes in the metric of teacher feelings of preparedness (due to alterations in the TIMSS framework); this would affect all grade levels and education systems.\nAt grade eight, teacher experience ranged from 5.00 to 26.72 years, with a mean of 15.77 years (see Appendix A). In other words, grade eight teachers who teach mathematics have 15.77 years of teaching experience on average across test cycles, as measured by TIMSS. The comparable mean for the restricted sample of eighteen countries was 15.21 years. The number of years of teacher experience reported by grade eight teachers started at a lower level and ended at a lower level than grade four, suggesting there were between-grade differences in the level of teacher experience. The trends suggested modest change in net experience, increasing from 15.01 years in 2003 to 15.78 years in 2015. The within-country analysis of grade eight teacher experience also revealed similar findings to grade four; some countries displayed consistency in reported teacher experience at grade eight and some countries displayed variation in reported teacher experience at grade eight. For example, teacher experience in Australia, Italy, and the United States was relatively consistent across cycles at grade eight, while there was more variation in reported teacher experience at grade eight in Chile, Egypt, and Chinese Taipei. The education systems that consistently reported the lowest number of years of teacher experience at grade eight included Ghana and Botswana; both reported multiple values <nine years. Those that consistently reported the highest number of years of teacher experience at grade eight included Romania and the Russian Federation; both reported multiple values >20 years.\nThe descriptive statistics for teacher gender in grade eight differ from those for grade four. At grade eight, teacher gender varied between 0.00 and 1.00, with a mean of 0.42 for both the overall sample and the more restricted sample of eighteen countries (see Appendix A). This mean holds over time and implies that teachers were more often female, and also that for grade eight the gender distribution was more equal between males and females than at grade four. This also aligns with our general conception that teachers in elementary grades are more likely to be female, whereas teachers in upper elementary and high school are more evenly distributed between males and females. While many countries, such as the United States, had consistent values for grade eight teacher gender over time, others, like Japan, displayed a level of variation. Generally, there appeared to be more within-country variation for grade eight teacher gender than there was at grade four. For all four cycles of TIMSS that we investigated, Ghana, Morocco, and Japan consistently reported having more male teachers than female teachers, whereas the Russian Federation, Latvia, Lithuania, and Georgia reported that their teachers were almost exclusively female teachers.\nAt grade eight, the range in student performance scores over time and across countries varied between 264 and 621 score points, with an international mean of 475 (see Appendix A). The examination of the mean over time yields similar findings to that for grade four, with the mean slightly increasing from 468 in 2003 to 481 in 2015, and from 490 in 2003 to 501 in 2015 for our more restricted sample (Table 4.3). In other words, overall TIMSS performance has improved over the test cycles that we considered in our analysis. In general, there was greater variation in the within-country analysis of student performance at grade eight than at grade four. For example, changes in Chile's grade eight student performance scores were substantial, with a score of 387 in 2003 rising to a score of 427 in 2015. This increase aligns with the overall international increase in TIMSS performance over time. Meanwhile, Malaysia saw a drop in grade eight student performance, their mean score being 508 in 2003 and 465 in 2015. Australia was one of the few countries whose student performance scores were consistent over time at grade eight. As we found for grade four, countries with the highest grade eight student performance over time were largely located in East Asia, while countries with the lowest grade eight student performance over time were often located in West Asia and Africa."}, {"section_title": "Teacher Preparation to Teach Mathematics", "text": ""}, {"section_title": "Teacher Time on Mathematics", "text": ""}, {"section_title": "Teacher Preparedness", "text": ""}, {"section_title": "Teacher Gender", "text": ""}, {"section_title": "Student Performance", "text": ""}, {"section_title": "Books in the Home", "text": "The number of books in the home (Books) is a control variable that serves as a proxy variable to indicate student socioeconomic status. In the TIMSS survey, students are asked to estimate the number of books in their home, with responses placed on a 1 to 5 scale. A larger value denotes more books in the home, which generally corresponds to higher socioeconomic status. Values for books in home looked similar across grades four and eight, ranging between 1.61 and 4.04 at grade four, and 1.84 and 4.31 at grade eight (Appendix A). The international mean across cycles for books in home was 2.82 at grade four and 2.81 at grade eight. International means were quite similar for our more restricted sample of 18 countries, being 2.85 at both grade four and grade eight. Within-country variation across cycles was minimal, indicating that there was little change in socioeconomic conditions across the TIMSS administrations. In general, countries with higher values for books in home were the wealthier countries, whereas countries with lower values for books in home were less wealthy countries."}, {"section_title": "Student Language", "text": "Student language (Lang) is a control variable that captures the alignment between the language the test is delivered in and how often that same language is spoken in the student's home. This variable was measured on a four-point scale. A lower value indicates more overlap between the language of the test and language spoken at home, for example, a value of 1.00 denotes that the student always speaks the language of the test at home, whereas a value of 4.00 means that the student never speaks the language of the test at home. Values for student language at grade four ranged between 1.03 and 3.08, with a mean of 1.47 (or 1.49 in our more restricted sample of 18 countries; Table 4.3). The distribution of student language indicated that, in most instances, the language of the test was always or almost always spoken at home. Grade eight results were quite similar, with a mean of 1.52 (1.57 for the restricted sample of commonly participating countries; Table 4.3)."}, {"section_title": "Consistency Across Pooled, Multilevel, and Classroom-Means Models", "text": "We tested the basic linear model using three different statistical models. The first is a simple pooled within-country model using ordinary least squares (OLS) regression. The second is a multilevel model that clusters students within classrooms, with student variables at level one and teacher variables at level two. The third model aggregates student-level variables at the classroom level to create classroom means (in other words, classrooms rather than students are the unit of analysis). These classroom-mean results are analyzed using a single-level model. We focused on five teacher-level variables: teacher experience (Exp), teacher education to teach mathematics (Mathprep), time spent on teaching mathematics (Mathtime), instructional alignment with national standards (Alignment), and self-reported preparedness to teach mathematics (Prepared). Our analyses included participating TIMSS education systems where all these variables were available and excluded systems where some variables were unavailable. Consequently, we applied our three types of model (pooled, multilevel, and classroom means) to 307 cases at both grades four and eight for the 2003,2007,2011, and 2015 cycles of TIMSS. Each of the 307 cases represents an educational system in a single cycle of TIMSS. With three statistical models per case, this comprises 921 separate regressions, with 1535 teacher effectiveness variables compared across models (307 \u00d7 5 = 1535) (see Table 5.1). In terms of the consistency of statistical inference across all three models, our results showed that, among the 1535 comparisons, 1151 (75.0%) produced similar estimates, either significant or non-significant, across the pooled, multilevel, and classroom-means models. Among those comparisons with consistent estimates of significance, 78 (5.1%) comparisons were significant with same direction, and 1073 (69.9%) cases were statistically non-significant (p > 0.05). That is, although the estimates of regression coefficients and the standard errors were slightly different across the three models, two-thirds of them were substantively identical. In over two-thirds of comparisons, none of the models identified a statistically significant effect of teacher effectiveness measures on student outcomes. There was one exceptional case where all three model estimates were statistically significant, but in opposite directions. This unusual case considered alignment of the grade eight curriculum in Malta in the 2007 cycle of TIMSS; coefficient estimates for the single-level and classroom-means models were 160.3 and 103.5, Notes a Models may be pooled single-level models, multilevel models, or classroom-means models respectively (positive and statistically significant), however, the coefficient estimate for the multilevel model was \u221233.0 (negative and statistically significant). We also compared the three models in pairs to assess the statistical significance and directional discrepancy of the regression coefficient estimates. This approach looked at partial consistency among two statistical models, rather than across all three. Sixty-one (4.0%) comparisons were statistically significant with same direction for both the single-level and multilevel model, but not for classroom-means model. For instance, the estimates of grade four teacher experience in Iran for 2003 using the single-level and multilevel models were 1.2 and 1.5, respectively, but the estimate of the same predictor using the classroom-means model was \u22120.6, which was not statistically significant. In some cases, even though both the single-level and multilevel models produced statistically significant estimates, the directions opposed each other. For example, when analyzing grade eight data for Jordan in 2007, while the estimate of preparedness in single-level model was 32.1, it was \u22129.9 using the multilevel model. Similarly, grade eight teacher preparedness for Tunisia in 2007 was 8.7 with single-level model, but \u22125.5 with the multilevel model. When making comparisons between the multilevel and classroom-means models, there were 23 (1.5%) comparisons where the estimates of both models were statistically significant with same direction, where this was not true for single-level model. For instance, the estimate of grade four teacher experience for Chinese Taipei in 2003 was identical (0.3) across the three models, but this was not significant for the single-level model (the magnitude of the estimate was small, however). There was also one exceptional case where estimates of time spent on teaching mathematics were significant for both models but in opposite directions. For Iran in 2015 at grade eight, the time spent on teaching mathematics had a positive coefficient of 0.1 in the multilevel model, but a coefficient of -0.1 for the classroom-means model. However, given the very small effect size, this inconsistency should not be overstated. There were more consistent results between the single-and classroom-means models. We found that there were 52 (3.4%) comparisons that were statistically significant and in the same direction, where this was not the case for multilevel model. Interestingly, there were no comparisons between the single-level and classroom-mean models that showed opposing directions. However, there were 125 (8.1%) comparisons where the estimates were significant only for the multilevel model. Focusing on our five teacher-level variables, coefficients differed across the three models with regard to statistical significance for each variable. On examination of the 307 cases (countries per year) for each teacher effectiveness variable, we were able to classify the results into eight categories: (1) significant for only the multilevel model, (2) non-significant for only the multilevel model, (3) significant for both the single-level and multilevel models, (4) significant for both the multilevel and classroom-means models, (5) non-significant for both multilevel and classroom-means models, (6) non-significant for both single-level and multilevel models, (7) significant for all three models, and (8) non-significant for all three models ( Fig. 5.1). Our analysis strongly suggests that, overall, measures of teacher effectiveness have a weak and inconsistent association with student outcomes. The vast majority of the time (66-75% of the time), the three statistical models were in agreement that there was no statistically significant relationship with mean mathematics performance for any measure of teacher effectiveness.  When we considered specific teacher-level variables, for teacher experience there were 25 of the 307 cases (8.1%) where the estimates were statistically significant for only the multilevel model. In contrast, five (1.6%) cases of the estimates were statistically non-significant for only the multilevel model. Regarding significance in pairs, there were 19 (6.2%) cases where the estimates were statistically significant for both the single-level and multilevel models. We also found out that seven (2.3%) cases were statistically significant for only the multilevel and classroom-means models. Conversely, in terms of non-significance in pairs, in 13 (4.2%) cases the estimates were non-significant for both the multilevel and classroom-means models, and in six (2.0%) cases the estimates were non-significant for both single-level and multilevel models. Lastly, with respect to consistency across three models, in 19 (6.2%) cases the estimates were statistically significant across all three models. In the remaining 213 (69.4%) cases the estimates were non-significant for all three models. For teacher education to teach mathematics (Mathprep), the estimates were statistically significant for only the multilevel model in 22 (7.2%) of the 307 cases. In contrast, there were 13 (4.2%) cases where the estimates were statistically non-significant for only the multilevel model. Regarding significance in pairs, the estimates were statistically significant for only the single-level and multilevel models in 13 (4.2%) cases. We also found that only three (1.0%) cases were statistically significant for only the multilevel and classroom-means models. Conversely, in terms of non-significance in pairs, in 11 (3.6%) cases the estimates were non-significant for both the multilevel and classroom-means models, and there were 10 (3.3%) cases where the estimates were non-significant for both the single-level and multilevel models. Lastly, in six (2.0%) cases the estimates were statistically significant across all three models, while in the remaining 229 (74.6%) cases the estimates were non-significant for all three models. For time spent on teaching mathematics (Mathtime), the estimates were statistically significant for only the multilevel model in 26 (8.5%) of the 307 cases. In contrast, the estimates were statistically non-significant for only the multilevel model in eight (2.6%) cases. Regarding significance in pairs, there were seven (2.3%) cases where the estimates were statistically significant for both the single-level and multilevel models. We also found that only six (2.0%) cases that were statistically significant for both the multilevel and classroom-means models. Conversely, in terms of non-significance in pairs, 17 (5.5%) estimates were non-significant for both the multilevel and classroom-means models, and 10 (3.3%) estimates were non-significant for both the single-level and multilevel models. Lastly, considering consistency across three models, 28 (9.1%) estimates were statistically significant across all three models and the remaining 205 (66.8%) estimates were non-significant for all three models. For teacher alignment with national standards, estimates were statistically significant for only the multilevel model in 20 (6.5%) of the 307 cases. In contrast, the estimates were statistically non-significant for only the multilevel model in eight (2.6%) cases. Regarding significance in pairs, there were 13 (4.2%) cases where the estimates were statistically significant for both the single-level and multilevel models. We also found that only five (1.6%) cases were statistically significant for both the multilevel and classroom-means models. In terms of non-significance in pairs, eleven (3.6%) estimates were non-significant for both the multilevel and classroom level model, and in eight (2.6%) cases the estimates were non-significant for both the single-level and multilevel models. Lastly, 20 (6.5%) of the estimates were statistically significant across all three models, although, among these 20 cases, as we mentioned previously, for the grade eight curriculum in Malta in the 2007 cycle of TIMSS, the estimates for the single-level and classroom-means models were positive while the estimate for the multilevel model was negative. The remaining 222 (72.3%) estimates that were non-significant for all three models presented. For preparedness, there were 32 (10.4%) of 307 cases where the estimates were statistically significant only for the multilevel model. In contrast, 18 (5.9%) estimates were statistically non-significant only for the multilevel model. There were 11 (3.6%) cases in which the estimates were statistically significant for both single-level and multilevel models; among these 11 cases, the directions of the multilevel model estimates for grade eight data for Jordan and Tunisia from 2007 were \u22129.9 and \u2212 5.5, respectively. We also determined that only three (1.0%) cases were statistically significant for both multilevel and classroom-means models. Conversely, in 27 (8.8%) cases the estimates were non-significant for both multilevel and classroom-means models, and in six (2.0%) instances the estimates were non-significant for both the single-level and multilevel models. Lastly, only six (2.0%) educational systems had estimates that were statistically significant across all three models; the remaining 204 (66.4%) systems had estimates that were non-significant for all three models. When we focused only on the multilevel model, we found that the estimates of 291 (19.0%) cases showed there was a significant relationship between one of the measures of teacher quality (either a characteristic or a behavior) and student performance in mathematics, and there were 1244 (81.0%) non-significant relationships. Among the 291 statistically significant cases, student performance was most commonly related to teacher experience (in 70 cases [22.8%]), followed by teacher education (44 cases [14.3%]), time spent on teaching mathematics (67 cases [21.8%]), alignment (59 cases [18.9%]), and preparedness (52 cases [16.9%]). Finally, assuming that the results from the multilevel model are unbiased (or the least biased) estimates because of the substantive and empirical importance of student clustering within classrooms, there is a possibility that using the pooled or classroom-mean models leads to incorrect statistical inference. We found that there were 171 (11.1%) cases in which null hypotheses that coefficients were zero in population were incorrectly rejected (type 1 error) by either or both the single-level and classroom-means models. Moreover, there were 125 (8.1%) cases that failed to reject or incorrectly retained the null hypotheses (type 2 error). Although there are circumstances where classroom-means and single-level (non-clustered) analyses may yield substantively similar results, there were enough differences to warrant employing the more complex and computationally burdensome multilevel model."}, {"section_title": "Stability of Estimates Across Time", "text": "An alternative way of testing the robustness of the associations between teacher quality measures and student outcomes is to examine the stability of estimates for a particular country across time. Although changes in country-level means of (for example) teacher experience could be explained by substantive policy or labor market conditions, the relationship between teacher experience and student outcomes should not vary dramatically over a short span of time within a particular educational system. To test whether this assumption holds, the variables' coefficients estimated for each year were compared to establish whether there were significant differences between them. We based the theoretical framework used for the comparison procedure on the work of Clogg et al. (1995). They argued that, in large samples, the significance of the difference between the coefficients could be assessed using the following statistics: where \u03b2 1 and \u03b2 2 are regression coefficients from the models that are to be compared and SE is the associated standard error of the said estimates. The null hypothesis for such a test would be the equality of the coefficients. When employing a specific statistical test, the underlying assumptions of the test should be satisfied. Clogg et al. (1995) cautioned against the independence of coefficients when using this formula. Since these estimates were taken at different times, there is no reason to suspect dependency of samples and as such, this statistic is valid for the purpose at hand. However, since coefficients from multiple time points are being compared, the issue of multiple comparisons must be addressed (Curran-Everett 2000), in which the error rate increases as increasing numbers of pairs are compared. Several different methods have been suggested to adjust for this problem (Benjamini and Hochberg 1995;Hochberg 1988;Hommel 1988;Weisstein 2004). Here we adopted the correction method suggested by Benjamini and Hochberg (1995), which emphasized control for a false discovery rate while also minimizing the family-wise error rate. The variables that we assessed were: \u2022 The number of years the teacher has been teaching (Exp) \u2022 A teacher's formal education to teach mathematics (Mathprep) \u2022 Time spent on teaching mathematics (Mathtime) \u2022 Alignment of the topics taught with national standards (Alignment) \u2022 A teacher's self-reported preparation to teach mathematics topics (Prepared). After sorting the data available from each country and each sample year, 46 countries were found to have participated in TIMSS at least twice across the 2003-2015 sample period at grade four, and 50 countries were found to have participated in TIMSS at least twice across the 2003-2015 sample period at grade Notes Significance level is \u03b1 = 0.05. Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years eight. However, not all of these countries had longitudinal data for every variable, so the exact number of countries differed slightly. For each variable, we determined the percentage and proportion of countries that had significant differences between their estimated coefficients at both grade four and grade eight (Table 5.2). At grade four, approximately 15% of countries showed a significant difference in estimated coefficients for most of our variables across the sampling period, with the exception of teacher experience. The relationship between teacher experience and student outcomes was found to be inconsistent in around 24% of the countries. Drawing on these results, one plausible hypothesis would be that there is a subset of countries who consistently show significant differences between the variables, hence the similar percentage between variables. However, although some countries did appear more than once, the countries who showed significant changes between the coefficients were randomly distributed. In other words, the temporal instability of relationships did not appear to be a country-specific factor. At grade eight, the association between teacher instructional alignment and student mean mathematics performance was inconsistent in almost half the sample (22 countries), while the inconsistency for three other variables (preparedness, time on math, and experience) was \u226530%. The percentage of countries that exhibited significant differences was higher at grade eight than grade four. There was no clear pattern of countries who showed statistically significant differences in coefficients in all variables at grade eight. However, with such a high number of countries showing statistically significant variation, countries often demonstrated significant variation in effect for two or more variables. An important aspect is the existence of countries who not only showed a significant change in the coefficient but also a change in the coefficient sign. A change in the sign of the trend, rather than just the amplitude, implies a higher level of coefficient instability. Both grade levels showed the existence of statistically significantly differences in the coefficients of all measured variables, and, notably, grade eight data showed much higher percentages of statistically significant differences. High percentages of statistically significant differences can imply an issue with the measurement tools or indicate a highly variant sample across time. While more research and analysis is needed to support these initial findings, the high percentage of statistically unstable coefficients restricts our ability to establish a clear pattern. The problem is further compounded when we consider the existence of a few differences that changed sign. Scale evaluation and adjustment is needed to ensure that observed variability does not stem from the items themselves, rather than from the research population, or as a result of other factors. This secondary analysis of the multilevel models extracted coefficients and compared them individually. A more holistic approach to the topic of coefficient stability would be to include all of those time points into a single model, thus directly addressing the issue of stability over time; this strategy should be considered in future research."}, {"section_title": "Fixed Effect Analysis", "text": "To further explore the relationship between teacher quality and student outcomes, we undertook a country-level fixed effects analysis. One of the limitations of the empirical approaches that we used is that they are essentially correlative, making it difficult to attribute causation. A more serious concern is that the models include a limited number of predictors, and hence are subject to unobserved variable bias. The models focus exclusively on measures of teacher characteristics and behavior, and a few student-level indicators that are available in TIMSS. The advantage of fixed-effects models is that analyzing changes within a given unit can provide greater confidence in the association between dependent and independent variables provided the unobserved variables are invariant. Although there is reason to doubt that this assumption holds fully, a fixed-effect analysis should yield somewhat more robust estimates than a cross-sectional regression equation. Our fixed-effect country-level model is restricted to only those countries that participated in the 2007, 2011, and 2015 cycles of TIMSS for a particular grade level, and for educational systems that had country-level estimates available for all variables in the model. It should be noted that education systems are the unit of analysis here; this is not a studentor teacher-level fixed-effect analysis. The \"effects\" are therefore on the aggregate country level, and may not necessarily apply to particular teachers or students.  At grade four, the fixed-effects regression model did uncover a statistically significant association between changes in country-level means of teacher factors and changes in aggregate student mathematics achievement (Table 5.3). Specifically, countries that saw an increase in average time spent on mathematics in grade four saw higher mean student outcomes. Systems whose teachers had increasing levels of education was positive and approached statistical significance (p = 0.06), as did a negative relationship between changes in teacher experience and mean mathematics scores. Curricular alignment and teacher self-efficacy had no relationship to student outcomes. Interestingly, teacher gender had a strongly negative association with mathematics outcomes, suggesting that an increasing proportion of male teachers at grade four was associated with weaker mathematics scores. This is a rather curious result and merits more detailed investigation. At grade eight, time spent on mathematics was again significantly and positively associated with TIMSS mathematics scores, and countries whose teachers reported growing levels of preparedness to teach mathematics also saw higher student outcomes (Table 5.4). None of the other variables approached statistical significance. While these results should not be overstated, they do suggest that, in general, time spent on mathematics may have a positive relationship with student learning and that the failure to uncover a consistent association in other models could be due in part to the exclusion of relevant but unobserved variables. Two caveats should be kept in mind when interpreting the results of this analysis. As mentioned previously, the virtue of fixed-effects models is that they allow unobserved variables in a given unit (in this case a given educational system) to act as its own control, by identifying change over time. The governing assumption of Notes Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Books = index (1-5) of number of books in the home, Lang = index (1-4) of testing language spoken in the home, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years, Tmale = index of teacher gender (female = 0, male = 1), Performance = mean student TIMSS score in mathematics, SE = standard error. A p-value = 0.05 or lower indicates statistical significance such models is that any variables that are excluded are fixed, while all the factors with temporal variation and likely to have a relationship with the outcome of interest are included. This is, of course, an optimistic assumption; there are a number of social, educational, economic, and policy factors that influence student achievement that are likely to have altered during the course of TIMSS (and perhaps even in response to TIMSS testing). Secondly, this analysis aggregates at the education system level, which reduces the number of degrees of freedom (i.e., limits sample size), and is something of a departure for fixed-effects studies, which more typically consider individuals or smaller aggregates (like school districts) rather than entire educational systems. The results of the analysis should therefore be treated with considerable caution."}, {"section_title": "An Examination of Standard Errors", "text": "One of the distinctive features of large-scale studies like TIMSS is the estimation of standard errors. As described in detail in the TIMSS user guide (Foy 2015), TIMSS uses a complex sampling design; in stage one a random sample of schools is selected, and, in stage two, a randomly-selected intact classroom is selected. If the study were based on a straightforward random sample of all students of a given age or grade level, then the estimation of standard errors could be calculated using conventional means. Instead, TIMSS uses a jackknifing procedure, in which schools are paired and then any calculations (e.g., means and regression coefficients) are run separately with one of each pair weighted at zero and the weight of the other member of the pair doubled. Standard errors are then estimated by aggregating all of those separate estimates. The IEA has supported calculating means or simple linear regression models through the provision of macros (generated as part of the IEA Database Analyzer, a free specialist analysis package that can be downloaded from www.iea.nl/data). However, when running more complicated models (most especially multilevel models where students are clustered within classrooms), the jackknifing procedure can be computationally quite demanding, taking many hours of computing time to generate models for multiple countries over multiple TIMSS. The PISA study uses a related, but different approach in the estimation of standard errors. Unlike TIMSS, PISA selects a random population of 15-year-olds and then uses a balanced replicate weight system to calculate standard errors. However, a shortcut that is often used with success when analyzing PISA data is to use adjusted weights, such that the sum of weights equals the number of respondents in the study. An adjustment of this kind is necessary (if for no other reason) to prevent major downward bias in standard errors, since the weights in both TIMSS and PISA are meant to reflect the entire population of students in a country rather than the number of respondents (larger numbers resulting in smaller standard errors). This method has been used to produce results for unpublished studies that are quite similar to the full balanced replicate weight method, and can be convenient when conducting preliminary analysis (given the computational burdens of more formal procedures). However, it should emphasized that this strategy is not technically sound, and any analysis intended for publication or presentation should use the full-scale method. As discussed by , there are published studies in reputable journals that have failed to use appropriate statistical procedures, and, although the substantive results have been quite similar, they are not considered reliable. We conducted a secondary analysis to determine whether the adjusted weight procedure yielded similar standard errors to the jackknifing procedure. All of the multilevel statistical models run using the jackknifing procedure were re-run with student weights reweighted to equal the total number of respondents. We then compared the standard errors of the coefficients between the adjusted weight and jackknifing procedures. The purpose of this analysis was to determine whether the full jackknifing procedure was necessary to avoid downwardly-biased standard errors. Although there was certainly variation in the magnitude of the differences, on average, we found that standard errors calculated with jackknifing procedure were about twice as large as those calculated using an adjusted base weight (Table 5.5). The difference for grade eight (\u00d72.25) was larger than for grade four (\u00d71.90), and was reasonably consistent across years. In nearly every case, the standard errors to account for the complex sampling design were larger with the jackknifing procedure than those using an adjusted base weight; in some cases, four or five times as large. The proportional difference was also greater for teacher-related standard errors (\u00d72.37) than for student controls (\u00d71.45). This confirms that it is critical to account for the complex sampling design in TIMSS to avoid the risk of type I errors (false positives).  "}, {"section_title": "Discussion", "text": "This chapter has covered a great deal of detailed technical analysis, but the overarching implications are clear. First and most important, using basic statistical analysis based on TIMSS data, the relationship between teacher quality measures and student outcomes appear generally weak and inconsistent. After testing the robustness of the relationship between student outcomes and teacher characteristics in different education systems using alternative statistical models, methods of aggregation, and calculations of standard errors, we found that associations between teacher factors and student outcomes remained modest. When considered over a number of years, the most technically appropriate measure (multilevel estimates with jackknifed standard errors) suggested that there was a negligible relationship between teacher characteristics or teacher behaviors and student outcomes. Although there were education systems and years where teacher effectiveness measures were associated with higher student mathematics performance, this relationship was not robust across time and space. The weak associations between teacher experience and education mirror much of the research conducted in single-country studies. What is more surprising is that time on mathematics and content coverage has usually uncovered much stronger associations. Most studies that have found a relationship between instructional content and student outcomes have used measures of the volume and intensity of topics covered, as opposed to the alignment with national standards. This finding raises serious questions about the utility of standards-based reform, since there appears to be no strong relationship between teachers' fidelity to mathematics standards and student outcomes. Whether this indicates problems with the measurement of teacher instructional content or the quality of the standards themselves deserves greater attention. However, our results have a number of limitations, and should not be treated as definitive. The models included were restricted to a fairly limited number of variables and student controls (most seriously, prior student performance, which is not available in the TIMSS dataset), raising the potential for unobserved variable bias. There are also potential problems with the measurements employed, including possible differences in interpretability across varying cultural contexts (within and across educational systems), the indirect measure of teacher professional knowledge through self-reports, and changes in the mathematics topic framework used to measure instructional content coverage.\nIn the original  study, the researchers found that, although the latent construct of instructional quality was influenced by professional development,  Notes \u03c7 2 = chi-square, df = degrees of freedom, p = p-value, RMSEA = root mean square error of approximation, CFI = comparative fit index, TLI = Tucker-Lewis index, SRMR_W = standardized root mean square residual for the within level, and SRMR_B = standardized root mean square residual for the between level experience, and sense of preparedness, instructional quality was only weakly related to student outcomes in grade four. We adapted the model developed by  and applied it to the same cycle of TIMSS data (2011) to explore in greater detail the direct, indirect, and mediating effects of teacher effectiveness measures. The aim was to test whether the inclusion of opportunity to learn variables would strengthen the overall model and influence the statistical impact of instructional quality. The direct effects of instructional alignment and time on student mathematics achievement, and their mediating effects on the relationship between instructional quality and student mathematics were found to be positive and significant only in a small number of countries. As noted in Chap. 5, instructional alignment and time spent on teaching mathematics had a limited and inconsistent relationship to student outcomes, even including additional teacher-related variables, such as receiving professional development and the latent construct of instructional quality, which we incorporate and understand in our model as identifying pedagogical quality, as distinct from opportunity to learn variables. The findings here are consistent with those in Chap. 5, but are in stark contrast with the results of previous analyses using PISA data (see . These disparate outcomes could be the result of the different design of the two studies. TIMSS selects intact classrooms, whereas the PISA samples 15-year-olds in different classrooms and at different grades. As a result it is difficult to distinguish school or within-school/between-classroom effects in TIMSS studies. In addition, the measure of content coverage is quite different between the two sets of studies: the  work (using PISA) measured curricular intensity as opposed to alignment with national standards (the TIMSS measure). Further, the measure of opportunity to learn in TIMSS is teacher reported, while the comparable PISA variable is student reported. All of these factors could account for the differing ability of the present analysis to replicate the results from PISA studies, but in doing so they raise the possibility that the impact of time spent on teaching mathematics or instructional content are influenced by study design.   A final note relates to the issue of international comparability. The varying relationships among indicators of teacher quality across educational systems (measured by factor loadings and structural equation model structure) reinforces the challenge of merging data from multiple countries into a general global model of teacher effects on student learning. Our results suggest that the interrelationship of teacher factors to one another, and to student mathematics learning, is conditioned by cultural and national policy contexts, and that additional measures need to be included to identify the source of these differences.\nAn equity analysis of TIMSS data provides strong evidence that there is a broad, substantial, and enduring inequality in student outcomes. Cross-national analysis of within-country standard deviations demonstrates considerable variation in student performance, and students in high-SES classrooms generally outperform students in lower-SES classrooms. However, there is considerably less support for the hypotheses that there are important differences in teacher quality between types of classrooms, or that educational inequalities are based on such differences. Our analyses also raise important questions about whether teacher characteristics have similar effects on students when cultural contexts differ. The variation in the size, strength, and direction of indicators between study cycles also raises genuine concerns about overreliance on a single year of TIMSS data when making inferences about effect of teachers on students. Having said that, our analysis of equity does highlight one important conclusion: policymakers and researchers should be careful about attributing the lessons drawn from one educational system to another. It is simply not the case that low-SES students have less experienced or educated teachers in every national context (although in many they do), as many studies have found in the United States. In some educational systems at some grades, students in lower-SES classrooms may have the teachers that are more experienced and better prepared to teach. But other lessons do have more general applicability. For years now, a growing body of literature in the United States has suggested a straightforward equation of easily observable teacher characteristics are a poor indicator of quality instruction, absent of more robust statistical models and controls. The TIMSS data suggests that this lesson is broadly applicable to many countries. Equity remains an issue of vital concern, but an exclusive reliance on policies like improving teacher alignment or time spent on teaching mathematics may be unlikely to reduce these inequalities and improve student outcomes. . The role of schooling in perpetuating educational inequality: An international perspective. Education Researcher,44(4), 371\u2212386. Schmidt, W., McKnight, C., Houang, R., Wang, H., Wiley, D., Cogan, L., et al. (2001). Why schools matter: A cross-national comparison of curriculum and learning. San Francisco, CA: Jossey-Bass. Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (http://creativecommons.org/licenses/by-nc/4.0/), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder."}, {"section_title": "Data", "text": "For the analyses in this chapter, we used the 2011 grade four and grade eight student data, and their mathematics teachers' data from the IEA's Trends in International Mathematics and Science Study (TIMSS). TIMSS is an international assessment of student mathematics and science achievement at grade four and grade eight. A three-stage unequal probability sampling design was used to select the sampled population within each education system. For TIMSS 2011 at grade four, this resulted in an international sample from 58 education systems comprising 297,150 grade four students in 14,215 classrooms in 10,422 schools, and 14,576 mathematics teachers. At grade eight, 50 educations systems participated in TIMSS 2011, resulting in a sample comprised of 287,395 grade eight students in 11,688 classrooms in 9203 schools, and 13,190 mathematics teachers. Several participating education systems did not include the questions on mathematics standards in their country curriculum questionnaires, or the questions on teacher quality or instructional quality in their teacher questionnaires. We therefore excluded these countries entirely from our analyses, as well as any benchmarking participants. In many countries, several teachers taught mathematics in more than one classroom, and several classrooms had more than one mathematics teacher. For the classrooms with more than one mathematics teacher, data from one teacher was selected at random for the analyses. Our final sample for grade four thus included 45 education systems comprising 233,583 grade four students nested in 11,153 classrooms in 8268 schools, and 11,083 mathematics teachers. Our final sample for grade eight included 40 education systems comprising 228,107 grade eight students in 9002 classrooms in 7353 schools, and 8887 mathematics teachers. For most schools, only one classroom was selected, and thus there is no way to distinguish the classroom-level and school-level variances in student outcomes. We therefore opted to use a two-level model (i.e., students nested within classrooms) for each education system in this study, and did not undertake school-level analyses. Readers should note that, in this chapter, student gender, as well as several other variables, are coded differently in order to match the  operationalization, and hence different variable names may be employed."}, {"section_title": "Measures", "text": "Teacher instructional alignment with national curricular expectations (Alignment), time spent on teaching mathematics (Mathtime), and teacher experience (Exp) were operationalized as described in Chap. 3. The TIMSS 2011 mathematics score was used as a measure of student achievement. Several additional measures were included in  grade four study and are reproduced here for both grades four and eight, including teacher participation in professional development and a latent measure of instructional quality. In order to most closely mimic the Blomeke et al. (2016) study, we made only minor changes to the operationalization of student covariates and self-reported preparation to teach mathematics. As we discuss later, in several instances there was fairly low internal reliability in the constructs used, and so we modified the model design accordingly."}, {"section_title": "Teacher Education", "text": "Teachers' teaching experience was measured in years (Year). If a teacher's highest education level was ISCED Level 5A or higher, their highest level of formal education was coded as 1, else 0 was coded. If a teacher's major was mathematics or mathematics education, their major was coded as 1, else 0 was coded."}, {"section_title": "Preparation to Teach Math", "text": "Teachers were asked to indicate \"how well prepared do you feel you are to teach the following mathematics topics\". Response categories were \"not applicable\", \"very well prepared\", \"somewhat prepared\", and \"not well prepared\". If a topic was indicated as \"not applicable\", the response was recoded as missing data, and the responses of \"very well prepared\", \"somewhat prepared\" and \"not well prepared\" were coded as 1, 0.5, and 0, respectively. At grade four, we assessed this using eight topics related to number (NUM), seven topics related to geometric shapes and measures (GEO), and three topics related to data display (DAT). At grade eight, we assessed this using five topics related to number (NUM), five topics related to algebra (ALG), six topics related to geometry (GEO), and three topics related to data and chance (DAT). For each mathematics domain at each grade, the average score across the topics was used as the measure of a teacher's preparedness to teach in that domain. The internal consistency coefficients varied across countries, from 0.61 to 0.91 at grade four, and from 0.52 to 0.96 at grade eight."}, {"section_title": "Instructional Quality", "text": "We used three constructs to assess teachers' instructional quality. Teachers were asked \"How often do you do the following in teaching this class?\" The first construct concerned the clarity of instruction (CI), which was measured with two items: (1) \"summarize what students should have learned from the lesson\", and (2) \"use questioning to elicit reasons and explanations\". The second construct concerned cognitive activation (CA), which was measured by: (1) \"relate the lesson to students' daily lives\", and (2) \"bring interesting materials to class\". The third construct was supportive climate (SC), which was measured by: (1) \"encourage all students to improve their performance\", and (2) \"praise students for good effort\". The response categories were \"every or almost every lesson\", \"about half the lessons\", \"some lessons\", and \"never\", which were coded as 1, 2/3, 1/3, and 0, respectively. The average score of the items was used for each construct. The internal consistency coefficients of instructional quality varied across countries, from 0.20 to 0.76 at grade four, and from 0.21 to 0.73 at grade eight. "}, {"section_title": "Student-Level Covariates", "text": "Student gender (Gender) and number of books at home (Book) were used as student-level covariates. For student gender, girls were coded as 1, and boys were coded as 0. For the number of books at home, in this case \"none or few\" was coded as 0, \"one shelf\" was coded as 0.25, \"one bookcase\" was coded as 0.5, \"two bookcases\" was coded as 0.75, and \"three or more bookcases\" was coded as 1."}, {"section_title": "Analysis", "text": "The direct effects of instructional alignment and time on student mathematics achievement, and the indirect effect of instructional quality through instructional alignment and time were examined using multilevel structural equation modeling (see Fig. 6.1). We first examined the factor structures of professional development, preparedness to teach mathematics, and instructional quality at each grade, country-by-country. We used a multiple group approach to examine the configural invariance of the factors across countries, which indicated the same latent construct was represented by the same indicators. Next, we tested metric invariance (i.e., whether the same indicator showed the same factor loading on the latent construct across countries) for each latent construct at each grade. Note that the results are only directly comparable across countries when there is measurement invariance across countries. Second, we applied a two-level model without instructional alignment and time country-by-country at each grade. Student-level covariates were centered about their grand means. Finally, we constructed the hypothesized model for each grade and each country to examine the direct effects of instructional alignment and time, as well as the indirect effect of instructional quality through instructional alignment and time. The model was also fitted country-by-country. We conducted factor analyses of professional development, preparedness to teach, and instructional quality with teachers as the analysis units, and used teacher sampling weights in the analyses. For the multilevel structure equation model, the nested data structure (i.e., students nested within classrooms) was taken into consideration, robust standard errors were computed, and student and teacher sampling weights were used in the analyses. The model fit was evaluated using a likelihood ratio test and model fit indices."}, {"section_title": "Results", "text": ""}, {"section_title": "Descriptive Statistics", "text": "Average mathematics achievement scores for each educational system were between 245.94 and 606.27 at grade four, and between 332.76 and 611.10 at grade eight. The intraclass correlation coefficients (ICCs) for student mathematics achievement were between 0.07 and 0.56 at grade four, and between 0.09 and 0.79 at grade eight, indicating a need to explore both individual and school effects on student mathematics achievement. Instructional alignment in mathematics was between 0.34 and 0.66 at grade four, and between 0.26 and 0.84 at grade eight. On average, grade four mathematics teachers covered about 34-66% of their country grade-level mathematics standards, and grade eight mathematics teachers covered about 26-84% of their country grade-level mathematics standards in their teaching. Grade four teachers in Poland reported the poorest alignment with national mathematics standards, while grade four teacher in Australia reported the greatest percentage alignment with national mathematics standards. Similarly, for grade eight, mathematics teachers in Bahrain reported the poorest alignment with national standards, while teachers in Japan reported the greatest percentage alignment with national mathematics standards. On average, grade four teachers taught mathematics for 186-429 min per week, and grade eight teachers taught mathematics for 161-316 min per week. At grade four, mathematics teachers in Denmark spent the least time on mathematics, and teachers in Portugal spent most time on mathematics. At grade eight, mathematics teachers in Japan spent the least time, and mathematics teachers in the Lebanon spent most time on teaching mathematics. We noted that some countries that scored highly for instructional alignment did not report similarly high average instructional time on mathematics, and vice versa. Grade four teachers in Poland showed the least alignment with national mathematics standards, but their average time spent on mathematics was similar to the international average. Grade eight teachers in Japan taught about 84% of their national grade-level mathematics standards, however, they spent the lowest reported time on mathematics teaching. This suggests that instructional alignment and time spent teaching mathematics may play different roles in student achievement."}, {"section_title": "Measures of Professional Development, Preparedness to Teach, and Instructional Quality", "text": "The factor structures of professional development, preparedness to teach mathematics, and instructional quality were firstly examined country-by-country for each grade. The one-factor model of professional development was built with the three indicators: professional development in mathematics (PDM), professional development in mathematics instruction (PDS), and professional development in collaboration (COL). This model demonstrated a convergence problem in 15 countries (Australia, Croatia, Finland, Georgia, Germany, Honduras, Kuwait, New Zealand, Saudi Arabia, Slovak Republic, Slovenia, Sweden, United Arab Emirates, United States, and Yemen) at grade four, and in 14 countries (Australia, Chile, Ghana, Hong Kong, Iran, Japan, Korea, Lithuania, Morocco, Norway, Slovenia, Thailand, Tunisia, and Ukraine) at grade eight. These convergence problems were caused by the low correlation of COL with the other two indicators in these countries. Even in the countries with no convergence problems, the factor loadings of COL on the latent construct were <0.2 or even negative. Together, this indicates that COL measured a different construct from the latent constructs measured by PDM and PDS. To address the convergence problems of COL, PDM, and PDS in many countries, we used the three variables as separate predicators in a revised model instead of constructing a latent construct of professional development ( Fig. 6.2). The one-factor model of preparedness to teach was constructed from three indicators at grade four: preparedness to teach number (NUM), shapes and measures (GEO), and data display (DAT) at grade four. At grade eight there were four indicators: preparedness to teach number (NUM), algebra (ALG), geometry (GEO) and data and chance (DAT). The model converged in all countries at both grades. A multiple-group approach was used to build the factor model for all countries at each grade. In order to assess metric invariance, the factor loadings of the indicators were constrained to be equal across countries. A likelihood ratio test (LRT) was used to examine whether the metric invariant model was significantly different from the base model. At grade four, we found that \u03c7 2 = 224.19, d f = 88, which was statistically significant (p < 0.001). At grade eight, we found that \u03c7 2 = 259.77, d f = 117, which was also statistically significant (p < 0.001). In other words, the factor loadings of the indicators of preparedness to teach were significantly different across countries at both grades. The one-factor model of instructional quality was constructed from three indicators at both grades: clarity of instruction (CI), cognitive activation (CA), and supportive climate (SC). The one-factor model did not converge at grade four data in Northern Ireland, or at grade eight in Italy. This indicates that CI, CA, and SC measure different constructs in these two sets of data. Multiple-group models were applied to the remaining countries at each grade to examine the metric invariance. At grade four, we found that \u03c7 2 = 218.79, d f = 86, which was statistically significant (p < 0.001). At the grade eight, we found that \u03c7 2 = 168.95, d f = 76, which was statistically significant (p < 0.001). The factor loadings of the indicators of instructional quality were significantly different across countries at both grades."}, {"section_title": "Effect of Teacher Quality and Instructional Quality on Student Mathematics Achievement", "text": "As the factor analyses suggested that PDM, PDS, and COL measured different latent constructs in many countries, the three indicators were used directly as predictors in the models. As the factor loadings of preparedness to teach and instructional quality differed across countries, the models to explore the effects of teacher quality and instructional quality were built country-by-country rather than in a multiple-group fashion. The model did not converge for the grade four data from Australia, Malta, Netherlands, Romania, or England, or for the grade eight data from the Syrian Arab Republic or Tunisia 1 (Tables 6.1 and 6.2). In most countries, the chi-square statistics were statistically significant, which is common with large sample sizes. In countries with no convergence problems, Root mean square error approximations (RMSEAs) were generally <0.02, standardized root mean square residuals (SRMRs) for the within and between levels were <0.08, and the comparative fit index (CFI) and Tucker Lewis index (TLI) were >0.80. In many countries there were no convergence problems shown by the standardized coefficients of instructional quality and teacher quality effects on student mathematics achievement (Tables 6.3 and 6.4). At grade four, at least one of the professional development indicators showed significant effects on instructional quality in 16 countries. At grade eight, at least one indicator of professional development showed a significant and positive effect on instructional quality in 24 out of the 38 countries. In these countries, the effects of professional development indicators varied from 0.2 to 0.4. A teacher's score for professional development activities in mathematics, mathematics instruction, and collaboration was directly and positively linked to instructional quality, with higher scores indicating better instructional quality. However, these three professional development indicators showed weak relationships with student mathematics achievement in both grades four and eight. Their direct effects on student mathematics achievement were significantly positive in only eight out of 40 countries at grade four, and seven out of 38 countries at grade eight. In most countries, teachers' participation in professional development activities did not have any significant direct effects on student mathematics achievement. The effects of preparedness to teach on instructional quality were significant at grade four in 15 countries, and at grade eight in 14 countries. The effect sizes of preparedness to teach ranged between 0.2 and 0.5. The better prepared teachers felt to teach mathematics topics, the better their instructional quality. The direct effects of preparedness to teach on student mathematics achievement were non-significant in most countries. The direct effects of preparedness to teach were significant and positive in only two out of 40 countries at grade four, and nine out of 38 countries at grade eight. The three teacher education background indicators, experience, degree, and major, affected instructional quality significantly and positively in nine out of 40 countries at grade four, and in three out of 38 countries at grade eight. In comparison, their direct effects on student mathematics achievement were significant in more countries. Their effects were positively significant in 13 countries at grade four, and in 14 countries at grade eight. In these countries, the teachers with more experience, a higher degree, and who majored in mathematics major had more positive effects on student mathematics achievement. However, teachers' experience, degree, and major did not have any significant impact on their instructional qualities in many countries. The direct effects of instructional quality on student mathematic achievement were significant and positive in only two out of 40 countries at grade four, and in seven out of 38 countries at grade eight. For the non-significant effects of instructional 72 6 Relationships Between Instructional Alignment, Time \u2026 Notes \u03c7 2 = chi-square, df = degrees of freedom, p = p-value, RMSEA = root mean square error of approximation, CFI = comparative fit index, TLI = Tucker-Lewis index, SRMR_W = standardized root mean square residual for the within level, and SRMR_B = standardized root mean square residual for the between level quality on student mathematics achievement, the indirect effects of teacher quality indicators through instructional quality were non-significant in most countries. The significant indirect effects were found in only two countries at grade four, and in five countries at grade eight. In Korea, professional development in collaboration and preparedness to teach showed significant and positive indirect effects through instructional quality on student mathematics achievement at grade eight. When the number of professional development activities in mathematics instruction undertaken by a grade four teacher in Lithuania increased, their instructional quality and average student mathematics achievement level in their classroom also increased. In Oman, the effects of professional development in mathematics and degree were mediated by instructional quality at grade four, and the effects of professional development in mathematics instruction, preparedness to teach, and degree were mediated by instructional quality at grade eight. At grade eight, the effects of professional development in collaboration were mediated by instructional quality in Romania, the effects of professional development in mathematics instruction were mediated by instructional quality in Saudi Arabia, and the effects of preparedness to teach were mediated by instructional quality in Macedonia. Notes \u03c7 2 = chi-square, df = degrees of freedom, p = p-value, RMSEA = root mean square error of approximation, CFI = comparative fit index, TLI = Tucker-Lewis index, SRMR_W = standardized root mean square residual for the within level, and SRMR_B = standardized root mean square residual for the between level"}, {"section_title": "Effect of Instructional Alignment and Teaching Time on Student Mathematics Achievement", "text": "Based on the models outlined in Sects. 6.3 and 6.4, the final model was built on instructional alignment and class time spent on teaching mathematics. For each country we examined both the direct and mediating effects of instructional alignment and time spent on teaching mathematics on student mathematics achievement. These models were built for countries where no convergence problems were identified in the previous models. All models converged (Tables 6.5 and 6.6). As in previous models, the chi-square statistics were statistically significant in the final model in most countries. In countries with no convergence problems, RMSEAs were generally <0.02, SRMRs for the within and between levels were <0.08, and CFI and TLI were >0.80. However, we found that the model did not have a good fit to the grade eight data for Georgia. The effects of instructional alignment and time spent teaching mathematics on student achievement were examined after controlling for teacher and student characteristics (Tables 6.7 and 6.8). Teachers' instructional quality showed significant and positive effects on teachers' instructional alignment at grade four in Croatia, Iran, New Zealand, and Yemen, and at grade eight in Indonesia, Saudi Arabia, Ukraine, and the United States. In these countries, teachers with higher instructional quality levels also reported better alignment with national mathematics standards. Teachers' instructional alignment showed significantly positive effects on student mathematics at grade four in Denmark, Georgia, and Germany, and at grade eight in England, Indonesia, Italy, Lebanon, New Zealand, and Norway. Greater alignment between teachers' instruction and national mathematics standards was directly and positively associated with higher student achievement scores. Taking the effects of instructional quality on instructional alignment and the effects of instructional quality 76 6 Relationships Between Instructional Alignment, Time \u2026     Notes \u03c7 2 = chi-square, df = degrees of freedom, p = p-value, RMSEA = root mean square error of approximation, CFI = comparative fit index, TLI = Tucker-Lewis index, SRMR_W = standardized root mean square residual for the within level, and SRMR_B = standardized root mean square residual for the between level on student mathematics achievement together, instructional alignment showed a significant mediating effect on the relationship between instructional quality and student mathematics achievement only at grade eight in Indonesia. Teachers' instructional quality showed significant and positive effects on teachers' instructional time on mathematics at grade four in Croatia, Hungary, New Zealand, and Saudi Arabia, and at grade eight in Palestinian and Thailand. The higher the instructional quality teachers had, the more time they would spend on mathematics. Teachers' instructional time on mathematics showed significantly positive effects on student mathematics outcomes at grade four in Bahrain, Iran, and United Arab Emirates, and at grade eight in Chile, Chinese Taipei, Japan, Jordan, Morocco, New Zealand, Thailand, and Ukraine. The more time teachers spent on mathematics, the better mathematics achievement their students would have. Taking the effects of instructional quality and instructional time together, instructional time on mathematics showed a significant mediating effect on the relationship between instructional quality and student mathematics achievement in the grade eight data in Thailand."}, {"section_title": "Inequality in Teacher Quality: The Conceptual Terrain", "text": "Our study has focused on the relationship between teacher factors and mean student achievement. However, average performance can conceal massive differences among different groups of students. Hypothetically two countries can have very similar mean achievement but dramatically different distributions in achievement. This is the issue of educational equity, which has become a major focus of policymakers and researchers since at least the 1960s. In fact, a persuasive argument can be made that educational equity is as important as mean achievement. Concerns about equity are grounded in two issues, one practical and the other normative. First, despite the argument that there is an equity-efficiency trade-off (that overall increases in student learning come at the cost of more uneven distribution of equity in education) recent evidence suggests that no such trade-off exists, and, in reality, that greater educational equity is associated with higher average student performance (Parker et al. 2018) As a consequence, educational systems that generate 102 7 Teacher Effectiveness and Educational Equity more unequal outcomes may be depressing their stock of human capital by failing to tap into the potential of all of their students, with deleterious consequences for national prosperity. Second, educational inequality is also intrinsically problematic. The implicit social contract in most modern societies is that unequal rewards in the marketplace (i.e., large differences in wealth and income) can only be justified on the basis of fair competition. Educational systems have traditionally been viewed as the key mechanism for establishing this condition, by giving all students a fair chance to develop their talents. If some students are systematically disadvantaged in their chance to earn a good education, it calls into question the legitimacy of the social order. This is particularly so when there are entire groups of children that are systematically disadvantaged based on their background circumstances, such as their gender, race and ethnicity, socioeconomic status, or place of national origin, to name just a few examples. In outlining these conceptual issues, we have thus far glided over a very important distinction between inequality in educational outcomes and inequality in educational opportunities. While differences in educational outcomes may be strongly suggestive of background unfairness, and very high variation in student performance may signify a failure to maximize educational potential, differences in educational opportunities are more morally suspect and point to possible causes of educational inequality. It is patently unfair if some children are short-changed solely due to their ascriptive characteristics (gender, poverty, etc.), especially when those disadvantages are the product of policy. When schools are structured in such a way to ensure that more advantaged students have access to, for example, a more rigorous curriculum, higher quality teachers, or better facilities, then the educational system, and the people that manage and support it, are culpable for inequality. However, because policies are malleable, the extent to which policy is responsible for unequal opportunities indicates that these inequalities are also malleable. Policies can be changed. Although most studies of educational inequality have focused on specific countries, international and comparative studies are extremely valuable. The specific cultural and institutional contexts may influence the kinds of inequalities that manifest in particular countries, and so require careful examination on their own terms. However, there are some inequalities that are extremely common across educational systems, and these differences can provide important lessons about what causes inequality and how to reduce it. Arguably the most universal educational inequality is a consequence of socioeconomic status (SES). Although other types of inequality are certainly important, in virtually every educational system, students whose parents have lower incomes and less formal education perform worse by virtually any educational metric. Whether using PISA or TIMSS data, international large-scale assessments indicate that low-SES students register lower mean scores than their more affluent peers Montt 2011;. The precise nature of this relationship remains in dispute. While there is considerable evidence that low-SES children typically have fewer opportunities and resources in their homes and communities, the role of in-school factors remains unclear, and may vary greatly across educational systems. For example, research based on the United States indicates that high-poverty students usually have lower-quality teachers, whether measured by experience, educational background, or more sophisticated value-added modeling (Goldhaber et al. 2015). Results from the OECD's Teaching and Learning International Survey (TALIS) similarly show lower levels of teacher professionalism in economically disadvantaged schools in multiple countries. (OECD 2016) But a group of studies (Akiba et al. 2007;Burroughs and Chudgar 2017; have found that, by some metrics, there are countries where more economically disadvantaged students have access to higher quality teachers. There are other in-school factors where the inequalities are more stark and consistent, however. Comparative analysis by Chmielewski (2014) and  using PISA data, and Schmidt et al. (2001) using TIMSS data, indicate persistent inequalities in opportunity to learn rigorous mathematics content."}, {"section_title": "A Comparative Analysis of Inequality in Teacher Effectiveness", "text": "In this chapter, the basic approach is similar to that used in Chap. 5, except that, instead of treating mean student performance as the dependent variable, our focus is on educational inequality. Whereas Chap. 5 suggested that there was a fairly weak and inconsistent relationship between teacher quality measures and student outcomes, here we explore whether teachers' characteristics and behavior, as measured by TIMSS items, are related to educational inequality, and consequently whether changes in teacher quality have a role in promoting greater educational equity. As in Chap. 5, we aimed to identify common patterns across time and space, with an emphasis on consistent relationships, but, as discussed in Chap. 5, there are a number of methodological and substantive limitations to this approach, so the results should be treated as preliminary. We examined two measures of inequality: variation in student performance and differences between high-and low-SES classrooms. In our first set of analyses, we followed Montt (2011) and  in assessing overall inequality by using standard deviations in student outcomes as our measure. This measure of inequality captures overall differences in student outcomes without focusing on subgroup differences. More compressed distributions in TIMSS mathematics performance are considered as indicating lower levels of inequality in outcomes. As with the analyses of average outcomes, we focused on the 2003\u22122015 cycles of TIMSS, since many of the variables of interest were absent from the 1995 and 1999 iterations."}, {"section_title": "Inequality as Within-Country Variation I: Descriptives", "text": "The first step is to examine mean differences in within-country standard deviations, ignoring classroom-level effects. Country-level analysis was conducted for each country participating in TIMSS between 2003 and 2015 for both grade four and grade eight (Tables 7.1 and 7.2). At grade four, within-country score variation across all cycles ranged from a high of 114 points for Yemen in 2003, to a low of 53 points for the Netherlands in 2011. At grade eight, the highest standard deviation across all cycles considered ranged from a high of 113 points for Saudi Arabia in 2015, to a low of 58 points for Australia in 2011. At both grades four and eight, there was a general tendency toward greater within-country variation in student mathematics test scores in the Middle Eastern/Arab-speaking countries. Delving deeper into the data, we examined the subset of countries that participated in TIMSS between 2007 and 2015: there were 22 countries that participated in all cycles of TIMSS over this period at grade four, and 25 countries at grade eight. At grade four, the average within-country variation in mathematics scores changed very little overall, being 79.4 in 2007, and 80.0 in both 2011 and 2015. There was a fair degree of movement for particular countries, however. An equal number of educational systems (11 each) witnessed declines and increases in the size of standard deviations. The largest increases in inequality were exhibited by Iran (a 17 point increase) and the United States (a six point increase), while the largest declines were in Japan (seven points) and the Slovak Republic (five points). Patterns differed for grade eight. Most especially, there was a great deal more variation in the size of within-country performance variation. The standard deviations across the 25 countries were 85 points in 2007 and 2015, and 80 points in 2011. Further, the magnitude of the changes was far greater than in grade four. The average increase for countries that saw an increase in inequality was 13 points (compared to only four points at grade four). Similarly, the average size of the decline in those that saw shrinking standard deviations was 10 points at grade eight, compared with only three points at grade four. On balance, there were more countries with a shrinking inequality score (15 systems) than countries with a growing inequality score (10 systems). It is notable that, in 2015, the United States saw larger within-country variation in mathematics outcomes than in 2007 at both grade levels. Examination of within-country trends reveals few clear patterns. Concentrating on those systems that participated in at least three of the last four cycles of TIMSS, the data indicate no consistent trends at grade four. At grade eight, there was a steady increase in standard deviations between 2003 and 2015 in two systems (Armenia, totaling five points and Palestine, seven points), and a steady downward trend in score variation in four systems: New Zealand (14 points), Oman (34 points), Syria (19 points), and Tunisia (nine points). "}, {"section_title": "Inequality as Within-Country Variation I: The Influence of Teacher Factors on Student Variation", "text": "We further examined whether teacher factors and student controls might account for the apparently random variation in overall within-country inequality in mathematics scores. Replicating the fixed-effects analysis employed in Chap. 5, we constructed a model with two student-level controls (books in the home, and language of the test spoken at home) and five teacher-level predictors (alignment, time spent on teaching mathematics, teacher education, self-efficacy, experience, and teacher gender). The purpose of the model was to explore whether within-country temporal changes in teacher human capital might account for score variations. Of particular interest was whether greater alignment with national standards and more time spent on mathematics might be associated with lower standard deviations in mathematics outcomes. Although teacher characteristics such as experience and education are conventionally treated as measures of teacher quality, content coverage and time spent on mathematics could also be viewed as metrics of high-quality instructional practices (although, of course, time and content are influenced by school policies). This analysis yielded fairly weak results (Tables 7.3 and 7.4). At grade four, none of the predictor variables were statistically significant, and, contrary to expectations, the direction of association between time on mathematics and alignment was positive rather than negative; in other words, inequality increased. The predictors also failed to reach the 0.05 level of statistical significance at grade eight, although changes in self-efficacy were significant at the looser 0.10 cutoff. However, self-reported preparation to teach mathematics topics had a weak and non-significant association with greater inequality. Unlike grade four, at grade eight curricular alignment and time spent on teaching mathematics were associated with smaller standard deviations, although with very weak t-values.  Notes Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations; Books = index (1\u22125) of number of books in the home; Lang = index (1\u22124) of testing language spoken in the home; Mathprep = index (1\u22125) of teacher education to teach mathematics; Mathtime = mean number of minutes spent on mathematics teaching per week; Prepared = index (1\u22124) of self-efficacy to teach mathematics; Exp = experience teaching in years; Tmale = index of teacher gender (female = 0, male = 1). A p-value = 0.05 or lower indicates statistical significance"}, {"section_title": "Inequality as Differences Between High-and Low-SES Classrooms", "text": "Instead of employing standard deviations as a measure of educational inequality, one alternative is to consider classroom effects. We calculated the variation in student mathematics outcomes for students who all had the same mathematics teacher (in other words, within-classroom inequality), and then ran a series of  single-level within-country linear regressions using the standard set of predictors. Our main hypothesis was that teachers who spent more time on mathematics would be associated with smaller differences between students in their class, especially at grade four. These regressions also produced only very weak results (Tables 7.5, 7.6, 7.7, 7.8, 7.9, 7.10, 7.11 and 7.12). There were few statistically significant associations, and none of these relationships were consistent across time; this finding raises serious doubts about the stability of these associations, even within countries. Further, where there was statistical significance, there was no consistent direction of association, which suggests that there is no general cross-national association between teacher quality and within-classroom inequality. Time spent on mathematics was only statistically significant in one system at grade four (namely Hungary in 2011), but (surprisingly) in eight systems at grade eight. In most cases where p < 0.05, the relationship between time and within-classroom variation in performance was in the expected direction; in other words, more time spent on teaching mathematics led to a decrease in inequality. The only positive and statistically significant relationship was for Moldova in 2003. The strongest result was that for Japan, where more time spent on teaching mathematics was significantly associated with lower standard deviations in student outcomes in both 2007 and 2011. Our second method of analyzing educational inequalities also relies on classroom-level characteristics, but instead of aggregating all classrooms together, we differentiated high-and low-SES classes. The key variable we used to define socioeconomic status was the common proxy variable, number of books in the home. Our approach for identifying a classroom as high-or low-SES builds on that 112 7 Teacher Effectiveness and Educational Equity                used by , and Burroughs and Chudgar (2017), who both used interquartile differences. First we calculated the mean number of books in the home per classroom, and we then identified all of those schools above and below the 25th and 75th percentile, respectively. Finally, the average of classroom characteristics was taken for each key variable. Welch's t-test was used to determine whether these differences are statistically significant, since it is not as sensitive to variation in sample size or variance between groups, unlike Student's t-test (Derrick et al. 2016). However, it must be emphasized that our analysis may be vulnerable to Type I (\"false positive\") error, since standard errors were calculated using the adjusted weight model (as discussed in Chap. 5) instead of by using jackknife standard errors. The jackknifing procedure was developed for use with the entire sample of schools, not a subsample as employed here. Another limitation is that often only relatively few classrooms are compared against one another. The results should therefore be treated with caution. As might be expected, our analysis showed large and statistically significant differences in mean student performance between high-and low-SES classrooms in nearly every instance. At grade four, the gap was statistically significant in all but five cases, and statistically significant and negative (richer classrooms posting lower mathematics scores) in only two cases (Armenia in 2007 and Saudi Arabia in 2015). At grade eight, there was a statistically significant and positive advantage for high-SES classrooms in all but four cases. At grade four, as with other analyses, there were only a modest number of instances where the teacher quality differences between high-and low-SES classrooms were statistically significant (Table 7.13). The most powerful results at grade four were found for teacher self-reported preparedness to teach math, with statistically significant positive gaps (i.e., greater advantage for wealthier classrooms) in 15 instances, and statistically significant negative gaps in four cases. This inequality could be due in part to differences in teacher placement, but could also reflect biases in the instrument if teachers in advantaged schools were to have higher rates of professional satisfaction. However, there are some general (if non-significant) patterns. Pooling across cycles, there were 122 cases (educational systems across multiple years) where high-SES classrooms had more experienced teachers. Similarly, teachers in high-SES classes reported higher self-efficacy in 125 cases. The other variables saw much more variability in the relationship between classroom SES and measures of teacher effectiveness. In approximately half the TIMSS countries, low-SES classrooms had teachers who reported stronger alignment to the curriculum, better education to teach mathematics, and spent more time on teaching mathematics than teachers in high-SES classrooms. At grade eight, statistically significant differences in teacher quality were more common, but also occurred in both directions. High-SES classrooms registered significantly higher teacher experience in 37 cases, but lower teacher experience in four cases. A similar result was found for teacher education (25 positively significant versus eight negatively significant cases), alignment (21 positively significant versus seven negatively significant cases), and self-efficacy (39 positively significant versus three negatively significant cases). The results were more balanced for time spent on teaching mathematics (25 positively significant versus 28 negatively significant cases). The results were quite similar when all differences (not just those that were statistically significant) were considered. Although these results point to modest advantages for high-SES classrooms at grade eight and more equity at grade four, it should be remembered that the results were often quite inconsistent across years. In only a handful of cases was there a statistically significant difference for the same country across multiple years. For example, high-SES classrooms had higher mean teacher experience in four cycles of TIMSS for Iran and three for Syria. For time spent on mathematics, in Chinese Taipei, more affluent classrooms spent more time on grade eight mathematics with statistically significant differences in three different cycles of TIMSS, while there were multiple significant and negative differences (namely where low-SES classrooms had the advantage) for four cycles of TIMSS in Singapore and three cycles in the United States. Teachers in high-SES classrooms also had reliably higher self-efficacy in Jordan in three cycles of TIMSS."}, {"section_title": "What Does the TIMSS Tell Us About Teacher Effectiveness?", "text": "Abstract The central aim of this report was to investigate what international comparative assessments could reveal about the role of teachers in influencing student outcomes. A series of analyses attempted to identify potential trends in teacher quality and instructional metrics over time and their relationship with student achievement, but found no strong evidence for consistent predictable relationships between commonly-employed indicators of teacher effectiveness and student outcomes (both within and across educational systems). Further, although inequality in student outcomes remains pervasive across education systems, teacher quality is less subject to inequality, and, indeed, many countries have seen a rise in formal preparation to teach mathematics over the twenty years of IEA's Trends in International Mathematics and Science Study (TIMSS). While improving conventional measures of teacher quality may not have a significant impact on educational inequality, there is some evidence that increasing the average amount of time spent on teaching mathematics may reduce inequalities in student achievement. Researchers and policymakers should be extremely cautious about applying the associations identified in one education systems to a very different educational context. The results indicate that teachers with similar experience, credentials, and instructional strategies may regardless produce quite different results, indicating that parents, policymakers, community institutions, and cultural context likely play a powerful role in determining student outcomes. Chapter 4 focused on the first research question. Country-level descriptive data at grade four revealed that some teacher characteristics (e.g., teacher education) were fairly stable across time, but there was wide temporal variation in teacher behaviors like instructional alignment with national curricula and time spent on teaching mathematics. However, there were important differences in these variables between grades four and eight; at grade eight there was far greater variation in levels of teacher education, but less variation in time spent on teaching mathematics. Meanwhile, many countries saw increases in teacher characteristics like formal preparation to teach mathematics, perhaps in response to policy initiatives prompted by the TIMSS results. At both grades, there were many countries that demonstrated an increase in teacher self-efficacy over the twenty years of TIMSS. At both grades, some countries exhibited consistency in levels of teacher experience, while others demonstrated wide variation in this variable between cycles of TIMSS. Research question 2 was addressed in Chaps. 5 and 6. Chapter 5 identified relationships between teacher quality measures and mean student outcomes using several statistical approaches (pooled within country, students clustered within classrooms, classroom-level means, and country-level fixed effects models). Chapter 6 used multilevel structural equation modeling to explore the interactive effect of teacher characteristics and behaviors. The key takeaways from all of these analyses were: (1) There were no generally valid relationships between teacher characteristics and student mean outcomes, rather there were dramatically different relationships from one educational system to the next; (2) Of the two teacher behaviors associated with opportunity to learn considered in this study, time spent on teaching mathematics was the only behavior identified as statistically significant across countries in the fixed-effects model; and (3) Teacher instructional alignment with national curricular expectations has exceptionally weak associations with student outcomes. Chapter 5 also considered research question 3, examining the within-country consistency of statistical estimates across time and by analytical method. These analyses indicated that there were often differences in the strength and direction of many associations between teacher variables and student mathematics performance. This instability should give pause to researchers and policymakers who may be too quick to draw conclusions from one cycle of data or derived using one statistical method. The sensitivity of standard error estimates, which are critical to determining whether a relationship is statistically significant, should likewise warn researchers against neglecting the complex sampling design of TIMSS. The topic of student equity, addressed in research question 4, was the subject of Chap. 7. Consistent with other research (e.g., , our analysis demonstrated that there was considerable educational inequality, whether equity is understood simply as variation or as differences between high-and low-SES classrooms, and that this inequality varies considerably between education systems. However, there is was only a very weak relationship between this inequality and conventional measures of teacher effectiveness, whether those metrics were related to teacher preparation or to teacher behaviors. In short, at least according to our analyses, improving conventional measures of teacher quality may not have a significant impact on educational inequality. However, there is some evidence that increasing the average amount of time spent on teaching mathematics may reduce inequalities in student achievement. The research we have presented here is certainly extensive, but by no means conclusive. TIMSS operationalizes teacher-level variables in very specific ways, distinct from those in other research that have suggested stronger associations for teacher effectiveness measures. Teacher-reported preparation to teach mathematics topics is a less precise measure of teacher content knowledge than tests of that knowledge, which some studies have found to be related to student outcomes. Similarly, instructional alignment is based on very different assumptions from curricular intensity. Beyond this, there are other methods for exploring the potential of teacher instruction; for example, alignment and teacher preparedness is defined with a summary index, rather than being matched to more specific dimensions of student learning. It should be acknowledged that the design of TIMSS carries with it certain limitations. Because TIMSS only selects one or two classrooms within a given school, it makes it extremely difficult to differentiate teacher from school effects, or to identify within-school, between-classroom heterogeneity. The cross-sectional nature of TIMSS, and the lack of consistent country participation across cycles, also presents challenges. If there is one lesson that should be absorbed by readers of this report, it would be that researchers and policymakers should be extremely cautious about applying the associations identified in one education systems to a very different educational context. Simple transference of policy ideas that have enjoyed apparent success in one educational system can yield unexpected (or even disastrous) consequences in another. International comparative research is thus an extremely fruitful way to test the universality of given approaches. Further, this study suggests that the search for broadly applicable, reliable, easily collected measures of teacher effectiveness is likely to be long and difficult. On a more positive note, we found that replicating statistical models across different cultural contexts and time periods can be extremely fruitful. There is a strong temptation for researchers situated within a given educational system, or using a given set of data, to draw overly broad generalizations about the universality of their findings. Large-scale analyses employing studies from different countries, and replicated across time, can serve as a useful check on the robustness of scholarly work. Finally, our findings pose a challenge to those who would place too much responsibility for perceived educational ills on teachers. At least in the United States, there has been a tendency among some policy activists to present \"bad teachers\" as the reason for poor educational outcomes. The results of this study suggest that teachers with similar experience, credentials, and instructional strategies produce quite different results, which could mean that adequate cross-national measures of high-quality teaching are lacking, or that teachers' effectiveness is conditioned on other circumstances. The totality of the educational system itself, and the social structures it rests upon, powerfully shape student outcomes. Accordingly it is a profound mistake to place too high a burden on teachers (or schools). Teachers are essential to the educational project, but parents, policymakers, community institutions, and cultural context may also play a powerful role in student outcomes. . The role of schooling in perpetuating educational inequality: An international perspective. Education Researcher, 44(4), 371-386."}, {"section_title": "Reference", "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (http://creativecommons.org/licenses/by-nc/4.0/), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. Standard errors in parentheses. Notes Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Books = index (1-5) of number of books in the home, Lang = index (1-4) of testing language spoken in the home, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years, Tmale = index of teacher gender (female = 0, male = 1), Performance = mean student TIMSS score in mathematics "}, {"section_title": "Notes", "text": "Standard errors in parentheses. Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Books = index (1-5) of number of books in the home, Lang = index (1-4) of testing language spoken in the home, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years, Tmale = index of teacher gender (female = 0, male = 1), Performance = mean student TIMSS score in mathematics \nStandard errors in parentheses. Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Books = index (1-5) of number of books in the home, Lang = index (1-4) of testing language spoken in the home, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years, Tmale = index of teacher gender (female = 0, male = 1), Performance = mean student TIMSS score in mathematics \nStandard errors in parentheses. Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Books = index (1-5) of number of books in the home, Lang = index (1-4) of testing language spoken in the home, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years, Tmale = index of teacher gender (female = 0, male = 1), Performance = mean student TIMSS score in mathematics Notes Standard errors in parentheses. Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Books = index (1-5) of number of books in the home, Lang = index (1-4) of testing language spoken in the home, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years, Tmale = index of teacher gender (female = 0, male = 1), Performance = mean student TIMSS score in mathematics   \nStandard errors in parentheses. Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Books = index (1-5) of number of books in the home, Lang = index (1-4) of testing language spoken in the home, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years, Tmale = index of teacher gender (female = 0, male = 1), Performance = mean student TIMSS score in mathematics Notes Standard errors in parentheses. Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Books = index (1-5) of number of books in the home, Lang = index (1-4) of testing language spoken in the home, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years, Tmale = index of teacher gender (female = 0, male = 1), Performance = mean student TIMSS score in mathematics \nStandard errors in parentheses. Alignment = proportion of mathematics topics reported as covered by teachers compared with national expectations, Books = index (1-5) of number of books in the home, Lang = index (1-4) of testing language spoken in the home, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent on mathematics teaching per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years, Tmale = index of teacher gender (female = 0, male = 1), Performance = mean student TIMSS score in mathematics   Palestinian Exp 1.5 (0.4) 1.6 (0.4) 1.7 (0.5) G8Y07 Hungary Mathtime 0.4 (0.1) 0.5 (0.2) 0.4 (0.1) G8Y07 Indonesia Exp 1.6 (0.6) 2.1 (0.4) 1.5 (0.5) G8Y07 Indonesia Alignment 188.9 (47.7) 201.3 (38.3) 158.7 (40.6) G8Y07 Israel Exp 1.6 (0.6) 1.1 (0.5) 1.5 (0.6) (continued) United Arab Emirates Exp \u22121.0 (0.4) \u22120.9 (0.4) \u22121.0 (0.4) G8Y15 Egypt Mathtime 0.2 (0.1) 0.2 (0.1) 0.2 (0.1) Notes Standard errors in parentheses. Grade/year indicates grade level (where G4 and G8 are grade four and eight, respectively) and year (where e.g., Y07 is the year 2007), resulting in a composite abbreviation such as G4Y07 (which indicates Grade 4, 2007 cycle of TIMSS data). SLM = single-level model, MLM = multilevel model, CLM = classroom-level model, Alignment = proportion of mathematics topics covered compared with national expectations, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent teaching mathematics per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years Table B.2 Countries where the relationship of a given indicator of teacher quality with student achievement was statistically significant but in the different directions across the three statistical models Grade/year Country Predictor SLM MLM CLM G8Y07 Malta Alignment 160.3 (7.4) \u221233.0 (13.1) 103.5 (25.9) Notes Standard errors in parentheses. Grade/year indicates grade level (where G4 and G8 are grade four and eight, respectively) and year (where e.g., Y07 is the year 2007), resulting in a composite abbreviation such as G4Y07 (which indicates Grade 4, 2007 cycle of TIMSS data). SLM = single level model, MLM = multilevel model, CLM = classroom-level model, Alignment = proportion of mathematics topics covered compared with national expectations, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent teaching mathematics per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years Table B.3 Countries where the relationship of a given indicator of teacher quality with student achievement was statistically significant and in the same direction for the single-level and multilevel models  Notes Standard errors in parentheses. Grade/year indicates grade level (where G4 and G8 are grade four and eight, respectively) and year (where e.g., Y07 is the year 2007), resulting in a composite abbreviation such as G4Y07 (which indicates Grade 4, 2007 cycle of TIMSS data). SLM = single level model, MLM = multilevel model, CLM = classroom-level model, Alignment = proportion of mathematics topics covered compared with national expectations, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent teaching mathematics per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years Table B.4 Countries where the relationship of a given indicator of teacher quality with student achievement was statistically significant and in the opposite direction for the single-level and multilevel models Grade/year Country Predictor SLM MLM CLM G8Y07 Jordan Prepared 32.1 (10.0) \u22129.9 (5.0) 23.3 (14.5) G8Y07 Tunisia Prepared 8.7 (4.4) \u22125.5 (2.1) 5.5 (3.8) Notes Standard errors in parentheses. Grade/year indicates grade level (where G4 and G8 are grade four and eight, respectively) and year (where e.g., Y07 is the year 2007), resulting in a composite abbreviation such as G4Y07 (which indicates Grade 4, 2007 cycle of TIMSS data). SLM = single level model, MLM = multilevel model, CLM = classroom-level model, Prepared = index (1-4) of self-efficacy to teach mathematics Table B.6 Countries where the relationship of a given indicator of teacher quality with student achievement was statistically significant and in the opposite direction for the multilevel and classroom-mean models Thailand Mathprep \u22129.6 (3.4) \u22125.9 (3.4) \u22129.0 (3.8)"}, {"section_title": "G8Y15", "text": "United Arab Emirates Mathprep 12.8 (4.6) \u22123.1 (3.9) 12.8 (3.7)\nUnited Arab Emirates United Arab Emirates Prepared 20.9 (5.7) 0.4 (4.8) 11.5 (5.4) G8Y15 Canada (Quebec) Mathprep 7.1 (3.0) 4.3 (5.2) 7.4 (2.5) Notes Standard errors in parentheses. Grade/year indicates grade level (where G4 and G8 are grade four and eight, respectively) and year (where e.g., Y07 is the year 2007), resulting in a composite abbreviation such as G4Y07 (which indicates Grade 4, 2007 cycle of TIMSS data). SLM = single level model, MLM = multilevel model, CLM = classroom-level model, Alignment = proportion of mathematics topics covered compared with national expectations, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent teaching mathematics per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years Appendix B: Detailed Regression Estimates \u2026 Table B.8 Countries where the relationship of a given indicator of teacher quality with student achievement was statistically significant for only the multilevel model Grade/year Country Predictor SLM MLM CLM G4Y03 Canada (Quebec) Mathtime 0.0 (0.0) 0.0 (0.0) 0.0 (0.0) G4Y07 Algeria Mathprep 8.9 (5.8) 6.5 (3.1) 7.9 (6.3) G4Y07 Algeria Prepared \u22120.6 (9.4) 6.5 (3.1) 5.7 (11.7) G4Y07 Chinese Taipei  Czech Republic Mathprep 5.4 (2.9) 5.5 (2.5) 6.9 (4.8) G4Y11 Honduras Mathprep 3.2 (4.3) 4.6 (2.1) 2.7 (5.2) G4Y11 Hong Kong Mathprep 6.9 (3.9) 7.8 (3.8) 5.0 (4. Tunisia Exp 0.9 (0.5) 0.9 (0.4) 0.1 (0.6) G4Y11 Canada (Quebec) Alignment 0.4 (9.5) 25.7 (11.9) 17 (11.1) G4Y15 Australia Exp 0.0 (0.2) 0.4 (0.2) 0.1 (0.2) G4Y15 Australia Mathprep 4.3 (4.6) 7.7 (3.3) 9.4 (5.3) G4Y15 Bahrain Exp 0.6 (0.3) 0.9 (0.4) 0.6 (0.4) G4Y15 Chile Mathprep 5.6 (6.8) 9.6 (4.7) 3.7 (5.  Appendix B: Detailed Regression Estimates \u2026 Table B.9 Countries where the relationship of a given indicator of teacher quality with student achievement was statistically significant for only the single level model \nUnited States Mathtime \u22120.1 (0.0) \u22120.1 (0.1) 0.0 (0.0)\nUnited Arab Emirates (Abu Dhabi) Mathtime 0.0 (0.1) \u22120.1 (0.1) 0.0 (0.1)\nArgentina (Buenos Aires) Mathtime 0.0 (0.2) 0.1 (0.1) 0.1 (0.1) Notes Standard errors in parentheses. Grade/year indicates grade level (where G4 and G8 are grade four and eight, respectively) and year (where e.g., Y07 is the year 2007), resulting in a composite abbreviation such as G4Y07 (which indicates Grade 4, 2007 cycle of TIMSS data). SLM = single level model, MLM = multilevel model, CLM = classroom-level model, Mathtime = mean number of minutes spent teaching mathematics per week"}, {"section_title": "G4Y15", "text": "United Arab Emirates Exp 1.0 (0.5) 0.1 (0.4) 0.7 (0.5)\nUnited Arab Emirates Mathtime 0.1 (0.1) 0.0 (0.0) 0.1 (0.1)\nUnited Arab Emirates (Dubai) Prepared 27.3 (5.4) 5.1 (13.2) 12.1 (7.8)\nUnited States Prepared 12.4 (4.9) 7.7 (4.0   Notes Standard errors in parentheses. Grade/year indicates grade level (where G4 and G8 are grade four and eight, respectively) and year (where e.g., Y07 is the year 2007), resulting in a composite abbreviation such as G4Y07 (which indicates Grade 4, 2007 cycle of TIMSS data). SLM = single level model, MLM = multilevel model, CLM = classroom-level model, Alignment = proportion of mathematics topics covered compared with national expectations, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent teaching mathematics per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years 180 Appendix B: Detailed Regression Estimates \u2026 Table B.10 Countries where the relationship of a given indicator of teacher quality with student achievement was statistically significant for only the classroom means model Notes Standard errors in parentheses. Grade/year indicates grade level (where G4 and G8 are grade four and eight, respectively) and year (where e.g., Y07 is the year 2007), resulting in a composite abbreviation such as G4Y07 (which indicates Grade 4, 2007 cycle of TIMSS data). SLM = single level model, MLM = multilevel model, CLM = classroom-level model, Alignment = proportion of mathematics topics covered compared with national expectations, Mathprep = index (1-5) of teacher education to teach mathematics, Mathtime = mean number of minutes spent teaching mathematics per week, Prepared = index (1-4) of self-efficacy to teach mathematics, Exp = experience teaching in years Table B.11 Countries where the relationship of teacher experience (Exp) with student achievement was not statistically significant in all three models "}, {"section_title": "G8Y11", "text": "United Arab Emirates (Dubai) Exp \u22120.6 (0.6) \u22120.7 (0.6) \u22120.6 (0.6) (continued) Table B.12 Countries where the relationship of formal preparation to teach mathematics (Mathprep) with student achievement was not statistically significant in all three models Grade/year Country Predictor SLM MLM CLM Table B.13 Countries where the relationship of time teaching mathematics (Mathtime) with student achievement was not statistically significant in all three models Grade/year Country Predictor SLM MLM CLM"}, {"section_title": "G4Y03", "text": "Chinese Taipei Mathtime 0.0 (0.0) 0.0 (0.0) 0.0 (0.1) G4Y03 Cyprus Mathtime 0.1 (0.1) 0.1 (0.1) 0.0 (0.1)\nHong Kong Mathtime 0.0 (0.0) 0.0 (0.1) \u22120.1 (0.1) "}, {"section_title": "200", "text": "Appendix B: Detailed Regression Estimates \u2026 Table B.14 Countries where the relationship of alignment of teacher content coverage with national expectations (Alignment) with student achievement was not statistically significant in all three models"}]