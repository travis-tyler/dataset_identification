[{"section_title": "Executive Summary", "text": "The context of the report is increased interest in the UK in improving the measurement of the linkages between universities and business (referred to here as 'knowledge exchange'(KE)), including ability to benchmark performance with other countries. This report summarises primary and secondary sources on the US experience of measuring KE, including current analyses of US and UK KE performance (Part I), and US developments in improving measurements (Part II). Understanding of the breadth of KE as in the UK is less well developed in the USA and hence Part I focusses primarily on a narrower set of research and development (R&D) and technology transfer metrics. In Part I, the report sets the role of universities in the context of the overall US innovation system, as the basis to understanding what influences higher education (HE) KE performance. A range of policy measures and funds at US federal and state levels supports innovation, and the Bayh Dole Act which conferred ownership of intellectual property (IP) on universities has been one of the most influential of such instruments. An important aspect of any innovation system is the performance and funding of R&D. In the USA, businesses are the largest sector for both doing and funding R&D (noting that R&D covers a spectrum from the most basic to near to market). The US in general does more R&D as a percentage of gross domestic product (GDP) than the UK. The composition of R&D in the US also differs from the UK with more high tech R&D. The report identifies and reflects on concerns in the US about long-term trends in their innovation and R&D performance. There is a downward trend in federal, state and business funding of R&D, with only HE-funded R&D increasing (though HE R&D is a much smaller element than others). US companies also seem to be retreating from conducting more basic research in their own laboratories. There is concern about the performance and capability of US university technology transfer. Both research expenditure and IP handling is concentrated in the most research-intensive universities in the USA, as in the UK (though the UK system is even more concentrated than the US). IP performance, such as licensing income or spin-off numbers, is very variable even in top performing US universities, probably influenced by the nature of research subjects as well as technology transfer capability. Evidence suggests that US industry is less engaged with US universities in relation to research and research commercialisation activity than is the case in UK university-industry links. US university-business links may be more related to education and informal links. The US and the UK are very comparable on research quality measures such as citations and have similar areas of technological strengths, such as life sciences. International comparisons related to innovation systems, particularly university contributions, suggest that US performance has been weakening while the UK's has strengthened, though such comparisons are very broad brush. The focus of this investigation is the desire in many countries to improve and measure the impact of universities and research. However, Part II acknowledges that terminologies vary in different countries, and hence the report initially sets out a conceptual framework for defining KE, to enable a focus on comparable types of measurement in the US and the UK. Measurement of KE is set in the context of a systems approach to innovation, with a focus on the process through which changes in the interface between university and innovation systems occur. There are a number of major challenges in rigorous measurement, including tracking the different stages of the pathways to impact (e.g. through 'logic models') and providing counterfactual evidence. So while measuring KE is important, it is by no means easy and in the UK and the US, emphasis is placed on narratives and qualitative case studies, to contextualise any quantitative measurements. While the US has historically collected data on publications, R&D and technology transfer, it is only now considering how to improve and broaden measurements. Drivers for this are the increased policy focus on economic growth and the simultaneously increased pressure to demonstrate the value of public investments. Interest in measurements is also driven by increased expert interest in the relevant scholarly field. The report examines the main existing sources of data and new developments relevant to KE: \uf0b7 The National Science Foundation (NSF) HE R&D survey running since 1972. \uf0b7 The NSF Business R&D and Innovation survey, which was re-designed in 2008 based on a survey run since 1957. The survey was re-designed to capture significant changes in growth and innovation, for example, the importance of service and open innovation. The new survey captures partnerships with universities and other innovation partners, as well as exploring a range of teaching and research-related KE mechanisms. \uf0b7 The work of the Association of Public and Land Grant Universities (APLU) which has focussed particularly on regional and local economic development indicators. Indicator work has focussed particularly on industry links, workforce development (noting that talent is probably the most important economic contribution of universities) and incubation/acceleration of firms. APLU continues to seek to focus down on key indicators, taking account of the need to: o reduce burdens; o be sensitive to HE mission diversity; o not duplicate data from other sources; o reflect supply and demand side evidence; o contextualise data; and o collect and present data in a standard way nationally, including from federal sources. \uf0b7 The Science and Technology for America's Reinvestment: Measuring the Effect of Research on Innovation, Competitiveness and Science (STAR Metrics), a multi-federal agency approach with universities to link science investments with outcomes to inform public funding cases and allocation systems, with a particular focus on economic stimulus funding post 2008. The approach is particularly focussed on developing automated processes (using new digital technologies and computational tools) to collect data across the full logic model (linking inputs such as federal funding to activities in universities through to external outputs, outcomes and impacts). NSF is also developing its own cyberinfrastructure more generally, with a new Science of Science and Innovation Policy (SciSIP) programme. There is also increased interest in the USA in techniques such as web-scraping and linking of data sets. \uf0b7 The Association of University Technology Managers (AUTM) licensing survey focussed on research inputs and IP outputs. AUTM has also conducted surveys or explorations of technology transfer operations, wider KE mechanisms (based on UK experience), longer term economic impacts of IP (such as growth in sales or jobs) and case studies. \uf0b7 The University-Industry Demonstration Partnership (UIDP), which is an organisation of universities and companies, produces good practice and case study documents including measurement information. \uf0b7 Federal agency evaluations such as those produced by NSF of Industry/University Cooperative Centers. \uf0b7 Impact studies often conducted by individual universities and often focussed on influencing state governments (examples are of Georgia Tech and North Carolina State Universities). \uf0b7 National Center for Science and Engineering Statistics (NCSES) -science and technology indicators. A US National Research Council report in 2010 concluded that the US needed to improve on measurements of KE, picking up on examples such as the UK higher education-business and community interaction (HE-BCI) survey. Despite a number of bodies working on this topic, and similarities in conceptual understanding of the topic, this report concludes that there are still few metrics in the US that can be compared with those compiled in the UK -primarily technology transfer metrics (AUTM/HE-BCI IP statistics), co-publications, and, potentially, industry sponsored R&D in universities. The work of APLU and STAR Metrics may be the most promising for the future, though both are still some way off fruition. The wider AUTM KE work would be most useful in the UK but does not appear to be being taken forward at present. The US system is complicated by the different state and federal systems, and future UK efforts could potentially be focussed on local economic development aspects, as many US universities particularly focus their impact efforts on state governments. Qualitative information and sensitive contextualisation of data, as well as consideration of burden of collecting data (with potential to reduce this from new data technologies) will always be important in both countries."}, {"section_title": "Introduction", "text": "Demonstrating the value of public investments into the university base has never been more important as governments seek to make difficult trade-offs between different policy areas and ensure that resource allocation within policy areas is as efficient as possible. In addition to policymakers seeking to develop and evaluate their policies, individual institutions in receipt of public funds are also under intense pressure to demonstrate to their key stakeholders that they are using the funds both efficiently and effectively. Appropriately designed monitoring and evaluation systems with suitable indicators can be powerful tools for demonstrating the value of investments, help monitor performance and identify good practice. However, there are also a number of pitfalls that can lead to perverse outcomes. These will be discussed in this report. Despite this urgent need to capture and understand performance and demonstrate value for money, the current set of metrics on the performance and impacts of university-based investments remains relatively limited. This is particularly acute for those associated with stimulating increased knowledge flows between academics and users in the economy and society. The current set of indicators in the UK (the higher education-business and community interaction (HE-BCI) survey) focus heavily on a limited set of knowledge exchange (KE) mechanisms and focus on those that involve some transactional value. These indicators have been bolstered by other evidence sources and methods such as case studies combining quantitative indicators and more qualitative narratives, and the use of surveys. This report was sponsored by the Higher Education Funding Council for England (HEFCE) as a means to improve understanding of approaches to measurement in another leading edge innovation nation, the United States, with a long term view to improved benchmarking between the two countries. This report therefore turns to international developments in this area and in particular the efforts being made in the United States to develop new metrics. A 2010 report by the US National Research Council noted existing metrics at that time in the US were narrowly focussed on technology transfer but that various national metrics programmes which provide evidence on knowledge and technology transfer -including by the National Science Foundation(NSF)/National Institutes of Health (NIH), the Association of Public and Land-grant Universities (APLU), and the Association of University Technology Managers (AUTM) -were 'in flux'. This report therefore sought to establish progress and key developments in measuring KE-type activities in the US. The report draws upon both primary and secondary sources of evidence, including a review of the relevant literature and government documents relating to the development of metrics in this area in the US and a programme of fieldwork in the US by the report authors interviewing key experts directly involved in the design and development of KE-related metrics. The interview programme (details at Appendix D) covered national-level organisations involved with collecting data across institutions, and was therefore concerned with issues of comparability and aggregation, and individual universities to explore what was being done within specific institutions to capture and demonstrate how they interact with, and contribute to, the wider economy and society. The report is structured in two main parts. Part I (Chapters 2-3) explores the US innovation system, positioning universities within it. This is important as the context matters for interpreting evidence on the nature and value of the linkages that universities form with business and the wider innovation system. The structure of the innovation system -the different types of organisations within it, the policies and norms and other institutions that condition the 'rules of the game' -will have an important effect on the nature and strength of linkages that form between the knowledge base and the productive (industry/user) base. This part of the report also reviews existing comparative US-UK evidence on KE activities. The description and analysis are primarily focussed on narrower definitions of KE and the understanding of innovation, compared to norms in UK, focussed primarily on R&D and technology transfer. Part II (Chapters 4-7) explores in detail the efforts being made within the US to develop new metrics for capturing this type of activity. Since the US presently takes a narrower view of KE and innovation systems, considerable detail is given about underlying theories and models aimed at defining the scope and nature of metrics in this area. It starts by presenting a framework for the development of metrics (Chapter 4) before exploring the metrics being developed by key national-level organisations, including case studies of individual universities, within the US system (Chapter 5). Central to many of the discussions was the need to develop robust data sources but with the necessity to combine the quantitative metrics with more 'human' stories to help bring the narrative alive. Chapter 6 then provides a brief discussion on the efforts being made in the US to develop new data collection methods which seek to advance the types of metrics that could be developed and the way data are collected. Chapter 7 presents some conclusions on the potential to improve KE measurements, and its limitations. Part I is addressed primarily to policy-makers who are likely to be interested in the picture that can be drawn of each country's systems and the current points of comparison that can be made between the two countries. Part II is addressed primarily to analysts and experts, and gives an extensive account of the conceptual frameworks behind KE metrics developments, as well as considerable detail on all the current US data sources and emerging developments. This is intended to have longer term value to enable analysts and experts in the UK to seek out US sources and interrogate further whether more comparative research and analysis is possible."}, {"section_title": "Part I: Universities in the US Innovation System and Points of UK-US Comparisons for Knowledge Exchange 3 Universities in the US Innovation System", "text": "Before considering the various developments in metrics relating to KE and the role of universities in the US, it is important to understand a bit more about how universities fit within the US innovation system. They are frequently regarded as being central elements of the system: \"Research universities are the engines of the US innovation system. Of these, the nearly 200 public research universities conduct more than 60% of federally funded research. These institutions educate 85% of undergraduates and 70% of graduate students in US science and technology fields. \u2026 The role of research universities in starting new high-tech companies and commercialising technology has increased dramatically. Universities also host a range of public private research centres and consortia that bring together federal agencies, corporations, and national laboratories. The NSF sponsors a network of 55 University-Industry Cooperation Research Centers and a number of Engineering Research Centers at universities around the nation.\" (Wessner and Wolff, 2012, pp.44-45). Research universities are part of a research and education system which also includes a number of types of research-focussed organisations. These include 37 federally funded research and development (R&D) centres, of which 16 are national laboratories sponsored by government departments. A variety of other research centres are sponsored/funded by the military and by various departments of government, including Homeland Security, the Department of Health and Human Services, the Internal Revenue Service and the NSF. The national laboratories typically have a strong emphasis on key strategic national needs in relation to energy, space and defence and have strong industrial partnership histories. The Jet Propulsion Laboratory of NASA and the Department of Energy's largest national laboratories at Los Alamos, Lawrence Livermore, Sandia and Oak Ridge between them account for $20 billion of US funding for federally funded R&D centres which amounts to 55% of the total funding (Wessner and Wolff,p.45). The role of the federal government also encompasses a wide range of mission-specific or technology-specific programmes involving public private partnerships. The most well-known of these related to the funding of US technology start-ups include the Defence Advanced Research Project Agency (DARPA) and the Small Business Innovation Research Program (SBIR). The role of universities in the research and education system, and the role of these within the wider US innovation system are represented diagrammatically in Figure 3.1. The figure reveals the decentralised nature of the innovation system as a whole, with multiple routes of interconnections and intermediating agencies linking the administrative and political system with the industrial innovation sub-system and the research and education sub-system. It has been argued that the multiple pathways through which innovation policy funding may flow and strategic initiatives may be pursued, alongside a budgeting system which results in frequent review and potential revision, leads to a system which is able to respond relatively quickly to external perceived threats (see e.g. Rammer et al., 2007) "}, {"section_title": "Figure 3.1 The US Innovation System -Structure and Governance Patterns", "text": "Source: Adapted from Shapira and Youtie (2009) On the other hand it has been argued that this may lead to a lack of continuity and a lack of overall strategic direction, since the innovation system in a large and complex economy like the United States may be less amenable to changes in strategic direction than in the case of smaller or historically more centralised or co-ordinated innovation systems (Wessner and Wolff, 2012;Rammer et al., 2007). It should be noted that the US still focusses primarily on a narrower conception of the innovation system and measurements of innovation/KE linkages than the UK. Hence the focus in this section is primarily on R&D and technology transfer measurements. Globally there is now greater interest in wider understandings of innovation and knowledge-based interactions, as in OECD (2013). However, it has not been possible to provide comparisons of all innovation aspects, such as skills and human capital development or leadership and management elements, or societal dimensions. Part II considers these wider dimensions."}, {"section_title": "The US Policy Framework Directly Targeting University-Industry Interactions", "text": "As Figure 3.1 highlights, US universities operate in a policy context in which both the federal government and state governments play an important role, with a number of policies at both of these levels directly impacting on universities and their interactions with industry and other external users. At the federal level key legislation dates back to the 1980s with the University and Small Business Patent Procedure Act (Bayh-Dole Act) permitting universities and small businesses to obtain title to inventions funded by the federal government so as to license inventions. Subsequent to this universities set up technology transfer offices to implement these precepts, seek greater commercialisation of their research and access new sources of income for their institutions. The Cooperative Research Act eliminates damages from anti-trust violations so that firms, universities and federal laboratories can engage in joint competitive R&D, and the 1992 Small Business Technology Transfer Act established the Small Business Technology Transfer (STTR) programme to fund cooperative research involving small businesses, universities and federal laboratories. Nine federal agencies maintain a geographic network of federally funded R&D centres (FFRDC) and laboratories such as those of the US Department of Energy. The NSF has several national programmes directly targeting the university-industry interface, including the Engineering Research Centers (ERC), and the Industry-University Cooperative Research Centers (IURC). The latter began in the 1970s and were fully authorised in the 1980s. They aim to foster research involving industry, universities and government as well as support the development of research infrastructure, research and educational opportunities for students. The ERC programme begun in 1985 encourages university-industry consortia focussed on high risk research areas. The NSF has, as part of its educational programme, funded six university-based Science Learning Centers to conduct research and provide education. Education-based policies are further supported by nonprofit organisations such as the Kauffman Foundation with its Campuses Initiative to selected universities for entrepreneurship. There are also a number of technology bridging organisations which organise forums, workshops and conferences in which a variety of players in the innovation system, including universities, the private sector and policy makers, come together to discuss issues, review performance and engage in knowledge transfer and policy direction. The State Science and Technology Institute (SSTI) is an important institution fulfilling this KE role. Although federal policies are rarely targeted at specific regions/states, there is a wide variety of policies at the state level and these policies may play a significant role in the local and regional innovation systems. Arguably it is at the state level that universities play a more important role than at the national level (Shapira and Youtie, 2009). This is reflected in the efforts currently underway to develop metrics that capture and demonstrate the contributions of universities to the economy. In many states, universities (particularly the more research intensive universities) have introduced incubators for start-up companies and academic spin-outs, seed capital funds and technology transfer offices. A good example of state-led policy is the Ohio Technology-Based Economic Development (OTBED) programme launched in 2002 which evolved out of earlier technology programmes such as the Thomas Edison programme in 1984, aimed at encouraging commercialisation, and the Ohio 3rd Frontier Program. A key feature of the programme has been to support university research in areas that are aligned with Ohio's industrial and technological strengths. The OTBED programme includes a wide variety of initiatives in which universities may become engaged, including research and commercialisation collaboration (Research Scholars Program, Wright Centers of Innovation Program and Grants for Capital Equipment) and entrepreneurial support (Entrepreneurial Signature Program and pre-seed and seed funds award grants to bodies that invest in start-ups and product development assistance). In addition many impacts of the programme result from better linkages among research institutions, universities and industry and a general strengthening of the linkages and knowledge flows in the regional innovation system."}, {"section_title": "University R&D in an Innovations Systems Context: US and UK Compared", "text": "It is helpful to consider the role of universities and university research in the US innovation system in terms of who funds R&D activity and who carries out R&D activity. A Sankey diagram illustrating the main features of the US Innovation system in terms of R&D is shown in Figure 3.2. In this figure the thickness of the lines and the size of the circles are proportionate to the sums of money involved. The greatest amount of R&D in the US system is both funded and carried out by the business enterprise sector. Thus the analysis shows that business enterprise carried out $283.3 billion of R&D in 2011 which was 68% of total US R&D. The sector also funded $248.9 billion worth of R&D, the bulk of which it carried out itself. The thinner lines emerging from the funding circle of the business enterprise sector show that it also funded on a minor scale R&D which was carried out in the university and college system and in the not-for-profit sector. R&D carried out in universities and colleges accounted for 15% of the total R&D performed in the US in 2011. It was predominantly funded by federal government support with a smaller amount funded by internal sources. The federal government plays a major role in terms of both the funding and conduct of R&D. It accounted for 33% of all funding and 12% of all R&D carried out. Of total federal funding 28% went to support business enterprise R&D, 36% to fund the federal government's own R&D expenditure, 31% to fund university and college R&D with 5% supporting the not-for-profit sector. It is important to note that R&D as a whole includes research which stretches from the most basic scientific research to direct applications and product development. The R&D carried out by the university sector is more focussed at the basic end while the business enterprise sector's R&D is much more focussed on the product development and applied end of the spectrum. The interconnections between these extremes are, however, multiple as shown in the figure and in our discussion of national laboratories and public-private initiatives discussed above."}, {"section_title": "Figure 3.2 Gross Domestic Expenditure on R&D by Sector of Performance and Source of Funds -United States (OECD, 2011)", "text": "Source: OECD. Stats Extracts. Data extracted on 18 March 2013. Analysis by Hughes, A. and Mogoll\u00f3n, A., 2013 In characterising the US innovation system, it is useful to consider its characteristics in relation to the UK. This is done in the following 10 figures. The linkages between universities and business are significantly affected by the composition, nature and focus of all forms of R&D (noting that innovation systems are much wider than R&D, but that R&D data are most readily available to make international comparisons of the sorts below). Figure 3.3 shows R&D expenditure as a percentage of GDP in 2011. The US spends substantially more relative to GDP than the UK. This is true in terms of overall gross expenditure on R&D (GERD) expenditure on R&D, as well as on business expenditure on R&D (BERD) and on government expenditure on R&D (GovERD). It is noticeable, however, that higher education expenditure on R&D (HERD) is much closer as a percentage of GDP in the two countries and that the UK has a higher share than the United States. In addition, Hughes and Mina (2012), in their in-depth benchmarking study of the R&D landscape of the UK which included comparisons with the US, showed that the type of R&D undertaken within US and UK higher education (HE) institutions differs. The UK is more heavily geared towards applied research and experimental development compared with the US, where approximately 50% of R&D in US HE is characterised as 'basic' (Figure 3.4)."}, {"section_title": "Figure 3.4 HERD by Type of R&D (Latest Available Year)", "text": "Source: Hughes and Mina (2012) It is important to note that R&D is one of a number of intangible assets that contribute to innovation and that expenditure on tangibles (such as fixed investment in buildings, plant and equipment) are also important. Figure 3.5 looks therefore at expenditure on tangible assets (machinery and equipment) and intangible assets including R&D as a share of GDP for the latest year available. Once again, the US is shown to spend not only more on R&D and other intellectual property (IP) products, but also significantly more on machinery and equipment, and on brand equity, firm-specific human capital and organisational capital. Expenditure on software and databases is very similar in the UK and the US.  .6 shows that the US share of business R&D accounted for by manufacturing is around 60% which is significantly lower than the UK. The percentage of R&D expenditure which is generated by foreign controlled affiliates is also much lower in the United States. The United Kingdom is an international outlier in terms of this particular variable, and overseas controlled affiliates are overwhelmingly more important in UK R&D than is the case of the US, which is a relatively more domestically focussed economy in terms of the conduct of business R&D."}, {"section_title": "Figure 3.6 Expenditure on Manufacturing R&D, Small and Medium-Sized Firms and Foreign Affiliates", "text": "Share of manufacturing in business R&D (UK 2009, US 2000, at current prices). The US total excludes most or all capital expenditure. Business enterprise R&D expenditure by size class (UK 2010, US 2009. R&D expenditures generated by foreign-controlled affiliates (2008). Sources: OECD. StatExtracts and OECD iLibrary: Science, Technology and R&D Statistics (data extracted on 22 March 2013); OECD Science, Technology and Industry Scoreboard 2011. The figure also shows that both economies have their business expenditure on R&D overwhelmingly controlled by firms employing over 250 employees and in fact in both economies a handful of firms account for the majority of R&D. Interestingly Figure 3.7 shows that in the UK it is medium-sized firms which are proportionately more important than in the United States. In the US a relatively high proportion of business enterprise R&D expenditure in the innovation system is accounted for by the smallest firms (those employing fewer than 50 people). Figure 3.8 provides comparative information on a range of other characteristics of the US and UK innovation systems. (It is important to note that in order to allow them to be represented on the same spider diagram, the direct government funding of business R&D as a percentage of GDP and indirect government support through R&D tax incentives as a percentage of GDP have both been scaled up 100-fold.)"}, {"section_title": "Figure 3.8 Federal Funding of R&D, Support for R&D, and Business Funded in R&D in the HE and Government Sectors", "text": "Direct government funding of business R&D and tax incentives for R&D (UK 2009, US 2008. Percentages scaled up 100fold. Government-financed BERD to firms (UK 2008, US 2007. Sources: OECD. StatExtracts -MSTI (data extracted on 22 March 2013); OECD Science, Technology and Industry Scoreboard 2011 The first point to note is the greater importance of the role of the US government in funding business expenditure on R&D. In 2011 US federal funding of business expenditure on R&D was running at around 14% compared to between 8-9% in the UK. The USA also has a significantly higher proportion of its support for R&D in the form of direct government funding. This is a reflection of the wide range of agencies and programmes which sponsor and fund business R&D and which we outlined earlier. Indirect support through R&D tax incentives is relatively low compared to the UK and substantially less than direct funding. This is the exact opposite of the case in the UK. Figure 3.8 also shows the extent to which business funds R&D which is carried out in the HE and government sectors. Here the United States has a relatively low proportion of business involvement. The final two elements of the spider diagram show that government finance of BERD is more or less evenly spread between the smallest and medium-sized firms in the United States. However this support is considerably higher in both size classes than is true for the United Kingdom. Federal support for the financing of R&D is a substantial feature of the small and medium-sized private sector business R&D expenditure effort in the USA and, for the smaller size classes in particular, reflects the range of federal agency programmes, in particular the SBIR which emphasises this end of the size distribution of firms. So far we have looked at the overall patterns of R&D in the business enterprise sector. In relation to universities it is also of interest to examine the extent to which business R&D is distributed across sectors of varying technological intensity and also the R&D intensity of those sectors themselves (which may affect opportunities for university linkages based on R&D and technology transfer). Figure 3.9 therefore shows the distribution of business R&D between high technology, medium-high technology and medium-low to low technology sectors. The United States has a relatively high focus in its R&D effort on the high technology sector. Thus 70% of the US R&D effort is in those parts of manufacturing. This compares to around 20% in the medium-high technology and 10% in the medium-low and low technology sectors. It is noticeable that more of the UK's effort is in the medium technology than the high technology areas compared to the United States. To the extent that university R&D is more germane to the higher end of the technology spectrum this implies a potentially greater role for interactions with university based research (though noting that there may be more opportunities for linkages with university teaching in the low and medium technology sectors, where there is a need for improvement in absorptive capacity).  Finally, Figure 3.10 looks at the extent to which business R&D is high or low relative to value added in each of the three technologically intensive categories (as university technology transfer is more likely to play a role in the more technologically intense sectors). This figure shows that the United States has a relatively high R&D intensive effort in each of the sectors. Thus in manufacturing as a whole the ratio of R&D to value added is 10% in the US compared to around 7% in the UK. In high technology manufacturers the R&D intensity is nearer 35% in the US; in this case and in the mediumhigh technology manufacturing sectors the US substantially outstrips the United Kingdom."}, {"section_title": "Longer Run Trends", "text": "It is useful to set the analysis against longer run trends in the funding and performance of R&D in the US innovation system. Figure 3.11 shows the percentage of US HE R&D funded from different sources. The figure shows that since the early part of this century the proportion of funding accounted for by the federal government has been falling whilst that funded by universities themselves, although much lower, has been rising. Industry funding has been on a downward trend since the late 1990s; although it shows some recovery towards the end of the period, it remains below the levels achieved at the end of the last century.   Figure 3.12 is the extent to which industry has retreated from its position in conducting basic research since the late 1990s. Although there was some recovery in the share after 2006, it still remains below the levels achieved on average in the 1990s. The federal government also has exhibited a decreasing share. The counterpart to these changes has been an increase in the share accounted for by all others, which includes charitable and philanthropic funding. The overall picture which emerges is that there has been a retreat in the industrial sector from funding basic research. Moreover, it appears that within the industrial expenditure on R&D, the proportion which is focussed at the most basic end of the spectrum has itself been declining. The closure of well-known large labs with a substantive basic component is part of a wider trend in which business R&D has focussed on more market oriented patterns. This raises significant issues for the extent to which the US system is able to fund its basic research activities when taken alongside the decline in funding at state and federal level. (See, for example, the discussion in Wessner and Wolff, 2012, pp46-48). Thus Figure 3.13 shows long run falls in both federal and industrial funding of basic research albeit with some recovery of the latter in the most recent period.  "}, {"section_title": "Funding for Basic Research in the United States by Source of Funding", "text": "Source: Wessner and Wolff, 2012, p.48 Thus despite the scale of federal funding of the US university system and the role with which the latter is frequently attributed in driving the US innovation system, these trends have been associated with increasing concern about its role and performance in recent years. This has arisen as part of the general concern with the US economy's innovative and competitive performance as a whole (Wessner and Wolff, 2012; National Academy of Sciences/National Academy of Engineering/Institute of Medicine, 2010aMedicine, , 2010bMcPherson et al., 2009;Zemsky and Duderstadt, 2004). Part of the problem is seen to arise from a crisis of funding. Thus, although federal support for university R&D is high, in real terms state support has dropped substantially at the same time as the tuition costs to students and their families have increased. Decline in state funding has for example been associated with a significant cut in the University of California's budget of 20% in 2009 and of similar proportions in 2011. Similar declines are reported in Arizona and Georgia. \"In all, 32 US states cut their support of higher education in 2010 by 0.3% and 13.5%, with double digit declines in Missouri, Delaware, Iowa, Minnesota, Arizona and Oregon.\" (Wessner and Wolff, 2012, p.104). At the same time industrial support for R&D in the university sector has also been weakening with significant declines beginning in the early part of this century. \"Leading university and industry leaders have pointed out that US companies increasingly choose to work with foreign rather than US universities, encouraged by the more favourable IP rights that foreign universities offer and the strong incentives for joint industry-university research that foreign governments provide.\" (Wessner and Wolff, 2012, p.105). The number of spin-outs appears to have remained buoyant through to the first half-decade of this century. However, patent applications and new technology licenses have been flat-lining. Moreover, there has been increasing concern about the variable and often lacklustre performance of technology transfer programmes. Research suggests that over half of the 139 programmes analysed in a recent study failed to cover their costs with around 16% reporting that they were financially selfsustaining. This has led to a substantial debate about the purposes of technology transfer in terms of the relative significance to be attached to the public good as opposed to the generation of IP and associated revenues. (See for example National Research Council, 2012b; the discussion in Wessner and Wolff, 2012, pp110-111; and National Academy of Sciences/National Academy of Engineering/Institute of Medicine, 2010a and 2010b and the references therein.) Concern about rebalancing the US economy in the aftermath of the financial crisis has heightened interest in the role that US universities may play in resurrecting manufacturing. At the same time pressure on funding at federal and state level after the financial crash has led to an increasing emphasis on the ways in which the returns from federal support for university R&D may be measured and the process of KE enhanced (Olson and Merrill, 2011). The UK has had similar trends though over a longer period and from a generally lower base (Hughes and Mina, 2012)."}, {"section_title": "The Funding, Conduct and Outcome of University R&D in the United States: Disaggregation by University", "text": "So far we have focussed on R&D funding and expenditure at a relatively high level of aggregation. It is important to look at a more disaggregated level at the distribution of the funding of and expenditure on R&D within the university system itself. This helps understanding of the specific roles of universities and their linkages. In US, as in UK, universities are very diverse. In each of the following figures we rank US universities in terms of total R&D expenditure in millions of dollars in 2010. Each figure shows the ranks and shares of the top 10% of US universities ranked by R&D spend and then looks at how they are funded and their output in terms of patents licensing and start-ups. Figure 3.14 shows that the top 10% of spenders account for a disproportionate share of expenditure and of funding. These universities account for 38.6% of all university R&D and the University of California System alone accounts for 9.7%. There is broad similarity in terms of the total R&D spend and percentage of the overall expenditure which is funded by the federal government. Thus the top 10% of universities, as well as accounting for 38.6% of total R&D, also accounted for 37.9% of federally funded R&D. Their share of industrially funded R&D was, however, higher at 45.3%. Their share of miscellaneous categories was much less, but this source of funding is also a very small part of the total funding for university R&D. Thus even though the United States has a highly decentralised federal and state system of universities, a very high proportion of its activities is accounted for by the top 10% of universities.  It is to be noted, however, that this degree of concentration is much less than in the United Kingdom where the top 10% of universities in terms of research expenditure account for more than twice as much as their counterparts in the United States (see for example Hughes and Martin, 2012). Figure 3.15 uses the same ranking, but shows the extent to which ranking in terms of total R&D expenditure corresponds to ranking in terms of patent applications, patents issued and start-up activity. The data are less complete for the cumulative number of start-ups than for other elements in the table, but the overall impression is quite clear. Just as the concentration of research expenditure shows that the top 10% of universities accounted for 38.6%, so we find that the percentage of applications filed by these universities the number of patents issued and the number of start-ups initiated all fall within the range of 33%-36.3%. The rankings in terms of these other variables suggest, however, that a number of the top ranked universities in terms of research expenditure do not rank in the top 10% in terms of the other indicators in this figure. Thus, for example, Johns Hopkins University Applied Physics Lab is ranked sixth in terms of research expenditure, but 58 th in terms of patent applications filed, 76 th in terms of patent applications issued and 73 rd in terms of start-ups initiated. These relative rankings may be accounted for both by variations in the balance between basic, applied and developmental research encompassed in their research budgets, as well as by relative concern with and efficiency of their commercialisation activities. Another interesting feature of the table relates to the cumulative number of start-ups. Given the emphasis placed upon the role of start-ups, it is important to note how the numbers of start-ups are small, being over 10 in number in only the top five universities ranked by research expenditure and that no university has a cumulative total of over 93 (where such data are available). Thus the whole of the US system initiated only 202 start-ups in the year in question and the cumulative number of start-ups which were operational as of the last day of that year was 680. For the system as a whole the respective numbers were 613 and 3,339.   Figure 3.16 once again begins with the rankings in terms of research expenditure, but now looks at the licenses and licensing income and also the numbers of licenses generating more than $1m. Once again, the top 10% of research spenders account for between 35% and 41% of the various dimensions of licensing activity, which is roughly on a par with their share of research expenditure. Perhaps the most striking feature of the figure is the fact that for the university system as a whole there are only 156 licenses generating more than $1m of which 65 were accounted for by the top 10% of R&D spending universities and that the latter accounted for just under 41% of all such licenses income. Once again it appears that there are substantial variations within the top 10% of R&D spenders of the commercialisation of their research as reflected in licensing activity. The UK university system demonstrates similar trends of variation in research commercialisation activity between universities, reflected in annual HE Business and Community Interaction (HE-BCI) surveys and qualifying income for HEFCE KE/HE Innovation Funding (HEIF) published in KE/HEIF allocation reports (HEFCE, 2011)."}, {"section_title": "University-industry KE in the UK and US: Points of Comparison", "text": "There are a number of sources which provide potentially comparable, national statistics on a limited number of metrics associated with the exchange of knowledge from the knowledge base and the productive base."}, {"section_title": "Academic Publication of Research Outputs", "text": "Probably the most traditional method of knowledge dissemination from the academic base is through the publication of scholarly research outputs in peer-reviewed journals, conference proceedings, books and other academic-focussed media (noting that publications remain the predominant channel for sourcing university contributions to innovation, as reflected in UK Community Innovation Surveys). Key findings from a recent study by Elsevier (2011) include: \uf0b7 The UK is more productive in terms of articles and citations per unit R&D spend or unit researcher than comparator nations including the US. UK researchers generate more articles per researcher, more citations per researcher, and more usage per article authored as measured by global downloads of UK articles, than the other top research nations (US, China, UK, Japan, and Germany) (see Figure 4.1). \uf0b7 While the UK's world share of publications is growing more slowly than the world average, the citations of UK articles increased faster than the world average. The UK's share of the world's top 1% of most highly cited articles was second only to the US in 2010 (Figure 4.2). \uf0b7 The UK's field-weighted citation impact (measure of quality of publication), adjusting for structural differences between countries, was second only to the US, and was narrowing the gap: the citation impact of UK researcher publications has increased over time, while that of the US is decreasing (Figure 4.3). \uf0b7 A map of UK research strengths for 2010 shows over 400 areas in which the UK is very strong by international research standards. The US and UK have similar areas of comparative expertise compared to Germany, Japan and China, with the UK and US having proportionally more competencies in medical/health sciences, and in humanities/social sciences than comparator countries. However, within this, the US competencies are weighted towards medical sciences, while the UK competencies are weighted toward social sciences. Critically for both nations, they show significant strengths in multi-disciplinary areas compared with other nations. \uf0b7 The study found a high degree of international collaboration, measured by co-authorship across borders. One of the most frequent collaboration partners for UK researchers over the period 2006-2010 was the USA, emphasising the close ties between the two nations. \uf0b7 While UK researchers have a low and declining share of patents compared to other researchintensive countries, there is a high usage by R&D intensive corporations of articles authored by academics.  "}, {"section_title": ".4 International Collaboration Map for the UK Over the Period 2006-2010, Excluding Europe", "text": "Source: Elsevier (2011)"}, {"section_title": "Knowledge diffusion through co-publications", "text": "An important method for knowledge diffusion in the system remains the publication of academic papers derived from the research activities of higher education institutions (HEIs). The direct exchange of knowledge is strengthened when publications are co-authored by academics and their partners in industry. Hughes and Kitson (2012) showed that 46% of academics had produced joint publications with an external partner during the period 2005-08. Comparable evidence on academic-industry co-publications can be gathered through one of the global commercial repositories of publications such as the Web of Science (ISI Thomson Reuters) or Scopus. This information would allow the production of comparable metrics on co-publication rates, and metrics of 'impact' based on citation counts, for the US and the UK. Indeed, a recent Nesta study explored national differences in collaboration -as measured by the degree of co-publicationin the biomedical sector. It showed that the citation impact of publications jointly authored by both academia and industry is higher in the biomedical industry than those papers published alone, accounting for variations in citation rates between research fields and over time. It also showed that the relative citation impact of co-authored publications in the UK was higher than that in the US."}, {"section_title": "Figure 4.5 Relative Citation Impact of Biomedical Papers Across Seven Countries", "text": "Source: Marston, L. (2011) All Together Now: Improving Cross-Sector Collaboration in the UK Biomedical Industry"}, {"section_title": "Industrially sponsored research grants and contracts", "text": "One of the key KE mechanisms through which knowledge is exchanged between universities and industry is research through industrially funded grants and contracts. Both the UK and the US collect data on this activity at the institutional level: in the UK through the Higher Education Statistics Agency (HESA) and UK HE-BCI surveys, and in the US (currently), through the NSF HERD survey (see Section 4.2 for a more detailed discussion of this survey). However, it is important to consider the definitions used by each agency in the data collection. Table 4.1 shows that definitions vary somewhat between the UK and the US, with the greatest similarity between that used by the HESA Finance Statistics Return (FSR) and the NSF HERD survey. Should include all research grants and contracts income from industrial and commercial companies and public corporations (defined as publicly owned trading bodies, usually statutory corporations, with a substantial degree of financial independence) operating in the UK."}, {"section_title": "HE-BCI 2", "text": "Collaborative research Income should be returned for research projects which have public sponsorship (grant-in-aid from a government or public body) to support research performed in collaboration with at least one other non-academic organisation (collaborator). ... 'Collaborative research' must involve: grantin-aid from at least one public body, and a material contribution (which may be cash or 'in-kind' if specified in the collaborative agreement and auditable) from at least one external non-academic collaborator. Arguably the most comparable data source on the value of R&D funded by industry in the HE sector is provided by the OECD through their statistics on GERD, and presented in Section 2 of this report (in particular Figure 3.8). This shows that a much greater proportion of research undertaken in the HE and government sectors in the UK is funded by business compared with that in the US. However, a downside of this data is that it is only obtainable at the aggregate level prohibiting more granular comparisons between, for example, matched samples of different types of HEIs."}, {"section_title": "Perceived Strength of University-Industry Collaborations", "text": "Another source of comparable, national evidence is the World Economic Forum (WEF) Global Competitiveness Report. WEF collect a wide range of data that inform the competitiveness of nations and present country profiles. They break the index down into 12 'pillars' of competitiveness, the 12 th of which is 'innovation'. This pillar presents information on \uf0b7 PCT patents, applications/million population With the exception of patents per million population, the evidence that underpins the rankings for each of these components is drawn from the WEF annual 'Executive Opinion Survey'. This survey seeks the views of business executives covering 144 countries around the world to bolster the quantitative evidence with qualitative assessments of factors that are hard to quantify but are deemed important for national competitiveness. The latest survey received 14,059 responses, translating to approximately 100 per country. In 2011, the number of responses for the UK was 102 while the US generated 397. As such the samples at the national level are relatively small which may affect the robustness of the findings.  2008,2009,2010,2011,2012) Table 4.2 shows that the global rank of the UK for innovation has been improving, from 17 th in the world in 2008-09 to 10 th in 2012-13. The US, however, has seen its ranking for innovation fall from first to sixth over this period. A key source of improvement for the UK -based on the findings of the survey -has been the collaboration between universities and industry for R&D, which has seen the UK rise from ninth in the world to second, while the US has fallen from first to third; and the availability of scientists and engineers, where the UK has risen from 32 nd in the world to 12 th . In addition, the UK has risen from seventh in the world for the 'quality of scientific research institutions' to third, while the US has fallen from first to sixth between 2008-09 and 2012-13. The overall picture painted from the WEF executive opinion survey is that the quality of the knowledge base in the UK has improved relative to other nations, including its links with industry for R&D. However, one should exercise some caution due to the relatively small samples collected in each country."}, {"section_title": "Bespoke UK-US Surveys of University-Industry KE", "text": "In addition to the surveys or analyses that are, or at least in principle could be, undertaken regularly, a bespoke survey of university-industry linkages in the UK and US was funded by the Cambridge-MIT Institute and carried out in 2004. It sought the responses of firms in the two countries on their innovation activities and performance, including how they link with universities. This allowed for the first time direct comparisons between the two nations in this important area. The findings are discussed in detail in Cosh, Hughes and Lester (2006) and Hughes (2007). Key results include: \uf0b7 In 2004 there was a more frequent but less intensive and less highly valued set of interactions between the business sector and the university sector in the UK compared with the US. \uf0b7 The pattern of university-industry interactions suggests that there is a greater emphasis on the role that universities play in providing public space functions in the innovation system and in providing education in the US compared with the UK. \uf0b7 Areas where UK firms viewed university-industry interactions more frequently as highly important than their US counterparts included the recruitment of staff at post-doctoral level, use of licensing, and joint R&D projects. In contrast, US companies were more likely to view internships, graduate recruitment, and informal contacts as highly important compared to their UK counterparts. \uf0b7 Interactions involving innovation-related expenditure with universities were more prevalent in the US compared with the UK suggesting a greater depth and intensity of interaction in the former. \uf0b7 The smallest companies in the US are much more likely to cite universities as a highly important source of knowledge, both compared to large firms in their own nation, and to UK-based firms. The gap in the rating of universities as highly important sources of knowledge narrows considerably as the size of firm increases. In addition, a critical finding from a subsequent analysis of this survey data by Hughes (2007) found that UK firms are much more likely than their US counterparts to use a multiplicity of different types of knowledge in their innovation activities, covering sources from the company sector (e.g. internal knowledge, suppliers, customers); intermediary and regulatory sector; and the scientific knowledge base (including universities, private research institutions, commercial R&D labs etc.)."}, {"section_title": "Conclusions", "text": "Although present US-UK comparisons of KE are limited, this section has provided some key points of comparison to illustrate the similarities and differences of the two systems: \uf0b7 Both systems demonstrate multiple linkages between universities and businesses and the wider innovation systems of the two countries. \uf0b7 The US spends more on R&D than the UK, and more overall on innovation, and particularly more from business on R&D -though spend on HERD is similar in both countries. \uf0b7 HERD in the UK appears more applied than in the US. \uf0b7 The UK spends more overall on manufacturing R&D. US business does more high tech and high value R&D than UK business. The UK is far ahead on attracting overseas business spend on R&D into the country, whereas the US is primarily a domestic R&D system. \uf0b7 UK business R&D comes more from medium-sized companies, and US from small companies. Much the largest share of business spend on R&D in both countries is from a small number of large companies. \uf0b7 The US Government gives far more support to business R&D than happens in UK. \uf0b7 US business spends less on R&D in HE than UK business does in UK HE. \uf0b7 The US is now concerned about the weakening of its innovation system, including decreases in business spend on R&D and less business focus on basic research than previously. Also the US is concerned about the poor performance of its university technology transfer system. Some of these trends are similar to those of the UK, though the UK has always had a lower business R&D base and declines of business R&D happened earlier. The UK has always adopted a broader KE approach over a narrow technology transfer approach to universitybusiness linkages compared to the US. \uf0b7 US HERD and technology transfer outputs are very concentrated on the top 10 universities in the US HE system. UK HE is even more concentrated (twice the US system). Outputs even of the top university performers (by patents, licences and levels of BERD) are very diverse. \uf0b7 The US and the UK are very similar on traditional metrics of publications and bibliometrics, with the US slightly ahead. There are strong research linkages between the two nations. \uf0b7 On international league tables of innovation, the UK is tending recently to rise, and the US to fall, particularly on university related dimensions. \uf0b7 US university-business interactions tend to be fewer and deeper than the UK. US forms are more focussed on 'public space' functions of universities and technology transfer and teaching based linkages. UK businesses use a wider range of innovation sources, and their linkages are wider but shallower than those in US. The UK focus is more on research commercialisation. The US HE system seems more successful in making linkages with smaller companies than the UK system does.\nA 2010 report from the US National Research Council (2010) suggested that \"addressing metrics for quality as well as quantity of technology transfer activity, the report addressed all of the avenues of transfer and judged UK institutions on the whole to be well ahead of those in the United States\". It also noted that one of the main reasons for this was the systematic data collection effort in this area through the UK HE-BCI survey which covers a broad range of KE activities, and seeks other, more qualitative information on how the process is supported. It argued that the metrics programmes in the US at that time (pre-2010) were much narrower, but that the various national level metrics programmes -such as those by the NSF, AUTM and APLU were 'in flux'. This report therefore sought to determine the state of metrics development in the US in an attempt to assess whether it will be possible to develop a broader set of comparable metrics on which to make a more systematic comparison of the role and value of the university base in the two systems."}, {"section_title": "Part II: Developments in Metrics to Capture University Knowledge Exchange and the Contribution of Universities to the Innovation System", "text": "Part II initially presents a conceptual framework for informing KE metrics development. This formed an important underpinning of the discussions in the US given differences in the way universitybusiness linkages are positioned and defined in each country. The framework allowed discussions to centre around a common understanding of our definition of KE. There is then an explanation of the drivers for metrics development in the US, in particular relating to pressures on universities to demonstrate their contributions to economic growth and innovation, as well as demonstrating value for money as a condition of substantial budget commitments to stimulate the economy during times of extreme federal budgetary pressures. An extensive account is then given of all the existing US data sources in the relevant area, as well as new metrics initiatives, with a view to informing UK analysis and research on these topics. Finally some conclusions are drawn for prospects for improved US-UK KE comparisons in future. ]"}, {"section_title": "A Framework for Assessing the Value of University KE", "text": "A main focus of the examination of literature and discussions in the United States on KE was to assess opportunities to move beyond the existing points of comparisons given in Part I and to try to identify the nature and direction metrics development -primarily at the national level -to explore the potential for more meaningful and extensive KE comparisons in the future. Given current differences in organising frameworks for exploring KE and the large structural differences in innovation systems, considerable work was needed to explain to US audiences what was meant by KE from the UK perspective. This section therefore focusses on defining what is meant by KE (given that terminology varies in different countries), which then informed interviews and other evidence compilation. The assessment of the value of KE between universities and external partners needs to be framed within a conceptual framework that allows us to locate the activity within a wider system that is involved in translating university-based knowledge into economic and social value. Adopting an innovation system perspective, Hughes and Martin (2012) argue that the impacts arising from public investment in research will depend substantially on the capabilities and complementary investments by other actors in the innovation system to access and exploit the knowledge generated within the public research base. They argue that, as one of the main functions of universities in the system is to be inventive -to achieve new understanding of natural phenomena and technologies -that of the firm in knowledge economies is to turn knowledge into economically viable innovations. Therefore \"the central policy concern is not the relative impact of one expenditure form to another. Instead, it is a classic systems problem, namely how best to manage the boundaries between these two relatively specialised organisational forms so as not to damage the role played by the other\" (ibid, p.13). KE funding is therefore targeted at addressing this key systemic failure to strengthen the pathways through which knowledge can be accessed, exchanged and exploited to create economic value. The multiplicity of pathways that exist is now well researched (see, for example, PACEC/CBR, 2009; Hughes and Kitson, 2012; Ulrichsen et al., 2010. Figure 5.1 sets out a framework for analysing these pathways which act to link the university system with the wider innovation system, with a view to the exchange of knowledge and hence creation of economic and social value. It highlights the interconnectedness of research and teaching activities and the richness of the mechanisms by which universities engage with those in the economy and society seeking to use the knowledge created. Importantly, it seeks to distinguish between the 'traditional' knowledge diffusion mechanisms of academic publications and the movement of undergraduate and graduate students into the economy, from the more direct linkages that are created through what is increasingly being termed KE. Examples of this type of activity are provided in the shaded box in the centre of the diagram. This report focusses primarily on the metrics for capturing the performance and impacts of university KE activities as defined in this framework. As Hughes and Martin (2012) point out, assessing impact \"involves both the presence and effectiveness of the mechanisms or pathways by which knowledge is exchanged and connections made, but also the extent to which the nature of the pathways or connections between the public and private sector domains influences the direction and nature of the research in the former\" (p.13)."}, {"section_title": "Figure 5.1: Framework Positioning KE Activities Within the Wider Set of Knowledge Diffusion Mechanisms", "text": "Coupled with the fact that the ability of the public investment in universities to generate impact requires sufficient capabilities and complementary investments by other actors in the system, Hughes and Martin (2012) conclude that assessing impact becomes very challenging."}, {"section_title": "Empirical issues", "text": "Assessing the impact of public policy investments in the UK -and indeed elsewhere -often involves employing a logic chain framework such as that outlined in the HM Treasury Green Book (which provides guidance on policy appraisal and evaluation) and the Magenta Book (which provides indepth guidance on impact evaluation in the UK) (HM Treasury, 2004 and HM Treasury, 2011 respectively). The concept behind the use of logic models in policy evaluation is to provide a link between the inputs provided by the policy to the activities funded by it, the outputs generated, the outcomes these result in, and the impacts realised ( Figure 5.2). In addition, because investments targeting the strengthening of the boundary between universities and the wider innovation system typically seek to affect the behaviour of those at the interface (Hughes et al., 2011), the logic model set out in HM Treasury (2011) has been adapted to explicitly include this type of effect. Such models are commonly used in the UK to evaluate these types of policies, for example: evaluation of the English third stream (HEIF) funding programme (PACEC/CBR, 2009); evaluation of the Scottish SPIRIT demand-led KE funding programme (PACEC, 2012) and the UK Technology Strategy Board's Collaborative R&D Grants programme (PACEC, 2011). Figure 5.2 also highlights the need to explore whether the outcomes and impacts realised would have happened in the absence of the intervention: what is termed the 'counterfactual'. Assessing this can be done in a variety of ways, but often requires a number of strong assumptions to be made (Hughes and Martin, 2012). In addition to the counterfactual, one also needs to consider the extent to which public intervention leads to activity which substitutes or displaces private sector activity. Hughes and Martin (2012) outline literature that shows that public investments in research are often complementary to private investments, rather than substituting for them. In addition, Hughes et al. (2011) suggest that those KE activities that involve undertaking original research (for example, on a contract or collaborative basis) or those involved in directly translating original research into a format that can be exploited by an external organisation (including training based on original research), are much less likely to be displacing than those involved in presenting existing research or educational material. Capturing and measuring outcomes and impacts, let alone monetising them to establish cost-benefit estimates as is often demanded by policymakers to assess the value for money of their investments, is incredibly challenging and often not feasible. The feasibility of assessing value for money \"depends upon the complex cumulative nature and scope of the public support and the possibility of identifying a counterfactual to compare the actual situation to. ... If the relationship between final outcomes and the policy interventions are complex or 'distant' with many potential confounding factors, then a quantitative empirical impact evaluation is significantly less feasible. The same will be true if the effects build up gradually over an extended period of time.\" (Hughes and Martin, 2012, p. 17)."}, {"section_title": "Figure 5.2: Stylised Policy Evaluation Logic Model", "text": "However, regardless of the feasibility of measuring and quantifying impacts and assessing the counterfactual, understanding the processes by which the changes occur, from the investments made to the activities funded and outcomes and impacts arising from these, is a critical part of the logic model. Hughes and Martin (2012) therefore note the important emphasis on understanding the process as a guide to policy evaluation. They note that it is these connections and pathways between the different stages of the logic model that form the core of an innovation systems based approach to policy analysis and evaluation."}, {"section_title": "Figure 5.3: Relationship between time, attribution and impact", "text": "Source: Hughes and Martin (2012) Reflecting these challenges, Hughes (2012) adapts and extends the Treasury logic model to frame the analysis of the impacts arising from investments into the public research base ( Figure 5.3). Critically, while the logic model has a linear feel to it, as Hughes and Martin (2012) have argued, the model must recognise the processes through which the impacts are realised and hence the important feedback loops between the different stages and the diversity of pathways through which knowledge can flow. In addition, the framework of Hughes (2012) explicitly recognises the temporal dimension over which the movement through the different stages of the logic model may take place. The time-lags between investments and impacts in the case of investments in the university base may be very long (20+ years in some cases), and will inevitably vary discipline by discipline, project by project, and sector by sector. The framework also demonstrates the increasing importance of complementary assets in the process of realising socio-economic impacts from the original knowledge generated as the process moves further away from the initial investments; and the increasing difficulty decreasing ease of attribution of final impacts to the initial investments. Hughes and Martin (2012), by adopting the framework in Figure 5.3, bring out a number of key issues in analysing the impacts arising from investments into the university base: \uf0b7 The critical importance of complementary assets which may be well beyond the control of the public sector and may condition the scale of the impacts arising from the investment. This makes it important to position the university base and its activities within the wider innovation system. \uf0b7 The long time-scales involved in the process and the extreme uncertainty that is often accompanied by this type of investment. \uf0b7 The 'skewness' of the returns to innovation and hence the impacts of funding to support the translation process. This implies that many research efforts may yield low or no impact with a small number of activities dominating the impact. This underlines the importance of portfolio based analyses of research activities and must accept 'honourable dead-ends' in research. \uf0b7 Some types of impacts can be difficult to measure and proxies may be hard to obtain, leading to underestimation of the wider benefits and the overall impacts. They argue that the emphasis on the importance of understanding the processes by which impacts occur for the reasons outlined above lends itself to a 'narrative' approach to impact assessment (Hughes and Martin, 2012, p.21) which combines both quantification where possible with qualitative assessments of behavioural impacts, and measures of different kinds of outputs at each stage in the logic model. This is echoed by a report in the US (Olson and Merrill, 2011) which argues that there are dangers in relying too heavily on performance measures alone, given the types of limitations outlined by Hughes and Martin (2012) above and the potential for mixed signals to arise. A key message from this US report is that policymakers have a tendency to oversimplify what is a complex system that translates research outputs into innovations and economic/social wealth, drawing simplistic connections between inputs, outputs and outcomes. One contributor to the report suggests that rather than creating performance metrics that fit into the simplistic narrative, an effort should be made to improve the narrative. It suggests that case studies could play an important role in revealing the complex processes at play in the exploitation of research. These can help to produce \"synthetic systems-oriented insights that can have a powerful and enriching impact on policy making and 'hopefully, change the narrative\" (Olson and Merrill, 2011, p.14). Hughes and Martin (2012) also argue that the long time-scales and uncertainties involved between investment and impact suggest that evaluations assess changes in the intermediate level activities and outcomes, rather than focussing solely on final impacts (ibid, p.22). These include not least the behavioural changes that affect the choices of those involved at the different stages of the process."}, {"section_title": "Developing metrics", "text": "The above framework helps to focus the development of appropriate metrics that capture the different parts of the logic chain relating to KE activities between the HE base and users in the wider innovation system. Martin (2007) "}, {"section_title": "Deploying the framework", "text": "The above framework guided our interviews when exploring the different metrics being developed to capture KE. This was important because the term KE, as a unifying concept bringing together the broad range of activities that create direct linkages with users through which knowledge can flow, is less well accepted and understood in the US. The discourse often surrounds categories of KE such as technology transfer (spin-outs and licensing), commercialisation (including industrially sponsored research) and local economic development related support and outreach (providing support to local and state-wide companies which can include incubators, technology accelerators, science parks, training etc.).   "}, {"section_title": "KE Metrics Development in the US", "text": "As the introduction to this report noted, US metrics efforts in the area of knowledge and technology transfer/exchange are in flux, with different national-level organisations seeking to improve the breadth and depth of indicators available. Part I described some of the existing metrics that can be used in comparisons with the UK. Historically, key data related to R&D activity within the HE sector, including that funded through direct linkages with industry, have been captured by national surveys of HEIs. Similarly, data on knowledge diffusion through the traditional mechanisms of publication -including, importantly, copublication with industrial partners -are well established. In addition, the US has also for a long time measured the hard technology transfer activities of spin-outs, licensing and IP revenues through the well respected AUTM surveys. In the past few years there have been developments in KE-related metrics that attempt to go beyond these narrow KE mechanisms. These include a key programme of work ongoing at APLU and STAR Metrics, a multi-agency venture led by the NIH, the NSF and the White House Office of Science and Technology Policy (OSTP). AUTM has also recently reviewed the development of KE-related metrics and its role in the process."}, {"section_title": "Growing Pressures for Metrics Development in the US", "text": "Before presenting the key developments being made by different national initiatives, it is useful to outline why this debate is brewing in the US innovation system (reflecting some of the trends described in Part I). . They also emphasize the imperative to understand the processes and mechanisms through which knowledge moves between the research base and the production base. Coupled with these developments is growing pressure to better measure and demonstrate these benefits (APLU, 2011). This was reflected in a key recommendation of a recent report on managing university IP in the public interest (National Research Council, 2010 \uf0b7 Benchmarking accomplishments against historical or international measures and advocate for particular actions. Our interviews found that there is growing pressure from politicians to provide more robust evidence to justify their allocations against other priorities such as entitlement programmes, justice and education spending. There is a realisation that existing tools cannot satisfactorily meet their needs, in particular the reliance on aggregate measures and anecdotes. Traditional metrics of R&D spending as a share of GDP, publication rates, patent and citation counts etc. provide only limitedand potentially misleading -insights into the performance of a nation's research base. The measurement of science investments is a rapidly developing area of research, with a maturing community of scholars and practitioners. Developments include more refined measures, better data, and new estimation techniques. The latter include scorecards that compile measures nationally and internationally. Key efforts at the national level include the STAR Metrics programme and the APLU metrics programme, though significant difficulties remain."}, {"section_title": "Measuring National Level Research Activity within the HE Sector", "text": "The US, as in the UK, captures a range of evidence on research, development and innovation activity in the HE sector and in the private sector through large-scale, national surveys."}, {"section_title": "HERD survey", "text": "As in the UK, the US captures the amount of research activity -measured by the value of research grants -received by universities through the HERD survey managed by the NSF. This survey captures a wide range of metrics associated with R&D activity in the HE sector in the US including the following variables 4 : The HERD survey has been conducted annually from 1972 collecting information on R&D expenditures by academic field as well as by source of funds, focussing primarily on science and engineering (S&E) fields. This provides a valuable longitudinal dataset of how different types of research activity have evolved over time. However, from 2010 onwards, the survey was expanded to capture R&D within non-S&E fields. Previously, non-S&E R&D was reported but not included in the overall totals. In addition, the survey now includes expenditures on clinical trials and research training grants."}, {"section_title": "Business R&D and Innovation Survey", "text": "Another key national survey conducted by the NSF is the new Business R&D and Innovation Survey (BRDIS) which focusses on gathering information on innovation in the private sector in the US. The first year for the new BRDIS was 2008, replacing the former Survey of Industrial Research and Development which had been ongoing since 1957. The redesign was motivated by the need to capture the dramatically changed landscape in which business operated and the way in which it innovates. Importantly, the changes reflect the following key changes 5 : \uf0b7 The economy was manufacturing based; now it is largely service based. \uf0b7 R&D was conducted in company-owned central labs; now it is much more dispersed. \uf0b7 Government was the largest funder of R&D; now it is business. \uf0b7 Companies had primarily a domestic focus; now they have a global focus. The new BRDIS now explicitly explores the R&D partnerships that companies have with different sectors, including universities (by value of R&D performed). In addition, Question 4.37 of the survey asks companies whether they have performed \"any of the following activities with universities, students, or academic faculty... a) Hired academic consultants for short-term projects in science and engineering b) Hosted student interns pursuing undergraduate or graduate degrees in science or engineering for at least one month c) Hosted post-doctoral fellows in science or engineering for at least one month d) Had scientists or engineers from your company who served as visiting scientists or engineers at a college or university for at least one month e) Made monetary gifts to universities or colleges that were restricted to supporting R&D\" While the survey only allows for Yes/No responses to the above questions it does provide important detail as to the different mechanisms being used other than the direct funding of R&D in universities."}, {"section_title": "The Regional Economic Role of Universities: Metrics Development at APLU", "text": "APLU is a research and advocacy organization of public research universities, land-grant institutions, and state university systems. It has seven commissions that focus on key areas in HE, one of which is the Commission on Innovation, Competitiveness and Economic Prosperity (CICEP). One of the key aims of this commission is to lead \"efforts to bring clarity and visibility to the impact of APLU institutions on local and regional innovation, competitiveness, and economic prosperity.\" To help achieve this, it has a developed a number of initiatives, including: \uf0b7 Assessment Tools: Institutional assessment tools to enhance regional innovation and prosperity. \uf0b7 Economic Impact: Collaboration with the Association of American Universities and Bureau of Economic Analysis to develop guidelines for a standard approach to measuring and reporting university economic impact. \uf0b7 Metrics: Identifying new measures of university contributions to regional economic growth."}, {"section_title": "Measuring university contribution to regional economic growth at APLU", "text": "The motivation for APLU's efforts to develop new metrics centres on the need to better demonstrate the broader \"sweep of contributions to regional economies made by public universities\". These included (Freeman, 2012): Since then, APLU has been working closely with its member institutions, HE associations, federal agencies, and other national stakeholders, to identify and investigate the efficacy of potential metrics in this area. The focus was on identifying data that complements and expands upon information that is currently available through other sources such as the NSF HERD survey, the AUTM annual Licensing Activity Survey, and the STAR Metrics initiative (each of these will be discussed in this report). This work led to the identification of a wide range of metrics (in excess of 50, APLU, 2013) within the following categories of activity: 1. Relationships with industry 2. Developing the regional and national workforce 3. Knowledge incubation and acceleration programmes"}, {"section_title": "Relationships with industry", "text": "This first category stretches well beyond the traditional focus on technology transfer of research outputs through spin-outs and licensing activity recognising the importance of the wide range of mechanisms through which knowledge can be exchanged both from academia into industry and vice-versa. APLU (2013) argues strongly for the importance of the relationship in helping to shape the research agenda of academics, and the mutual benefits that can arise from the exchanges."}, {"section_title": "Developing the regional and national workforce", "text": "The second category of proposed metrics focussed on the contributions made by universities to the development of the regional and national workforce through students and alumni. They cite a range of important contributions including: \uf0b7 Developing knowledge and workplace skills valuable to both the student and their future employers through working on funded projects or placements with employers. \uf0b7 Contributing to enterprises where they work while a student, and to the specific project teams. \uf0b7 Using the income they receive to help offset the costs of their education. \uf0b7 Developing entrepreneurial skills through university academic courses and programmes, competitions and other related activities. \uf0b7 Starting up businesses while they are at university and/or becoming involved in new businesses upon graduation. APLU argues that the contribution of talent to the local and regional economies is probably the most important contribution most universities make to economic prosperity. The challenge then becomes how to retain students within their states upon graduation."}, {"section_title": "Knowledge incubation and acceleration programmes", "text": "The final category of metrics -knowledge incubation and acceleration programmes -attempts to capture metrics associated with the contribution universities can make by acting as local or regional centres for the development of new businesses (APLU, 2011). Some of these businesses may be exploiting technology originating from the university e.g. through purchasing a license to exploit a particular technology. However, universities often provide support for wider cohorts of local and regional businesses to support their development and growth. Examples cited in APLU 2011include providing mentoring and business plan support by specialist staff; providing physical space such as incubators or science parks; and providing technology acceleration programmes."}, {"section_title": "Narrowing down the metrics", "text": "APLU engaged with 35 of its members to pilot the metrics, focussing on both the feasibility of collecting the data and the 'utility' of the long list of initial metrics proposed. Following the pilot programme, it convened a workshop of APLU members, key stakeholders and experts to discuss the outcome of the pilots and narrowed the metrics down to the 20 thought to provide both the highest level of utility while remaining feasible in terms of the burden of data collection. These are shown in Table 6.1. The workshop raised the importance of ensuring complementarity with other national data collection efforts and developments, including those of AUTM, STAR Metrics, the National Institute of Standards and Technology (NIST), and the National Academy of Sciences (NAS). \uf0b7 AUTM has been developing an institutional engagement index which goes beyond hard technology transfer (see later in this report). \uf0b7 NIH/NSF are developing STAR Metrics, an automated system for capturing the impacts of federally funded research activity (see later in this report). \uf0b7 NIST is leading an effort to upgrade the metrics and develop best practice for federal agencies investing in science and involved in technology transfer. There is a growing recognition of the contribution of federal agencies to areas of technology transfer beyond the hard metrics of spin-outs and licensing, including, for example, education of postdoc students, publishing of peer-reviewed papers disseminating knowledge, and participating on standards committees. \uf0b7 NAS has been undertaking a project for the NSF National Center for Science and Engineering Statistics to develop policy-relevant, internationally comparable statistics on science, technology and innovation (STI), although more generally than those activities underpinned by university activity. \uf0b7 Nationally collected data on industrially sponsored research grants. \uf0b7 US Association of Small Business & Entrepreneurship on entrepreneurship data. \uf0b7 National Business Incubation Association on data associated with university-based incubators. However, as with many new data collection efforts, concerns were raised over the increased burden that this would place on universities. There was a view that universities already had large reporting requirements to different stakeholders: some mandatory such as state and federal funders, and some voluntary but established such as the AUTM surveys. Every effort therefore had to be made to collect only necessary data and to ensure that every attempt was made to leverage existing data provision by ensuring common data definitions. The pilot and focus group discussions during the October 2012 APLU metrics workshop also led to a number of key findings regarding the development of metrics (APLU, 2013): \uf0b7 The process of developing new metrics in itself has had value in raising awareness of the role and contribution of HEIs to economic development among key institutional and regional players. \uf0b7 There is a distinct need for new methods to measure university-based activity and its impact on the economy and wider society. Advances in metrics in this area will help to serve two key purposes: o Provide a national perspective on the efficacy and effectiveness of particular economic engagement programmes and initiatives of universities. o Provide universities and their stakeholders with baseline data from which to describe and evaluate the role of the institution in the regional economy. \uf0b7 Many metrics in this area capture the outputs of university activity. However, there is a need to go beyond output metrics better to understand the outcomes (e.g. jobs created). However, there is also an important recognition that many economic engagement activities of universities may not necessarily lead to direct outcomes. \uf0b7 There is a need to be able better to disaggregate national level data to more granular levels to make it more relevant to local and regional stakeholders. \uf0b7 Data -especially at the regional level -need to be embedded in a narrative about the institution's economic engagement activities. There was a consensus that 'data without explanation and context have little value'. \uf0b7 Data collection for the proposed metrics was challenging for the pilot institutions, either because there was no central data collection point for activity that was diffused around campus or because the institution had not collected the data. \uf0b7 Collecting the necessary data was resource intensive, often requiring at least one staff member or equivalent, which was difficult to justify during periods of tightening budgets. The discussions revealed significant disparities between institutions regarding the existence and feasibility of collecting specific types of data. \uf0b7 There was a potential for data overlap and duplication with other surveys and data collection efforts which needed to be minimised. Reflecting the above, APLU issued the following recommendations: \uf0b7 Contextualise the data: Data must be presented within a broader narrative that explains the meaning and value of the data, at both the regional and national level. \uf0b7 Avoid use of data for comparison: Use of collected data should discourage, to the extent possible, comparisons across dissimilar institutions with different missions, priorities and resources. \uf0b7 Recognise human resource constraints: Given the tightening budgets of many universities, any new data requirements need to be balanced against the overall resource burden on the institutions as well as the feasibility of collecting the data. \uf0b7 Standardise industry data: The workshop highlighted an important need to adopt a standardised framework for recording industry related data in order to generate comparable data. Existing systems such as the NAICS codes provide a potential standard, but there are questions as to what level is appropriate (three-digit/four-digit etc.). \uf0b7 Create an information clearinghouse: There is significant potential for the duplication of data requests and effort with numerous organisations collecting -or considering collectingdata relating the economic engagement activities of universities. A publicly available, national clearinghouse or central database of current and planned surveys would help to avoid such duplication of effort. \uf0b7 Facilitate federal agency cooperation: Useful outcome data (e.g. on employment and wage outcomes of university graduates) is held by a range of governmental agencies and access to this could be facilitated by improved intergovernmental collaboration."}, {"section_title": "STAR Metrics: An Automated System for Capturing Research Activity and Impact", "text": "STAR Metrics is a multi-agency venture led by an interagency consortium consisting of the NIH, the NSF and the White House OSTP. It also involves the Department of Energy and the Environmental Protection Agency (EPA). It is, at its core, a partnership between the federal government and universities to document the outcomes of science investments and directly link these back to the federal government's investments in research."}, {"section_title": "Origins and motivations of STAR Metrics:", "text": "The seeds of STAR Metrics can be traced back to frustrations in the mid-2000s with the inability to provide evidence-based assessments of how to optimise the federal investments in the science base, including both the level of investment and its allocation (Olson and Merrill, 2011). Indeed, the National Science and Technology Committee's Interagency Working Group on the Science of Science Policy identified the lack of data as a critical gap in developing evidence based science policy (Lane and Bertuzzi, 2010). The challenges with providing a robust evidence base on the allocation and impact of investments in the science base came to the fore with the passage of the 2009 ARRA which invested billions of dollars in the US science base. There was a belief among key political constituencies that innovation and research needed to become the centrepiece of the economic strategy for longer term economic growth. A key part of the evidence base underpinning this decision was derived from methods for estimating the impact of science based on input-output methodologies (Lane and Bertuzzi, 2010). Such approaches are based on spending flows and \"functionally equates the impact of science to the impact of building a football stadium or an airport: the impact is derived from the demand side, and depends on the amount of spending on bricks and mortar and workers.\" (Lane and Bertuzzi, 2010, p.3). Given the political focus on jobs, a key requirement of the stimulus package was the need to demonstrate that the investments were resulting in creating or retaining jobs in the US. However, as an interview with the co-chair of the STAR Metrics programme noted, universities are very different from other types of recipients of the stimulus funding such as local government. One key difference was, unlike the latter, universities don't often have 'shovel ready' projects that can be rolled out immediately. University-based investments take time to ramp up and even longer for the impacts to be realised (unlike the building of a road). In addition, as has been mentioned a number of times in this report already, the pathways to impact for university-based investments are highly complex and can often be very difficult to quantify and measure. The stimulus funding required quarterly reporting on jobs created or retained. This was vastly different from what universities were used to and would potentially have placed significant reporting burdens on the organisations. This was a key motivation for establishing STAR Metrics. The initial development of STAR Metrics was greeted with a lot of scepticism and with universities needing to be convinced on the value of sending their data to the database. They were worried about benchmarking and the implications for funding allocations and for misinterpretation of the data. An interview with one of the key individuals leading the development of the system suggested that the following factors were critical for overcoming these barriers: \uf0b7 The importance of developing trust with the universities. \uf0b7 Developing an inclusive process, focussing on being part of a team \uf0b7 The importance of the pilot project with just six universities before rolling it out to over 100. One key incentive for universities to engage was highlighted in an interview with one of the founding partners (a private university). The reporting requirements for the stimulus package were potentially heavily burdensome. The STAR Metrics system provided a way to reduce this burden in a way that other methods could not. Another incentive was the growing need to demonstrate their value to local stakeholders, going beyond anecdotal information and a 'spiritual belief' that universities were valuable. This provided a unique source of data that hitherto had not existed within universities, contributing valuable management information to university leaders on their portfolio of research activity."}, {"section_title": "STAR Metrics: an overview", "text": "The objective of STAR Metrics is \"to create a data infrastructure that will permit the analysis of the impact of science investments using administrative records as well as other electronic sources of data\". It was built on three principles (reproduced from Lane and Bertuzzi, 2010, p.5): 1. To use the right unit of analysis focussing on scientists and the creation, dissemination and adoption of knowledge. 2. To use current technology, taking advantage of technologies to automate data collection. 3. To collaborate with the scientific community to understand the appropriate data and metrics that should be used to describe the creation, transmission and adoption of knowledge in their fields. The programme is being implemented in phases ( Figure 6.1). Key outputs from Phase I include the following variables, assessed on a quarterly basis, and available in different forms such as per grant, per dollar of funding or by agency providing the funding: Importantly, it aims to create a platform that links inputs to outputs/outcomes, which is often lacking in many performance evaluation systems. Central to the ethos of STAR Metrics is exploring the ability to use state of the art digital technologies to collect and capture the scientific, economic, social, and workforce impacts of science investments. Phase 2 is still in development and ideas are being put forward (Lane and Bertuzzi, 2010) including:"}, {"section_title": "Figure 6.1 STAR Metrics", "text": "\uf0b7 Use existing administrative data -for example from the US Patent Office -to link patent data and associated critical publications back to federally funded research. This should allow the system to trace the knowledge flow and potentially the mobility of researchers in the system, and identify link of academic principal investigators to the private sector. \uf0b7 Match administrative records of universities to the data held by statistical agencies. This could help link undergraduate and graduate students, and postdoctoral researchers to jobs they take up subsequent to their work on federally funded research projects. It would also allow the tracing of employment and income trajectories and tie this to the firms and industries in which they work. \uf0b7 Greater exploitation of the cyberinfrastructure which can create flow reports of citations, patents, and publications using web-scraping techniques both during and after federally funded research projects. Some of these techniques will require advances in techniques to capture data and confronting how to use confidential and potentially highly sensitive data, but Lane and Bertuzzi (2010) note that these issues are being developed and addressed by a range of researchers, agencies and others. They conclude that, \"in general, it will be necessary to build an open access, cyberinfrastructure enabled, collaborative environment which can be used so that the research community can collaborate with the federal agencies to generate summary indicators about where science investments have been and are being made, together with information about the economic, social and scientific impacts over space and time\" (Lane and Bertuzzi, 2010, p.10). A recent presentation by Bertuzzi et al. (2011) identifies portfolio characterisation as a potential 'product' of STAR Metrics. This has the potential to enable funding agencies to perform gap analyses to determine what is being funded in which areas by the federal government and help these agencies locate expertise in key topic areas; helping researchers find other programmes that are being funded similar to their research topics and other researchers in similar areas; and help senior university leadership identify their institutional strengths. Another 'product' identified is the R&D dashboard helping to provide key stakeholders with evidence on what research is being funded in their state/city, the researchers active in key areas, and the outputs of this research."}, {"section_title": "Building on Technology Transfer Metrics at AUTM", "text": "Another key source of metrics providing evidence on KE between universities and users in the economy and society is AUTM. The core focus of AUTM is the commercialisation of research through technology transfer and this is reflected in the metrics it collects."}, {"section_title": "AUTM Licensing Activity Survey", "text": "AUTM runs what is perhaps the most well known (and well used) survey of university commercialisation activity -the AUTM Licensing Activity Survey. This survey now goes back over 20 years with the first survey dating back to 1991. This survey collects data on the licensing and spinout activity of its members. Table 6.2 shows the range of metrics collected by the survey collects 6 : \uf0b7 $36 billion of net product sales were generated (69 institutions responded to this question from a total of 186 respondents to the wider survey). \uf0b7 Start-up companies from 83 responding institutions employed 24,653 FTEs. However, AUTM did note that some respondents were unable to give answers to the above questions as data was not readily available and that this is an area of development for the organisation."}, {"section_title": "Other AUTM surveys", "text": "In addition to the licensing survey, AUTM also run a number of other surveys that build the evidence base on the commercialisation of research. Since 2004, they have run the AUTM Salary Survey, a \"worldwide survey of compensation and benefits of academic licensing professionals and organizational structures of offices performing technology transfer\" 7 . Importantly, in 2009, they decided to run a 'transaction survey' which explored the activities of technology transfer offices beyond licensing, recognising that \"royalty revenue metrics can lead to a misunderstanding of the scope of work and duties of a technology transfer office both within our professional community and in the eyes of policy makers and senior university administrators\"."}, {"section_title": "Development of an institutional economic engagement index", "text": "Reflecting the recent growth in the pressure better to understand and demonstrate the contribution of universities to the economy, AUTM spent three years exploring new metrics for technology and knowledge transfer (AUTM, 2011b)."}, {"section_title": "Figure 6.2: Framework Positioning KE Activities Within the Wider Set of Knowledge Diffusion Mechanisms", "text": "Source: Library House (2008) The approach taken by AUTM built on the framework which seeks to explain the relationship between universities and the wider innovation system developed at the University of Glasgow (Library House, 2008). As a result, it has clear links with the metrics available in the UK through the HE-BCI database. The complexity of the innovation system into which the university links led AUTM to emphasise a 'basket' of metrics rather than trying to develop a simple direct measure of university economic impact. They explored metrics in the following categories (AUTM, 2011b): This resulted in a 'proposal' of metrics which aim to capture the breadth of mechanisms through which universities contribute. Details of the metrics proposed in each of the above categories can be found in Appendix C. However, the metrics proposed do not represent the intention of AUTM to collect them all, but rather an attempt to guide data collection and synthesis efforts of individual institutions as they seek to capture and present their contributions. It recommends that these metrics are brought together in a single report at the institutional level, with institutional senior administrators best placed to do this. Importantly, it emphasises the importance of embedding the reporting of the metrics within the specific context of the given institution. AUTM (2011b) argues that the \"city; local, regional and national government; business support services and policies; funding; etc. all impact what an institution can do. In addition, once an organization external to the research institution has control over a research institution asset, that external organization's actions are much more critical to any potential impact than the institution's activities\". The AUTM proposal makes an important point that the final economic impact is created by the partners of universities rather than by the university itself. In realising these final economic impacts, the partners are subjected to many other external factors beyond the control and influence of universities that will shape success. Coupled with APLU's efforts, it represents possibly the effort which most closely reflects the concept of KE we focus on here in the UK. It worked with US HE associations, governmental organisations and non-profit groups to identify the new metrics."}, {"section_title": "AUTM Better World case studies", "text": "In addition to the now well established AUTM surveys outlined above, the organisation also systematically collects case studies through their 'Better World Project' to \"promote public understanding of how academic research and technology transfer have changed people's way of life and made the world a better place\" (AUTM, 2011c). The case studies are drawn from its members and help to raise awareness of successes and provide many stories of the products and services that would not have existed without technology transfer. Each year has a loose theme that runs through the case studies. Previous titles and descriptions are outlined in Table 6.3 below. The project addresses a need to bring an much greater understanding and appreciation of the academic origins of successful technologies and products that are impacting people's lives in real ways which \"too often \u2026 have been forgotten or lost in the passage of years, or simply never told\" (AUTM, 2006). At its heart, they seek to bring the story of how academia impacts on society to the human level; how the research that is undertaken impacts on real aspects of people's lives in order to make the process of the contributions made by universities and their academics accessible. The case studies focus on telling the story of how the seeds were sown for the innovation including the ideas and key underpinning research undertaken in the university base. They then go on to outline how the research was commercialised and taken to market. There is naturally a heavy focus on the impacts resulting from the innovation. However, the emphasis is on bringing to life the human level impacts of the technologies rather than trying to get to quantifiable and monetisable estimates of impact."}, {"section_title": "Estimating the economic impact of licensing activity using AUTM data", "text": "There have been some important attempts to exploit the AUTM data to estimate the economic impact of university inventions from US universities through licensing activity (see for example, Pressman et al., 1995, and a more recent study by Roessner et al., 2013). The models look at two important areas of impact: on post-production sales and jobs (Roessner et al., 2013) and on preproduction investments (Pressman et al., 1995). Pre-production investment is defined as \"money spent developing new products and efficient ways to produce and market these products. It excludes the costs of producing (or investment required to produce) mature products\" (Pressman et al, 1995, p. 28)."}, {"section_title": "Estimating the pre-production impact of licensing", "text": "The 1995 study by Pressman et al., based at the MIT Technology Licensing Office, looked at the economic impacts of licensing activity through inducing investment from private sector firms in developing innovations from technologies arising from the university base. This was designed to complement estimates then being made by AUTM staff on post-production product sales and jobs created. Data was obtained through a survey of a sample of MIT licensees on pre-production investments and jobs created through the licenses. Based on their survey sample -drawn from MIT's 1993 portfolio of 205 active exclusive licenses -they found that the total self-reported investment was $205 million, and 470 FTE jobs were generated. They then extrapolated this to the MIT portfolio, finding that the licenses generated an induced investment of $922 million and employment of approximately 2,300 FTEs. Extrapolating further to the wider university sector based on data from the AUTM surveys (based on two different methods), the authors estimated that university licensees generated between approximately $2.5 billion and $5 billion in pre-production investment per year depending on the method used. These investment levels were estimated to contribute between 20,000 and 40,000 jobs to the national economy-before sales of licensed products. A similar study by Kramer et al., 1997) at the University of Pennsylvania's Center for Technology Transfer confirmed these results. Following the same method, they found that exclusive patent licenses at the University of Pennsylvania generated $151 million in induced investments and created 242 full-time equivalent jobs. Extrapolating to the wider university base, they estimated, using 1995 AUTM data, that such licenses generated induced investments of $4.6 billion and 27,000 jobs created per year nationally."}, {"section_title": "Estimating the post-production economic impact of licensing", "text": "Attempts have been made to estimate the post-production economic impact of licensing activity from US universities. Prominent examples include a model developed by AUTM (outlined in Pressman, 2002) and a more detailed model developed by Roessner et al., (2013). Both models exploit the assumption that royalty agreements are often based on a percentage of sales of new products developed using the university IP (Roessner et al, 2013). Combining data on royalty rates with licensing revenues can yield valuable insights into the total product sales associated with the university IP. Census or other data can be used to estimate the loaded cost of an R&D engineer allowing the conversion of the estimates into a figure for jobs supported by the sales. The Pressman (2002) model -which emphasises the role of licensing activity in stimulating preproduction investments in firms that underpin products and services -used FY2000 AUTM data based on two different royalty rate assumptions. The key findings are shown in the table below. The model developed by Roessner et al. (2013) goes beyond that developed by AUTM and combines licensing data for US universities with national input-output model coefficients to provide a more complete estimate of the national economic impact of university licensing activity. They argue that you have to move beyond sales revenues as these do not themselves represent economic impact. They also argue that university expenditures arising out of royalties from licensing themselves have a significant indirect and induced economic impact that needs to be accounted for in any model. It estimates both the impact on GDP and the impact on other industries' production (gross output). The impacts on GDP account for both the licensing receipts of universities and the outputs resulting from the license agreements. The impacts on gross output (production) include both the direct effect of expenditures of university royalty receipts (including any additional sponsored research flowing to the university as a result of the license) and the indirect effect on the output and employment of the university as well as other industries. The model developed by Roessner et al. (2013) also exploits the assumption that many royalty agreements are based on percentages of sales of products attributable to the university IP. This allows the authors to estimate the direct impact of the university licensed products by using the national input-output model to convert the attributable sales figures into changes in income (compensation, indirect business taxes, and gross operating surplus/profit) of companies \"operating under sales-based university licensing agreements\" (Roessner et al., 2013). In addition, they add the direct contribution of university expenditures associated with the licensing income through gross royalty income supporting salaries within the university, equipment, overhead costs etc., and through expenditures of research income from firms that contract for R&D as a direct consequence of the licensing agreement. Their model estimates that, over the period 1996-2010 assuming a 2% average royalty rate and no product substitution, university licensing activity contributed \u00a3686.9 billion to gross industry output (in 2005 prices). At this rate, the contribution to GDP was \u00a3277.6 billion (2005 prices). At a 5% average royalty rate, the contribution to gross industry output was \u00a3293.3 billion (2005 prices) and to GDP was \u00a3122.2 billion."}, {"section_title": "University-Industry Demonstration Partnership Case Studies", "text": "Another key organisation in the university-industry landscape is the University-Industry Demonstration Partnership (UIDP). It is supported by the Government-University-Industry Research Roundtable (GUIRR) which is in turn sponsored by the US NAS, the National Academy of Engineering, and the Institute of Medicine. The UIDP is \"an organization of universities and companies who seek to build a stronger relationship between these parties\". It provides a forum bringing together university and industry representatives to \"meet and discuss operational and strategic issues such as contracting, intellectual property, and compliance matters\". They argue that \"these conversations might otherwise never take place, and they serve to help university representatives better understand the culture and constraints of their industry counterparts, and vice versa\" 8 . They have produced a range of practical documents which support those involved in the universityindustry research collaboration process both at the operational level and at the strategic level. As with AUTM, they are also working with their members to collect short case studies that 9 : \uf0b7 Provide UIDP members (and other interested parties) with easily accessible examples of successful university-industry (U-I) collaborations to inspire new partnerships and help them recruit partners through these concrete collaboration examples. \uf0b7 Raise awareness of the range of U-I collaboration models. A key feature of these case studies is the emphasis on the role they can play in disseminating lessons learned from successful university-industry collaborations \"to inspire new high value, high return partnerships\" 10 . The case study template has emerged from the work the UIDP and its predecessors have been developing on university-industry partnerships (NCURA/IRI, 2006;UIDP, 2012). The case study template seeks to collect evidence on 11 : \uf0b7 Project type (access to resources; involvement with researchers; economic development; student oriented involvement; involvement with centres of expertise and schools; other) \uf0b7 Parties involved (including whether consortium or 1:1) \uf0b7 Level of engagement (transactional; collaborative; alliance) \uf0b7 Background (including prior working; how idea was conceived; motivations for the project etc.) \uf0b7 Staffing (academics; industry staff; students; disciplines involved) \uf0b7 Role of government (involvement of local/federal funding including source and value, and any nonmonetary involvement) \uf0b7 Budget (importance of financial considerations; co-funding; how funding was allocated if not donated to institution; governance structure) \uf0b7 IP (how ownership of IP was addressed) \uf0b7 Obstacles encountered and how they were overcome \uf0b7 Outcomes (achievements; institutionalisation of relationships; replicability of experience) \uf0b7 Growth opportunities from the project \uf0b7 Measuring success (specific metrics, both financial and non-financial) \uf0b7 Keys to success \uf0b7 Lessons learned To date (spring 2013), seven case studies have been reported on the UIDP website. They do not always report on all of the areas above and are relatively brief in the information provided. The section on measuring success is only reported on in three of the seven cases and lacks much detail. An example of the more detailed responses to the measuring success question is from the BP/Berkeley Energy Biosciences Institute. They outline a basket of measures including: \uf0b7 IP rights, commercial licenses and products are merely three measures of success for an industry/university/government research partnership. Other factors include: students trained, publications, grants, public outreach, new faculty positions, demonstration of collaboration models, innovation acceleration, raising awareness of the modes of academicindustry engagement and outcomes of cooperation, jobs created, the relevance of academic research to manufacturing, improved infrastructure, leveraging of resources, recruitment and retention, economic development, methods of financing translational R&D, and impacts on academic culture and norms. 6.7 Evaluation and Impact Measurement at the NSF 6.7.1 Evaluation at the NSF Metrics exist for the evaluation of specific programmes such as the ERC programme which supports university research in partnership with industry and the Industry/University Cooperative Research Centers (I/UCRC) Program in which each centre conducts research that is of interest to both the industry and the university with which it is involved, relying on the involvement of graduate students in their research projects. However, no systematic framework or common methodology currently exists to permit consistent comparative evaluation. The I/UCRC Program was started in 1973 and aims to develop long-term partnerships among industry, academia, and government. As of 2011, there were 55 active I/UCRCs involving over 100 universities. There were more than 750 faculty researchers along with 750 graduate students and 200 undergraduate students involved in a wide range of projects. The centres are catalyzed by a small investment from the NSF and are primarily supported by industry centre members (90%), state governments and national laboratories and other agencies (10%) concerned with supporting technological development and innovation, with the NSF taking a supporting role in their development and evolution. Leverage of NSF funding is high. Each centre is established to conduct research that is of interest to both the industry and the centre. An I/UCRC contributes to the nation's research infrastructure base and enhances the intellectual capacity of the engineering and science workforce through the integration of research and education. The I/UCRC Program has adopted a customer driven decentralised approach to evaluation whereby each centre is required to submit an evaluation report prepared by an on-site independent evaluator. This is undertaken by conducting a survey of all centre participants using an instrument prepared by the NSF for collecting both qualitative and quantitative data. Process and outcome data are collected annually from member firms and faculties about their satisfaction and a variety of outcomes and impacts. This on-going monitoring is complemented by periodic targeted studies addressing specific issues in more detail. Programme wide evaluation measures include for example: \uf0b7 Impact on R&D: $ value of member follow-on funding triggered by centre research projects. \uf0b7 Impact on R&D: centre member cost avoidance resulting from participation in research that might otherwise have been too risky to do themselves. \uf0b7 Impact on commercialisation: three separate Compendia of Technology Breakthroughs of the I/UCRC Program (2004,2007,2009) have been produced to catalogue industry nominated breakthroughs growing out of I/UCRC research. \uf0b7 Impact on human capital: many students gain their graduate degrees through I/UCRC and faculty directors of IUCRCs have benefited in their career development. \uf0b7 Self-sustaining I/UCRC Impacts: an important goal of the programme has been to create lasting institutional structures (capacity and capability) for cross sector collaboration. Two thirds of centres for example are still operating some 30 years since start-up and years after NSF funding ceased. \uf0b7 Leveraged Industry-University cooperation: IUCRCs have generated industry support for scientific research eight-10 times the NSF funding during their NSF support. The IUCRC annual evaluation reports using a common survey instrument provide a systematic quantitative and qualitative longitudinal monitoring of the performance of the centres and in this respect it provides an important historical record of the programme and is a useful first step towards developing performance and evaluation metrics based on participant responses. The NSF has recently initiated an internal project in the Directorate for Engineering, aimed at developing an infrastructure and methodology for undertaking the evaluation of each of its 75 programmes. The intention is to develop logic models for each of 75 programmes, although not necessarily within a common system of metrics."}, {"section_title": "Sub-National Economic Impact Measurement", "text": "At the sub-national level, publicly funded universities are facing pressures at both the state and city levels to demonstrate their economic and societal impacts. They are required to report on performance in key areas set out by the state such as educational participation and performance, and research activity. Many also commission economic and social impact studies to assess and quantify the impacts of their institution (or university system depending on whether the study is commissioned by an individual university or the wider system). Arguably, it is these state and more local pressures that are one of the driving forces behind the APLU metrics efforts. In addition to such performance monitoring and economic/social impact studies, specific initiatives at the state level or individual university level are sometimes the subject of ex-post evaluation."}, {"section_title": "University economic and social impact studies", "text": "Like universities in the UK, many US universities or university systems commission economic and/or social impact studies. These studies often look at the contribution of the university through a number of mechanisms including: \uf0b7 Direct, indirect and induced economic impacts arising out of the spending of the institution (often the primary focus of many studies), students, and visitors \uf0b7 Contributions to the workforce \uf0b7 Contributions through research \uf0b7 Impacts of capital investments \uf0b7 Contributions to the community and cultural life of their areas Many studies focus primarily on the direct, indirect and induced impacts of university spending and how this feeds into supporting jobs in different sectors of the local and regional economies with the other areas of contribution receiving significantly less attention in terms of quantification. Workforce contributions often focus on the training of students, and in some cases discussions extend to the scale of continuing education in the existing workforce. Some studies look at the location and contribution of their alumni (e.g. the 2006-07 study of UC San Diego, CBRE Consulting (2008) and the MIT 2009 study (Roberts and Eesley, 2009)) These track the entrepreneurial activity of their alumni base and estimate the value to the economy of these companies. However, there are big questions that remain unanswered in such methods regarding how to estimate the attribution of company revenues and employment to university activity. Some studies also estimate the wage differentials of their graduates compared with other graduates and non-graduates to estimate the impact of the university on labour productivity. The contribution of research will often focus on the scale of research activity based on research grants and contracts from different sources (including federal, state and industry). Beyond this, there are often qualitative general statements about the value of research in supporting economic activity, and some studies will quote research which has quantified the return to research investments. Those active in the commercialisation of research through technology transfer will track the standard metrics of university start-ups and licensing revenues and in a few cases such as the 2006-07 study of UC San Diego, report on the scale of their invention portfolio and external investment raised. However, in general, few studies go into detail with regard to KE-related activities. Those that do appear to concentrate mostly on presenting data which is already captured and presented in other areas such as industrially sponsored research, spin-outs and licensing revenues. Some notable exceptions include a study of the universities in Boston (Appleseed, 2003) which provides examples of university-industry partnership that have formed between its universities and industry and the role of universities in attracting R&D-related investments to the area. It also looks specifically at the support provided for business development in the area through licensing activity, support for startups, incubators and access to investments. The 2006-07 study of UC San Diego provides data on other non-research related KE mechanisms such as continuing education and networking. In that year the university, which employed 7,566 full time and part time academic staff, attracted 20,000 enrolments to their continuing education courses, with a budget of $30 million (including fees, contracts, grants, sponsors, and donors). However, our fieldwork suggests that there appears to be growing concern over the robustness of these studies. They tend to be commissioned from consultancies using proprietary methods with no standardisation of methodology over what should and should not be included, and how estimates should be calculated. This has led to huge variations in the resulting impacts being reported and less trust in the results by key stakeholders."}, {"section_title": "Assessing economic impact and industrial engagement at Georgia Tech", "text": "The research looked in detail at a case study of Georgia Institute of Technology, a university identified by Tornatzky (2002) as one of the most advanced in their activities building alliances with industry and playing an active role in the economic development of their region. Georgia Tech was originally founded to promote economic development and industrialisation in the State of Georgia with a mission as a technical institute to train specialists for business and industry (Youtie and Shapira, 2008). Over time it has developed into a broad-based, interdisciplinary technology university that acts as a 'knowledge hub' in its local and state economy actively fostering \"knowledge exchange, learning and innovation through new methods and the development of boundaryspanning activities\" Shapira, 2008, p. 1202). Interviews with the senior leadership at Georgia Tech emphasised the importance of its mission to support economic development at different levels from the city of Atlanta to the State of Georgia as well as contributing to the national level technology and innovation development. Central to this mission is their work to engage more closely with external partners at these different levels. A key senior leadership figure within the institution noted that they are putting effort into improving the monitoring and performance systems of their activities, including exploring the potential for developing 'balanced scorecard' approaches (developed by Kaplan). There was also a belief that such evidence was important for demonstrating the value of their activities to key stakeholders such as the state. A balanced scorecard approach was seen as a potentially valuable way to capture their different objectives including research excellence and driving economic development, while also building in measures to capture the performance of processes that underpin these activities (such as their contracting systems with industry). There are ambitions to expand the set of standard metrics used to monitor and assess their contribution to economic development (including industry contracts, licenses and the associated revenues) to include services provided to external partners such as testing services and facilities, as well as exploring the potential to collect data on consultancy activity. Many of the major organisations within the university, such as the Georgia Tech Research Corporation which manages the IP arising from the university; the Georgia Tech Research Institute which undertakes applied, contract-based research for clients covering government and industry; and the Enterprise Innovation Institute which has a mission to support companies in the local and state economy, have to produce annual reports. These capture and present a range of data and case studies that help to illuminate -either explicitly or implicitly -their economic and social impacts on industry and the world. Efforts are being made by the university to bring the data and case studies to the 'human level' and highlight how their activities are changing people's lives on the ground, reflecting a general view from the fieldwork. For example, one of the key organisations within Georgia Tech that works closely with companies in the state and helps to drive their economic development activities is the Enterprise Innovation Institute (EI 2 ). Its mission is to help \"enterprises of all kinds improve their competitiveness through the application of science, technology, and innovation\" (EI 2 , 2010) and provides a key connection for businesses into the university. It lists just over 150 staff and it brings together a range of programmes including (not exhaustive): \uf0b7 Advanced Technology Development Center (ATDC): an incubator that provides coaching, connections, and a community to foster the development of technology start-ups in Georgia. \uf0b7 Innovation Corps (I-Corps): prepares scientists and engineers to extend their focus beyond the laboratory and foster entrepreneurship that will lead to the commercialization of technology. \uf0b7 Flashpoint: helps early-stage startups minimize risk and accelerate growth through a process called Startup Engineering. \uf0b7 Georgia Manufacturing Extension Partnership (GaMEP): helps manufacturers increase topline growth and reduce bottom-line costs through strategic planning, innovation management, process improvement, ISO standards, sustainability, and energy services. \uf0b7 Georgia Tech Procurement Assistance Center (GTPAC): helps Georgia businesses identify, compete for, and win government contracts in order to sustain and grow their businesses. \uf0b7 VentureLab: transforms the innovations of Georgia Tech faculty, research staff, and students into companies. \uf0b7 Startup Ecosystems: helps governments, communities, foundations, entrepreneurs, and small businesses foster value creation by applying innovative ideas, technology, and policy to initiatives focused on economic growth \uf0b7 Integrated Program for Startups (GT:IPS): provides training and support to Georgia Tech faculty and students interested in launching companies based on Georgia Tech IP. Each year it provides a 'report card' as part of its annual report. In its latest report (EI 2 , 2012), it claims to have: \uf0b7 Helped Georgia manufacturing companies reduce operating costs by $38 million, increase sales by $451 million, and create or save 978 jobs. EI 2 served 1,370 companies during the year. \uf0b7 Evaluated 199 research innovations developed in Georgia Tech's research programme, and helped form 30 new enterprises that, together, attracted nearly $21 million in investment. \uf0b7 Assisted 261 companies interested in collaborating with Georgia Tech. Projects resulting from those collaborations created or saved 3,342 jobs and produced more than $1 billion in capital investment. \uf0b7 Helped Georgia companies win $715 million in government contracts, creating or saving an estimated 14,304 jobs. \uf0b7 Assisted 85 minority entrepreneurs, who reported more than $77 million in new contracts, increased sales, new bonding, or new financing. \uf0b7 Served 322 technology startup companies that, together, generated capital activity (venture capital investment and mergers/acquisitions) of more than $222 million. \uf0b7 Helped Georgia companies prepare 75 proposals for SBIR grants, which resulted in more than $7 million in awards. \uf0b7 Assisted 3,056 students through EI 2 technology accessibility services, and saved the university system of Georgia $1.4 million by reusing textbooks converted for students with disabilities. The data is complemented by case studies of impact to help contextualise the data and highlight specific instances of how their activities have helped individual companies on the ground. An interview with another senior figure within the university argued that another key metric that can be used to help demonstrate the value of the university to the state legislature was the amount of R&D income secured from out of state. While it is not an outcome measure, he argued that it does highlight the scale of R&D activity -$242.8 million in applied research for government and industry by the Georgia Tech Research Institute alone -that occurs in the state directly as a result of the presence of the university, before any impacts of the research activity on the state are taken into account 12 . Finally, during the fieldwork, Georgia Tech was in the middle of completing an economic impact assessment of its institution. While there was a heavy emphasis on the creation and safeguarding of jobs in the state -given the difficult economic climate and the focus on jobs -efforts were also made to capture other key areas of impact including: research and innovation, looking at faculty activity, partnerships and technology commercialisation; student destinations; technology firm incubation; and community impacts. The assessment also recognised that there were those areas of impact where estimates could be obtained quantitatively (e.g. economic impact of the expenditures of the institution), and those where the role of the university was in enabling companies and other organisations to innovate and compete more effectively. The focus here was in exploring the 'catalysing effects' of the university: those effects on innovation and competitiveness that would not happen if the university was not there. While this section was more qualitative in nature, it is clear from the 'report card' of EI 2 that data do exist on the scale of interactions and reach of their support."}, {"section_title": "Assessing economic impact and industrial engagement at North Carolina State University", "text": "Our second case study of university progress in developing impact metrics derives from a case study of North Carolina State University. Three important developments stimulated NC State to establish a university-wide task force in 2006 to assess the economic impact of the university on the economy of the state: \uf0b7 Receipt of the engaged university credential from the Carnegie Foundation. \uf0b7 A requirement by the Kaufman Foundation to measure the impact of a grant they had awarded to NC State to develop an entrepreneurial initiative. \uf0b7 Participation in a programme (UNC Tomorrow) to assess the state economic impact of NC State. The remit of the task force, which began work in 2007, included not only the establishment of an inventory of NC State activities and events impacting on the economy but also the establishment of meaningful metrics for monitoring impacts. A first report IMPACT: Benchmarking Economic Development Impacts was published in 2008 and a second report IMPACT: What Counts is What's Counted' in 2010. These reports, which deployed a logic model approach, covered a range of activities including knowledge creation and diffusion, technology transfer and commercialisation, training, testing services, university/industry programmes and curricula development. The inventory of NC State engagement activities covered: \uf0b7 Curricula in classes and programmes with an outreach component \uf0b7 Experiential and service learning \uf0b7 Knowledge creation and diffusion in partnership with external organisations \uf0b7 Technology transfer and commercialisation \uf0b7 Public events and understanding \uf0b7 Technical and expert assistance and training \uf0b7 Clinical/diagnostic and testing services \uf0b7 University/industry research programmes Logic models were used to depict the relationship between inputs/resources, activities and expected outputs, outcomes and impacts (see below)."}, {"section_title": "Figure 6.3 Knowledge Effects and Measurement", "text": "Source: NC State 2008The task force developed logic models for each of the eight categories of impact identified. Although impact measurement was preferred, if meaningful measurements could not be made it was accepted that understanding the path to the impact was both necessary and important. Moreover the pilot runs demonstrated to the task force that measurement must involve those that experienced the outcome or impact. Examples of the logic models developed are shown below.  As a result of the pilot studies the task force concluded with a number of recommendations: \uf0b7 Evaluation must include results from people and enterprises impacted instead of relying on perceptions of academics and those engaged in outreach. \uf0b7 NC State should adopt the Benchmarking Economic Development Impact (BEDI) framework throughout the university as part of its annual reporting responsibilities, suitably aligning research and outreach functional activities and impacts with university goals. The BEDI framework and logic models should be available for adoption by other universities in the University of North Carolina system. \uf0b7 NC State should evaluate short -term contributions using the logic model with respect to the ultimate impacts they produce. \uf0b7 A centralised evaluation office should be set up to form a critical mass of expertise available to the entire university. This office should develop and apply the logic model and provide consultative resources for university departments to develop customised models and measurements. There are efforts being made in the US to develop new data collection techniques to collect more relevant and robust evidence on issues relating to science policy and allow new indicators to be developed that can inform the science and innovation policy debate. This is partly motivated by the need to improve the evidence base on the impact of investments by the research funders while not placing additional burdens on the researchers. It also reflects the significant and rapid advances in digital technologies along with new computational tools which allow new types of data to be collected without placing additional reporting requirements on researchers. In particular, the internet is enabling the development of new kinds of forecasting and data collection methods that provide useful insights in almost real time. As part of this effort, the NSF is developing its cyberinfrastructure, which can store, integrate, sort, extract and permanently archive information, in the belief that it can provide new and exciting opportunities for assessing research. In addition, the NSF is also looking at new technologies that can gather data on how NSF funded research fellows' careers have evolved over time. It has set up an ongoing research programme -the Science of Science and Innovation Policy (SciSIP) to support its efforts. The SciSIP focusses on research to advance the scientific basis of science and innovation policy by developing, improving and expanding models, analytical tools, data and metrics that can be applied in the science policy decision-making process. Key areas of research supported include: \uf0b7 Examinations of the ways in which the contexts, structures and processes of science and engineering research are affected by policy decisions. \uf0b7 The evaluation of the tangible and intangible returns from investments in science and from investments in R&D. \uf0b7 The study of structures and processes that facilitate the development of usable knowledge, theories of creative processes and their transformation into social and economic outcomes. \uf0b7 The collection, analysis and visualisation of new data describing the scientific and engineering enterprise. A key body for developing indicators in this area and for collecting data is the National Center for Science and Engineering Statistics (NCSES). Its STI indicators programme faces several challenges (National Research Council, 2012a): \uf0b7 Traditional surveys face increasing expense, declining response rates, and lengthy time-lags between when data are gathered and when derived indicators and other statistics can be published. \uf0b7 Tools for data extraction, manipulation, and analysis are rapidly evolving. \uf0b7 Repositories of STI measures that users demand are distributed among several statistical agencies, and private repositories. \uf0b7 Sources of knowledge generation and innovation are expanding beyond the traditional developed countries to emerging and developing countries. \uf0b7 Users' expectations are rising, and they are demanding more access to statistics that are closer to the actual measures of what they want to know. The report also cites Groves (2011) who noted that surveys were increasingly facing \"threatened coverage of frames; falling participation rates; increasing reliance on non-response adjustments; and for surveys with high response rate targets, inflated costs\". There was a belief within a panel at this meeting that \"NCSES will have to use surveys more efficiently and increase use of web-based tools for harvesting data, particularly on human capital measures and output measures related to scientific discoveries and innovation, and databases from other government agencies and private providers\"."}, {"section_title": "Web-Scraping", "text": "An emerging avenue for acquiring data from the internet is 'web-scraping'. Web-scraping collects data publicly available on the web and may prove particularly useful for gathering information on the human capital component of science and technology indicators. Web-scraping seeks to take semi-structured data from a public web page and turn it into structured data recorded in a database. A key advantage of this type of technique is that it could be carried out continuously allowing for (near) real time statistics to be generated. For example, the increased posting of CVs online by job seekers contain a wealth of information about that individual's educational background and aspirations; social network sites can reveal insights into the personal and professional networks of academics; bibliometric databases often provide information on the organisational affiliation of the academics which can allow the tracking of their careers over time. For example, some sources include (National Research Council, 2012a): \uf0b7 Facebook, Google+: number of students at a university, how many major in which fields. \uf0b7 Mendeley, Academia.edu, CiteULike: how many researchers are active in which fields, how many collaborations, who collaborates with whom, how useful is a given piece of research. \uf0b7 LinkedIn, Monster.com, Zerply: the composition of the labour force, geographic breakdown, skill sets, and similar information. However, a finding of National Research Council (2012a) was that while some of these social networks may contain useful information, it may be possible to gather this type of data more efficiently from administrative records. One note of caution, however, is the legality of scraping of data from commercial companies, and approaches may potentially require negotiation with the site owners to access the data. Despite the advances in web-scraping technologies, National Research Council (2012a) highlights some fundamental questions that still require further research: \uf0b7 What kinds of statistical methods are required to analyse this type of data? \uf0b7 What are the tradeoffs with using web-based data sources instead of survey data? \uf0b7 Is it possible to adjust web-based data to represent a survey sample or to estimate errors? \uf0b7 Is it possible to use a traditional survey to calibrate web-based data? \uf0b7 How frequently must this be done? In another note of caution, Boyd and Crawford (2011) "}, {"section_title": "Blending Data and Linking Datasets", "text": "What is increasingly evident is that there are different types of data that can be collected that could lead to potentially valuable insights into the diffusion of knowledge through university-industry engagement. This then raises the important question of the feasibility and implications of blending different data types such as administrative records, scientometric tools, and surveys, to produce a more robust evidence base, and develop the necessary techniques to achieve this and analyse the resulting evidence. In addition, another key challenge is whether different datasets held either within a single organisation or across different public or private sector organisations can be linked together to provide a much richer data set. For example, National Research Council (2012a) suggests that the NCSES explore the linking of data from the BRDIS with the HERD survey and administrative longitudinal data, suggesting that this may help to provide a rich dataset linking knowledge inputs to outcomes."}, {"section_title": "Few existing points of comparison", "text": "We found that there are currently still few metrics on KE mechanisms on which comparisons can be made. The limited set of metrics include: spin-outs and licensing (through data collected by AUTM and HE-BCI); and co-publications between universities and industry and associated citation impact indicators (using data from ISI Web of Knowledge or Scopus). Another possible area of comparison is the value of industrially sponsored research in universities. As highlighted earlier in the report, the closest comparison on this metric at the institution level is likely to be between the HESA metric on research grants and contracts from industry, and the NSF HERD survey metric of R&D expenditures from business. At the national level, OECD data on gross expenditure on R&D, isolating that funded by business in the HE sector, is the closest comparable metric."}, {"section_title": "Steps towards a broader set of metrics, but few potential points of comparison without adapting UK-based metrics", "text": "The US is starting to focus on developing metrics that capture a wider range of contributions of universities to the economy, going beyond the hitherto narrow focus on technology transfer metrics. The most promising avenues in this area include the work of APLU and STAR Metrics. The initial set of metrics chosen by APLU to take further towards wider implementation reflect those that were believed by its working group to be both feasible in terms of robust data collection and utility (value of its use). A key finding from the APLU pilot programme testing out the collection of the broad range of metrics found that much of the data was not commonly nor systematically collected, creating burdens on universities to generate usable information in the short run. Some of the pilot universities did, however, believe that the process had created a debate within their institutions as to how they could better demonstrate their value to their key stakeholders. Concerns were raised by some at the APLU metrics development workshop in October 2012 that the process had gone from exploring a highly granular suite of metrics to a '30,000 foot view' which may be too high level to be of significant use. The APLU metrics programme is still being developed and implemented. However, it will take a few more years before they yield useful data on different mechanisms. However, even if the full set of metrics are collected, the potential for comparison with the UK would be limited without the collection of additional data here in the UK. Should the AUTM institutional economic engagement metrics be developed further, this would allow for more direct comparisons, given that the guiding framework was influenced heavily by the experiences of the UK. However, as noted in their paper on the proposed metrics, AUTM does not see itself as the collector of much of this information and will remain primarily focussed on technology transfer-related metrics of KE."}, {"section_title": "Importance of case studies and narratives", "text": "Another key message from the US is that, for the metrics collection efforts to be effective for policymaking, they need to be brought down to the 'human' level. The key focus therefore in the US is to develop examples and case study narratives which provide the rich qualitative evidence of how specific investments affect the lives of the citizens in their country."}, {"section_title": "State-driven metrics for public US universities", "text": "Given that the public US university system is organised and funded directly at the state level, it is unsurprising that an overriding primary mission of these universities is to contribute to state-level economic development. As such, it was clear from our interview programme that efforts to understand the role and value of universities in the economy at the institutional level were primarily driven by, and geared towards, a state-level set of stakeholders rather than the federal government (although specific federally funded research programmes may have specific reporting requirements). This adds another layer of complexity that we do not have here in the UK, in systematically collecting robust and aggregated data at the national level drawn out of state systems and data, given that state-level objectives for their university systems may differ."}, {"section_title": "Logic models and comparative policy evaluation", "text": "It was apparent from the interviews that both countries use similar logic models to frame evaluations. This provides a potentially consistent framework in which to consider different types of indicators being developed in different countries. However, comparisons of specific policies or support initiatives need to take into account potential differences in additionality and the extent to which certain gross impacts would have happened in the absence of the intervention or support initiative."}, {"section_title": "Survey fatigue and new techniques for automating data collection", "text": "As in the UK, US stakeholders have raised the difficulties associated with collecting data through surveys due to 'survey fatigue'. New data collection techniques are being explored, with STAR Metrics being the most advanced in terms of development, and broad in terms of coverage. Others looking more broadly at STI indicators are exploring whether it is possible systematically to collect and exploit information published on the internet (either publicly or through proprietary databases) and link it to other datasets collected by government. Comparisons need to take account of the differing contexts and focus on the ability of users to access and absorb university-generated knowledge and expertise In conclusion, the report highlights -as many others have recently done -the many and varied channels through which universities contribute to innovation in the wider economy and to society. In addition, as reflected in Part I and evidenced by the national comparison of firms by Cosh, Hughes and Lester (2006), the patterns of interaction differ somewhat between the two nations. Hence, focussing on individual metrics -which often focus on activities and output mechanisms rather than impacts -may provide misleading information on the appropriateness and value of specific KE mechanisms and result in incentives and investment support being channelled to specific activities that may be ineffective given the wider structure of the national innovation system. Comparisons may therefore be best made from the perspective of the users of university-generated knowledge and expertise, and their ability to access and absorb this knowledge into their innovation activities. Finally, given that public university systems in the US are both organised and directly funded at the state-level, it may be more insightful to undertake systematic comparative analyses of the role and contribution of university-industry KE to economic development, and the importance of government policy in supporting it, at this level. This would need renewed focus in the UK on systems and data on innovation at regional and local levels, which will be more of a challenge with the restructuring of UK approaches to sub-national growth with the abolition of Regional Development Agencies in favour of more local approaches (through Local Enterprise Partnerships). This would though chime with most recent UK policy narratives on the role of universities in place-based innovation, such as in the Witty Review (BIS 2013). correlations and other data analysis techniques which create propositions of links. This can lead to erroneous interpretations with consequences for policy decisions. \uf0b7 Data reporting is manual by the grant principal investigators which can result in quality variations, and only requires reports to be made during the period of the award, well before likely outcomes may have been realised. \uf0b7 Data infrastructure does not allow for the tracking of students supported by the grants, despite the perceived importance of federal agencies of their impacts on the labour market and socially. Given the political focus on jobs, a key requirement of the stimulus package was the need to demonstrate that the investments were resulting in creating or retaining jobs in the US. However, as an interview with the co-chair of the STAR Metrics programme revealed, universities are very different from other types of recipients of the stimulus funding such as local governments. One key difference was, unlike the latter, universities don't often have 'shovel ready' projects that can be rolled out immediately. University-based investments take time to ramp up and even longer for the impacts to be realised (unlike the building of a road). In addition, as has been mentioned a number of times in this report already, the pathways to impact for university-based investments are highly complex and can often be very difficult to quantify and measure. The stimulus funding required quarterly reporting on jobs created or retained. This was vastly different from what universities were used to and was a key motivation for establishing STAR Metrics. The initial development of STAR Metrics was greeted with a lot of scepticism and with universities needing to be convinced on the value of sending their data to the database. They were worried about benchmarking and the implications for funding allocations and for misinterpretation of the data. An interview with one of the key individuals leading the development of the system suggested that the following factors were critical for overcoming these barriers: \uf0b7 The importance of developing trust with the universities. \uf0b7 Developing an inclusive process, focussing on being part of a team. \uf0b7 The importance of the pilot project with just six universities before rolling it out to over 100. One key incentive for universities to engage was highlighted in an interview with one of the founding partners (a private university). The reporting requirements for the stimulus package were potentially heavily burdensome. The STAR Metrics system provided a way to reduce this burden in a way that other methods could not. Another incentive for this university to participate was the growing need to demonstrate its value to local stakeholders, going beyond anecdotal information and 'spiritual belief' that universities are good. This provided a unique source of data that hitherto had not existed within universities. In addition, the system was seen as providing valuable management information to university leaders on their portfolio of research activity."}, {"section_title": "STAR Metrics: An Overview", "text": "Objective: To create a data infrastructure that will permit the analysis of the impact of science investments using administrative records as well as other electronic sources of data. It is built on three principles (reproduced from Lane and Bertuzzi, 2010, p.5): 1. To use the right unit of analysis. Although current federal agency systems are built to administer awards, the new reporting demands on agencies require a new management information structure needs to be built with a different conceptual basis. The appropriate unit of analysis in that structure is scientists and clusters of scientists; the appropriate outcomes of scientific investments are the creation, dissemination and adoption of knowledge 2. To use current technology. Fundamental transformations in digital technology can be used simultaneously reduce the need for manual reporting and facilitate the capture of appropriate outcomes -substantially improving the quality and reliability of the data infrastructure. 3. To collaborate with the scientific community. Domain scientists have the deepest understanding of the appropriate data and metrics that should be used to describe the creation, transmission and adoption of knowledge in their fields. Social and behavioural scientists have the best understanding of how to theoretically and empirically tease out the impact of interventions. The programme is being implemented in phases ( Figure 6.1), with the first two being (from Lane and Bertuzzi, 2010): Phase I: Develop uniform, auditable and standardized measures of the impact of science spending (including those made through the ARRA stimulus package as well as non-ARRA investments) on job creation, using data from research institutions' existing database records. It identifies how many scientists are supported by federal science funding. Importantly, this includes graduate students, undergraduate students and research staff. It captures information about the jobs created through subawards, subcontracts and overheads. Phase II: Develop measures of the impact of federal science investment on scientific knowledge (using metrics such as publications and citations), social outcomes (e.g. health outcomes measures and environmental impact factors), workforce outcomes (e.g. student mobility and employment), and economic growth (e.g. tracing patents, new company startups and other measures). The programme collects the data elements in Figure B.2. These allow the system to calculate measures of employment by occupation supported by federal science funding over time on a quarterly basis. \uf0b7 Scientific knowledge (such as publications and citations..) \uf0b7 Economic growth (through patents, firm start ups and other measures) \uf0b7 Workforce outcomes (e.g. through student mobility and employment) \uf0b7 Social outcomes (such as health and environment) It aims to create a platform that importantly links inputs to outputs/outcomes. This is often lacking in evaluation systems. Central to the ethos of STAR Metrics is exploring the ability to use state of the art digital technologies to collect and capture the scientific, economic, social, and workforce impacts. Phase II is still in early development and ideas are being put forward including (from Lane and Bertuzzi, 2010): \uf0b7 Use existing administrative data such as from the US Patent Office to link patent data and associated critical publications and federally funded research. The data identifies the patent assignees and technology classes, linking this back to the academic research outputs and to the specific inventors. This should allow the system to trace the knowledge flow and potentially the mobility and links of principal investigators from the university system to the private sector. \uf0b7 Match administrative records of universities to the data held by statistical agencies. This could help link undergraduate and graduate students, and postdoctoral researchers to jobs they take up subsequent to their work on federally funded research projects. It would also allow the tracing of employment and income trajectories and tie this to the firms and industries in which they work. \uf0b7 Greater exploitation of the cyberinfrastructure which can create flow reports of citations, patents, and publications using web-scraping techniques both during and after federally funded research projects. Some of these techniques will require advances in techniques to capture data and the confrontation of how to use confidential and potentially highly sensitive data, but Lane and Bertuzzi (2010) note that these issues are being developed and addressed by a range of researchers, agencies and others. They conclude that, \"in general, it will be necessary to build an open access, cyberinfrastructure enabled, collaborative environment which can be used so that the research community can collaborate with the federal agencies to generate summary indicators about where science investments have been and are being made, together with information about the economic, social and scientific impacts over space and time.\" (Lane and Bertuzzi, 2010, p. 10). A recent presentation by Bertuzzi et al. (2011) identifies portfolio characterisation as a potential 'product' of STAR Metrics. This has the potential to enable funding agencies to perform gap analyses to determine what is being funded in which areas by the federal government and help these agencies locate expertise in key topic areas; to help researchers find other programmes that are being funded similar to their research topics and other researchers in similar areas; and to help senior university leadership identify their institutional strengths. Another 'product' identified is the R&D dashboard helping to provide key stakeholders with evidence on what research is being funded in their state/city, the researchers active in key areas, and the outputs of this research. Illustrates the real impact of technology transferbringing the results of research into use for the benefit of the general public, our institutions and the communities we serve 2008a The Art of Collaboration: The Relationships that Bring Academic Innovations to the Marketplace Collaboration is a vital component of technology transfer. Whether among researchers, departments or between university offices and the business community, local and national governments or nonprofit organizations, it is these working partnerships that cultivate great ideas and transform them into technologies that benefit society. The report presents technologies that vastly improve the speed at which drugs and fluids can be administered in an emergency, how what started as a \"curious compound\" now provides hope to millions battling cancer and how a researcher working on artificial limbs helped develop voice identification technology that may one day help fight terrorism "}]