[{"section_title": "Abstract", "text": "Abstract: This article extends single-level missing data methods to efficient estimation of a Q-level nested hierarchical general linear model given ignorable missing data with a general missing pattern at any of the Q levels. The key idea is to reexpress a desired hierarchical model as the joint distribution of all variables including the outcome that are subject to missingness, conditional on all of the covariates that are completely observed and to estimate the joint model under normal theory. The unconstrained joint model, however, identifies extraneous parameters that are not of interest in subsequent analysis of the hierarchical model and that rapidly multiply as the number of levels, the number of variables subject to missingness, and the number of random coefficients grow. Therefore, the joint model may be extremely high dimensional and difficult to estimate well unless constraints are imposed to avoid the proliferation of extraneous covariance components at each level. Furthermore, the over-identified hierarchical model may produce considerably biased inferences. The challenge is to represent the constraints within the framework of the Qlevel model in a way that is uniform without regard to Q; in a way that facilitates efficient computation for any number of Q levels; and also in a way that produces unbiased and efficient analysis of the hierarchical model. Our approach yields Q-step recursive estimation and imputation procedures whose qth-step computation involves only level-q data given higher-level computation components. We illustrate the approach with a study of the growth in body mass index analyzing a national sample of elementary school children."}, {"section_title": "Introduction", "text": "A seminal contribution to statistical methodology is the development of efficient methods for handling missing data within the framework of a general linear model (GLM [1] [2] [3] [4] [5] [6] [7] ). These methods provide efficient estimation of the GLM given incomplete data. In particular, model-based multiple imputation now provides state-of-the-art methods for handling missing data [5] . These approaches are founded on a comparatively mild assumption in many applications that missing data are ignorable [2, 4] .\nThis article extends the methodology to an arbitrary Q-level hierarchical GLM where lower-level units are nested within higher-level units [8, 9] . Many multi-level observational studies and controlled experiments produce missing data. In cluster-randomized experiments, the dominant design involves the random assignment of whole schools, hospitals or communities, rather than students, patients or adults to treatments [10] . Multi-level analysis is pervasive in health, education and social science studies [11] [12] [13] [14] . Surveys involve multi-stage sampling designs [15] . A ubiquitous problem is that explanatory as well as outcome variables may be subject to missingness at any of the levels.\nIn longitudinal studies, hierarchical data subject to missingness may be estimated by maximum likelihood (ML) in a structural equation model (SEM) where latent means include missing data [16] [17] [18] [19] [20] . SEM software such as Mplus [21] , Amos [22] and EQS [23] performs ML estimation of such models. When these models are formulated by multi-group analysis, the number of groups is the number of missing patterns [16, 19, 20] .\nRecent advances have extended the single-level methods to multi-level ignorable missing data. Liu et al. [24] considered Bayes inference to longitudinal designs having a fixed within-subject design with repeated measures at level 1 nested within persons at level 2 where the data are missing at both levels. Schafer and Yucel [25] developed Bayes and ML inference for a broader class of two-level designs in which the level-1 design could vary across level-2 units with level-1 data subject to missingness. Goldstein and Browne [26, 27] took a Bayesian approach to a two-level factor analysis where missing outcomes were imputed by a Gibbs sampling step. Shin and Raudenbush [14, 28] extended these methods to a two-level model where the outcome and covariates may have missing values at both levels. Shin and Raudenbush [29] and Shin [30] illustrated an efficient ML method to estimate a three-level model with incomplete data. To estimate a three-level hierarchical linear model with incomplete data, Yucel [31] modified a single-level imputation method [6, 32] and a two-level imputation method [25] to carry out the Gibbs Sampler to sequentially impute cluster-level missing values, intermediate-level missing values given the multiply imputed cluster-level data and then, the lowest-level missing values given the multiply imputed data at higher levels. These advances guide us with continuous outcomes. Goldstein et al. [33] and Goldstein and Kounali [34] used a Markov Chain Monte Carlo method to impute a mixture of continuous and discrete outcomes subject to missingness in a two-level model.\nShin and Raudenbush [28] illustrated two ways to handle two-level missing data: direct ML estimation (MLE on Y obs ) and a two-stage procedure of multiple imputation followed by the second stage analysis of the multiply imputed data (MLE on Y mi ). This article generalizes the two methods to an arbitrary number of Q levels and an arbitrary number of outcomes defined at any level. A key emphasis in this article is the difference in logic and assumptions between the two methods. Using MLE on Y obs , one first writes down a desired hierarchical model, then reparameterizes the model in terms of the joint distribution of outcome and covariates subject to missingness given the completely observed covariates. Great care must be taken, so that the transformation is one-to-one in order to insure unbiased estimation [14, 28] . This task generally requires the imposition of constraints on regression surfaces at each level to avoid the proliferation of covariance components at higher levels of the joint distribution. One challenge for this article is to formulate these constraints within the framework of the Q-level model. We show that the unconstrained joint model identifies contextual effects [9] and interaction effects that are typically extraneous for the desired model. In contrast, MLE on Y mi generally implies that the imputation model should be unconstrained, allowing the data analyst to impose the desired constraints at the second stage when using conventional software to analyze the imputed data. A challenge with MLE on Y mi is that the need to avoid constraints at stage 1 may lead to the formulation of extremely high-dimensional imputation models that may be difficult to estimate well. The two methods have characteristic advantages and disadvantages. MLE on Y obs imposes more assumptions than does MLE on Y mi , because MLE on Y obs imposes distributional assumptions on all variables subject to missingness while for MLE on Y mi , such assumptions do not affect the observed data. Given the pluses and minuses, this article considers a hybrid approach that combines the two methods. Our aim is to formulate a Q-level model that unifies single-and multi-level models into a single expression, facilitating extension of existing missing data methods to an arbitrary number of levels of a linear model with efficient estimation and computation. The model has two representations: a hierarchical linear model for a response variable conditional on covariates and a marginal model that represents the joint distribution of all variables -the response and covariates -that are subject to missingness conditional on the completely observed covariates. It is essential to clarify the relationship between these two models; in particular, the conditional model is always equivalent to the joint model after imposing certain constraints on the more general joint model. To clarify the needed constraints in a general Q-level setting, we find it revealing to reparameterize both forms of the model such that all variables subject to missingness are decomposed orthogonally by level. In this model, random components are correlated within but uncorrelated between levels. The required constraints then fall out naturally for any number of levels.\nThe next section defines the joint model and decomposes all variables subject to missingness into orthogonal random components. Section 3 considers the problem of estimation and multiple imputation. The orthogonal decomposition is helpful. The key insight is that if we stack the joint model by level, we can write down estimation formulas at level q using level-q data only given higher-level computation components that are uniform for all q even if we ignore all other-level data. This recursive representation yields efficient computations using conventional ML methods such as the EM algorithm [1] . Thus, orthogonal decomposition by level transforms a seemingly intractable computational problem into a sequence of familiar, solvable problems as described in Section 3. Section 4 introduces the conditional hierarchical linear model. We show that the joint model represents more parameters than desired in the hierarchical model and describe how to constrain the joint model for identification of the desired hierarchical model. Incorporating the constraints is essential to avoid bias for MLE on Y obs . For MLE on Y mi , the constraints do not reduce bias but may nonetheless be practically necessary for computation involving high-dimensional models. Analyzing data from a large, nationally representative longitudinal sample of children, we illustrate these methods to study predictors of the growth of body mass index (BMI) between ages 5 and 15 in Section 5. This is a three-level problem, with up to seven repeated measures on children who are sampled within their elementary schools. Section 6 concludes with a discussion of limitations and next steps in the Q-level research agenda."}, {"section_title": "Joint model", "text": "All the models described in this article are subsets of a multi-level p-variate model\nwhere every element of Y is subject to missingness, \u03bc may be a linear function of completely observed covariates, Z is a matrix of completely observed covariates having random effects b and V \u00bc Z\u00c5Z T . For simplicity of exposition, we shall assume \u03bc \u00bc 0 in this section. We partition Y \u00bc \u00bdY\nis a vector of p q variables at level q in a hierarchy of Q levels for p \u00bc P Q q\u00bc1 p q . In the case of Q \u00bc 2 where occasions are nested within children, for example, elements of Y 1 such as BMI and daily television viewing hours (TV) vary across occasions at the lower level 1, and elements of Y 2 such as years of highest parent education and birth weight vary among children at the higher level 2.\nThe variance covariance matrix V may be structured by the fact that Y q varies at level q or higher. In the case of Q \u00bc 2, for example, the BMI in Y 1 varies within as well as between children, while the birth weight in Y 2 varies between children but not within a child. Thus, we partition Z \u00bc\u00afQ q\u00bc1 Z q \u00bc diagfZ 1 ; Z 2 ; . . . ; Z Q g, a diagonal matrix having diagonal submatrices \u00f0Z 1 ; Z 2 ; . . . ; Z Q \u00de, and b \u00bc \u00bdb\nT , and decompose Y q orthogonally by level as\nwhere Z rq is a matrix of known covariates having level-r unit-specific random effects \u03b5 rq , N\u00f00; \u03c0 r qq \u00de for subscript and superscript r denoting the level of variation. The orthogonal random effects \u03b5 rq are independent between levels so that \u00c5 qq \u00bc\u00afQ r\u00bcq \u03c0 r qq , but correlated within levels by cov\u00f0\u03b5 rq ; \u03b5 rs \u00de \u00bc \u03c0 r qs so that cov\u00f0b q ; : \u00bd4\nThus, all random effects b of the joint model (1) may also be expressed as \u00f0\u03b5 1 ; \u03b5 2 ; . . . ; \u03b5 Q \u00de, displayed vertically in Table 1 . Their parameters are \u03c0 \u00bc \u00f0\u03c0 1 ; \u03c0 2 ; . . . ; \u03c0 Q \u00de. This expression is useful for deriving estimators as will be described in the next Section."}, {"section_title": "Estimation of the joint model", "text": "The orthogonal decomposition by level shown in Table 1 enables us to write down the joint model (1) as a familiar mixed linear model (2) for any level q. Next, we shall exploit the fact that if we stack these levelspecific models such that there is an equation at level q and a second equation stacked at all levels higher than q, we can write down familiar estimation formulas that use level-q data only given higher-level computation components even when we completely ignore all data at other levels. Moreover, the estimation formulas remain uniform for all q to produce efficient computation formulas as will be explained below. Therefore, the orthogonal decomposition of the joint model (1) enables us to obtain general, recursive and familiar estimation formulas for the Q-level problem. \nEq. [5] for q \u00bc 1 expresses the joint model (1) where Z 1 may include covariates having random effects at all levels. Often, the model (5) itself is of interest [29, 30] . For a positive integer n, let I n denote an n by n identity matrix. In this article, we focus on estimation of the model (5) where Z qq \u00bc I p q for all q as many applications do. In what follows, we use the Kronecker product A # B that multiplies matrix B to each scalar element of matrix A [35] . In particular, I n # B \u00bc diagfB; . . . ; Bg."}, {"section_title": "Estimation", "text": "In deriving estimators, it is essential to aggregate the stacked-up joint model (5) \nin a familiar form [28] that is uniform for all q and has recursive V [28] given computation components at level q \u00fe 1, starting from the highest level q \u00bc Q until we estimate the desired model for Y 1 m with arbitrary Q levels at q \u00bc 1. The initial step is to estimate the single-level model (7) for q \u00bc Q, a special case of Shin and Raudenbush's two-level model. We formalize the recursive estimation within each iteration of the EM algorithm after defining notation for estimation below. A major advantage of this approach is that the step-q estimation uses only level-q data given higher-level computation components for efficient computation as will be shown in the following section.\nTo \u00de for the entire sample. If we denote \u03b5 qim \u00bc \u03b5 q in column q of Table 1 for unit i nested within cluster m, the CD log-likelihood of \u03c0 may be expressed as\nP Nqm i\u00bc1 lnf \u00f0\u03b5 qim j\u03c0\u00de for the density f \u00f0\u03b5 qim j\u03c0\u00de of level-q unit-specific \u03b5 qim , N\u00f00; \u03c0 q \u00de. The CD To estimate fixed effects, let \u03bc \u00bc \u00bd\u03bc 1 \u03bc 2 . . . \u03bc Q for \u03bc q \u00bc X q \u03b2 q in the model (1) where X q is a matrix of completely observed covariates having fixed effects \u03b2 q . We replace (2) to express the stacked-up model (5) as , respectively. Given current \u03b2 0 , the Fisher scoring equivalent to the Newton-Raphson update i\u015d\nThe following section describes efficient recursive computation of\u03b2 based on X clustering of sample data discussed above gives rise to a Q-level GLM. Next, we show that the aggregated joint model (7) enables us to write down efficient Q-step recursive estimation formulas the qth-step computation of which involves level-q data only and thus is not unduly burdened with respect to the number of Q levels, p variables and random effects."}, {"section_title": "Efficient computation", "text": "The conventional E step based on b To formulate the recursive computation, let The Fisher scoring on \u03b2 for Q \u00bc 3, for example, computes\n33m X 3mobs and H The recursive estimation efficiently handles missing data one level at a time. Consequently, the computation will be efficient given a number of variables subject to missingness at higher levels. In that case, the observed joint model (8) yields recursive computation that is not excessively burdened with respect to Q, p and the number of random effects. On the other hand, given missing data at level 1 only, this approach amounts to the conventional EM algorithm. The inverse of the Fisher information matrix yields var\u00f0\u03b8\u00de.\nMultiple imputation is based on Y [28] . Thus far, we have focused on estimating the joint model (1) for variables subject to missingness given completely observed covariates. However, our goal in this article is to estimate a general Q-level hierarchial GLM for a univariate response conditional on covariates where the covariates as well as the response may have ignorable missing data at any of the levels. To efficiently estimate the GLM, we have to reparameterize it in the form of the joint model (1). The next section will introduce the desired GLM, clarify its relationship with the joint model and describe methods to efficiently estimate the GLM via the joint model."}, {"section_title": "Hierarchical general linear model", "text": "The aim of this article is to estimate a Q-level hierarchial GLM that is a special case of the joint model (1) in which a univariate response is defined at the lowest level of aggregation. We show that the joint model overidentifies the desired model, in general, and describe how to constrain the joint model to be a one-to-one transformation of the GLM. Without the one-to-one correspondence, the estimated GLM via MLE on Y obs may be substantially biased [28] . For simplicity of explication, we first consider the desired GLM where all covariates having fixed effects are subject to missingness. This consideration is without loss of generality, because completely observed covariates having fixed effects do not affect the constraints on the joint model. After explaining the needed constraints for MLE on Y obs , we consider a more realistic GLM having both covariates subject to missingness and covariates completely observed.\nWe write the general Q-level hierarchial GLM\n. . e T Q T , and \u03c4 \u00bc\u00afQ r\u00bc1 \u03c4 r where A and Y r are vectors of p 1 \u00c0 1 level-1 and p r level-r covariates having fixed effects \u03b3 1 and \u03b3 r , respectively, D r is a vector of p Dr covariates having level-r unit-specific random effects e r , N\u00f00; \u03c4 r \u00de independent across levels and p D \u00bc P Q r\u00bc1 p Dr . Both R and C are subject to missingness, while D is known. We assume D 1 \u00bc 1 and that D r carries an intercept as many applications do, although it is not required to have one.\nThe aim of this article is to efficiently estimate the Q-level hierarchical GLM (14) given incomplete data. To do so, we must reparameterize eq. [14] in the form of the joint distribution (1) of all variables subject to missingness -including the response and covariates at any level given D. We define the first element of \nis a special case of the\nand C implies Z rq \u00bc I pq for q > 1. Then, V \u00bc var\u00f0R\u00de cov\u00f0R; C\u00de cov\u00f0C; R\u00de var\u00f0C\u00de :\nas the form of the joint model (1) for efficient estimation of the GLM (14) in this article. Then, the GLM (14) implies\nWhen Q \u00bc 1, the reparameterization is one-to-one between eqs [1] and [14] , and no difficulties arise in computation and interpretation as illustrated in Section 4.1. However, when Q > 1, we find that the reparameterization required to equate the conditional model (14) to the corresponding joint model (1) can be quite challenging. Without imposing constraints, the joint model will over-identify the conditional model (14) . We can readily comprehend this problem in the case of two-level models shown in Sections 4.2 and 4.3. We then generalize our approach in the subsequent section. We see that the problem of over-identification can become severe, as covariates, levels and random coefficients are added to the model."}, {"section_title": "Single-level model", "text": "Eq. [14] for C \u00bc A, \u03b3 \u00bc \u03b3 1 , D \u00bc 1 and e \u00bc e 1 expresses the conventional ordinary least squares (OLS) regression model as the conditional distribution of R given covariates A. Efficient estimation of the model from ignorable missing data [2, 4] is straightforward when we estimate the corresponding joint model (1)\nThat is, the p 1 parameters in the OLS model (14) and the \u00f0p 1 \u00c0 1\u00dep 1 =2 variance and covariance components in V CC are one-to-one functions of the p 1 \u00f0p 1 \u00fe 1\u00de=2 parameters in the joint model (17) . Equivalently, the p 1 parameters in the OLS model are one-to-one functions of \u00f0V RR ; V RC \u00de without redundantly counting the number of parameters in V CC .\nThe general forms of the joint model (1) implied by eq. [16] and the conditional model (14) remain intact when we consider the hierarchical linear model with arbitrary Q levels. A central concern of interest to this article is that, when we move beyond the single-level case for Q \u00bc 1, the desired model (14) is not a one-to-one transformation of the joint model. To see how this works, we consider two-level data where level-1 units (e.g. students) are nested within level-2 units (e.g. schools) before we consider arbitrary Q levels. We shall consider the cases of the two-level model with a random intercept and the two-level model with random coefficients."}, {"section_title": "Random-intercept model", "text": "a special case of model (14) with where\n\" #\n. We can see now that the desired model (18) constrains the joint model (19) by\nTo see how many constraints the desired model (18) has placed on the joint model (19) , the constrained model (18) identifies p 1 \u00fe p 2 \u00fe 1 parameters, while the unconstrained joint model (19) identifies 2p 1 \u00fe p 2 parameters in \u00f0V RR ; V RC \u00de. Therefore, the constrained model (18) has p 1 \u00c0 1 fewer parameters than does the unconstrained joint model (19) . The key constraints occur in the variances and covariances (20) and (21) where the association \u03b3 1 between R and A is constrained to be the same at both levels. An alternative form of the unconstrained model (19) replaces \u03b3 1 with \u03b3 11 in eq. [20] and \u03b3 1 with \u03b3 12 in eq. [21] . This would allow the association between R and A to be different at the two levels, inducing what is known in the social science and public health applications as a contextual effects model [14] . The constraints (20) and (21) impose \u03b3 12 \u00c0 \u03b3 11 \u00bc 0, that is, no contextual effects.\nThe analysis aims to efficiently identify the environmental factors of childhood BMI such as television watching and school quality after controlling for natural growth as well as ethnic and social disparities in BMI. At level 1, over time nested within children, we model change in BMI as a function of incompletely observed TV and time. At level 2, between children nested within schools, we include incompletely observed measure of the safety around the home, age, birth weight and socioeconomic status, and completely observed female and race ethnicity indicators. At level 3, between schools, we include an incompletely observed measure of the safety of the school by GRAFFITI and a completely observed indicator for private school. In terms of our general model (30), we, therefore, have T3 T4 T5 T6 T7,  W   T 2 \u00bc \u00bdFEMALE BLACK HISPANIC ASIAN PACIFIC ALASKAN OTHER and W T 3 \u00bc \u00bd1 PRIVATE where T2 through T7 are dummy indicators for spring-K through spring-G8. Rather than subjecting the mean growth in BMI to a polynomial curve [11, 37] , W 1 controls for it as the difference in mean BMIs between each time point and fall-K. Table 4 ; \u00bd31\nWe compare the estimates to the counterparts under the MLE on Y mi . Most strikingly, the key environmental effect of television watching (TV) under investigation increases by 126% to 0.18. The gaps in mean BMIs of black, Hispanic and American Indian or Alaskan students relative to white students are noticeably underestimated and so are the intercept and the effects of T3 and T7. The level-1 and -2 error variances are understated, while the level-3 error variance is over-represented. This example is comparatively benign with only one covariate, TV, at level 1 and four covariates at level 2 subject to missingness. With more covariates subject to missingness at nested levels, this method has the potential to produce severely biased inferences. To correctly apply the MLE on Y obs for the desired hierarchical model (30) , the transformation should follow estimation of the joint model under constraints (29) :\nCC \u03b3 according to Corollary 4.3. To see how the constraints work, replace the right-hand side in eq. [31] with the constraints."}, {"section_title": "Random-coefficients model", "text": "As the number p D of random coefficients increases, the number of potentially extraneous parameters generated will increase non-linearly if no constraints are imposed. To show how aggravated the overidentification can become, consider a random-coefficients model that adds level-1 covariates E 2 having random coefficients to the model (18)\nanother special case of model (14) for\nand V CC as in the model (19) . The desired model (22) implies constraining the joint model (23) "}, {"section_title": "\u00bd25", "text": "To see how many constraints the desired model (22) has placed on the joint model (23), the constrained model (22) identifies\ncomponents in \u00f0V RR ; V RC \u00de. Therefore, the model (22) has p D2 \u00f0p 1 \u00fe p 2 \u00c0 1\u00de \u00c0 p 2 fewer parameters than does the unconstrained joint model (23) . Again, the key constraints occur in the variances and covariances (24) and (25) where not only is the association \u03b3 1 between R and A constrained to be the same at both levels, but the covariance components \u03c0 2 R1A and \u03c0 2 R12 that yield extraneous interaction effects between E 2 and C are also set to zero. That is, the desired model (22) has no contextual effects of A and no interaction effects between E 2 and C. Next, we extend the model (14) to an arbitrary number of Q levels."}, {"section_title": "Q-level model", "text": "We now focus on how to efficiently estimate the hierarchical GLM (14) for the arbitrary number of Q levels. Unlike the single-level case, however, the joint distribution (1) over-identifies the desired model (14) . This over-identification poses a major computational challenge, as it represents the components of cov\u00f0R; C\u00de \u00bc V RC that are extraneous for subsequent analysis and that rapidly multiply as Q, p and p D increase. The consequence is that estimation of the over-identified hierarchical model (14) may produce substantially biased inferences in the case of MLE on Y obs or computational problems in the case of MLE on Y mi .\nTo show the over-identification explicitly, we reexpress all random effects of the joint model (1) in Table  1 according to the decomposition Y \u00bc \u00bdR C T T as listed in Table 2 . Column q lists level-q unit-specific random effects \u03b5 q , N\u00f00; \u03c0 q \u00de that may now be partitioned as\nThe random effects \u00f0\u03b5 qR ; \u03b5 qC \u00de and their variances and covariances \u00f0\u03c0 \nT and \u03b5 3C \u00bc \u00bd\u03b5\nT . Overall, the random effects of the joint model (1) produce P Q q\u00bc1 p Dq P q r\u00bc1 p r \u00c0 p D covariance components between R and C, while the desired model (14) implies p \u00c0 1 elements in \u03b3. Consequently, the potential for severe over-identification exists if no constraints are imposed on eq. [1] .\nA key task, then, is to formulate a general approach to imposing constraints, one that applies to any value of Q and any number of covariates. The following theorem shows a conditional model the joint model (1) \nFor each covariate in Y q , the conditional model (26) expresses the association between the covariate and R to be distinct at each level s ! q, while the desired model (14) represents a single effect of the covariate on R.\nConsequently, the joint model (1) produces P Q q\u00bc1 p Dq \nT for all q in addition to the constraints (27) .\nFor another example, if the contextual effects of A are desired at level 2 but no other levels in the model (28) , then the additional constraints would be \u03b3 identifies hierarchical model (14) ."}, {"section_title": "Model (14) under the constraints (29) is equivalent to model (28) for", "text": "RjC for all s > 1 and all q. Given Q-level incomplete data, eq. [1] under constraints (29) identifies hierarchical model (14) , while the joint model under partial constraints \u0393 q such as constraints (27) may identify desired contextual effects of C or interaction effects between D and \u03b5 C [14] . All these applications may be carried out via MLE on Y obs , MLE on Y mi or a hybrid method of imputation following estimation of the constrained joint model. The choice will depend on computational feasibility and the goal of the application. Given an analyst's model (14) , MLE on Y obs constrains the joint model (1) to just identify the analyst's model, while MLE on Y mi is more generally applicable by enabling the data analyst to explore, in addition, contextual effects of C and interaction effects involving D. Consequently, MLE on Y obs is tailored to estimation of the analyst's model, whereas MLE on Y mi estimates an over-identified joint model so that it enables the data analyst to explore multiple hierarchical models for correct specification of the analyst's model. When MLE on Y mi is desired, but produces an unconstrained joint model (1) that is extremely high dimensional and thus difficult to estimate well, the hybrid method enables estimation of fewer parameters and thus reduces computational burden in estimation by imposing partial constraints such as eq.\n[27] on the joint model. Now, we consider a more general model (14) The next section illustrates an application to three-level large-scale survey data subject to missingness at all levels. We illustrate MLE on Y mi , which is more generally applicable than MLE on Y obs and the hybrid method. Estimation and multiple imputation are carried out by C programs written by the first author. The imputation program uses a random number generating library of C routines, RANDLIB 1.3 by Barry W. Brown, James Lovato, Kathy Russell and John Venier. Analysis of imputed data and complete-case analysis are carried out by HLM 7 [36] . The convergence criterion is the difference in the observed log-likelihoods between two consecutive iterations less than 10 \u00c05 . The statistical significance is discussed at a significance level \u03b1 \u00bc 0:1. The user-friendly two-level program that implements MLE on Y mi is expected to be released to the public in software package HLM 7 in the year 2014. The user-friendly three-level program is under development at the time of writing this manuscript."}, {"section_title": "Illustrative examples", "text": "In this section, we aim to identify the determining factors of BMI during childhood that may span three levels, occasions nested within a child attending a school, via analysis of the Early Childhood Longitudinal Study -Kindergarten Cohort of 1998 (ECLS-K [15] ). Specifically, we consider ethnic and social disparities in the growth of BMI and ask how environmental exposures such as television watching and school quality are associated with growth in BMI. The ECLS-K is a nationally representative sample of 21,260 kindergartners in the United States who attended 1,018 schools in 1998. The study followed the children in fall-kindergarten (K) of 1998, spring-K of 1999, fall-first grade (G1) of 1999, spring-G1 of 2000, spring-third grade (G3) of 2002, spring-fifth grade (G5) of 2004 and spring-eighth grade (G8) of 2007. Due to cost constraints, a random subsample (41-54%) of students transferring schools were followed from K to G5. Furthermore, the fall-G1 data collection was limited to 27% of base-year students in a 30% subsample of the schools. Therefore, the ECLS-K contains many item-and unit-nonresponses. For example, only 5,044 first graders had their BMI measured in fall of 1999. Consequently, researchers have analyzed the ECLS-K without the third wave in longitudinal studies of obesity [11, 13, 37] . With the G8 data available since 2009, the longitudinal analysis demands challenges as less than 7% of the children attended the same school from K to G8.\nA longitudinal analysis of the ECLS-K should involve all seven waves of data to yield efficient analysis. Furthermore, missing data may be present at multiple levels. The approach in this article enables all waves and available data to be analyzed for efficient and unbiased inferences. The \"all available data\" include children with item-as well as unit-nonresponse, because a child with time-varying characteristics missing but individual or school characteristics observed strengthens inferences at higher levels [29, 30] . Mobile students transferring schools are nested within their original schools in fall-K and analyzed.\nFollowing the previous studies of the ECLS-K [11, 12, 37, 38] , we analyze the raw BMI as a ratio of body weight in kg to height in meters squared. Table 3 summarizes the data for analysis of 21,210 children who attended 1,018 schools in 1998 after dropping 50 children with most characteristics missing including gender and race. Also dropped are 6 eighth-grade BMIs ranging 98-207 that are influential on the fitted regression and 13 extraneous heights and weights such as a 20-pound weight and a height reduced by more than 10 inches.\nAfter dropping the influential and extraneous observations, the standard deviation of G8 BMIs reduces from 6.29 to 5.29. With seven occasions nested within most children, there are a total of 148,451 occasions at level 1 nested within 21,210 children at level 2 attending 1,018 schools at level 3. BMI and the daily number of hours spent watching television (TV) are time varying [11, 13, 37] . The BMI ranges 7.1-57.5. To produce TV, maximum daily television viewing hours exceeding 7 per weekday and 10 per weekend day were set to 7 and 10 hours, respectively. TV was measured in spring-K for the first time and then once in every other data collection. It is unreasonable to think that the TV values between fall-K and spring-K for each child are different enough to treat all the values missing in fall-K. The analysis uses the TV measured in spring-K for the first two data collections. In addition, the analysis considers six dummy time indicators from spring-K to G8 to control for the natural growth in BMI at level 1; base-year home neighborhood safety (HOMESAFETY), base-year age in months (AGE), birth weight in pounds (BIRTHWEIGHT), base-year socioeconomic status (SES), a female indicator (FEMALE) and six race ethnicity indicators at child level or level 2; and base-year school neighborhood safety (GRAFFITI, the amount of graffiti around school) and a private school indicator (PRIVATE) at school level or level 3.\nAn unsafe neighborhood is associated with elevated BMI among adults [28] . HOMESAFETY has three scales: not safe or low (0); somewhat safe or medium (1); and very safe or high (2), while GRAFFITI, the lower the safer, has four scales: none (0); a little (1); some (2); and a lot (3) . Preliminary analysis shows that higherorder than linear association between the safety factors and BMI is unlikely. BMI and TV miss 38 and 44% of their values overall and 76 and 77% in fall-G1, respectively. HOMESAFETY, AGE, BIRTHWEIGHT and SES miss 5-11%, while GRAFFITI is missing for 26% of the schools. Complete-case analysis entails removing the 262 schools with missing GRAFFITI and dropping 5,381 students attending the schools and their data from analysis. The resulting inference is inefficient and may be considerably biased as will be illustrated below. The 2,166 missing birth weights in fall-K were recovered from later data collections. The 21,210 students are 49% female and 55% white. Out of the 1,018 schools, 26% are private. The mean BMI grows with acceleration until G5."}, {"section_title": "Random-coefficients model with missing data", "text": "The analysis above reveals that black, Hispanic and American Indian or Alaskan students have elevated BMIs relative to white counterparts on average controlling for other covariates in the model. The minority students may attend lower-quality schools than those that white counterparts attend which, by hypothesis, contributes to the disparity in BMI. School quality may be indicated by school characteristics such as school safety, school-mean socioeconomic status, contents of school meals, physical education time and school sector [12, 13, 37] . If this hypothesis is true, then the minority students may have a randomly varying effect on BMI across schools of different qualities. Among the minority students, Hispanic students stand out in BMI. Overall, Hispanic students are half as likely to attend private schools as white students. They also attend schools having about three times as much graffiti around as those that white students attend on average.\nThe random-intercept model above is extended to a random-coefficients model where the Hispanic indicator has a random effect on BMI across schools. The desired model (30) has\n! and all other components identical to those of the random-intercept model. The corresponding unconstrained joint model (1) has an 8-by-8 covariance matrix \n=m [6] . The p-value is P\u00f0F 2;\u03bd > D\u00de \u00bc 0:59 where F 2;\u03bd is a random variable from the F distribution with 2 numerator and \u03bd denominator degrees of freedom for \u03bd \u00bc \u00f0m \u00c0 1\u00de\u00f01 \u00fe 1=r\u00de 2 =2 3=m \u00bc 974. This test yields an approximate range of p-values between twice and one half the computed value [6, 40] . The computed p-value 0.59 gives enough precision to conclude the random-intercept (null) model. Therefore, we do not find evidence that the slope for the Hispanic indicator varies randomly across schools. The unconstrained joint model identifies 18 covariance components between R and C, while the desired random-coefficients model has six effects of C on R. Consequently, 12 covariance components between R and C are extraneous for subsequent analysis. Constraints to identify the desired model via MLE on Y obs are\nCC \u03b3 and \u03c0 "}, {"section_title": "Discussion", "text": "This article presented methods for efficient and unbiased analysis of a Q-level hierarchical GLM given incomplete data with a general missing pattern at any of the Q levels. Our general approach uniformly expresses the Q-level model for Q ! 1 that greatly facilitates extension of existing single-level and two-level efficient missing data methods to general Q-level data; reexpresses the desired model as a joint distribution of the variables, including the outcome, that are subject to missingness conditional on all of the covariates that are completely observed and efficiently estimates the joint distribution. This approach confronts two major challenges. As the number of Q levels, the number, p, of variables subject to missingness and the number, p D , of random coefficients increase in the hierarchical model, the joint distribution may become extremely high dimensional and difficult to estimate well. Moreover, the joint model, in general, overidentifies the desired hierarchical model. The problem of over-identification can grow severe as levels, covariates, and random coefficients are added to the hierarchical model. The consequence is that the overidentified hierarchical model may produce considerably biased inferences as was illustrated in this article.\nTo overcome the computational challenges, we derived, within each iteration of the EM algorithm, recursive Q-step computation formulas for efficient estimation of the joint distribution where computation at each step involves single-level data only given higher-level computation components. The consequence is efficient computation that is not excessively burdened with regard to Q, p and p D . Furthermore, we showed how to impose constraints on the joint distribution within the framework of the Q-level hierarchical model in a way that is uniform without regard to Q and in a way that produces unbiased and efficient analysis of the hierarchical model. MLE on Y obs by allowing an analyst to explore multiple hierarchical models for the correct specification of the desired model. We may also take advantage of extra variables not of direct interest in the desired hierarchical model, but highly correlated with variables subject to missingness to more precisely impute missing data at multiple levels [28] . The ECLS-K has a great majority of students transferring schools. Thus, it may be more appropriate to consider a cross-classified model for the analysis that relaxes the strict hierarchy of nesting a student within a single school. Estimation of a cross-classified model is challenging, because the growths in the outcome of students while attending the same schools become depentent to produce a complicated network of dependence among children and schools [9] . All schools for each child and all children for each school may have to be analyzed at once to fully account for the dependence. With many covariates subject to missingness at multiple levels, the joint model of variables subject to missingness may be too highly dimensioned to estimate well. Therefore, a valuable future research topic is development of a method for efficient estimation of a cross-classified model given incomplete data.\nOne restriction of the general Q-level hierarchical model is that the covariates having random effects should be completely observed. If the covariates are subject to missingness, they should appear on the left-hand side of the corresponding joint model for efficient handling of the missing data as well as on the right-hand side of the model for estimation of the random coefficients. Such a joint model is not multivariate normal, and the factorization under joint normality that leads to the desired conditional hierarchical linear model does not apply. Consequently, the ML approach is challenging. Relaxing this assumption is beyond the scope of this article.\nIt took 21 seconds to complete each iteration in estimating each joint model in Table 4 on a 2.8 GHz laptop computer that has 8 GB memory. The estimated random-intercept and -coefficients models took more than 5 hours to converge at 867th and 894th iterations, respectively. No attempt to accelerate the convergence has been made. The convergence criterion is the difference in the observed log-likelihoods between two consecutive iterations less than 10\n\u00c05 . In some of our two-level test runs, we compared computation times for estimation of a joint model between our program with a convergence criterion of the difference in log-likelihoods between two consecutive iterations less than 10 \u00c06 [28] , and an alternative program with a convergence criterion of the percentage difference in log-likelihoods between two consecutive iterations less than 10 \u00c06 and the Aitken acceleration [41] , the alternative program converged not only to practically identical estimates and standard errors but up to 90% faster than did our program in terms of the number of iterations. Considerable saving in computation time is anticipated with the likewise acceleration in the three-level applications. It took us about 2 minutes to generate a single imputation for the results in In Section 5.2, we found no evidence that the slope for the Hispanic student indicator varies randomly across schools, based on the test statistic recommended by [39] . This test provides an approximate range of pvalues between twice and one half the computed p-value. More accurate p-values may be obtained at the expense of extra computational effort [2, 6, 39, 42] . Because the corollaries to Theorem 4.1 establish one-to-one correspondence between hierarchical model (30) and joint model (1), the MLE on Y obs enables an alternative likelihood ratio test between the two analyst's models directly based on their constrained joint models.\nOur illustrative examples in Section 5 are based on a large sample. The performance of our estimators in terms of bias and efficiency involving a small sample is yet to be assessed. Therefore, simulation studies on the small-sample performance of our methods will be a useful future research area.\nThe analysis in this paper involved discrete covariates, the safety factors, subject to missingness at levels 2 and 3. Although it is improper for the normal linear joint model to describe the marginal distribution for the discrete factors, the implied conditional distribution is the desired hierarchical model. An advantage is that it allows the discrete covariates subject to missingness to be analyzed by the efficient missing data method [6, 28] . In addition, the impact of the joint distribution assumptions on the desired conditional model by the MLE on Y mi is comparatively weak because the distributional assumptions do not affect the observed data. A valuable future extension of this approach is to a hierarchical generalized linear model given incomplete data. "}, {"section_title": "Fisher information", "text": "We express V "}, {"section_title": "Likelihood", "text": "The observed log-likelihood l\u00f0\u03b8jd obs \u00de / \u00c0 "}]