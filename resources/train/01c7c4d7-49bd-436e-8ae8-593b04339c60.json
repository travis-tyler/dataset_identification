[{"section_title": "Abstract", "text": "Abstract. We propose a unified Bayesian framework for detecting genetic variants associated with a disease while exploiting image-based features as an intermediate phenotype. Traditionally, imaging genetics methods comprise two separate steps. First, image features are selected based on their relevance to the disease phenotype. Second, a set of genetic variants are identified to explain the selected features. In contrast, our method performs these tasks simultaneously to ultimately assign probabilistic measures of relevance to both genetic and imaging markers. We derive an efficient approximate inference algorithm that handles high dimensionality of imaging genetic data. We evaluate the algorithm on synthetic data and show that it outperforms traditional models. We also illustrate the application of the method on ADNI data."}, {"section_title": "Introduction", "text": "In this paper, we propose a generative probabilistic model for genetic variants associated with a disease using imaging data as an intermediate phenotype. The search for genetic variants that increase the risk of a particular disorder is one of the central challenges in medical research, and has been traditionally performed via genome-wide association studies (GWAS). Such studies examine each genetic marker and its correlation with the incidence of the disease independently of all other genetic markers in the study. However, some variants may have a weak but cumulative effect that cannot be identified by traditional GWAS analysis [12] . Imaging genetics introduces imaging-based biomarkers as a promising intermediate phenotype (i.e., endo-phenotype) between genetic variants and diagnosis. Imaging provides a rich quantitative characterization of disease and promises to aid in identifying genetic variations that are correlated with the clinical variables [1, 17] . Furthermore, multivariate analysis using imaging endo-phenotypes promises to stratify the population in more informative ways than the binary diagnosis. A commonly used approach in imaging genetics is to isolate image-based features affected by the disease, and then identify the relevant genetic markers that explain the observed image variations. In this work, we jointly model image-based phenotypes and clinical indicators to identify genetic variants associated with the disorder.\nImaging genetics presents numerous challenges in clinical studies due to the relatively small number of subjects and extremely high dimensionality of images (hundreds of thousands of voxels) and genetic data (millions of single nucleotide polymorphisms (SNPs)). To address the problem of high dimensionality and small sample size, earlier algorithms considered only a few imaging candidates (voxels, regions, or other biomarkers) or only a few genetic markers in the analysis [5, 15] . The reduced joint dataset is then analyzed in a univariate testing framework, where each pair of a candidate genetic variant and an imaging biomarker is tested for association via a standard statistical test. Examples include using activation maps of the prefrontal cortex to find SNPs associated with schizophrenia [15] , and searching for changes of gray matter volume correlated with the Alzheimer's Disease risk factor APOE gene [5] .\nMore recently, genome-wide voxel-wise analysis has been demonstrated using univariate methods [18] . Unfortunately, massive univariate analysis has several limitations. Due to multiple comparisons, a corrected conservative significance level is selected to limit the false positive rate, but this also dramatically reduces the power of the test. Moreover, the univariate methods are unlikely to identify weaker variants that jointly create an additive effect.\nMultivariate techniques aim to overcome shortcomings of univariate analysis [9, 20] . A common approach is to use multivariate regression combined with regularization to extract a sparse set of coefficients for correlated genetic variants and image features. For example, low rank representations can be approximated via sparse reduced rank regression (sRRR) [19, 20] , Partial Least Squares (PLS) [9] or Canonical Correlation Analysis (CCA) [9] . Unfortunately, these unsupervised methods do not use the subject class label (e.g., diagnosis) directly, and thus the detected genetic markers and image features are not immediately related to the disease of interest. The image features relevant to the disease are identified separately from modeling the relationship between the genetic and imaging data. For example, sRRR has been demonstrated using brain regions pre-selected for Alzheimer's disease (AD) via Linear Discriminant Analysis [19] . In contrast, we model and estimate relevant genetic variants in the context of a particular disease. Our method is applicable to any set of image biomarkers, such as anatomical regions, tissue appearance, or functional measures. We are motivated by applications to the AD and use local measures of atrophy as image features.\nOur model includes a common assumption of genetic studies that only a small set of SNPs is associated with any particular disease. This subset of genetic markers induces variation in certain image-based features, and a subset of these measures exhibits changes that are discriminative with respect to the disease phenotype. Therefore, if a brain region is irrelevant to the target disease, it is ignored even if its measures are highly correlated with some genetic variants.\nIn the remainder of the paper, we define a generative model for the relationship among genetic, imaging and disease measures, derive an efficient inference algorithm to identify relevant brain regions and genetic loci, and demonstrate the method on synthetic data and the ADNI study [13] . We show that our algorithm outperforms standard univariate and regression analysis for genetic variant detection on synthetic data and yields promising results on real data. "}, {"section_title": "Model", "text": "Our model structure is illustrated schematically in Fig.1 . We are motivated by anatomical brain studies, but the model is general. Let y n be the disease phenotype (0 or 1) for subject n in the study (1 \u2264 n \u2264 N ). Let x n and g n be vectors of M imaging biomarkers (features) and S genetic markers (SNPs) for subject n, respectively. We capture the overall process via two coupled regression models: a logistic regression predicts class label y n from image features x n ; a ridge regression associates genetic variants g n with image features x n . The graphical model in Fig.2 presents the relationships among variables of the model. All variables are summarized in Table 1 . Below, we first define the relationship between imaging features and the disease phenotype and then specify the generative model for the relationship between SNPs and image features. Note that we do not model a direct link between genetic variants and disease label, but it is captured indirectly through image features."}, {"section_title": "From Imaging Features to Disease Phenotype", "text": "We adopt a Bayesian model based on logistic regression for predicting binary class label y n from image features x n [2] :\nwhere \u03c8(a) = 1 1+e \u2212a is the logistic function and \u03b7 \u2208 R M are the regression coefficients that we treat as latent random variables. Similar to prior work [3] , we propose to use a spike-and-slab prior to promote sparse solutions for the regression coefficients \u03b7 [7, 14] :\nwhere \u03b4(\u00b7) is the Delta Dirac distribution concentrated at 0, parameter \u03b2 controls sparsity (0 \u2264 \u03b2 \u2264 1), and N (\u00b7; \u03bc, \u03c3 2 ) is a Gaussian distribution with mean \u03bc and variance \u03c3 2 . In a deterministic regression context, one can view the spike-and-slab prior as a combination of 0 and 2 norms for regularization. We find it convenient to introduce a latent Bernoulli random variable b m that selects the regime for the regression coefficient \u03b7 m :"}, {"section_title": "From Genetics Variants to Imaging Features", "text": "In modeling the relationship between genetics and imaging, we treat image features relevant for disease prediction differently from all other image features. If feature m is relevant for disease prediction (i.e., b m = 1), variations in the values of this feature are explained by a sparse subset of the genetic variants g n \u2208 R S . We define a m \u2208 {0, 1} S to be a vector of latent Bernoulli random variables that specify a subset, or mask, of relevant genetic markers that affect feature m, and arrive at the second regression component of our model:\nwhere v m is the vector of regression coefficients, nm \u223c N (\u00b7; 0, \u03c3 2 0 ) is the noise in the image feature m in subject n, and \u00b7, \u00b7 and denote the inner and element-wise products, respectively. While an obvious modeling choice for regression coefficients {v sm } would be to treat them as latent random variables with a spike-and-slab prior, the large number of such variables (S \u00d7 M ) makes it computationally intractable. We therefore model regression coefficients {v sm } as unknown but deterministic variables.\nIf image feature m is irrelevant for predicting disease (i.e., b m = 0), we do not model genetic contributions, and assign the probability mass uniformly between the observed feature values, i.e., p(x) = 1 N \u03b4(x \u2212 x nm ). Furthermore, we set a sm = 0 with probability 1 for all s. Combining the two regimes, we obtain the genetic selection prior:\nand the image feature likelihood:"}, {"section_title": "Complete Model", "text": "We define Z = {\u03b7, b, A} to be the set of latent variables, D = {X, y} to be the set of data variables that we model, and \u03c0 = {\u03c3 "}, {"section_title": "Inference", "text": "Our goal is to compute the posterior probability p(Z|D; G, V, \u03c0) of the latent variables that summarizes genetic and imaging influences in our model. Because of coupling of variables in the joint model, computing the posterior distribution is intractable, necessitating approximation via sampling or variational methods. Due to the amount of data and its dimensionality, sampling is computationally impractical. We therefore derive a Variational Bayes approximation [2] that estimates the lower bound for the log-likelihood p(D; G, \u03c0) and seeks distribution q that minimizes the cost functional:\nThe optimal distribution q provides an approximation to the posterior distribution p(Z|D; G, \u03c0) [2] . We choose a factorization for the distribution q that captures most model assumptions and yet is computationally tractable:\nwhere:\nVariational parameters \u03c1 m , \u03bd m , \u03c2 m and \u03c4 s of the approximating distribution q define the optimization space. In this formulation, the estimate of \u03c4 s is interpreted as relevance of the genetic variant s. The estimate of \u03c1 m provides a measure of relevance for image feature m. We define {\u03c4 , \u03c1, \u03bd, \u03c2} to be the set of all parameters \u03c4 s , \u03c1 m , \u03bd m , \u03c2 m . Given the parametrization above, all terms in the cost function F (q) can be optimized analytically, except for the logistic regression term p(y n |\u03b7, x n ). For this term, we employ the variational treatment [8] that leads to improved accuracy over Laplace approximation [2] and has been successfully used in prior work [3] . Specifically, we replace the logistic function with its lower bound:\nwhere \u03be n controls the tightness of the lower bound for subject n and should be optimized. We define \u03d1 = {V, \u03c4 , \u03c1, \u03bd, \u03c2, \u03be} to be the full set of parameters of distribution q, where V and \u03be are deterministic parameters of the model, and the rest are parameters of q. Using Eqs. (7)- (9), we can maximize F (q) = F (\u03d1) by updating elements of the variational parameter vector \u03d1. We omit the derivations due to space constraints, but summarize the resulting updates in Appendix A.\nEvery update iteration reduces the cost function F (\u03d1), which in turn brings q closer to the posterior distribution p(Z|D, G; V, \u03c0).\nOur imaging genetics regression bears resemblance to previously demonstrated sRRR regression [20] that considers X = GV. Our update for V can be viewed as a solution of a system of linear equations:\nwhere \u2020 indicates a pseudo-inverse, and the second term diag( 1\u2212\u03c4 \u03c4 ) weighs the SNPs based on their importance. We do not impose rank or sparsity constraints on the regression coefficients matrix V, although they can be added in a fashion similar to [20] ."}, {"section_title": "Results", "text": "We evaluate our model on synthetic data using univariate tests and the sRRR method [20] as baseline algorithms. We also illustrate our method on the ADNI dataset, where we recover several top SNPs associated with the risk of AD."}, {"section_title": "Synthetic Data", "text": "We generate synthetic data to match a realistic scenario as much as possible. In this section, minor allele frequency (MAF) refers to the frequency of the less common allele in the population at a particular genetic location. A genetic marker (or SNP) g ns is represented by the count of minor alleles at location s in subject n, i.e., g ns \u2208 {0, 1, 2}. We employ the widely used population genetics software package PLINK [16] to simulate 1,020 SNPs with a minor allele frequency uniformly sampled from an interval [0.05, 0.95], for 400 healthy subjects and 400 patients. For SNPs relevant to the disease, the heterozygote odds ratio is defined as the ratio of patients to controls with g ns = 1, normalized by the same ratio for g ns = 0. Similarly, one can define the homozygote odds ratio. These ratios control the disease risk in the patient population. The simulated SNPs are split into three sets:\n\u2022 Set G 1 includes 20 disease causative SNPs that affect selected areas of simulated images. The odds ratio is set to 1.125 for heterozygote SNPs, with a multiplicative homozygote risk. Other odds ratios yield similar results (we tested 1.0625 to 1.5, not shown due to space constraints).\n\u2022 Set G 2 includes 20 SNPs that are irrelevant to the disease (i.e., odds ratio is 1) but affect other areas in simulated images.\n\u2022 Set G 3 includes 980 null SNPs that are independent of both label and images. Based on the class labels and the genetic variants, we generate image voxels, organized in several sets:\n\u2022 Voxels in set I 1 are affected by causative SNPs (G 1 ), and thus are indirectly associated with the disease. These voxels are separated into three regions. Voxel intensity in this set is correlated with genetics:\nwhere c r nk is the intensity value of voxel k in region r for subject n. The region weights w r are drawn from a normal distribution N (\u00b7; 0, 1), and r kn is Gaussian noise. Our experiments explore a range of values for the noise variance \u03c3 2 noise .\n\u2022 Voxels in set I 2 are determined by non-causative SNPs G 2 , and thus are irrelevant to disease. We dedicate one region to this category: \u2022 Voxels in set I 3 are related to the disease but are not related to genetic markers, and are therefore not helpful in causative SNP detection. In fact, such features confuse the detector as they get selected as relevant to disease at the cost of features in I 1 . We generate these voxels as follows:\n\u2022 Voxels in set I 4 are not relevant to either label or genetic markers. These voxels are sampled from N (0, \u03c3 2 noise ).\nWe use the synthetic data to evaluate detection of disease causative SNPs with our method. We observe that our algorithm is not sensitive to the hyper-parameters, which we set as follows: log to the variance of image features. As a first baseline, we perform univariate Bonferroni corrected ttests directly between SNPs and class labels, omitting imaging. As a second baseline, which we refer to as supervised sRRR, we perform univariate voxel filtering using class labels, followed by sRRR multivariate regression between surviving voxels and genetic variants to recover relevant SNPs [20] . We compare the methods in different image noise regimes by varying the variance \u03c3 2 noise in Eqs (10)- (11), and run 50 different independent simulations for each noise regime. Fig.3 (a) reports detection rates (TP) of disease causative SNPs in G 1 . To set the detection thresholds we fix the false positive rate to 1%. We observed similar behavior for a broad range of low false positive rates (not shown). We focus our experiments on low false positive rates because at higher rates false detections become comparable with, and ultimately overwhelm true detections. We find that for a given false positive rate, our algorithm detects significantly more disease causative SNPs in G 1 than the baseline algorithms, and has lower standard deviation than the supervised sRRR pipeline. The direct univariate t-tests only detect SNPs that have a very strong independent association with disease label. To illustrate the behavior of the methods at different false positive rates, we report the receiver operating characteristic at two different noise levels in Fig.3(b,c) . Our approach achieves a better detection than the baseline methods. "}, {"section_title": "ADNI Dataset", "text": "We apply our method on a subset of the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset that includes T1-weighted MR images and 620,000 genetic variants for 228 AD patients and 187 normal controls (NC). All images were pre-processed and non-rigidly aligned to a common [4] . We compute the tissue density map, indicating expansion or contraction of gray matter using the determinant of the Jacobian of the deformation field. The map values in the template space are proportional to the volume of structures in the original brain scan. To reduce image dimensionality, we aggregate voxels into supervoxels using spatial k\u2212means clustering [11] and obtain about 1700 supervoxels. We define our image features x nm as the average value of the tissue density map in a supervoxel. We use a SVM classifier to asses the discriminative power of the resultant features and obtain 86% classification rate of AD versus NC, close to the state-of-the-art results [4] . We used the ENIGMA protocol to pre-process the genotype data 1 . Briefly, PLINK was used to eliminate SNPs on the basis of standard quality control criteria, e.g., low MAF (< 0.01), poor genotype calling (call rate < 95%) and deviations from Hardy-Weinberg equilibrium (P < 1 \u00d7 10 6 ). We then performed imputation using the Mach software 2 . Finally, we pre-selected 960 SNPs that have the strongest association with AD overlapped with SNPs reported in a prior AD-GWAS study involving over 16,000 individuals [6] .\nWe ran our algorithm with 10 initializations, and selected the run that achieved the lowest value of the cost function. As before, we set: log x is the variance of image features. Fig.4 illustrates the posterior probabilities of SNP relevance \u03c4 , averaged over the swept parameters. We list the top SNPs in Table 2 . The top variants are APOE-4 and APOE-3, which are strongly correlated with AD [6] . We also detect variants on APOC1, TOMM40 and PVRL among our top hits, all of which are on chromosome 19 and have been frequently reported [6] . Similarly, several chromosome 22 variants are identified [10] . Fig.4 illustrates the average posterior probability of feature relevance \u03c1. Among high probability regions are hippocampus and temporal lobe, which have been frequently reported to undergo significant shrinkage in AD [4] , and are associated with memory."}, {"section_title": "Conclusion", "text": "We proposed and demonstrated a unified framework for identifying genetic variants and image-based features associated with the disease. We capture the associations between imaging and disease phenotype simultaneously with the correlation from genetic variants and image features in a probabilistic model. We derive an algorithm that iteratively refines the relevant variants using disease phenotype and imaging features. It also isolates representative features that are discriminative with respect to the disease and are modulated by the genetic variants. We demonstrated the benefit of simultaneously performing these two tasks in simulations and in a context of a real clinical study."}]