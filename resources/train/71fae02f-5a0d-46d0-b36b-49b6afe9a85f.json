[{"section_title": "Abstract", "text": "The Ruth L. Kirschstein National Research Service Award (NRSA) program is a major research training program administered by the National Institutes of Health (NIH) with funds appropriated each year by Congress. This study examines the impact of NRSA postdoctoral fellowships on subsequent research-related career outcomes using NIH administrative records on applicants who applied for a fellowship between 1996 and 2008. We find that postdoctoral fellowships increased the probability of receiving subsequent NIH research awards from 6.3 to 8.2 percentage points and of achieving an NIH-funded R01 award, an indication of an independent research career, from 4.6 to 6.1 percentage points. Our findings demonstrate that the NRSA postdoctoral fellowship awards have the potential to promote retention of scientists in NIH-funded research and in the biomedical workforce pipeline."}, {"section_title": "INTRODUCTION", "text": "The National Institutes of Health (NIH) has advanced the frontier of biomedical research and innovation since its inception in the 1930s. The NIH mission includes funding and training the next generation of scientists. Since 1974, the NIH has formally committed to training highpotential, early-career scientists to carry out the nation's biomedical research agenda through the congressionally mandated Ruth L. Kirschstein National Research Service (NRSA) Award.\nWhile the NRSA programs are subject to periodic review (National Research Council 2011), few researchers have specifically examined the impact of NIH's investment in the NRSA F32 postdoctoral program on subsequent receipt of NIH funding for research. Using NIH administrative records on applicants and awardees of NRSA F32 fellowships between 1996 and 2008, this study provides evidence that an F32 fellowship substantially increases the likelihood of obtaining subsequent NIH research funding, including the probability of an NIH R01 grant, which is a major indicator of transition to an independent biomedical research career.\nWe examine two questions: (1) Does the NRSA F32 fellowship affect the likelihood of future NIH funding? These outcomes are measured by whether a fellowship applicant or awardee applies for or receives a Research Project Grant (RPG) award, 5 the number of RPG awards, and whether they appear as an NIH RPG applicant four years or more from the time they applied for the NRSA F32 award; (2) Does the NRSA F32 award contribute to an NIHfunded independent research career? This outcome is measured by the probability of receiving an NIH R01 award, considered a milestone that establishes an independent research 5 In recent years, Research Project Grant awards include the following grant mechanisms: R00, R01, R03, R15, R21, R33, R34, R35, R36, R37, R50, R56, R61, RC1, RC2, RC3, RC4, RF1, RL1, RL2, RL9, P01, P42, PM1, PN1, RM1, UA5, UC1, UC2, UC3, UC4, UC7, UF1, UG3, UH2, UH3, UH5, UM1, UM2, U01, U19, U34, DP1, DP2, DP3, DP4, DP5. For more information, see: https://grants.nih.gov/grants/glossary.htm#ResearchGrants. While the definition of RPGs changes slightly from year to year, these mechanisms give a general overview of the mechanisms generally included in research project grant awards. 5 career, four years or more after applying to the NRSA F32 award (Science Careers Editors 2007 , Rockey 2014 . We use the scoring of fellowship applications and matching techniques that allow us to analyze the outcomes of individuals who received the fellowship award from those whose application scores and observable characteristics are similar, but who did not receive an award.\nWe find that the average treatment effect of an NRSA F32 postdoctoral award (for all applicants) increases the future probability of receiving NIH research funding by anywhere from 6.3 to 8.2 percentage points and the probability of receiving NIH R01 funding by anywhere from 4.6 to 6.1 percentage points on average. We find that the benefits are slightly larger for the average treatment effect on the treated (for those who received the award), increasing the probability of receiving NIH funding by 7.0 to 8.8 percentage points and the probability of receiving an NIH R01 award by 4.9 to 6.5 percentage points. Overall, this study provides evidence demonstrating the positive impact of the F32 program and informs policymakers regarding the value of future investments in the program.\nThe paper proceeds as follows. First, we review the literature on the effect of particular postdoctoral and graduate appointment types on career outcomes. Second, we introduce the NRSA F32 fellowship award and scoring process. Third, we discuss the data. Fourth, we examine the fellowship award process and our matching identification strategy. Fifth, we evaluate the results and robustness checks. Finally, we conclude with our discussion of the impact of the NRSA F32 award on career outcomes. 6 "}, {"section_title": "BACKGROUND", "text": "The NRSA program has multiple award mechanisms that fund research training in biomedical science (NIH 2001; NIH 2002; NIH 2003) . These include institutional training programs for undergraduates, graduate students and postdocs and individual fellowships for graduate students pursuing PhD students or postdoctorates. Historically, NRSA fellowships have been highly competitive. In 2008, the NIH allocated around $751.2 million in funding to NRSA programs to support research training for 16,370 undergraduate students, graduate students and postdoctoral researchers (https://report.nih.gov/nihdatabook/NIH Office of Budget, 2017) . 6 Of these NRSA awardees or appointees 1,487 (around 9.1% percent) received the NRSA F32 postdoctoral fellowship award. Between 1998 7 and 2008, the number of F-series fellowship awards funded by the NIH increased by 15.2 percent, as shown in panel A of Figure   1 . While NIH increased the total number of F-series awards, it also diversified the F-mechanism by funding more positions in other F-series awards, causing the total number of NRSA F32 postdoctoral fellowship awards funded in any given year to decrease over the period by 21.9 percent (see Figure 1 , panel A).\nOur analysis focuses only on the NRSA F32 postdoctoral award, which is an award applied for or received prior to or during a transition toward research independence. Also important to note is that even though overall the F-series fellowship awards have experienced growth over the period of our study, they grew much more slowly than the number of PhDs conferred in biological sciences during that time. According to the National Science Foundation, the number of new PhDs in biomedical sciences grew annually from 5,838 in 2000 to 7,797 in 2008, an increase of 33.6 percent between 2000 and 2008 (Fiegener, 2011). 7 "}, {"section_title": "The Effect of Postdoctoral Study on Career Outcomes", "text": "There are a limited number of studies that have examined the impact of a postdoctoral appointment (postdoc) on later career outcomes. Those that do have combined many academic fields making it difficult to generalize the results to fields like biomedical science (Su 2013 , Levitt 2010 , National Science Board 2014 , Nerad & Cerny 1999 . Several studies investigated the impact of a postdoc on subsequent placement in academic careers. Su (2013) found that longer duration postdocs are not associated with improved academic placements. Levitt (2010) examined the association between the 1992-94 cohorts of NRSA F32 postdocs and their subsequent biomedical careers. He found significant gender differences in outcomes; women were more likely to leave scientific research careers than men. Career trajectories of women appeared to be affected by measures related to their mentor's quality. For female postdocs, the higher the mentor's h-index, the more likely the postdoc was to receive an NIH grant. Levitt concludes his study by raising the possibility that his results may not be extrapolated to more recent NRSA cohorts.\nSome studies indicate a negative impact of postdoctoral and graduate appointments. Kahn and Ginther (2017) found that individuals who took a postdoc in biomedical fields were paid substantially less in future employment than those who skipped the postdoc. Although the postdoc was useful for obtaining an academic tenure-track research position, Kahn and Ginther found that the likelihood of achieving this goal dropped considerably over time. Blume-Kohout (2016) used the Survey of Earned Doctorates to examine whether graduate research assistantships or grants were more effective at launching research careers than graduate student support by NIH training grants or fellowships. Surprisingly, she found that graduate students with research assistantships had more successful research outcomes in terms 8 of research-focused jobs (Blume-Kohout 2016) although this study did not address postdocs funded by different mechanisms. The evidence on the impact of postdoctoral and graduate training on later career outcomes in general is mixed, and the evidence on the impact of NRSA postdoctoral fellowships using an adequate methodology in particular is limited, prompting this study. That said, studies assessing the impact of federal investments in training the biomedical research workforce, including evaluation studies commissioned by the federal government, show that individuals participating in NIH training programs experience higher rates of remaining in scientific research in comparison to their counterparts who did not receive formal NIH training (Pion 2001; Mantovani et al 2006) .\nOur work is most closely related to studies by Jacob and Lefgren (2011a, 2011b) . Using a regression discontinuity design (RDD), these authors found that receiving an NIH postdoctoral fellowship increased publications by 20 percent in the next five years relative to non-awardees (Jacob and Lefgren 2011a) . In addition, their study found that NIH postdoctoral fellows received higher dollar amounts in subsequent NIH funding compared to non-awardees. Our analysis below indicates that RDD has limitations for estimating the impact of the NRSA F32 award because not all NIH institutes and centers fund NRSA F32 proposals in the order of the score received. A detailed discussion of the F32 application, review and award process is discussed below."}, {"section_title": "The NRSA F32 Postdoctoral Proposal Process", "text": "A thorough understanding of the NRSA application and award process is necessary for the development of our empirical approach. The goal of the NRSA F32 award is \"to enhance the research training of promising postdoctoral applicants who have the potential to become We posit that applicants who meet the basic requirements for the NRSA F32 award are willing to apply if the benefit of winning is higher than the cost of applying. Applicants are required to have a research doctorate or professional degree by the time of the award, be a citizen or a permanent resident of the United States, and have a sponsor (who functions as a mentor), and a sponsoring institution. All of these requirements limit the size of applicant group and make it more homogeneous, limiting the impact of unobserved characteristics on the probability of receiving an award.\nSelection to receive an NRSA F32 fellowship award depends on multiple measures: First, each new application is evaluated for scientific merit by an NIH Scientific Review Group (SRG), which, for the most part, is developed and run by the NIH Center for Scientific Review (CSR). 10 CSR is an independent body that provides institutes services related to peer review, as well as documenting the evaluation and scoring of applicants. NIH SRGs for NRSA F32 fellowships, like SRGs for other funding mechanisms, include accomplished scientists and experts as external reviewers. The SRG evaluation considers observable characteristics of the applicants, (the applicant's past academic and research records, publications); observable characteristics of the sponsor (the sponsor's general qualifications); research potential, , (references, the applicant's research goals); research environment (training environment); the research proposal, , plus the perception of the reviewer in that period . Each reviewer, r, assigned to an application, i, for institute or center, j, in a particular year, t, and council round, q, gives a preliminary reviewer overall review score, , for each application defined as:\n(2)\nEquation 2 gives a final overall review score, , for each discussed application, i, who applied to an institute or center, j, in year, t, in council round, q, and is simply determined by the mean score of all SRG members' preliminary scores. NIH review panels score proposals A sharp regression discontinuity design is appropriate if, NIH institutes and centers fund the majority of proposals in the order of the score. Aberrations in funding of proposals with review scores near the cutoff would constitute a fuzzy regression discontinuity design. However, if institutes skip several (competitive) low-scoring proposals and reach for higher scoring proposals that are more consistent with institute priorities or because of other administrative hurdles on low-scoring applications, then an RDD has limitations. We turn now to the data before evaluating the appropriate methods for determining the impact of the F32 award on subsequent career outcomes."}, {"section_title": "DATA AND METHODS", "text": "We use administrative records from the NIH's Information for Management, Planning, Analysis, and Coordination (IMPACII) system from 1996 to 2008. NIH matches IMPACII records to data from the National Science Foundation's (NSF) Survey of Earned Doctorates (SED), an annual census of doctoral recipients from U.S. institutions. 11 The NSF SED contains information on individual demographics, characteristics of graduate study, and future career 13 plans. By linking these datasets, we are able to obtain missing data and add additional individuallevel covariates on our sample. We used demographic variables before or at the point of PhD completion extracted from the SED including age at PhD completion, gender, race/ethnicity, marital status at PhD completion, PhD field of study, and type of doctorate education funding.\nWe used the two data sources to construct one large panel dataset for analysis, limiting our sample to those who applied for NRSA F32 funding between 1996 and 2008, and then observing these individuals' NIH application and funding patterns through 2015.\nWe use detailed fellowship and subsequent NIH grant application and funding information, including application review score, funded or non-funded status, timeframe and institute/center (IC) receiving applications or funding the award, as well as previous grant funding or training affiliations. This information comes from IMPACII for NRSA F32 postdoctoral fellowship applicants from 1996 to 2008. We further queried IMPACII for subsequent applications for NIH funding and awards for these individuals. Similar to Jacob and Lefgren (2011a), we define our outcome variables to identify research award application or receipt four or more years out from the individual's NRSA F32 application year. Table 1 shows descriptive statistics for all fellowship applications from 1996 to 2008 by award status. Awardees and non-awardees differ across a number of observable characteristics.\nAwardees are younger, more likely to be married and white. Awardees are significantly less likely to be black or Hispanic. Individuals with MD degrees are less likely to receive fellowship awards whereas PhDs are more likely. Individuals with biomedical or social science degrees are more likely to receive fellowship awards compared with those whose PhD field is not reported.\nIndividuals who have had T32 predoctoral traineeships are more likely to receive awards. NRSA F32 awardees are significantly more likely aspire to and to receive subsequent NIH funding as 14 measured by the number of RPG applications and awards, the probability of an RPG award, and the probability of an R01 award. As expected, awardees have significantly lower (better) scores on their last observed F32 application. In the next section, we examine whether NIH institutes and centers fund proposals in the order of the score, and whether a regression discontinuity design (RDD) is warranted.\nOur analysis sample is a subset of the full sample. We drop all applications that are higher than the 60 th percentile in each council round because scores for these applications are not consistently saved in the reporting database and practically none of them get funding. Some institutes and centers have too few applicants for our preferred analysis method, so we drop applicants from seven institutes and centers for this reason. Finally, the dataset we use is incomplete for some council rounds prior to fiscal year 1996 and are dropped. Our final analysis sample contains 14,276 individuals, and descriptive statistics are reported in Table 2 . In our analysis sample, awardees and non-awardees no longer differ in terms of age at application, marital status, or likelihood of having a prior T32 traineeship."}, {"section_title": "An Analysis of NIH Institute and Center Award Behavior", "text": "Each institute and center has discretion in deciding who is offered a fellowship based on the current research priorities of the institute. Institutes and centers vary in their process for awarding a fellowship. For this study, we interviewed staff at various institutes and centers who provided a representative view of the variation in procedures across NIH. Through our interviews, we learned that the process for awarding fellowships is complex.\nThe review and scoring of fellowship proposals and NIH institute and center budgets create scoring thresholds that theoretically would support the use of a regression discontinuity 15 design (RDD) like the one used in Jacobs and Lefgren (2011a). Decisions of who to fund are made at the year, institute, 12 and council round. Jacobs and Lefgren only use year and institute to estimate an RDD model, which we demonstrate below is not an optimal method for evaluating training fellowships given the fellowship selection process at NIH.\nIf awards are based solely on the review score allocated from best (lowest) score to worst (highest) score until the institute budget allocations for the fellowship are exhausted, the percent of applicants selected out of order would be zero or close to zero. If this were the case, a sharp RDD would be valid because, in this scenario, the institute follows the guidance of the review score for the best (lowest) scores. If, however, an institute has funded a majority of applicants with meritorious scores and some discretion is used regarding awards to applications with scores near the pay line, we would observe minimal disorder in funding. In this example, the institute uses discretion to potentially skip some applicants close to the pay line in order to fund applications with slightly worse scores but that best fit within their scientific priorities and where the institute staff believes the applicant has the best-case scenario for future success. If this were the case, a fuzzy RDD would be appropriate.\nAdditionally, institutes could just chose to use a significant amount of discretion when selecting proposals for funding in order to meet institution goals related to scientific priorities or, perhaps, diversity of the workforce. For institutes who engage in this behavior, no real cutoff exists and an RDD is not appropriate.\nOur interviews with NIH staff indicated that the funding process is multifaceted. The institute receives an application's review score, which, in most cases, is defined by the study section through the NIH's Center for Scientific Review (CSR). Once the institute receives the scores, the staff assesses the full application, including the summary statement from peer 12 For the rest of this paper, \"institute\" will be used to refer to NIH Institutes and Centers."}, {"section_title": "16", "text": "review, the quality of the training institution, and the alignment of the research proposal with the institute's research priorities. Institute staff, specifically program officers at each institute then generally participate in a team meeting in which they defend the proposals that best match their defined priorities. Together, the program officers, the training director and other institute staff make a joint decision for recommendations to the institute director. Either the institute director or his/her delegate makes the final decision and signs off on which proposals to fund. Institute directors vary in terms of direct involvement in the consideration and final approval of proposals. Before a final decision is made and the candidates are informed, the budget office reviews and signs off on the final list of candidates, primarily making sure sufficient funds are available for the recommended awards.\nDecisions related to fellowship funding at NIH use discretion. Figure 3 illustrates why RDD is not the appropriate design for evaluating fellowship awards. It demonstrates the range of discretion used in fellowship decision making for the full sample over the period of our study. In a given council round, anywhere from around 6.9 percent to 20.9 percent of applicants received a decision that was not based on their ranked score. Either the institute's funded the applicant even though other applicants had better scores or the institute's final decision was not to fund the applicant even though they had better scores than others that received funding.\nWhat does this mean for our study? Figure 3 illustrates the level of non-compliance for an RDD method and the strong tendency for discretion in decision making within each council round. While the level of discretion has decreased in recent years, over the entire sample, around 12.3 percent (1 in 8) of all applications within a given council round received a decision that was not in line with the peer review score. Given the large proportion of 17 discretion used within council rounds, we argue that RDD is an invalid method for evaluating the true impact of early career training on later career outcomes as it relates to the NRSA F32 award.\nUsing Matching to Identify the Causal Effect of the NRSA F32 Award\nAs described above, the NIH's multi-step selection process for NRSA fellowships and research grants generates a review score via a systematic peer review process. Given this, and the fact that the groups of individuals applying to the awards are relatively homogenous given the total population, we use matching techniques, specifically Propensity Score Match (PSM)\nand Nearest Neighbor Match (NNM). While we understand that any unobserved characteristics that are different between funded and unfunded confound our results, we argue that matching is a feasible approach for the following reasons. First, we can control for unobserved differences by institute and council round by controlling for these factors.\nAdditionally, selection is made at the institute level, and any unobserved differences among applicants are also unobserved by the institute and, therefore, not a driving component of the selection process. In short, there is no self-selection of fellowship award offerings. Finally, the groups of individuals who apply for funding are relatively homogeneous within the institute. They all clearly excel in academics, have been encouraged to apply by their mentors (which means their mentors believe they have a chance of getting the award), and are typically intensely interested in biomedical research. Given the unobservable variation that could exist, we argue that within this select group of applicants, it is minimal.\nWe use the potential outcomes framework employed in econometric analysis to estimate the causal effect of fellowship awards on subsequent NIH funding outcomes (Rubin 2004). To fix ideas, let be the treatment when an individual's fellowship application is funded, and let if the application is not funded. In the potential outcomes framework each individual has two potential outcomes of subsequent NIH funding: if the individual receives the award treatment and if the individual is not treated. For each individual, the causal effect of the award on subsequent NIH funding is defined as the difference in potential outcomes . However, each individual is only observed when they receive the award or they do not, and we must estimate the counterfactual outcome, in this case, using matching methods.\nIn order to implement matching methods, we assume that treatment is independent of the outcome conditional on covariates, . This is the unconfoundedness assumption, which means that the treatment is conditionally independent of the outcome after conditioning on observable characteristics. Given unconfoundedness, we can define the average treatment effect in terms of potential outcomes as the expected value of potential outcomes:\nWe can define the average treatment effect on the subsample of the treated as:\nWe use two matching methods to identify the ATE and ATT. First we employ propensity score matching, defining the propensity score as the probability of receiving treatment conditional on observed characteristics . In order to implement propensity score methods, the propensity scores for the treated and untreated in our sample must overlap such that . Although the unconfoundedness assumption cannot be tested directly, we can examine whether the propensity score has a causal effect on a pseudo outcome 19 that was determined prior to the treatment. If the estimated effect of the treatment on the pseudo outcome is significant, then unconfoundedness has likely been violated (Imbens 2015) . We can evaluate the overlap assumption directly by assessing the balance of the covariates in the treated and untreated groups as well as visually inspecting the overlap in the propensity scores.\nPropensity score matching has been widely used in economics and other social sciences (Imbens 2015) . However, King and Nielson (2016) and Imbens (2015) note that propensity score estimates break down if the propensity score model fits to the data too well. As a result, we cannot use the review score to estimate the propensity score related to fellowship funding.\nThus, we use the coarsened exact matching (CEM) algorithm (Blackwell et al 2009) to improve the balance of the data, and nearest-neighbor methods to facilitate matching on the review score.\nWe use both propensity score matching and nearest neighbor matching after reducing the data using the CEM algorithm."}, {"section_title": "RESULTS", "text": "We begin the analysis by estimating the probability of receiving an NRSA F32 award in the full and analysis samples using probit models; Table 3 reports marginal effects. In addition to covariates listed in the table, all models include controls for institute and council round. In the first column, using the full sample, several covariates predict the likelihood of receiving an NRSA F32 award. Several age dummy variables are statistically significant as well as an indicator for sex being missing in the data. Blacks and Asians are significantly less likely to receive an award, but those indicating Other race are significantly more likely to receive the award. Having an MD, PhD, or MD/PhD degree increases the probability of the award as does having a field in biomedicine or social science. Those applicants who have been predoctoral 20 trainees are significantly more likely to receive an award, but those who have been postdoctoral trainees are not. We include the score in the second column, and many observable characteristics lose statistical significance. Proposals with lower review scores are significantly more likely to receive funding. Older applicants (age greater than 37) are less likely to be funded, as are applicants with sex missing, those who are black, and NRSA T32 postdoc trainees. PhD and MD/PhD applicants are about 9 percentage points (ppt) more likely to receive fellowship awards than individuals who hold other medical professional degrees such as DVMs or DDSs.\nThe analysis sample deletes observations that have review scores above the 60 th percentile or those that have applied to smaller institutes. As Table 2 indicated, the treatment and control groups in the analysis sample are more closely related than in the full sample. After controlling for review score, institute, and council round, only the sex missing variable has a significant negative impact on the likelihood of receiving a fellowship award. We tested the joint hypothesis that the institute and council round fixed effects were significantly different from zero, and rejected that hypothesis (p<.000) in both cases. Thus, our argument that NRSA F32 applicants are relatively homogeneous is supported by the analysis, conditional on the review score, council round, and institute. The probit models in Table 3 are the basis of the propensity score estimates used in our matching models below. Table 4 presents the propensity score matching (PSM) estimates of the ATE and ATT for the analysis sample. As mentioned previously, if we include the review score in the propensity score estimates, the propensity score becomes too precise, and the matching algorithm breaks 21 down (King and Nielson 2016, Imbens 2015). Thus, our propensity score estimates include institute and council round fixed effects and the covariates listed in column 3 of Table 3 . The first row of Table 4 shows the ATE of the NRSA F32 award on the number of RPG awards, number of RPG applications, the probability of an RPG, the probability of an R01 and the probability of never applying for additional funding. The ATE estimates indicate that the fellowship award increases the number of RPG awards by 0.15; increases the number of RPG applications by 0.73; increases the probability of an RPG award by 8.2 ppt; increases the probability of an R01 award by 6.0 ppt; and decreases the likelihood of never applying for subsequent NIH funding by 11.2 ppt. The ATT estimates are remarkably similar in size and magnitude."}, {"section_title": "Propensity Score Matching", "text": "In order for the estimates to be considered valid, there should be considerable overlap in the propensity score estimates of the awardees and non-awardees. Figure 4 Panel A shows this PS overlap for the analysis sample. The mass of the kernel density estimate of the propensity score for receiving an award lies to the left of that for not receiving an award. In order to improve the overlap, Imbens (2015) recommends trimming the tails of the propensity score distribution below .1 and above .9. The second row of Table 4 presents the ATE estimates after this trimming. The estimated effects of the fellowship award on the ATE and ATT fall somewhat after trimming but remain statistically significant. Figure 4 Panel B indicates that the overlap in propensity scores appears quite similar. Finally, Smith and Todd (2005) recommend trimming the propensity score in order to optimize the common support. We trimmed the propensity scores below .33 and above .67. Figure 4 Panel C indicates that the overlap has improved considerably after this trimming. Our estimated effect of the ATE and ATT remain significant but are smaller. The ATE estimates after the .33 and .67 trimming indicate that the 22 fellowship award increases the number of RPG awards by .11, increases the number of RPG applications by .67, increases the probability of an RPG award by 6.7 ppt, increases the probability of an R01 award by 4.8 ppt, and decreases the likelihood of never applying for subsequent NIH funding by 10.2 ppt. As before, the ATT estimates are remarkably similar in size and magnitude.\nAlthough we cannot test the unconfoundedness assumption directly, Imbens (2015) recommends using PSM on pseudo outcomes that occur prior to the award treatment. Given the SED data, we evaluate whether the fellowship award predicts the probability that an applicant has a PhD degree, the applicant's field of highest degree is in biomedicine, and the applicant's doctoral funding was from a fellowship or scholarship. Table 5 presents these results and finds no significant impact of the fellowship award on these pseudo outcomes."}, {"section_title": "Nearest-Neighbor Matching", "text": "Given the sensitivity of the PSM to the propensity score specification and recommendations to use alternative methods by King and Nielson (2016) , we used nearestneighbor matching for the analysis sample. Throughout we use the Mahalanobis distance for nearest-neighbor matching. Let be the set of control variables for those receiving the fellowship award and be the set of control variable for non-awardees. The Mahalanobis distance is given by:\nand V is the covariance matrix of X. Mahalanobis distance will reduce differences between the treated and control groups by an equal percentage for each covariate in the matrix X. 23 We experiment with a variety of specifications of the covariate list and matching approach for the nearest neighbor matching. First we match on the review score only since it is a significant determinant of fellowship funding and we could not include it in the PSM approach.\nSecond, we match on the review score, institute and council round. Third, we match on review score and council round, and impose exact matching on institute. Fourth, we match on all of the variables in the fourth column of Table 3 and impose exact matching on the institute. We drop about 1,000 observations that do not have an exact match leaving us with 13,653 in the analysis sample. We concentrate on the estimates of the ATE in the last column of Table 6 where the number of covariates is the largest. The nearest neighbor matches increase the number of RPG awards by .10, the number of RPG applications by .73, the probability of an RPG award by 6.3 ppt, the probability of an R01 award by 4.6 ppt, and reduces the probability of never applying for subsequent NIH funding by 9.8 ppt. These estimates are somewhat smaller than the PSM estimates but still statistically significant. Blackwell et al (2009) recommend coarsened exact matching (CEM) for sample selection as a way to improve the balance of the matching estimator by exactly matching on categorical values of the data. They show that the coarsened data have significantly improved balance and balances nonlinearities and interactions in the sample. We begin by using the CEM algorithm to perform exact matches by institute and fiscal year of funding. Next we use the nearest neighbor matching and same covariates to estimate the ATE, and these estimates inherit the balance properties from the CEM procedure. These estimates appear in the bottom of Table 6 . Despite the sample size reduction from 13,653 to 8,630, the nearest-neighbor matches after the CEM algorithm are remarkably similar to the full analysis sample. 24 We also use the CEM sample to estimate propensity score matches in Table 7 . The first row of Table 7 repeats the ATE estimates of the effect of fellowship awards on our outcomes.\nThe second row reports the ATE after employing the CEM algorithm to improve the balance.\nThe estimated effects of NRSA F32 awards are virtually identical despite the significant sample size reduction. Figure 4 Panel D indicates significant improvements in the overlap of the propensity score estimates."}, {"section_title": "DISCUSSION", "text": "Overall, our findings provide evidence that both the NRSA F32 award and the process used to make funding decisions matter for future engagement with NIH as an independent researcher. The NRSA fellowships for postdoctoral scientists increase the probability that awardees will receive NIH research funding later in their career. These results provide strong evidence to the science policy community and leaders that using mechanisms like the NRSA F32 fellowship to prepare and sustain a biomedical research workforce does achieve the goal of keeping scientists in NIH-funded research careers. These results are also consistent with the recommendations of NIH's Biomedical Workforce Working Group, which suggested that the number of postdoctoral students receiving fellowships should increase (NIH 2012) .\nA limitation of our study is that it does not allow us to examine the extent to which funding from other agencies or research organizations affects those that do and do not receive NRSA F32 funding. However, if individuals were able to receive support from other sources in early career and then develop their NIH-funded research, we would expect this to bias our estimates downwards. Thus, our results may be considered a lower-bound on the impact of fellowships on subsequent NIH funding and an independent research career. 25 In Fiscal Year 2016, one NRSA F32 award cost the federal government, on average, around $60,000 per individual. If a fellowship usually lasts, on average, two years, then the total cost to NIH of funding training via the NRSA F32 mechanism is around $120,000 per individual.\nOur study shows that making that kind of investment today in young scientists increases the chance that they remain in a scientific research career.\nCongress used to require the National Research Council to conduct a periodic review of the impact of the NRSA training program (National Academies 2011). Furthermore, several researchers and policymakers have noted an increasing length of time spent in training as graduate students or postdocs (Alberts et. al. 2015 , Tilghman & Rockey 2012 ). These reports have called for policies designed to promote researcher independence. One viable option would be to expand the number of NRSA F32 fellowship awards available."}, {"section_title": "CONCLUSION", "text": "During the time of our study, the total number of NRSA F32 awards granted decreased; however, their impact as an early career training mechanism to keep individuals in NIH-funded, future, independent science careers was robust. Of interest to note, the number of NRSA F32 applications during the NIH doubling years decreased. The decrease in applicants occurred when funding for postdoctoral researchers on R01 and RPG research grants became more available.\nPostdoctoral appointments on RPG and R01 grants do not require postdocs to develop a research proposal distinct from their mentors' research in order to be appointed, and this may influence the direction of their careers.\nOur study is related to work where the NRSA F32 award was modeled as a regression discontinuity and the peer review scoring mechanism was used as a cut off to determine the 26 causal effect of NIH funding at the margin (Jacob and Lefgren 2011a). We found that these methods have significant limitations. NIH institutes and centers take their job seriously with staff devoting time, energy, and effort to selecting candidates who have the right mix of institutional support, innovative ideas, and alignment with institute scientific priorities. Candidates are not solely selected based on the review score. Proposals with competitive scores are skipped over for administrative reasons as well, either the package is not complete or additional review is required because of human subjects research requirements or other complexities that may delay the application. This means, however, that at least for the NRSA F32 fellowships, regression discontinuity is not an optimal method for this analysis.\nUsing matching methods, we find robust results that overall the NRSA F32 keeps postdoctoral researchers in NIH-funded science at higher rates than they would otherwise experience. Along the margin of being funded or not, the NRSA postdoctoral fellowship award mechanism significantly improves the probability of receiving subsequent NIH funding and launching an independent research career.\nOur findings provide that targeted and focused NIH training programs associated with independent research ideas can have a significant impact on keeping individuals in academic science and engaged in NIH-funded research. The F32 programs can be seen as a viable mechanism for this purpose. Future research should address the issues of cost-benefit and whether the amount of investment in these trainings programs matches the return. 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 Coarsened Exact Matching--Nearest Neighbor Estimates"}]