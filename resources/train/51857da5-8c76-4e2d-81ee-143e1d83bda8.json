[{"section_title": "Abstract", "text": "The primary motivation and application in this article come from brain imaging studies on cognitive impairment in elderly subjects with brain disorders. We propose a regularized Haar wavelet-based approach for the analysis of three-dimensional brain image data in the framework of functional data analysis, which automatically takes into account the spatial information among neighboring voxels. We conduct extensive simulation studies to evaluate the prediction performance of the proposed approach and its ability to identify related regions to the outcome of interest, with the underlying assumption that only few relatively small subregions are truly predictive of the outcome of interest. We then apply the proposed approach to searching for brain subregions that are associated with cognition using PET images of patients with Alzheimer's disease, patients with mild cognitive impairment and normal controls."}, {"section_title": "", "text": "1. Introduction. Alzheimer's disease (AD) is the most frequent cause of dementia in our increasingly aging societies, representing a significant impact on the US population with 10% prevalence in individuals aged above 70 years old [Plassman et al. (2007) ]. Despite the prevalence, this disease remains quite a mystery; there is neither a cure nor a definite treatment to arrest its course and, currently, the only definite way to diagnose AD is to examine the brain tissue after death. According to recent studies [Leifer (2003) ], early diagnosis of AD is of great value since new drug therapies can be used to potentially delay the progression of the disease. To this end, much progress has been made in assisting the early diagnosis of AD with neuroimaging techniques. One such widely used neuroimaging technique is positron emission tomography (PET) imaging, which is one of the most promising tools for the early diagnosis of AD, and it is of great scientific interest in understanding the association between PET images and cognitive impairment. In particular, the fluorodeoxyglucose (FDG) PET has been used to measure the cerebral glucose metabolic activity for over 20 years.\nFDG PET scans used in the preparation of this article were obtained from a large multi-center follow-up study on Alzheimer's disease and early dementia, the Alzheimer's Disease Neuroimaing Initiative (ADNI). A total of 403 FDG PET scans were acquired for this application, including 102 normal control (NC) subjects, 206 subjects with mild cognitive impairment (MCI) and 95 subjects diagnosed with AD. In this study, we consider the baseline FDG PET scans with a standard 160 \u00d7 160 \u00d7 96 voxel image grid as the predictor to the cognitive performance as measured by the mini-mental state exam (MMSE), which is a questionnaire test that is used to screen for cognitive impairment [Cockrell and Folstein (1988) ]. The maximum MMSE score is 30 and, on average, MMSE scores decline as the disease progresses. The goal of our study is to identify brain subregions that are most closely related to the prediction of MMSE scores.\nMany methods have been developed for the analysis of brain image data in order to identify disease-related brain subregions. Most of these methods focus on region of interest (ROI) and voxel-based univariate analysis; see, for example, Luo and Nichols (2003) , Grimmer et al. (2009) and Shin et al. (2010) , among many others. For AD in particular, several studies have shown that reduced metabolic activity in some regions of the brain, such as the posterior cingulate and the temporal and parietal cortices, are associated with the progression of cognitive impairment [Foster et al. (1984) , Minoshima et al. (1995 Minoshima et al. ( , 1997 ]. These methods are intended to provide statistics by doing a separate analysis for each ROI or voxel and then to draw inferences at the region-or voxel-level. As a result of testing millions of hypotheses, appropriate adjustments for multiple comparisons have to be considered. In the neuroimaging literature, a distinction is often drawn between such univariat analyses and an alternative, multiple covariate regression models that treat every voxel as a covariate. Since the number of voxels is much larger than the number of scans, the ordinary least squares for linear regression cannot be implemented without applying, for example, some dimension reduction techniques. Such analysis, however, may lead to difficulties in interpretations and practical implications. Both the traditional univariate and multiple covariate approaches (if applicable) have one major limitation in common: they are developed without considering the spatial information of the brain, possibly resulting in some loss of information. There is an emerging awareness of the importance of taking such information into REGULARIZED FUNCTIONAL REGRESSION 3 account. For example, multiple covariate analysis can be conducted with a focus on extracting principal components from the images [Friston et al. (1996) , Kerrouche et al. (2006) ]. More recently, a variety of Bayesian spatial modeling approaches have been proposed to model the correlation between neighboring voxels, which need to carefully specify the prior distributions; see, for example, Bowman et al. (2008) , Kang et al. (2011) . Our way of addressing this issue is to treat the entire 3D image as a single functional input, which allows retaining all the information from the original image without modeling the spatial correlation between voxels explicitly. Specifically, in this article, we treat PET image data as the 3D functional observations, and propose a novel Haar wavelet-based regularized approach to analyze PET image data in the framework of functional data analysis.\nFunctional regression models are known as one of the standard techniques in functional data analysis. It is noted that the models can be defined as functional in one or both of two ways: the response variable is functional; at least one of the covariates is functional. In this article, we focus on the functional linear regression model with a scalar response variable and a single functional predictor. Using the 1D case as an illustration, the functional linear regression model relates a scalar response variable Y to a functional predictor X(t) as follows:\nwhere \u03b2(t) is the regression coefficient function and t refers to time or location. For the 3D case we consider later, t is replaced by the coordinate (u, v, w) . Regularization methods, such as the roughness penalty approach or using restricted basis functions [Ramsay and Silverman (2005) ], can be implemented to produce an estimator of \u03b2(t) that is meaningful in interpretation and useful in prediction.\nFor the functional linear regression model (1.1), James, Wang and Zhu (2009) proposed a regularized approach that focuses on producing sparse and highly interpretable estimates of the coefficient function \u03b2(t). This approach involves first dividing the domain into a fine grid of points, and then using appropriate variable selection methods to determine whether the dth derivative of \u03b2(t) is zero or not at each of the grid points, that is, \u03b2 (d) (t) = 0 for one or more values of d \u2208 {0, 1, 2, . . .}. They proposed the Dantzig selector [Candes and Tao (2007) ] and a Lasso-type approach for the estimation of \u03b2(t) using piecewise constant basis, where the Dantzig selector seems to be more natural. Empirical results show that their methods perform well when p, the number of basis functions, is not too large. When functional data are measured over a very fine grid such as brain image data, the Dantzig selector faces the challenge of solving a huge linear programming problem and the Lasso-type algorithm can be extremely slow; note that for the latter the fast coordi-nate descent algorithm [Fu (1998) , Daubechies, Defrise and De Mol (2004) , Friedman et al. (2007) , Wu and Lange (2008) ] does not apply due to the penalty on derivatives. Without imposing sparsity, Reiss and Ogden (2010) considered the functional principal component regression for image data.\nIn this article, we choose the Haar wavelet basis instead of the piecewise constant basis for analyzing 3D image data and show that the Haar waveletbased approach presents a number of advantages. First, it yields regional sparseness without imposing constraints on derivatives, which is needed in James, Wang and Zhu (2009) . In other words, by shrinking corresponding wavelet coefficients to zero, the estimator of the regression coefficient function can be exactly zero over regions where no relationship to the response variable is present. Second, the Haar wavelet transform offers a way to overcome the issue of high multicollinearity caused by high neighboring spatial correlations. Third, our approach is flexible enough to allow the coefficient function to be estimated at different levels of smoothness through choosing different levels of the Haar wavelet decomposition. Fourth, the Haar wavelet transform can be applied as a dimension reduction technique prior to model fitting for high-dimensional image data by setting a common set of close to zero wavelet coefficients of PET images to zero, which is an effective way of removing voxels outside the brain or in the ventricles. It should be noted that a recent article by Zhao, Todd Ogden and Reiss (2012) considered a general wavelet-based Lasso approach in functional linear regression, but only concerned 1D \u03b2(t). The Haar wavelet transform is a useful tool for image and signal analysis and has many other applications. For example, Picart, Butensch\u00f6n and Shutler (2012) and Lovejoy and Schertzer (2012) discussed the use of Haar wavelet transforms in geophysics and climate research.\nThe rest of this article is organized as follows. In Section 2 we review some background on wavelet decomposition and properties of Haar wavelet basis functions using a 1D functional linear regression model as an illustration and then propose the \u2113 1 regularized shrinkage estimation for general functional data, including both 1D and 3D cases. To evaluate the numerical performance of our approach, we conduct extensive simulations in Section 3. We present the analysis of ADNI 3D PET image data in Section 4 and make some concluding remarks in Section 5. We also show that the proposed method achieves the desirable nonasymptotic error bounds for prediction and estimation, the so-called oracle inequalities, meaning that the method performs equally well (up to a constant) as if the true subregions with nonzero regression coefficient were given. The theoretical results are provided in the online supplementary material [Wang et al. (2014) ].\n2. Regularized Haar wavelets method. For ease of presentation, we describe the proposed methodology starting with the 1D case given in (1.1), then extend it to the 3D case using a tensor product of three 1D wavelet expansions.\n2.1. Choice of basis. Basis expansions are commonly used in analyzing functional data. Among a variety of choices of basis expansions, wavelets have the important ability to allow simultaneous time (or space in this article) and frequency localization. Unlike many other commonly used basis systems, wavelet transforms are highly adaptable to different levels of smoothness and more capable of capturing edges, spikes and other types of discontinuities, especially for wavelet transforms with relatively small support such as the Haar wavelets. Wavelet transforms also provide a powerful tool to compress the data. A compressed approximation of the signal can be achieved by penalizing the wavelet coefficients [Wand and Ormerod (2011) ], which involves shrinking small coefficients to zero and possibly shrinking the large ones without affecting the main features of the data. Hence, it is advantageous to use wavelet transforms to decompose images as well as the regression coefficient function for estimation.\nIn many applications, it is often the case that the association between X(t) and Y in model (1.1) is sparse and potentially discontinuous at the boundaries of subregions. In particular, only few brain subregions in the aforementioned PET images are believed to be related to cognitive impairment. To better identify such patterns, we choose to use Haar wavelets. The Haar wavelet transform is easily calculated and affected less by discontinuities. In addition, sparsity of \u03b2(t) can be recovered by shrinking its wavelet coefficients to zero. The scaling function (also called a father wavelet) \u03c6 and the mother wavelet \u03c8 of Haar wavelets defined on [0, 1) are given below:\notherwise. The Haar wavelet bases are then generated in the form of translations and dilations of the above father and mother wavelet functions as\nwhere j = 0, 1, . . . and k = 0, 1, . . . , 2 j \u2212 1. The index j refers to dilations and k refers to translations and \u221a 2 j is the normalizing factor. It is noted that the basis functions are orthonormal. Therefore, for a sufficiently fine resolution J , the coefficient function \u03b2(t) in (1.1) defined on [0, 1) can be expanded in a Haar wavelet series:\nwhere a j 0 ,k = 1 0 \u03b2(t)\u03c6 j 0 ,k (t) dt are the approximation coefficients at the coarsest resolution j 0 , d j,k = 1 0 \u03b2(t)\u03c8 j,k (t) dt are the detail coefficients that characterize the finer structures of \u03b2(t) as j grows, and e(t) is the approximation error that goes to zero as J goes to infinity. The Haar wavelet representation of a signal thus consists of approximations together with details that can provide the desirable frequencies. See, for example, Walker (2008) for more details about Haar wavelets.\n2.2. Model estimation. Rewrite \u03b2(t) in (2.1) by\nwhere B(t) denotes the collection of all \u03c6 j,k (t) and \u03c8 j,k (t) in the above Haar wavelet expansion, and \u03b7 is the corresponding wavelet coefficient vector of length p. Plugging (2.2) into (1.1), we obtain\nwhere\nIt should be noted that C i is the wavelet coefficient vector of X i (t) when we decompose X i (t) using the same set of Haar wavelet basis functions as those in (2.2). Model (2.3) can then be rewritten as follows:\nOnce an estimator\u03b7 is obtained from (2.4), \u03b2(t) can then be estimated by B(t) T\u03b7 .\nIn practice, X(t) is observed on only a finite set of grid points {t 1 , . . . , t p }, which also determines the highest and yet practically meaningful level of decomposition for \u03b2(t). For the discrete wavelet transform, p is required to be a power of 2. Using the usual terminology for Haar wavelets [see, e.g., Walker (2008) and that used in the MATLAB Wavelet Toolbox (2011b)], we define the level 1 Haar wavelet decomposition by computing the average and the difference on each consecutive pair of values, and the maximum level is log 2 p. The level number is directly determined by the integer j 0 in (2.1). For any level of Haar wavelet decomposition, the total number of basis functions \u03c6 j,k and \u03c8 j,k is always p, and the collection of \u03c6 j,k and \u03c8 j,k then forms a set of p-dimensional orthonormal basis functions.\nA key advantage of using Haar wavelets is as follows. When \u03b2(t) = 0 in large regions of t \u2208 [0, 1) (in the ADNI brain image analysis where t is 3D, this would correspond to that large regions in the brain are not associated with the cognitive performance measured by MMSE), the coefficient vector \u03b7 in (2.2) should be sparse with e(t) = 0 for those regions, that is, \u03b2(t) can be well approximated by an economical wavelet expansion with few nonzero coefficients. We consider the Lasso approach [Tibshirani (1996) ] and implement the method with the fast coordinate descent algorithm to obtain a desirable sparse solution for the wavelet coefficients.\nFor a given j 0 , which corresponds to a specific level of Haar wavelet expansion, the Lasso estimator for \u03b7 is given b\u0177\nwhere \u00b7 1 and \u00b7 2 denote the \u2113 1 and \u2113 2 norms, respectively, and \u03bb \u2265 0 is a tuning parameter. In our estimating procedure, j 0 is also a tuning parameter.\nIt should be noted that in general the Haar wavelet coefficients with large magnitudes are related to salient features. The magnitudes of detail coefficients should be proportional to the differences between every pair of values, that is, larger magnitudes indicate sharper changes at corresponding locations and zero magnitudes indicate no change. If both detail and approximation coefficients of the Haar wavelet transform are close to zero, then \u03b2(t) is close to zero. Thus, we are able to obtain a sparse solution of \u03b2(t) by shrinking its small wavelet coefficients to zero.\n2.3. Selection of tuning parameters. In addition to the Lasso tuning parameter \u03bb in (2.5), we also need to take into account the level of the Haar wavelet decomposition. There should exist an optimal level of decomposition for \u03b2(t) in terms of certain criterion, such as AIC, BIC or cross-validation. If the length of observed X i (t) is p, then the maximum possible level of the discrete Haar wavelet transform is log 2 p, which is relatively small. Moreover, lower levels are usually considered in real applications. Therefore, including two tuning parameters does not increase computational burden by much.\n2.4. 3D case. The ADNI's FDG PET brain images are 3D. A 3D function can be decomposed using a tensor product of three 1D Haar wavelets. In particular, the 3D Haar wavelet transform can be considered as averaging and differencing operations [Muraki (1992) ]. The averaging operation is constructed by the 3D scaling function below:\nThe differencing operation is taken in seven directions constructed by the 3D wavelet functions as follows:\nLet the image X i (u, v, w) be a 3D functional predictor and Y i be a scalar response variable (MMSE, e.g.) for subject i, i = 1, . . . , n. The 3D functional linear regression model can be written as\nFor a sufficiently fine resolution J , the 3D coefficient function \u03b2(u, v, w) can be approximated by\nDenote the set of all basis functions \u03c6 j,{k,l,m} and \u03c8 q j,{k,l,m} in (2.7) by B(u, v, w) and the wavelet coefficients in (2.7) by \u03b7, then \u03b2(u, v, w) can be written as\nPlugging (2.8) into model (2.6), we obtain u, v, w) du dv dw, which is equivalent to the wavelet coefficient vector when we apply the 3D wavelet transform to X i (u, v, w), and \u03b5 * i = \u03b5 i +\n0 X i (u, v, w)e(u, v, w) du dv dw. Then the methodology proposed in the previous subsections for the 1D case can be applied directly.\nFollowing the calculations of Bickel, Ritov and Tsybakov (2009), we can show that our proposed method also enjoys the nonasymptotic oracle inequalities similar to the linear model with high-dimensional covariates. All the theoretical results are provided in the online supplementary material [Wang et al. (2014) ]. It should be noted that the results are derived using the 1D notation for the estimator\u03b2(t) for simplicity, but they hold exactly for the 3D case of\u03b2(u, v, w).\n3. Simulation studies. To investigate the performance of the proposed Haar wavelet-based approach, we have conducted extensive simulations for both 1D and 3D functional data. The results for 1D cases can be easily visualized, whereas the 3D case mimics the brain images more naturally.\n3.1. 1D simulation. We consider a variety of settings of X(t) and \u03b2(t). For X(t) = X * (t) + E(t) defined on 0 \u2264 t \u2264 1, where E(t) \u223c N (0, \u03c3 2 E ) is the noise term independent of time t, we consider the following two scenarios: -Fourier: X * (t) = a 0 + a 1 sin(2\u03c0t) + a 2 cos(2\u03c0t) + a 3 sin(4\u03c0t) + a 4 cos(4\u03c0t).\n-B-splines: X * (t) is a linear combination of cubic B-splines with interior knots at 1/7, . . . , 6/7 and coefficients a i , that is, X * (t) = a i \u03c6 i (t), where \u03c6 i (t) are the B-spline basis functions.\nIn both scenarios, the coefficients a i \u223c N (0, 1). To assess the performance of the proposed approach in identifying continuous and discontinuous signals, we consider two cases of the regression coefficient function \u03b2(t):\n-Case 1: \u03b2(t) is a smooth function,\notherwise.\n-Case 2: \u03b2(t) is piecewise constant,\nFor each curve X * (t), we record p = 128 equally spaced measurements for convenience. The variance of the noise term E(t) is set to be\n, where X * (t j ) is the mean of X * (t j ). The error term \u03b5 in model (1.1) also follows a normal distribution N (0, \u03c3 2 ). The value of \u03c3 2 is determined by the signal-to-noise ratio\nwhere \u03c3 2 g is the sample variance of g(X i ) = X i (t)\u03b2(t) dt. The simulation results presented in this article are under SNR = 9, which is also considered in Example 4 of Tibshirani (1996) . For the Lasso method, Zou (2006) observed that smaller SNR usually yields smaller relative prediction error. For each of the settings, we use n = 100 training observations to fit the model. The optimal tuning parameter is selected by using one of the following methods: (i) validating by a separate validation (SV) data set of the same size; (ii) 5-fold cross-validation (CV); (iii) AIC and (iv) BIC [Zou, Hastie and Tibshirani (2007) ] given below:\nwheredf is the number of nonzero elements of\u03b7 in model (2.4). We estimate \u03c3 2 by the refitted cross-validation method introduced in Fan, Guo and Hao (2012) . We then generate n = 10,000 test observations to calculate the mean squared errors (MSEs) of the corresponding selected models. The procedure is repeated 100 times and the average MSEs and their standard errors (SE) for each of the models are presented in Table 1 . We also report the percentages of correctly identified zero regions and nonzero regions in Table 1 . We can see that all four methods perform reasonably well, while the nonpractical SV method performs the best. The CV method seems to have a nice trade-off between sparsity and prediction accuracy. Averages of the estimates of \u03b2(t) using the CV method over 100 replications are shown in Figure 1 .\nWe also conduct permutation tests to assess the significance of the regularized estimates of \u03b2(t). For each of the training data sets, we generate 200 permutation data sets by randomly shuffling the response values. Using the same model selection technique for each of the 200 permutation data sets, 200 sets of\u03b2 perm (t) are obtained. At each t j , j = 1, . . . , p, the two-sided "}, {"section_title": ". Average of\u03b2(t) estimated using 5-fold cross-validation with 100 replications (solid line). The dashed line is the true \u03b2(t). The top panel is for case 1, and the bottom panel is for case 2.", "text": "critical values are set to be the 2.5th and 97.5th percentiles of\u03b2 perm (t j ) for the significance level of 0.05. Supposing the null hypothesis is \u03b2(t j ) = 0 at each t j , we will reject the null hypothesis if\u03b2(t j ) is within the critical region. Repeating this permutation process 100 times, we can compute the percentages that we reject the null hypothesis at each t j . The results of the permutation tests using the CV method are presented in Figure 2 , which shows high rejection frequency in the regions where \u03b2(t) is nonzero.\n3.2. 3D simulation. For the 3D case, we generate the following type of images X(u, v, w) = X * (u, v, w) + E(u, v, w) with\nwhere a i \u223c N (0, 1) and E(u, v, w) \u223c N (0, \u03c3 2 E ) with \u03c3 2 E similarly defined as in the 1D case. For simplicity, we record 32 \u00d7 32 \u00d7 32 equally spaced measurements in the unit cube. We define the coefficient function \u03b2(u, v, w) as follows: where a = 1/8, b = 40/3 and c = \u03c0/6. Note that \u03b2(u, v, w) is zero outside a ball that is located in the center of the unit cube. The error term \u03b5 in model (2.6) also follows a normal distribution N (0, \u03c3 2 ) with SNR = 9. We generate 400 training images and apply the 3D Haar wavelet transform to decompose each image and obtain the wavelet coefficient matrix. Optimal tuning parameters are selected using the same procedures as for the 1D case. The results are summarized in Table 2 . Figure 3 illustrates the comparison of the true \u03b2(u, v, w) and the mean estimates of \u03b2(u, v, w) over 100 replications at five different slices, which shows that our approach performs reasonably well in detecting signals based on visual inspection and on the high percentage of correctly identified nonzeros and zeros reported in Table 2 . 4. ADNI PET analysis. The FDG PET data used in the preparation of this article were obtained from the ADNI database (adni.loni.ucla.edu). The ADNI was launched in 2003 by NIA, NIBIB, FDA, private pharmaceutical companies and nonprofit organizations, as a $60 million, 5-year publicprivate partnership. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), PET, other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of MCI and early AD. Determination of sensitive and specific markers of very early AD progression is intended to aid researchers and clinicians in developing new treatments, monitoring treatment effectiveness, and lessening the time and cost of clinical trials. The Principal Investigator of this initiative is Michael W. Weiner, MD, VA Medical Center and University of California, San Francisco. ADNI is the result of efforts of many co-investigators from a broad range of academic institutions and private corporations, and subjects have been recruited from over 50 sites across the U.S. and Canada. The initial goal of ADNI was to recruit 800 adults, ages 55 to 90, to participate in the research, approximately 200 cognitively normal older individuals to be followed for 3 years, 400 people with MCI to be followed for 3 years and 200 people with early AD to be followed for 2 years. For up-to-date information, see www.adni-info.org.\nIn the ADNI's FDG PET study, the injected dose of FDG was 5.0 \u00b1 0.5 mCi, and subjects were scanned from 30 to 60 minutes post-injection acquiring 6 five-minute frames. The scans were preprocessed by the following steps: each frame was co-registered to the first frame of the raw image file; six co-registered frames were averaged to create a single 30-minute PET image; each subject's co-registered, averaged PET image from the baseline PET scan was reoriented into a standard 160 \u00d7 160 \u00d7 96 voxel image grid with 1.5 mm cubic voxels and the anterior-posterior axis of the subject is parallel to a line connecting the anterior and posterior commissures (the AC-PC line). It should be noted that the number of voxels in each image is over 2.4 million, so the approach via linear programming, as in James, Wang and Zhu (2009) , is too computationally expensive for this application. The data set consists of 403 scans, including 102 NCs, 206 subjects with MCI and 95 subjects diagnosed with AD. The demographic characteristics of the 403 subjects are described in Table 3 . The goal of our analysis is to identify brain subregions that are most closely related to MMSE scores; we therefore choose not to adjust for age and other demographic variables. The summary of MMSE scores among the three groups of participants is given in Figure 4 . We treat each PET image as a realization of the 3D functional predictor and then fit the 3D functional linear regression model (2.6). The voxel values outside the brain are set to zero prior to implementing the 3D Haar wavelet transform. We further reduce the computational cost by excluding those columns of the wavelet coefficient matrix where all the elements are zero.\nIn terms of applying the 3D Haar wavelet transforms to each subject's PET image data, we consider all the possible levels of the Haar wavelet decompositions. Two tuning parameters are therefore included in the model selection procedure: the level of the 3D Haar wavelet decomposition and the lasso regularization parameter.\nFirst, we employ a 10-fold cross-validation to evaluate the predictive power of the proposed method. Specifically, for each set of 10% observations, we leave them out as a test set, use the remaining data as the training data to fit a model (including selecting the tuning parameters via 5-fold cross-validation) and compute the prediction error on the data points that have been left out. We aggregate these quantities by using the predictive R-square given by 1 \u2212 (y i \u2212\u0177 i,\u2212i ) 2 / (y i \u2212\u0233) 2 , where\u0177 i,\u2212i denotes the predicted value of y i calculated by using the estimator obtained from the training data generated from the cross-validation. The result is 0.26 for the ADNI data set, whereas the standard R-square is 0.51, suggesting a moderate predictive power of the model. Second, we investigate the voxels that are selected by our method. We use 5-fold cross-validation to the full data set to choose the optimal set of tuning parameters. The identified clusters of voxels [\u03b2(u, v, w) = 0] are shown on selected axial slices in Figure 5 , which are presented from the bottom of the brain to the top. The clusters of voxels with hot colors show a positive association to prediction of MMSE scores, whereas those with cold colors show a negative association. Each small square represents a small cluster of voxels. To assess the significance of the selected voxels, similar to what we have done in simulation studies, we permute the response variable MMSE score 200 times. It turns out that 95.3% of the selected voxels are significant at the 5% level. In addition to this pointwise testing, we also consider the global test described by Nichols and Holmes (2001) , which provides a way to control the family-wise error rate by comparing\u03b2(t j ) to a \"maximal statistic.\" It turns out that only 15.6% of the selected voxels are significant at the 5% level, which is more conservative than the pointwise testing procedure. To further evaluate the stability of the selection, we generate 100 bootstrap samples and for each bootstrap sample, we apply our method including the tuning parameter selection via 5-fold cross-validation. Similar approaches also have been employed by other researchers, such as Sauerbrei and Schumacher (1992) , Royston and Sauerbrei (2008) and Meinshausen and B\u00fchlmann (2010) . To summarize the results, we count the number of times that each voxel is selected over 100 bootstrap samples and denote it as the bootstrap inclusion frequency (BIF). The voxel BIFs are presented in Figure 6 . The locations of these more frequently selected voxels are also presented in the 3D sagittal view in Figure 7 for ease of understanding. It can be seen that the highly selected brain regions agree well with the results in Figure 5 . We note that the clusters of voxels identified in our analysis shown in Figures 5 and 6 reveal high associations of the expected anatomical regions with cognitive deficits. For example, the orange ones on slices \"+12\" and \"+18\" in Figure 5 and the big cluster on the same slices in Figure 6 indicate that the posterior cingulate/precuneus cortex is significantly related to cognitive impairment; the blue ones on slices \"\u221260,\" \"\u221254\" and \"\u221248\" in Figure 5 and the clusters on the same slices in Figure 6 suggest that the medial temporal/hippocampal cortex is also closely involved; the red ones on slices \"\u221242,\" \"\u221236\" and \"\u221230\" in Figure 5 and the corresponding clusters on the same slices in Figure 6 correspond to the lateral temporal cortex. Many studies have demonstrated that the most prominent metabolic abnormalities are found in these regions; see, for example, Foster et al. (1984) , Minoshima et al. (1995 Minoshima et al. ( , 1997 , Mueller et al. (2005) . In our study, we have particularly found the most predictive voxels of the cognitive impairment in these regions. Other involved regions include the superior lateral parietal cortex and the frontal cortex, which are all known to be related to the progression of Alzheimer's disease.\n5. Discussion. In this article we propose a highly effective Haar waveletbased regularization approach that can be easily applied to analyzing multidimensional functional data. Analysis of the PET image data demonstrates that our approach is useful in finding brain subregions that are most responsible for cognitive impairment in elderly people. It has great potential to efficiently assist the diagnosis of disease in neuroimaging studies, yielding easily interpretable results. Our approach is also computationally fast because of the implementation of the coordinate descent algorithm with the MATLAB glmnet package. For example, the real data analysis of 403 subjects' PET image data can be finished in less than two hours on a 64-bit Intel Xeon 3.33 GHz server with about 35 GB of RAM, including the selection of tuning parameters. We should note that another practical advantage of our approach is that the wavelet transform itself can reduce the dimensionality of the large volume of brain image data. As a result, we can then apply the proposed approach on reduced data sets. In such situations, although the resolution of the original PET images is decreased, the results remain largely the same since the related subregions are usually not comprised of a single voxel but of a cluster of voxels."}]