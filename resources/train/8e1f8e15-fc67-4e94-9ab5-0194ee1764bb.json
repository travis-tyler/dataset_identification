[{"section_title": "Abstract", "text": "Abstract: Two geographically related questions with regard to hurricane-induced storm-surge impacts were investigated: (1) What observational scale of analysis is appropriate? (2) Is the effect of observational scale on model results predictable? These two research questions were investigated in the context of storm surge-induced impacts to single-family residential structures in Florida. The study was conducted for 21 coastal counties in Florida at five spatial scales of analysis: parcel, block, block group, tract, and county. The research findings reveal a monotonically decreasing relationship between predicted standardized residential loss (the ratio of predicted loss at scale X and the predicted loss at parcel scale) and the observational scale of analysis. This monotonic relationship was consistent for most Florida counties, primarily due to the notable spatial distribution of housing units and proximity to the coastline."}, {"section_title": "INTRODUCTION", "text": "A growing body of literature has shown that in recent decades the physical intensity and frequency of tropical storms have increased, and Gulf Coast communities are more vulnerable to the impacts of coastal hazards, notably tropical storms, than any other region in the United States (Liu and Fearn, 1993; Emanuel, 2005; Subcommittee on Disaster Reduction, 2005; Webster et al., 2005; Donnelly and Woodruff, 2007) . Despite their increasing vulnerability to coastal hazards, coastal communities in the U.S. have experienced significant population growth. As per the U.S. Census Bureau (2011), in 2009, about 52% of the total U.S. population was residing in 675 coastal counties. There has also been significant growth in the size and value of coastal properties. According to the AIR Worldwide Corporation (2008) , 2 the estimated insured values (in 2007) for coastal counties from Texas to Maine were nearly $9 trillion.\nAnticipated sea level rise (SLR) may also exacerbate the risk to coastal housing stock. While some scientific research on modeling tropical storm impacts on residential loss from storm surge 203 the anthropogenic environment and future SLR-related impacts are ongoing, we are unaware of any refereed studies using fine-scale data (e.g., parcel or block-level analysis). Previous storm-surge and sea-level-rise studies used aggregate scales of analysis, such as the vulnerability study by Kleinosky et al. (2007) using block-group data and a principal components-derived vulnerability model. CoreLogic, a private company conducting research for the insurance industry, using parcel level data and simple in/out of the storm-surge polygon in their model, estimated $44.9 billion and $27 billion in residential property at risk in Miami-Dade and Tampa metropolitan areas, respectively (CoreLogic, 2011) . The CoreLogic modeling approach did not look at inundation levels. Most research has focused on the natural environment, particularly changes in storm/tidal inundation levels (e.g., McInnes et al., 2003 McInnes et al., , 2009 or changes in wetlands (e.g., Gornitz et al., 2001 ). However, the public media predicts disastrous consequences to coastal communities from future coastal flooding events. The Nature Conservancy (2010) indicated that \"sea levels could continue to rise between 4 inches and 36 inches in the next 100 years\" and \"climate change will cause hurricanes and tropical storms to become more intense\" thereby leading to \"billions of dollars in damage to property and infrastructure.\" When referring to 100 years out, The New York Times media suggested dramatic impacts while quoting research scientists: \"You start thinking about every coastal city on the planet hiding behind a wall, with storms coming\" (Gillis, 2010) . Though the SLR alone would not likely impact structures and infrastructures dramatically, the result of a tropical storm combined with the sea level rise is of greater concern.\nThe risk of considerable impact and subsequent financial loss from future tropical storms alone is large and increasing. Hurricanes Andrew (1992) , Katrina (2005) , Ike (2008) , and Irene (2011), which caused financial damage in the range of $5 billion to $72 billion, are examples of some of the largest economic disasters in U.S. history (Swiss Re, 2011a , 2011b . In the next decade, numerous studies will examine the coupled financial impacts from tropical storms and sea level rise. Undoubtedly, those studies will be conducted at a variety of spatial scales, likely obtaining different results in predicted impacts from future tropical storms, which may result in reduction of the public and the scientific community's confidence in any of these scientific results.\nBecause spatial data are available at varying spatial scales (also known as spatial resolutions or observational unit sizes), a number of scale-related studies have concluded that modeled results vary with the spatial scale of analysis (Meentemeyer, 1989; Cutter et al., 1996; Flowerdew et al., 2001; Tranmer and Steel, 2001) , while very few studies have concluded that modeled results vary in a predictable manner (Mandelbrot, 1967; Clark and Avery, 1976; Chow and Hodgson, 2009) . It is, therefore, desirable to identify through empirical research a causal relationship between spatial scales of analysis and modeled results. This approach, also known as scaling, can be used to predict modeled results at one observational scale of analysis based on results obtained at another observational scale of analysis (Marceau, 1999; Atkinson and Tate, 2000) .\nA tendency in hazard modeling research is to use aggregate data obtained at relatively coarse spatial scales (e.g., counties or census tracts) because: (1) due to confidentiality issues detailed characteristics (e.g., race, income, economic attributes) are not available at finer scales; and (2) modeling is more efficient at coarser scales. Thus, while it seems plausible that finer spatial scales of analysis are generally better, such is not the practice in hazards research. Therefore, scaling modeled results in hazard modeling would be extremely useful. For example, conducting a study at a coarser observational scale of analysis (e.g., census tract) and then scaling the results to a finer observational scale (e.g., parcel level) would result in a more accurate prediction of storm-surge impacts. In this research, we ask \"Can modeled storm surgeinduced financial loss based on one spatial scale of analysis be used to estimate loss at another spatial scale of analysis-without actually conducting studies at both scales of analysis?\"\nIn the spirit of Mandelbrot's (1967) work, the theoretical purpose of this research was to probe for a relationship between scale of observation and modeled hurricane storm-surge loss. If such a relationship was present, we then sought to empirically define it. Specific research questions explored in this paper include the following:\nIs the estimated storm surge-induced financial loss related to the geographic 1.\nscale of analysis (e.g., census block, block group) in a predictable manner (Fig. 1A) ?\nIn GIS-based modeling approaches for estimating hazard loss, the total losses (e.g., in dollars) for a county should be the same regardless of the observational unit (e.g., block, block group) used for the analysis. Depending upon the interpolation technique used to distribute housing units within a census unit, there is the likelihood of allocating housing units to parts of a census unit where no housing units actually exist. This can result either in underestimating the number of housing units in flood-prone areas or in overestimating the number of at-risk housing units by assigning them to flood-prone areas.\nThe relationship between estimated loss and change in census scale is unknown. Other scale-related studies have demonstrated that the reliability of statistical outcomes increases at coarser scales (Gehlke and Biehl, 1934; Robinson, 1950; Clark and Avery, 1976; Flowerdew et al., 2001; Tranmer and Steel, 2001) . In this study, it was hypothesized that the financial loss would monotonically increase at coarser scales of analysis (i.e., block, block group, census tract, and county in Fig. 1A ) for every county (e.g., County A and B in Fig 1A) .\nIf estimated financial loss is related to observational scale of analysis, what 2.\nis the functional relationship (e.g., linear, nonlinear) between observational scale and modeled financial loss?\nIf modeled loss is influenced by spatial scales, how does the 3. uncertainty (expressed as the variation in results) in modeled financial loss vary with observational scales ( Figure 1B) ?\nIf the observational scale of analysis influences modeled loss in a predictable manner, then it may be possible to compare the loss estimates conducted at different scales. For instance, for counties where parcel-level data are unavailable, we could estimate dollar loss at a coarser scale using aggregate data, and then downscale for a more accurate estimate. Because we did not have a theoretical basis to estimate the form of the functional relationship, several linear/non-linear approaches were used to determine the form of the functional relationship.\nIf no strong relationship exists between observational scale and modeled loss, then the relationship between the variation (range, standard deviation, or other measure of dispersion) in modeled loss and scale of observation may be explained. For example, it residential loss from storm surge 205 may be assumed that the variability of modeled loss might be greater at coarser scales (e.g., census tracts) than at finer scales (e.g., blocks). This hypothetical variability of modeled loss with change in spatial scale of analysis is depicted in Figure 1B . An understanding of this variance in relationship would help establish prediction bounds for modeled loss estimates. The x-axes of Figures 1A and 1B correspond to the hierarchical spatial scales at which this study was conducted (i.e., blocks, block groups, tracts, and counties), and the y-axis corresponds to the modeled aggregate financial loss at each scale of analysis in a county.\nThis paper begins with a brief overview of scale-related studies, as well as stormsurge and hazard loss modeling tools and techniques. To isolate the scale-related variables and control for extraneous effects, we designed and implemented a storm-surge model, a coastline generalization model, and a loss estimation model. A discussion of the models and methodology implemented to investigate the functional relationship between observational scale of analysis and modeled storm surge-induced financial loss is presented in the methodology section. Finally, the empirical results, a discussion of results, and conclusions drawn from the results are presented in the results and conclusion sections."}, {"section_title": "PREVIOUS RESEARCH Scale", "text": "Numerous studies have been conducted to investigate the effects of spatial scales on statistical and modeled outcomes in social, physical, and geographic information (GI) sciences. The variation in the strength, directionality, or variation in a statistical relationship and modeled outcomes due to the change in the observational unit of analysis results in the modifiable areal unit problem (MAUP) in GIScience or the \"change of support\" problem in mathematics. The earliest known work on this problem was conducted in 1931 by Henry Sheldon, who first noted the variation of statistical results due to observational scale (i.e., the number of units of analysis such as census tracts) (Gehlke and Biehl, 1934) . Shortly thereafter, Gehlke and Biehl (1934) observed a general increase in the correlation coefficient between the variables male juvenile delinquency and median monthly rent for each set of geographic areas (comprising different sets of census tracts). Since then, many other scientists (Robinson, 1950; Clark and Avery, 1976; Openshaw and Taylor, 1979; Jelinski and Wu, 1996; Flowerdew et al., 2001; Tranmer and Steel, 2001; Walsh et al., 2004; Chow and Hodgson, 2009 ) have examined the effect of the MAUP and have generally found a monotonic relationship between observational scales and a dependent variable.\nSuch studies (discussed above) exploring an empirical relationship between spatial scales and measured variables have yielded several conclusions: (1) the strength of the relationship (e.g., correlation coefficient) varies; (2) the direction of the relationship varies; or (3) the confidence (e.g., variance) in the strength and the directionality of the relationship varies. In general, the apparent strength (e.g., typically measured by a linear correlation coefficient) between variables was often found to increase (i.e., becomes a stronger relationship) as the observational unit size increases. Although these conclusions in our scientific studies are disturbing, very little guidance has been provided by these studies about how to proceed or how to identify an \"optimum\" scale of analysis, which in itself is quite problematic (Levin, 1992) .\nA more useful method might be to explore how and why scale matters by implementing a \"scaling\" technique, which will enable extrapolating measurements at one spatial scale to another with the help of a functional relationship between the predictive variable (e.g., modeled hazard loss) and the observational scale of analysis (Meentemeyer, 1989; Marceau, 1999; Atkinson and Tate, 2000) . The most notable research elucidating this approach was conducted by Mandelbrot (1967) who developed a functional relationship between the length of Great Britain's coastline (i.e., the predictive variable) and cartographic scale (i.e., the scale of analysis). Mandelbrot identified an empirical formula to predict the coastline length measured at one map scale based on the measurement at another map scale. "}, {"section_title": "207", "text": "In this paper, we postulate that changes in spatial scales influence the modeled loss in a predictable manner. We seek to explain why and how such a relationship exists by modeling financial losses resulting from tropical storm surge-induced damage to residential structures (i.e., direct financial loss) rather than the less understood indirect losses at multiple spatial scales."}, {"section_title": "Modeling Storm Surge", "text": "Many 2D and 3D shallow water equations and numerical storm-surge models have been developed to estimate storm-surge depth and storm-surge impact zones based on the wind speed, barometric pressure of the hurricane eye, the tidal state, the wave run-up, the bathymetric properties, and the depth and width of the continental shelf (McInnes et al., 2003; Chen, 2006) . Most of these models are fundamentally based on Holland's (1980) research. The Sea, Lake, and Overland Surge from Hurricanes (SLOSH) is a 2D model often used to forecast potential surge zones associated with various categories of tropical storms (NOAA, 2008a) . The model is also used in the Hazards of U.S.-MultiHazard (HAZUS-MH) tool for storm-surge modeling. The SLOSH model accuracy varies between \u00b120% in comparison with observed surge depth, and uses a variable resolution elevation model, such that the cell size of the storm-surge depth layer is smaller near the coast, and increases in size in a radial pattern with an increase in inland distance (NOAA, 2008a) .\nRUNUP and ADCIRC are two 2D models commonly used in FEMA's flood mapping program for estimating surge depth. The RUNUP model uses the bathymetric properties and the deep-water wave characteristics to estimate the wave run-up, which adds to the amount of water piled up onshore by a tropical storm event. The ADCIRC (A Parallel Advanced Circulation Model for Oceanic, Coastal, and Estuarine Waters) model estimates the inland water depth from the wind and the tidal effects during a storm (Luettich and Westrink, 2004) . The ADCIRC, like SLOSH, uses a variable resolution elevation model, typically ranging in cell sizes (or sampling distance) from 50 km in the deep ocean to 100 m inland (Ceyhan et al., 2007) .\nA number of other non-proprietary techniques have been developed for modeling storm-surge depths. Cheung et al. (2003) developed a wave model to estimate the wave run-up based on Holland's (1980) wind model. In this model, the estimated storm-surge water from storm winds is combined with the wave model output to compute the total inland water depth. Based on the inverse distance weighted concept, Raber and Tullis (2007) developed a surge interpolation model. The Raber and Tullis model used a LiDAR-derived DEM and a set of observed locations with surge height information for Hurricane Katrina-impacted areas, but did not account for the wind and the wave impact on surge depth.\nDespite their wide acceptability and use by FEMA, both the SLOSH and ADCIRC models yield surge depth at variable spatial resolutions. As the focus of this study was to determine the impact of observational scale of analysis on modeled financial loss, it was not appropriate to use these two models for storm-surge modeling in this research. While the RUNUP model is available for public use, the model requires considerable data input, such as bathymetric data, wave set-up, wave period, deep water wave height, roughness coefficients, etc. Although the Digital Flood Insurance Rate Maps (DFIRM) can also be used to depict the storm-surge impact zone in the study, the DFIRM maps are not always corrected and the error associated with their generation is not always reported (NRC, 2009) . For this scale-related research, an open-source, zero-dimensional simplified storm surge approach developed by Chen (2006) was used. Fixed parameter values for all observational scales of analysis were used.\nA storm surge is a typical consequence of a landfalling tropical cyclone, with widespread impacts from more intense cyclones (e.g., hurricanes). For this study, Chen's surge model (Chen, 2006) , a zero-dimensional model based on Holland's (1980) wind model, was modified to model the wind-driven waves during a storm surge. Holland's wind model is a fundamental model form that has also been used by others (McInnes et al., 2003 (McInnes et al., , 2009 ). This model estimates water depth (above the local datum, such as MSL) along a coast based on the maximum sustained wind speed, the striking angle, the forward velocity, the barometric pressure related to a specific storm (i.e., low air pressure or suction effect at the hurricane eye), and the continental shelf width and depth. Chen's surge model is expressed as\nwhere \u03b7 is surge height above the datum (m), P r is atmospheric pressure at radius r (meter (m)) from the eye (Pascal), \u03c1 W is water density (kg/m 3 ), g is gravity (m/sec 2 ), L is continental shelf width (m), D is continental shelf depth (m), H is incident openocean wind wave height (m), 101200 is surrounding neutral air pressure in Pascals, and 0.15 is the wind wave set-up coefficient.\nThe variables \u03b7, P z , and \u03c4 x are functions of r (radius of maximum wind), which is the distance from the center of the eye at landfall to another coastal point under consideration. The wind stress on the ocean surface is represented by \u03c4 x . Wind stress is derived as:\nwhere \u03c1 a is the air density constant (1.2 kg/m 3 ), C a is the wind drag coefficient (.002), and w 10 is wind speed at the standard 10 meters height (m/s). Boundary layer wind speed (10 meters height) is the sum of the gradient and forward translation velocity of the hurricane (10 meters height):\nGradient wind speed V g is estimated using Holland's wind model (Holland, 1980) :\nwhere V g is gradient wind speed (m/s) at radius r, V i is storm translation speed (m/s), P n is ambient neutral air pressure (Pascal), P c is center eye pressure (Pascal), f is the Coriolis parameter (s -1 ), and \u03c1 a is air density. The profile of air pressure at radius r is given as\nCoefficients A and B are derived from the following equations:\nwhere V M is the maximum sustained wind speed at the 10 m standard height (m/s), e is the natural logarithm base, and R W is the radius of maximum winds (km). Water depth (d) above the local terrain is derived as:\nwhere t is tide height above datum at landfall time (m), v is the elevation of surface above datum at the cell of interest (m), and \u03b7 is the surge height above the datum (m).\nAs the model did not account for the wave run-up and the wave set-up, for verification, the model output was compared with data for Hurricane Katrina. A linear regression between the observed and the predicted surge-depth for 234 High Water Mark locations in the Hurricane Katrina-impacted areas in Mississippi (FEMA, 2008) resulted in an adjusted R 2 of 0.57. The intercept of the regression model was 0.889, which suggested that surge depths were under-predicted by approximately 89 cm. The under-prediction could be due to lack of inclusion of the wave run-up, the wave set-up, the bathymetric and the tidal conditions. As the goal of this study was to establish a scaling relationship, the y-intercept was set at 0.0, meaning no addition (e.g. to the 89 cm) to the modeled surge depth was made to compensate for under-prediction.\nAt each of the 760 potential hurricane landfall points, the shoreline orientation angle was computed to ensure perpendicular striking of the synthetic hurricane. The following Hurricane Katrina characteristics were used: V M (maximum sustained wind speed at the 10 m standard height) = 57 m/s; P c (center eye pressure) = 923 mbar, P n (ambient neutral air pressure) = 1005 mbar, R W (radius of maximum winds) = 55 km, and V t (storm translation speed) = 6.7 m/s. Storm-surge layers representing surge depth at each hurricane landfall point were generated. Finally, all storm-surge layers were superimposed, and the maximum surge depth at any given location was determined. This layer (i.e., Storm Surge Elevation (SSE)) was used to model the maximum loss due to the maximum surge depth in the study site."}, {"section_title": "Modeling Hazard Loss", "text": "Hazard modeling approaches first predict the physical magnitude (e.g., surge depth), second the geographic location of structures at risk, and finally the impact from the spatial overlap between physical magnitude and structures. Simplistic hazard modeling studies utilize an in/out of hazard region (e.g., inundated area, high wind area, etc.) approach to assign a binary value of \"impacted\" to each region within the hazard zone. However, impact to a structure or region is a function of the magnitude of wind/water-the deeper the water the greater the impact. Thus, a more appropriate method is to utilize a damage curve depicting the functional relationship between the physical force of a hazard (e.g., surge depth, wind speed) and the potential damage to structures (e.g., DAMD-CoE, 1988; NOAA, 2008b) to model hazard loss.\nConsiderable research has been conducted to develop loss estimation tools (e.g., HAZUS-MH, CATS) and models for estimating direct and/or indirect loss during a hazard event (Hooke, 2000) . The HAZUS-MH modeling package is the most widely used loss estimation tool to assess potential losses from natural hazards, such as earthquakes, floods, and hurricanes (Rose, 2005; Schneider and Schauer, 2006) . The HAZUS-MH tool computes both direct and indirect economic losses, and incorporates geographic information system functionalities to visually represent the spatial distribution of loss. The Consequence Assessment Tool Set (CATS) uses real-time weather data, remote sensing images, demographic information, and infrastructure data to determine population and resources impacted by natural and industrial hazards (SAIC, 2010) . The CATS is used to prepare evacuation and contingency plans, and in providing relief support. The Arbiter of Storms (TAOS) is a hazard model that uses wind, wave, and boundary layers as well as hydrodynamic models to generate a stormsurge layer (KAC, 2010) . Socio-economic, geophysical, and land use/cover data along with the storm-surge layer are used in TAOS to compute damage to structures and infrastructures. In addition to these comprehensive toolsets, numerous direct loss estimation techniques focusing on damage to residential structures have been developed, most of which are proprietary in nature and are used by insurance agencies (Watson and Johnson, 2004) .\nTo identify the relationship between financial loss and the observational scale of analysis, we needed to hold all model parameters constant while the geographic scale of analysis changed. With existing modeling packages this is either not possible or problematic because of (1) the proprietary nature of existing loss estimation techniques or (2) the black-box nature of the HAZUS-MH, CATS, and TAOS models. Therefore, in this study, an open-source modeling approach based on a static surgedepth-damage function was developed."}, {"section_title": "METHODOLOGY", "text": "Florida was chosen as the study area for this scale-related research because of its vulnerability to future hurricane storm surges and the large magnitude of properties at residential loss from storm surge 209 risk. Since 1884, about 150 major and minor hurricanes and 260 tropical storms have made landfall in the state (FDEM, 2008) . During 1900-1996, 24 of the 57 hurricanes that made landfall in the state were Category 3 or higher (FDCA, 2006) . A Category 3 hurricane is characterized by 110 mph wind speeds or greater and a storm surge of 8 feet or greater (FDCA, 2006) . Based on historical evidence, Florida has a high probability of experiencing the impact of a Category 3 or higher hurricane, and is expected to experience the highest storm-surge level in the world next to Bangladesh (FDCA, 2006; FDEM, 2008) . Florida is also one of the fastest-growing states in the U.S. (OEDR, 2008) . During 1990-2007, Florida experienced a 41% increase in population. By the year 2025, Florida's population will be approximately 24 million people, with most residing in coastal communities (FDCA, 2006) . The total estimated value of property in coastal Florida counties in 2002 was $870 billion (FDCA, 2006) . Due to the perpetual increase in population and cost of property in the coastal counties, it is safe to assume that Florida would experience significant financial loss from a future hurricane-induced storm surge.\nParcel boundaries and tax assessor's data for 21 of the 35 coastal counties were obtained from the Florida Department of Revenue for the year 2005 (Fig. 2) . All single-family residential parcels for the study counties were extracted using the zoning code provided in the tax-roll data. Small polygonal areas (<20 m 2 ) that were likely \"orphaned\" parcels or spurious polygons were eliminated, as they would not contain structures. Duplicate parcels were also removed. To obtain a consistent set of the "}, {"section_title": "210", "text": "kar and hodgson number of housing units at each geographic scale we utilized the county assessor's data rather than the U.S. Census Bureau's data.\nUsing the tax assessor's data, we computed the total number of parcels and housing units within a census unit (e.g. a block) by summarizing all the parcels (or housing units) present in the census unit. The total number of housing units present in each census unit at each census scale (i.e., block, block group, census tract, county) was also derived. Using the tax assessor's enumeration obviated the definitional variations of housing unit versus single-family structures summarized by the U.S. Census. Thus, the \"true\" number of housing units at each geographic scale of analysis was derived by aggregating the tax assessor's data at the parcel level to coarser scales of analysis. Thus, parcel-level data were used as the reference data to compute error at each census scale of analysis. It is possible that the \"date\" or record supplied by each tax assessor's office for their data may vary by up to 12 months. This research focused on the scaling relationships rather than focusing on incredibly accurate counts of housing units for one specific day/month of a common year. Regardless, our estimates of total housing units by census unit are considered much more accurate than the U.S. Census counts with a 74% response rate. All geographic data were projected to the Universal Transverse Mercator (UTM) map projection (Zone 17 North) in the North American Datum 1983.\nAs mentioned above, to overcome the deficiencies of existing loss estimation models (e.g. HAZUS-MH, CATS, etc.), to obviate the problems of a \"black-box\" model (e.g., SLOSH), and to control all parameters of the input model(s), a stormsurge model and a loss-estimation model were developed and implemented in this study (Fig. 3) . A discussion of these models is provided in the following sections."}, {"section_title": "Housing Unit Distribution", "text": "A dasymetric areal interpolation technique (Fisher and Langford, 1996; Eicher and Brewer, 2001; Langford and Higgs, 2006) using land use/cover information was implemented to distribute housing units within the residential zones of each census unit. A preliminary study with Miami-Dade County was conducted to determine the best land use/land cover (LULC) data available for the interpolation process. Three different LULC databases were obtained from the United States Geological Survey (USGS), the Gap Analysis Program (GAP), and the National Oceanic and Atmospheric Administration's (NOAA) Coastal Change Analysis Program (C-CAP). Residential housing units at each census scale were distributed uniformly within the residential zones defined by each land use/cover data sets-no housing units were distributed in non-residential land cover. Using the housing unit distribution at the parcel scale as reference data, the summary error at each census scale for Miami-Dade County was computed. A comparison of errors at each census scale indicated that the NOAA C-CAP data were best (i.e., provided the least amount of error) for areal interpolation. The NOAA C-CAP data were then used to distribute housing unit counts within residential zones at each census unit at each census scale in the 21 counties.\nThe housing unit distribution layer was used to generate the Total Assessed Value (TAV) layer representing the distribution of assessed value of housing units within residential zones in a census unit. The TAV layer was derived by summarizing the assessed values of all homes present in the parcels in a census unit. For instance, if "}, {"section_title": "212", "text": "kar and hodgson three housing units of assessed values $10,000, $20,000, and $30,000 were present in a census unit, the total assessed value within the same unit in the final TAV layer was $60,000."}, {"section_title": "Foundation Elevation Estimation", "text": "The foundation elevation (FE) of a structure and local flood elevation are the key determinants in estimating the loss a structure may experience from a storm surge. In other words, the depth of water within a structure is the best single predictor of expected damage. The higher the storm surge the greater is the resulting damage (e.g., flooring, sheetrock walls, electrical fixtures/wiring, etc.). The flood insurance industry assumes no loss if the highest water level is below the elevation of the first floor. We assumed the first floor elevation was a fixed height above the foundation elevation for each structure. Although it can be assumed that each residential structure in waterfront properties is located at the highest elevation of a parcel, this assumption may not be accurate due to changes in building codes over time, homeowner interests, and other factors.\nBecause the parcel-level data are not always available, a preliminary study was conducted for Miami-Dade County using building footprint centroids as the reference data to develop an appropriate method for estimating the foundation elevation of structures. The following questions were explored: (1) Which elevation statistic (e.g. average parcel elevation, parcel centroid elevation) in a parcel best represents the actual elevation of a residential structure? (2) Which elevation statistic best represents the FE for all structures in a census scale (e.g., block, block group, tract, county)?\nUsing the digital elevation data obtained from the USGS at 10 m and 30 m spatial resolutions, the FE values were extracted at building footprint centroids, within parcels and within all census units for Miami-Dade County. At the parcel scale, the FE values derived at building footprint centroids were correlated with the FE values determined at parcel centroids, and the minimum, maximum, and average FE values determined within a parcel. The correlation coefficients ranged from 0.988 to 0.998 (10 m DEM) and 0.990 to 0.997 (30 m DEM). Because the building footprint centroid data were unavailable for other study counties, and because the correlation coefficient between the FE computed at a building footprint centroid and a parcel centroid was very high, regardless of the DEM resolution, the FE value computed at the parcel centroid was deemed a reliable proxy for the FE at the parcel scale.\nTo determine the appropriate FE statistic at census scales, an error analysis using aggregated data was conducted. The root mean square error (RMSE) between the FE estimated in a census unit and the FE of all parcels present in the census unit was computed by using equation (1):\nwhere E RMSE is the root mean square error, CE j is the minimum, maximum, or average elevation of a census unit, PE' is minimum/maximum/average elevation of all parcel residential loss from storm surge 213 centroids present in the census unit, and m is total number of census units (i.e., blocks, block groups, tracts).\nThe average elevation within a census unit exhibited the least amount of error regardless of the DEM cell size when compared to the average FE of all parcel centroids present in the census unit. The 10 m cell size was also found to yield slightly lower RMSE error at all census scales. The average elevation of a census unit was linearly regressed with the average elevation of all the parcel centroids present in the unit. The analysis indicated that at finer scales (i.e., block) the coefficient of determination was close to 1.0, which decreased at coarser scales (e.g., block group, census tract, and county). It was clear that the average elevation of a census unit was a very good representation of the aggregated FE of all buildings at their actual locations within the census unit. Therefore, the average elevation derived from a 10 m DEM within a census unit was used as the best proxy for the FE of all residential structures present in the unit at all census scales.\nInstead of using an individual set of slope and intercept coefficients for each study county at each census scale, the average elevation of the census units and the average elevation of parcel centroids present in the census units for all 21 counties were regressed at each census scale (e.g., block, block group, tract). The resulting aggregate slope and intercept coefficients were used to convert the DEM layer at each census scale to the final FE layer at that scale for the entire study site."}, {"section_title": "The \"Coastline\"", "text": "A coastal county is expected to experience the maximum surge depth and the maximum residential damage if its residential density is highest on the right-quadrant of a hurricane landfall location, and the striking angle of the hurricane at landfall location is 90\u00b0. It might be argued that a greater storm-surge depth may result in some estuaries or embankments that are at other angles to the coast. For this study, to explore the scaling questions, it was essential to compute the maximum loss the study counties will experience from future hurricane landfall locations. As a hurricane could strike any part of a coastline, the coastline was systematically sampled to generate a set of landfall points along the coastline.\nTo accomplish the systematic sampling of a \"coastline,\" a line generalization technique was implemented to generalize the coast boundary and to systematically (every \"n\" meters) sample potential landfall points along the coast. Although a number of generalization techniques exist, such as the Douglas-Peucker algorithm and the Bend Simplification algorithm, these techniques remove the \"non-critical\" points from an original line, thereby, generalizing the line and maintaining its approximate shape. These algorithms do not create \"new\" points to retain the shape. In this study, NOAA's Mean High Water (MHW) boundary was used as the mapped coastline. This MHW line was generalized by using the principal curve algorithm (Hastie and Stuetzle, 1989; Banfield and Raftery, 1992) . The resulting generalized coastline was: (1) appropriate for physical processes, such as a hurricane; (2) smoother than the original coast boundary; (3) \"close\" to the vertices of the original coastline; and (4) retained critical points \"best\" describing the bending characteristics of the original coastline. The coastline was divided into 2.5 km length segments, and the beginning and end points of each 214 kar and hodgson segment were used as potential landfall points. For the entire state, a set of 760 points (separated by 2.5 km) was used as potential hurricane landfall points.\nRegarding the use of a \"generalized\" coastline for sampling hurricane land fall locations, we note the large differences in physical processes and census units (e.g., blocks). The storm-surge water depth does not vary greatly across a small census unit (e.g., a block)-the uncertainty of Holland's general boundary layer wind model and subsequent storm-surge model is much greater than the variation in surge depths based on a generalized coastline and the scale at which the hurricane wind processes are occurring."}, {"section_title": "Loss Estimation", "text": "Detailed structural characteristics (e.g., elevation at the first floor, location of building footprint, etc.) are required to develop a surge-damage functional relationship similar to those derived by Burrus et al. (2001) , DAMD-COE (1988) , NOAA (2008b), and FEMA (2011) . As these variables are seldom available for large geographic areas, such as counties, a simplified loss estimation model based on a percent damage-surge depth curve was developed. The curve represents percent damage to a structure based on standing surge depth at the structure location. In this study, the curve was created by using storm-surge height, local elevation, and estimates of base-floor height as inputs.\nEach structure was assumed to be elevated by two feet (0.6096 m) above the FE. This assumption may not be perfectly valid; however, for modeling the scaling relationship, deviations from this assumption will not influence the relationship between an observational scale and the modeled loss. Two feet (0.6096 m) were added to the FE layer at all observation scales to generate a Zero Damage Height (ZDH) layer, which is equivalent to the first floor elevation from the ground. By subtracting the ZDH from the SSE layer, the Storm Surge Height (SSH) within each structure was computed at each census scale. At the parcel scale, two feet (0.6096 m) were also added to the FE and as it was assumed that a structure will be located at the highest elevation in a parcel, the minimum surge elevation within each parcel was used to compute SSH.\nTo generate a percent damage-surge depth curve, the following assumptions were made. If the SSE is less than the ZDH, no damage to the structure would occur. For water levels between two to four feet (0.6096-1.2192 m) above the ground, the floor of a structure would be damaged, causing 25% damage. Four feet (1.2192 m) of the SSE would result in standing water of two feet (0.6096 m) above the ZDH, which would damage flooring, electrical wiring and outlets, and switches for most of the appliances, resulting in roughly 40% damage. For an SSE of 10 feet (3.048 m), eight feet (2.4384 m) of water above the ZDH would damage the flooring, electrical wiring and outlets, all the appliances, doors and windows, and most of the walls of the first floor. At 10 feet (3.408 m) of SSE, a structure would suffer roughly 80% damage. Finally, an SSE of 12 feet (3.6576 m) will result in 10 feet (3.408 m) of water inside a structure, damaging the entire first floor including the ceiling and would result in 100% damage. This piecewise percent damage-surge depth relationship was used to develop the percent damage-surge depth curve (Fig. 4) . At each observational scale, the computed SSH was used along with the percent damage-surge depth curve to determine the percent damage (PD). This percentage damage was then multiplied by the Total Assessed Value (TAV) layer at each census unit to compute dollar loss within the unit. Summation of losses within all census units at a census scale for the county resulted residential loss from storm surge 217 in total loss to residential structures at that scale. This approach was implemented to compute the total loss at each census unit at each census scale for the 21 counties."}, {"section_title": "RESULTS AND DISCUSSION", "text": "To reiterate, we assume the modeled loss at the parcel scale of analysis is the best representation of reality (as compared to other census scales). To explore the scaling relationship, the modeled loss at a given scale was normalized using the modeled loss at the parcel scale as reference:\nStandardized losses less than 1.0 indicate an underestimation of modeled loss. For instance, a standard loss of 0.80 would be an underestimation (by 20%) in the expected loss. Analysis results (Fig. 5 and Table 1 ) reveal a monotonically decreasing relationship between the standardized loss and the observational scale of analysis for most counties. With only slight exceptions, this monotonic relationship was remarkably consistent in under-predicting the storm-surge damage as the observational scale increased. This under-prediction was particularly acute at observational scales coarser than the block level. In fact, modeled loss at the county scale was under-predicted for counties with a large percentage of their population residing along the coastline by more than 50 percent (e.g., Levy, Okaloosa, Walton, and Monroe counties). This finding is particularly important to studies of financial losses from tropical storms and sea-level rise, and hazard studies in general, as most of these studies are conducted residential loss from storm surge"}, {"section_title": "219", "text": "at a relatively coarse scale of analysis (e.g., county, tract, or block group). Very few hazard-loss studies are conducted at fine scales because the socio-economic variables (e.g., income, home value) important to other aspects of analysis are only reported at coarser census scales. We believe this relationship and the deviations are due to the areal interpolation technique used in most hazard studies. While the dasymetric method of interpolation was used for all observational scales, the density of residential housing units was held constant within the residential land cover class. The use of finescale observational data obviates, to a large extent, the variations in residential density within a single residential land cover class. Some deviations from this strong monotonically decreasing relationship between the modeled loss and observational scales were noted. For example, the estimated loss at the block level was slightly higher than that at the parcel scale for Franklin, Gulf, Miami-Dade, Martin, Palm Beach, and Taylor counties. This finding may be due to the over-estimation of housing units in flood-prone areas by the dasymetric interpolation technique. The scale-loss relationship was increased monotonically for Jefferson County, and was non-monotonic (i.e., neither monotonically increasing nor decreasing across all scales) for Monroe, Duval, Taylor, and Walton counties (Table 1) . Jefferson County is rural in nature (contains only 3,240 parcels and 3,647 housing units), and a small part of the county boundary borders the coastline. The housing units in this county are, in large part, located approximately 10 miles inland (wetlands adjacent to the coast), and 0.19 percent of the housing units are exposed to storm-surge impact at the block level. The aggregate loss estimated at parcel, block, block group, tract, and county scales are: 0.000264, 0.000059, 0.000852, 0.001005, and 0.002156 billion dollars, respectively. It is evident that the dasymetric interpolation technique inappropriately assigned houses to storm-surge areas at coarser census scales (e.g., county or tract levels), resulting in higher modeled loss at coarser census scales.\nMonroe County is located at the southern tip of Florida, where the populated areas are situated largely on the Florida Key islands. A rate of exposure analysis indicated that due to its location and low elevation about 96.18% of the housing units at the block scale would be impacted by a hurricane storm-surge. Thus, the estimated loss at the parcel scale is close to the loss estimated at other census scales.\nDuval County is located in the northeastern corner of the state and is densely populated (224,762 housing units) . Given that the housing units are concentrated in the central part of the county, about 1.79 percent of the housing units at the block level are exposed to storm-surge impact. However, the dasymetric interpolation technique assigned houses to storm-surge areas, especially at the county scale, resulting in a non-monotonic relationship. Like Jefferson and Duval counties, Taylor and Walton counties are rural in nature and most of the housing units in these counties are located inland. However, the dasymetric interpolation model inappropriately assigned houses to all areas within a census unit, including storm-surge areas along the coast that are not heavily populated. This may explain the non-monotonic relationship for both counties.\nThe estimated standardized loss at coarser scales (e.g., block group, tract, and county) was quite high for Jefferson County (Table 1) . In Taylor County, the modeled loss was extremely high at the block scale. Thus, Jefferson and Taylor counties were considered as statistical outliers. Before conducting other statistical analyses, the normality of the entire data set was tested using the Shapiro-Wilks test. For the entire data set with outliers, the W or test statistics were 0.564, 0.389, 0.458, and 0.351 at the block, block-group, tract, and county scales, respectively. The p or significance values were 0.000 at all census scales. As the W statistics were small and p values were less than 0.05, it was evident that the data set is non-normal at all census scales. Without the outliers (i.e. Jefferson and Taylor counties), the W statistics were 0.951, 0.960, 0.918, and 0.964 at the block, block-group, tract, and county scales, respectively. The p or significance values were more than 0.05 at all census scales. Thus, without these county outliers the data set could be considered normal. Jefferson and Taylor counties were eliminated from the dataset to derive prediction bounds and variance of standardized losses.\nThe standardized loss at the block level varies from 92 to 104 percent (Table 2 ). Thus, block-level data could be used as a very good estimate of structural loss at the parcel scale. However, at other census scales, the standardized loss varies dramatically. "}, {"section_title": "221", "text": "For instance, at the county scale the proportional loss ranges between 15 and 101 percent. It is also apparent that the variability in standardized loss is greater at coarser scales than at finer scales (Table 2 ). This finding is consistent with the alternative hypothesis that the variance in the modeled loss increases at coarser scales (Fig. 1B) .\nBecause of the presence of strong variation, prediction bounds (standardized proportional loss including the expected error margin) were computed for 19 counties (Table 3) . Prediction bounds at the block scale indicate standardized modeled loss would range between .913 and 1.06 percent, and at the county scale, standardized modeled loss would range between .169 and 1.17 percent.\nThe Robust Tukey Line regression method, which is not influenced by the presence of outliers and uses the median instead of the mean, was used to develop a functional relationship between standardized estimated loss and observational scale (represented by an ordinal scale) for all 21 counties. The slope (-0.060) and intercept (1.060) coefficients of the regression model indicate that, on average, actual loss (estimated at parcel scale) would be underestimated by an additional 6% with each successive coarser observational scale.\nThe coefficients of the Robust Tukey Line could be used to upscale or downscale the estimated loss. Suppose a county with a housing unit density distribution pattern along the coast similar to that of one of our study counties has a modeled loss of $5 billion at the county scale. To compute a more accurate estimate of the potential loss at the parcel scale, the model-derived Tukey line equation can be used:\nStandardized Loss scale X = 1.060 -(0.060 * X) ,\nwhere Standardized Loss scale X is the standardized loss at the modeled scale, X is the observational scale of analysis and is categorical in nature (as per this study X = 1 for parcel, X = 2 for block, X = 3 for block group, X = 4 for census tract and X = 5 for county). By substituting 5 for X, standardized loss at the county scale would be: 1.060 -(0.060 * 5) = 1.060 -0.300 = 0.760. By modifying equation 11, modeled loss at the parcel scale will be: \nThus, rather than assuming the best estimate of loss is $5 billion (based on a county scale model) a more accurate modeled loss would be 5.0/0.760 = $6.57 billion (based on the predicted loss at the parcel scale)."}, {"section_title": "SUMMARY AND CONCLUSION", "text": "One of the major findings of this study is that in coastal counties there is, in general, a monotonically decreasing relationship between surge-induced modeled loss and observational scale of analysis. The variance of computed loss at the block scale is lowest, which increases at coarser census scales. Thus, studies estimating financial losses from a future storm surge will, in general, under-predict loss if the study is conducted at coarser census scales (e.g., block through county) and will result in higher uncertainty at coarser scales. This finding was true for all counties in which the population density was greater near the coast. The explanation of this scaling relationship is linked to modeling the spatial distribution of housing units and the location of the \"hazard\" (e.g., the storm surge). The housing unit distribution model (i.e., dasymetric areal interpolation technique) was found to be the key factor influencing estimated financial loss variation at census scales. The use of a dasymetric interpolation model does not overcome the deficiencies with coarse-scale observational data.\nThe slope of the scale-modeled loss relationship is not constant for all study counties. The slope is steep and the relationship is significant for counties with dense population along the coastline. The scaling relationship, however, is sometimes increasing or non-monotonic for rural counties or counties with relatively higher housing unit density in the inland areas.\nThis research documents our findings for 21 coastal counties in Florida for which parcel and tax roll data were available. As the observational scale-modeled loss relationship is based on the housing unit distribution, we feel it is extendable to other regions with similar population concentration along the coast. The question \"are the results extendable to other hazards?\" is a somewhat different problem and is dependent upon the proximity of populated areas to the location of the hazard. Nonetheless, "}, {"section_title": "223", "text": "in case of most hazards, such as earthquakes, wildfires, and flooding events, the hazard intensity is usually higher in the immediate vicinity of the hazard event. Therefore, it is plausible for such a scaling relationship to exist for other hazards. Like Mandelbrot's 1967 study, a statistical relationship between observational scale and estimated loss was established using the Robust Tukey Line approach. As the scaling relationship is dependent upon the housing unit distribution pattern within a county, for those counties where (1) the distribution pattern is unknown or (2) the county has a high housing unit density along the coastline, the robust Tukey line could be used to upscale or downscale estimated loss.\nAnother finding of this study is that in the absence of structure location data, elevations at the parcel centroid or the average elevation within a parcel could be used as a proxy to represent foundation elevation at the structure location. The average elevation within a census unit could also be used as the best proxy for foundation elevation of residential structures in the census unit.\nWe note that the newly developed models can be refined to increase their effectiveness and efficiency. Future research would focus on (1) using improved data sets, (2) conducting the study in coastal counties that have experienced hurricane impacts in the past for validation, and (3) implementing the model for other hazard types. As Florida now has a statewide elevation database derived from high-spatial-resolution LiDAR data, the differences in estimated loss between high-spatial-resolution LiDAR data and 10 m \u00d7 10 m USGS NED data could be explored to determine the loss estimation error from DEM quality/resolution. Possible scaling relationships for other natural hazards, such as hurricane winds, wildfire, earthquakes, or riverine floods could be examined.\nThese findings clearly indicate that greater uncertainties and generally, large underpredictions result from using coarser observational scales (e.g., census tracts and counties) to model hazard impacts. Sadly, such coarse observational scales are commonly used in hazard studies because historically and by design these coarse observational scales have been generally stable over time with little movement in boundaries. Thus, census tracts or counties are good choices for conducting longitudinal analyses of the hazardousness of a place. Furthermore, detailed population and housing characteristics are only available at coarser spatial scales in the U.S. and other countries to mask confidential data. While these reasons would encourage the continued use of censustract or county scales of observation in hazard studies, it is clear that the resulting uncertainty and error are strong deterrents to using such coarse spatial scales. Perhaps, the use of a geographic scaling approach as suggested here will serve to lessen the modeling error resulting from the use of aggregate scales of observation."}]