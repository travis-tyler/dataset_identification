[{"section_title": "Abstract", "text": "State-of-the-art forecasting methods using Recurrent Neural Networks (RNN) based on Long-Short Term Memory (LSTM) cells have shown exceptional performance targeting short-horizon forecasts, e.g given a set of predictor features, forecast a target value for the next few time steps in the future. However, in many applications, the performance of these methods decays as the forecasting horizon extends beyond these few time steps. This paper aims to explore the challenges of long-horizon forecasting using LSTM networks. Here, we illustrate the long-horizon forecasting problem in datasets from neuroscience and energy supply management. We then propose expectation-biasing, an approach motivated by the literature of Dynamic Belief Networks, as a solution to improve long-horizon forecasting using LSTMs. We propose two LSTM architectures along with two methods for expectation biasing that significantly outperforms standard practice."}, {"section_title": "INTRODUCTION", "text": "Modeling time varying data is a fundamental problem in Data Science with applications in a variety of fields such as medicine, finance, economics, meteorology, and customer support center operations. Using models trained on time series data to forecast future values is a well studied area to which methods ranging from classical statical models such as Autoregressive integrated moving average (ARIMA), simple machine learning techniques such as support vector machines (SVM) have been applied. Of recent interest is the application of recurrent neural network (RNN), particularly networks based on state-of-the-art Long short-term memory (LSTMs) [10] cells.\nLSTM-based methods have shown great success in short-horizon forecasting, where forecasts are made for a small number of time steps beyond the last observations recorded in training data. Examples of this short-horizong forecasts are stock prediction [12] , recommender systems [23] and ICU diagnosis [16] . Unfortunately, these approaches can be lacking when long-horizon forecasts, where Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). forecasts are made for a large number of time steps beyond the last recorded observations. The ability to capture temporal and causal aspects inherent in the data for longer time spans is missing in these models.\nThe following examples illustrate situations in which long-horizon forecasts are invaluable:\nAlzheimer's Prognosis A person with Alzheimer's Disease (AD) that presents clear symptoms is usually accurately diagnosed by physicians. Unfortunately, by the time a person has developed clear symptoms of dementia or AD, treatment options are limited. There are no current treatments that provably cure or even slow progression of AD [15] . Clearly then, the value of identifying patients at early stages of the disease, or even before disease onset, is a key goal in utilizing effective preventative interventions. This requires diagnosis years in advance; After all, it is much more challenging to capture patient changes in a long-horizon (e.g, predict that a cognitively normal patient will most likely develop dementia in 5 years) vs short-horizon (e.g, diagnose a patient who currently shows clear symptoms of dementia). As an illustration of the significance of this problem, the EuroPOND consortium created the TADPOLE challenge [6] as a contest to predict AD prognosis over long-horizon forecasts.\nEnergy Consumption Monitoring and controlling energy consumption is major issue in developed and developing countries. A fundamental requirement of power system operators is to maintain the balance between generation and load. An example of that is electricity consumption, for electrical power is a main energy form relied upon in all economic sectors all over the world. The prediction of electricity consumption, especially over long-horizons is a key component for successful long-term management (e.g. power flow) of the electrical grid. [1] Population growth Government policymakers and planners around the world use population projections to gauge future demand for food, water, energy, and services, and to forecast future demographic characteristics. Population projections can alert policymakers to major trends that may affect economic development and help policymakers craft policies that can be adapted for various projection scenarios. The accuracy of population projections has been attracting more attention, driven by concerns about the possible long-term effects of aging, HIV/AIDS, and other demographic trends [3] . To produce accurate projections, the model must track changes in the attribute parameters such as the mortality rate, birth rate and health-care etc over time. This exaggerates the problem from just predicting population growth to predicting all the factors that affect the population growth either directly or indirectly.\nLong term economic consequence of political changes One of the largest political changes in the last decade was the Arab spring that swept the Middle East in early 2011 and dramatically altered the political landscape of the region. Autocratic regimes in Egypt, Libya, Tunisia, and Yemen were overthrown, giving hope to citizens towards a long-overdue process of democratic transition in the Arab world. While the promise of democracy in the Arab transition countries was seen as the driving force in the uprisings, economic issues were an equally important factor. Political stability is very difficult, if not impossible, to achieve if the economy is in disarray [11] , therefore studying the economical effects of the Arab spring on the Middle East became a very interesting problem for economists. Long term and short term effects are very different in this case and to be able to capture each appropriately, changes in parameter trends over time must be taken into consideration.\nIn this paper we focus on the first two examples: we look at forecasting brain ventricular volume as a biomarker for neurodegenerative disease progression [18] ; we also look at forecasting electrical energy consumption in the United States.c To illustrate the problem of long-horizon forecasting, we applied a state of the art Long Short-Term Memory (LSTM) [10] model datasets in these application areas (dataset details below). This is depicted in Figures  1 and 2 , where each shows the change in mean absolute forecast error over the forecasting horizon when predicting ventricular volume and electricity consumption respectively. In both cases, the LSTM model achieves good results for short-horizon forecasts. However, as the forecasting horizon increases, accuracy worsens significantly. To improve prediction accuracy, we can instead build conditional multivariate models that incorporate relevant features for prediction. For instance, in the Alzheimer's case we could include other physiological measurements for each subject, or in the electricity case, we could incorporate metereological and economic indicators that could affect electricity consumption. A challenge faced when using these multivariate models is that we need predictive features at all time points in order to make forecasts, but data from future time points are obviously not available. This scheme may yet improve prediction accuracy if we assume that values for these predictive features persist over the forecasting horizon. This assumption may hold for short-horizon forecasts, but is obviously violated in long forecasting horizons. We could at this point train a multivariate LSTM network to forecast predictive features along with the target forecast of interest but the difficulty of training LSTM networks increases substantially as the number of predictive features increases, making this approach prohibitive in many cases. This paper proposes, implements, and evaluates a scheme to inject bias into LSTM networks in a manner that significantly improves the accuracy of their forecasts over long-term horizons. Our contributions are as follows:\n\u2022 Introducing long-horizon forecasting problem in LSTMs.\nWe introduce and discuss the problem of LSTM architectures in creating forecasts over long-horizons and illustrate the problem in two distinct important application areas.\n\u2022 Propose methods to incorporate bias into LSTM models that significantly reduce the the long-horizon forecasting problem To the best of our knowledge this is the first paper to address the long-horizon forecasting problem in LSTMs. That is, this is the first multivariate model that captures changes over a long period of time on a large scale.\n\u2022 Empirical evaluation of long-horizon forecasts We show cases in which long-horizon problem exists, and show that introducing model bias to LSTM improves the accuracy and outperforms state-of-the-art models."}, {"section_title": "BACKGROUND 2.1 LSTM", "text": "A popular choice for forecasting are recurrent neural networks (RNNs) based on Long Short-Term Memory (LSTM) [10] cells. Since LSTMs incorporate memory units that explicitly allow the network to learn when to \"forget\" previous hidden states and when to update hidden states given new information, they have been utilized effectively for sequences or temporally based data. The LSTM cell is shown in figure 3. The state updates satisfy the following operations:\nHere \u03c3 is the logistic sigmoid function and \u2299 is the Hadamard (element-wise) product;\nare the bias terms. In addition to a hidden unit h t , the LSTM includes an input gate i t , forget gate f t , output gate o t , input modulation gatec t , and memory cell c t .\nWhile other variations of LSTM are commonly employed, including Gated recurrent unit GRU [4] , No Forget Gate (NFG), No Peepholes (NP), No Input Activation Function (NIAF), and others, a comparison between different variations of LSTM [8] showed that while computationally cheaper, these variations did not improve upon the standard LSTM architecture significantly. Since we are proposing a general purpose long-horizon forecasting model we will use the standard LSTM shown in figure 3 as the basis of the RNNs we implement in this paper."}, {"section_title": "Dynamic Network Models", "text": "Dynamic Network Models (DNM) [5] are a probabilistic method to define multivariate conditional models for time series. Introduced in 1992 they extend static belief network to support time series data by including temporal dependencies between representations of a static belief network across times.\nConsider a simple application in Alzheimer's diagnosis where you have two predictor features, say a summary of an MRI scan and the result of a cognitive test, and a target of interest to be forecasted, for example, Alzheimer's diagnosis. Figure 4 shows a DNM where the nodes represent the state of these variables at time t, and edges indicate conditional dependence structure within predictors and the target variable. There are two types of dependencies, contemporaneous dependencies between variables at the same time point. In our example, arcs between nodes with types MRI scans, cognitive tests and diagnosis at time t indicate the dependence of diagnosis on predictor features at specific time t. Non-contemporaneous dependencies are indicated by edges between nodes at different time points, for example, time t and t + 1. These models are usually defined by parametric models of the conditional probability distributions specified by the contemporaneous and non-contemporaneus structure described by the network as illustrated above. As such, these methods present two issues: network structure has to be either pre-specified or learned from data (belief structure learning is a challenging problem), and estimation of the parameters of the conditional probability models themselves which is usually done via maximum-likelihood [7] via updates to parameters as observations are processed over time arrive. Once parameters are estimated, the conditional-probability distributions of the model may be re-evaluated. In the example mentioned above the diagnosis at time t depends on the MRI scans and cognitive tests at time t, denoted by Q[d t |s t , c t ]. In addition, the diagnosis at time t depends on the diagnosis and cognitive tests at time t \u2212 1, denoted by R[d t |d t \u22121 , c t \u22121 ]. Hence the prediction of diagnosis is given by :\nWhere \u03b1 is the likelihood that the diagnosis predicted from the information time t \u2212 1 is correct, and (1 \u2212 \u03b1) is the likehood that diagnosis predicted from the information time t is correct. Here, \u03b1 is calculated using maximum-likelihood after each new observation and hence the next prediction uses the new \u03b1 such that the model considers the changes in contemporaneous dependencies and noncontemporaneous dependencies over time. We will use a similar concept in our work but use a non-parametric LSTM networks to make forecasts, which circumvents the structure learning issue discussed above, but presents shortcomings over the DBN idea for long-horizon forecasts.\nIn order to perform forecasts using DBNs we would solve arg max\nwhere E X (f ) corresponds to the expectation of function f over X . In this case, f is the probability model defined by the DBN and X the predictor features. Methods like the EM algorithm, based on the parameteric assumption of the model, are used to solve this optimization problem. This leads to a natural interpretation where forecasts are, in a sense, biased using the expectation of predictor features. Our proposed methods in this paper are motivated by this observation. We extend non-parametric LSTM models by adding additional input features that capture the expectation of predictor features so forecasts are therefored biased in a sense similar to that of DBNs."}, {"section_title": "MODELS", "text": "In this section, we describe two different forecasting schemes: a multivariate LSTM with a single output shown in Figure 5 , and a multivariate LSTM with multiple outputs shown in Figure 6 . We also propose two methods to compute expectation bias and show how to incorporate it expectation bias into each of these two architectures."}, {"section_title": "Multivariate LSTM with single output and bias", "text": "The first approach, model 1 ( Figure 5 ), describes Multivariate LSTM Recurrent Neural Networks. The input to the first LSTM are the observed predictor features, but for all future LSTMs the input is the expectation bias term e i,t for time t and the value of output from the previous LSTM. We introduce a new termx i,t :\ne i,t is the output of the expectation bias function at time t for feature i. We will define how to compute this in Section 3.3. The resulting model is:\nwhere n is the number of features and\u0177 is the predicted value. The optimization objective is to minimize the difference between the predicted output and the actual output, i.e. minimize ( loss (\u0177, y))\n3.2 Multivariate LSTM with multiple outputs and bias Figure 6 shows a multivariate LSTM recurrent neural network, where the outputs of an LSTM are concatenated with inputs from a bias function then passed as inputs to the next LSTM. As such, all features are predicted via the model for each time step. Each feature is represented as a concatenation of predictor features and the expectation bias:\nwhere, as before, e i,t is the output of the bias function for time t and x i,t is feature i at time step t. Now, we have the following model:x 1,t +1 ,x 2,t +1 , . . . ,x n,t +1 = LSTM(x 1,t ,x 2,t , . . . ,x n,t ) (7)\nWe define a loss function based on the predicted value and the observed values across all features, i.e.\nHere,x i is the predicted value of feature x i with \u03b1 i \u2208 [0, 1] a hyper-parameter which indicates the importance of each feature such that n i=1 \u03b1 i = 1.\nThe target is finally predicted as a function of the outputs LSTM, i.e\u0177 t +1 = f(x 1,t +1 , . . . ,x n,t +1 ) (9) Similar to the multivariate LSTM in model 1, the latest observations are taken as input and predictions are generated. The objective function is given by\nwhere \u03b1 is another hyper-parameter that weighs prediction error between target and the loss of the LSTM in predicting feature values."}, {"section_title": "Bias", "text": "We motivated the idea of incorporating expectation bias to improve long-horizon forecasts from dynamic network models described in section 2.2. In this section we show how to compute the expectation bias terms included in the two models defined above using empirical expectation estimates of predictor features x i . Here, input to the bias function is the features x 1,t , . . . , x n,t and time t. We propose two methods for bias calculation below."}, {"section_title": "Population Averaging:", "text": "In this method, expectation bias is calculated based on stationary population averages of predictor features x i using the following equation:\nwhere, \u00b5 i is the popoulation average of predictor feature x i across observations N :\n\u03b2 (t) is a time varying function defined by the user depending on the dataset. This function can differ in complexity from simply being \u03b2 (t) = 1 t to a more complex equation. However, \u03b2 (t) \u2208 [0, 1] where \u03b2 (t) = 1 at t = 1 and \u03b2 (t) = 0 at t \u2192 \u221e."}, {"section_title": "Clustering:", "text": "We can extend the above model to better capture heterogeneity across the N observations in a dataset. Here, we group observations together, specifically using the K-Means clustering algorithm [9] and use empirical expectation estimates within clusters to define empirical bias.\nDetermining the number of clusters in a data set is not straight forward, since the correct choice of K is often ambiguous. There are several methods to for choosing K including, the elbow method, X-means clustering, silhouette method and cross-validation. In our implementation, the silhouette method [22] was used to get an optimal value for K, and different Ks around the given optimal were also considered, i.e if initial K = 3 then K = 2 and K = 4 were tested to evaluate the sensitivity of our method to the number of clusters.\nEuclidean distance was used to assign samples to cluster center. Let c j denote the center of cluster j, x i is the value of feature i for the sample, and n is the number of features per sample; the distance is then calculated by the following equation:\nThus, a given sample is assigned to its closest center. The cluster centers are calculated during training to reduce computational overhead at prediction. The assigned cluster center is the bias value"}, {"section_title": "EXPERIMENTS", "text": "We show cases where long-horizon problem exists and how unbiased LSTMs are not able to provide accurate predictions for such problems. We compare the performance of biased and unbiased in models 1 and 2, where unbiased baselines are defined as follows. Baseline 1: Unbiased multivariate LSTM with a multiple output. Model 1 described in section 3.1 is compared with unbiased multivariate LSTM shown in figure 7 . The output of LSTM at time t isx * t +1 , while its inputs arex * t and the initial value of all other features x 1 , x 2 , . . . , x n at time t = 1. Accuracy: The mean absolute error (MAE) at every timestep is used to measure model accuracy. MAE at timestep t is given by\nwhere M is the number of observations acquired by the time the forecasts are evaluated, y i t is the actual value at that time t and\u0177 i t is the predicted value at time t. Evaluation: In order to study the effectiveness of expectation bias on long-horizon forecasting, we used two publicly available datasets to evaluate the models. The first dataset is from the Alzheimer's Disease Neuroimaging Initiative (ADNI) 1 , this dataset was used to predict the change in ventricular volume over time. We are particularly interested in forecasting the ventricular volume since there is a link between ventricular enlargement and Alzheimer's disease (AD) progression [18] [20] . The second dataset is monthly electricity consumption across the United States for individual states. The dataset is obtained from Energy Information Administration (EIA) [21] and NOAA's National Centers for Environmental Information (NCEI) [19] . Here, the goal is to forecast amount of electricity in Megawatt hours consumed by each state in the United States per month. Details of the datasets, setup and results will be given in the sections bellow."}, {"section_title": "Ventricular forecasting", "text": "Data Description. We are using the ADNI dataset published as part of the Tadpole challenge [6] , which consists of 1628 subjects that are either cognitively normal, stable mild cognitive impairment, early mild cognitive impairment, late mild cognitive impairment or have Alzheimer disease. This data was collected over a 10 year period, and measurements were typically taken every six months. Since subjects are allowed to enter and leave the trial at any point the number of visits per subject was different. Figure 9 shows the number subjects observed at each of the follow-up visits. The data consists of 1835 features that represent the following biomarkers:\n\u2022 Neuropsychological tests administered by a clinical expert.\n\u2022 MRI metrics measuring brain structural integrity.\n\u2022 FDG Positron Emission Tomography (PET) measuring cell metabolism, where cells affected by AD show reduced metabolism.\n\u2022 AV45 and AV1451 PET measuring a specific protein (amyloidbeta and tau respectively) load in the brain.\n\u2022 Diffusion Tensor Imaging (DTI) inferring microstructural parameters related to cells and axons.\n\u2022 Cerebrospinal fluid (CSF) Biomarkers.\n\u2022 Others including diagnosis, genetic and demographic information.\nData preparation. In order to prepare data for forecasting the following steps were followed:\n\u2022 Make all observations have same amount of time between them Since all visits are 6 months apart except for the second visit, which is 3 months after the initial visit, all data from visit 2 was discarded.\n\u2022 Transform time series into supervised learning problem This was done by making feature data at time t-1 the feature targets, and Ventricle value at time t the prediction target.\n\u2022 Feature Scaling Feature standardization was used, which makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unitvariance (dividing by the standard deviation). The general method of calculation is to determine the distribution mean and standard deviation for each feature, and standardize from there.\n\u2022 Missing data We analyzed missing data and divided each observation into two categories: missing at random or not missing at random. For example if one exam is only done once at the first visit for all subjects then it is not missing at random, and in this case we insert the correct value of that exam for future time points. For data missing at random, Hot Deck was used for imputation.\n\u2022 Feature selection We used a random forest [2] to select features with highest cross entropy reduction. The package used was the standard randomForest package in R.\nSetup. The setup is similar to that of the TADPOLE Challenge [6] . Data was divided into two datasets: a training dataset that contains a set of measurements for every individual that has provided data to ADNI in at least two separate visits, and a test data set. Individuals in the test dataset are not used when forecasting or training/building training models. The goal is to make month-by-month forecasts for normalized ventricular volume of each individual in the test dataset for a period of 5 years. Training Dataset was then divided into two sub-dataset: training and validation to facilitate hyperparameter estimation.\nOur LSTM was implemented using TensorFlow [17] . We train each LSTM for 500 epochs using Adam: A Method for Stochastic Optimization [13] . We used variable length LSTM since the number of visits per subject is not constant. Our final networks use 2 hidden layers and 64 memory cells per layer with a learning rate 0.0003. These architectures are also chosen based on validation performance. For population averaging bias \u03b2(t) is defined as:\nWhere 20 was chosen as it is the maximum number of possible visits in the training dataset. For clustering bias, the performance of Models when K = 2, K = 3 and K = 4 were compared.\nSequential target replication [14] was used for training, i.e if the LSTM has T timesteps then the error at that timestep t = 2 is loss (\u0177 2 , y T ). Our loss is a combination of the final loss and the average of the losses over all steps:\n\u03b1 is a hyper-parameter that indicates the importance of each time step. Figure 10 shows an unrolled LSTM with target replication. Each box represents a timestep, and the target for all timesteps is equal to that of the last timestep y T . This technique teaches the network to pass information across many sequence steps in order to affect the output. Target replication showed promising results when applied to a medical dataset in Lipton, Zachary C., et al. [16] . Results. Figure 11 summaries the performance of unbiased models in comparison with biased models. The bars represent the average of the mean absolute error across all forecasts. The plot shows that in most cases biased model do better or as well as unbiased models. Figure also shows that the value of K in biased cluster model can affect the performance significantly. "}, {"section_title": "Electricity forecasting", "text": "Data Description. The dataset contains 4 features; electricity consumption in Megawatt Hours, population count, price of Kilowatt Hours, and average temperature. Price of electricity was obtained from the Energy Information Administration (EIA), [21] while average temperature of that state was obtained from NOAA's National Centers for Environmental Information (NCEI) [19] . Data from January 2007 till October 2017 monthly for every state and the District of Columbia was available in the dataset.\nData preparation. One problem with this dataset is seasonality -the presence of variations that occur at specific regular intervals less than a year. Figure 12 is a plot of average electricity consumption in Megawatt Hours, temperature and price across all states; all three features show seasonality. We transformed the time series by removing dependencies between observations, so the difference between observations was used as features instead of the the observation value. Features where then scaled using the same method described in section 4.1. Setup. Models were trained on data from January 2007 through October 2015. We then made month-by-month forecasts of normalized Megawatt Hours of electricity consumed by each state from November 2015 through October 2017. A 2 layer LSTM with 64 memory cells per layer and learning rate of 0.0001 was trained with 500 epochs using Adam. For population averaging bias \u03b2(t) = 1 t was used, and for clustering bias the performance of Models when K = 2, K = 3 and K = 4 were compared. Sequential target replication was not used for this dataset.\nResults. Model 1: Baseline for model 1 for this dataset is shown in Figure 2 , unbiased LSTM was able to accurately predict the first month but as forecasting horizon increased the accuracy of the baseline model decreased significantly for all states (observations). Figure 13 compares unbiased LSTM (baseline) with biased LSTM using population average and clustering at K = 4, the plot shows that adding expectation bias significantly improved LSTM performance. Although the long-horizon forecasting problem did not disappear completely, i.e., accuracy still decreases in the expectation biased models as the forecasting horizing increases, however the effect is significantly reduced. Figure 14 shows the effect of changing the number of cluster centers on biased LSTM. For models with clusters K = 2 and K = 4 expectation biased significantly improves LSTM performance across the entire horizon, the model with K = 3 outperforms the baseline at the beginning but then its performance deteriorates quickly. This shows that like many machine learning techniques the choice of the number of cluster will affect the performance of the model. Figure  15 . In this case, the long-horizon forecasting problem is not as severe since the number of features predicted by the multiple output LSTM is small (4) and the number of time points was relatively large and thus the LSTM was able to learn to predict the features fairly well. This shows that in cases where the number of features is limited, one might consider forecasting all of the features in order to prevent the long-horizon forecasting problem. Since this dataset for model 2 did not show horizon problem adding bias did not help increase the accuracy of LSTM. Note however, that performance of expectation biased model 1 is better than unbiased model 2."}, {"section_title": "CONCLUSION AND FUTURE WORK", "text": "We described long-horizon forecasting problem in LSTM and introduced two different LSTM forecasting architectures that incorporate expectation bias, an idea motivated by the Dynamic Belief Network literature. We have shown that severe long-horizon forecasting accuracy decay can be significantly improved by expanding LSTMs to incorporate expectation bias as proposed here.\nPerhaps a key point to our results is that our models are relatively simple, and are therefore amenable to training with moderate number of observations. Unlike methods that would address long-horizon forecasting by possibly increasing the depth of LSTM networks, our method of bias can improve error without necessarily singificantly increasing the cost of training models over those used in standard practice. Furthermore, our expectation bias models scale well (especially the linear scaling of Model 1) as the dimensionality of the problem applications increases.\nIn future work, we plan to conduct further in-depth studies on architecture changes to the state model of LSTM cells to, analogous to the long and short term memory implemented by these cells, capture both short and long-term horizon forecasts. We also plan to explore other expectation biasing methods. For instance, using the EM algorithm instead of K-means to obtain expectation estimates, and using Autoregressive integrated moving average (ARIMA) based methods. In addition to these ideas, we will gauge the effectiveness of expectation bias on deep learning models that struggle to maintain accuracy in the distant future."}]