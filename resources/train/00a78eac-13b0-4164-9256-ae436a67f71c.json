[{"section_title": "Introduction", "text": "A commonly held belief in survey research is that increased burden is negatively correlated with survey cooperation. Federal Statistical Agencies and others are currently striving to lessen the reporting burden placed on respondents, as per the U.S. Office of Management and Budget's (OMB) government wide goal of five percent yearly reduction of information collection burdens. (Paperwork Reduction Act of 1995; see also Machin 1997 for a review of survey burden reduction efforts in the UK.) Burden may be defined in a number of ways -length of the interview or questionnaire, number of contacts, difficulty in reporting the requested data, etc. While there have been some studies to suggest that burden decreases survey response, the empirical evidence is not overwhelming. In the United States, the OMB monitors all federal information collections. The United States Paperwork Reduction Act of 1995 directed agencies to reduce burden. The planned amount of burden on the public required for survey data collections must be reported and approved by OMB before data collection is allowed. This burden is measured by estimating the time required for each individual to report, which is summed over all respondents for a total measure of burden. For each Federal survey, respondents are informed of an estimated amount of time required for their response. The length of the survey questionnaire is often assumed to be positively correlated with survey nonresponse. However, the evidence to support this claim is inconsistent at best. A literature review by Bogen (1996) found that while this claim was supported in some studies, other studies showed exactly the opposite. In addition, some studies showed that there was little relationship, either positive or negative, between questionnaire length and cooperation. Survey burden may also be defined as the number of survey contacts. In surveys of certain populations, sample units may be contacted on numerous occasions over time. This is particularly true in establishment surveys. Large or unique operations are selected with near certainty for recurring surveys, and are often included in samples for multiple surveys. Cooperation in any particular survey may be affected by the number and frequency of times an establishment has been selected for surveys by that organization in the past. The sum of the length of time of previous survey contacts is also assumed to adversely affect survey participation. The most common evidence for this comes from panel survey response patterns. Most panel surveys, which contact respondents multiple times over the course of data collection, suffer from attrition from the original sample (see Kalton, Kasprzyk, and McMillen 1989 for a discussion of nonresponse in a variety of panel surveys). This is taken to be evidence that increased contacts and total time spent providing data result in subsequent nonresponse. Frankel and Sharp (1981) also found that the length of a single completed survey interview was related to expressed willingness to participate in later interviews. Respondents who participated in a 25-minute interview were more likely to agree to participate in a future interview than respondents participating in a 75-minute interview. However, there was little difference in actual cooperation between those who had the long or short initial interview when later contacted for the second interview. There is also some evidence that past survey experiences may trigger future refusals. DeMaio (1980) found that one of the most common reasons for refusing interviews in later waves of the CPS panel was \"unfavorable past experiences\" as survey respondents. However, although respondents had obviously been in a survey before (the previous panel wave), \"unfavorableness\" may be due to either the accumulated burden of repeated interviews or any one of a plethora of other factors. These factors may be related to the panel or other recalled contacts from that or other organizations. Many panel surveys do not recontact early wave refusals in later waves of data collection. However, for panel surveys that do recontact early wave refusals, a significant proportion of them will respond on subsequent contacts (Presser 1989). This implies that accumulated burden does not always trigger subsequent survey refusals. U.S.D.A.'s National Agricultural Statistics Service (NASS) contacts farms and ranches in the United States for many surveys. For example, the Quarterly Agricultural Surveys collect data on crop and livestock inventories and production; the Agricultural Labor Survey collects information on hours worked and wages; the Agricultural Resource Management Survey collects information on production practices, chemical and pesticide use, and farm economics. A particular farm or ranch may be selected for any or all of these surveys, both within a single year and over multiple years. In NASS surveys, initial evidence suggested that accumulated burden may contribute to later nonresponse. During 1990 and 1991, the reasons given for refusing to participate in NASS's ongoing Farm Costs and Returns Survey (now titled the Agricultural Resource Management Survey, or ARMS), which collected detailed expenditure, income, cost of production and demographic data, were collected. Some respondents did report refusing because they had been contacted on this survey or other surveys in the past (O'Connor 1991(O'Connor , 1992. However, this was not the most frequently cited reason for refusing to participate (which was \"too busy/lack of time\"). Anecdotal information has led to the widespread belief in NASS that the ARMS is considered by respondents to be very burdensome and is thus more prone to refusals. In particular, many in NASS believe that inclusion in an ARMS sample leads to an increased likelihood to refuse subsequent NASS surveys. For this reason, elaborate cross-survey sampling techniques are employed to minimize the amount of overlap between the ARMS sample from year to year, and between the ARMS sample and other survey samples. However, no quantitative evidence for or against this theory has ever been gathered. Similarly, in a survey of farmers and ranchers in North and South Dakota, the selfreported number of past U.S.D.A. requests for data was not positively correlated with willingness to provide data to U.S.D.A. in the future (Jones, Sheatsley, and Stinchcombe 1979). This survey also did not find the frequency or number of survey requests to be a primary reason for refusing to participate in U.S.D.A. surveys. Instead, invasion of privacy was the number one reason cited for refusing to participate. The number of surveys that NASS is conducting in the population of farm and ranch operators has increased somewhat in recent years, while the size of the population has been decreasing. This suggests that the number of times an operation may be contacted by NASS and the frequency of these contacts are increasing over time. In addition, as is the case with many surveys of establishments, those with unique characteristics may be selected with certainty or near certainty for many surveys for which they are eligible. Large establishments will nearly always be asked to participate in ongoing surveys, even though the survey samples are cross-sectional and \"independent.\" Agricultural establishments' eligibility for appearing in a survey sample and probability of their appearing in one are also related to the types of commodities they produce. Diversified operations with multiple commodities (and other characteristics, such as hired labor) will be eligible for selection in multiple surveys. More specialized operations with fewer commodities or items of interest will be eligible for far fewer survey contacts (but may be included in all or most surveys collecting information on those specific commodities). We did not consider the overall number of surveys an operation could have been selected for in our set of surveys, since this would never be apparent to the respondent. This article presents an analysis of the relationship between various types of burden imposed by NASS and survey responses. In order to determine the accumulated burden on sampled operations and how this is related to participation in subsequent surveys, this article examines a set of contacts made by NASS with farm and ranch operations in the United States from January 2000 to December 2003. The article is not based on a controlled experiment but instead compares the characteristics of actual survey responders and survey refusals."}, {"section_title": "Methods", "text": "Interview disposition (completed, refused, noncontact) was recorded for each agricultural operation in the United States for the Crop/Stocks Surveys, the Agricultural Labor Surveys, the Hog Surveys, the Cattle Surveys, the Cattle on Feed Surveys, the Sheep Surveys, the December Chickens and Eggs Surveys, the Rice Stocks Surveys, the Agricultural Resource Management Surveys, and the Agricultural Yield Surveys conducted by NASS between January 2000 and December 2003. Details about these surveys appear in Appendix A. There are 184 possible survey contacts in this set. (However, it is unlikely that any agricultural operations included in this study would have qualified for all 184 of these survey contacts.) All survey samples were selected from NASS's list frame of all known farms and ranches in the United States. Samples were stratified on the basis of survey-related control data (usually size and presence of certain commodities) maintained on the list frame. Mode of contact varied, but most involved primarily telephone, with limited face-to-face and mail. The exception to this was the economic and agricultural management surveys, which were entirely face-to-face interviews. The sensitivity and difficulty of the surveys also varied. However, with the exception of the Agricultural Resource Management Survey (ARMS), all surveys generally collected data which are readily available to farmers and ranchers. The ARMS collects extremely detailed and potentially sensitive income, expense and debt information, in addition to information on pesticide and chemical use. The samples were not all independent. For example, the monthly Agricultural Yield Survey samples are subsets of the crops/stocks samples. Also, if operations are in one yield survey, they are in all subsequent yield surveys in a given crop year. This had some data collection implications since interviewers might tell operators they would likely be recontacted. However, interviewers might not know this fact and notification of additional known survey contacts is not mandated by official NASS policy. For surveys other than the sequence of yield surveys, interviewers do not normally know what other surveys an operation may be selected for. Thus, they are not able to tell respondents how many contacts they may have in the future. There is no way to know what any individual respondent was told about possible subsequent contacts. It should be noted that this analysis does not include all of the survey contacts that NASS makes within this population. However, included are those surveys which are part of national estimating programs and those with the largest samples sizes that target the broadest populations. Other surveys are conducted which may target specific specialized subpopulations (large cattle feedlots, horticultural operations, etc.), which probably have minimal overlap with the surveys we examined. These surveys are not included here, but may have contributed to the accumulated burden. In order to measure the effect of burden on later response, we examined response in several surveys and related that response to previous NASS survey burden imposed on the operations during the four years included in our data set. Because we were primarily interested in sampled operations that refused to participate, not those that we were unable to contact, we included only two types of response in our analysis: those that were contacted and provided survey data, and those that were contacted but refused to participate. Other noncontacts were minimal and were not included in our analyses."}, {"section_title": "Results", "text": ""}, {"section_title": "Assessment of Accumulated NASS Survey Burden", "text": "Once we combined response information from the 184 possible survey contacts we were able to see how many times NASS had contacted farm and ranch operations and how they responded to the contacts. The results are shown in Table 1. The total number of operations that were contacted on these surveys was 579,531. The maximum number of times an operation had been contacted was 103, although 72% of sampled operations (419,363) were contacted four times or less in the four-year period. Particularly striking in this table is the number of operations that were contacted only once or twice. This is by far the most common number of times an operation was contacted. The 2002 Census of Agriculture reported 2,128,982 farms in the U.S. So an even larger number (73%) of U.S. operations were never contacted by NASS during this period. Table 1 also shows the number of times potential respondents refused to provide survey data. The number of people who refused 100 percent of the time they were contacted is very small. Surprisingly, there are no \"100 percent refusals\" in the group of respondents who were contacted 65 times or more. There also does not appear to be any pattern to respondents' willingness to respond. That is, it does not appear that respondents cooperated then started to refuse, or vice versa. The cooperate/refuse pattern appears random across the repeated contacts. If, in fact, more contacts make people less cooperative, then we should see an increase in the percent of time operations refuse as the number of contacts increases. We do not see this pattern in our data. It is interesting that the few operations with the largest number of contacts in our data set are more cooperative than operations with fewer contacts. A formal test of the relationship between the overall percentage of surveys refused and the number of surveys an operation was selected for was performed with a simple regression model. The overall refusal percent was modeled by the count of the number of surveys for which the operation was contacted. The coefficient on the number of surveys was 2 0.1948, with a p-value of less than 0.0001 and an R-square of 0.0010. With the large number of observations (579,531) available, the statistical significance is not surprising. This means the number of surveys accounts for only one tenth of one percent of the  "}, {"section_title": "Effect of Burden on Survey Response", "text": "In order to analyze the effect of prior survey burden on later survey contacts, we compared operations that cooperated and provided survey data with operations that were contacted but refused to provide any data. We made these comparisons for ten target surveys and various measures of previous NASS survey burden. As an indication of accumulated burden, we looked at several things traditionally thought of as burdensome to survey respondents. The first burden measure we investigated was the number of times operations had been contacted by NASS in the past (as noted before, in our analysis this included 184 possible survey contacts from January 2000 until the time of data collection for each of the ten surveys in question). Table 2 shows the results. In five of the ten target surveys, operations that completed the survey had fewer prior NASS survey contacts than those who refused to cooperate. Three cases showed refusals with fewer prior contacts, while two cases showed no significant difference (a \u00bc 0:10). While there may be some effect of prior respondent burden on survey participation, it was not a consistent result. , including all survey types and data collection periods within the four-year study. b The n's are the number of operations that completed or refused to participate in the target survey. c The t-values were calculated for two-tailed hypothesis tests, with unequal variance adjustment when appropriate. We next looked at the interview length of the most recent contact and the total interview length of all NASS contacts in the previous four years. We do not have measures of actual interview times for our survey contacts so interview lengths were counted as the total OMB approved estimate of minutes of burden for each survey. The OMB estimate is a NASS provided estimate of the average number of minutes that should be required to complete the survey, based on pretesting and limited small studies. The same number of minutes is assigned to all survey respondents regardless of their characteristics or actual survey response. Comparisons of cooperating and refusing operations on this measure are shown in Table 3. For the interview length of the most recent contact, six of the ten target surveys showed that operations that completed the target survey had a shorter previous interview length than those that refused (statistically significant at a \u00bc 0:10). In two cases, refusals had a shorter interview, while there was no significant difference in another two cases. There may be some effect of prior interview length on response in some target surveys, though the imperfections associated with using the OMB approved interview length make any generalization suspect. As for the total length of all previous NASS survey contacts in the four-year study period, for six of the ten target surveys, operations that completed the target survey had a lower total a Avg. prior interview length is the mean number of minutes (measured as the total OMB approved estimate of minutes) of the operations' last NASS survey contact. b The n's are the number of operations that completed or refused to participate in the target survey. c The t-values were calculated for two-tailed hypothesis tests, with unequal variance adjustment when appropriate. interview length time (statistically significant at a \u00bc 0:10). Two surveys showed refusals had less time, while there was no difference in another two surveys. Again, there may be some impact of prior total interview length on response behavior in some target surveys, but the analysis of interview length is problematic. See Table 4 for details. \"Unfavorable\" prior survey experiences have been suggested as contributors to later nonresponse (DeMaio 1980). One way a survey experience might be perceived as unfavorable to respondents is if they have to provide information that is difficult to report, is sensitive, or requires a lot of time or effort to provide. While most of the surveys in our data set have relatively short estimated completion times and are felt to request information that is relatively easy to provide, Phase 3 of the Agricultural Resource Management Survey (ARMS) takes 90 minutes on average to complete (with some interviews lasting up to several hours). It also asks for several types of information that might be deemed sensitive, such as detailed financial information and pesticide use. This survey is widely believed in NASS to be extremely burdensome and difficult. For this reason, we suspected that participation in an ARMS survey might adversely affect cooperation on later surveys. If this were true, survey completion rates for operations that had been in a prior ARMS should be lower than for operations that had not. For this part of the study, the operations in a Avg. total interview length is the mean number of minutes (measured as the total OMB approved estimate of minutes) of the total length of the operations' NASS survey contacts for the previous 4 years. b The n's are the number of operations that completed or refused to participate in the target survey. c The t-values were calculated for two-tailed hypothesis tests, with unequal variance adjustment when appropriate. each of the ten target surveys were split into two groups, based on whether or not they had previously been in Phase 3 of ARMS during the four years of the study. Completion rates for each group were calculated and compared. (Note that this is for all operations selected to be in the ARMS Phase 3, regardless of whether the operation refused or completed the interview.) In the June 2003 Crops/Stocks survey, the survey with the largest sample in our set, the completion rate for operations that had been in a prior ARMS Phase 3 was 76.9 percent, while the percentage for those operations that had not was 69.8 percent. Surprisingly, operations in a prior ARMS Phase 3 had a higher completion rate, by 7.1 percentage points, exactly the opposite of what conventional thinking would expect. For five of the ten target surveys, operations in a prior ARMS Phase 3 showed a higher completion rate (statistically significant at a \u00bc 0:10). Two of the surveys showed a lower completion rate, and three surveys showed no significant difference (see Table 5). This indicates that operations in the long, complex ARMS Phase 3 do not always have lower completion rates in future surveys. The next measure of burden we looked at compared the number of days since the most recent contact, or how much \"time off\" an operation had had since the last interview. Comparisons are shown in Table 6. Four of the ten target surveys showed that producers who completed the target survey had had a longer break since the previous interview The n's are the number of operations that were in or were not in ARMS Phase 3 prior to the target survey. c The difference is calculated by subtracting the percent complete from operations IN a prior ARMS Phase 3 from the percent complete from operations NOT IN a prior ARMS Phase 3. d The t-values were calculated for two-tailed hypothesis tests, with unequal variance adjustment when appropriate. (statistically significant at a \u00bc 0:10). For three of the target surveys, refusals had had more time off, and there was no significant difference in the other three target surveys. There is no obvious, generalized pattern of number of days since last contact affecting response rates. Even in the cases that did show a statistically significant difference, this is difficult to translate into practical application. For example, for the June 2003 Crops/Stocks Survey, operations that completed the survey had an average of 344.03 days since they were last contacted, whilst operations that refused had an average of 354.16 days since the most recent contact. Even if the difference in averages is statistically significant, there may be little practical application when averages are 11.3 months versus 11.6 months since the most recent contact."}, {"section_title": "Discussion", "text": "In this article we have tried to define \"survey burden\" in a number of ways that are traditionally used by survey researchers. After selecting several burden measures, we examined these burdens (as imposed by NASS) to see if they affected cooperation on ten different subsequent surveys. We examined these factors separately since many of them are not independent (for example, being in the ARMS significantly adds to your total a Avg. no. days since contact is the mean number of days since the operations' last NASS survey contact (completed or refused). b The n's are the number of operations that completed or refused to participate in the target survey. c The t-values were calculated for two-tailed hypothesis tests, with unequal variance adjustment when appropriate. length of surveys). In addition, any attempt to reduce burden would likely focus on a single aspect of burden at a time. For example, efforts might be made independently to shorten interview lengths, or to reduce the number of contacts a respondent might receive. If burden imposed by NASS is correlated with cooperation on NASS surveys, NASS may want to consider ways to decrease the burden on individual operations as a means to increase later response. However, none of the types of burden we looked at appeared to be systematically related to future survey cooperation in the surveys we examined. These surveys are typical of NASS surveys and are representative of the types of information collected and the operations in most other NASS surveys. In addition, there may be other ways in which respondent burden may be defined. For example, anecdotal evidence suggests that the timing of a survey contact may affect its perceived burden. Farmers may feel a contact is more burdensome during extremely busy times, such as planting or harvesting. Establishments may perceive respondent burden more in terms of seasonal activities occurring when they are contacted, rather than by how long or how frequent the surveys are. The number one reason for refusing to participate in the 1990 and 1991 FCRS survey was \"too busy/lack of time,\" not anything specific to the survey content or their prior survey experiences (O'Connor 1991(O'Connor , 1992. Similarly, in a survey of farmers and ranchers in North and South Dakota, self-reported numbers of past U.S.D.A. requests for data were not positively correlated with their willingness to provide data to U.S.D.A. in the future (Jones, Sheatsley, and Stinchcombe 1979). This group also did not cite the frequency or number of survey requests as a primary reason for refusing to participate in U.S.D.A. surveys. Invasion of privacy was the number one reason cited by this group for refusing to participate. The effect of these differing perceptions on response or refusal may be explained in terms of a \"leverage-saliency theory\" of survey participation. Groves, Singer, and Corning (2000) have theorized that the factors contributing to response are unique to any individual survey respondent. Any particular survey request will have particular features relevant to the respondent, each with its unique saliency to that respondent. The combined importance (or leverage) and saliency of the particular feature is what influences the respondents' propensity to respond. Anything we would classify as \"burden\" would be posited to have negative saliency and negative leverage. If respondents do participate in a survey, either this means that respondents have more positive (salience and leverage) attributes to outweigh them, or that they place little negative salience and leverage on those \"burdens.\" What does this mean with respect to our results? Some of our burdens may not be salient to respondents (i.e., respondents may not remember contacts hundreds of days apart), or the respondents may not recall the time spent in the previous contact. Similarly, these burdens may have little leverage if they are not perceived as being too long. Groves, Singer, and Corning's theory suggests that if burdens are not salient they will be of little consequence. Similarly, if they do not hold much leverage (i.e., respondents remember quite well, but do not feel too negatively about them) this will also be of little consequence. Key to Groves et al.'s theory is that both sides -positive and negativemust be considered together to understand a participant's propensity to respond. Negative attributes can be quite high if there are enough offsetting positive attributes. So knowing about burden alone may not be enough to predict response. We have found in other research (McCarthy, Johnson, and Ott 1999) that knowledge of NASS and positive opinions of NASS are positively correlated with response. These factors appear to have a much higher leverage/saliency for NASS respondents than anything we have identified as burden. Future research perhaps should focus on identifying both positive and negative survey attributes. In addition, leverage may change for an attribute over time. It is clear this may have implications for panel surveys, but it may also apply to multiple independent survey contacts within the same population. If operations are repeatedly asked to report similar information, it may become easier and less burdensome over time as they become more familiar with the reporting task. In addition we may be benefiting from both \"foot in the door\" and \"door in the face\" effects. Freedman and Fraser (1966) found that once a person agrees to a small request, the requestor has a \"foot in the door\" and is more likely to gain cooperation with subsequent more burdensome requests. Since some of our surveys are short and relatively easy to complete they may facilitate later survey response. In contrast to \"foot in the door, \" Cialdini, Cacioppo, Bassett, and Miller (1978) have also shown that when initial requests are refused and the requestor gets a \"door in the face,\" people will have a greater propensity to respond to subsequent requests if they think they are smaller, less burdensome ones. Both of these factors may have increased the subsequent tendency to respond for those operations selected for the burdensome ARMS survey. For ARMS refusals, response may be boosted for the later \"low ball\" request for participation in an easier survey. For ARMS respondents, being in a prior survey may have gotten our foot in the door. Following ARMS, their cooperation in the ARMS interview is also the NASS \"foot in the door\" for any subsequent survey requests. Of course, our results do not reflect contacts by organizations other than NASS; we only included contacts over which we have control. Agricultural operations are subjected to requests from other agricultural businesses, in addition to requests targeted at the general population. We do not know how this burden from sources other than NASS affects their cooperativeness on NASS surveys. We do know, from other research (McCarthy, Johnson, and Ott 1999), that sampled operations that have more knowledge and more positive opinions of NASS are more likely to cooperate on our surveys. Because farmers and ranchers are a specialized population, they may respond differently to response burden. As representatives of establishments as opposed to households, they may be less likely to refuse cooperation because the survey topics are personally relevant to them and they may realize ways in which the survey results affect them. This may be true of other establishment populations as well. Our findings obviously are based on a special population, so research on other survey populations and with households is needed to generalize these findings."}, {"section_title": "Conclusion", "text": "Our finding that survey burden, as traditionally defined, does not uniformly affect future survey cooperation should not be taken to mean that NASS should ignore trying to reduce the number of times they contact operations. Federal statistical agencies should be commended for efforts to reduce burden on respondents, since the latter usually provide data voluntarily and without compensation. However, if the objective of reducing burden is to increase cooperation, we may be disappointed with the results of burden reduction efforts. One alternative strategy might be to increase the burden on a smaller group of respondents and forgo the objective of making burden as small as possible for everyone. If burden is concentrated on a small group within the population, additional resources could then be spent on maximizing the cooperation of this smaller group (i.e., getting our foot in the door) who would be asked to participate in many more surveys than they currently are. Whether or not cooperation could be maintained with greatly increased amounts of data being collected is, of course, unknown. To a respondent, it would be similar to being asked to be in an ongoing panel survey (for which high response rates can be achieved). However, instead of panel waves, each contact would be for a different and separate survey. Our research suggests that this may be a fruitful avenue for future research efforts. Indeed, those operations we contacted most frequently were among the most cooperative. Cooperation on agricultural surveys may be tied more to other phenomena than survey burden. We have also collected information about respondents' and nonrespondents' attitudes toward NASS as the survey sponsor (McCarthy, Johnson, and Ott 1999). Differences in the feelings potential respondents have about the survey sponsor and the perceived effect of survey statistics on respondents appear to be much more closely related to survey cooperation or refusal than burden. While survey organizations should continue to strive to reduce burden on their respondents, particularly those in limited populations, we should also be looking for real correlates of survey response. Conventional measures of burden, while long assumed to be directly related to survey cooperation, may, in truth, have little effect on response. If that is the case, resources spent on traditional burden reduction in pursuit of increased response rates may be money ill spent."}]