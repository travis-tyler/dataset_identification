[{"section_title": "Abstract", "text": "Abstract: This paper briefly reviews recent and current National Institute of Standards and Technology (NIST) research aimed at improving standard provisions and advancing structural design practice for wind loads. The research covers: (i) New wind speed maps for the conterminous United States; (ii) Risk-consistent estimation of wind load factors for use with the wind tunnel procedure; (iii) Modern peaks-over-threshold approaches to estimation of peak wind effects; (iv) Userfriendly procedures for the database-assisted design of rigid and flexible structures; methodologies; (ix) Joint climatology of wind speeds, storm surge and waves heights, and estimates of their combined effects on structures."}, {"section_title": "INTRODUCTION", "text": "\"Wind engineering is an emerging technology and there is no consensus on certain aspects of current practice : : : \" (SOM 2005). Much of the ongoing research reviewed herein was prompted by the NIST recommendation, following the Federal Building and Fire Investigation of the WTC Disaster and the SOM (2005) report, that \"nationally accepted performance standards be developed for : : : estimating wind loads and their effects on : : : buildings for use in design : : : \" (NIST 2011). That research led to the development of (i) new wind speed maps for the conterminous United States (Pintar et al. 2015) , (ii) a simple methodology for determining wind load factors or design mean recurrence intervals (MRIs) of wind effects (Simiu et al. 2017b ), (iii) peaks-over-threshold methods for estimating peak wind effects, demonstrated to significantly outperform methods currently in use , (iv) user-friendly procedures for the database-assisted design of rigid and flexible structures, which limit the contribution of the wind engineer to (a) participating in the preliminary design process, and (b) providing the requisite wind velocity and aerodynamic pressure time series data in formats fully open to effective scrutiny, while leaving the structural engineer in full control of the final design process, including the dynamic analyses and the determination of the global forces, the internal forces, and the peak demand-to-capacity indexes (Simiu and Yeo 2015) , (v) novel, effective approaches to codification of pressures on cladding and components Gierson et al. 2015 Gierson et al. , 2017 , and (vi) a recent proposal for modifying ASCE 7-10 Standard provisions for the design of super-tall buildings by the wind tunnel procedure, determined on the basis of modern models of the planetary boundary layer to be severely unconservative (Simiu et al. 2017a) . More recently, with the publications of the Technical Investigation (Kuligowski et al. 2014 ) of the May 22, 2011 Joplin, MO, Tornado, and the Measurement Science R&D Roadmap for Windstorm and Coastal Inundation Impact Reduction (NIST 2014) , NIST added to its research agenda (vii) Computational Wind Engineering, with the objective of developing computational procedures capable of providing, in the not too distant future, a substitute for certain types of aerodynamic testing (Yeo and Chowdhury 2013) , (viii) the development of tornado-resistant design methodologies, since (a) the tornado hazard has recently been estimated to be significantly higher than shown in current tornado wind speed maps, and (b) the US death toll in tornadoes is greater than in hurricanes and earthquakes combined (data available from 1950 to present) (Kuligowski et al. 2014 , Phan et al. 2010 , Phan and Simiu 2011 , and (ix) the development of joint probabilities of hurricane wind speeds, storm surge, and waves and of approaches to the probabilistic estimation of their combined effects on coastal structures (Phan and Simiu 2011) ."}, {"section_title": "WIND SPEED MAPS FOR THE CONTIGUOUS UNITED STATES", "text": "NIST has recently led an effort to improve upon the ASCE 7-10 (ASCE 2010) wind speed maps for inclusion in the ASCE 7-16 Standard (to be released in early 2017). In the new maps, super-stations-which resulted in an artificially uniform spatial distribution of wind speeds over most of the contiguous United States-are no longer used, and risk-consistent maps are obtained using statistical spatial smoothing techniques to individual stations. Also, peaks-over-threshold (POT) models for individual stations are used in place of classical extreme value models applied to maximum yearly data. A summary of the procedure used for the contiguous US-areas not prone to hurricanes (Pintar et al. 2015) follows.\nThe available raw data are the time histories of peak wind gusts, mostly over 11 m/s at more than 1,000 stations. Winds were classified by storm type. Data from hurricanes and tornadoes were excluded, with all remaining data classified as either thunderstorm or non-thunderstorm. The data were checked for quality and were converted to speeds at 10 m height above ground over terrain with open exposure. No stations in service for less than 15 years were considered.\nThe procedure has two stages. In the first stage, the two-dimensional Poisson process described by Smith (1989) , which is a POT model, was used to estimate all return speeds of interest for all stations deemed suitable. In the second stage, the return speeds were smoothed using local regression (Cleveland and Devlin, 1988) to produce the final maps.\nAn advantage of POT over classical models is the ability to leverage more data. Whereas classical extreme value models describe the probability distribution of the maximum value over, for example, one year, POT models describe the stochastic nature of all observations crossing some high threshold. As part of this work, an approach to choosing an optimal threshold based on the data was developed and employed.\nLocal regression is a well-established general purpose statistical approach to smoothing. In this particular setting, the return value at some location would depend on all stations within a neighborhood of that location. The closest stations are weighted most heavily. Neighborhoods are chosen dynamically to include a fixed proportion of the available stations. Thus, neighborhoods in the western United States are expanded in comparison to those in the east. Figure 1 depicts the map of non-hurricane wind speeds with a 50-year MRI. The points show station locations. SOM (2004) notes that the ASCE 7 Standard is incomplete insofar as it provides no guidance on wind load factors appropriate for use with the Standard's wind tunnel procedure. The purpose of the NIST research on this topic is to contribute to such guidance. For example, design wind effects with a 50-year mean recurrence interval, the classical expression for the wind load factor \u03b3 as a function of the uncertainties in the micrometeorological, wind climatological, aerodynamics and dynamics elements that determine wind loads can be written as follows (Ellingwood et al. 1980) :"}, {"section_title": "WIND LOAD FACTORS FOR USE IN THE WIND TUNNEL PROCEDURE", "text": "where p pk is a peak wind effect (e.g., pressure, force, moment, deflection, acceleration), and the aerodynamic coefficient C p,pk \u00f0\u03b8 m \u00de depends upon the area being considered, which can be as small as a roof tile or as large as an entire building. Once this dependence is taken into consideration, for rigid structures the gust response factor G = 1 and COV(G) = 0. COV is covariance, and V(N) is the wind speed with an N-year MRI, estimated from samples of largest wind speeds regardless of wind direction \u03b8; \u03b8 m is the direction for which the product G(\u03b8) C p,pk (\u03b8) is largest; E z is a terrain exposure factor assumed for simplicity to be independent of direction; z denotes height above the surface; and K d is a wind directionality reduction factor that takes into account the fact that the direction \u03b8 m and the directions of the largest directional wind speeds typically do not coincide. The factor k in the first equation is based on calibration against past practice. According to Ellingwood et al. (1980) , it is reasonable to assume k \u2248 2, which, for rigid structures, typical uncertainties, and N = 50 years, yields \u03b3(50 yrs) \u2248 1.6. The design peak wind effect is p pk des \u00f0N = 50 yrs\u00de \u2248 \u03b3\u00f0N = 50 yrs\u00dep pk \u00f050 yrs\u00de (3) Figure 1 . Map of non-hurricane wind speeds for a 50-year MRI Source: Pintar et al. (2015) .\nwhere the overbar denotes mean. This straightforward approach allows practitioners to use appropriate wind load factors applicable when the uncertainties are different from those assumed in the ASCE 7 Standard. Illustrations of the approach are presented for a variety of cases of practical interest in Simiu et al. (2017b) . The approach reflects the fact that the various uncertainties should not be accounted for in isolation. Rather, to achieve risk-consistent designs, they should be accounted for collectively, in terms of their joint effect on the design wind loading. C p,pk \u00f0\u03b8,\nwhere the peak pressure coefficient C p,pk is a function of wind direction \u03b8, the length of the pressure record T and the number of epochs n in which it is subdivided. F r is the probability that the variate C p,pk \u00f0\u03b8, T\u2215n\u00de is not exceeded in r epochs, with r \u2265 n. Assuming that the EV Type I distribution is an appropriate model, the use of the probability F r = 0.8 rather than F r = 0.5704 would be inconsistent with the meaning ofp pk as a mean value. The deviation from the mean is accounted for by Eqs. 1 and 2. It need not and should not be accounted for twice: once in Eqs. 1 and 2, and once by selecting a value for F r greater than the mean. It could be argued that the use of the 0.78 or 0.8 value of F r is consistent with storm durations in excess of one hour (e.g., three hours). Note, however, that if a storm duration longer than one hour was assumed, the expected peak corresponding to it should be estimated directly by using in Eq. 5 with a value of r consistent with that duration. Also, the assumption that the storm durations are longer than one hour would clearly violate the accepted design practice, which follows the convention of a storm duration of one hour (see, e.g., ASCE 7-10, Eq. 26.9-11; ASCE 7-10 Commentary, Figure C26 .5-1). The design wind effect is equal to the estimated expectation of the peak wind effect times a wind load factor. Simple calculations based on the expression for the load factor given in Simiu et al. (2017b) show that the load factor is not affected significantly by errors associated with the interpolations required in typical database-assisted design applications (see section on database-assisted design). However, if the available wind speed records are very short (5 years, say), the wind load factors RECENT AND CURRENT WIND ENGINEERING RESEARCH AT THE NATIONAL increase by amounts that can exceed 15%. If, as is done in the ASCE-7 Standard, the wind load factor is accounted for by using increased MRIs of the design wind effects, those MRIs must be commensurate with the estimated wind load factor. For example, for N = 50 years, the increased MRIs of the design wind effects may have to be longer than the 700-yr value specified in the ASCE 7 Standard."}, {"section_title": "ESTIMATION OF TIME SERIES PEAKS USING THE TWO-DIMENSIONAL POISSON PROCESS AS A PEAKS-OVER-THRESHOLD MODEL", "text": "As shown in the next section, the database-assisted design procedure makes use of time histories of pressures measured in the wind tunnel at large numbers of taps on the external surface of building models; wind effects on structural members consist of time series obtained via weighted summations of individual pressure time histories. The design process assures that, after the application of appropriate safety margins, the combined estimated peak wind effect and gravity load effect do not exceed the member capacity. Given the time series of a wind effect, it is therefore necessary to estimate the distribution of its peak corresponding to a specified storm duration (e.g., one hour). The preceding section showed that special attention needs to be paid to the mean and coefficient of variation of that distribution, and notes that the mean of the distribution, rather than the 80 th percentile specified in the ISO 4354 (2009) Standard, should be used in calculations. The procedure for estimating peaks usually partitions the time series into n = 16 equal epochs (Gavanski et al. 2016) . The respective n maximum values are then fitted to a EV Type I (Gumbel) distribution. A weakness of this approach is the arbitrary choice n = 16, since the estimates can depend significantly upon n. NIST has recently developed the following six-step approach, denoted POTMax, based on a peaks-over-threshold (POT) model consisting of a two-dimensional Poisson process described by Smith (1989) :\n(1) If a minimum is considered, as in Figure 2 , reflect the measurements about zero to estimate the distribution of a maximum. (2) De-cluster the observations x by forming clusters and discarding all but the cluster maxima, thus obtaining the de-clustered data x dec . (Clusters are observations between an up-crossing and the following down-crossing of the mean. De-clustering is required to meet the independence assumption on which the POT model is based). (3) Select the threshold u (dashed line in Figure 2 ). The threshold is selected by an optimization procedure described in Pintar et al. (2015) . (4) Fit the POT model to the declustered and thresholded data (x decl > u; dots in Figure 2 ) via maximum likelihood estimation. In structural engineering applications, one may conform to accepted practice by fixing the model's tail length parameter to zero (i.e., specifying the Gumbel distribution). (5) "}, {"section_title": "DATABASE-ASSISTED DESIGN AND ITS APPLICATION IN STRUCTURAL ENGINEERING PRACTICE", "text": "Estimates of wind effects on buildings by database-assisted design (DAD) methods can be far more accurate than those based on the reductive information available in standards. An upgraded version of DAD was developed that streamlines the RECENT AND CURRENT WIND ENGINEERING RESEARCH AT THE NATIONAL wind and structural engineering components of the design process via the direct computation of demand-to-capacity Indexes (DCIs, i.e., left-hand sides of design interaction equations). The computation achieves the rigorous combination of imperfectly correlated time series of wind forces and effects, thus eliminating errors due to subjective estimates of combined effects. This approach is applicable to any rigid or flexible building (Simiu and Yeo 2015) . It allows the structural engineer to control all phases of the design, including the dynamic analysis, and the computation of global and internal forces and of the requisite DCIs; the wind engineer participates in the preliminary design, and produces the requisite wind speed and aerodynamic data.\nNIST's DAD work on rigid buildings has focused on simple buildings with gable roofs, portal frames, and bracing parallel to the ridge (Habte et al. 2017) . Useful features of this work include (i) the capability to use the two largest building aerodynamics databases available worldwide, (ii) the use of large simulated extreme wind speed databases, (iii) a novel interpolation scheme that allows the design of buildings with dimensions not represented in the databases. One important limitation for any interpolation procedure is that the roof slopes being considered should not correspond to qualitatively different aerodynamic behaviors, which would be the case if one of the slopes is less than, while the other slope exceeded, approximately 22\u00b0, or if one of the slopes is less than, while the other slope exceeded 39\u00b0(Stathopoulos 2013, personal communication). For details, see Habte et al. 2017, (iv) an effective multiplepoints-in-time algorithm for estimating peaks, (v) parameter-free methods for estimating DCIs with specified MRIs, and (vi) accounting for P-delta effects (Coffman et al. 2010 , Habte et al. 2017 ). The results obtained confirm (i) the published results showing that the ASCE 7-10 envelope procedure can significantly underestimate wind effects, (ii) the mutual consistency of the two aerodynamic databases being used, and (iii) DAD's potential for practical use. Updated software is being developed for flexible structures, for which dynamic analyses are performed by the structural engineer using inputs based on actual member sizes as determined from wind speed and aerodynamic pressure data. For rigid buildings the software developed for the implementation of the procedure and a user's manual are available in NIST (2004) and in Habte et al. (2016) , respectively. Figure 4 shows the peak DCI associated with axial force and bending moment for a frame column as a function of wind speed and direction. Such plots, used in conjunction with the matrix of simulated peak directional wind speeds in a large number of storm events yield, via non-parametric statistics, DCIs with any design MRI. If, for any cross section, the DCI differs significantly from unity, the procedure is iterated until that cross section is sized appropriately.\nExamples of interpolation results are shown in Figure 5 . Note that, even if the results of the interpolations are in error by, say, 10% or even 15%, the consequent global errors in the design values are considerably smaller, as shown by the results on the estimation of wind load factors (Simiu et al. 2017b )."}, {"section_title": "CODIFICATION OF PRESSURES ON COMPONENTS AND CLADDING", "text": "Current ASCE 7-10 (2010) specifications of wind pressures on low-rise buildings are based on data that are in some cases thirty to forty years old. Advances in computer technology currently allow simultaneous recording of as many as hundreds of pressure taps. Also, wind tunnel test measurements are now available for many building geometries. The NIST/UWO database (NIST 2004 ) and the Tokyo Polytechnic University (TPU) database (Tamura 2012) are the most referenced databases. "}, {"section_title": "RECENT AND CURRENT WIND ENGINEERING RESEARCH AT THE NATIONAL 9", "text": "Wind Engineering for Natural Hazards Downloaded from ascelibrary.org by University of Illinois At Urbana on 10/16/18. Copyright ASCE. For personal use only; all rights reserved. Duthinh et al. (2015 ) establish a clear and reproducible methodology for using the NIST-UWO database, to calculate peaks of wind pressure over different size areas of building surfaces. This is an essential component to updating wind pressure coefficients for components and cladding and for eliminating deficiencies in the current wind load specifications.\nThe time series of the aerodynamic force is obtained by summing up the product of pressure time series measured in wind tunnel tests at adjoining pressure taps by their respective tributary areas or cells. Cell boundaries are straight lines equidistant to adjacent taps, but the taps are at the center of cells only in a regular grid. This summation is carried out for all combinations of tributary areas that make up rectangular areas, and is simplest when the grid of taps is regular. Special consideration must be given to the study zone edges and corners, which generally do not coincide with cell boundaries, and to the places where grids of different densities merge.\nTo limit the number of combinations for large zones of interest, and not to lose any data (as some of the cells along the long edges of roofs have an aspect ratio of 3.5), the aspect ratio of the rectangles formed by the aggregation of cells is limited not to exceed four. This aspect ratio covers many practical units of components and cladding, and allows consideration of long, narrow zones along the edges of roofs and walls. This choice also covers all \"effective wind areas used to evaluate (GC p )\", whose width, according to the Commentary of ASCE 7-10, \"need not be taken as less than one-third of the length of the area. This increase in effective wind area has the effect of reducing the average wind pressure acting on the component.\"\nNote that there are two consecutive steps in the selection of the peak wind pressures for design purposes: selection of peaks over time, and selection of peaks over all wind directions. The selection of the peaks over all wind directions is inherent in the envelope method, as defined in the ASCE 7 Standard. Finally, the peaks corresponding to the most unfavorable combination of cells forming various areas are chosen for the development of design specifications.\nAn alternative method of area averaging of pressures measured by irregularly spaced taps was developed by Gierson et al. (2015 Gierson et al. ( , 2017 . In this method, the assignment of tributary areas uses Voronoi (1908) diagrams, which in turn can be derived from Delaunay (1934) triangulation. Delaunay triangulation consists in connecting a set of taps by straight lines forming triangles that (1) do not overlap, (2) cover the entire interior space formed by the taps, and (3) do not have any taps within a triangle's circumcircle. A Voronoi diagram is created by drawing perpendicular bisectors to the previously generated lines. Regions formed by these bisectors contain one tap each, and bound the area that is closer to that tap than to any other tap. A MATLAB (2014) function used to automate this procedure is able to generate both Delaunay triangulation and Voronoi diagrams from an arbitrary set of Cartesian coordinates. In this application, the Cartesian coordinates are selected as pressure tap locations on a flattened representation of the building. This method provides a general, automated means to assign tributary areas to irregularly spaced taps.\nNext in this alternative method, a grid consisting of identical rectangles is superposed on a flattened representation of the building enclosure. Grids of various size are placed at various offsets with respect to the pressure taps, and the wind tunnel pressure time series are area-averaged from their tributary areas into the corresponding grid areas using Boolean algebra. The two methods produce comparable results for the same data set (Figure 6 shows a limited comparison) and when applied to the UWO and the TPU databases respectively.\nResults reported in Duthinh et al. (2015 and in Gierson et al. (2015 Gierson et al. ( , 2017 show significant underestimation of wind pressure coefficients by ASCE 7-10 (2010) for the roofs and walls of low-rise buildings. Possible reasons for the underestimation include the fact that wind tunnel tests from four or five decades ago used many fewer pressure taps than nowadays, and even fewer taps could be read simultaneously, given the technology available at the time. Future work includes the validation of these conclusions by alternative methods for the estimation of peaks (see section Estimation of non-Gaussian time series peaks using the two-dimensional Poisson process as a peaks-over-threshold model above). All buildings in the NIST-UWO database are being investigated, together with those in other publicly available databases such as the TPU. Only at the conclusion of the study can more definitive recommendations be made, including "}, {"section_title": "RECENT AND CURRENT WIND ENGINEERING RESEARCH AT THE NATIONAL", "text": "possibly changes in the number, size, shape and location of the various wind pressure zones, together with their associated pressure coefficients."}, {"section_title": "MODERN PLANETARY BOUNDARY LAYER MODELING AND ITS IMPLICATIONS FOR ASCE 7-10 PROVISIONS ON SUPER-TALL BUILDING DESIGN", "text": "In the ASCE 7-10 Standard (2010) the wind speeds in the Planetary Boundary Layer (PBL) are modeled by strictly empirical power laws developed mostly in the 1960s. In these models, wind speeds increase monotonically within the boundary layer up to the gradient height z g (a term applied in the Standard to both cyclostrophic and geostrophic conditions), specified to be 200 to 250 m for water surface exposure, 300 to 350 m for open terrain exposure, and 400-450 m for suburban terrain exposure; for elevations z \u2265 z g the wind speed is assumed to be constant and equal to the gradient speed. However, in the 1990s and subsequent years, theory supported by PBL flow measurements and Computational Fluid Dynamics (CFD) Direct Numerical Simulation, established the role played by the free flow in determining the PBL characteristics and developed realistic PBL models that are significantly different from ASCE 7-10 models. As shown by Zilitinkevich and Esau (2002) among others, neutrally stratified flows can be either of the \"truly neutral\" or the \"conventionally neutral\" type. \"Truly neutral\" flows are characterized by a Kazanski-Monin surface buoyancy flux parameter \u03bc b = 0 and the number \u03bc N = N/| f | = 0, where N is the Brunt-V\u00e4is\u00e4la frequency and f is the Coriolis parameter. Zilitinkevich and Esau (2002) note that \"truly neutral flows are observed during short transition periods after sunset on a background of residual layers of convective origin,\" \"are often treated as irrelevant because of their transitional nature, and are usually excluded from data analysis;\" \"neutrally stratified PBLs are almost always 'conventionally neutral,' that is, neutral and developing against a background stable stratification; they have parameters \u03bc b = 0, \u03bc N \u2260 0; typically, 50 < \u03bc N < 300. Simiu et al. (2016) showed that at mid-latitudes, for heights of up to a few kilometers, (i) the mean velocities U(z) (parallel to the friction velocity) increase monotonically with height, (ii) the velocities V(z) (normal to the friction velocity), and the veering angles, are negligibly small for buildings with height h < 1 km, and (iii) the mean wind profile can be described by the log law up to elevations that, for the strong wind speeds of interest in structural design, far exceed those indicated in ASCE 49-12 Standard (2012) . For further details, see Simiu et al. (2017a, Figure 6 ).\nSince PBL heights are considerably greater than the ASCE 7-10 gradient heights z g , for h > z g the PBL model inherent in the Standard is not appropriate. To eliminate the possibility of unconservative designs, the Standard must explicitly provide for an exception to its definition of gradient heights by specifying that the increase of mean wind speeds with height for elevations z > z g be taken into account for buildings with height h > z g . For example, considering a building with height h = 10 m and 71.6 m \u00d7 71.6 m in plan (Baker et al. 2000) , it is assumed that the terrain exposure is suburban, with roughness length z 0 = 0.3 m; the natural frequency of vibration and the damping ratio in the fundamental mode are 0.1 Hz and 0.02, respectively; and the mean hourly wind at 10 m above ground in open terrain is 35 m s \u22121\n. The mean hourly wind speed at 10 m above ground over suburban terrain is then estimated to be U(10 m) \u2248 29 m s \u22121 . According to the ASCE 7-10 (2010) Standard, the PBL height is z g = 366 m, meaning that, for elevations z > z g = 366 m = 0.6h, U(z) \u2261 U(0.6h) and the turbulence intensity vanishes. Calculations of along-wind response then yield a deflection at the top of the building \u03b4(h) = 1.05 m. On the other hand, if it is assumed that the contemporary PBL model is valid, the calculated peak deflection is \u03b4(h) = 1.61 m. The difference between the two results is due to the fact that in contemporary PBL modeling, mean speeds increase, and the flow is turbulent, up to z > h = 610 m > z g = 366 m.\nASCE 7-10 (2010) Section 31.4.3 applied to buildings states: \"Loads for the main wind force resisting system determined by wind tunnel testing shall be limited such that the overall principal loads in the x and y directions are not less than 80% of those that would be obtained from Part I of Chapter 27 : : : The overall principal load shall be based on the overturning moment for flexible buildings : : : \" Since in the example above h > z g , this means that, according to the Standard, the design overturning moment shall not be less than 80% of its calculated value corresponding to the deflection \u03b4(h) = 1.05 m, i.e., to the design overturning moment based on Table 26 .9-1. However, this deflection would be an artifact of the unrealistic ASCE 7-10 specifications. In fact, since the PBL height exceeds the height h = 610 m, the intent of the ASCE 7-10 Section 31.4.3 would be satisfied if the overturning moment used in design was greater than 80% of the larger overturning moment consistent with a peak deflection \u03b4(h) = 1.61 m, rather than with the smaller value \u03b4(h) = 1.05 m obtained by using the low gradient height specified in ASCE 7-10 Table 26 .9-1. We assumed that the tall building may be affected aerodynamically by neighboring structures (as was the case, for example, for the WTC twin towers or the Petronas towers in Kuala Lumpur)."}, {"section_title": "COMPUTATIONAL WIND ENGINEERING", "text": "NIST is currently engaged in an effort to develop CFD algorithms for use in structural engineering. As part of that effort, the authors performed three-dimensional simulations of turbulent Atmospheric Boundary Layer (ABL) flows over open terrain and of flow past a square cylinder, and are assessing the quality of the simulated flows from a wind/structural engineer's viewpoint.\nComparative study of subgrid-scale models in wall-bounded flow. Subgridscale (SGS) models are required in large-eddy simulations (LES) of turbulent flows. We conducted a comparative study of different SGS models, including kEqn (k-equation eddy viscosity, Yoshizawa 1985) , WALE (Wall-adapting local eddyviscosity, Nicoud and Ducros 1999), Sigma (Nicoud et al. 2011) and CSGS (Constrained SGS, Chen et al. 2012 ) models to investigate their performance in wall-bounded flow. The flow considered in the study has the advantages of being well-documented and validated in the fluid dynamics literature and of being similar to atmospheric boundary layer flow near a wall. Wall-resolved LES simulations of channel flows were performed at Reynolds number Re \u03c4 = 395. The simulations showed that the sensitivity of the results to the SGS model is greatest in the buffer sublayer. From a benchmark DNS (Direct Numerical Simulation) result (Moser et al. 1999) , it was found that the WALE and Sigma models perform better in profile that agrees with the DNS results to within about 5%. A remarkably close match is found in the viscous sublayer for all models. In the logarithmic sublayer and outer layer, all profiles the simulation of the fluctuations, while the CSGS model achieves the best mean velocity profile. The SGS dissipation influences strongly the velocity fluctuations but has little effect on the mean flow and the log-layer mismatch. As shown in Figure 7 , all SGS models achieve a mean-velocity display the log-layer mismatch problem. However, in the buffer sublayer, where turbulence flow is the most intense, the simulated flows show the highest deviations from SGS models used in this study.\nLarge-eddy simulations of atmospheric boundary-layer (ABL) turbulence. We performed large-eddy simulations of model-scaled neutrally stratified ABL flows. The kEqn model was employed for the SGS motions, and a wall shear model (Schumann 1975 ) was applied on the ground. The mean streamwise velocity profile is approximately logarithmic, yet near the ground the log-layer mismatch persists. The second and third moments of the turbulence represent well the underlying physics. The SGS dissipation agrees well with the analytical counterpart from the theory. The spatial spectra follow well the \u22125/3 power law at large wavenumbers. The spatial coherences decay exponentially as functions of reduced frequencies. Except for a well-known problem of the log-layer mismatch (i.e., the mean velocity near the ground), the turbulence statistics can be simulated adequately by LES using simple SGS and wall models. Figure 8 shows that the simulation represents adequately convective ABL flow contributing to the vertical turbulent energy transport.\nURANS and hybrid LES/RANS simulations of flow over a bluff-body. Simulations of flow past a square cylinder were performed by using URANS (Unsteady Reynolds-Average Navier-Stokes) and Hybrid LES/RANS based IDDES (Improved Delayed Detach Eddy Simulation, Shur et al. 2008 ) and the Gieseking blending function (Gieseking et al. 2011) simulations to numerically investigate the velocity field around, and pressures distribution and forces over a square cylinder immersed in a uniform, smooth oncoming flow with Reynolds number Re = 21400 (Ke and Yeo 2016) . The vortex shedding responses in terms of Strouhal number, the pressure distribution, the velocity profile and the velocity fluctuations obtained by numerical simulations were compared with experimental data (Bearman and Obasaju 1982 , Lyn et al. 1995 , Nishimura and Taniike 2000 , Noda and Nakayama 2003 . Both URANS and IDDES simulations accurately predict the vortex shedding frequency and the velocity field upwind of the wake region. The study (Ke and Yeo 2016) shows that the finest spanwise Figure 8 . Contours of the normalized streamwise x-velocity in a vertical yz-cross section. The black lines are streamlines of (v,w) , with the line width coded by its magnitude Source: Shi and Yeo (2017) ."}, {"section_title": "RECENT AND CURRENT WIND ENGINEERING RESEARCH AT THE NATIONAL 15", "text": "Wind Engineering for Natural Hazards Downloaded from ascelibrary.org by University of Illinois At Urbana on 10/16/18. Copyright ASCE. For personal use only; all rights reserved.\ngrids do not necessarily produce the most reliable results. Rather, if a spanwise cell spacing is appropriately chosen (e.g., H/24 in this study where H is the dimension of the square cross-section), the IDDES model reasonably predicts the wake region flow (in terms of pressure coefficient distribution, streamwise and cross-stream velocity profiles and rms (root mean square) velocity fluctuations), while URANS is less effective in predicting pressures on the rear surface near the wake (Figure 9 )."}, {"section_title": "TORNADO HAZARD MAPPING AND TORNADO-RESISTANT DESIGN", "text": "Even though the United States experiences more than 1,200 tornadoes annually, and tornadoes have caused more fatalities per year than hurricanes and earthquakes combined (since the beginning of official tornado record in 1950), building codes, standards and practices do not require conventional buildings to be designed for tornado hazards except for storm shelters 1 , safe rooms 2 , and the safety-related Figure 9 . RMS pressure coefficients. Similar results were obtained for mean pressures Source: Ke and Yeo (2016) . A storm shelter specifically designed to meet FEMA safe room recommended criteria as provided in FEMA P-320 or P-FEMA 361. structures, systems, and components 3 of nuclear power plants. Based on findings from its technical investigation of the deadly 2011 tornado in Joplin, Missouri, NIST \"recommends that nationally accepted performance-based standards for the tornado-resistant design of buildings and infrastructure be developed and adopted in model codes and local regulations to enhance the resiliency of communities to tornado hazards. The standards should encompass tornado hazard characterization, performance objectives, and evaluation tools\" (Kuligowski et al. 2014) . Toward that end, NIST is also working to develop a new generation of tornado hazard maps, which will underpin a planned national performance-based design standard for tornadoes .\nA major challenge in developing accurate tornado hazard maps is understanding the limitations and biases in the tornado databases maintained by the National Weather Service (NWS), which go back to 1950. Changes over time in weather observing technology, communications technology, information technology, tornado science, NWS tornado rating and reporting practices, and many other factors complicate the analysis of the available tornado climate data. One element of this challenge is the so-called population bias, where tornadoes are under-reported in areas with smaller populations, where they are less likely to be observed or are classified as less intense than they really are. This is because observed damage to structures is the primary means for assigning tornado intensity ratings. Under-classification was documented for 51 Midwest super-cell tornadoes by Alexander (2010) , who compared F (Fujita) or EF (Enhanced Fujita) ratings (a) assigned by the NWS based on observed damage, and (b) developed from mobile radar measurements (Figure 10 ). According to the measurements 82% were strong or violent tornadoes (EF2-EF5), whereas 69% of the same set of 51 tornadoes were rated and recorded by the NWS as weak (EF0-EF1). Systematic empirical and modeling studies are currently underway to quantify the population bias. Preliminary results from a geospatial analysis of tornado data from 1995 to 2005 indicate that in rural areas where the average building density is only a few buildings per square kilometer, which characterizes much of the most tornado-prone US including the Great Plains, Midwest, and Southeast, the observed rate of tornado occurrence may be as much as an order of magnitude smaller than in more densely populated areas. A complementary modeling study is also being conducted, where simulated tornadoes are passed over grids of different spacing, with each grid point representing the location of a hypothetical building or other damage indicator. Early results from this modeling approach are consistent with observations from the empirical study and from the mobile radar climatology (Alexander 2010) , indicating that many tornadoes in rural areas have not been detected and included in the database, and many tornadoes in the database have been rated as less intense than they really were."}, {"section_title": "JOINT WIND, STORM SURGE, AND WAVES HAZARDS AND COMBINED EFFECTS", "text": "Hurricanes, which produce strong wind, storm surge, and waves, wreak havoc on the lives and infrastructure of coastal communities. Of these hurricane hazards, storm surge -a local rise in sea elevation -is perhaps the most devastating element. Storm surge depends on the tidal stage, barometric pressure, Coriolis effect, wind stress, and wave forcing, and is strongly influenced by the local topography and bathymetry. Thus, designing for the effects of the combined hurricane wind, storm surge, and wave hazards requires a multi-hazard approach that can account for their combined effects and the influence of local topography and bathymetry. NIST developed methodologies for (1) computing the joint probability of wind speeds and storm surge heights, with consideration of site specificity (Phan et al. 2007 , and (2) integrating the Simulating Waves Nearshore (SWAN) third-generation wave model into the Sea, Lake, and Overland Surges from Hurricane (SLOSH) model (Phan et al. 2010) . Briefly, the methodology for computing the joint probability of wind speeds and storm surge heights calls for (1) mass hydrodynamic simulations using SLOSH for the \"basin\" of interest (Figure 11 shows a typical SLOSH simulation); (2) the development of joint histograms of wind speeds and storm surge heights that result from the mass hydrodynamic simulations (Figure 12 shows the joint histogram of peak wind speed/storm surge height at the Port of Tampa); (3) the computation of the joint probability of wind speed/storm surge height exceedance from the joint histogram (Figure 13) , and (4) the mean recurrence intervals of joint hurricane wind speed/storm surge events for the site of interest as the inverse of the bivariate joint annual probability of exceedance for the site.\nThese methodologies are aimed at developing site-specific, risk-based design criteria for structures subjected to hurricane wind, storm surge, and wave effects. One of the approaches for developing structural design criteria makes use of the time series of the sum of the simultaneous wind speed and storm surge effects, and involves the following steps (Phan et al. 2007 ): v ij and corresponding storm surges s ij for all i, j with i = 1, 2, : : : , n, n = number of simulated hurricanes used in the calculations, j = 1, 2, : : : , m, and m is the number of wind speed directions considered (e.g., m = 16). The combined effect could be the maximum stress in a member under gravity, wind and storm surge, or the left-hand side of the interaction equation for members subjected to combined axial load and bending; or the aggregate loss of electrical power in a specified region due to damage to overhead power lines induced by wind and damage to underground cables caused by seepage of water following a storm surge and the consequent flooding.\n2. Perform a probabilistic analysis of the univariate time series \u03c3 i similar to the analysis applied to hurricane wind effects representing the maximum of the directional effects in each of a number n of simulated hurricanes (see Phan and Simiu, 2011) . This analysis can yield effects \u03c3 N corresponding to any specified mean recurrence interval N.\n3. For a design to be acceptable \u03c3 N must be less than the corresponding specified limit state associated with the mean recurrence interval N."}, {"section_title": "SUMMARY AND CONCLUSIONS", "text": "A brief review was presented of recent and current NIST research on wind effects on structures, aimed to improve and modernize current standard provisions and design practices, and achieve a more resilient built environment in regions subjected to significant wind loads. The review covered research on: the development of the contiguous US wind maps included in the ASCE 7-16 Standard to replace earlier maps according to which the extreme wind climate is the same throughout most of the US territory: the development of wind load factors for use in the wind tunnel procedure, and the need to change the ISO 80% percentage point for the design peak pressure coefficients by a 57% percentage point; the estimation on non-Gaussian peaks using the peaks-over-threshold two-dimensional Poisson process; the codification of pressures on components and cladding; the development of Computational Wind Engineering algorithms aimed to achieve numerical tools for use in structural engineering practice within the next decade; progress in tornado hazard mapping and tornado resistant design; and joint wind, storm surge, and wave hazards and their combined effects on structures.\nThe recent and current wind engineering work summarized herein is part of an effort anticipated to be of the order of ten years, aimed at improving the resilience of the built environment in the United States through retrofitting and design practices and to achieve more economical as well as safer structures subjected to windstorms, including loads due to tornadoes, storm surge and waves. Tools being developed for this purpose include Computational Fluid Dynamics methods and Database-assisted Design. In addition to the research described here to better understand US tornado climatology, being conducted to support development of new tornado hazard maps and performance-based design methods and standards for tornado hazards, NIST is also working to improve future tornado data collection and climatology. In collaboration with NOAA, NIST is leading development of a new ASCE standard on tornado wind speed estimation. The standard will incorporate major improvements to the EF scale and address other damage-based methods for estimating wind speeds, including forensic engineering and treefall pattern analysis as well as methods using measurements during the tornado, including in situ (anemometry) and remotely sensed (radar) data."}]