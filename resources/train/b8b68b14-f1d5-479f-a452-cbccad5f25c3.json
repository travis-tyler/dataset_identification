[{"section_title": "List of", "text": ".3 B&B sample composition   Table 3.3 Final completion status for locating problem cases Table 3.4 Final completion status by \"maximum call\" status Table 3.5 Total number of interviewing minutes monitored and error rates  Table 4.2 Case disposition by demographic characteristics of sample Table 5. 1 Interview administration time by section Table 5.2 Item non-response Table 5.3 Consistency between original interview data and reinterview data: education items Table 5.4 Discrepancies between original interview data and reinterview data: employment items 33        Tables (Continued)   Table 7.6  Design effects for all respondents   49   Table 7.7  Design effects for female respondents   50   Table 7.8 Design effects for male respondents 51 Table 7.9 Design effects for Black respondents 52 Table 7.10 Design effects for Asian respondents 53 Table 7.11 Design effects for Hispanic respondents 54 Table 7.12 Design effects for White respondents Table 7.13 Design effects for respondents at 4-year public institution  The authors would like to thank Norman Bradburn and the members of the technical advisory board for their guidance in the development of the survey design and their assistance in developing the study instruments. Finally, we extend thanks to the willing participants in the B&B study who devoted their time and were forthcoming with the information that is the basis of this report. 9 vii Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report 1. An Overview of the Baccalaureate and Beyond Study 1.1"}, {"section_title": "Purpose of the Study", "text": "The Baccalaureate and Beyond Longitudinal Study (B&B:93) tracks the experiences of a cohort of recent college graduates, those who received the baccalaureate degree during the 1992-93 academic year and were first interviewed as part of the National Postsecondary Student Aid Study (NPSAS). This group's experiences in the areas of academic enrollments, degree completions, employment, public service, and other adult decisions will be followed for about 12 years. Ultimately, B&B:93 will provide data to assess the outcomes of postsecondary education, graduate and professional program access, and rates of return on investment in education. The U.S. Department of Education's National Center for Education Statistics (NCES) is authorized to conduct the B&B:93 study under Section 404(a) of the National Education Statistics Act of 1994, Title IV of the Improving America's Schools Act of 1994, P.L. 103-382, which states: \"The duties of the Center are to collect, analyze, and disseminate statistics and other information related to education in the United States and in other nations, including (1) collecting, acquiring, compiling ..., and disseminating full and complete statistics on the condition and progress of education at the pre-school, elementary, secondary, and postsecondary levels in the United States, including data on ... student achievement at all levels of education; ... educational access to and opportunity for postsecondary education, including data on financial aid to postsecondary students; teaching, including data on course-taking, instruction, the conditions of the education workplace, and the supply of and demand for, teachers, which may include data on the proportions of women and men, cross-tabulated by race or ethnicity, teaching in subjects in which such individuals have been historically underrepresented; the learning and teaching environment, including data on libraries; the financing and management of education, including data on revenues and expenditures; and ... (3) conducting longitudinal studies as well as regular and special surveys and data collections, necessary to report on the condition and progress of education; . . .\" 1.2"}, {"section_title": "Analytic Objectives", "text": "As the 1992-93 cohort of college and university graduates advances through adulthood, the effects of postsecondary education will become increasingly important. The B&B:93 study will provide data to address issues in several major areas of educational policy: educational attainment; access to graduate and professional schools; the rate of return on educational investment; and patterns of preparation and engagement in teaching. Attainment and outcome assessment. Degree completion, licensing, and certification are central to educational attainment and outcome assessment. Questions in this area include the following: Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report Are bachelor's degree recipients able to enter the work force or graduate school soon after acquiring the degree or within the time periods they expect? Do bachelor's degree recipients enter jobs related to their major fields of undergraduate study? How long do bachelor's degree recipients take to complete the bachelor's degree? Does this vary by field of study, type of school, age of student, or time of first entry into a postsecondary program? How long does it take to obtain a job in an area related to the field of study? Does the required time differ by degree attained? Does it differ by field? Graduate and professional program access. Entrance into graduate or professional school after completing the bachelor's degree raises many of the same questions as initial entry into the work force. In many fields, it is necessary to complete a graduate program to get a job in the field. In other fields, such as teaching, additional study may be required to continue working or to be promoted in the field, even though graduate education is not required for initial entry into the field. In most fields, graduate education enhances the ability to perform, even if it is not strictly required for entrance, continuation, or promotion. Therefore, it is important to determine whether persons who wish to continue their education beyond the baccalaureate degree have the opportunity to do so. Questions in this area include the following: Are people who want to enter graduate school immediately after completing the bachelor's degree able to do so? Why do some graduates delay entry into graduate or professional study? Do these persons persist in seeking to enter and do they succeed in entering later? Are those who want to enter graduate school after gaining some work experience able to do so when they planned, or are they further delayed? Do they carry out their original plan or later decide against graduate school? How long do they delay entry? What proportion of students who have no plans for graduate school at the time they complete the bachelor's degree later change their minds and attempt to enter graduate school? Do these persons have the access they would have had if they had attempted to enter graduate school immediately after completing the bachelor's degree? Are there additional difficulties associated with later decisions to enter graduate school? Rate of return. Rate of return refers to the financial payoff or other value of the bachelor's degree relative to the expense in time and money of obtaining the degree. There are two perspectives for gauging the rate of return. From the perspective of the individual, the rate of return can be measured in terms of monetary reward and personal satisfaction. From the perspective of society, rate of return can be measured in terms of the contribution a student makes to the nation's productivity as well as through community involvement and public service. For example, societal returns to investments in postsecondary education include the work performed by bachelor's degree recipients in public service areas such as teaching, volunteer work, and other community service.  For both the individual and society, rate of return can also be gauged by the adequacy of the individual's preparation for entry into work and community service and by the individual's acquired ability to gain from and contribute to that experience. B&B:93 examines the rates of return from postsecondary education from the perspectives of both the individual and society. Specific questions include the following: What proportion of bachelor's degree recipients enter jobs related to their fields of study immediately after receiving the bachelor's degree? Are these persons able to work effectively and advance in their work without additional schooling or do they encounter obstacles which can only be overcome by seeking additional education? Do persons who complete graduate school have a better chance to obtain positions in their field than persons who do not complete graduate school? Is there a difference in starting salaries between those who have completed graduate school and those who have not? Is there a long term difference in salary? How many bachelor's degree recipients are eligible or qualified to enter public service professions such as teaching? How many enter full-time positions in public service fields for which they are qualified? Is the proportion of persons who enter public service fields higher or lower among persons seeking jobs immediately after completing the B.A. than among those who first attend graduate school? Do bachelor's degree recipients who enter public service positions advance in their jobs at the same rate as bachelor's degree recipients who enter non-public service jobs? Patterns of teaching. Another important feature of the B&B:93 program is that the sample has been designed to facilitate the study of elementary and secondary school teaching careers. Data from B&B:93 will be used in the monitoring of supply and demand characteristics of the labor market, and career patterns of teachers, including movements into and away from this profession over time. Many of the same issues discussed earlier, concerning initial aspirations and expectations versus ultimate decisions, will be examined. Additional considerations include measuring quality, noting comparative values, and measuring monetary returns to teaching. Specific questions that the B&B:93 program will help address include: What is the proportion of new college graduates who enter the teaching profession as their first career versus those who are attracted to it later in life? What are the defining characteristics of these groups? What is the rate at which teachers change careers, and how does it compare to careerchanging patterns of other professionals? How satisfied are teachers in their careers versus those who are employed in other occupations? What are the potential sources for new teachers, that is, where do those who enter teaching come from (and, of those who left it, where did they go)? How do teachers compare with non-teachers along the lines of gender, race-ethnicity, and socioeconomic backgrounds? First Follow-up Methodology Report In summary, B&B:93 will contribute to a comprehensive statistical investigation of educational policy issues and help to fulfill NCES's mission, to report on the condition and progress of American education in all its aspects. In recognition of its broad mandate, NCES has expanded its data collection program to investigate educational experiences beyond the traditional span of postsecondary education. Baccalaureate and Beyond, with its wealth of data on the consequences of postsecondary education, will contribute to the study of education as a lifelong process."}, {"section_title": "2.", "text": "B&B:93 Sample Design  The B&B:93 sample design represents all postsecondary students in the United States who completed a bachelor's degree in the academic year 1992-93 (AY 93). The B&B:93/94 sample was a subsample of the students selected for the 1993 National Postsecondary Student Aid Study sample, a nationally representative sample of all postsecondary students. The B&B:93/94 sample of baccalaureate degree graduates includes those students in the NPSAS:93 sample who were identified by the institution or during the student interview as potentially eligible for B&B:93/94. Cases were identified as potentially eligible for B&B:93/94 if there was information indicating that the respondent had received, or expected Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report (1) Attend a sampled institution between July 1, 1992 andJune 30, 1993; and (2) Be enrolled in one or more of the following: Course(s) for credit toward a degree or formal award; or Degree or formal award program of at least three months duration; or Occupational or vocational program of at least three months duration. Students who took courses only for remedial or avocational purposes and did not receive credit, who only audited courses, or who took courses strictly for pleasure rather than as a part of an academic, occupational, or vocational program or course of study were not eligible for NPSAS. Furthermore, students enrolled in high school or solely in a GED program were ineligible for NPSAS:93, even if they satisfied the above conditions. A total of 82,016 students were selected for the NPSAS:93 sample, with a final eligible sample size of 79,269. In addition, NPSAS:93 included all students who received a baccalaureate degree between July 1, 1992 andJune 30, 1993. (Students who had completed degree requirements prior to July 1, 1992 but were awarded a degree after that date were also eligible.) Table 2.1 provides the NPSAS:93 student sample sizes by type and institutional sampling stratum. The baseline cohort for the B&B study is represented by the \"Baccalaureate\" column of the table.\nElse if institution stratum = 18 (private, not-for-profit, 2-year) or = 19 (private, for-profit, 2-year) or = 21 (private, not-for-profit, less-than-2-year) or = 22 (private, for-profit, less-than-2-year) Set B&BSTRAT = 16 (private, 4-year, bachelors, low ed) [IS 18 (1) After collapsing institution stratum and sample type, the distribution of B&BSTRAT and B&BTYPE for the 11,192 eligible B&B sample members is as follows: Step 3. Impute baseline NPSAS:93 weights for 23 eligible B&B sample members and calculate updated baccalaureate degree control totals. The B&B:93/94 sample included 26 cases for which the NPSAS:93 baseline weight was equal to zero. In B&B:93/94, 23 of these cases were completed and 3 were determined to be ineligible. The NPSAS:93 baseline weight for the 23 eligible cases was imputed using the average of all non-zero baseline weights within the same institution at which the baccalaureate degree was attained. One of the cases with a missing weight happened to be the only representative in their institution. The baseline NPSAS:93 weight was imputed for this case by using the average across all non-zero weights within the same institution stratum and student type cell. The baseline weights for all B&B eligible students were further adjusted for final degree totals. Control totals for baccalaureate degrees awarded were calculated based on the IPEDS completions file for academic year 1992-1993. The NPSAS institution sample frame was matched to the IPEDS file and the total number of baccalaureate degrees awarded was calculated by institution stratum. Table 7.4 summarizes the control totals for each B&B stratum. An adjusted weight Bo was calculated for each case by multiplying the base weight by the ratio of the sum of degrees awarded to the sum of the base weights for the appropriate institution stratum. The adjusted total number of baccalaureate degrees for academic year 1992-1993 is 1,184,758 degrees. This weight will serve as the B&B base weight used in all future weight adjustments.\nEach cell was checked to see that it met two conditions: the cell contained at least 15 students the weighted response rate for the cell was at least two-thirds (67%) of the overall weighted response rate. 3. Any cells that did not meet both conditions were combined into larger cells. This was done by combining student types 3 and 4 within the same institutional stratum. If this larger cell did not meet the criteria specified above, all student types from that institutional stratum were combined."}, {"section_title": "B&B Student Sample", "text": "In order to provide a base year sample for B&B:93/94, NCES introduced several design modifications in NPSAS:93. First, the number of sample institutions offering only four-year undergraduate programs or programs of less than four years was reduced relative to the number of sample institutions offering post-graduate programs. Second, the number of sample students in four-year institutions was increased by 20 percent. Finally, the sample sizes of graduate students and professional students were slightly reduced. These three changes in the NPSAS sample design reflect the goal of following a large sample of bachelor's degree recipients through post-bachelor's degree experiences. Based on these changes in the NPSAS:93 sample design, approximately 16,300 potential baccalaureate degree recipients were identified. These students were identified using institutionally provided lists of students who filed for graduation in the 1992-93 academic year.  22. Private, for-profit, less-than-2-yr ' More than 15 percent of baccalaureate degrees awarded in education. 2 Any baccalaureate degrees awarded in education. 'More than 25 percent of baccalaureate degrees awarded in education. 40ne institution sampled as a 2-year institution (based on the IPEDS IC file) was determined to be a 4-year institution. It is classified as such in all NPSAS:93 analysis tables. 5 One institution sampled as a less-than-2-year institution (based on the IPEDS IC file) was determined to be a 4-year institution. It is classified as such in all NPSAS:93 analysis tables. SOURCE: NCES, Baccalaureate and Beyond:93/94 a Methodology Report for the National Postsecondary Student Aid Study, 1992-93 (Loft, Riccobono, Whitmore, Fitzgerald, Berkner, Malizio, NCES 95-211 Student Aid Study, 1993. During the data collection period it became clear that many of the NPSAS nonrespondents and the cases identified late as potential B&B respondents (sample types 2, 3, and 4 in Table 2.3) were not, in fact, eligible for B&B. Because of the costs involved in contacting ineligible respondents, it was desirable to select only a subsample of these cases to be included in the final B&B sample. The subsample was selected from the group of nonrespondents in the sample who did not complete a full B&B interview in NPSAS:93 (sample types 2,3, and 4 in Table 2.3). All students who were respondents in NPSAS (sample type 1) were included in the final B&B sample. The subsample selection was carried out by constructing a file of all B&B eligible nonrespondents in sample types 2, 3, and 4 as of November 1, 1994. Complete cases, cases with pending interviewer appointments, sample members determined ineligible, and cases finalized as non-interviews (primarily hostile refusal cases) were excluded from the subsampling file. This file was then sorted by institution stratum, student stratum, and student sample type in order to affect stratification in the selection process. A systematic sample of 200 persons, from approximately 450 in the file, were selected. The subsampling process decreased the B&B sample size to 12,478, as shown in Table 2.3 above."}, {"section_title": "B&B:93 Sample Eligibility", "text": "During data collection, for both the interview and transcript components, it was discovered that many of the respondents who had been designated by NPSAS as B&B sample members were not eligible to be included in the sample. Sample eligibility was determined in two ways: first, by confirming with respondents the date they received their baccalaureate degrees, and second, by examining the transcripts received from baccalaureate institutions. The final B&B:93 sample includes respondents identified as eligible in either portion of the study, as described in subsequent sections of this report. The sample which will be followed for future rounds and cross-component eligibility is discussed in the chapter describing the transcript component (see Table 6.3). Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report 3."}, {"section_title": "Data Collection: Telephone and Field Procedures", "text": "Overview. An initial mailing containing a letter and informational leaflet was sent to all 12,731 B&B:93/94 sample members in the summer of 1994 --Wave 1 cases in June, and Wave 2 cases in July -inviting them to participate in the study.' The letter, included in Appendix A, provided a summary of the survey objectives, an introduction to NCES and NORC, and a promise of strict adherence to the privacy protection laws. The letter also provided a toll-free 800 number for sample members to obtain further information or to schedule an interview. Telephone interviewing began approximately one week after the advance letter mailing. Interviewing commenced on June 15, 1994 for Wave 1, and August 5, 1994 for Wave 2. Telephone interviewing continued until October 8, 1994, a period of 16 weeks. Cases that were pending at the end of this time were sent to field interviewers and worked from October 8 through December 31, 1994, a field period of 12 weeks.2 Figure 3.1 summarizes the flow of cases through the major activities in the B&B:93/94 survey. As shown, case records for the sample were loaded into the CATI Telephone Number Management System (TNMS) and delivered to interviewers. Cases were delivered primarily during peak contacting periods which included Monday through Thursday evenings, Saturday morning and afternoon, and afternoon and evening hours on Sunday. A total of 7,456 cases (68 percent of 10,958 eligible cases) were completed in-house. An analysis of the case delivery management is presented in section 3.1; CATI production is described in section 3.2. Respondents refusing to participate in the B&B:93/94 study presented a significant problem during data collection. A full 20 percent of the eligible sample refused to participate at some time during the interviewing effort. CATI refusal conversion specialists contacted these respondents in an effort to persuade them to participate. Respondents who continued to refuse participation were contacted by field interviewers for in-person follow-up. Section 3.3 presents an analysis of the problem and describes the refusal conversion process. Due to the different types of sample members in the B&B:93 student sample (see section 2.3), treatment of these cases occurred in two waves. Wave 1 cases, corresponding to student sample types 1 and 2, totaled 11,626 sample members; sample types 3 and 4 constituted the 1,105 sample members in Wave 2. "}, {"section_title": "Paths toward case completion", "text": "Load Sample into CATI (12478) Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report on Monday through Friday, 8:00 a.m. -6:00 p.m. on Saturday, and 11:00 a.m. -11:00 p.m. on Sunday. Cases were delivered to interviewers by the TNMS eight times over a two-week period, or four times each week, before being filed to a queue for supervisor review. The calling algorithm for the week had a built-in preference for Saturday and Sunday; cases were delivered twice during the weekday evenings, once on Saturday, and once on Sunday. This pattern was repeated the second week and, if no contact had been made with the respondent, the case was reviewed by a supervisor and either sent to locating or sent back to the floor to be called during an off-cycle period. The calling delivery cycle was stopped as soon as an appointment was set to call the respondent. From that point forward, appointments were determined when the respondent was called. Figure 3.2 presents data on case completion by day of the week. Although the number of completed cases does not vary significantly in the remainder of the week, the graph does show that Sundays were not particularly effective days to call respondents. In fact, during the summer months, respondents were more likely to complete an interview on weekday evenings than on a weekend day. Project staff expected that many respondents would try to delay the interview because of their busy lifestyle. B&B:93/94 interviewers attempted to complete the interview when the respondent was contacted and attempted not to let the respondent delay the interview. However, appointments were very common and B&B interviewers tried to accommodate all requests for appointments made by respondents. To ensure that interviewers were available to keep scheduled appointments and not involved in other calls, cases that had requested appointments were delivered to telephone interviewers 20 minutes early.  "}, {"section_title": "CATI Production", "text": "Data collection began on June 15, 1994. Week-by-week production and cumulative completes are diagrammed in figure 3.3.3 The graph shows that the first two weeks of data collection were the most successful, with the first week (actually, ten days) of production being the highest. Production for the majority of the following weeks averaged about 600 cases per week. Finally, in the last third of the data collection period, production decreased to about 200 cases per week, as the last and hardest cases were handled and more cases were sent to the field. 16"}, {"section_title": "Cumulative", "text": "The number of calls per completed case is the best estimate of the level of effort required in the interviewing task. The TNMS tracks every call, writing to a log file the outcome of the call and the date and time of the attempt. Estimates of the level of effort necessary to complete a telephone interview can be estimated from the data in the log file. The number of calls required to complete cases for the B&B:93/94 sample is presented in Table 3.1. These data are consistent with level of effort estimates for the B&B:93/94 sample and actual experience with similar samples. Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report "}, {"section_title": "Refusal Conversion", "text": "A total of 2,175 respondents (19.8 percent of the total eligible sample) refused to complete the interview at some point in the interviewing process, a refusal rate about twice as high as originally expected. Early in the data collection period, a supervisor reviewed the call notes for each refusal in order to better understand the reasons respondents chose not to participate, and to tailor the approach to converting refusals. The supervisor found that the cases fell into several major categories, and generally followed the same distribution as for the field test. The review showed that previous experience with the NPSAS:93 survey was still a significant factor in whether or not a sample member chose to participate. Indeed, many sample members who refused either confused the B&B:93/94 study with NPSAS:93, or refused to participate based on their prior experience. Other major refusal reasons were typical of most surveys: no time or too busy; not interested in participating, interview length too long; or confidentiality issues. A three-stage process to convert sample members who refused to participate was planned and executed. All cases were sent a letter addressing the specific reason the respondent refused. Samples of these letters are included in Appendix B. The letters were followed up by a phone call from a refusal converter at the central CATI site. Only one attempt was made by the phone center to convert refusals; continuing refusals were forwarded to the field to be contacted in person by a field interviewer. Refusal conversion calls began about four weeks after the start of data collection. Several B&B:93/94 trained interviewers were selected to convert refusal cases. The interviewers were chosen for their calm and assertive style of interacting with respondents. The interviewers attended a briefing that included a review of the types of refusals and a general practice of gaining cooperation. The CATI refusal converters were able to convert and complete 25 percent of the refusal cases; another 49 percent were converted by field interviewers. In all, NORC interviewers were able to successfully complete interviews with 1,611 (74.1 percent) of the 2,175 initial refusals.  "}, {"section_title": "Respondent Locating", "text": "Cases were loaded into the TNMS with the \"best\" telephone number for reaching the respondent based on the prefield locating information. Interviewers were trained to follow all leads provided by this telephone number and to update the number when new information was discovered. However, if the interviewers were unable to locate a respondent, the case was moved to the Case Management System (CMS) for further locating attempts. Prior to the start of data collection, B&B:93/94 staff identified the most effective locating resources for finding B&B:93/94 respondents. Those resources are listed below in the order in which they were used: Last known telephone number of the parent(s) Last known telephone number of a contact person Other NPSAS obtained locating leads (when available) Credit database (TRW and Equifax) Bachelor degree school alumni office The B&B:93/94 main study employed a locating strategy which was used successfully in the field test. Central office telephone locators were teamed with locators in the field to expeditiously work cases which were not previously located. Matching the expertise of the central office locators with the regional knowledge of the field locators was expected to result in a more thoughtful, thorough, and cost efficient way to find respondents. A locating supervisor coordinated the locating effort between the telephone and field locators for each team. Each week the supervisor reviewed the cases assigned to each of the teams, making suggestions for additional work or concurring with the nomination of the case for field work. Some cases remained unlocatable at the close of telephone operations; these were turned over to and worked by the field interviewers. Using this strategy, central office locators were able to find and complete 47 percent of the 3717 locating problem cases. The field locators were slightly less successful, completing 41 percent of the unlocatable cases. (The bulk of locating problem cases were the more difficult to work and probably held hidden refusals, as evidenced by the higher final refusal status in the field.) Table 3.3 shows a breakdown of the locating problem cases and the level of effort expended in the CMS. Of the 3,717 cases with locating problems, 3,264 (87.8%) were successfully traced and interviewed.   "}, {"section_title": "Maximum Calls", "text": "Another problem identified and tracked during data collection was the number of times a sample member was contacted by the telephone center. The limit of \"maximum calls\" was set at 14 contact attempts. A \"call\" was counted each time there was some contact with the respondent's household; this could be a contact with the respondent, a contact with someone else in the house, or an answering machine. Using these parameters, a total of 2,687 cases fell into the maximum calls problem category. It was initially thought that these cases were actually hidden refusals and that the sample members were implicitly refusing to participate by avoiding any contact attempts. However, as table 3.4 shows, the completion rate for this group was almost as high as that for the entire sample. It is apparent that this type of problem case was better handled by the field interviewers; 57 percent of the maximum call cases Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report were interviewed by the field staff versus 33 percent completed by the telephone center. It would seem that a personal contact may have been necessary to gain cooperation from reluctant sample members. "}, {"section_title": "Field Operations", "text": "In early October, the telephone center ceased work on B&B:93/94 and all pending cases were transferred to NORC's field staff. All were cases the telephone center had been unable to complete because the respondent refused, was evasive, or had not yet been located. (Field staff actually began working a small number of cases in late August, as the telephone center began filtering hard refusal cases to the field.) Field manager and interviewer recruiting. Seven field managers (FMs) were hired to supervise field interviewers (FIs). These FMs were the same FMs hired and trained to work on the field test. The field was set-up to use a team management approach. There were three teams each with two FMs; each manager was responsible for a specific geographic region of the United States. Field interviewers were recruited and hired as needed contingent upon the location of cases. A total of 150 FIs were hired for B&B:93/94. Field manager training. The seven field managers received five hours of self-study and twohour telephone training calls. The main focus of training for the FMs was how to use the CMS. (FMs used the CMS for reviewing cases nominated for field work as well as for entry of cost and production information). A Field Manager's manual was developed which described the role and expectations of the FMs as well as administrative specifications. The self-study time was largely devoted to review of all field interviewer materials, the FM manual and hands-on practice with the CMS. The telephone training calls were geared towards teaching the FMs the skills needed to adequately use the CMS, reviewing administrative procedures and answering questions. Field interviewer training. The training program for field interviewers included three hours of self-study and a brief telephone review with their field manager. A self-study manual was developed which described the study, task-specific procedures, and the role and expectations of the field staff. A self-study exercise, designed for interviewers to assess their own knowledge of the information, was also enclosed with their manual. Once interviewers had carefully read through their manual and completed the self-study exercise, a telephone review was scheduled with their FM. The field managers reviewed procedures, answered questions, and assessed the interviewer's understanding of the procedures. Field production. A total of 3,698 cases (29.6 percent of the total sample) were sent to the field. The cases sent to the field were the most difficult: 40 percent were refusals, and 60 percent were cases that had been contacted 14 times without completion or were cases that had not been located. When the telephone center nominated a case for completion by the field, the case was reviewed by a team of telephone and field supervisors who discussed whether further efforts in the telephone center would be fruitful. If the case was sent to the field, a telephone center supervisor assigned the case to one of the three field teams based on the geographic location of the case, or if unknown the original address NORC had for the respondent at the start of data collection. Case materials were sent to the field manager, including a face sheet with locating and demographic information, a call history report with notes made by telephone shop interviewers and locators describing each contact made with the respondent/contact/locating resource, and a resource listing with all of the locating resources used and/or available for the case. The cases were then reviewed by the FMs before being assigned to a field interviewer. Hardcopy materials were used in two ways: by the FM for making case assignment decisions, and as a reference for the field interviewer assigned to work the case. Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report Figure 3.4 shows the weekly and cumulative production rates for the field data collection.4 The field staff completed 3,050 (82.4 percent) of the total case workload, bringing the final B&B:93/94 response rate to 92 percent. As compared to CATI production rates, the field exhibited a slow initial completion rate (because of the small number of cases being worked), and then a steady weekly production of about 200 cases. 8/20 8/27 9/3 9/10 9/17 9/24 10/1 10/8 10/15 10/22 10/29 11/5 11/12 11/19 11/26 12/3 12/10 12/17 12/24 12/31 Weekly SOURCE: NCES, Baccalaureate and Beyond:93/94 3.7"}, {"section_title": "Quality Assurance", "text": "Cumulative Extensive quality control procedures were instituted for the following data collection activities: interviewing, locating, and refusal conversion. These procedures are detailed below."}, {"section_title": "Measures of Productivity", "text": "Daily automated production reports, which contained statistics on the number of cases completed and/or located and the inputs required to attain completion (e.g., effort, labor, and time) were used to measure and monitor CATI productivity. These data allowed the B&B staff to pinpoint productivity problems with both the interviewing and locating efforts, and to correct for any problems demanding attention."}, {"section_title": "Interviewer Monitoring", "text": "In addition to monitoring system performance, the data collection staff are subject to quality monitoring. This check-and-balance process enables the supervisory staff to evaluate the extent to which data quality remains within statistical control, and to identify potential difficulties arising from interviewer  and locator training and performance, the individual survey questions, or other aspects of the data collection process. The statistical quality control (SQC) monitoring procedure used in B&B extends traditional monitoring criteria, which focus specifically on interviewer performance, to an evaluation of the data collection process in entirety. The improved SQC monitoring system randomly selects active work stations and segments of time to be monitored, determines what behaviors will be monitored and precisely how they will be coded, and allows for real-time performance audits, thereby improving the timeliness and applicability of corrective feedback and enhancing data quality. All in-use work stations were randomly selected at 15 minute intervals for monitoring by a supervisor according to pre-scheduled monitoring sessions. Using an on-line data capture program equipped with audio and visual capabilities, supervisors responded directly to ongoing interviews by entering evaluation data directly onto data capture screens. For assessment of locating skills, the monitor assigned performance ratings to various skills on a 0-5 scale where \"0\" indicates the skill was not observed, and ratings of 1-5 correspond to increasingly higher level of skill mastery and acceptability. The data capture screen also allowed supervisors to log question numbers associated with errors and general comments pertaining to these errors. Another data capture screen collected very general information and commentary on non-interviewing activities such as refusal conversion. Lastly, a summary screen allowed monitors to record observations of skill (or lack of skill) for the entire evaluation session using the 0-5 rating scale. Consistent with the daily production reports generated for system monitoring, statistics were reported daily for interviewers' sessions. Daily statistics are presented in table 3.5. Control charts were utilized to track the average number of errors associated with each minute of observed interviewing. Error rates for project staff stayed within the predetermined limits set for the phone center. In addition, Pareto analysis was utilized to identify the most frequently observed errors encountered in a monitoring session. Taken together, these quality control measures ensured the integrity of the data garnered during data collection. Quality control procedures were also established for field interviewing. The first two intervieweradministered completed questionnaires were directed to a FM for editing. These cases were edited, logged, and appropriate feedback given to the interviewer. Additionally, ten percent of these caseswhether administered over the phone or in person were validated by FMs. When deemed necessary, the FM continued to edit additional cases to monitor data quality. The need for additional monitoring was based on the FM's subjective judgement of the FI's level of skill. As with the edited cases, validated cases were logged and reported weekly. Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report  Table 4.1 presents information on the final disposition for all cases that were initially included in the sample. In all, 12,478 of the cases that were identified as potential B&B sample cases during the NPSAS data collection were included in the B&B data collections. Of these cases, 1520 were found to be ineligible or out of scope, primarily because their graduation date fell outside the July 1 -June 30 window. A total of 10,958 cases were considered to be eligible during the interviewing period of B&B:93/94, and interviews were completed with 10,080 (92%) of these respondents. The majority of interviews were conducted by telephone interviewers located at a central facility, using a computer-assisted telephone interviewing system. Approximately 68 percent of eligible cases were completed in the telephone center; another 2 percent were designated as final non-respondents. The remaining 3698 cases (30 percent) were sent to field interviewers who were geographically dispersed across the country. The majority of these cases had been contacted by telephone interviewers, but had not been completed because the respondent had refused. Others were referred because the telephone center had been unable to locate the respondent, or to speak personally to the respondent to complete the interview. Field interviewers completed an additional 2624 interviews, about 70 percent of those that were sent to the field, bringing the cumulative total of completed cases to 10,080. An examination of the final dispositions shows that 92 percent of eligible respondents participated in the study, approximately 6 percent refused to take part, and another 1 percent did not participate for other reasons. Just under 1 percent of respondents could not be located. Table 4.2 presents more detailed information on respondents and non-respondents by age, sex, and ethnic background. Table 4.2 contains information concerning the percentage each subgroup that completed the interview. Response rates were similar across almost all of these demographic subgroups. Ninety-nine percent of young respondents (those 22 and under) participated, while approximately 91 percent of those over 22 participated. Males and females participated at approximately equal rates. Response rates were approximately equal among whites, blacks, and American Indians 93 percent of eligible respondents in each group participated. Among Asians and Pacific Islanders, the completion rate was slightly lower, just under 90 percent. The comparatively high rate of non-response that appears in Table 4.2 for those sample members in which age, sex, or race is missing results from the fact that many of these cases were non-respondents in NPSAS, as well as B&B:93/94. Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report  "}, {"section_title": "Length of Interview", "text": "The use of Computer-Assisted Telephone Interviewing yields many advantages, one of which is accurate evaluation of the length of time elapsed during the completion of each section of the interview. The CATI instrument used in this study included several \"time stamps\" which enable us to look carefully at the amount of time taken by the \"average\" respondent to complete each section. These data are presented in Table 5.1. The instruments used for data collection in the NPSAS:93 and B&B:93/94 studies are presented in Appendices C and D, respectively. The average length of a completed interview was 32 minutes. Of this, approximately 2 minutes was spent updating information about the undergraduate career that was missing in the NPSAS file. Within the B&B interview, approximately 6 minutes was spent collecting information about postbaccalaureate education. Another 8 minutes was spent collecting information about the respondent's work since graduating from college, and approximately 3 minutes was spent gathering information about training experiences since college graduation. The demographics, civic participation, and educational loan sections of the interview comprised approximately 12 minutes. A subsample of respondents were asked about their experiences teaching in elementary and secondary schools since receiving their baccalaureate degrees. Among those asked these questions, another 6.45 minutes was spent collecting these data. However, when averaged across all respondents, less than one minute was spent in collecting this information. One of the goals of B&B was to reduce item non-response by using a variety of innovative techniques to build respondent rapport, including the use of conversational interviewing. Neverthe less, some items, particularly those requiring the recollection of specific numeric figures (i.e., test scores and dates; income figures) were answered by less than 90 percent of respondents who were asked. These items are displayed in table 5.2.6 Of the over 1,000 variables included in the final data set, 68 variables contain over 10 percent missing data, due to respondents declining to answer the question, or responding that they could not give an accurate answer. The first section of Table 5.2 contains items concerning graduate entrance examinations and professional licensing exams. The largest categories of non-response in this table are the \"don't know\" responses to items concerning test scores and dates. It should be noted that \"don't know\" can sometimes be a legitimate response to the test score item, since some respondents had taken a test but had not yet received word of their scores. In other instances, \"don't know\" signifies that the respondent had difficulty recalling the information requested and could not provide a number. High levels of don't know responses are also evident in the items regarding college grades. Respondents also had difficulty recalling detailed information concerning undergraduate loans and loan payments when the respondent had more than three loans. Respondents were asked about each type of loan individually, and information on up to seven loans was collected. Item non-response appears to be a problem for information collected -on-loaniEr four through seven. Note-that relatively few respondents were asked about this number of loans. As in other surveys, items that required respondents to reveal exact dollar amounts for income were not answered by some respondents. One item with high non-response, HSEHDIN, was only asked of respondents who said they were \"head of the household\" and were living with another adult, other than a spouse. The next three items that appear in the table, TOTINCS , ANNINCS, and TOTINCM were asked as a closed-ended categorical question when the respondent did not provide an answer to the original question. When these income questions are combined into a single categorical variable, nonresponse is under 15 percent. Few of the remaining items have significant non-response. It is especially notable that the two primary sections of the survey, concerning post-baccalaureate education and employment, had very little missing data. Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report Table 5.2.--Item non-response for items with more than 10% \"Don't know\" or \"Refused.\"  "}, {"section_title": "Reinterviews", "text": "A group of 100 respondents was recontacted several weeks after being interviewed. These respondents were asked a subset of items included in the initial interview to help assess the quality of those items. Since resources were limited, we focused on items from the education and employment sections that had been problematic in the field test, and were modified between the field test and the main survey. Table 5.3 provides information on the discrepancies between responses to education items in the two interviews. Results indicate that the questions elicited similar information in both interviews. Ninetytwo percent of respondents gave consistent responses when asked whether they had taken any courses for credit since graduating from college. Of the eight percent in which responses were inconsistent, most were cases in which a short enrollment spell was mentioned in the initial interview that was not reported in the reinterview. As a followup to this question, respondents were asked to name the school they attended; all respondents except one provided consistent names across both interviews. Eighty-five percent of all cases had similar information concerning dates of attendance, and eighty-seven percent had consistent information concerning the usual time of attendance in the two interviews. Table 5.4 presents information on the consistency of responses to employment items. Ninety-six percent of respondents gave consistent information across surveys when asked whether they had worked since graduation.' Almost three-quarters of respondents gave the same number in both surveys when asked about the number of jobs they held since graduation; twenty-six percent gave inconsistent responses. Upon closer scrutiny, many of the discrepancies resulted from jobs held around the time of graduation that were reported in one survey, but not the other. Respondents were asked about the number of jobs held since graduating; interviewers were instructed to include jobs that began before graduation if the job ended after graduation. Confusion over whether to include such jobs accounts for many of the inconsistencies noted in the reinterview. Information about the beginning and ending dates of jobs and about unemployment status during the periods between jobs were used to construct month-by-month employment status variables for each respondent. In the table below, the average number of discrepancies across interviews in monthly employment status is presented for three periods: the period preceding graduation for most respondents, the summer following the modal graduation date, and the academic year following the modal graduation date. It appears that information was reliably captured for all months except for the summer months following graduation --approximately 28 percent of cases contained inconsistent data concerning employment status in the summer months. These inconsistencies are due to several causes. For example, in some cases the beginning and ending dates of jobs are off by a month; in other cases a job held at the time of graduation is included in one interview and not another. Among respondents who were not working, there is some inconsistency in whether they are classified as unemployed or out of the labor force during this time. Jobs held between the original interview and the reinterview were excluded from all analyses."}, {"section_title": "31", "text": "Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report   July, 1992-April, 1993 Average number of discrepancies in employment status, each month: May, 1993-August, 1993 Average number of discrepancies in employment status, each month: September, 1993-November, 1994  In addition to data gathered from sample members, B&B:93/94 included a transcript component which attempted to capture student-level course-taking and grades for eligible sample members. Transcripts were requested for all sample members from the NPSAS schools from which they received their bachelor's degrees. Data were captured at both the school and student levels; school-level data such as school type, schedule, and grading systems were gathered first and used to guide the entry of studentlevel courses, credit hours, and grades. 6.1"}, {"section_title": "Transcript Collection Procedures", "text": "Data collection for the transcript component began in August, 1994, when a packet was mailed to all 715 NPSAS:93 sample schools from which B&B sample members graduated. The contents of this packet included: a B&B informational leaflet; letters from NCES, NORC, and the American Association of Collegiate Registrars and Admission Officers; a list of professional organization endorsements; instructions for sending transcripts; a student checklist with the names and other relevant information for each student for whom a transcript was requested; a request for reimbursement form and postage paid return envelope in which to send student transcripts. In addition to student transcripts, schools were asked to provide a course catalog and information on their grading and credit-granting systems and school term. A transcript was requested for all 12,478 students in the B&B:93 sample, although not all transcripts were coded due to sample member ineligibility (see section 6.3 for more information on eligibility criteria). Prompting of nonresponding schools began in September, 1994, by the telephone center. An attempt was made to address any concerns of the school staff regarding confidentiality or the release of transcripts. At this time, NORC prompters also tried to take any steps necessary to assist the registrar or other school official in gathering the needed information. The majority of schools (595) had sent their transcripts by the end of December 1994. Table 6.1 shows the completion rate for the transcript component. In all, 626 of the 635 (99 percent) eligible schools complied with our request for student transcripts, resulting in a transcript collection rate of 98 percent at the student level."}, {"section_title": "Baccalaureate and Beyond Longitudinal Study 93/94", "text": "First Follow-up Methodology Report "}, {"section_title": "Transcript Processing Procedures", "text": "The design of the B&B:93/94 transcript processing system capitalized on the work done by previous NORC studies (i.e., HS&B, NELS2). The process flow and system however, were changed in four significant areas. First, since the sample of schools from which transcripts were collected was known, the system was designed around the school as the primary unit, rather than the student. Second, transcripts were entered after all school level information about schedule, grading, and credit-granting systems were collected and verified. The system enforced these parameters and ensured that the transcripts were internally consistent within the school. Third, the transcript coders worked with the full transcript when entering and coding courses. This allowed them to view each entry in context and make intelligent, informed decisions when difficult situations were encountered. Finally, the system was designed so that course-level information (in a unique school) was only entered once; subsequent duplicate course entries were selected by the coder from a dynamic school-level list of all courses entered from previous transcripts. School-level coding. Receipt control and data entry of course catalogs, grading system descriptions, and school term information from the schools began in September 1994. The institutional information was checked for accuracy and completeness, and those schools with incomplete school information, missing grading systems, or missing catalogs were contacted to retrieve missing items. The grading and credit-granting system used by each school was captured before transcript data were entered. The allowable grades, their quality points (the points per credit for the grade), and the grades counting toward credit were entered into the master grading system table. Each school unit in the database referenced a unique grading system, and only those grades allowed for the school were available to course coders. If new grades were found during course coding, entry was stopped until supervisors could ascertain the correct grading system for the school.  Each course was designated as being a quarter, semester, trimester, clock hour, examination, transfer, study abroad, or other term type. The term type designation, however, had no bearing on the normalized number of credits assigned to each course on the transcript. Instead, the actual minimum number of credits required for a baccalaureate degree was entered at the school level for each school in the sample. The number of credits received for each course was entered at the course level, and the normalized number of credits for each course calculated by multiplying by 120 over the total credits required for a degree. Student-level transcript coding. After the school-based information was entered, the transcripts were processed; transcript data entry and course coding were combined into one procedure. All transcripts from a school were processed by the same coder. Before specific course information was entered, general student-level information from the transcript was entered. These data, such as major and minor field of study, grade point average, high school graduation date, and baccalaureate degree data were entered for all students. Transcripts are typically organized by courses taken per term. Keeping the course-term link is important for reporting intensity of enrollment. Terms are also important in determining the uniqueness of a course. Courses are unique by school, course abbreviation, and term. This allows for separate coding of special study courses that vary from term to term (i.e., \"Special Studies: Babbage and the history of early Computers\"; next term, same department \"Special Studies: Advanced Fractal/Chaos Applications\"). In order to maintain this link, transcript data were entered term-by-term. The coder chose the term description (e.g.,Winter, '90) from the list set up for that school, and then proceeded to enter the courses within that term. Courses or blocks of courses which came from outside sources (e.g., transfer, foreign study, advanced placement credit) were entered by source, and the source noted in the term description field. Within each school, all course abbreviations (i.e., ENGL 101), titles, usual credits, and course codes were stored as new courses were discovered, entered, and coded. When the coder entered the course abbreviation, any title previously stored was displayed. If the title matched the transcript, the coder accepted the entry and verified the number of credits. Note that the number of credits granted for a course was edited since it varied from student to student. For example, Independent Study courses may vary greatly in the number of credits earned. Also, some courses may have optional labs or discussion groups. After verifying the credits, the grade was selected. Only grades from the school's grading system list were allowed. Any disallowed grades were investigated and resolved by the transcript supervisor, usually by researching the course catalog or school institution data or by calling the registrar. If the course didn't match a pre-existing entry, the coder searched the school-level table to see if other courses existed for the abbreviation. If a course did not exist in the table, the coder entered the full course title, the number of credits, and the grade. These procedures allowed for a robust, automated, school-level course database which greatly improved the quality, and increased speed and efficiency of transcript data entry. Although transcripts were requested from only the baccalaureate degree granting institutions, these transcripts often were sent to us with transcripts from previous transfer schools attached. A decision was made to code these transcripts. However, no attempt was made to collect additional information from these 1,938 schools. Because we lack the school-level information for these transcripts, this information is not the same quality as information coded from the baccalaureate transcripts.  During the course of transcript collection, it was found that some NPSAS sample schools from which a sample member was reported to have received a bachelor's degree, actually did not offer that degree. In most cases this was confirmed by data on the school in the Integrated Postsecondary Education Data System (WEDS) database. Students attached to these sample schools were considered out-of-scope for transcript processing. In other cases, the school did grant baccalaureate degrees but did not award a degree to the student. Again the student was considered out-of-scope. In most of these out-of-scope cases ineligibility was confirmed by the respondent questionnaire status. In all cases where the respondent was eligible in the B&B CATI (completed the questionnaire or non-response) and a transcript was received, the transcript was entered regardless of whether or not a bachelor's degree was awarded. The determination of transcript eligibility involved the interaction of both transcript status and questionnaire status. Table 6.2 shows the matrix of questionnaire dispositions and transcript dispositions.  As shown above, the combination of questionnaire and transcript status resulted in various final outcomes, which then informed the decision whether or not to process the transcript or count the sample member as eligible. The final eligibility criteria are best defined as: A sample member is eligible for B&B:93/94 if he or she received a baccalaureate degree from the sample school between July 1, 1992 andJune 30, 1993;OR If he or she completed a B&B interview and satisfied one of the following criteria: received a baccalaureate degree from another school during the reference period; earned at least 75 percent of the credits needed for a baccalaureate degree from the NPSAS school; the respondent interview data showed that he or she attended multiple schools. Table 6.3 provides information on the eligibility of cases in the interview and transcript components of the study. Any case that was found to be eligible in either component of the study will be retained for future rounds. (In the CATI study, eligibility was determined by respondents' selfreported graduation.) Excluded from future follow-up will be the 1178 cases that were found to be ineligible in both components of the study, as well as the 108 cases that were found to be ineligible in one component and were non-respondents in the other. Thus, 11,192 cases will be followed in subsequent Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report rounds of the study. It should be noted that regardless of eligibility prior, only those respondents who reported having completed their baccalaureate degree in the course of the interview were retained as interview completers. "}, {"section_title": "6.4", "text": ""}, {"section_title": "Quality Control", "text": "The transcripts data entry system was designed to minimize the majority of coding and entry errors which occur with tasks of this type. Based on the most up-to-date experiences with the NELS Third Follow-up transcript component, a data entry program was designed to automate as many of the data entry steps as possible. As described in section 6.2, much of this automation occurred on the course level, where the bulk of data entry errors usually take place. In addition to system design, the coding supervisors regularly undertook quality control checks of entered data, as well as monitoring individual coders. Analyses of interim data files created during production showed that the problematic areas for data entry occurred with transfer schools and transfer credits. While some transfer transcripts were entered, the quality of these data is not at the same level as data from the sample school transcript for several reasons: (1) transfer transcripts were not requested from the transfer school and therefore, were not systematically received; (2) full information about the transfer schools was not obtained (i.e., course catalogs, number of credits required for degree, type of credits granted, etc.). First Follow-up Methodology Report"}, {"section_title": "7.", "text": "Weights Development Documentation for B&B:93/94 Sample B&B:93/94 final weights were calculated by adjusting the baseline National Postsecondary Student Aid Survey (NPSAS:93) weights. Adjustments were made for tighter B&B eligibility criteria applied in B&B:93/94 and for nonresponse in the B&B:93/94 survey. NPSAS:93 sample development and weights calculation documentation can be found in \"Sampling Design and Weighting Report for the 1993 National Postsecondary Student Aid Study\" published in February, 1995 (Whitmore, Traccarella, and Iannacchione, 1995). The B&B:93/94 weights adjustment started with the NPSAS:93 base weight calculated for all B&B eligible sample members (No). A summary of the interim weight components and final B&B weight distribution can be summarized as follows: Variables defined in the weights development process: B&B:93/94 final weight adjusted for nonresponse (non-respondents are assigned a value = 0) B&BSTRAT: Adjusted institution stratum for B&B weight B&BTYPE: Adjusted student type for B&B weight A summary of the final distribution for No, Bo, and B1 is as follows: Weights Development Procedure Step 1. Calculate the final B&B:93/94 case disposition The final B&B:93/94 case disposition for weights development and further analysis was created by combining the final survey disposition (CATI) with the final disposition from the Transcript component. The final survey disposition reflects the final data collection disposition and includes complete cases, cases determined to be ineligible for B&B, and cases for which no response was attained. The final transcript component disposition was determined by our ability to collect and code the sample member's undergraduate transcript. Information from the transcript was used to determine whether sample members were eligible for B&B. The valid values from the transcript component disposition include complete (and eligible), ineligible, and not received. Refer to table 6.3 for the breakdown of transcript and CATI eligible cases. The final disposition of all cases is presented in table 7.2. Step 2. Collapse institution stratum and student type cells. NPSAS:93 interviews were completed, and B&B eligible sample members were identified, from all 22 institution strata and all 5 student types defined in the NPSAS:93 sample universe. For the purpose of control total, and non-response, adjustments the B&B:93/94 sample were collapsed into 48 cells. These 48 cells include the 16 institution strata containing institutions which grant baccalaureate degrees, and within each stratum three student types (baccalaureate degree eligible--business majors (type 4), baccalaureate degree eligible--all other degrees (type 5), and all other students (types 1-3 collapsed into type 3). The following rules were used to collapse student type and institution stratum: If student type =1 (other undergraduates) or =2 (graduates) or =3 (first professional students) Set B&BTYPE =3 (other) 2. Else B&BTYPE = student type Institution Stratum: 1. If institution stratum (IS) = 17 (public, 2-year) or = 20 (public less-than-2-year) Set B&BSTRAT = 14 (Public, 4-year, bachelors, low ed) [IS 17 (10 cases)+IS 20 (0 cases)=10 cases recoded]"}, {"section_title": "54", "text": "Baccalaureate and Beyond Longitudinal Study 93/94 First Follow-up Methodology Report Step 4. Adjust for non-response and calculate final B&B:93/94 weight Non-response adjustments for the weight variables were calculated using the following process: 1. Non-response adjustment cells were created by cross-classifying cases by two variables: institution stratum and student type."}, {"section_title": "4.", "text": "Once all cells were defined, the B&B weight variable was multiplied by the inverse of the weighted response rate for the cell. In more formal terms, if we define the indicator Ihb, = 1 if surveyed B&B sample member I in student stratum b and institutional stratum h responded to the survey, and let Ihb, = 0 if the sample member did not respond to the survey, then the response rate for sample members in institutional stratum h and student stratum b, Rhb, is where nhb is the number of sampled students in student stratum b and institutional stratum h. The final B&B:93/94 weight adjusted for nonresponse, B1, is Final response rates for each strata are presented in the following table. 46 First Follow-up Methodology Report The design effect is defined as the ratio of the variance, corrected for the sampling design, to the variance based on a simple random sample. Most complex multi-stage sampling designs result in a design effect greater than one, that is, the variance of an estimate is actually larger than the variance would be had the data been based on a simple random sample. To estimate the variance using information about the sample design, it is necessary to use statistical procedures such as Taylor Series approximations, Balanced Repeated Replication, or Jacknife Repeated Replication. For B&B:93/94, NORC used the Taylor Series procedure to calculate the standard errors. The impact of departures from simple random sampling on the precision of sample estimates is often measured by the design effect (designated as DEFF), the ratio of the design-corrected variance to the variance based on SRS assumptions. The square root of the design effect (also called the root design effect, and designated as DEFT) is also useful. The following formulas defined the design effects and root design effect for this section: where DESIGN-SE designates the standard error of an estimate calculated by taking into account the complex nature of the survey design, and SRS-SE designates the standard error of the same estimate calculated as if the survey design was a simple random sample. Standard errors for thirty proportions based on B&B:93/94 data were calculated. Tables 7.7 through 7.15 present estimates of the design effects for these variables for various subgroups of the population. The design effects presented in the first table are based on the entire population; later tables present estimates for subgroups by sex, race, and type of school attended. For each variable and group, the table contains the percent estimate, the design-corrected standard error, the standard error for the same percent estimate based on SRS assumptions, the unweighted n on with the estimate is based, the design effect and the root design effect. Researchers who use the Data Analysis System prepared for use with B&B:93/94 will find that the program automatically produces design-corrected standard errors. Researchers using the restricted use files are cautioned to use a package (such as SUDAAN or OSIRIS) which can produce the designcorrected standard errors, or to adjust the standard errors produced by typical packages by multiplying them by the mean root design effect for that subgroup.          The B&B study is designed to follow college graduates through further education and career choices. The study will build upon the information collected in the National Postsecondary Student Aid Study (NPSAS), for which you were interviewed not long ago. Whereas, NPSAS focused on your experience as an undergraduate student, B&B will collect information about your employment and education experiences after graduation. The B&B study is being conducted by the National Opinion Research Center (NORC), at the University of Chicago. The interview will take about 35 minutes, although many interviews will be shorter than that depending upon individual experiences. Both NORC and the National Center for Education Statistics will assure that your privacy is protected. New federal laws provide stiff fines and prison sentences for the disclosure of your identity or the misuse of information you provide to us. Please see the back of this letter for additional information about our uncompromising pledge of confidentiality protection. An interviewer from NORC will telephone you soon. We thank you for your participation. If you have questions or would like to arrange an interview time, please call the study at its toll-free number, 1 (800) 597-7870, and ask for the B&B Coordinator. NORC's general number is 312 We are asking these questions in order to gather information about the experiences of college graduates after they leave college and move on to graduate or professional education, work, or other activities.\nNo information collected under this authority may be used for any purpose other than the purpose for which it was supplied. Information will be protected from disclosure by federal statute (42 US Code 242m, section 308d). NCES may use the data only for statistical purposes and violators are subject to fines and imprisonment for misuse. Data will be combined to produce statistical reports for Congress and others. No individual data that links your name, address, telephone number, or student identification number with your responses will be reported. August, 1994 Dear ;(1`A n interviewer from the National Opinion Research Center at the University of Chicago called you recently on behalf of the National Center for Education Statistics (NCES), the research center within the U.S. Department of Education. The interviewer asked you to participate in the Baccalaureate and Beyond Study (B&B), however, you did not wish to participate at that time. We want to talk to you because we are interested in learning about the impact of post-secondary education on the lives of those who attain a bachelor's degree. The results of this study will provide Congress and the educators who recommend government policy with the information they need to decide on improvements in the quality of education in America. Your views and experiences are vital to the success of this study. You have helped NCES in the past with the National Postsecondary Student Aid Study; and we again ask for your assistance by your participation in B&B, so that we can effect constructive changes in the American educational system. All of your responses will be held in strict confidence and any information which could identify you will be separated from your interview. You may have participated in the National Postsecondary Student Aid Study (NPSAS) and remember the length and intricacy of that survey. We want you to know that the Baccalaureate and Beyond (B&B) survey takes only 30 minutes, on average, to complete; this is significantly shorter than the NPSAS interview. Also, the B&B interview has an entirely different focus than the NPSAS study; in B&B we are interested in your education and employment experiences after you received your bachelor's degree. We realize that you are very busy and that your time is valuable. All you need to do is answer the questions we ask over the telephone; you do not have to fill anything out. If necessary we can schedule several short appointments to fit your schedule, at times most convenient to you. I have asked one of our interviewers to call you soon. We would appreciate a few minutes of your time to explain the study and to arrange for an interview at your earliest convenience. I sincerely hope that we have stressed the importance of your contribution to this study. Please call the B&B Coordinator toll-free at 1 -800-597 -7870 if you have any questions about the study. We want to talk to you because we are interested in learning about the impact of post-secondary education on the lives of those who attain a bachelor's degree. The results of this study will provide Congress and the educators who recommend government policy with the information they need to decide on improvements in the quality of education in America. Your views and experiences are invaluable. You have helped us in the past with the National Postsecondary Student Aid Study; and we again ask for your assistance by your participation in B&B, so that we can effect constructive changes in the American educational system. All of your responses will be held in strict confidence and any information which could identify you will be separated from your interview."}, {"section_title": "3.", "text": "Participation is voluntary. You may skip questions you do not wish to answer; however, we hope that you will answer as many questions as you can."}, {"section_title": "HS/rip", "text": "We realize that you are very busy and that your time is valuable. The interview takes about 35 minutes and all you need to do is answer the questions we ask over the telephone; you do not have to fill anything out. We can schedule multiple interviews to fit your schedule. We can also schedule an appointment for the most convenient time possible. I have asked one of our interviewers to call you soon. We would appreciate a few minutes of your time to explain the study and to arrange for an interview at your convenience. I sincerely hope that we have stressed the importance of your contribution to this study. Please call the B&B Coordinator toll-free at 1-800-597-7870 if you have any questions about the study. An interviewer from the National Opinion Research Center at the University of Chicago called you recently on behalf of the U.S. Department of Education. The interviewer asked you to participate in the Baccalaureate and Beyond Study (B&B); however, you explained that you did not wish to complete the interview because you are concerned about the sensitive nature of some of the questions. Let me assure you that we provide rigorous protection of the privacy of all respondents in the study. All of your responses will be held in strict confidence and any information which could identify you will be separated from your interview. The results of the study are reported in only summary or statistical form. In addition to the strict confidentiality procedures we follow in our organization, the Privacy Act of 1974 ensures that the confidentiality of respondents in federally funded research projects is legally protected. If you are still apprehensive, please remember that you always have the option of refusing to answer certain questions during the interview. The results of this study will provide Congress and the educators who recommend government policy with the information they need to decide on improvements in the quality of education in America. Your views and experience as a college graduate are invaluable. You have helped us in the past with the National Postsecondary Student Aid Study; and we again ask for your assistance by your participation in B&B, so that we can effect constructive changes in the American educational system. I have asked one of our interviewers to call you soon. We would appreciate a few minutes of your time to explain the study and to arrange for an interview at your convenience. I sincerely hope that we have stressed the importance of your contributions to this study. Please call the B&B Coordinator toll-free at 1-800 -597 -7870 if you have any questions about the study. An interviewer from the National Opinion Research Center at the University of Chicago called you recently on behalf of the U.S. Department of Education. The interviewer asked you to participate in the Baccalaureate and Beyond Study (B&B); however, you explained that you were not interested in participating in a government study at that time. Although the National Center for Education Statistics sponsors the study, the National Opinion Research Center is a not-for-profit social science research center committed to conducting research in the public interest. We serve the public by collecting and reporting information about attitudes and behaviors of the American public. This can only be achieved when everyone who is randomly selected for a study participates. Your views and experience as a college student and graduate are invaluable. You have helped us in the past with the National Postsecondary Student Aid Study; and we again ask for your assistance by your participation in B&B, so that we can effect constructive changes in the American educational system. All of your responses will be held in strict confidence and any information which could identify you will be separated from your interview. The results of the study are reported in only summary or statistical form. I have asked one of our interviewers to call you shortly after you have received this letter. We would appreciate a few minutes of your time to explain the study and to arrange for an interview at your convenience. I sincerely hope that we have stressed the importance of your contribution to this study. Please call the B&B Coordinator toll-free at 1-800-597-7870 if you have any questions about the study.  2= at least $5,000 but less than $10,000 (U64_UXT) IY55 :440/ 40 : 1 3= at least S10,000 but less than $20,000 2=at least $5,000 but less than $10,000 (U64_UXT) IY63 :440/ 49 : 1 3 =at least $10,000 but less than $20,000 (1992) 4r-or at least $20,000 but less than $30,000? 2=at least $500 but less than $1000 3 =at least $1,000 but less than $2,500 4=at least $2,500 but less than $5,000 5=at least $5,000 but less than $10,000 6=at least $10,000 but less than $25,000 7=or, $25,000 or more? D 2=at least $500 but less than $1000 3=at least $1,000 but less than $2,500 4=at least $2,500 but less than $5,000 5 =at least $5,000 but less than $10,000 6=at least $10,000 but less than $25,000 7=or, $25,000 or more? D 1508 :441/ 60 : 1 Would you estimate the amount currently owed 1= less than $5,000 2 =at least $5,000 but less than $10,000 3 =at least $10,000 but less than $15,000 4=at least $15,000 but less than $25,000 5=at least $25,000 but less than $50,000 6 =or, $50,000 or more D, R ..less than $1,000 2 = ...at least 1,000 but less than $5,000 3 = ...at least $5,000 but less than $10,000 4 = ...at least $10,000 but less than $20,000 ..less than $500 2 = ...at least $500 but less than $1,000 3 = ...at least $1,000 but less than $2,000 4 = ...at least $2,000 but less than $3,000 5 = ...at least $3,000 but less than $4,000 6 = ...or, $4,000 or more?  Would you estimate your (and your spouse's) other taxable income in (1991/1992) was... I = ...less than $500 2 = ...at least $500 but less than $1,000 3 = ...at least $1,000 but less than $2,000 4 = ...or, $2,000 or more? NZ49 :521/ 50 : 1 3 = ...at least $2,000 but less than $3,000 FOR 1992 (1992) 4 = ...at least $3,000 but less than $4,000 5 = ...at least $4,000 but less than $5,000 6 = ...or, $5,000 or more? ..less than $500 2 = ...at least $500 but less than $1,000 P 3 = ...at least $1,000 but less than $2,500 4 = ...at least $2,500 but less than $5,000 5 = ...at least $5,000 but less than $7,500 6 = ...at least $7,500 but less than $10,000 7 = ...or, $10,000 or more? (and your spouse's) cash, savings, and checking accounts were worth... (2) Would you estimate the current value of your (and your spouse's) cash, savings, and checking accounts to be worth... I = ...less than $10,000 2 = ...at least $10,000 but less than $20,000 3 = ...at least $20,000 but less than $30,000 4 = ...at least $30,000 but less than $40,000 5 = ...at least $40,000 but less than $50,000 6 = ...or, $50,000 or more? D (and your spouse's) retirement and/or pension accounts were worth... (2) Would you estimate the current value of 1 = ...less than $50,000 2 = ...at least $50,000 but less than $100,000 3 = ...at least $100,000 but less than $250,000 4 = ...at least $250,000 but less than $500,000 5 = ...at least $500,000 but less than $1,000,000 6 = ...or, $1,000,000 or more? ..less than $25,000 2 = ...at least $25,000 but less than $50,000 3 = ...at least $50,000 but less than $100,000 4 .= ...at least $100,000 but less than $250,000 5 = ...or $250,000 or more? D,R P N014-92 NE14-Cur N014 :522/ 6 : 7 (as of May, 1992) NEI4 :522/ 69 : 7 (current) (I) How much was still owed as of May. 1992? (2) How much is currently owed? 0 NONE ..less than $25,000 2 = ...at least $25,000 but less than $50,000 3 = ...at least $50,000 but less than $100,000 4 = ...at least $100,000 but less than (2) Would you estimate the current value of your (and your spouse's) business/farm to be worth... 1 = ...less than $25,000 2 = ...at least $25,000 but less than $50,000 3 = ...at least $50,000 but less than $100,000 4 = ...at least $100,000 but less than (2) How much is currently owed? NX17-92 NY17 -Cur. NX17 :522/ 30 : 1 (as of May, 1992) NY17 :523/ 13 : 1 (current) (1) Would you estimate the amount owed as of MAx.1222 was... (2) Would you estimate the amount currently 1 = ...less than $25,000 2 = ...at least $25,000 but less than $50,000 3 = ...at least $50,000 but less than $100,000 4 = ...at least $100,000 but less than ..less than $25,000 2 = ...at least $25,000 but less than $50,000 3 = ...at least $50,000 but less than $100,000 4 = ...at least $100,000 but less than $250,000 5 = ...or, $250,000 or more?"}, {"section_title": "SKIP TO NB21/N21B", "text": "(2) Would you estimate the amount currently owed to be... ..less then $5,000 P 2 = ...at least $5,000 but less than $10,000 3 = ...at least $10,000 but less than $20,000 4 = ...at least $20,000 but less than $30,000 5 = ...at least $30,000 but less than $40,000 6 = ...at least $40,000 but less than $50,000 7 = ...or, $50,000 or more?     SKIP: GOTO PBASCHL_WHY INSTRUCTIONS: if pbaschl_dates(n)=9696 then \"insert\"=\"Are\"; else \"insert\"=\"Were\"  INSTRUCTIONS: if pbaschool_dates(n)=9696 then \"insert\"=\"do\"; else \"insert\"=\"did\" TUITION_APP(N) AQ number: 304 ITERS: 3 655 Now I'd like you to think about the period from July 1, 1993through June 30, 1994. During that period, how much were your total tuition and fees prior to any discounts or waivers at \"PBASCHOOL(N)\"? RANGE: 1/25000 QX0: Record the amount of tuition that the school normally charges during the reference period and SAMPLE: ASK ONLY IF PBASCHL_PROGRAM(N) = 4, 5, 6, 9 AND PBASCHL DATES include any time between July 1, 1993 andJune 30, 1994 "}, {"section_title": "PBASCHL_ROOM(N)", "text": "AQ number: 305 ITERS: 3 Other than tuition, what were your total costs of attending \"PBASCHOOL(N)\" during SAMPLE: Ask only if PBASCHL_PROGRAM(N)= 4, 5, 6, this same period (July 1, 19931, June 30, 1994. Total costs include lab fees, 9 AND PBASCHL DATES include any time 'books, transportationi living expenses and-other.expenses xelating to.attending between July 1, 1993 andJune 30, 1994. that school. RANGE: 1/99000 QXQ: All costs related to attending school should be included."}, {"section_title": "SKIP:", "text": "INSTRUCTIONS: if pbaschool_dates(n)=9696 then \"insert \" = \"is \"; else \"insert\"=\"was\" PBASCHL_AID$(N) \nLOOP CHANGE = 1 OR 6.\nITERS: RANGE: 0/999000 QXQ: Given implies that the money is not expected to be INSTRUCTIONS: repaid. Money borrowed for education includes money borrowed to cover tuition, room and board, fees, books, lab materials, and other living expenses. "}, {"section_title": "681", "text": "If R has more than one April job, probe for full time employer. If more than one full time job, pick the job with most hours worked in April. How satisfied (are/were) you with your opportunity for further education at \"APRILJOBEMPLOYER\"? (Are/Were) you...      working full-time, but expects to be working only part-time, code \"NO.\" Full-time employment: a person works 35 or more hours per week at a given job."}, {"section_title": "OCCEXPECT2", "text": "What do you expect your occupation will be two years from now? SAMPLE: AQ number: 649 INSTRUCTIONS: ASK ONLY IF \" P_H0048\" = MISSING AND ((\"P_D006\" <> 4 OR \"P_D008\" <> 2 OR 3) AND \"P D012\" <> 2) 10/13/95   less than $5,000 2 at least $5,000 but less than $10,000 3 at least $10,000 but less than $20,000 4 at least $20,000 but less than $30,000 5 at least $30,000 but less than $50,000 6 at least $50,000 but less than $75,000 7 at least $75,000 but less than $100,000"}, {"section_title": "S60", "text": "10/13/95 "}, {"section_title": "861", "text": "ITERS: 1 less than 85,000 2 at least $5,000 but less than $10,000 3 at least $10,000 but less than $20,000 4 at least $20,000 but less than $30,000 5 at least $30,000 but less than $50,000 6 at least 850,000 but less than $75,000 7 at least 875,000 but less than $100,000 8 or $100,000 or more inlaws, aunts, uncles, grandparents, etc., but excluding support you receive from your spouse)."}, {"section_title": "ITERS:", "text": "RANGE: 0/999000 QXQ: Borrowed implies that the money is expected to be repaid at some time in the near future."}, {"section_title": "SKIP: INSTRUCTIONS:", "text": "GRADFAMILYSUPPORT AO number: 801 How much money have you been given by your family, for graduate or professional education, since getting your bachelors degree? (Include money from parents, inlaws, aunts, uncles, grandparents, etc., but excluding support you received from your spouse) SAMPLE: Ask only for graduate or first professional programs."}, {"section_title": "DEBTSPOU", "text": ""}]