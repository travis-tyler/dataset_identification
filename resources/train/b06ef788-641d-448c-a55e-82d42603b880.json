[{"section_title": "", "text": "\u2022 As of 2017, across the Nation, 55 percent of assessed rivers and streams; 71 percent of lakes; and 84 percent of bays and estuaries nationally have impaired water quality. Agriculture is the largest source of impairments in rivers and streams and the second-largest source in lakes and ponds. \u2022 Drought is the leading cause of production risk and crop insurance indemnity payments in the United States. Practices such as irrigation adoption can reduce drought vulnerability. \u2022 Many farmers and ranchers use practices that enhance soil health. In 2012, 35 percent of all cropland acres were in no-till and 3 percent were planted with a cover crop, two practices that promote soil health. \u2022 Based on a land use-based measure of quality, pollinator forage habitat increased between 1982 and 2002, then declined until 2012. The decline was greatest in the Northern Plains, a summering ground for commercial beehives. \u2022 Between 2007 and 2012, the number of farms producing energy or electricity onfarm with solar panels, geothermal exchange, wind turbines, small hydro, or methane digesters increased from 1.1 to 2.7 percent. \u2022 Federal funding for the five largest voluntary programs that encourage land retirement and adoption of conservation practices on working lands was roughly $6 billion in 2017. In real (inflation-adjusted) terms, conservation spending increased in the 2002 and 2008 Farm Acts and declined in the 2014 Farm Act. \u2022 Since 1992, freshwater wetlands in the contiguous United States have held steady at around 111 million acres. \u2022 Between 2012 and 2018, acreage enrolled in USDA's Conservation Reserve Program (CRP) declined from 29.5 million to 22.4 million acres. However, land enrolled in the continuous portion of the CRP increased from 5.3 million to 8.1 million acres. \u2022 In 2016, an estimated 1.7 percent of farms were enrolled in the USDA's Environmental Quality Incentives Program (EQIP), and 5.1 percent were enrolled in the Conservation Stewardship Program (CSP). Some of the increase in the number of very small farms that stabilized the farm count, however, occurred because of changes in how USDA's National Agricultural Statistics Service (NASS) conducts the Census of Agriculture. NASS now adjusts the farm count to account for undercoverage of small farms and has increased its efforts to contact all small farms for the Census. In addition, the $1,000 farm sales cutoff to qualify as a farm is not adjusted for inflation and has not changed since the current farm definition was adopted in 1974. This means that when commodity prices increase, the number of farms increases because less physical production is required to qualify as a farm. In other words, we do not know how much of the increase in small farms is due to measurement issues and how much is due to the actual entry of small farms. While farm numbers appear to have stabilized, production has shifted to larger farms. Between 1991 and 2017, farms with gross revenue of $1 million or more (in 2017 dollars) increased their share of U.S. production from 30 percent to 39 percent. Today's farms are diverse, ranging from very small retirement and residential farms to large operations with gross revenue in the millions of dollars. It is important to differentiate between small farms that dominate the farm count and larger farms that dominate production totals."}, {"section_title": "Farm Diversity-Classifying Small and Large Farms", "text": "One way to view the diversity of farms is to categorize them into more homogeneous groups. A farm classification developed by USDA's Economic Research Service focuses on family farms, where the majority of the business is owned by the principal operator-the person most responsible for running the farmand relatives of the principal farm operator. The classification identifies four types of small family farms (annual revenue less than $350,000): retirement, off-farm occupation, farming-occupation/low-sales, and farming-occupation/moderate-sales (see box, \"Farm Types\"). Small farms dominate the farm count, making up 89 percent of all U.S. farms in 2017 (table 1.1.1). Production, however, is concentrated among the remaining groups: midsize, large, and very large family farms, as well as nonfamily farms. Together, these classes accounted for 74 percent of the value of agricultural production in 2017. Large-scale family farms (annual gross revenue above $1 million) alone accounted for 39 percent of U.S. farm production, while comprising only 3 percent of farms. Large-scale farms account for much larger shares of agricultural production than their share of farmland. This is largely due to their commodity mix: large-scale farms include many fruit and vegetable operations, cattle feedlots, and dairy farms, which generate high values of production on limited land bases."}, {"section_title": "Working land programs 4", "text": ""}, {"section_title": "Total payments 5", "text": "Small family farms Retirement 10.7 1.3 3.9 1.7 21.6 1.5 5.3 Off-farm occupation 40.8 4.9 17.1 5.9 28.6 10.5 10.9 Farming-occupation "}, {"section_title": "Multiple-Operator Farms", "text": "In addition to the principal operator, some farms may have additional, or secondary operators involved in running the farm business. There were 728,200 multiple-operator farms in 2016, representing 38 percent of all U.S. farms (figure 1.1.2). 1 Because farms are generally family businesses, most secondary operators are family members, particularly on smaller farms. On larger farms, secondary operators are more likely to come from outside the family, and often add specific management skills needed for the farm business."}, {"section_title": "1", "text": "Numbers on multiple-operator and multiple-generation farms for 2017 are not displayed due to changes in the methodology for collecting data on operator demographics in the 2017 ARMS. Program (CRP) targets environmentally sensitive land, not the production of commodities (see chapter 3.23, \"Conservation Reserve Program: Status and Trends\"). Retirement, off-farm occupation, and low-sales family farms together received 73 percent of CRP payments in 2017. Participating farmers in each of the three groups tend to enroll large shares of their land in these programs. Because their main job is off-farm, off-farm occupation operators have limited time to spend farming. Off-farm occupation farmers may find CRP attractive because participating in the program requires little time. Given their advanced age, many retired farmers having environmentally sensitive land available may choose to participate in the CRP as they scale down their operations. The same forces may also be acting on low-sales operators, who average 62 years of age and may also be scaling down their operations.\nA similar question was asked in the TOTAL survey regarding \"permanent\" conservation practices, such as the construction of grassed waterways and terraces. The pattern of results from this question are similar to those for one-season conservation practices. Farmland ownership has gained additional attention in recent years as it relates to the leasing and sale of land for energy production. Non-operator landlords, who owned 31 percent of all U.S. farmland in 2014, control a larger share of land leased for oil and gas production (figure 1.4.2). Specifically, nonoperator landlords, some of whom do not live near the land they rent out, owned 36 percent of farmland on which oil and gas rights had been sold and 52 percent of farmland on which the rights had been leased. This suggests that entities that own farmland, but are not directly involved in its use for agricultural production, may be more likely to exercise nonagricultural use rights to gain access to additional streams of income. Oil and gas (O&G) production rights sales and leases by ownership type Farmland consists primarily of land used for crops, pasture, or grazing but also includes acres of idled cropland and woodland. In the U.S. agricultural productivity accounts, land stock is measured as the real value of total farmland, which is nominal land value deflated by a land price index from ERS's productivity accounts. In addition, the land stock is also adjusted by quality differences across counties and States.   1948195319581963196819731978198319881993199820032008 Total output Total farm input Total factor productivity (TFP) Source: USDA, Economic Research Service, \"Agricultural Productivity in the U.S.\" series.\nAll estimates of research spending in this chapter are adjusted for inflation to 2012 dollars using the ERS research deflator. Inconsistencies in one of the major series underlying this deflator-faculty salaries for U.S. educational institutions-preclude updating the base year to 2017. Performers of agricultural research include Federal researchers, who generally study issues of national importance and accounted for about $1.3 billion of research spending in 2014. State-level research at the Land Grant Universities/State Agricultural Experiment Stations (LGU-SAES) and other cooperating institutions, usually other universities, accounted for $2.9 billion. Research at these academic institutions is typically directed at issues of local and regional importance and at fundamental scientific questions. Industry was the largest performer of food and agricultural research in 2014, at $11.8 billion (fig. 1.6.1). Private-sector research is usually nearest the marketplace. Roughly half of private-sector research was spent in the food sector, where much of it is oriented toward improving food manufacturing processes and developing new food products. The other half goes toward research related to agricultural inputs, which is much more likely to have a direct impact on production agriculture. The U.S agricultural research system is characterized by numerous links between institutions. State-level institutions receive funds from several Federal agencies other than USDA, and USDA funds State-level institutions through a variety of instruments. The private sector and USDA exchange funds or conduct joint research through grants, cooperative agreements, contracts, and trusts. USDA, State-level institutions, and private firms all transfer technology through the patent-licensing mechanism or research consortia.\nThere is no universally recognized STIR value that defines the upper boundary of soil disturbance consistent with conservation tillage. The national conservation practice standard (USDA-NRCS, 2016) indicates a maximum STIR rating of 80. In actually implementing conservation programs, however, STIR ratings as low as 60 are used to define the upper bound of conservation tillage in some States.\nFor additional information about the costs, benefits, and tradeoffs associated with soil health and soil health practices for farmers and society, see Dale and Polasky, 2007;Hansen and Ribaudo, 2008;Robinson et al., 2012;and Snapp et al., 2005. Although farmers may benefit from improved soil health, additional costs of using soil health practices include buying seed to plant a cover crop, which farmers receive no revenue from since it is not harvested or sold. In addition, benefits from soil health practices may take years to realize. For these reasons and others, Federal and State programs may subsidize the cost of soil health practices that otherwise might be foregone by farmers. USDA's Natural Resources Conservation Service (NRCS) administers two programs that provide financial assistance to farmers to retain or use soil health practices and enhancements: the Environmental Quality Incentives Program (EQIP) 2 and the Conservation Stewardship Program (CSP). 3 Farmers receive payments to implement or maintain practices like nutrient management, no-till, cover cropping, and pasture/rangeland management and restoration (see chapter 3.24, \"Working-Lands Conservation Programs\"). EQIP's budget has increased since 1997 as it grants more contracts to eligible producers. EQIP expenditures on nutrient management and terracing have decreased, while expenditures on cover crops have increased ( fig. 3.19.4). 1998 99 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 Note: See box \"Selected Soil Health Management Practices\" for definitions of practices. Terraces are a structural practice designed to reduce runoff and soil erosion by constructing an earth embankment or ridge that is perpendicular to a field's slope. Between 1998 and 2015, the total EQIP budget expanded from $19 million to $800 million. Source: USDA, Economic Research Service using data from USDA, Natural Resources Conservation Service, EQIP practice suite payments in the United States. 2 EQIP provides payments up to 75 percent of the incurred costs and income foregone of certain conservation practices and activities (USDA Natural Resources Conservation Service, 2017c).\nThe variation in estimates of the economic value of pollinators is largely driven by assumptions about producer adaptation. Higher values assume no adaptation, hence they represent an upper bound on the losses should pollinators disappear.  Note: Annual colony loss estimates from the Bee Informed Partnership are for the period from October 1 to September 30 of the following year; winter loss estimates are for October 1 to April 1 of the following year. Before 2010-11, data on summer losses were not gathered. The data on the number of honey-producing colonies are from NASS Honey Report. Source: USDA, Economic Research Service using data from the Bee Informed Partnership (2017) and from USDA, National Agricultural Statistics Service, Honey Report (USDA-NASS, 2018). The increase in colony numbers since 2008, even as colony mortality remains high, is due to beekeeper management, such as splitting colonies and the purchase of \"packages\" (small honey bee colonies containing a queen and a few thousand bees). By monitoring for pests and pathogens to inform the application of miticides, antibiotics, and other chemicals, and by providing supplemental feeds, intensified management can reduce colony losses. All of this management may result in increased costs to beekeepers. While both wild bees and managed honey bees contribute to agricultural production, they in turn depend on forage resources-the pollen and nectar of flowering plants that bees feed on to survive. The quality and quantity of forage resources available to pollinators depends on land use and land cover (LULC). Shortening the distance between crop fields and natural habitat can enhance pollination by wild pollinators. A particular plot of land's impacts on honey bee health may be less pronounced than on the health of native pollinators, both because honey bees cover a larger landscape (over 2 miles) to meet their nutritional requirements and because hives can be relocated by beekeepers. A potential cause of increased honey bee losses could be a nationwide trend toward land uses and land covers that provide less forage for bees.   \nThe profitability of farming wetlands was assumed to equal the operation's suitable wetland acreage times the rental value of surrounding cropland.\nThe EBI consists of a number of different factors that account for water quality, soil erosion, wildlife habitat, and other effects of retiring a parcel of cropland. The EBI combines measures of these effects, along with the requested asking price, to produce a single score for each offer. Alongside these changes in the acreage cap, many commodity prices peaked in 2013 before retreating to pre-2008 levels by 2016. These changes may influence interest in the CRP. In the 2012, 2013, and 2014 general signups (when 4.8 million, 3.8 million, and 4.5 million acres were offered to the program), a higher-than-usual share of offers was accepted-averaging 82 percent-compared with the 66-percent acceptance rate that prevailed between 1997 and 2006 (fig. 3.23.3). Furthermore, around 80 percent of offered acres were from parcels already enrolled in the program, compared to an average of 33 percent before 2006. 2 In 2016, this trend in acceptance rates reversed. From the 1.8 million acres offered, the CRP accepted only 22 percent (about 400,000 acres), of which 45 percent were from land already enrolled. As of July 2018, the average rental rate for general CRP signup was $52/acre, while the average rental rate for continuous signup was $137/acre. These rates vary by year of enrollment: from 2004 to 2012, average rental rates varied between $46 and $54 per acre; average rates in 2014 and 2016 were around $64 an acre."}, {"section_title": "Chapter 1.2-Major Land Uses in the United States", "text": ""}, {"section_title": "Daniel Bigelow", "text": "\u2022 As of 2012, grassland pasture and range (29 percent) and forest (28 percent) uses account for the largest shares of land in the United States. \u2022 More than half of all land in the United States (53 percent) is used for some type of agricultural purpose, including crop production, grazing, farmsteads, and farm roads. \u2022 Land use can vary substantially within regions-for example, 75 percent of Iowa is cropland versus just 41 percent of Ohio. The U.S. land area totals nearly 2.3 billion acres. In 2012, grassland pasture and range uses accounted for the largest share of land use (29 percent of all land), followed by forest uses (28 percent) and cropland (17 percent). Just under 53 percent (1.18 billion acres) of U.S. land is used for some type of agricultural purpose, including crop production, grazing, farmsteads, and farm roads. 1\n\u2022 Starting in the early 2000s, a boom in farmland values took place, with average U.S. farm real estate value nearly doubling in inflation-adjusted terms. \u2022 Since 2015, however, the value of cropland has declined by nearly 5 percent, while pastureland values have been relatively stable. \u2022 Cropland values in the Corn Belt and Northern Plains, where many farmers specialize in cash grain commodity production, have exhibited the largest recent declines. In recent years, farm real estate (land and buildings) has accounted for more than 80 percent of total farm asset value. Farmland values are a useful barometer for measuring the overall financial well-being of the farm sector. During the farm financial crisis of the 1980s, farmland values fell precipitously (figure 1.3.1). After an ensuing period of relative stability and modest growth, inflation-adjusted farm real estate values increased rapidly between 2000 and 2014, a trend that coincided with historically low interest rates and strong farm earnings.  1970 1972 1974 1976 1978 1980 1982 1984 1986 1988 1990 1992 1994 1996 1998 2000 2002 2004 2006 2008  At the national level, cropland values nearly doubled between 2003 and 2018, increasing from an average of $2,165 to $3,983 per acre (in inflation-adjusted 2016 $USD; figure 1.3.2). The value of pastureland has also grown, albeit more modestly. After a short period of decline amid the Great Recession of 2007-08, commodity price increases (particularly for corn and soybeans) spurred the boom in cropland values over 2010-13. However, farm real estate and land value appreciation has slowed over the past few years. Between 2015 and 2018, the real value of cropland declined by nearly 5 percent. Pastureland values have been more stable, declining by less than 1 percent between 2015 and 2018. Growth in farmland values is contemporaneous with a shift in the expected stream of net returns that owning farmland may yield. This is influenced by factors that affect the economy as a whole, as well as those that are specific to the farm sector. For example, rising farm loan interest rates can put downward pressure on land values because the expected net returns from owning land decline when borrowing costs increase and investment alternatives become more attractive (e.g., Oppedahl, 2017). Expectations of the income stream may also be changing due to decreased commodity prices: at the end of 2017, the ratio of prices received by farmers to production costs was 13 percent lower than in 2013. In addition, 2018 USDA projections indicate that the inflation-adjusted prices of three major crops will either hold constant (wheat) or exhibit modest declines (corn and soybeans) over the next 10 years (USDA, 2018). Farmland values exhibit considerable regional variation (table 1.3.1). For example, the highest farmland values are generally found in the Corn Belt, Pacific, and Northeast regions. Land values in the Corn Belt are associated with cash-grain commodity prices and growing conditions. Hence, as a result of the 2010-13 commodity price boom, cropland values grew more rapidly in the Corn Belt than in any other region. However, since 2015, the value of cropland in the region has declined as corn and soybean prices have trended back toward their historical average. A similar downward trend in cropland value has taken place in the Northern Plains, another region where values are strongly associated with cash-grain commodity prices and production. In contrast, the relatively high farmland values in the Northeast are mainly due to non-agricultural influences (such as the expansion of urban and suburban land use) that bid up the value of farmland. As a result, cropland values in the Northeast, on average, did not show an uptick stemming from the increase in commodity prices, as they did in cash-grain production areas such as the Corn Belt. The relative dependence of land values on net returns to crop production is captured by patterns in cropland cash rents. For instance, cropland cash rents in the Corn Belt ($204/acre in 2018) are far higher than those in the Northeast ($80.50/acre). In many regions, the difference in value between cropland and pastureland is stark, with cropland commanding a premium due to the higher per-acre returns associated with crop production and the relative scarcity of high-quality cropland. However, in some areas, particularly the Southeast, land values for these two uses are more comparable, with pastureland values often exceeding the value of cropland. As in the Northeast, the value of pasture in the Southeast is influenced by development pressures from high-density urban areas. Recreational income (e.g., hunting and wildlife viewing) may also play a role in pushing pastureland value above its agricultural production value (Doye and Brorsen, 2011).\n\u2022 In 2014, 61 percent (557 million acres) of U.S. farmland was owned and operated by the same entity. The remaining 39 percent of land was rented out by landowners to tenant operators. Roughly 80 percent of rented land is owned by a non-operator landlord. \u2022 About 54 percent of all cropland was rented out, compared to just 28 percent of pastureland. \u2022 Non-operator landlords, who own 31 percent of all U.S. farmland, own a disproportionate share (52 percent) of land where oil and gas rights have been leased. Farmland ownership and tenure shape many decisions in the U.S. agricultural sector, including those related to production, conservation, and succession planning. In 2014, 61 percent of the 911 million acres of land in farms in the contiguous United States was owner-operated, meaning that it was owned and operated by the same farming entity (figure 1.4.1). The remaining 39 percent of land was rented out by the landowner to a tenant farm operator.  About one-fifth of rented land (8 percent of all farmland) was rented from one farm operator to another. The remainder, about 31 percent of all farmland, was owned and rented out by \"non-operator landlords,\" landowners who are not actively involved in a farm operation but own farmland and rent it out to one or more farm operators. Nearly half of the land rented out by non-operator landlords is owned by individuals, while the remainder is split between partnerships, corporations, trusts, and other ownership arrangements. In terms of land use, 54 percent of all cropland was rented out in 2014, compared to just 28 percent of pastureland. Small family farms-those with less than $350,000 in gross cash farm income-are generally less reliant on rental markets, with only 31 percent of land in such operations obtained through renting. Land tenure arrangements may affect environmental stewardship and adoption of conservation practices, since tenant farmers might lack the incentives to manage land in a way that maximizes long-term land productivity. One way to study this issue is to look at the division of decision making between landlords and tenants for different types of farm decisions. In general, tenants are responsible for day-to-day decisions on the vast majority of land for many aspects of farm management and production, including crop/ livestock choices, fertilizer and chemical applications, and harvesting. However, landlords tend to have significantly more involvement in decisions concerning one-season conservation practices and government program participation. 1 In addition, relative to operator landlords, non-operator landlords are more likely to cede control of decision-making to their tenants for many farm decisions. For example, on land rented from nonoperator landlords, tenants had sole responsibility for fertilizer and chemical application decisions on 93 percent of land, a share that drops to 83 percent for land rented from other operators (table 1.4.1). The disparity is even starker for decisions regarding one-season conservation practice adoption, where landlords are not involved in decisions on 82 percent of non-operator land versus just 67 percent of land rented out by farm operators. This suggests that operator landlords, who may have direct experience with the benefits of conservation practices, are more likely to be engaged with how these practices are adopted on the land they own regardless of whether or not they are currently operating the land. "}, {"section_title": "Land Use Varies by Region and Over Time", "text": "Since 1949, the first year of the most recent version of the ERS Major Land Uses (MLU) data series, areas of land in the top land-use categories have fluctuated. 2 For example, between 1949 and 1997, land used for grassland pasture and range decreased by 52 million acres (8 percent), but the land in this category has increased by 75 million acres (13 percent) since 1997 (figure 1.2.1). Total cropland declined by approximately 86 million acres (18 percent) between 1949 and 2012, but there were fluctuations within this interval due to Federal land retirement programs, market trends, and technological improvements. In contrast, the total acreage of urban land has exhibited a consistent upward trend over the past 60 years as cities expand to accommodate economic and population growth. Regional land-use patterns vary based on differences in soil, climate, national and local policies and programs, topography, and population. For example, roughly 62 percent of land in the Southeast region is in forest use, compared to just 3 percent of land in the Northern Plains (figure 1.2.2). Similarly, land use varies between States within a given region. In Ohio, for instance, 41 percent of land is cropland, which contrasts with nearly 75 percent of Iowa. (State-level estimates and sources for all MLU categories are available in the ERS Major Land Uses data product.) 1 In 2012, the Census of Agriculture reported that there were 914 million acres of farmland in the United States. The amount of land used for agricultural purposes reported in Major Land Uses is higher because the National Agricultural Statistics Service (USDA, NASS) definition of a farm for census purposes only covers land in operations that are capable of earning at least $1,000 in revenue in a given year and may not include all low-value land used for agricultural purposes, such as grazing.  1949195419591964196919741978198219871992199720022012 Grassland pasture and range Forest-use land grazed Special uses -agricultural  While land-use changes are not uncommon, most land remains in the same use from year to year. Between 2007 and 2012, according to the USDA, Natural Resource Conservation Service's (2014) National Resources Inventory, 97-99 percent of privately owned cropland (including land enrolled in USDA's Conservation Reserve Program (CRP)), pasture/range, urban land, and forest land did not change use. Over a longer period, 1982-2012, the rate of land-use change is larger, with 83, 86, and 91 percent of cropland/ CRP land, pasture/range, and forest land, respectively, remaining in its 1982 use. Where they occur, transitions between land uses take place for a variety of reasons. Changing commodity and timber prices, agricultural and natural resource policies, and environmental factors (such as droughts) can cause landowners to convert land from one use to another. Proximity to urban areas can also lead landowners to develop or sell their land for residential, commercial, or industrial purposes. However, in contrast to land-use changes between undeveloped uses (e.g., cropland to pasture, or vice versa), land development is generally irreversible. Once developed, land is rarely converted back to agricultural or forest-based uses. In 2012, total cropland-which includes cropland used for crops, idled cropland, and cropland used for pasture-was 392 million acres, its lowest level since the MLU series began in 1945 (figure 1.2.3). This is largely attributable to a reclassification of cropland temporarily used for pasture to permanent grassland pasture and range that resulted from several changes to the questionnaire used in the 2007 and 2012 Censuses of Agriculture. Grassland pasture and range, at 655 million acres in 2012, reached its highest level since the start of the MLU series. Apart from the decline in cropland pasture, the remaining cropland uses, as a whole, increased by roughly 7 million acres (2 percent) over 2007-12.  1949 1954 1959 1964 1969 1974 1978 1982 1987 1992 1997 2002 2007 2012 Harvested cropland Crop failure Summer fallow Idle cropland Cropland pasture Source: USDA, Economic Research Service calculations drawing on data from USDA, National Agricultural Statistics Service and USDA, Farm Service Agency. See sources and reference list in Bigelow and Borchers (2017) for detailed source descriptions. Three competing influences explain the recent changes in non-pastured cropland acreage. First, 2007-12 was a period marked by increasing prices for major commodities, particularly corn, incentivizing farmers to devote additional land to crop production. Offsetting increases in harvested cropland acreage over this period were increases in failed and idled cropland. These two latter changes are, at least in part, attributable to the severe droughts that afflicted several leading crop-producing States in 2011 and 2012 (see chapter 3.16, \"Farm-Level Adaptation to Drought Risk\"). Failed cropland increased by 3 million acres (38 percent) over 2007-12, while idled cropland increased by 2 million acres (1 percent). The idled cropland category, however, also includes land enrolled in the Conservation Reserve Program (CRP), which fell by over 7 million acres over the same period (see chapter 3.23, \"Conservation Reserve Program\"). Disregarding CRP land, then, a 9-million-acre increase in idled cropland accompanied the droughts experienced during this period. Last, fallowed cropland acreage also continued its long-term decline in recent years, a trend that is partly attributable to increases in the adoption of reduced-tillage practices, which are an alternative means to enhance soil moisture in arid regions (see chapter 2.12, \"Crop Production Management: Tillage Practices\").   Bigelow and Borchers (2017) for detailed source descriptions. The mix of crops grown in the United States can change in response to market incentives and agricultural policy and programs (figure 1.2.4). Increases in U.S. soybean plantings from 1995 to 2013, for instance, are contemporaneous with a large increase in exports. The decline in wheat plantings in that time period, on the other hand, occurred alongside increased foreign competition, CRP participation in wheat-producing areas, and improved corn and soybean seed varieties that allow these crops to be planted in areas previously used primarily for wheat. The use of crops as a biofuel input source has also contributed to the large gains in planted corn acreage-the main input in ethanol production-in recent decades (see, e.g., Wallander et al., 2011;Beckman et al., 2013;and chapter 3.18, \"Renewable Energy\")."}, {"section_title": "Chapter 1.3-Farmland Values", "text": ""}, {"section_title": "Chapter 1.4-Farmland Ownership and Tenure", "text": ""}, {"section_title": "Tenant responsibility for decisions by landlord type and production/management practice, 2014", "text": "Non-operator landlords (percent) "}, {"section_title": "Government program participation 70 58", "text": "Note: The percentages in the table represent the percentage of total rented acres for the landlords who responded to the decision section of the 2014 TOTAL questionnaire. Values in the table represent the percentages of rented acres characterized by situations where decisionmaking was solely the responsibility of the tenant. \"One-season conservation practices\" include reduced tillage, no till, cover cropping, and other practices that may vary from season to season. Government programs accounted for in the \"Government program participation\" category include both commodity and conservation programs. It is not possible to determine if the respondents actually adopted conservation practices or enrolled in Government programs. Source: USDA, Economic Research Service and National Agricultural Statistics Service 2014 Tenure, Ownership, and Transition of Agricultural Land (TOTAL) survey."}, {"section_title": "Patterns in Output, Input, and Productivity Growth", "text": "Output growth derives from growth in the use of inputs (capital, land, labor, and intermediate goods) and TFP. Input growth has been the main source of economic growth for the U.S. aggregate economy and for most sectors, but the agricultural sector is different (Jorgenson et al., 2014). While total farm output grew 170 percent from 1948 to 2015, total inputs used in agriculture grew by only 7 percent. Nevertheless, the input composition changed markedly, shifting from labor and land toward machinery and intermediate goods (including energy, agricultural chemicals, purchased services, and other materials) (fig. 1.5.3). Between 1948 and 2015, labor and land inputs declined by about 75 and 25 percent, respectively, while intermediate goods and capital (excluding land) grew by 134 percent and 78 percent, respectively.  1948 1958 1968 1978 1988 1998 2008 Total output Capital (excluding land) Land"}, {"section_title": "Labor", "text": "\nFarm labor fell consistently from 1948 until more recent years. Productivity growth in U.S. agriculture is all the more remarkable given labor's long-term contraction. Over 1948-2015, agricultural labor declined on average 0.46 percent each year-a rate unmatched by any other economic sector. The decline in farm labor (both farmers and hired laborers) occurred as workers sought higher wages and other income opportunities in the nonfarm sector, and/or as farmers relied more on machinery use and purchased servicesincluding custom machinery work and contract labor service (Wang et al., 2015)."}, {"section_title": "Intermediate goods", "text": "Note: Data are expressed with an index that is calculated relative to the data in 1948, where data in 1948 are set to equal 1. Intermediate goods include feed and seed, energy use, fertilizer and lime, pesticides, purchased services, and other materials used. Source: USDA, Economic Research Service, \"Agricultural Productivity in the U.S.\" series."}, {"section_title": "Capital (excluding land)", "text": "Capital input (including the flow of services from farm machinery, service buildings, and inventory) in agriculture increased sharply just after WWII, reflecting rapid mechanization in U.S. agriculture. During 1973-79, U.S. agriculture expanded rapidly, fueled by a growth in exports. Agricultural exports continued to grow until 1981. Real (inflation-adjusted) interest rates also fell or remained very low between 1975 and 1980-which decreased the cost of investment. As a result, farmers invested more in farm machinery, service buildings, and inventories. However, in the early 1980s, an appreciating U.S. dollar slowed agricultural exports. Declining demand for U.S. agricultural commodity exports and rising borrowing costs reduced farmers' incentives for further investment in farm machinery and structures. Capital investment declined between 1979 and 1986 and remained stable until the 2000s, when rising agricultural commodity prices and declining real interest rates once again spurred increased investment in machinery and service buildings (see Wang et al., 2015, for more detailed discussion.) Land and intermediate goods Total factor productivity growth TFP growth measures output growth that cannot be explained by growth in inputs, such as innovations in onfarm tasks, changes in the organization and structure of the farm sector, improvements in animal and crop genetics, or other embodied and disembodied technical changes. 3 Between 1948 and 2015, TFP grew at 1.38 percent per year on average. As a result, by 2015, U.S. farm-sector productivity was 152 percent above its 1948 level. With total inputs (including land, labor, capital, and intermediate inputs) growing by merely 7 percent, productivity growth nearly single-handedly led farm output to grow 170 percent above its 1948 level. Long-term TFP growth is mainly driven by technical change, which is primarily fueled by research and development (R&D) investment from public and private sectors (see chapter 1.6, \"Agricultural Research and Development,\" for more details). It can also be enhanced by public infrastructure, extension, and technology spillover from other sectors or neighboring regions (Wang et al., 2015). Yet, in the short term, estimated TFP can fluctuate considerably from year to year, largely in response to transitory events-such as bad weather and pest outbreaks-or to changes in input use affected by macroeconomic activities or short-term policies. Eventually, TFP growth will return to its long-term trend following these temporary shocks. 2 See Wang et al. (2015) and Ball et al. (2016) for more details regarding how land input is measured in U.S. agricultural productivity accounts."}, {"section_title": "3", "text": "Embodied technical change (ETC) originally referred to the technological advances embodied in the capital goods that make equipment work faster or better in some way. This term can be applied to other inputs when the quality of that input is improved. Disembodied technical change is technical change not associated with any particular input.\nHorticulture crops accounted for the remaining 2.0 percent of agricultural water use applied. Horticulture crops produced under protection, covering 1.4 billion square feet (equivalent to about 32,000 acres), used approximately 54,400 acre-feet of water, or just 0.06 percent of U.S. irrigation water use in 2013. The shift from gravity-flow to pressurized-sprinkler application systems has been particularly significant. In general, annual applied water rates under pressurized-sprinkler systems are considerably lower than under gravity-flow systems (1.2 af/acre compared with 2.3 af/acre across the West in 2013). In 1984, 62 percent of irrigated acres relied on gravity systems, compared with just 34 percent of irrigated acres in 2013. Over the same period, the share of Western irrigated acres using pressure-sprinkler (including drip/ trickle) irrigation systems rose from 37 to 76 percent (with some acres irrigated with both systems). The corresponding shift in Western applied water use by irrigation technology has been more dramatic as water scarcity has intensified. Water applied using gravity systems steadily declined from 71 percent to 41 percent of total applied water, with a corresponding increase in water applied with pressure-sprinkler systems. While the trend from gravity to sprinkler systems is observed over the entire 30-year period, the decline in gravity systems and concurrent expansion in sprinkler area and water use accelerated after the late 1990s. The extent and timing of these shifts, however, vary significantly across the Western States.\nCSP provides payment to maintain existing conservation activities, add additional activities, and to adopt a resourceconserving crop rotation (USDA Natural Resources Conservation Service, 2017d). Between 2006 and 2016, the number of acres that received EQIP payments for cover cropping more than quadrupled (from 240,418 to 1,120,311), while annual spending on cover crops increased more than tenfold. Between 2010 and 2015, the number of acres receiving CSP payments for at least one soil health practice or enhancement grew from just under 7 million to more than 30 million ( fig. 3.19.5). Note: These data include only active and completed contracts. For contracts that included more than one land unit and/or more than one soil health practice or enhancement (of the 100 practices or enhancements we considered to be related to soil health), we used the maximum value of the planned acres for each land unit that had at least one soil health practice/enhancement applied (to avoid double counting). Source: USDA, Economic Research Service calculations using USDA, Natural Resources Conservation Service, ProTracts database. Chapter 3.20-Pollinators: Honey Bee Status and Trends Daniel Hellerstein, Claudia Hitaj, and David Smith \u2022 Of the 2.7 million honey bee colonies in the United States in 2017, 87 percent were managed commercially. \u2022 Since the early 2000s, annual honey bee colony loss has fluctuated between 30 and 45 percent, versus a historical average of 15 percent. \u2022 Almost half (44 percent) of honey bee colonies spend summer in the Northern Plains States of Montana, North and South Dakota, and Minnesota, where forage resources declined between 2002 and 2012. About one-third of the world's food crops depend on insect pollinators-including managed honey bees and more than 4,000 species of native bees and other insects (USDA-NRCS, 2017). Some crops, such as almonds and melons, require insect pollination to produce nuts or fruit; others, such as tomatoes and apples, receive a yield boost from insect pollination. Production of pollinated crops increased rapidly in the past decade. Between 2007 and 2016, the production value of almonds grew by 85 percent in real terms, while the production value of both apples and blueberries grew by about 15 percent. Estimates of the economic value provided by pollinators vary widely, with low estimates (in the hundreds of millions of dollars) considering only direct payments to beekeepers and higher estimates (as high as $19 billion) considering the maximum potential for lost agricultural production absent honey bees. An intermediate value of $15 billion is often cited (Pollinator Health Task Force, 2016). 1 Of 2.7 million honey bee colonies in the United States in 2017 (USDA-NASS, 2018), about 87 percent were managed commercially by beekeepers with more than 500 colonies (Bee Informed Partnership, 2015). Honey bees provide an estimated 80 percent of pollination services (by value), with the rest provided by wild bees and other native pollinators (Losey and Vaughn, 2006). U.S. honey production from these colonies amounted to $336 million in 2016, along with $149 million in earnings from other products (including queen bees and beeswax) and $353 million from pollination services. Honey bees and other pollinators face a variety of stressors, including diseases, insect pests, nutritional deficiencies, pesticide exposure, and changing landscapes. These factors, which can have synergistic effects, can affect the productivity and survival of pollinators. Honey bee colony numbers peaked at 5.9 million in 1947. After declining to 2.3 million colonies in 2008, colony numbers have since increased to 2.7 million by 2016/2017 ( fig. 3.20.1). Despite a net increase in the number of managed honey bee colonies, annual losses of honey bee colonies have spiked over the last decade. Between 2006 and 2007, some 30 percent of honey bee colonies were lost during the overwinter period (October 1 through April 1), compared to a historical rate of 15 percent (Burgett et al., 2010). Though the overwinter loss rate has since diminished (21 percent in 2016-17), summertime losses have grown. The net result is that annual colony loss between 2012-17 averaged 40 percent, compared with 36 percent in 2010-11."}, {"section_title": "Sources of Agricultural Output Growth", "text": "In addition to long-term trends, ERS also examines the sources of agricultural output growth-apportioning increases in output among changes in inputs (both quantities and quality/composition) and TFPfor the entire period and in 12 subperiods (defined by business cycles in accordance with fluctuations in the overall U.S. economy) (table 1.5.1). Between 1948 and 2015, farms shifted to higher quality labor, mainly due to a more highly educated labor force. Increased labor quality made a positive contribution to output growth in 11 of 12 subperiods (table 1.5.1). On average, labor quality through changes in farm labor's educational attainment and other demographic characteristics contributed to output growth at 0.12 percentage points a year, offsetting part of the contraction in labor quantity. Still, over the entire period, the decline in overall labor input contributed negatively to output growth by nearly -0.5 percent per year. On the other hand, while the changes from durable equipment, service buildings, and inventory (capital, excluding land) made positive contributions to output growth in 9 of 12 subperiods, shrinking land use still made overall contribution of aggregate capital (including land) to output growth of -0.04 percentage points per year. Growth in intermediate goods contributed positively to output growth in 9 of 12 subperiods and accounted for about two-fifths of output growth for the entire period, offsetting negative contributions from labor and capital to output growth.  1948-2015 1948-1953 1953-1957 1957-1960 1960-1966 1966-1969 1969-1973 1973-1979 1979-1981 1981-1990 1990-2000 2000-2007 2007-2015  During 1948-2015, the net contribution of all inputs was 0.1 percentage point per year, leaving TFP growth the major source of output growth in all but the 1948-1953 and 1973-79 subperiods. Since the United States is one of the largest producers and consumers in the world agricultural commodity market, sustainable productivity growth in the U.S. farm sector is critical to global food security. Given that innovation fueled by R&D is the major driver of productivity growth (see chapter 1.6, \"Agricultural Research and Development,\" for more discussion), steadily growing investment in agricultural research is essential if agricultural production is to meet growing worldwide demand."}, {"section_title": "Sources of growth in U.S. farm sector, 1948-2015 (average annual growth rates in percent)", "text": ""}, {"section_title": "Chapter 1.6-Agricultural Research and Development", "text": ""}, {"section_title": "Paul Heisey", "text": "\u2022 Both private and public sectors help fund agricultural research and development (R&D), but due to its rapid growth, private spending is now much greater than public spending-which fell in real terms between 2006 and 2014. Private research spending on agricultural input R&D alone-not including food research-surpassed total public spending in 2010. \u2022 In 2014, the private sector funded over three-quarters of all food and agricultural R&D in the United States. \u2022 Public and private agricultural R&D investments are generally complementary rather than competitive. For example, in 2014, the private sector dominated farm machinery and food manufacturing research, while the public sector performed nearly all U.S. research on the environment/natural resources and human nutrition/food safety. The growth in agricultural productivity over the past seven decades (see chapter 1.5, \"Agricultural Productivity and Sources of Growth in the U.S. Farm Sector\") can be attributed largely to investments in agricultural research and technology development (OECD, 2016;Wang et al., 2013). Genetic improvements in crops and livestock, improved agricultural chemicals and fertilizers, more efficient agricultural machinery, and cost reductions in farm management techniques have transformed U.S. agriculture. As agricultural productivity has increased, the agricultural research portfolio has expanded to include areas such as the environment; the quality, safety, and nutritional value of food products; the treatment of farm animals; the livelihoods of farm workers; and the resilience of rural communities. These objectives have refocused public agricultural research to include the characteristics of agricultural products and the impacts of production methods, in addition to technology development. Corporate agribusiness has played an increasingly larger role in developing new technologies and providing services for agriculture."}, {"section_title": "Multiple Institutions Operate in a Complex System", "text": "Agriculture has benefited from a unique Federal-State partnership in agricultural research and extension, with a history of collaboration with the private sector. The funders of agricultural and food research include nongovernmental sources-primarily the private business sector, but also foundations and farmer organizations-that provided over three-quarters of the funding in 2014, or about $12.4 billion in real (inflation-adjusted) dollars. 1 The Federal Government-including USDA as well as other agencies such as the National Science Foundation (NSF) and the National Institutes of Health (NIH)-contributed $2.6 billion, and State governments just under $1 billion (fig. 1.6.1)."}, {"section_title": "Private-Sector Research Has Increased While Public Research Has Fallen", "text": "Historically, public institutions played a direct role in developing new agricultural technologies and encouraging their commercialization and adoption by farmers. Advances in the biological sciences, broader intellectual property rights protection, and expansion of agricultural markets have stimulated private-sector R&D. Since about 1980, growth rates in public R&D have been generally low ( fig. 1.6.2). Growth in private investment has generally been higher, but with greater variation. In the early 2000s, public and private agricultural research investments began to diverge more rapidly. Total private agricultural and food R&D doubled between 2003 and 2014, while public R&D fell. By 2010, private R&D for agricultural inputs alone surpassed the public level for all agricultural research.  "}, {"section_title": "Focus of Private and Public R&D Differs", "text": "In many ways public and private agricultural research efforts are complementary rather than competitive. Little incentive exists for private firms to pursue research whose results benefit society as a whole rather than the specific innovator. The incentives that encourage firms to fund and perform R&D are private returns (i.e., the economic benefits from new products and technologies that can be captured through market sales). But companies cannot capture all the potential economic benefits from R&D activities. Some benefits may accrue to farmers as lower production costs even after higher prices from new technologies have been taken into account. Some R&D benefits may go to consumers in the form of safer or cheaper food. Benefits may go to other firms that develop related applications from the scientific information generated, even from other private research, as private research is only partially protected by intellectual property like patents or by trade secrets. Still other benefits are enjoyed by society as a whole, in the form of better health or improved environmental quality. The social returns (benefits to society as a whole) from many kinds of research can be much higher than their private return. Thus, the private sector focuses mainly on R&D related to marketable goods and technologies. The food industry, which has little impact on agricultural productivity, accounts for the largest category of private agricultural R&D. Much food industry R&D is directed toward product development and marketing research. The private sector also dominates farm machinery research. On the other hand, public-sector research addresses applied areas with large social benefits, such as environmental protection, nutrition, and food safety ( fig. 1.6.3).  Both private-and public-sector R&D is directed at the broad general areas of plant and animal research. Private plant research has grown very fast. In the mid-2000s public and private plant research expenditures were roughly equal; by 2014, private investment was over 2.5 times more than public investments in plant research. Within private plant research, crop seed and biotechnology investment has grown particularly rapidly. Gene transfer technologies have enhanced researchers' abilities to tailor crops for specific uses, such as resistance or tolerance to diseases, pests, herbicides, or environmental conditions such as drought (see chapter 2.7, \"Biotechnology and Seed Use for Major U.S. Crops\"). Broader intellectual property protection, such as the expansion of the right to patent crop varieties, has also stimulated private seed-biotechnology research investment. The share of private crop seed and biotechnology research has grown as the share of agricultural chemical research has fallen, in part because of the development of combined crop seed and agricultural chemical technologies, such as herbicide-tolerant varieties. New technologies such as gene editing may eventually enhance the development of improved crop varieties and livestock breeds even further. In the longer run, public and private research investments are complementary, even in the area of crop research, though there may be short-run substitution of public and private research funding. For some time, public crop breeders have focused more on \"basic plant breeding research\" and \"germplasm enhancement,\" while private-sector researchers concentrate on downstream development of cultivars that are marketed directly to farmers. As private-sector investment in crop research has grown, the public sector has reallocated its research portfolio toward more basic biological research or to other research for which private firms cannot capture all the benefits through the prices they charge. Public research generally operates on a longer timeframe as well, allowing it to address problems with lower probabilities of short-term payoff. U.S. agricultural productivity growth has been marked by large increases in aggregate output with almost no change in aggregate input use (see chapter 1.5, \"Agricultural Productivity and Sources of Growth in the U.S. Farm Sector\"). R&D has been a major driver of agricultural productivity growth (OECD, 2016), and the research-related changes in agricultural technology that have accompanied productivity growth have therefore influenced both input use and the environmental impacts of agriculture. "}, {"section_title": "Seth Wechsler", "text": "\u2022 Adoption rates for genetically engineered (GE) crops rose rapidly in the years following their commercialization in 1996. As of June 2018, approximately 9 out of every 10 acres of domestic corn, cotton, soybeans, sugarbeets, and canola were cultivated using GE seeds; approximately 80 percent of U.S. corn and 82 percent of cotton acreage was planted with seeds that were \"stacked,\" or genetically engineered to be both herbicide tolerant (HT) and insect resistant (Bt). \u2022 The commercialization of Bt crops led to a decrease in synthetic soil-applied and foliar insecticide use; for example, insecticide use among U.S. corn farmers fell by over 80 percent from 1996 to 2017. \u2022 Initially, the commercialization of HT crops led to increases in glyphosate use and decreases in the use of other herbicides. Recently, the use of glyphosate, and the use of herbicides other than glyphosate, has increased-largely due to the development and spread of glyphosate-resistant weeds."}, {"section_title": "Adoption Rates for Genetically Engineered Crops Rose Rapidly in the Early 21st Century", "text": "Building on the results of public biomedical research, large life-science companies invested millions of dollars in efforts to develop profitable crop biotechnologies throughout the 1980s. These efforts culminated in 1996 with the commercialization of genetically engineered (GE) corn, soybean, and cotton crops. GE canola was commercialized in 1998. GE alfalfa and sugarbeets were commercialized in 2005. Herbicide-tolerant, or HT, crops are not damaged when they are sprayed with broad-spectrum herbicides (such as glyphosate or glufosinate) that damage most conventional varieties. Planting HT crops allows farmers to use nonselective, broad-spectrum herbicides throughout the growing season (even after crop emergence). Insect-resistant crops contain genes from a soil bacterium (Bacillus thuringiensis) that produces a naturally occurring insecticide. Unlike conventional insecticides, which can be leached from soils or adversely affected by soil pH, the toxins produced by Bt crops are concentrated in plant tissues. So, planting Bt crops helps ensure that insects are controlled throughout the growing season. Adoption rates for GE crops rose rapidly in the decade following their commercialization. As of 2017, approximately 9 out of every 10 acres of corn, cotton, soybeans, sugarbeets, and canola produced in the United States were cultivated using HT seeds (figure 2.7.1). Approximately 8 of every 10 acres of corn and cotton acres were cultivated using Bt seeds (figure 2.7.2). Although other GE traits have been developed (such as virus, fungus, cold, and drought resistances), crops with HT and Bt traits are the most prominent of the commercially available, genetically engineered varieties. Most GE corn and cotton seeds are \"stacked\" with both HT and Bt traits. As of 2017, approximately 80 percent of U.S. corn and cotton acreage was planted with stacked seeds (figure 2.7.3).  "}, {"section_title": "GE Seed Use Affects Farmers' Pest Control Decisions, Yields, and Operating Costs", "text": "Choosing to plant GE seeds can alter farmers' revenue, operating costs, and input use. These impacts vary by crop and production system. However, certain trends are particularly striking. Planting Bt crops tends to increase yields (when insects are present) and decrease insecticide use. For instance, Wechsler and Smith (2018) found that planting rootworm-resistant corn increased U.S. farmers' yields by over 6 bushels per acre (approximately 4 percent) in 2005 and 3 bushels per acre (approximately 2 percent) in 2010, while reducing insecticide use dramatically. From 1996 to 2017, insecticide use among U.S. corn and cotton farmers fell by over 80 percent (figure 2.7.2). In some cases, the widespread use of Bt seeds has suppressed local pest populations (Hutchison et al., 2010). These reductions have benefited many U.S. farmers (not just those planting Bt seeds) and may have contributed to further decreases in insecticide use. After World War II-which led to the development of growth-regulating herbicides like 2,4-D-and prior to the development of HT varieties, U.S. farmers achieved high levels of weed control using crop rotations, tillage, and herbicide applications. Perhaps because U.S. farmers effectively managed weeds prior to the commercialization of HT seeds, there is mixed evidence as to whether HT adoption increases farmers' yields. For instance, Nolan and Santos (2012), who analyzed field trial data from 2002 to 2007, found no difference in yields on fields planted with HT or conventional corn seeds. Shi, Chavas, and Lauer (2013) found that average corn yields were actually lower on fields planted with HT seeds than on fields planted with conventional ones. There is evidence that planting HT crops simplifies weed management systems, and that this simplification confers time and labor savings to farmers (Gardner et al., 2009). Fernandez-Cornejo, Hendricks, and Mishra (2005) find that HT adoption is associated with increases in off-farm income. However, time and labor savings can also be employed on the farm, and may partially explain increases in farm size over time. There is evidence that HT adoption benefits farmers by reducing their reliance on tillage for weed control (Fernandez-Cornejo et al., 2012). Reducing tillage can lower fuel, equipment, and labor costs. It can also improve soil structure and increase water infiltration, while reducing soil erosion and nutrient runoff (Wade, Kurkalova, and Secchi, 2016). The rapid adoption of HT technologies, and their ubiquity in domestic field crop production, suggests that U.S. farmers benefit from the use of herbicide-tolerant seeds, especially since HT (and Bt) seeds are more expensive than their non-GE counterparts. It is clear that the herbicides used in HT production systems (the vast majority of which are formulations of an active ingredient called glyphosate) provide excellent post-emergent weed control (Wechsler, McFadden, and Smith, 2017). The use of herbicides other than glyphosate decreased by approximately 65 percent over this time period. 1 Many scientists perceived that this shift had environmental and human health benefits because glyphosate is less toxic than many of the herbicides it replaces (Duke and Powles, 2008) Though herbicide application rates initially declined following the commercialization of HT corn and cotton, these rates have increased over the course of the last decade, in part due to the development and spread of glyphosate-resistant weeds (see chapter 2.8, \"Pest Management\"). Herbicide application rates increased by over 95 percent on soybeans and over 68 percent on canola from 2006 to 2017 (figure 2.7.1). Recently, new varieties of GE seeds that are tolerant of the herbicidal active ingredients dicamba and 2,4-D have been commercialized. It remains to be seen how the introduction of these technologies will affect the herbicide use and weed control decisions of U.S. farmers. 1 Figure 2.7.3 "}, {"section_title": "Share of acres planted with stacked seeds has increased over time", "text": ""}, {"section_title": "Chapter 2.8-Pest Management", "text": ""}, {"section_title": "Richard Nehring", "text": "\u2022 In 2012, U.S. producers spent over $9 billion on pesticides to control pests such as insects, mites, and weeds. \u2022 The development of herbicide resistance in several weed species has contributed to increased recent herbicide use. From 2010 to 2014, herbicide application rates (per planted acre) rose by 24 percent on U.S. soybeans, 26 percent on wheat, 25 percent on cotton, and 21 percent on corn. \u2022 Weed resistance to newer herbicides has led to expanded use of some older herbicides. Pests-such as insects, mites, and weeds-can reduce crop yields or the quality of production, while the cost of managing pests can reduce farm profitability. To control pests, farmers rely on pesticides like herbicides, insecticides, and fungicides; pesticides also include soil fumigants, plant growth regulators, defoliants, and desiccants. Pesticides can be synthetic (developed in laboratories and manufactured) or natural (chemical compounds occurring in nature)."}, {"section_title": "Pesticide Trends", "text": "According to U.S. Environmental Protection Agency (EPA) data, U.S. agricultural producers spent over $9 billion on 899 million pounds of pesticide active ingredient in 2012. That was about 32 percent more (in inflation-adjusted terms) than was spent in 2007, and 10 percent more pounds of pesticide active ingredient. Corn accounted for 46 percent of all pesticides (by weight) applied to the five major crops in 2014, and hence nearly one-third of all pesticide applications. The second largest crop, soybeans, accounted for another 31 percent of pesticides applied in 2014. 1 Throughout this chapter, we aim to use the latest data available for the selected series at the time the report was prepared. Because of changes in the data sources and methodology used in EPA source documents, pesticide expenditures reported here for 2007 differ substantially from those reported for 2007 in the 2012 Agricultural Resources and Environmental Indicators report (USDA, Economic Research Service)."}, {"section_title": "2", "text": "Pesticide applications are often reported in pounds of active ingredient. The same quantities of different pesticides may have differing levels of toxicity, modes of action, target pests, and environmental impacts; hence, not all pounds are the same. Nonetheless, aggregated quantity data are widely reported and provide a useful base for tracking applications, while taking account of changes in pesticide attributes.  Changes in pesticide use follow from several factors: changes in the mix of crops produced (with a substantial shift of acreage to corn and soybeans after 2000); the widespread adoption of genetically engineered crops, which led to reductions in insecticide use and changes in the types of herbicides used; the availability of new chemical compounds with lower application rates; boll-weevil eradication in cotton-producing States, which reduced insecticide use; and shifts in input prices, which encouraged greater pesticide use. 4 Between 1980 and 2016, pesticide prices rose by 87 percent while farm wages rose by 200 percent; the shifts in relative prices encouraged farmers to adopt practices that reduced the use of labor and increased the use of pesticides and equipment (figure 2.8.3).  1982 1984 1986 1988 1990 1992 1994 1996 1998 2000 2002 2004 2006 2008 \nIrrigated farms with horticultural crops grown under protection (e.g., greenhouses) account for the majority (73.3 percent) of sales from all irrigated horticulture farms.\nThe 2017 wheat and 2012 soybean survey asked only about no-till. The 2015 cotton and 2016 corn surveys asked whether no-till or strip-till was used. Note: \"No-till\" means planting without tilling since the previous harvest. \"Strip-till\" means tilling only a narrow strip over the row (used only in row crops). \"Full-width\" tillage is tilling the entire soil surface. For each survey, respondents are asked whether no-till or striptill was used in each year over a 4-year period. For example, \"continuous\" no-till or strip-till means that no-till or strip-till was used in each year of the 4-year period. Source: USDA, Economic Research Service and USDA, National Agricultural Statistics Service, Agricultural Resource Management Survey, 2012Survey, , 2015Survey, , 2016, and 2017.\nThe Farm Service Agency defines land in \"wetland restorations\" as acreage enrolled in conservation practices CP9, CP23, CP23A, CP30, CP31, CP37, and CP38 wetland and land enrolled in the Farmable Wetlands Program. These include both wetland and associated upland buffers.  The Wetlands Reserve Program (WRP), initiated by the 1992 Farm Act and terminated by the 2014 Farm Act, restores and protects wetlands through the purchase of 30-year and permanent easements. Landowners forgo the land's agricultural use and must maintain the health of the wetland ecosystem. While the land can be sold, the easement remains in effect. Over the WRP's more than 20-year life, nearly 2.7 million acres were enrolled. Approximately 93 percent (about 2.5 million acres) are, and will continue to be, protected by permanent easements. The 30-year easements will begin to expire in 2023. In the WRP's final 4 years, its annual financial obligations ranged from $414 to $696 million (2016 dollars). The obligations include easement purchases, wetland restoration costs, and technical assistance. WRP obligations after 2013 support actions on easements enrolled before the 2014 Farm Act. The Agricultural Conservation Easement Program (ACEP), created by the 2014 Farm Act, consolidated three former conservation easement programs: the WRP, the easement portion of the Grassland Reserve Program, and the Farm and Ranch Land Protection Program. In its first 3 years, ACEP's annual financial obligations were somewhat stable, ranging from $317 to $346 million. But obligations rose sharply to $536 million in FY 2017. ACEP restores and protects wetlands through its Wetlands Reserve Enhancement Partnership (WREP). Like the WRP, the WREP is voluntary and seeks to permanently restore, protect, and enhance wetland ecosystems. The WREP enrolled 91,800 acres in 2017, about 80 percent more than its 2014-2016 average annual enrollments (table 3.22.2). While this jump was substantial, the WREP's 2017 enrollment is a little less than three-quarters of the WRP's lifetime annual average enrollment of over 130,000 acres. The growth in annual ACEP enrollments is much more substantial than its WREP component-ACEP enrollment in 2017 was nearly triple the 2014 enrollment. This rise was largely due to a quadrupling in non-WREP enrollments. Other Federal agencies support wetland conservation. For example, the U.S. Fish & Wildlife Service (FWS), through its Small Wetlands Acquisition Program, has acquired permanent, limited-interest wetland easements on nearly 3 million farmland acres in the Prairie Pothole Region since the program's beginning in 1958. By accepting an FWS easement, a landowner agrees to not convert the eased wetland to agricultural use but may continue current land uses.\nDuring each general signup, a threshold score is set after all offers are received and scored. Thus, setting a threshold score effectively determines what share of offers are accepted. The overall decline in CRP acreage has been driven by reductions in the acreage enrolled via CRP's general signup. However, acres enrolled through \"continuous signups\"-including land in one of the many State-Federal conservation partnerships under the Conservation Reserve Enhancement Program (CREP) -has steadily increased. Continuous signups target high-priority environmental concerns. In contrast to general signups, which use offer attributes (such as the asking price and the parcel's soil erodibility) to rank offers, continuous signups accept all offers that meet more stringent eligibility requirements, including location and the conservation practice to be installed. From its inception in 1999, acres enrolled through continuous signup has steadily increased, with over 2.6 million acres in 2003, 3.9 million acres in 2007, and over 5.3 million acres in 2012. As of July 2018, 35 percent of CRP land (8.1 million acres) was enrolled via continuous signup. This includes about 399,000 acres of farmable wetland, and about 989,000 acres under CREP. CREP comprises over 45 Federal/State partnerships designed to address specific environmental objectives through targeted CRP enrollments. Acres enrolled via CREP increased from about 530,000 acres in 2003 to 980,000 acres in 2007 to 1.25 million acres in 2011, before declining to around 1.06 million acres by September 2017. Beginning with the 2002 Farm Act, total funding for EQIP increased to over $800 million per year and has remained at comparable levels in subsequent Farm Acts (figure 3.24.1). Total authorized funding for 2014-18 is $6.35 billion, 60 percent of which is targeted to natural resource concerns related to poultry and livestock production. The remainder is directed toward practices that address conservation priorities on working cropland. A minimum of 5 percent of EQIP funding is specified for wildlife habitat. The goals of CSP are to encourage producers to address resource concerns in a more comprehensive manner by: (1) undertaking additional conservation activities; and (2) improving, maintaining, and managing existing conservation activities. The key to addressing these goals in CSP is the use of conservation \"enhancements,\" which are either improved versions of traditional conservation practices or specified bundles of practices. To participate in CSP, farmers and ranchers must, at a minimum, have already addressed at least one resource concern throughout their property and agree to address at least one additional priority resource concern during the 5-year contract term. CSP is considered a \"pay for performance\" program in that it scores contracts based on an estimate of conservation performance and provides higher payment levels for higher performance. More recently, CSP has moved toward payment rate structures that reflect the different levels in costs and performance across types of practices and enhancements. Following the 2014 Farm Act, funding for CSP increased to EQIP-comparable levels ( fig. 3.24.1). Relative Role in the Landscape While EQIP and CSP now have similar levels of funding, their different structures mean that they serve slightly different types of farms and have slightly different roles across the landscape. Based on data from the 2016 Agricultural Resource Management Survey (ARMS), a smaller share of farms, less than 2 percent, was participating in EQIP (table 3.24.1). The average EQIP participant reported receiving about $18,000 in financial assistance in the survey year, with the average contract covering practices that treat 223 acres; the average CSP participant reported receiving about $15,000 in financial assistance on 554 acres. Since these numbers are self-reported in a producer survey, these averages are slightly different than participation rates calculated based on NRCS administrative data. While there are several reasons that the two data sources differ, both types of data indicate that EQIP covers fewer total acres but provides a higher average payment per contract or per treated acre. "}, {"section_title": "Herbicide Trends", "text": "Herbicides are the dominant type of pesticide applied in the United States. Herbicide quantities applied to the five major crops trended downward between 1982 and 2002, from 435 to 288 million pounds, but then grew to 511 million pounds by 2014. In turn, the herbicide glyphosate accounted for a growing share of all herbicides used. In contrast, insecticide quantity has trended downward since 1982. Herbicides can be grouped into several categories. In the 1960s through 1980s, the major herbicide classes were amides, anilines, carbamates, phenoxys, and triazines. Some of these \"old-line\" herbicides commonly used in U.S. crop production include 2,4-D, atrazine, and acetachlor. In the 1980s and 1990s, herbicides based on ALS inhibitors-and to a lesser extent Acetyl-CoA carboxylase (ACCase) and Protoporphyrinogen oxidase (PPO) inhibitors-were introduced. \"New-line\" herbicides commonly used in U.S. crop production include acifluorfen, clethodim, and glufosinate (see Osteen and Fernandez, 2016, for a more complete list). Last, glyphosate-first sold commercially in 1974-is considered new line, but is in a group of its own to reflect its relative importance."}, {"section_title": "4", "text": "The cotton boll weevil (Anthonomus grandis Boheman) has been eradicated from all cotton-producing States, except for a part of Texas (USDA, APHIS, 2013). See also Southwest Farm Press (2017) for recent progress in the eradication program. Major factors affecting overall herbicide use trends since 1980 include: 1. Changes in crop acreage, influenced by economic and policy factors; 2. The replacement of older compounds with newer ones that are applied at lower per-acre rates; 3. The adoption of genetically engineered crops since the mid-1990s (see chapter 2.7, \"Biotechnology, Seed Use, and Pest Control for Major U.S. Crops\"); and 4. Evolution of herbicide resistance in weeds."}, {"section_title": "Changing Mix of Herbicide Types Used in the United States", "text": "Since new-line herbicides are generally applied at lower rates, their increasing use, together with declining crop acreages through the late 1980s, contributed to declines in aggregate herbicide quantities applied between 1982 and 2002 (Osteen and Fernandez, 2016). The year 1996 saw the introduction of corn, cotton, and soybean seeds that were genetically engineered to be tolerant of the broad-spectrum herbicide glyphosate, sold under the Roundup label. This allowed farmers to spray the herbicide on field after the crop emerged, thus easing weed management for farmers. Glyphosate was quite effective at controlling a wide range of weeds; it was less environmentally damaging than old-line herbicides; and the herbicide's price also fell sharply after it went off-patent in 2002. The expansion of corn, cotton, and soybean acres planted to glyphosate tolerant seeds accelerated rapidly, and led to the displacement of other herbicides by glyphosate. Glyphosate use in the U.S. agricultural sector increased sevenfold between 1995 (the year before glyphosate-tolerant seeds were introduced) and 2014. Heavy reliance on a single mode of weed control encourages the spread of weeds that are resistant to that mode, as resistant individual weeds survive and propagate Owen, 2015). The heavy, and often exclusive, reliance on glyphosate in many areas led to the rapid emergence and spread of glyphosate-resistant weeds, but there is evidence that weeds are developing resistance to other herbicides as well (Heap, 2015; Owen, 2015). Farmers responded to growing weed resistance by increasing their use of other old-and new-line herbicides, but also by increasing their application rates for glyphosate. (Peterson et al., 2018). From 2010 to 2014, glyphosate use increased by 41 million pounds, but use of old-line herbicides increased by 51 million pounds. By 2014, while glyphosate was still the largest-selling herbicide product, old-line herbicides as a group accounted for half of herbicide quantity applied. Application rates (for all herbicides) increased by 20 percent from 1.67 pounds per acre in 2010 to 1.92 pounds in 2014, reflecting more intensive use. We can track the use of old-line herbicides, glyphosate, and other new line herbicides for the four major herbicide-using crops-corn, cotton, soybeans, and wheat. We illustrate the share of herbicide-treated acres receiving each kind of herbicide in figure 2.8.4 and the shares of each herbicide type in total herbicide applied (by weight) in figure 2.8.5. Finally, we track average application rates, per acre treated with herbicide, in figure 2.8.6. Several patterns stand out: \u2022 Glyphosate was used more widely and intensively in soybeans than in corn, cotton, or wheat (figure 2.8.4 and figure 2.8.5). \u2022 All four crops show a decline in the share of acres treated with glyphosate in recent years: after 2010 (corn and cotton) or 2012 (soybeans and wheat, figure 2.8.4). \u2022 Looking at shares of herbicides applied by weight ( fig. 2.8.5), the prevalence of glyphosate use increased slightly for corn, rose for wheat, and fell for cotton and soybeans in the most recent year for which data were available. \u2022 Old-line herbicides increased their share of total pounds applied for both cotton and soybeans, stabilized in corn, and decreased in wheat (figure 2.8.5). \u2022 Application rates increased persistently for each of the four crops after 2002 (figure 2.8.6). Old-line treatment acres New-line treatment acres Glyphosate treatment acres"}, {"section_title": "Cotton Wheat Soybeans Corn", "text": "Note: Years displayed reflect years of survey data availability, which vary by crop. The final year of data displayed (2016 for corn, and 2015 for cotton, wheat, and soybeans) reflects the latest USDA NASS survey years for that crop. Old-line herbicides were in families first observed in the 1964, 1966, or 1971 surveys; glyphosate was first observed in the 1976 survey; and new-line herbicides were in families or modes of action (MOAs) first observed in the 1976 or later surveys (Fernandez and Osteen, 2016). Source: USDA Economic Research Service using data from USDA, National Agricultural Statistics Service (NASS), Quick Stats.   "}, {"section_title": "Summary", "text": "Herbicides account for the vast majority of pesticide applications by U.S. farmers. Patterns of herbicide use have shifted in recent years. Total application of herbicides has increased in the last decade, after showing little trend for nearly 25 years. The resurgence of old-line herbicides is evident as producers struggle with herbicide resistance in weeds caused by recurring use of the same chemicals, such as glyphosate (Arp, 2017). In short, herbicide-use patterns differ by crop, with variations in the mix of old-line and new-line (including glyphosate) herbicide use driven by weed resistance and other factors."}, {"section_title": "Chapter 2.9-Nutrient Management", "text": "Roberto Mosheim \u2022 Commercial fertilizer consumption was about 22 million short tons in 2015, recovering from the 18-percent drop between 2008 and 2009. \u2022 Since 1997, nitrogen recovery rates (the share of applied nutrient taken up by the harvested crop) on corn, winter wheat, and cotton have hovered around 70 percent, while recovery rates for phosphate have remained around 60 percent. \u2022 The shares of planted acreage where application rates exceed 125 percent of the crop's agronomic need (a measure of nutrient overapplication) have decreased for both nitrogen and phosphate. This chapter examines the key technological and economic drivers of plant nutrient consumption and trends in nutrient use efficiency. 1 There is a complex interaction between fertilizer use and subsequent benefits and costs. On the one hand, crop plants require inorganic nutrients such as nitrogen, potash, and phosphate for crop production. On the other hand, excessive application of nutrients can damage air and water resources through soil erosion, runoff, volatilization, and leaching (Ribaudo et al., 2011). When fertilizer applications are warranted for crops, the application of excess nutrients can be reduced by implementing what USDA's Natural Resources Conservation Service 2 and The Fertilizer Institute promote as the 4Rs. The 4Rs direct farmers to apply nutrients using the right source of nutrients (matching fertilizer type to crop needs), at the right rate (matching amount of required fertilizer(s) to crop needs), at the right time (making nutrients available when crops need them most), and in the right place (applying nutrients where crops can use them) (The Fertilizer Institute, 2017). The 4Rs can increase profitability-by reducing fertilizer expenses and by better targeting its use to raise yields-and reduce the undesirable environmental impacts of excessive nutrient use. 3"}, {"section_title": "Variability in the Use of Nutrients", "text": "Commercial fertilizer use surged from 7.46 million short tons 4 in 1960 to a peak of 23.68 million short tons in 1981 (figure 2.9.1). Total commercial fertilizer consumption of nitrogen, phosphate, and potash increased as more acres were devoted to high-yield crop varieties and as developed hybrids responded well to more intensive use of commercial fertilizer (EPA, 2017b). Total applications of nitrogen, phosphate, and potash use on corn, soybeans, and wheat increased from 1964 to 1981 but declined for cotton. The expansion of total nutrient use through 1981 reflects expanded acreage (except cotton acreage, which fell slightly), increases in application rates, and a higher share of acres receiving fertilizer. This long expansion in fertilizer use ended in 1982. Since then, fertilizer use has 1 Data sources include the most current data from USDA-ERS Fertilizer Use and Price data products, based on \"Commercial Fertilizers, 2015\" published in October 2018, and the latest commodity-specific Phase II surveys-corn, 2016; cotton, 2015; soybeans, 2012; and winter wheat, 2017.  The implementation of the 4Rs conforms with precision agriculture. For example, Schimmelpfennig (2016), Snyder (2016), and Bruulsema (2017) examine technologies such as global positioning system (GPS) mapping, grid or zone soil sampling, yield monitors, and variable-rate technology (VRT) that can improve nutrient use and reduce environmental risk (see chapter 2.11, \"Precision Agriculture\"). fluctuated over time in line with changes in cropping system implementation and fertilizer/crop prices, but has shown no persistent trend. Lower fertilizer prices generally meant increased fertilizer use until the energy crisis of 1973, when fertilizer prices jumped temporarily to their highest level ever. Still, nutrient use kept increasing (figure 2.9.2). 5 Commercial fertilizer prices slid until 2002, when they bottomed out at $247 per ton-historically, the lowest (inflation-adjusted) average fertilizer price for which data are available. Since 2002, fertilizer prices have fluctuated significantly, with no clear effect on fertilizer use. Domestic fertilizer demand does not affect fertilizer price, but global events in energy markets do. For example, movements in key fertilizer feedstock prices like natural gas affect fertilizer prices and, in turn, demand. A key event, the global economic crisis of 2008/2009, put downward pressure on natural gas prices, which in turn reduced fertilizer prices. Fertilizer prices fell 18 percent from 2008 to 2009 (fig. 2.9.2) and fertilizer use dropped 14 percent because of reduced global incomes. 6 By 2015, fertilizer use and price were back to pre-crisis levels. Fertilizer prices have fallen relative to 2015, but nitrogen fertilizer prices appear to have stabilized thus far in 2018 (Schnitkey, 2017 and."}, {"section_title": "5", "text": "USDA-ERS constructed a price index for fertilizer using the prices (see USDA-NASS, Agricultural Prices, 2017) of anhydrous ammonia, urea 44-46 percent nitrogen, ammonium nitrate, sulfate of ammonium, and super-phosphate 44-46 percent phosphate. USDA-NASS stopped publishing these prices in 2015. The price data were deflated by the Consumer Price Index (2016 = 100). 6 Shane et al. (2009) document the effects of the 2008/2009 world economic crisis on U.S. agriculture. An increase in natural gas production came after the ascendancy of horizontal drilling and hydraulic fracturing in the United States-in October 2011, hydraulically fractured wells became the predominant method for new United States oil and gas development (EIA, 2018). In turn, the increase in the supply of this crucial raw material in the manufacture of nitrogen fertilizer put downward pressure on fertilizer prices at the cost, however, of an increased risk of environmentally damaging drinking water resources (EPA, 2016). The above interactions between fertilizer prices and quantity are important from an environmental perspective. For example, how responsive is fertilizer demand to movements in fertilizer price? The literature (Roberts and Heady, 1982;Yang and Shumway, 2015) finds that the sensitivity of fertilizer demand to fertilizer price is very small (within its historic price ranges). Meanwhile, domestic fertilizer prices are highly dependent on prices determined in the international market, including the price of natural gas, a crucial raw material in the manufacture of ammonia, which in turn is fundamental to inorganic nitrogen fertilizer. Weak demand response to price affects implementation of best practices in the application of fertilizer and influences policies designed to contain the environmental damage from the overapplication of nutrients.  1960 1966 1972 1978 1984 1990 1996 2002 2008 2014 Fertilizer use \nFor more detailed information on U.S. irrigated agriculture characteristics by farm-size class, see the ERS data product \"Irrigated Agriculture in the United States.\" increased water demands due to rising evapotranspiration rates and potentially greater frequency and severity of drought (Georgakakos et al., 2014). In most river basins of the Western States, surface-water supplies are fully appropriated, and opportunities for large-scale water-supply development are limited. These trends, taken together, are expected to intensify competition for existing water allocations, heightening the importance of water conservation for a sustainable irrigated agriculture sector."}, {"section_title": "Nutrient Recovery Rates Remain Constant for Most Crops", "text": "A well-designed nutrient management plan decreases nutrient expenses and lowers the environmental impact of nutrient use. Nutrient recovery is the ratio of the amount of nutrient in the harvested crop to the amount of nutrient applied (Huang and Beckman, 2012). Partial recovery occurs when the amount applied exceeds the amount that plants can absorb, resulting in environmental loss. The partial recovery index varies between 0 and 100, with 0 being the least efficient and 100 being the most efficient use of applied nutrients. Figures 2.9.3 and 2.9.4 show nitrogen and phosphate recovery ratios for corn, winter wheat, cotton and soybeans. 7 For corn, nitrogen efficiency increased from 58 percent in 1997 to 76 percent in 2015; for winter wheat, it increased from 56 percent in 1997 to 71 percent in 2016; for cotton, it increased from 58 percent in 1997 to 68 percent in 2014; and for soybeans it increased from 43 percent to 46 percent between 2005 and 2011. 8 Phosphate recovery increased from 60 percent in 1997 to 65 percent in 2015 for corn, but decreased from 64 percent (1997) to 60 percent (2016) for winter wheat. For cotton, phosphorus recovery increased from 58 percent in 1997 to 66 percent in 2014, with much variability in between. Phosphate recovery for soybeans fell from 74 percent in 2005 to 58 percent in 2011. This last result, however, is based on only 2 years of observations. Nutrient use efficiency increases can be tied to the improved varieties of crops being grown-ones that have been bred for higher nutrient use efficiencies-as well as to improved crop management practices that enable more efficient uptake of the applied nutrients (e.g., more farmers are following the 4Rs).  Nutrients employed in these crops represented about 60 percent of the total amount of nutrients consumed in the United States. Available data were employed to generate comparable variables across time to generate meaningful nutrient trends. Also, 2000 was the last year when nutrient use data were collected for corn, soybeans, cotton, and wheat at the same time. Winter wheat production is about 10 percent of total wheat production. 8 Mourtzinis et al. (2018) conclude that nitrogen (N) management decisions have a measurable, but small, effect on soybean yield and that given the growing pressure for increasing food production, it is imperative to further examine all soybean N decisions (application method, timing, and rate) in terms of environmental and cropping system aspects. Farmers have mostly increased nutrient recovery rates across crops and have reduced the amount of land that uses excess nutrients. These efforts, in turn, have lowered the variability of adverse environmental outcomes across farmers. Empirical studies of environmental performance of nutrients in agriculture indicate that input combinations and the technology with which they are applied are factors that significantly affect environmental efficiency and productivity (Coelli et al., 2007). Moreover, practices such as crop rotation, use of precision agriculture tools, and monitoring nutrient uptake levels can help farmers boost production without increasing nutrient applications.  Chapter 2.10-U.S. Irrigated Agriculture: Farm Structure, Technology, and Conservation"}, {"section_title": "Glenn Schaible and Marcel Aillery", "text": "\u2022 Irrigated farms accounted for approximately 39 percent of U.S. farm sales for crop and livestock products and 50 percent of U.S. crop sales in 2012. Irrigation's importance is significantly higher in the more arid Western States, where 72 percent of U.S. irrigated acres were located and where irrigated farms accounted for nearly 60 percent of the region's farm sales and more than 70 percent of regional crop sales. \u2022 Most U.S. irrigated farms (64 percent) were low-sales farms (under $150,000 in annual farm sales); however, large-scale farms ($1,000,000 or more) accounted for 60 percent of irrigated acres, 62 percent of farm water applied, and 79 percent of irrigated farm sales. Per-farm sales in the United States averaged $514,400 for irrigated farms and $133,600 for dryland-only farms. \u2022 While irrigated agriculture has become more water-use efficient over time, future irrigation efficiency gains will depend increasingly on adoption of improved onfarm water-management practices in combination with high-efficiency irrigation application systems. Irrigated agriculture relies heavily on the Nation's water resources to provide an important contribution to the U.S. agricultural economy. Irrigation is the largest use of U.S. freshwater withdrawals (42 percent) and, historically, accounts for the largest share of the Nation's consumptive water use (some 80+ percent) (USGS, 2018(USGS, , 1998. Rising water demands and heightened water scarcity are likely to intensify pressures on agricultural water supplies. Technological change has driven an increase in agricultural water-use efficiency, and continued investment in water conservation across farms is expected to further increase efficiency gains, with potential benefits for farm-level returns, drought resilience, and water quality."}, {"section_title": "Defining Water Use", "text": "The U.S. Geological Survey estimates water withdrawals, or the quantity of water withdrawn from a water source (e.g., a river, lake, or aquifer) by U.S. economic sector (USGS, 2018). USDA's Farm and Ranch Irrigation Survey (FRIS) reports onfarm applied water use, based on producer estimates of the quantity of water applied to the field for a particular crop and onfarm irrigation application system (USDA, 2014b). Crop consumptive water-use refers to the quantity of water actually consumed (taken up) by the crop over its various growth stages for plant retention and evapotranspiration. Withdrawal estimates generally include conveyance losses from the water source, while estimates of field water applied do not. Consumptive-use estimates, as compared to crop consumptive use, may or may not account for associated system efficiency losses (e.g., evaporation, deep percolation, and runoff) and salt-leaching requirements, which can vary for a given crop, location, and irrigation system. Which estimate to use and how to use it are important in clarifying discussions of water use and policy. Roughly 56 million acres-or 7.6 percent of all U.S. cropland and pastureland-were irrigated in 2012. Among major U.S. field crops, irrigated acreage shares were highest for cotton (40.6 percent) and alfalfa hay (34.8 percent), followed by corn (14.7 percent), sorghum (12.2 percent), soybeans (9.4 percent), and wheat (6.9 percent). Irrigation is used on 36 percent of the acres in high-value specialty crops-fruits, vegetables, berries, and nuts-and also supports the livestock and poultry sectors through irrigated production of animal forage and feed crops. Much of the U.S. irrigated area is concentrated in the 17 Western States, 1 which accounted for 72 percent of U.S. irrigated acreage and nearly 70 percent of farm sales from all U.S. irrigated farms in 2012. In the West alone, irrigated farms generated nearly 60 percent of the region's total farm sales and more than 70 percent of regional crop sales. Horticulture crops generally include floriculture and bedding crops, propagative materials, mushroom crops, nursery crops, and sod. Many of these crops, as well as fruits and vegetables, are often grown in greenhouses (e.g., as horticultural crops under protection). Irrigated horticulture farms accounted for $16.5 billion in U.S. farm sales in 2012, representing about 12.1 percent of farm sales for all irrigated farms. Farm sales from irrigated horticulture farms are concentrated largely in California (20.2 percent of U.S. irrigated horticulture farm sales in 2012), Florida (11.9 percent), Texas (6.3 percent), Oregon (5.5 percent), and North Carolina (4.6 percent). 2 1 Washington, Oregon, California, Idaho, Nevada, Arizona, Montana, Wyoming, Colorado, Utah, New Mexico, North Dakota, South Dakota, Nebraska, Kansas, Oklahoma, and Texas."}, {"section_title": "Location of U.S. Crop Irrigation", "text": "Agricultural census data illustrate the distribution of U.S. irrigated agriculture in 2012 ( fig. 2.10.1), as well as the change in irrigated acreage over time. From 2002 to 2007, U.S. irrigated acreage expanded by nearly 1.3 million acres (2 percent), with Nebraska accounting for 72 percent of the increase. Most of the remaining area expansion occurred in the Mississippi Delta and Southeast regions (primarily Arkansas, Mississippi, and Georgia). From 2007 to 2012, irrigated area declined by nearly 0.8 million acres nationally, with acreage contractions exceeding 10 percent in Texas, Colorado, Oregon, New Mexico, and Oklahoma, due in part to drought conditions that contributed to water-supply shortages. From 2007 to 2012, irrigated area in the Eastern States expanded by roughly 8 percent. The five leading irrigation States in 2012 accounted for slightly more than half of irrigated acres nationally. Nebraska had the largest share of U.S. irrigated area with 8.3 million acres (15.1 percent of the national total), followed by California at 7.9 million acres, Arkansas at 4.8 million acres, Texas at 4.5 million acres, and Idaho at 3.5 million acres.  "}, {"section_title": "Acres of irrigated land, 2012", "text": ""}, {"section_title": "Water Use by Type of Agriculture and Trends by Irrigation Technology", "text": "Based on USDA's most recent survey of irrigated farms-the 2013 Farm and Ranch Irrigation Survey (FRIS)-U.S. irrigated farms applied 88.5 million acre-feet (maf) of water in 2013 (USDA, 2014b). The vast share of water used for agriculture is associated with irrigation water applied to field-crop and specialty-crop production on open fields, accounting for roughly 98.0 percent of the U.S. total. 3 Total farm water applied has been relatively stable over time for the 17 Western States, ranging from about 74.3 maf in 1984 to 75.8 maf in 2013 ( fig. 2.10.2). Estimated irrigated acres in the West have also been relatively stable, ranging from about 39.1 to 39.6 million acres during the same time period. While the aggregate average annual rate of applied water has held fairly constant (at about 1.9 acre-feet (af) per acre), dynamic factors influencing agricultural water demand-including changes in irrigated area and cropping patterns, higher crop yield and water consumptive use, shifts in withdrawals by water source, and rates of irrigation technology adoption-have varied across the West. Note: Water-use information from USDA's FRIS reports onfarm water applied, not withdrawals. Also, the area tracked includes only acres irrigated in the open. It excludes area (square-feet) under protection on horticulture operations. Source: USDA, Economic Research Service using USDA, National Agricultural Statistics Service 1984, 1988, 1994, 1998, 2003, 2008 data."}, {"section_title": "Farm-Size Characteristics of Irrigated Agriculture", "text": "Most irrigated farms are low-sales farm operations with under $150,000 in annual farm sales. Of the 229,200 irrigated farms across the United States in 2013, 64 percent were low-sales farms. 4 However, large-scale farms-those with $1,000,000 or more in farm sales-occupy most of the irrigated acres and use most of the applied irrigation water. These farms account for 60 percent of U.S. irrigated area and 61.5 percent of farm water applied. For the Western States, the largest irrigated farms-those with farm sales of $350,000 or more (22 percent of irrigated farms)-account for nearly 80 percent of the region's applied irrigation water. Large-scale irrigated farms account for most of the value (79 percent) of farm production sales from irrigated farms, reflecting both their larger acreages and more extensive investment in irrigation systems. Low-and moderate-sales irrigated farms, which account for 75-78 percent of all irrigated farms, accounted for just 7.7 percent of irrigated farm production sales. For all irrigated farms, the average farm sales ($ per farm) across the United States in 2012 was nearly four times that of farms not irrigating: $514,400 per irrigated farm, compared to $133,600 per nonirrigated farm. 5"}, {"section_title": "Importance of Conservation for Irrigated Agriculture", "text": "Many forces\u2500such as population and economic growth, expansion of the U.S. energy sector, Native American water-right claims, and water quality and ecosystem restoration initiatives-are driving increased demands for water resources across the country. On the supply side, continued overdraft of groundwater aquifers (where withdrawals exceed annual hydrologic recharge) is expected to reduce the future availability of groundwater supplies for irrigation use in important agricultural regions. While the precise effect of climate change on water resources is uncertain, climate change is projected to shrink surface-water supplies in much of the West through reduced snowpack, shifting precipitation patterns, and higher evaporative losses. At the same time, warming temperatures are expected to contribute to 4 Farm-size characteristics of irrigated farms were summarized based on USDA data from the 2013 Farm and Ranch Irrigation Survey (FRIS). Four farm-size classes were examined based on the \"total farm sales (FS)\" variable acquired from the 2012 Census of Agriculture: (1) low-sales farms (FS < $150,000); (2) moderate-sales farms (FS $150,000 to < $350,000); (3) mid-size farms (FS $350,000 to < $1,000,000); and (4) large-scale farms (FS $1,000,000 and more). See chapter 1.1, \"Farm Numbers and Size,\" for characteristics of all farms (irrigated plus non-irrigated)."}, {"section_title": "Onfarm Irrigation Efficiency: Benefits and Opportunities for Improvement", "text": "Improvements in physical irrigation systems and water management have helped to increase onfarm irrigation efficiency, or the share of applied water that is beneficially used for crop production. Gains in water-use efficiency provide various farm-level benefits, including improved crop yields and potential savings in water costs and other applied inputs. Improved water-use efficiencies, particularly when implemented in concert with watershed-scale conservation measures that limit expansion in irrigated area or reduce water withdrawals, can provide off-farm benefits as well, including fish and wildlife habitat, and reduced ecosystem and human health risks associated with environmental degradation. While substantial technological innovation has already occurred in U.S. irrigated agriculture, additional water-use efficiency gains are achievable (Schaible and Aillery, 2016; see also chapter 3.16, \"Farm-Level Adaptation to Drought Risk\"). 6 Based on FRIS results, much of the growth in high-efficiency systems reflects the expansion in pressurized sprinklers and micro-irrigation systems ( fig. 2.10.3). The share of acres using more efficient gravity systems peaked in the late 1990s, but then declined as farmers increasingly turned to the even more efficient pressure-sprinkler/micro-spray and drip systems. However, more than half of irrigated cropland acres in the West continue to be irrigated with more traditional application systems.  1994, 1998, 2003, 2008, and 2013. 6 To assess shifts in relative irrigation efficiency over time, Schaible and Aillery (2016) characterize irrigation systems as either \"traditional\" or \"efficient\" depending on acreage by irrigation application system and their components reported in the FRIS for both gravity and pressurized systems. FRIS data also indicate the potential for increased irrigation efficiency through more extensive use of onfarm water-management practices that improve the rate and timing of applied water. Fewer than 10 percent of irrigators make use of soil-or plant-moisture sensing devices or commercial irrigation scheduling services, while fewer than 2 percent use computer-based crop-growth simulation models to determine irrigation requirements based on consumptive-use needs by crop-growth stage under local weather conditions."}, {"section_title": "Irrigation Investments and Continued Agricultural Water Conservation", "text": "Irrigators annually make significant capital investments in onfarm irrigation equipment and infrastructure-$2.6 billion in 2013 (72 percent in the West), with the large majority (90 percent) of these investments financed privately. Farms receiving public financial assistance for irrigation investments through USDA's Environmental Quality Incentives Program (EQIP) represent fewer than 5 percent of all irrigated farms reporting irrigation investments. Further improvements in farm water conservation remain an important USDA farm policy goal (USDA, 2018). Through improved irrigation production systems that combine investments in irrigation technology with innovative water-management practices (e.g., a low-pressure sprinkler system with use of advanced sensor technologies), producers are better able to maximize the efficiency of their irrigation systems. Potential for real water savings at the watershed scale will depend on reduced system losses, the disposition of those losses (e.g., evaporation versus recharge), and as necessary, managed reductions in consumptive water use under more highly efficient systems. Institutional measures-such as tiered water pricing, withdrawal restrictions, water markets, conserved water rights, and instream flow requirementsmay further incentivize investments in irrigation efficiency for farm-level water conservation or environmental quality protection."}, {"section_title": "Chapter 2.11-Precision Agriculture", "text": ""}, {"section_title": "David Schimmelpfennig", "text": "\u2022 Precision agriculture allows farmers to save on seed, fertilizer, and pesticide costs; increase yields in certain situations; and be better stewards of farm resources. By 2016, 15-40 percent of U.S. farms used variable-rate application equipment, which adjusts input application rates depending on field conditions. \u2022 Labor-saving self-steering guidance systems for tractors and combines were the most popular precision agriculture technology, reaching 50-60 percent of farm planted acres growing corn, peanuts, rice, and spring wheat. \u2022 Precision technologies are associated with increased use of soil conservation tillage, erosion reduction, and nutrient control practices. Precision agriculture (PrecAg) enables extremely localized crop production management through a number of different technologies. The most popular technologies-as identified in the USDA's Agricultural Resource Management Survey (ARMS, conducted by USDA's Economic Research Service and National Agricultural Statistics Service) between the late 1990s and 2016-are tractor guidance systems that use a global positioning system (GPS), GPS yield and soil mapping, and variable-rate input technology (VRT) applications. These three technologies help farms gather information on current stateof-field conditions and to then adjust production practices. VRT instructs machinery and field operation equipment-such as sprayers and seeders-to automatically control input flow rates. This allows farmers to manage their seed, fertilizer, and pesticide applications foot by foot rather than field by field-and to do so on a per application basis. The more variable infield growing conditions are, both in time and space, the more valuable VRT is to farmers.  GPS yield maps synthesize GPS coordinates from yield monitors mounted on combines. Operators can use these maps of crop yields to identify where higher and lower levels of inputs should be applied. Yield monitor data are dense, showing foot-by-foot differences in crop yields in a field during harvest, which can vary greatly year to year depending on rainfall and the specific mix of production practices used. Even with difficulties in interpretation caused by this annual variability, 1 GPS yield mapping was used on 30-45 percent of planted acres for corn and soybeans (2012-16). The use of yield maps for cotton, peanuts, rice, and spring wheat is less common, but also has increased ( fig. 2.11.2).  Soil maps are created from laboratory tests on soil core samples. Although analyzing soil cores can be expensive, even with samples only taken every 20-50 feet in a field, soil cores do provide detailed information on soil characteristics and micronutrient levels. These data are typically used to create zones showing soil types, soil nitrate levels, and pH acidity readings. Like yield maps, farmers use GPS coordinates to georeference points on a field; unlike yield maps, soil characteristics are relatively stable year to year. Thus, zones on soil maps showing soil and micronutrient levels are easier to use (to interpret yields) than yield maps, which are strongly influenced by weather conditions. GPS soil mapping was used on around 20 percent of corn, soybean, and peanut planted acres (2012-16), 15 percent of rice (2013), and 10 percent of spring wheat planted acres (2009) (no figure is shown for these percentages). Guidance systems steer tractors and combines automatically, which helps reduce operator fatigue and pinpoint precise field locations. Guidance systems reduce costs by improving the accuracy of spray applications and the seeding of field-crop rows. The ends of rows, in particular, benefit from more accurate application of inputs. Manually turning farm machinery around to return in the opposite direction in adjacent sets of rows on a field can cause overlaps and missed spots for applied inputs. Guidance systems can also help extend working hours during time-sensitive production periods during the crop year because guided machinery works well in the floodlit dark. Guidance systems had the highest adoption rate of all precision agriculture technologies-used on between 45 and 65 percent of planted acres for corn, peanuts, rice, and soybeans (2012-16), and over 55 percent of planted acres for spring wheat (2009) ( fig. 2.11.3). Outfitting equipment with VRT is expensive, but  shows that VRT improves average profits. In 2010, corn acres using VRT saw a 1-percent increase in profits. About a fifth of planted acres for several crops (figure 2.11.1), such as soybeans and rice, used VRT in 2012-13. Perhaps more surprising is that VRT's supporting technologies-such as GPS mapping, soil mapping, and auto-steer guidance systems-are also profitable on their own. Mapping and auto-steering, for example, added between 2 and 3 percent to corn farm profits in 2010. The use of these precision technologies is associated with improved onfarm stewardship. Conservation tillage improves soil structure and organic matter (chapter 2.12, \"Crop Production Management: Tillage Practices\" and chapter 3.19, \"Soil Health\"). In soybean production, precision agriculture users are about 10 percent more likely than nonusers to practice conservation tillage for all three precision technologies examined (table 2.11.1); 55 percent of U.S. soybean farms use some form of conservation tillage. Erosion control refers to structures erected for grade stabilization, as well as water-control basins, filter strips, field borders, and contour farming/strip cropping. These practices are used on about one-third of all soybean farms, with 5-8 percent more precision agriculture users than nonusers practicing erosion control; guidance users are the most likely to practice erosion control (relative to nonusers of guidance). Fertilizer is applied to benefit production, but when fertilizer is overapplied it can degrade water resources through runoff and groundwater contamination. Farmers indicated in their ARMS survey responses if they had changed any of their cropping practices to reduce their use of fertilizer or applied nutrients on soybean fields (2012) (most commonly potassium, phosphorus, or lime, as soybeans are nitrogen-fixing) or changed the type of fertilizer used on rice paddies (2013) to reduce fertilizer use. Almost one-quarter of both soybean and rice farmers indicated that they had changed practices to reduce fertilizer use, and a statistically higher number of these farmers used precision agriculture than did not (table 2.11.1). Variable-rate technology (VRT) provides interesting crop comparisons. When VRT was adopted on soybean farms, the share of farms that reduced fertilizer use increased by 17 percent (from 21 to 38 percent). This suggests that soybean farmers use VRT as a way to reduce fertilizer use. For rice farms that reduced fertilizer, on the other hand, the difference between the share of VRT users and nonusers is only 2 percent. Overall, VRT use in rice has climbed to over 20 percent, suggesting that many rice farmers use VRT to increase the accuracy of fertilizer placement without reducing their overall use of fertilizer. This means that VRT may not help reduce fertilizer use in all cases but, in some circumstances, fertilizer savings with VRT can be substantial. 2 While other chemicals can be applied using the VRT method, fertilizer is typically the most important from a cost and yield impact perspective. Rice is an exception, where nonfertilizer chemicals applications using VRT have bigger payoffs. Several factors are likely to influence the effectiveness of precision technologies in the future. Wireless sensor technologies for crop plants or soil are likely to increase the volume of data on growing conditions available to farmers. Internet-enabled devices can collect sensor data and make crop practice recommendations in real time in a farmer's fields. These developing technologies are likely to be combined with programming known as artificial intelligence (AI), or application equipment may be built with machinelearning capability that can supply more sophisticated recommendations to farmers. These AI and machine-learning innovations can combine data that are growing more plentiful in new ways to produce novel insights on crop-practice effectiveness. This evolution of data availability and data use is going on while farmers are developing more data-driven relationships with trusted advisors and agricultural input retailers, who may use these data resources to help farmers come closer to fully exploiting their data. \u2022 No-till (a form of conservation tillage) varies widely across crops, including 40 percent of soybeans (2012), 18 percent of cotton (2015), 27 percent of corn (2016), and 45 percent of wheat (2017). \u2022 Farms that alternate no-till/strip-till with full-width tillage include roughly 30 percent of all corn, soybean, cotton, and wheat acreage Reducing or eliminating tillage can reduce soil erosion, conserve soil moisture, and promote better soil health by minimizing soil disturbance and keeping crop residues on the soil surface ; see also chapter 3.19, \"Soil Health\" ). Conservation tillage encompasses a range of tillage practices. In a no-till system, farmers plant directly into the undisturbed soil with the residue of the previous crop still on the soil surface. In a mulch-till system, the soil is tilled lightly but much of the previous crop residue is maintained on the soil surface. In a strip-till system soil disturbance is limited by tilling only narrow strips where seeds are planted, also providing an opportunity to place fertilizer below the soil surface. No-till is more efficient than mulch-till in terms of soil health, soil moisture conservation, and soil erosion control because it causes less soil disturbance and maintains greater soil residue cover. When compared to mulch-till, no-till can also mitigate sediment and nutrient loading in bodies of water and preserve soil depth and productivity (Rittenburg et al., 2015). Limiting soil disturbance and maintaining residue can also increase soil carbon sequestration and improve soil properties in a number of ways, including increased water holding capacity, higher soil organic matter content, and reduced soil compaction (USDA, NRCS, 1996). Evidence also suggests, however, that long-term gains in soil health can be achieved only through consistent application of a suite of practices that includes minimal tillage and practices that increase (1) residue cover and (2) the portion of the year soil is covered by a growing crop (using cover crops, for example) (USDA, NRCS, 2014). Conservation practices are often part of conservation plans required for highly erodible cropland to maintain eligibility for most Federal agricultural programs. Climate and weather may also play a role in the tillage decision; farmers may use no-till or strip-till to conserve soil moisture in dryer regions or when soil moisture reserves are low, but use other tillage systems when soil moisture is ample (Ding et al., 2009) or in relatively cold conditions (Soule et al., 2000)."}, {"section_title": "Tillage Practices Vary by Crop", "text": "In the field-level portion of USDA's Agricultural Resource Management Survey (ARMS), producers of specific crops are surveyed on a multiyear cycle (e.g., corn producers were surveyed in 2005, 2010, and 2016) to generate a wide range of information on crop production practices. Tillage estimates are based on the sequence of field operations as reported by respondents. Tillage practices can be defined by the level of soil disturbance. Conservation tillage ranges from no-till to a maximum level of soil disturbance-a Soil Tillage Intensity Rating (STIR) of 80 (USDA, NRCS, 2016). 1 In general, no-till increased from 2000 to 2007 (Horowitz et al., 2010). More recent data show that trends in no-till adoption are mixed. Over 2004-17, wheat producers increased the share of planted acres under mulch-till or no-till from 37 percent to 67 percent ( fig. 2.12.1). No-till accounted for a large majority of the increase. More modest changes in conservation tillage were observed for corn, soybeans, and cotton. For cotton and corn, no-till adoption rates showed only modest gains in the most recent surveys (2015 and 2016, respectively). In soybeans, no-till adoption declined between the two most recent surveys (2006 and 2012). For corn, mulch-till adoption has also been fairly constant from 2005 to 2016. For soybeans and cotton, mulch-till adoption rates have increased slightly. The field-level ARMS data for wheat (in 2017), soybeans (in 2012), cotton (in 2015), and corn (in 2016) provide a 4-year history of no-till/strip-till use. 2 Farmers were asked about no-till use in the survey year and the 3 previous years (although the surveys are crop-specific, any crop could have been grown on the surveyed field in the 3 previous years). Despite the benefits of no-till/strip-till, other tillage practices were used on roughly 80 percent of acres in corn, soybeans, wheat, and cotton at least once during a 4-year period ( fig. 2.12.2). No-till was used exclusively for 4 years on 21 percent of soybean acres (2012) and 28 percent of wheat acres (2017). No-till or strip-till was used exclusively on 18 percent of corn acres (2016) and 9 percent of cotton acres (2015)."}, {"section_title": "Many Farmers Use No-Till or Strip-Till on a Portion of Their Cropland", "text": "Many farmers who use no-till use it on only a portion of their crop acreage. For example, farmers often rotate tillage practices along with crops (Robertson et al., 2014), using no-till/strip-till on crops that are thought to be well suited for the practices (e.g., soybeans) and conventional or mulch tillage for crops where no-till/strip-till are perceived to be more risky (e.g., corn) (Reimer et al., 2012). Some farmers may also select their tillage practice based on field characteristics. For example, farmers may use no-till/striptill on highly erodible land to control soil erosion and use conventional tillage on land that is not highly erodible (Prokopy et al., 2008). ARMS data for 2010-11 provide a detailed, farmwide look at how farmers used no-till/strip-till on the four most widely grown crops. During those years, 56 percent of all land used for corn, soybeans, wheat, and cotton was on farms that used no-till/strip-till on some portion of land used for these crops. Roughly 23 percent of land in these crops were on a farm where no-till/ strip-till was used on every acre (full adopters). Another 33 percent of acreage was on farms where a mix of no-till, strip-till, and other tillage practices were used (partial adopters). Partial adopters used no-till/strip-till on roughly half of their cropland (15 percent of land in the four major crops). Intensity of use among partial adopters varies regionally ( fig. 2.12.3). Partial adopters in the Heartland, Prairie Gateway, Eastern Uplands, and Southern Seaboard used no-till/strip-till on 16-20 percent of acres in 2010-11. In the Northern Great Plains, Heartland, and Prairie Gateway regions-which account for 72 percent of U.S. corn, soybean, wheat, and cotton acreage-more than half of these crop acres were on farms that used no-till/strip-till to some extent. Farmers who use no-till/strip-till on a part of a particular crop acreage have the equipment and expertise (at least for some crops) to use no-till/strip-till but choose to till other portions of their cropland. These farmers may be well positioned to use these practices on a larger share of acres if/when it is advantageous to do so.  It is not uncommon for farmers who use no-till/strip-till to do so on all their acreage for an individual crop ( fig. 2.12.4). About 25 percent of corn acres, 27 percent of cotton acres, 37 percent of soybean acres, and 39 percent of wheat acres (2010-11) occurred on farms that used no-till/strip-till on all the acres in those crops. However, full adoption for one crop does not mean that the farmer will apply that practice to other crops. Only 23 percent of acres in all four crops were located on farms that adopted no-till/strip-till on 100 percent of their acres. That farmers use no-till/strip-till on all acres of a particular crop is consistent with the notion that tillage choice and crop choice are closely tied.  The long history and comprehensive standards associated with the organic food label, along with its widespread use worldwide, distinguishes organic labels from other eco-labels that have emerged in recent years. In 2000, USDA published national organic standards that reflected decades of private-sector development. USDA's national regulatory program is designed to facilitate interstate trade, reduce fraudulent product claims, and provide consumer assurance that all organic products sold in the United States meet a high national standard. All growers, processors, and distributors that want to label or advertise their products as organic must meet the national standard and must also be certified by a USDA-accredited State or private group unless their annual organic sales are under $5,000. USDA regulations define organic farming as an ecological production system that fosters resource cycling, promotes ecological balance, and conserves biodiversity. Organic farmers are required to avoid most synthetic chemicals and must adopt practices that maintain or improve soil conditions and minimize erosion. Organic production systems can be used to increase farm income, as well as reduce pesticide residues in water and food, reduce nutrient pollution, improve soil tilth and organic matter, lower energy use, reduce greenhouse emissions, and enhance biodiversity (Reganold and Wachter, 2016;Delate, 2015;Baranski et al., 2014)."}, {"section_title": "Consumer Demand Drives Adoption of Organic Systems", "text": "Organic products have shifted from a lifestyle choice for a small segment of consumers to a commonplace interest for many consumers. In 2014, Gallup included questions on organics in its annual food consumption survey for the first time and found that 45 percent of Americans actively tried to include organic foods in their diets, with an even higher share of younger survey respondents (ages 18 to 29) reporting that they actively try to include organic foods. The share of Americans with annual household income under $30,000 that actively tried to include organic foods was 42 percent, similar to the share for households with incomes of $30,000 to $74,999 (45 percent) and households with incomes over $75,000 (49 percent). Organic retail sales have shown double-digit growth during most years since USDA set national organic standards and continue to grow rapidly. The Organic Trade Association estimated U.S. organic retail sales at $49.4 billion in 2017, up 6.4 percent from the previous year. While organically grown fresh produce is still the top organic category in terms of U.S. retail sales, U.S. organic milk products have higher price premiums and market share. According to a recent ERS analysis, the highest organic market share in 2014 was for organic milk (14 percent of total sales), followed by organic eggs and organic vegetables (both at nearly 7 percent), and organic fruit (nearly 6 percent) (Greene et al., 2017). In 2015, the United States had 3.2 million acres of certified organic cropland and 2.2 million acres of certified organic pasture (including rangeland). While that land accounted for less than 1 percent of all U.S. farmland, the organic adoption rates varied widely across crop and livestock sectors. For example, organic farming systems were used on nearly 10 percent of U.S. vegetable acres in 2015, but less than 0.3 percent of acres devoted to major U.S. feed grains (corn and soybeans); the share of U.S. dairy and poultry production managed under organic systems falls in between. The number of certified organic operations in the United States has more than doubled over the last decade in response to rising consumer demand. The United States had over 21,700 certified organic operations in 2015-60 percent were crop and livestock farmers, while 40 percent were processors, manufacturers, and other food handling operators. USDA's organic regulatory program data show that organic farm production and food-handling operations are concentrated in California (the country's top fruit and vegetable producer), the Northeast (which has many small-scale organic farms), and the Upper Midwest (a major producer of organic milk) ( fig. 2.13.1). Northeastern States have the highest share of certified organic farmers, particularly Vermont and Maine, where 5 and 6 percent, respectively, of all farmers are certified organic. In California, more than 3.6 percent of all farmers are certified organic (Greene et al., 2017).  "}, {"section_title": "Certified organic operations are concentrated in the West, Northeast, and Upper Midwest", "text": ""}, {"section_title": "Common Organic Practices Include Complex Rotations, Cover Crops, and Pasture", "text": "The ecological approach to farming defined by USDA in the national organic standards affects the entire production system (USDA-AMS, 2000). Farmers who shift to organic farming systems from more chemical-intensive systems must make changes across the spectrum of their production inputs and practices. Under organic farming systems, the fundamental components and natural processes of ecosystemssuch as soil organism activities, nutrient cycling, and species distribution/competition-are used as farm management tools. Organic producers rely on complex rotations, cover crops, biological pest management, and other nonchemical practices. For example, crops are rotated, food and shelter are provided for the predators and parasites of crop pests, crop residues are cycled, and planting/harvesting dates are carefully timed (USDA-NRCS, 2016). Conventional farmers use these practices much less frequently than organic farmers. Since the mid-2000s, USDA has surveyed specific organic commodity sectors in the detailed Agricultural Resource Management Survey (ARMS), and also has begun conducting periodic surveys of all organic producers. ERS studies based on data from these surveys confirm that many of the practices associated with soil health are much more widely used in organic farming systems than in conventional systems (see chapter 3.19, \"Soil Health\"). For example, organic soybean producers often rotate row crops with small grain and meadow crops, and include an idle year in the rotation, while conventional producers mainly use a rotation of continuous row crops (McBride and Greene, 2009). Almost all conventional soybean producers use chemical pesticides for pest and weed control, while organic producers rely on a suite of nonchemical practices. ERS studies show similar patterns for the other field crops. Other practices that contribute to soil health, soil productivity, and nutrient cycling-including cover crops, animal manure, and compost-are also more widely used in organic farming systems. Data from USDA's national surveys show that nearly 40 percent of all organic field crop and specialty crop producers use cover crops, much higher than among conventional producers ( fig. 2.13.2). According to ARMS data, over half of organic apple producers and over 20 percent of organic corn producers use compost, compared with under 3 percent of conventional apple and corn producers (Osteen et al., 2012). Animal manure is also much more widely used in organic field crop production than conventional production. Tillage is more widely used in organic systems than in conventional systems, and no-till organic systems are still not used commercially in most parts of the country. In a no-till system, farmers plant directly into the undisturbed residue of the previous crop without tillage, except for nutrient injection, which can reduce soil erosion and sediment loss to water and wind. It can also increase soil carbon sequestration (the amount of carbon retained in the soil) and improve the physical, chemical, and biological properties of the soil. Organic no-till systems generally require specialized farm equipment to drill seed into cover crop residues and are more challenging to implement than conventional no-till systems, which rely on chemical herbicides to kill vegetation. Despite heavier use of tillage in organic farming, long-term cropping system experiments at Iowa State University, USDA-Beltsville, Rodale Institute, the University of Minnesota, and others have found that organic cropping systems can sequester as much soil organic carbon, for example, as no-till conventional systems (Delate, 2015). Organic livestock production systems attempt to accommodate an animal's natural nutritional and behavioral requirements and prohibit the use of antibiotics and hormones in livestock production. USDA organic regulations require that organic dairy cows and other ruminant livestock obtain part of their dry matter intake (forage) from pasture during the grazing season, while many conventional dairy operations did not use any forage from pasture as part of their feeding mix (McBride and Greene, 2009). Rotational grazing-managing where and when livestock graze in order to prevent overgrazing and to optimize pasture growth-is a soil health strategy that is also used more frequently in the organic dairy sector. According to USDA's 2012 Census of Agriculture, 65 percent of organic livestock producers use rotational grazing, compared with 22 percent of conventional livestock producers ( fig. 2.13.2)."}, {"section_title": "USDA Has Expanded Conservation Assistance to Organic Producers", "text": "USDA requires a 3-year transition period before conventional farmers can earn organic price premiums, and organic producers also face many challenges after transitioning. Respondents to USDA's ARMS organic surveys have indicated that weed control, certification paperwork, compliance costs, and input sourcing are among the most difficult aspects of organic production (McBride et al., 2015;McBride and Greene, 2009). Also, U.S. organic producers who grow crops near genetically engineered (GE) crop operations use avoidance practices, such as delaying corn planting until after GE corn is planted, to minimize accidental mixing of organic and GE crops ( fig. 2.13.3), which may lower yields from planting at a suboptimal time (Greene et al., 2016). Certified organic corn was planted later than genetically engineered (GE) corn in 2010 to avoid cross-pollination Since the early 2000s, USDA and Congress have widened access for organic and transitioning producers to conservation, risk management, and other farm programs. The 2008 Farm Act, for example, expanded USDA's Environmental Quality Incentives Program (EQIP) to include conservation practices related to organic production, as well as those related to conventional production. Congress designated lower payment caps for the EQIP Organic Initiative than for the regular EQIP program, although organic and transitioning farmers compete against a smaller pool of applicants and can also choose to enroll in the regular program instead. Under the Organic EQIP Initiative, USDA provided more than 6,800 farms across the country with $115 million in assistance between 2009 and 2016 to help producers implement conservation practices on organic and transitioning farms (fig 2.13.4). This program may be particularly useful for transitioning farmers who have not already adopted many of the conservation practices used in organic production. Chapter 2.14-Manure Management"}, {"section_title": "Nigel Key and Stacy Sneeringer", "text": "\u2022 In 2012, manure was applied to over 22 million acres in the United States, or 2.6 percent of all cropland and pastureland. \u2022 About 78 percent of hog producers applied manure or litter on their own land, compared to 95 percent of dairies and 52 percent of broiler operations. \u2022 About 54 percent of hog producers, 41 percent of dairies, and 66 percent of broiler operations had a nutrient management plan  for balancing the quantity of manure and fertilizer nutrients applied to farmland with the quantity of nutrients taken up by crops. Manure management-how manure is captured, stored, treated, and used-affects the profitability of livestock operations and can influence environmental quality. Manure contains nutrients-such as nitrogen, phosphorus, and potassium-that can reduce crop production costs by substituting for commercial fertilizer. However, overapplying manure nutrients to cropland can increase the risk that these nutrients flow into surface water. Nutrients from manure and fertilizer that are not taken up by plants can run off into surface water where, in sufficient concentration, they can harm plant and marine life. Agriculture is a major source of the nutrient pollution causing harmful algal blooms and hypoxic \"dead\" zones in several water bodies, including the Chesapeake Bay, Gulf of Mexico, and the Great Lakes. Because manure harbors a wide variety of microorganisms that can be pathogenic to animals and humans, it must be properly contained and managed. How manure is managed can also affect local air quality (haze, small particle concentrations, odor) and greenhouse gas emissions. Managed livestock waste accounts for about 13 percent of U.S. agricultural greenhouse gas emissions. The decomposition of manure stored in lagoons, ponds, tanks, or pits produces carbon dioxide and methane, each greenhouse gases. When manure is handled as a solid or deposited on fields, it tends to produce much lower greenhouse gas emissions. Lagoon and pit manure handling systems that emit relatively large amounts of methane, a potent greenhouse gas, are common on dairy and hog operations."}, {"section_title": "Manure Management Policies", "text": "Multiple local, State, and Federal policies and regulations are designed to mitigate the environmental harm from animal manure. In 2003, the U.S. Environmental Protection Agency revised Clean Water Act regulations for controlling runoff of manure nutrients from the largest animal feeding operations. The regulations now require operations designated as Concentrated Animal Feeding Operations (CAFOs) and discharging manure effluent to seek National Pollutant Discharge Elimination System (NPDES) permit coverage. CAFOs with NPDES permits must have a nutrient management plan (NMP) that identifies practices to ensure the agronomic use of nutrients. Important components of an NMP include soil and manure testing for nutrient content, balancing farm-available nutrient resources with farm crop needs, and monitoring the operation's total nutrient balance to account for nutrients generated, field-applied, and moved offsite. Enforcement of the Federal CAFO rules falls largely to individual States. Odor from livestock operations has been a source of friction in many agricultural communities, and several States have adopted odor regulations. These State policies may contain odor standards or require management methods such as separation distances, odor plans, or \"good neighbor practices.\" Several States include odor stipulations in their general permits for livestock operations. To help defray the costs of meeting environmental regulations, producers can apply for financial assistance from the USDA's Environmental Quality Incentives Program (EQIP). Financial assistance provided by EQIP may be used to help develop and implement a nutrient management plan, construct appropriate animal and manure handling/storage facilities, or transfer and apply manure to land in an approved manner."}, {"section_title": "Manure Management on Hog, Dairy, and Broiler Operations", "text": "Manure is applied to some cropland throughout the United States. According to the 2012 Census of Agriculture, manure was applied to over 22 million acres in the United States, which represented 2.6 percent of total cropland and pastureland. The application of manure to cropland was most prevalent in regions with high concentrations of livestock production including the Northeast, Upper Midwest, and Southeast ( fig. 2.14.1). Manure in hog and dairy operations is usually collected and stored in lagoons, pits, or tanks. Lagoons are large earthen containment structures into which manure and wastewater is flushed and maintained in liquid form until removed. Manure pits are often located under hog production facilities where, in the typical system, manure drops into pits through slatted floors and is stored in a slurry form until removed. These storage structures hold the manure until it can be land-applied on the same farm or nearby farms to meet crop nutrient needs. Technologies for land application include liquid/slurry manure spreaders that may or may not incorporate manure into the soil, and irrigation systems that spray or spread the liquid manure solution on nearby fields. The different systems for manure management have very different impacts on the nutrient content of the manure, primarily nitrogen, and thus on the amount of land needed to spread manure. For example, handling manure in pit or tank storage and using slurry spreaders to inject the manure into the soil manages the manure for its potential fertilizer value. This system is designed to retain manure nitrogen for crop use, and thus it requires more land on which to apply the manure if the operation is following a nitrogen-based nutrient management plan. In contrast, handling manure from lagoon storage and distributing it with irrigation increases the release of nitrogen into the atmosphere, reducing the manure's nitrogen content and requiring less land for application. On broiler operations, manure is typically collected along with bedding material (e.g., wood shavings) and feathers when houses are cleaned. The mixture of bedding and manure (called litter) is relatively dry, which makes it easier and cheaper to store and transport than hog and cow manure. When a poultry house is cleaned out, the litter can be immediately spread on a field or stored for later applications. When stored, litter is often kept in a shed to reduce rainwater runoff of nutrients. On some livestock operations, manure is directly deposited on the fields by grazing animals. However, on most confined livestock operations, manure is collected and then spread on the operation's own fields or removed from the operation and spread on nearby farmland. The amount of manure that is applied onfarm versus removed depends on how much cropland the farm controls, the nutrient uptake of the crops grown on the farm, and the demand for manure on nearby farms. The USDA's Agricultural Resource Management Survey (ARMS), which focuses on different types of livestock producers every 4 or 5 years, provides detailed information about farm production practices, including manure management. 1 Based on the 2009 ARMS, 78 percent of hog operations applied manure on their own operations-with about an equal share applying in solid, liquid, or slurry form (table 2.14.1). The average hog operation applied manure to 105 acres of land, which represents about a fifth of the average operation's cropland. About 21 percent of hog operations removed manure from their operations, with most giving it away. Only 5 percent of hog farms sold manure, reflecting weak demand for hog manure in regions where hogs are produced. Dairy operations were more likely than hog operations to use manure on their own operations. In 2010, 95 percent of dairies applied manure onfarm, mostly in solid form. The average dairy applied manure to 156 acres, which represents about half of the dairy sector's average crop acreage. Only 10 percent of dairies removed manure from their operation, again with most of this given away for free. In 2011, only about half (52 percent) of broiler operations applied manure onfarm; a large portion of broiler growers have no cropland. Growers who do have cropland apply manure at a high rate; on average, manure is applied on over 90 percent of available crop acres. With little cropland for spreading manure, almost three-quarters of all broiler operations removed some manure from their operation in 2011. Broiler litter is relatively valuable. Almost two-thirds of operations either sold manure or exchanged it for services (such as cleaning out the broiler house). 1 Detailed information about manure management was not collected after 2011. "}, {"section_title": "Manure Nutrient Management Practices", "text": "In addition to deciding whether to apply manure onfarm, growers must decide how much manure to apply to their crops. A nutrient management plan (NMP), which can be voluntary or required by statute, specifies a set of nutrient management practices that a farmer should take to match applied manure and commercial fertilizer nutrients with the absorptive capacity of the land and crops. About two-thirds of broiler operations had an NMP in 2011, compared with 54 percent of hog operations (2009) and 41 percent of dairies (2010, table 2.14.2). Manure nutrient testing, a practice required as part of many Statemandated manure management plans, was employed by about a third of hog and broiler operations and 22 percent of dairy operations. Farmers apply commercial fertilizer to crops in addition to manure if the manure nutrients do not meet the nutritional needs of the crops. Testing the nutrient content of manure can save costs by avoiding the overapplication of supplemental commercial fertilizer. About 43 percent of all dairy operations adjusted their fertilizer nutrients, compared to 31 percent of hog operations and 14 percent of broiler operations. Some hog and dairy operations adjusted the nutrient content of manure via modification to their feed formula or feeding schedule, typically to reduce the nitrogen or phosphorus content of the manure. This allows the same amount of manure to be spread over a smaller amount of land while providing the same amount of nutrients. Adjusting the nutrient content of manure via feed was practiced by a third of hog operations, but only 7 percent of dairy farms. EQIP payments for manure management were used primarily for installing manure handling and storage facilities, manure hauling, and application or for a nutrient management plan (development, testing, and recordkeeping). EQIP payments were not common: the share of hog, dairy and broiler operations that received these payments ranged from 2 to 4 percent over 2009-11 (see chapter 3.24, \"Working Lands\"). \u2022 By the end of 2017, 44 percent of U.S. broiler chickens were raised without any antibiotics. \u2022 Between 2004 and 2015, the share of finishing hogs sold or removed from operations reporting that they did not know or did not report whether antibiotics were used for growth promotion rose from 7 percent to 35 percent. \u2022 Use of antibiotics for purposes other than disease treatment is associated with a 1-to 3-percent increase in the productivity of hog and broiler operations. The animal agriculture sector is a major user of antibiotic drugs for disease treatment, disease control, and disease prevention. These drugs are pivotal for animal health and farm productivity, but many of the antibiotics used on the farm are in the same classes as those used in human medicine. Agricultural use of antibiotics important for disease treatment in human medicine-called \"medically important\" antibiotics by the FDA 1 -is an increasing source of public health concern. Routine use of antibiotics, in humans or animals, can promote antimicrobial resistance, such that antibiotics fail to contain bacterial infections. The U.S. Centers for Disease Control and Prevention (CDC) estimates that over 2 million people in the United States annually become ill from resistant infections, with at least 23,000 dying (CDC, 2013). Other estimates suggest that by 2050, antimicrobial resistance will result in more deaths than cancer worldwide (Review on Antimicrobial Resistance, 2016). While antibiotics administered to livestock have been linked to human health risks, the extent of these risks remains a matter of debate. Concerns over antibiotic resistance have led to calls to use the drugs more judiciously in all settings, and to examine alternatives to their use. In 2017, new U.S. Food and Drug Administration (FDA) rules went into effect making it illegal to provide medically important antibiotics in feed or water to livestock for production purposes such as growth promotion (U.S. FDA, 2012 and. These new requirements now compel veterinarians to oversee all use of in-feed or in-water medically important antibiotics in livestock, rather than having some available over the counter. Consumers and major retailers also are increasingly demanding livestock products resulting from animals that never received any antibiotics for any purpose. In response, several major food retailers have placed restrictions on the use of antibiotics for production purposes by their meat suppliers (Pew Charitable Trusts, 2015). Changes in antibiotic use will lead to a series of adjustments in animal agriculture as producers change production practices, with potential repercussions for prices and volumes in livestock markets."}, {"section_title": "Use of Antibiotics in the Livestock Sectors", "text": "Reasons for antibiotic use, extent of their use, who makes the decision to use them, how restrictions on use would be felt in the industry, and how policies could be implemented all depend on the structure and organization of livestock production. Broilers. Almost all U.S. broiler production is carried out through production contracts between growers and integrators. Integrators own and operate feed mills, hatcheries, and processing plants. They also provide feed, chicks, and veterinary services to growers, who raise the chicks to market weight on their own farms under contracts with the integrators. Integrators dictate feed formulations, including administration of antibiotics. Antibiotics may be used to treat sick birds, and flocks may also be given a course of antibiotics in feed or water to prevent the spread of disease when outbreaks are detected in nearby houses or farms or when cull rates rise within a house. Antibiotics are also often injected into eggs or chicks to improve early viability. Before FDA requirements ended the practice in 2017, medically important antibiotics were fed to broilers to promote growth (U.S. FDA, 2012 andNRC, 1999). Between 2006 and 2011, the share of broilers raised without antibiotics except for disease treatment rose from 44 to 48 percent. The percentage of birds removed from operations reporting they did not know whether their birds were raised without antibiotics except for disease treatment rose from 29 to 32 percent ( fig. 2.15.1). As integrators often supply feed, many growers may not know whether antibiotics are in their feed. A growing share of broiler production is performed under product lines termed \"raised without antibiotics\"; in these settings, no antibiotics (including non-medically important ones) are administered for any purpose. Flocks that get sick are treated with antibiotics but sold under a different product line. By the end of 2017, 44 percent of broiler chickens were raised under these \"raised without antibiotics\" product lines following the announcements of two leading companies (according to USDA, Agricultural Marketing Service's Agricultural Analytics). Hogs. Hog production has become increasingly vertically integrated and specialized in terms of the animal lifecycle. Integrators provide contract growers with feed, veterinary services, and animals. Contracted sow operations farrow young pigs, which are shipped to nursery operations. There they are raised to feeder weights and then shipped to finishing operations. After being fed to market weights, integrators either ship the hogs to their own packing plants or sell them to others. Hogs may be treated for diseases with antibiotics at any point in their lifecycle, but an especially risky time occurs in the pre-weaning and nursery stages. In 2012, 10 percent of pre-weaning piglet deaths were caused by scours (another name for diarrhea), an illness frequently treated with antibiotics. In the finishing stages, respiratory problems are the most prevalent disease-induced causes of death (75 percent); these instances are also treated with antibiotics (USDA, APHIS, 2015). Before the FDA requirements ended the practice in 2017, antibiotics were fed to both young (nursery) pigs as well as market (finishing) hogs to promote growth. Between 2004 and 2015, the share of finishing hogs sold or removed 2 from operations reporting that they did not administer antibiotics for growth promotion declined from 41 percent to 31 percent ( fig. 2.15.2). Over the same time period, the share of operations stating they did not know-or did not report-whether antibiotics were administered for growth promotion rose by 28 percentage points. This was coupled with a comparable decline in hogs raised at operations reporting that they did use antibiotics for growth promotion. Thus, for finishing hogs, producers seemingly became less willing or able to report on their use of antibiotics for growth promotion between 2004 and 2015.  Survey, 2004Survey, , 2009Survey, , and 2015 Independent hog producers sell animals. Contracted hog producers have hogs \"removed\" from their facilities. Hence the phrase \"sold or removed.\" Trends for nursery hogs are less easy to interpret. The share of nursery hogs sold or removed from operations that did not administer antibiotics for growth fell from 65 to 51 percent between 2004 and 2009, but then rose to 55 percent between 2009 and 2015. The share of operations stating that they did not know or report whether antibiotics were administered rose from 6 to 17 percent (2015), while the share of nursery hog operations reporting that they did use antibiotics for growth promotion remained around 29 percent. Because of these shifts, it is difficult to tell whether use of growth-promoting antibiotics in nursery pig production rose or fell between 2004 and 2015. Beef cattle. Beef cattle production can be divided into two stages. On cow-calf operations, calves are birthed and raised until weaning. In 2007/2008, nearly 16 percent of cow-calf operations reported adding antibiotics (inclusive of non-medically important antibiotics) to cattle feed to prevent disease and/or promote growth (USDA, APHIS, 2012). On stocker, backgrounding, and feedlot operations, cattle are fed to slaughter weight. Animals are often shipped long distances to these operations. Co-mingling of cattle from various locations increases the threat of disease spread, so animals often receive preventive injections of antibiotics upon arrival. In 2011, a quarter of cattle at large-scale feedlots received injected antibiotics (USDA, APHIS, 2012). Nearly half of cattle at large-scale feedlots received medically important antibiotics in feed (USDA, APHIS, 2013)."}, {"section_title": "Dairy.", "text": "Unlike hogs or broilers, dairies do not operate under production contracts. Dairy operators often retain female cows for their entire lifecycle, while selling male calves for beef. Antibiotics are used on dairy farms to treat and prevent disease, but they also have been used in heifer rations for growth promotion. Diarrheal and respiratory problems are frequent in preweaned dairy calves. To help prevent these illnesses, dairy operations fed 40 percent of pre-weaned heifers medicated milk replacer in 2014 (USDA, APHIS, 2016a). After heifers are bred and give birth, they may contract diseases or disorders that are often treated with antibiotics. In 2014, 93 percent of dairy operations provided antibiotics for prevention of intramammary infections between lactation periods (USDA, APHIS, 2016b). Notably, the FDA has established minimum intervals between the last dose of antimicrobials and the time of slaughter to allow antibiotic residues in meat to reach levels safe for human consumption (U.S. FDA, 2014). Likewise, if dairy cows have been treated with antibiotics, they must be withdrawn for a time before their milk can be sold into the food chain."}, {"section_title": "Economics of Reducing Antibiotic Use", "text": "Antibiotics may reduce the use of other inputs (such as feed) and lower morbidity and mortality. If the gains from using antibiotics outweigh the costs, then antibiotic use can increase livestock productivity and efficiency. Indirectly, antibiotics may influence the scale and type of production; if antibiotics reduce the amount of space needed per animal, then more animals can be raised per square foot. Reducing antibiotic use may require adjustments to production processes. Farm operators may need to provide more feed to reach production targets, but they may also use other animal drugs, feed supplements, administer vaccines, alter sanitation practices, change genetic lines, or modify housing environments through capital investments. Such adjustments influence the financial outcomes from reducing antibiotic use and may also affect animal health and environmental outcomes. Reducing use of antibiotics may yield higher production costs, which can lead to higher prices and lower market supply. Use of antibiotics for purposes other than disease treatment is associated with a 1-to 3-percent increase in productivity on hog and broiler operations. The increase in the cost of production from ceasing antibiotic use is estimated to lead to an increase of 1 percent in wholesale prices and a drop in output of less than 1 percent (Sneeringer et al., 2015). \u2022 Participation in voluntary conservation programs is influenced by regional differences in drought risk. Producers in higher risk regions are more likely to participate in EQIP (Environmental Quality Incentives Program) contracts that include irrigation efficiency improvements or water conservation. \u2022 Irrigation can be an important source of drought resilience, but drought often leads to severe curtailment of surface-water supplies for irrigation. In some areas, irrigators can offset reduced surface-water availability through increased groundwater pumping, which can extend droughts' long-term impacts through depleted groundwater levels."}, {"section_title": "Drought Risk", "text": "The risk of drought is a concern for agricultural producers throughout the county. Drought-a reduction in water availability due to a combination of low precipitation and high temperatures-can reduce productivity and lead to severe losses in farm income. Droughts are measured both in terms of duration and severity, and their impact can be dependent on their timing. A variety of policy options address drought, many involving large-scale investments in infrastructure or major changes in water allocation that are beyond the agricultural sector's control (Schwabe and Connor, 2012). This chapter focuses on farm-level decisions that can attenuate the impacts of drought, which can be influenced by existing infrastructure and institutional arrangements. Drought is the leading driver of production risk in U.S. agriculture (fig. 3.16.1). No other source of production risk-including flooding, early frosts, and pests-is as nationally significant as drought in terms of lost agricultural production and income. A major drought can reduce crop yields, limit planted or harvested acreage, reduce livestock productivity, and increase costs of production inputs such as animal feed and irrigation water. Regions differ in how frequently they experience severe drought. Some regions, such as parts of the Midwest, Northeast, and coastal Northwest, have experienced severe or extreme drought for about 1 of every 5 years, on average, from 1900 to 2016. Other areas face higher drought risk. For example, areas in the Southwest, Southeast, Northern High Plains, and intermountain West have had severe or extreme drought about once every 3 years ( fig. 3.16.2)."}, {"section_title": "Group 3: Natural Resources and Conservation", "text": "Precipitation and temperature vary widely by region, so climatologists measure droughts relative to local climate conditions. For example, the conditions associated with an extreme drought in central Ohio can look like average, non-drought conditions in semi-arid western Kansas. Farmers in different regions tailor their crop choices, production systems, and decisions on inputs (like how much fertilizer to apply) based largely on average weather conditions in their area-which makes them vulnerable when those conditions change."}, {"section_title": "Adaptation to Drought Risk", "text": "In general, adaptation is the process of altering behaviors and characteristics to improve suitability to a given environment. For example, increased drought risk stemming from climate change may prompt farmers to alter their production practices or investments. Adaptive changes are generally taken to minimize damages to livelihoods stemming from adverse events, and/or to capitalize on any opportunities presented. Almost all farmer actions can be viewed as adaptation, because the physical, biological, and economic environment in which farmers operate changes continuously. The likelihood of increased risk and severity of drought-defined both by temperature and precipitation-is one of many factors to which farmers will adapt in coming years and decades (IPCC, 2014). Note: Drought frequency is the number of years when at least 1 summer month (June, July, or August) had moderate or worse drought (PMDI \u2264 -2.00). Source: USDA, Economic Research Service using historical data by climate district from the National Oceanic and Atmospheric Administration, Palmer Modified Drought Index (PMDI). Adaptation may be shortrun or longrun. Shortrun adaptation generally involves minimal fixed or sunk costs and often provides drought remediation for only one or two seasons. For example, shifting planted acreage from a drought-sensitive to a drought-tolerant crop would be a short-term adaptation to increased drought risk. Likewise, a shift into drought-sensitive crops would be adaptive for a farmer who is less exposed to drought (if prices of the drought-sensitive crop are expected to increase in response to changes in supply). Longrun adaptations to increased drought risk will generally be more expensive and less reversible, but sometimes more effective. For example, farmers may buy or sell land in response to changing expectations of its future value, or farmers could install water-saving infrastructure on their farms, such as checkdams on tile drainage systems. ERS research has shown that farmers in higher risk drought regions are more likely to enroll in the Environmental Quality Incentives Program (EQIP) for financial assistance that supports drought-mitigating practices ."}, {"section_title": "Irrigation and Drought Adaptation", "text": "Irrigation can be a straightforward response to drought. When available precipitation cannot meet crop water requirements, irrigators can add water to meet the demand if an adequate water supply is available. However, expanding irrigated acreage as a response to increased drought risk may not be feasible. Irrigation levels are constrained by water availability, which is a function of climate, geology, investments in the infrastructure required to store and transport water, and water allocation institutions. Irrigated acreage, as a percentage of total cropland, is clustered in particular areas, generally near major rivers, aquifers, and other accessible water sources ( fig. 3.16.3).  , 1998, 2003, 2008 and 2013. Irrigated acreage predominates in dry areas and areas with high drought risk. To the degree that climate change and/or competing uses of water reduces the supply of water for irrigation, farmers may adapt by improving their irrigation efficiency, such as by shifting irrigation to evening hours to reduce the amount of water lost to evaporation or investing in more efficient irrigation infrastructure (see chapter 2.10, \"Irrigated Agriculture\"). In some places, expansion of supplemental irrigation-where crops are primarily rainfed but water is applied when necessitated by dry spells-may be an effective adaptive response. Such responses are particularly timely amid hot and dry spells during critical crop-development periods, despite sufficient average rainfall. Increases in hot/dry spells are consistent with most projections of climate change into the coming century. Farmers generally have limited control over the availability of groundwater or surface-water reserves for irrigation. Irrigation reduces drought vulnerability in many areas by allowing farmers to augment precipitation where sufficient groundwater is available. In other areas, surface-water irrigation is possible, but its infrastructure is costly. Some irrigators rely almost exclusively on large aquifers, such as the Ogallala Aquifer in the High Plains and the Mississippi Embayment in the southern Mississippi River region. Many of these aquifers have recently been subjected to severe overdraft, which significantly reduces the availability of groundwater as a buffer to drought. In the intermountain West, many irrigators draw on both groundwater and surface-water supplies, which can allow users to apply excess surface water in wet years to replenish groundwater reserves that are overdrafted in dry years. In California and other Western States, surface-water supplies are highly vulnerable to drought. Reservoir storage systems help economize on irrigation supplies during periods of reduced stream flows, providing a buffer against short-term drought. However, reliance on surface water for irrigation creates its own form of drought vulnerability. Prolonged drought generally reduces the quantity of surface water delivered, compromising farm production systems that depend heavily on surface water for irrigation. Furthermore, most aspects of water allocation are under the purview of State laws. Many States have established institutions for allocating water rights among competing uses and users based on seniority (\"prior appropriation\" water rights). When water availability is low, senior water rights holders in those States are first in line for water allocation. Water is delivered fully in order of seniority until allocation limits are reached, and then remaining rights holders receive no deliveries. This makes irrigators with less senior water rights particularly vulnerable during periods of drought. In some areas, States and local water districts have established markets to allow for the trading of water rights."}, {"section_title": "Tile Drainage and Adaptation", "text": "Tile drainage ( fig. 3.16.4) has traditionally been installed to address problems of excess water, rather than drought. Tile drains help farmers to quickly remove excess water from the soil profile, allowing them to work the fields and avoid waterlogging. However, major droughts (e.g., 1956, 1988, and 2012) have led to yield losses in areas that are tile drained since these areas do not typically have irrigation. Modified tile drainage may allow some producers to temporarily restrict flow, if they are able to temporarily close or restrict the systems and retain more water in the soil profile as a safeguard against drought."}, {"section_title": "Soil Health and Adaptation", "text": "Many farms may lack the water supply to use irrigation as a drought adaptation strategy, or the slope and soil profile to make tile drainage effective. However, all farms may improve their resilience to drought by investing in soil health. Soil organic matter provides numerous agro-ecological functions and is a prime indicator of overall soil health (see chapter 3.19, \"Soil Health\"). Investing in soil health practices that increase soil organic matter can enable the soil profile to retain more water while also improving infiltration and reducing runoff during intense rain events. Effective soil organic matter practices vary by region and production system, but include conservation tillage and cover cropping. Both approaches encourage soil carbon stocks to accumulate faster than their natural rate of decomposition. While the economics of these systems are highly contextual and not fully understood, they may constitute an important adaptive strategy in many areas. "}, {"section_title": "Conclusion", "text": "A variety of options are available to farmers for adapting to drought risk. Few of these options will completely eliminate risk exposure, and almost all are constrained by existing institutional arrangements, public policies, and infrastructure investments. Drought adaptation includes not only irrigation but also tile drainage and measures to promote soil health. Chapter 3.17-Water Quality: Pollutants From Agriculture David Smith, Stacy Sneeringer, and Maria Bowman \u2022 According to the U.S. EPA's 2017 National Water Quality Inventory, 55 percent of assessed rivers and streams, 71 percent of lakes, and 84 percent of bays and estuaries nationally had impaired water quality as of 2016. \u2022 The number of U.S. water bodies designated as impaired increased 40 percent between 2005 and 2016, due mostly to the completion of new assessments. \u2022 An index of toxicity-weighted pesticide use, based on drinking water quality thresholds, has declined from 1992 to 2009, due primarily to restrictions on the use of a few pesticides. The Nation's water is an important resource that is necessary for survival and well-being. We rely on it for drinking, to irrigate our crops, and as a source of food and recreation. When water is polluted it can become unsafe to use and expensive to clean. Agriculture is one of the largest sources of pollutants in the Nation's rivers, streams, and lakes. Before leaving the field, these pollutants (i.e., fertilizers, chemicals, and sediments) are important for producing food. As both pollutants and productive inputs, fertilizers, chemicals, and soils have both positive and negative effects on human well-being. Under the Clean Water Act, water quality standards are set based on whether bodies of water are used for protection and propagation of aquatic life, for recreation, for public drinking water, and/or for other purposes. Water bodies not meeting these water quality standards are considered impaired and must have a pollution limit determined for them. Assessments, impairments, and pollution limits are reported to the U.S. Environmental Protection Agency (EPA) by the States as part of the National Water Quality Inventory. Because of the uneven implementation of the Clean Water Act across State governments, assessing trends in water quality is difficult. As of 2016, 32 percent of rivers and streams, 44 percent of lakes, and 64 percent of bays and estuaries have been assessed for water quality (U.S. EPA, 2017). Of those water bodies that have been assessed, 55 percent of rivers and streams, 71 percent of lakes, and 84 percent of bays and estuaries have impaired water quality; in short, the EPA determined that these 42,904 water bodies do not support their designated uses (e.g., fishing, recreation, and/or drinking water; EPA 2017). This is an increase of approximately 40 percent from 2005, when 25,823 water bodies were designated impaired. This increase in impairments is mostly due to the completion of new assessments of water bodies, therefore making it difficult to analyze trends in the number of water bodies that are polluted. The largest causes of impairments in rivers and streams are sediments, nutrients, and pathogens. While these pollutants can come from other sources, according to the National Water Quality Inventory, agriculture is the largest source of impairments in rivers and streams and the second largest source in lakes and ponds.\nAgricultural operations are uniquely suited for renewable energy production, as farms often require large amounts of electricity and feature ample space to house solar power installations or wind turbines. In other cases, nongrid-connected renewable power installations are the only way to economically power electric fences or water pumps in remote locations. As the economics of both utility-scale and distributed renewable power evolve, the rate of adoption of renewable power on farms may continue to increase; the share of farms with renewable power installations more than doubled from 2007 to 2012. Farms produce corn used in ethanol production as well as soybeans, canola, and animal fats used in biodiesel production. Increased acreage due to additional biofuel feedstock demand affects land management, with implications for soil productivity, water quality/quantity, air quality, and greenhouse gas (GHG) emissions. Because regions differ in how crop production translates to environmental outcomes, the effect on environmental indicators (e.g., soil erosion, nutrient runoff, and GHG emissions) varies considerably by region. In some regions, the changes in environmental measures are greater than the change in acreage, indicating an intensification of input use and, possibly, expanded production on marginal lands. Technological advances in cellulosic biomass may induce more farmers to grow cellulosic feedstock, such as switchgrass, for the advanced biofuel market. This development would carry with it the benefit of reduced nutrient runoff, as native grasses, including switchgrass, have extensive root networks that reach deep into the soil and increase water filtration, nutrient holding capacity, and erosion control. \u2022 Farmers can use management practices, such as no-till and cover crops, to build soil health. According to the 2012 Census of Agriculture, 35 percent of cropland acres were in no-till and 3 percent were planted with a cover crop. \u2022 As farmers have adopted soil health and soil conservation practices, they have contributed to declining rates of soil erosion. Between 1982 and 2012, erosion on cultivated cropland (due to water and wind) declined by 45 percent. \u2022 USDA incentivizes farmers to adopt soil health practices through programs such as the Environmental Quality Incentives Program (EQIP) and the Conservation Stewardship Program (CSP). Between 2006 and 2016, the number of acres receiving EQIP payments for cover cropping more than quadrupled. Between 2010 and 2015, the number of acres receiving CSP payments for at least one soil health practice or enhancement grew from just under 7 million to more than 30 million. Soil health refers to \"the continued capacity of soil to function as a vital living ecosystem that sustains plants, animals, and humans\" (USDA Natural Resources Conservation Service, 2017a). Healthy soil can support crop or livestock production, while at the same time generating ecosystem services-such as reducing nutrient pollution to streams and rivers-that benefit society. Soil scientists have developed several indicators-soil organic carbon, soil aggregation, readily available carbon/nitrogen pools, and soil microbial activity/diversity-that reflect underlying soil processes to help assess the health of agricultural soils (NRCS, 2018b). Soil health is related to soil type and location, but can also be influenced by land use and management decisions made by farmers. One important indicator of soil health, soil organic carbon, varies greatly across the United States ( fig. 3.19.1). "}, {"section_title": "Major Agricultural Pollutants", "text": "Sediment is the second largest cause of water quality impairments, just behind pathogens, in rivers and streams (U.S. EPA, 2017). Historically, much of this sediment was thought to be due to erosion on agricultural fields. In the 1980s and 1990s, however, erosion rates declined (see figure 3.19.3 in \"Soil Health\") due to improved cropping practices such as conservation tillage (see chapter 3.24, \"Working-Lands Conservation Programs\"). Cropping practices, such as tile drainage, also contribute to sediment erosion within river and stream channels through increases in peak stream flow (Argabright et al., 1996;Zaimes et al., 2006;Belmont et al., 2011;Schottler et al., 2014). Agriculture is the largest source of impairments from sediment followed closely by within-channel sources (i.e., hydro modification and habitat alterations). Significant sediment loss occurs in areas with high rates of water erosion and/or a high proportion of agricultural land (see chapter 1.2, \"Major Land Uses\"). Total sediment losses due to water erosion are highest in the Corn Belt and the Mississippi Delta due to the high proportion of land used for agriculture (figure 3.17.1). Field erosion rates are highest in the southeastern U.S. due to high precipitation and steep topography. "}, {"section_title": "Soil loss (tons) by county due to water erosion, 2012", "text": "1,200,000 -6,000,000 600,000 -1,200,000 300,000 -600,000 200,000 -300,000 100,000 -200,000 Less than 100,000 No data Soil loss (tons per year) Source: USDA, Economic Research Service using data from the 2012 National Resources Inventory (USDA, 2012b). Nitrogen and phosphorus are the second leading cause of impairments in lakes (mercury is the leading cause) and the third leading cause in rivers and streams (EPA, 2017). Excess nutrients can cause algal blooms, which can kill fish and other aquatic life. Algal blooms can even make people sick from the toxins produced and elevated bacterial levels. Nitrogen can also contaminate ground water. In agricultural areas, nitrate concentrations exceeded Federal drinking water standards in 20 percent of shallow domestic wells (Dubrovsky et al., 2010). Crop farmers require these nutrients to grow their crops (see chapter 2.9, \"Nutrient Management\"), and often add nutrients to the soil by applying fertilizer or manure. While most nutrients are taken up by crops and pasture, nitrogen and phosphorus can leave the field or pasture and contaminate surface water through runoff and/or ground water through leaching. Sometimes farmers have leftover manure after applying enough to meet the nutrient needs of the crops. Farms with excess manure can transport or sell manure to other farms or businesses that can use or dispose of the manure (see chapter 2.14, \"Manure Figures 3.17.2 and 3.17.3 show the ratio of the county-wide amount of available nutrients to the agronomically appropriate nutrient requirements for crops and pasture. Available nutrients include the amount of manure nutrients recoverable for later application to crops and pasture plus purchased commercial fertilizer. Values of the ratio greater than one suggest that farms within that county use more manure and fertilizer nutrients than are being taking up by crops and pastures, and therefore these counties exhibit a higher risk of nutrient runoff or leaching. The measure underestimates the risk of run-off, because it allows for recoverable manure nutrients to be applied off-farm within a county, instead of just on the farm where it is generated (see Gollehon et al., 2017, for estimates of farm-level excess). Other factors also contribute to run-off risk, including the prevalence of tile drainage, proximity to waterways, topographic features, and soil quality. Available nutrients tend to exceed agronomic cropland and pastureland needs in counties with high levels of manure from livestock production and little available cropland and pastureland.  "}, {"section_title": "Ratio of phosphorus from commercial fertilizer and manure to crop/pasture uptake by county, 2012", "text": "County ratio Under USDA, Natural Resources Conservation Service (NRCS) assumptions of \"full\" nutrient management, if 1.2 pounds of nitrogen are applied to a crop or pasture, 0.2 pound is either lost to the environment or returned to the soil as the non-harvested portion of the plant. Under \"acceptable\" nutrient management, if 1.4 pounds of nitrogen (1.05 pounds for phosphorus) are applied, then 0.4 pound is lost. In figure 3.17.2, counties with a ratio of nitrogen applications to uptake greater than 1.4 are at a higher risk for nutrient run-off even if only \"acceptable\" nutrient management is employed. Farmers use pesticides to control insects (insecticides), weeds (herbicides), fungus (fungicides), and other pests (see chapter 2.8, \"Pest Management\"). In 2014, nearly 1 billion pounds of active ingredients were applied on U.S. cropland (USGS, 2017). Once applied, pesticides can remain in the soil for weeks, months, or years. On average about 30 percent of the pesticides applied remain in the soil after 60 days (figure 3.17.4). Persistent pesticides, with long half-lives, can travel off the field and into waterways where they may harm fish and other aquatic life. Pesticides are the cause of over 1,800 impaired water bodies in the United States (EPA 2017). Agricultural pesticides that cause the most impairments are Dichlorodiphenyltrichloroethane (DDT), chlorpyriphos, and atrazine. DDT is an insecticide that was banned by the EPA in 1972 but persists in the environment for years. Chlorpyriphos is an insecticide used in the production of corn, orchards, and grapes. Atrazine is an herbicide used primarily in corn for weed control. Use of atrazine has ranged between 60 and 80 million pounds annually despite increases in the use of alternative herbicides such as glyphosate (USGS, 2017). Pesticides may also contaminate ground water and well water. Pesticides were detected in 53 percent of groundwater samples but the levels seldom (1.8 percent of samples) exceeded drinking water quality benchmarks (Toccalino et al. 2014). In the 1990s, toxicity, as measured by an index based on drinking water quality thresholds, declined (Figure 3.17.4), primarily due to restrictions on the use of an insecticide primarily used in cotton production (parathion) and an herbicide primarily used in corn production (cyanazine). Higher toxicity from agricultural pesticides occurs in the Corn Belt due primarily to the continued use of atrazine on corn (figure 3.17.5). Fumigant use in fruit and vegetable production contributes to the high toxicity of pesticides used in the Southeast, California, and the Pacific Northwest. Toxicity (water quality, 1996 = 1.0) Index Note: The agricultural pesticide toxicity index is calculated by dividing the average pesticide usage (kilograms per acre) by the water quality threshold (parts per billion) for each active ingredient and then summing across all active ingredients. The index for toxicity is normalized so that the index equals 1.0 in 1996 and so only comparisons between years are valid. The index for the persistence of agricultural pesticides is the estimated average percentage of the initial application that is still in the soil at 60 days based on the soil half-life and the formula for exponential decay. Source: USDA, Economic Research Service based on data from the U.S. Geological Survey (2017) and . Agricultural pesticide toxicity index using water quality thresholds by county, 2014 Toxicity index 0.00 -0.08 0.09 -0.21 0.22 -0.38 0.39 -1.00 > 1.00 No data Note: The agricultural pesticide toxicity index is calculated by dividing the average pesticide usage (kilograms per acre) by the water quality threshold (parts per billion) for each active ingredient and then summing across all active ingredients. This index is normalized so that it equals 1.0 for the average index per acre in 2014. Source: USDA, Economic Research Service based on data from the U.S. Geological Survey (2017) and . Following new guidance in 1996 from the EPA, the last two decades have been marked by a dramatic increase in the number of Clean Water Act assessments and the number of pollution limits. Since 2005, States have issued over 50,000 pollution limits, with two-thirds of river and stream miles, half of lakes, and a third of bays/estuaries still to be assessed. Agricultural sources of pollution are largely exempt from regulation under the Clean Water Act. Therefore, the Federal Government relies on voluntary conservation programs (see chapter 3.21, \"Conservation Spending\") and grants to States to reduce agricultural point and nonpoint sources. Of the water bodies that have been assessed and found to be impaired, only 5 percent have been restored enough to support their designated use."}, {"section_title": "Chapter 3.18-Renewable Energy", "text": "Claudia Hitaj and Scott Malcolm \u2022 From 2007 to 2012, the number of farms producing onfarm renewable energy more than doubled to 57,299 (2.7 percent of all farms). \u2022 Ethanol production grew from 3.9 billion gallons in 2005 to 15.8 billion gallons in 2017. \u2022 In the 2016-17 marketing year, about 37 percent of corn production was used as a feedstock for ethanol production, and about 27 percent of soybean production was allocated to biodiesel production. Since the early 2000s, farmers have increased renewable energy production in response to cost and technology improvements, as well as Government incentives for renewable energy and the Renewable Fuel Standard (RFS), which mandates the use of biofuels in transportation. Onfarm energy-generation technologies include wind power, solar power, small hydropower, methane digesters, and geothermal exchange. Farmers can also produce renewable power indirectly by growing biomass feedstocks, leasing land for utility-scale solar power installations, or leasing their wind rights and hosting utility-scale wind turbines. Some of the renewable power produced on farms is for the farm's own consumption only-such as for solar-powered electric fences or water pumps for watering livestock in remote areas-and is not grid-connected. Farmers can also connect their renewable power systems to the grid, receiving a credit for part of the electricity generated and selling any excess electricity to the grid. At the other extreme, the renewable power produced may go exclusively to the grid, as in the case of utility-scale wind turbines that are part of a larger wind power plant facility potentially covering multiple farms."}, {"section_title": "Onfarm Renewable Power Production Varies Regionally", "text": "In 2007, 23,451 U.S. farms (1.1 percent of all U.S. farms) produced energy onfarm with solar panels, geothermal exchange, wind turbines, small hydro, or methane digesters (USDA-NASS, 2014). By 2012, farms producing renewable energy had more than doubled to 57,299 (2.7 percent of farms) ( fig. 3. USDA defines a farm as any place that produced and sold or normally would have produced and sold at least $1,000 of agricultural products during a given year. Farm businesses include only farms where the primary operator is currently employed and spends the majority of work time on agricultural production, or, if the primary operator is largely employed off-farm, the operation has over $350,000 in annual gross cash farm income. Note: Ethanol and biodiesel refer to farms producing these biofuels directly for consumption by the operation and do not refer to farms growing feedstocks, such as corn and soybeans, used to produce biofuels. Source: USDA, Economic Research Service using data from the 2012 Census of Agriculture (USDA, NASS, 2014). The capacity of renewable energy systems installed onfarm is, on average, less than 100 kilowatts (kW) for wind and 4.4 kW for solar (Xiarchos and Vick, 2011). However, a small wind system of 100 kW can generate 840 kilowatt hours (kWh) in a day (assuming a 35-percent capacity factor), meeting a substantial share of electricity consumption on most operations. In 2014, electricity consumption on farms ranged from about 1,110 kWh per day for peanut farms to 806 kWh per day for dairy farms, 250 kWh per day for corn farms, and 150 kWh per day for wheat farms. 2"}, {"section_title": "Solar Power", "text": "In agriculture, solar energy can be used in a solar thermal system or in a photovoltaic (PV) system to convert solar radiation to electricity. Solar energy generated on farms is used to power electric fencing, lighting, water pumps, pond aeration, and ventilation. Farmers can take advantage of the Federal investment tax credit, which amounts to 30 percent of expenditures to install a solar system after the exclusion of any subsidized portion of the project."}, {"section_title": "Wind Power", "text": "In 2012, wind turbines could be found on 9,054 U.S. farms. Most turbines are owned by energy companies who lease the wind rights from the farm landowners. A 2009 survey, which limited the response to wind turbines owned by the farm operation, showed that only 1,420 U.S. farms (0.06 percent of operations) owned wind turbines, and the majority of these turbines had a capacity of less than 100 kW (smallscale) (USDA-NASS, 2011). In contrast, utility-scale wind turbines have a capacity of 1,000 to 2,500 kW. In 2014, farm operators who leased their wind rights earned on average $3,320 per year in lease income (table 3.18.1). Income from leasing oil and gas rights, such as for drilling oil or gas wells in shale plays, is much higher, averaging $57,000 in 2014 for the United States as a whole and about $157,000 in Pennsylvania (Marcellus shale) and North Dakota (Bakken shale) (Hitaj and Suttles, 2016). "}, {"section_title": "Biofuel and Cellulosic Feedstock Production", "text": "Since 2005, the Renewable Fuel Standard and its supporting programs have contributed to a growing market for renewable transportation fuels. Ethanol production grew from 3.9 billion gallons in 2005 to 15.8 billion gallons in 2017 (EIA, 2018a). In the 2016-17 marketing year, about 37 percent of corn production was used as a feedstock for ethanol production, while about 27 percent of soybean production was allocated to biodiesel production (USDA-ERS, 2018). The biodiesel market is smaller than the ethanol market, and soybeans provide about half of biodiesel feedstocks. In 2017, 1.6 billion gallons of biodiesel were produced from soybeans (53 percent), animal fats (9 percent), corn oil (13 percent), and canola oil (12 percent), among other sources (EIA, 2018b). Biofuels are generally produced in commercial ethanol and biodiesel plants, though some farms (less than 0.3 percent of farms in 2012) produce biofuels directly on the operation: 4,099 farms produced biodiesel and 2,364 farms produced ethanol in 2012. Biodiesel and ethanol produced directly on farms can be for farm use or for outside sale. Unlike ethanol and biodiesel, cellulosic biofuels are derived from nonfood biomass feedstocks, including crop residues, wood wastes, energy crops, and municipal solid wastes. Volumes of cellulosic biofuel production are small relative to corn ethanol production in the RFS, although cellulosic feedstocks can also be used for electricity production. Cellulosic biomass may have an advantage over conventional biofuels because its sources are either waste products or dedicated energy crops, such as switchgrass and miscanthus, which may be harvested from land not productive for food agriculture. Technological challenges in producing biofuel from cellulosic feedstocks have resulted in annual reductions of the cellulosic biofuel mandate in the RFS since enactment of the Energy Independence and Security Act in 2007. The mandate was first exceeded in 2014 with production of 33 million gallons of cellulosic ethanol. In 2012, nearly 12,000 farms (0.5 percent) harvested cellulosic biomass, including crop residue, grasses, and woody biomass (and excluding grains, oilseeds, and wood), for use in the production of renewable energy (USDA-NASS, 2014)."}, {"section_title": "Soil organic carbon stocks in the United States, 2013", "text": "Estimated carbon stocks in top 100 centimeters Many farmers and ranchers use practices that contribute to soil health, such as no-till or reduced tillage, cover cropping, nutrient management, and prescribed or rotational grazing of livestock (see box, \"Selected Soil Health Management Practices\"). These practices exemplify one or more key principles that contribute to soil health: keep the soil covered as much as possible, disturb the soil as little as possible, keep plants growing throughout the year to feed the soil, and diversify as much as possible using crop rotation and cover crops (USDA Natural Resources Conservation Service, 2017). According to the 2012 Census of Agriculture, 35 percent of U.S. cropland acres were in no-till, and 3 percent were planted with a cover crop. Over 130,000 farms (9 percent of farms) planted a cover crop in 2012 (excluding Conservation Reserve Program acreage) for a total of 10,280,793 acres. Almost a quarter of the cover crop acreage nationally was planted on farms ranging in size from 200 to 499 acres; 22 percent was on farms with more than 1,000 acres. Though smaller farms made up a small share of the total acreage planted to cover crops, 70 percent of the operations that planted cover crops farmed fewer than 50 acres. Some regions report using practices such as no-till and cover crops more frequently. For example, no-till/ strip-till and cover cropping were more widely used in the Southeast in 2012 (fig. 3.19.2;Wade et al., 2015). Farmers manage their soil differently due to many factors, including topography and local weather patterns. Farmers with hilly or bare land may derive more benefits from implementing practices such as no-till because they decrease soil erosion and benefit crop production. Fields with high erosion indexes may also be required to implement such practices as part of \"conservation compliance\" in order to be eligible to receive farm program benefits (Claassen et al., 2017). Cover cropping may be more common in the Southeast due to greater relative benefits from weed control or from cover cropping on ultisol soils that suffer from poor soil texture/structure and low organic matter (Duzy, 2017). It may also be easier to establish and terminate a winter cover crop in the Southeast, which has a longer growing season than most other regions (see chapter 2.12, \"Crop Production Management: Tillage Practices\"). "}, {"section_title": "Share of harvested cropland acreage with cover crops by county, 2012", "text": "Percent with cover crops 0-1 1-5 5-10 10-15 15-56 Note: County boundaries are clipped to show only cropland. Source: USDA, Economic Research Service using data from the 2012 Census of Agriculture . Other areas may have high rates of cover cropping because State agencies or local groups provide payments to cover the cost of seed, labor, and equipment to grow cover crops. For example, in Maryland, nearly 560,000 acres were planted to cover crops (more than 27 percent of the State's cropland acres) in 2016-17 as the result of a State program that paid $35-$75/acre for farmers to plant a cover crop (USDA National Agricultural Statistics Service, 2012; Maryland Department of Agriculture, 2016 and 2017). Another management practice that contributes to soil health is rotational or management-intensive grazing, practiced by 23 percent of farms with pastureland according to the 2012 Census of Agriculture. In addition, farms with certified organic crop acreage use soil health practices such as cover cropping in combination with manure application to substitute for synthetic nitrogen use and maintain soil health and fertility (see chapter 2.13, \"U.S. Organic Farming Systems,\" chapter 2.9, \"Nutrient Management,\" and chapter 2.12, \"Crop Production Management: Tillage Practices\"). As farmers have adopted soil health and soil conservation practices, they have helped reduce soil erosion (for more information on the impact of soil erosion on water quality, see chapter 3.17: \"Water Quality: Pollutants From Agriculture\"). Between 1982 and 2012, the NRCS National Resources Inventory (NRI) shows erosion on cultivated cropland (due to water and wind) declined by 45 percent, from 2.9 billion tons in 1982 to 1.6 billion tons in 2012 ( fig. 3.19.3). Though part of this decline is due to less land being cropped over time, a large portion is due to changes in farm management practices. Recent evidence suggests that some farmers may be monitoring the health of their soil. For example, the 2015 Agricultural Resource Management Survey (ARMS) found that 16 percent of farmers with cotton fields and 11 percent of farmers with oat fields report testing their soil for soil organic matter .  1982 1987 1992 1997 2002 2007 2012 Water (sheet and rill) Wind Source: USDA, Economic Research Service using data from the National Resources Inventory (Claassen et al., 2017). Farmers may benefit from improving soil health through improved yields in crop production or in forage production for ranchers. 1 In addition, the soil's ability to hold more water may help crops withstand extreme weather, including droughts or floods (see chapter 3.16, \"Farm-Level Adaptation to Drought Risk\"). Other benefits can include lower fertilizer or pesticide costs due to improved nutrient cycling or pest/weed suppression, as well as a sense of well-being from environmental stewardship. Society can also benefit when farmers manage for soil health. Healthy soil can have a positive impact on water quality by decreasing soil erosion and nutrient runoff into streams and rivers (see chapter 3.17, \"Water Quality\"). Enhanced soil health can also lower greenhouse gas emissions from agriculture and increase carbon storage, helping to mitigate climate change. Because societal benefits do not accrue to farmers themselves, they may not always consider such benefits when they make decisions about using soil health practices. There may also be uncertainty and tradeoffs with respect to the public benefits of soil health practices. For example, crops that are genetically engineered to be resistant to the herbicide glyphosate have facilitated no-till and cover crop adoption because farmers are able to use herbicides for weed control and to terminate cover crops before planting the subsequent crop. However, to the extent that herbicide use increases with no-till or cover crop use, this could hasten the development of herbicide-resistant weeds or compromise the health of soil biota (Kremer et al., 2007)."}, {"section_title": "Change in pollinator Forage Suitability Index (FSI), 2002-2012", "text": "Oversummering grounds Percent change in FSI -100 to -6 -6 to -3 -3 to 3 3 to 6 7 to 100 Note: Each hexagon covers 600 square miles. Data are not displayed in hexagons that have less than 10 NRI points (blank with no border). The \"oversummering\" area of the Dakotas is outlined in black. Source: USDA, Economic Research Service analysis using land use/cover data from USDA, Natural Resources Conservation Service, National Resources Inventory (NRI) and forage suitability scores from Koh et al. (2016)."}, {"section_title": "114", "text": "Chapter 3.21-Conservation Spending Seeks To Improve Environmental Performance in Agriculture"}, {"section_title": "Roger Claassen", "text": "\u2022 Conservation programs provide financial and technical assistance to support the adoption of conservation practices on U.S. farms. \u2022 After significant increases in conservation program spending under the 2002 and 2008 Farm Acts, funding leveled off under the 2014 Act. \u2022 The shift in funding from land retirement to working land programs, begun under the 2002 Farm Act, continues. Note: This chapter was prepared before the Agriculture Improvement Act of 2018 became law. For an update on conservation programs and conservation program spending, please see Agriculture Improvement Act of 2018: Highlights and Implications on the Economic Research Service website. Some farming practices can degrade natural resources and the environment. Sediment, nutrient, and pesticide runoff and leaching, for example, can impair water quality (see chapter 3.17, \"Water Quality: Pollutants from Agriculture\"). Other practices can provide environmental benefits through careful management of agricultural land. For example, enhancing wildlife habitat on agricultural land by providing nesting material for migratory birds can help increase wildlife populations. USDA's conservation programs help agricultural producers improve environmental factors like soil quality, water quality, air quality, wildlife habitat, and greenhouse gas emissions."}, {"section_title": "A Portfolio of Incentive Programs", "text": "The USDA conservation effort relies mainly on voluntary incentive programs. Voluntary incentive programs can avoid the inherent difficulties in regulating geographically diffuse and elusive (difficult to monitor) sources of pollution and can minimize economic harm to farmers by offering a range of incentives and assistance programs. The following programs account for more than 95 percent of all USDA conservation program spending. The Conservation Reserve Program (CRP) generally provides 10-to 15-year contracts to remove land from agricultural production. The latest acreage cap under the 2014 Farm Act for this program is 24 million acres. Most of the land enrolled in the CRP was in crop production prior to CRP enrollment and is now planted to grass or trees. Historically, a large majority of CRP contracts enrolled whole fields or whole farms. Increasingly, however, CRP contracts fund high-priority, partial-field practices such as filter strips and grass waterways, rather than whole-field or whole-farm enrollments (see chapter 3.23, \"Conservation Reserve Program\"). Up to 2 million acres of the 24 million acre CRP cap can be used for a specific grasslands enrollment where each landowner agrees to keep the land in grazing use rather than tilling it for crop production or converting it to any other use. The Agricultural Conservation Easement Program (ACEP) provides long-term or permanent easements for preservation of wetlands and the protection of agricultural land (cropland, grazing land, etc.) from commercial or residential development."}, {"section_title": "115", "text": "The Environmental Quality Incentives Program (EQIP) provides financial assistance to farmers who adopt or install conservation practices on land in agricultural production. Common practices include nutrient management, cover crops, conservation tillage, field-edge filter strips, and fences to exclude livestock from streams. Sixty percent of program funds are targeted to livestock-related practices and at least 5 percent are targeted to wildlife-related practices. The Conservation Stewardship Program (CSP) supports ongoing and new conservation efforts for producers who meet stewardship requirements on working agricultural and forest lands. Farmers and ranchers must demonstrate a high level of stewardship to be eligible for the program and must agree to further improve environment performance over the life of the CSP contract (up to 10 years). Participants receive financial assistance for adopting new conservation practices and for stewardship, based on previously adopted practices and the ongoing maintenance of those practices. The Regional Conservation Partnership Program (RCPP) is designed to coordinate conservation program assistance with partners to solve problems on a regional or watershed scale. Financial assistance is coordinated through RCPP but provided to producers largely through \"covered\" programs: EQIP, CSP, ACEP, and the Healthy Forests Reserve Program. Up to 7 percent of the dollars or acres available/eligible under each of these programs is allocated through RCPP. Finally, through Conservation Technical Assistance (CTA), USDA provides ongoing technical assistance to agricultural producers who seek to improve the environmental performance of their farms. Over time, a natural back-and-forth shift between dryland and wetland habitat results in variations in wetland acreage. Natural shifts occur, for example, when changes in groundwater levels turn dryland to wetland, or vice versa. Between 1992 and 2012, about 1.5 million wetland acres became dryland and some other type of aquatic habitat, while about 1.6 million dryland and non-wetland aquatic habitat acres became wetland (table 25 "}, {"section_title": "USDA Wetland Conservation Efforts", "text": "USDA protects wetlands through Wetland Compliance (WC), the Conservation Reserve Program (CRP), the Wetlands Reserve Program (WRP), and the Agricultural Conservation Easement Program (ACEP). Wetland Compliance (WC)-also known as \"Swampbuster\" -was established in the 1985 Farm Act and aims to protect existing wetlands by penalizing farmers who convert wetlands (e.g., by taking away their eligibility for most USDA programs). WC does not prohibit the use of wetlands and is not designed to improve wetland ecosystems, but proponents argue that it protects some wetlands at little cost. Others argue that the program is ineffective and imposes a burden on farmers. Claassen et al. (2017) evaluated the effectiveness of WC and concluded that, across their study area (the Prairie Pothole Region of Montana, the Dakotas, Minnesota, and Iowa), WC is likely to be effective at preserving about 75 percent of potentially productive wetland acreage, offer limited protection on 15 percent, and be ineffective on the remaining 10 percent. In that study, WC was considered to be effective when expected compliance penalties exceeded the profitability of farming the drained wetland acreage, ineffective when there was no compliance penalty, and moderately protective otherwise. 1 The Conservation Reserve Program (CRP) sets aside cropland through 10-and 15-year rental contracts. The CRP establishes grassland, forestland, and wetland cover. By retiring the land and establishing vegetation, the CRP protects and improves wetland ecosystems while the land is under contract. The CRP began targeting wetlands (with the surrounding uplands) in 1997. Most wetlands existed prior to program enrollment and were farmed when conditions allowed. While the bulk of CRP wetlands are enrolled via the Wetland Restoration conservation practice (CP23), USDA's Farm Service Agency (FSA) enrolls wetland under the CRP Farmable Wetlands Program and a variety of other continuous conservation initiatives such as Duck Nesting (CP 37) and Bottomland Hardwood Trees (CP31). 2 CP 23 contracts are a mix of wetland and upland buffer. This buffer, which helps protect and improve the health of wetland ecosystems, cannot be more than three times the size of the wetland. CRP wetland acreage trended upward until 2008-when the early CP23 agreements began to expire-and has varied in subsequent years. After reaching 2.3 million acres in 2012, CRP wetland acreage has not fluctuated substantially; as of July 2018 it stands at 2.3 million acres. This includes 1.2 million acres under CP23, 440,000 acres under CP37, and 300,000 acres in the Farmable Wetland Program. For all CRP acres in a wetland practice, inflation-adjusted rental rates showed little change until 2008, when they began to rise sharply, nearly doubling to about $117 (2016 dollars) by 2017 ( fig. 3.22.1)."}, {"section_title": "Wetlands' Private Costs and Public Benefits", "text": "Wetlands may impose costs on farmers and provide a variety of private and public benefits. Gelso, Fox, and Peterson (2008) evaluated two types of wetland costs-opportunity costs (loss of the land's output) and nuisance costs (expenses incurred by the need to maneuver equipment around wetlands). Based on a survey of farmers, they found nuisance costs to be substantially greater than opportunity costs. In one scenario, a 1.6-acre wetland on a 160-acre field was estimated to impose an annual opportunity cost of $71 and a nuisance cost of $529 (2016 dollars). Analysts have not yet been able to measure the size and value of USDA's impact on wetland ecosystems. Wetlands' public benefits depend on the value the public places on the services provided by wetland ecosystems. Two recent studies (Hansen et al. (2015) and Hansen and Loesch (2017)) evaluated some wetland ecosystem services and estimated that: \u2022 The annualized values of new wetlands' sequestration of greenhouse gases range from $0 to $138 per wetland acre in the areas studied. \u2022 The benefits duck hunters gain from new Prairie Pothole wetlands range from near $0 to $154 per wetland acre per year. These benefits exceed the cost of restoring and protecting the wetland in about 60 percent of the region. Being shallow, isolated, and often wet only in the spring, the Prairie Pothole wetlands provide excellent duck nesting habitat. However, because of these characteristics, they provide virtually no fishing benefits. \u2022 Across about half of the Upper Mississippi and Ohio River watersheds, new wetlands can remove water-borne nitrogen for less than $0.17 per pound. \u2022 Wetlands are not likely to provide notable flood-protection benefits unless they are located where flooding is due to short, rapid downpours and they are directly upstream of urban areas. \u2022 In 2014, 597 wetland-associated species were listed as imperiled. However, the value of new wetlands' contribution to increased species survival cannot be calculated because the effects of new wetlands and the values the public places on increased survival probabilities are unknown.  \u2022 About 35 percent of CRP acres is enrolled through continuous signups that target high-priority environmental concerns. \u2022 Between 2012 and 2014, acceptance rates in CRP's general signups increased from about 66 percent to 80 percent, but then declined to 22 percent in 2016. Now over 30 years old, as of October 2018 the USDA's Conservation Reserve Program (CRP) had enrolled over 22.4 million acres of environmentally sensitive cropland under 10-to 15-year contracts with qualifying landowners. With 2018 annual rental payments of around $1.8 billion, the CRP continues to be USDA's largest conservation program (see chapter 3.21, \"Conservation Spending Seeks To Improve Environmental Performance in Agriculture\"). The CRP is voluntary, with eligible landowners offering to enroll land primarily under one of two methods with a third option added under the 2014 Farm Act. In the first two types of enrollment, land enrolled in the CRP is retired from crop production, and the land is planted to a selected \"conservation practice\" such as native grasses, tree cover, or pollinator habitat. The older, and larger, method is \"general signup.\" General signups, which normally occur every year or few years, are several weeklong periods during which landowners can submit offers to enroll cropland in the CRP. At the end of the signup period, the program scores each offer using an Environmental Benefits Index (EBI), 1 and then accepts all qualified offers that exceed a threshold score. The second enrollment type (established in 1996) is \"continuous signup,\" which accepts offers at any time of the year, though these offers must meet more stringent eligibility criteria. There are a number of continuous signup initiatives, each with its own geographic and coverpractice requirements. The third enrollment type is CRP Grasslands enrollment, which has a continuous signup with ranking periods. Under CRP Grasslands, landowners and operators can protect grassland-including rangeland, pastureland, and certain other lands-while maintaining the areas as grazing lands. The CRP's size and goals have changed, from its early emphasis on limiting crop production and soil erosion to one that now considers a broad set of conservation goals including wildlife and pollinator habitat, as well as soil, water, and air quality. The CRP allows for grazing in limited circumstances. Driven by improvements in conservation practices and evolving legislative mandates, commodity markets, and environmental concerns, the CRP continues to adapt."}, {"section_title": "Multiple Resource Concerns Are Addressed", "text": "Working-lands programs address multiple resource concerns on farms, including air quality (odor, gaseous emissions), livestock and poultry waste (manure), fish and wildlife habitat, plant condition (forage quality, noxious and invasive plants), soil condition (organic matter, compaction, salinity), soil erosion, water quality, and water quantity (drainage, irrigation). Plant condition, water quality, and soil erosion are the resource concerns that received the largest shares of financial assistance in the EQIP program ( fig. 3.24.2). (Similar data are not available for CSP.) Resource concerns addressed through EQIP vary widely across regions, driven largely by climate and predominant types of agriculture ( fig. 3.24.3). Water quantity is a major issue in regions where irrigated crops are common: the Basin and Range, Mississippi Portal, Fruitful Rim, and Prairie Gateway regions. Water quality and soil erosion are major concerns in the Heartland, Mississippi Portal, Southern Seaboard, and Northern Crescent regions.  "}, {"section_title": "Distribution of Environmental Quality Incentives Program contract obligations by resource concern, 2011-13", "text": "Air quality, 3% Domestic animals, 10% Energy, 1% Fish and wildlife, 11%"}, {"section_title": "Plant condition 22%", "text": "Soil condition 10%"}, {"section_title": "Soil erosion 19%", "text": "Water quality 19% Water quantity, 8% Note: Contracts that address multiple resource concerns have total obligations divided equally between those concerns for purposes of calculating the shares of funding for each concern. Source: USDA, Economic Research Service analysis of data from USDA, Natural Resources Conservation Service, ProTracts database. Note: Contracts that address multiple resource concerns have total obligations divided equally between those concerns for purposes of calculating the shares of funding for each concern. Contracts are assigned to regions based on administrative county codes. Source: USDA, Economic Research Service analysis of data from USDA, Natural Resources Conservation Service, ProTracts database. Figure 2.14.1 uses the 2012 Census; the 2017 Census will be released in the spring of 2019. Tables 2.14.1 and 2.14.2 use the 2009 hog, 2010 dairy, and the 2011 broiler surveys. The broiler survey is the latest available, with no date set for a future survey. More recent hog and dairy surveys (2015 hogs, 2016 dairy) do not ask detailed questions about manure handling (e.g., how the manure was applied, whether and how it was removed, whether the operation has a nutrient management plan, whether the operation adjusted manure nutrient content via feed, or whether the farm received EQIP payment for manure management), and so were not used. Chapter 2.15: Antibiotic Use in U.S."}, {"section_title": "Livestock Production", "text": "Data on broilers raised without antibiotics except for disease treatment are from the 2006 and 2011 ARMS broiler surveys. The 2011 broiler survey is the latest available, with no date set for a future survey. The 2017 statistic on broilers produced under product lines termed \"raised without antibiotics\" is from USDA AMS Agricultural Analytics. Data from the 2004, 2009, and 2015 ARMS hog surveys are used to estimate the percentage of hogs that were administered antibiotics for growth promotion; the 2015 hog survey is the latest available. Statistics quoted from APHIS's National Animal Health Monitoring System (NAHMS) use the most recent surveys available. Chapter 3.16 Farm-Level Adaptation to Drought Risk Data on crop insurance and drought comes from USDA, Risk Management Agency's publicly available \"Summary of Business -Cause of Loss\" files and is adjusted using ERS farm-income data. Data for the drought risk measure come from publicly available National Oceanic and Atmospheric Administration (NOAA) Palmer Drought Index historical data from 1900 to 2016. The data on irrigated cropland are from the Census of Agriculture publicly available county-level data and are up to date (1998)(1999)(2000)(2001)(2002)(2003)(2004)(2005)(2006)(2007)(2008)(2009)(2010)(2011)(2012)(2013). The tile drainage map is from a special requested dataset from NASS from the 2012 Census of Agriculture. Chapter 3.17: Water Quality: Pollutants From Agriculture Data are from the 2012 Census of Agriculture and the USGS Pesticide National Synthesis Project . We also use the EPA 2017 Water Quality Assessment. The most recent USGS Pesticide National Synthesis Project data are available for 2015. We choose not to use the 2015 data because there was a major shift in methodology in 2015. Starting in that year, no data on seed treatments were reported."}]