[{"section_title": "Introduction", "text": "One of the six national goals states: \"13y the year 2000, American students will leave grades four, eight, and twelve having demonstrated competency over challenging subject matter, including... mathematics (U.S. Department of Education, 1990. P.5). Related to this goal, mathematics reformers suggest that the intent of mathematics instruction should include to promote learning across a broad range of mathematical topics, and to promote learning of mathematical thinking, reasoning, and problem-solving skills (e.g. American Association for the Advancement of Science, 1989;National Council of Teachers in Mathematics, 1989;National Research Council, 1989). The question we are left to answer is \"How do we most effectively promote the learning of mathematics?\" Much of the research on educational attainment concludes that the effects of educational inputs such as per pupil spending, teacher experience, and teacher educational background are unimportant predictors of education outcomes. Additionally, the impact of an educational input is inconsistent across studies. Moreover, research suggests that individual and family background information explain most of the variation in student achievement (Hanushek, 1986). In order to ensure that the most is being done to improve the learning of mathematical skills among our nation's youth including mathematics thinking, reasoning, and problem solving skills, we must engage in the rigorous study of factors that affect learning. The current paper suggests that this should be done via the utilization of criterion-referenced scores such as probability of proficiency scores. Proficiency scores allow one to asses how well as student has mastered concepts within a given skill category, while the probability of proficiency score offers the probability that a student is proficient at a given skill level. Research of factors related to 4 Probability of Proficiency 4 student learning typically involves the use of sonic type of total cognitive score as the final outcome measure. However, in utilizing a total score, one assumes that variables related to student learning are have a homogeneous affect on learning across academic skill levels. This study purports to show that the relationship between education indicators and academic learning differ, depending upon the specific skill level under investigation."}, {"section_title": "Method", "text": "For this paper, multilevel structural equation modeling was used to estimate the multilevel models of mathematics proficiency. The use of multilevel structural equation modeling allows one to capture the multilevel, organizational nature of schooling, including the interrelationships amongst indicators within and across levels of the system (Darling-Hammond, 1992;Oakes, 1986;Porter, 1986;Willms, 1992). It also affords the decomposition of the relationships between variables of the model into direct, indirect, and total effects of variables within and between levels of the system. Finally, multilevel structural equation modeling allows for a measurement model to be specified, affording the inclusion of latent variables (for a discussion of multilevel structural equation modeling, see Appendix of this paper, and see Kaplan & Elliott, 1997; for a brief explanation of parameter estimation, see Kaplan & Elliott, 1997;for detailed information about parameter estimation see Muthen, 1994; and for details on soflware implementation, see Bentler, 1989;Kaplan & Elliott, 1997;Nelson & Muthen, 1991)."}, {"section_title": "Data Source", "text": "The data for this research comes from the public release files of the First Follow-Up Study of the National Education Longitudinal Study of 1988, commonly referred to as NELS:88 Probability of Proficiency 5 (NCES, 1988). NELS:88 is an ongoing study of a national sample of students as they progress from the eighth grade, through high school, and onto postsecondary education and / or work (NCES, 1995). Its primary purpose is to collect policy relevant information concerning such areas as the effectiveness of schools, curriculum paths, special programs, and curriculum content and exposure. NELS:88 collects information on family background, student aspirations and attitudes, experiences in and out of school, and high school transcripts. It also contains data from students' teachers, schools, and parents. The base year data was collected in 1988, when the students were in 8th grade. A follow-up study is done every two years. This study utilizes the first follow-up study, when the sampled students were in the tenth grade. The subset of data used in this research was obtained as follows. Of the 20,706 students appearing in the first follow-up study, only those students whose mathematics teachers participated in the teacher survey and whose school administrator participated in the school survey were retained. Next, indicators were chosen for the within-school model, consisting of data from the student and teacher survey. After listwise deletion of any missing data and multiple response, the final student level sample size used in the development of the within-school model was N=4848. Once the within school model was estimated, the between-school model was developed. The data for this model was obtained by merging the within-school data with indicators to be used in the between-school model. Only those schools with at least 10 students were retained. After listwise deletion based on the between-school variables, the between-school sample was G=I I I, and the within-school sample was reduced to N=1504 (1504 students within I I I schools)."}, {"section_title": "Probability of Proficiency 6", "text": "Because of the sampling design of NELS:88, there were too few students within classrooms to estimate a three level student within classroom within school model. Therefore, the multilevel model was conceptualized as a two level model consisting of a within-school level and a between-school level. Several teacher level variables appear in the within-school model, because those teacher level indicators were hypothesized to vary within schools. The author realizes that this may introduce some bias in the estimation results, however, it was important theoretically to have the teacher-level variables in the model. Moreover, since the ratio of teachers to students was approximately one-to-one, the bias should be at a minimum."}, {"section_title": "Selection of Indicators", "text": "Selection of the indicators for the within-and between-school models was guided by the education indicators literature (see e.g. Catterall, 1989;Murnane and Raizen, 1988;Oakes, 1989;Shavelson, Webb, & Rowley, 1989; for a review of the indicators literature, see Elliott, 1996). However the choice of indicators was limited to data available from the public release files of the first follow-up of NELS:88. Indicators of the within-and between-school models consist of a combination of single item indicators, and scales which were developed via maximum likelihood exploratory factor analysis (MIEFA).\u1e80"}, {"section_title": "ithin-School Indicators", "text": "The within-school indicators are presented in Table I. Within-school indicators at the teacher level include (see Table 1 for details on coding): GRADING, a scale measuring the In each case a variety of alternative factor structures with oblique rotation were explored. The criterion for choosing the number of factors was based on the change in chi-square goodness of fit when the number of factors changed as well as substantive signifiCance and interpretability of the factors. Scales were formed via unit weighting of the variables defining the factor. Probability of Proficiency 7 emphasis the teacher gives to different areas when setting student grades; YRSEXP the number of years of secondary teaching; ENRICH, a scale consisting of responses to six questions related to the teacher's participation in enrichment; and SIZE: the number of students enrolled in the mathematics course. Student-level within-school indicators include (see Table I for details on coding): HOMEWORK: the amount of time the student spends in and out of school on homework each week; CLUB: the student's extent of participation in academic clubs; PROBLEM: the student's perception of the teacher's emphasis on teaching problem solving skills; EFFORT: how often the student tries as hard as he or she can in mathematics class; REQUIRED: a dichotomous indicator of whether the current matheri--iatics class is required or an elective (0=required); PRIOR: a measure of the student's prior mathematics grades; and HANDS: a scale measuring how often the student uses computers, hands-on materials, models, and calculators in mathematics class. The final outcome measure of the within-school model is MATH: the probability of mathematics proficiency. This outcome is calculated at each of five mathematics skills levels wherein MATH 1 is the probability of mathematics proficiency at Level I, defined by \"single step operations which rely on rote memory,\" MATH2 is the probability of mathematics proficiency at Level 2, defined by \"simple operations with decimals, fractions, powers, and roots.\" MATH3 is the probability of mathematics proficiency at Level 3, defined by \"simple problem solving, using low, level mathematical concepts.\" MATH4 is the probability of mathematics proficiency at Level 4, defined by \"understanding intermediate level mathematical concepts and the use of multi-step solutions. MATHS is the probability of mathematics proficiency at Level Sdefined by \"being able to solve multi-step complex problems \" Since MATH is calculated at each of the five skill levels."}, {"section_title": "BEST COPY MAMIE 8", "text": "Probability of Proficiency 8 each student has five probability of proficiency scores. These scores offer, for a given student, the probability of proficiency at the corresponding skill level."}, {"section_title": "Between-school Indicators", "text": "The between school indicators are presented in Table 2, and include: LUNCH: the percent students receiving free or reduced lunch in the school; SALARY: average teacher salary within a school; MTEACHR: the number of full-time mathematics teachers; GROUPING. a dichotomous variable measuring if the school use homogeneous grouping for placement of tenth grade students in the mathematics class (0=no), DROPOUT: a dichotomous indicator of whether the school has 0 a dropout prevention program (0=no), STAFDEV a measure of how much emphasis the school places on staff development programs; ADVMATH: the number of advanced mathematics courses offerred; and PRESS: a measure of the academic press of the school (see Table 2 for details on coding)."}, {"section_title": "Results", "text": "Two independent models of schooling were developed as a precursor to the formulation of the multilevel model of schooling. A within-school model was developed to model variation across students. However, students are nested within schools. Therefore, a school-level model was developed to explain the effects of school level variables upon the average levels of the student level variables across schools. Once the separate models were developed, a multilevel model combining the two separate models was estimated."}, {"section_title": "Probability of Proficiency 9", "text": ""}, {"section_title": "Results of Within-School Model", "text": "Five within-school models were developed, using LISREL (Joreskog & Sorbom, 1993). The first model of indicators related to probability of mathematics proficiency was developed using the probability of mathematics proficiency at Level 3. Level 3 was chosen as the outcome since the sample displayed the most variation in the probability of mathematics proficiency at Level 3. Once the initial model was estimated, it was assessed for goodness-of-fit by looking at the various fit indices offered by LISREL (Joreskog & Sorbom, 1993)  Once the initial model was assessed for goodness-of-fit, ways to improve the fit of the model were investigated. The approach used to modify the model was suggested by Saris, Satorra, and Sorbom (1987), and by Kaplan (1989;, which utilizes information from both the Modification Index (MI) and the Expected Parameter Change (EPC). The MI, developed by Sorbom (1989), measures the expected drop in the value of the chi-square statistic if a fixed parameter is freed in the model. The EPC provides the approximate size of a fixed parameter if. it is freed (Saris, et al., 1987). Possible modifications to the model were scrutinized to make sure that they made substantive sense, and to make sure that they were in agreement with the underlying theoretical model of schooling as suggested by the education indicators literature. Once the within-school model developed with the outcome at Level 3, it was estimated four additional times, using each of the other probability of proficiency levels as the final student outcome measure. This way one can obtain information about how the factors included in the within-school model differentially effect the student's probability of proficiency across skill levels."}, {"section_title": "Probability of Proficiency 10", "text": "Assumptions underlying the use of structural equation modeling were exaMined Two of the within-school model outcomes, the probability of mathematics proficiency at Level I and at Level 5 displayed high levels of skewness and kurtosis (see Table 3), violating the assumption of multivariate normality. These abnormalities are believed to reflect a ceiling effect for the case of Level I and a floor effect for Level 5, due to the nature of the mathematics assessment developed by NCES. The Level 1 items are too easy for most tenth grade students, therefore most of the students perform well on those items. This results in a ceiling effect at Level 1. For Level 5, a floor effect is exhibited because the items at Level 5 are too hard for most tenth grade students (a majority of tenth graders have not been exposed to Level 5 skills). Most tenth grade students perform poorly on those items, resulting in a floor effect at Level 5. Violations of the assumption of multivariate normality could inflate chi-square as well as biased standard errors of estimates. However, since one of the purposes of this paper is to explore the use of probabilities of proficiency as outcomes, it was decided not to transform the data to be more normally distributed."}, {"section_title": "Results of Within-school Model, Developed Using Level 3 as Outcome", "text": "The first model to be estimated was a within-school model with the probability of proficiency at Level 3 as the outcome measure (see Figure 1) Descriptive statistics of all withinschool variables are presented in Table 3. Results of this initial model show that the model does not fit the data (see Table 4). Six modifications were made to the initial model, based upon the values of the modification index (MI) and expected parameter change (EPC). Those paths with high Nils along with high EPCs were freed if the path made substantive sense (see Table 5). Results of the final Probability of Proficiency I I model are displayed in Table 4 and Figure 2. While the model still does not statistically fit the data, statistical fit is much improved over that of the initial model, with a large decrease in chisquare, increase in NNF1, and a value of RMSEA close to 0.05. Next the final model was re-estimated, using the four other probability of proficiency levels as outcomes. As can be seen from the various fit indices, the models vary in degree of fit. depending upon which outcome measure is used (see Table 4). Table 5 displays the Mk and EPCs for each re-estimate of the within-school model developed on the probability of proficiency. at Level 3. As evident from Table 5 the modifications made based on Level 3 would not have been made when using the other prObability of proficiency levels as outcomes. For example, the MI and EPC for the first modification with Level 3 as the outcome are 94.79 and 0 13, respectively. However, when the outcome is Level 1, the MI and EPC are 0.12 and 0.00, respectively. These values are much lower than in the previous model. Low Mils and EPCs for the first modification are also seen when Level 2 and Level 5 are the outcome measures. Results from the MIs and EPCs could possibly be interpreted as the relationship between the use of hands-on manipulatives and computers on the probability of mathematics proficiency is important for learning simple problem solving and intermediate level concepts (Levels 3 and Level 4, respectively). However, using hands-on materials may not be as important for Level 1 and Level 2, where most students already have a high probability of proficiency anyway. At Level 5, most students have a low probability of proficiency because the items are very hard. Therefore, using hands-on materials may not make any difference in learning. Alternatively, results for Level 5 could be due to Level 5 skills not lending themselves to the use of hands-on materials."}, {"section_title": "BEST COPY AVAILABLE", "text": "Probability of Proficiency 12 Table 6 through Table 10 present the direct, indirect, and total effects of the final within-school model developed from probability of proficiency at Level 3, and estimated with the other levels as outcomes' Several findings emerged across all skill levels which are supported by previous literature on mathematics learning. For example, work by Reynolds and Walberg (1992) support the result that prior achievement is a powerful predictor of current achievement Their work also offers supporting evidence that student effort indirectly affects achievement in mathematics, as mediated by such factors as prior grades. In comparing the direct effects of the model when-using different outcome levels, there are several differences worth noting. There is a moderate amount of variation in the size of the direct effect of HOMEWORK on MATH. When Level I is used, the effect is 0.062, at Level Probability of Proficiency 13 amount of homework that the student does, but more importantly, the kind of homework the student does. In fact, Sasser (1990/91) offers evidence that.students who receive computer tutorials as homework in mathematics class show higher achievement than students who receive traditional textbook exercises as homework (he studied 92 college freshman and sophomore volunteer elementary education majors in their learning of concepts of algebra). The point is that the strength of the relationship between amount of homework and probability of proficiency differs, depending on which level of probability of proficiency is used as the outcome measure. Variation also exists in the strength of the relationship between the use of hands-on materials in the classroom and the probability of mathematics proficiency across the five skill levels. Stronger direct effects are evident at Level 3 and Level 4, while a much weaker relationship is evident Level 5. The direct effect of the use of hands-on materials upon the learning of Level 1 and Level 2 skills are almost zero, although the use of hands-on materials does have a significant total effect upon the probability of learning Level 4 skills. Evidence supporting the effect of the use of hands-on materials, and more specifically computers, upon a student's problem-solving ability (Levels 3, 4, and 5) come from a variety of studies. For example, Blume and Schoen (1988) found that skills developed from computerusage transferred to mathematical problem-solving. Programmers used systematic trial more frequently than and corrected more errors in their work than non-programmers. Consistent with their finding is work by McCoy and Burton (1988) who found that \"after programming instruction, both the ability to use mathematical variables and mathematical problem solving ability significantly improved. A later study by McCoy and Dodi (1989) found that computer usage increased problem-solving achievement in mathematics. Finally, Damarin, Dzaik, Stull, and Whiteman (1988) found significant increases in problem solving ability as a result of using 14. Probability of Proficiency 14 computer based instructional materials across ninth-, tenth-, and twelf1h-grades, in the corresponding mathematics courses. The next analysis involved the calculation of the intraclass correlatiOns for each of the within-school variables. Intraclass correlations provide a measure of the proportion of variance in the within-school variables due to the existence of variation between-schools. A large intraclass correlation suggests the need for a multilevel analysis (see Muthen,199 I ). The intraclass correlations ranged from 3% to 40% (see Table 11), providing evidence of between-school variation and therefore warranting a multilevel analysis."}, {"section_title": "Results of Between-School Model", "text": "Since the intraclass correlations suggested the need for a multilevel analysis, a between-school model was explored, to be combined with the within-school model in the development of the multilevel model. Descriptive statistics for the between-school variables are presented in Table 12 (for a diagram of the between-school model, see Figure 2). The initial between-school model was found to fit the data: x2 (10) =14.50, p > .05; NNFI = 0.768; RMSEA = 0.065; P(RMSEA < 0.05) = 0.333. For the between-school model here were no violations of assumptions underlying structural equation modeling. Model modifications were investigated in the same manner-as for the within-school model. No modifications were made, therefore the initial between school model is also the final model. Table 13 presents the direct, indirect, and total effects of the between-school model. There are several moderately large effects worth noting, including the total effect of LUNCH on PRESS (-0.1666) and the total effect of LUNCH on ADVMATH (-0.2506), the total effect of STAFDEV on PRESS (0.2638), and the total effect of ADVMATH on MTEACHR (0.2296)."}, {"section_title": "Probability of Proficiency 15", "text": ""}, {"section_title": "Results of Multilevel Model", "text": "The building of the multilevel model involved the combining of the two separate unilevel models, while allowing paths to be estimated between the between-school indicators and the intercepts of the within-school variables. This assumes that there exists a between-school model which can explain the variation in the intercepts and means of the within-school indicators across schools. Five multilevel models were estimated, differing only in the final within-school outcome (level of probability of mathematics proficiency). To combine the between-and withinlevel models into each of the five multilevel models, the paths between PRESS and the intercepts and means of the indicators of the within-school model, with the exception of YEARS, SIZE, REQUIRED, and PRIOR, were allowed to be estimated. These four indicators (YEARS, SIZE. REQUIRED, and PRIOR) are assumed to be exogenous to the multilevel model (they are not explained by the model, but rather are inputs to the model). Fit statistics are presented in Table 143. Although the chi-square statistic suggests that the models do not fit the data (with possible exception of Level 5), the alternative fit indexes offer evidence that each of the five multilevel models fit the data, with some variation in fit across models. Since the alternative fit indexes offer evidence of fit, and there was no substantive justification to add or remove paths across the levels, the multilevel model was not modified beyond the initial specification. The standardized regression coefficients of the within-school intercepts on PRESS are given in Table 15. Most of these effects are small and insignificant, and some of the signs of the coefficients do not make substantive sense (see Table 15). The intercepts are interpreted as the expected values of the indicator, given that the other indicators arc zero. However, zero may not be an admissible value for many of these indicators. Therefore, the coefficients relating the intercepts to the school level variables may not be interpretable. This problem is the issue 01 centering which is related to the identification problem in the context of multilevel structural equation modeling (see; Bryk & Raudenhush, 1992;Kaplan & [thou, 1995). ."}, {"section_title": "Discussion", "text": "The purpose of this paper was to explore the use of the probability of mathematics proficiency as a measure of student achievement. It was hypothesized that relationships specified between indicators of a model of schooling may differ, depending upon which level of probability of proficiency is under investigation. It was also theorized that by using the five outcome levels. one would gain more information about the complex relationships between indicators of schooling_ and student learning, versus using a total mathematics achievement score as the final outcome measure. By breaking down the total score into skill categories one can study the relationships between important education indicators and student achievement at a specific skill level. Also, the relationships between indicators may differ across skill types. This is information that would not be obtained with the use of a total mathematics achievement score. Several interesting findings emerged. First, in developing the within-school model, differences in the magnitudes of the modification indices and expected parameter change statistics emerged, depending on which level of outcome was used. Therefore, if one uses the method of model modification involving either the MI, EPC, or both (see Saris et al., 1987;Kaplan 1989Kaplan , 1990, then the modifications made to the five models may differ. Thus, different models may The sample size for the multilevel analysis is N G = 1393. Probability of Proficiency 17 emerge, dependent upon which level of probability of proficiency was under investigation. This suggests that the relationships between the indicators in the model differ, depending upon the skill level being studied. It is quite possible that different indicators might be required to study the effects of schooling on student proficiency at different skill levels. A related finding was that the five within-school models differed in degree of statistical fit. For identical models, except for the final outcome measure, results yielded differential values across a variety of statistical fit indexes. This offers additional evidence of the need for different within-school models of the probability of mathematics proficiency across skill levels to explain the interrelationships between indicators of student achievement and the learning, of different skills. Finally, several estimated effects between indicators varied in magnitude, dependinQ, upon which level of outcome was under investigation. Although the differences were moderate, they show that the relationships between indicators of the model differ across skill levels. This result, combined with the differences in statistical fit of the model to the data, and the differences in Mils and EPCs across models, offer evidence for the need to separately develop models to explain student achievement for each given skill level. It is important to note that these skill levels are developmental, as discussed in the . domain of cognitive psychology. One aspect of cognitive psychology related to the learning at specific skill levels is the development of working memory. As a person develops, he or she can construct more complex working memory programs which allow for quicker operations. This affords the retention of longer and more complex instructional subroutines (such as problemsolving strategies, Chi, 1977). A second aspect related to learning at specific skill levels is the development of long-term memory and its relation to knowledge acquisition (Farnham-Diggory, Probability of Proficiency 18 1990). For example, conceptual knowledge2 starts developing at infancy and gradually becomes hierarchical. Procedural knowledge' is acquired more rapidly from birth, while analogial knowledge does not change with development, but rather gets used increasingly more effectively. Therefore, with development conies the capacity for learning at higher skill levels, as well as an increase in one's probability of proficiency at each skill level. Cognitive development affects the understanding and use of numeracy mechanics, or basic skills (Farnham-Diggory, 1990). Basic skills consist of (1) first order skills; and (2) secondorder skills. First-order skills deal with small units such as addition, subtraction, multiplication, and division. They include the retrieving of \"number facts\" and calculating. These would include the use of simple operations, or Level 1 and Level 2 skills as defined by NCES (1988). Secondorder skills deal with larger units and are usually considered to be the problem-solving skills, or Level 3, Level 4, and Level 5 skills (NCES, 1988). These involve the learning mathematical heuristics, or \"rules-of-thumb\" to help guide one in finding a correct solution (Shoenfeld, 1985). The heuristics become more complex with development, allowing one to solve increasingly more complex problems. Thus, offering evidence that the skill levels are defined by NCES (1988) are hierarchical as well as developmental in nature (se e.g. Seigler, 1991, regarding the development of academic skills). Therefore, factors affecting cognitive development may also explain some of the variation in student learning at specific skill levels. 'Conceptual knowledge is the knowledge of general forms or prototypes. .3 Procedural knowledge is skill knowledge, or knowledge of how to do something. It is learned through practice. 'Analogical knowledge if knowledge that preserves the patterned structure of information and aids with the recall of other information, such as facts or concepts (Farnham-Diggory, 1990)."}, {"section_title": "Probability of Proficiency 19", "text": "Conclusions / Caveats This article discussed the use of probability of proficiency scores as a means to gain invaluable information about how school factors can differentially affect student learning across skill levels. An important limitation emerges from this work. The public release files of NELS:88 contain variables that have been recoded to preserve the confidentiality of the respondents. For example, many continuous variables have been converted to Likert scales. Since the metric of Likert scales are potentially meaningless (a few of the indicators have meaningful zero values wherein zero means \"a lack of the characteristic being measured by that indicator\"), the use of categorical data limits the interpretation of the coefficients relating the within and between-school levels. Therefore future work should involve the re-estimation of this model, either by utilizing the confidential files of NELS:88, which contains variables that have been suppressed from the public release files, as well as many variables in their original continuous form (before recoding), or by using another data set that contains more variables coded in a meaningful metric. "}, {"section_title": "Probability of Proficiency 25 Appendix", "text": "The use of multilevel structural equation modeling will allow one to capture the multilevel, organizational nature of schooling, and the interrelationships amongst indicators within as well as across levels of the system (Darling-Hammond, 1992;Oakes, 1986;Porter, 1991;Willms, 1992). Studies of school systems up until this point have routinely either ignored the organizational structure of schools, used aggregated data, or used data from several levels of schooling within a uni-level model, and have therefore offered at best biased results and misleading conclusions (see e.g. Bryk & Raudenbush, 1988;Lee & Bryk, 1989). A few of the earlier studies (before the development of sophisticated multilevel modeling techniques) recognized the problems of using aggregated data, but justify its use by acknowledging the difficulty of estimating and interpreting multilevel analysis in the same model (e.g. Bidwell and Kasarda, 1975). There has recently been a flurry of activity in developing and estimating multilevel regression models of education (e.g. Bryk & Raudenbush, 1992;Fitz-Gibbon, 1991;Gamoran, 1991;Monk & King, 1994;Lockheed & Longford, 1991;Zuzovsky & Aitkin, 1991). However. HLM is limited since it cannot model the structural relationships existing amongst variables witY,in and between levels of the system, nor can HLM decompose the relationships between variables rif the model into the direct, indirect, and total effects of the variables within and between levels of the system. Multilevel Structural equation modeling offers this information, plus it can allow fo: a measurement model to be specified, affording the inclusion of latent variables. For ease of discussion about multilevel structural equation modeling 1 will assume that the indicators are valid and reliable. However, I recognize that in most cases this assumption is unreasonable and point out that the technique can be extended to the case wherein multiple measures are used via the building of a multilevel measurement model (see Muthen, 1991 The model to be discussed below has been previously discussed in Kaplan and Elliott (in press) Probability of Proficiency 26 Starting with the within-school model, it is assumed that the intercepts and means of the students level indicators vary across schools. It is also assumed that there exists a betweenschool model which can explain this variation. Finally, it is assumed that the slopes are fixed. Keeping the aforementioned assumptions in mind, the within-school model can be written as follows: where yig is a vector of student level indicators, some of which are exogenous for the ith student (t = I ND in the gth school (g = G), ag is a vector of intercepts of the student level indicators which are assumed to vary across schools, By is a matrix of regression coefficients relating the student level coefficients to each other, and cis, is the disturbance term for the student level equation. Equation 1  where it is assumed that (I By) 1 exists (Muthen, 1994). As explained above, it is assumed that there exists a between-school model that explains the variation in the means and intercepts of the within-school indicators across schools. This variation can be modeled as follows: where a is the grand mean vector across G schools, zg are school level exogenous and endogenous indicators, Ba is a matrix of regression coefficients which relate zg to the intercepts of the student level indicators, and 8g is a vector of disturbance terms. As explained by Muthen (1994), equations (1), (2), and (3) allow intercepts and means to vary as a function of school level indicators. As alluded to by Muthen (1994), and Probability of Proficiency 27 explained by Kaplan & Elliott (in press), the between-school indicators zg are allowed to follow a separate between-school model, written as follows: where T is a vector of means and intercepts for the school level exogenous and endogenous .indicators, Bz is a matrix of coefficients which relate school level indicators to each other, and u, is a vector of disturbances. Equation 4  From a series of substitutions using equations (1) through (5) comes the expression for the ith students score in the gth school, taking into account the structural relationships within and between schools. This model can be expressed as It is evident form equation 15that the expected value of the student's scores in the gth school is the weighted sum of the grand mean vector of student level variables (a) and the grand mean vector of the school level variables (T). Ai 1 or Proficiency 20 GRADING \"Indicate the importance you give to each of the Each part was rated as follows:  Probability of mathematics proficiency at Level 2 as continuous, ranging from 0 -1. defined by \"simple arithmetical operations on whole numbers (single step oeprations which rely on rote memory.\" MATH2 Probability of mathematics proficiency at Level 2 as continuous, ranging from 0-1 defined by \"simple operations with decimals, fractions, powers, and roots.\" MATH3 Probabiltiy of mathematics proficiency at Level 3 as continuous, ranging from 0-1 defined by \"simple problem solving, using low level mathematical concepts \" MATH4 Probability of mathematics proficiency at Level 4 as continuous, ranging from 0-1. defined by \"understanding intermediate level mathematical concepts and the use of multi-step solutions. MATHS Probability of mathematics proficiency at Level 5 as continuous, ranging from 0-1. defined by \"being able to solve multi-step complext problems.\""}, {"section_title": "35", "text": "Probability of Prolicioncy Table 2 Between-School Model Indicators"}, {"section_title": "Variable Definition", "text": "Coding LUNCH Percent students on free or reduced lunch in the 0=0%, 1=1-10%, 2 =1 1 -50 %, 3=50-100% school."}, {"section_title": "SALARY", "text": "Average teacher salary within a school (in dollars). 1=$0-$14999, 2=$15000-$17499, 3=17500-$19999, 4=520000-522499, 5-522500-524999, 6=525000+ MTEACHR The number of full-time mathematics teachers.            DOCUMENT IDENTIFICATION: S /ve 694i/ ERIC rao.a.10kcii Ce--C)C\" tCt 'eta/ S CAD( -eS I V\\ 1-k_ --C11)d CC \"e.\\)\\-\\R)-(-5\\n Eaoco._#Lio,-,J-elcAkcer,r-5 AA0,2A-4,ev-rial-7c3 len CAA-DiE:Pretok-Salk 1euVS,"}]