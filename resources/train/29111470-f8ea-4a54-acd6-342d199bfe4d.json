[{"section_title": "Abstract", "text": "Abstract-Identifying Alzheimer's disease (AD) earlier before the neurodegeneration is too severe and where treatment is not currently available, might aid in preventing AD onset. Specifically, patients initially diagnosed with early mild cognitive impairment (eMCI) are known to be a clinically heterogeneous group with very subtle patterns of brain atrophy. To examine the boarders between normal controls (NC) and eMCI, Magnetic Resonance Imaging (MRI) was extensively used as a non-invasive imaging modality to pin-down subtle changes in brain images of MCI patients. However, despite the large body of research works on MCI/NC and major advances in neuroimaging technologies and brain image analysis and learning methods, eMCI research remains limited by the number of available MRI acquisition timepoints. These can be grouped into (i) single-timepoint and (ii) multi-timepoint (or longitudinal) based MCI diagnosis frameworks. Ideally, one would learn how to classify MCI patients with high accuracy from data acquired at a single timepoint, while leveraging 'non-existing' follow-up observations. To this aim, we propose novel supervised and unsupervised frameworks that learn how to jointly predict and label the evolution trajectory of intensity patches, each seeded at a specific brain landmark, from a baseline intensity patch. Specifically, both strategies aim to identify the best training atlas patches at baseline timepoint to predict and classify the evolution trajectory of a given testing baseline patch. The supervised technique learns how to select the best atlas patches by training bidirectional mappings from the space of pairwise patch similarities to their corresponding prediction errors -when one patch was used to predict the other. On the other hand, the unsupervised technique learns a manifold of baseline atlas and testing patches using multiple kernels to well capture patch distributions at multiple scales. Once the best baseline atlas patches are selected, we retrieve their evolution trajectories and average them to predict the evolution trajectory of the testing baseline patch. Next, we input the predicted trajectories to an ensemble of linear classifiers, each trained at a specific landmark. Last, we use weighted majority voting to label the testing subject as NC or eMCI. Our classification accuracy increased by up to 10% points in comparison to single timepointbased classification methods."}, {"section_title": "I. INTRODUCTION", "text": "D ETECTING Alzheimer's Disease (AD) in a very early stage might help better monitor disease progression and improve the quality of lives of AD patients. Dementia, and AD by extension, is becoming an increasingly common problem as life expectancy goes up in developed countries [1] .\nParticularly, identifying early Mild Cognitive Impairment (eMCI) which is an early manifestation of Alzheimer's disease [2] remains a formidable challenge in dementia neuroscience. This is partly due to subtle anatomical fingerprint of eMCI, which makes it hard to differentiate from typical normal control (NC) brain anatomy and structure. However, disentangling the eMCI brain from the NC brain is a clinical problem with great significance due to the prevalence of AD [3] . Typically, neuroimaging and cognitive scores are widely used for AD diagnosis [4] . It is desirable to be able to diagnose dementia with only the use of structural Magnetic Resonance Imaging (MRI), as structural MRI scans can be taken quickly and at a low cost using equipment with widespread availability compared to other imaging modalities such as PET or functional MRI [5] .\nCurrently, this process places a burden on medical experts as they must individually examine structural MR images. Early MCI atrophy patterns are subtle and eMCI patients might show no additional clear signs of cognitive impairment aside from minor memory issues [6] . Leveraging advanced machine learning can help automate eMCI diagnosis and alleviate the burden on these experts by providing them with reliable, automated and efficient reading and interpretation of MRI data. As such, a vast number of studies devised neuroimagingbased machine learning methods to predict and diagnose AD patients from a single MRI acquisition timepoint [7] , [8] , [9] or multiple available timepoints [10] , [11] , [12] , [13] .\nAmong the longitudinal studies, [10] devised similarity maps capturing the relationship between registered baseline and follow-up neurimages to distinguish between stable MCI patients and MCI converters. [12] designed a temporally structured support vector machine (SVM) classifier which captures the longitudinal unfolding of MCI over time by flexibly integrating any number of available follow-up MRIs to boost the classification performance. In another work, [11] demonstrated the potential of utilizing longitudinal neuroimaging data, even with incomplete measurements, to improve the classification of stable and converted MCI patients based on sparse modeling. A longitudinal multimodal MRI model was proposed in [13] arXiv:1907.06064v1 [eess.IV] 13 Jul 2019\nto learn how to predict MCI brain state evolution towards AD state by devising a sparse linear regression model with a group regularization constrained to group the weights corresponding to the same brain region across multiple time points so that selected altered brain regions are consistent across differnet timepoints. Next, by extracting longitudinal features from the original baseline and longitudinal data, an SVM is trained for classification. Notably, all these works all of these works incorporated multiple timepoints into their frameworks to leverage additional relevant information for increasing the classification accuracy of different demented brain states. However, these methods require more than a single acquisition timepoint for diagnosis. This might hinder the possibility of administering early clinical treatment, if available, where early MCI patients are diagnosed with high accuracy solely from baseline medical data. As potential preventive treatment [14] is more likely to succeed the earlier the disease is detected, requiring subjects to wait for multiple measurements at different timepoints may impede their recovery.\nOn the other hand, several other works focused on using a single acquisition timepoint for dementia diagnosis and classification, avoiding the limitation of requiring patients to wait for multiple scans. An ensemble of SVMs was proposed in [7] to distinguish between NC and AD patients using MRI data. Ten classification methods from a single timepoint were compared in [9] to perform three AD-related classification tasks: classifying AD against NC, MCI against NC, and MCI converters against stable MCI patients. In a different work, [8] proposed an automatic classification framework by training support vector machines to reliably distinguish AD from normal aging in individual structural MRI scans.\nHowever, these works missed out on the potential of incorporating longitudinal MRI data into their frameworks, which could further boost the classification performance by learning how to identify feature that best capture demented brain changes. More recently, a review paper [15] surveyed neuroimaging-based methods for dementia diagnosis and prognosis published in MICCAI 1 proceedings between 2010 and 2016. They identified 28 seed works developed using image or network brain data for MCI and AD diagnosis. Interestingly, predictive methods for early dementia diagnosis seem to be lagging behind, holding various untapped potentials for substantially advancing translational medicine. Notably, the majority of the reviewed methods only focused on classification (e.g., NC vs MCI). While the ultimate goal of classification is to provide a computer-aided diagnosis for better clinical decisions, predicting future progression of early demented brains from a baseline observation (i.e., a single timepoint) remains a priority as it might help delay conversion from MCI to AD when early treatment is addressed to the patient. For instance, if one can learn how to foresee abnormal local changes in the brain during MCI progression, these can provide more discriminative features that unfold over time for classifying MCI in a very early stage when such changes remain subtle compared with normal controls.\nTo overcome all these limitations, we propose to diagnose a patient at an early stage solely based on a single baseline MRI data, leveraging longitudinal information that we learn how to accurately predict at follow-up timepoints. Specifically, we propose the first framework to jointly classify and predict the evolution trajectory of MRI from a single acquisition timepoint (i.e., baseline observation) in four key steps. First, we identify key voxels (or landmarks) at baseline t 1 in the target anatomical region of interest (ROI) across all training subjects. The detected landmarks seed the training of our methods as we aim to predict the evolution of intensity voxels in their local neighborhoods. Specifically, in the second step, we propose two novel supervised and unsupervised frameworks to predict patch evolution trajectory at each landmark, individually. Both strategies are rooted in the assumption that: if one can learn how to identify the best neighboring atlas patches to a given testing patch at baseline timepoint, one can use the available neighboring atlas patches at follow-up timepoints to predict the evolution trajectory of the testing patch over time. Since the only available observation to predict from is at baseline timepoint, one can only examine the relationship between the testing samples and training samples at baseline to learn how to predict the missing follow-up observations. Simple but intuitive, such assumption showed great promise in learning how to predict the evolution of the multi-folded cortical surface from a single timepoint using neonatal MRI [16] , [17] , [18] . Given an input baseline testing patch, the first strategy learns how to select baseline 'atlas patches' supervised by their patch prediction error at a follow-up timepoint t 2 . The second strategy leverages unsupervised high-dimensional manifold using multiple-kernel learning to identify the local neighboring atlas patches to a given testing patch at a specific landmark. In the third step, we linearly average the followup atlas patches at t 2 of the selected baseline atlas patches to predict the testing patch at t 2 . Last, we train an ensemble of linear SVM classifiers to automatically label each predicted patch-wise evolution trajectory. By aggregating the predicted labels at each landmark using weighted majority voting, the label of the testing subject is predicted.\nThe contributions of our paper span multiple directions and present different kinds of advances:\nConceptual advance. To the best of our knowledge, this is the first work that aims to learn how to predict followup observations to better classify from a single baseline observation, with application to early MCI. Specifically, this paper defines the state-of-the-art in addressing this problem by proposing two innovative solutions based on supervised and unsupervised learning, which are rooted in the preliminary assumption that if one can learn how to identify the best atlas patches at baseline timepoint for the joint prediction and classification task, one can leverage the corresponding atlas patches at follow-up timepoints to predict and classify the evolution trajectory of a baseline testing patch.\nTechnical advance. We propose two novel techniques for learning how to select the best neighboring atlas patches for a given testing patch at baseline. The first one adapts multiple kernel manifold learning for building a manifold of baseline test and atlas patches to learn how to model the relationship i (see Section II for more details), to map the intensity dissimilarity vector between a pair of patches to an error prediction vector. Basically, we compute the prediction error for a pair of training patches as the average of the prediction error produced when (i) using the first training patch to predict the evolution trajectory of the second training patch and (ii) using the second training patch to predict the evolution trajectory of the first training patch. This atlas patch selection strategy is supervised by the potential of the selected training atlases in producing low prediction errors at follow-up timepoint t 2 . (B) Unsupervised atlas patch selection strategy. We use multiple kernel learning to learn the pairwise similarity between training atlas patches and testing patch at baseline t 1 , which can nicely capture the latent distributions of landmark-seeded patches at different bandwidths. This allows to identify to most similar baseline atlas patches to the target testing patch. Given the selected best atlas patches by strategy (A) or (B), we then linearly average the follow-up atlas patches at t 2 of the selected baseline atlas patches to predict the testing patch at t 2 . Last, we train an ensemble of linear SVM classifiers to automatically label each predicted patch-wise evolution trajectory. By aggregating the predicted labels at each landmark using weighted majority voting, the label of the testing subject is predicted. patch centred on landmark i for subject s at timepoint tx p tx i,s predicted patch centred on landmark i for subject s at timepoint tx \u03b1 s,s coefficient vector which maps the t1 patch of subject s to the t1 patch of subject s d s,s element-wise difference between patches of subjects s and s"}, {"section_title": "Fig. 2:", "text": "Modeling the similarity between a baseline atlas patch p t1 i,s of subject s centered at landmark i and a second baseline atlas patch p t1 i,s for the proposed supervised atlas selection (SAS) strategy. We give an example of two training atlas patches with varying similarities to an input baseline training patch. We can clearly see how the quotient vector \u03b1 s,s (resp., \u03b1 s,s ) locally captures the degree of similarity between both patches. across training and testing patches using different bandwidths that can capture a heterogeneous distribution of patches at baseline. The second one proposes a novel strategy that trains bidirectional regressors to learn how to identify in a supervised manner the atlas patches, which if selected for predicting the testing patch evolution trajectory, would also lead to improving the classification accuracy of the testing subject as healthy or early demented.\nClinical and translational advances. This is the first framework to jointly predict and classify brain image evolution over time from a single timepoint. It can be integrated into the clinical diagnosis framework for accurate brain disorder diagnosis and treatment planning using a single early observation. This will help alleviate the need to acquire multiple measurements (e.g., MRI scans) at different timepoints for diagnosis and prognosis. One early measurement will be sufficient given that the predictive model works well.\nGeneric methodological advance. The proposed core methods are generic and can be evaluated on any anatomical region of interest including the whole brain. They can be also utilized to improve the prediction accuracy by existing image and shape-based evolution prediction frameworks [16] , [17] , [18] , which simply used predefined metrics (such as Euclidean distance) for modeling the relationship between testing sample and atlases. 2 "}, {"section_title": "II. PROPOSED SUPERVISED AND UNSUPERVISED PATCH-BASED EVOLUTION TRAJECTORY PREDICTION AND CLASSIFICATION FROM BASELINE MRI", "text": "Here, we detail the key steps of the proposed the supervised and unsupervised atlas patch selection strategies for jointly predicting and labeling landmark-seeded evolution trajectories while solely relying on a single MRI acquisition timepoint.\nNotations. Throughout this paper, we denote matrices by boldface capital letters, e.g. X, and scalars by lowercase letters, e.g. x. Bold lower case letter x stands for a vector. The transpose and is represented by X T . In addition, I denotes the identity matrix. For easy reference and enhancing the readability, we have summarised the major mathematical notations in Table I . Fig. 1 displays the key steps of the proposed patch-specific evolution trajectory prediction and classification framework from a baseline MRI using supervised and unsupervised strategies. Both strategies share a common ground which charts the selection of the best training atlas patches for the target prediction and classification task, at each landmark individually. Using the supervised atlas patch selection strategy, we first learn a mapping function f t1 i at each landmark x i , which aggregates two bidirectional regressors f\ni (see Section II for more details), to map the intensity dissimilarity vector between a pair of patches to an error prediction vector. Basically, we compute the prediction error for a pair of training patches as the average of the prediction error produced when (i) using the first training patch to predict the evolution trajectory of the second training patch and (ii) using the second training patch to predict the evolution trajectory of the first training patch. This atlas patch selection strategy is supervised by the potential of the selected training atlases in producing low prediction errors at follow-up timepoint t 2 . As for the unsupervised atlas patch selection strategy, we use multiple kernel learning to learn the pairwise similarity between training atlas patches and testing patch at baseline t 1 , which can nicely capture the latent distributions of landmarkseeded patches at different bandwidths. This allows to identify to most similar baseline atlas patches to the target testing patch. Given the selected best atlas patches by either strategies, we then linearly average the follow-up atlas patches at t 2 of the selected baseline atlas patches to predict the testing patch at t 2 . Last, we train an ensemble of linear SVM classifiers to automatically label each predicted patch-wise evolution trajectory. By aggregating the predicted labels at each landmark using weighted majority voting, the label of the testing subject is predicted. We detail below the steps of each proposed strategy.\nLandmark extraction. Several brain disorders alter the morphology and structure of specific anatomical brain regions leading to local expansion or atrophy at the region boundary. Voxels located at the edge of target anatomical regions might present discriminative features to use for investigating the presence of eMCI in a particular brain. Hence, for each training subject, we apply a Sobel filter to the training label map (or segmentation image) of the target ROI across all slices to detect its edge. Next, by linearly averaging training edges of a particular ROI, we associate with each voxel and edge density value indicating its intensity occurence across training samples. Ultimately, by thresholding the edge density map, we identify the key training landmarks seeding the centers of our patches for devising the proposed supervised and unsupervised atlas patch selection strategies. For each ROI, we define the threshold as the mean minus the standard deviation of intensity distribution drawn from training patches. For a new testing subject, we extract patches centered at the landmarks set using the training samples.\nSupervised atlas patch selection for predicting patch evolution trajectory using bidirectional atlas patch to prediction error regressors. Inspired by the work of [19] on learning how to select image atlases for accurate brain image segmentation, we propose a supervised atlas patch selection framework guided by the error a particular base line atlas at t 1 can produce when selected for predicting the patch evolution trajectory of a testing subject at a follow-up timepoint t k , k \u2265 2. Specifically, given n\u22121 training patches, we train our supervised atlas selection model for each left out testing subject. To do so, for each pair of training patches in the training set comprising n \u2212 1 patches, we compute their element-wise absolute difference as shown in Fig.1-A . While excluding self-differences, this produces an intensity disparity matrix of size (Fig. 2) . Basically, \u03b1 s,s maps the t 1 patch of subject s to the t 1 patch of subject s. If p t1 i,s has a zero-element, then the corresponding element in vector \u03b1 s,s is set to a high value. We note that we chose the intensity quotient of two patches \ni that maps the intensity disparity matrix at each landmark x i onto the corresponding prediction error vector e t1 i ( Fig. 1-A) .\nHowever, we note that if a subject a is used to predict another subject b at t 2 , the prediction error p \nin the 'negative' unidirectional intensity disparity matrix). To distinguish between both unidirectional disparity matrices, we use 'positive' and 'negative' directional differences, however, elements in both matrices are positive (Fig. 3) . In the next step, we train two separate regressors: one regressor function f i to predict the error of using subject s to predict p t2 i,tst . Ultimately, each training atlas patch will be assigned the average error (f\n. Ultimately, we select the top K atlas patches at t 1 with the lowest prediction errors, then average their corresponding patches at t 2 to output p t2 i,tst . Unsupervised patch selection for predicting patch evolution trajectory using multi-kernel patch manifold learning. To identify the baseline atlas patches whose follow-up images best represent the baseline testing patch in an unsupervised manner, we propose to learn pairwise patch intensity similarities ( Fig. 1-B) . Fundamentally, we adapt the MKML framework introduced in [20] to cluster generic data to our aim. MKML efficiently learns sample-to-sample similarity measure that best fits the structure of the data by combining multiple Gaussian kernels. It demonstrated significant outperformance in comparison with clustering methods that used pre-defined similarity measures such as Euclidean similarity and Pearson correlation, instead of learning it in a data-driven manner [20] . Given n samples, each represented by a d-dimensional feature vector (i.e., patch intensities in our case), MKML outputs an n \u00d7 n patch similarity matrix S.\nGiven a testing baseline patchp t1 k,tst seeded at landmark x k , we first learn a baseline similarity matrix S t1 k modeling the relationship between baseline training and testing patches. Instead of using one predefined distance measure which may fail to capture the nonlinear relationship in the patch data, we use m multiple Gaussian kernels {K l } m l=1 , weighed by a set of coefficients {w l } m l=1 to learn. In fact, by estimating the weights associated with each kernel, one can model the similarity between patches at different scales, thereby capturing spread out patch distributions as well as dense patch distributions when present in the dataset of interest. Adopting multiple kernels allows to better fit the true underlying statistical distribution of intensity patches. Besides, multiple kernels have been shown to correspond to different informative representations of the data and often are more flexible than a single kernel [20] , [21] .\nAdditionally, constraints are imposed on kernel weights to avoid a single kernel selection [20] .\nThe Gaussian kernel at scale \u03c3 l is expressed as follows:\n, where s,s is defined as: s,s = \u03c3 l (\u00b5 s + \u00b5 s )/2, where \u03c3 l is a tuning param-\n, where KN N (p t1 i,s ) represents the top k neighboring subjects of subject s. The computed kernels are then averaged to further learn the similarity matrix S t1 k at landmark x k and baseline timepoint t 1 through an optimization framework formulated as follows:\nk (i, j) refers to the relation between the similarity and the kernel distance with weights w l between two subject-specific patches. The learned similarity should be small if the distance between a pair of patches is large.\n\u2022 \u03b2||S t1 k || 2 F denotes a regularization term that avoids overfitting the model to the data.\n\u2022 \u03b3tr(L\nL is the latent matrix of size n \u00d7 c where n is the number of subjects and c is the number of clusters. The matrix (I n \u2212 S t1 k ) denotes the graph Laplacian.\n\u2022 \u03c1 l w l logw l imposes constraints on the kernel weights to avoid selection of a single kernel.\nAn alternating convex optimization is adopted where each variable is optimized while fixing the other variables until convergence [20] . Finally, based on the landmark-specific learned matrix S t1 k , we select the top K training patches (or K atlas patches) that are most similar to the target testing patch at baseline. Finally, we predictp t2 i,tst as a weighted average of corresponding K atlas patches at follow-up t 2 .\nPredicted patch-based trajectory labeling using ensemble SVM classifier. Last, at each landmark x i , we classify the patch evolution trajectory for a testing subject as 'healthy' or 'disordered'. Given a landmark-seeded predicted patch evolution trajectory, we train a linear SVM classifier using the concatenation of baseline training patches {p The left out testing subject is then labelled using a weighted voting scheme on predicted labels outputted by all SVMs (i.e. across all landmarks). The weights of the votes are assigned based on the posterior probabilities of the classification being correct, as estimated by the SVM classifiers."}, {"section_title": "III. RESULTS", "text": "Data and model parameters. We evaluated both supervised and unsupervised strategies using 30 NC (Normal Control) and 30 eMCI subjects acquired from the Alzheimer's Disease Neuroimaging Initiative (ADNI GO) [22] , [23] , [24] database (adni.loni.usc.edu), each with two T1-weighted MRIs (a baseline and a 6-month follow-up). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimer's disease (AD).\nEach MRI was pre-processed using the following steps as detailed in http://adni.loni.usc.edu/methods/mri-tool/ mri-analysis/ correction steps. These include (1) correction of image geometry distortion due to gradient non-linearity using Gradwarp [25] , (2) B1 non-uniformity correction of image intensity, and (3) N3 intensity correction using histogram peak sharpening algorithm to reduce residual image intensity nonuniformity [26] . All T1-weighted images have a resolution of 1.2 \u00d7 1.01 \u00d7 1.01mm and a volume size of 196 \u00d7 256 \u00d7 256. Next, we fed each T1-weighted image into FreeSurfer [27] which performs skull stripping, brain mask extraction, brain tissue segmentation into different anatomical regions of interest by registration to the Montreal Neurological Institute (MNI) space [28] . Each registered and segmented T1-weighted image is sampled to a uniform 1 3 mm resolution and a volume of size 256 \u00d7 256 \u00d7 256.\nFor evaluation, we tested each method using a leave-one-out cross-validation scheme on landmark patches extracted from the left and right hippocampi and the lateral ventricles. We selected these preliminary ROIs due to their prevalence in the dementia literature [9] , [10] as well as the demonstrated link between AD and the atrophy rates of the hippocampus [29] , [30] , [31] , [32] as well as the expansion of the lateral ventricles [33] , [34] .\nHyperparameter optimization is used to tune and set each linear SVM classifier's cost parameter C, using a nested cross-validation scheme with 5 folds on the training data. We evaluate values from an exponentially growing sequence between 2 \u22126 and 2 15 to find the best assignment for C. We fixed the patch size to 11 \u00d7 11 \u00d7 11 across all methods and ROIs. For MKML, we first used grid search to optimize both the number of clusters c and the number of kernels across all landmarks. For the number of clusters, we explored the range between 1 and 3. The optimal number of clusters generally was set to 2 or 3 clusters since when exceeding 3 clusters, the patch clusters become imbalanced. c = {2, 3} captures well the baseline patch distribution across landmarks. For MKML parameters, we set the number of clusters c = 2 for the right hippocampus and set c = 3 for all other regions. As for the number of kernels, we explored values between 1 and 10. Next, for each strategy, we optimized the third hyperparameter K. Basically, by varying the number of atlas patches K between 1 and 6, we noted that the performance starts dropping when generally exceeding 2 atlas patches. Hence, we ended up selecting 1 or 2 depending on the target ROI. Specifically, across all ROIs, MKML strategy was run with the parameter K (the number of atlas patches selected for prediction) set to 1. For the supervised atlas selection (SAS) strategy, K was set to 1 for the left hippocampus, 2 for the right hippocampus and the left lateral ventricle and 3 for the right lateral ventricle. For MKML, we set the number of kernels to 3 for the left and right lateral ventricles, 5 for the right hippocampus, and 7 for the left hippocampus. The edge density threshold for choosing landmark voxels has been set to 0.19 for the left lateral ventricle, 0.18 for the right lateral ventricle, and 0.15 for the hippocampi based on the automatically defined threshold using the mean and standard deviation of the intensity distribution in each target ROI.\nResults and performance. 3 . Prediction. The mean absolute error in predicted intensity is displayed in Fig. 4 for each prediction method. The best prediction performance was con-sistently achieved by SAS in all four ROIs, with a higher prediction error in left and right hippocampi. However, noting that MAE is not a normalized metric, using an alternative normalized evaluation measure can help better discern prediction performance across regions in relation to the classification performance (Table II) . Hence, we compute the average Pearson correlation between the ground truth patches and their corresponding predicted patches and report the results in Table III . Clearly, both SAS and MKML produced very promising prediction results in the left and right ventricles, respectively. However, we note a low prediction performance particularly in the right hippocampus. Fig. 5 displays the patch prediction results at two representative landmarks in the left ventricle using (SAS) method. The absolute residual patches show an overall very promising high similarity between the ground truth and predicted patches except a few bright local voxels.\nClassification. The classification performances of the proposed methods are reported in Table II for each region of interest. In Fig. 4 , we compare the performance of the prediction step of our framework side-by-side with the overall classification performance. The best performing method varies by region, but it can be seen that MKML consistently provided improvements over baseline-only classification in three of the four regions. It led to improvements of 5, 10 and 3.33 percentage points in the left lateral ventricle, the left hippocampus and the right hippocampus, respectively. SAS performed less consistently, leading to an improvement over the baseline-only method only in the lateral ventricles. It did however achieve the highest classification accuracy out of all the methods tested on the left lateral ventricle, providing a boost of 8.34 percentage points over the baseline-only method, and gave the highest specificity for the ventricles.\nUltimately, our results show the most discerning regions for prediction to be in the left hemisphere, and point to the possibility of achieving consistent accuracy improvements upon baseline-only classification using the MKML prediction method proposed in our framework. We would like to emphasise that the main contribution of this work is to highlight the great potential of predicting longitudinal data from baseline data in increasing classification accuracy and its potential use in the diagnosis of neurological disorders. The performance of the strategies proposed can be further improved by leveraging enhancing methods such as learning features using deep learning instead of simply utilizing patch intensities as well as tapping into the active field of feature selection methods.\nIV. DISCUSSION This paper proposed a joint prediction and classification framework which learns how to predict a subject's MR intensity image at a future timepoint and leverages this prediction to improve diagnosis accuracy whilst diagnosing based on a single timepoint using two novel supervised and unsupervised atlas patch selection strategies.\nEvaluation of results. The proposed MKML prediction method provides a consistent improvement of up to 10 percentage points in overall classification accuracy in both of the ROIs evaluated in the left hemisphere. The improvement seen in the right hemisphere was limited, with a marginal improvement of 3.33 percentage points in the right lateral ventricle and no improvement in the right hippocampus. It could be the case that the atrophy patterns in the right hemisphere are not discerning enough at the early MCI stage for our framework to detect similarities between eMCI patients and predict the second timepoint as effectively as in the left hemisphere. This could be attributed to the difference in the rates of atrophy that occurs under AD on each side of the brain, as AD-related atrophy is typically more visible in the left hemisphere [35] , [36] , [37] .\nSupervised atlas selection offered a marginal improvement in overall classification accuracy of 1.67 percentage points in the right lateral ventricle, and offered the best overall classification accuracy of 81.67% for the left lateral ventricle, though it offered no improvement over the baseline method in the hippocampi in either hemisphere. It also had the highest specificity in both of the lateral ventricles. Such performance can be nicely explained in the light of the results revealed in Table III , where the prediction of the right hippocampus evolution trajectory using SAS was very low compared to other ROIs, thus it did not outperform the baseline method (Fig. 4-D) . A reason for this could be in fixing the patch size across ROIs, which we opted for in this paper for comparative training at a fixed spatial scale. Also, we note that for SAS the direction of the error influences the classification accuracy, as well as the magnitude of the error. For instance, if the true patch has dementia-related atrophy at the voxel being predicted, it could be acceptable to predict an intensity value which is lower than the true voxel intensity, as the predicted voxel intensity should still fall on the same side of the hyperplane of an SVM as the true intensity value and lead to a correct classification, whereas predicting intensities higher than the true voxel value by the same error margin could point to the lack of atrophy and cause a misclassification, despite both predictions having the same mean absolute error.\nRemarkably, leveraging the predicted patches by SAS and MKML boosted the classification results -except for the right hippocampus where the prediction error was very large. However, we would like to bring to the attention of the reader that the performance of these methods ultimately depends on the presence of a training atlas patch which is sufficiently similar to the testing patch, since an underlying assumption in both methods is that the best predictors of the closest neighbour of the testing subject will also be good predictors of the testing subject. It is possible, therefore, that these methods could perform more consistently across landmarks with an expanded set of training samples.\nLimitations and recommendations for future work. We note that the proposed supervised atlas patch selection strategy assumes that the multiplication of an intensity patch of subject s at baseline by a weighting vector \u03b1 can produce the intensity patch of a different subject s . By applying the weighting vector \u03b1 forward to selected follow-up atlas patches, we predict the full evolution trajectory of a given testing patch. However, there is no theoretical proof that this assumption holds aside from the fact that the follow-up data predicted in this way generally boosted the subject classification performance as healthy or demented from a single MRI acquired at baseline. This is a proof-of-concept that needs to be further investigated.\nAdditionally, our current landmark-detection scheme uses threshold values which are pre-defined using the mean minus the standard deviation of intensity distribution in the target ROI. We expect that learning the optimal number L of landmarks from the training dataset and picking the L landmarks with the highest edge density would lead to improved results regardless of the dataset of interest. For instance, one can learn how to identify the best landmarks for the target classification task by leveraging advanced landmark detection techniques such as [38] . We also note that for a relatively fair comparison across regions, subjects and methods, we opted for fixing the patch size (i.e., using a fixed spatial scale), however, the optimal patch size for each region can be alternatively learned. This will be investigated in our future work. Besides, instead of solely relying on the patch intensity for best candidate atlas patch selection, we can use more advanced similarity measures that capture local atrophy (e.g., local deformation field with respect to a healthy template) and structural information (e.g., label patches). Since the proposed framework define the stateof-the-art in joint image evolution trajectory prediction and classification from a single timepoint, we opted for using simple intuitive measures. So far, we have only explored Gaussian kernels [20] for learning the patch manifold space. Other manifold learning techniques such as local nonlinear embeddings [39] and Riemannian approaches [40] for identifying the best atlas patches for the target prediction and classification tasks.\nIn our future work, we will evaluate our generic supervised and unsupervised patch-based trajectory evolution prediction and labeling frameworks on various neurological datasets with denser follow-up observations to predict and classify. We will also investigate the effectiveness of the framework on other regions which are highly correlated with AD, such as the entorhinal cortex [41] , [42] . In addition to predicting image intensity evolution trajectory, one can also extend the proposed strategies to handling 3-dimensional shapes [43] , [16] , [18] as well as connectomes [44] , thereby designing a holistic brain evolution trajectory prediction framework from baseline."}, {"section_title": "V. CONCLUSION", "text": "In this paper, we proposed both supervised and unsupervised patch-based evolution trajectory prediction and classification frameworks for accurate diagnosis of early MCI patients. Our initial results show that our framework can consistently boost the classification accuracy by up to 10 percentage points using the MKML method, and by 8 percentage points using the SAS method over the baseline-only method in the left hemisphere, with SAS achieving the highest classification accuracy of 81.67%. Remarkably, predicting longitudinal MRI data from a single acquisition timepoint largely improved the classification of NC and eMCI subjects, without resorting to any additional enhancing methods (e.g., feature selection techniques). One early measurement proved to be sufficient given that the predictive model works well. In our future work, we intend to further replicate our results in other neurological datasets and incorporate other high-dimensional brain representations such as the cortical surface which atrophies during MCI development. Furthermore, investigating similarity maps quantifying patch similarity between different timepoints [10] can further improve our classification accuracy while leveraging the predicted follow-up images. "}, {"section_title": "ACKNOWLEDGMENT", "text": ""}]