[{"section_title": "Abstract", "text": "Abstract Motivated by the need for understanding neurological disorders, large-scale imaging genetic studies are being increasingly conducted. A salient objective in such studies is to identify important neuroimaging biomarkers such as the brain functional connectivity, as well as genetic biomarkers, which are predictive of disorders. However, typical approaches for estimating the group level brain functional connectivity do not account for potential variation, resulting from demographic and genetic factors, while usual methods for discovering genetic biomarkers do not factor in the influence of the brain network on the imaging phenotype. We propose a novel semiparametric Bayesian conditional graphical model for joint variable selection and graph estimation, which simultaneously estimates the brain network after accounting for heterogeneity, and infers significant genetic biomarkers. The proposed approach specifies priors on the regression coefficients, which clusters brain regions having similar activation patterns depending on covariates, leading to dimension reduction. A novel graphical prior is proposed, which encourages modularity in brain organization by specifying denser and sparse connections within and across clusters, respectively. The posterior computation proceeds via a Markov chain Monte Carlo. We apply the approach to data obtained from the Alzheimer's disease neuroimaging initiative and demonstrate numerical advantages via simulation studies.\ncomputation yields posterior samples of cluster membership allocations for each column of B. In order to estimate functional modules, we compute the optimal clustering over MCMC iterations using the least squares criteria by Dahl (2006) . Denote by (m) , the vector of cluster allocations at the m-th MCMC iteration. The optimal cluster is selected as where \u0394 i,j ( (m) ) = 1 if (i, j) belong to the same cluster under (m) , and 0 otherwise, m = 1, \u2026, T, and \u03c0\u0302 is the estimated matrix of pair-wise probabilities of belonging to the same Kundu and Kang "}, {"section_title": "Introduction", "text": "During the last two decades, tremendous progress has been made in both neuroimaging and high-throughput genotyping technology, which has resulted in the development of an emergent interdisciplinary field known as imaging genetics, focusing on the genetic dissection of neuroimaging and clinical phenotypes. The goal of imaging genetics studies is to discover the brain-wide, genome-wide association patterns, which drive complex neurological disorders [such as Alzheimer's disease (AD), autism spectrum disorder and major depressive disorder]. A key objective in these studies is to characterize important neuroimaging and genetic biomarkers, which are associated with psychological disorders.\nOne important neuroimaging biomarker that has shown tremendous promise is the group level brain functional connectivity (Biswal et al., 1995; Smith et al., 2012; Huang et al., 2010 , Kim et al., 2015 , which characterizes the coherence of the neural activities among distinct brain regions for a collection of subjects. However typical approaches for estimating the group level brain network often fail to account for heterogeneity across subjects, resulting from demographic, clinical and genetic variations. This may lead to spurious associations and erroneous inferences. In addition to functional connectivity, several genetic biomarkers have been shown to be predictive of neurological disorders. Such biomarkers are often inferred by modelling the association between gene products/variants and the brain imaging phenotype (Stein et al., 2010; Zhu et al., 2014; Stingo et al., 2013) , because of the knowledge that some neuroimaging traits are closer to the action of the gene compared with clinical phenotypes (Mier et al., 2010; Munafo et al., 2008) . However, existing approaches for detecting such associations usually do not take into account the underlying brain functional network influencing the imaging phenotype.\nTo our knowledge, the body of work for inferring genetic associations with the imaging phenotype to discover genetic biomarkers for neurological disorders and the literature on estimating the brain functional connectivity have developed in a largely independent manner. In fact, there is a scarcity of approaches that can achieve the two goals simultaneously. To bridge such a gap through this work, we propose to jointly (i) estimate the group level brain functional network, after accounting for extrinsic sources of variation, and (ii) infer significant genetic and demographic associations with the imaging phenotype, leading to the discovery of important biomarkers. In addition, the proposed approach identifies functional modules, which contains brain regions having similar activation patterns influenced by covariates and deciphers the connectivity within each of these modules. The emphasis on functional modules is motivated by modular brain networks, which is a well-known feature of brain organization confirmed by several previous studies (Meunier et al., 2010) .\nA natural approach to fulfilling the aforementioned stated goals is the conditional Gaussian graphical model, which structures the multivariate outcome as a sum of a linear term involving covariates and a Gaussian residual encapsulating the graphical structure. The estimated graph under the conditional Gaussian graphical model provides a meaningful group level brain network comprising intrinsic connections after teasing out effects of thirdparty nodes and external sources of variation. Another advantage under this model is being able to compare brain networks across multiple groups, where it is imperative to account for variations because of genetic and demographic factors to make the comparisons meaningful. This is particularly useful for our real-data application where we seek to compare the functional connectivity between subjects with AD, subjects with mild cognitive disorder and healthy individuals. In this work, we impose sparsity on brain networks, which is supported by findings showing that a brain region usually interacts with only a few other regions in neurological processes (Stam et al., 2007; Supekar et al., 2008) .\nTo our knowledge, there is a limited literature for conditional graphical models, with the primary focus being essentially limited to genetic studies. Frequentist approaches such as Yin & Li (2011 and Cai et al. (2013) mainly focus on graph estimation after adjusting for covariates. However, the performance of the variable selection by those methods is not well assessed. On the other hand, the Bayesian approach proposed by Bhadra & Mallick (2013) assumes the same inclusion status for each covariate across all nodes (imaging phenotypes in our case), which makes this approach clearly inadequate for imaging genetics applications.\nA key challenge in conditional graphical models is achieving good variable selection and graphical model estimation simultaneously, with these two goals being closely intertwined. In particular, model misspecification in terms of an overly sparse coefficient matrix can lead to spurious associations between nodes because of lack of adjustment for confounders (as noted by Yin & Li, 2011) , while an artificially dense coefficient matrix is expected to cause overfitting, which may result in poor estimates for the strength of associations (as evidenced in Section 3). Ideally, a parsimonious Bayesian approach is desirable, which can provide a balance between the two goals, while providing uncertainty quantification to address the heterogeneity inherent in imaging genetics applications.\nTo achieve objectives (i) and (ii), we propose a flexible Bayesian conditional graphical model for joint covariate selection and graphical model estimation. The proposed model clusters the columns of the regression coefficient matrix under an infinite mixture of Laplace prior, which results in groups of nodes having similar activation patterns depending on covariates. The prior on the regression coefficients shrinks unimportant effect sizes to zero and yields groups of nodes that are related to covariates by similar magnitudes. The brain functional connectivity is estimated by a novel class of semiparametric graphical priors depending on the unknown cluster allocations, which specify sparse associations across clusters, but allow for denser connectivity within a cluster. Such a prior is motivated by modular brain networks (Nicolini & Bifone, 2016) and encourages functional modules characterized by distinct subnetworks. The method is straightforward to implement via a Markov chain Monte Carlo (MCMC). We design a post-MCMC approach involving multiplicity corrections for variable selection, which is able to identify important covariates influencing the imaging phenotype, as well as the functional modules.\nWe note that the emphasis on functional modules and corresponding subnetworks stems from the concept of modular brain networks, which describes the brain as a network of interconnected components comprising anatomically and/or functionally related brain regions (Sporns, 2010) . Modular systems naturally tend to be small-world networks (Pan & Sinha, 2009) , which is a well-established property in human brain organization. Moreover, widely used multivariate methods based on principal component analysis or independent component analysis have confirmed that the brain can typically be decomposed into subsystems of functionally connected brain regions (Guo, 2011; Calhoun et al., 2008) . Another recent work by Wang et al. (2016) demonstrated that the brain network (derived using partial correlations) can be divided into different modules, with sparse connections across these modules but denser connections within each module. Motivated by such existing studies, we propose a data adaptive approach to estimate a modular brain network after accounting for covariate information, where the functional modules are learned from the data.\nThe paper is organized as follows. Section 2 proposes our semiparametric conditional graphical model and develops a posterior computation scheme, Section 3 lays out our simulation study, and Section 4 applies our methods to the analysis of Alzheimer's disease neuroimaging initiative (ADNI) data."}, {"section_title": "Methodology", "text": ""}, {"section_title": "Semiparametric conditional graphical models", "text": "Let X and Z be the n \u00d7 p and n \u00d7 q dimensional outcome and covariate matrices, respectively, with the i-th row of X and Z being denoted as x i and z i , i = 1, \u2026, n. In our imaging genetics applications, x i corresponds to the multivariate imaging phenotype, while z i denotes the supplementary genetic and demographic information for the i-th individual. We assume that the rows of X have been centred; thus, it is not necessary to include an intercept term. Consider the following conditional graphical model:\n( 1) where \u03b4 \u03b8 denotes a point mass at \u03b8, N(\u00b7) and DE(\u00b7) denote Gaussian and double exponential/ Laplace distributions, respectively, \u03b5 i denotes the residual, \u03b2 k = (\u03b2 k1 , \u2026, \u03b2 kq ) T is the vector of regression coefficients, which captures the effect of covariates on the k-th outcome measurement (k = 1, \u2026, p), and \u03a3 G is the covariance matrix, which is defined conditional on the graph G. The prior on the covariance matrix and the graph space is discussed in detail in (2). We denote B = (\u03b2 1 , \u2026, \u03b2 p ) as the coefficient matrix, so that x i = z i B + \u03b5 i in (1).\nThe prior on the regression coefficients in (1) follows an infinite mixture of Laplace distributions, with the k-th component having a shrinkage parameter \u03bb k , and an associated weight w k , k = 1, \u2026, \u221e. The weights are structured as stick-breaking weights, so that w k = \u03bd k \u03a0 l<k (1 \u2212 \u03bd l ), \u03bd k ~ Beta(1, M), with . The mixture of Laplace prior enables dimension reduction by clustering the columns of B into distinct groups and encourages shrinkage of unimportant effect sizes towards zero. Each resulting cluster comprises nodes, which have similar activation patterns and are related to the covariates by similar magnitudes. In the special case when \u03bb k = \u03bb for all k, the prior on the regression coefficients reduces to a Dirichlet process mixture of Laplace distributions (Sethuraman, 1994) . The total number of clusters (H) is random and increases with the precision parameter M. The ingenuity of our approach lies in proposing a novel class of semiparametric graphical priors in (2), which translates the parsimony implied by the clustering of the columns of B into sparsity in the precision matrix, via a modular structure.\nWe assume that the support of the graph space is restricted to the class of decomposable graphs \u2133. To construct the prior on \u2133, first, fix the number of clusters induced under the mixture prior in (1) to be H. Further, denote the clusters as (S 1 , \u2026, S H ), with S h containing the indices of p h nodes belonging to cluster . Define the edge set E under the graph G as E:= {e(k, l), k < l, k, l = 1, \u2026, p}, where e(k, l) takes values 1 or 0 depending on whether the (k, l)-th edge is present in E or not. We formalize the semiparametric graphical prior \u03c0(G | S 1 , \u2026, S H ), defined conditional on cluster allocations, as follows:\n( 2) where 1(\u00b7) is the indicator function, Be(\u00b7) denotes a beta distribution, Ber(\u03c9) denotes the Bernoulli distribution with inclusion probability \u03c9, and HIW(b, D) refers to the hyper inverse-Wishart prior (Dawid & Lauritzen, 1993; Lauritzen, 1996) with scale matrix D and b degrees of freedom. The scale matrix is assumed to be diagonal in our work, that is, D = diag(d 1 , \u2026, d p ), with d j ~ \u03c0(d j ), j = 1, \u2026, p. The hyper inverse-Wishart prior in (2) restricts the support of to a space of positive definite matrices having zero off-diagonal elements corresponding to absent edges. We refer to the prior on the covariance in (2) as the semiparametric hyper inverse-Wishart prior or spHIW, because it is defined conditional on the unknown clustering parameters. We note that a change in the number of clusters and cluster memberships under the mixture distribution in (1) will result in corresponding changes in the graphical prior in (2). Formulation (2) specifies the edge inclusion probabilities as \u03c9 1 or \u03c9 0 , depending on whether the edge corresponds to two nodes belonging to the same cluster or different clusters. We choose hyper-parameters a \u03c9,0 , b \u03c9,0 , to have a small prior mean, and a \u03c9,1 , b \u03c9,1 , to have a larger prior mean, so as to encourage a higher density of edges within clusters, and sparse edges across clusters. The proposed approach thus results in a modular structure for the graph, such that there are sparse connections between modules, but denser connections within each module. The composition of the functional modules, as well as the subnetworks associated with the modules, are learned from the data.\nBecause the prior in (2) is defined conditional on the clustering parameters, it is appealing to derive the marginal prior \u03c0(G) after integrating out these parameters. First, note that (3) where G \u2208 \u2133, K is the normalizing constant, and t 1G , t 0G , represent the number of edges within and across clusters, respectively. We noted previously that, when \u03bb j = \u03bb for all j = 1, \u2026,\u221e, the prior on the regression coefficients in (1) is a Dirichlet process mixture of Laplace distributions. In this special case, we can use results from Kyung et al. (2010) to obtain the following marginal form of the prior on the graph space:\nwhere \u03c0(G | S 1 , \u2026, S H ) is defined as in (3), \u0393(\u00b7) denotes the Gamma function, and the set H contains all possible clustering allocations S 1 , \u2026, S H , given H clusters."}, {"section_title": "Variable selection", "text": "We propose a post-MCMC variable selection approach, which proceeds by constructing credible regions accounting for multiplicity corrections. The variable selection enables us to infer (i) covariate effects on individual nodes and (ii) subsets of covariates determining clusters of nodes. It is understood that the covariates that affect a particular cluster may influence one or more connections between nodes in that cluster. Further, a group of covariates may affect more than one cluster, in which case it is possible that these covariates explain the dependence between such codependent clusters.\nWe construct rectangular credible regions incorporating multiplicity corrections as := {\u03b2 jk : | \u03b2 jk |/std( \u03b2 jk ) \u2264 U \u03b1* , j = 1, \u2026, q, k = 1, \u2026, p}, where std(\u03b2 jk ) is the standard deviation for \u03b2 kl , and \u03b1 * is the multiplicity adjusted width of the credible intervals. The aforementioned credible intervals enable us to test a set of local hypotheses versus for j = 1, \u2026, q, k = 1, \u2026, p, where the threshold for each regression coefficient is adjusted according to its standard deviation and hence is different from hard thresholding approaches, which choose a fixed threshold. The local hypothesis tests can be performed using a t-test at a significance level \u03b1 * = \u03b1/(pq) under a Bonferroni correction. Although it is straightforward to use more sophisticated alternatives such as the false discovery rate approach (Benjamini & Hochberg, 1995) , a simple Bonferonni correction performs adequately for our simulations studies and data applications."}, {"section_title": "Posterior computation", "text": "We propose an efficient approximate posterior computation scheme using a parameter expansion strategy. Under the original formulation (1), the computation of cluster membership probabilities for different columns of B will require p matrix inversions of order p \u2212 1 each, which can be computationally restrictive. We devise a parameter expanded model to bypass the need of inverting matrices when computing cluster memberships. We fit the modified model:\nwhere \u03b1 i = (\u03b1 i1 , \u2026, \u03b1 ip ) T can be interpreted as the intercept term, which captures the graph information, and \u03b4 ~ Be(a \u03b4 , b \u03b4 ) is the residual variance. The prior on the graph and the covariance matrix is defined similarly as in (2). Marginalizing out the intercept in (4) yields\n, when \u03b4 \u2248 0, which essentially gives back our original formulation (1).\nThe computational advantage of (4) stems from the fact that all elements in the data matrix X are independent conditionally on B, \u03b1 1 , \u2026, \u03b1 n , \u03b4. This allows the following form of the posterior distribution, conditional on the clustering (S 1 , \u2026, S H ) :\nwhere s j \u2208 {1, \u2026, H} denotes the cluster membership for the j-th column in B, j = 1, \u2026, p.\nUnder (5), it is straightforward to compute the cluster membership for a particular column independently of the other columns, in a computationally inexpensive manner that does not involve matrix inversions. In practice, the approximation under (4) is implemented by specifying a conjugate prior on \u03b4 with mode near zero and having a small variance, which results in posterior samples of \u03b4 = O(10 \u22123 ), where a 1 = O(a 2 ) implies that |a 1 /a 2 | is bounded.\nIn our experience, this choice works adequately for a variety of scenarios.\nWe use an MCMC algorithm for the posterior computation, which proceeds by (i) updating the cluster memberships and cluster atoms conditional on other parameters; (ii) updating the graph conditional on the cluster memberships, and then updating the inverse covariance matrix conditional on the graph; and (iii) updating the intercepts and residual variance conditional on the other parameters. We update the graph using a Metropolis-Hastings step in a manner similar to Bhadra & Mallick (2012) , where the proposal distribution changes a non-zero element in the adjacency matrix to a zero element with probability 1 \u2212 a G , and the reverse proposal occurs with probability a G . Except for the graph, all remaining parameters in (5) can be sampled via closed form posteriors. The MCMC steps are described in detail in the Supporting Information section.\ncluster, computed over all MCMC iterations. The final estimated graph structure is computed in a manner consistent with this optimal clustering, by computing the marginal inclusion probabilities of edges using MCMC samples corresponding to the clustering * , and including edges with high probabilities.\n3 Simulation studies"}, {"section_title": "Description", "text": "We consider three simulation settings (Cases I-III) with varying dimensions involving a true model of the form x i ~ N(z i B 0 ,\u03a3 0 ) where \u03a3 0 is the true covariance matrix, and B 0 = (\u03b2 01 , \u2026, \u03b2 0p ) are the true regression coefficients. For Cases I and II, the number of non-zero rows in the coefficient matrix (B 0 ) are 10 and 5, respectively, where the elements in these non-zero rows are randomly set to 2, 3 or 0, and the proportion of zeros are high to ensure a sparse coefficient matrix. For both cases, the inverse covariance matrix is generated as follows. First, we generate \u03a3 * having elements \u03c3 * (l, l\u2032) = 0.5 (||l \u2212 l\u2032| + 1| 1.4 \u2212 2|l \u2212 l\u2032| 1.4 + ||l \u2212 l\u2032| \u2212 1| 1.4 ), l, l\u2032 = 1, \u2026, p, which corresponds to a fractional Gaussian noise process with Hurst parameter as 0.7. We then invert \u03a3 * to obtain \u03a9 * and subsequently fix all off-diagonal elements of \u03a9 * to be zero if the absolute value is less than 0.05, to obtain . Finally, we rescale the diagonal elements of as to obtain a diagonally dominant matrix, which is positive definite, denoted as . This is the true precision matrix that is used to generate the data. The true graph G 0 is obtained by including all edges corresponding to an absolute partial correlation greater than 0. Note that the true model is a violation of the clustering as well as the block diagonal assumptions inherent in the proposed methodology. We consider dimensions (n, p, q) = (100, 80, 100), (100, 80, 200) for Cases I and II.\nFor Case III, we fit our model (1) and (2) to the positron emission technology (PET) data for individuals with mild cognitive impairment (MCI) obtained from the ADNI dataset, and then use the fitted model to simulate data. The dataset in question contains PET measurements recorded for 121 MCI samples (n), with additional information on q = 546 single nucleotide polymorphisms (SNPs). The imaging measurements were summarized into p = 42 regions of interest in the brain as in Huang et al. (2010) , which are outlined in Table I . These regions are distributed in the frontal, parietal, occipital and temporal lobes and are considered to be potentially related to AD. We fit our model using dichotomized SNP data with value 1 if the minor allele frequency is 1 or 2, and 0 otherwise. This fitted model that is used to generate data that corresponds to a high dimensional multivariate response regression model, having 546 covariates and 140 edges.\nWe compare our approach (spHIW) with (i) the sparse seemingly unrelated regression (SSUR) method by Bhadra & Mallick (2012) for simultaneous graphical model estimation and variable selection; (ii) a multivariate version of the Bayesian lasso (Park & Casella, 2008) denoted as BLASSO designed to perform variable selection; and (iii) the frequentist graphical lasso (Friedman et al., 2008) denoted as GLASSO for graphical model estimation without accounting for covariates; we implemented spHIW and BLASSO in MATLAB, while the MATLAB code for SSUR was obtained from the authors of that article. The GLASSO was implemented using the R package glasso.\nFor the Bayesian approaches, we ran 25,000 MCMC iterations with a burn in of 5000. The initial adjacency matrix for the proposed approach and SSUR was chosen to be identity corresponding to a null graph, and the parameters in the hyper inverse-Wishart prior for these approaches were defined as b = 3, D = dI p . We imposed a conjugate Gamma prior on d, which seemed to work well in a variety of scenarios. In addition, we specify independent Gamma priors on \u03bb l , l = 1, \u2026, q, as well as M ~ Ga(1, 1) and \u03b4 \u22121 ~ Ga(1000, 1). All results are reported over 50 replicates."}, {"section_title": "Comparison criteria", "text": "We looked at several metrics for comparisons, including (i) out-of-sample prediction in terms of mean squared error or MSE; (ii) estimation of true regression coefficients in terms of L 2 error; (iii) estimation of the precision matrix in terms of L 1 error; (iv) area under the receiver operating characteristic (ROC) curve for variable selection; and (v) area under the ROC curve for graphical model estimation. The predicted test samples were obtained using posterior predictive distributions under Bayesian approaches, and this was used to compute MSE. However, it was not possible to report MSE under GLASSO because it does not incorporate covariate information. Estimation of the precision matrix and regression coefficients under our approach was based on MCMC samples corresponding to the optimal clustering as outlined in Section 2.3, while it was based on all MCMC samples for the other Bayesian approaches.\nTo compute the area under the curve (AUC) for variable selection accuracy under our approach and BLASSO, we examine a series of regression models obtained by including all covariates for which |\u03b2\u0302k l |/se(\u03b2\u0302k l ) > t kl , and excluding remaining variables. Here, t kl is a threshold that controls the sparsity of the regression model, and \u03b2k l , se(\u03b2k l ) are the estimated mean and standard errors for \u03b2 kl , k = 1, \u2026, q, l = 1, \u2026, p. For SSUR, the AUC for variable selection was computed by looking at a series of regression models obtained by varying the threshold for the posterior inclusion probabilities. On the other hand, we computed the AUC for graphical model estimation under the spHIW, and SSUR by examining a series of graphs obtained by varying the threshold for posterior inclusion probabilities for edges. Again, only the MCMC samples corresponding to the optimal clustering was used to compute the graph under our approach. The AUC for graph estimation under GLASSO was obtained by examining a series of models corresponding to different values of the penalty parameter."}, {"section_title": "Results", "text": "The numerical results under all approaches are reported in Table II . Our approach exhibits a lower error for estimating the true regression coefficients compared with BLASSO under Case I, but slightly higher error under Case II. The error under our approach was lower compared with SSUR for all scenarios. The AUC for variable selection is the highest under BLASSO, while it is the lowest for SSUR (close to 0.5). The poor AUC under SSUR is due to the inclusion of almost all covariates in the model, which indicates the inability of the approach to differentiate between important and unimportant covariates. In spite of having a lower AUC for variable selection compared with BLASSO, the proposed approach does significantly better in terms of out-of-sample prediction. This points to the advantage of incorporating the graph structure for prediction purposes, as opposed to assuming independence within the outcome measurements. SSUR has the largest out-of-sample MSE, in spite of reporting an overly large regression model.\nFor graphical model estimation, we note the proposed approach, SSUR, and GLASSO all have a similar AUC. However, the proposed approach produces the smallest error for estimating the precision matrix, which points to a superior ability to accurately estimate partial correlations. We conjecture that a lower error in estimating the partial correlations is due to the removal of external sources of variation, which when unaccounted for can potentially lead to erroneous estimates for strength of associations.\nIn summary, for Cases I and II, the proposed conditional graphical model has superior outof-sample prediction performance by incorporating the underlying graph structure but suffers from a poorer variable selection performance due to the presence of a sizable number of additional covariance parameters. In contrast, the competing SSUR approach does very poorly in terms of variable selection and out-of-sample prediction. Both SSUR, which includes almost all covariates in the regression model, and GLASSO, which does not include any covariate at all, have comparable graph estimation performance, but higher errors when estimating the strength of associations. This underlines the role of accurate variable selection as an important factor in the estimation of conditional associations.\nFor Case III where the data resembles a real-world application, the proposed approach has superior performance compared with all approaches. In particular, the method has comparable out-of-sample prediction, but a lower error for estimating true regression coefficients, and a significantly higher AUC for variable selection. The higher AUC compared with Cases I and II points to the increased ability of the proposed method to differentiate between important and unimportant variables when the dimension of the multivariate outcome is moderate compared with the sample size, even when the number of candidate predictors is large. We also observe that the proposed approach has an improved graphical model estimation performance relative to competing approaches, as evident from significantly higher AUC, and a substantially smaller error for estimating partial correlations."}, {"section_title": "Application to imaging genetics 4.1 Description of Alzheimer's disease neuroimaging initiative data", "text": "The ADNI collected a large amount of imaging, genetic and clinical data. The goal of the ADNI study is to determine whether different imaging biomarkers, along with genetic variants and clinical markers are strongly associated with the AD and the progression of MCI. In this article, we primarily concentrate on identifying (i) important connections in the functional brain network after accounting for age, gender, handedness, weight and genes; (ii) functional modules or collections of regions of interest in the brain, which work together to drive brain functions, and the corresponding subnetworks; and (iii) important genes influencing the imaging phenotype and the functional modules. The brain network is computed using PET measurements; however, it is straightforward to apply the method to other imaging modalities such as magnetic resonance imaging (MRI). We perform the analysis separately for the MCI, AD groups and healthy controls (HCs) and compare results across the three groups. We begin with a data description. 4.1.1 Imaging data-ADNI 1 collected the longitudinal PET scans at multiple time points across different imaging sites. To study the association between the imaging biomarkers and genetic variants, we used the PET scans at baseline for 49 AD patients, 121 MCI patients and 71 healthy subjects. The standard preprocessing steps including co-registration, normalization and spatial smoothing (8 mm full width at half maximum (FWHM)) were applied to the PET dataset. We considered 90 brain regions that are defined according to the automated anatomical labelling system. We computed the PET regional summaries using the first principal component scores over all voxels with each region, in a similar fashion as in Bowman et al. (2012) . This 90 \u00d7 1 dimensional summary vector of PET scans is our outcome variable."}, {"section_title": "Genetics data-", "text": "The SNPs in the ADNI study were genotyped using the Human 610-Quad BeadChip (Illumina, Inc., San Diego, CA, USA). By following Zhu et al. (2014) and Wang et al. (2012) , we only focused on SNPs that belong to the top 40 candidate genes reported in the AlzGene database (http://www.alzgene.org) as of 10 June 2010. Before the data analysis, we performed standard preprocessing steps (Wang et al. 2012 ) on the SNP data for quality control. We also removed the SNPs having (i) more than 1% missing values, (ii) minor allele frequency less than 5% and (iii) the Hardy-Weinberg equilibrium p-value less than 10 \u22126 . The final dataset includes 614 SNPs on 37 genes. Figure 1 shows the number of the SNPs in the analysis per gene. The total number of covariates is 618 including preselected 614 SNPs and four demographic variables including handedness, age, gender and weight."}, {"section_title": "Analysis results", "text": "Brain network identification-Based on the MCMC samples, we computed the posterior edge inclusion probabilities of the brain network for each group. By thresholding the probability at 0.5, the group-specific brain networks are obtained in Figure 2 . Specifically, the AD, MCI and HC networks have 79, 102 and 73 important edges, respectively. There are 14 edges shared by all the three groups. Some of the common edges are in the default mode network (Buckner et al., 2008) . For example, the functional connections between left and right precuneus (related to self-consciousness) appear in all the three networks, which implies that AD or MCI subjects have similar functional activities between the two precuneus regions as the HC subjects. Also, all the three networks contain edges between the left and right hippocampus, which indicates that the two regions are still functionally connected in the AD and MCI groups, although the damage in the Hippocampus has been confirmed to be related to AD.\nin Figure 3 . It can be seen that AD and MCI have two similar functional modules: communities 1 and 2, while the modules related to HC are quite different from the AD and MCI groups. Functional module 1 for AD and MCI groups collect many regions in parietal and temporal lobes, with the number of connections being 29 and 42, respectively. We observe that some functional connections between the two hemisphere are missing in the AD group compared with the MCI group. For example, the AD network does not have the functional connections between the right and left fusiform gyrus, the functionality of which is mainly related to face and body recognition (McCarthy et al., 1997) .\nThe functional module 2 in both AD and MCI networks include hippocampus and parahippocampal in temporal lobe. The total numbers of connections between these two regions and all other regions are six in the MCI network and only two in the AD network. This implies that these regions become more isolated in AD group compared with the MCI group, which has been confirmed by previous findings (Supekar et al., 2008; Huang et al., 2010) . The functional module 3 for the AD group mainly includes four regions: postcentral gyrus, precentral gyrus, paracentral lobule and supplementary motor area, whose functions are mainly related to the motor skill and sense of touch. Because this is a separate module in the AD group, these regions have much fewer connections compared with the HC group, which potentially implies reduced motor skills and sense of touch for AD subjects. Compared with the brain networks for AD and MCI groups, our analysis only detects two functional modules for the HC, which implies increased connectivity compared with the AD and MCI patients.\nImportant genes for brain networks-Based on the MCMC samples, we identify important SNPs associated with each functional module for AD, MCI and HC groups (Table  III) . For example, SNP \"rs2018334\" on NEDD9 is significantly associated with the subnetwork community 2 in the AD group, which is supported by the findings by Wang et al. (2012) . GAB2 was also recognized as an important gene for both AD and MCI groups, but not the HC group; this corresponds to prior evidence implying that the gene modifies late onset AD risk in APOE \u03b54 carriers and influences Alzheimer's neuropathology (Reiman et al., 2007) . Keeping in line with prior findings, CH25H was found to be significantly associated with AD risk but not MCI or HC (Wollmer, 2010) . Further, genes that promote MCI disease risk but are not associated with HC individuals include ECE1, which is associated with cognitive ability in elderly individuals and disease risk (Hamilton et al., 2012) , as well as ADAM-10, which regulate neuronal plasticity affecting AD (Marcello et al., 2013) , and phosphatidylinositol binding clathrin assembly protein (PICALM), which was one of the first AD loci identified by genome-wide association studies, and which has also been validated in independent samples. In addition, SORL1, which is known to be a potential tool for identifying MCI subjects at high risk of conversion to AD (Piscopo et al., 2015) , is found to be significant in the MCI and HC groups, but not with the AD group. In addition to the aforementioned genes, we found that age is a significant predictor for community 1 in the MCI group."}, {"section_title": "Discussion", "text": "We have developed a new Bayesian semiparametric conditional graphical model for imaging genetics studies and applied it for analyzing the ADNI dataset. Our approach can jointly estimate the brain network after accounting for external sources of variation and infer important genetic and demographic factors associated with the imaging phenotype and the brain network. It can also simultaneously discover functional modules in the brain and infer the connectivity within each such module. To our knowledge, the proposed method is among the first to jointly address the aforementioned aims and is expected to provide deeper insights in imaging genetic studies, compared with existing approaches. Given the high dimensional nature of the data in imaging genetics applications, it would be interesting to explore the scalability of the proposed approach as p and/or q increases. Our initial experiments suggest that the semiparametric conditional graphical model scales well with the number of covariates q, but the computational speed may become slower as p is increased. However, more effort is needed to examine such scalability issues, and we leave this topic for future investigation. Functional modules or communities for Alzheimer's disease (AD), mild cognitive impairment (MCI) and healthy control (HC) groups, along with important genes. The arrows relate the subnetworks to the significant genes influencing them. Each such gene can influence one or more connections in the functional modules, as well as one or more phenotypes in that module. Table II Numerical comparison for different approaches under all cases. Stat (Int Stat Inst). Author manuscript; available in PMC 2017 June 12."}]