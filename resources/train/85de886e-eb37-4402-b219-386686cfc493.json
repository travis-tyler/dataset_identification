[{"section_title": "List of Appendixes", "text": ""}, {"section_title": "List of Tables", "text": ""}, {"section_title": "List of Tables (continued)", "text": "\n"}, {"section_title": "INTRODUCTION", "text": "The U.S. TIMSS Advanced 1995 &2015 Technical Report andUser's Guide provides an overview of the design and implementation of the Trends in International Mathematics and Science Study (TIMSS) 2015 and TIMSS Advanced 2015 in the United States and one participating benchmarking state: Florida."}, {"section_title": "TIMSS and TIMSS Advanced 2015 in Brief", "text": "The Trends in International Mathematics and Science Study (TIMSS) is an international comparative study designed to measure trends in mathematics and science achievement at the fourth and eighth grades, as well as to collect information about educational contexts (such as students' schools, teachers, and homes) that may be related to student achievement. TIMSS has been administered every 4 years since 1995, with the sixth and most recent administration, in 2015, providing a 20-year trend line. The United States has participated in every administration of TIMSS, which includes 1995TIMSS, which includes , 1999TIMSS, which includes , 2003TIMSS, which includes , 2007TIMSS, which includes , 2011TIMSS, which includes , and 2015 for the eighth grade and all but 1999 for the fourth grade (when it was not administered internationally). TIMSS is designed to align broadly with mathematics and science curricula in the participating education systems and, therefore, to reflect students' school-based learning. Because it is an international study, TIMSS provides valuable benchmarking information on how U.S. students compare to students around the world. TIMSS Advanced is an international comparative study designed to measure the advanced mathematics and physics achievement of students in their final year of high school who are taking or have taken advanced courses. TIMSS Advanced also collects information about educational contexts (such as schools and teachers) that may be related to advanced students' achievement. TIMSS Advanced was administered previously, in 1995 and in 2008, and most recently in 2015. The United States participated in the 1995 and 2015 administrations. Like TIMSS, TIMSS Advanced is designed to align broadly with curricula in the participating education systems and, therefore, to reflect students' school-based learning of advanced mathematics and physics. TIMSS Advanced can inform policymakers, researchers, educators, and the public about the degree to which students in the United States excel in advanced mathematics and physics and may be prepared to undertake more specialized study in science, technology, engineering, and mathematics compared to their international peers. TIMSS and TIMSS Advanced are both sponsored by the International Association for the Evaluation of Educational Achievement (IEA) and conducted, in the United States, by the National Center for Education Statistics (NCES) in the Institute of Education Sciences within the U.S. Department of Education. The TIMSS and TIMSS Advanced assessments are developed through an international collaborative process involving input from the U.S. and international experts in mathematics, science, and measurement. These experts develop frameworks that define the knowledge and skills to be assessed and are designed to align broadly with mathematics and science curricula in the participating countries. The results, therefore, suggest the degree to which students have learned mathematics and science concepts and skills likely to have been taught in school. A large and diverse group of education systems, spanning six of the world's continents, participated in TIMSS 2015. These education systems included 49 IEA member countries and six benchmarking participants 1 that participated in the fourth-grade assessment and 38 IEA member countries and six benchmarking participants that participated in the eighth-grade assessment. Nine education systems-all IEA member countries-participated in TIMSS Advanced 2015. A detailed explanation of TIMSS and TIMSS Advanced 2015 from an international perspective can be found in five reports published by the IEA and available online. "}, {"section_title": "Sampling", "text": "TIMSS and TIMSS Advanced are sample-based assessments, meaning that while only a sample of students take the assessments, they are selected in such a way as to allow the results to be generalizable to a larger target population. The TIMSS and TIMSS Advanced target populations are based on standardized definitions, and the sampling is conducted following standardized and refereed international procedures. TIMSS required participating countries and other education systems to draw probability samples of students who were nearing the end of their fourth or eighth year of formal schooling, counting from the first year of the International Standard Classification of Education (ISCED) Level 1 (or primary schooling). (For additional information on ISCED levels, see http://uis.unesco.org/en/topic/international-standard-classification-education-isced). In the United States, one sample was drawn to represent the nation at grade 4 and another at grade 8. The U.S. national sample included both public and private schools, randomly selected and weighted to be representative of the nation at grade 4 and at grade 8. (See the section on sampling weights and standard errors in this report for definitions.) In addition, because Florida participated in TIMSS 2015 as a benchmarking participant, separate public school samples were drawn for Florida at both grades. In total, the U.S. national sample in 2015 consisted of 250 schools and 10,029 students at grade 4, and 246 schools and 10,221 students at grade 8. The weighted school response rate for the United States was 77 percent at grade 4 before the use of substitute schools (schools substituted for originally sampled schools that refused to participate) and 85 percent with the inclusion of substitute schools. At grade 8, the weighted school response rate before the use of substitute schools was 78 percent and 84 percent with the inclusion of substitute schools. The weighted student response rate at grade 4 was 96 percent and at grade 8 was 94 percent. Student response rates are based on a combined total of students from both sampled and substitute schools. TIMSS Advanced required participating countries to draw probability samples of students in their final year of secondary school-ISCED Level 3-who were taking or had taken courses in advanced mathematics or who were taking or had taken courses in physics. In the United States, two samples of twelfth-graders were drawn to represent the nation-one for advanced mathematics and one for physics. The courses that define the target populations had to cover most, if not all, of the advanced mathematics and physics topics that were outlined in the assessment frameworks. In the United States, this was defined as a calculus course for eligibility for the advanced mathematics population and a physics course, such as Advanced Placement (AP) physics, for the physics population. The U.S. national samples included both public and private schools, randomly selected and weighted to be representative of the nation's advanced mathematics and physics students at the end of high school. (See the section on sampling weights and standard errors in this report for definitions.) In total, the U.S. national sample in 2015 consisted of 241 schools for advanced mathematics and 165 schools for physics (of the original sample of 348 schools for both subjects). The weighted school response rate for the United States for advanced mathematics was 72 percent before the use of substitute schools and 76 percent with the inclusion of substitute schools. The weighted school response rate for the United States for physics was 65 percent before the use of substitute schools and 68 percent with the inclusion of substitute schools. In terms of the number of students, the U.S. national sample consisted of 2,954 students in advanced mathematics and 2,932 students in physics. The weighted student response rate was 87 percent for advanced mathematics and 85 percent for physics. Student response rates are based on a combined total of students from both sampled and substitute schools. "}, {"section_title": "Assessment Design", "text": "TIMSS and TIMSS Advanced 2015 included student booklets containing assessment items as well as contextual background questionnaires. Questionnaires for principals and teachers were self-administered, primarily using an online survey system. The assessment booklets were constructed such that not all of the students responded to all of the items. This is consistent with other large-scale assessments, such as NAEP. To keep the testing burden to a minimum, and to ensure broad subject-matter coverage, TIMSS used a rotated block design that included both mathematics and science items for each student. That is, students encountered both mathematics and science items during the assessment. TIMSS Advanced also used a rotated block design, but each student took only one subject, either advanced mathematics or physics. The fourth-grade assessment consisted of 14 booklets, each requiring approximately 72 minutes. The eighth-grade assessment also consisted of 14 booklets, each requiring approximately 90 minutes. The assessments were given in two equally timed sections, with a 5-to 10-minute break in between. At both grades, the mathematics and science items were each assembled separately into 28 blocks of items. Booklets consisted of four blocks each, including at least one mathematics block and at least one science block. The TIMSS Advanced assessments consisted of six booklets for advanced mathematics and six booklets for physics, each requiring approximately 90 minutes. Each student completed just one booklet. In both subjects, booklets consisted of three blocks each. After the cognitive assessment, students completed a 30-minute questionnaire designed to provide information about their backgrounds, attitudes, and experiences in school."}, {"section_title": "Test Administration", "text": "Test administration for TIMSS and TIMSS Advanced in the United States started in April and continued through June 2015. The administration was carried out by professional staff trained according to the international guidelines. School personnel were asked only to assist with listings of students, the identification of space for testing in the school, and the specification of any parental consent procedures required. The International Study Center monitored compliance with the standardized procedures."}, {"section_title": "Scoring", "text": "Both the TIMSS and TIMSS Advanced assessment items included both multiple choice and constructedresponse items. A scoring rubric (guide) was provided for every constructed response item. The National Research Coordinator in each country was responsible for the scoring and coding of data in that country, following established guidelines. \nEach team worked on different items. Scorers were able to view only the one active item that they were assigned by their supervisors and were not able to score other items from any other team. The exception was with the linked items from the \"themed\" blocks. In this situation, a question or questions required reference to a previous answer. For instance, question 4 in the block may have required data or the answer from questions 1 and 2 in order to answer the question. In this situation, the ePEN setup was designed so that the scorer had access to screens with all of the pertinent responses, again only as assigned by the supervisor. The answers could not be submitted to ePEN until all questions from the set were scored to make sure that the scorer had all the needed information to score all related items. Scoring quality was monitored continuously. The ePEN system allowed interrater reliability reports to be run almost as soon as scoring began. Another monitoring method used was back-reading of already scored responses. This allowed the scoring supervisor to look at responses by category. The scoring supervisor also could review responses either by scorer or by score point agreements or splits. Scoring supervisors checked completion statistics as well."}, {"section_title": "Scaling", "text": "Total scores for mathematics and science in TIMSS, and advanced mathematics and physics in TIMSS Advanced, along with scores that reflect performance in specific domains of each subject, were estimated using an item response theory (IRT) model. For example, the TIMSS 2015 eighth-grade assessment had four scales describing four mathematics content areas and four science content areas, as well as three cognitive domains in each of mathematics and science. Benchmark scores were also derived. IRT estimation procedures were also used to place scores from the six TIMSS assessments conducted in 1995,1999,2003,2007,2011, and 2015 on the same scale (the scale of the 1995 administration). This allows for the calculation of trends in achievement even though the makeup of the countries participating in TIMSS changes over time. Scaling for TIMSS Advanced follows a similar process, using data from the 1995, 2008, and 2015 "}, {"section_title": "Plausible Values", "text": "To keep student burden to a minimum, TIMSS and TIMSS Advanced purposefully administered a limited number of assessment items to each student-too few to produce accurate individual content-related scale scores for each student. The number of assessment items administered to each student, however, is sufficient to produce accurate group content-related scale scores for subgroups of the population. These scores are transformed during the scaling process into plausible values to characterize students participating in the assessment, given their background characteristics. Plausible values are imputed values and not test scores for individuals in the usual sense. If used individually, they provide biased estimates of the proficiencies of individual students. However, when grouped as intended, plausible values provide unbiased estimates of population characteristics (e.g., means and variances for groups). Plausible values represent what the performance of an individual on the entire assessment might have been, had it been observed. They are estimated as random draws (usually five) from an empirically derived distribution of score values based on the student's observed responses to assessment items and on background variables. Each random draw from the distribution is considered a representative value from the distribution of potential scale scores for all students in the sample who have similar background characteristics and similar patterns of item responses. Differences between plausible values drawn for a single individual quantify the degree of error (the width of the spread) in the underlying distribution of possible scale scores that could have caused the observed performances. More detailed information can be found in the Methods and Procedures in TIMSS 2015 (Martin, Mullis, and Hooper 2016a).\nDuring the scaling phase, plausible values were used to characterize scale scores for students participating in the assessment. To keep student burden to a minimum, TIMSS and TIMSS Advanced purposefully administered a limited number of assessment items to each student-too few to produce accurate individual content-related scale scores for each student. The number of assessment items administered to each student, however, is sufficient to produce accurate group content-related scale scores for subgroups of the population. These scores are transformed during the scaling process into plausible values to characterize students participating in the assessment, given their background characteristics. Plausible values are imputed values and not test scores for individuals in the usual sense. If used individually, they provide biased estimates of the proficiencies of individual students. However, when grouped as intended, plausible values provide unbiased estimates of population characteristics (e.g., means and variances for groups). Plausible values represent what the performance of an individual on the entire assessment might have been, had it been observed. They are estimated as random draws (usually five) from an empirically derived distribution of score values based on the student's observed responses to assessment items and on background variables. Each random draw from the distribution is considered a representative value from the distribution of potential scale scores for all students in the sample who have similar background characteristics and similar patterns of item responses. Differences between plausible values drawn for a single individual quantify the degree of error (the width of the spread) in the underlying distribution of possible scale scores that could have caused the observed performances. This approach to the estimation of scale scores ensures that the estimates of the average performance of student populations and the estimates of variability in those estimates are more accurate than those determined through traditional procedures, which estimate a single score for each student. An accessible treatment of the derivation and use of plausible values can be found in Beaton and Gonz\u00e1lez (1995). A more technical treatment can be found in Methods and Procedures in TIMSS 2015 (Martin, Mullis, and Hooper 2016a) and in Methods and Procedures in TIMSS Advanced 2015 (Martin, Mullis, and Hooper 2016b).\nAs noted earlier, the assessment design was based on Balanced Incomplete Block (BIB) spiraling of assessment items to increase content-area coverage without a concomitant increase in the assessment time demanded of students. Each student completed only a subset of the total pool of assessment items, with the resulting data containing missing values for other items in the pool but not in the subset administered to the student. The trade-off for increased coverage through BIB spiraling is increased measurement error in the scores available for each student. This is accommodated through the estimation of five plausible values for each student rather than a single unreliable point estimate. Plausible values are random draws from the estimated distribution of a student's achievement. A detailed description of the TIMSS or TIMSS Advanced 2015 scaling can be found in Methods and Procedures in TIMSS 2015 (Martin, Mullis, and Hooper 2016a) and Methods and Procedures in TIMSS Advanced 2015 (Martin, Mullis, and Hooper 2016b). What this means for those analyses of TIMSS and TIMSS Advanced data that include achievement measures is that the analyses need to be done five times and the results averaged. For example, if one was regressing mathematics achievement on a number of family and school attributes, it would be necessary to estimate this equation five times and then average each set of five parameter estimates. It would not be legitimate to take the mean of the five plausible values in the first instance and then regress this mean on a number of family and school attributes."}, {"section_title": "Weighting", "text": "Responses from the groups of students were assigned sampling weights to adjust for the complex sample design that resulted in students having an unequal, but known, probability of selection. Additionally, an adjustment for school and student nonresponse was built into the weighting. The estimation of sampling weights was carried out by Statistics Canada. More detailed information can be found in the Methods and Procedures in TIMSS 2015 (Martin, Mullis, and Hooper 2016a) and Methods and Procedures in TIMSS Advanced 2015 (Martin, Mullis, and Hooper 2016b). In analyses of the TIMSS and TIMSS Advanced data, it is necessary to use sampling weights to obtain accurate population estimates."}, {"section_title": "Reporting TIMSS and TIMSS Advanced Results", "text": "Achievement results from TIMSS and TIMSS Advanced are reported on a scale from 0 to 1,000, with a scale average of 500 and standard deviation of 100. Even though the education systems participating in TIMSS and TIMSS Advanced have changed across the assessment rounds from the first administration (TIMSS and TIMSS Advanced in 1995), comparisons between the 2015 results and prior results are still possible because the achievement scores in each of the assessments are placed on a scale that is not dependent on the list of participating education systems in any particular year. In addition to numerical scale results, TIMSS and TIMSS Advanced also include international benchmarks. The international benchmarks provide a way to interpret the scale scores and to understand how students' proficiency in a subject varies at different points on the scales. Each successive point, or benchmark, is associated with the knowledge and skills that students successfully demonstrate at each level. TIMSS describes four benchmarks of achievement (Advanced, High, Intermediate, and Low) and TIMSS Advanced describes three benchmarks of achievement (Advanced, High, and Intermediate). A more detailed explanation of the assessment's equating, scaling, and benchmarks can be found in the Methods and Procedures in TIMSS 2015 at http://timssandpirls.bc.edu/publications/timss/2015methods.html and Methods and Procedures in TIMSS Advanced 2015 at http://timss.bc.edu/publications/timss/2015-a-methods.html."}, {"section_title": "U.S. International and National Data Files", "text": "Three versions of the U.S. national data are available as follows: \uf06e The TIMSS and TIMSS Advanced U.S. international data files that are available as part of the international database released by the International Study Center. The U.S.-specific TIMSS data files can be downloaded from http://timssandpirls.bc.edu/timss2015/international-database. The U.S.-specific TIMSS Advanced data files are available separately and can be downloaded from http://timssandpirls.bc.edu/timss2015/advanced-international-database. The TIMSS and TIMSS Advanced 2015 international data files are available in two versions: a public-use version and a restricted-use version. A number of variables are not included in the public-use version in order to minimize the risk of disclosing confidential information. These variables include information about students' year and month of birth, testing date, as well as school enrollment (see exhibit 5-1 in chapter 5 of this technical report for a complete list of variables removed from the international public-use data files). The restricted-use versions of the TIMSS and TIMSS Advanced 2015 international data files are available by request through the IEA Study Data Repository (http://www.iea.nl/data.html) to obtain permission and access to the restricted-use version of the TIMSS and TIMSS Advanced 2015 international data files. A description of the restricted variables removed from the public-use data files are presented in chapter 4 of the TIMSS 2015 User Guide for the International"}, {"section_title": "1-8", "text": "Database (Foy 2017a) and the TIMSS Advanced 2015 User Guide for the International Database (Foy 2017b). These data files conform to the international specifications common to the data files from all countries. However, they do not include the U.S.-specific adaptations made to a few questions in the questionnaires or the additional questions added to the school and student questionnaires, such as the question on race/ethnicity added to the student questionnaire. Data for Florida are not currently included in the international data files due to potential confidentiality issues. The Florida student file that meets confidentiality standards is expected to be released at a later date."}, {"section_title": "\uf06e", "text": "The TIMSS and TIMSS Advanced U.S. national public-use data files that are available through the National Center for Education Statistics. The TIMSS and TIMSS Advanced U.S. national dataset can be downloaded from http://nces.ed.gov/timss/datafiles.asp. These U.S. data files include the U.S.-specific adaptations made to questionnaire items and additional questions added to the school and student questionnaires. The TIMSS and TIMSS Advanced U.S. national publicuse data files also include the international restricted variables listed in exhibit 5-1 of chapter 5.\nThe TIMSS and TIMSS Advanced U.S. national restricted-use data files that are available through the National Center for Education Statistics. Access to these microdata files may be obtained by completing a restricted-use license agreement with NCES. The restricted-use data files are provided only on CD-ROM or DVD-ROM. These data files contain supplemental link files that link TIMSS or TIMSS Advanced school ID numbers to the school ID numbers as they appear in the publicly available Common Core of Data (CCD) or the Private School Universe Survey (PSS). In addition, race/ethnicity is provided with all available categories and free or reducedprice lunch is provided as a continuous variable. Because these data can reveal the identities of participating schools, the restricted-use data files are only made available to those who obtain a NCES restricted-use data license. Directions on how to obtain the license can be found at http://nces.ed.gov/pubsearch/licenses.asp. In addition to the TIMSS Advanced 2015 data files, a set of the TIMSS Advanced 1995 school and student data files are provided in public-use and restricted-use data formats for trend analysis purposes. Additional information about the TIMSS Advanced 1995 U.S. public-and restricted files is described in chapter 5. Researchers do not need to process the TIMSS microdata (public-use or restricted-use) in order to access and analyze the data. The TIMSS data, including Florida and national variables (race/ethnicity, free lunch) can be analyzed using the NCES International Data Explorer (IDE). The IDE provides for U.S. trend analysis as well as comparisons with all participating TIMSS countries. The IDE generates userdefined reports that include options for tables, gap analysis, regression analysis, and significance testing. The IDE can be accessed at http://nces.ed.gov/surveys/international/ide/. Data for Florida are available via Florida-specific, restricted-use data files. Access to these files may be obtained by completing a restricted-use license agreement with NCES. These restricted-use data files are provided only on CD-ROM or DVD-ROM. The Florida-specific, restricted-use data files contain all of the variables in the public released national data files plus the supplemental link files that link TIMSS school ID numbers to the school ID numbers as they appear in the publicly available Common Core of Data (CCD). Because these data can reveal the identities of participating schools, the restricted-use data files are only made available to those who obtain a NCES restricted-use data license. Directions on how to obtain the license can be found at http://nces.ed.gov/pubsearch/licenses.asp. The most comprehensive explanation of the TIMSS and TIMSS Advanced international data, and hence of the U.S. international data file, is provided in the various TIMSS and TIMSS Advanced 2015 publications produced by the International Association for the Evaluation of Educational Achievement (IEA), particularly the TIMSS 2015 User Guide for the International Database (Foy 2017a) and the TIMSS 2015 Advanced User Guide for the International Database (Foy 2017b). These publications provide detailed descriptions of the content and format of the data in the TIMSS and TIMSS Advanced 2015 international data files and should be seen as the primary reference. The U. S. TIMSS 2015and TIMSS Advanced 1995 Guide draws heavily on the international user's guide for much of its data file-related content. This content is supplemented with detail on those aspects of the TIMSS and TIMSS Advanced data that were unique to the United States. TIMSS fourth-and eighth-grade Florida samples. The samples are described in sections 2.1.1-2.1.3.\nSENWGT is a transformation of TOTWGT that results in a weighted student sample size of 500 in each education system. This weight may be appropriate for \"crosscountry\" analyses that require each education system to have the same number of students, rather than proportionately more students from larger education systems and fewer from smaller education systems, which is the case if TOTWGT is used.\nHOUWGT, another transformation of TOTWGT, ensures that the weighted sample corresponds to the actual sample size in each education system. This weight can be important since TOTWGT inflates sample sizes to approximate the population size, and software systems that use the actual sample size to compute significance tests would give misleading results under these conditions.\nMinor language adaptations were made to the wording of some assessment items. 15 In addition to the ITSEX variable that indicates student gender, the TIMSS and TIMSS Advanced data files also include student-reported gender variable (i.e., ASBG01 for TIMSS grade 4; BSBG01 for TIMSS grade 8; for TIMSS Advanced, MSBG01 for Advanced Mathematics and PSBG01 for Physics) collected from the student questionnaire.\nSeveral U.S.-specific variables without international counterparts were added to the student and school questionnaires. Otherwise, the U.S. instrumentation is the same as the international instrumentation. "}, {"section_title": "U.S. TIMSS Fourth-and Eighth-Grade National Samples", "text": "The sample design for the fourth-and eighth-grade school samples was developed to retain most of the properties of the previous TIMSS U.S. school samples, and to follow international requirements as given in Chapter 3 of Methods and Procedures in TIMSS 2015 (Martin, Mullis, and Hooper 2016a). Like the 2011 TIMSS sample, the U.S. sample followed a two-stage sampling process with the first stage a sample of schools, and the second stage a sample of classrooms within schools. All students in sampled classrooms were selected for assessment. There was no oversampling for either grade in 2015. The overlap with the 2015 National Assessment of Educational Progress (NAEP) school samples was minimized for the 2015 TIMSS. The TIMSS samples were selected before the NAEP samples due to TIMSS scheduling constraints. Thus the overlap between the samples was minimized when the 2015 NAEP samples were selected. The student population for the fourth grade 2015 TIMSS is the set of all fourth-graders in the United States in both public and private schools. The TIMSS school sample consists of 300 schools containing a fourth-grade class. The schools were selected with probability proportionate to the school's estimated grade enrollment of fourth-graders from the 2015 NAEP school frame. A total of two fourth-grade mathematics classes were selected within each school in an equal probability sample (unless there were only one or two classes, in which case all fourth-grade classes were taken with certainty). The overall sample design was intended to approximate a self-weighting sample of students as much as possible in accordance with the international guidelines, with each fourth-grade student in the United States having an equal probability of being selected. The student population for the eighth-grade 2015 TIMSS is the set of all eighth-graders in the United States in both public and private schools. The TIMSS school sample consists of 300 schools containing an eighth-grade class. The schools were selected with probability proportionate to the school's estimated grade enrollment of eighth-graders from the 2015 NAEP school frame. A total of two eighth-grade mathematics classes were selected within each school in an equal probability sample (unless there were only one or two classes, in which all eighth-grade classes were taken with certainty). The overall sample design was intended to approximate a self-weighting sample of students as much as possible in accordance with the international guidelines, with each eighth-grade student in the U.S. having an equal probability of being selected. "}, {"section_title": "U.S. TIMSS Advanced National Sample", "text": "The International Association for the Evaluation of Educational Achievement (IEA) overall design for the 2015 TIMSS Advanced replicates the TIMSS 2008 Advanced study, in which the United States did not participate. However, the U.S. sample followed a two-stage sampling process with the first stage a sample of schools, and the second stage a sample of advanced students within schools rather than classrooms. The overlap with the 2015 NAEP grade 12 school sample was minimized for the 2015 TIMSS Advanced. The NAEP grade 12 sample was selected before the TIMSS Advanced sample. Thus the overlap between the samples was minimized when the TIMSS sample was selected. A single TIMSS school sample consisting of 348 schools containing at least one twelfth-grade class was selected for both subjects (advanced mathematics and physics). The schools were selected with probability proportionate to the school's estimated grade enrollment of twelfth-graders from the 2015 NAEP school frame. Within each sampled school, separate student samples were selected for advanced mathematics and physics in systematic equal probability samples. The student sampling algorithm was designed to meet international guidelines with a target of 4,000 in advanced mathematics and physics for a total of 8,000 sampled advanced students."}, {"section_title": "TIMSS Florida Samples", "text": "A TIMSS public school state sample was drawn for Florida at both fourth and eighth grade. The 2015 TIMSS state sample replicated the national sample design whenever possible. The school frame to draw the Florida state samples was identical to the national frame of public schools in Florida. The overlap with the TIMSS national and 2015 NAEP school samples was minimized for the 2015 Florida samples at both fourth and eighth grade. The Florida state school sample consists of 54 schools at both grades four and eight containing a fourth-and eighth-grade class, respectively. The rest of this chapter describes the school samples. Section 2.2 describes the sampling frame-the data sources, data preparation, and the stratification variables. Section 2.3 describes the stratification. Section 2.4 describes the national school sample selection-the measure of size, substitute schools, and selecting classrooms and students. Section 2.5 provides tabulations within subgroups for the frame and sample. Section 2.6 describes the state school sample selection. The data collection methods are covered in a chapter 4."}, {"section_title": "School Sampling Frames", "text": "The U.S. school sampling frames for fourth, eighth, and twelfth grades were developed from two national databases in the National Center for Education Statistics-public schools in the Common Core of Data (CCD-http://nces.ed.gov/ccd/) and private schools in the Private School Survey (PSShttp://nces.ed.gov/surveys/pss/). These sources provide full coverage of all fourth-, eighth-and twelfthgrade students in the education system in the United States. The TIMSS school frames were constructed using the 2012-13 CCD and the 2011-12 PSS, the most current data at the time of the frame construction. The data preparation of the school frames benefited from procedures developed for the National Assessment of Educational Progress (NAEP), a large educational survey in the United States. The school frames used the NAEP 2015 school frame as an input data source."}, {"section_title": "U.S. TIMSS 2015 and TIMSS Advanced 1995 & 2015 Technical Report and User's Guide", "text": "\n\nThis page intentionally blank. 3-1\n3-7\nThis page intentionally blank. 4-1\n\n\nYour school has been randomly selected to participate in TIMSS in spring 2015. Your school will receive a confidential report with information about how your students performed on TIMSS 2015's released items (i.e., questions made public after the assessment). Information about how students performed across the United States and in other participating countries on those same released items will be made public, and you can compare your students' performance on the released items against those national and international results. Participating schools will receive $200, and each school's TIMSS school coordinator (the school staff person designated to work with TIMSS representatives) will receive $100 as a thank you for his or her time and effort. Participating students will receive a small gift as a token of appreciation. TIMSS is described in more detail in the enclosed materials. In the United States, TIMSS is sponsored by the National Center for Education Statistics (NCES), part of the U.S. Department of Education, and is conducted by Westat, a research organization based in Rockville, Maryland. The U.S. Office of Management and Budget has approved the data collection under OMB #1850-0695. For information on the confidentiality of the data collected, please see the enclosed FAQ. I hope you will participate in this voluntary study because it is important that the United States has a nationally representative sample of schools. For now, I am writing only to notify you of the assessment. The assessment window is March 30-May 29, 2015. In June, I will send you an assessment date. Should there be a conflict on that date, a TIMSS representative will work with you to identify an alternate. Our goal is to schedule the assessment date prior to the beginning of the school year so that you may include it on your 2014-2015 school calendar. At the beginning of the school year, I will send you detailed information about the assessment and will ask you to identify a school coordinator. TIMSS representatives will provide significant support to schools, bring all necessary materials, and administer the assessment. If you have any questions, please do not hesitate to contact me, or the toll-free TIMSS information hotline at 855-445-5604 or TIMSS@westat.com. You may also get more information about this study by contacting Dr. Stephen Provasnik at NCES at 202-502-7480 or stephen.provasnik@ed.gov, or by visiting the TIMSS website at http://nces.ed.gov/timss/. Your participation in the TIMSS 2015 is very important to its success. Our chief state school officer, (name), and your district superintendent, (name), support TIMSS and look forward to your school's participation. Thank you for your time and for supporting this important international study.  \u00a7 9543. By law, the data provided by your school, staff, and students may only be used for statistical  purposes and may not be disclosed, or used, in identifiable form for any other purpose except as required by law  (20 U.S. Code,  \u00a7 9573) I am writing to inform you that (school name) has been select to represent schools across the United States by participating in an important international study in 2015: the Trends in International Mathematics and Science Study (TIMSS). TIMSS is the longest ongoing international assessment of student achievement in mathematics and science. Since 1995, TIMSS has measured trends in academic achievement at grades 4 and 8 in countries around the world, including the United States. In 2015, TIMSS will also assess advanced mathematics and physics at grade 12. Known as TIMSS Advanced, this 12th-grade assessment will provide education policymakers with valuable information about how many high school students are excelling at highly specialized science, technology, engineering, and mathematics (STEM) content in a global context. Results from these assessments are used by researchers and policymakers to chart national progress against international standards and other countries around the world, informing national discussions about international competitiveness. Your school has been randomly selected to participate in TIMSS Advanced in spring 2015. Your school will receive a confidential report with information about how your students performed on TIMSS 2015's released items (i.e., questions made public after the assessment). Information about how students performed across the United States and in other participating countries on those same released items will be made public, and you can compare your students' performance on the released items against those national and international results (provided your school meets response rate and sample size requirements). Participating schools will receive $200, and each school's TIMSS school coordinator (the school staff person designated to work with TIMSS representatives) will receive $100 as a thank you for his or her time and effort. Participating students will receive a small gift as a token of appreciation. TIMSS Advanced is described in more detail in the enclosed materials. TIMSS Advanced is sponsored in the United States by the National Center for Education Statistics (NCES) in the U.S. Department of Education and is conducted by Westat, a research organization based in Rockville, Maryland. The U.S. Office of Management and Budget has approved the data collection under OMB #1850-0695. For information on the confidentiality of the data collected, please see the enclosed FAQ. I hope you will participate in this voluntary study because it is important that the United States has a nationally representative sample of schools. For now, I am writing only to notify you of the assessment. The assessment window is March 30-May 29, 2015. In June, I will send you an assessment date. Should there be a conflict on that date, a TIMSS representative will work with you to identify an alternate. Our goal is to schedule the assessment date prior to the beginning of the school year so that you may include it on your 2014-2015 school calendar. At the beginning of the school year, I will send you detailed information about the assessment and will ask you to identify a school coordinator. TIMSS representatives will provide significant support to schools, bring all necessary materials, and administer the assessment. If you have any questions, please do not hesitate to contact me, or the toll-free TIMSS information hotline at 855-445-5604 or TIMSS@westat.com. You may also get more information about this study by contacting Dr. Stephen Provasnik at NCES at 202-502-7480 or stephen.provasnik@ed.gov, or by visiting the TIMSS website at http://nces.ed.gov/timss/. Your participation in the TIMSS 2015 Advanced is very important to its success. Our chief state school officer, (name), and your district superintendent, (name), support TIMSS and look forward to your school's participation. Thank you for your time and for supporting this important international study of preparedness for STEM careers.  \u00a7 9543. By law, the data provided by your school, staff, and students may only be used for statistical  purposes and may not be disclosed, or used, in identifiable form for any other purpose except as required by law  (20 U.S. Code,  \u00a7 9573).\n\nA-10 A-5. TIMSS 2015 Parent Notification Letter: Grade 4\nWhere can I find out more about TIMSS? More information about TIMSS is available at the TIMSS website at http://nces.ed.gov/timss or http://timss.bc.edu. If you would like to contact a TIMSS staff member directly, please feel free to call the TIMSS hotline at 855-445-5604 or email us at TIMSS@westat.com. Between March and May 2015, your teenager's school will be one of several hundred schools nationwide taking part in a special component of the Trends in International Mathematics and Science Study (TIMSS), called TIMSS Advanced. The schools were selected randomly to represent the nation's schools that offer courses in advanced mathematics and physics. Within each school, twelfth-grade students were selected randomly to represent the nation's twelfth-graders who have taken or are taking advanced mathematics, such as calculus, or advanced physics. Your teenager was among those students selected to take part in TIMSS Advanced."}, {"section_title": "2-3", "text": "Eligible schools in the school frames included schools operating in the 50 states and the District of Columbia, Department of Defense (DoD) domestic schools, and Bureau of Indian Education (BIE) schools. Schools in Puerto Rico and U.S. territories, DoD schools overseas, adult education institutions with no fourth-, eighth-or twelfth-grade students, and non-education institutions (e.g., home schools and correspondence schools) were ineligible for the study."}, {"section_title": "Fourth-Grade Frame", "text": "Any school having a fourth grade was included on the TIMSS fourth-grade school sampling frame. Table  2-1 presents frame tabulations of the number of schools by the school grade span (lowest to highest grade level of the school). "}, {"section_title": "Eighth-Grade Frame", "text": "Any school having an eighth grade was included on the TIMSS eighth-grade school sampling frame. Table 2-2 presents frame tabulations of the number of schools by the school grade span (lowest to highest grade level of the school). "}, {"section_title": "Advanced Frame", "text": "Any school having a twelfth grade was included on the TIMSS Advanced school sampling frame. Table  2-3 presents frame tabulations of the number of schools by the school grade span (lowest to highest grade level of the school). To supplement the twelfth-grade frame data, NCES worked with the College Board to provide a file with data on schools that offered advanced placement (AP) courses in 2013. The College Board data supplemented the frame data with school information on students who took AP exams. The College Board file included school information such as the NCES School ID and school name and address that was used in matching to the school frame. The data on the College Board file included frequencies of students taking AP exams in calculus, physics, and both calculus and physics. The 2013 College Board file was merged to the twelfth-grade frame first by NCES ID and then by school name and address when possible. Approximately 97 percent of over 13,100 schools listed on the College Board file were matched to the frame. The matched schools constituted almost 40 percent of the over 33,000 schools on the frame. The schools that matched to the College Board file will hereinafter be called \"AP schools\" and the nonmatches \"non-AP schools.\" Counts of eligible advanced mathematics and physics students were needed to estimate the number of advanced students that would be sampled to ensure the U.S. design met the international target sample sizes of advanced mathematics and physics students. However, only grade enrollment data were available by school on the school frame, not information on courses that students were students enrolled in. Because these actual counts of advanced mathematics and physics students were not available on the school frame, estimates of eligible student counts were computed with the available information. Besides the AP frequencies from the College Board, the only information available was the percentage of graduates who earned credit in calculus and/or physics according to the 2009 High School Transcript Study (HSTS). In non-AP schools, estimates of students in calculus and/or physics were calculated by multiplying the grade 12 enrollment by the total percentage of graduates who earned credit in calculus and/or physics according to the HSTS shown in table 2-4. For example, if the grade 12 enrollment in a school was 100, then an estimated 16.8 and 4.6 percent of students earned credit in calculus and physics, respectively. In AP schools, the frequencies of students taking AP exams in calculus, physics, and both calculus and physics were adjusted based on the HSTS percentages. This was done within each school by adjusting the AP counts in calculus, physics, and both calculus and physics by the comparable ratio of total percentage of advanced to AP students. For example, the number of advanced mathematics students in a school was estimated by multiplying the AP calculus count in the school (from the College Board) by a ratio of 16.8/11.3 (i.e., the ratio of the total percentage of calculus graduates to the percentage of AP calculus graduates from table 2.4). The estimated average frame counts of eligible students using the algorithm described above are shown in table 2-5 by enrollment and College Board file match status. Even though less than 40 percent of the schools on the frame were AP schools, the vast majority of the grade 12 and advanced students were from the AP schools as the AP schools were on average much larger. For example, the average number of advanced mathematics students in all schools was 19.9, but in AP schools it was 39.5. "}, {"section_title": "Stratification", "text": "The sample design was a stratified systematic sample within each stratum, with sampling probabilities proportional to size (PPS). Stratification was used for sample efficiency and consistency with previous designs. For grades 4 and 8, twelve explicit strata were formed by the following variables, shown in alphabetical order: \uf06e census region-Northeast, Midwest, South, and West; \uf06e poverty level 3 -for public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the free or reduced-price lunch program (FRPL), 4 and \"low\" poverty is defined as having less than 50 percent eligible; and \uf06e school type-school is either under public control (operated by publicly elected or appointed officials) or private control (operated by privately elected or appointed officials and derives its major source of funds from private sources). For the Advanced sample, nine explicit strata 5 were formed by the following variables shown in alphabetical order: \uf06e AP status-indicates whether or not the school had students who took a calculus, physics, or both calculus and physics AP test in 2013; \uf06e census region-Northeast, Midwest, South and West; and \uf06e School type-school is either under public control (operated by publicly elected or appointed officials) or private control (operated by privately elected or appointed officials and derives its major source of funds from private sources). Within each stratum for all three samples, the frame was implicitly stratified by the following three categorical stratification variables: \uf06e locale-urban-centric locale code (i.e., city, suburb, town, rural); \uf06e race/ethnicity status-student population in the school is \"15 percent or above\" or \"below 15 percent\" Black, Hispanic, Asian, Hawaiian/Pacific Islander, American Indian and Alaska Native students, and multiracial students; 6 and \uf06e estimated grade enrollment."}, {"section_title": "Fourth-Grade Stratification", "text": "The following tables show the total number and percentage of fourth-grade students and schools in the TIMSS 2015 school frame by census region (table 2-6), poverty level (table 2-7), school type (table 2-8),  locale (table 2-9), race/ethnicity status (table 2-10), and by poverty level, school type, and region (table 2-11).  NOTE: For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the free or reducedprice lunch program (FRPL), and \"low\" poverty is defined as having less than 50 percent eligible. Because no FRPL data were available for private schools, all private schools are categorized as \"low.\" SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2015.    "}, {"section_title": "Eighth-Grade Stratification", "text": "The following tables show the total number and percentage of eighth grade students and schools in the TIMSS 2015 eighth-grade school frame by census region (table 2-12), poverty level (table 2-13), school  type (table 2-14), locale (table 2-15), race/ethnicity status (table 2-16), and by poverty level, school type, and region (table 2-17).  NOTE: For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the free or reducedprice lunch program (FRPL), and \"low\" poverty is defined as having less than 50 percent eligible. Because no FRPL data were available for private schools, all private schools are categorized as \"low.\" SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2015.    NOTE: Detail may not sum to totals because of rounding. Region of country is based on Census Bureau definitions. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the free or reduced-price lunch program (FRPL), and \"low\" poverty is defined as having less than 50 percent eligible. Because no FRPL data were available for private schools, all private schools are categorized as \"low. "}, {"section_title": "Advanced Stratification", "text": "The following tables show the total number and percentage of twelfth-grade students and schools in the TIMSS 2015 Advanced school frame by AP status level (table 2-18), census region (table 2-19), school  type (table 2-20), locale (table 2-21), race/ethnicity status (table 2-22), and by AP status, region, and school type (table 2-23).       "}, {"section_title": "National School Samples", "text": ""}, {"section_title": "Measure of Size", "text": "The goal for the TIMSS sample was to attain a self-weighting student sample. To achieve this, schools' probability of selection was related to their measure of size (MOS), which is proportional to its share of the target population, that is, the fourth-, eighth-, or twelfth-grade enrollments. This method also reduces the chance of selection for smaller schools. This improves cost efficiency by increasing the number of students per school. However, students in schools with enrollments of only a few students would have very large weights if selected. To minimize the impact of these small schools on variances and estimates, the minimum measure of size was set to 5. The following is a summary of the steps for assigning measures of size to the schools on the TIMSS frames. Determine the estimated target population size for the school. This is the estimated enrollment per grade (4, 8, or 12) from the school frame. If the grade enrollment was not available, it was calculated by dividing the school's total enrollment by the number of grades in the school. The measure of size according to the estimated enrollment per grade is 5 if the grade enrollment is less than or equal to 5, and is equal to the grade enrollment (grade 4, grade 8, or grade 12) otherwise."}, {"section_title": "Fourth-and Eighth-Grade Samples", "text": "The U.S. national fourth-and eighth samples used a two-stage design-a stratified systematic sample of schools with sampling probabilities proportional to size (PPS) and then classes within sampled schools. The school selection probability was configured such that all fourth-or eighth-grade students in the United States would have approximately equal probability of being selected in the samples. Note that in large schools, a smaller proportion of the classes (and therefore of the students) is selected, but this lower rate of selecting students in large schools is offset by a larger probability of selection of large schools, as schools are selected with probability proportional to size. A sample of 300 schools was drawn from the fourth-and eighth grade frames. A systematic sample was selected independently in each stratum where the measure of size is the estimated number of students in fourth or eighth grade."}, {"section_title": "2-14", "text": "Within each explicit stratum, the frames were implicitly stratified by two categorical stratification variables. The order of the stratification is not given because of confidentiality concerns. Each frame was sorted in alternating (serpentine) sort order according to these school characteristics, implicitly stratifying the frame. The last sort within the implicit stratification was by grade enrollment (measure of size or MOS) in descending order. Alternating the \"sort order\" sorts a frame from lowest to highest value with respect to the first sort variable, then within each level of the first sort variable, the second sort variable alternates its sort order, from lowest to highest for the first level of the first sort variable, then from highest to lowest for the second level of the first sort variable, then again from lowest to highest for the third level of the first sort variable, and so on. Each of the variables will alternate the sort order within each level of the preceding sort variable. This means that schools adjacent on the list are not substantially different or at most different by one sorting characteristic."}, {"section_title": "Advanced Sample", "text": "The target population for advanced mathematics was \"students in the final year of secondary schooling who have taken courses in advanced mathematics.\" The target population for physics was \"students in the final year of secondary schooling who have taken courses in physics.\" The courses that define the target populations have to cover most, if not all, of the advanced mathematics and physics topics that were outlined in the TIMSS Advanced 2015 Assessment Frameworks. The IEA TIMSS Advanced framework specifies, at the highest level, that the target population includes students who have taken courses that contain the following content, respectively: In some countries the target populations are 100 percent overlapping, and in others, like the United States, they are overlapping to a variable degree. Defining the target population in the United States is more challenging than in most countries. The United States does not have a common curriculum across the country and students do not follow a uniform course-taking sequence. Therefore, students may have taken these courses prior to their senior year, and many different courses may meet the framework criteria. Complicating things further, the school lists that form the sampling frames are obtained from the NCES CCD (public school) and PSS (private school) files, neither of which includes courses offered in the schools. Also, students may take these courses in their high schools, or in colleges/universities, or virtually. For the purpose of this study, eligibility for advanced mathematics was defined as have taken or were taking a calculus course, and for physics as have taken or were taking an advanced physics course similar to AP physics. In order to quantify the proportion of the school-leaving age cohort taking advanced mathematics and physics courses, TIMSS Advanced computed a TIMSS Advanced Mathematics Coverage Index (TAMCI) and a TIMSS Advanced Physics Coverage Index (TAPCI) for each participating country. In part, these indices reflect the overall sampling coverage of the respective populations in each country; but, more importantly, they show that only a very select group of final-year students were considered eligible for TIMSS Advanced 2015, and that the percentages of these students varied across countries. The TIMSS Advanced coverage indices for advanced mathematics and physics were defined as follows: TAMCI = Estimated total number of students in the advanced mathematics population Total national population in the corresponding age cohort \u00d7 100% TAPCI = Estimated total number of students in the advanced physics population Total national population in the corresponding age cohort \u00d7 100% The numerator in each index is the total number of students eligible for TIMSS Advanced 2015, either for advanced mathematics or physics, as estimated from the weighted samples. The denominator is an estimate of the size of the eligible age cohort in 2015 corresponding to the mean age of the target population. The final-year age cohort for each country was defined to be the age corresponding to its average age at the time of testing, as estimated from the weighted samples, and its size was estimated from national census figures. The estimated target populations were estimated from the weighted samples. The TIMSS Advanced coverage indices for advanced mathematics and physics for the U.S. were 11.4 and 4.8 percent, respectively. The overlap with the 2015 NAEP school sample was minimized for the 2015 TIMSS Advanced. The NAEP grade 12 sample was selected before the TIMSS Advanced sample, and therefore the overlap between the samples was minimized when the TIMSS sample was selected. The Advanced sample was selected using a version of the Keyfitz procedure (Keyfitz 1951); Chowdhury, Chu, and Kaufman (2000) have described the implementation of the procedure. The method is used to minimize overlap between one or more surveys. By minimizing the overlap with the NAEP sample, the assessed students could be included in only one study with proper probabilities. This was accomplished by partitioning the frame into the following two groups shown in order as in table 2 of the paper. The two groups were as follows: 1. Schools not selected for the NAEP sample; and 2. Schools selected for the NAEP sample. With this design, the method accomplished the goal of selecting the entire state samples from group 1 and none from group 2. For the schools in group 2, this was due to the sum of the school's probabilities of being selected for the state sample and the national sample was always less than one. In that case, their conditional probabilities are zero. Unlike the fourth and eighth grade designs, there was oversampling for the Advanced sample in 2015 by oversampling AP schools in order to increase the overall yield of advanced students. The oversampling rate was set so that non-AP schools were undersampled at half the rate of the AP schools that effectively oversampled the AP schools. Oversampling the AP schools increased the student sample yield by sampling more schools with a larger enrollment of eligible students, and undersampling the non-AP schools lessened the number of sampled schools that likely contained no eligible students. The oversampling was set at this rate and not at a higher rate due to the increase in design effect of the unequal weights. Despite the fact that not all of the non-AP schools had any eligible students, they still needed to be given a chance of selection as it was not possible to identify those schools definitively on the frame. Excluding those schools would not meet the international sampling guidelines. The Advanced sample used a two-stage design-a stratified systematic sample of schools with sampling probabilities proportional to size (PPS) and then students within sampled schools. A systematic sample was selected independently in each stratum with PPS sampling where the measure of size was the estimated number of students in twelfth grade. The TIMSS Advanced main study sample consisted of high schools with a target of 4,000 in advanced mathematics and physics for a total of 8,000 sampled students and a goal of 3,600 assessed students per subject. A sample of 350 schools was targeted in an effort to ensure 300 eligible and participating schools where school eligibility was determined by offering at least one of the eligible courses for advanced mathematics and physics. A sample of 348 were sampled which varied slightly from the target due to the overlap control. Undersampling the non-AP schools by a factor of one-half resulted in 304 and 44 AP and non-AP sample schools, respectively. Course catalogues were obtained from all participating schools, and their calculus and advanced physics courses were coded to determine eligible schools. Mathematics and science department chairs were also asked to identify eligible courses from their catalogues."}, {"section_title": "Substitute Schools", "text": "Although efforts were made to secure the participation of all schools selected, it was anticipated at the time of sampling that not all schools would choose to participate. Therefore, as each school was selected for a sample, the two neighboring schools in the sampling frame were designated as substitute schools. The first school following the sample school was the first substitute, and the first school preceding it was the second substitute. If an original school refused to participate, the first substitute was then contacted. If that school also refused to participate, the second substitute was then contacted. There were several constraints on the assignment of substitutes. One sampled school was not allowed to be a substitute for another, and a given school could not be assigned to be a substitute for more than one sampled school. Furthermore, substitutes were required to be in the explicit stratum as the sampled school. If the sampled school was the first or last school in the stratum, then the second school following or preceding the sampled school was identified as the substitute. If the first substitute school did not have the same implicit stratification values as the sampled school, the first and second substitute were switched. With international consent, the substitute school assignment also avoided the NAEP sample schools whenever possible within the above rules. Under these rules, it was possible to identify two substitutes for each sampled school."}, {"section_title": "Selecting Classrooms-Grades 4 and 8", "text": "The final stage of selection for grades 4 and 8 was of classrooms within schools. Within each sampled school that agreed to participate in TIMSS at fourth or eighth grade, all classrooms in the school were listed on the classroom sampling frame. Classroom lists were gathered from participating schools electronically using an adaptation of a secure E-Filing process. E-Filing was successfully used in the Program for International Student Assessment (PISA) 2012, and provides advantageous features such as efficiency and data quality checks. Schools accessed the E-Filing system through the MyTIMSS.com website. Once the list of classrooms was received from a school, it was formatted for importing into WinW3S, the international sampling and data management software. Schools were asked to indicate the names of all classes containing fourth-or eighth-grade students, the number of fourth-or eighth-grade students in the class, and whether it was a \"special class\" in which all or most of the students were learning disabled or classified as having limited English proficiency. Even though TIMSS does provide accommodations, classrooms were excluded from the subsequent classroom sampling if all or most of the students were learning disabled. Classrooms with fewer than 15 students were collapsed into pseudoclassrooms so that each classroom on the school's classroom sampling frame had at least 20 students. 7 An equal probability sample of two classrooms or pseudoclassrooms was sampled from the classroom frame for each school. All students in sampled classrooms (pseudoclassrooms) were selected for assessment."}, {"section_title": "Selecting Students-Advanced", "text": "The second stage of selection for the TIMSS Advanced sample was of students within schools. Within each sampled school that agreed to participate in TIMSS Advanced, all eligible advanced mathematics and physics students in the school were listed on the student sampling frame. Similarly to the method described for grades 4 and 8, student lists were gathered from participating schools electronically using an adaptation of a secure E-Filing process. However, once the list of students was received from a school, it was not imported into WinW3S software, which only sampled classrooms. The student sampling was designed to meet international guidelines described earlier. The students were sampled within each school using the following algorithm: 1. Select all students eligible for both advanced mathematics and physics, up to a total of 40. Otherwise take a sample of size 40."}, {"section_title": "2.", "text": "Assign one-fifth of the doubly eligible students to the mathematics assessment and the rest to physics.\nStudent disability status (SD). Information for this variable is derived from student lists submitted by the school coordinators of participating schools. This variable is in the restricted-use student files.\nOmitted or invalid. The respondent had a chance to answer the question but did not do so. This code also was used for responses that were not interpretable.\nA variable named COMPARISON that flags students in the 1995 sample who can be compared with the 2015 sample (for details, see below under section 5.13.7, Special Considerations in Comparing the TIMSS Advanced 1995 and 2015 Student Data)."}, {"section_title": "3.", "text": "Select all students eligible for physics only, up to a total of 20. Otherwise take a sample of size 20.\nLogically not applicable. The respondent answered a preceding filter question in a way that made the following dependent questions not applicable to him or her."}, {"section_title": "4.", "text": "Select one-quarter of the mathematics-only students, subject to a maximum of 40 and a minimum of 10 (or all students if there are fewer than 10). Based on data from 2009 HSTS (see Table 2-4), on average in a school with 500 grade 12 students the expected eligibility was as follows: A. 3.4 percent of graduates earned credit in both calculus and advanced physics. Therefore, 17 students are eligible for both mathematics and physics. All would be sampled, and 3 or 4 assigned to mathematics and 13 or 14 to physics.\nNot reached (only used in the achievement files). This code indicates those items not reached by the students due to a lack of time. SAS and SPSS control code for all the data files include the code for handling/converting missing data. The control code files are programs that contain data definition statements used by SAS and SPSS statistical software to generate data files from flat data files in .dat format. They provide list of statements that specify the name, type, decimal specification, and location for each variable in the data files. The control code files also provide statements that assign variables labels (i.e., variable descriptions), missing values, and value labels based on category descriptions."}, {"section_title": "2-18", "text": "B. 4.6 percent of graduates earned credit in advanced physics, but 3.4 percent earned credit in calculus as well. Therefore 1.2 percent (4.6-3.4) of graduates, or 6 students, are eligible for physics only. All would be sampled for physics."}, {"section_title": "C.", "text": "16.8 percent of graduates earned credit in calculus, but 3.4. percent earned credit in physics as well. There 13.4 percent (16.8-3.4) or 67 students are eligible for mathematics only. Either 16 or 17 would be sampled for mathematics. Therefore, 39 or 40 students from such a school would be sampled, with about equal numbers assessed in mathematics and physics. The maximum sample size in any school was 100 students. This would be in a very unusual school, that had at least 40 double specialists, at least 20 physics-only specialists (or 40), and at least 160 mathematics-only specialists; so there would be at least 220 specialists, when specialists are 18 percent of the total U.S. student population."}, {"section_title": "Tabulations Within Subgroups for Frame and Sample", "text": "This section provides an overview of the frame and sample for the explicit and implicit strata used in the sample process. The PPS sampling and stratification worked effectively: the sample percentage of schools is close to the measure-of-size (MOS) percentage of the frame for all the implicit strata. For these stratadefining subgroups, tables 2-24 through 2-41 present the following summary tabulations in these subgroups: \uf06e Total measure of size. This is the summation of MOSij over the subgroup. Note that this is larger than the national population student size because the minimum MOSij is set to 5 for small schools; and \uf06e Sample size. This is the final realized sample size of schools in the subgroup for the U.S. TIMSS fourth-or eighth-grade samples. 8 The measure of size (MOS) is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These are consistently larger than the estimated student sample size (reported in tables 2-1 through 2-14), which is the estimate of the number of students in the sampled schools and has no minimum per school.  NOTE: Measure of size is the estimated number of students enrolled in the target grade with a minimum of 5 students per school. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the free or reduced-price lunch program (FRPL), and \"low\" poverty is defined as having less than 50 percent eligible. Because no FRPL data were available for private schools, all private schools are categorized as \"low.            "}, {"section_title": "Fourth-Grade Tabulations", "text": ""}, {"section_title": "2-19", "text": ""}, {"section_title": "Advanced Tabulations", "text": "This section provides an overview of the advanced frame and sample distribution by each of the stratification variables.       "}, {"section_title": "State School Samples", "text": "The school frame used to draw the state samples was identical to the national frame of public schools in Florida. 9 The rest of the design was similar to the national design where possible. There were only two explicit strata per state (high/low poverty level), as the other national strata did not apply to state samples. As with the national samples, the frame was implicitly stratified by location, race/ethnicity enrollment, and estimated grade enrollment. Tables 2-42 and 2-43 show the number and percentage of students and schools included in the Florida TIMSS fourth-and eighth-grade school sampling frame and sample, respectively, by poverty level, locale, and race/ethnicity status. The MOS for each school was the same as in the national design. Substitute schools were assigned using the same procedure. The procedure for selecting classrooms was also the same as in the national design.    "}, {"section_title": "School Selection for the Florida State Samples", "text": "A TIMSS public school state sample was drawn for Florida at both fourth-and eighth-grade. Ideally, the objective for the Florida state samples was that they would not include the schools that were previously selected as part of the TIMSS national sample. The Florida state samples were selected using a version of the Keyfitz procedure (Keyfitz 1951); Chowdhury, Chu, and Kaufman (2000) have described the implementation of the procedure. By again following the Keyfitz procedure outlined in table 2 of Chowdhury, Chu, and Kaufman, the procedure allowed us to minimize the overlap with the TIMSS national and the NAEP state operational public school sample or \"Alpha sample\" 10 samples. By minimizing the overlap with the national sample, the assessed classrooms can be included in only one study with proper probabilities. This was accomplished by partitioning the frame into the following four groups shown in order as in With this design, the method accomplished the goal of selecting the entire state sample from group 1 and none from the other groups. For the schools in groups 3 and 4, this was due to the sum of the school's probabilities of being selected for the state sample and the national sample was always less than one. In that case, their conditional probabilities are zero. The Florida state school sample consists of 54 schools at both grades four and eight containing a fourth and eighth grade class, respectively."}, {"section_title": "PARTICIPATION RATES AND NONRESPONSE BIAS", "text": "To minimize the potential for response biases, IEA developed participation or response rate standards that apply to all participating education systems and govern whether or not data are included in the TIMSS and TIMSS Advanced 2015 international datasets and the way in which aggregate statistics are presented in the international reports. These standards were set using composites of participation rates at the school, classroom, and student levels, and were calculated both with and without the inclusion of substitute schools (for an explanation of substitute schools, see section 2.4.4) that were selected to replace schools refusing to participate. The standards take the following three forms, distinguished primarily by whether or not meeting the school participation rate of 85 percent requires the counting of substitute schools: Category 1: Met requirements. Participants that meet one of the following three sets of conditions are considered to have fulfilled the IEA requirements: (A) Obtain an unweighted school response rate of at least 85 percent without replacement (rounded to nearest whole percent) AND an unweighted student response rate (after rounding) of at least 85 percent; OR (B) A weighted school response rate of at least 85 percent without replacement (rounded to nearest whole percent) AND a weighted student response rate (after rounding) of at least 85 percent; OR (C) The product of the (unrounded) weighted school response rate without replacement and the (unrounded) weighted student response rate of at least 75 percent (after rounding to the nearest whole percent). Participants in this category appear in the tables and figures in international reports without annotation, and are ordered by achievement score. Category 2: Met requirements after substitutes. In the case of participants not meeting the category 1 requirements, but who had a weighted school response rate of at least 50 percent without replacement (after rounding to the nearest percent) AND HAD EITHER: (A) A weighted school response rate of at least 85 percent with replacement (after rounding to nearest whole percent) AND a weighted student response rate (after rounding) of at least 85 percent; OR (B) The product of the (unrounded) weighted school response rate with replacement and the (unrounded) weighted student response rate of at least 75 percent (after rounding to the nearest whole percent). Those participants able to satisfy only the category 2 standard are included in the tables and figures but are annotated to indicate their response rate status. Category 3: Unacceptable sampling response rate even when substitute schools are included. Participants that could provide documentation to show that they complied with TIMSS and TIMSS Advanced sampling procedures and requirements but did not meet the requirements for Category 1 or Category 2 were be placed in Category 3. Participants in this category appeared in a separate section of the achievement tables, below the other participants, in international reports. These countries were presented in alphabetical order."}, {"section_title": "TIMSS and TIMSS Advanced Participation Rates of U.S. Schools, Classrooms, and Students", "text": "The raw numbers on which the various participation rates are based, along with the participation rates themselves, are shown in    "}, {"section_title": "Interpreting School Participation Rates (TIMSS Fourth-Grade Example)", "text": "The fourth-grade school sample consisted of 300 schools and was designed to yield a representative school sample for TIMSS. Five ineligible schools were identified on the basis that they served special student populations or had closed or altered their grade makeup since the sampling frame was developed. This left 295 eligible schools, of which 228 agreed to participate. The fourth-grade school participation rate before substitution was 77 percent (unweighted). The analogous weighted school participation rate was also 77 percent. In addition to the 228 participating schools from the original sample, 22 substitute schools also participated for a total of 250 participating schools at the fourth grade in the United States. This gave a weighted (and unweighted) school participation rate after substitution of 85 percent."}, {"section_title": "Interpreting Classroom Participation Rates (TIMSS Fourth-Grade", "text": ""}, {"section_title": "Example)", "text": "In accord with the international requirements, schools agreeing to participate in TIMSS at grade 4 were asked to list their fourth-grade mathematics classes as the basis for sampling at the classroom level. Schools appeared to be able to identify classes in this way without any problems. A total of 1,118 mathematics classrooms were identified as a result. At this time, schools were given the opportunity to identify special classes-classes containing all, or a majority of, students with intellectual and/or functional disabilities, or students who were non-native-language speakers. While these classes were regarded as eligible, the students as a group were treated as excluded since, in the opinion of the school, their disabilities or language capabilities would render meaningless their performance on the assessment. A total of 33 classrooms were excluded in this way. This left a pool of 1,085 eligible classrooms from which the sample was drawn. While the students in these excluded classrooms did not figure in the participation rate calculations, they did count in the population coverage calculations, and this is reflected in the higher exclusion rate for the United States. In the international report the United States is annotated to reflect this fact. Classrooms with fewer than 15 students were collapsed into \"pseudoclassrooms\" prior to sampling so that each eligible classroom in a school had at least 20 students. Two classrooms (regardless of whether regular classrooms or pseudoclassrooms) were selected per school where possible. In schools where there was only one classroom, this classroom was selected with certainty. Some 488 classrooms were selected as a result of this process, and 487 participated in TIMSS. Weighted and unweighted classroom participation rates were 100 percent. Subsequently, schools were asked to list the students in each of the 488 sampled classrooms at the fourth grade, along with the teachers who taught mathematics and science to these students. At this time, schools were given the opportunity to identify particular students not suited to take the test because of functional and/or intellectual disabilities and/or because they were non-native-language speakers (students with disabilities or non-native-language speakers who had been mainstreamed; see definitions in section 3.3)."}, {"section_title": "Interpreting Student Participation Rates (TIMSS Fourth-Grade Example)", "text": "A total of 11,267 fourth-grade students were listed as being in these classrooms. (In mixed-grade classrooms only students in the target population were considered.) At the outset, 648 of these were excluded because of functional or intellectual disabilities or because they were non-native-languagespeakers. Additionally, in the months between the listing of students and the time of the assessment, 147 students were classified as withdrawn, as they were no longer in the school/classroom at the time of the assessment. As a consequence, 10,472 students were considered eligible to take the assessment. On the day of the assessment some 443 students were absent, leaving 10,029 students who completed a TIMSS 2015 assessment booklet. Participation rates were calculated on the number of eligible students (10,472). Since 10,029 of the 10,472 eligible students were assessed, the weighted (and unweighted) student participation rate was 96 percent."}, {"section_title": "Combined Participation Rates", "text": "The combined school, classroom, and student weighted participation rate standard of 75 percent used by TIMSS in situations in which it was necessary to recruit substitute schools was met for the grade 4 and 8 samples in TIMSS 2015. The weighted product of the separate participation rates for TIMSS at grade 4 was 81 percent (also unweighted) and at grade 8 was 79 (78 percent unweighted). The application of international guidelines means, however, that U.S. statistics describing fourth-and eighth-grade students in TIMSS are annotated in international reports to indicate that coverage of the defined student population was less than the IEA standard of 95 percent (see section 3.3.3 for details on coverage standards) and that participation rates were met only after substitute schools were included. The weighted product of the separate participation rates for TIMSS Advanced mathematics was 66 percent (also 66 percent unweighted) and physics was 58 percent (60 percent unweighted). The Florida grade 4 and 8 samples both met the participation requirements for category 1 above and are considered to have fulfilled the IEA requirements. The weighted and unweighted product of the separate participation rates for Florida grade 4 was 90 percent and grade 8 was 95 percent."}, {"section_title": "Participation Rates for All Countries", "text": "For comparable fourth-and eighth-grade school, classroom, and student participation rates in other nations in TIMSS, see exhibits C-3 through C-8 in TIMSS 2015 International Results in Mathematics (Mullis et al. 2016a) and in TIMSS 2015 International Results in Science (Martin et. al. 2016). For comparable participation rates in other nations in TIMSS Advanced, see exhibits C-3 through C-5 in appendix C in TIMSS Advanced 2015 International Results in Advanced Mathematics and Physics (Mullis et al. 2016b)."}, {"section_title": "Exclusions", "text": "The nationally defined target population is described in Chapter 3 of Methods and Procedures in TIMSS 2015 (Martin, Mullis, and Hooper 2016a) and Methods and Procedures in TIMSS Advanced 2015 (Martin, Mullis, and Hooper 2016b). All schools and students excluded from this population are referred to as the \"excluded population.\" Exclusions could occur at the school level, with entire schools being excluded, or within schools, with specific students or entire classrooms excluded."}, {"section_title": "School Exclusions", "text": "Countries could exclude schools that provided instruction only to students in the excluded categories defined under \"withinschool exclusions,\" such as schools for the blind."}, {"section_title": "Within-School Exclusions", "text": "Countries were asked to adapt the following international within-school exclusion rules to define excluded students: Students with intellectual disabilities. Students who, in the professional opinion of the school principal or other qualified staff members, were considered to be intellectually disabled or who had been tested psychologically as such. This included students who were emotionally or mentally unable to follow even the general instructions of the test. Students were not to be excluded solely because of poor academic performance or normal disciplinary problems. It should be noted that students with dyslexia, or other such learning disabilities, should be accommodated in the test situation if possible, rather than excluded. Students with functional disabilities. Students who were permanently physically disabled in such a way that they could not perform in the TIMSS or TIMSS Advanced testing situation. Functionally disabled students who were able to respond were included in the testing. Non-native-language speakers. Students who were unable to read or speak the language(s) of the test and were unable to overcome the language barrier of the test. Typically, a student who had received less than 1 year of instruction in the language(s) of the test was excluded."}, {"section_title": "Exclusions in the U.S. National Samples", "text": "As noted earlier, schools were given the opportunity to exclude any special classes among the total number of classes in the fourth or eighth grade. These classes were made up largely of students with functional or intellectual disabilities or students who were non-native-language speakers, as defined above. Classes identified in this way were excluded from the class sampling procedure. Subsequently, schools were given the opportunity to exclude students from the sampled classes-essentially, students with functional or intellectual disabilities, or non-native-language speaking students in the United States who had been mainstreamed. Nevertheless, students with disabilities and/or English language learners were allowed access to many accommodations that they received on their state assessments. These procedures resulted in a (weighted) student exclusion rate of 6.8 percent in the fourth grade for TIMSS, and 5.1 percent for TIMSS in the eighth grade based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (93 and 95 percent for TIMSS at fourth and eighth grade, respectively) as acceptable although falling below the desired range of 95 percent or better for the fourth grade. The tabulations shown in the international reports show the United States fourth grade annotated to indicate this fact. These procedures also resulted in a (weighted) student exclusion rate of 0.1 percent in the TIMSS Advanced mathematics and 0.1 percent in the TIMSS Advanced physics. IEA standards define this degree of coverage of the target populations as acceptable. Lastly, these procedures resulted in a (weighted) student exclusion rate of 4.7 percent in the fourth grade for Florida and 2.8 percent in the eighth grade for Florida. IEA standards define this degree of coverage of the target populations as acceptable."}, {"section_title": "Nonresponse Bias Analysis", "text": "The National Center for Education Statistics (NCES) standards for surveys stipulate that a nonresponse bias analysis is required at any stage of data collection with a weighted unit response rate of less than 85 percent (without substitution). Because the U.S. TIMSS 2015 weighted school response rates at grade 4, grade 8, Advanced mathematics, and Advanced physics are below 85 percent, NCES required an investigation into the potential magnitude of nonresponse bias at the school level in the U.S. samples, which is the focus of this section. The Florida samples did not require that a nonresponse bias analysis be performed because their weighted school and student participation rates were above 85 percent. A bias analysis was conducted in the United States to address potential problems in the data owing to school nonresponse for TIMSS grades 4 and 8 and for both subjects in TIMSS Advanced. The purpose of the analysis was to examine whether the participation status of schools was related to various characteristics and thus introduced the potential for bias in the results. The results suggested that there is some potential for nonresponse bias in the U.S. grades 4 and 8 samples (prior to substitution) based on the characteristics studied. It also suggested that, while there was some evidence that the use of substitute schools at grade 4 reduced the potential for bias, it did not reduce it substantially. At grade 8, the use of substitute schools did not reduce the potential for bias, nor did it add to it substantially. However, after the application of school nonresponse adjustments, there was no evidence of resulting potential bias in the final sample in either grade. Analyses of TIMSS Advanced suggest that there is little potential for nonresponse bias in the advanced mathematics sample based on the characteristics studied. It also suggests that, while there is some evidence that the use of substitute schools has not reduced the potential for bias, it has not added to it substantially. Moreover, after the application of school nonresponse adjustments, there is little evidence of resulting potential bias in the final sample. In physics, however, the results suggest that there is some potential for nonresponse bias in the sample based on the characteristics studied. It also suggests that, while there is some evidence that the use of substitute schools reduced the potential for bias, it has not reduced it substantially. Moreover, after the application of school nonresponse adjustments, there is some evidence of resulting potential bias in the final sample with the largest bias in the school-level characteristic locale. The full text of the nonresponse bias analysis conducted for TIMSS and TIMSS Advanced 2015 can be found in appendixes F and G, respectively."}, {"section_title": "SURVEY OPERATIONS", "text": "This chapter describes data collection and related activities for TIMSS and TIMSS Advanced 2015 in the United States. These activities included recruitment of schools for the national and Florida samples; sampling of students within schools; development of the instruments; field operations undertaken to administer the assessment; post-assessment activities associated with scoring and data entry; and several activities associated with the preparation of the data to meet international standards."}, {"section_title": "Recruiting Districts and Schools", "text": "The established protocol for seeking the participation of schools in studies such as TIMSS and TIMSS Advanced, where participation is voluntary, is to (1) notify state education authorities that they have districts and schools selected for the assessment, (2) inform authorities at the district level that schools within their districts are being sampled, and (3) contact the sampled schools. For public schools, steps 2and 3were conducted by NAEP State Coordinators in each state education agency. Participation may be refused at any of these levels, so several considerations were important in this context, specifically the need to establish the value of participation; establish the timing of the assessment window in conjunction with mandatory federal, state, and local assessments; and address concerns about the burden on schools. Private schools, including nonreligious affiliated private schools, were contacted directly. In the case of Catholic schools, the diocese was informed and schools were then contacted."}, {"section_title": "Timing of Recruitment Activities", "text": "Assessment dates needed to be established early in the school year in which the assessment was to take place or, better still, toward the end of the previous school year. In total, the recruitment phase for TIMSS and TIMSS Advanced extended from April 2014 through May 2015, as indicated in exhibit 1-1 in chapter 1. States were contacted toward the end of April 2014. Following this, contact with districts began in May 2014 and continued through the summer. Schools were contacted beginning in June 2014 and activities continued through May 2015."}, {"section_title": "The Impact of the Sampling Design on Recruitment Activities", "text": "The sampling design played an important role in the design of recruitment activities. For TIMSS, at both grade levels, 300 schools were sampled in the first instance, along with 300 first substitutes and 300 second substitutes, for a total of 900 schools at each grade level. For TIMSS Advanced at grade 12, there were 348 schools in the original sample, along with 348 first substitutes and 348 second substitutes, for a total of 1,044 high schools. In gaining the cooperation of schools, at each grade level the sampled schools were approached in the first instance. Operationally this meant first informing the districts in which these schools are located and then approaching the schools themselves. If a sampled school refused to participate, the district of the first substitute school was approached and the district-school permission procedure began anew. If the first substitute school refused as well, then the district of the second substitute school was approached, and then the second substitute school. "}, {"section_title": "Contacting States and Districts", "text": "The chief state school officer and state assessment director in each of the 50 states and Washington, DC were contacted beginning in April 2014. Each person received a combined TIMSS and TIMSS Advanced package that included an NCES cover letter, instructions on how to obtain the sampled schools in the state, a brochure describing the study, a timeline of activities, a summary of activities for the school coordinator, and a sheet of frequently asked questions. A copy of the letter sent to states is provided as exhibit A-1 in appendix A. Several items of TIMSS and TIMSS Advanced information materials (exhibits B-1 through B-13 in appendix B) were included with the letter. Similar packages were supplied to NAEP State Coordinators. NCES and Westat held a series of webinars to explain TIMSS and TIMSS Advanced, to describe the processes used to report participation, and to answer questions about the study. In many cases, NAEP State Coordinators created personalized contact letters for districts and schools. Westat tracked cooperation status weekly through a secure automated reporting system used by NAEP State Coordinators. After informing the states, similar packages of recruitment materials were sent to the superintendent and the assessment director of each district by the NAEP State Coordinator (or diocese by Westat field staff) containing sampled schools. A copy of the letter sent to districts is provided as exhibit A-2 in appendix A. Several items of TIMSS and TIMSS Advanced information materials (exhibits B-1 through B-13 in appendix B) and a list of sampled schools were included with the letter. During this time, if a sampled school in a cooperating district refused to participate and was judged a firm refusal, a similar district package was sent out to the district of the first substitute school linked to the sampled school. A parallel procedure was adopted with the second substitute district and school in those cases where a first substitute school refused to participate."}, {"section_title": "Follow-Up Contact", "text": "In each case, NAEP State Coordinators or Westat field staff were available to district contacts to discuss the study and answer questions."}, {"section_title": "Special security requirements.", "text": "As a matter of course, each TIMSS and TIMSS Advanced field staff member had a current FBI clearance and fingerprints on file. In addition, all field staff had eQIP clearance as well. These requirements satisfied school security requirements."}, {"section_title": "Contacting Schools", "text": "After district approval was secured, schools were contacted with an initial school information packet. Private schools and some parochial schools not linked with a diocese were contacted directly. Each school information package was sent by the NAEP State Coordinator on a flow basis governed by receipt of district approval. A copy of the cover letter included in the school package is shown as exhibit A-3 and A-4 in appendix A. Copies of TIMSS and TIMSS Advanced information materials (exhibits B-1 through B-13 in appendix B) were included with the letter. identifying excluded students in the sampled classrooms at grade 4 and 8 and among sampled students for TIMSS Advanced; \uf06e liaison with staff, students, and parents as necessary; \uf06e arranging for space and for the release of students from classes on assessment day; \uf06e ensuring completion and return of the school and teacher questionnaires; and \uf06e holding secure, until the end of the school year, the confidential files that linked student names with IDs and then destroying them."}, {"section_title": "Informational Materials and Gifts", "text": "Given that most of the initial contact with states, districts, and schools was by mail, particular attention was paid to developing materials that would promote the value of participation and assure all concerned that the burden on schools would be minimal. These materials included the following: After the assessment, schools and school coordinators were paid incentives of $200 and $100, respectively. Students each received a carabiner with a mini-flashlight attached. Some additional documents were used to maintain contact with schools throughout the year and to inform school coordinators of coming TIMSS and TIMSS Advanced activities. A MyTIMSS website was launched in early 2015 that shared information about school coordinator responsibilities and other information in preparation for assessment day. Professional development webinars were conducted on various topics in large-scale international assessments that school staff could attend, and for which they could receive certificates of attendance for possible use in maintaining their local certification. Drafts of parent notification letters were available to all schools, and parent approval letter, forms, and fact sheets were supplied to those schools indicating that parent approval was required. Examples of the parent approval materials are provided in exhibits A-6 through A-22 in appendix A. The parent notification/approval process is discussed further below."}, {"section_title": "Gaining Cooperation Recruiters", "text": "Private schools at grades 4, 8 and 12 were recruited by two experienced Westat recruiters known as \"gaining cooperation recruiters\" (GCRs), who were experienced with recruiting schools from previous rounds of similar studies (NAEP, PISA, TIMSS, and PIRLS), and a GCR field manager. GCR field manager responsibilities. The field manager engaged in the recruiting phase of the study had the following responsibilities: \uf06e coordinating recruitment activities of the GCRs within their assignment; \uf06e holding weekly one-on-one telephone meetings with their GCRs to monitor progress on gaining-cooperation activities and to troubleshoot recruitment strategies; \uf06e monitoring and maintaining the Field Management System, ensuring that the disposition codes provided by GCRs gave an accurate portrayal of participation status; and \uf06e acting as troubleshooters to handle special issues that arose during the recruiting process. GCR responsibilities. The primary responsibility of the two GCRs was person-to-person interaction with the schools along with some more administrative tasks, as follows: \uf06e making telephone contact to sampled schools, and in some cases, their diocese, within their assignment to obtain permission to conduct TIMSS and TIMSS Advanced; meeting weekly with the field manager by conference call to discuss progress."}, {"section_title": "Monitoring the Recruiting Progress", "text": "Progress in recruiting districts and schools was monitored by Westat through the MyTIMSS School Control System for public schools being recruited by NAEP State Coordinators. MyTIMSS is a secure password-protected website, with access restricted to NAEP State Coordinators and Westat home office staff. NAEP State Coordinators were required to update the MyTIMSS School Control System for each contact made with districts or schools using an electronic record of calls that included updating the disposition code for the district/school in question. The disposition codes in the MyTIMSS School Control System indicated whether the school was pending, refusing, or cooperating. Using these status codes, the Westat home office tracked the progress of recruitment and generated weekly reports. These weekly reports enabled the operations of recruitment (and eventually assessments) to be closely monitored."}, {"section_title": "Difficulties in Gaining Cooperation", "text": "The principal reasons given by both districts and schools for refusing to participate included, in approximate order of occurrence, the following: \uf06e conflict with mandatory federal, state, and/or local assessments whose outcomes had direct implications for districts, schools, teachers and students, and with AP testing for TIMSS Advanced, with direct implications for students; \uf06e the related matter of the burden that additional testing placed on students at the cost of instructional time; \uf06e concerns about too much testing and parents opting out of assessments; and \uf06e the limited return on the school's investment of time because they would not receive much usable information on the school, and none on particular students."}, {"section_title": "Sampling Students Within Schools", "text": "For TIMSS 2015, grade 4 and grade 8 students in participating schools were sampled in a two-stage process. In the first stage, schools were asked to provide lists of fourth-grade classrooms or eighth-grade mathematics classrooms that indicated the number of students in each class. An equal probability sample of two classrooms (or pseudoclassrooms) was identified from the classrooms listed for each school. A pseudoclass is two or more classes that were too small to be assessed alone but were combined with other small classes in the sampling software. In the second stage all students in sampled classrooms (or pseudoclassrooms) were selected for assessment. For TIMSS Advanced 2015, similarly to TIMSS 2015, a two-stage sampling process was conducted with the first stage a sample of schools, and the second stage a sample of advanced students within schools rather than classrooms. Detailed descriptions of sampling designs and methods are covered in chapter 2. These procedures are standardized internationally and embodied in software made available to each country. The software was developed by the International Association for the Evaluation of Educational Achievement (IEA) Data Processing Center and is known as IEA Windows Within School Sampling Software, or WinW3S (IEA Data Processing Center 2014). The WinW3S system provides for forms generation, data entry, class sampling, student sampling, student-teacher linkages, the random assignment of assessment booklets to students, the production of various survey tracking forms, and the printing of labels for test instruments and questionnaires. Westat home office staff attended a WinW3S training session led by IEA. In a departure from previous administrations of TIMSS, Westat developed an E-File system to integrate the data collection with the WinW3S sampling system. This eliminated the hard-copy collection of class and student data and the requisite resulting data entry and cumbersome back and forth with schools. The staff assigned to process the electronic data collection reviewed the incoming data, clarified any issues or inconsistencies with the schools (via school coordinators), properly formatted and imported the data into the WinW3S, and executed the sampling procedures within the WinW3S system. The staff responsible for the sampling processing also generated the materials (all of the forms and labels) needed by field staff and schools for the TIMSS assessment. All Westat staff handling PII signed nondisclosure affidavits, and all PII were kept secure on Westat secure servers."}, {"section_title": "Obtaining Electronic Class Lists From Schools at Grades 4 and 8", "text": "As previously noted, the data collection for the sampling information from schools was, for the first time in TIMSS, conducted electronically. In preparation for the TIMSS and TIMSS Advanced 2015 assessment period, Westat coordinated with school staff and field staff to set up secure, passwordprotected file transfer protocols between schools and Westat. The implementation of the secure TIMSS E-File system eliminated the tedious and difficult task of converting hard-copy information into the electronic data within the WinW3S. Another benefit of the new E-File system was that seamless automated electronic receipting and data tracking were incorporated into the data collection and administrative operation, which was not possible in previous TIMSS administrations. School coordinators worked with schools to collect, review, and provide Westat with the data that would match what had been previously captured in the hard-copy forms. The treatment for TIMSS (grades 4 and 8) was handled the same as for TIMSS Advanced although the data collected took a different path. For TIMSS, all classes from the schools with grade 4 and grade 8 students were requested along with the list of all students in those classes (see section 4.2.2). For TIMSS Advanced, Westat worked with the schools and/or school coordinators to pre-select the courses that met the criteria to be eligible for the study. Westat then requested the list of all twelfth-grade students who had taken or were taking the eligible classes regardless of whether the class was taken in grade 11 or grade 12. Therefore, there are no Class Listing Forms for TIMSS Advanced. For TIMSS, an EXCEL template with the data elements requested in the Class Listing Form (CLF) was transmitted to the school coordinator. The CLF template was used to create a list of the eligible classes, some attributes of each class, and the names of the teacher(s) teaching each class. An illustrative Class Listing Form template for grade 4 is shown in exhibit 4-1 for a small school. Exhibit 4-2 illustrates the class listing form template for a larger grade 4 school that has a different science teacher than the mathematics teacher. A Class Listing Form for grade 8 is shown in exhibit 4-3 that shows the students are linked only to their mathematics class and teacher. In order to properly link these students to a science teacher and science class, the schools submitted a teacher list (as seen in exhibit 4-4) that identified all of the science teachers and the classes they taught. Later on in the process, this information was used to generate a Student-Teacher-Linking Form that was sent to the schools to indicate which science teachers/classes the student was taking. The templates provided to the schools allowed for some flexibility in how the schools provided the data. For example, if the school information system stored students' month and year of birth (MOB and YOB) in a single field, or in multiple fields, Westat provided alternative templates for them to use. Westat wanted to minimize the burden for schools in providing the requisite data. Often schools could provide much of the data requested in an automated way by pulling the data directly from their school information systems. By eliminating much of the manual entry by schools, and by providing flexibility even when manual entry was necessary, the quality and speed of obtaining data from schools was enhanced. That allowed TIMSS data collection and sampling to take place closer to the time of assessment, which provided for a more stable sample of classes and students in these classes than if samples were provided earlier in the school year. Since the E-File system was set up to communicate with each school, the administrative information (school name, TIMSS-generated ID, and grade assessed) was already pre-loaded into the data request Westat would send and receive from the schools. Schools were asked to complete the remaining information for each eligible fourth-grade class or eighth-grade mathematics class in the school. "}, {"section_title": "TIMSS 2015 Grade 4: Class Roster Definitions", "text": "\uf0b7 Class name. Record the class name that is typically used by your school to refer to the class. For example, it may be that your school uses the grade plus a letter for the class name (4a, 4b, etc.), the grade plus a number (4.1, 4.2, etc.), the class location (Room 7, Room 8, etc.,) or some other scheme. This is important because these identifiers will be used to indicate to the Test Administrator which classes will be tested. \uf0b7 Class group or track (if applicable). If your school assigns students to specific classes based on their ability, please indicate the relevant level: Low ability, Average ability, or High ability. \uf0b7 Number of students. Enter the number of fourth-grade students in each class. In the case of multigrade classes (e.g., students from more than one grade level in the same class), only the fourth-grade students should be counted as a class in the list. For example, if three grade 3 students, five grade 4 students, and ten grade 5 students form a multigrade class, then you should record five students for the number of students in this multigrade class. \uf0b7 Class exclusion status (if applicable). As a rule, all classes are to be included. TIMSS 2015 will offer many accommodations that should allow most students to participate. Click on the Documents link on the left panel to see what accommodations are provided or allowed. All class-level exclusions must be approved. If you indicate a class-level exclusion, a TIMSS representative will contact you to discuss. Examples of potential class-level exclusions include classes where all students belong to at least one of the following three exclusion status categories, and none of the students can be assessed with TIMSS accommodations: 1 = students with functional disabilities. These are students who have physical disabilities in such a way that they cannot perform in the TIMSS testing situation. Students with functional disabilities who are able to perform should be accommodated in the test situation, within reason, rather than excluded. 2 = students with intellectual disabilities. These are students who are considered, in the professional opinion of the school principal or by other qualified staff members, to have severe intellectual disabilities or who have been tested as such. This includes students who are emotionally or mentally unable to follow even the general instructions of the test. Students should not be excluded solely because of poor academic performance or normal disciplinary problems. It should be noted that students with dyslexia, or other such learning disabilities, should be accommodated in the test situation, within reason, rather than excluded. 3 = non-native language speakers. These are students who are unable to read or speak the language(s) of the test and would be unable to overcome the language barrier in the test situation. If all students in the excluded class do not belong to the same exclusion category, please identify the category corresponding to the majority of students. \uf0b7 Name of mathematics teacher: Name of the teacher teaching mathematics content to the fourth-grade class. \uf0b7 Name of science teacher: Name of the teacher teaching science content to the fourth-grade class."}, {"section_title": "TIMSS 2015 Grade 8: Class Roster Definitions", "text": "The class roster definitions for grade 8 followed those described above for grade 4 except that science teacher was not collected in the class sampling form template. Rather, TIMSS also required the school to provide the list of eighth-grade science teachers in order to link information about science teachers to the assessed students. Schools were asked to enter each teacher's name and the course the teacher taught (e.g., biology, integrated science) into the template (exhibit 4-4). Sampling classes. For grades 4 and 8, WinW3S generated an equal probability sample of two classes (or pseudoclasses) where possible, based on the information in the CLF template. If only one gradeappropriate class was available in a school, this class was selected with certainty."}, {"section_title": "Identifying Students and Their Teachers", "text": "For TIMSS, schools were given the option of providing the list of the students in each of the mathematics classes listed in the Class Listing Form template or to wait for the results of the WinW3S class sampling selections. In the latter case, after class sampling was completed, Westat provided the schools with the sampled classes. The schools then provided Westat with the students of these selected classes using the Student Listing Form template. Westat provided the schools with multiple templates to allow them flexibility in completing the templates. The format of the student names and the format of the month and year of birth are often stored differently across schools so the templates attempt to simplify and lessen the burden on schools when they provide these data. Exhibit 4-5 presents the grade 4 student list template. For TIMSS Advanced, the courses that were identified as eligible for participation in the assessment based on the school course catalogs and interactions with the school were included in the templates sent to the schools. The schools listed all of the twelfth-grade students that had taken these courses in their junior and/or senior years of high school. The template to gather the student information used for the sampling assignments is shown in exhibit 4-7. For each eligible advanced course, schools were asked to provide the students and teachers of these classes, and furnish the information in this template for each respective subject: TIMSS Advanced requested a complete and current list of all twelfth-grade students who have taken or were currently taking eligible advanced mathematics and physics courses in order to draw a random sample of students to participate in the TIMSS Advanced assessment. More details of the student sampling procedures in TIMSS Advanced students are presented in chapter 2. Eligible courses for each school were sent to the school via email. The student data electronic file (E-File) must be submitted as a Microsoft Excel file. A comparable template was provided to schools to collect TIMSS Advanced physics information."}, {"section_title": "Student-Teacher Linkage Form and Student Tracking Form", "text": "For TIMSS, once the class sampling has been conducted, the student lists submitted by the schools were imported into the WinW3S for each sampled class. Similar to TIMSS, for TIMSS Advanced, once the student sampling has been conducted from the student lists submitted by the participating schools, the list of sampled students was imported into the WinW3S. Students who were sampled for advanced mathematics were identified as session 01, and students were sampled for physics were identified as session 02 in the WinW3S software. The WinW3S then generated the Student-Teacher Linkage Forms (STLF) and Student Tracking Forms (STF) for each sampled class for TIMSS grades 4 and 8, and for each sampled session for TIMSS Advanced. The STLFs and STFS were provided to the schools around the assessment time. These forms were transmitted back to the schools for further updates. The Student Tracking Form was designed to provide test administrators with student IDs, student identifiers in the form of date of birth and sex, the booklet assignment to each student, and the means to record the completion of the assessment and associated questionnaire. The student names shown in the first column of the form were removed following the assessment and retained by the school to ensure confidentiality. An example of an STF containing fictitious information is provided in exhibit 4-9. The participation and eligibility status were recorded in the electronic form and imported into the WinW3S to update the participation fields. The primary purpose of the STLF is to link students to their mathematics and/or science teachers and classes. School staff and field staff ensured that the data found on both of the forms were correct and matched the student records from the school. Discrepancies were reviewed, and edits were made to the forms. Assessment booklets were assigned based on the booklet assignment from the WinW3S generation of the STF. Examples of an STLF and an SLF containing fictitious information are provided in exhibits 4-8 and 4-9, respectively, for TIMSS grade 8. Because the STF and STLF provide the same level of information for TIMSS grade 4, grade 8, and TIMSS Advanced, the examples shown are sufficient for the understanding of their function. The STLF forms were returned to Westat where the links were entered into the WinW3S as the software does not yet allow the automation for this function. The data found on the STF, however, were automated, and all updates to student status and participation on the form were imported into the WinW3S. As the school and teacher questionnaires were conducted online in the IEA Online Survey System (OSS), the tracking of teacher and school participation in the survey could be automated. This system contained a monitoring feature to track completion of teacher and school surveys. USA Gender (column 4): 1 = Female; 2 = Male Exclusion/Accommodation Status (column 5): 1 = Students with functional disabilities; 2 = Students with intellectual disabilities; 3 = Non-native language speakers; 4 = Requires Accommodations Subject Codes (Column 6): 1 = Mathematics; 2 = Physics; 3 = Biology; 4 = Chemistry; 5 = Earth Science; 6 = Integrated Science; 8 = Physics/Chemistry; 9 = Biology/Earth Science; 10 = Biology/Chemistry; 11 = Physics/Biology; 12 = Physics/Earth Science; 13 = Chemistry/Earth Science; 14 = Natural Science; 15 = Scientific Work; 16 = <Country Specific 1>; 17 = <Country Specific 2> [c] [d] Class (Course) Name: [a]  Rosen, Susan  "}, {"section_title": "Instruments for TIMSS and TIMSS Advanced", "text": "All TIMSS and TIMSS Advanced instruments were developed by the IEA as a collaborative effort involving representatives from every country participating in the study. For TIMSS, at each grade the primary instruments for TIMSS 2015 consisted of a combined mathematics and science assessment; a student questionnaire; a curriculum questionnaire; a school questionnaire; and teacher questionnaires to be completed by the teachers teaching mathematics and/or science to the students in the sampled classrooms. For TIMSS Advanced the instruments included a physics assessment; an advanced mathematics assessment; a physics student questionnaire; an advanced mathematics student questionnaire; a curriculum questionnaire; a school questionnaire; and teacher questionnaires to be completed by the teachers teaching physics or advanced mathematics to the sampled students. The TIMSS assessment instrument took the form of 14 booklets containing mathematics and science items in rotated item blocks. While some of these items have to remain confidential for use in coming TIMSS assessments, others are available on a restricted use basis. An IEA permission request form to access and use the TIMSS 2015 restricted items is available at http://timssandpirls.bc.edu/timss2015/international-database/assessment-items.html. The assessment for TIMSS Advanced consisted of 6 booklets for physics and 6 booklets for advanced mathematics and presented items in rotated item blocks. Like TIMSS, some items have to remain confidential for use in coming TIMSS Advanced assessments while others are available on a restricteduse basis. The permission request form for TIMSS Advanced restricted use items is available at http://timssandpirls.bc.edu/timss2015/advanced-international-database/. The TIMSS student questionnaires were grade-specific and bound into the assessment booklet with the assessment items for the particular grade. TIMSS Advanced student questionnaires were also bound into either the physics or advanced mathematics assessment booklet. The school questionnaires were designed as an online instrument to be completed by the school principal for both TIMSS and TIMSS Advanced. Teacher questionnaires were also developed as online instruments. A single fourth-grade online teacher questionnaire was designed for TIMSS mathematics and/or science teachers of the students in the sampled classrooms. Separate questionnaires were provided for the TIMSS mathematics teachers and science teachers of the students in the sampled eighth-grade classrooms. TIMSS Advanced physics and advanced mathematics teacher questionnaires were provided for teachers of students taking either a physics or advanced mathematics assessment. "}, {"section_title": "The TIMSS Mathematics and Science Assessment and TIMSS Advanced", "text": ""}, {"section_title": "Physics and Advanced Mathematics Assessment", "text": "The following summarizes the rationale for and development of the TIMSS and TIMSS Advanced 2015 assessments. Complete detail is provided in the Methods and Procedures in TIMSS 2015 (Martin, Mullis, and Hooper 2016a) and Methods and Procedures in TIMSS Advanced 2015 (Martin, Mullis, and Hooper 2016b)."}, {"section_title": "Assessment Frameworks", "text": "For both TIMSS and TIMSS Advanced, the test development effort began with a revision of the frameworks that define the knowledge and skills assessed in previous TIMSS 2011 and TIMSS Advanced 2008 assessments (Mullis et al. 2009;Garden et al. 2006). The frameworks were updated to reflect changes in the curriculum and instruction of participating countries. Extensive input from U.S. and international experts in mathematics, science, and measurement contributed to the final shape of the frameworks. Maintaining the ability to measure change over time was an important factor in revising the frameworks. The complete subject area frameworks for TIMSS and TIMSS Advanced 2015 are available at http://timssandpirls.bc.edu/timss2015/frameworks.html and http://timssandpirls.bc.edu/timss2015advanced/frameworks.html."}, {"section_title": "Content and Cognitive Domains", "text": "The TIMSS and TIMSS Advanced assessments measure students' knowledge and skills across specific content domains defined for each grade and subject (exhibit 4-10). The assessment items across these content domains measure what students can do across a range of cognitive skills or processes: knowing, applying, and reasoning. TIMSS and TIMSS Advanced science and physics frameworks also describe the science inquiry practices to be measured. "}, {"section_title": "Item Development", "text": "Over one-half of the assessment items used in TIMSS 2011 and in TIMSS Advanced 2008 were kept confidential and included in the respective TIMSS and TIMSS Advanced 2015 assessments to measure trends. To replace assessment items that had been released following the previous assessments, education systems submitted items for review by subject-matter specialists. Additional items were written by the International Association for the Evaluation of Educational Achievement (IEA) Science and Mathematics Review Committees (SMIRC) for TIMSS and TIMSS Advanced and by item-writing and subject area specialists. The items were reviewed by participating countries, the SMIRC, and subject matter experts in assessment to ensure that the content, as defined in the frameworks, was covered adequately. Items were field-tested in most of the participating education systems. Results from the field test were used to evaluate item difficulty, how well items discriminated between high-and low-performing students, the effectiveness of distracters in multiple-choice items, scoring suitability and reliability for constructedresponse items, and evidence of bias toward or against individual countries or in favor of boys or girls. In addition, cognitive labs were conducted in the United States for 20 grade 4 mathematics, 20 grade 4 science, 20 grade 8 mathematics, 20 grade 8 mathematics, 20 advanced mathematics and 36 physics items to evaluate the clarity, format, and content of these items.  "}, {"section_title": "Assessment Booklets", "text": "To keep the testing burden to a minimum while ensuring broad subject matter coverage, TIMSS used a rotated block design that included both mathematics and science items. This is consistent with other largescale assessments such as the National Assessment of Educational Progress (NAEP). The rotated item design meant that, while no students responded to all of the items, each student encountered both mathematics and science items during the assessment. The 2015 fourth-and eighth-grade assessments consisted of 14 booklets, assembled from 28 distinct item blocks at each grade level. Fourth-grade blocks contained approximately 10-14 assessment items, while eighth-grade blocks contained 12-18 items. Each booklet contained four blocks, including at least one mathematics and at least one science block. The fourth-grade booklets required about 72 minutes, and eighth-grade booklets required about 90 minutes. The TIMSS Advanced assessments consisted of 6 booklets for advanced mathematics and 6 booklets for physics, assembled from 9 distinct blocks, each requiring approximately 90 minutes. Each student completed just one booklet. In both subjects, booklets consisted of 3 blocks each."}, {"section_title": "Calculator Use in TIMSS and TIMSS Advanced", "text": "Calculator use was not permitted during the TIMSS fourth-grade assessment. However, the TIMSS policy on calculator use at eighth grade was to give students the best opportunity to operate in settings that mirrored their classroom experiences. As a consequence, calculators were permitted, but not required, for the eighth-grade assessment materials. In the United States this meant that students in the eighth-grade were allowed, but not required, to use calculators. The TIMSS Advanced policy allowed the use of calculators on both the physics and advanced math assessments. Students were instructed to bring their personal calculators to the assessment as long as they were not devices with access to the Internet. The calculators could not be a laptop or other portable computer, pocket organizer, cell phone, device with a typewriter-style keyboard, electronic writing pad, or pen-input device. During the assessment the TIMSS Advanced test administrator confirmed the calculators met the requirements and monitored their use by the students."}, {"section_title": "Context Questionnaires", "text": "As in prior administrations, TIMSS and TIMSS Advanced 2015 included self-administered questionnaires for principals, teachers, and students. To create the questionnaires for 2015, the 2011 versions of the TIMSS questionnaires and the 2008 versions of the TIMSS Advanced questionnaires were reviewed extensively by the National Research Coordinators from the participating countries as well as the Questionnaire Item Review Committee (QIRC). Based on this review, the QIRC eliminated or revised some questions and added several new ones. Like the assessment items, all questionnaire items were field-tested and the results reviewed. As a consequence, some of the questionnaire items were revised prior to their inclusion in the final questionnaires. The questionnaires requested information to help provide a context for the performance scores, focusing on such topics as students' attitudes and beliefs about learning, their habits and homework, and their lives both in and outside of school; teachers' attitudes and beliefs about teaching and learning, teaching assignments, class size and organization, instructional practices, and participation in professional development activities; and principals' viewpoints on policy and budget responsibilities, curriculum and instruction issues, and student behavior, as well as descriptions of the organization of schools and courses. For 2015, online versions of the school and teacher questionnaires were offered to respondents as the primary mode of data collection. Paper versions were also available, if requested."}, {"section_title": "U.S. Adaptations to the Assessment Items and Questionnaires", "text": "Source versions of all instruments (assessment booklets, questionnaires, and manuals) were prepared by the IEA in English and translated by the participating countries into the primary language or languages of instruction in each country. In addition, it was sometimes necessary to adapt the instruments to better fit language usage, even in countries that use English as the primary language of instruction. Other adaptations to fit national education characteristics were sometimes required as well. All adaptations were reviewed and approved by the IEA to ensure they did not change the substance or intent of the question or answer choices."}, {"section_title": "U.S. Adaptations to the Assessment Items", "text": "As in previous cycles of TIMSS and TIMSS Advanced, the U.S. adaptations to the international instruments were minimal and designed to make the assessment more readable to U.S. students without changing the essence of the assessment item. For example, at times names of individuals were changed to more familiar forms (for example, \"Ahmed\" to \"Andrew\"), nouns with British origins were changed to their U.S. equivalent (for example, \"cinema\" to \"movie theater\"), Imperial English spellings were changed to American English (for example, \"organisation\" to \"organization,\" \"programme\" to \"program\"), and some changes to the text of instructions were also made to better mirror the administration procedures in the United States."}, {"section_title": "U.S. Adaptations to the School, Teacher, and Student Questionnaires", "text": "Adaptations made to the school, teacher, and student questionnaires were of the following five main types: \uf06e changes to general instructions made in the interests of enhancing clarity; \uf06e changes designed to make question text more readable to U.S. students, similar to those made to the assessment items as described above; changes to ensure some questions were kept in trend with previous assessments. A detailed list of changes made to the questionnaires is provided in appendix E. Both the original text from the international version of the questionnaire and the changed text from the U.S. version are shown. Text that has been changed in the U.S. version is underlined in that version. Both international and U.S. questionnaire item numbers, or other location indicators, are provided in each instance. Where appropriate, a crosswalk between the U.S. and international versions of the set of response categories of items is provided in the \"Comments\" column."}, {"section_title": "Translation and Verification of Instruments", "text": "Each country prepared translations of the instruments according to translation guidelines established by the IEA. As the international versions of the instruments are produced in English, the U.S. did not need to engage in the full-fledged translation required of many nations. However, the adaptations made to the U.S. instruments required verification by the IEA to ensure their suitability for the current cycle of TIMSS and, if trend items, their continuity with previous cycles. Further details on the translation process can be found in Martin, Mullis, and Hooper 2016a and Martin, Mullis, and Hooper 2016b."}, {"section_title": "Production of Assessment Booklets and Questionnaires", "text": "Upon receiving IEA approval of the adaptations, Pearson applied the adaptations to the international questionnaires and item blocks and then assembled the final assessment booklets. Quality control procedures for this process included a review of each adaptation made to the questionnaires and item blocks as well as a full review of the assembled instruments in a final layout proof. In mid-December 2014, electronic files were sent to the TIMSS & PIRLS International Study Center for layout verifications. Final approval to print was given in early February 2015. The student assessment booklets and student questionnaires were printed on scannable form. The teacher and school paper and pencil versions of the questionnaires were printed on non-scannable form. A similar procedure was applied to the online school and teacher questionnaires. Adaptations were made to the online instruments using software provided by the IEA Data Processing and Research Center (DPC). A set of output files was produced for each questionnaire, and these were uploaded to a secure server and verified by the IEA DPC."}, {"section_title": "Scannable Document Preparation and Printing", "text": "The student cognitive assessments and student questionnaires were printed as scannable documents combined into 14 single booklets at grades 4 and 8 for TIMSS, and six physics and six advanced mathematics booklets for TIMSS Advanced. Document production was divided into two phases. The preparation phase included the mockup and design of forms, typesetting, composition, and editing for text accuracy and process ability. The production phase included final platemaking, printing, binding, and any finishing procedures (counting, wrapping, etc.) that were required prior to packaging and distribution. After a form was created, it was thoroughly inspected for grammar, spelling, and punctuation to ensure that it matched the approved electronic files. Subsequently, copies of these proofs were subject to a technical review of \"scan ability,\" oval placement, and spine code assignment. Immediately after printing, sample documents were selected from predetermined locations throughout the print run for testing. Before shipping, a sample from each carton of multipage documents was inspected to ensure that the pages of the booklets were in the correct sequence. After binding, all documents were boxed to ensure that material quality was maintained during transit to the packaging facility."}, {"section_title": "Preparation and Printing of Non-Scannable Documents", "text": "The teacher and school questionnaires were produced as non-scannable documents. In the first stage, proofs of each document were reviewed against the original electronic files. Once accuracy was certified, printing was initiated. During this process staff checked a 10 percent sample of the printed form against the approved document to ensure that accuracy was maintained throughout the printing process."}, {"section_title": "Online Questionnaires", "text": "Once verified by IEA DPC, each questionnaire for school and teachers was loaded to a secure NCES server and thoroughly tested by NCES and Westat to ensure that responses were being captured correctly and that the instruments were functioning properly."}, {"section_title": "Field Operations", "text": "The activities discussed here refer to those associated with the administration of the assessments in participating schools. In the United States the administration of the assessments was carried out by professional staff trained according to the international guidelines. School personnel were asked only to assist with listings of students, the identification of school space for the assessment, and the specification of parental consent procedures needed for sampled students. Field operations centered on three main tasks: recruiting and training of field staff, scheduling the assessments, and administration of the assessments within the schools. Field staff consisted of test administrators and assistant administrators. Test administrators managed the assessments in the schools, while assistant administrators assisted in the assessment administration, conducting one of the assessments because in most schools two separate classrooms were assessed simultaneously. All had previous experience with other educational assessments in schools, and all had FBI clearance based on fingerprint and background checks, as well as eQIP security clearances. Test administrators and assistant administrators also signed a statement of nondisclosure indicating that they would maintain confidentiality of all survey materials and of the data collected. The total complement of field staff consisted of one field director, 5 field managers, 64 test administrators, and 64 assistant administrators. The field director reported directly to the Westat home office and met weekly to discuss progress and any problematic issues arising in the field. Field managers reported to the field director, Test administrators reported to a field manager who coordinated and monitored their work and, in turn, the test administrators coordinated and supervised the work of the assistant administrators. "}, {"section_title": "Responsibilities of Field", "text": ""}, {"section_title": "Training", "text": "A 2\u00bd-day, in-person training for test administrators was held on March 11-13, 2015. The attendees received the Test Administrator Manual 5 days prior to the training session and were given four paid \"study hours\" to become familiar with the information prior to training. The agenda for this training session is provided as exhibit C-1 in appendix C. TIMSS and TIMSS Advanced were very similar in terms of general procedures; therefore the training was centered on TIMSS. TIMSS Advanced was referenced at specific times when a unique training point needed to be made or when procedures differed. The first day of training focused on the responsibilities of a TIMSS test administrator, TIMSS data collection materials, the Preassessment Call Checklist, and entering preassessment call information into the MyTIMSS School Control System. In addition, accommodations allowed on TIMSS and increasing grade 12 student participation were discussed. The second day included discussion about the procedures to be followed in preparing for, arriving on, and conducting the assessment day. The third half day dealt with what to do once the assessment was completed, and the appropriate methods for packing and shipping the assessment materials to Pearson Educational Measurement. Privacy and security of test materials was reviewed and test administrators met with their field managers to review assignments and schedules. Field staff were assigned laptop computers to take with them for the duration of TIMSS and TIMSS Advanced data collection. Printers for use with the laptops were issued and sent to each test administrator after training. Test administrators were also provided with an official TIMSS/TIMSS Advanced 2015 photo ID badge to wear while representing TIMSS and TIMSS Advanced in the schools. \nThe United States sent one scoring representative to attend the grade 4 and grade 8 international scoring training in Willington, New Zealand in November 2014. Two additional scoring representatives were sent to the TIMSS Advanced international scoring training in Prague, Czech Republic in March 2015. These training sessions were sponsored by IEA and were mandatory to participate in the TIMSS assessment. Materials from these sessions along with additional materials constructed specifically for this purpose were used to train the scoring supervisors and scorers. Two additional scoring directors were hired for the grade 4 and grade 8 mathematics and science items. These scoring directors were trained by the scoring representative who attended the training in New Zealand. There were 11 scoring supervisors hired to train and oversee the scorers on the grade 4 and grade 8 mathematics and science items. Eighty-three scorers organized into 11 teams, with 6 to 8 scorers per team, were hired to score these items. All were hired based on their experience with similar mathematics and science scoring projects. Two physics scoring supervisors and one advanced mathematics scoring supervisor were hired to train the scorers on the TIMSS Advanced items. Twenty-four scorers organized into three teams of 8 were hired to score the physics and advanced mathematics items. These supervisors and scorers were hired based on their background with physics and calculus. Training activities for the scorers followed the same routine as the international training, with supervisors leading each small team reading the item prompt; reading the rubric or scoring guide aloud; reading aloud each of the anchor papers and explaining the reasoning behind the score; allowing the scorers time to complete the practice papers; reviewing each of the practice papers; and opening individual scoring on the electronic Performance Evaluation Network (ePEN). Training on and scoring of the items was completed one at a time, with the exception of the linked items, which were scored together."}, {"section_title": "Scheduling Assessments", "text": "The approximately 900 schools taking part in TIMSS and TIMSS Advanced 2015 were dispersed across the country, although with concentrations in the more populous states and cities. Scheduling assessment dates for these schools required the optimization of school preferences for a particular date with the assessment date preferences of nearby schools and the location of field staff in an effort to keep travel and related expenses to a minimum. The basic approach adopted involved the geographic mapping of schools and assignment of a preliminary date, along with the location of field staff. This formed the foundation for discussions with schools, and the assignment of schools to field staff. In essence, geographical clusters of schools were assigned assessment dates clustered in time insofar as this was possible."}, {"section_title": "Obtaining Assessment Dates From Schools", "text": "Prior to recruitment of schools, Westat staff collected date information for the sampled schools, including dates associated with state testing, holidays, breaks, field trips, and the like. This information was used to set a tentative date for each school."}, {"section_title": "Mapping Schools", "text": "In a second step a geographic map of participating grade 4, grade 8, and grade 12 schools was developed based on the addresses of the schools. The map allowed the ready identification of obvious clusters of schools in large metropolitan areas and also allowed for identification of less concentrated clusters in broader geographical areas as well as isolated schools. To establish optimal regions for assessment administrators, geographic clusters of schools were defined in an iterative process that took into account the location of field staff and their caseload. A total of 59 regions of varying size were identified in this way."}, {"section_title": "Assigning Tentative Assessment Dates", "text": "The provisional assessment dates were then mapped to the schools in each cluster and represented in the MyTIMSS School Control System. Within clusters, assessment dates were balanced against the location of schools in relation to one another. With some minor modifications to regions, schools in relatively close proximity were assigned to provisional assessment weeks. This process identified smaller clusters of schools that could be assessed within a week without undue travel and related expenses. For the most part, assessments were scheduled on Tuesday through Thursday, leaving Monday and Friday as travel days."}, {"section_title": "Negotiating Final Assessment Dates", "text": "Once tentative dates were established, field staff contacted schools to negotiate a final assessment date. For the most part, schools accepted the dates proposed. When this was not possible, field staff used the work area spreadsheet and a work area map to negotiate an alternative assessment date that would minimize staff travel. Final assessment dates and times were confirmed by email with the school coordinator."}, {"section_title": "Assignment of Schools to Test Administrators", "text": "For the most part, field staff were assigned a region based on their location and availability with most regions relatively close to the test administrator's home address. Balancing these several demands resulted in some variation in the caseload of test administrators. During the course of the assessments, which ran from end of March 2015 through to early June 2015, some reassignments of schools and/or work areas were necessary."}, {"section_title": "Troubleshooting", "text": "Five of the test administrators and five assistant administrators were recruited as regional troubleshooters who would be available to cover last-minute changes in assessment dates, staff illnesses, and the like. Each of these staff also had their own assignments, essentially schools that did not easily fit into an identified region or assessment date window."}, {"section_title": "Recruiting Parents and Students", "text": "During recruitment and scheduling contacts with schools, field staff asked about district and/or school requirements for notifying parents about their child's participation in TIMSS or TIMSS Advanced. School requirements fell into the following three main categories: The school would simply send parents a notification of the child's participation in TIMSS along with some informational material; \uf06e Passive consent. The school was required to ask parents for permission for the child to participate but permission would be assumed unless there was a formal objection; and \uf06e Active consent. The school was required to ask parents for permission for the child to participate and the child could not participate until the parents provided formal approval. Almost all schools opted for parental notification. To assist schools in this task the school coordinator was provided with one of three draft letters to parents, one for each of the three forms of parent permission. These letters could be edited as appropriate and sent out on school stationery. Consent forms to accompany the passive and active consent letters were also provided along with an information sheet describing TIMSS or TIMSS Advanced. English and Spanish versions of each of these documents were made available to the schools. Copies of these materials as they apply to fourth-grade, eighth-grade and Advanced students are provided as exhibits A-5 through A-20 in appendix A."}, {"section_title": "Organizing the Assessment Session at the School", "text": "Approximately four to two weeks prior to each school's assessment date, the test administrator called the assigned school coordinator. Using a Preassessment Call Log, test administrators were instructed to verify previously obtained information on items such as the school's address, principal's name, assessment date, session location, requirements for entering the school, and parking arrangements as well as the status of the within-school sampling forms for the school. The information obtained was maintained within the School Folder and updated as a basic reference. The Preassessment Call Log is provided as exhibit C-2 in appendix C. On assessment day each test administrator, accompanied by an assistant administrator, arrived at the school with all of the materials needed for the assessment. One session box of materials was provided for each of the sampled classes. For TIMSS Advanced, physics and advanced mathematics materials were in separate session boxes, for sessions of students selected for either physics or advanced mathematics. Each session box contained the estimated number of student assessment booklets required, plus three unassigned booklets to accommodate any changes in class enrollments at grades 4 and 8. Upon arrival, the test administrator met with the school coordinator to make any updates to the Student Tracking Form that would affect the preparation of student materials (for example, the addition of new students, the withdrawal of listed students from the school or class, or a change in exclusion status of a sampled student). Test administrators arrived at the school about an hour before the scheduled assessment to prepare booklets for distribution and take care of other arrangements for the assessment. Following the prescribed international procedures, the test administrator did not open the booklet bundles until 45 minutes before the assessment. At that time, the booklets were assigned to students in the random order established by the IEA sampling software, and labels were placed on the booklets. TIMSS pencils were provided to all students. As required by international rules, simple-function calculators were provided at the eighth-grade level only, and then only at the discretion of the school. Students participating in the TIMSS Advanced assessment were instructed to bring their own scientific calculator to the assessment. Students kept the TIMSS pencils as gifts, but calculators distributed during the assessments were collected with the booklets after the assessment."}, {"section_title": "Administering the Assessment", "text": "Assessments were administered by reading verbatim from a standardized script according to the instructions in the TIMSS and TIMSS Advanced Test Administrator Manuals. A copy of each of the sessions scripts are provided in appendix C. The script began with a brief introduction to the study. The assessment booklets, each in a security envelope, then were distributed. The students were instructed to remove their booklet from the envelope, and the general instructions and instructions for Part 1 were read. Following this, the students were instructed to begin Part 1 of the assessment. After the allotted 36/45 minutes (grade 4/grade 8/12), a short break was provided. After the break, the instructions for Part 2 were read and students were instructed to begin Part 2 of the assessment. After the allotted 36/45 minutes for this part of the assessment, students were instructed to stop work, and a longer break was provided. Following the break, the student questionnaire was administered; it was not time-limited but was typically completed in about 30 minutes. While students completed each section of the assessment, the test administrator checked that the students were working in the correct section of the assessment booklet, answered any questions students had, and ensured the allotted section timing was followed as specified by the assessment procedures and guidelines."}, {"section_title": "Postassessment Activities", "text": "Following the assessment, test administrators instructed the students to remove an identifying label from the cover of the booklet, place the booklets in the security envelope, and seal it. The students handed their booklets to the administrator, received their gift, and were dismissed. The test administrator then recorded participation codes for each session and packed the booklets and school and teacher questionnaires into the shipping box. The test administrators made copies of the Student Tracking Form and the Session Report Form, placing the original documents in the TIMSS and/or TIMSS Advanced Storage Envelope to be kept at the school. To maintain the security of student names, the test administrator removed and destroyed the column of student names from the copies of the STF and placed the de-identified STF and Session Report Form in with the assessment booklets and questionnaires. The session materials were sealed and shipped to Pearson."}, {"section_title": "Receipt Control, Scoring, Data Entry, and Editing", "text": "Westat field staff sent the completed assessment materials along with any related materials directly to Pearson following the completion of the assessment session at a school. Pearson recorded the receipt of materials, scored the open-ended responses, captured and edited the multiple-choice assessment items, and created data files from this information. The data files were sent to Westat."}, {"section_title": "Receipt Control", "text": "TIMSS documents were received at Pearson from April 1, 2015 through June 9, 2015. As assessment materials were returned to Pearson, receipt dates were recorded and sent to Westat twice a week. Pearson updated the electronic student tracking forms with the participation status and any other updates made by the test administrators during and after testing. These electronic files were sent to Westat on a weekly basis. Pearson checked in and processed assessment booklets from approximately 312 grade 4, 311 grade 8 and 271 grade 12 schools. This included the additional schools from Florida, which participated as a Benchmarking state. School personnel had the option to complete their teacher and school questionnaires online or complete a hard copy and return them with the assessment booklets. Those returned to Pearson were sent to the Westat home office for entry into the online system. "}, {"section_title": "Receipt Control System", "text": "Two systems were used by Pearson to monitor the receipt and processing of assessment booklets after the assessments-the Process Control System and Workflow Management system. These systems enabled Pearson's project staff to determine the status of any selected school; verify materials from a completed school had been received; identify discrepancies in student or school information; and obtain information on the status of data processing activities for a particular batch of booklets. The Process Control System contained a list of all participating schools and monitored the status of all sampled schools and assessment booklets. School materials were returned to Pearson packaged in their original boxes. A barcoded label containing the school ID was applied prior to shipping the booklets out to the Westat administrators. This barcode was scanned upon arrival at Pearson. Daily receipt reports were provided to project staff. Opening staff checked each school shipment to verify that the contents in the box matched the school ID indicated on the label. Each school shipment was then checked for completeness and accuracy based on procedures outlined in the IEA Survey Operations Manual. Any discrepancies were recorded and project staff alerted to determine the cause. Once a school shipment was opened and verified as being complete, the booklets were organized into work units and batched. The computerized Workflow Management System allows the user to track the flow of work through every processing step."}, {"section_title": "Booklet Accountability", "text": "Prior to the distribution of materials, a barcode was applied to the assessment booklets. These booklets were then organized into bundles. The barcodes within each bundle were scanned to a file that was used to control distribution to field staff or a particular school. This assignment of bundles to schools and/or administrators was recorded in the Materials Distribution System. After receipt of the school shipment after the assessment, a manual count was made to ensure all booklets from the original bundle were present. The assessment booklets were submitted for scanning and editing. The unused booklets were batched and the booklet identification barcode scanned. This file and the processed documents file were compared to the original bundle security file created before distribution. A report listing the unmatched booklet identification numbers was printed and used to confirm any nonreceipt of individual booklets. This report was given to the Westat home office. All assessment booklets were returned to Pearson. After the batches of documents had successfully passed the scanning and editing process, they were sent to the warehouse for storage. The storage locations of all documents were recorded in Pearson's inventory control system, which permits the rapid retrieval of any document, should it be necessary. Used and unused materials are securely stored until permission is given to destroy them."}, {"section_title": "Scoring the Assessment Items", "text": "In "}, {"section_title": "4-30", "text": "The United States scored approximately 366,900 grade 4 and grade 8 science student responses; approximately 364,868 grade 4 and 8 mathematics student responses; and approximately 52,700 physics and 51,300 advanced mathematics student responses for TIMSS Advanced. This included the number of responses selected for interrater reliability or second scoring."}, {"section_title": "Cross-Country Scoring Reliability Study", "text": "In international assessments, it is also important to gather information about how reliably the scoring was conducted from country to country so that valid international comparisons can be made of students' achievement. To document the reliability of constructed-response scoring across TIMSS countries, a cross-country scoring reliability study was conducted. The Cross-country Scoring Reliability Study was introduced to estimate the degree of agreement between scorers in different countries. Cross-country reliability scoring allows scorers from each participating country to score the same set of student responses from other English speaking countries. The IEA Data Processing Center assembled a sample of student responses to be scored and distributed the sample to each participating education system along with the IEA Cross-Country Scoring Reliability Software (CCSRS). The sample responses involved 21 (11 mathematics and 10 science items) items at the fourth grade and 26 (13 mathematics and 13 science items) items at the eighth grade. All of the items were trend items from TIMSS 2011. After scoring the U.S. responses for an item with their team, two scorers then completed scoring of the international responses that were preloaded on desktop computers. While the individuals making up the pairs varied, no scorer worked on items that he or she had not been trained to score. Completion reports were only available with the CCSRS system. Once scoring was completed, the scored files were sent back to the IEA through a secure FTP site."}, {"section_title": "Trend Reliability Scoring", "text": "To document the reliability of constructed-response scoring between the TIMSS 2015 scorers and the TIMSS 2011 scorers in the United States, TIMSS included a trend scoring reliability study. The trend reliability scoring allows scorers of the TIMSS 2015 assessment to score a subset of student responses collected in the United States for TIMSS 2011. The IEA Data Processing Center assembled a sample of student responses to be scored and distributed it to each participating education system along with the IEA Trend Scoring Reliability Software (TSRS). Only education systems participating in 2015 that also participated in TIMSS 2011 took part in the trend scoring reliability study. There were 44 grade 4 items and 60 grade 8 items for TIMSS trend scoring. A total number of responses (200) were divided equally by the number of scorers who were assigned to the item block. The main trend reliability scoring process took place in parallel with the main study scoring for TIMSS 2015."}, {"section_title": "Data Entry", "text": "The data in the TIMSS scannable student booklets was collected with an optical-scanning equipment that captured images of the open-ended constructed-response items, multiple-choice responses, and intelligent character recognition (ICR) fields. The data values captured from the multiple-choice items were coded as numeric data. Unmarked fields were coded as blanks and the editing staff was alerted to missing or encoded critical data. The images of open-ended constructed-response items were saved as a digitized computer file and uploaded into the ePEN scoring system for scoring. ICR was used to read various hand and machine printing in the documents. Image clips of the ICR fields were displayed to online editing staff for verification. In addition to capturing the student responses, the barcode identification numbers used to maintain process control were decoded and transcribed to the TIMSS computerized data file."}, {"section_title": "Data Editing", "text": "Each data set produced by the scanning system was validated for type and range of response. The dataentry and resolution system used was able to simultaneously process a variety of materials from all grades, subject areas, and assessment booklets as the materials were submitted to the system from scannable media. The data records in the scan file were organized in the same order in which the paper materials were processed by the scanner. As the program processed each record within a batch from the scan file, it wrote the edited and reformatted data records to the pre-edit file and recorded all errors on the edit file. The program generated an online edit file of the data problems and resolution guidelines. Image clips requiring edits were routed to online editing stations for the imaged scanned documents. All data values that were out of range were read \"as is\" but were flagged as suspect. All data fields that were read as asterisks (*) were recorded on the online edit file. Because the asterisk code indicated a double response, these items were identified for possible resolution by editing staff. Each field was validated for range response and any values outside of the specified range. Corrections were made immediately. The system employed an edit/verify system, which meant two different people viewed the same suspect data and operated on it separately. The verifier made sure the two responses (one from either the entry operator or the ICR engine) were the same before the system accepted the item as being correct. If it could not be determined, it was escalated to a supervisor. When the edit process produced an error-free file, the booklet ID number was posted to the TIMSS tracking file by grade and school. This permitted staff to monitor the TIMSS processing effort by accurately measuring the number of documents processed. The posting of booklet IDs also ensured that a booklet ID was not processed more than once."}, {"section_title": "File Creation and Consistency Checks", "text": "In a final step the data from the assessment score files were merged with the student scanned data. At this time, final output files were produced for each file type. The final files were checked to ensure the data were in the correct format. In earlier editing functions, data were checked for completeness and compliance with the international codebook specifications. In addition, a check was performed to verify correct linking and matching of student and school data files. The student data files were loaded in the WinW3S software such that all data from the assessments and questionnaires were available in the format required by IEA."}, {"section_title": "Data Preparation", "text": "As noted in the previous section, the data collected for TIMSS and TIMSS Advanced 2015 were imported into data files according to a common international format, as specified in the IEA Data Management Expert-TIMSS & TIMSS Advanced 2015 MS data entry software. The software facilitated the checking and correction of data by providing various data consistency checks. The data files in this format were sent to the IEA Data Processing Center, where they were subjected to an extensive series of data cleaning and consistency checks. The overriding concern of these checks was to ensure that all information in the database conformed to the internationally defined data structure, national adaptations to questionnaires were reflected appropriately in the codebooks and documentation, and all variables used for international comparisons were comparable across countries."}, {"section_title": "International Data Cleaning Procedures", "text": "The IEA Data Processing Center was responsible for checking the data files from each country, applying standard cleaning rules to verify the accuracy and consistency of the data, and documenting electronically any deviations from the international file structure. Queries arising during this process were addressed to national centers, and this process was repeated as necessary to ensure the data were consistent and comparable within and between countries. Following this cleaning step, countries were provided national univariate and reliability statistics along with data almanacs containing international univariate statistics and item statistics. This allowed countries to examine their data with those of other participating nations. Once any problems arising from this examination were resolved, sampling weights produced by Statistics Canada and IRT-scaled student proficiency scores in mathematics and science were added to the file. "}, {"section_title": "Data Confidentiality Safeguards", "text": "While the National Center for Education Statistics (NCES) and data contractors routinely pledge confidentiality to respondents, concerns about the potential for disclosure of information about individual survey respondents have recently increased, particularly with software and online services available to individuals that could facilitate respondent identification. Data confidentiality laws have been enacted since the Privacy Act of 1974 to further ensure the protection of personally identifiable information (PII). The Education Sciences Reform Act of 2002 explicitly requires that NCES protect the confidentiality of all data collected from respondents in NCES-sponsored surveys. More specifically, NCES Standard 4-2, Maintaining Confidentiality provides the guidelines for limiting the risk of data disclosure for data released by NCES (Seastrom 2002). Data disclosure occurs when an individual respondent has been identified through the use of the survey item responses and other external data sources. The procedures used to reduce the risk of data disclosure for TIMSS and TIMSS Advanced 2015, in accordance with the guidelines specified in NCES Standard 4-2, are described below. All students, teachers, and schools participating in TIMSS and TIMSS Advanced 2015 do so with the assurance that their identities will not be disclosed. All employees handling the data have signed affidavits of data confidentiality. The names of schools, students and teachers are removed by the field staff from the TIMSS questionnaires and assessment booklets, and are either physically cut or blacked out on the corresponding TIMSS forms. School, student, and teacher names are replaced by computergenerated school, student, and teacher IDs. Furthermore, any hard-copy questionnaires and assessment booklets are sealed by security stickers to ensure that neither school nor project field staff can access the questionnaire responses provided by the respondents. Additionally, the following NCES disclosure statement has been placed in all of the TIMSS questionnaires, including school and teacher questionnaires administrated online: After the TIMSS and TIMSS Advanced data was collected, procedures were implemented to ensure the confidentiality of the school, student, and teacher responses. The Institute of Education Sciences (IES) requires that survey data cannot be transmitted to foreign entities prior to ensuring the confidentiality of the data and approval by the IES Disclosure Review Board. The TIMSS and TIMSS Advanced disclosure analyses focused on the two Disclosure Review Board-required components for securing the confidentiality of the TIMSS data. They included (1) the identification and masking of potential disclosure-risk TIMSS schools by comparing the study variables with publicly available school files, using probabilistic matching and deterministic swapping on school-level data, and (2) the implementation of an additional measure of uncertainty of school, student, and teacher identification with the random swapping of data elements within the school, student, and teacher files. The confidentiality analyses were designed to provide reasonable assurance that the 2015 TIMSS U.S. public-use data files will not allow identification of individual schools, students, or teachers when compared to publicly available data collections. No publicly available data collections identify either students or teachers by name, but two data collections identify schools by name. The NCES regularly publishes the Common Core of Data (CCD), a detailed public school listing, and the Private School Survey (PSS), a detailed private school listing. Any potential identification of teachers and students will arise through the identification of their associated schools. Providing a reasonable degree of assurance that TIMSS schools cannot be identified thus ensures that teacher and student data also remain unidentifiable. Nevertheless, the proposed confidentiality procedures included perturbing student-and teacher-level data. It should be noted that the TIMSS data do not contain any information of a personal or sensitive nature (such as drug use or sexual activities). Anyone intent on identifying the TIMSS schools could take the TIMSS public-use U.S. school data and search the CCD and PSS files for matching schools. For example, one could match a public school from the TIMSS U.S. school file against the CCD school file by first identifying variables common in both files. One then could compare a TIMSS school record to each CCD school record, assigning each pair a probability of being a true match based on the common variables. The CCD record (or records) with the highest probability would best match the traits of the TIMSS school. A TIMSS school could then be identified from the school name and address attached to the CCD school record. The user could take a similar approach in identifying a TIMSS private school from the PSS school file. Because the variables in the TIMSS and TIMSS Advanced 2015 data files were obtained from responses to the school questionnaire, which often vary from the CCD and PSS data, exact profile matches are unlikely. Even then, one would not know for certain whether any of the matched schools were the actual TIMSS and TIMSS Advanced schools or whether the match had simply arisen by chance. Nevertheless, school matching analyses were undertaken using probabilistic matching algorithms approved by the IES Disclosure Review Board for use in disclosure analyses. These algorithms identified schools whose school questionnaire responses provided some potential for identification. To provide further protection, elements of the data from schools identified as \"disclosure risks\" in this way were perturbed using the procedures approved by the IES Disclosure Review Board. After perturbation, the data were subjected to another round of analyses to ensure that the potential for identification no longer existed. An additional measure was taken to reduce further the risk of disclosure of an individual respondent. This random data swapping measure is an IES Disclosure Review Board requirement that reduces disclosure risk by modifying microdata. In random data swapping, a probability sample of records is paired with other records on the file using selected characteristics, and then some identifying variables are swapped between the pairs of records (Kaufman, Seastrom, and Roey 2005). The sampling rate and variables for TIMSS and TIMSS Advanced swapping were designed to protect the confidentiality of the data without affecting the usability of the dataset. All questionnaire data (school, teacher, and student) were involved in the swapping. This method is an effective way of keeping as much valuable data as possible while protecting respondent identity. Swapping preserves the univariate frequencies, means, and variances, although it may slightly affect multivariate relationships. Pre-and post-swapping percentage distributions (unweighted and weighted) and correlations were reviewed to ensure data quality was maintained. Confidentiality analyses of this kind were conducted before the U.S. data files were delivered to the Data Processing Center for cleaning, and prior to the score scaling and estimation of sampling weights. Because of increasing security concerns from the international community, an additional data confidentiality measure was implemented by the IEA DPC for both TIMSS and TIMSS Advanced 2015. School IDs were scrambled for each education system's participating schools as a security measurement for de-identification. This procedure puts an additional safeguard into place that makes it difficult to trace collected information back to the source. Because of the hierarchical ID naming convention employed by IEA DPC, the scrambling of the school IDs also affected the teacher and student IDs, thus making these IDs scrambled as well."}, {"section_title": "The Estimation of TIMSS and TIMSS Advanced Student Proficiencies", "text": "All cycles of TIMSS and TIMSS Advanced used item response theory (IRT) methods to produce score scales that summarized the achievement results. With this method, the performance of a sample of students in a subject area or sub-area could be summarized on a single scale or a series of scales, even when different students had been administered different items. IRT scaling provides estimates of item parameters (for example, item difficulty and item discrimination) that define the relationship between the item and the underlying variable measured by the test. Parameters of the IRT model are estimated for each test item, with an overall scale being established as well as scales for each content area and cognitive domain specified in the assessment framework. To allow for the calculation of trends in achievement, comparisons of scores across the six TIMSS assessments conducted in 1995, 1999, 2003, 2007, 2011 and 2015 and comparisons of scores across the TIMSS Advanced assessments conducted in 1995 and 2015 were necessary. To this end, achievement scores from all five TIMSS assessments were placed on the same scale. The three TIMSS Advanced cycles were subjected to the same treatment. Details are provided in Methods and Procedures in TIMSS 2015 (Martin, Mullis, and Hooper 2016a) and in Methods and Procedures in TIMSS Advanced 2015 (Martin, Mullis, and Hooper 2016b)."}, {"section_title": "International Benchmarks", "text": "International achievement benchmarks were developed to provide a concrete interpretation of what the scores on the TIMSS mathematics and science achievement scales and on the TIMSS Advanced physics and advanced mathematics scales mean. TIMSS and TIMSS Advanced each used scale anchoring to summarize and describe student achievement at points on the mathematics and science (for TIMSS), and advanced mathematics and physics (for TIMSS Advanced) scales. TIMSS identifies four benchmarks: Advanced (625), High (550), Intermediate (475), and Low (400). TIMSS Advanced has the same top three benchmarks but no Low benchmark. Scale anchoring involves selecting benchmarks (scale points) on the TIMSS and TIMSS Advanced achievement scales to be described in terms of student performance and then identifying items that students scoring at the anchor points can answer correctly. Subsequently, these items are grouped by content area within benchmarks and reviewed by mathematics and science experts for TIMSS grades 4 and 8, and advanced mathematics and physics experts for TIMSS Advanced. These experts focus on the content of each item and describe the kind of mathematics, science, advanced mathematics, or physics knowledge demonstrated by students answering the item correctly. The experts then provide a summary description of performance at each anchor point leading to a content-referenced interpretation of the achievement results. Detailed information on the creation of the benchmarks is provided in the \"Using Scale Anchoring to Interpret the TIMSS and TIMSS Advanced 2015 Achievement Scales\" section of Methods and Procedures in TIMSS 2015 (Martin, Mullis, and Hooper 2016a) and in Methods and Procedures in TIMSS Advanced 2015 (Martin, Mullis, and Hooper 2016b)."}, {"section_title": "The Estimation of Sampling Weights", "text": "Because of the complex sampling design used in TIMSS and TIMSS Advanced, students were assigned sampling weights. In general the sampling weight assigned to a student is the inverse of the probability that the student would be selected for the sample. When responses are weighted, each contributes to the results for the total number of students represented by the individual student assessed. Weighting also adjusts for school and student nonresponse. The internationally defined weighting specifications for TIMSS and TIMSS Advanced require that each assessed student's sampling weight should be the product of the following:  "}, {"section_title": "TIMSS AND TIMSS ADVANCED 2015 DATA FOR THE UNITED STATES AND FLORIDA", "text": "The TIMSS and TIMSS Advanced 2015 international databases, released by the TIMSS and PIRLS International Study Center, contain student achievement data as well as student, teacher, school, and curricular background data for 47 countries and 6 other education systems at grade 4 and for 39 countries and 6 other education systems at grade 8 for TIMSS, including Florida as a benchmarking state for the U.S.; and for 9 countries for TIMSS Advanced 2015. The following five basic types of data files are available for each education system in both the TIMSS and TIMSS Advanced international datasets: 1. achievement files containing item response data and scale scores for the TIMSS or TIMSS Advanced assessment; 2. background files with information from students, from their mathematics and science teachers in TIMSS or their advanced mathematics and physics teachers in TIMSS Advanced, and from the principals of their schools; 3. student-teacher linkage files that contain the information needed to link data on students to that of their teachers; 4. constructed-response scoring reliability files providing data on the reliability of scoring for this type of item; and 5. curriculum data files that contain the responses of countries or participating education systems to the curriculum questionnaires. These databases provide comparable data across education systems on detailed measures of student achievement in mathematics and science for TIMSS participating education systems, 11 detailed measures of achievement in advanced mathematics and physics for TIMSS Advanced participants; information on educational practices and student outcomes; linking variables between student achievement and background information from students, teachers, school principals, and curriculum experts; and achievement scales on a metric that is common to all cycles of TIMSS and TIMSS Advanced respectively, allowing for the analysis of trends. The international data files are available in two versions: a public-use version and a restricted-use version. The public-use data files are available as SAS export files or SPSS \".sav\" files through https://timssandpirls.bc.edu/timss2015/international-database/ (TIMSS) or https://timssandpirls.bc.edu/timss2015/advanced-international-database/ (TIMSS Advanced). The restricted-use data files are available by request through the IEA Study Data Repository (http://www.iea.nl/data.html). Discussions of these types of data files can be found in the TIMSS 2015 User Guide for the International Database (Foy 2017a) or the TIMSS Advanced 2015 User Guide for the International Database (Foy 2017b). These are the most comprehensive and detailed references for the TIMSS and TIMSS Advanced 2015 data and should be seen as the primary references. The U.S. international data files, which are part of the TIMSS and PIRLS International Study Center international databases, do not include the U.S.-specific adaptations made to a few questions in the questionnaires or the additional questions added to the school and student questionnaires, such as the question on race/ethnicity added to the student questionnaire. In addition, data for Florida are not included in the international data files due to potential confidentiality issues. For users who are only interested in TIMSS and TIMSS Advanced 2015 data pertaining to U.S. and/or Florida, NCES releases the U.S.-specific and Florida data files separately from the international databases mentioned above. In addition to the TIMSS Advanced 2015 data files, a set of the TIMSS Advanced 1995 school and student data files are also provided by NCES for trend analysis purposes. This chapter focuses on the contents of the NCES-released data files."}, {"section_title": "U.S.-Specific and Florida Data Files Released by NCES", "text": "Similar to the TIMSS and PIRLS International Study Center, NCES released the data in two versions: \uf06e public-use data files, which include 1) TIMSS and TIMSS Advanced 2015 U.S. national data, and 2) TIMSS Advanced 1995 U.S. national data. These data are available by download from https://nces.ed.gov/timss/datafiles.asp. The data files are in ASCII format and are named as indicated in Exhibit 5-1. SAS and SPSS codes for reading these data files can also be downloaded from the NCES website. 12 \uf06e restricted-use data files, which include 1) TIMSS and TIMSS Advanced 2015 U.S. national data, 2) TIMSS Advanced 1995 U.S. national data, and 3) Florida 2015 data. These data can only be obtained by completing a restricted-use license agreement with NCES. The restricted-use data files are provided only on CD-ROM or DVD-ROM. These datasets contain the supplemental link files that link TIMSS or TIMSS Advanced school ID numbers to the school ID numbers as they appear in the publicly available Common Core of Data (CCD) or the Private School Universe Survey (PSS). In addition, race/ethnicity is provided with all available categories and free or reduced-price lunch is provided as a continuous variable. Because these data can reveal the identities of participating schools, the restricted-use data files are only made available to those who obtain a NCES restricted-use data license. Directions on how to obtain the license can be found at http://nces.ed.gov/pubsearch/licenses.asp. Exhibit 5-2 lists the restricted-use data files released by NCES. "}, {"section_title": "TIMSS and TIMSS Advanced 2015 Student Achievement Data Files and Variable Names", "text": "The data files contain the IRT-scaled achievement scores for overall mathematics and science/physics, as well as scores for the several mathematics and science/physics content domains and the three mathematics and science/physics cognitive domains. A set of five plausible values characterizes each of these achievement scores. For analytic convenience, these same achievement scores are also provided as an addition to the student background data files. Exhibits 5-3, 5-4, and 5-5 show the nomenclature for identifying the various overall content domain and cognitive domain achievement scale score variables, each of which is represented by five plausible values. The achievement score variable names are based on an eight-character string defined below. In exhibit 5-3, these conventions are illustrated by reference to the first plausible value for each of the total, content domain, and cognitive domain achievement scales at each grade level for TIMSS. In exhibits 5-4 and 5-5, these conventions are illustrated by reference to the first plausible value for each of the total, content domain, and cognitive domain achievement scales at each grade level for TIMSS Advanced. For example, ASMMAT01 is the first plausible value for the fourth-grade mathematics total score, while ASSSCI02 is the second plausible value for the total science score. ASMNUM03 is the third plausible value for the mathematics content domain \"Number,\" and ASSEAR04 is the fourth plausible value for the science content domain \"Earth science.\" Similarly, ASMKNO01 is the first plausible value for the mathematics cognitive domain \"Knowing,\" and ASSAPP05 is the fifth plausible value for the science cognitive domain \"Applying.\""}, {"section_title": "First character of the variable name (ASMMAT01):", "text": "Exhibit "}, {"section_title": "TIMSS and TIMSS Advanced 2015 Benchmark Achievement Variables", "text": "The TIMSS and TIMSS Advanced achievement files also contain a set of variables indicating which international benchmark the students reached. For TIMSS, the overall mathematics and science scales at both grades have five plausible values defined as the international benchmark level reached (Advanced, High, Intermediate, and Low). Similarly, for TIMSS Advanced, the overall advanced mathematics and physics scales have five plausible values defined as the international benchmark level reached (Advanced, High, and Intermediate). The international benchmark variables follow the achievement score variable naming convention but substitute the letters \"IBM\" in the fourth through sixth positions of the variable name. Therefore, ASMIBM01, ASMIBM02, ASMIBM03, ASMIBM04, and ASMIBM05 are the five benchmark variables describing the fourth-grade overall mathematics score. Similarly, BSMIBM01 through BSMIBM05 are the five benchmark variables describing the eighth-grade overall mathematics score, and BSSIBM01 through BSSIBM05 are the five benchmark variables describing the eighth-grade overall science score. For TIMSS Advanced, MSMIBM01 through MSMIBM05 are the five benchmark variables describing the overall advanced mathematics score, and PSPIBM01 through PSPIBM05 are the five benchmark variables describing the overall physics scores. Details for TIMSS are provided in the TIMSS 2015 User Guide for the International Database (Foy 2017a, p. 57) and for TIMSS Advanced in TIMSS Advanced 2015 User Guide for the International Database (Foy 2017b, p. 51-52)."}, {"section_title": "TIMSS and TIMSS Advanced 2015 Background Questionnaire Data Files", "text": "Student, teacher, and school files contain the responses to the questions contained in the respective background questionnaires administered in TIMSS and TIMSS Advanced 2015, along with a file used to link the student and teacher background data appropriately when student and teacher files are merged."}, {"section_title": "TIMSS and TIMSS Advanced 2015 Student Background Data Files", "text": "The student background data files contain students' responses to questions in the student questionnaire along with students' mathematics and science achievement scores (as plausible values). At the fourth grade, there was a single version of the student questionnaire for TIMSS. There were two versions of the student questionnaire at the eighth grade for TIMSS: a version for education systems in which science is taught as an integrated subject (general science version), and another version for education systems in which the sciences (biology or life science, physics, chemistry, and Earth science) are taught separately. For eighth-grade students who were administered the general science version, as was the case for the United States and Florida, questions that appeared only in the separate science version were coded as \"not administered.\" For students in those education systems assigned the separate science versions, questions asked only in the general science version were coded as \"not administered.\" For TIMSS Advanced, there were two versions of the student questionnaire administrated: one for advanced mathematics and one for physics. The student background data files also contain a number of identification variables, tracking variables, sampling and weighting variables, and derived variables that were used to produce some of the exhibits in the international reports."}, {"section_title": "TIMSS and TIMSS Advanced 2015 Teacher Background Data Files", "text": "The mathematics and science teachers of the students sampled for TIMSS 2015 were administered at least one questionnaire for each TIMSS class taught. The teacher background data files contain one record for each of the classes taught. If teachers taught more than one class, they were expected to complete only one set of general background questions (part A), irrespective of the number of classes taught, and a separate part B (class-specific questions) for each class they taught. Responses to the single questionnaire administered to fourth-grade teachers of TIMSS are found in the teacher background data files. Separate TIMSS teacher questionnaires were administered to eighth-grade mathematics and science teachers. The responses of teachers to the mathematics questionnaire are found in the mathematics teacher background data files, and the responses of teachers to the science 5-9 questionnaire are in the science teacher background data files. Variable names for questions repeated in both questionnaires are the same. For TIMSS Advanced, teachers who taught advanced mathematics classes were administered the advanced mathematics teacher background questionnaire that had questions about their background and their teaching practices in the classes of the sampled students. Similarly, teachers who taught physics classes were administered the physics teacher background questionnaire that had questions about their background and their teaching practices in the classes of the sampled students. The responses of teachers to the advanced mathematics questionnaire are found in the advanced mathematics teacher background data files, and the responses of teachers to the physics questionnaire are in the physics teacher background data files. In all of the teacher files, each teacher has a unique identification number (IDTEACH) and a link number (IDLINK) specific to the class taught by the teacher and to which the information in the data record corresponds. The IDTEACH and IDLINK combination uniquely identifies, within an education system, a teacher teaching a specific class. For example, students linked to teachers identified by the same IDTEACH but different IDLINK are taught by the same teacher but in different classes. It is important to note that the teachers in question do not constitute a representative sample of teachers in an education system but rather are the teachers who taught a representative sample of students. To reflect this fact, for the most part, the teacher data should be analyzed only in conjunction with the student-teacher linkage data files and weighted with student sampling weights."}, {"section_title": "TIMSS and TIMSS Advanced 2015 School Background Data Files", "text": "The school background data files contain the responses of school principals to questions about school policy, resources, and environment asked in the school questionnaire. That file also contains a series of identification variables, link variables, and sampling variables. The school data files can be merged with the student data files by using the education system and school identification variables. Details of the merging procedure using the SPSS-linked IEA International Database (IDB) Analyzer or using SAS programs for TIMSS are described in the TIMSS 2015 User Guide for the International Database (Foy 2017a); for TIMSS Advanced, these details are provided in the TIMSS Advanced 2015 User Guide for the International Database (Foy 2017b)."}, {"section_title": "TIMSS and TIMSS Advanced 2015 Student-Teacher Linkage Data Files", "text": "The TIMSS and TIMSS Advanced 2015 student-teacher linkage data files contain information required to link the student and teacher data files. These files contain one entry per student-teacher linkage combination in the data. For instance, if three teachers are linked to a student, there are three entries in the file corresponding to that student. The sole purpose of the student-teacher linkage data files is to link teacher-level data with student-level data to perform appropriate student-level analyses where teacher characteristics are disaggregated over students."}, {"section_title": "TIMSS and TIMSS Advanced 2015 Curriculum Questionnaire Data Files", "text": "In addition to the background questionnaires, TIMSS and TIMSS Advanced 2015 provide data on the curriculum of the participating education systems. For TIMSS there is a separate file for each grade, while for TIMSS Advanced there is a separate file for advanced mathematics and one for physics."}, {"section_title": "Variable Naming Conventions for Background Variables", "text": "The background variable naming convention is based on a seven-or eight-character string defined below. These conventions are illustrated by reference to an item in the fourth-grade school questionnaire. This item asks principals to report the population size of the community in which the school is located. 13 The letters \"B,\" \"C,\" and \"E,\" and \"P\" are used in the eighth-grade student background data files for variables corresponding to questions about separate sciences asked in the separate science version of the student questionnaire. \"P\" is also used in TIMSS Advanced: Physics student background data files for group identification. The letter \"M\" is used in the fourth-and eighth-grade student background data files for variables corresponding to questions about mathematics. It is also used in the TIMSS Advanced: Advanced Mathematics student background data files for group identification. "}, {"section_title": "5-11", "text": ""}, {"section_title": "Summary Indices and Derived Variables", "text": "The TIMSS and TIMSS Advanced 2015 questionnaires often devote several questions to a single construct. In these cases, responses to the individual items were combined to create a derived variable. A TIMSS or TIMSS Advanced index is a special type of derived variable that assigns students to one of three levels-high, medium, or low-on the basis of their responses to the component variables. These variables are described in detail in Supplement 3 of the TIMSS 2015 User Guide for the International Database (Foy 2017a) and in Supplement 3 of the TIMSS Advanced 2015 User Guide for the International Database (Foy 2017b)."}, {"section_title": "Specific Variable Naming Conventions for TIMSS Advanced 1995", "text": ""}, {"section_title": "Background Variables", "text": "Similar to TIMSS and TIMSS Advanced 2015 variables, the naming convention for the TIMSS Advanced 1995 background variables permits the identification of the population and questionnaire from which it was obtained based on 7-or 8-digit codes. However, there are some slight differences. The general definitions of the variable naming conventions for TIMSS Advanced 1995 are indicated below: "}, {"section_title": "Sampling and Weighting Variables", "text": "Several sampling and weighting variables are included in the TIMSS and TIMSS Advanced 2015 data files. They are listed and described below in conjunction with a discussion of how and when these weights are used. Because TIMSS and TIMSS Advanced 2015 use a complex sampling design, sampling weights need to be used to generate accurate population estimates. The sampling weights account for the sample design, any stratification or disproportional sampling of subgroups, and also include adjustments for nonresponse (see Joncas and Foy 2012). As noted, the sample of students is not a simple random sample and, consequently, students in the sample do not have an equal probability of selection. Sampling weights adjust for this unequal probability and, in so doing, provide for statistical estimates reflective of the student population from which the sample was drawn. Sampling weights also include adjustments for school and student nonresponse. All TIMSS and TIMSS Advanced analyses require the application of sampling weights. Provisions for weighting data are a standard feature of virtually all software likely to be used in analyses. The sampling weights included in the TIMSS and TIMSS Advanced 2015 data files are described in exhibits 5-6 and 5-7. Note that teacher background data files do not have any sampling weight variables and teacher weights are located in the student-teacher linkage files. Analyses with teacher data are weighted properly by merging the teacher files with the student-teacher linkage files as described later in this chapter under section 5.11.5, Special Considerations in Using the Teacher Data."}, {"section_title": "5-13", "text": "Exhibit The characteristics of TIMSS and TIMSS Advanced 2015 sampling weight variables are as follows: \uf06e TOTWGT sums to the student population size in each education system and is appropriate for \"within-country\" 14 analyses and \"cross-country\" analyses where the analyses are conducted \"country-by-country\" and compared."}, {"section_title": "5-14", "text": "\uf06e Unlike TOTWGT, SENWGT, and HOUWGT, which are designed for use in studentlevel analyses from all student-level files, SCHWGT is designed for use in schoollevel analyses where the schools are the units of analysis. -TCHWGT, MATWGT, SCIWGT, and PHYWGT are specifically designed for analyses that link teacher background data to student data, for TIMSS and TIMSS Advanced 2015. -TCHWGT is used for analyses using all teachers for TIMSS 2015 grades 4 and 8. -MATWGT and SCIWGT are used for analyses of mathematics and science teachers, respectively, for TIMSS 2015 grades 4 and 8. -MATWGT and PHYWGT are used for analyses of advanced mathematics and physics teachers, respectively, for TIMSS Advanced 2015."}, {"section_title": "Structure and Design Variables in TIMSS and TIMSS Advanced 2015 Data Files", "text": "The TIMSS and TIMSS Advanced 2015 data files also contain unique numerical identification variables for each respondent along with sample design information."}, {"section_title": "Identification Variables", "text": "In all TIMSS and TIMSS Advanced 2015 data files, identification variables are included to label countries, students, teachers, or schools. These variables also are used to link cases between the different data file types. The identification variables are the same across TIMSS and TIMSS Advanced 2015, have the prefix \"ID,\" and are described below. \uf06e IDCNTRY is a six-digit country identification code based on the ISO 3166 classification. \uf06e IDPOP identifies the target grade; \"1\" for the fourth grade, \"2\" for the eighth grade, and \"3\" for TIMSS Advanced. \uf06e IDGRADE identifies the target grade of the participating students; \"4\" and \"8\" for most TIMSS countries and \"12\" for TIMSS Advanced. IDTEACH is a six-digit identification code that uniquely identifies a teacher within a school. \uf06e IDLINK uniquely identifies the class for which a teacher answered a questionnaire."}, {"section_title": "Tracking Variables", "text": "Information about students, teachers, and schools provided by the survey tracking forms described earlier is stored in the tracking variables. These variables have the prefix \"IT.\" All tracking variables are included in the student background data files. ITLANG is included in the student achievement and student background data files. "}, {"section_title": "TIMSS and TIMSS Advanced 2015 Codebook Files", "text": "Each data file released by NCES is accompanied by a codebook file. The codebooks are in the html format. The codebook files for public-use data can be downloaded from https://nces.ed.gov/timss/datafiles.asp. The codebook files for restricted-use data will require users to complete a restricted-use license agreement with NCES. Directions on how to obtain the license can be found at http://nces.ed.gov/pubsearch/licenses.asp."}, {"section_title": "TIMSS and TIMSS Advanced 2015 U.S. Instrumentation", "text": "As noted earlier, the U.S. national instrumentation differs from the international instrumentation in several ways: \uf06e Minor language/expression adaptations were made to some of the instructions on the school, teacher, and student questionnaires."}, {"section_title": "5-16", "text": "\uf06e For a few questionnaire items, response alternatives were changed but in a way that allowed a crosswalk to the international response alternatives."}, {"section_title": "Background Questionnaire Items With U.S. Adaptations to Response Alternatives", "text": "As the description of U.S. national adaptations in appendix E makes clear, there were a number of relatively minor changes to the wording of the international item stems and response alternatives in the questionnaires. Most of these adaptations do not require comment, as they are identical in format between the international and U.S. versions of the questionnaires (for example, they contain simple wording changes). In some cases, however, the adaptations resulted in item response formats not immediately comparable between the international and national versions of the questionnaires. As indicated in appendix E, there are instances in which the international and U.S. versions of variables have different sets of response codes; \"instructional time\" and \"highest level of formal education\" in the teacher questionnaire are two examples. This means that, for these items, the data are not identical in international and U.S. versions of the data files. For the \"instructional time\" item, the U.S. international version recorded total instructional time in minutes only whereas the national version recorded total instructional time in both hours and minutes. There were a few instances where the data in the national variables were changed to be consistent with the international version of the variables. For the \"highest level of formal education\" item, the variable has six response categories in the U.S. international file and seven categories in the U.S. national file. However, as indicated in appendix E, crosswalks between international and U.S. versions of these questions allow for the conversion of the U.S. response codes to the international format."}, {"section_title": "U.S.-Specific Variables", "text": "There are two types of U.S.-specific variables: (1) those with data from a source other than a questionnaire, and (2) those with data collected through questionnaires from national questions added to the international version of the questionnaires."}, {"section_title": "5-18", "text": "Variables with data from sources other than a questionnaire Data collected from school records covered the following: 1. Whether a school was public or private. Information for this variable is derived from the Common Core Data (CCD). Although information about the type of school is available in the school questionnaire with nine separate categories that differentiate the types of public, private, charter, and alternative schools, the derived variable for public or private school provides a collapsed binary indicator for identifying schools as either public or private. Because the 9-category \"type of school\" variable came from the principals' responses while the binary variable is derived from CCD, the data from the former variable may not match the data from the latter one. For example, for the schools with missing data in the 9-category \"type of school\" variable, data are available in the derived variable. This variable is included in the public-use school files."}, {"section_title": "Student English language learner status (ELL)", "text": ". Information for this variable is derived from student lists submitted by the school coordinators of participating schools. This variable is in the restricted-use student files. Coupled with school records, data collected from the College Board provided AP status for the U.S. TIMSS Advanced 2015 students. Two variables are derived based on the course type and AP course taken status (uncollapsed and collapsed). Uncollapsed variable include both AP and IB course categories. This variable provides the highest AP course taken for students who took AP courses. For non-AP students, the variable identifies if they took an IB course (either standard-level or high-level) or another advanced mathematics or physics course. In creating these derived variables, the primary source of data was the school records, which listed the courses taken by the students. If the school records were unclear or missing, then the College Board data collected for the students was checked to see which (if any) AP tests were taken. If there were no College Board data, any additional information collected from the school was used when determining their eligibility to participate in TIMSS Advanced 2015. Collapsed variable only includes AP and non-AP course categories. These variables are in the public-use student files. "}, {"section_title": "Variables with data collected through questionnaires", "text": "U.S.-specific items were added to the student, teacher, and school questionnaires. Nine questions were added to the TIMSS and TIMSS Advanced student questionnaires: 1. a two-part question designed to measure the student's race/ethnicity; 2. a question that asked for language other than English spoken at home; 3. a question about additional activities outside of school (TIMSS grades 4 and 8); 4. a question about participation in science club, science fair, or science competition (TIMSS grades 4 and 8); 5. a question that asked about number of days absent; 5-20 6. a multiple-part question that asked students to indicate whether they had repeated a grade in school (TIMSS grades 4 and 8/TIMSS Advanced student questionnaires). 7. a question that asked students to indicate how hard the test was compared to other tests they have taken this year in school; 8. a question that asked students to indicate how hard did the students try on the test compared to other tests they have taken this year in school; and 9. a question that asked students to indicate the importance of doing well on the test. Specifically for the TIMSS Advanced, six questions were added to the student questionnaires: 1. a multiple-part question that asked students to indicate grade level and courses completed during high school for mathematics and physics courses; 2. a multiple-part question that asked students to indicate Advanced Placement (AP) coursetaking during high school; 3. a question that asked students to indicate online coursetaking for mathematics or science courses; 4. a question that asked students to indicate International Baccalaureate (IB) coursetaking for mathematics or physics courses; 5. a question that asked students to indicate activities related to postsecondary preparation that students took part during the school year; and 6. a question that asked students to indicate extracurricular activities students participated during the school year. One question was added to the TIMSS and TIMSS Advanced teacher questionnaires that asked teachers to identify the year they started teaching. Specifically for the TIMSS grade 8 teacher questionnaires, one question was added to ask teachers to identify the title of the mathematics or science course being taught to the students being assessed. Three questions were added to the TIMSS and TIMSS Advanced school questionnaires: 1. the percentage of students in the school eligible for free or reduced-price lunch; 2. the percentage of students in the school who are English language learners; and 3. a specification of the type of school. Specifically for the TIMSS grades 4 and 8, two additional questions were added to the school questionnaires: 1. a question about the average income level of the school's immediate area; and 2. a multiple-part question about evaluating the practice of teachers. For TIMSS Advanced, one additional question was added to the school questionnaire that asked principals whether their schools have a special program or track to prepare students for courses such as calculus or advanced physics. The following sections include detailed descriptions of the U.S.-specific variables.\nIn TIMSS Advanced 1995, U.S.-specific items were added to the school and student questionnaires. One additional question was added to the school questionnaire that asked principals about expectations for parental involvement at school. Five additional questions were added to the student questionnaires: 1. a question that asked about student's race/ethnicity; 2. a three-part question that asked students about studying mathematics before or after school; 3. a three-part question that asked students about studying science before or after school; 4. a question about time student spent each day on mathematics homework; and 5. a question about time student spent each week on science homework."}, {"section_title": "Race/Ethnicity (TIMSS 4 and 8/TIMSS Advanced Student Questionnaire)", "text": "Students' race/ethnicity was obtained through student responses to a two-part question in the student questionnaire. Students were asked first whether they were Hispanic or Latino and then whether they were members of the following five racial groups: (1) White; (2) Black or African American; (3) Asian; (4) American Indian or Alaska Native; or (5) Native Hawaiian or other Pacific Islander. Multiple responses to the second of these questions were allowed. 16 A composite variable with six categories was constructed in which results are shown separately for (1) Whites; (2) Blacks; (3) Hispanics of any race; (4) Asians; and (5) Multiracial. The sixth category was labeled as \"Other\" and consisted of the small numbers of students indicating that they were American Indian or Alaska Native, and Native Hawaiian or other Pacific Islander. 17"}, {"section_title": "Language Other Than English Spoken at Home (TIMSS 4 and 8/TIMSS Advanced Student Questionnaire)", "text": "This item extended the international question about how often students spoke English at home to ask those students who indicated that they did not always speak English if they spoke Spanish or another language. 18"}, {"section_title": "Additional Outside Activities (TIMSS 4 and 8 Student Questionnaire)", "text": "The measure of outside of school activities was collected using a prompt with four yes/no questions. The prompt states, \"The following questions ask about the activities you do outside of school. The yes/no questions were as follows: \uf06e Do you play on a sports team outside of school? \uf06e Do you play a musical instrument outside of school? 16 Race/ethnicity is provided with all categories in the restricted-use dataset. 17 Race/ethnicity is provided as a composite variable in the public-use dataset. The state benchmarking restricted-use datasets contain both the categorical and composite forms of the variable. 18 At grade 4 and 8, students who responded to items ASBG03 (grade 4) and BSBG03 (grade 8) that they \"always\" speak English at home were supposed to skip items ASXG03B (grade 4) and BSXG03B (grade 8), which ask students to identify the foreign language that they sometimes use at home. However, about 12 percent of students (1246 cases) at grade 4, and 5 percent of students (464 cases) at grade 8 responded that they \"always\" speak English at home and also identified a foreign language that they sometimes use at home. For TIMSS Advanced, less than 4 percent of advanced mathematics students and less than 3 percent of physics students who responded that they \"always\" speak English at home also identified a foreign language that they sometimes use at home. "}, {"section_title": "Number of Days Absent (TIMSS 4 and 8/TIMSS Advanced Student", "text": ""}, {"section_title": "Questionnaire)", "text": "TIMSS and TIMSS Advanced students were asked about their school attendance over the last month prior to the assessment. The students were asked to select one response option. The question and response options were as follows: How many days were you absent from school in the last month? \nEighth-grade students were asked whether they had ever repeated a grade in either \"elementary school\" and/or \"middle or junior high school.\" The response alternatives were yes/no in each case. Students who took TIMSS Advanced were asked the same question, but included an option for \"high school.\"\nTIMSS Advanced students were asked how hard was the TIMSS Advanced assessment compared to most other tests they have taken this year in school. The response options were as follows: \nTIMSS Advanced students were asked how hard they tried on the TIMSS Advanced assessment compared to most other tests they have taken this year in school. The response options were as follows: \nTIMSS Advanced students were asked how important it was to them to do well on the TIMSS Advanced assessment. The response options were as follows:  \nTIMSS and TIMSS Advanced teachers were asked to indicate the year that they started teaching.\nPrincipals were asked to indicate practices that were used to evaluate teachers at their schools in yes/no responses. Following is the list of practices for evaluating teachers: \nIn TIMSS Advanced 1995, principals were asked to indicate graduation requirements in their schools. Following is the list of graduation requirement in the school questionnaire: "}, {"section_title": "Repeating a Grade (TIMSS 4 and 8/TIMSS Advanced Student", "text": ""}, {"section_title": "Difficulty of the Test (TIMSS 4 and 8/TIMSS Advanced Student", "text": ""}, {"section_title": "Effort on the Test (TIMSS 4 and 8/TIMSS Advanced Student", "text": ""}, {"section_title": "Importance of the Test (TIMSS 4 and 8/TIMSS Advanced Student", "text": ""}, {"section_title": "Online Coursetaking (TIMSS Advanced Student Questionnaire)", "text": "TIMSS Advanced students were asked whether they are currently enrolled or have taken online mathematics or science courses. The response options were as follows: Yes, for high school credit; 19 Advanced Placement (AP) Physics B was discontinued in 2014 by the College Board and replaced by AP Physics 1 and 2 for the 2015 exam administration. However, these changes in course titles are not reflected in the TIMSS Advanced 2015 student background questionnaire due to the timing of the study instrument preparations and data collection. TIMSS Advanced students were asked whether they are currently enrolled or have taken an International Baccalaureate (IB) mathematics or science courses. The response options were yes/no."}, {"section_title": "Activities Related to Postsecondary Preparation (TIMSS Advanced Student Questionnaire)", "text": "TIMSS Advanced students were asked to indicate postsecondary education preparation-related activities that students have done during the current school year. Following is the list of activities: "}, {"section_title": "Extracurricular Activities (TIMSS Advanced Student Questionnaire)", "text": "TIMSS Advanced students were asked to indicate whether they have participated in various extracurricular activities during the current school year. Following is the list of extracurricular activities: "}, {"section_title": "Year Started Teaching (TIMSS 4 and 8/TIMSS Advanced Teacher", "text": ""}, {"section_title": "Mathematics Course Taught (TIMSS 8 Teacher Questionnaire)", "text": "Eighth-grade mathematics teachers were asked about the nature of the mathematics course they taught to the TIMSS students. The response alternatives provided were as follows: "}, {"section_title": "Science Course Taught (TIMSS 8 Teacher Questionnaire)", "text": "Eighth-grade science teachers were asked about the nature of the science course they taught to the TIMSS students. The response alternatives provided were as follows: Earth science (e.g., geology, earth and the solar system, fossils)."}, {"section_title": "Poverty Level in Public Schools (Percentage of Students Eligible for", "text": ""}, {"section_title": "Free or Reduced-Price Lunch) (TIMSS 4 and 8/TIMSS Advanced School", "text": "Questionnaire) The measure of poverty level in public schools was obtained from principals' responses to the school questionnaire. The question asked the principal to report, as of approximately October 2014, the percentage of students at the school eligible to receive free or reduced-price lunch through the National School Lunch Program (NSLP). This continuous variable is provided in the restricted-use school file. To provide data for public-use, Common Core Data (CCD) are used to derive a new variable with five categories: (1) less than 10 percent, (2) 10 to 24.9 percent, (3) 25 to 49.9 percent, (4) 50 to 74.9 percent, and (5) 75 percent or more. 20 Because the continuous form of the variable came from the principals' responses while the categorical form of the variable is derived from CCD, the data from the former form may not match the data from the latter form. For example, if data from the school questionnaire is unavailable, information from the CCD is recorded in the public-use school file, but recorded as \"missing\" in the restricted-use school file. The effect of this replacement on the confidentiality of the data was examined as part of the confidentiality analyses described earlier in chapter 4 in Section 4.6.2."}, {"section_title": "Limited-English Proficient (LEP)/English Language Learners (ELL) (TIMSS 4 and 8/TIMSS Advanced School Questionnaire)", "text": "Principals were asked to report the percentage of such students and were provided with the following eight response categories: (1) 0 percent; (2) 1-5 percent; (3) 6-10 percent; (4) 11-25 percent; (5) 26-50 percent; (6) 51-75 percent; (7) 76-90 percent; and (8) over 90 percent. 20 Florida restricted-use datasets contain both the categorical and composite forms of the variable."}, {"section_title": "Type of School (TIMSS 4 and 8/TIMSS Advanced School Questionnaire)", "text": "Principals were asked to identify their schools using one of the following 10 response categories: (1) regular public school; (2) regular public school with magnet program; (3) magnet school or school with special program; (4) special education; (5) alternative curriculum; (6) vocational; (7) charter school; (8) independent private school; (9) religiously affiliated private school; or (10) other school."}, {"section_title": "5.8.24", "text": "Average Income Level of School's Immediate Area (TIMSS 4 and 8"}, {"section_title": "School Questionnaire)", "text": "Principals were asked to indicate the average income level of the school's immediate area using one of the following three response categories: (1) high; (2) medium; or (3) low."}, {"section_title": "Evaluating the Practice of Teachers (TIMSS 4 and 8 School", "text": ""}, {"section_title": "Special Program for Calculus or Advanced Physics (TIMSS Advanced School Questionnaire)", "text": "Principals were asked to indicate whether they have a special program or track to prepare students for courses such as calculus or advanced physics in yes/no response. "}, {"section_title": "Missing Data", "text": "Data derived from the student, school and teacher questionnaires and from the student assessments contain missing data in varying amounts. Four sources of missing data are identified: 1. Not administered. The respondent was not administered the actual item. He or she had no chance to read and answer the question."}, {"section_title": "Imputation", "text": "No imputation for missing values was undertaken. However, missing data on the measure of school poverty (proportion of students eligible for free or reduced-price lunch) reported by schools was replaced as described in the Poverty Level in Public Schools section of this chapter.\nNo imputation for missing values was undertaken for the TIMSS Advanced 1995 data files."}, {"section_title": "TIMSS Advanced 1995 U.S. National Data Files", "text": "As noted earlier, in addition to the TIMSS Advanced 2015 data files, a set of the TIMSS Advanced 1995 school and student data files are provided in public-use and restricted-use data formats for trend analysis purposes. No teacher questionnaire was administered to the teachers of students in their final year of secondary school for TIMSS Advanced 1995; therefore, no teacher data files are available for TIMSS Advanced 1995. "}, {"section_title": "TIMSS Advanced 1995 U.S. National Adapted Variables", "text": "In TIMSS Advanced 1995, U.S.-specific national adaptations were added to replace the international counterpart questionnaire items in the school questionnaires. These national adaptations were created to replace the international questionnaire structure in order to capture U.S.-specific information. Two school questionnaire items had national adaptations added to replace the international questionnaire structure: 1. a multipart question that asked principals to indicate whether mathematics and science courses are available to Grade 12 students in the school; and 2. a multipart question that asked principals to indicate graduation requirements."}, {"section_title": "Courses Available to Grade 12 Students in School (TIMSS Advanced 1995 School Questionnaire)", "text": "In TIMSS Advanced 1995, principals were asked to indicate yes or no on whether a list of mathematics and science courses are available to grade 12 students in their school. Following is the list of courses in the school questionnaire: "}, {"section_title": "Graduation Requirements (TIMSS Advanced 1995 School", "text": ""}, {"section_title": "TIMSS Advanced 1995 U.S.-Specific Variables", "text": "As with TIMSS Advanced 2015, there were two types of U.S.-specific variables in 1995: (1) those with data from a source other than a questionnaire, and (2) those with data collected through questionnaires from national questions added to the international version of the questionnaires. Variables with data from sources other than a questionnaire 1. Information about whether a school is public or private is derived from the Common Core Data (CCD). This variable is in the public-use school files and serves as an indicator of whether a school is public or private."}, {"section_title": "Race/Ethnicity (TIMSS Advanced 1995 Student Questionnaire)", "text": "Students' race/ethnicity was obtained through student responses to a question in the student questionnaire. Students were asked to identify which one of the following five racial/ethnic groups best describes them: (1) White (not Hispanic); (2) Black (not Hispanic); (3) Hispanic; (4) Asian or Pacific Islander; or (5) American Indian or Alaska Native. Alternatively, they could also choose \"Other (specify)\" as one of the choices. Multiple responses to the question choices were not allowed. A derived uncollapsed variable with six categories was constructed in which results are shown separately for (1) White; (2) Black; (3) Hispanic; (4) Asian; and (5) American Indian. The sixth category was labeled as \"Other\" and consisted of the small numbers of students indicating that they were either multiracial or had selected \"Other\" from the response choice. Student race/ethnicity is provided with uncollapsed categories in the restricted-use dataset. For the public-use dataset, student race/ethnicity is provided as a collapsed composite variable with (1) White; (2) Black; (3) Hispanic; (4) Asian; and (5) Other."}, {"section_title": "Studying Mathematics/Science Before or After School (TIMSS Advanced 1995 Student Questionnaire)", "text": "TIMSS Advanced students were asked about studying mathematics and science before or after school. The students were asked to indicate \"yes\" or \"no\" for where they studied, with whom they studied, and specific educational-related home possessions for studying. The yes/no questions for each part were as follows: Think of the last time you studied mathematics/science before or after school. TIMSS Advanced students were asked about how much time they spent each day on mathematics homework. The response options were (1) I am not taking math this year; (2) None; (3) 15 minutes; (4) 30 minutes; (5) 45 minutes; (6) 1 hour; or (7) More than 1 hour."}, {"section_title": "Merging Data Files", "text": "In preparing TIMSS 2015 or TIMSS Advanced 2015 data for analysis it may be necessary to merge two (or more) of the data files named in exhibits 5-1 and 5-2. Not every analysis requires merging of files, however. For example, analyses looking at the relationship between student background and achievement can be done using the student background file alone. However, analyses that examine the relationships between school and/or teacher and/or student characteristics and student achievement require that files be merged. Standard merging procedures as implemented in SPSS, SAS or Stata can be applied. Examples are provided below along with illustrative SAS and SPSS code. (These various merges are facilitated for SPSS and SAS users who choose to work with the IEA International Database [IDB] described below.) The merging procedures illustrated below follow the same pattern as previous TIMSS studies (see Foy 2017a for TIMSS Grades 4 and 8; see Foy 2017b for TIMSS Advanced) and are illustrated with TIMSS grade 8 data. The user needs to replace file names in order to run the merges for TIMSS grade 4 or TIMSS Advanced."}, {"section_title": "5-38", "text": "Exhibit 5-11. Illustrative SPSS code for merging U.S. TIMSS eighth-grade student and school data get file = 'C:\\TIMSS2015\\Data\\T8_SCHOOL15.SAV'. sort cases by IDSCHOOL. save outfile = \"C:\\TIMSS2015\\Data\\SCHOOL.SAV\". get file = 'C:\\TIMSS2015\\Data\\T8_STUDENT15.SAV'. sort cases by IDSCHOOL. save outfile = \"C:\\TIMSS2015\\Data\\STUDENT.SAV\". match files / file= \"C:\\TIMSS2015\\Data\\STUDENT.SAV\" / table= \"C:\\TIMSS2015\\Data\\SCHOOL.SAV\" / by IDSCHOOL. save outfile = 'C:\\TIMSS2015\\Data\\MERGE1.SAV'. "}, {"section_title": "Merging Student and Teacher Data", "text": "In the United States, the TIMSS grades 4 and 8 student samples were based on intact classrooms. The teachers of the students selected in this way are not a sample of teachers and should be seen as the \"teachers of the sampled students.\" To maintain this linkage, merges of teacher and student data must use the student-teacher link file (T8_STD_TCH_LINK15.DAT), which also contains the appropriate teacher sampling weights. Exhibits 5-12 and 5-13 provide illustrative code for merging the student and the mathematics teacher files in SAS and SPSS. The sample code provided illustrates the merge involving the eighth-grade mathematics teacher file with the student file. The same logic applies to a merge involving the science teacher file (T8_STEACHER15.DAT). Additional examples of how to merge the student and teacher files using SAS and SPSS are provided in chapters 2 and 3 of the TIMSS 2015 User Guide for the International Database ((Foy 2017a) and TIMSS Advanced 2015 User Guide for the International Database (Foy 2017b)). In the SAS example, the program creates a temporary SAS dataset (TEACHER) using the permanent mathematics teacher file, T8_MTEACHER15, located in the directory defined as bM6. It then sorts the teacher data by the teacher ID (IDTEACH) and the link ID (IDLINK). A similar procedure is used for the student-teacher link file (STDTCH), using the permanent file T8_STD_TCH_LINK15 in the bM6 directory, which is also sorted by the teacher ID and the link ID. The weight variable for mathematics teachers (MATWGT) is used as a selection variable because mathematics teachers have been selected. The result is a merged file called TEACHMRG with disaggregated teacher data. This file is merged with the student file (STUDENT). The final dataset is a permanent dataset called MERGE2 in the bM6 directory that contains the merged file from TEACHMRG and STUDENT using IDSTUD as the merge variable. The SPSS student-teacher merge in exhibit 5-13 uses a file containing the teacher variables (T8_MTEACHER15.SAV) and sorts the cases by IDTEACH and IDLINK. The file is then saved as TEACHER. The same procedure is used for the student-teacher linkage dataset T8_STD_TCH_LINK15.SAV. The \"match files\" command merges the two files by the ID variables IDTEACH and IDLINK, and the merged output file is saved as TEACHMRG. To include the student data, the student file is selected (T8_STUDENT15.SAV), sorted by IDSTUD and saved as STUDENT. This file is merged with TEACHMRG using IDSTUD to create the final file MERGE2.SAV containing both teacher and student variables. Exhibit 5-13. Illustrative SPSS code for merging U.S. TIMSS eighth-grade student and mathematics teacher data get file = 'C:\\TIMSS2015\\Data\\T8_MTEACHER15.SAV'. sort cases by IDTEACH IDLINK . save outfile = \"C:\\TIMSS2015\\Data\\TEACHER.SAV\". get file = 'C:\\TIMSS2015\\Data\\T8_STD_TCH_LINK15.SAV'. select if MATWGT > 0. sort cases by IDTEACH IDLINK. save outfile= \"C:\\TIMSS2015\\Data\\STDTCH.SAV\". match files / file=\"C:\\TIMSS2015\\Data\\STDTCH.SAV\" / table=\"C:\\TIMSS2015\\Data\\TEACHER.SAV\" / by IDTEACH IDLINK. sort cases by IDSTUD. save outfile = \"C:\\TIMSS2015\\Data\\TEACHMRG.SAV\". get file = \"C:\\TIMSS2015\\Data\\T8_STUDENT15.SAV\". sort cases by IDSTUD. save outfile= \"C:\\TIMSS2015\\Data\\STUDENT.SAV\". match files / file= \"C:\\TIMSS2015\\Data\\TEACHMRG.SAV\" / table= \"C:\\TIMSS2015\\Data\\STUDENT.SAV\" / by IDSTUD. save outfile = \"C:\\TIMSS2015\\Data\\MERGE2.SAV\". "}, {"section_title": "Merging Student, School, and Teacher Data", "text": "In merging student, teacher, and school data together to form a single dataset, the procedures from sections 5.10.1 and 5.10.2 are combined. Exhibits 5-14 and 5-15 show illustrative SAS and SPSS code designed to achieve this three-way merge. Note that the teacher weight variables are specifically designed for using teacher background data in student-level analyses and are located in the student-teacher linkage files not in the teacher background data files. Analyses with teacher data need to be weighted properly by merging the teacher files with the student-teacher linkage files. As in the previous examples, the sample code is based on eighth-grade mathematics teacher file. A merge involving the eighth-grade science teacher file follows the same logic. This example uses the same merging steps as with the previous school and teacher examples (MERGE1 and MERGE2), and then merges the output files by the student ID, IDSTUD, into a final permanent file MERGEALL containing linked student, school, and teacher data at the student level. Exhibit 5-15. Illustrative SPSS code for merging U.S. TIMSS eighth-grade school, mathematics teacher, and student data get file = 'C:\\TIMSS2015\\Data\\T8_SCHOOL15.SAV'. sort cases by IDSCHOOL. save outfile = \"C:\\TIMSS2015\\Data\\SCHOOL.SAV\". get file = 'C:\\TIMSS2015\\Data\\T8_STUDENT15.SAV'. sort cases by IDSCHOOL. save outfile = \"C:\\TIMSS2015\\Data\\STUDENT.SAV\". match files /file= \"C:\\TIMSS2015\\Data\\STUDENT.SAV\" /table= \"C:\\TIMSS2015\\Data\\SCHOOL.SAV\" /by IDSCHOOL. sort cases by IDSTUD(A). save outfile = \"C:\\TIMSS2015\\Data\\MERGE1.SAV\". get file = 'C:\\TIMSS2015\\Data\\T8_MTEACHER15.SAV'. sort cases by IDTEACH IDLINK. save outfile = \"C:\\TIMSS2015\\Data\\TEACHER.SAV\". get file = 'C:\\TIMSS2015\\Data\\T8_STD_TCH_LINK15.SAV'. select if MATWGT > 0. sort cases by IDTEACH IDLINK. save outfile = \"C:\\TIMSS2015\\Data\\STDTCH.SAV\". match files /file= \"C:\\TIMSS2015\\Data\\STDTCH.SAV\" /table= \"C:\\TIMSS2015\\Data\\TEACHER.SAV\" /by IDTEACH IDLINK. sort cases by IDSTUD(A). save outfile = \"C:\\TIMSS2015\\Data\\MERGE2.SAV\". match files /file= \"C:\\TIMSS2015\\Data\\MERGE2.SAV\" /table= \"C:\\TIMSS2015\\Data\\MERGE1.SAV\" /by IDSTUD. save outfile = \"C:\\TIMSS2015\\Data\\MERGEALL.SAV\". "}, {"section_title": "Merging TIMSS or TIMSS Advanced 2015 Data with Restricted-Use Data", "text": "Users who have been granted a license to use the restricted-use TIMSS or TIMSS Advanced 2015 data will receive a restricted-use CD-ROM that contains an additional link file. This file provides a way to merge TIMSS or TIMSS Advanced data with school data from the Common Core of Data (CCD) and the Private School Survey (PSS). The NCESSCH (the NCES unique public school identification code) from the TIMSS or TIMSS Advanced file is used to merge with NCESSCH from the CCD file. The PPIN (the private school's unique identification number) from the TIMSS or TIMSS Advanced file is used to merge with the PPIN from the PSS file. Illustrative SAS and SPSS code is provided in exhibits 5-16 and 5-17."}, {"section_title": "5-44", "text": "Exhibit 5-17. Illustrative SPSS code for merging U.S. TIMSS eighth-grade school data with restricted (CCD and PSS) data get file = 'C:\\TIMSS2015\\Data\\T8_RESTRICTED_USE15_SCH.SAV'. sort cases by NCESSCH. save outfile = \"C:\\TIMSS2015\\Data\\SCHOOL.SAV\". get file = 'C:\\TIMSS2015\\Data\\CCD.SAV'. sort cases by NCESSCH. save outfile = \"C:\\TIMSS2015\\Data\\CCD.SAV\". match files /file= \"C:\\TIMSS2015\\Data\\CCD.SAV\" /table= \"C:\\TIMSS2015\\Data\\SCHOOL.SAV\" /by NCESSCH. save outfile = \"C:\\TIMSS2015\\Data\\MERGE1.SAV\". "}, {"section_title": "Some Notes on Analyzing the TIMSS and TIMSS Advanced 2015 Data", "text": "The design of TIMSS and TIMSS Advanced raises several special considerations for the analysis of TIMSS and TIMSS Advanced data. First, the assessment design necessitates the use of five plausible values rather than a single score for each of the various measures of mathematics and science for grades 4 and 8, and advanced mathematics and physics for TIMSS Advanced. Second, since the sampling design is not a simple random sample in which each student had an equal probability of selection, sampling weights need to be applied to generate unbiased estimates of population parameters. Third, the complex sampling design also means that the calculation of the standard errors of the various statistics generated requires special procedures."}, {"section_title": "Estimating Sampling Variance", "text": "The complex sampling design used in TIMSS and TIMSS Advanced 2015 complicates the task of computing standard errors. Most standard analysis software systems such as SAS and SPSS provide estimates based on the assumption of a simple random sample. Given the TIMSS and TIMSS Advanced sampling design, such standard errors underestimate the true standard errors. TIMSS and TIMSS Advanced adopt the jackknife repeated replication (JRR) technique because it is computationally straightforward and provides approximately unbiased estimates of the sampling errors of means, totals, and percentages. The variables necessary for these JRR procedures are included as part of the TIMSS and TIMSS Advanced 2015 data files: JKZONE, the sampling zone (stratum) of the student's school; and JKREP, the sampling replicate (primary sampling unit) of the student's school. There are, however, several options for estimating sampling errors that avoid the assumption of simple random sampling. The SPSS-and SAS-linked International Database (IDB) Analyzer software is designed specifically by International Association for the Evaluation of Educational Achievement (IEA) for analyzing TIMSS and TIMSS Advanced international data files. This software is freely available from the IEA website at http://www.iea.nl/data.html. Special-use software is also available for estimating the standard errors of statistics generated from complex sampling designs. Among the packages available are AM, available from the American Institutes for Research at http://am.air.org/about2.asp; WesVar, available from Westat at https://www.westat.com/our-work/information-systems/wesvar-support/download-wesvar; and SUDAAN, available from Research Triangle Institute at http://www.rti.org/sudaan. Some software packages provide for these capabilities as well. In addition, SAS macros suitable for this purpose are available as part of the TIMSS 2015 User Guide for the International Database, as well as in the TIMSS Advanced 2015 User Guide for the International Database (Foy 2017a;Foy 2017b). See also the work by Stapleton (2006Stapleton ( , 2008, which suggests procedures that can be used to generate appropriate standard errors for statistics generated by structural equation modeling techniques."}, {"section_title": "5.11.3", "text": "The IEA International Database (IDB) Analyzer and International Data"}, {"section_title": "Explorer (IDE)", "text": "As described in section 5.3.3 and 5.11.2, the IEA IDB Analyzer was developed by the IEA Data Processing and Research Center (IEA DPC) as a plug-in for SPSS and SAS. It can be used in conjunction with SPSS and SAS. It is not a stand-alone analysis system. The IEA IDB Analyzer enables users to combine SPSS and SAS data files and conduct analyses using SPSS and SAS without actually writing programming code. The IEA IDB Analyzer generates SPSS syntax and SAS program that take into account information from the sampling design in the computation of statistics and their standard errors. In addition, the generated SPSS syntax and SAS program makes appropriate use of plausible values for calculating estimates of achievement scores and their standard errors, combining both sampling variance and imputation variance. The IEA IDB Analyzer consists of two modules-a merge module and an analysis module. The merge module is used to create analysis datasets by combining data files of different types and from different countries and selecting subsets of variables for analysis. The analysis module provides procedures for computing various statistics and their standard errors. All statistical procedures offered within the analysis module of the IEA IDB Analyzer make appropriate use of sampling weights, and standard errors are computed using the jackknife repeated replication (JRR) method. Percentages, means, regressions, and correlations may be specified with or without achievement scores. When achievement scores are used, the analyses are performed five times-once for each plausible value-and the results are aggregated to produce accurate estimates of achievement and standard errors that incorporate both sampling and imputation errors. The use of the IEA IDB Analyzer is described in detail with worked examples in chapter 2 of both the TIMSS 2015 User Guide for the International Database and the TIMSS Advanced 2015 User Guide for the International Database (Foy 2017a;Foy 2017b). Readers intending to use this user-friendly software are urged to read this user guide in detail. Researchers who intend to use the IEA IDB Analyzer with SPSS should execute the SPSS programs. Likewise, those who intend to use the IEA IDB Analyzer with SAS should execute the SAS programs described in the chapter 3 of the TIMSS 2015 User Guide for the International Database and the TIMSS Advanced 2015 User Guide for the International Database (Foy 2017a;Foy 2017b). In addition to IEA IDB Analyzer for basic analysis and exploration of TIMSS and TIMSS Advanced data, NCES has developed a relatively simple, interactive online data analysis tool: the International Data Explorer (IDE), which can be found at http://nces.ed.gov/surveys/international/ide. The IDE allows users to analyze all the international variables for all participating education systems and the U.S.-specific variables; however, it does not include U.S. restricted-use data. The IDE does not require SPSS or SAS for analyzing the data. It provides users with the capabilities to create statistical tables and charts of TIMSS and TIMSS Advanced data across countries and years on the website. This tool allows users to point and click in a self-contained module, unlike the IEA IDB Analyzer software that must be used in conjunction with SPSS and SAS. Also unlike the IEA IDB Analyzer, the IDE does not provide access to data files for merging, transforming, or otherwise manipulating data. This tool reports averages for subject by selected variables and exports reports in HTML, Excel, Word, or PDF."}, {"section_title": "SAS Programs and Macros", "text": "The TIMSS 2015 User Guide for the International Database and the TIMSS Advanced 2015 User Guide for the International Database (Foy 2017a; Foy 2017b) also provide assistance for those investigators who wish to conduct their analyses using SAS. The user guide includes a number of SAS programs needed to process the SAS data files, compute survey results, and carry out example analyses. These are described in detail with worked examples in chapter 3 of the user guide. Readers intending to use SAS for their analyses are urged to read this chapter in detail. The following SAS programs and macros are available at https://timssandpirls.bc.edu/timss2015/international-database/downloads/T15_Programs.zip (for TIMSS 2015) and https://timssandpirls.bc.edu/timss2015/advanced-internationaldatabase/downloads/TA15_Programs.zip (for TIMSS Advanced 2015): "}, {"section_title": "Special Considerations in Using the Teacher Data", "text": "The teachers in the TIMSS and TIMSS Advanced 2015 data files are the teachers of nationally representative samples of students and are not representative samples of teachers in the participating countries. As a result, analyses with teacher data should be made with students as the units of analysis and reported in terms of students who are taught by teachers with a particular attribute. When analyzing teacher data, it is first necessary to link the students to their respective teachers. The student-teacher linkage data files were created for this purpose. Since student achievement scores (plausible values), jackknife replication information, and teacher weighting variables are found in the student-teacher linkage data files, it is only necessary to merge the teacher background data files with the student-teacher linkage data files. For analyses linking teacher variables to student background variables, it is also necessary to merge the student background data files with the teacher background data files after having been combined with the student-teacher linkage data files."}, {"section_title": "5-48", "text": "In general, to perform analyses using the teacher background data files, follow the steps below. 1. Identify the variables of interest in the teacher background data files and note any specific national adaptations to the variables. 2. Retrieve the relevant variables from the teacher background data files, including analysis variables, classification variables, identification variables (IDCNTRY, IDTEACH, and IDLINK), and any other variables used in the selection of cases. 3. Retrieve the relevant variables from the student-teacher linkage data files, including plausible values of achievement, classification variables, identification variables (IDCNTRY, IDSTUD, IDTEACH, and IDLINK), sampling (JKZONE and JKREP) and weighting (MATWGT, SCIWGT, or TCHWGT) variables, and any other variables used in the selection of cases. 4. Merge the teacher background data files with the student-teacher linkage data files using the variables IDCNTRY, IDTEACH, and IDLINK. 5. If student background variables also are needed, merge the student background data files with the merged student-teacher data files from the previous step using the variables IDCNTRY and IDSTUD. One further point to note: fourth-grade teachers were given a single questionnaire with mathematics and science sections. If a teacher taught only mathematics or only science to the TIMSS fourth-graders, that teacher would complete only one of these sections. In frequency distributions of the variables in these sections, teachers who did not answer the questions for this reason are shown as \"not administered.\""}, {"section_title": "Special Considerations in Using the School Data", "text": "In general, to perform analyses using the school background data files, follow the steps below. 1. Identify the variables of interest in the school and student background data files and note any specific national adaptations to the variables. 2. Retrieve the relevant variables from the school background data files, including analysis variables, classification variables, identification variables (IDCNTRY and IDSCHOOL), and any other variables used in the selection of cases. 3. Retrieve the relevant variables from the student background data files, including plausible values of achievement, classification variables, identification variables (IDCNTRY and IDSCHOOL), sampling (JKZONE and JKREP) and weighting (TOTWGT) variables, and any other variables used in the selection of cases. 4. Merge the school background data files with the student background data files using the variables IDCNTRY and IDSCHOOL. "}, {"section_title": "Special Considerations in Comparing the TIMSS Advanced 1995 and 2015 Student Data", "text": "As noted previously, in addition to the TIMSS Advanced 2015 data files, a set of the TIMSS Advanced 1995 school and student data files are provided in public-use and restricted-use data formats for trend analysis purposes. The 1995 student files contain a variable, COMPARISON, which serves as an indicator variable if the student can be used for analyses that compare TIMSS Advanced 1995 and 2015 students. A value of one (1) indicates that the student is included in the comparison group, while a value of two (2) indicates the student is not included in the comparison group. As described in chapter 2 of this technical report, the TIMSS Advanced student population is defined based on a student's mathematics and science coursetaking during high school. The target population for advanced mathematics is defined as students in the final year of secondary schooling who have taken courses in advanced mathematics. The target population for physics is defined as students in the final year of secondary schooling who have taken courses in physics. The courses that define the target populations have to cover most, if not all, of the advanced mathematics and physics topics that are outlined in the TIMSS Advanced 2015 Assessment Frameworks (Mullis and Martin 2014). In addition, chapter 2 of this technical report provides sampling information and summarized description of the IEA TIMSS Advanced framework for both advanced mathematics and physics. For the purpose of TIMSS Advanced 2015, participation eligibility for advanced mathematics is defined as students who have taken or were taking a calculus course at the time of the assessment, and for physics is defined as students who have taken or were taking a second-year physics course. To ensure eligibility to participate in the study, the actual courses taken by students are provided by schools and confirmed by both school staff and school course catalogs. The TIMSS Advanced 2015 target population differs from that for TIMSS Advanced 1995, for which students were designated as \"specialists\" in advanced mathematics and/or physics by the school. An advanced mathematics \"specialist\" is defined as a student who has taken a pre-calculus, calculus, or AP calculus course. A physics \"specialist\" is defined as a student who has taken a first-years physics course (which did not include physical science courses, but may have included general physics courses). Student who met criteria for advanced mathematics were eligible to take the advanced mathematics assessment. Student who met criteria for physics were eligible to take the physics assessment. Students who met both criteria of advanced mathematics and physics were considered as \"combined specialists\" and were eligible to take a combined advanced mathematics-and-physics assessment. Students who met neither set of criteria were defined as \"generalists\" (or \"non-specialists\") and were eligible to take the twelfth-grade mathematics and science literacy assessment. Although the trend analysis is conducted on comparable students based on their coursework, the manner in which the coursework has been identified and substantiated differs in the two administrations and should be recognized. The criteria used to identify a subset of the U.S. students in the TIMSS Advanced 1995 population that is comparable with the 2015 sample and to generate the COMPARISON variables in the 1995 student data files are based on the following: \uf06e school identifying the student as a specialist for advanced mathematics and/or physics; and \uf06e student self-reported coursetaking information from the student background questionnaire. As part of the TIMSS Advanced 1995 student background questionnaire, students were asked to report the highest level course taken in mathematics and science during high school. The student responses from the questionnaire were used to differentiate students who took calculus and advanced physics courses. If a school defined a student as an advanced mathematics \"specialist,\" and the student reported taking a calculus course, then the student is included in the advanced mathematics subset that is comparable to the TIMSS Advanced 2015 advanced mathematics sample (i.e., COMPARISONS = 1 in the TA_M_STUDENT95 data file). Similarly, if a school defined a student as a physics \"specialist,\" and the student reported taking a second-year physics, Advanced Placement (AP), or International Baccalaureate (IB) physics course, then the student was included in the physics subset that is comparable to the TIMSS Advanced 2015 physics sample (i.e., COMPARISONS = 1 in the TA_P_STUDENT95 data file). For additional information about TIMSS Advanced 1995 databases, please see the User Guide for the TIMSS International Database-Final Year of Secondary School (Gonzalez, Smith, and Sibberns 1998). The United States is participating in an important international study in 2015: the Trends in International Mathematics and Science Study (TIMSS). TIMSS is the longest ongoing international assessment of student achievement in mathematics and science. Since 1995, TIMSS has measured trends in academic achievement at grades 4 and 8 in countries around the world, including the United States. In 2015, TIMSS will also assess advanced mathematics and physics at grade 12. Known as TIMSS Advanced, this 12th-grade assessment will provide education policymakers with valuable information about how many high school students are excelling at highly specialized science, technology, engineering, and mathematics (STEM) content in a global context. Results from these assessments are used by researchers and policymakers to chart national progress against international standards and other countries around the world, informing national discussions about international competitiveness. Some schools in your state have been randomly selected to participate in TIMSS in spring 2015. I am writing to ask your agency to support the participation of those selected schools. TIMSS is described in more detail in the enclosed materials. In the United States, TIMSS is sponsored by the National Center for Education Statistics (NCES), part of the U.S. Department of Education, and is conducted by Westat, a research organization based in Rockville, Maryland. The U.S. Office of Management and Budget has approved the data collection under OMB #1850-0695. For information on the confidentiality of the data collected, please see the enclosed FAQ. While participation in this study is voluntary, your support of school participation in your state is invaluable so that the United States has a representative sample of schools across the country. Within the next few weeks, your NAEP State Coordinator will contact sampled school districts to inform them of their schools selection for the assessment. In the meantime, if you have questions about the study, please do not hesitate to call Dr. Chris Averett at 240-314-2492 or send an email to TIMSS@westat.com. You may also get more information about these studies I am writing to notify you that (number) schools in your district have been randomly selected to participate in the 2015 administration of an important international study in 2015: the Trends in International Mathematics and Science Study (TIMSS). TIMSS is the longest ongoing international assessment of student achievement in mathematics and science. Since 1995, TIMSS has measured trends in academic achievement at grades 4 and 8 in countries around the world, including the United States. In 2015, TIMSS will also assess advanced mathematics and physics at grade 12. Known as TIMSS Advanced, this 12th-grade assessment will provide education policymakers with valuable information about how many high school students are excelling at highly specialized science, technology, engineering, and mathematics (STEM) content in a global context. Results from these assessments are used by researchers and policymakers to chart national progress against international standards and other countries around the world, informing national discussions about international competitiveness. Selected schools are notified in advance so that principals can place the assessment window on their calendars and incorporate TIMSS into the planned school program. I am writing to ask for your support of the participation of those selected schools. Each school will receive a confidential report with information about how its students performed on TIMSS 2015's released items (i.e., questions made public after the assessment). Information about how students performed across the United States and in other participating countries on those same released items will be made public, and schools can compare their students' performance on the released items against those national and international results (provided the school meets response rate and sample size requirements). Participating schools will receive $200, and each school's TIMSS school coordinator (the school staff person designated to work with TIMSS representatives) will receive $100 as a thank you for his or her time and effort. Each student who participates will receive a small gift as a token of appreciation. TIMSS is described in more detail in the enclosed materials. In the United States, TIMSS is sponsored by the National Center for Education Statistics (NCES), part of the U.S. Department of Education, and is conducted by Westat, a research organization based in Rockville, Maryland. The U.S. Office of Management and Budget has approved the data collection under OMB #1850-0695. For information on the confidentiality of the data collected, please see the enclosed FAQ. While participation in this study is voluntary, your support of school participation in your district is invaluable so that the United States has a representative sample of schools across the country. The schools will be contacted soon with more information about the TIMSS assessment. The list of selected schools from your district is attached. Please include the TIMSS assessment window (March 30 to May 29, 2015) on your district test calendar. (Name), our NAEP State Coordinator, will contact your staff with additional information. If you have any questions, please do not hesitate to contact me, or the toll-free TIMSS information hotline at 855-445-5604 or TIMSS@westat.com. You may also get more information about this study by contacting Dr. Stephen Provasnik at NCES at 202-502-7480 or stephen.provasnik@ed.gov, or by visiting the TIMSS website at http://nces.ed.gov/timss/. I know that I can count on you to help accomplish our goal of 100 percent participation. Thank you for your time and support. I am writing to inform you that (school name) has been selected to represent schools across the United States by participating in an important international study in 2015: the Trends in International Mathematics and Science Study (TIMSS). TIMSS is the longest ongoing international assessment of student achievement in mathematics and science. Since 1995, TIMSS has measured trends in academic achievement at grades 4 and 8 in countries around the world, including the United States. Results from these assessments are used by researchers and policymakers to chart national progress against international standards and other countries around the world, informing national discussions about international competitiveness."}, {"section_title": "SCHOOL LETTERHEAD", "text": "Dear Parent or Guardian, This letter is to inform you about an important international study of student learning being conducted in our school this spring. The Trends in International Mathematics and Science Study (TIMSS) provides important information for benchmarking student performance in mathematics and science at grades 4 and 8 in the United States against countries around the world. Since 1995, TIMSS has measured worldwide trends in student knowledge of mathematics and science. The next TIMSS assessment will be in spring 2015. Our school has accepted an invitation from the National Center for Education Statistics (NCES), part of the U.S. Department of Education, to participate in TIMSS 2015. {Insert number} of our 4th-grade classes will take part. {This/One of these} is your child's class. The enclosed summary sheet provides some background information about TIMSS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. To have an accurate picture of what U.S. 4th-graders can do in mathematics and science, it is important that each student selected take part in the study. In addition to answering mathematics and science questions, students will be asked to complete a brief questionnaire about themselves. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students enjoy taking part, and participating students will receive a small gift that we think they will like. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed or used in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Thank you for taking the time to learn about this important study. Estimado padre/madre o tutor, Por medio de la presente queremos informarle acerca de un importante estudio internacional que se realizar\u00e1 en nuestra escuela esta primavera acerca del aprendizaje de los estudiantes. El Estudio Internacional sobre las Tendencias en Matem\u00e1ticas y Ciencias (TIMSS, por sus siglas en ingl\u00e9s) proporciona informaci\u00f3n importante para evaluar el rendimiento de los estudiantes de 4\u00b0 y 8\u00b0 grado en Estados Unidos en matem\u00e1ticas y ciencias en comparaci\u00f3n con otros pa\u00edses del mundo. Desde 1995, TIMSS ha medido las tendencias a nivel mundial en el aprendizaje de los estudiantes de matem\u00e1ticas y ciencias. Nuestra escuela ha aceptado una invitaci\u00f3n del Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s), parte del Departamento de Educaci\u00f3n de Estados Unidos, para participar en TIMSS 2015. Participar\u00e1n {Insert number} de nuestras clases de 4\u00b0 grado. {Esta/Una de estas} es la clase de su hijo. El resumen adjunto ofrece informaci\u00f3n de trasfondo de TIMSS, explica lo que implica la participaci\u00f3n en el estudio para cada estudiante seleccionado e incluye un n\u00famero de tel\u00e9fono y un correo electr\u00f3nico de contacto donde usted podr\u00e1 encontrar respuestas a cualquier pregunta que tenga. Para tener una imagen precisa de lo que los estudiantes de 4\u00b0 grado en Estados Unidos pueden hacer en matem\u00e1ticas y ciencias, es importante que cada estudiante seleccionado participe en el estudio. Adem\u00e1s de contestar las preguntas de matem\u00e1ticas y ciencias, a los estudiantes se les pedir\u00e1 que contesten un cuestionario corto acerca de ellos mismos. Quisi\u00e9ramos pedirle que apoye esta iniciativa animando a su hijo a participar; sin embargo, la participaci\u00f3n en este estudio es completamente voluntaria. Las experiencias anteriores sugieren que los estudiantes disfrutan de la participaci\u00f3n. Adem\u00e1s, los estudiantes que participen recibir\u00e1n un peque\u00f1o regalo que creemos les gustar\u00e1. This letter is to inform you about an important international study of student learning being conducted in our school this spring. The Trends in International Mathematics and Science Study (TIMSS) provides important information for benchmarking student performance in mathematics and science at grades 4 and 8 in the United States against countries around the world. Since 1995, TIMSS has measured worldwide trends in student knowledge of mathematics and science. The next TIMSS assessment will be in spring 2015. Our school has accepted an invitation from the National Center for Education Statistics (NCES), part of the U.S. Department of Education, to participate in TIMSS 2015. {Insert number} of our 8th-grade classes will take part. {This/One of these} is your child's class. The enclosed summary sheet provides some background information about TIMSS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. To have an accurate picture of what U.S. 8th-graders can do in mathematics and science, it is important that each student selected take part in the study. In addition to answering mathematics and science questions, students will be asked to complete a brief questionnaire about themselves. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students enjoy taking part, and participating students will receive a small gift that we think they will like. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed or used in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Thank you for taking the time to learn about this important study. Estimado padre/madre o tutor, Por medio de la presente queremos informarle acerca de un importante estudio internacional que se realizar\u00e1 en nuestra escuela esta primavera acerca del aprendizaje de los estudiantes. El Estudio Internacional sobre las Tendencias en Matem\u00e1ticas y Ciencias (TIMSS, por sus siglas en ingl\u00e9s) proporciona informaci\u00f3n importante para evaluar el rendimiento de los estudiantes de 4\u00b0 y 8\u00b0 grado en Estados Unidos en matem\u00e1ticas y ciencias en comparaci\u00f3n con otros pa\u00edses del mundo. Desde 1995, TIMSS ha medido las tendencias a nivel mundial en el aprendizaje de los estudiantes de matem\u00e1ticas y ciencias. Nuestra escuela ha aceptado una invitaci\u00f3n del Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s), parte del Departamento de Educaci\u00f3n de Estados Unidos, para participar en TIMSS 2015. Participar\u00e1n {Insert number} de nuestras clases de 8\u00b0 grado. {Esta/Una de estas} es la clase de su hijo. El resumen adjunto ofrece informaci\u00f3n de trasfondo de TIMSS, explica lo que implica la participaci\u00f3n en el estudio para cada estudiante seleccionado e incluye un n\u00famero de tel\u00e9fono y un correo electr\u00f3nico de contacto donde usted podr\u00e1 encontrar respuestas a cualquier pregunta que tenga. Para tener una imagen precisa de lo que los estudiantes de 8\u00b0 grado en Estados Unidos pueden hacer en matem\u00e1ticas y ciencias, es importante que cada estudiante seleccionado participe en el estudio. Adem\u00e1s de contestar las preguntas de matem\u00e1ticas y ciencias, a los estudiantes se les pedir\u00e1 que contesten un cuestionario corto acerca de ellos mismos. Quisi\u00e9ramos pedirle que apoye esta iniciativa animando a su hijo a participar; sin embargo, la participaci\u00f3n en este estudio es completamente voluntaria. Las experiencias anteriores sugieren que los estudiantes disfrutan de la participaci\u00f3n. Adem\u00e1s, los estudiantes que participen recibir\u00e1n un peque\u00f1o regalo que creemos les gustar\u00e1. This letter is to inform you about an important international study of student learning being conducted in our school this spring. The Trends in International Mathematics and Science Study (TIMSS) provides important information for benchmarking student performance in mathematics and science in the United States against countries around the world. Since 1995, TIMSS has measured worldwide trends in student knowledge of mathematics and science at grades 4 and 8. The next TIMSS assessment will be in spring 2015 and will include TIMSS Advanced at grade 12. TIMSS Advanced measures advanced mathematics and physics achievement for students in their final year of secondary school. It will provide information about how many students are excelling at highly specialized science and mathematics content in comparison with countries around the world. In the United States, TIMSS Advanced students have taken or are taking calculus or an advanced physics course. Our school has accepted an invitation from the National Center for Education Statistics (NCES), U.S. Department of Education, to participate in TIMSS Advanced 2015. A select number of our high-achieving students will participate, along with your teenager. The enclosed summary sheet provides some background information about TIMSS Advanced, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. To have an accurate picture of what U.S. 12th-graders who have taken calculus or advanced physics can do, it is important that each student selected take part in the study. In addition to answering mathematics and physics questions, students will be asked to complete a brief questionnaire about themselves. I urge you to support this effort by encouraging your teenager to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students enjoy taking part, and participating students will receive a small gift that we think they will like. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed or used in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Thank you for taking the time to learn about this important study. Estimado padre/madre o tutor, Por medio de la presente queremos informarle acerca de un importante estudio internacional que se realizar\u00e1 en nuestra escuela esta primavera acerca del aprendizaje de los estudiantes. El Estudio Internacional sobre las Tendencias en Matem\u00e1ticas y Ciencias (TIMSS, por sus siglas en ingl\u00e9s) proporciona informaci\u00f3n importante para evaluar el rendimiento de los estudiantes en Estados Unidos en matem\u00e1ticas y ciencias en comparaci\u00f3n con otros pa\u00edses del mundo. Desde 1995, TIMSS ha medido las tendencias a nivel mundial en el aprendizaje de los estudiantes de matem\u00e1ticas y ciencias en 4\u00b0 y 8\u00b0 grado. La pr\u00f3xima evaluaci\u00f3n TIMSS en la primavera de 2015 incluir\u00e1 TIMSS \"Advanced\" para 12\u00b0 grado. TIMSS \"Advanced\" mide los logros de los estudiantes en matem\u00e1ticas y f\u00edsica avanzadas en su \u00faltimo a\u00f1o de escuela secundaria. Proporcionar\u00e1 informaci\u00f3n acerca de cu\u00e1ntos estudiantes se distinguen en cursos altamente especializados de ciencias y matem\u00e1ticas en comparaci\u00f3n con otros pa\u00edses del mundo. En Estados Unidos, los estudiantes en TIMSS Advanced han tomado o est\u00e1n tomando un curso de c\u00e1lculo o de f\u00edsica avanzada. Nuestra escuela ha aceptado una invitaci\u00f3n del Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s) del Departamento de Educaci\u00f3n de Estados Unidos para participar en TIMSS \"Advanced\" 2015. Participar\u00e1 un n\u00famero selecto de nuestros estudiantes de alto rendimiento, junto con su hijo. El resumen adjunto ofrece informaci\u00f3n de trasfondo de TIMSS \"Advanced\", explica lo que implica la participaci\u00f3n en el estudio para cada estudiante seleccionado e incluye un n\u00famero de tel\u00e9fono y un correo electr\u00f3nico de contacto donde usted podr\u00e1 encontrar respuestas a cualquier pregunta que tenga. Para tener una imagen precisa de lo que pueden hacer los estudiantes de 12\u00b0 grado en Estados Unidos que han tomado c\u00e1lculo o f\u00edsica avanzada, es importante que cada estudiante seleccionado participe en el estudio. Adem\u00e1s de contestar las preguntas de matem\u00e1ticas y f\u00edsica, a los estudiantes se les pedir\u00e1 que contesten un cuestionario corto acerca de ellos mismos. Quisi\u00e9ramos pedirle que apoye esta iniciativa animando a su hijo a participar; sin embargo, la participaci\u00f3n en este estudio es completamente voluntaria. Las experiencias anteriores sugieren que los estudiantes disfrutan de la participaci\u00f3n. Adem\u00e1s, los estudiantes que participen recibir\u00e1n un peque\u00f1o regalo que creemos les gustar\u00e1. This letter is to inform you about an important international study of student learning being conducted in our school this spring. The Trends in International Mathematics and Science Study (TIMSS) provides important information for benchmarking student performance in mathematics and science at grades 4 and 8 in the United States against countries around the world. Since 1995, TIMSS has measured worldwide trends in student knowledge of mathematics and science. The next TIMSS assessment will be in the spring of 2015. Our school has accepted an invitation from the National Center for Education Statistics (NCES), part of the U.S. Department of Education, to participate in the TIMSS 2015 main study. {Insert number} of our 4th grade classes will take part. {This/One of these} is your child's class. The enclosed summary sheet provides some background information about TIMSS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. To have an accurate picture of what U.S. 4th graders can do in mathematics and science, it is important that each student selected take part in the study. In addition to answering mathematics and science questions, students will be asked to complete a brief questionnaire about themselves. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. If you have any objection to your child joining in the TIMSS activities, please let us know by completing the attached consent form and returning it to the school. Thank you for taking the time to learn about this important study. This letter is to inform you about an important international study of student learning being conducted in our school this spring. The Trends in International Mathematics and Science Study (TIMSS) provides important information for benchmarking student performance in mathematics and science at grades 4 and 8 in the United States against countries around the world. Since 1995, TIMSS has measured worldwide trends in student knowledge of mathematics and science. The next TIMSS assessment will be in the spring of 2015. Our school has accepted an invitation from the National Center for Education Statistics (NCES), part of the U.S. Department of Education, to participate in the TIMSS 2015 main study. {Insert number} of our 8th grade classes will take part. {This/One of these} is your child's class. The enclosed summary sheet provides some background information about TIMSS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. To have an accurate picture of what U.S. 8th graders can do in mathematics and science, it is important that each student selected take part in the study. In addition to answering mathematics and science questions, students will be asked to complete a brief questionnaire about themselves. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. If you have any objection to your child joining in the TIMSS activities, please let us know by completing the attached consent form and returning it to the school. Thank you for taking the time to learn about this important study. This letter is to inform you about an important international study of student learning being conducted in our school this spring. The Trends in International Mathematics and Science Study (TIMSS) provides important information for benchmarking student performance in mathematics and science in the United States against countries around the world. Since 1995, TIMSS has measured worldwide trends in student knowledge of mathematics and science at grades 4 and 8. The next TIMSS assessment will be in the spring of 2015 and will include TIMSS Advanced at grade 12. TIMSS Advanced measures advanced mathematics and physics achievement for students in their final year of secondary school. It will provide information about how many students are excelling at highly specialized science and mathematics content in comparison with countries around the world. In the United States, TIMSS Advanced students have taken or are taking calculus, or an advanced physics course. Our school has accepted an invitation from the National Center for Education Statistics (NCES), U.S. Department of Education, to participate in the TIMSS Advanced main study. A select few of our highachieving students will participate, along with your teenager. The enclosed summary sheet provides some background information about TIMSS Advanced, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. To have an accurate picture of what U.S. 12 th graders who have taken calculus or advanced physics can do, it is important that each student selected take part in the study. In addition to answering mathematics and physics questions, students will be asked to complete a brief questionnaire about themselves. I urge you to support this effort by encouraging your teenager to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. If you have any objection to your teenager joining in the TIMSS activities, please let us know by completing the attached consent form and returning it to the school. Thank you for taking the time to learn about this important study. This letter is to inform you about an important international study of student learning being conducted in our school this spring. The Trends in International Mathematics and Science Study (TIMSS) provides important information for benchmarking student performance in mathematics and science at grades 4 and 8 in the United States against countries around the world. Since 1995, TIMSS has measured worldwide trends in student knowledge of mathematics and science. The next TIMSS assessment will be in the spring of 2015. Our school has accepted an invitation from the National Center for Education Statistics (NCES), part of the U.S. Department of Education, to participate in the TIMSS main study. {Insert number} of our 4 thgrade classes will take part. {This/One of these} is your child's class. The enclosed summary sheet provides some background information about TIMSS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. To have an accurate picture of what U.S. 4th graders can do in mathematics and science, it is important that each student selected take part in the study. In addition to answering mathematics and science questions, students will be asked to complete a brief questionnaire about themselves. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Before we can allow your child to join in the TIMSS activities, we must have your written consent. Please let us know by completing the attached form and returning it to the school. Thank you for taking the time to learn about this important study and to consider your child's participation in it. This letter is to inform you about an important international study of student learning being conducted in our school this spring. The Trends in International Mathematics and Science Study (TIMSS) provides important information for benchmarking student performance in mathematics and science at grades 4 and 8 in the United States against countries around the world. Since 1995, TIMSS has measured worldwide trends in student knowledge of mathematics and science. The next TIMSS assessment will be in the spring of 2015. Our school has accepted an invitation from the National Center for Education Statistics (NCES), part of the U.S. Department of Education, to participate in the TIMSS 2015 main study. {Insert number} of our 8th-grade classes will take part. {This/One of these} is your child's class. The enclosed summary sheet provides some background information about TIMSS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. To have an accurate picture of what U.S. 8th graders can do in mathematics and science, it is important that each student selected take part in the study. In addition to answering mathematics and science questions, students will be asked to complete a brief questionnaire about themselves. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Before we can allow your child to join in the TIMSS activities, we must have your written consent. Please let us know by completing the attached form and returning it to the school. Thank you for taking the time to learn about this important study and to consider your child's participation in it. This letter is to inform you about an important international study of student learning being conducted in our school this spring. The Trends in International Mathematics and Science Study (TIMSS) provides important information for benchmarking student performance in mathematics and science in the United States against countries around the world. Since 1995, TIMSS has measured worldwide trends in student knowledge of mathematics and science at grades 4 and 8. The next TIMSS assessment will be in the spring of 2015, and will include a TIMSS Advanced component at grade 12. TIMSS Advanced measures advanced mathematics and physics achievement for students in their final year of secondary school. It will provide information about how many students are excelling at highly specialized science and mathematics content in comparison with countries around the world. In the United States, TIMSS Advanced students have taken or are taking calculus, or an advanced physics course. Our school has accepted an invitation from the National Center for Education Statistics (NCES), U.S. Department of Education, to participate in the TIMSS Advanced main study. A select few of our high achieving students will participate, along with your teenager. The enclosed summary sheet provides some background information about TIMSS Advanced, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. To have an accurate picture of what U.S. 12 th graders who have taken calculus or advanced physics can do, it is important that each student selected take part in the study. In addition to answering mathematics and physics questions, students will be asked to complete a brief questionnaire about themselves. I urge you to support this effort by encouraging your teenager to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Before we can allow your teenager to join in the TIMSS activities, we must have your written consent. Please let us know by completing the attached form and returning it to the school. Thank you for taking the time to learn about this important study and to consider your teenager's participation in it. Sincerely, Between March and May 2015, your child's school will be one of several hundred schools nationwide taking part in the Trends in International Mathematics and Science Study (TIMSS). The schools were selected randomly to represent the nation's schools and, within each school, fourth-or eighth-grade students were selected randomly to represent the nation's fourth-or eighth-graders. Your child was among those students selected to take part in TIMSS."}, {"section_title": "What is TIMSS?", "text": "TIMSS is an international assessment that measures student learning in mathematics and science. Every 4 years since 1995, TIMSS documents worldwide trends in the mathematics and science achievement of fourth and eighth-graders. The National Center for Education Statistics within the U.S. Department of Education sponsors U.S. participation in TIMSS. Along with more than 50 other countries, the United States will take part in the 2015 TIMSS cycle as we did in 1995, 1999, 2003, 2007, and 2011. What is the purpose of TIMSS 2015? TIMSS measures trends in mathematics and science achievement at the fourth-and eighth-grade levels as well as collects information about school and teacher practices related to instruction. It provides a unique opportunity to compare U.S. students' math and science knowledge and skills at the fourth-and eighth-grade levels with that of their peers in countries around the world. TIMSS complements what we learn from national assessments by identifying the strengths and weaknesses of student performance relative to students around the world. The results inform national discussions about education as well as international competitiveness. What is involved? TIMSS staff will visit the school and administer the study, which will take approximately 2\u00bd hours. The assessment itself is 90 minutes, with breaks between sections. Students will also be asked some questions about themselves and their educational experience.\nTIMSS is an international assessment that measures student learning in mathematics and science. Every 4 years since 1995, TIMSS documents worldwide trends in the mathematics and science achievement of fourth-and eighth-graders. The National Center for Education Statistics within the U.S. Department of Education sponsors U.S. participation in TIMSS. Along with more than 50 other countries, the United States will take part in the 2015 TIMSS cycle as we did in 1995, 1999, 2003, 2007, and 2011. TIMSS 2015 will include the TIMSS Advanced component, which will be administered to twelfth-graders. What is the purpose of the TIMSS Advanced? TIMSS Advanced measures advanced mathematics and physics achievement for students in their final year of secondary school. It will provide information about how many students are excelling at highly specialized science and mathematics content in comparison with countries around the world. In the United States, TIMSS Advanced students have taken or are taking calculus or an advanced physics course. What is involved? TIMSS staff will visit the school and administer the study, which will take approximately 2\u00bd hours. The assessment itself is 90 minutes, with breaks between sections. Students will also be asked some questions about themselves and their educational experience.\nThe Trends in International Mathematics and Science Study (TIMSS) is an international assessment and research project designed to measure trends in mathematics and science achievement at the fourth-and eighth-grade levels as well as collect information about school and teacher practices related to instruction. Since 1995, TIMSS has been administered every 4 years. TIMSS 2015, the sixth study in the series, will involve students from more than 50 countries, including the United States. "}, {"section_title": "What are the benefits?", "text": "The nation as a whole benefits from TIMSS by having a greater understanding of how the knowledge and skills of U.S. fourth-and eighth-graders compare with fourth-and eighth-graders from other countries. Schools that participate in TIMSS will receive $200, and each student who participates will receive a small gift that we believe they will like. The entire assessment is administered by trained staff from Westat, a research organization under contract to the U.S. Department of Education's National Center for Education Statistics. All of the information collected is safeguarded, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (ESRA, 2002), 20 U.S. Code, Section 9543. Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose except as required by law (20 U.S.C., \u00a7 9573). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole.\nThe nation as a whole benefits from TIMSS by having a greater understanding of how the knowledge and skills of the best prepared U.S. twelfth-graders compare with twelfth-graders from other countries who have taken specialized mathematics and science courses. Schools that participate in TIMSS will"}, {"section_title": "Why is TIMSS important?", "text": "TIMSS provides a unique opportunity to compare U.S. students' math and science knowledge and skills at the fourth-and eighth-grade levels with that of their peers in countries around the world. TIMSS complements what we learn from national assessments by identifying the strengths and weaknesses of student performance relative to students around the world. The results inform national discussions about education as well as international competitiveness. TIMSS provides valuable benchmark information on how U.S. students compare to students around the world, allows educators and policymakers to examine other educational systems for practices that could have application to the United States, and contributes to ongoing discussions of ways to improve the quality of education of all students."}, {"section_title": "What type of assessment is TIMSS?", "text": "The TIMSS mathematics and science assessment is developed through an international consensusbuilding process involving input from U.S. and international experts in mathematics, science, and measurement. In a final step, the assessment is endorsed as suitable by all participating countries. The assessment contains a mix of questions; some require students to select appropriate responses while others require that students solve problems and provide written answers. Examples of released TIMSS items are available at http://nces.ed.gov/ timss/educators.asp."}, {"section_title": "Key findings from TIMSS 2011 Mathematics", "text": "\u2022 At grade 4, the U.S. average mathematics score (541) was higher than the TIMSS scale "}, {"section_title": "Science", "text": "\u2022 At grade 4, the U.S. average science score (544) was higher than the TIMSS scale average of 500. The United States was among the top 10 education systems (6 education systems had higher averages and 3 were not measurably different) and scored higher, on average, than 47 education systems. The U.S. science average score at grade 4 was not measurably different than in 2007. \u2022 At grade 8, the U.S. average science score (525) was higher than the TIMSS scale average of 500. The Trends in International Mathematics and Science Study (TIMSS) is an international assessment and research project designed to measure trends in mathematics and science achievement at the fourthand eighth-grade levels as well as collect information about school and teacher practices related to instruction. Since 1995, TIMSS has been administered every 4 years. TIMSS 2015, the sixth study in the series, will involve students from more than 50 countries, including the United States."}, {"section_title": "Why was my school selected for participation?", "text": "Schools of varying demographics and locations were randomly selected so that the overall U.S. sample is representative of the overall U.S. school population. The random selection process is important for ensuring that a country's sample accurately reflects its schools and, therefore, can fairly be compared with samples of schools from other countries.\nSchools of varying demographics and locations were randomly selected so that the overall U.S. sample is representative of the overall U.S. school population. The random selection process is important for ensuring that a country's sample accurately reflects its schools and, therefore, can fairly be compared with samples of schools from other countries. Will all our twelfth-grade students be asked to participate? No. Only twelfth-grade students who have taken or are taking calculus or advanced physics courses are eligible to participate. A sample of eligible students will be selected for each subject: advanced mathematics and physics. The teacher and school questionnaires are administered online from a secure website. Teacher questionnaires take about 35 minutes to complete and ask teachers questions about their experience, available resources, and instructional practices. School questionnaires take about 30 minutes to complete and ask about school practices and resources."}, {"section_title": "Will all our fourth-or eighth-grade students be asked to participate?", "text": "It depends on the number of fourth-or eighth-grade classrooms in the school. In schools with only one or two such classrooms, all students will be asked to participate. In schools with more than two such classrooms, only students in two randomly selected classrooms will be asked to participate. In addition, some students with special needs or limited English proficiency may be excused from the assessment."}, {"section_title": "Who conducts the TIMSS assessment?", "text": "The entire assessment process will be conducted by trained staff from Westat, a research organization under contract with the National Center for Education Statistics in the U.S. Department of Education. NCES is authorized to conduct this study under the Education The teacher and school questionnaires are administered online from a secure website. Teacher questionnaires take about 35 minutes to complete and ask teachers questions about their experience, available resources, and instructional practices. School questionnaires take about 30 minutes to complete and ask about school practices and resources."}, {"section_title": "Do teachers need to help administer the assessment?", "text": "No. Westat field staff will visit the school on the day of the assessment, bringing with them all the materials required, and they will handle the entire administration of the assessment.\nNo. Westat field staff will visit the school on the day of the assessment, bringing with them all the materials required, and they will handle the entire administration of the assessment. When will the assessment be conducted? The assessment will be conducted between March 30 and May 29, 2015. Each school will be notified of its scheduled assessment date in summer 2014. A TIMSS representative will work with schools to identify an alternate date should there be a conflict on that date. Where will the assessment be conducted? The assessment will be conducted in the schools that are selected to participate."}, {"section_title": "When will the assessment be conducted?", "text": "The assessment will be conducted between March 30 and May 29, 2015. Each school will be notified of its scheduled assessment date in summer 2014. A TIMSS representative will work with schools to identify an alternate date should there be a conflict on that date."}, {"section_title": "Where will the assessment be conducted?", "text": "The assessment will be conducted in the schools that are selected to participate."}, {"section_title": "How long does the assessment take?", "text": "The assessment session is approximately 2\u00bd hours and includes the administration of the assessment, a questionnaire that students complete, and a break between the two. The questionnaire takes approximately 30 minutes to complete.  TIMSS Advanced is more than an assessment of student knowledge in advanced mathematics and physics. TIMSS Advanced also considers the context in which learning occurs. Students, teachers, and schools are asked about a variety of aspects of the environments in which content is taught, learned, practiced, and applied. In this way, TIMSS Advanced provides each country with a rich source of information on the factors influencing mathematics and science achievement. \nThe assessment session is approximately 2\u00bd hours and includes the administration of the assessment, a brief calculator survey, a questionnaire that students complete, and a break. The questionnaire takes approximately 30 minutes to complete."}, {"section_title": "Why is TIMSS Advanced important?", "text": "TIMSS Advanced provides a unique opportunity to compare the achievement of U.S. twelfth-grade students who have taken advanced mathematics or physics courses with that of their peers in countries around the world on advanced mathematics and physics content. TIMSS Advanced will provide educational policymakers with valuable information about how many students are excelling at highly specialized science, technology, engineering, and mathematics (STEM) content in a global context. The results will inform national discussions about education, preparedness for postsecondary education, and international competitiveness. TIMSS Advanced provides valuable benchmark information on how U.S. students compare to students around the world, allows educators and policymakers to examine other educational systems for practices that could have application to the United States, and contributes to ongoing discussions of ways to improve the quality of education of all students."}, {"section_title": "What type of assessment is TIMSS Advanced?", "text": "The TIMSS Advanced mathematics and physics assessment is developed through an international consensus-building process involving input from U.S. and international experts in mathematics, science, and measurement. In a final step, the assessment is endorsed as suitable by all participating countries. The assessment contains a mix of questions; some require students to select appropriate responses while others require that students solve problems and provide written answers. The Trends in International Mathematics and Science Study (TIMSS) is an international assessment and research project designed to measure trends in mathematics and science achievement at the fourthand eighth-grade levels as well as collect information about school and teacher practices related to instruction. Since 1995, TIMSS has been administered every 4 years. In 2015, TIMSS will involve students from more than 50 countries, including the United States. TIMSS Advanced measures trends in advanced mathematics and physics achievement for students in their final year of secondary school. It will provide information about how many students are excelling at highly specialized science, technology, engineering, and mathematics (STEM) content in comparison to students in other countries around the world. TIMSS Advanced was administered in 1995 and 2008 and will be administered again in 2015. In 2015, TIMSS Advanced will be administered in 11 countries, including the United States."}, {"section_title": "What will happen with the collected data?", "text": "The data from the assessment will be used to evaluate how the knowledge and skills of U.S. students compare to those of their peers in other participating countries. By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed or used in identifiable form for any other purpose except as required by law [Education Science Reform Act of 2002(ESRA 2002, 20 U.S. Code, Section 9573]. Reports of the findings from the assessment will not identify participating districts, schools, students, or individual staff. Individual responses will be combined with those of other participants to produce summary statistics and reports."}, {"section_title": "Are schools required by federal law to participate?", "text": "No. School participation is voluntary. However, we hope you will participate in this study so that students like those in your school are accurately and fairly represented. Where can I find more information about TIMSS? Visit the TIMSS website at http://nces.ed.gov/timss or the TIMSS international website at http://timss.bc.edu. For additional information about TIMSS 2015, contact the TIMSS U.S. information hotline at 855-445-5604 or email TIMSS@westat.com. "}, {"section_title": "Summary of School Activities", "text": "For additional information, go to http://nces.ed.gov/timss or the TIMSS international website at http://timss.bc.edu. \uf0b7 Refer to the important definitions in the Class Roster Definitions document in the Documents section of MyTIMSS. \uf0b7 Record the Class Name that is typically used by your school to refer to the class. \uf0b7 For classes with students from more than one grade level, include in Number of Students only those students in grade 4. For example, if the class has 5 third-graders, 6 fourth-graders, and 4 fifth-graders, enter \"6\" as the Number of Students in this class. \uf0b7 Use the most current enrollment information. \uf0b7 Include all classes, even if they typically are excluded from your state testing program, or all students take alternate assessments. You can indicate information about the class in Class Exclusion Status. \uf0b7 Name of mathematics teacher and name of science teacher may be the same. \uf0b7 Print a list of the classes you included for your future reference using the Print button. @westat.com or call 1-855-457-1577."}, {"section_title": "U.S. TIMSS 2015 and TIMSS", "text": ""}, {"section_title": "If you need assistance, email TIMSSefile", "text": ""}, {"section_title": "B-15", "text": "Exhibit B-7. TIMSS 2015 Grade 4 Submit Class List Tip Sheet-continued entering each teacher. Continue until you have entered information about all science teachers who teach eighth-grade students."}, {"section_title": "Example:", "text": "When you have entered information for eighth-grade mathematics classes, and eighth-grade science teachers, in your school, click on the Finished button."}, {"section_title": "Additional tips for submitting information about your eighth-grade mathematics classes:", "text": "\uf0b7 Refer to the important definitions in the Class Roster Definitions document in the Documents section of MyTIMSS. \uf0b7 Record the Class Name that is typically used by your school to refer to the class. \uf0b7 For math classes with students from more than one grade level, include in Number of Students only those students in grade 8. For example, if the class has 5 seventh-graders, 6 eighthgraders, and 4 ninth-graders, enter \"6\" as the "}, {"section_title": "TIMSS 2015: Instructions for Grade 8 Submit Student List", "text": "Along with the list of classes, TIMSS needs a complete and current list of all students in grade 8 in order to draw a random sample of mathematics classes (and therefore students) to participate in the assessment. Your student data electronic file (E-File) must be submitted as a Microsoft Excel file. You may use one of the TIMSS Grade 8 Excel Templates (located in Documents on www.mytimss.com and described below) or you may provide an Excel file with the same information. If you cannot submit your student data with this information in an Excel file, please call or email the TIMSS E-File Help Desk at TIMSSefile@westat.com or 1-855-457-1577."}, {"section_title": "TIMSS Advanced 2015: Instructions for Grade 12 Submit Student List", "text": "TIMSS needs a complete and current list of all 12th-grade students who have taken or are currently taking eligible advanced mathematics and physics courses in order to draw a random sample of students to participate in the TIMSS Advanced assessment. Eligible courses for your school were sent to you via email. Your student data electronic file (E-File) must be submitted as a Microsoft Excel file. You may use one of the TIMSS Grade 12 Excel Templates (located in Documents on www.mytimss.com and described below) or you may provide an Excel file with the same information. If you cannot submit your student data with this information in an Excel file, please call or email the TIMSS E-File Help Desk at TIMSSefile@westat.com or 1-855-457-1577. If you call, please press 2 to access the TIMSS Advanced E-File Help Desk. Step"}, {"section_title": "-Compile Data in an Excel File", "text": "Prepare an Excel file with the following data elements for all students in grade 12 who have taken or are currently taking one or more of the eligible courses in your school. Refer to the recent email from TIMSS@westat.com for a list of eligible courses."}, {"section_title": "Data Element Description Student Name", "text": "The preferred format is First Name, Middle Name (or Initial), and Last Name in separate columns. However, TIMSS will accept student names in one column. Student  You may use one of the templates provided or create your own Excel file with these data for each student. It is preferred that you include column headers as the first row in your E-File, as in these templates. However, E-Files without column headers will be accepted. Template 1 has student name in three separate columns, and month of birth, day of birth and year of birth in three separate columns. It also has \"Advanced Math\" and \"Physics\" courses in separate worksheets. Advanced Mathematics Worksheet"}, {"section_title": "Physics Worksheet", "text": "Template 2 has student name in one column, and date of birth in one column. It also has \"Advanced Math\" and \"Physics\" courses in separate worksheets. \uf0b7 Use the template or provide column headers. Student information should begin on the second row. There should be no empty rows within the student data. \uf0b7 Be sure to give your file a unique, descriptive name. Within Excel, click on File, then Save As, and give your file a name such as \"Your School Name Grade 12.xls.\" \uf0b7 The first row of data in your file will be read as the column header unless you indicate otherwise on the Submit Student List webpage. Each succeeding row will be considered a student record. Step"}, {"section_title": "-Upload Your Excel File", "text": "Once your file is prepared and checked for accuracy and completeness, login to www.mytimss.com and select \"Submit Student List\" from the left-hand menu. After you have submitted your student list, the webpage will still have the \"New file\" section below the Hello, this is _____________________ (your name) representing the Trends in International Mathematics and Science Study, or TIMSS. You were contacted by the Westat home office earlier this year to complete the sampling of the students who will be participating in TIMSS. I am calling to confirm the assessment logistics, discuss accommodations, and to answer any questions you may have."}, {"section_title": "IF WE DO NOT HAVE THE COMPLETED STUDENT TEACHER LINKAGE FORM:", "text": "Did you receive the email alerting you that the Student Teacher Linkage Form(s) are ready for you in MyTIMSS?"}, {"section_title": "Yes (ASK THE SCHOOL COORDINATOR TO LOCATE THE FORM BACK AND CONTINUE)", "text": "There are two forms, one form for each assessment session to be conducted at your school. On each form we need you to record the student's gender and date of birth. If any of the sampled students have special needs and should be excluded, please put the appropriate exclusion code in the Exclusion Status column. We will discuss any student who can be assessed with accommodations allowed by TIMSS shortly. We also need you to list each sampled student's math and science teachers in the appropriate columns. My records show that we will be conducting the assessment on _______________ (assessment date). DISCUSS ASSESSMENT DATE. ____________________________________________________________________________ ____________________________________________________________________________ ____________________________________________________________________________ 5. Let's review the students who can be assessed with TIMSS allowed accommodations. Go over each student identified as needing accommodation on the Student Tracking Form. Record the student information on the Accommodation Planning Form and mark the appropriate accommodation to be provided to the student. Answer any questions the school coordinator has about the accommodations. Refer to the Accommodation Chart. 15. Ask where you should report when you arrive at the school and tell the School Coordinator that you will be arriving at least one hour before the scheduled assessment time to get your materials ready. Administering the Grade 4 TIMSS Assessment The instructions marked with the \uf026 symbol and printed in bold in the administration script must be read aloud to the students word for word to ensure that the testing sessions are conducted in the same way in all countries. Although you should become familiar with these instructions before the actual testing, do not attempt to memorize them. Read these instructions exactly as they are written. Comments that are not in bold are not to be read aloud. They are instructions for you only. To begin the testing session: -Make sure that the Class ID is recorded at the top of the Test Administration Form. If missing, you can find it on the Student Tracking Form, column [b]. -Make sure that students are seated quietly, with nothing on their desks except for a pencil. -Record the current time in cell (9a) of the Test Administration Form. -Begin reading the administration script. Introduction \uf026 Good morning/afternoon, everyone! My name is (YOUR NAME). This school has been chosen to take part in an important international project to study what students around the world know and can do in mathematics and science. Different countries from all over the world are taking part in this study. You will be taking a mathematics and science test. While I talk to you about today's test, I would like you all to be quiet, stay at your desks, and listen carefully. Students should have only a pencil and his or her booklet for the duration of the achievement test administration. As you hand out the test booklets, make sure that each student receives the booklet specially prepared for him or her. You can do that by reading the name on each test booklet and giving it to that student. Do not allow students to open the test booklets until you tell them to do so. Record the student's participation status in column 7 (Achievement Session) of the Student Tracking Form. If you are administering a makeup session, use the shaded part of column 7 (Achievement Session). If a student is absent, put that test booklet aside. Do not give it to anyone else, since each test booklet is marked for a specific student. If there is a student in the classroom who is not listed on the Student Tracking Form, or an originally assigned booklet is damaged, assign one of the three spare booklets or one from your bulk supplies to the student. After the test booklets are passed out and the Student Tracking Form has been completed, say the following to the students: \uf026"}, {"section_title": "Does everybody have his or her test booklet?", "text": "If yes, then continue. If not, find out why and proceed as described before. \uf026 Please take your test booklet out of the envelope. Turn to the first page in the booklet that says \"General Directions.\" Please read along as I read the directions aloud. Please do not admit any students into the testing session at this point.\nIf yes, then continue. If not, find out why and proceed as described before. \uf026 Please take your test booklet out of the envelope. Turn to the first page in the booklet that says \"General Directions.\" Please read along as I read the directions aloud. Please do not admit any students into the testing session at this point.\nWhen all problems are resolved and you have the students' attention again, proceed with the instructions for Part 2. Begin timing the 45 minutes for the second part of the session. Record the current time in cell (12a) of the Test Administration Form. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. If a student is finished early, make sure that he or she has a book to read. Ten minutes before the testing session ends, say the following: \uf026 You have 10 minutes left to work on the second part of the booklet. Make sure you try to finish answering all of the questions in the second part of your booklet. After the last 10 minutes have passed, say: \uf026 Your time is up. Please answer the calculator survey if you have not done that yet, and then close your booklets and put your pencils down. Do not write anything more. Record the current time in cell (12b) of the Test Administration Form, then say:\nIf yes, then continue. If not, find out why and proceed as described before. \uf026 Please take your test booklet out of the envelope. Turn to the first page in the booklet that says \"General Directions.\" You will now have five minutes to read the directions quietly. Please do not admit any students into the testing session at this point. Below are the general directions that the students will read in their test booklets."}, {"section_title": "General Directions", "text": "\uf026 In this test, you will answer questions in mathematics and science. You may find some questions easy, and you may find some questions difficult. Try to answer all questions, the difficult ones as well as the easy ones. \uf026 For some questions, you choose the answer you think is correct, and fill in the oval next to it. Example 1 shows this kind of question with the oval next to the correct answer filled in.\n\uf026 In this test, you will answer questions in mathematics and science. You may find some questions easy, and you may find some questions difficult. Try to answer all questions, the difficult ones as well as the easy ones. \uf026 For some questions, you choose the answer you think is correct, and fill in the oval next to it. Example 1 shows this kind of question with the oval next to the correct answer filled in.\nYou will have 90 minutes to answer the questions in this booklet. It is important that you attempt every question, giving the best answer that you can. Calculators may be used, and [mathematics/physics] formulas are provided on the pages following these directions. However, you may not use any device that can connect to the Internet. Some questions require you to select the correct answer from the options provided and fill in the oval next to the answer you believe to be correct, as shown in Example 1. Example 1 in Advanced Mathematics booklets: Example 1 in Physics booklets: If you are not sure of the answer to a question, fill in the answer you think is most likely to be correct. If you decide to change your answer, completely erase your first choice. Then, fill in the oval next to your new choice. Other questions require you to write answers in the space provided in your booklet. Some of these questions require you to \"show your work.\" For these questions, be sure to give a complete explanation or show all the steps you used to obtain your answer. Example 2 in Advanced Mathematics booklets: If you use a calculator in answering one of these questions, you still must describe all the steps you used to obtain your answer. The following illustrates a calculator explanation of Example 2."}, {"section_title": "\uf026", "text": "The oval with the letter \"C\" has been filled in because there are 60 minutes in one hour. If you are not sure about the answer to a question, fill in the oval next to the answer you think is best, and move on to the next question. Make sure students with the calculator accommodation know they are allowed to use their own calculator during the test. Make sure all students begin working on the correct part of the booklet. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. Ten minutes before the testing session ends, say the following: \uf026 You have 10 minutes left before the break. Make sure you try to finish answering all of the questions in the first part of your booklet before the break. After the last 10 minutes have passed, say: \uf026 Your time is up. Please close your booklets, and put your pencils down. Do not write anything more. We will now take a short break. Record the current time in cell (10b) of the Test Administration Form.\nWe will now take a short break. Afterwards, I will ask you to answer a short questionnaire. If you leave the room, please be back on time.\nThe directions are printed at the beginning of your questionnaire. I will also read them to you. It is important that you follow the directions very carefully so that you understand how to mark your answers. Now turn to the first page titled \"Directions.\" Make sure that the students have their booklets open to the Directions page before proceeding. \uf026 Example 1 is one kind of question you will find in this booklet. Make sure that all students are following along and are looking at Example 1 in their booklets.\nIn Example 1, the question asks, \"Do you go to school?\" Below this question are a \"Yes\" and a \"No\". Since you all go to school, you should all fill in the oval next to \"Yes.\" Give students time to fill in the oval next to \"Yes\" and make sure they understand how to do it. Once everyone has completed the example, move on to Example 2. Make sure that all students are following along and are looking at Example 2 in their booklets. \uf026 Example 2 is another kind of question you will find in this booklet. \uf026 This question asks \"How often do you do these things?\" Letter (a) says, \"I talk with my friends.\" You are given four choices for how often you do this: Every day or almost every day; Once or twice a week; Once or twice a month; and Never or almost never. \uf026 Fill in the oval below your answer. For example, if you talk to your friends every day or almost every day, fill in the first oval under \"Every day or almost every day.\" Give students time to fill in their answers to all parts of the Example 2 question and make sure they understand how to answer this kind of question. Once everyone has completed the example, move on to Example 3. Make sure that all students are following along and are looking at Example 3 in their booklets.\nExample 3 is another kind of question you will find in this booklet. \uf026 Example 3 says, \"What do you think? Tell how much you agree with these statements.\" Letter (a) says, \"Watching movies is fun.\" You are given four choices for how much you agree with the statement: Agree a lot, Agree a little, Disagree a little, or Disagree a lot.\nFill in the oval below your answer. For example, if you really agree a lot with that, fill in the first oval under \"Agree a lot.\" If you really disagree a lot, fill in the oval under \"Disagree a lot.\" Give students time to fill in their answers to all parts of the Example 3 question and make sure they understand how to answer this kind of question. Then continue reading the final directions: Once all students have finished and have closed their booklets record the current time in cell (13b) of the Test Administration Form. Then say: \uf026 Thank you very much for participating in this study. Your work will help us to learn more about our students and schools. \uf026 Please close your booklets and insert the booklet into the envelope it was in when you received it and seal the envelope closed. Once you have done this, remove the label that contains your name from the envelope. Peel it off and I will collect it. Collect the labels tear them up and throw them away. Then, collect the test booklets and envelopes and keep them secure. Check against the Student Tracking Form to make sure that you have received all of them. Use the sequential number you assigned to the front of the envelope to help in this process. Thank you again for your help in conducting this important international study. Administering the Grade 8 TIMSS Assessment The instructions marked with the \uf026 symbol and printed in bold in the administration script must be read aloud to the students word for word to ensure that the testing sessions are conducted in the same way in all countries. Although you should become familiar with these instructions before the actual testing, do not attempt to memorize them. Read these instructions exactly as they are written. Comments that are not in bold are not to be read aloud. They are instructions for you only. To begin the testing session: -Make sure that the Class ID is recorded at the top of the Test Administration Form. If missing, you can find it on the Student Tracking Form, column [b]. -Make sure that students are seated quietly, with nothing on their desks except for a pencil and their own calculator. -Record the current time in cell (9a) of the Test Administration Form. -Begin reading the administration script. Introduction \uf026 Good morning/afternoon, everyone! My name is (YOUR NAME). This school has been chosen to take part in an important international project to study what students around the world know and can do in mathematics and science. Different countries from all over the world are taking part in this study. You will be taking a mathematics and science test. While I talk to you about today's test, I would like you all to be quiet, stay at your desks, and listen carefully. Students should have only a pencil, a calculator, and his or her booklet for the duration of test administration. As you hand out the test booklets, make sure that each student receives the booklet specially prepared for him or her. You can do that by reading the name on each test booklet, and giving it to that student. Do not allow students to open the test booklets until you tell them to do so. Record the student's participation status in column 7 (Achievement Session) of the Student Tracking Form. If you are administering a makeup session, use the shaded part of column 7 (Achievement Session). If a student is absent, put that test booklet aside. Do not give it to anyone else, since each test booklet is marked for a specific student. If there is a student in the classroom who is not listed on the Student Tracking Form, or an originally assigned booklet is damaged, assign one of the three spare booklets or one from your bulk supplies to the student. After the test booklets are passed out and the Student Tracking Form has been completed, say the following to the students: \uf026\nThe oval with the letter \"C\" has been filled in because there are 60 minutes in one hour. If you are not sure about the answer to a question, fill in the oval next to the answer you think is best, and move on to the next question. Make sure all the students are seated. When the students are seated and quiet redistribute the test booklets, if necessary. Then, say the following: \uf026\nWe will now take a short break. Afterwards, I will ask you to answer a short questionnaire. Please be back on time.\nIn Example 1, the question asks, \"Do you go to school?\" Below this question are a \"Yes\" and a \"No.\" Since you all go to school, the oval next to \"Yes\" is filled in.\nIn Example 2, the question asks \"How often do you do these things?\" Letter (a) says, \"I talk with my friends.\" You are given four choices for how often you do this: Every day or almost every day; Once or twice a week; Once or twice a month; and Never or almost never.\nIn this example, the student talks to his or her friends every day or almost every day and the first oval under \"Every day or almost every day\" is filled in. If not all of the students raise their hands, allow for additional time and say: \uf026 You will have more time to continue answering this questionnaire. If you have already finished all the questions, then you can use this time to review your answers. Once you have finished, please close your booklet and read quietly at your desk. Once all students have finished and have closed their booklets, record the current time in cell (13b) of the Test Administration Form. Then say: \uf026 Thank you very much for participating in this study. Your work will help us to learn more about our students and schools. Please stay seated. \uf026 Please close your booklets and insert the booklet into the envelope it was in when you received it and seal the envelope closed. Once you have done this, remove the label that contains your name from the envelope. Peel it off and I will collect it. Collect the labels tear them up and throw them away. Then, collect all test booklets and envelopes and keep them secure. Check against the Student Tracking Form to make sure that you have received all of them. Use the sequential number you assigned to the front of the envelope to help in this process. Thank you again for your help in conducting this important international study. Please answer questions 14 through 18 on the Test Administration Form. Administering the TIMSS Advanced Assessment The instructions marked with the \uf026 symbol and printed in bold in the administration script must be read aloud to the students word for word to ensure that the testing sessions are conducted in the same way in all countries. Although you should become familiar with these instructions before the actual testing, do not attempt to memorize them. Read these instructions exactly as they are written. Comments that are not in bold are not to be read aloud. They are instructions for you only. To begin the testing session: -Make sure that the Class ID is recorded at the top of the Test Administration Form. If missing, you can find it on the Student Tracking Form, column [b]. -Make sure that students are seated quietly, with nothing on their desks except for a pencil and their own calculator. -Record the current time in cell (9a) of the Test Administration Form. -Begin reading the administration script. Introduction \uf026 Good morning/afternoon, everyone! My name is (YOUR NAME). This school has been chosen to take part in an important international project to study what students around the world know and can do in advanced mathematics and physics. Different countries from all over the world are taking part in this study. You will be taking an advanced mathematics or physics test, and answering a short questionnaire. Please listen carefully while I read the instructions for today's test. Students should have only a pencil, a calculator, and his or her booklet for the duration of test administration. As you hand out the test booklets, make sure that each student receives the booklet specially prepared for him or her. You can do that by reading the name on each test booklet, and giving it to that student. Do not allow students to open the test booklets until you tell them to. Record the student's participation status in column 7 (Achievement Session) of the Student Tracking Form. If you are administering a makeup session, use the shaded part of column 7 (Achievement Session). If a student is absent, put that test booklet aside. Do not give it to anyone else, since each test booklet is marked for a specific student. If there is a student in the classroom who is not listed on the Student Tracking Form, or an originally assigned booklet is damaged, assign one of the three spare booklets or one from your bulk supplies. After the test booklets are passed out and the Student Tracking Form has been completed, say the following to the students: \uf026\nThe directions are printed at the beginning of your questionnaire. It is important that you follow the directions very carefully so that you understand how to mark your answers. Now turn to the first page titled \"Directions.\" Make sure that the students have their questionnaires open to the Directions page before proceeding. \uf026 You will have 5 minutes to read the directions quietly. Below are the general directions that the students will read in their questionnaires."}, {"section_title": "Break", "text": "If the room will be left unattended during the break, collect the booklets from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets after the break, just like you did at the beginning of the testing session, making sure that each student receives the same test booklet he/she was working on during the first half of the testing session.\nIf the room will be left unattended during the break, collect the booklets from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets after the break, just like you did at the beginning of the testing session, making sure that each student receives the same test booklet he/she was working on during the first half of the testing session."}, {"section_title": "Instructions for Part 2", "text": "Record the current time in cell (11a) of the Test Administration Form. Make sure all the students are seated. When the students are seated and quiet redistribute the test booklets, if necessary. Then, say the following: Begin timing the 36 minutes for the second part of the session. Record the current time in cell (12a) of the Test Administration Form. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. If a student is finished early, make sure that he or she has a book to read. Ten minutes before the testing session ends, say the following: Record the current time in cell (12b) of the Test Administration Form, then say:"}, {"section_title": "Administering the Student Questionnaire", "text": "Before you begin the questionnaire administration: -Make sure that you have the corresponding Student Tracking Form and Test Administration Form. -Make sure all the students are in the class; all are seated quietly, and have a pencil. When ready, say: \uf026 Now you will complete a short questionnaire. Turn to the colored divider page in your booklet. Do not begin the questionnaire until I tell you to do so."}, {"section_title": "Directions", "text": "In this booklet, you will find questions about yourself. Some questions ask for facts while other questions ask for your opinion. Each question is followed by a number of answers. Shade in the circle next to or under the answer of your choice as shown in the example below. \u2022 Read each question carefully, and pick the answer you think is best. \u2022 Fill in the oval next to or under your answer. \u2022 If you decide to change an answer, completely erase your first choice. Then, fill in the oval next to or under your new answer. \u2022 Ask for help if you do not understand something or are not sure how to answer."}]