[{"section_title": "Abstract", "text": "Non-rigid cortical registration is an important and challenging task due to the geometric complexity of the human cortex and the high degree of inter-subject variability. A conventional solution is to use a spherical representation of surface properties and perform registration by aligning cortical folding patterns in that space. This strategy produces accurate spatial alignment, but often requires high computational cost. Recently, convolutional neural networks (CNNs) have demonstrated the potential to dramatically speed up volumetric registration. However, due to distortions introduced by projecting a sphere to a 2D plane, a direct application of recent learning-based methods to surfaces yields poor results. In this study, we present SphereMorph, a diffeomorphic registration framework for cortical surfaces using deep networks that addresses these issues. SphereMorph uses a UNet-style network associated with a spherical kernel to learn the displacement field and warps the sphere using a modified spatial transformer layer. We propose a resampling weight in computing the data fitting loss to account for distortions introduced by polar projection, and demonstrate the performance of our proposed method on two tasks, including cortical parcellation and group-wise functional area alignment. The experiments show that the proposed Sphere-Morph is capable of modeling the geometric registration problem in a CNN framework and demonstrate superior registration accuracy and computational efficiency."}, {"section_title": "Introduction", "text": "Non-rigid shape registration is an important area of research in medical imaging, in particular for establishing cross-subject spatial correspondence in the cerebral cortex. This type of spatial alignment has been shown to improve the statistical power of group functional MRI (fMRI) analysis [1, 2] resulting from the improved correspondence of functional areas. Due to the geometric complexity of the cortex and the large variability between individuals, cortical surface registration remains a challenging task. Inter-subject surface alignment is commonly driven by geometric features that describe measures of cortical shape (folding), such as sulcal depth or local curvature [3, 4, 5, 6] .\nA widely used cortical surface registration approach is to map the surface onto the unit sphere in order to perform computations in this canonical domain. Existing efforts are mainly focused on the adaptation of registration algorithms in the Euclidean space [3, 4, 7] . These aim to optimize a similarity metric between the target and the deformed source volumes, regularized by various energies [8] . FreeSurfer [3] registers an individual surface to a probabilistic atlas computed from a representative set of subjects by minimizing the squared difference between the average convexity across subjects and that of the individual, weighted by the inverse variance of the convexity across subjects. The Multimodal Surface Matching tool [7] uses a similarity between the input and reference mesh features in a coarse-to-fine manner. The deformation is driven by aligning local patches around control points, i.e. vertices of a low resolution mesh, and then propagated to the high resolution input mesh via interpolation. Spherical Demons [4] modifies the classical Demons method [9] using velocity vectors tangent to the sphere. The two-step optimization of classical Demons also holds for the spherical case in which the second step handles the deformation regularization by spherical thin plate spline interpolation. To encourage desirable mathematical properties such as invertibility, diffeomorphic transforms have seen extensive methodological development, yielding state-of-the-art tools [10, 11] . Unfortunately, since these methods solve an optimization problem for each image pair, they often exhibit long execution times.\nHigh computational costs have led to an increase in the popularity of supervised [12, 13, 14] and unsupervised [15, 16, 17] learning-based registration algorithms. Considering the difficulty of establishing ground truth spatial correspondences, supervised methods require predictions from existing algorithms [14] , simulations [13] , or both [12] . In contrast, unsupervised methods make use of Spatial Transformer Networks (STN) [18] to warp the moving image in a differentiable way, enabling end-to-end training [15, 17, 19, 20, 21] . Some unsupervised methods [15, 17, 20] model a stationary velocity field as latent variables representing deformations in a generative probabilistic model. They use a scaling and squaring layer [22] for the Lie group exponentiation of the velocity field to generate diffeomorphic transforms, thus guaranteeing topology preservation. These methods have demonstrated high quality performance in registering various types of medical images. Therefore, we build on these concepts when working with surfaces.\nRecent studies have developed geometric convolutional neural networks (CNN) [23, 24, 25, 26, 27] that operate on a spherical manifold to solve classification and detection tasks. To address the distortions introduced by projecting signals to a planar image, regular convolutions with increased kernel sizes near polar regions have been utilized [23] . Spherical CNNs encode rotational instead of translational equivariance into the network in Euclidean space to solve classification problems [24] . In SphereNet, the convolution kernel on the sphere has been approximated by encoding the vertex neighborhood information on 2D tangent planes, which enables adapting existing CNN architectures to the omnidirectional setup for object detection and classification tasks [25] . Geometric CNNs (gCNN) [26] also deal with convolution and pooling operations of a CNN on a mesh surface. However, they have so far only been tested on sex classification, using cortical thickness images. A convolutional kernel dis-cretized by an unstructured mesh was recently proposed and evaluated on spherical MNIST classification and 3D object detection tasks [27] . Most existing work, however, focuses on the construction of spherical convolutional kernels and, to the best of our knowledge, neural networks have not yet been extended to surface registration. Compared with classification or detection tasks, besides convolution and pooling operations on spheres, a learning-based registration method should address local deformations defined on spheres. However, existing spatial transformation networks [28, 29] for spheres only address global deformations, which are not suitable for accommodating nonlinear deformation fields.\nIn this paper, we propose a diffeomorphic framework combining a generative model for surfaces with CNNs to register individual cortical surfaces to an atlas space. This framework adapts conventional VoxelMorph for registering Euclidean images [17] to spherical manifolds. In order to address the limitations of 2D planar projection, we construct a weighted neighborhood graph defined on 2D grids, which accounts for the non-uniform metric tensor of the spherical representation to encode a stationary velocity field. Considering that the 2D projection operation samples the arc-length for each latitude to the same number of points, we also take sampling distortion into account at different latitudes in the likelihood model. We quantify the performance of our framework through two applications: the generation of cortical parcellations and the alignment of functional activations. The experimental results demonstrate that our framework yields better registration accuracy to state-of-the-art classical methods at a significantly reduced computational cost, and more accurate results compared to current learning-based methods.\nThe remainder of this paper is organized as follows. We first introduce the cortical registration problem, review the conventional VoxelMorph [17] framework, and propose our method and network structure. We then describe two evaluation experiments including cortical parcellation and functional alignment, and show results for these experiments. Finally, we present our discussions and conclusions."}, {"section_title": "Methods", "text": "Numerous studies using FreeSurfer have demonstrated its efficacy in spherical-based cortical registration. We build on ideas for our surface representation from the FreeSurfer spherical registration [3] and model the unsupervised learning structure for the registration field following VoxelMorph [17] ."}, {"section_title": "Registration problem definition", "text": "In the FreeSurfer spherical registration pipeline [3] , surface geometry is encoded as a convexity attribute at each mesh vertex and the representation of the atlas surface is computed from a group of adult subjects. In order to register the surfaces of an individual to the atlas space, first a white matter mesh is generated and mapped to the unit sphere by minimizing metric distortion [3] . Next, an optimal rotational alignment is computed by global search over two rotation angles on the sphere. Then a 2D canonical warp is computed to align the subject's convexity pattern with that of the mean pattern encoded in the atlas, by minimizing the mean squared difference, weighted by the inverse of the atlas variance. Our goal is to compute this canonical warp using a CNN framework.\nLet S x be the unit sphere and I x the corresponding scalar field over the sphere (e.g. sulcal depth or curvature) projected into 2D longitude/latitude parameterization. Let I a be the atlas mean image as defined in FreeSurfer, and M and N be the number of image rows and columns. Let \u03a3 a = diag(\u03c3 2 1 , \u03c3 2 2 ...\u03c3 2 M N ) be a diagonal matrix where each diagonal element denotes the variability of the corresponding feature at a particular vertex as defined in the FreeSurfer atlas variance image. The goal is to find the spatial transformation \u03a6 : S 2 \u2192 S 2 given I x and I a that maximizes the a posteriori probability of the transform assuming certain smoothness priors on the warp."}, {"section_title": "VoxelMorph", "text": "We assume a diffeomorphic deformation based on a stationary velocity field v, denoted as \u03a6 v , and adapt a generative probabilistic model following VoxelMorph [17] . VoxelMorph uses Maximum a Posteriori (MAP) estimation to obtain the most likely velocity field v * at each voxel/pixel given a pair of images. VoxelMorph models the prior probability of v as a zero-mean multivariate normal distribution, p(v) = N (v; 0, \u03a3 v ), where \u03a3 v is the covariance matrix. An individual image can be estimated by warping the FreeSurfer atlas, thus we model the warped image I\nwhere \u03a6 v is the inverse transformation of the atlas warping to the individual. The aim is to maximize the posterior probability p(v|I x ; I a ) = p(v)p(Ix|v;Ia) v p(v,Ix;Ia)dv , where the marginalization over v is intractable. In this case, a variational approximation q \u03c8 (v|I x ; I a ) is adopted with parameters \u03c8, by minimizing its dissimilarity, Kullback-Leibler (KL) divergence, with the true posterior probability. For simplicity, the approximate posterior q \u03c8 (v|I x ; I a ) is restricted to a multivariate normal distribution N (\u00b5 v|Ix;Ia , \u03a3 v|Ix;Ia ) where \u00b5 v|Ix;Ia and a diagonal \u03a3 v|Ix;Ia are functions estimated with a U-Net core [30] , as shown in Fig. 2 .\nUsing the above assumptions, maximizing the posterior probability can be approximated by minimizing the following loss:\nwhere q is short for q \u03c8 (v|I x ; I a ). The first term describes the reconstruction loss and the second term is a KL divergence term, encouraging the estimated posterior probability q \u03c8 (v|I x ; I a ) to be close to the prior p(v). VoxelMorph encourages the smoothness of the velocity field v by setting\nwhere the parameter \u03bb controls the scale of the velocity field and L is the graph Laplacian matrix defined on the Euclidean grid. L is computed as L = (D \u2212 A), where A is the neighborhood adjacency matrix and D is the graph degree matrix. Thus, Eq. (1) can be rewritten as:\nwhere K is the number of samples v k \u223c q used to approximate the expectation. We use K = 1. We treat the fixed atlas I a and the warped individual image I x \u2022 \u03a6 v as M N \u00d7 1 vectors. We denote this naive application of the registration of 2D projected images as the 2D VoxelMorph method and it serves as a benchmark in our experiments.\nUnfortunately, the 2D projection step introduces two main problems, as shown in Fig. 1 :\n\u2022 varying level of distortions with different latitudes (distortion increases from the equator to the poles); and\n\u2022 inability to represent the periodic property of \u03b8 and the geometry of the poles (an enclosed spherical surface is projected onto a rectangular image region, introducing discontinuities at the image borders).\nHence, the 2D VoxelMorph method over-weights the alignment for near-pole regions, yielding misalignment in most regions even compared to global rigid registration as shown in Section 3."}, {"section_title": "Proposed Method: SphereMorph", "text": "To address the above issues, we propose SphereMorph. We start by defining the registration problem in the spherical domain. The spherical representation of an individual's surface is first rotated for a rigid alignment with the atlas, as in FreeSurfer. The spherical surface is parameterized by the longitude \u03b8 and latitude \u03d5 and sampled to an M \u00d7 N two-dimensional image with a geometric or functional feature, e.g. convexity, assigned as a pixel intensity measure. Prior correction. We assume that the displacement field is smooth on the sphere considering the anatomical continuity via a graph Laplacian regularizer. We define a neighbour connectivity graph G S on the spherical manifold and represent the velocity with respect to Cartesian coordinates as a signal defined on this graph. Let T denote the conversion from polar to Cartesian coordinates, that is [x, y, z] T = T ([\u03b8, \u03d5]) = [sin \u03d5 cos \u03b8, sin \u03d5 sin \u03b8, cos \u03d5] T , then the geodesic velocity at each vertex V er Each vertex on the projected image is considered as a node and each grid edge connecting two adjacent nodes as their edge in G S . We connect leftmost and rightmost nodes due to the periodicity in longitude. The weight of the connection between vertices in G S varies with location to account for the horizontal edge distance on the spherical surface which is proportional to sin \u03d5. Thus, we define the weight of each grid edge connecting vertices V er i (\u03b8 i , \u03d5 i ), V er j (\u03b8 j , \u03d5 j ) as:\nWe construct the corresponding neighborhood adjacency matrix A S with entries A S ij = w ij and the degree matrix D S with diagonal entries D S ii = j w ij . Finally, we denote the Laplacian of this weighted graph as L S = D S \u2212 A S and define the covariance of geodesic velocity as \u03a3 \u22121 v = \u039b Sv = \u03bbL S . Intuitively, this formulation can be seen as increasing the regularization near the poles, where the Euclidean distance between mesh nodes is small, and decreasing the weighting near the equator where the Euclidean distances are larger.\nDistortion correction. For VoxelMorph, which deals with Euclidean image registration, the sampling of grid points is equally distributed. However, a spherical parameterization leads to denser sampling grids for regions at higher latitudes as shown in Fig. 1 . Thus, we assign mesh locations from these regions lower weights in computing the data-fitting term, by introducing a diagonal matrix S \u2208 R M N \u00d7M N with each diagonal entry encoding the resampling weight S ii = sin \u03d5 i for each vertex V er i (\u03b8 i , \u03d5 i ) and model p( The input spherical representation is first rigidly aligned to the atlas using convexity patterns and then projected onto a polar coordinate system. The Spherical U-Net core takes parameterized input image I x and atlas mean image I a as inputs and estimates the distribution, \u00b5 v|Ia;Ix and \u03a3 v|Ia;Ix , of the velocity field v, which is then sampled and integrated using scaling and squaring steps to generate the deformation field \u03a6 v .\nThe first data-fitting term in Eq. (1) is then modified as:\nLoss function. Starting with Eq. (1) and taking into account the spherical geometry, we arrive at the below objective function:\nwhere \u00b5 v |Ix;Ia = f (\u00b5 v|Ix;Ia ) and \u03a3 v |Ix;Ia = f (\u03a3 v|Ix;Ia ). The first term in Eq. (5) is the datafitting term, which encourages matching surfaces after warping and the second term drives the posterior to approximate the smoothness prior defined on a spherical grid. Network structure. Figure 2 illustrates the individual stages of our pipeline. For a given vertex at location (\u03b8, \u03c6), we utilize inverse gnomonic projection, which maps points on the tangent plane to the spherical surface as in SphereNet [25] , to obtain the corresponding locations on the projected image for the neighbor vertex on its tangent plane. We implement the convolution and pooling operations in each 3 \u00d7 3 local tangent patch shown in Figure 1 and build a UNet core [30] , which contains four downsampling and four upsampling layers. Following the sampling layer, seven scaling and squaring operators take the layer output, or velocity field, and return a diffeomorphism \u03a6. 2D VoxelMorph uses a dense spatial transformer layer on (\u03b8 , \u03c6 ) after displacement to retrieve the warped image while SphereMorph warps the image by computing the interpolation grids as ((\u03b8 +2\u03c0) mod 2\u03c0, \u03c6 ) for transformer layer. The model is implemented in Keras with a Tensorflow backend and the ADAM optimizer as part of the VoxelMorph package. We conducted all the experiments on the same workstation with Intel Xeon X5550@2.67GHz and used NVIDIA Tesla P40C for all CNN-based methods."}, {"section_title": "Experimental setup", "text": "To demonstrate the accuracy and efficiency of the proposed registration framework, SphereMorph, we used two sets of experiments, cortical parcellation and fMRI group analysis, on two independent test data sets."}, {"section_title": "Data 3.1.1. Training data set:", "text": "We used the surface convexity maps of the left hemispheres of 800 randomly selected FreeSurfer-processed subjects from the publicly available Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset [31] as training data and the spherical atlas from FreeSurfer as the fixed image in our model. The ADNI dataset consists of longitudinal T1-weighted scans from 836 subjects that are divided into four classes: elderly controls (n = 252), early mild cognitive impairment (eMCI, n =215), late MCI (lMCI, n = 176), and AD (n = 193). The subjects were scanned on average 4.8 times (minimum: a single time; maximum: 11 times; 4013 scans in total), with a mean interval between scans equal to 286 days (minimum: 23 days, maximum: 1567 days). The mean age at baseline of the subjects was 75.1 \u00b1 6.6 years. Since the ADNI project spans multiple sites, different scanners were used to acquire the images; further details on the acquisition can be found at http://www.adni-info.org."}, {"section_title": "Test data sets:", "text": "(1) We used FreeSurfer-processed MRI scans of 39 subjects from a cohort recruited by the Washington University Alzheimer's Disease Research Center (ADRC) [32] . The MRI scans were acquired on a 1.5T Vision system (Siemens, Erlangen Germany). T1-weighted magnetization-prepared rapid gradient echo (MP-RAGE) scans were obtained according to the following protocol: two sagittal acquisitions, FOV = 224, Matrix = 256\u00d7256, Resolution = 1 \u00d7 1 \u00d7 1.25mm 3 , TR = 9.7 ms, TE = 4 ms, Flip angle = 10, TI = 20 ms, TD = 200 ms. Two acquisitions were averaged together to increase the contrast-to-noise ratio. For the cortical parcellation experiment, we separated the data set into two: 9 validation subjects and 30 held-out test subjects. All subjects have 34 cortical areas manually annotated [33] , making them ideal for evaluating registration accuracy.\n(2) Additionally, we used another set of 100 unrelated young and healthy subjects from the Human Connectome Project (HCP) [34] as a second test set. The HCP project used state-of-the-art fMRI hardware and acquisition parameters in a sample of highly educated, healthy subjects. For each subject, seven task fMRI sessions were collected, including working memory, gambling, motor, language, social cognition, relational processing and emotional processing, totaling 48:30 min of fMRI data. The acquisition parameters and minimal preprocessing of these data have been described extensively elsewhere [35, 36] ."}, {"section_title": "Baselines", "text": "We compared our proposed registration method to rigid registration on the sphere (i.e. two rotations) and four other nonlinear registration methods: a 2D version of VoxelMorph, Multimodal Surface Matching (MSM) [7] , Spherical Demons (SD) [4] , and FreeSurfer (FS) spherical registration [3] . We trained 2D VoxelMorph using the same training set as described above and selected the hyperparameter \u03bb that yielded the best performance on the validation set. MSM is a surface-based registration approach that offers significant flexibility with regards to the set of features that are used to drive the spatial alignment. MSM drives the deformation via aligning local patches around control points in a multi-resolution fashion. It is implemented on CPU using a fast, multi-resolution, discrete optimisation scheme, offering significant computational speed-up compared to other classical methods. We ran MSM over three resolution levels with five iterations per level. Spherical Demons, a fast diffeomorphic landmark-free surface registration tool implements the regularization for its objective function via iterative Gaussian smoothing. We explored a range of smoothing iteration numbers (5, 10, 15, 20) to optimize performance and used the results of 10 iterations."}, {"section_title": "Evaluation", "text": "To evaluate registration accuracy, we relied on the resulting spatial transformations to project the atlas parcellation back to individual scan space. For an accurate registration solution, the test subjects cortical parcellations will resemble the manually outlined versions. In order to quantify how well they match, we computed the Dice overlap coefficient [37] , the overall Mean Minimum Distance (MMD) as well as the individual MMD measures for each anatomical region. The Dice overlap coefficient, Dice(M, A) = 2 * R M \u2229A R M +R A , quantifies the surface area overlap (R M \u2229A ) between manual (R M ) and automatic method-generated parcels (R A ) and the MMD describes the discrepancy between the parcellation boundaries: M M D(M, A) = 1/N * \u03a3 i d(m i , a i ) where d(m i , a i ) denotes the Euclidean distance between a vertex m i on a manual boundary and its corresponding closest vertex a i on an automatic method-generated boundary. Additionally, we also tested how consistently the various registration methods aligned anatomical features, such as convexity/sulcal depth and curvature.\nIn the second set of experiments, we mapped all individuals within the group to the HCP's 2mm standard grayordinates space [35] , using the displacement field, then computed group maps of task-evoked activations. To evaluate the quality of the group alignment quantitatively, we computed average correlations between the group-average and the projected individual activation maps across 86 task contrasts derived from the seven fMRI tasks. Table 1 summarizes registration accuracy and computation time for all methods. It illustrates that the proposed method ran approximately 20 times faster than the conventional registration method in FreeSurfer. On a CPU, the default FreeSurfer pipeline takes around 13 minutes to complete the spherical registration while the total computation time of our proposed framework is approximately 0.65 minutes, including the initial alignment, deep network deployment, and displacement field mapping. Compared with other registration methods including MSM and Spherical Demons (SD), CNN-based methods provide more than an order of magnitude improvement in execution speed. Figure 3 shows representative cortical segmentation results from all the methods for two test subjects from the ADRC dataset. The 2D VoxelMorph-estimated annotation exhibits large differences compared to the ground truth in the lateral occipital regions (marked by white arrows), while FreeSurfer and SphereMorph provide results close to the manual annotations. Table 1 provides an overview of registration accuracy by comparing manual annotations to parcellations generated by the different registration methods, including rigid alignment, 2D Voxelmorph, MSM, SD, FreeSurfer as well as our proposed method. Our proposed method and FreeSurfer achieved the highest accuracy. SphereMorph yields significantly higher overall Dice coefficients than MSM after performing a one-tail Wilcoxon rank sum test on their respective Dice coefficients (p = 0.0318). The deep learning baseline, 2D VoxelMorph, performed significantly worse. This is due to the fact that this method does not account for the distortions intrinsic to the spherical coordinate system. Figure 4 compares parcel-wise Dice overlap coefficient values associated with the different registration methods. Our method produced higher mean Dice overlap coefficients than MSM for all structures except the Entorhinal, Paracentral and Middletemporal, and showed significant improvement in regional Dice overlap coefficient compared to MSM in the Temporalpole (p = 0.0090), Parahippocampal (p = 0.0102), Transversetemporal (p = 0.0051), Caudalmiddlefrontal (p = 0.0237), Rostralmiddlefrontal (p = 0.0433) and Lingual (p = 0.0148) regions. Compared to Spherical Demons, SphereMorph produced higher mean regional Dice coefficients than SD in 26 out of total 34 regions."}, {"section_title": "Results", "text": ""}, {"section_title": "Computational Efficiency", "text": ""}, {"section_title": "Cortical Parcellation experiment 4.2.1. Parcellation Accuracy", "text": ""}, {"section_title": "Group average sulcal maps", "text": "To evaluate the performance on a finer scale, we also computed the group mean sulcal depth maps after registration for the test data. The resulting mean and standard deviation maps are displayed in Figure 5 . We assume that a better group alignment leads to a sharper group mean and smaller group variation. As expected, the group mean maps provide more detailed information for all nonlinear registration methods than rigid alignment. Moreover, all these methods show smaller standard deviations, suggesting that they provide better alignment in convexity. All nonlinear registration methods exhibited similar distributions of sulcal variations across brain regions. Specifically, the pre-central, post-central and insula regions show lower standard deviation, suggesting higher agreement of cross-subject convexity in these regions."}, {"section_title": "Robustness Analysis", "text": "We investigated the impact of pole positioning on the registration accuracy for Sphere-Morph by projecting the sphere using 9 different north pole locations spanning \u03b8 \u2208 (0, \u03c0/2, \u03c0), \u03c6 \u2208 (0, \u03c0/6, \u03c0/3, \u03c0/2) and registering the corresponding 2D planar images with corresponding atlas data. We generated the deformed sphere and then re-computed all the regionand distance-based metrics. To evaluate the robustness with respect to different projection centers, we conducted analysis of variance (ANOVA) between all the computed evaluation metrics for these 9 groups. None of the ANOVA analyses (overall Dice: F = 0.2, p = 0.9842, overall MMD: F = 0.93, p = 0.4821) found any significant differences between the 9 groups of cortical parcellations, indicating that the registration accuracy is not sensitive to the arbitrary location of the poles. Figure 6 illustrates the quality of group-wise alignment of convexity after MSM, Spherical Demons, FreeSurfer, and our method on our second test data set. Our method yielded smaller variations within the group than MSM (p = 0.0013), just as in the case of the cortical parcellation experiments."}, {"section_title": "Cross-subject alignment of fMRI activation maps 4.3.1. Group average maps", "text": "While we expect folding patterns to be predictive of functional areas, this relationship is variable and complex. In order to assess how well the various methods align functionally homologous regions across subjects, we computed group average functional activation maps for all 86 tasks using registration driven by sulcal depth information. Figure 7 compares group activation results from the 100 subjects for the Gambling reward contrast. Our method improves the functional alignment across subjects over MSM, particularly in the inferiorparietal and precuneus regions, indicated by the arrows. To evaluate the group alignment performance quantitatively, we computed the average correlations between the group-average and individual activation maps after registration across 86 task contrasts derived from seven tasks. Figure 8 displays average correlations for the different registration methods. For all 86 contrasts, SphereMorph resulted in significantly higher correlation coefficients than MSM (increase of 0.043 \u00b1 0.009, p = 0.028 and relative increase of 8.99 \u00b1 2.85%, p = 0.0024)."}, {"section_title": "Alignment performance analysis using multi-modality features", "text": "We evaluated the performance for the proposed SphereMorph using curvature and (separately) T1/T2 features to their respective atlases, using our sulcal depth alignment as initialization. We computed a 'T1/T2' atlas from three rounds of CNN registration within group. Figure 9 compares the group agreements in task activation for only sulc and two cascade processes using respective curvature and T1/T2 maps. Using T1/T2 as input post sulcal depth-based registration significantly improves the group agreement level (p < 0.01) in four MOTOR tasks, including RF, RF-AVG, neg-RF and AVG-RF, as indicated by the arrows. All four tasks are related to right finger tapping. Figure 10 displays the group average activation for RF constrast. Using the T1/T2 map leads to a larger region with positive response in the paracentral and superiorfrontal areas (marked by arrows) compared to using sulcal depth as the only input."}, {"section_title": "Discussions and Conclusions", "text": "In this paper we present a learning-based method, SphereMorph, for registering cortical surfaces and investigate its performance using two sets of experiments, by comparing it to rigid alignment, 2D VoxelMorph, MSM, Spherical Demons, and FreeSurfer. The proposed SphereMorph yields results that are comparable or superior to the state-of-the-art methods for alignment of folding patterns, cortical parcellation and functional alignment, while offering approximately a 20\u00d7 computational speedup, showing the accuracy and efficiency of our method for cortical registration.\nSphereMorph takes 2D parameterized images as input, outputs the deformation field in a 2D canonical space, then warps the sphere in the original Cartesian space. We directly address two issues associated with the 2D projection: the effects of substantial distortions introduced by the parameterization and the violation of continuity at the borders of the 2D plane (i.e. the imposition of spherical topology). To account for the distortion introduced by the parameterization, we modify the data likelihood term and construct the deformation velocity on a graph weighted by the metric tensor of the parameterization. We use the same weights as in existing work by Khasanova and Frossard [38] to construct our graph as it has been shown to be capable of encoding the geometry of an omnidirectional camera in the final feature representation of an image. In the implementation of network structure, we encode the neighborhood information by leveraging a 3 \u00d7 3 spherical kernel defined in SphereNet [25] instead of a conventional 2D kernel for the network convolution and pooling operations. In addition, we modify the spatial transformer layer to represent the periodicity of longitude in spherical coordinates. Combining these adaptations, our model shows a higher agreement with manual parcellations compared to 2D VoxelMorph, which does not account for distortions and topological changes induced by the 2D parameterization. For 2D VoxelMorph, each point on the rectangular grid contributes equally to the registration, resulting in the alignment of regions near the poles affecting the energy functional more than other regions with the same area in the Euclidean embedding space. Thus, the optimized deformation is over-fitted in these regions. Our experimental results confirm this when comparing the automatically generated parcellations to the manual ones. With an excessive weighting of the alignment of these polar regions, 2D VoxelMorph performs even worse than the initial alignment.\nOur proposed registration framework is applicable to any signal or feature that can be represented or sampled onto the cortical surface. However, in the cortical parcellation experiment, the ADRC dataset only has structural scans. Hence, we trained our model as well as MSM and SD using convexity values to drive the registrations. Our proposed SphereMorph shows significant smaller group variations and higher overall Dice coefficients when compared to MSM, suggesting SphereMorph achieves better structural alignment than MSM.\nIn addition to the accuracy of the structural alignment, when using the same feature (i.e. convexity) for registration, both qualitative and quantitative evaluation results for the taskrelated experiments demonstrate that the proposed method also yields higher agreement of functional regions across subjects than the current registration method in the Human Connectome Project (HCP) pipeline [35] . SphereMorph improves the within-group correlation coefficients significantly for all tasks compared with MSM. The group agreement in convexity is also higher after SphereMorph registration than with MSM. This implies the relationship between cortical folding patterns and boundaries of functional areas as demonstrated in previous work [39] . However, using folding-based features alone may not be sufficient to provide an accurate functional alignment across the entire cortex due to regions with highly variable folding patterns across subjects, as well as structure-function variability. Thus, in the functional alignment experiments, we take the sulcal depth registration as initialization and then use cortical T1/T2 maps as input of our network for a multi-step alignment. The cortical T1/T2 maps are computed based on the ratio of T1-weighted to T2-weighted images which correlates with many functionally distinct areas in individual subjects [40] . The combination of T1/T2 and sulcal depth shows significant improvement in group alignment of MOTOR-related tasks, indicating the correlation between T1/T2 and MOTOR-related regions.\nOur proposed model can include other contrasts in addition to the convexity metrics used above to drive the registration. Existing studies have shown the improvement in group registration accuracy relying on features generated from resting-state functional MRI (rfMRI) after conventional convexity-driven registration [7, 41] . In the future, we will investigate the use of these to further improve the accuracy of our technique."}, {"section_title": "MSM", "text": ""}, {"section_title": "Spherical", "text": "Demons FreeSurfer Figure 7 : Task fMRI alignment resulting from convexity-driven spatial registration using MSM, Spherical Demons, FreeSurfer and SphereMorph. The maps show group activation results from 100 subjects for the Gambling task reward contrasts (with the outline of Freesurfer-based cortical parcellations for easier interpretation). SphereMorph improves the functional alignment across subjects over MSM, particularly in the inferiorparietal and precuneus regions, indicated by the arrows. Figure 9 : Comparison of agreement in 86 task activations using different features. We take the 'sulc' and 'curv' atlases from FreeSurfer and compute a 'T1/T2' atlas from three rounds of CNN registration within group. Contrasts showing significant improvement (p < 0.01) after incorporation of the T1/T2 feature are pointed out by arrows.\nsulc sulc + T1/T2 Figure 10 : Task fMRI alignment driven by using different feature maps (sulcal depth and sulcal depth + T1/T2). The maps show group activation results from 100 subjects for the MOTOR task: RF contrasts, with the outline of Freesurfer-based cortical parcellations for easier interpretation. The arrows highlight the paracentral and superiorfrontal areas, where using the T1/T2 map leads to a larger region with positive response compared to using sulcal depth as the only input."}]