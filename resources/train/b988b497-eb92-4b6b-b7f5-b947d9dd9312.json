[{"section_title": "Introduction", "text": "Examination systems constitute a vital part of accountability systems in schools. Virtually all education systems examine students' educational achievement only that this examination takes place in very different ways. A pivotal feature of the execution of exams is whether they are designed, carried out, and graded by individual teachers or whether they are conducted by an entity external to schools. In external-exam systems, every student takes the very same tests, thus making the central exams an intrinsic part of the school system. The exams, which are usually administered by a public agency, tend to be based on the schools' curriculum and grade student performance into multiple levels of achievement based on an external standard, not just relative to students in a class. While often referred to as central exams, \"central\" need not necessarily mean that the exams are administered by the national government; it can also refer to centralization at some regional level. Being external, neither the teachers nor the students can determine or know the specific questions contained in the exams. To improve performance, it is necessary to teach, or respectively learn, the whole curricular standards on which the exams are based. The external exams may be given in each grade in primary and/or secondary school, in several grades, or as in the special case considered in the empirical part of this paper they may take the form of exit exams administered at the end of secondary education, with a minimum score generally required for graduation. The incentives that students, teachers, schools, administrators, and parents face differ substantially between external-exam systems and teacher grading. This paper analyzes these differences and assesses their impact on the functioning of the education system and ultimately on students' academic performance. The analysis draws on new international evidence from two large cross-country comparative studies of student performance, TIMSS and TIMSS -Repeat.' The original TIMSS study was conducted in 1994/95. TIMSS-Repeat was conducted in 1998/99, with the data only recently made available. Data on nationally representative samples of middle-school students is available for 39 countries in TIMSS and for 38 countries in TIMSS-Repeat, with 23 countries Participating in both studies. Students were tested in math and science, two central areas in the curriculum of I The original meaning of TIMSS was \"Third International Mathematics and Science Study,\" as it followed two individual mathematics studies and two individual science studies that had been conducted between 1964 and 1984. TIMSS has since been renamed the \"Trends in International Mathematics and Science Study,\" as assessments are now meant to be conducted on a regular basis every four years. The TIMSS-Repeat study is also known under the acronyms TIMSS-R and TIMSS 1999."}, {"section_title": "2", "text": ""}, {"section_title": "4", "text": "BEST COPY AVAILABLE any education system. The data used in this paper includes performance data in both math and science for about 450,000 individual students, as well as background data on families, school resources, and institutional settings for individual students, teachers, and schools. This rich micro database allows the estimation both of how students perform in education systems with and without central exams, and of whether the extent of school autonomy, teacher influence, and parental involvement have different consequences in education systems with and without central exams."}, {"section_title": "Information, Monitoring, Incentives, and Behavior", "text": "Accountability systems generally consist of three components: performance standards, measurement of student performance, and consequences for measured performance. Centralexam systems are a specific way of measuring performance, usually against some pre-defined standards, that do not necessarily have to have explicit consequences attached to the tests. In contrast to many accountability systems currently discussed in the United States that set explicit monetary rewards or sanctions in response to performance such as school-based accountability systems with monetary consequences for schools or merit-pay systems with monetary consequences for teachers , central-exam systems usually do not set monetary rewards or sanctions themselves. Instead, they rely on the \"spontaneous\" behavior of the different stakeholders in the education process, thereby working mostly indirectly through implicit consequences.2 Most importantly, central exams provide information on how individual students perform relative to the national (or regional) student population. This information is not given in the absence of central exams, when classroom teachers grade their students. In the latter setting, performance is generally not comparable across classrooms, and nobody knows whether a mark earned in one class reflects the same scope of contents as a mark earned in another class. In contrast, the information provided by central-exam systems signals the performance of students, teachers, and schools, and it thus facilitates the monitoring of the behavior of the different stakeholder in the education system. Given that the whole education process is fraught with agency problems where principals cannot directly observe what their agents are doing giving agents leeway to act \"opportunistically\" , this role performed by central exams may be pivotal to how the education system works. The information they create may be used by a lot of stakeholders in education and even beyond the actual education system. Rewards for capable and striving teachers may come from their heads of school who now are able to monitor teachers' performance, and rewards for studious students may come from the labor market, where potential employers or institutions of higher education now have the necessary information to compare different students' performance. Likewise, lazy students may be sanctioned in the labor market, and both teachers and schools may be pressured to perform by parents and administrators, who now possess the necessary information to evaluate their performance. In effect, central exams thoroughly change the incentives faced by the different stakeholders in education, focusing incentives on student learning. In terms of teaching and learning, a pivotal difference in the incentive mechanism of central exams relative to teacher-set exams is that neither teachers nor students know beforehand which specific questions are going to be asked. Teachers therefore cannot \"get away\" with skipping whole content areas in the classroom. They are instead forced to teach the whole subject areas as prescribed in the standards and cannot effectively scale down the standards. Furthermore, if well implemented, the possibility of teacher cheating for example by discussing the specific questions of the exam beforehand or by telling students that certain content areas will not be covered in the exam is eliminated. It has been stressed that central-exam systems focus on students as the pivotal stakeholders in education (Hanushek 2002). The recent discussion on accountability systems in the United States tends to argue that schools should be the primary unit of accountability (Ladd 2001). In this paper, I will argue and present supporting evidence that this contrast between central-exam and school-based accountability systems in terms of whose behavior should be targeted may be more apparent than real. By focusing incentives on student performance, central-exam systems alter the way all stakeholders in education behave. The evidence suggests that the changes induced in the behavior of teachers and schools may actually be more important than the changes induced in the behavior of students. Summary of findings. The evidence from TIMSS-Repeat confirms previous evidence from TIMSS that students in countries with central exit-exam systems perform better in their middleschool years both in math and in science than students in countries without central exams. This finding holds even after controlling for a large set of variables reflecting for family background, resource endowment, and other institutional features of the school system. The size of the performance difference is substantial, lying in the range of 35 to 47 percent of an international standard deviation in test scores, and it increases from seventh to eighth grade. Students from each performance quartile of a country perform better in central-exam systems. While in math, higher-performing students seem to gain slightly more from central exams, no such difference among performance quartiles is evident in science. There is some evidence that central-exam systems dampen the effect of parental education on students' performance, thereby leading to more equal educational opportunities for students from different social backgrounds. Evidence 5   7from the inclusion of a large set of controls and from restricting the analysis to within-region variation suggests that the case for substantial bias in the estimates is weak. Central exams alter the way schools and teachers behave. Increased autonomy for schools in decision-making areas that include scope for opportunistic behavior, such as budgetary decisions and the determination of teacher salaries, has much more beneficial effects when central exams are in place. This finding is consistent with the claim that opportunistic behavior is decreased when central exams enable better monitoring of schools' behavior. At the same time, there is some evidence that central exams limit the useful freedom of schools and teachers in decisionmaking areas that do not include much scope for opportunistic behavior, such as day-to-day tasks like choice of supplies and textbooks. Central exams seem to ensure that student learning is focused on the educational goals of the system, with the effect of regular testing and homework on student performance generally being more beneficial in central-exam systems. The involvement of interested parents is conducive to student performance in central-exam systems even when teachers deem this involvement as limiting their teaching, a result not found in systems without central exams. This may be attributed to the better information available to parents in central-exam systems. Given that the performance tests of TIMSS and TIMSS-Repeat are general tests of students' knowledge in math and science on which representatives from all participating countries have agreed, these tests may be viewed as an independent test of whether central exams lead to real increases in the students' knowledge or whether they just lead to teaching and learning to the specific high-stakes central exam. The fact that students in central-exam systems perform better on the TIMSS and TIMSS-Repeat tests suggests that students in central-exam systems do indeed learn more in terms of mathematical and scientific knowledge, rather than just learning the specific central exam. Given the serious shortcomings of most school-and teacher-based accountability systems, central-exam systems seem to be a promising alternative device for focusing the incentives of all educational stakeholders on student learning."}, {"section_title": "How Central Exams Change Behavior", "text": "2.1 Central Exams as an Accountability Device to Mitigate Agency Problems Accountability systems are often defined narrowly as systems that \"reward and punish schools by allocating funding according to whether the school meets certain performance criteria\" (Figlio and Page 2002). In this paper, I define accountability systems more broadly as any device that attaches consequences to measured educational performance. That is, the two common features of accountability systems are that they measure students' educational achievement directly, and that they attach consequences to measured performance. These consequences may be positive (rewards) or negative (sanctions), they may be implicit as well as financial or otherwise explicit, and their target may be any educational stakeholder, be it districts, schools, teachers, or students. While good performance would generally be rewarded, poor performance may lead either to sanctions or to more positive consequences such as additional assistance. Proponents of accountability systems hope that attaching consequences to student outcomes will lead to better educational performance in the school system (cf. Hanushek and Raymond 2001). Without such proper consequences, the motivation of educational stakeholders to put effort into improving educational outcomes may be rather low. By holding stakeholders accountable for performance, their incentives to work in order to yield superior performance are increased. Why should explicit systems to introduce accountability be necessary in the first place? The answer is that a whole network of principal-agent relationships prevents accountability from being automatically secured in education. The first feature of a principal-agent relationship is \"asymmetric information\": The agent who is under a contract to a principal to perform a task has more information on what exactly he is doing than the principal. That is, the principal's monitoring of the agent's behavior is imperfect, limiting the principal's ability to hold the agent accountable. For example, teachers and parents do not perfectly know how much effort a student puts into learning; heads of school and parents cannot perfectly monitor how well a teacher prepares his or her lessons and what he or she does in the classroom. The second feature of a principal-agent relationship is that the agent and the principal have different interests. For example, students may be more interested in leisure relative to putting effort into learning than their parents would want them to be; heads of schools and teachers may be more interested in 7 9 their own finances and in a bearable workload relative to students' learning than parents and administrators would want them to be. Such differing interests make the lack of accountability in principal-agent relationships a problem. The extent to which agents' interests differ from their principals' interests will obviously depend on the specific task or decision-making area in question. For example, the difference in interests between principals and agents may be larger when the decisions affect the financial well-being of the agent than when they do not. Together, incomplete monitoring due to asymmetric information and divergent interests lead to the possibility of \"opportunistic\" behavior on part of the agent that is, the agent will further his own interests rather than the principal's. Accountability systems produce information on performance. As a result, they may be able to ease the monitoring problem inherent in principal-agent relationships. Central exams are one such accountability device. By producing comparable information on student performance, they go some way towards eliminating the informational asymmetry between principals and agents ubiquitous in education. Thus, they enable an improved monitoring of the behavior of the different stakeholders in education. Figure 1 provides a stylized picture of educational stakeholders and the monitoring relationships among them.3 Students, the ultimate focus of the whole system, are most directly monitored by their parents and by their teachers. After having completed their general education, their educational performance may also be monitored by potential employers and institutions of higher education. Teachers are monitored by the heads of their schools and by the parents of the students whom they teach. Schools in turn are monitored by the educational administration and by the parents of their students.C entral exams can provide the principals in this network of agency relationships with information that is not available in education systems without central exams, facilitating the monitoring of agents' behavior. The different principals may use this information in order to infer consequences on their agents in response to the agents' performance. This helps align the incentives of the different agents with the goal of the education system, namely the educational This picture is rather stylized as further educational stakeholders and relationships can be thought of from which it abstracts. However, it is assumed that it identifies the most important features affecting student performance. performance of the students. As a result, agents' effort to improve performance should increase, and teaching and learning should become more focused on the educational goals of the system. These beneficial effects of central exams on educational performance should be especially large when tasks are involved that include a large potential for opportunistic behavior, that is, when both informational asymmetries and interest differentials involved in the principal-agent relationship are large. In such cases, a lot of opportunism diversion of behavior from the goals of the education system can be curbed. Administrators, Schools, Teachers, and Students This basic mechanism of how central exams affect behavior in the education system can be detailed more clearly when focusing on the different principal-agent relationships depicted in Figure 1. The behavior of all educational stakeholders parents, administrators, schools, teachers, and students is affected by the existence of central exams, establishing several channels through which central exams may impact how school systems work and, ultimately, how students perform in terms of educational knowledge. In addition, the existence of central exams may change the way in which other institutional features of the school systems, such as the degree of decentralization in decision-making, affect behavior and student performance.5"}, {"section_title": "The Impact Channels of Central Exams: Effects on the Behavior of Parents,", "text": "Parents. Given central exams, parents have information on the performance of their children against an established standard and relative to other students in the education system. This is valuable information: Parents can not only assess their child's performance against an absolute standard, but they also have some knowledge to decide on who might be responsible for this performance. For example, parents will generally know the performance of some other students in their child's class and the average performance in the country. Thus, in contrast to a system of teacher grading, parents now know whether it is mainly their own child who is doing badly or whether it is the whole class which is performing badly. That is, with central exams they are in a better position to monitor the performance of students, teachers, and schools. Consequently, parents are able to put pressure on students and/or teachers whomever they deem responsible for the poor performance of their child. When teachers grade their students themselves and students get marks relative to their class mean only, parents are not able to observe the performance of the class relative to the country mean and thus have no information on which to base a potential intervention. The existence of the information disseminated by the central exams on part of the parents is thus likely to affect the behavior of both students and teachers (see below). In the same way, parents can now monitor the performance of the whole school relative to other schools, and of the administrative entity relative to others. Moreover, the rather implicit monitoring by parents may have the advantage over any system of explicit monitoring by some administrative mechanism that given their decentralized knowledge, parents may be able to assess fairly well what quality the student intake of a school has in terms of prior ability and thus what might and might not be expected in terms of ultimate performance. Explicit systems of school-based monitoring from above, in contrast, seem to be hard to implement in a meaningful way (see Section 6 below). While central exams provide information to all parents, not necessarily all parents will be willing and able to make use of it. Thus, the impact of central exams might differ depending on how strongly parents care for their child's progress. In central-exam systems, parents who show interest in how much their child is learning have a meaningful foundation to intervene and will probably use this opportunity to pressure students and teachers to increase their effort, but parents who are less concerned with their child's educational performance may not make use of the additional information. Involvement of interested parents in the teaching process may thus be more beneficial in a central-exam system, while this channel may not work with parents who are less interested. Administrators. Just like parents, administrators can also get valuable information from central-exam systems that enables them to monitor schools' performance and to draw consequences from their relative performance. While a school's low teaching effort might not be noted by administrators who lack comparable performance information, it would be more likely to attract administrators' attention with central exams. Administrators will usually have even more comparative information on performance than parents because they have access to measured performance for all the students in the systems and for successive years. This enables them to monitor the relative performance of schools and teachers even closer. Crucially, administrators will also have stronger incentives themselves to ensure good performance of the 10 12 school system because given the information spread by central exams, their behavior will now be more closely monitored by parents, the electorate, and the government. 6 Given the equivocal meaning of the term \"principal,\" this paper refers to the person responsible for a school as the \"head of school.\" In terms of the principal-agent theory detailed above, the head of school is both an agent in his relationship with administrators and parents and a principal in his relationship with teachers."}, {"section_title": "11", "text": "BEST COPY AVAILABLE 13 that is, when information asymmetries as well as differences in interests between schools and parents or administrators are both large , the extent of monitoring is vital to whether autonomous decisions will be carried out in the interest of student learning or not. Without central exams, schools with substantial autonomy may act in ways inconsistent with furthering student achievement without penalty, as their detrimental behavior cannot be observed. With central exams, by contrast, the results of such opportunistic behavior will be observed, forcing schools to lean more towards behavior conducive to student performance. Informational asymmetries are quite large in most areas of educational decision-making. However, the extent to which schools' own interests run counter to the interest of furthering student knowledge will depend on the specific task, or area of decision making, in question. It might be expected that schools have a strong self-interest running counter to student learning whenever there is money involved in the decision, as it is only natural to try to increase the personal payoff for a given level of work (or, conversely, to reduce the level of work for a given payoff). It is in this group of tasks where devices that hold agents accountable should have their largest beneficial impact. By contrast, schools' own interests may be well in line with student learning in such decision-making areas as the choice of textbooks or supplies, as it is not obviously in the interest of schools to use poor supplies. In these tasks, the scope for opportunistic behavior is limited, and the need for accountability systems is correspondingly small. The effects of school autonomy also depend on whether decentralized knowledge is important for a specific task. In many decision-making areas, local decision-making is likely to be more informed because it can draw on the decentralized knowledge that is available to schools, but not to any central entity. The extent to which decentralized knowledge is important again depends on the decision-making area in question. For example, the best way to transfer educational contents to students may vary among schools in different locations, making local discretion regarding the most suitable teaching techniques and supporting equipment vital. By contrast, decisions concerning the body of knowledge that students should be taught may be best made at a central level, rather than by individual schools. These two considerations, severity of opportunism and importance of local knowledge, jointly determine the expected net impact of school autonomy in a given area of decision-making on students' educational achievement in systems without and with central exams. Figure 2 summarizes these relationships. If, on the one hand, there is no danger of opportunism in a task, the impact of school autonomy will be equivalent in systems without and with central exams: It will be conducive to student learning when local knowledge is important to the task (cell [N2a] in Figure 2), and it will have no impact on student performance when there is no specific local knowledge involved [N1].7 The one exception to the equivalence between the two systems in the absence of opportunism is when central exams limit the leeway within which schools can decide and when at the same time local behavior beyond this leeway would be superior [N2b]; in this case, central exams might reduce the extent to which school autonomy is beneficial for achievement. If, on the other hand, the potential for opportunistic behavior is large, decentralized decisionmaking will have substantially different effects in systems without and with central exams. If there are no central exams and local knowledge is not vital [01], the possibility of opportunistic behavior will make school autonomy strongly detrimental to student learning. As schools' incentives are focused on student learning when central exams are in place, the negative impact of local behavior will be eliminated. When local knowledge is important for a task [02], the negative impact of school autonomy in systems without central exams is lessened to some extent, although the detrimental effect of opportunism may still overcompensate the positive influence of local knowledge. But once opportunism is curbed through central exams, it can be expected that decentralized decision-making will lead to superior outcomes as it can draw on superior local knowledge. In short, changing the way in which decentralization affects outcomes is one impact channel through which central exams may affect educational performance, and they should be especially helpful whenever opportunism can be curbed. Similarly to school autonomy, decentralization of decision-making authority to individual teachers will have different effects in systems with and without central exams. Teacher autonomy in tasks where local teacher knowledge might help informed decisions but where the scope for opportunism is substantial should change from being detrimental to student learning without central exams to being conducive under a central-exam system. An example of substantial scope for opportunistic behavior by teachers may be tasks involving money for supplies. 7 If central knowledge is superior in a task, then rendering schools autonomy in this task might even be detrimental to student achievement. Students. Central-exam systems also align the incentives of students with increased educational achievement through several channels. Teachers and parents have better performance information to monitor students' behavior. As teachers' incentives are aligned more closely with students' educational performance through central exams (see above), their capability to monitor their students' performance enables and impels them to initiate appropriate consequences. Even more, parents can monitor their children's performance better given central exams, and it is generally the assessment and behavior by their parents that children care most about. Having to expect decisive actions as a result of their performance should change students' own effort to achieve high performance. A further channel through which central exams prompt students to achieve higher is by increased external rewards for learning. As potential employers and institutions of higher education have central exams at their disposal to assess applicants' educational performance, they can base their hiring decisions more on observed educational performance. Thereby, students get incentives from outside the school system to increase their performance. Additionally, central-exam systems might alter the behavior of students' peers relative to a system of teacher grading. With teachers grading relative to the class level, peer pressure against learning (\"nerd harassment\") might be a viable strategy to lower average performance of the class, which allows every student in the class to get the same grades at a lower effort level (Bishop 1999a,b). The existence of central exams should decrease this peer pressure against learning, because the mark received by one student is no longer affected by the marks of other students in the class and because lowering the standards taught in the class will hurt all students in the class. It is sometimes hypothesized whether central-exam systems or other accountability systems affect students of different ability levels differently. On the one hand, if the standards to be tested are set too high, central exams might affect the behavior of high-performing students, but not of low-performing ones. While the impact channels running through altered teacher and school behavior might still render positive effects also for low-performing students, high performers would gain disproportionately. On the other hand, if the central exams were only minimumcompetency tests, low-performing students might be positively affected, but top-performing ones might not be affected at all. A similar pattern would emerge if high-performing students were entirely self-motivated to achieve higher performance so that additional incentives might have no noticeable effects, while poor-performing students need some pressure from the incentives established by central exams. Contrarily again, high performers might get positively motivated by central exams, while poor performers might have their initiative blocked by the fear of not doing well enough. In the end, if the central exams are implemented to grade students into multiple levels of achievement, students of different ability levels might just be affected equivalently, and there might be no notable difference in the impact of central exams on the performance of students with different initial ability, as everybody responds to incentives. In a similar way, it is not clear ex ante whether students from different family backgrounds would be affected differently by central exams. In sum, student performance may be expected to increase under a system of central exams. However, these improvements need not predominantly come through increased student effort, but may instead arise from many different channels. Through increased monitoring, the incentives of all agents in the education process are directed at furthering of students' knowledge. However, it is ultimately an empirical question how strongly the different 15 i7 stakeholders respond to their altered incentives by focusing their behavior on the advancement of student performance. Thus, the remainder of the paper analyzes the empirical evidence on the overall impact of central exams and on the behavioral responses of the different actors."}, {"section_title": "International Data", "text": ""}, {"section_title": "The Micro Databases of TIMSS and TIMSS-Repeat", "text": "While the mode of exam systems does vary within a few countries, the main variation is across countries. Therefore, the empirical evidence in this paper draws on two large international comparative studies of student achievement, the Third International Mathematics and Science Study (TIMSS) of 1995 and its replication in 1999. In the following, the original TIMSS study will be referred to as TIMSS-95, and the repeat study will be referred to as TIMSS-Repeat. While students from three different age levels were tested in TIMSS-95, the number of participating countries was by far the largest at the lower-secondary or middle-school level. The target population of TIMSS-95 in middle school were the two adjacent grades with the highest share of 13-year-old students, which were seventh and eighth grade in most countries. TIMSS-Repeat was conducted only at the middle-school level, with the target population being the upper grade of the two adjacent grades with the highest share of 13-year-old students (eighth grade in most countries). Within each participating country, a random sample of schools was selected, and one class within each target grade of these schools was randomly chosen and entirely tested in both math and science, yielding a representative sample of students within each country. Both studies were conducted by the International Association for the Evaluation of Educational Achievement (IEA), an independent cooperation of national research institutes and governmental research agencies. The development of the test contents was a cooperative process involving national research coordinators from all participating countries. This, together with the fact that all participating countries endorsed the curriculum framework and that substantial efforts were made to ensure high-quality sampling and testing in all countries, should make the student performance tested in the TIMSS tests comparable across countries. As two thirds of the test items of TIMSS-95 had been released to the public after the study was conducted, these items had to be replaced in TIMSS-Repeat. The items substituted were similar in terms of content, format, and level of difficulty. In both studies, a quarter of the items (meant to cover a 16 18 third of the testing time) were free-response items, sometimes requiring extensive responses, while the remainder of the items were multiple-choice questions. Both studies also performed a test-curriculum matching analysis that restricted the analysis to items definitely covered in each country's curriculum; this had little effect on the overall achievement patterns.9 In addition to testing students in math and science, the two studies collected contextual information in three background questionnaires: a student questionnaire, a teacher questionnaire, and a school questionnaire. Each student answered questions about his or her demographic characteristics and home background. The math and science teachers of each tested class answered questions about their personal characteristics and classroom environments. Heads of school answered more general questions about the school's administrative structure. The set of participating countries differed between the two studies. Of the 39 countries for which complete data sets had been available for TIMSS-95, 16 did not repeat the assessment in 1999. Thus, 15 of the 38 countries participating in TIMSS-Repeat were new to the international assessment. The difference in participating countries allows for a test of the robustness of previous findings obtained using TIMSS-95 data on a substantially altered set of countries. Table 1 shows the countries participating in TIMSS-95 and in T1MSS-Repeat. The first two columns report the size of the student samples in each country in the TIMSS-95 and the TIMSS-Repeat assessments, respectively. The average sample size across all participating countries was 6,834 students in TIMSS-95 and 4,751 students in TIMSS-Repeat. In total, the TIMSS-95 database contains micro-level information on 266,545 individual students in seventh and eighth grade from 6,107 schools. The TIMSS-Repeat database contains equivalent information on 180,544 individual students in eighth grade from 6,068 schools. The subsequent columns of Table 1 report the average performance in math and science of the countries participating in TIMSS-95 and TIMSS-Repeat. For most of the countries that participated in both studies, the difference between the performance levels achieved in 1995 and 1999 was small and statistically insignificant (see Mullis et al. 2000;Martin et al. 2000b). 9 For details on the content areas covered in the math and science tests, on sampling and implementation procedures, questionnaire development, translation verification tests, data collection, quality control procedures in all steps of the study, data processing, and test-score scaling in TIMSS-Repeat, see the TIMSS documentation contained in Mullis et al. (2000), Martin et al. (2000a,b), and Gonzalez and Miles (2001). For details on TIMSS -95, see WoBmann (2002a) and the references therein. The TIMSS-95 database used in this paper is taken from WO8mann (2002a), which contains a detailed description of its construction and content. This database combines the TIMSS-95 performance data in math and science with data from the different background questionnaires for each individual student and includes imputed values for missing values of questionnaire data. The TIMSS-Repeat database was constructed for the purposes of this paper. The construction of this new database is described in the Appendix. The two micro databases based on the two TIMSS studies include rich student-level data for representative samples of students from all the participating countries. Drawing from the background-questionnaire data contained in the databases, the analysis in this paper uses 17 variables to control for students' family background, 13 variables to control for resource endowment and teacher characteristics, and 18 variables to control for the institutional setting of the education system.1\u00b0 To enable an even higher statistical precision in the estimation, the two databases were also pooled into one large TIMSS dataset containing information on 447,089 students. The TIMSS micro databases were merged with data on the existence of central-exam systems in the participating countries. While in some countries, central exams exist at several grade levels during secondary school, the most common form of central-exam systems is schoolleaving exams at the end of the upper-secondary school level. Therefore, the measure of central exams used in this paper is whether a country (or regions within a country) has a system of central exit exams or not, with all forms of \"curriculum-based external exit exam systems\" (CBEEES, see Bishop 1999a) included. The measure does not recognize university entrance exams, as these are usually not taken by all students and do not constitute an integrated part of the school system. The exam data used in this paper, most of which was provided by John Bishop, is based on reviews of comparative-education studies and educational encyclopedia, interviews with representatives of the national education systems, government documents, and background papers.ii The data is presented in the final columns of Table 1. When central-exam systems were present in some parts of a country but not in others, the value indicates the share of students in the country facing central exams. While the central-exam data refers to exit exams at the end of upper-secondary school, the data on students' educational performance refers to the lower-secondary or middle-school level. to For a complete list of these control variables, see Appendix Table Al a.   18   20 Central exams might be expected to have the most direct impact on performance in the year leading to the exam, but their impact should also extend into lower levels. This is especially the case for exit exams, which tend to test all the knowledge learned in secondary school and whose signaling effect may change incentives during the whole school life of a student. As the impact of school-leaving exams should become more salient the closer students are to taking them, the effects on student performance should become stronger in higher grades. This implication can be tested using the TIMSS-95 data, which allows a comparison between seventh-and eighth-grade performance."}, {"section_title": "What Can Be Learned from International Evidence on Central Exams:", "text": "Opportunities and Limitations The use of international comparisons to estimate the effect of central exams on student performance presents both opportunities and limitations. Its main virtue lies in the fact that the institutional variation that exists between countries is an important source of information that can be exploited institutional variation that is not given within most countries. Thus, the variation both in central exams and in the extent of school autonomy can help to shed light on the effects hypothesized in Section 2. To test the hypotheses on how central-exam systems affect student performance, variations in student performance have to be related to variations in exam systems and other institutional features. As these are not given within most countries, the international evidence has the potential to reveal relationships not usually evident in national data (see Understanding the sources of international variation in student performance is also an interesting research question in its own right. For example, recent research has shown that international differences in student performance matter a lot for international differences in economic growth and levels of development (Hanushek and Kimko 2000;Barro 2001;Wol3mann 2003). However, cross-country comparisons also face important limitations. First, the extent to which findings from cross-country evidence apply to individual countries may be limited. For example, if the research question is how a specific reform would affect performance in a specific country, it might be especially instructive to look at the performance in countries that are similar to the one in question in all respects except for the one regarding the reform issue. If, by contrast, the comparison country exhibits many other institutional features that differ from the country in question, assuming the same behavior and results in response to the reform might be poor inference, as different institutional settings may set different incentive environments and thus cause different behavioral responses (cf. Hoxby 2002b). This limitation can, however, be alleviated by using a multiple regression analysis that both incorporates multiple countries and controls for multiple influences. Controlling not only for the influences of family background and resource endowments, but also for institutional features of the school system, the most important effects of other features that might differ between countries should no longer affect the estimate of the specific reform issue of interest. Even more, this is where the use of individual student data comes in as especially helpful. While much of the previous cross-country research was performed at the country level and was thus unable to account for differences in local features within the school systems (e.g. Given that many institutional specifics will affect educational outcomes at the same time as central exams, the most severe limitation facing a cross-country analysis of the impact of central exams probably is the potential for bias due to omitted variables. The inference from international evidence might be affected by country characteristics that the analysis does not perfectly take into account. In addition to other institutional settings of the school systems, some people argue that much of the international variation in student performance may be due to more fundamental cultural differences. In as far as such cultural differences are related to the existence of central-exam systems, the estimates of the coefficient on central exams might pick up these other cross-country differences and thus be a biased estimate of the impact of central exams. One way to assess the potential for omitted-variable bias in the estimation of the impact of central exams is to include controls for additional institutional features of the school system. This Two more issues of the interpretation of the international evidence presented in this paper have to be addressed. First, it might be argued that the existence of central-exam systems may be endogenous to the level of educational performance in a country. This would again introduce bias into the estimate of the effect of central exams on student performance. However, it seems unlikely that endogeneity would introduce a noteworthy effect in this case, both because the potential size of such a bias may be deemed relatively small and because the existence of centralexam systems is generally a long-run institutional feature of the school systems that does not change often. As central-exam systems have been in place for decades in most countries, they would certainly not be endogenous to the performance of individual students in school today. Even more, the idea of endogeneity of a central-exam system would presumably be that governments introduce such a system in order to improve the poor performance of students. In this case, performance would have a negative effect on the prevalence of central exams, biasing standard least-squares estimates of the effect of central exams on student performance downwards. The estimates presented in this paper would thus be conservative estimates of the impact of central exams as they \"err on the right side.\" Second, there is unfortunately not much information about the specifics of the different central-exam systems in the different countries. In some systems, the performance of students and schools on the exam may be made publicly available, while this may not be the case in others. Some school system may use the exam information to decide on whether a student is promoted to the next grade or has to repeat the grade, while others may not. Some systems may have regular central exams during secondary education, others not. Some central exams may be purely multiple choice, while others may have essay-type questions. Unfortunately, the evidence presented in this paper does not say much about these specific features of different central-exam systems, but can only produce estimates of the general effect of whether there is central examination at all or not. As a further consequence of this and of the potential for the omission of other influence variables, the coefficients on central exams estimated in this paper should be interpreted as measures of the impact of central-exam systems and everything else that goes with them which might, in some cases, be testing earlier in school, no-social-promotion policies, and other educational policies. To sum up what can be learned from international comparisons, they establish a major source of information on the effects of central-exam systems not available in within-country research, as long as their limitations are borne in mind. If the research question is what role central exams can play in an explanation of the cross-country variation in student performance, attention has to be given to attempts to minimize the potential for biasing effects, and the interpretation of the results should bear these in mind. If the question is what a specific country say, the United States can learn from the international evidence on central exams and student performance, one should additionally focus the analysis on the effects of central exams in settings that are most relevant for the country. In the United States, which has a highly decentralized school system with substantial local autonomy in terms of funding, teacher contracting, and curricular choices, this may mean that the interaction effects of central exams with local autonomy may be especially relevant. While reduced-form estimates of the impact of central-exam systems may not necessarily translate directly to the United States, a more detailed look at the different impact channels may be highly informative for American policymakers."}, {"section_title": "Central Exams and Student Performance:", "text": "The International Evidence The results of the base regressions are reported in Table 2a for math, and in Table 2b  According to these estimates, students in countries with central-exam systems scored 40.9 percent of a standard deviation higher on the TIMSS-95 math test than students in countries without central-exam systems, controlling for effects of family, resource, and institutional background. Similarly, the lead of in countries with central exams was 47.0 percent of a standard deviation in the TIMSS-Repeat math test. In the pooled math regression, the lead was 42.7 percent of a standard deviation. In science, students in countries with central-exam systems scored 39.7 percent of a standard deviation higher in TIMSS-95, 35.9 percent higher in TIMSS-Repeat, and 35.9 percent higher in the pooled analysis. All these coefficients on central exams are statistically significant at the 1 percent level. Thus, the first result of this analysis is that the findings based on the TIMSS-Repeat test, with its differing set of participating countries, confirm previous findings derived from TIMSS-95 (Bishop 1997(Bishop , 1999aWol3mann 2002a) that central exams seem to exert a substantial positive impact on the educational performance of students. Furthermore, the size of the estimated coefficient is robust to the use of the new dataset: When the impact size is allowed to differ between the two tests in the pooled regression by including an interaction term between central exams and a dummy for the TIMSS-Repeat test, the difference in the size of the estimate is statistically insignificant both in math and in science. The substantial size of this impact estimate can be seen when comparing it to the impact sizes estimated for other policy reforms in other studies. For example, Krueger (1999) found for the It is informative to analyze how much of the international variation in student performance is due to the existence versus lack of central-exam systems in the different countries. In the specification of the pooled datasets that includes all the family, resource/teacher, and institutional control variables, adding the central-exam variable increases the explained proportion of the total variation in student test scores (the R2) by 2.4 percentage points in math (from 0.260 to 0.285) and by 1.9 percentage points in science (from 0.237 to 0.256). Relative to the total cross-country variation, which is 34.1 percent of the total cross-student variation in math test scores and 28.5 percent of the total variation in science test scores, this proportion of the variance additionally explained by central-exam systems is 7 percent of the total crosscountry variation, both in math and in science. That is, about 7 percent of the international variation in math and science performance can be attributed to the existence of central-exam systems. gain in effectiveness of resource usage might even over-compensate any direct cost of implementing a central-exam system."}, {"section_title": "Effects by Grade", "text": "The measure of central exams used in this paper is one of exit exams at the end of uppersecondary school, while student performance is tested in seventh and eighth grade. Thus, the reported results suggest that central exit-exam systems send incentive signals down to grades in lower-secondary school. As suggested in Section 3.1 above, these incentive signals might be expected to be stronger in eighth grade than in seventh grade. This hypothesis can be tested using the TIMSS-95 data, as students from both grade levels were tested in this test.16 Unfortunately, this is not possible for the TIMSS-Repeat data, as this tested only eighth-grade students. In TIMSS-95, the impact seems to be larger for students in higher quartiles, while in TIMSS-Repeat it seems slightly smaller for students in higher quartiles. To see whether these differences in point estimates are statistically significant, Panel B of  In sum, the results show that the disadvantage of coming from a less beneficial family background seems to be reduced by central exams in math, while the pattern is less clear in science. This suggests that, at least in math, central-exam systems work towards equalizing opportunities for students from different family backgrounds. Together, the evidence on effects by performance quartiles and by family background suggests that high-ability students from poor family backgrounds seem to gain the most from central exams."}, {"section_title": "The Potential for Bias in the Estimates", "text": "It has been shown in Section 4.1 that the biases from omitting measurable variables of family, resource, and institutional background are relatively small and generally attenuate the estimate of the impact of central exams. These findings may dampen concerns about any potential bias due to unmeasured omitted variables. As argued in Section 3.2, eliminating the inter-regional variation and confining the analysis to intra-regional variation might be another way to evaluate the potential for biases, as any biasing impact of differential cultural backgrounds should be mitigated. In the TIMSS-Repeat math study and in the TIMSS-95 science study, the estimate on central exams does not change much by the inclusion of the regional dummies, and in the TIMSS-Repeat science study, it increases. In the pooled regressions, a statistically significant positive estimate prevails which is smaller in the case of math when the regional dummies are included and larger in the case of science. Neither in the pooled math estimation nor in the pooled science estimation is the difference in the coefficient estimate on central exams between the regression with and without regional dummies statistically significant.18 Thus, the case for substantial omitted-variable bias seems to be weak also on the basis of the comparison of the base estimation to the within-regional estimation. The cautious conclusion to be drawn from these findings should be that the potential size of a bias seems small in most cases, that the direction of any bias can be either upwards or downwards, and that the case against interpreting the base estimates of Tables 2a and 2b as reasonably accurate estimates of the actual impact of central exams on student performance is weak. 18 Based on Hausman tests, the standard error of the difference of 0.142 in math is 0.089, and standard error of the difference of 0.058 in science is 0.069. The only case where the difference is statistically significant is, obviously, the TIMSS-95 math case (0.348 (0.093)); this is also the only case where the Hausman test rejects the null hypothesis that all coefficients (including the control variables) combined are not systematically different (2(45) = 61.89, probability >x2= 0.048)."}, {"section_title": "30", "text": "BEST COPY AVAILABLE 1..) 9 4.)"}, {"section_title": "How Do Central Exams Change the Working of the Education System?", "text": "The previous section presented results on the overall impact of central-exam systems on student performance without distinguishing between different impact channels. This section asks whether and how central exams exert their effects through several impact channels by changing the behavior of the different stakeholders in the education process. This is tested by analyzing whether different institutional features of the school system that relate to the influence of schools, teachers, and parents in the education process have different effects on student The first decision-making area analyzed is whether schools have autonomy over their 19 While the regressions on which the pictures in Figure 3 are based control for the whole set of family, resource, and institutional controls listed in Table Al a, they do not control for interaction terms between central exams and other variables. As will become evident in Table 7 below, the estimate of the genuine effect of central exams gets very imprecise once a whole set of interaction terms is introduced. Excluding other interaction terms allows to base the size of the bars depicting the impact in central-exam systems on reasonably exact, statistically significant estimates of the general effect of central exams. Figure 3 are statistically significantly different from zero."}, {"section_title": "All estimates reported in", "text": ""}, {"section_title": "32", "text": ""}, {"section_title": "BEST COPY AVAILABLE", "text": "The results depicted in Figure 3a Figure 2). This seems to be the case in the task of determining teacher salaries (Figure 3b). In systems without central exams, students in schools that have autonomy in determining teachers' salaries perform worse than students in schools that do not have salary autonomy. This might reflect that schools again behave opportunistically in this decision-making area where money is involved, as long as they cannot be held accountable to their behavior. In systems with central exams, by contrast, students in schools with salary autonomy perform better, not worse, than students in schools without salary autonomy. That is, the effect of school autonomy is reversed once central exams are in place. It seems that in salary decisions, heads of school know better than any external agency which teacher worked hard and deserves a bonus or pay rise and which teacher does not. Again, the evidence on salary   Figure 2, where there is not much scope for opportunism the choice of a poor textbook would probably hurt the teachers themselves as much as the students , where the local knowledge of teachers is important on which textbook might be best for their students, and where central exams to some extent limit teachers' capabilities to make the best choices. It should be borne in mind, however, that the most obvious pattern in all pictures of Figure 3 is that student performance is substantially better when central exams are in place. The change in school and teacher behavior reflected in the different impact of school and teacher autonomy between systems with and without central exams seems to be one of several channels through which this superior performance comes about. Furthermore, the positive impact of central exams is especially apparent in decisions where opportunistic behavior can be curbed, and this is especially the case wherever financial resources are involved, such as budgetary and salary decisions. Tables 7a and 7b present evidence on including a complete set of interaction terms between central exams and other institutional features of the school system as in equation 2for the pooled TIMSS-95/TIMSS-Repeat data in math and in science. The first column in both tables reports the coefficient estimates fli on the different institutions I, and the second column reports the estimates /32 on the interaction term El between each institution and central exams of the same regression. The last two columns report equivalent evidence for a specification that additionally controls for interaction terms between student characteristics and central exams. The pattern of results presented in Figure 3 is robust against the inclusion of other institutional interactions and of family-background interactions, and that the pattern in science is very similar to the pattern in math. (Note that to determine the combined impact of central exams and an institutional characteristic, the three coefficient estimates on central exams, on the institutional coefficient, and on their interaction term have to be added.) In the richest specifications, the point estimate of the coefficient on central exams, which reflects the effect of central exams in the absence of all the characteristics depicted by the institutional and familybackground variables, is no longer statistically significant as the standard error increases.  \nOr 6  All regressions control for all the family, resource, and institutional control variable reported in Table A  BEST COPY AVAILABLE Every two columns headed \"Coefficient\" and \"Interaction with c.e.\" together report the results of one regression. \"Coefficient\" reports the coefficient on the variable labeled in each row, while \"Interaction with c.e.\" reports the coefficient on the interaction term between central exams and the variable labeled in the row. BEST COPY AVAILABLE CC   Every two columns headed \"Coefficient\" and \"Interaction with c.c.\" together report the results of one regression. \"Coefficient\" reports the coefficient on the variable labeled in each row, while \"Interaction with c.e.' reports the coefficient on the interaction term between central exams and the variable labeled in the row. BEST COPY AVAILABLE BEST COPY AVAILABLE 62 Appendix: Construction of the TIMSS-Repeat Database The TIMSS-Repeat database used in this paper was constructed in a similar way to WoBmann's (2002a) TIMSS-95 database. The database construction starts by combining data from the TIMSS-Repeat math and science performance files with data from the TIMSS-Repeat student, teacher, and school background-questionnaire files for all participating countries. If a student had more than one teacher in math or science, he or she was assigned the teacher who instructed him or her for the longest period of time. While complete performance data was available for all students, the different background questionnaires to a different extent contain missing values in the different variables. It was chosen to exclude student observations with an excessive amount of missing data, while imputing values for the remaining missing data. In order to determine the observations to be excluded, the availability of a set of core variables in each background questionnaire was observed, which were 10 variables in the student background questionnaire, 16 variables each in the math and science teacher questionnaire, and 25 variables in the school questionnaire. If in all four questionnaires, more than half of the core variables were missing, the student was dropped entirely from the sample. This was the case for 156 students, scattered across seven countries. For the remaining 180,544 students, more than half of the core variables were answered in at least one of the questionnaires. As one would give away a lot of valuable information and presumably introduce substantial sample-selection bias if one dropped also these students from the sample because, for example, the teachers of a specific student might have answered their questionnaires poorly, but the student and school questionnaire of this student may be available and well-answered , it was chosen to impute values in these remaining cases of missing values. Using a set of 22 basic variables that were available for nearly all students as predictor variables,23 an ordered probit model was estimated to forecast the probability of occurrence associated with the different categories of each qualitative survey variable, based on the observations with available values on this variable. For the observations with missing values on this variable, the category with the highest probability based on the coefficients estimated by the ordered probit model and on the basic predictor variables of these observations were imputed. Similarly, the category with the highest probability of occurrence based on a probit model was imputed for missing values of dichotomous variables, and missing values of discrete variables were imputed using a leastsquares model.24 In the now complete database that contains imputed values for missing data, the qualitative questionnaire data were transformed into dummy variables (indicating whether a specific state was given or not) for the subsequent estimations. 1.019' (0.036) Age (years) -0.114' (0.007) -0.170' (0.007) -0.133' (0.006) Sex (female) -0.073' (0.008) -0.071' (0.007) -0.073' (0.006) Born in country 0.083' (0.013) 0.212' (0.020) 0.176' (0.013) Living with both parents 0.109' (0.008) 0.118' (0.010) 0.107' (0.007)  BEST COPY AVAILABLE  Class size (no. of students) 0:003* (0.001) -0.006' (0.001) -0.002' (0.001) Student-teacher ratio (10 students) 0.002' (0.001) -0.004' (0.001) -0.002' (0.001) No shortage of materials 0.066' (0.013) 0.088' (0.017) 0.065' (0.011) Great shortage of materials -0.092' (0.020) -0.059' (0.022) -0.088' (0.016) Instruction time (100 hours per year) 0.003 (0.004) 0.021' (0.005) Instruction time (hours per week) -0.001 (0.002) -0.005' (0.002) Teacher characteristics Teacher's sex (female) 0.089' (0.011) 0.084' (0.015) 0.101' (0.010) Teacher's age (years) -0.002 (0.001) -0.001 (0.001) -0.002+ (0.001) Teacher's experience (years) 0.004' (0.001) 0.007' (0.001) 0.007' (0.001) Teacher's education Secondary only 0.078\u00b0(0.042) -0.271 ' (0.083) 0.069\u00b0(0.038) BA or equivalent 0.008 (0.041) 0.066 (0.071) 0.104' (0.036) MA/PhD 0.154' (0.043) 0.177+ (0.072) 0.247' (0.037) Other post-secondary 0.016 (0.078) 0.030 (0.053) Constant 4.355' (0.107) 4.475' (0.170) 3.977' (0.102) Students ( Significance levels (based on clustering-robust standard errors): 1 percent. 5 percent.\u00b0 10 percent.\u00b0 Standard error has countries as the level of clustering. BEST COPY AVAILABLE 70"}, {"section_title": "Some of the interaction effects have not yet been discussed in", "text": ""}, {"section_title": "The Impact of Regular Testing and Homework With and Without Central Exams", "text": "Teachers often use devices to monitor students' efforts in order to increase their performance. Two such devices are regular testing of students' educational progress and the assignment of homework to have students practice their knowledge. In central-exam systems, the impact of such devices on student performance might be altered in two ways: First, teachers' incentives are aligned with student performance due to their own increased monitoring by parents and heads of schools, which should increase teachers' efforts to focus these devices on ensuring high student performance. Second, as students themselves get better monitored, their own effort should increase and get better focused on educational achievement (see Section 2.2 above)."}, {"section_title": "Scrutiny of testing is measured discretely by teachers' responses on how many hours per", "text": "week they normally spend outside the school day preparing or grading student tests or exams. Similarly, homework assignment is measured discretely in hours per week based on teachers' reports on how often and for how many minutes they usually assign homework. In math, both scrutiny of testing and homework have positive effects on student performance both in systems with and without central exams (Table 7a) (Table 7b). This shows that monitoring devices such as regular testing and homework assignment do not seem to further student performance strongly as long as agents' incentives are not aligned with the goal of increased student performance. As long as this is not the case, the design and content of these devices do not seem to be well focused, a problem that is especially severe in the case of subjects whose content may be less coherent in the absence of explicit standards (for example, science as compared with math). Given the alignment of incentives with student performance in central-exam systems, teachers' and students' efforts in the design of and performance on tests and homework seem to get better focused on enhancing students' educational achievement."}, {"section_title": "The Impact of Parental Influence With and Without Central Exams", "text": "All effects discussed so far may be linked to changes in the behavior of parents who are able to increase the monitoring of educational achievement once they have the information generated by central exams. As argued in Section 2.2, this positive effect of central exams will be especially salient with parents who are strongly concerned with their child's educational progress, but not as much with parents who are less concerned about their child's education. Two measures contained in the TIMSS teacher background questionnaires may help to shed some light on this differential impact. First, teachers reported to what extent, in their view, parents uninterested in their children's learning and progress limit how the teachers teach their class. Second, teachers also reported whether their teaching is limited by parents interested in their children's progress. The math performance of students in the different situations is depicted in Figure 4.21 Students whose teachers reported that their teaching was not substantially limited by uninterested parents performed better than students whose teachers reported that their teaching was limited by uninterested parents, irrespective of whether a central-exam system was in place (Figure 4a).22 The results are different for the involvement of parents who are interested in their child's progress, however. In systems without central exams, students whose teachers reported that their teaching was limited a lot by interested parents again performed worse. But in centralexam systems, students whose teachers reported that interested parents limited how they teach their class performed just as well as students whose teachers did not say so. That is, even though teachers judged the intrusion of interested parents as limiting their teaching, student performance in fact did not suffer from this \"limitation.\" In science, the negative impact of uninterested parents was even more negative in systems with central exams than in systems without central exams (Table 7b). For interested parents limiting teaching, the negative effect in systems without central exams is turned around to be positive when central exams are in place. Even though teachers complained that their teaching was limited by the involvement of interested parents, the performance of students was actually furthered by this parental intervention. While the involvement of interested parents may limit student performance in systems without central exams because parents do not have well-founded information on which to base their interventions, central-exam systems seem to ensure that interested parents have the information necessary to intervene properly. Parents uninterested in their child's educational progress do not seem to make use of this information, and their lack of interest hurts students' educational performance. But it seems that the involvement of interested parents can never go all the way to being detrimental when central exams are in place, even when teachers might judge it to be so. While there is no data to estimate the effect of the involvement of interested parents when it is approved by the teachers, it seems likely that this would be even superior for teaching and learning. 21 As was the case in Figure 3, the regressions on which Figure 4 are based control for family, resource, and institutional controls, but not for interaction terms between central exams and other variables. 22 In the specification of the estimation equation that controls for all other institutional interaction effects (Table  7a), the negative impact of uninterested parents with central exams is even worse than without central exams. The international evidence based on TIMSS-95 and TIMSS-Repeat confirms that central exams are a powerful accountability device. Student performance in math and science is substantially higher in school systems with central exams than without central exams, and this is true for students from all performance quartiles and family backgrounds. Parents, administrators, schools, teachers, and students all appear to respond to the changed incentive environment created by central exams by behaving more favorably to students' educational achievement. Parental involvement grows more informed and effective. Opportunistic behavior of schools and teachers is curbed, so that local autonomy in many decision-making areas becomes an attractive One criticism often given to all test-based accountability systems is that they might lead to \"teaching to the test\" rather than real increases in students' knowledge. As this is obviously an important issue, three comments on this question are in order. First, the performance information used in this paper does not originate from the accountability-creating test. Instead, the measures of student performance in math and science are students' test scores in the international TIMSS tests, which were accepted by representatives of all participating countries as covering the basic math and science curriculum for middle-school students. Even more importantly, no stakes for students or schools were attached to the TIMSS tests. If teachers were just teaching how to take the specific central exam, and if students were just learning how to take this specific exam, then this should not affect students' performance on the TIMSS tests. Thus, the fact that students in countries with central-exam systems did perform substantially better on the TIMSS tests allows 39 the inference that the central exams indeed caused superior math and science knowledge of the students and not just an increased capability of taking the one specific central exam. Second, the valuation of \"teaching to the test\" depends crucially on what exactly is meant by this (cf. Hoxby 2002a). If, as in the previous paragraph, it refers to just teaching how to take a specific test (\"teaching the test\") for example, by giving students answers to specific questions that will be asked in the test as opposed to increasing students' knowledge in the subjects, this is clearly not an outcome to be aimed for. If, by contrast, it refers to teaching being more focused on the content areas covered by the test (\"teaching towards the test\") as opposed to teaching other content areas that are not part of the test, this is precisely consistent with the aims of implementing a central-exam system: Central exams are meant to focus attention on the goals of the education system, and as long as these goals are clearly spelled out and as the central exams cover exactly these content areas, this helps in aligning the working of the school system with its goals. Third, much of the capacity of central exams to lead to real knowledge gains depends on the quality of the exam. It is possible to devise the exams in a way that makes teaching how to take the specific exam hardly feasible. Having the exam performed by outside proctors and using fresh questions each year will assure that \"teaching the test\" is not possible (Hoxby 2002a). As a final assessment, the relative merits of central exams as an accountability device may be compared to other accountability systems, such as teacher merit pay, school-based accountability systems, or district report cards. There is much discussion in the literature about which educational stakeholders should be targeted by accountability systems. Much of the current U.S. discussion on educational accountability seems to favor rewards for high-achieving schools and/or sanctions for failing schools. For example, Ladd (2001: 386) argues that \"subject to some important qualifications related to funding and capacity, schools are an appropriate unit for 40 accountability purposes and have clear advantages compared to other possible units of accountability, such as school districts, individual teachers, and students.\" In contrast to this recommendation, central-exam systems primarily target the individual students who take the central exam (cf. Hanushek 2002). However, the arguments and evidence presented in this paper show that the incentives created by central-exam systems extend far beyond the individual student. With central exams providing the information necessary to monitor educational outcomes, all stakeholders are more likely to face consequences for their behavior. Thus, central exams not only have the direct effect of changing students' incentives, but they also work indirectly to change incentives all the way up the agency \"ladder\" spanning from students over teachers and schools to administrators. As all these stakeholders respond to incentives, their behavior becomes more closely aligned with furthering students' educational performance. The practical merits of other accountability systems are less clear. Performance-related pay for teachers has generally been deemed a failure in the American public school system (cf. Mumane and Cohen 1986;Ballou 2001). Several recent studies have hinted at substantial implementation problems facing school-based accountability systems that rely on value-added measures of performance. For example, value-added measures of a school's performance at a particular grade have been shown to vary substantially in ways unrelated to school performance, both due to ability differences in the student sample and due to one-time factors (Kane and Staiger 2001;Figlio and Page 2002). Additionally, Ladd and Walsh (2002) find that even the more sophisticated value-added measures of school effectiveness currently implemented, which follow the performance of students from year to year, fail to thoroughly account for resource differences and measurement error in the test-score data. Since measurement errors are amplified when the data used is based on changes rather than levels, this problem is especially severe for value-added measures. However, one would not want to base schools' performance assessments on level measures of their students' performance, which are strongly determined by the students' social background. Thus, both school-based accountability systems based on value-added measures of performance and those based on level measures of performance could lead to distorted incentives and arbitrary performance evaluations for schools. By contrast, studentbased central-exam systems, which are based on level measures of performance, are less prone to arbitrariness and create incentives that induce each student to get the best possible performance out of his or her ability and social background. Despite their apparent connotation of centralizing decision-making, central-exam systems ironically may require less central regulation and allow more flexibility at the local level. For external-exam systems to exert their beneficial incentive effects, it is not required that any central person or agency has detailed knowledge of the educational production process in every school. Central administrators may in practice lack the necessary information to intervene in a beneficial way and the solutions for different failing schools may in fact differ depending on backgrounds, customs, and local experiences. Rather than trying to micro-manage schools by central regulators, external exams change the system so that the incentives of all stakeholders are better aligned with the goals of the system. If adequately motivated to improve performance and equipped with valid performance information, local stakeholders may actually be better equipped than any central agency to evaluate accountability and thus to reward or punish performance. Given the implementation problems of accountability systems that rely on central regulation, evaluation, and intervention, the relative merits of external-exam systems as an accountability device make them a highly attractive policy. BEST COPY AVAILABLE   "}, {"section_title": "50", "text": "BEST COPY AVAILABLE "}, {"section_title": "TIMSS-Repeat", "text": "Coef. Coef.\nCoef."}, {"section_title": "SE. Pooled", "text": "Coef."}, {"section_title": "S. E.", "text": "\nCentral exams' -waand guaoiad :(siona plupuuislsnqw-wia)snia uo pasug) sianal aouuoup.15!s .0upa1sn1 jo !anal atil se sapwnoo aye1 algid sup u! papodal S10113 plupums lld sasaywand ut Slain piupurislsnqw-2upaisnij 'u 1 V alqui ul pal odal alqupun !alma puoprupsu! puu 'aomosal `X!!wuj at!) nu 10j 10.0l100 SUOISS3.10.1 IIV 'Ploos aDua!osigium luuopuwalu! sson :alcmign wapuadau uo!ssaBaa auo wau slinsal spodal uwnloo goe3 :g pund aoumwojiad i!aqijo stwai ul kuunoo gaea ul swaprus atll jo aRrenb auo /quo sl uo!ssaBal aw Lil paprilow swapnis jo aidums youa u! uo!ssala, iunp!A!pui ue wwj sllnsal suoclai !too qou3 :v Ruud  Inter."}, {"section_title": "Science", "text": ""}, {"section_title": "TIMSS-95", "text": "\nCoef. Inter."}, {"section_title": "S.E.", "text": "Coef. S. E."}, {"section_title": "Pooled", "text": "Coef.\nCoef. Inter.\nCoef. Inter. Central exams' Every two columns headed \"Coef.\" and \"Inter.\" together report the results of one regression. The column headed \"Coef.\" reports the coefficient on the variable labeled in each row, while the column headed \"Inter.\" reports the coefficient on the interaction term between central exams and the variable labeled in the row. Dependent variable: TIMSS international math/science test score. All regressions control for all the family, resource, and institutional control variable reported in Table A I a. Clustering-robust standard errors in parentheses. Standard errors have schools as the level of clustering unless noted otherwise. Significance levels (based on clustering-robust standard errors): 1 percent. 5 percent.\u00b0 10 percent. Standard error has countries as the level of clustering."}, {"section_title": "Math", "text": ""}, {"section_title": "TIMSS-Repeal", "text": "Coef. Inter."}, {"section_title": "Science TIMSS-Repeat", "text": "Coef. Inter."}]