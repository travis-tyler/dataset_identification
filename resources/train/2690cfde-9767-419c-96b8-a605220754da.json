[{"section_title": "Preface", "text": "In the last decades, the study of natural hazards, disasters, and emergency planning has undergone a process of convergence and integration, shifting the focus from either a physical, human, or governance perspective to an integrated analysis; from studying single events to thinking in terms of systemic processes and complexity. Along with this convergence a fluent dialogue among researchers and practitioners has emerged, supporting the exchange of concepts, models, expertise, and tools. In the meantime, the efficiency of emergency planning and management has markedly improved and has become the most developed component of risk governance. The improvement of early warning systems, based on enhanced environmental monitoring and forecasting, has gradually been incorporated and is substantially dependent on new geospatial technologies which allow for highly accurate spatial and temporal coverage and resolution. Nonetheless, the persistent evidence of escalating material damage and sustained loss of life creates great public concern and a lack of confidence in these measures. In the last few years this convergence of ideas and expertise from various disciplines has brought human dimensions to the forefront of the policy agenda of international organizations and governments, and vulnerability has become a key topic of scientific research. The study of global environmental change, and particularly climate change, has brought issues of adaptation and mitigation to public attention as suitable strategies for responding to the predicted effects of global risks. This new circumstance points to a change in the nature of risk governance towards a strengthening of preventive measures and an enhancement of efficiency. This book addresses and analyzes proactive approaches to the governance of risk from natural hazards, recognizing them as the most suitable strategy in dealing with the set of pressing factors leading many populations to increase their risk exposure. Proactiveness does not imply that the role of emergency preparedness and disaster response be diminished, but does indicate instead a closer integration of these phases of risk management within the broader approach of risk governance. Disasters will, in one way or another, still occur. Decision makers respond to the social demand for safety with the development of civil protection systems, with a deeper analysis and monitoring of natural hazards that will help to enhance early warning and prediction. They begin to fail however, with risk communication, and hardly react at all with risk mitigation actions, since these imply a change of paradigm. Those measures with mid-term effects involving modification of the individual and collective behavior of large human groups, and whose effectiveness depends on cooperation rather than on command and control approaches, or on the implementation of technologies, are rarely preferred. Governments, both in developed and developing countries, favour short-term policies which mask other priorities only recognized too late, as they are dependent on inconspicuous decisions made by citizens day after day. This book brings together seventeen contributions from different disciplines, with various but complementary points of view, to discuss the directions and key components of risk governance. It explores the various approaches envisaged to broaden the scope of the distinct and rather separate public policies related to the management of risks from natural hazards, including emergency management, environmental manage-ment, community development, and spatial planning. This allows for an exploration of the effective integration of the social, economic, and environmental dimensions towards an efficient implementation of sustainable development. The book looks to a convergence in a form of multilevel, integrated, participative, and adaptive governance that may efficiently respond to the increasing uncertainty brought about by escalating risk exposure and global environmental change. The text explores how spatial planning, as an existing comprehensive policy instrument, may contribute to risk governance with its strong capacity to influence the occupation of hazard-prone areas and the avoidance of risk accumulation. Comprising both urban and regional planning, it focuses on the regulation of land use, looking to the future while taking into account present needs, demand for natural resources and existing, limiting physical factors. Spatial planning has the potential to integrate mitigation, adaptation, and vulnerability reduction measures into the framework of socioecological systems. But this is not sufficient. A stronger cooperation between all levels of administration, enhanced public participation, and the transfer of knowledge from experts to lay people will all facilitate an increase in capacity, awareness, and empowerment of individuals and organizations. This collection of essays reviews the central role of emergency management in risk policy, and the progression from the cycle of disaster to concepts such as socialecological systems, vulnerability, resilience, mitigation, and adaptation, thereby supporting a conceptual shift towards a more holistic vision. The book seeks to contribute to the augmentation of the conceptual framework of risk governance and to increase the awareness of practitioners and decision-makers in adopting proactive policies. It is concerned with the advancement of a systemic and conceptually integrated perspective of risk policy and presents many issues of interest to risk scholars. Questions yet to be resolved include whether risk management can be integrated into spatial planning or whether other planning approaches should be explored. Ron C\u00f6rvers (1964) studied Environmental Geography at Radboud University Nijmegen and holds a Ph.D. from Utrecht University. His thesis Network steering in nature development focused on the feasibility of area-specific projects. His research interest at ICIS, Maastricht University, is in the field of governance for sustainable development. He is also an associate professor at the School of Science at the Open Universiteit Nederland where he has a longstanding experience in the development of innovative (e-learning) courses in the field of environmental policy and sustainable development. for developing and coordinating projects in the field of European territorial development and cohesion. Before joining ESPON, Michaela worked as Research Assistant at the University of Trier, focusing on European regional development and urban policy and collaborating in and managing projects in these fields. Prior to that, she worked in the management, implementation and evaluation of European Structural Funds Programmes in Germany. Donald M. Hooper earned a doctorate in geological sciences from the State University of New York at Buffalo. He is a volcanologist and geomorphologist with research experience in landscape evolution-terrain analysis, surface processes, volcanic processes, volcanic hazards, digital topography and remote sensing, desert processes and landforms, numerical modeling, and planetary geology. Dr. Hooper is a Senior Research Scientist at the Center for Nuclear Waste Regulatory Analyses (CNWRA) and is a member of the Geological Society of America and the American Geophysical Union. Reshmi Krishnan Theckethil is a Ph.D candidate at the Department of City and Regional Planning, Cornell University. Her doctoral research examines rearticulation of urban spaces of Western Indian region of Kachchh through post disaster planning and policy interventions, and the negotiated outcomes of urban planning practice. Her research interests include human and socio-political dimensions of technological solutions to urban disaster vulnerability and local institution-building for democratic decision-making. She has done pro-bono work for NGOs in India, advocating for the rights of lower income residents to affordable housing, and promoting participatory decisionmaking in urban policy and disaster risk reduction. She also works as a consultant to the World Bank Institute. Ren\u00e9 van der Lecq is a Spatial Planner (M.S. University of Nijmegen). As a Project Expert at the ESPON Coordination Unit (Luxembourg) he is responsible for developing and coordinating projects in the field of European territorial development and cohesion. Before joining ESPON, Ren\u00e9 worked for the Ministry of Flanders (Belgium) where he built up expertise in policy preparation and implementation in the field of spatial planning and territorial cohesion at regional, cross-border and European level. Teimuraz N. Matcharashvili is professor of dynamics of control of complex systems at the Georgian Technical University, Tbilisi, Georgia. He is Head of the Department of Dynamics of Geophysical Fields and Computing Geophysics at the Institute of Geophysics, Tbilisi, Georgia. His research concerns quantitative and qualitative analysis of the dynamics of natural processes using linear and non linear time series techniques in seismology, geomagnetism, hydrology, and climate change. His work has been published in leading peer reviewed scientific journals and proceedings of international scientific conferences. Philipp Schmidt-Thom\u00e9 is a Geographer (MSc University of Bonn) with a postgraduate in hydrogeology and engineering geology (University of T\u00fcbingen). He holds a Ph.D. in Geology (University of Helsinki) and is based at the Geological Survey of Finland since 1998. As a senior scientist he focuses on environmental geology, natural hazards and climate change adaptation. He is specialized in interdisciplinary cooperation with spatial planning and regional development. He is an officer in the Commission on Geoscience for Environmental Management of the International Union of Geological Sciences."}, {"section_title": "Contents", "text": ""}, {"section_title": "Preface v Urbano Fra Paleo", "text": ""}, {"section_title": "Contributors vii", "text": "Introduction Hazard mitigation and land use planning are orientated toward the future. Both are focused on anticipating upcoming needs and impacts, rather than responding to yesterday's events. Both are proactive rather than reactive. Both inject long-range thinking into short-range actions. In concert, they provide a powerful approach for reducing vulnerability, and creating more disaster resilient communities that are able to \"resist or absorb an impact, organize [themselves] to overcome or recover from the consequences of the impact, and adapt or learn from the experience\" [1, p. 5]. To this end, resiliency implies sustainable development where property investments are avoided or at least limited in hazardous areas, where the mitigating qualities of the natural environment are maintained, and where disaster recovery is envisioned to offer opportunities to build mitigation into redevelopment [2]. This chapter examines the basic powers and benefits of urban planning in mitigating hazard vulnerability. We explore the major challenges posed to integrating mitigation with planning. We argue that the trend in increasing numbers and severity of disasters are predictable outcomes of well-intentioned, but short-sighted, public policy decisions. These decisions create what urban planning scholar Raymond Burby [3] refers to as the local government paradox wherein vulnerable communities fail to enact effective planning programs to prevent hazard-induced losses. Failure to overcome these challenges leads to a cycle of increasingly hazardous urban development and larger, more significant losses. Our position is consistent with the main conclusion of the second assessment of natural hazards research set forth in Disasters by Design [4]. In spite of increasing knowledge about the causes and consequences of hazards, losses increase in part because of where and how we \"design\" communities. White, Kates and Burton [5] echoed this position by asserting that losses continue to grow because of a failure to effectively make use of knowledge on where and how our communities should develop. We believe the time is right for building the capacity of communities to reinvigorate mitigation planning given the awareness of the un-sustainability of contemporary land use and urban development practices. The staggering costs of recent disasters, notably Hurricane Katrina ($200 billion from flooding), and losses that are rising at rates that exceed increases in population and gross national product [6] has increased public awareness of the need to act beforehand. In the future megacatastrophes may no longer be viewed as low probability events and may become the rule rather than the exception. In this chapter, we review the benefits and challenges associated with hazard mitigation planning. We then offer five sets of choices that planners, elected officials, and the public make to advance planning for mitigation, including: 1) building community capacity to do mitigation, 2) creating a high quality plan, 3) selecting a mix of regulatory and spending tools for plan implementation, 4) setting up a monitoring program to gauge achievement of plan goals, and 5) designing national and state policy aimed at building local commitment and capacity to support planning for mitigation. Finally, we assess the role of land use planning in mitigating hazards with the goal of creating more disaster resilient communities."}, {"section_title": "Land Use Planning Applied to Hazard Mitigation: In Concept", "text": "Land use planning provides an important means to achieve mitigation by influencing human settlement patterns as its analytical tools and policy recommendations are inherently geospatial in nature affecting the location, type and density of development. Equally important, is the notion that the power of planning resides in its process orientation -engendering community participation and empowerment, the sharing of information and collaborative problem solving. Simply put, planning transforms \"knowledge into action\" [7]. The practice of land use planning is highly applicable to reducing natural hazard losses and fostering more resilient communities [3,22]. Hazard mitigation planning can be defined as a coordinated series of structural and non-structural actions and processes designed to reduce the likelihood of future damages to property, while minimizing the health and safety-related impacts associated with natural hazards and disasters. Plans rely on a mix of mitigation strategies that fall into four principal categories: 1) public information (e.g. hazard disclosure, mapping of hazards, education and outreach initiatives), 2) structural property protection (e.g. building and infrastructure hardening, elevation of flood-prone property, levees, seawalls), 3) natural resource protection (e.g. beach, dune and wetlands preservation, riparian buffers) and 4) hazard avoidance (e.g. limiting future development in hazard zones, relocating existing development from hazard zones)."}, {"section_title": "P. Berke and G. Smith / Hazard Mitigation, Planning, and Disaster Resiliency 2", "text": "Selecting a hazard mitigation strategy should involve both the process of identifying a coordinated set of actions or \"projects\" targeting buildings and infrastructure that are currently at risk as well as the application of land use techniques, policies and processes focused on pre-event hazards avoidance. Examples of land use planning tools that can be used for this purpose include zoning, subdivision regulations, building codes, and the public financing of capital improvements. The benefit of taking a land use planning approach, broadly defined, limits the level of exposure to hazards before an event occurs in addition to tackling problematic decisions made in the past. There is no one mitigation strategy taken in isolation that can guarantee disaster resilience. However, an overreliance on structural engineering-based approaches such as levees, seawalls and \"hardened\" infrastructure ultimately limits resilience. Structural methods encourage additional investments in known hazard areas, while at the same time can fail catastrophically as in New Orleans during Hurricane Katrina. Noted geographer Gilbert White observed in 1975 that structural hazard control works \"\u2026will be of little value if the reduction in damages that they accomplish is more than offset by new damage potential resulting from additional development in floodplains\" [8, p. xviii]. Communities engaged in the development of a hazard mitigation plan benefit from the involvement of individuals trained in the art of public participation and dispute resolution [9]. Mediation, negotiation, facilitation and policy dialogue are routinely used by practicing land use planners. The use of these techniques improve the quality of plans and their ease of implementation as those that will be affected by the policies recommended and decisions made regarding varied land use options and alternatives are involved throughout the process. Developing a plan is a process and one which provides an opportunity to engage a wide collection of stakeholders who have a vested interest in the final product. In addition to serving as mediator and consensus builder, the planner is often required to advocate on behalf of an idea or principle [10]. This may include challenging past and proposed development patterns that unnecessarily place the larger community at risk or disproportionately impact the poor or other socially vulnerable populations. Tackling these issues requires the identification of complimentary interests, and moving beyond initially stated positions that may on their face appear to represent an intractable dilemma. Once identified and agreed upon by participants, complimentary policy choices can be codified in the plan."}, {"section_title": "Links to Resiliency and Sustainable Development", "text": "Land use planning is increasingly using the concept of sustainable development to describe the aims of the profession [11]. Planning viewed through this prism addresses the interconnectedness of social, economic and environmental issues. Sustainable development and planning also share a future orientation. Framed in the larger sphere of sustainability, hazard mitigation planning provides a unique subtext that bridges social, economic and environmental issues in a complimentary way [12,1]. While scholars have embraced the concept of hazard mitigation as an integrative theme, it has yet to gain widespread acceptance among practicing planners [9]. More recently, hazards researchers have turned to the concept of disaster resiliency to describe the linkage between sustainable development and hazard mitigation [13,14,1]. Disaster resilient communities are inherently more sustainable than others that do not take action to reduce their exposure to natural hazards. Disasters are destructive events that in extreme cases can physically obliterate a jurisdiction to a point where they may never regain their pre-event economic, social and environmental condition. A resilient community is able to bounce back following a disaster, in large part because it has incorporated hazard mitigation and preparedness measures into their community that reduce the magnitude, extent and duration of disruptions associated with a disaster. The speed at which a community is able to reinstate supporting infrastructure such as power, water and sewer services, reopen schools and businesses, and repair damaged housing is an important indicator of a resilient community. Similarly, the reconstitution of existing institutions and organizations is also critically important. These include not only local government, non-profits and community groups, but also kinship ties and other social relationships. Disaster resiliency, like sustainability, has been described across ecological, economic, and social dimensions. Ecological resiliency describes the inherent adaptability of healthy natural environments that routinely respond to fluctuations in temperature, rainfall, ground motion, erosion, wind, fire and other natural hazards. Environmental scientists use the term \"carrying capacity\" to describe the upper limit of human impacts on the system. Exceeding this limit produces unsustainable perturbations in the system, leading to an eventual collapse. Humans possess the unique ability to exceed the carrying capacity of the natural system and make purposeful choices to balance growth with associated environmental impacts. Understood in the context of disaster resiliency and sustainable development, natural hazards are part of the larger environment and serve an important function. Disasters occur when human settlement patterns interact with natural hazards. If we assume that humans are part of the natural environment, then in order to facilitate sustainable, disaster resilient communities, our actions must recognize the importance of striking a balance between economic development and the preservation of the environment which ultimately sustains us. Economic resiliency implies an ability of businesses and individuals to withstand financial shocks to the system, including those associated with disasters. Businesses may be impacted by a downturn in profits or a loss of investments and other holdings. Individuals may suffer from the loss of a job or difficulties associated with finding employment that provides a livable wage. All of these factors can be triggered or exacerbated by a disaster. Businesses, like the communities in which they reside, are differentially vulnerable to the impacts of disasters. The pre-event adoption of hazard mitigation strategies and preparedness measures by business owners and individuals can alleviate some of the associated exposure to the damaging effects of disasters. A comprehensive mitigation strategy involves the larger community as the vulnerability of infrastructure (e.g. roads, bridges, telecommunication systems) can limit the distribution of goods and services, while an abundance of housing stock that is vulnerable to hazards can hinder the ability of employees to return to work expeditiously following a disaster. Social resiliency is tied directly to the strength of social networks and interpersonal bonds. These relationships provide psycho-social support, a venue for the exchange of information, and the sharing of resources before and after disasters. In a larger sense, social networks and interpersonal bonds help to define a sense of place or community that can influence the nature of recovery following disaster as tight knit groups are more likely to assist one another and develop coordinated strategies to P. Berke and G. Smith / Hazard Mitigation,Planning,and Disaster Resiliency 4 address common problems. However, the same characteristics can lead to insularity and a reluctance to seek out or embrace new information or assistance from those located outside their community. Closely related to social resiliency is the concept of institutional resiliency which can be gauged by the level of coordination within and across organizations. High levels of organizational preparedness and interorganizational coordination facilitates resiliency. The concept of horizontal and vertical integration provides a useful framework to understand this process. Vertical integration can be described as the degree to which differing organizations such as federal, state and local governments coordinate their actions. Horizontal integration involves the coordination across similar organizations such as the non-profit community. Berke, Kartez and Wenger [15] found that high levels of vertical and horizontal integration increase the likelihood of integrated hazard mitigation and sustainable development strategies. Figure 1 visualizes the links among resiliency, mitigation, and planning for sustainability that is adapted from Godschalk, Kaiser and Berke's [2] three legged stool concept. The seat of the stool illustrates mitigation planning for disaster resiliency. The three legs represent the environmental, economic and social values of resiliency that must be in balance for the community to support the ultimate goal of sustainability. A community mitigation planning program must not be out of balance wherein one value is emphasized at the expense of other values. As a result, a community's viability and survival could become endangered. The three legged stool metaphor reveals the that reflect values supported by a mitigation strategy premised on the best available science-based information."}, {"section_title": "A Model Linking Resiliency, Mitigation, and Planning for Sustainability", "text": ""}, {"section_title": "Challenges to Mitigation Planning", "text": ""}, {"section_title": "Weak Plans and Ordinances", "text": "Several studies have documented successful examples of how individual communities integrate vulnerability data and hazard mitigation policies into local planning [16,17]. However, the general pattern of findings from the few studies that have evaluated cro sectional samples of local planning programs report that communities have not integrated specific, well-developed mitigation provisions into their local land use plans and development ordinances. Berke and Godschalk [18] conducted a meta-analysis of 16 published plan quality evaluations to identify strengths and weaknesses of plans based on eight key principles of plan quality: breadth of goals, scientific basis, policies, internal consistency, implementation, monitoring, horizontal integration, and vertical integration (these principles are discussed in more detail in section 5.2.2). Unlike traditional research methods, meta-analysis uses summary statistics from individual primary studies as the data points in a new analysis. The meta-analysis by Berke and Godschalk transforme the score for each principle from each study into a standardized score --this permitted analysis of findings across studies. Standardized scores were computed by firs identifying the maximum possible score of each principle in each study, and then dividing the reported score of a given principle by the total maximum score to determine a proportionate score [18, pp. 5-6]. Proportionate scores ranged from a low of 0 to a high of 1. A mean for each principle was then computed based on the proportionate scores from all studies. The meta-analysis revealed that while plan quality varies with the plan topic (e.g smart growth, sustainable development, watershed protection, housing affordability, landscape ecosystems, coastal resources, and human rights of indigenous people) and setting (Holland, New Zealand, U.S.), a clear pattern emerged among the seven studies that examined hazard mitigation provisions of plans. Notably, breadth of goals, degree of use of vulnerability-science based information, and strength of mitigation policies were found to be weakest (see figure 2). The principles of implementation (actions to be taken to carry out plans, timelines, assignment of organizational responsibility), monitoring/evaluation, vertical integration (compliance with state and nation mitigation policies), and horizontal integration (policy coordination across adjacen local governments) were moderately strong. Internal consistency across goals, policies implementation actions, and monitoring plan performance to achieve goals was the highest scoring principle. Source: Adapted from Berke and Godschalk [18]. While it is heartening to learn that plan authors are preparing internally consistent documents, given the complexity of linking goals, policies, implementation actions, and monitoring indicators within the plans, these findings are troublesome since goals, vulnerability data, and policies serve the critical direction-setting framework of plans. Goals identify desired community disaster resiliency ideals. Polices guide day-to-day actions, and vulnerability-science provides the information used to set goals and policies. A weak direction-setting framework means that a community is less likely to exert control over its planning agenda and ensure that long-range public interests supersede short-range interests and private concerns. Mitigation is often reduced to a series of disconnected \"projects\" intended to address past \"mistakes,\" and is therefore not part of a comprehensive and integrated planning approach. A weak direction setting framework also means that plans will not provide a clear, relevant basis for implementation, monitoring and evaluation. Moreover, while plans may meet minimum national and state legal requirements (i.e., strong vertical integration), plans lack strong locally-driven mitigation actions necessary to implement state and federally mandated mitigation strategies. The emphasis on projects is not surprising as the plans are often viewed as simply a means to an end -gaining access to pre-and post-disaster hazard mitigation funding -rather than a means to comprehensively reduce vulnerability [9]. As noted, these studies also reveal the limited application of vulnerability sciencebased information in the fact base of local plans and implementation practices. Consequently, knowledge is limited about the location of hazards, exposure of people and property to hazards, and effectiveness of alternative mitigation policies. This finding is consequential, as goals and policies in plans were found to be weak. A thorough understanding of the location of hazards, an inventory and assessment of the level of exposure of different population groups and the built environments is an essential ingredient to crafting plans that effectively reduce community vulnerability."}, {"section_title": "Land Use Management Paradox", "text": "Planning scholar Ray Burby contends that the land use management paradox is a major obstacle to creating high quality plans that advance more resilient and sustainable communities [3]. The paradox arises when local governments fail to adopt mitigation practices even though disaster losses are primarily local. Mileti [4, p. 66] found that only a small proportion of total disaster losses in the U.S. are covered by federal disaster relief, and that most losses are not insured as they are \"borne by victims.\" As a result, we would expect that mitigation would be a high priority for local officials. The paradox is that few local governments are willing to reduce natural hazards by managing development. While significant loss could be avoided through sound planning and development requirements, the existence of this pattern of community behavior is well documented [18,3]. Political reasons that explain the paradox include: the low priority local governments place on hazards relative to other issues (e.g., unemployment, crime, housing, and education); mitigation measures are often not visible like roads and schools; and the costs associated with implementing mitigation policies are short-term but benefits are not likely to occur during the terms of elected officials [24]. Further, because land and its use is inherently contentious, particularly when framed around where and how individuals, businesses and communities can build relative to hazards [19], local governments are reluctant to incorporate land use measures into a proactive hazard mitigation strategy. Local land use planners fail to recognize that hazard mitigation planning falls within their professional purview [9]. Instead, plan-making is framed in the context of emergency management and considered the responsibility of local emergency management officials even though they possess limited experience in land use planning and working with local planning officials [20]. Economic reasons center on federal disaster policies that create disincentives for local governments (and individuals) to act. Federal incentives have encouraged localities to take risks that they will not have to pay for in the future [21]. Incentives include but are not limited to FEMA (Federal Emergency Management Agency) postdisaster assistance that covers 75% of cost for rebuilding public infrastructure, subsidized beach nourishment programs, subsidized flood insurance for residences under the NFIP (National Flood Insurance Program), and homeowner tax credits that cover residences in hazardous locations. If local governments believe that the federal government will meet their needs to minimize risk and recover from disaster, they have less incentive to spend limited resources on mitigation. In sum, local communities are increasingly bearing the impacts of disasters, and the potential benefits of local mitigation planning have not been realized [4]. Unless the challenges discussed above are overcome, disasters will be repeated continuously. While policy analysts are increasingly recognizing the adverse effects of national policies that subsidize unsustainable behavior [3], change in the disaster relief politics that motivate such policies are unlikely. The modern vehicles for preventing loss of property and life are thus not disaster relief, but building local mitigation planning programs that foster disaster resiliency. This entails exploring the policy alternatives and making thoughtful choices aimed at building local capacity to plan through an engaged and supportive public, the development of strong inter-organizational partnerships, and the use of relevant vulnerability science-based information."}, {"section_title": "Strategic Choices in Designing a Mitigation Planning Approach", "text": "The conceptual framework illustrated in Figure 3 guides the organization and presentation of different sets of choices that planners, elected officials, and the public make in building local capacity to create and implement plans, and monitor the resiliency outcomes. It consists of five sets of choices and the relationships among them. We also posit that the most effective choices are those tailored to local contexts (e.g., level of vulnerability to hazards, existing capacity to plan, socioeconomic characteristics of different population groups, prior disaster experience). Starting with outcomes, the goal is to seek community resiliency that strikes an appropriate balance among economic, environmental, and equity values. The first choice involves building community capacity to undertake mitigation planning across technical, administrative, fiscal and political dimensions. The second choice includes the design options for creating a mitigation plan, and ways to pursue principles of plan quality such as goals, facts, and policies. The third choice entails plan implementation that relies on a range of local regulatory, taxing, and spending powers. The fourth choice includes decisions about monitoring and evaluation of plan performance. Finally, national and state government policy involves choices aimed at building local commitment and capacity, and designing, implementing, and monitoring of mitigation plans based on various actions. "}, {"section_title": "Choice 1: Building Local Capacity to Plan", "text": "The long term viability of a plan requires choices in building and maintaining local capacity across technical, administrative, fiscal and political dimensions. Technical capacity refers to the access to analytical tools (e.g. GIS, loss estimation software) and the applicable skills of staff involved in the plan-making process. Examples include improving the ability to collect and analyze data or apply dispute resolution techniques. Closely associated with technical capacity is the larger issue of effective administration. This requires maintaining staff capable of administering programs, policies and plans over time. Fiscal capacity is measured by financial demands placed on a jurisdiction and access to both internal and external resources to address them. Internal resources are usually tied to an annual budget, while external resources include alternative sources of funds obtained through grants, loans or other sources of revenue that are not part of the normal local government budgetary process. Developing the political will to confront issues surrounding development and hazards is not easy nor often discussed in the context of capacity-building. However, it is crucial to question choices made by entrenched political interest groups who advocate maintaining the status quo, particularly when alternative choices may affect their ability to profit from existing pro-growth conditions. The adoption of land use and other regulatory measures benefit from the establishment of supporting coalitions, including those who may initial oppose such measures. Developing a sound program that has wide support garnered through public participation can minimize fluctuations in political support for principles that can be politicized or perceived as inherently liberal, even though, correctly framed, they should resonate with a wide range of beliefs, including fiscal conservatives [19]. Planning provides the means to build capacity. One option is to involve the public when conducting a risk assessment. The process of assessing risk allows a community to prioritize mitigation actions based on the nature of differing hazard scenarios. The risk assessment process also allows for public involvement in developing an approach that is grounded in local knowledge. The anecdotal stories of \"old timers\" who experienced previous events can provide valuable insights. It also allows members of the community to become engaged in the analysis and therefore, more likely to agree with the final results and the policies that are created to mitigate the findings. Conducting a capability assessment involves identifying existing policies, programs and plans that compliment or contradict the aims of the mitigation plan. Once identified, those involved in the planning process can target areas in need of improvement based on this assessment and adopt new or improved policies and programs. For example, if the capability assessment identified that the local Capital Improvement Plan includes a proposed investment in new infrastructure (e.g. roads, water and sewer) in an area prone to hazards, the plan should note this and provide a set of policy alternatives that would mitigate or alleviate the risk. Choices may include limiting or excluding public investment in these areas or hardening exposed infrastructure."}, {"section_title": "Choice 2: Creating a Mitigation Plan", "text": "Communities should consider two sets of choices in creating a mitigation plan. One involves three levels of choices in deciding on the type of mitigation plan design. The P. Berke and G. Smith / Hazard Mitigation, Planning, and Disaster Resiliency 10 second involves ways to achieve plan quality principles when preparing new plans or updating existing plans."}, {"section_title": "Choice 2a: Three Levels of Plan Design Options.", "text": "While plans reflect different local goals associated with vulnerability and sustainability, type of hazards, and feasibility in mitigation policy solutions, planners and their communities can employ differing planning options. The intent is to create a plan that best supports the concerns and capabilities of all population groups, takes advantage of opportunities presented by federal and state policies, and is integrated with a community's other planning efforts. The three levels are described in the sections below and summarized in Table 1. The first-level option describes a mitigation plan as a separate, stand alone plan focusing only on hazards or as part of a comprehensive plan. In some cases, it may make sense to write a separate plan -when the threat posed by a hazard is extremely high; when hazards are high on the local agenda (e.g. after a disaster event) and there is a special opportunity to forge a commitment to mitigation strategies; and when the community has no comprehensive (or general) plan or the plan is weak or out-of-date. The difficulty in making a stand-alone plan is that the concerns about vulnerability reduction could become isolated from other local plans and programs that already have standing in the community. These plans focus on hazards, as well as other ongoing community goals and programs (e.g., land use and urban development, social service delivery, health, and economic development). It is possible to integrate a stand-alone plan into other plans at a later date. The second-level option includes two choices: whether mitigation will be integrated into a comprehensive hazard plan focused on all four stages of the disaster planning cycle (mitigation > preparedness > response > recovery) or a series of stagespecific plans. Communities may choose to formulate a comprehensive hazards plan because the activities that take place in each stage are often interdependent and require coordination. Mitigation activities can occur before or after a disaster strikes as mitigation is a critical component of a recovery plan, ensuring that future vulnerability is reduced during reconstruction. Mitigation can also be incorporated into an emergency preparedness and response plan. For example, highways and bridges used for evacuation and shelters needed for safe havens should be designed to withstand disaster forces and located in places that limits exposure to these forces. In some cases, a mitigation plan focused on a particular stage is most appropriate. For example, if a community does not have a comprehensive land use plan or the plan is weak and out-of-date, then a stand-alone mitigation plan would be most effective in linking pre-disaster mitigation to urban development activities. When a land use plan is prepared or updated, critical mitigation provisions could be fully integrated as an element in the comprehensive land use plan. The third-level option includes four choices: whether to focus on explicitly defined hazard-prone areas (e.g., floodplains) or take a more communitywide approach; and whether to address a single hazard or take an all-hazards approach. In most situations, communities should plan for all types of hazards found in their jurisdiction. This ensures that no hazard is overlooked and the threat to highly vulnerable populations is understood. In some cases, a specific hazard in a specific location may be the best choice. This is particularly important for disadvantaged populations that may be concentrated in a specific location and subject to a particular hazard. Box 1 illustrates distinctions in the choices made by two communities in creating their mitigation plans. The Lee County (Florida) plan illustrates an integrated approach to the design of a mitigation planning program [17], and the City of Roseville (California) [22] represents a stand-alone approach. Lee County [17] in Florida takes a comprehensive approach to integrating mitigation into other local planning activities (Level 1) and across the stages of the disaster policy cycle (Level 2). The mitigation approach is communitywide and covers multiple hazards (Level 3), including, for example, inland flooding, hurricane surge and winds. Specific hazard mitigation strategies are integrated into the local land use plan, disaster recovery plan, and evacuation and sheltering plan. Several of the key policies include: In \"hurricane vulnerability zones,\" defined as areas requiring evacuation in the event of a 100-year or Category 3 hurricane: o limit growth in areas that have inadequate highway capacity to evacuate residents-at-risk, or o increase evacuation and shelter capacity to accommodate new growth; In \"coastal high hazard zones,\" defined as areas subject to inundation from a Category 1 hurricane: o Direct new development out of hazard zones by reducing hazard exposure for infrastructure, and limiting public expenditures that subsidize development; o Redirect existing development during disaster recovery; and Restore protective features of natural systems (e.g., wetlands, mangroves, and beachfront sand dunes). The City of Roseville [22] mitigation plan in California is a stand-alone mitigation plan (Level 1) that is not integrated into other local plans. It focuses on the single mitigation stage of the disaster policy cycle (Level 2). It takes a communitywide approach to hazards rather than focusing on specific locations, and focuses on multi-hazards, including, for example, floods, earthquakes, droughts, and landslides (Level 3). As indicated below, the high priority mitigation policies are aimed at the mitigation stage, including, for example: Implement As noted, we believe that in most instances the Level 1 and 2 choices of the Lee County approach will enhance prospects for coordination of actions into more established local planning, and actions across stages. This offers more opportunity for mitigation issues and policy solutions to be acted upon."}, {"section_title": "Choice 2b: Plan Quality Principles.", "text": "Every local mitigation plan brings together a series of choices designed to fit the unique circumstances of a particular community. Plans vary in types of hazards that are addressed, emphasis on values and goals (equity, economic vitality, environmental protection), and importance placed on regulatory-and incentive-based mitigation policy solutions. Yet, it is possible to assess differences in plan format, specificity, and substantive emphasis based on principles of accepted practice. In our view, a \"highquality plan provides a clear and convincing picture of the future, which strengthens the plan's influence in the land [and hazard] planning arena\" [11, p. 69]. We present a set of principles designed to offer guidance on how to integrate vulnerability-science based information into plans, ensuring the public goals from diverse interest groups are represented, and policy solutions fit local values and capabilities to ensure plan implementation. They are intended to assist local urban planners, emergency managers, elected officials, and the public in preparing plans aimed at making communities more disaster resilient. The principles are based on two conceptual dimensions of plan quality originally derived by Berke,Godschalk,and Kaiser [11,: 1) internal plan quality that includes the content and format of key components of the plan (e.g., issues and vision statement, fact base, goal and policy framework, implementation, monitoring) needed to guide land use in the future; and 2) external plan quality that accounts for the relevance of the scope and coverage to reflect stakeholder values and the local context, which shapes the use and influence of the plan. Table 2 shows the plan quality principles and examples of specific criteria grouped under each principle. We identified seven internal principles with principles 1 through 6 reflecting the sequence of tasks that comprise a comprehensive mitigation plan. The sequence starts with issue identification and visioning (1), followed by direction setting elements that include goals (2), fact base for policy selection (3), and policies for guiding future settlement patterns (4). Characteristics 1 through 4 provide the foundation for plan implementation actions (5), and monitoring and evaluation (6) that tracks and assesses the effectiveness of the plan in resolving issues and achieving goals. Finally, internal consistency (7) addresses how well the first six plan elements are integrated. Three external characteristics include organizational and presentation (8) to foster comprehension and understandability of the plan, inter-organizational coordination (9) to facilitate coordination among other plans (e.g., transportation, open space, housing), and compliance to ensure consistency with federal and state mandates (10). The principles of plan quality are suggestive, and not comprehensive. They are intended to provide guidance with user discretion. They offer a starting point to help local planners systematically think about how the needs, concerns and capabilities of diverse population groups should be included in a disaster plan. Given differences in local purposes and circumstances, there may be variations in the applicability of criteria under each principle. Local planners and their communities should modify the principles and criteria to fit their own needs. Table 2. Principles of plan quality for hazard mitigation. 3. Fact base: analysis of current and future conditions, and explanation of reasoning. Vulnerability assessment: 3.1. Delineates type, magnitude, duration, speed of onset, and frequency of hazard occurrence. 3.2. Includes current and projected future population and employment exposed to hazards."}, {"section_title": "Includes current and projected capacity and demands for facilities and services that support vulnerable populations (shelters, transportation, medical).", "text": "Techniques that clarify, explain, and illustrate facts: 3.4. Includes maps that visually portray location of different population groups, housing, and facilities. 3.5. Includes tables that aggregate data by vulnerable population groups, land use activities, and infrastructure. 2. Goals: reflections of public values that express desired future land use and development patterns. 2.1. Statements of desired conditions that reflect the breadth of community values (equity, economy, environment). 1. Issue identification and vision: description of community needs, assets, trends and future vision of resiliency. 1.1. Assessment of major issues, trends, and disaster impacts associated with forecasted change. 1.2. Description of major opportunities for and threats to resilient land use and development patterns."}, {"section_title": "A vision that identifies what the community wants to be vis-a-vis disaster resiliency.", "text": "Internal principles P. Berke and G. Smith / Hazard Mitigation, Planning, and Disaster Resiliency 14 "}, {"section_title": "Choice 3: Developing a Plan Implementation Strategy", "text": "A third major area of choice in the mitigation planning process is the implementation of the plan -sometimes called the development management program [11]. In contrast to choices about building local capacity to plan and selecting plan design options, plan implementation is about the choice of the types of local government powers used to implement the plan. In the U.S. context a particular implementation strategy involves choices among four types of local government powers: Regulatory power: To direct and manage urban development in ways to achieve desirable land use patterns and to mitigate hazards, local governments can use the tools of zoning and subdivision regulation, building codes, urban growth boundaries, floodplain regulations, and so forth. Spending power: To control public expenditures to achieve community goals, such as concurrency of infrastructure provision with urban growth or restricting provision of infrastructure in hazardous areas, local governments can use capital improvement programs and budgets. Taxing power: To support community programs such as infrastructure building and hazard mitigation, local governments can use tools like special taxing districts and preferential assessment for agriculture and open spaces. Acquisition power: To gain control over lands that are hazardous, local governments can make use of the right of eminent domain, purchase of development rights, and acceptance dedication of conservation easements. The mix of powers selected varies according to community capacity, plan goals and plan policies. Use of the powers varies according to whether the plan focuses on future development, existing development, or both. The former alternative implies limiting new private and public development in hazardous areas by investing in new roads and utilities outside of hazard areas, requiring building standards to strengthen new structures, or requiring a change in the densities of uses allowed in hazard areas. The second option of existing development involves the use building regulations or tax incentives to retrofit and strengthen structures, or acquisition of property at risk and relocation of residents and businesses. (See Box 1 for examples of how local government powers are applied to mitigation of new and existing developments.) Use of powers also varies according to whether the plan focuses on taking action before or after a disaster or both. Pre-disaster mitigation tends to be more preventative and addresses future development. Post-disaster mitigation makes use of windows of opportunity that often open after events to rebuild without replicating past unwise development decisions [23]."}, {"section_title": "Choice 4: Creating a Monitoring and Evaluation Program", "text": "The central activities of a monitoring and evaluation program are to track how well community resiliency and broader sustainability goals are achieved, and to evaluate the performance of plan policies and implementation efforts. Objectives that are measurable (e.g., number of structures and linear feet of water and sewer lines exposed to hazards) should be assigned to each plan goal, sources of data for monitoring should be specified, and organizations responsible for collecting the data should be identified. Provision for systematic monitoring and evaluation can be incorporated into the plan, or set up as a separate activity. Regardless, the establishment of regular monitoring and evaluation schedule is essential if the plan is to be an effective guide to action given that hazards and vulnerability are continually dynamic. While there are considerable substantive benefits of mitigation, many of the benefits achieved through planning are generated by the process of plan making. Communities might decide to assess how planning builds support for mitigation, engenders participation in decision making activities, and stimulates education and outreach initiatives. In addition to process-oriented benefits, a larger question begins to emerge. Communities must make choices about whether and how to measure the P. Berke and G. Smith / Hazard Mitigation,Planning,and Disaster Resiliency 16 interconnected benefits achieved between hazard mitigation and other sustainable development goals of economic vitality, healthy natural systems, and equity in access to the benefits of achieving economic and environmental goals. One option is to consider the concept of disaster resiliency as a bridge between the two. Monitoring and evaluation also provide options to support accountability and transparency of plans. Accountability offers assurances for the public that planned actions can be monitored, allowing for both plan continuity and the support of the larger coalition who bought into the process in the beginning. Transparency compliments accountability. As mitigation actions are implemented, knowledge about performance should be opened to the public through regular plan performance reports. If for some reason planning actions are not being accomplished, this should be noted and corrective actions taken through the plan update process. It is important to determine why the action was not completed. Was there a loss in capability required to achieve the desired objective? Did social, economic or environmental factors hinder implementation?"}, {"section_title": "Choice 5: Design federal and state mitigation planning programs", "text": "As discussed, the land use management paradox is a major obstacle to creating high quality hazard mitigation plans. Local governments have little incentive to develop strong hazard mitigation planning programs on their own. Prior research indicates that state and national mandates for local mitigation planning can build constituencies for risk reduction initiatives, including those that emphasize the use of land use tools [21,24]. They also motivate higher quality local plans and reduced disaster losses by mandating that local governments prepare and implement plans [c.f. 3,25]. May [26] characterizes local planning mandates by drawing attention to two conceptual dimensions: structural and facilitating. The structural dimension specifies the choices involving: 1) level of explicitness in goals, policies and performance standards for local plan content and format, 2) strength of coercive measures that are applied to local governments to achieve compliance, 3) degree of flexibility in procedural requirements -plan preparation timelines, plan-amendment procedures, and periodic update requirements. The facilitating dimension specifies the degree to which mandates entail: 1) local technical capacity building -technical assistance, staff training, and development of databases, 2) local commitment buildingencouragement of local participation and meaningful negotiation, 3) funding for plan preparation, and 4) use of coercion authorized by a mandate. the choices made in the design of the hazard mitigation features of two local planning mandates [24]: the State of Florida's (in the U.S.) Comprehensive Planning Act of 1976, and New Zealand's Resource Management Act of 1991. Notably, the structural features of the New Zealand mandate are considerably more flexible and broad in guiding hazard mitigation plan-making. The Florida mandate contains specific and detailed provisions that stipulate the content of local plans. In contrast, the New Zealand mandate emphasizes regulatory goals and outcomes, rather than prescribed contents, assumpting that local governments can devise the best means within their jurisdictions for reaching established goals. The intent of New Zealand's mandate is that central government should not intervene in local planning decisions. Local governments must make their own choices and live with them as national subsidies and post-disaster recovery assistance were to be substantially reduced. The situation in Table 3 illustrates an application of May's conceptualization in a comparison of P. Berke and G. Smith / Hazard Mitigation,Planning,and Disaster Resiliency 17 Florida is quite different as the goal is to reduce local government reliance on national resources, even though the subsidies and recovery bailouts will still be available. The key results of this comparison are that choices should include a mix of coercive and cooperative features [24]. Florida's approach yields local plans that have a stronger scientific basis that is likely due to the stronger technical capacity building feature in the mandate and higher levels of funding. Local plans in Florida also incorporate a greater range of mitigation policies due to more stringent and coercive regulatory requirements that stipulate policies that local governments must include in their plans. New Zealand had a stronger local political commitment to mitigation as indicated by more aggressive mitigation goals in local plans and less need to rely on coercion to achieve local compliance. Thus effective mandates represent a mix of the two approaches. "}, {"section_title": "Conclusions and Implications", "text": "This chapter reviewed the role of land use planning in mitigating the vulnerability posed by natural hazards. The role of local government in planning for mitigation that supports resilient human settlements was emphasized. We argue that the trend in increasing numbers and severity of disasters are predictable outcomes of short-sighted public policy decisions that incentivize development in hazard locations and pose a serious obstacle to effective local hazard mitigation planning. We also presented a set of choices that demonstrate how local governments are able to create high-quality plans that fit local conditions and capabilities. We then discussed the choices that national (and state) governments can make that build local capacity, and improve the quality and outcomes of local plans. Achieving resilient human settlements within the broader context of sustainability should be a central goal of local planning efforts. Indeed, sustainable communities minimize exposure to hazards and enhance resiliency when confronted by natural hazard forces. To be more sustainable, efforts aimed at community resiliency must integrate mitigation with other social, economic, and environmental goals. Indeed, every development policy and project (public and private) should be evaluated based on several criteria: mitigation functions of natural systems should not be disrupted; land use decisions for mitigation should support economic vitality; environmental and economic benefits of mitigation should be distributed equitably across all population groups; and all stakeholders should be engaged throughout the mitigation planning process."}, {"section_title": "Introduction", "text": "The past half century has been sobering for advocates of planning and policy making as ways of managing the urban environment. By today's standards there was an almost naive faith in the power of government intervention as a means of limiting harms from development and ensuring a high quality of urban life. We now know that much more is involved in accomplishing development goals than specifying a set of standards and associated penalties for not complying with development rules. We also know that the imperative in industrialized countries to promote economic progress has undermined long-run sustainability by allowing urban development in areas subject to natural hazards. Recognition of the limitations of the approaches of the past has led to a questioning of the adequacy of existing schemes for local government hazard mitigation planning and for regulating development to reduce risk. The intergovernmental dimensions of planning for countries with multi-tiered systems of governance were also little understood a half century ago. Direct national specification of development goals and direct control of key development decisions bypassed thornier intergovernmental issues (and resulted in widespread policy failure). In the intervening period, these dimensions have taken on added significance. A newly restricted sense of the proper scope of national government in a number of industrialized countries, heralded by the election of reform-minded governments in the 1980s, set the stage for rethinking governmental roles. These roles were further challenged with concerns about governmental abuse of property rights under restrictive regulations and questioning of the efficacy of traditional command-and-control approaches to managing development. At the same time, local government land-use planning has taken on new cogency with increased recognition of the negative consequences of urban development in hazardous areas and inappropriate uses of land for the quality of the environment and safety of people and property. In recognition of these quandaries, policy makers in higher-level (national and state/provincial) governments have searched for tools to manage development to foster and obtain the benefits of economic development, while foregoing the exposure to environmental hazards and other problems that often accompany rapid changes in land use. In the United States and elsewhere this has led to renewed interest in local government land-use (development) plans as tools higher-level governments can use to guide development decision making in the public and private sectors. The goals sought have varied, but in general higher-level governments increasingly want to ensure that local governments foster development in ways that are environmentally, economically, and socially sustainable. The revival of interest in land-use plans draws attention to the policy question we address in this chapter: what is the most effective way for higher-level governments to work with local governments to craft land-use plans and manage urban development to reduce the risks posed by natural hazards? In broad terms, higher-level governments have answered this question in one of two alternative ways. One features a strong topdown approach to planning and development management while the other features collaboration between higher-and lower-level governments and between governments and citizens. The traditional response, which we term \"command-and-control,\" emphasizes centralization of power in government bureaucracies, development of plans and development standards by experts, detailed prescription of rules by central governments for local government plan-making and by local governments for private land development and building, legal formalism, and coercion to force both local governments and, in turn, the private sector to comply with prescribed development rules and standards. A newer response, which we term \"cooperative,\" emphasizes sharing of power between higher-level and local governments and between local governments and citizens, dialogue among governmental, citizen, and business stakeholders in crafting plans and development regulations, and enforcement of regulations based on flexible interpretation of rules. The defining characteristics of these two approaches are summarized in Table 1. The implications of the cooperative approach for intergovernmental planning systems are described in our book, Coerce or Cooperate:? Rethinking Intergovernmental Environmental Management [1]. Table 1. Planning policy designs for sustainability.\nRisk management contexts pose challenges of integrating the best available science with sensitive social and political processes that seek ends of responsiveness to public concerns, legitimacy with respect to potentially affected stakeholders, and practicality in terms of producing implementable outcomes. Understandably perhaps, responsible community and government officials sometimes espouse \"participation\" easily but put it into effective practice with much more difficulty. In this chapter, we seek to transcend the ambiguities and vagueness of appeals to public \"participation\" by specifying and distinguishing three elemental and practical components of it: subprocesses of dialogue, debate, and negotiation. To do that, we first explore how to integrate forms of \"voice\" or \"participation\" with what some find more suspect as the work of \"negotiation.\" We then turn to distinguish practically and analytically three forms of inclusive, interest-satisfying participatory or deliberative processes -dialogues, debates, and negotiations-that can be entangled for better or worse in complex participatory processes seeking real negotiated agreements upon action. We begin to clarify how to integrate these processes through their corresponding practices of facilitating, moderating and mediating deliberative interactions. In this way, we hope to elucidate real possibilities of participatory planning and analysis in the face of the challenges of risk management. We will see that we often reduce \"participation\" to argumentation at our own risk; this reductive move will blind us far more than instruct us. We will come to see that multi-stakeholder negotiation can be understood as a form of networked practical intelligence; carefully organized negotiation processes might produce not idealized and suspect \"harmony\" of views (the typical misreading of \"consensus\") but instead practically informed, contextually sensitive, insightful working agreements crafting uniquely fitting responses to demanding situations [1,2]. We will see, too, that in contentious settings, everyone faces traps of gullibility, traps of failing to inquire, failing to learn, for no group can reasonably be expected to be fully revealing or disclosing of the information they prize the most [3]. Public processes of participation, while hardly simply games of cards, may yet share more with poker than with any kinds of idealistically open speech. All this will provide a clear sense that hard-headed theories of persistent, contentious difference are right, but not right enough; they hardly get us in the door to learn how we might, with our ineradicable differences, sometimes still plan, analyze, and live together, even if as we differ by culture or class, values or interests, and more.\nThe work What is a disaster? Perspectives on the question, edited by Enrico L. Quarantelli in 1998 [1], followed by What is a disaster? New answers to old questions, edited in 2005 by Ronald W. Perry and Enrico L. Quarantelli [2], represented a continuing effort to advance the conceptual construction of disaster theory and is now a classic text in risk literature within the field of sociology. This remarkable examination of a single concept helped to exchange perspectives, identify differences in objectives, focus and develop understanding of the phenomena studied, in order to define the boundaries of a whole area of study. This uncommon kind of essay has drawn attention to the need for discussion and the establishment of some consensus about basic concepts within the scientific community, though this may cause us to feel unable to catch the disaster tortoise, as in the Achilles paradox. Concepts evolve, as paradigms do, and are differently understood by laypeople, practitioners, policymakers, and scholars; and not only between disciplines but within them. A certain level of consensus regarding the basic concepts is required in order to increase the cohesion within a scientific field and to facilitate dialogue among students and practitioners. Unfortunately, concepts are often taken for granted. One of the concepts in risk analysis and management that has received less attention, is the process of exposure; and by referring to it, I am entering into the definition of its boundaries. This paper explores the basic assumption that risk accumulation in communities and society is due to an increasing exposure induced by the satisfaction of basic needs or specific wants, the transference of exposure among agents and generations, and poor risk knowledge. This premise is based upon the contention that societies evolve through stages of cumulative maladaptation to the environmental conditions within a social-ecological system. Thus, risk exposure to natural hazards occasionally leads to disaster, and disasters are derived from the very nature of the social component of the system [3]. The chapter began by referring to the binomial opus What is a disaster? in order to bring the reader's attention to the social dimensions of risk, because disasters are the unwanted deferred but presumed outcome of a poor decision made in the more or less distant past by a social agent. Risk can be characterized as a spatial decision that has ill located people and assets. The aim of this chapter is to explore the elements of exposure and raise important and fundamental questions in order to place this concept in a central position in risk analysis, and propose a specific framework of study. Exposure is understood as the root cause of individual and community risk from natural hazards, the trigger of disaster, and a sign of the failure of society to plan accordingly to local environmental conditions. Individual and collective decisions which do not take into account the relations and processes within social-ecological systems, cause not only an environmental impact, but a social problem too. Thus it is essential to analyze the root determinants of risky behavior, not only of a cognitive nature, but also those resulting from external factors. The succession and interactions of these factors help to construct a workable framework for research in the field of exposure and elaborate a proactive risk policy. In this paper I review the complexity of human behavior surrounding the occupation of hazard-prone lands, conceptually understood as a dynamic superposition of cognitive, economic, and inheritance layers, framed by a set of opposing and reinforcing socio-economic and political constraints and facilitators. It should be noted that the currently dominant vulnerability paradigm has obscured the concept of risk exposure, impeding its development by diluting its conceptual boundaries. Furthermore, the heterogeneous interpretations of vulnerability do not facilitate differentiation. Here, vulnerability is understood as the differential capacity to cope with the hazard, and exposure is reviewed within this context. The next sections provide support for this argument. In section 1 exposure is examined in the context of risk analysis resulting from locational choices and the interaction between social and natural systems. Section 2 analyses the balance between gains and losses, particularly in reference to the temporal scale. Section 3 looks at the relationships between exposure and vulnerability, identifying both commonalities and distinguishing attributes. Section 4 identifies the drivers of exposure as push-pull factors, emphasizing the role of basic human needs and knowledge accumulation. Section 5 reviews how those factors come together and produce various classes of risky behavior. Section 6 describes the types of exposure in light of hazard dimensions and the capital at risk. The paper ends with sections 7 and 8, where a specific framework for the analysis of exposure in the context of socio-ecological systems is proposed.\nThe Rio Declaration of 1992 gave the precautionary principle its most well-known formulation: \"[W]here there are threats of serious or irreversible damage, the lack of full scientific certainty shall not be used as a reason for postponing cost-effective measure to prevent environmental degradation [1].\" The special significance of the precautionary principle is that it can require regulatory action in cases where scientific proof of harm is not yet conclusive. This principle is the product of a thirty year evolution in environmental law. It inspired the Vienna Convention of 1984 concerning protection of the ozone layer. Earlier, in the 1970s, it developed in German jurisprudence in the form of the Vorsorgeprinzip. Earlier still, American laws and judicial decisions from the 1960s and 1970s incorporated a precautionary logic, if not the principle itself. As a principle, precaution has become widely influential in environmental law, particularly in Europe. In the same year as the Rio Declaration, the precautionary principle was mentioned in the Treaty of European Union (article 130 R). A year 2000 European Council resolution made it apply not only to EU institutions but to all member states. In 2005, France gave the precautionary principle constitutional status by including it in its Charter for the Environment (article 5). This rapid ascent to the highest level of judicial norms does not mean that the precautionary principle has no detractors. Critics of the precautionary principle often portray it as antithetical to science-based environmental risk management [2,3,4,5]. They charge that when uncertainty of environmental harms is allowed to serve as a trigger for action, unfounded fears and prejudices will come to direct public policy. Opponents object, too, that the principle's application to individual environmental hazards contradicts a fundamental tenet of rational risk management: all sources of risk must be assessed in relation to one another, not one at a time. Typically, those who reject the precautionary principle argue that science-based risk management is the best and most comprehensive approach to handling environmental hazards. Such criticisms, we believe, rest on misunderstandings of the precautionary principle. Science-based risk management and the precautionary principle are complementary, not contradictory. Far from rejecting science, the precautionary principle calls for more and wider scientific investigation of poorly understood environmental phenomena. Far from letting irrationality infiltrate policy-making, the precautionary principle promotes reasoned policy incorporating standards such as proportionality and revisability. Nor should one detect anti-science populism in interpretations of the precautionary principle that favor submitting regulatory decisions to deliberative public scrutiny. Carefully structured, forums allowing for public involvement can enhance the search for truth where uncertainty and administrative opaqueness make regulation particularly problematic. The precautionary principle is a necessary component in a comprehensive scheme responding to environmental risk. What makes a policy comprehensive is not single-minded methodological consistency, but an ability to embrace the full range of risks that we face today. If, as we contend, there are hazards whose peculiar characteristics slip through the net of science-based risk management, then environmental policy is in need of a supplementary principle.\nThe Netherlands is committed to climate mitigation and adaptation policies. Up to now, much attention has been paid to mitigation policies at the global level (Kyoto protocol and post-Kyoto negotiations), both by the European Union (climate and energy policies have been adopted to limit global warming to 2 o C above pre-industrial levels within this century) [1] and at the national level (the Dutch government aims to meet EU targets, by increasing sustainable energy use by 20%, reducing greenhouse gas emissions by 30% and cutting energy use by 2% a year by 2020) [2]. However, it is increasingly becoming clear that we also need to adapt to a changing climate. There are already signs in nature that climate is changing, despite major uncertainties in the predictions of long-term climate developments and their consequences at regional and local levels (the latter being even more difficult to predict), and the Intergovernmental Panel on Climate Change (IPCC) claims that the world will definitely become warmer this century. This chapter focuses on adaptation to climate change, and more specifically on the governance of adaptation policies. Climate adaptation is a context-specific process, and the challenges, conditions and options for the best adaptation to a changing climate differ from place to place. Hence, national and international top-down climate adaptation strategies and regional or local bottom-up initiatives will need to move in tandem. This will not happen automatically, however, but will require coordinated action by public authorities and private stakeholders in developing public policies and societal activities. Efforts to cope with complex societal problems such as climate change have led to a new steering philosophy being embraced, called governance. Governance can be described as a structured multi-stakeholder process involving representatives of the government, the business community and civil society, and allowing a plurality of values, beliefs, needs and interests to be merged into coordinated action [3]. What governance of adaptation to climate change might mean in practice can be illustrated by a case study of the Gelderse Poort project in the Netherlands [5]. The Gelderse Poort is an area in the river basin of the Rhine, for which policy ambitions include nature development (habitat creation and repair) in the embanked floodplains and giving the river, which had been forced into a narrow channel between embankments, more space. The underlying idea is that a more natural river system is regarded as the best protection against climate change [6]. The steering philosophy applied in the Gelderse Poort project, which was developed specifically for this area, can be interpreted as an example of governance.\nThe allure of prediction of unwanted future evolution has always been strong. Foreseeing the future to avoid phenomena exceeding certain spatial, temporal, energetic and other scales remains a dream of humanity. These singular phenomena -extreme events commonly referred to as catastrophes or disasters-are still controversial as regards whether or not they appear endogenously, generated by the system dynamics, or exogenously, being induced by some external perturbation [1,2]. From both the scientific and popular points of view, the notion of extreme events encompasses a collection of attributes including surprising, rare, or exceptional. In a purely scientific sense, unique characteristic indicators of extremes events are their large, burst-like deviations from the mean in a series of observations or measurements, just like the inexplicable and unpredictable nature of their origin [3,4]. The impact of a singular event is thus not the most important. This means that from the scientific point of view, a singular event is an extreme event, regardless of its (positive or negative) impact on human life, environment or material property. On the other hand, a societal definition of extreme events assumes that they cause \"great consequences\" -a huge impact on society. Whenever these rare, natural or anthropogenic events occur, they might have essential (mostly devastating, rarely positive) consequences for society. From this point of view, singular phenomena with low or no impact on society can not be considered as extreme catastrophic events, even if their characteristic values essentially exceed common spatial, temporal, or energetic scales of everyday life. Conventional, popular knowledge about disastrous extreme events says, that: The type of disaster that could occur at any time is rarely known, Where and when a disaster arising 'by chance' will occur is unknown, How a disaster will unfold in geographic space over time is unknown, and We are rarely able to cope with the consequences of extreme events. On the other hand, during the last decades, society's attention to floods, hurricanes, tornadoes, landslides, avalanches, temperature anomalies, volcanic eruptions, or earthquakes has increased. The need to cope with the consequences of these extreme events is becoming more and more urgent. Scientists from different fields have much contributed to the current understanding in natural catastrophes. A huge body of data and knowledge on extreme events has already been accumulated [3,5]. At the same time, social needs mentioned above motivate scientists to carry out new, comprehensive investigations of the problem of dynamical and statistical aspects of hazardous extreme events. Moreover, notwithstanding the problems of predicting unresolved present complex natural systems, agreement is increasing that \"\u2026 [scientists] can no longer afford to leave all extreme event-related considerations solely to policy or decision-makers.\" [4, p.2]. This in turn means there is a need for more scientific rigor in disastrous event related research and considerations. From this point of view, the main societal question to researchers is; will modern data analysis methods, based on recent progress in complex systems theory and nonlinear dynamics may provide useful scientific insights to the prediction of major disasters? To answer this question, basic concepts of complex systems dynamics and predictability should be briefly revised. \nIn his 1980 book Disaster Planning [1] Harold Foster famously wrote that victims trapped under rubble or threatened by fire and water cannot afford the luxury of bureaucratic procrastination. Efficiency in emergency management is essential if lives are to be saved and damage limited, and it must be backed by substantial planning work. The primary objective of emergency planning is to ensure that in a crisis resources are used in the most efficient manner possible in order to rescue and care for victims, limit and prevent damage, and restore acceptably normal conditions as soon as possible. It is a question of supply and demand, in which the efficiency of the former reduces the latter (Figure 1). Although the efficiency of an emergency plan is very difficult to measure, it should be considered in proportion to the reduction of the negative consequences of a disaster. Improvisation is to some extent unavoidable, but good emergency response depends on foresight, and thus on anticipating the needs of stricken populations during future crises and disasters. Hence, there is always an important role for emergency planning. This chapter starts from the premise that many aspects of future emergencies can be foreseen. Few crises are entirely unexpected and occur in a manner that is entirely novel. Although all emergencies are to some extent unique in the composition and sequence of events, most are composed of elements that have some basis in past disasters or crises. Even an event as unprecedented as the collapse of the World Trade Center in New York on 11 September 2001 was not the first occasion in which structural collapse, fire and aircraft collision had occurred amid the tall buildings of Manhattan. Thus it is not difficult to find a rationale to justify a systematic, pre-planned response to future emergencies. The chapter considers the underlying principles of emergency planning.\nHigher energy prices and increased emissions of CO 2 force a reconsideration of the priorities for the future of cities in developing countries. Also the results of rapid urbanization and of climate change force them to think about their future, besides the traditional urban environmental issues such as urban pollution, traffic congestion and inappropriate waste collection. Water stress can be noted in many countries [1]. A deteriorating environment accelerates the trend towards a gradual shortage of fresh water. While freshwater supplies are clearly limited, for most people water scarcity is caused by competition between water uses and by political, technological and financial barriers that limit their access to water [2]. Cities are facing new risks through climate change and environmental problems. The ecological city approach promoted by the Switch project is an effort to counter negative developments. The Switch project (Sustainable Water Improves Tomorrow's Cities' Health) with support from the European Union (EU) is seeking a paradigm shift in urban water management. Its purpose is to make water treatment more sustainable and to protect the quality of drinking water sources. Also it wants to reduce risks such as water-related diseases, droughts and flooding. However, the results of research into environmental degradation and risks need to be absorbed by a decision structure, which can implement the necessary policies and projects. These decision making institutions tend to have a different history, role and way of functioning in different countries. Hence proposals will be developed for the interface of risk research and urban management. The approach will be illustrated by taking Ghana. To assure that the relevant research by Switch and others would be undertaken and that the results of the work would be used to improve the water and sanitation situation in Accra, the capital of Ghana, a Learning Alliance was setup. It functions as a platform where strategic directions for Accra towards a more ecological city are identified and their content is determined. The challenge is now to be heard by the authorities and to make spatial planning a strategy for risk mitigation or, even better, to promote urban management structures capable of dealing with the environmental risks in Third World cities. In this contribution we first introduce the approach of the Switch project, which embodies a more ecological attitude towards water and environmental issues. The project has opted for the learning alliance approach. We will illustrate what this would mean for Accra, the capital of Ghana. This includes a discussion about sustainability and following an integrated approach to urban water management. An overview of how Ghana deals currently with water related issues will also be given. Examples of some other eco-city initiatives will be mentioned, before suggesting the main strategic directions for urban water management in Accra and drawing some conclusions.\nThe European territory is affected by a range of natural hazards [1]. Even though damages and losses caused by natural hazards are often not as catastrophic as in other regions of the world, natural hazards do affect the potentials for regional/economic development in Europe. Besides fatalities and injuries, damages can lead to substantial financial losses, especially in areas with a high density of population, density of builtup areas and infrastructure. It is often suggested that the potential effects of climate change on hydrometeorological hazards may increase in frequency and magnitude. Even though the definite climate change effects on e.g. storminess are still uncertain, it can be expected that European regions will experience changes, such as in precipitation patterns and subsequent changes of flood occurrences [2]. Reactive responses to this come not only in the form of growing importance of natural hazards and related risks in some national European planning systems [3] but also by the European Commission which suggested that risks should receive more attention in territorial development projects. This contribution explores the achievements that the European collaboration in the field of spatial planning and territorial development has made with respect to natural hazards in order to give an indication up to what extent European spatial planning and territorial development policies might be used to implement a European strategy for mitigation and adaptation to natural hazards. The article first gives an overview of some relevant policy achievements. Subsequently it expounds the achievements of applied research that has been conducted within the framework of the ESPON 2006 Programme. The article concludes with an overview of relevant future research activities in the framework of the ESPON 2013 Programme and how new evidence might further support the ongoing policy debate.\nToday the European Union simulates one nation with its social and economic systems, including the possible adoption in times to come of one Constitution. French hazard risk management policies have evolved as a result of European Union (EU) land use, environmental and industrial safety directives. In free societies, development of longterm strategies for creating sustainable urban environments requires political will and a buy in from the citizens. Current and future steps that are being taken towards an integrated policy of risk management in EU should include rehabilitation of the emergency management process as well. The French system, as presented in this paper, is based on principles of risk management that place as much emphasis on the front end (pre-disaster) as on the back end (post-disaster).\nThe storm surge and subsequent catastrophic damage from Hurricane Katrina along parts of the Gulf of Mexico coastline [1,2] demonstrated that coastal communities are not prepared for geophysical events of such magnitude. Two worldwide trends-one biophysical and one societal--suggest an increasing potential for a repeat of the Katrina catastrophe. The significant biophysical trend is sea level rise (SLR) associated with global climate change [3,4,5,6,7]. In addition to accelerated coastal erosion, ecosystem degradation, and saline intrusion, SLR will likely increase the inland penetration of hurricane storm surge [8,9]. The significant societal trend is the continuing development of low-lying coastal land that increases the amount of community assets in storm surge-prone areas [8,9,10]. These two trends, as well as other biophysical and socioeconomic changes, are taking place simultaneously, thus placing multiple, often synergistic stresses on coastal communities [11]. The increase in future storm-surge zones due to SLR and continuing socioeconomic development of these zones suggest coastal communities, both in the Gulf Coast and elsewhere, will become increasingly vulnerable to hurricane storm surge. Therefore, comprehensive vulnerability assessments are needed in hurricaneprone communities to facilitate planning aimed at reducing potential losses from contemporary and climate-change-enhanced hazards. To support risk-reduction planning effectively, these vulnerability assessments must successfully integrate geospatial analysis and stakeholder involvement. This chapter summarizes a case study in west-central Florida (USA) to demonstrate how vulnerability assessments that integrate geospatial analysis and stakeholder input are used to understand and communicate current and future SLRrelated vulnerability in hurricane storm-surge zones. To structure this case study, we first discuss vulnerability as a conceptual framework, vulnerability assessments as they apply to hurricane storm-surge and SLR hazards, and stakeholder interaction.\nThe land surface deforms both vertically and horizontally as a result of geological and geophysical processes, many of which have significant implications for natural hazards. Observations of land surface deformation are used to forecast the likelihood of earthquakes as a function of location and to predict the places and times of volcanic eruptions and landslides. These types of hazards can generate major damage, causing thousands of deaths and the loss of billions of dollars each year [1]. In the last two decades, the development of remote sensing technologies has advanced at an accelerated pace, allowing precise measurements of topography, or topographic changes, over consequential temporal and spatial scales and an increase in our capability to assess, mitigate, and forecast natural hazards. Airborne-and space-based remote sensing using the rapidly evolving technologies related to synthetic aperture radar (SAR), especially interferometric synthetic aperture radar (InSAR), and light detection and ranging (LiDAR), have been proven useful in capturing the dynamics of these events, enabling detailed measurement of the accumulation of strain along earthquake-prone faults [2], the preeruptive inflation of volcanoes [3 -8]; and landslide mapping and monitoring [9 -12]. Policymakers, emergency managers, and responders from international and federal to regional, state, and local jurisdictions are increasingly using geospatial information products that were developed from these technologies to address the operational requirements of the decision-making process. In this chapter, we will first explain the basics of InSAR and LiDAR as emergent technologies, and then briefly review applications used to study and assess risks due to earthquakes, volcanoes, and landslides. This chapter is not intended as a comprehensive treatment of these technologies but rather recognizes their contribution to understanding, anticipating, and monitoring natural hazards, and thus how they provide essential information resources for professionals, volunteers, and organizations active in all phases of disaster planning and emergency management."}, {"section_title": "R.J. Burby and P.J. May / Rethinking Traditional Central Governments' Hazard Mitigation Policies 22", "text": ""}, {"section_title": "Comparison of policy and planning features", "text": ""}, {"section_title": "Features", "text": "Command-and-control design Cooperative design"}, {"section_title": "Planning paradigm and objective", "text": "Technical rationality to build management capacity for hazard mitigation. Communicative rationality to build ecological capacity for hazard mitigation. Assumptions about local governments/private sector commitment to sustainability Commitment to hazard mitigation is likely to be low. Commitment is not a problem when policies are developed through cooperative and consensual means."}, {"section_title": "Source of policy ideas", "text": "Higher-level governments. Higher and lower-level governments and citizens."}, {"section_title": "Emphasis of higher-level policy", "text": "Prescribe planning and regulatory process and action. Specify regulatory actions and conditions along with required process. Prescribe planning process and goals. Specify planning components and considerations, including citizen involvement in decision making."}, {"section_title": "Means used by higher-level governments to affect commitment", "text": "Sanctions for failing to meet deadlines or adhere to prescribed actions. Inducements to participate in planning process; information about hazards and solutions that enhance mitigation."}, {"section_title": "Planning process specifications", "text": "Specification of technically rational planning procedures to assess problems and generate and evaluate policy alternatives. Strong emphasis on adherence to prescribed rules and procedures. Specification of communicatively rational planning process to identify policy problems and courses of action. Provision for local discretion to respond to varying citizen concerns. Flexibility in application of guidelines. Strong emphasis on building capacity to reach policy goals."}, {"section_title": "Potential problems", "text": "Inefficiencies and gaps due to application of uniform rules in varying local circumstances. Inability to enforce uniform application of rules. Weak capacity to monitor behavior. Political backlash. Gaps in local government and citizen interest in participating in planning and policy processes. Lack of commitment to policy goals and slippage in compliance. Insufficient resources. Adapted from [1] 1. Command-and-Control and Cooperative Governance Systems Governance systems for planning and development management entail the imposition of procedural and/or substantive requirements (mandates) by higher level (national or state/provincial) government on local governments, either as direct orders or as conditions for assistance. Each design, command and control or cooperative, can in theory be used to enhance the adherence of local governments to higher-level policy objectives. But, the designs differ in terms of their underlying assumptions and use of policy tools. The command-and-control design treats local governments as regulatory agents charged with following rules prescribed by higher-level governments. These mandates spell out detailed standards and procedures for achieving policy goals, thereby reducing the discretion of lower-level governments in policy formulation and development management. Sanctions are applied when governments fail to undertake their prescribed roles or deviate from the procedural prescriptions of mandates. Commandand-control mandates pay some attention to building the capacity of local governments to comply, but that is secondary to putting in place monitoring systems for compliance and invoking penalties for noncompliance. The cooperative design tries to enhance local government interest in and ability to work toward achieving higher-level policy goals. Local governments act as stewards in seeking appropriate means to meet goals they share with higher-level governments. These regimes prescribe planning or process elements to be followed (a form of policy mandate), but they do not prescribe the particular means for achieving desired outcomes. Cooperative mandates use financial and technical assistance for the dual purpose of enhancing the commitment of local governments to sustainability and increasing their capacity to act. The compelling logic of each form of intergovernmental mandate is very different. Command-and-control mandates are highly paternalistic. The logic is that mandating governments know the appropriate actions to be taken by local governments and citizens. Given expected reluctance to comply, the approach is to compel the desired actions. Cooperative intergovernmental policies are less paternalistic. The logic is that higher-level governments know that action must be taken, but there is uncertainty as to what that best constitutes. Local governments are told to think seriously about the problems and their solutions following prescribed planning processes that entail considerable interaction with citizens and various stakeholders, but the specific actions are either left to local governments to determine or are arrived at through argumentation or deliberative, consensus-building processes involving representatives of government at all levels and citizens. The two forms of intergovernmental policies differ in their assumptions about local government commitment to policy goals such as reduction of risks from natural hazards and about their capacity to carry out actions in order to reach these goals. The command-and-control design presumes there will be conflicts among layers of government over goals or means for reaching goals. The solution is to apply sanctions to recalcitrant governments. The cooperative design assumes local governments do not have any fundamental disagreements with policy aims and therefore do not have to be forced to comply. But this commitment needs to be mobilized, for which financial and other inducements can be important, as can cooperative planning processes that build understanding of problems needing attention. By removing barriers created by deficiencies in capacity and understanding and by enhancing commitment by providing information about problems needing attention, cooperative intergovernmental policies seek local government compliance with the overall objectives of higher-level governments for hazard mitigation, but it leaves the means of reaching these objectives to the discretion of local governments."}, {"section_title": "R.J. Burby and P.J. May / Rethinking Traditional Central Governments' Hazard Mitigation Policies 24", "text": ""}, {"section_title": "Approaches to Plan-Making", "text": "Both policy designs feature plan-making to enhance the capacity of local governments to manage land-use change in ways that contribute to long-term sustainability. However, each views capacity and the roles of planning in enhancing capacity in a different light. The command-and-control design sees planning as a way to enhance management capacity--the ability of local governments to identify problems, formulate policy alternatives, attract and manage resources, and administer programs. In command-and-control planning systems, planning processes are guided by the tenets of instrumental rationality and the plans that emerge from this process are often highly prescriptive in nature. They involve a fact component that includes compilation of data on community characteristics and natural hazards needing attention and technical analyses designed to evaluate the efficacy of potential solutions to the problems that have been identified. Goals and policy components of plans refine objectives and specify policies planners propose for dealing with particular issues, sometimes in such detail that they are almost blueprints for action. Armed with a plan, the command-andcontrol policy design believes local governments will be more capable of coping with problems such as natural hazards than they would be without a plan, just as they are more competent when they develop adequate administrative leadership, management routines, and other more traditional aspects of management capacity. In contrast, the cooperative design focuses on enhancing what political scientists term ecological capacity. Ecological capacity refers to the ability of governments to act because the community understands the nature of policy problems, demands governmental attention to them, and is willing to provide requisite resources and abide by appropriate regulatory requirements. Ecological capacity may be particularly critical in achieving governmental actions that advance hazard mitigation, given the complex nature of environmental hazards, uncertainty about appropriate courses of action to reduce risk, varying distributions of costs and benefits among stakeholders, controversial nature of plans that propose rules that restrict development opportunities, and resulting high potential for conflict. Plans can build ecological capacity in several different ways. When plans are developed collaboratively with citizens and stakeholders who will be affected by the policies plans propose, they should enhance locally-shared knowledge of problems (both current and prospective), identify locally-relevant options for solving problems and accomplishing goals, and foster the development of consensus on particular courses of action. In combination, these attributes of planning processes and plans may help communities devise programs, such as limitation of development in hazardous areas, which are difficult for higher-level governments to mandate directly. In addition, by making environmental hazards and their mitigation more transparent locally, plans developed through cooperative planning processes may also empower previously underrepresented groups who, as a result of a plan, for the first time become aware of their exposure to hazards and armed with knowledge about potential solutions. To the extent all of this occurs, cooperatively devised plans may be both technically and communicatively rational."}, {"section_title": "Potential Weaknesses of the Two Policy Designs", "text": "Both the command-and-control and cooperative designs have potential weaknesses that may limit their ability to move local governments toward the adoption of policies to enhance hazard mitigation. The command-and-control approach can produce inefficiencies due to the attempted application of uniform policies to widely divergent local situations, which can lead to both reluctance to apply available sanctions to force compliance and, if such sanctions are imposed, to political backlash and attempts to reverse or emasculate the policy. Local governments complain of being straightjacketed in their attempts to deal with problems and local planners, as well as planning theorists, sometimes view the technical planning processes advocated as not feasible in practice and politically na\u00efve. The cooperative approach also has potential weaknesses. It assumes local governments, and, in turn, citizens actually want to participate in planning processes and attend to problems that higher-level governments think are important. This may be problematic, particularly in the case of policy issues, such as hazard mitigation, where the benefits from planning and policy reform are widely distributed, often temporally remote, and many times beyond the direct understanding and control of local governments and citizens. Scholars of local government decision making, furthermore, have noted that because local leaders develop stable patterns of policy making, it can be difficult to counteract the prevailing momentum and persuade them to pursue different courses of action. Finally, local political elites whose interests are not likely to be served by enlarging government decision making, may actively resist the development of participatory planning processes, even when mandated by higher-level governments. In sum, while a case can be made for both the command-and-control and cooperative policy designs, each contains potential weaknesses that can limit its efficacy as an approach for reducing exposure to natural hazards in community development. We turn next to two empirical studies that shed light on the reality of the claims made for (and against) each design."}, {"section_title": "Evaluating Intergovernmental Outcomes", "text": "A critical test for intergovernmental planning and development management systems is whether they secure the whole-hearted participation of lower-level governments and whether they foster more attention by local governments (commitment, capacity and effort) to important societal problems such as the reduction of risks from natural hazards. We measured and compared these outcomes for a command-and-control system in the United States and a cooperative system in Australia, each of which was established in 1985 to, among other goals, foster public safety through planning and policy development for the use of areas subject to natural hazards."}, {"section_title": "The Florida Command-and-Control Approach", "text": "The command-and-control system we examined was enacted through the Florida Local Government Comprehensive Planning and Land Development Regulation Act. This legislation mandated preparation of local comprehensive plans and accompanying landuse regulations and required that they be consistent with state goals, regional policy plans,  Through Rule 9J-5 and a model local plan, the Florida  Department of Community Affairs spelled out the contents it expected to see in local  plans, including specific provisions for the mitigation of natural hazards in coastal areas.  Rule 9J-12 established an enforceable schedule of due dates for the plans, and Rule 9J-11 established procedures for review of local plans and land use regulations to ensure their compliance with state goals and standards. The legislation established severe sanctions for local governments that failed to plan, including the potential for withholding 1/365th of state revenue-sharing funds for each day a plan was late. Local governments that planned but failed to meet state standards were subject to an administrative hearing and order to rectify any deficiency. To build local capacity to plan, the state distributed almost $25 million in planning grants between 1986 and the initial deadline for plan preparation in 1989. The state also provided extensive technical assistance through workshops, manuals, and newsletters."}, {"section_title": "The New South Wales Cooperative Approach", "text": "The cooperative planning system we examined was put in place by the \"merits\" floodplain management policy adopted in 1985 by the State of New South Wales in Australia. The merits policy represented a complete reversal of a previous command-and-control approach to flood problems. Through a series of policy circulars from 1977 to 1982, the state Planning and Environmental Commission established command-and-control floodprone land policies that sought local governmental actions in halting future development in flood-hazard areas and removal of past obstructions in floodways. These policies had legal authority derived from the state role in mandating local land-use and development regulation under the 1979 Environmental Planning and Assessment Act of New South Wales. This act established state policies for local regulation of land use and development in a manner consistent with state policy objectives. The flood-prone land policy was a highly controversial directive that became a political issue as part of the 1984 state elections. The policy contributed to the defeat of the Labor government in 1984, which led to a rollback of the policy and institution in 1985 of its merits-based approach to floodhazard mitigation. The merits flood-hazard mitigation policy is a cooperative intergovernmental mandate. Under this policy, local governments are required, as a condition for subsequent aid, to develop land-use plans and development rules that lessen flood loss while taking into account social, economic, and ecological, as well as flooding considerations. Eligibility for flood-control grants and the immunity of local council liability for flood losses are contingent on following the merits-based planning process. However, the policy leaves it up to local governments to determine the use and protection of property in flood-prone areas subject to achievement of state policy goals. The intent was not to straight-jacket local governments into prohibiting development. Several features of cooperative policy designs are evident in this policy approach. The policy requires completion of a planning process, rather than particular floodmanagement actions as a condition for future aid and waivers of immunity. The policy emphasizes policy goals rather than prescribed standards, under the assumption that local councils can devise the best means within their communities for reaching the goals. The policy emphasizes a participatory planning process through formation of a floodplain management planning committee composed of representatives of all stakeholders. Another key feature of the policy design is building local capacity for floodplain management. The key instruments for this are the advice contained in the State Floodplain Development Manual, state-provided technical assistance in carrying out flood studies, the availability of state matching funds for floodplain management programs and structural flood control works, and public education. As was the case in Florida, these efforts have entailed extensive funding and other assistance provided by relevant state agencies. The cooperative philosophy was underscored by our interviews with state personnel charged with implementing the merits policy. Rather than thinking of withholding funds as a stick to coerce local governmental action, state personnel described the availability of state funds as an incentive for good floodplain management planning. This philosophy is aptly depicted by one manager's characterization of dealings with local governments: \"It doesn't help [state] government objectives to threaten local councils; we work with them to encourage good floodplain management.\""}, {"section_title": "Sources of Data and Caveats", "text": "We developed data about local governmental compliance with the Florida and New South Wales intergovernmental mandates by conducting surveys of local government officials in each place. The first survey, conducted in 1990, evaluated planning and other hazard mitigation efforts in a random sample of thirty local governments in Florida. The survey procedure involved personal visits and interviews with local planning directors and their staffs and a mail-back questionnaire for more detailed information about development management practices and the local context. The second survey, conducted in 1993, evaluated planning and other hazard mitigation efforts in 127 of the 155 local councils subject to some form of flood risk in New South Wales. Survey data in both Florida and New South Wales were supplemented with data from the respective national decennial censuses (1990 in the United States and 1991 in Australia). The surveys were comparable, subject to differences in terminology, in the types of questions and resultant measures of key variables. There are extraneous factors that potentially are not controlled by the research design and statistical measurements we employed. In particular, any differences between Florida and New South Wales that can account for planning and development management effort and that are not measured and controlled could produce spurious results. Factors with that potential include the substantial exposure of local governments in Florida, but not New South Wales, to tropical cyclone hazards and the much greater growth pressures experienced in Florida, where average rates of population growth over the 1980s decade were more than double those in New South Wales. In combination, these two factors could create a climate in Florida much more conducive to local government attention to natural hazards than existed in New South Wales, so that effects we attribute to the command-and-control Florida planning mandate could in fact be a product of the policy environment rather than the policy studied. We controlled statistically for risk exposure as one way of addressing these threats to internal validity. Another caveat stems from the fact that most of the data are cross-sectional. They provide an understanding of local government effort, commitment, and capacity after policies had been in place for up to eight years. What we attribute as policy influences of the state planning mandates may be the legacy of prior policies, and our finding of differential policy effects may stem in part from different starting points."}, {"section_title": "R.J. Burby and P.J. May / Rethinking Traditional Central Governments' Hazard Mitigation Policies 28", "text": ""}, {"section_title": "Our Findings: Intergovernmental Policy Outcomes", "text": "Policy designs in both Florida and New South Wales used local planning as a vehicle for accomplishing state objectives for sustainability and hazard mitigation. In Florida, the state insisted that local comprehensive plans and land development regulations incorporate state goals for public safety and state standards regarding the exposure of people and property to risk. The government of New South Wales viewed plans as necessary to insure that localities gave balanced consideration to the merits of development in flood hazard areas. Thus, compliance with the procedural step of actually preparing a plan is an important test of the ability of the mandates to influence local governments. Procedural compliance was much greater in Florida than in New South Wales. Only 2 percent (7 of 457) of the local governments in Florida failed to meet the 1989 deadline for plan preparation, and by 1994 all had prepared plans as mandated by the state. In contrast, eight years after the 1985 merits policy was adopted in New South Wales 38 percent of the local councils for which the policy is potentially relevant (flood hazards were identified by the state as a potentially serious problem) had not started the planning process, and only 37 percent actually had a floodplain management plan in place. Clearly the concern we noted earlier that participation in planning can be problematic with cooperative intergovernmental regimes is, in fact, a real dilemma for the cooperative approach. Adherence to prescribed planning processes, however, is a means to, but not an end in itself of an intergovernmental planning system. Another critical test of the efficacy of the policies consists of their impacts on local government planning and development management efforts. Table 2 presents a comparison of these outcomes while also taking into account differences in risks attributable to dominant hazards in each setting. For moderate to high risk settings, the respective mean effort and commitment scores for local governments are not statistically distinguishable for the command-and-control and cooperative planning systems. Despite lower procedural compliance under the cooperative system, the mean level of effort and related governmental commitment was comparable, if not slightly better, among these jurisdictions. The situation was clearly different among low risk jurisdictions in New South Wales for which the mean scores for effort and commitment were lower by some 20 percent than the corresponding scores of higher-risk jurisdictions. These low-risk jurisdictions were also less likely to participate in the planning process or to complete the preparation of a plan. This is potentially a serious problem, since planning measures work best to enhance hazard mitigation when they are applied before substantial development has been allowed to take place in hazardous areas. They work best as preventive, not remedial, measures. The last row of Table 2 shows a notable difference in relevant planning staff capacity (per capita) between New South Wales and Florida. These latter differences were only partly historic ones. There is strong evidence that the Florida planning legislation led to expansion of local government planning staffs. The expenditures of Florida cities for planning increased an average of 20 percent during years of required plan preparation, and in Florida counties by an average of 16 percent during the same time period. Table 3 shows our multivariate analyses of variation in effort, commitment, and staff capacity. Our primary research interest is the relative effect of the type of intergovernmental mandate (shown in the first row) on each of these factors. The results for effort suggest that the increased coercion and prescription of the Florida commandand-control planning system resulted in lower effort in comparison to the New South Wales cooperative system. Everything else equal, the cooperative system seems to be more effective in inducing local government planning and development management effort. These findings are consistent with the expectation that cooperative policy influence, controlling for different levels of commitment, has greater impact on local effort than command-and-control policies. As expected, governmental commitment to addressing hazard mitigation and the overall resource situation (as reflected by our proxy variable, population) are key influences on local planning and development management effort. Staff professionalism, measured by the proportion of planning staff with professional certification, also comes into play. This is consistent with the view that professional planners become advocates for hazard mitigation. The effects of the remaining variables are consistent with what one might expect, although they are often not statistically significant. The importance of commitment as an intermediary variable in influencing local government effort to plan for and manage development draws attention to our modeling of commitment, shown in the middle column of Table 3. We find only modest statistical evidence that a command-and-control system stimulates commitment when controlling for other factors. This finding seems to reflect the mixed predictions about mandate influence on local governmental commitment.  Table 2."}, {"section_title": "R.J. Burby and P.J. May / Rethinking Traditional Central Governments' Hazard Mitigation Policies 30", "text": "b Since commitment and capacity are endogenous variables they are excluded as explanatory variables for their respective models. Our modeling of staff capacity suggests that Florida's command-and-control mandate was stronger in inducing enhanced planning capacity while other factors have effects generally as would be expected. The negative effects of population are reflective of the fact that we are using a per capita measure of capacity, making it difficult for large jurisdictions to have high capacity (even though we use a logged value). Although these findings suggest that the threat of coercion is a strong impetus to building necessary planning capacity, two caveats apply to these findings about the effects of a commandand-control mandate on capacity. First, the explanatory power of this modeling is much lower than the other models. Second, as noted earlier, some of this effect may be attributable to the fact that Florida jurisdictions have historically had larger planning staffs than in New South Wales where planning only came into its own in the late 1970s."}, {"section_title": "Conclusions", "text": "In this chapter, we have considered two basic intergovernmental approaches that can be used by central governments in multi-tiered systems to achieve desired goals that rest on actions at lower levels of government. Though our focus has been the mitigation of natural hazards through planning for and managing urban development, in recent years various scholars have addressed issues similar to those that we raise here concerning the governance of coastal and forest management in Europe [2], protection of coastal areas in the United States [3], and innovation in intergovernmental implementation more generally [4]. These studies reinforce the basic tenets of this chapter and have findings that largely concur with those that came out of the research we did in the early 1990s that is reported here in evaluating the efficacy of the different approaches using data from the states of Florida in the United States and New South Wales in Australia. Our statistical results for the degree of effort and commitment of local governments to hazard mitigation provide what appear to be paradoxical findings concerning the intergovernmental effects of cooperative and command-and-control planning systems. On the one hand, when controlling for risk and other factors, the cooperative New South Wales mandate seemed to produce an effect on hazard mitigation effort (what might be termed substantive compliance) as strong, if not stronger, as that obtained with the more coercive Florida mandate. On the other hand, the results for commitment suggest that the command-and-control Florida mandate produced somewhat higher governmental commitment than that produced under the cooperative New South Wales mandate. Combined with our finding of greater procedural compliance among Florida jurisdictions, the cooperative New South Wales mandate seems to be less effective in securing local government commitment to policy objectives. Cooperative mandates appear to work well and induce significant local government effort when there is local commitment to dealing with natural hazards as a policy problem. However, command-and-control mandates appear to be more effective in securing requisite commitment--at least in the short run. Considering these outcomes, it seems possible to us that a hybrid approach combining features of the command-and-control and cooperative planning systems might be more effective than a system that relies exclusively on either command and control or cooperative principles. The command-and-control approach, as implemented in Florida, seems to be much more effective in securing local government participation in planning processes than the cooperative approach, as implemented in New South Wales. In addition, the command-and-control approach can build commitment among local officials, at least in the short run, and can induce them to devote resources to the planning function. But, the evidence is not solely in favor of a command-and-control intergovernmental planning system. The cooperative system as implemented in New\nThe Gelderse Poort project gives priority to nature development, while also addressing other types of land use, river management and the quality of the environment. The extremely high water levels in the rivers in the 1990s and the current debate on climate change have put the issue of safety and flood protection back at the top of the agenda. It is a moot point whether the national and provincial governments involved in the Gelderse Poort project will be able to influence the interdependencies of other public authorities and private stakeholders in such a way that cooperative action will take place to realize the policy objectives for the area. A look at the Gelderse Poort project from a governance perspective allows some lessons to be learned [5]: In practice, the principle of cooperative action by all relevant parties means that some public authorities are cooperating (ministries and provincial authorities), while crucial private stakeholders (clay extractors and farmers) are only marginally involved. In practice, the principle of shared understanding and common problem definition usually means that the focus is on a policy issue defined by a toplevel public authority (nature development, room for rivers), sometimes supplemented by different interests or points of view (such as clay extraction). Support from the provincial authorities is crucial for area-specific projects (since national government consists of competing ministries and municipal authorities lack the capacity to manage regional projects). The societal support for nature development is unreliable (interest groups for agriculture, nature conservation and recreation have different perceptions of the pros and cons of nature development), and support for nature is generally fragmented. The principle of creating win-win outcomes by combining nature development with other socio-economic activities such as clay extraction or agriculture are often more cosmetic than realistic. External conditions can play a significant role in area-specific projects, an example being the 1990s high water levels, which were crucial in accelerating plans for nature development in the area along the main rivers, but may have the side-effect that not all intended types of nature can be achieved. This chapter addressed some important features of Dutch society, such as the continuing growth of the population and economic activities in low-lying areas, as well as changes in the natural environment, such as climate change, sea level rising, high water levels in the rivers and land subsidence. The upshot of all these characteristics is that the risk of flooding (in terms of probability multiplied by consequence) has increased significantly. The Dutch government is developing flood protection policies for the areas along the main rivers which involve a shift from building higher and stronger dikes towards nature development and its aim to contribute to biodiversity. In addition, the government has launched the concept of giving the rivers more space to move in, to increase safety in the surrounding areas. In area-specific projects, such as the Gelderse Poort project, different policy concepts might clash, and it will be a real challenge for public authorities and private stakeholders involved in this kind of project to merge different values, beliefs, needs and interests into cooperative action. The underlying steering philosophy for these multi-stakeholder processes can be regarded as an example of governance.\nThe main argument of this article is that by providing an understanding of the community and its social processes, social assessments make it possible to identify the direct and indirect social impacts of natural disasters and developing socially R. Sairinen / Social Impact Assessment for Environmental Disaster Management 145 sustainable ways of recovery before and in some cases also after the natural disaster. By understanding and anticipating future hazard events, communities, public authorities and development organisations can minimise the risk disasters pose to socio-economic development [9]. Applying social impact assessment to disaster management requires that disasters themselves should be understood as a social phenomenon. Disasters always have a social dimension and, whatever their cause, their effects are invariably rooted in societal processes that render certain groups or individuals particularly vulnerable to their impacts. We can differ at least following disaster management situations where the usage of SIA is relevant: anticipating the potential social impacts of natural hazards and technological risks; assessing short-term impacts after natural disaster; assessing longer-term impacts when thinking about post-disaster developments; developing climate change adaptation policies; developing land-use plans and emergency programmes for risk areas; and developing appropriate and effective mitigation mechanisms to hazards. The main targets for making the SIA in the conditions of disaster are the following: To understand how a disaster changes the life and welfare of residents, communities and regions (direct and indirect impacts). To understand the potential impacts of a disaster for gender and various social, ethnic and age groups (vulnerability of various population groups). To develop mitigation, adaptation or compensation measures for the harmful social impacts (adaptive capacity). To alert planners and decision-makers to likely social change (planning tool). To help communities cope with the impacts of disaster and the post-disaster conditions (community empowerment). Around the world there exist various modes of social and community assessments concerning conditions of natural disaster. In this article, some of these applications such as Vulnerability and Capacity Assessment (VCA), Community Risk Assessment (CRA) and Community (Environmental) Assessment were shortly introduced. In these various methods, the main focus can be different, but the basic principles are mainly the same: interest in vulnerabilities and vulnerable groups, looking for social resilience, capacities of recovery and adaptation, and emphasizing participatory approaches. The latter means that whether they are rural, urban or semi-urban neighborhoods, it is crucial that communities exposed to hazards can contribute to the risk assessment and planning process.\nTo answer the question about present scientific insights to major disaster prediction, it should be said that the issue which needs to be addressed is not deterministic prediction, but an objective evaluation of distribution, memory, scaling and other characteristics of complex natural processes, along with an estimation of the extent to which processes of interest are predictable and whether control of these processes may be achievable. In short, how we view, understand and quantify complexity will determine how we elaborate prognoses and make decisions. It is clear that prediction related research must become interdisciplinary, and will require new kinds of scientists, many of whom will need to be first-rate in more than one field. The most significant message we want to convey is that non-deterministic, complex, randomlike natural systems also allow for some degree of predictability. At present, the most realistic for such systems is to extract probabilistic information, and to make specific predictions about the future value of the observable in the sense of the most probable outcome, or the outcome that yields the least average prediction error.\nEmergency planning is a key factor in the creation and maintenance of societal resilience against hazards, threats, crises and disasters. The term resilience (from the Latin resiliere -'rebound') has been adapted from rheology, in which it describes the ability of materials to resist and absorb stresses without excessive deformation or fracture by a mixture of ductility and rigidity. In an analogous manner, society must resist and adapt to threats [18]. A vital part of this is to anticipate them and be ready to react effectively when they materialise, which is the essence of emergency planning. However, not all threats can be foreseen. Donald Rumsfeld, who was US Defence Secretary under George W. Bush, gained censure from the Plain English Campaign for his remark, \"There are known knowns; there are things we know we know. We also know there are known unknowns.\" Despite his contorted phraseology, there is enough truth in his remark for it to merit serious consideration. Accordingly, with tongue only slightly in cheek, I propose an \"extended Rumsfeld classification\", as follows: known knowns: we know what is what, known unknowns: we are aware of what we do not know, unknown knowns: we do not fully realise that we know certain things, and unknown unknowns: we are unaware that we do not know certain things. Hence, there are degrees of ignorance, and also of awareness of one's own ignorance. This prompts the question of how we can deal with emerging risks. In some cases we have enough information to construct emergency planning scenarios. For example, in the 20th century there were eight pandemics, which gives us a basis to hypothesise the progression of a 21st century pandemic of avian influenza or other contagious and potentially lethal disease, even though many of the details are a matter of conjecture. On the other hand, biological, chemical and radiological threats have few precedents and hence the scenarios, if they exist, are much more conjectural. Finally, there may be hazards that have yet to emerge, for which no scenarios can be constructed and contingency plans simply do not exist. The current vivacity of emergency planning is perhaps a reflection of the ancient Chinese curse, for we do indeed \"live in interesting times\". With climate change, technological complexity, growing societal vulnerability, new forms of terrorism, emerging infectious diseases and the prospect of more intense environmental extremes, the need for disaster preparedness has never been greater. Fortunately, the field is becoming gradually more professional, and this includes the more widespread adoption of emergency plans by local, regional and national public authorities, business and the custodians of cultural heritage. Much remains to be done, but it is axiomatic that we should seek to \"foresee the foreseeable\", even if this means \"thinking the unthinkable.\" In conclusion, the emergency planning process is summarised in Figure 6 [19,20]. At its best it should involve constant improvement and produce a \"living document\", an instrument that is frequently updated and frequently a source of education for its users.   Abstract. Recovery is a long-term decision process in the face of rapid change, involving many individual actors and organizations making decisions about rebuilding, planning, and financing. Communities must make rapid decisions about physical reconstruction and economic development, while at the same time making critical decisions regarding management and financing, all under great time pressure. It is tempting to think of a disaster-affected community as a \"blank slate\" upon which a new, improved, disaster-resistant community can arise, under the guidance of rational planning. In fact, actual post-disaster situations are much more complex, and, although some forces facilitate the opportunity for positive change, there are at least an equal number of countervailing forces resisting such change. Significant change is difficult to achieve, because the political and administrative environments resist it, and because the historic evolution of the city reflects the deep-seated desires of its inhabitants. Still, physical changes do occur -usually in limited parts of a city-and they sometimes are able to bring about social and economic improvements. The challenge for planners is to learn how to maximize the limited opportunity for positive post-disaster change. This paper briefly summarizes some of the complexities of the post-disaster decision environment and suggests some ways to maximize positive change following disasters. Keywords. Post-disaster recovery, urban planning, mitigation planning Post-disaster recovery is complex. [1,2] It is a long-term decision process in the face of rapid change, involving many individual actors and organizations making decisions about rebuilding, planning, and financing. Communities must make rapid decisions about physical reconstruction and economic development, while at the same time making critical decisions regarding management and financing, all under great time pressure. Reconstruction Following Disaster, by Haas et al [3] was the first study to take a comprehensive view of the recovery process. They examined two recent (1972 Rapid City flood, 1972 Managua, Nicaragua earthquake) and two older (1964 Alaska earthquake, 1906 San Francisco earthquake) disasters in order to identify common policy issues and extract common lessons on the forces that affect reshaping of a city following disaster. Although they were probably overconfident in declaring that \"the reconstruction process is ordered, knowable, and predictable\" (p. 261), their study contained a great deal of insight that has been confirmed by subsequent disasters: The city is almost always rebuilt on the same site, and it usually looks familiar to its residents. It is usually a bit safer than before the disaster, though not as improved as it could have been. Factors that increase the speed of reconstruction include: availability of large external resources, innovative national leadership, existence of prior plans, community consensus, and wide dissemination of information. Ongoing urban trends accelerate after the disaster. They especially note that urban decentralization-which has been a general international trend for the past century-increases after disasters. Recovery is not an egalitarian process. Those who can pay for the best locations rebuild the soonest and in the prime places; others will follow. Those with greater access to resources before the disaster continue to have greater access. The opportunity to do comprehensive re-planning is rarely fulfilled, because it costs too much in time and uncertainty. As they observe, \"There is already a plan for reconstruction, indelibly stamped in the perception of each residentthe plan of the pre-disaster city. The new studies, plans and designs compete with the old\" (p. 268). This observation is echoed by a contemporaneous study, describing how the city of Xenia, Ohio resisted the opportunity for change after a devastating tornado in 1974 [4].\nUrban management provides an integrated approach to the issues identified by the urban stakeholders; it may opt for a comprehensive approach to manage urban risks. In this case it needs to be clear what will be integrated, how and by whom. Integrated Urban Water Management (IUWM) can be achieved in each of the cities studied if we work towards preparing an IUWM plan. A major assumption of this approach is that if we follow a holistic approach we will have better results. Secondly, we assume that policy will be driven by scientific research, rather than by consultancy reports. Such plans may be too ambitious for big cities like Accra and Beijing, and we may have to content ourselves with providing strategic directions for moving towards a more ecological city, such as those mentioned for Accra. We argue it is important to understand the interrelations between flooding, water and sanitation and the broader issues, such as the required governance structure research in all of these directions. Investments in water, for example, have huge health consequences, which also need to be taken into consideration 7 . A challenge in developing countries will be to incorporate informality. For example, small scale operators in the water and sanitation sector could get a better chance to make a real contribution to the health of the people. The learning alliance can help to introduce some of these new ideas in Accra.\nChoosing collectively to build a city in a given location, choosing individually to live in a specific place and in a specific way or choosing politically a type of urbanization depend on what level of risk is acceptable. Therefore, a disaster is neither a natural disaster nor an industrial disaster, but always a human adjustment disaster insofar as it results from risk exposure and vulnerability [12]. This is why French risk and disaster management considers complex risks independently from their type. This is also why procedures are differentiated enough to be adapted to local conditions since eventually, current and past local planning choices are the root of future disasters. Today, EU's apparatus exist to deal with disaster incidents, but it consists mainly in mutual assistance and quick response procedures. Excepting SEVESO, which is just a directive and not a regulation of the European Union -i.e. an act made to orient member countries policies but leave them with a huge amount of leeway as to the exact rules to adopt-there is no common policy but rather a coordination of national devices. The French system, which gives equal importance on the front end (pre-disaster) and in the back end (post-disaster), is based on the idea that emergency management effectiveness needs appraisal of social, economic and environment risk acceptability [13]. Therefore, subsequent to any disaster it is crucial to examine not only the casualties and damages but also to learn and incorporate lessons from the failures into remedying policies. To do so, arbitration between regulating information and functional information is required [14]. Functional information concerns technical and scientific knowledge about individual local administrative units or regional functions (for example in terms of resource generation, consumption, population dynamics, climatic nature, etc.). Regulating information is made of social codes, collective memory, environmental representations, and also analogical transposition of disaster events which already took place somewhere else. When regulatory mechanisms are lax, areas become more prone to disasters. Sometimes, there are excellent reasons to neglect the acquisition of regulatory information, but generally reasons are less acceptable: on one hand, regulating information costs a lot to acquire in the short term and pays off only in the future, in an invisible way (avoiding disasters); on the other hand, a disaster is followed by recovery actions and reconstruction, which means massive investments and side benefits for the whole area. Many actors consider catastrophes creating windows of opportunity for urban renewal [15]. These long-term strategies require political will and a buy in from the citizens. Citizen participation, NGOs and private initiatives are crucial to formulate risk and disaster management policies, which shows that risk management is more a political than a technical issue.\nThe GIS modeling completed for this research allowed the research team to identify the level of exposure of various Sarasota County demographic groups, land uses and land covers, critical and essential facilities, and economic activities. The GIS and spatial dependency network analysis when completed should allow the research team to identify critical nodes of infrastructure located within contemporary and future risk zones. These findings should allow the research team to assess vulnerability more accurately and provide local stakeholders with valuable information that they can use for hazard mitigation and SLR adaptation planning. The ability of local stakeholders to participate in the vulnerability assessment contributed extensively to the findings of this case study. The examples provided by this case study illustrate that GIS-based SLR modeling can be coupled with stakeholder interaction and incorporated into long-range comprehensive plans for coastal communities. The need to address these and other issues is apparent, and the framework we have introduced shows promise for increasing risk awareness and affecting adaptive change in local communities. Our efforts to incorporate biophysical, socioeconomic, and internal and external vulnerability indicators into a framework that also considers geospatially dependent vulnerability appears to be an effective methodology for a more comprehensive localized vulnerability assessment. Research is ongoing that seeks to determine the effectiveness of this framework. Future research will complete a comprehensive content analysis concerning the focus group session conducted for this case study to gain a more complete understanding of the types of decisions promoted by focus group participants. Follow-up interviews with focus group participants will also be conducted in order to gain an understanding of the effectiveness of the methodology presented in this chapter."}, {"section_title": "R.J. Burby and P.J. May / Rethinking Traditional Central Governments' Hazard Mitigation Policies 32", "text": "South Wales led to a stronger planning effort among more committed governments than we found in Florida. Thus, a hybrid system that produces both the across-the-board participation in planning that can be attained by a command-and-control system along with the strong effort that can be induced by the freedom given local governments in a cooperative system would be ideal. A hybrid intergovernmental planning system might be accomplished by implementing a command-and-control system in a flexible, cooperative way with governments that agree to participate in planning, while using coercive measures to force participation by recalcitrant governments that will participate only after the threat or imposition of sanctions. If the planning undertaken is also of a hybrid nature, embodying both technically rational and participatory planning procedures, that should have the effect of building a constituency that will demand attention to natural hazards (or, for that matter, other policy that addresses issues of local concern). Thus, even though participation in planning has to be forced initially, if a cooperative approach to planning is pursued, in the long run the planning processes established should be selfsustaining. Without the use of cooperative procedures, forced participation could be extremely half-hearted and the resulting level of effort to foster hazard mitigation could be similarly shallow."}, {"section_title": "Rethinking Risk Management Policies:", "text": "From \"Participation\" to Processes of Dialogue, Debate, and Negotiation"}, {"section_title": "Integrating Effective Participation with Interest-Satisfying Negotiations", "text": "So let us grant from the outset that risk management takes place in contested political settings in which interests, values and identities differ, in which conflicting claims about what ought to be dominate far more than any overall consensus on any public good. We begin with the initial conditions of facing substantial differences of commitment, value, tradition, perspective, allegiance and identity as these shape the settings in which public governance and planning take place. If we want not only to respect and respond to differences among stakeholders -residents, landowners, merchants, farmers, others-and to figure out effective strategies of action, we must ask how we can integrate rather than oppose or treat separately the twin challenges of \"citizen participation\" and \"effective negotiations\" as well. We must reject discussions of participation that simply give us accounts of voice disconnected from decisionmaking, accounts of expression disconnected from negotiation, accounts of showing up and taking part disconnected from actually making a difference with respect to the outcomes of pressing one's case. Similarly, we must reject discussions of negotiating agreements that do not deal forthrightly with including affected stakeholders or their representatives. We should, in effect, demand, first, that accounts of participation in planning address making a difference in terms of action, and, second, that accounts of negotiation in planning reject exclusive deal-making between powerful but hardly representative elite decision-makers. We come then to Table 1 that arrays more and less inclusive participation, higher and lower voice, across the top from left to right -with more effective and less effective negotiations arrayed from top to bottom along the left. This generates four quadrants as follows: Lower-Left: Here we have lots of voice but little being negotiated, and we might think of public hearings. Many \"participate\" and can speak, even if they can hardly speak to one another or make any agreements, and typically with three minutes each in which to speak, these \"participants\" leave such formally organized hearings more resentful, angry, suspicious of public power, and even cynical than when they arrived. We hear lots of noise but see nothing decided. Upper-Right: Here we have few participants but much being negotiated and traded. We might think of back-room deal making and decisions made by the \"old boys.\" Participation of stakeholder representatives suffers but deals take shape. The few participants make decisions indeed, but leave many affected stakeholders out of the action. Lower Right: Here we have few participating and little being negotiated. We might think of administrative processes as usual; these do not typically organize public participation or negotiate outcomes. Officials process cases, review data, consult experts, and issue decisions. Administration has influence, but neither participation nor effective negotiation has much role. Upper-Left: So here we come to the challenge of integrating high levels of voice, inclusion, and participation with effective -value creative and allocative-negotiations whose agreements will be practically implemented because they actually serve the interests of the parties who've made the working agreements in the first place. We can call the work in this quadrant not just \"democratic deliberations\" but \"multistakeholder mediated negotiations,\" and the differences between these terms turn out to be instructive in itself. Significantly enough, we shall see, democratic deliberations contain three distinct, if at times overlapping, moments or even processes, what we can refer to as moments of \"dialogue,\" \"debate,\" and \"negotiation.\" Each of these moments has an important role to play in democratic processes and yet, unless parties to deliberations take steps not to confuse these three deliberative activities, chaos can easily result instead of consensus, aggravation can result instead of practical agreement."}, {"section_title": "The Challenge of Effective Democratic Deliberation: Integrating Practices and", "text": "Processes of Dialogue, Debate and Negotiation consequences of those options. At times, too, though perhaps rarely, these processes might produce actual working agreements on practical steps that parties can subsequently take or authorize for action by virtue of their community, organization, or political positions. But these outcomes of learning together, mutually recognizing one another, generating and evaluating options, sorting out disagreements and disputes and actually coming together to agree on courses of action-these outcomes present potentials, but certainly not easily assured results. As if these potential outcomes were not difficult enough to achieve, we've said nothing yet about the histories that \"participating\" stakeholders bring: histories of distrust of one another, anger and resentment at how they've been treated or respected or disrespected in the past, histories of inequality of information, economic resources, social status, and, of course, political power. Participation in practice can hardly be non-political, and political processes take place on level playing fields only in academic imaginations, not in any real community or public policy setting. No wonder, then, that city planners espouse \"citizen participation\" in theory, but they know very well how difficult any meaningful participation can be in practice. When many parties come together to discuss this neighborhood or that proposed development or those regulations of open space, nothing guarantees productive outcomes. Neighbors and merchants often can and do not just disagree with each other-they can and often do escalate their differences. They can stereotype one another, impugn one another's real motives, hide information, and act dismissively or in what other parties certainly find less than respectful ways. They want each other often to be less selfish or romantic or narrow or pig-headed, even if they might not use just those words, and sometimes in exasperation in public meetings they'll say so. \"We need to build this building to bring jobs and tax revenues to the city: we can't just keep everything as it was thirty years ago!\" \"We don't need another big bulky building in the Center to create low-end jobs, generate lots of new traffic, worsen the congestion in the area, and wipe out even more public or open space!\" So the challenges of convening functionally democratic, public deliberations remain daunting: to integrate inclusive stakeholder participation with productive negotiations that will actually serve the interests of those included stakeholders. This work involves not only \"dealing with differences,\" but also, of course, the real dramas, real contingencies and struggles, of seeking to mediate public disputes (thus the title of Forester [3]). We can make theoretical and practical progress here, though, once we recognize that this work itself consists of three interwoven elements of distinct kinds of practical interactions between passionate stakeholders: elements and even processes of dialogue, debate, and negotiation. Woven together these make practical public deliberations possible, but if we confuse one with another, we're likely to produce chaos rather than any working consensus. In dialogue, participants try for the most part to express themselves and to understand each other. In debate, participants try to argue their points and find flaws in the arguments of 'the other side.' In negotiation, participants try for even more: less concerned about deep understanding, less concerned about the academic or doctrinal qualities of positions, stakeholders negotiating with each other search for agreements upon action, practical agreements that answer the question, \"what can we do now?\" To be clear, some participatory processes may focus upon one or the other of these ends. So a public dialogue might seek a better and deeper understanding between city residents, between immigrants and old-timers, between those of differing ethnic groups, between those of differing identities. Here we see innovative organizations like the Public Conversations Project 2 exploring frontiers with kindred spirits developing Study Circles and similar dialogic forms of citizen engagement 3 . Or yet other participatory efforts may seek less to promote interpersonal understanding than to clarify better and worse arguments, better and worse policy proposals, for example. Here, of course, careful listening and understanding serve a less dialogical and more evaluative purpose: knowing which argument, which policy proposal to improve education or to provide neo-natal health care, for example, appears more sound, a better bet as a basis for public action. Here we see equally innovative organizations devoted to increasing public intelligence and the acuity of public deliberations like James Fishkin's Center for Deliberative Democracy at Stanford University 4 . Fishkin's work on deliberative polling extends far beyond the staging of conventional policy debates 5 to assess how public deliberators change their views on public policy options and decisions after being exposed to conflicting sources of expert opinion and judgment. Or yet other efforts to promote fruitful public participation might focus on getting involved stakeholders not so much to understand each other, and even less to decide who's right or wrong, but more to come to a practical agreement about what they're going to do. So planners and public officials of many kinds can find themselves \"in between\" conflicting stakeholders who press differing agendas: some to build and others to slow or stop development, some to route bus services or put public services here and others to place those services there, and so on. In these cases, foundations or non-profits or government agencies might sponsor actual participatory processes in the form of practical negotiations between actually affected stakeholders-enabling participation and negotiations seeking stable agreements between affected parties to shape future (re)development more or less, to shape environmental protection more or less, and so on. Notice, now, that in many complex cases strands of dialogue, debate, and negotiation might well interweave with one another. To debate well, one needs not only to make counterarguments but to understand one's adversary as well. To negotiate well, likewise, understanding where the other \"is coming from\" may well help more than hurt us (and \"them\" too!). Nevertheless, these processes of dialogue, debate, and negotiation can easily get in each other's way. Who among us has not heard one party say to another, \"Stop arguing for a moment and listen: you're not understanding what they're saying at all!\" Who among us has not had our patience fray at times wondering if talk, talk, talk supposedly in the service of \"understanding\" will ever lead to action? So we should consider the opportunities as well as the traps that these three ordinary processes pose for parties to public deliberations, for the success of public deliberation may well depend on how the elements (or moments or phases) of dialogue, debate, and negotiation take shape in any real case. These processes, sketched roughly in Table 2 below, can tug in differing directions, and each one reflects deeply engrained and even studied traditions of thought and practice. Before considering how these practices and processes can complement one another, let's characterize them one by one."}, {"section_title": "Dialogue", "text": "When we engage in dialogue, we do so with the knowledge that perceptions of the world vary, that the very same elephant looks one way from the front and another way from the rear. We know that \"knowledge\" can be socially constructed and, more importantly, that what someone means by what they say can differ quite a bit from what they've literally just said. So we know, often, that \"This is a great computer\" means something different when heard from a salesperson than from a technologically savvy friend. In dialogue, we engage in a form of interaction we can call 'conversation.' Participants in dialogue expect to be able to speak and listen to one another; they expect to be able to tell their stories while taking care not to dominate one another's time and attention. In dialogue we try to gain understanding of one another, not to convince or persuade or control the other but to say what we feel to be important and to appreciate and consider in turn what others feel to be important too. Here our dominant line of questioning involves variants on the basic query, \"What do you mean?\" \"Could you help me understand what that means to you?\" But all is not rosy: in dialogue some may find themselves impatient and wish for some resolution to issues at hand; some may be frustrated with what they see as \"talk, talk, talk\" and \"understanding\" but no action. However much \"mere talk\" can frustrate some deeply concerned to \"act\" now, the tradition of dialogue itself demands respect and claims a central place in philosophical understandings of language and interpretation. Whether dialogue is foundational to language use or not, long traditions of hermeneutics and phenomenology, for example, concern themselves with the challenges of appreciating and understanding the possibilities of dialogue [4]."}, {"section_title": "Debate", "text": "When we debate another, we typically treat them, and their words, differently. In debate, we try to establish the correctness of our position and the limits, partiality, weaknesses or simply mistakes of the positions and claims of those we're debating. In debate, we listen, of course, but we are conversing less and arguing more. If in dialogue we try to understand what the other person means, what they take to be significant and valuable and at stake, in debate we attend less to the other person and more to their claims and the vulnerability of their claims, their arguments. So here our central line of questioning involves variants of, \"Can you prove that? What could possibly justify that conclusion?\" In debate we try to vindicate our arguments and show why the arguments of the others are misleading, wrong, based on faulty evidence or methods. Of course, when the other tells us that our arguments are misleading, wrong, and so on, we might not appreciate it, and so it's easy to understand that the relationships between debaters can easily be more fraught or tense than the relationship between those in dialogue. In dialogue, participants may not come to agree on things, but they might appreciate each other more, respect each other more, trust each other more, give each other some measure of recognition and dignity that their previous less well-informed opinions might have not allowed. In debate, of course, we may also not come to agree on things, but one of us is arguing that the other is simply wrong, not adequately informed, or not using methods of analysis or logic correctly. If dialogue does not produce winners and losers, those 'right' and those 'wrong,' debate often does. Little surprise then that the participants in debate might not come to appreciate, respect or dignify each other more than they had before. So those in dialogue risk too much \"talk\" without resolution, those in debate may find themselves with resolution (one has prevailed and established the better argument) even as they have weakened or damaged their relationships (since the loser might not have appreciated the other's implications that their use of methods or evidence had not been competent!). But debate plays a crucial role in modern societies, of course. We could hardly imagine the scientific enterprise itself without appreciating the highly sophisticated institutions devoted to advancing debates transforming on an almost daily basis our understandings of physics, chemistry and biology, engineering and medicine, for example. Our very notions of research and scholarship, of course, involve disciplines and institutions that organize argumentation via publications and debate in the \"community of scientists\" who present their latest findings and offer them for refutation or substantiation by others. Debate as a practice has intellectual moorings every bit as serious as dialogue, moorings in the philosophical traditions of critical rationalism and the broader philosophies of science (see e.g. classically Popper [5])."}, {"section_title": "Negotiation", "text": "When we negotiate with another person, in contrast, we approach them and what they say quite a bit differently. We care to understand them, surely, and we consider whether we take their arguments or claims to be well-founded, of course, but we take something else to be still more important: we're trying to find a way to act together, to solve a problem or divide up resources or to coordinate our actions. We negotiate to decide upon a policy, to split up a budget, to agree upon a future use of land, and so on. We negotiate to produce an agreement upon action -not understanding, not a winning argument, but a course of action. We're concerned first of all not with what the other means but with what they might agree to do; we're concerned less with disproving their claims than we are with inventing a course of action that we can really, practically implement. We're less concerned with publically demonstrating that their logic or use of statistics is faulty than we are with demonstrating publically that we have come to an agreement. When we negotiate, we want to get something done, and if we're concerned about what's public, we want the public announcement of our agreement to act to help cement each party's commitment. So our line of questioning here involves variants of, \"What if we try this? What can you propose? What if we do this in addition or instead?\" We're oriented to acting, and if keeping quiet a bit about why the other person's just wrong about some belief will help us get done what we want to get done, we'll choose our priority of acting over the lesser priority of telling the other person how wrong they are. Negotiation too draws upon diverse intellectual traditions, both in social science (e.g. economics) and in philosophy (e.g. pragmatism). Negotiation, of course, has its shadow side or its practical traps, too, just as do the processes of dialogue and debate. If we worry about too much talk in dialogue or about escalating nasty relationships in debates, we might worry about lousy compromise, lose-lose outcomes that punish all parties, in negotiations. No wonder then that \"participation\" strikes many as idealistic, desirable, if at times unpractical while \"negotiation\" strikes many as quite practical but threatening the betrayal or sacrifice of our principles, threatening opportunism and convenience rather than actually achieving the goals we seek."}, {"section_title": "Integrating Dialogue, Debate and Negotiation via Facilitating, Moderating and Mediating", "text": "We have a plausible case, so far, that these processes of dialogue, debate and negotiation differ from one another, but so what? In the abstract, these three stand as distinct, perhaps, and they seem not to complicate each other. In practice, unfortunately, things are not so simple, for in any given \"meeting\" participants can easily wonder what they're there for: to understand one another without deciding upon action, to figure out who's right and who's wrong, to commit finally to a course of action, or to some particular combination of these possibilities? In any real world in which time and resources, trust and certainty, may well be in short supply, participants don't want to waste their time, feel themselves being used rather than acting to serve their values and interests. When meetings convene participants with differing agendas, differing resources, differing priorities, the meetings themselves can easily be chaotic and infuriating if some participants have come to make decisions but others \"just\" want to talk and listen, if some have come to find out whose position's really right but think that decision-making too soon risks putting expediency above quality. We have all been there and heard, \"We need to discuss this more and not rush into it,\" \"We can't talk this to death, we need to act and act soon!\" \"We can't jump into this without more analysis; We won't even know what we're doing\" -and so on. So the practical point of this analysis may be three-fold: first, our meetings are often disappointing because as we participate in them, we bring seriously differing objectives and frustrate one another: one hopes to talk and be heard and the other wants to act; one wants to judge who's right and wrong and the other would like to understand what the real issues are in the first place, and so on. Second, though, those convening, leading and managing our meetings often seem uncertain what they're trying to do as we meet; they are clear about being efficient and productive, but they are unclear about what we're really going to do as we meet together. They're unclear, that is, about their own roles in helping us, managing us, leading us-either to facilitate our dialogues sensitively so we gain better understanding, or to moderate our debates carefully so we identify the stronger and weaker arguments, or to mediate our negotiations pro-actively so we can come to mutually agreed upon commitments to act to serve our interests-or, perhaps, to integrate moments of facilitation, moderation, and mediation to help us understand, learn and act together. Third, our meetings are too often boring or ugly or uncomfortable or all three, so little wonder that all but the professional meeting-goers might dread going to any more of them. The strands of understanding via dialogue, learning through debate, and coming to act together through negotiation may often be interwoven, but they need not be confused. More practically, planners and managers, community leaders and public administrators, too, need to develop and refine the distinct and related skills and competences of facilitating understanding, moderating argument, and mediating negotiator's contradictory proposals for action. Again, in real cases, these processes and skills can complement one another. Think simply of typical stages of the management of public disputes. At some point early or late in the history of a case, a community leader or a public official may try to address a dispute by calling together interested parties or \"stakeholders.\" After initially then assessing who's affected and who might be willing to talk to one another and what the costs of continuing a given dispute might be, this community leader or public official might then convene interested parties to listen to each other, to learn about one another's priorities and interests and fears and goals, to begin to search for ways of acting together that will be better for everyone than the status quo. That search process -can we develop a strategy of action that will be better for us than we have invented before -will then very likely involve the parties learning about their environment and their options, about legal and economic possibilities, about technological possibilities, about shifts forthcoming in policy and regulations, and so on. Sometimes only after such assessment, convening, and learning can participants then actually take the next step to negotiate courses of action that they can agree to and implement. In that rough trajectory that runs from assessment through convening to learning and negotiation, we can easily see how the work of facilitation of dialogue might far outweigh that of mediation in the early stages of assessment and convening, how the work of moderating might have a particular place as parties try to debate conflicting views, and of course how the work of mediating might then take particular prominence as parties come to invent and craft proposals for real action as they negotiate. We offer this deceptively simple scheme for both practical and analytic purposes. We believe that the vagueness of appeals to public \"participation\" should not undermine its actual efficacy. We suggest that distinguishing and then re-integrating the processes of dialogue, debate and negotiation-and their corresponding practices of active facilitating conversation, moderating arguments, and mediating negotiators' proposals-can help us do better to realize the potentials of actually participatory governance in contexts of risk and natural hazard management. Author's note We find a dearth of work on participatory processes in disaster risk reduction contexts. Rarely do we find discussions of the dynamics of participatory process in these settings. Several authors, though, emphasize the need for participation from a social justice and political economy perspective [6,7,8,9]. Versions of this paper began in seminars given at the University of Amsterdam and the University of Newcastle. Comments appreciated from critical readers."}, {"section_title": "Patterns of Risk: Spatial Planning as a Strategy for the Mitigation of Risk from Natural Hazards", "text": "Introduction Over the past several decades the recurrence of natural disasters has continued to remind people of their capacity to cause devastation to communities, and at times even countries. Tsunamis, earthquakes, hurricanes, storm surges, heat waves, droughts and floods have costs hundreds of thousands of lives and hundreds of billions of dollars of damage in recent decades. This trend appears to be increasing over time and seems likely to continue to do so as a result of shifting hazard and vulnerability. In particular, climate change seems likely to make some natural hazards worse. Many of the disasters that have occurred were avoidable to some degree, since there was good knowledge of both the hazards and the vulnerable communities that were exposed to them. Examples include the Sarno landslides in Italy [1], Hurricane Katrina in the United States, and devastation from earthquakes to poorly built buildings in China, Turkey and Iran. Nevertheless, in spite of this prior knowledge people continue to place their communities in harms way. Why? The explanation as to why this still occurs is multi-faceted and complex and should play a role in future disaster prevention. Experience has shown that the traditional emphasis that society places on preparedness and response as compared to mitigation and prevention is inefficient, and results in more frequent or more severe disasters. The old adage that \"an ounce of prevention is worth a pound of cure\" is as true in mitigating natural hazard risk as it is in any other realm. In order to reduce disaster impacts, greater emphasis needs to be placed upon mitigation and prevention; thus the importance of spatial planning for disaster prevention. Not all mitigation is effective however; in fact some mitigation strategies have been critiqued as either being ineffective or even prone to increasing risk. This issue is critical and is best understood within a broad holistic framework. One field that satisfies this criterion is that of \"risk management\", and it is from this perspective that this paper will consider the mitigation of natural hazards."}, {"section_title": "Mitigation and Risk Management", "text": "Risk management is a formal planning process used to identify risk, estimate its potential impact, develop strategies to manage it, and monitor it over time. Strategies to manage risk include acceptance, avoidance, reduction and transference. Political, social, environmental, economic and engineering factors are all relevant to the process. The issue under consideration, mitigation, is part of a larger risk management process and specifically refers to a-priori structural and non-structural actions or measures taken to reduce the potential impact of disasters. Examples include dams, dykes, land use planning, legislation and sometimes insurance 2 . The set of adaptation options are illustrated in Figure 1 [2], which shows a decision tree based upon the above. Mitigation falls under the boxes \"purposeful adjustments\" and \"choose change and reduce losses\". It is worth noting that some organizations are now differentiating between mitigation and prevention (which refers to actions designed to totally prevent damage from hazards). For the purposes of this paper prevention will be considered part of mitigation. Risk management within the disaster context is often portrayed as the \"disaster management cycle\" (also referred to as the \"emergency management cycle\" or the \"disaster risk management cycle\"). Mitigation is captured explicitly within this model, which is composed of the overlapping phases of mitigation/prevention, preparedness, response and recovery. This model has been widely accepted within the practitioner community and has been particularly useful in emphasizing the importance of phases other than preparedness and response. In order to be effective, these phases must engage both formal (e.g. legislation and policy) and informal processes and networks (e.g. trusting relationships between colleagues), and must rest upon sufficient system capacity (human, financial and material). Other models, such as that used by Australia ( Figure 2), situate disaster management within a more typical risk management process. This exemplifies a riskbased, rational decision-making process that works well when threats, coping strategies and timeline are well understood, and stakeholder buy-in exists.  Mitigation in the above model occurs within the \"Treat Risks\" box, where the choice tree of adjustments (as seen in Figure 1) can be used to select desired strategies. However, as previously noted, not all mitigation strategies have been effective; some have even been counterproductive and have ultimately increased disaster losses [4]."}, {"section_title": "D. Etkin / Spatial Planning as a Strategy for the Mitigation of Risk from Natural Hazards 46", "text": "Researchers have argued, for example, that the national flood insurance program in the U.S. has resulted in increased flood losses [5]. Similarly, some communities protected by engineering structures have suffered devastating losses (e.g. New Orleans, Mississippi River floodplain). Reasons for these losses include biased risk perceptions, unfounded beliefs in the degree of safety provided by mitigation strategies, and disconnects between those who make and often benefit from risk decisions and those who suffer losses."}, {"section_title": "Risk Defined", "text": "Different communities use the word risk in different ways. Most commonly it is either used to mean the probability of some potentially damaging event (such as the risk of flooding is 20%), or a combination of likelihood and consequence. Within the natural hazards community the definition normally used is Risk = Vulnerability x Hazard [6]. Though this appears to be a simple mathematical equation, in reality it is far more complicated. Risk is viewed as being socially constructed, which means that it is composed of important subjective and qualitative features. This can be seen both in terms of the threats that are chosen for evaluation and the metrics used to measure them, such as the value of human life or the environment. As well, from a methodological perspective, there are fundamental difficulties with evaluating risk such as how to weight different types of vulnerabilities when they are combined (such as gender as compared to education) and the complexity with which different factors are related to each other (e.g. poverty and health). These issues make vulnerability assessment an extremely difficult issue to deal with quantitatively."}, {"section_title": "A Disaster Model", "text": "There is no universally accepted meaning of the word disaster [7]. A working definition of the term is, however, helpful within the context of this chapter. For this purpose the definition used by the UN International Strategy for Disaster Reduction (ISDR) will be used. A disaster is therefore defined as \"A serious disruption of the functioning of a community or a society causing widespread human, material, economic or environmental losses which exceed the ability of the affected community or society to cope using its own resources.\" It is not possible to conceptually separate one's understanding of the term disaster from a disaster model. The meaning used in this chapter (vague as it is, and must be) views it as an event that happens to people and communities when some extreme or hazardous event triggers an existing vulnerability, but also one that is experienced and interpreted through the windows of their psychology, worldview and culture. A modified version of the Pressure and Release (PAR) disaster model [6] will be used to illustrate this process ( Figure 3). The essence of this modified model is that chains of cause and effect largely rooted in social processes create a progression of vulnerability that results in unsafe conditions in human settlements. As well, a progression of hazard exists that has inputs that are both exogenous and endogenous. The PAR model has been widely adopted within the disaster and emergency management and has been a powerful tool to deepen understanding from a social science perspective about why disasters happen. This adaptation of PAR has the advantage of providing a more dynamic view of hazard and of linking hazard and vulnerability in a more formal way. Figure 3 can also be used as a schematic to illustrate the definition of risk used within the natural hazards and disaster management community (i.e. Risk = Vulnerability x Hazard). Many of the root causes in the above model are presented as being common to both vulnerability and hazard, thus creating an important common nexus. An example is an economic system, which can create the type of environmental degradation that makes many hazards worse, but that also creates a critical infrastructure system that lacks resilience because of an emphasis on short-term profit making. This \"chain of cause and effect\" model views disaster primarily as an external event that happens to people, is rooted in the tradition of western rationality, and empowers people and communities to change their disaster experience by altering their external, social and constructed world. An alternate view, still common in much of the world, is rooted in fatalism or faith/belief systems that place people as victims to forces beyond their control [8] such as Nature or God. Within these systems sin, guilt and punishment often play a predominant role [9]. For example, some people believe that the 2005 Tsunami in Indonesia was sent by God to punish people for their evil ways [10]. One aspect of the disaster cycle that is not obvious from Figure 3 is a return loop, where the social processes that affect hazard and vulnerability are altered by the impact disasters have on people and communities. For example, many of the policies related to land use and building codes, and the development of the insurance and reinsurance industries occurred in the aftermath of disaster, as society strived for ways to mitigate or prevent these events. This would be portrayed in Figure 3 as arrows progressing from disaster to the cause and effect chains. Mitigation or prevention can occur in any one of boxes 1-5. Within the original PAR model this is considered as the release phase."}, {"section_title": "Patterns of Risk", "text": ""}, {"section_title": "Disaster Data", "text": "Risk, as a consequence of hazard and vulnerability, result in disasters that can be measured and therefore disaster data can be used to as a proxy to empirically estimate risk. There are several datasets used for this purpose [11]. Internationally the most common datasets are those created by reinsurance companies (Munich Re and Swiss Re) and the Centre for Research in the Epidemiology of Disasters (CRED). Typical metrics used are mortality, number of people affected, and economic or insured loss (either total or normalized in some way -per capita for example). The choice of metric greatly affects ranking of disaster data, as illustrated in Figures 4a, b, which show global spatial patterns of natural disasters from CRED (Note how the patterns change when the number of disasters are normalized by population). Maps of economic impact show a similar pattern. For example, total economic loss makes disasters appear much greater in wealthier countries, whereas disaster loss in relation to income or GDP would emphasize poorer countries. Where lives lost are used as a measure, disasters in the developing world dominate the charts. Using insurance data as a proxy for disaster is a particularly poor choice, except for the industry affected, because some countries do not have an insurance culture and therefore even major disasters may have relatively small insured losses.   An important detail is that disaster data is intimately connected to ethics and values. This is not just because the data represent deaths, injuries, loss of livelihoods and the terror and misery of those affected, but also because the choice of metric used to represent these events reflects fundamental values on the part of the analyst. Additionally, there are significant methodological and data accessibility problems in measuring the economic cost of disasters, as well as determining number of lives lost or people affected [13]. Some countries will, at times, exaggerate disaster losses in order to generate larger amounts of aid, while others may minimize their impacts for political reasons (such as how China handled their SARS epidemic). Some metrics such as misery, enticing though they might be, are so qualitative that they are very difficult to estimate and therefore are not often used. The most important thing to remember when attempting to make sense of disaster data is that it is generally rather poor. This does not mean that inferences cannot be made from it, but rather that the data should be interpreted with care. One characteristic of disaster data is that it has what are called \"heavy tails\". This refers to the very large proportion of impacts that result from the few events at the tail end of the probability distribution. This can be illustrated as follows: the National Climate Data Centre in the U.S. publishes a list of billion dollar weather disasters 3 . Using their data of 78 events, over half of the cumulative costs resulted from the worst 5 disasters, with Hurricane Katrina alone accounting for almost \u00bc of the total amount. The implications of this for risk analyses are significant. Unless worst case scenarios are included with reasonable estimations of their impacts, risk assessments will be very biased towards low estimations. In spite of this it is often the case that estimations of worst case scenarios are excluded (probably because of the difficulty of making them, or because they cause people to feel helpless) and when included are often not accurate due to the many difficulties in such an estimation. Loss estimations are particularly difficult and unstable when probabilities are very small and potential impacts are very large."}, {"section_title": "Hazard and Vulnerability", "text": "In addition to disaster data, there are numerous maps showing patterns of natural hazards on a variety of spatial scales; one example is the World Map of Natural Hazards by Munich Re. Another more quantitative example is the Global Seismic Hazard Assessment Project 4 ( Figure 5), which has produced a global map of peak ground acceleration that a site can expect during the next 50 years with 10 percent probability; regional data is also available from the same source. National geological and meteorological departments often have similar but more detailed maps or data available. Within Canada many such maps are part of the National Building Code; examples include ground shaking, wind speed and snow loads.  Figure 6 is an example. A third class of maps relates to the built environment, particularly critical infrastructure. When hazard and vulnerability data are available in GIS format they can be overlain in order to estimate risk. One example is Figure 7, which shows the location of large cities in relation to climate risk. A web search using the words \"hazard, vulnerability, risk map\" will point to numerous cases. Another example is New York State, United States, that has a web based GIS Information Systems Clearinghouse 5 . As well, the Federal Emergency Management Agency (FEMA) runs a GIS based program called HAZUS that can be used to estimate potential losses from disasters. Though it is for a specialized purpose, the insurance and reinsurance industries (for example, Munich Re and Swiss Re) as well as some private companies devote considerable resources to the development of catastrophe models that they use to estimate potential losses from extreme events such as hurricanes and earthquakes. These models can also be useful to other groups of professionals such as urban planners. 5 "}, {"section_title": "Trends over Time", "text": "Both hazard and vulnerability shift over time and therefore the number and types of disasters do as well. Historically, there is evidence that disasters have been increasing in frequency (Figures 8a, b). Both the CRED and insurance data sets show large increases in the number of disastrous events over the past several decades. There are many reasons for this, including that many of the world's largest cities are located in hazardous regions. This is often the case because of the proximity of natural resources or good transportation, and it follows that as these cities grow in size risk will continue to increase. Other reasons for this increase include better reporting, increases in population and wealth, shifts in population to more hazardous areas, environmental degradation and urbanization. It is difficult to tease apart the contributions of the various factors, but most discussions of disaster data infer a real increase (e.g. [4]). Climate warming resulting from the emission of greenhouse gases into the atmosphere seems likely to affect the future frequency and intensity of some natural hazards, particularly heat waves, floods and droughts [17]. Attempts have been made to combine anticipated changes in climate with social vulnerability. For example, Diffenbaugh et al [18] reflects on the link between population and poverty as well as relative climate change. Such projections are, of course, subject to a number of assumptions and caveats. Parry et al. [19] also attempt to estimate the numbers of people who might be exposed to hazard in 2050 and 2080 as a result of the impacts of climate change (Figure 9).  These projections have raised serious concerns amongst scientists, environmentalists and insurers regarding the ability of society to cope with future risks (e.g. [20], [21]). In particular, ecologists warn of ecological and environmental devastation resulting from the 6th great extinction of species on this planet. This may occur as a result of changes in land use, pollution, overfishing, and habitat destruction, in addition to climate change. For this reason, many argue that the precautionary principle 6 should be applied, and that society should immediately alter practices that result in environmental degradation. The Kyoto Protocol is one result of that perspective. Global trends in development and greenhouse gas emissions suggest that both hazard and vulnerability will continue to increase for some time, and therefore it seems very likely that the number of disasters will continue to increase in tandem. Disasters, though the risk is omnipresent, are uncertain future events 7 . This uncertainty is exacerbated by significant changes occurring in both hazard and vulnerability, and therefore decisions made today must be done within that context. This can be viewed in a simplified way as shown in Table 1. First, consider the two right hand columns. A survey of the scientific literature in several realms, including climate change, urbanization, technological change, the environment and ecology strongly suggest that the second column is a very unlikely future (e.g. [20], [17]). This leaves column one as the probable future. The choice then, is to mitigate and avert many of the worst impacts of future disasters, or not to invest in current mitigation and let future generations pay the price of our generation's neglect (though it is likely that many of the impacts will begin to be felt by those currently alive). This is largely based upon research that suggests an average benefit:cost ratio for mitigation of 4:1 [22]. The only way a rational decision can be made for \"no mitigation\" is to take a selfish perspective and assign no or little value to people and communities who will be affected by future disasters. Some might consider this a valid choice, but it should be explicitly stated and discussed within any strategic plan. Ideally, this should be part of a broad public participation process [23]."}, {"section_title": "Risk Homeostasis", "text": "\"Risk Homeostasis Theory maintains that, in any activity, people accept a certain level of subjectively estimated risk to their health, safety, and other things they value, in exchange for the benefits they hope to receive from that activity.\" [24]. This theory emphasizes the notion that people have set points of risk taking behavior, similar to the way our bodies have a set point of temperature. The theory proposes that if people's perceptions of risk change, then so does their behavior. Specifically, behaviors will become riskier if relative to some level of acceptable risk, perceptions are that risk has decreased (and visa versa). This has important consequences for mitigation. For example, the well known \"levee effect\" (e.g. [25], [26]) is related as follows: In order to reduce risk, dams and levees (or dykes) are built to control water flows. People then perceive that they are \"safe\" and develop within the protected areas. However, though these areas are subject to floods less frequently than before the structural mitigation was in place, extreme events still occur from time-to-time that exceed the design standards of the protective works. The resulting disaster is often all the worse as a result of the development. Additionally, structural protections will sometimes simply fail as a result of poor design or maintenance, or just because even well designed systems have a non-zero probability of failure The Canadian Flood Damage Reduction Program (FDRP) in the Province of Quebec is another example of a program that was ineffective. This program was a federal-provincial partnership that mapped flood plains for about 1200 communities across Canada. From a scientific viewpoint it was very successful. However, studies of a number of Quebec communities [27] have shown that even after the flood risk information was provided to the municipalities, development within flood plains continued unabated. The assumption was that this risk information would be used to alter development patterns -a typical perspective of physical scientists. Politicians and many others, however, respond to a much broader decision-making framework, which includes time frames bounded by limited electoral terms and economic drivers. Mitigation strategies that are based upon top-down command-and-control methodologies and that have as an underlying assumption that human behavior will not change as a result of the imposition of the strategy, tend to suffer from the reality that people do adjust their risk taking behavior as a consequence of perceived changes in their risk environment. This accounts for the failures of some mitigation strategies. From the point of view of a psychologist, a preferred approach is to create incentives for risk avoidance and disincentives for risk taking behaviors [24]. One common critique of some insurance or disaster assistance programs is that they do the reverse and encourage people to create more vulnerable communities or to rely upon aid, as opposed to developing long-term community resilience."}, {"section_title": "Risk Perception & Mitigation Strategies", "text": "Given the above discussion, the importance of risk perception is clear. If people adjust their risk taking behavior as a result of their perceptions, then biases or other problems related to risk perception are crucial in determining resulting actions. Where perceived risks are biased, people will become either more or less exposed to risk than they intend. The former is dangerous while the latter may result in missed opportunities. Empirical research shows that people have a poor ability to estimate risk. For example, Lichtenstein et al. [28] found that the range of people's estimates for the number of deaths per year due to a variety of causes in the U.S. covered a range of 3 orders of magnitude smaller than reported numbers. In addition, rare deaths were consistently overestimated while common ones were underestimated. Weber [29] notes three important aspects of how people assess risk: \"(1) The first is the causal importance of visceral reactions towards risk. (2) The second claim is that there are two pathways to establish concern, or the feeling of being at risk that are differentially effective. The first, more effective path is through personal exposure to (adverse) consequences, typically repeatedly and over time. The second, less effective path is through the consideration and possibly mental simulation of adverse consequences based on a statistical summary of the hazard, typically provided by domain experts. (3) The last claim concerns that fact that people's visceral reactions to risky situations often have little correspondence to more objective measures of risk that quantify either the statistical unpredictability of outcomes or the magnitude or likelihood of adverse consequences.\" Risk related to events that may not take place until some distant future, especially if people have no recent experience of a similar nature (such as with climate change), will tend to be based upon statistical estimations or a cognitive risk estimation process disconnected from affective or visceral reactions. These result in a bias that tends to underestimate the importance of such events. Another important factor is the belief that technological forms of protection, particularly structural mitigation, have the capacity to create extremely high levels of safety [4], more so than actually exists from a more empirical perspective. As discussed above in the section on risk homeostasis, this biased risk perception results in changes in behavior that put communities at increased risk (see Box 1 for an example). Slovic [30] in his book The Perception of Risk reflects on this point when he says that \"We live in a world in which information, acting in concert with the vagaries of human perception and cognition has reduced our susceptibility to accidents and diseases at the cost of increasing our vulnerability to massive social and economic catastrophes.\" The main factors that contribute to people's limitations in assessing risk (also known as bounded rationality) are: A limited range of known or acceptable alternatives. o Law, culture, lack of knowledge. Misperception of risks. GULFPORT, Illinois, June 19, 2008 http://www.cbsnews.com/stories/2008/06/19/national/main4196963.shtml (AP) Juli Parks didn't worry when water began creeping up the levee that shields this town of about 750 from the Mississippi River -not even when volunteers began piling on sandbags. After all, the U.S. disaster aid agency FEMA had assured townspeople in 1999 that the levee was sturdy enough to withstand a historic flood. In fact, some relieved homeowners dropped their flood insurance, and others applied for permits to build new houses and businesses. Then on Tuesday, the worst happened: The levee burst and Gulfport was submerged in 10 feet of water. Only 28 property owners were insured against the damage. \"They all told us, `The levees are good. You can go ahead and build,\"' said Parks, who did not buy flood coverage because her bank no longer required it. \"We had so much confidence in those levees.\" \"People put all their hopes in those levees, and when they do fail, the damage is catastrophic,\" said Paul Osman, the National Flood Insurance Program coordinator for Illinois. \"New Orleans is the epitome; a lot of those people didn't even realize they were in a floodplain until the water was up to their roofs.\" o The notion that disasters are cyclical as opposed to random, including a misunderstanding of the meaning of 'return period'. o Denial of dreaded events. o Fatalism, which results in a lack of preventative actions. o Not understanding independent events. o Overconfidence in mitigation. Denial of uncertainty (such as the \"Fallacy of misplaced concreteness 8 \"). Crisis orientation, which leads to an over emphasis on response and not enough on mitigation and prevention. People have a strong tendency to use heuristics or rules of thumb to estimate probability and risk. Research shows that there is a large degree of overconfidence in these estimations, typically because of insensitivity to the tenuousness of the assumptions upon which they are based. Slovic [30] notes that \"\u2026 individuals are strongly conditioned by their immediate past and limit their extrapolation to simplified constructs, seeing the future as a mirror of that past\", and that \"We are essentially trialand-error learners, who ignore uncertainty and rely predominantly on habit or simple deterministic rules\". As well, perceived risk is influenced (and sometimes biased) by the \"imaginability and memorability\" of events. For such reasons people often do not have valid perceptions, even for many of the risks that they are exposed to."}, {"section_title": "Conclusion", "text": "Data over the past few decades suggests that the frequency and magnitude of disasters have been increasing, though there are a number of confounding factors that make precise analysis difficult. In the future it seems likely that both hazard and vulnerability will continue to worsen, and as a result the trend towards more and worse disasters is expected to continue. Because of this good mitigation strategies will become increasingly important. These strategies must be developed within a broad holistic framework, such as through a risk perspective. In particular, how people perceive and respond to risk is critical and must be part of any planning process. Adopting a more narrow structure results in policies that tend to be sub-optimal at best or counter productive at worst.\nIn this paper I have sought to examine the nature and drivers of exposure as a root cause of individual and community risk from natural hazards and as an indicator of societal failure to adapt, despite success in disaster response. I have also aimed to elaborate an operational conceptual framework for the analysis of exposure that may facilitate its study and the design of public policies to deter communities from increasing their exposure. A critical point in the argument is the issue of the relationship between exposure and vulnerability as properties of social-ecological systems. It is contended that both are complementary but disparate concepts, although more interdisciplinary discussion and debate is needed to explore their unambiguous or, else, fuzzy boundaries. It is maintained here that we may consider exposure as the potential for loss, and vulnerability as the potential for differential loss. The association of exposure with behavior -as risky individual or collective actions-and its spatial dimension, establish a definitional separation from vulnerability. The rationale of this chapter is based on the assertion made by Quarantelli [3] who sees \"\u2026disasters only in the unwanted behaviors of persons and groups.\" In the light of this statement, the proposed TNK framework focuses on three primal elements that explain risk exposure; the historical nature of hazard-prone land occupation, the satisfaction of basic human needs and economic wants, and the insufficient environmental knowledge of communities. Although it may seem the model emphasizes social processes as a sum of individual actions, this is not at all the case. Social factors intervene throughout not only as facilitators or constraints on individual actions, but also as determinants of the historical and economic levels. This framework may help to clarify the factors and actors intervening in a certain scenario and contribute to the adoption of more efficient policies to anticipate and to reduce exposure. The important role of risk knowledge as a driver calls for enhancing general competence, not only by means of transferring knowledge, but also by changing people's understanding of risk. Basic needs satisfaction operates as a key driver in developing countries as do wants in developed countries. As a matter of fact, the importance of needs is most visible when a disaster occurs, when the lack of resources drives people back to a condition of survival. Their dissatisfaction pushes large human groups to occupy land in hazard-prone areas without consideration of their weakness. Global-scale economic development policies have to be applied to deal with the lack of access to basic needs, although clearly, this task is immense. The satisfactory implementation of risk governance should be comprehensive, integrating reactive and proactive strategies, in order to satisfactorily respond to disasters, but also to anticipate exposure and increase coping and adaptive capacity. Mitigation and adaptation will remain abstract terms unless we clearly identify the elements upon which to act. Abstract. The precautionary principle can require regulatory action in cases of potential environmental damage, even before conclusive scientific proof of harm has become available. Critics charge that this inherently puts the principle at odds with rational risk management, which should be based on sound science and costbenefit analysis. This chapter clarifies the significance of the precautionary principle by answering a variety of criticisms. The precautionary principle is not anti-science; it calls for more and wider scientific investigation of poorly understood environmental phenomena. It does not oppose hazard assessments done by experts, but it does make experts answerable to a broader public. Yet the deliberative turn in implementing the precautionary principle does not expose it to charges of populism. By using standards such as proportionality and revisability, the precautionary principle promotes reasoned policy-making in cases where risks are insufficiently understood. Finally, precaution is not to be equated with prohibition. Precautionary measures include anticipatory actions such as intensified monitoring, increased safety margins, systematic labeling, and spatial planning that creates protected zones for certain activities. The complexity of precautionary action is a reflection of the complexity of our societies and of the links they create with nature.\nThree lessons emerge from our discussion. First, the precautionary principle contributes to environmentally sound public policies not by overturning science-based risk management but by compensating for its weaknesses. It is true that, compared to science-based risk management, the precautionary principle lowers the evidentiary threshold for triggering a public policy response to environmental risk. In comparison to cost-benefit analysis, it favors more deliberative public involvement in the regulatory processes. None of this is to deny, however, that many risks are reasonably well understood. If so, science-based risk management can be quite appropriate. But where the science is uncertain and consequences are serious and irreversible, a more stringent standard of safety is needed. The precautionary principle is for confronting new types of environmental risk. Second, the precautionary principle is not a policy straightjacket. The measures it supports are proportioned to the degrees of uncertainty in different precautionary situations, as well as to the anticipated severity of the consequences. It allows for a wide range of policy responses. If there are worries that a fish stock may be in danger of collapse, options might extend from spatial planning of fishing activity (with permanent or temporary exclusion zones), to changing quotas so that they include more conservative assumptions about population recovery periods, to seasonal interruptions on fishing, to requiring the implementation of a special a feedback monitoring regime. Furthermore, not just prohibitions and penalties, but also incentives and rewards for good stewardship practices could be part of a package of precautionary programs 4 . Whatever policies are proposed should, at a minimum, be subject to stakeholder discussions, multidisciplinary scrutiny, and broad public commentary. Precaution is a call to heightened awareness, participation and policy creativity. Third, the precautionary principle is anything but anti-science. It takes carefully designed, long-term studies to reveal the effects of trace chemicals on various animals' metabolism. It takes satellite observations, polar expeditions and detailed analyses of atmospheric chemistry to detect the depletion of the ozone layer. It takes comprehensive ecological studies to discover the interdependence of species and essential geophysical characteristics of particular habitats. Scientific research is indispensable to the precautionary principle. Without research, there can be no early detection of risks. And the principle requires continuous efforts to gain new scientific understanding. Furthermore, it promotes action, not inaction. It requires that measures be taken -research, monitoring, labeling, staged measures of confinement and openrelease, and so forth -thus acknowledging an imperfect understanding of the danger and its accompanying mechanisms. Precautionary measures can be relaxed or reinforced as the dangers become better understood. The precautionary principle started its international career not as a challenge to the role of scientific expertise, but as a pragmatic response to the growing (but still incomplete) scientific understanding of the causes of large-scale environmental damages. The precautionary principle is not a simple juridical or moral principle in the traditional sense, something that might furnish simple criteria allowing for an easy decision in most cases. Yet the complexity of precautionary action is not a defect in the precautionary principle itself. It is a reflection of the complexity of our societies, of the forms of knowledge they construct, and of the links they establish with nature. The United Nations considers the challenge of climate change will be lost or won in the urban areas [1]. Urban areas maintain a dynamic bidirectional relationship with global biophysical processes like climate change. On one hand, an important part of the greenhouse emissions are directly or indirectly connected with urban areas. On the other, good part of the negative consequences of climate change will impact urban areas, particularly in poor countries [2]. International organizations, national governments, and local mayors, have begun to pay attention to climate change. Many of the local responses to climate change are taking place in industrialized countries and they tend to focus on the mitigation of greenhouse gases with only a few cities addressing adaptation. In comparison, only a small number of urban areas in poor countries or emerging economies have created responses to climate change. The majority of local authorities and urban stakeholders in those countries consider that the negative impacts of climate change will occur too far away in the future. Their priority is solving current social, urban and environmental problems before addressing climate change. Unfortunately, many of those problems aggravate their vulnerability to the negative consequences of climate change. Further delays addressing them will increase the social, economic, and environmental cost of climate change in the short and longterm. This chapter stresses the need of addressing urban systems within the framework of regional and global biophysical systems (climate change). Considering urban growth only as the outcome of local forces creates an incomplete perspective of complex realities. The size, form, structure, and function of urban areas and their likely future growth trajectories are critical elements to be considered in the discussion of climate change and the sustainability of societies. The chapter focuses on the vulnerability of urban areas to the potential impacts of climate change in poor countries and emerging economies and explores the role of urban planning in building adaptation strategies. The first part of the chapter briefly addresses the concepts of vulnerability and adaptation to climate change in order to create a better understanding of those concepts. The chapter presents then a brief summary of some of the potential negative consequences of climate change in urban areas. The last part of the chapter reflects on how urban planning can help cities reduce their vulnerability and better adapt to climate change.\nOver the past two decades, the development of remote sensing technologies has advanced at an accelerated pace, allowing the introduction of derived products for operational decision making and increasing our capability to assess, mitigate, and forecast natural hazards. Integrated airborne-and satellite-based observations, combined with ground-based methods, are providing new levels of understanding of natural hazards that often lead to disasters. However, much remains to be M. Necsoiu  accomplished. While considerable progress has been made in addressing knowledge and technological development, the future should focus on demonstrating and refining the potential for these technologies to reduce the loss of life and property. The increased participation of policymakers, emergency managers, and responders in the decision-making process using products derived from these technologies could ultimately enhance operational capability in disaster management. consensus conference 96, 97 constraint 62, 74, 80, 84, 109, 113, 114, 119, 176, 192, 229 14, 19, 22, 24, 25, 27, 34-38, 41, 44, 45, 102, 105, 114, 116-120, 126, 128, 130-132, 134, 135, 139, 145, 178, 190, 195, 197, 199, 205, 207, 209, 211, 227 "}, {"section_title": "Delineating Exposure", "text": "The seemingly universal equation risk = hazard \u00d7 exposure \u00d7 vulnerability is, actually, not so universal. In practical terms the formula is frequently reduced to risk = hazard \u00d7 vulnerability, obviating the primary concept of exposure in a conscious or unconscious process of simplification, emphasizing the remaining factors. Yet the equation is not only a simple expression of the interactions, but an enunciation of the succession of factors that intervene in the emergence of risk. In consequence, risk management strategies focus on a particular component of risk and consequently, solutions are sought differently. While structural measures aim at reducing one or various dimensions of the hazard, vulnerability assessment focuses on understanding and modifying the properties of the elements at risk. Yet with almost contradictory approaches, structural measures and land use planning seek a common goal, each dealing with the root causes of risk, hazard, or exposure. The implications are critical because the former modifies the dimensions of hazard without removing the cause. On the other hand, since physical events are seen as extraordinary phenomena, for a long time reaction rather than anticipation, which addresses the preventable causes of disaster, has been seen as the best possible approach. Exposure is the result of a basic locational decision, both individually and collectively (i.e. as members of a group or society) adopted. It is an initiating event, the presocratic arche, the first principle of risk. Hewitt [4] has defined it as the critical factor, although particularly when referring to technological hazards. Therefore the study of exposure should be centered on human behavior, analyzing the agents and the key decision factors that act as its drivers. Cutter [5] focused on the identification of the root causes of vulnerability and on the transference of threat burdens as the two key themes on the agenda for the study of the dimensions of terrorism after the 9/11 disaster. Exposure is closely linked to the concepts of adjustment and adaptation if we think of these in terms of human-environment relationships, and not in terms of strategies to deal with risk. Burton, Kates, and White [6] distinguish between short-term adjustment as a purposeful and incidental action, and adaptation as a long-term human trial-anderror response to environmental changes. Still, in light of increasing human losses caused by disasters, it seems cultural adaptation is sub-optimal and, far from adaptation, we observe instead, maladaptation. To a certain extent this can be attributable to a human deficit of environmental knowledge. Burton, Kates, and White [6] contend that \"The practices might be described as cultural adaptations in the long term or incidental adjustments in the short term. In either case they are largely unconscious on the part of the farmer. In a sense he farms better than he knows.\" Cognitive and economic factors play an important role in driving exposure, because knowledge is limited and the number of alternatives, small. To get a complete picture of the intervening cognitive factors in decision making is an arduous task that may not help to operatively advance risk governance, since the complexity increases at each step and level of detail. Since the goal of risk governance is to find a balance between It is broadly accepted that exposure refers to the occurrence of individuals, households, and communities, alongside assets, structures, infrastructures and functions, natural resources or ecological services within the reach area of a hazard that are threatened by a contingent event. Subsequently, the level of impact of an event will depend both on the dimensions of the hazard and the vulnerability of those exposed elements. In exposure, there is an overlap between the scene of human activity and the areal coverage of a natural process identified as a hazard. Sometimes this spatial relationship is quite unclear, since the extension of the latter is so variable. The progression from a condition of hazard to the condition of risk is subtle, a side effect of the human occupation of certain areas of the earth\u00b4s surface and the modification of the natural environment. To a certain extent, exposure is an externality of human relocation coupled with land development in a certain physical location that is subject to a threat. Exposure is a gradual, sometimes sudden, process of capital accumulation that may be followed by a phase of release, according to the pressure-release model. Smith [7] indicates that incubation of disaster potential in communities at risk is the result of decisions to occupy hazardous areas. Actually, sudden collective relocation, such as in the case of the rapid urbanization in coastal China, is uncommon. Instead, collective exposure has most often been the result of a gradual accumulation of clusters of people, structures, and economic activities [8] over a period of decades, centuries, and even millennia. Jones and Clark [10] elaborated a qualitative typology of non-exclusive, but complementary, land use changes that include intensification, extensification, marginalization, and abandonment, as a kind of land-use change universals. Urban areas experience both processes of intensification, with the extreme phenomenon of megacities, and extensification with urban sprawl, which coincide with the other two processes in other geographical areas. Extensification gives rise to exposure and vulnerability, whereas intensification amplifies both exposure and vulnerability. Individual exposure occurs swiftly however, and it changes abruptly from a state of detachment to contact. Britton [9] notes how the sum of individual decisions in the normal course of life, significantly contributes to the increase of community risk. In sum, the advancement of exposure seems to be non-linear but instead to follow cycles of accumulation at a constant, slow rate of growth (via urbanization) interspersed with rapid increases, -development of large residential areas, infrastructures or industrial facilities-and rapid destruction in disaster events. Derwent Whittlesey proposed the term sequent occupance [11] to designate the sequential process of land occupation and transformation of a certain place over time. Although land use change is continuous, Whittlesey realized it simply cannot be studied and understood without slicing time into layers of occupation. A layer is a discrete state, or a stage in a continuum that facilitates the understanding of the momentary participating elements and their relationships. Each stage has been influenced by prior occupance through its imprint; it is dependent on past interventions and will determine some of the characteristics of subsequent stages, signaling the genetic nature of each cultural landscape. Human structures, or more generally, capital and location are transferred from one generation to the next. Undoubtedly exposure is likewise inherited. Meining [12] observed \"\u2026the powerful fact that life must be lived amidst that which was made before. Every landscape is an accumulation.\" Human landscape evolves and, at any certain moment, is the result of the accumulation of past short-range decisions. It may look like exposure is always local, but this is not invariably the case, since hazard source and impact areas may be a long distance away from each other. Hazards, such as tsunamis or hurricanes, travel considerable distances over a certain time to finally land somewhere further. In the same way the concept of ecological footprint [13] establishes a relationship between very distant elements. The resources demanded by urban dwellers are remotely produced and their waste disposed of far from the city. The environmental pressure -as well as economic and social-is dislocated from the source of demand, which leads to poor urban awareness of the impact of decisions, as we will see later. Risk exposure is multi-hazard, multi-level and multi-scale. Communities are simultaneously exposed to various hazards, each contributing with a different magnitude, diverse dimensions, or geographical origin. Adger [14] has reflected on the multi-scale nature of vulnerability, although for the purposes of this paper we would rather use the notion of multi-scale when dealing with spatial dimensions, and refer to multi-level instead. In this multi-hazard landscape, which Cutter [15] termed hazardscape, each danger is experienced at different levels. For instance, the aggregation of risks in flooding areas within seismic regions, means people are exposed to paired risks, but their possible effects are dissimilar. Apart from the nature of the hazard the effects are also determined by the extent of contact. We have learned how the principal dimensions: areal, temporal, together with magnitude, generate a great complexity and variety of environmental conditions. Yet in the case of compound hazards, this is not so straightforward. Human agency produces unsustainable communities, for individuals have the capacity to make unsuitable choices that will involve future generations, and local and distant communities have the capacity to wrongly manage and engage on a collective basis. Risk can be seen as a basic dimension of sustainability when communities suffering frequent and costly disasters are not able to subsist or are barely maintained at a high cost. Both concepts of ecological footprint and spatial welfare economic (SWE) analysis [8] seek to address the issue of spatial sustainability. Although the former has been criticized and found to have some drawbacks [16], it has been conceptually useful to establish outlying relationships. The examination of the spatial dimensions of sustainability enables measurement of the current state -and here is the difficulty in finding appropriate indicators-and to identify achievable policies in land use planning and transportation at the local and regional levels. Conscious or unconscious risk exposure is caused by an effort to obtain a benefit or increase opportunities, and disasters are events inevitably associated with household devastation and failure. Therefore, the next question to emerge is whether individual damage is also associated with social loss, and how this issue is examined by actors and experts."}, {"section_title": "The Gain and Loss Balance", "text": "Individual and collective land use decision-making processes seek to satisfy immediate and mid-term needs, anticipating an expected payoff in the form of habitation, food supply, increased markets, higher accessibility, or revenue. But such gains may easily turn to losses of capital when hazard strikes. Disasters cause numerous but identifiable direct and indirect losses to individuals, households, and communities, but there is not complete agreement on the effects for society as a whole. One of the first challenging tasks is to calculate those costs. Once direct costs have been assessed after a disaster, indirect costs may then be estimated. However, total costs cannot be easily projected by using direct costs, since total costs increase nonlinearly [17]: This is why most studies concentrate on the short-run impact, and less on the analysis of long-term effects. While consensus about negative short-run economic effects [18] is widespread, with notable exceptions such as Tol and Leek [19] who observe positive effects on macroeconomic variables, there is a boiling debate about the effects over the long run. Raschky [18] indicates that with economic development, losses are gradually reduced, mitigating the effects of natural hazards at a constantly diminishing rate, up to a point where increasing wealth inverts this relationship and causes higher economic losses. According to this school of economic thought, disasters help to boost economic activity of countries hit by a natural hazard. Skidmore and Toya [20] find, in a macroeconomic framework, a clear positive association between the number of disasters and economic growth, measured as national GDP. However not all types of events across the world produce comparable effects. Recurrent climatic disasters, easier to model and forecast, fuel long-term economic growth because human costs can be mitigated, as opposed to geological hazards, which are infrequent and harder to anticipate, and do not seem to produce a favorable economic impact. This controversial perspective, which claims to be rooted in studies by Dacy and Kunreuther [21] and Albala-Bertrand [22], basically contends that disasters are an opportunity to update the capital stock and adopt new technologies; a chance to improve the infrastructure by clearing out the damaged and outdated. The event triggers a cycle of creative destruction [23], a paradoxical phenomenon -firstly proposed by Schumpeter [24]-of stimulus for economic innovation and mobilization of governmental and nongovernmental aid and investment, loans, rebuilding effort, new jobs, and insurance payouts. Critics do not solely come from other schools of thought but from the close libertarian field, as acknowledged by Donald Boudreaux [25], who claim this assertion falls within the \"broken window fallacy\". This principle was expressed by Fr\u00e9d\u00e9ric Bastiat in his work, Ce qu'on voit et ce qu'on ne voit pas (What is seen and what is not seen, 1850), where he contends that destruction is not profitable because society loses the value of objects unnecessarily destroyed. Somehow the value of non-measurable costs and hidden costs over comprehensive macroeconomic costs must be recognized. Long-term approaches seem to focus solely on the benefits for physical and financial capitals but disregard the short-term impacts on human and social capitalssuch as loss of human lives, rupture of social networks, bewilderment at the loss of a source of income-, which are not easily measurable. Recovery after a shock is based not only on reconstruction but also rehabilitation, which implies investment in the renovation of physical capital and not exclusively its substitution. Low-frequency high impact events, both climatic and geologic, are very difficult for experts to anticipate and for people to incorporate into their knowledge. This is particularly true in developing countries where early warning has not been sufficiently developed. Thus, human costs cannot be mitigated. Measurement, when difficult, needs to make use of macroeconomic and proxy variables; so that error may easily propagate and invalidate modeling. Disasters might also generate gains that have not been sufficiently identified, because scholars are seeking negative rather than positive characteristics. This is the position of Quarantelli [3]. Thus, students prefer to stay with the basic assumption of the badness of disaster, and consider it as socially dysfunctional or a social problem. A U. Fra Paleo / On Exposure to Natural Hazards: Revisiting a Neglected Primal Action 66 different approach considers disasters as a component of the evolutionary character of social systems and a step in its adaptation [3]. Does this imply that social systems are more evolved -from the point of view of risk management-than fifty years ago? It is apparent that from the organizational perspective they are more developed, yet from the perspective of losses it seems they are not. Then, apart from the possible positive effects of disaster, where should we look for efficiency in order to measure evolutionary success? If losses and gains are to be measured, we need to understand the social and economic components at stake. In the risk equation they are located within the vulnerability factor. Therefore, an examination of its connections with exposure is necessary."}, {"section_title": "Exposure and Vulnerability", "text": "Exposure is frequently cited as a component of vulnerability. But, is exposure a component of vulnerability or, is it an entity per se? Furthermore, what are their mutual dependencies? Adger [14] or Turner and colleagues [26] are examples of scholars who agree with the first statement, although there is certain disagreement in the literature on the constituent elements of vulnerability. Thus we return to the opening comment regarding the need for discussion and convergence. Most authors refer to sensitivity as a component, while some do not contemplate resilience or adaptive capacity, unless these concepts are assimilated into the same notion. Hewitt [4] makes an important point when he asserts that vulnerability is often taken to mean hazard exposure and is defined in terms of human occupancy of hazard-prone locations. Adger [14] refers to exposure as the \"\u2026nature and degree to which a system experiences environmental or socio-political stress.\" We do not find elements of vulnerability here, but a state of contact between the natural and social systems. Instead, vulnerability is referred to as ability, capability, susceptibility, or sensitivity to stress or to changes in the environment. If we assume that vulnerability should shift away from geographical location [14] then it becomes scale-free and decoupled from exposure, which is always spatial. Someone turns vulnerable to a hazard when it is exposed to this threat, inasmuch we may infer it exposed in recognizing it as vulnerable. Both concepts indicate potentiality and anticipate disruption. Nevertheless, two differently vulnerable persons may be equally exposed to the same hazard in a certain site, but each might not find exposure equally affordable. The environment is both a threat and an opportunity. Human beings live in extreme environments where temperatures are very low, high, or have a great oscillation, water can be scarce, rainfall irregular or too abundant, slopes excessively steep, or vegetation in short supply. In sum, humans are used to severe conditions and variability. So, why not populate only more favorable environments despite the recurrent and sudden variations of a different nature? Everywhere we find background exposure to a set of short-wave low-amplitude environmental changes. Human settlements adapt more easily to this setting. A higher level of exposure occurs when any particular dimension of the environmental processes exceeds the threshold of human (individual, group, or community) adjustment or adaptation capacity. While the concept of exposure includes the likelihood of being injured or killed, of damaging infrastructures or collapsing buildings by the impact of a hazard, vulnerability pertains to the differential capacity of individuals or communities to anticipate, cope, and recover from a hazardous event. Vulnerability is defined by the characteristics of the people, and vulnerability attributes are themselves determined by structural factors and processes outside the reach of one\u00b4s household or livelihood [27]. These authors contend that the strength of people\u00b4s livelihoods, of their access to basic assets and to social protection, determines individual and group vulnerability. We may say that exposure identifies the feasible areas of disaster and the capitals at risk, whereas vulnerability facilitates the understanding of the differential effect on populations at risk under a condition of disaster. The constituents of vulnerability and the causes of exposure may not correspond, since early drivers of each may have changed or vanished. Exposure is constant over time -unless hazard dimensions have changed or have been modified-while vulnerability varies, increasing or decreasing with the deterioration or improvement of the standards of living after settlement or development. Also, the effects of an event may reach distant regions where people vulnerable to this hazard have settled, having been motivated by a variety of other factors. New hazards may arise or their dimensions vary because of changing conditions such as the application of structural measures, triggered events, or global environmental change. In this case exposure is supervenient, and not derived from initial conditions. However, it is not straightforward to differentiate between ordinary -background-variability and extraordinary variability, as the study of climate change indicates, unless changes are sufficiently resolved. The next two sections will identify the principal determinants of human exposure to natural hazards and examine how they interact in the drive toward risky decisions."}, {"section_title": "Identifying the Drivers of Exposure", "text": "The recommendation 3.3 of the report Facing hazards and disasters: understanding human dimensions [28] indicates that \"Research is needed to assess the degree to which socially vulnerable population segments might be \"pushed\" into geographical areas of high hazard exposure [\u2026] to assess the degree to which socially advantaged population segments are \"pulled\" into exposed and vulnerable structures.\" In this statement authors argue for a detailed analysis of exposure by adopting a specific avenue. In 1889 Ernest Ravenstein theorized in the Laws of migration that the movement of people is explained by unfavorable conditions pushing people out of their livelihood, while complementary favorable conditions in some other location pull them out or attract people to settle. This push-pull framework is a useful model that helps to understand why some hazardous zones are left behind after an extreme event or why areas with valuable resources -but prone to hazard-attract people. Raschky [19] identified three principal drivers of risk exposure, classifiable as push or pull factors: the exploitation of scarce resources, the growth of population, particularly in urban areas, and the migration of middle-class people from these over-populated areas to the outskirts and coastal zones in order to increase their living standards. Even though these factors may be too comprehensive or too general, they point to an earlier primary determinant, the satisfaction of various human needs and economic wants. Human settlement is driven by the search for a living, for a way of living, or simply for survival. Needs are objective universal requirements to sustain life and facilitate human development, and they act as a driving force which motivates individual behavior to U. Fra Paleo / On Exposure to Natural Hazards: Revisiting a Neglected Primal Action 68 action. Their satisfaction is a key determinant, much stronger than the simple search for utility, as formulated in the theory of expected utility, which Kahneman considers to be unsatisfactory [29]. Under pressure, individuals, concerned with short-term outcomes, seek an increase of their resource accessibility rather that a final state. Prospect theory argues that change of wealth is the carrier of utility and choices are always made by considering gains and losses. Maslow [30] identified five categories of basic human necessities that he organized hierarchically. The physiological needs, \"the starting point for motivation theory\" were classified by Maslow as basic low-order requirements that, once relatively satisfied in the first place, permit the emergence of higher-order need levels. Those basic needs for survival are food and safe drinking water for nourishment, health, rest, clothing and shelter, while safety and security have been recognized as second level needs. On top of the pyramid are the psychological needs. The hierarchical character of this theory has been discussed by other authors. Manfred Max-Neef [31] contends that fundamental human needs are more limited and constant through cultures and across historical time periods, and rejects the hierarchy by deeming needs as paired or complementary. Unsatisfied structural needs are found both in poverty and nonincome poverty. The former is a condition of shortage in the supply of physiological needs, which may include shelter, healthcare, sanitation facilities, education or access to information, and may adopt different degrees from indigence to destitution. If, in addition, there is an absolute lacking of material goods, people reach a condition of extreme poverty or destitution. Nonincome poverty refers specifically to restricted access to health and safety. Large populations living in urban areas and inhabiting vast geographical areas are in this condition. Also severe regression in living conditions is found in communities that suffered a disaster caused by a natural hazard, persistent droughts that lead to bad harvest and famine, or social disasters such as conflicts or war. Many people are concurrently in the two conditions. In order to satisfying needs and pursue their livelihoods, people expose themselves or are exposed, in their search for a source of income, job, or mode of production. Individuals do not make decisions based only on the identifiable local exposure to natural hazards, but on opportunities for employment. Furthermore, they accept risk on a collective basis, as members of a community. Employees in large farms, forestry, aquaculture, or the extraction of natural resources in rural areas follow a similar pattern, as do workers with a job in industry or services living in urban areas and metropolitan regions. It seems as if households, whose economy is based on selfconsumption or small-scale manufacture, would have a better chance to decide upon their exposure to risk, although this is not the case. The attempt to satisfy basic requirements (safe food and drinking water), and security needs (housing) drive the occupation of riverbanks, seashore, and slopes for cultivation. Housing and work places happen simultaneously. Sessility and place attachment are important factors in risk transference. Passing on titles, properties, debts, and obligations from one generation to the next in hazardprone areas results in the accumulation of capital by past and present generations. Real property such as a house, land, or business, and financial instruments are means of production that provide for their livelihood. Ownership and control over these means of production implies the inheritance of location -hazardous or not-along with them. Unless people migrate to other areas seeking employment or business opportunities, inheritance becomes a factor of exposure. One\u00b4s ancestors have already made locational decisions based on their own needs and knowledge so that, if poorly located, the present living conditions of the descendents are jeopardized. The risk has been transferred by past generations and it will be passed on to the descendants. Exposure has been inherited. Quite opposed to stagnation, mobility of people and money act as escalating drivers of risk transference as well. The circulation of financial capital from one area to another, facilitates the disengagement between the owner of the capital and the site of development. The shareholder is not informed by the developer, who is likely aware of some of the local environmental conditions where the investment is being made. The property purchaser \"pulls in\" or enters poorly informed or misinformed. This course of action produces a vertical economic transfer of risk and is the counterpart of a horizontal transfer of risk among citizens, both caused by human mobility. The role of people mobility, with families changing their residence and selling properties in areas at risk, should not be disregarded. One part benefits, although this is not necessarily dependent upon someone else's loss, the situation may evolve into a win-lose strategy if disaster does occur. Unintentionally or consciously, citizens hand their own risk over to other citizens and initiate a chain of risk takers, risk neutrals, and risk seekers. Dislocation of population has multiple causes, including large local environmental changes triggered by governments or companies to develop land, construct dams or other major infrastructures, start mining operations or logging, and cause displacement of large communities and environmental refugees. An unequal public participation and sharing of power allows power groups the ability to appropriate scarce resources. This competition leads to to intrasocietal conflict and ultimately to outmigration. These disruptive events expulse populations from one region to another and hazard-prone areas are occupied, in total absence of awareness of local environmental conditions. Subjacent to settlement processes and the spatial pattern of occupation lays the question of the information available to people and their subsequent understanding of the environmental conditions. Risk awareness may act as a push or pull factor governing human behavior when options are accessible."}, {"section_title": "The Role of Knowledge Accumulation", "text": "Human interaction with nature over long periods leads to the acquisition of environmental information and the achievement of an understanding of the operating mechanisms and roles of the system components. Individuals and groups acquire information and accumulate knowledge that helps them to improve their livelihood security and sustainability through lifelong learning and community history. Due to the nonlinear nature of complex systems [32] this ongoing and dynamic learning process turns into adaptive learning. As Dwyer and Minnegal [33] have observed in Lakes Entrance fishers -state of Victoria, Southeast Australia-\"\u2026experience, knowledge and skill underwrite a fisher's engagement with the environment from which he derives his livelihood\u2026\" The theory of endogenous growth emphasizes the accumulation of knowledge as a source of sustained economic development, gained through a variety of channels, including education and experience [34,35]. In this way we may find a relationship between endogenous growth and the concepts of environmental learning and knowledge accumulation. The knowledge possessed by an individual is the aggregation of individual experience, local knowledge, and outer knowledge. The integration of these different types of knowledge produces many complementarities but is not free from conflict, due to the inconsistencies found in the structuring of reasoning."}, {"section_title": "U. Fra Paleo / On Exposure to Natural Hazards: Revisiting a Neglected Primal Action 70", "text": "Individual experiential trajectories differ considerably among individuals according to repeated personal experiences [36] and the dominant influence exerted by inter-generational transfer of experience [37] from ancestors, completing or shaping perception. Both lay people and managers respond to risk according to their personal understanding and experience [37], and all people recognize and characterize hazards within the space and time they observe [38]. This is why perception of global warming is low, since personal experience is hardly identifiable [36]. Innovation, a process of doing and reflecting, facilitates the acquisition of knowledge, skills, and selfconfidence [40] regarding the coping strategies to handle variations in the environment. The iterative processes of observation, experimentation, and re-evaluation of management and coping practices provide capacity; and these learning mechanisms are a source of adaptations and response capacity for dealing with new processes and environmental dynamics [41]. Local knowledge has been identified as a part of the culture held by any particular community. If we speak of the information on the functioning of the ecosystems and the human interactions, or the impact of local hazards, we are referring to what is called environmental or ecological knowledge, a component of local knowledge. Locally generated through experience and practice -a knowledge-practice-belief complex [39]-, it is shared by its members, handed down through generations, and communicated within the community by cultural transference. A local knowledge system is a cumulative body composed of various knowledges, beliefs, values, expertise and worldviews about the relationships between the human system and the bio-physical system [42,43]. Place attachment and sense of place are identifiable signs of the close relationship of people with places. However, knowledge is neither quantitatively nor qualitatively homogeneous within a community. Among the multiple factors are the differences in human perception, social links, access to information, and role and power within a community. Bankoff [44] also notes that local knowledge lacks universal application, since it has emerged in a unique environment and only has relevance to it. Those individuals who change their residence will hold a knowledge that may not be applicable to the new location. This informal knowledge is useful for researchers in order to gain a better understanding of the local conditions -a fine-scale understanding that feeds scientific knowledge-and to promote public participation in hazard analysis and in the implementation of risk planning. Encouraging community participation and dialogue empowers people, because local knowledge is a resource controlled by the most vulnerable [44]. Moller and colleagues [45] argue that local knowledge is based on observations over long periods of time, it incorporates large sample sizes, and sometimes features subtle, multivariate, cross checks for resource and ecosystem change. However traditional ecological knowledge is neither complete nor absolutely accurate. Butler [46] found that people dwelling in an avalanche-prone area had deficient information about the risk and were not aware of the preparedness measures. In the same way Kunreuther [47] contends that individuals underestimate risk of lowprobability high loss events, given that they tend to underinsure against natural hazards. Without doubt, demographic processes have an important role in transforming the suburban and rural risk knowledgebase. In the first place, depopulation reduces the local hazard knowledge [48] and, secondly, suburbanization brings foreign populations who are not informed of local environmental conditions, and may or may not be aware of the existing hazards. Nonetheless, newcomers gain more accurate environmental information with time [6]. Decoupling social actors from the natural environment is U. Fra Paleo / On Exposure to Natural Hazards: Revisiting a Neglected Primal Action 71 extreme in urbanization, since urban residents are much less informed due to their higher mobility and lack of contact with the surrounding environment [6]. In these areas, exposure increases exponentially, as does vulnerability. Outer knowledge reaches communities via a broad range of sources, particularly through domain experts [36] and mass media. However their impact is limited. Media do not adequately contribute to knowledge accumulation since, as Alexander [49] has observed, the information disseminated is shallow, and lacks a full explanation of historical factors and a clear vision of causality. It is noteworthy that structured risk communication of scientific knowledge has a lesser role, for its focus on certain population segments through designed programs. Risk knowledge reflects a certain understanding of how the world works. Its basic component is the comprehension of the hazard dimensions, gained through experienced local and distant events or disasters. These dimensions, systematized by Burton, Kates and Smith [6], can be grouped into three major categories: released energy, and spatial and temporal properties. Spatial properties include areal extent and spatial dispersion, while temporal properties consist of frequency, duration, and temporal spacing. Conceivably, locals may not acquire such detailed knowledge, particularly regarding their complex relations. Some properties are automatically accessed and will influence decisions, while others must be reasoned, but this does not ensure that the most accessible features are also the most relevant [29]. For example, hazard scale -macro or micro-is not an issue [48] for local population, but historical lineage is a highly perceived dimension. The key relationship intensity-duration-frequency (IDF) -an index in the design of stormwater facilities-, is an observable but apparently complex example of knowledge integration. The apprehension of the combination of hazard properties seems only achievable through the analysis of observed historical data measurements in a certain place. Some hazards are not easily identified due to their low frequency, for their revisitation pattern often exceeds an individual life span. Others are not associated to a site, due to their long-distance genesis, such as hurricanes. Sometimes the hazard interactions are not fully known, the etiology not identified, or the impact on human society not fully understood. Thus, judgments are based on limited data or with restricted validity, that are interpreted according to heuristic rules, but these do not always guarantee optimal actions [29,50]. Frequently heuristics are useful in order to facilitate the complex tasks of assessing probabilities and making estimations, but at times they lead to errors [50]. Disasters are occasions for learning and the social exchange of hazard information and the arousal of the knowledgebase [51]. However, Boin [52] notes that even disasters do not become completely helpful events, since individuals and organizations alike fail or refuse to learn from them, or knowledge is gained too slowly. Smith [37] compared individual judgment with expert risk assessment, and found that some degree of subjectivity is found in both laypeople and the learned. An intricate set of misjudgments and disinformation allows decisions to be made based on inaccurate information. Flyvbjerg [53] identified two causes of misinformation: optimism bias and strategic misrepresentation. According to the first, people tend to underestimate costs, believing they are at less risk, overestimate the advantageous outputs of planned actions, and misjudge frequency or duration of phenomena. This appraisal optimism also affects managers, who see a better chance to get projects approved in a context of organizational or political pressure [53]. Strategic misrepresentation plays a key role when, based on the same premises, the intention is to mislead or lie. Finally we must consider the intervention of cognitive biases in information accumulation, such as selective exposure and inside views. People prefer to receive concurrent information that agrees with their own worldviews and decisions already made, rather than face conflicting facts. According to the theory of cognitive dissonance of Leon Festinger [54] the reception of information through mass media follows the same pattern [56], it reinforces people's predisposition instead of having a major influence. The reduction of dissonance has proven to be effective in motivating exposure to communication [57]. Associated with selective exposure are the processes of selective perception and retention [56], or informational utility [58]. People living in hazardous areas elaborate inside views, produced by the familiarity with the locale, that act as filters that shape people's understanding of reality and only evolve with learning [59]. Habituation to hazard exposure makes people judge it as part of daily life, and relax adjustment measures. Other fundamental factors of predisposition to information exposure [56] are the group to which the person belongs, the flow of information within the community, and the opinion of community leaders. The socio-cultural paradigm has suggested that culture provides individuals with a map of the hazards and variables that represent a threat to livelihood [55]. Given that information is not complete, not all the alternatives are necessarily known and reliably assessed, and likely economic outcomes are taken into account [6] and, thus, decisions are not taken in a completely rational framework. For example, rare events have a smaller impact on people's evaluation of their options for their smaller probability of having recently occurred [36]. Public diminishing concern about other threats has also been observed when interest concentrates in a certain hazard, resembling the single action bias, which describes the tendency of decision makers to not take any further action when a resolution to reduce a risk of their concern has already been adopted [36]. Just as knowledge varies among individuals, coping strategies are variable within the bounds of the same community, and responses are not universal [40], particularly the combined provision of immediate food supply and longterm sustainable livelihood strategies. According to Heijmans [40] these depend on household conditions comprising composition, available food supply, place of residence, and variables associated with knowledge, such as past experience and the skills of family members."}, {"section_title": "Risky Decisions", "text": "Exposure is the result of personal and community choices, aside from transference by way of inheritance or relocation, and actors will make different sorts of decisions in complex contexts of uncertainty and risk on the basis of judgment about what might be optimal for their status at the time. The collection and evaluation of information in order to reduce uncertainty and make more rational decisions is, by the same token, recognized as a key process in economic growth and resource management by the Austrian school of economics. But, aware of the limitations in knowledge acquisition, the maximization of expected utility is tempered by the effect of bounded rationality. Still, the role of information in the realm of economic, risk, and general decision-making processes should not be discounted nor underestimated. The scale of decision in microeconomics is at the individual level, just as in risk exposure land occupation tends to be the outcome of a tension between societal and individual interests. Besides a consumer of products, the citizen is a consumer of limited natural resources and space. Britton [9]  \"One of the basic postulates of sociology is that each person acts on the basis of his or her definition of the situation [\u2026] Human beings do not passively respond to environmental stimuli, but rather we constantly interpret what we perceive. It is difficult to account for the social action of others except in terms of how those actors define the situation they find themselves in. The way people define a situation is the reality for them and they fashion attitudes, behavior and action accordingly.\" Societal exposure is an amalgamation of inconsistent and incompatible individual, community, and organizational decisions at different levels, and does not respond to an elaborated plan, according to the garbage can model of decision making [3]. \"This argues that organizations (and in our view, societies) instead of having clear and consistent goals and values operate instead from a variety of inconsistent and ill-defined preferences.  In essence, transference, the fulfillment of basic needs, and the level of knowledge -or eventually nescience-of the hazard dimensions function as key primary operative drivers of risk exposure (Figure 1). Other cognitive factors, such as perception, attitudes, or values, intervene along the entire process of decision making as protodrivers, while economic, social, environmental, and political factors act both as known risks and the expected benefits people perceive shapes their subsequent behavior [7]. Quarantelli [3] argues that \"Attribution theory suggests that the research focus should be on what actors see as the circumstantial and contextual pressures rather than looking for some predisposing attitude or motive that moves them to protodrivers, constraints or facilitators, anticipating behavior. The tradeoff between the U. Fra Paleo / On Exposure to Natural Hazards: Revisiting a Neglected Primal Action 74 action.\" and Maslow [30] indicates that \"Motivation theory is not synonymous with behavior theory. The motivations are only one class of determinants of behavior.\" Dwyer and Minnegal [33] found that commercial fishers make decisions in a context in which socio-economic features are taken into account as much as biophysical and legal components. Fishers must judge the opportunity of cooperating or competing with others and their decisions are based not only on these understandings but also on interpretations and manipulations of social interactions. Immediate advantages -basic resources or profit-are certainly sought, but deliberate exposure does not imply acceptance of damage [38], collapse, or trauma. Inspired by Quarantelli's [3] use of Leo Tolstoy's metaphor of men as rivers, and based on the pattern of T and O medieval maps, Figure 1 illustrates the framework of exposure analysis proposed here. These maps, which look like a T inscribed in an O, represented the Northern Hemisphere as an encircling ocean flowing around the known continents -Europe, Africa and Asia-separated in three parts by the middle sea, with Jerusalem in the center. In the model presented here, the social-ecological system is conceptually represented by the wheel of exposure, with the biophysical system encircling the social system, providing resources and ecological services. Transference, satisfaction of needs and wants, and available knowledge occupy a central position in human behavior, which navigates the rivers human well-being and lifestyle in search of resources and services. Natural hazards, one of the dimensions of physical systems, are constantly interfering with this endeavor. According to this model three classes of inhabitants can be recognized in hazardous zones: risk takers, risk neutrals, and risk seekers. Risk seekers have a behavioral profile centered in purposeful, sponte sua, acceptance of risk and uncertainty. While having access to other non-risky or less-risky alternatives, they seek a higher reward. Once located in hazardous areas, they accept and discount the lossesalthough it does not mean they seek disaster-, share them with other people [6], adopt adjustments or, simply disregard them. These individuals have obtained a sufficient amount of information in order to understand the phenomena in the area and feel the risk is under control. They make financial or labor commitments with the expectation of obtaining high returns. Risk seekers see opportunities to satisfy economic or recreational endeavors and accept a strategic exposure, since exposed land is generally more productive or valuable, and these benefits offset the risk. Commonly, wealthier social groups are associated with this kind of behavior [6]. Chance takers can be simply gamblers or, possibly, risk transferors. Slovic and colleagues [60] indicate that some persons make decisions grounded on the gambler's fallacy, basing their behavior on the assumption that an observed period of past harmful events should be followed by a calmed stage. They just play a game against nature [33]. Risk transferors are indifferent to and inconsiderate of the needs of their peers. They trade without giving all the information they have or are misinformers, or in other words, they are antisocial risk seekers. Risk takers adopt risky behavioral strategies by occupying and developing hazardprone land for the production of food, goods, or pursuing shelter in an absence of options, constrained by social or economic factors. They have a certain level of local risk knowledge but lack information on accessible opportunity within a scenario of social inequity. People with a low level of resources -particularly land ownership and dwelling-on which to base their livelihood, with poor information on their rights to these resources and little access to institutions, have very limited livelihood and risk strategies. Heijmans [40] found in the surroundings of active volcano Mount Mayon, in the Philippines, that poor farmers consider hazards a collateral environmental component. In this case risk mitigation is not a priority. Their survival is linked to deprived living conditions and dependent on other more important risks like food shortage and malnutrition, safe drinking water, primary health care and diseases, or eviction from their lands. Farmers perceive exposure to a hazardous event as less risky than daily struggle for a living which \"\u2026increases the level of tolerable risk of being exposed to a possible volcanic eruption.\" [40] This stance was also found by Buckle [48] in developed countries. In his survey in the state of Victoria, Australia, he realized how \"...local respondents moved the discussion away from these events and towards their principal concerns which were typically long term social processes, which the respondents themselves clearly identified as disasters...\" A disaster is any type of event or process that significantly disrupts local daily life and which jeopardizes future prospects, and is not just limited to natural hazards. He observes that locals emphasize process over event, pointing out the factors that might interrupt everyday life. Risk neutrals are those people who, unaware of the risk posed by a certain hazard in an area, are already settled or are in the process of establishing themselves in order to make their living. Most commonly they are displaced residents, environmental refugees from areas in conflict, or individuals who have been misinformed and whose risk has been transferred by a risk taker or a newly informed inhabitant. Population mobility in developed countries drives many people to this condition of exposure that unintentionally placed them in hazard-prone areas without complete information. These newcomers have not benefitted from the environmental knowledge within the community of arrival. In brief, both the risk taker and the risk seeker accept living with uncertainty but, while the latter is resilient, the former may not endure disaster. The first does not have options, while the second lacks will to settle somewhere else. Both can be successful in the short term, until disaster materializes. Risk neutrals also can be unconsciously successful, but any future event will turn them into risk takers, if they survive. Risk aversion entails a universal, widespread human preference to make decisions in an environment that is more certain, although possibly accepting a lower expected payoff, but this is not always feasible and it implies more accurate knowledge. To some degree individual choice is not very dependent on risk aversion since people will avoid or seek different degrees of risk at different times in their lives. However, as societies develop, there is an increasing demand for absolute safety. A zero risk society is an idealized goal. Rubenstein [61] finds a window in the reasoning of the liberal situationist school of thought -within the needs theory-for a tentative operative resolution of conflict behavior, by altering the external situation, conceivably using social learning as a pathway. According to this perspective, by changing the existing social conditions, risk attitude can be shifted, since coercive methods to modify behavior have been demonstrated to be ineffective when individuals are acting on the basis of unsatisfied imperative needs [62], as is the case with populations dwelling in hazardous areas of developing countries. Individuals vary regarding the ultimate motivation for their exposure, at the same time they also vary in their vulnerability when exposed to the same specific hazard. The question is whether the intervention of specific dimensions of the hazard and the interaction with particular human components produce different types of exposure."}, {"section_title": "Types of Exposure", "text": "Exposure to a hazard entails being subjected to all and every one of its dimensions, although not in the same combination at all times and at the same level, so that each event is unique in the short term, and each hazard produces its own exposure and vulnerability. The term hazardscape [15] identifies the unique complex combination of natural hazards in a certain geographical area -its multihazard nature-, their role in shaping and transforming the landscape, and the human adaptation to those environmental conditions. We have seen how background risk exposure extends over the entire Earth surface, modified by zonal and seasonal variation, but it is the magnitude of the changes that distinguishes a hazard from a standard environmental variation. Low-to-medium intensity events may be very frequent in certain areas making their inhabitants develop wide-ranging schemes to tackle this chronic exposure. Both resistance and resilience reach high levels, due to the periodical reoccurrence or to the duration of natural processes, which leads to identify states of persistent exposure in some geographical areas. The exposure of non critical resources or compatible land uses points to a well developed adaptive capacity. Where people are exposed to rare events -at the human scale-of a high magnitude, any future event will be catastrophic. And the damages produced by disaster will challenge the adaptive capacity of households or communities for at least one generation. These types of exposure (Table 1) delineate levels of risk that range from acceptable to intolerable, and through tolerable and manageable risks. Thresholds separating these levels are neither sharp nor fixed since they vary with time, space, and agent. The level of exposure may be so high, exceeding both the estimated resistance and resilience of a community, that governments may decide to relocate a population before a disaster occurs. Unfortunately, this policy is rare, because it is very expensive to waste already invested built capital. As a result, any future disaster will exceed the community coping capacity or absorptive capacity [6], a term equivalent to the concept of carrying capacity in ecology. Local hazards are confined to areas where its coverage is identifiable by laypeople and where more effective control may be exerted. Other hazards, such as tropical storms or earthquakes, originate far away from the impact area and the association between source and target is contingent, so that their areal extent is probabilistic. This off-site risk exposure is much more difficult to manage since awareness in low probability areas is very difficult to increase and only mitigation measures are applicable. Time geography contends that time and space are an aggregate that has to be studied in concert when dealing with location and mobility. Human life is developed in a certain geographical area and has duration, and daily individual activities make social agents go from one place to another, tracing lifelines -see [63] for further details on the concept-across villages, cities, or regions. This notable feature leads to an argument against the spatial and temporal continuity of individual exposure. As people move from home to workplace, to recreation areas and back home again, they are continuously changing their type and level of risk exposure, following a discontinuous pulsed pattern that varies daily, weekly, and seasonally. As described earlier, disasters have local direct effects identifiable as capital losses and many short-and long-range hidden costs. The interruption, reduction, or disturbance in the provision of industrial and public services impedes the flow of materials, assets, and financial capital to places far away from the scenario of disaster. Industries and people in other regions become second-level victims of the event, bearing lower-intensity post-disaster economic and social effects. Indirect exposure is felt far away from the area of impact, so that the exposed area turns out to be not only local but somehow global. In complex disasters, when one hazard triggers another hazard and a chain of disasters is set off, a similar pattern is observed. A community at risk exposes tangibles and intangibles, and damage or destruction will degrade them and affect the functioning and productivity of the social system. Although references to the exposure of physical assets are frequently found, less attention has been paid to intangibles, because they are not easily measured or identified and are commonly included in the indirect effects. However their role is very relevant. Classical economic theory identifies labor, land, and capital as the three factors of production, but this grouping is not sufficiently operational for the purpose of exposure analysis. The five capitals framework [64] is of more help in identifying those assets at risk: natural, human, social, manufactured, and financial capital. Hence, social welfare is dependent on the availability and quality of these stocks of goods and services which provide for a way of life. Natural capital supplies a flow of resourcesrenewable and non-renewable-, energy, and ecosystem services. Constanza and colleagues [65] have identified seventeen major categories of ecosystem services, functions, and goods. Even small changes at the micro scale may dramatically alter the functioning of ecosystems and have an impact on human activities [65] or the stocks of other types of capital. As was seen in the section above, the stock of knowledge, skills, experience, information and innovation abilities configure the human capital held by the population, acquired by way of personal experience, shared transmission, formal and informal education, and training. This knowledgebase is an expandable and transferable resource that is applied to labor and resource development. Social capital is a measure of the connectedness and structure of the social network to organize services. The interactions among individuals and groups within communities, based on family links and trust, allows for mutual assistance, exchange of information, leadership, and coordination of actions through organizations. The physical or built capital is made up of the buildings, factories, and infrastructures, machines and equipment which allow for housing, manufacture, transportation, and provision of services. Infrastructures are a class of physical asset that require continuous maintenance, and are enlarged or adapted in order to allow for a continuous standard of service. Certain infrastructures are designated by administrations as critical due to their key role in the provision of basic services to a U. Fra Paleo / On Exposure to Natural Hazards: Revisiting a Neglected Primal Action 78 geographical area, whose disruption may compromise the operations of recovery and the process of getting back to normal after a disaster. Loss of jobs and sources of income, the erosion of investments, and profit downturn are consequences of the damage to the productive system that is based on this capital. Finally, the financial capital, which includes money and its multiple forms, is the resource that mobilizes other types of capital within the economic system and in the process of disaster recovery. Individuals, groups, and organizations own variable amounts of these capitals. This condition plays a key role both as a driver to different levels of exposure and as a measure of people's vulnerability and the potential impact of a disaster."}, {"section_title": "A Framework for Exposure Analysis", "text": "Once the principal dimensions of exposure have been examined, its insertion in risk analysis and the differentiation with vulnerability established, and the key determinants have been identified ( Figure 1) it is necessary to elaborate the context to explain the course of exposure in order to successfully intervene in the process. Figure 2 synthesizes the main drivers and their interactions in a simplified framework of analysis, while Figure 3 places this approach in the broader context of social-ecological systems. As discussed, exposure is examined both as a collective failure to adapt to local environmental conditions and as the outcome of individual decisions made under various pressures to which humans are subjected, tempered or supported by the social setting. Survival in some individuals and maximization of benefit in others, expectation of a certain output by everyone, combine with cognitive and cultural factors such as values, attitudes, worldviews, and knowledge, to produce an action. The intricacy of the interactions among these components in precursory, early or late phases of the decision-making process of settlement in hazardous areas, makes it difficult to understand and, even more, to intervene in the process. Cognitive factors of risk exposure have been studied extensively, with particular attention paid to the influence of biases over perception and attitude. However, less interest has been demonstrated in integrating the complexity of internal and external factors and in adopting an operational framework to work with exposure. A model that facilitates an explanation of the exposure history is needed, and this perspective should place its focus on the resulting action, the risky behavior. The software risk management model proposed by Boehm [66] focuses on the reduction of risk exposure early in the software development life-cycle by adopting the cleanroom process approach [67]. This advanced approach is based on the understanding that risk avoidance should precede risk elimination in order to save costs, since estimates indicate that fixing problems in any late phase of software production is 100 times more expensive than fixing them earlier. The TNK (Transference-Needs-Knowledge) framework ( Figure 2) is proposed here to provide a simplified and operational model to overcome complexity and facilitate the comprehension of risk exposure in a certain location. The conceptual model was previously described in section 5 so that the flow and interactions among components might now be explained. Decisions based on basic needs or wants may directly lead to exposure in absence of any kind of understanding of place hazardousness since food production is a priority for a deprived household, without consideration of the risk of settling in a hazard-prone land. But individual behavior is unavoidably filtered by facilitators that will push or pull people, and constraints, that will prevent them from populating an area. If awareness arises before action takes place, there is a process of reformulation of the decision on the basis of the needs and options available. When needs are imperative and options are non-extant at the time, the same point is reached and, again, the context plays its role. If not pushed by needs, people check their options; if pushed, then needs are re-evaluated and compared with options available. When these are attainable, preferences may arise and play a role in the decision-making process. In prospect theory this corresponds to the evaluation phase of the choice process, when the agents rate each of the alternative actions [68] after evaluating likely losses and gains. Nevertheless, the chance of having different alternatives is neither accessible for all nor are the options abundant at all times, for this is closely related to economic rent. It also should be observed that those living in hazardous areas have gained exposure by transference from past generations or fellow citizens, so that only may consider avoidance if they succeed in becoming aware. In this case the process begins again. The distinction between direct and indirect behavioral pathways leading to exposure resembles the difference between intuitive and deliberate thought processes theorized by Kahneman [29]. Intuitive, or system 1, processes are automatic and involuntary, while system 2 processes are based on intentional deliberative reasoning. Variations in accessibility will determine the intervention of any of these systems, as variations in economic rent, capital accumulation, and knowledge will have an influence in exposure emergence or in its class. Without options or suitable knowledge, populations are driven to hazard-prone areas and only an increase in knowledge and economic capacity -human, manufactured, and financial capitals-may increase their options and the probability of acting more successfully, like the \"\u2026acquisition of skill selectively increases the accessibility of useful responses...\" [29]. The model suggests that decisions are made first at the level of the individual domain but, ultimately, go through the social domain which facilitates or impedes the realization of individual actions, as indicated in Figure 2. It also shows that individual decisions are the result of the intervention of overlapping contingent determinants, as layers of judgment that operate sequentially. The intervention of subjacent factors at each single layer should not been ignored, but their identification adds a high degree of complexity. In this framework, cognitive factors intervene both in knowledge and when preferences are shown, and these are not known until choices are made [3]. Social, cultural, or political factors intervene in the context of action, making actions possible by facilitators or else restraining them by interfering constraints, as well as protodrivers of transference, knowledge, and needs. Since behavior is inevitably based on incomplete knowledge or inaccurate information, decisions flow in uncertain scenarios and under unrealistic perceptions [53]. Tracking exposure implies studying the root causes of this action, by going backwards from the lower levels and identifying the pressing needs, the gaps in knowledge, and the historical processes that are causing or caused the occupation of hazardous places. Tracking also requires deep exploration of the environmental processes in or out of a region that may pose a threat to the population and assets, identifying the paths connecting hazards and vulnerability. Thus, the goals of risk governance are to prevent and manage disaster, to reduce vulnerability and, ultimately, to mitigate or avoid hazard exposure."}, {"section_title": "Exposure in Social-ecological Systems", "text": "In the last two decades there has been a shift in risk analysis from an earlier focus on the study of hazards to a closer examination of the role of the social and economic settings and changes -largely neglected [3]-in incubating disasters. Particularly, the field of disaster sociology has made a great conceptual contribution in this respect. Although a wide range of perspectives in this field of study should be welcomed, it should not serve to set aside the biophysical system and its interactions with the social system within the framework of social-ecological systems. There is no advantage in decoupling the concept of disaster from the concept of hazard, which would only result in a loss of theoretical background. Exposure is the interface between hazard dimensions and social drivers, where historical, cultural, economic, and cognitive features converge. Risk from natural hazards has to be examined in the light of complexity theory, with two complexities intertwining, or in other words, natural and social systems constantly interacting in multiple directions. The progression of risk in complex social systems is dependent on the initial conditions or on the emergence of exposure, and small variations of its determinants will produce different states of risk and, eventually, disasters. The scheme shown in Figure 3 summarizes the components and processes within social-ecological systems from the point of view of risk from natural hazards, placing land use, capital accumulation, vulnerability, and exposure in a central position, and integrating the TNK framework. The two subsystems are easily identifiable but not separated, for many interactions are identified: society gets natural resources and services provided by the natural subsystem, which is depleted or deteriorated as pollutants are introduced and the structure and functioning of ecosystems are thereby modified, which puts the natural environment under socio-economic stress. In the same way, environmental processes act as biophysical stressors on human society, producing risk and, eventually, disasters. As seen before, these generate recurrent losses which point to a condition of maladaptation, and -question still discussed-gains. Land use changes are the result of social and economic processes which use land as a resource or as a product of consumption, initiating a progressive accumulation of capitals.  Some feedbacks may be observed, particularly those derived from risk and disaster. Both produce identifiable forms of inequity. People exposed to risks live in fragile environments where changes threaten their survival and livelihood, weakening their economic status and source of income and compromising the exposure of future generations. This unsustainability is not only the result of social inequity but also due to this transference of risk. Thus, disasters are a manifestation of unsustainable land use practices and become triggers of sudden impoverishment of large populations, further increasing social and economic inequity. Finally, it should be noted that some positive feedbacks may be observable to a greater or lesser degree. People gain a better knowledge of local or off-site hazard dimensions that will help them make adjustments and better adapt to environmental conditions by reducing vulnerability and mitigating exposure. Social learning and adaptation are key processes in social-ecological systems from the perspective of risk from natural hazards. A disaster should be seen as a social occasion [3] for the examination of the failures in reducing capital exposure to environmental processes and for increasing adaptation, as well as for modifying the socio-economic conditions that allow for social, economic, and environmental inequity. It is an occasion for gaining more collective knowledge and competence to deal with natural hazards through social learning. The KSA (knowledge, skills, and attitudes) model, based on Bloom's KSC model [69], indicates that understanding is gained through cognitive competence; skills through functional competence; while attitudes and behavior are obtained through social competence. Thus, knowledge, skills, and social attitude and behavior are judged as related, complementary dimensions of competence [70]. The concept of competence refers to the person's capability to interpret the components of the local environment and successfully perform in this particular context, just as knowledge implies the ability to apply it to a specific purpose when appropriate. Even though competence does not ensure complete success in the implementation of measures and in achieving outstanding performance [71], it can be improved through learning. Risk governance should not only seek effectiveness in risk management, but also foster a risk-competent society, supporting the combined acquisition of knowledge, skills, and attitudes by adopting a holistic approach to competence, by bridging the gap between actual performance and non-risky performance standards. With this view, competence development should not exclusively focus on transferring knowledge and skills to individuals, but on changing people's understanding of risk, adopting Sandberg\u00b4s [70] position on labor enhancement. According to the bounded rationality reference system, information is a necessary condition, but is not sufficient to make right decisions, since human capacity to manage and process information is limited. Dodgson [72] distinguishes between single-loop learning, concerned with gaining knowledge to solve problems that are framed by existing models, and double-loop learning, concerned with the elaboration -based on learning-of new models to solve those same problems."}, {"section_title": "The Case for the Precautionary Principle", "text": "We make the case for the precautionary principle from two different angles, first based essentially on recent environmental experience, the second more theoretical 2 . The experiential case begins from a recognition, first, that modern technologies are capable of inflicting long-term, large-scale damage on this planet's life-supporting ecosystems; and second, that conclusive scientific evidence of such damage may not become available in time to avert it [6]. In recent decades, we have come to perceive that greenhouse gas emissions are altering climate conditions on the entire planet, with potentially catastrophic results for some parts of the globe. Chlorofluorocarbons have been implicated in causing a hole in ozone layer, thus exposing parts of the earth to damaging levels of ultraviolet radiation. The spread of agricultural biotechnologies, the genetically modified crops that are so hotly debated in Europe, raise concerns that we are beginning to dramatically alter the genetic structure of the plants on which all of humanity depends. And the problem is, these sorts of issues involve environmental change that is gradual and delayed. The ecosystemic interactions are exceedingly complex, such that scientific evidence of the causal relation between human activity and the environmental harm is slow in coming. Decades of scientific controversy and uncertainty may pass before the need for protective measures becomes clear. Yet some of these processes are virtually irreversible, such that delaying preventive action condemns us to whatever consequences the practice ends up causing [7]. That is why precautionary measures can be justified even before the scientific community has reached a consensus about the nature or extent of the danger. Depletion of ocean resources, chemical contamination of the Great Lakes, deterioration of the ozone layer, and carcinogenic chemicals all represent problems to which the precautionary policies might apply. Precaution is the appropriate response to one of the great discoveries of the twentieth century: Humanity's attempts at technical mastery can, in the medium or long term, cause damages that are difficult to predict in the beginning, difficult to identify when they occur, and subject to uncertainties that are difficult to dissipate. A supplementary principle of risk management is necessary in relation to these types of environmental harms because they elude the three essential strategies that modern societies have developed for reducing or coping with risk. The first and oldest method of risk reduction is to seek increased technological mastery of environmental conditions. Many technological advances can, after all, be interpreted as forms of risk management. Agriculture is risk management. It reduces the risk of famine by creating a more dependable food supply. Refrigeration is risk management insofar as it reduces the likelihood of bacterial contamination in food. Draining swamps and building sewers are forms of risk management: Such projects decrease the incidence of disease. Dikes and dams and canals reduce the risks of flooding. While technological fixes have often had wonderful successes at reducing such risks on one scale, too often they have been introduced without attention to their effects on larger-scale ecosystemic processes that assure the reproduction of life over the longer term. At the same time, our understanding of such these processes is limited and often uncertain. Precisely because of their complexity and scale, and because changes in them may take decades to appear, uncertainty plagues studies of these phenomena. The second method of risk management consists in the development of the insurance industry. In effect, insurance allows individuals to collectivize risk [8]. Insurance does not eliminate risk, of course, but it makes it calculable and compensable. There will always be risks that one's property will be destroyed in an accident or that a health problem will interrupt one's work-life. Yet the probability of such misfortunes befalling any particular individual, during any particular stretch of time, are relatively small. Once data concerning a large number of individuals has been collected and analyzed, probabilities can be calculated with considerable confidence. Insurance premiums can then be charged that are proportional to the risk. The cost of insurance should discourage overly risky activities. Meanwhile, the money collected D. Bourg  allows compensatory pay-outs to those who suffer misfortune. In the case of both individual insurance and collectivized programs of risk prevention and compensation, the modern notion of risk is inseparable from the idea that danger can be objectified, quantified and made subject to expert calculation. But some developing environmental risks fit very poorly with these preconditions. Anthropogenic climate change is a novel phenomenon, with many uncertainties surrounding its severity, local incidence, and duration. Moreover, the costs that it may impose are of such a magnitude that they threaten the financial viability of the insurance industry [9]. Meanwhile, the risks of genetically modified crops are so poorly understood that insurers have refused to cover potential damages from them. Such refusals do not mean, of course, that the hazard goes away. In the absence of something like the precautionary principle, it simply means that the general population and future generations, rather than the risk producer, bear the risk. The third method of environmental risk management calls on the state to regulate sources of environmental degradation. This task is essentially an extension of the process of risk collectivization that took place throughout the twentieth century in the form of welfare state programs. Like workplace safety regulations or unemployment insurance programs, environmentally-motivated zoning, chemical screening or pollution abatement legislation establishes norms limiting the risks that individuals can reasonably impose on one another. In principle, states can set whatever evidentiary thresholds they please -including precautionary ones -to justify such regulation. The demands of international trade, however, create pressure for harmonized standards. And in the last decades of the twentieth century, science-based risk management, championed by the United States, has enjoyed growing international influence. When one country challenges another's food and safety standards as a restraint on trade, the World Trade Organization has insisted on resolving such disputes by reference to the standard of \"sufficient scientific proof.\" Cass Sunstein argues that \"regulatory states all over the globe are becoming cost-benefit states\" -ones whose risk assessment methods emphasize quantitative actuarial methods and scientific evidence in making comparative judgments about acceptable dangers [10]. The problem, again, is that certain types of environmental damage are too novel or too subtle in their early stages for these evidentiary requirements to be met. And so these risks slip through the net of state regulation as well. The experiential case for the precautionary principle highlights what are sometimes called \"new risks\" and concludes that a more cautious rule for anticipating and preventing them is necessary [7]. More theoretically, the precautionary principle can be seen as an instance of \"maximin\" reasoning in risk-taking [11]. The expression \"maximin\" is short for \"maximize the minimum.\" The idea is that in certain situations, it makes sense not to gamble on maximizing expected benefits but to foresee possible worst outcomes and to choose the option whose worst possible outcome is least bad. Stephen Gardiner [11] supplies the following example: Suppose that in a given situation, you have two actions, A and B, available to you. If you choose A, then there are two possible outcomes: either (A1) you will receive $100, or (A2) you will be shot. If you choose B, there are also two possible outcomes: either (B1) you will receive $50, or (B2) you will receive a slap on the wrist. According to a maximin strategy, one should choose B. Such a strategy makes sense, but only under certain conditions. qualitative as well. Certain values play a key role in the quality of life, largely conceived. Yes, we gamble all the time with lesser values, especially ones that we are confident can be replaced or foregone if we happen to lose. But there are other values that people are reluctant to put on the gaming table (their lives, their freedom), except perhaps in dire circumstances. In cases where these values are at risk, maximin reasoning has its proper field of application. Uncertainty: Choosers do not know probabilities attached to the various outcomes or have reason to be skeptical about reported probabilities. If they knew the probability of getting shot was very low, it might seem rational to choose (A1). But since they do not know how to calculate the relevant probabilities, they avoid cost-benefit reasoning. Relatively small expected gains: \"The decision-makers care relatively little for potential gains that might be made above the minimum that can be guaranteed by the maximin approach [11].\" That is, while benefits are promised, their attractiveness is not all that great compared to the attractiveness of the least bad outcome. Realism: \"[T]he outcomes considered [in the maximin strategy] are in some appropriate sense 'realistic', so that, for example, only credible threats are considered [11].\" Realism demands that those who foresee a risk be required to provide some evidence of the alleged problem. There must be some reputably credentialed experts who are alarmed, some body of scientific theory that explains how the risk might materialize. The precautionary principle meets the \"severe loss\" condition by including language referring to potential damages that are \"serious and irreversible.\" In fact, it would be more correct to say \"irreversible and serious,\" since irreversibility is the more general characteristic. Irreversibility signifies that it is impossible to return to the prior condition, in relation to a given situation. Where the environment is concerned, irreversibility can refer to a large number of situations having different degrees of seriousness. The disappearance of a single species is not necessarily serious, whereas speeding up the natural rate of species loss certainly does constitute a grave threat to the totality of ecosystems, as well as to humanity by and by. The seriousness of an irreversible phenomenon is established as a function of diverse criteria: obligations to other species, the consequences for humanity in the present and in the future, potential damages on a local, regional or global scale, and so forth. In all of these cases, there are scales of seriousness and margins for legitimate interpretive disagreements. These margins, it must be admitted, present challenges in the application of the precautionary principle. Gardiner's \"uncertainty\" condition appears in the precautionary principle, with this caveat: Not only must the occurrence of damages be uncertain (which is the case for any risk), but the uncertainty must stem from a lack of scientific knowledge, properly speaking. If this knowledge is relatively complete, there is no reason to have recourse to precaution. But if it is partial and therefore shot through with uncertainty, then precaution may be necessary. In relation to the occurrence of uncertain events, economists distinguish between \"risk\" and \"uncertainty.\" When uncertainty is bounded by an objective probability distribution -that is, founded on statistical data -then economists speak of risk. This is the case, for example, in relation to the risk of highway accidents or flooding. Properly speaking, spatial planning and land management policies that are designed to avoid catastrophes on known flood plains are therefore preventive in nature. On the other hand, when a risk is not limited by probabilities, economists speak of uncertainty. The consequences of climate change, for instance, are uncertain because this phenomenon is without precedent. There is no D. Bourg  long series of similar cases that might be studied statistically. We are far from understanding all of the consequences of the increasing concentration of atmospheric carbon dioxide on climate, in the first place, because we do not understand all the mechanisms contributing to climate regulation (especially linkages between oceans and the atmosphere). Nor do we know what the reactions of ecosystems will be to climate change. Uncertainties related to global warming can even transform risks that were previously well understood into ones where precaution is appropriately invoked. Precautionary spatial planning becomes necessary as climate change alters the frequency and predictability of catastrophic typhoons, droughts and rising sea levels. Uncertainty is exacerbated by our inability to forecast how human consumption of fossil fuels will change over the coming century. We are thus confronted with an accumulation of lacunae in our scientific understanding of relevant phenomena. Moreover, there are degrees of uncertainty in scientific pronouncements. Knowledge concerning climate change rests on a solid theoretical foundation: physics and a quarter century of intense research (with observations, experiments, model building and simulations), all evaluated according to respected protocols by the international scientific community (organized within the Intergovernmental Panel on Climate Change. The IPCC's warnings are anything but the conjecture of some isolated whistle-blower. More generally, we can follow French economist Olivier Godard in ranking scientific uncertainties in a hierarchy that runs from less plausible to more plausible [12]. The ranking begins with \"simple scientific conjecture,\" most often announced by an isolated researcher. Next one may speak of an \"hypothesis that is unproven by resulting from accepted scientific methods [12]\" After that come \"supported hypotheses\" -ones backed up by models, simulations, observations and experiments -but that are as yet taken up only by a minority of researchers. This contrasts with a supported hypothesis that is \"deemed plausible by a majority of scientists,\" then with a \"hypothesis that is validated, but thus far only in a single case\" and thus in need of being \"reproduced, confirmed or criticized [12]\" Godard's uncertainty scale ends with the case of a \"result accepted by a large majority of researchers, (but) still subject to criticisms or reservations from a minority [12].\" This last step best describes the situation regarding knowledge about climate change, except that in this case we are dealing not with a circumscribed result or scientific pronouncement, but with the arrival of a complex phenomenon with a possible cascade of consequences. Exploring those consequences requires combining work from diverse scientific disciplines with heterogeneous methodologies. Precaution is situated between prevention and development risk. Prevention applies to cases where a risk is well understood; development risk denotes cases where a risk is totally unknown right up to the moment when damages occur. According to the European Union directive on development risk and defective products, manufacturers who can show that no evidence of danger was available at the moment when a product was put on the market are exempt from liability. Precaution lies between prevention of known risks and policy in respect to development risk, which is identified only after the fact. The precautionary principle concerns insufficiently understood risk, with all the degrees of uncertainty mentioned above. "}, {"section_title": "Implementing the Precautionary Principle", "text": "There are two key steps when implementing the precautionary principle. The preceding discussion of uncertainty makes it clear that the first step consists in establishing the state of available knowledge. This initial evaluation must conform to criteria of transparency, multidisciplinary expertise, and openness to evolving knowledge. Transparency implies that scientists and experts involved in studying a potential danger must make public their employment history and the manufacturers with whom they have contracts [13]. It is clear that a researcher who has developed some new device or method will wish to promote it and thus will not be the person best placed to make out its disadvantages or risks. Similarly, a researcher who has contracts with a given manufacturer will have difficulty taking positions contrary to those of the manufacturer. Still, a demand for perfect independence often cannot be met. Some areas of research are so closely linked to industry that it is difficult to find experts who have no connection to the industry. How reliable would an expert in the production of electricity be who had no professional ties in the industry itself? The criterion of transparency allows us to situate the views of various people, without disqualifying anyone a priori. The call for multidisciplinary expertise stems from a recognition that risks arise from social and natural phenomena whose complexity transcends the understanding of any one or small number of scientific fields [14]. Multiplying the disciplinary angles in the study of an environmental phenomenon is a crucial precaution. To turn over the study of genetically modified organisms exclusively to molecular geneticists would be absurd, since molecular genetics alone cannot foresee effects that occur at an agronomic or ecosystemic level. Contributions form evolutionary biologists, ecological scientists, and entomologists and others are necessary for an evaluation of the risks of GMOs and of their plausible advantages. In addition to the natural sciences, the social sciences have contributions to make in foreseeing risks, since social practices too can turn out to be risk-generating. Openness to evolving knowledge is an additional requirement for assessing states of affairs in precautionary situations. As knowledge grows, it becomes more possible to take adequate and efficient preventive measures. Thus the first step in the implementation of the precautionary principle is not limited to a static review of the state of knowledge; it requires scientific efforts aiming at the production of knowledge [15]. This is one reason why the precautionary principle is a principle of public policy. Only a public authority wielding significant resources can mobilize this sort of research program. The second step in implementing the precautionary principle consists in adopting measures designed to reduce the risk. These measures must be \"provisional and proportionate,\" in the accepted phrasing. The adjective \"provisional\" (or temporary) is somewhat unsatisfactory, but it would be difficult to go back on it at this point. The problem is that some precautionary measures are probably for the long term and so hardly seem \"provisional.\" Imagine, for example, that the world manages substantial and timely greenhouse gas emission reductions, thus avoiding the most dangerous climate change scenarios. Still, nations would be obliged to maintain, for an indefinite period of time, an atmospheric CO 2 concentration equal to or less than three gigatons (the absorption capacity of the oceans). How much sense does it make to talk of \"provisional\" measures in such case? In fact, this word carries another risk: the temptation to put an arbitrary expiration date on precautionary measures (e.g. the three D. Bourg  year limit on certain biotechnology safeguards written into the Cartagena Biosecurity Protocol). There is no assurance that some arbitrarily fixed number of years will suffice to reveal relevant dangers linked to a product or process. Bioactive molecules can have delayed effects that become manifest only many years, even decades, after initial exposures (as in the case of diethylstilboestrol, a synthetic hormone that caused cancer in the daughters of women treated with it). But one cannot ignore the economic effects of prolonging precautionary measures indefinitely. So rather than \"provisional\" measures, it would be preferable to talk of \"revisable\" ones, as proposed by Godard. Revisable suggests better that there is a dynamic of knowledge acquisition that applies to cases of uncertainty. It expresses the necessity for public authorities to re-examine protective measures in light of evolving scientific knowledge, which is the principal guarantee of their efficacy and avoidance of arbitrariness. \"Proportionate\" -the second adjective applying to precautionary measures -is of capital importance. Proportionality is to precautionary action what cost-benefit ratios are to prevention. Faced with damages that are not yet proven, whose nature and extent remain uncertain, cost-benefit analysis is obviously impossible. But there are other means to introduce rationality into decisions: There should be a judicious balancing of policies; guardrails against policy drift should be set up. It is appropriate, first to proportion precautionary measures to the general quality of the risk. Too often it is assumed that precaution means prohibition. Not so. Sometimes a moratorium would be a proportionate response -and sometimes not [16]. A moratorium makes sense in relation to a particular type of genetically modified plant (one that might have \"weediness\" characteristics or that might spread its genes to local food crops). But another GMO might, after extended experiments in confined laboratory settings, demonstrate no problematic characteristics and might be unable to interact with native or crop species in an area. In that case, precaution may indicate less stringent measures: buffer areas surrounding cultivated areas, regular monitoring, on-going research. In some cases, a moratorium makes no sense. Climate change creates precautionary situations, yet we are never going to suspend our greenhouse gas emissions, pure and simple! Precaution requires diminishing emissions significantly and progressively. It is appropriate, second, to proportion measures to the quality of the scientific case concerning the danger. Consider some examples. The virus causing avian influenza, H5N1, might become transmittable to man and thereby cause a global pandemic more deadly that the Spanish flu of 1918-19, with its 100 million dead. This hypothesis conforms to biological knowledge that we currently possess. The World Health Organization takes the danger seriously. The degree of plausibility, combined with the seriousness of the feared effects, is enough to justify measures like study of a vaccine and increased surveillance of the phenomenon. On the other hand, a failure of proportionality is apparent in relation to policies concerning greenhouse gases. Given the solidity of the scientific case demonstrating the dangers of anthropogenic climate change, the Kyoto accords, which avoid any immediate measures that might affect current lifestyles, and the recent agreement between the United States and Australia, which wagers on future technologies (largely, coal gasification accompanied by CO 2 sequestration) to solve the problem, are shockingly inadequate. But in the other direction, it would be completely contrary to proportionality to ban some substance based on the conjecture of a sole researcher. In such a case, hypothesis-testing, not prohibition, is the measured response. The third connotation of the adjective \"proportionate\" goes back to the need to make sure that precautionary measures are economically rational: They must achieve D. Bourg  the maximum effect with the minimum means [17]. If one takes into account the likely increase in the number of risks the world faces, there is a strong case for optimizing the use of available scarce resources. The precautionary principle does not itself require or rule out any particular policy approach. In the case of measures to reduce greenhouse gas emissions, precaution does not by itself decide between \"cap and trade\" systems or state-imposed emission standards. If they can both achieve the precautionary goal, but one is less costly than the other, then the least cost solution has a point in its favor. Of course, a consideration like social justice could still tip decision-making balance in the other direction. Finally, \"proportionate\" refers to the requirement that any application of the precautionary principle be preceded by a comparison of expected consequences of the projected policies, on the one hand, and absence of action on the other. Precautionary action is sensible only if it actually brings about a positive and appreciable change. If the Kyoto process were to end around 2012, at the end of its first stage, the result of the actions by the signatories -reducing average world temperature-would be practically zero. Kyoto is significant only if its stages are continued and strengthened beyond the first stage."}, {"section_title": "Public Involvement in Precautionary Decision-making", "text": "When implementing the precautionary principle, an additional desideratum grows not out of the principle's explicit language, but out of the need to situate it in relation to democratic procedures. We believe that there is a strong case for a deliberative interpretation of the precautionary principle. What we mean by that is: The processes that trigger and implement precautionary measures in relation to an environmental risk should include regularized forms of non-expert citizen participation and deliberation. Deliberation implies opportunities to discuss, question, persuade, and come to judgments about the environmental risk that is in question. This is not just a matter of educating citizens --i.e., of getting them to understand and accept decisions that have already been made in other parts of the regulatory apparatus. The objective is to make citizen deliberation a formal part of the process, just as regulatory bodies systematically include scientific and economic advisors. Over the past thirty years or so, there have been numerous experiments with what is called \"participatory or deliberative technology assessment [18,19].\" The Danish Board of Technology developed the procedures of \"consensus conferences\" in the 1980s to get citizens involved in assessing technologies like nuclear power and biotechnology. Other procedures go under names like scenario workshops and citizen panels and citizen debates. Each has different ways of selecting citizens, and of organizing debate. Nonetheless, these forums have certain common features that are important for carrying out deliberative precaution. First, each form strives to get a fair representation of citizens involved in a deliberative process. The citizens are not specialists in the policy area in question. Second, the process includes opportunities for the citizens to interact with experts. Risk assessment inevitably involves expert evaluations of the issue. It is uncertainty among experts that triggers the precautionary principle to begin with. So a crucial part of participatory technology assessment is giving citizens an opportunity to hear and explore those uncertainties. Citizen participation therefore does not mean merely letting policy be influenced by opinion polls. There is an educative process involved in which citizens acquire some basic D. Bourg  competence in the policy area through interaction with experts. Finally, all of these modes of deliberation depend on the use of procedures designed to facilitate debate and to bring deliberations to a conclusion. A consensus conference, for example, requires participants to develop a series of policy recommendations. Having examined and weighed the issues, having engaged in a back and forth process of criticism and persuasion, participants have to finalize their views with their own best attempt to look at the issue from the point of view of the public interest. In the Danish case, their recommendations are submitted to the Parliament. In France, precautionary policy in relation to genetically modified crops was shaped in light of a consensus conference and other structured public consultations. Giving precautionary decision-making a deliberative interpretation seems to set the principle on a collision course with science-based risk management. Once again, however, we see more complementarity than contradiction. The anticipated collision seems inevitable if one looks at risks solely within the perspective of science-based risk management. The general public seems hopelessly inconsistent and ill-informed in its assessment and ranking of risks [10]. The purpose of scientific studies of risk and costbenefit evaluations is to make policy more rational. They mobilize scientific evidence of harms, quantify their frequency and costs, and prioritize forms of risk reduction as a function of cost-benefit ratios. If these methods make policy more rational, however, they do so by sidelining the public from any direct participation in risk analysis. The precautionary principle does not in itself represent a frontal challenge to this reasoning. The precautionary principle is meant to coexist with science-based risk management, as it does in environmental statutes across Europe. Formulations of the precautionary principle typically include descriptions of the type of situations to which it refers. Article 5 of France's constitutional Charter for the Environment requires that three conditions be met before it can be applied: there must be reputable forecasts of environmental damage, scientific uncertainty about these forecasts, and the danger serious and irreversible consequences if preventive action is not undertaken [20]. Spelling out conditions like these, as well as calling for \"temporary measures commensurate with the risk,\" shows how proponents of precaution have adapted the principle to make it work with science based risk management. In non-precautionary situations, conventional forms of quantitative risk assessment are appropriate. On the other hand, proponents of science-based risk management should acknowledge that their justifications falter in relation to poorly understood risks, and that this has implications for participation. There are three reasons to build deliberation into applications of the precautionary principle. (1) Public deliberation provides an opportunity for risk evaluation that is more or less independent of the world views associated with particular professions and forms of expertise. Science-based risk management aims to eliminate bias by privileging expertise and quantification in risk assessment. Yet there is a type of bias in expertise itself. One may hear a genetic biologist employ a reductionist materialism in which all living organisms are described as \"no more than\" a complex set of genetic codes. Economic modeling can rely on a narrow view of man as a rational utility maximizer. In an attempt to put a price on as many variables as possible -even ones not normally sold directly on markets -cost-benefit analysts devise alternative measures based on controversial assumptions about the value of human life or of environmental goods. These perspectives are implicitly action-oriented. They incline judgment toward changing the world first and then adapting to adverse consequences later. No one should assume, however, that action-oriented perspectives are necessarily or D. Bourg [22]. A group of sociologists compared what decision-making leaders thought were the grounds of public distrust of GMOs, and what citizens actually said when they were questioned in discussion groups. The results were striking. The leaders attributed public reticence to factors like ignorance and an irrational attachment to things labeled \"natural.\" What the researchers found, however, was that most public concerns had to deal with the adequacy of already-existing measures that had been taken to control risks. The citizens asked questions like these: Do the regulatory agencies actually have enough power and the funds to counterbalance the interests of the large firms that want to develop these products? What contingency plans exist in cases where unanticipated harmful affects occur? Can the rules imposed by the regulatory authorities really be applied effectively? In all of these questions, what we hear is a certain dose of skepticism regarding the real workings of the regulatory authorities. There are suspicions that regulatory policies have been designed as much to push policy ahead as quickly as possible, for the benefit of certain interests, as to protect the public good. Bringing people from outside the official regulatory process into that process, to examine its real working, could help reinforce safety measures. And that is the point of the precautionary principle. (2) Public deliberation is crucial because precautionary policies will have broad effects on people's choices and future life-styles. Precaution may alter the commercial availability of chemicals (e.g., pesticides, fertilizers, insulators, plastics) used in everyday life. This will have consequences on prices, comforts, and the ease of controlling insect pests or plant diseases. Precautionary spatial planning to protect endangered species or to prevent the degradation of marine and coastal areas may put new conditions on access to areas of a people's territory. In the case of measures taken to avoid global warming, precaution is sure to affect transportation and energyproduction policies, thus changing people's opportunities for mobility and their choices of means to heat homes and offices. When consequences of such breadth are involved, the consecrated democratic principle 'What touches all should be decided by all' surely comes into play. If precaution requires shouldering burdens, care should be taken that the public experience these burdens as self-chosen, to the extent possible. This is important not only to make precautionary policies legitimate, but also to ensure D. Bourg  maximum public compliance with them -which may determine their success. At any rate, because of the uncertainty that is, by definition, constitutive of precautionary situations, the argument for public deliberative involvement is particularly strong. It is one thing to delegate rule-making authority to experts when there are well-proven dangers to be avoided. It is quite another to limit people's field of choices when the experts themselves are in doubt. In that case, the people have no sufficient reason to delegate authority and therefore retain their right to decide what policies they are willing to live with. (3) In some cases, the involvement of non-experts can contribute to a better understanding of risk-creating situations. Workers may have real-world experience with how materials are handled in their workplace -experience that contradicts experts' assumptions about adherence to norms. Local citizens also have accumulated experience with local terrain and wildlife. Laypeople's day-to-day observation of patterns of pathologies in local populations should not be discounted as mere hearsay. All of these can help pick up weak signals of incipient dangers [23]. None of this means that public judgments should simply substitute for expert ones. The point is to get the public and experts to interact in new ways: using well-developed procedures, the two bodies educate, challenge, and check each other."}, {"section_title": "Precautionary Obligations and Response to Criticisms", "text": "The exact relationship between the precautionary principle and authoritative regulatory policy is still in flux. Is the precautionary principle merely one principle among many that may be invoked by environmental risk managers? Or does it have an obligatory character? If obligatory, on whom does the obligation fall directly: On regulators only? Or on those whose activities generate the potential risk? Answers to these questions fall into three broad categories. First, precaution may be a simple approach. It is then conceived as a philosophical and not a juridical principle. A juridical principle inherently implies particular obligations and modes of implementation. For example, the \"polluter pays\" principle creates an obligation to impose monetary sanctions on polluters, in proportion to the cost of pollution cleanup. This principle cannot be implemented without precise measures of application being put into place. In contrast, an \"approach\" implies no obligation and leaves authorities completely free to decide if precaution is appropriate or not. Precaution has this status in the United States, to the extent that it is recognized at the federal level at all. Preference for a precautionary approach has also generally been the norm in international negotiations. Both the Rio and Johannesburg Declarations lean toward this interpretation. The World Trade Organization has refused to recognize the precautionary principle as a legal rule. But this situation is evolving. According to the French legal scholar Christine Noiville, the seemingly unbridgeable gap between proponents of the precautionary principle, on the one hand, and the Dispute Resolution Panel of the WTO might yet be overcome [24]. In the Agreement on Sanitary and Phytosanitary measures in international trade, the WTO now allows that states to prohibit imports of products they consider dangerous for their people, even without \"sufficient scientific proof.\" They can do so, however, only temporarily and in emergency situations. In order to maintain its decision beyond a certain deadline, it must supply \"adequate scientific evidence.\" Now, this requirement of \"scientific proof\" is in direct opposition to the D. Bourg  way the precautionary principle manages uncertainty. Nonetheless, the SPS agreement does allow for a temporary weakening in burden of proof: this is a first acceptance, however tacit, of a precautionary logic -even if the goal of precaution is, above all to anticipate crisis situations by close attention to potential threats. And there is more. Since \"scientific proof\" is far from being available in every case, the WTO's jurisprudence has distanced itself from its reference texts. It is now evolving in the direction of a more modest requirement, that of a \"reasonable link\" between a prohibited product and the damage that is feared. In other words, it is enough that the risks be plausible in order to justify some restraints on international trade. At a regulatory level, things are evolving towards too. The contending party is allowed a \"reasonable period\" before it has to furnish the \"sufficient proof.\" So the OMC now recognizes that when long studies are necessary to get the required scientific information, or even when such information can be gotten only through increasing use of a product, a short period cannot be required. A sort of rapprochement can be seen developing between WTO decisions and precautionary logic. A second interpretation elevates precaution to the level of positive law. Understood in this way, precaution becomes a constraining principle, carrying with it an enforceable obligation to act. Certain measures to implement it are also called for. Precaution then becomes a public policy principle that imposes obligations especially on national or regional authorities. (Local authorities are unlikely to have the financial means to support a special research program or to impose complex restrictive measures.) Under this interpretation, it becomes possible to sue the state or its agencies. This was the case, for example, when France's highest administrative court, the Conseil d'\u00c9tat, rendered judgment in a case brought by Greenpeace, to cancel an authorization for the cultivation of transgenic corn on French soil. The court froze the authorization, resting its decision in part on the precautionary principle in a 1995 French environmental law. A third interpretation turns the precautionary principle into a general norm of legal interpretation. This would allow any judge to hold any technological decision-maker liable for failing to exercise due precaution, without reference to any conditions defined by particular laws. In the French case concerning GMOs, Greenpeace and others could have sued Novartis directly rather than the authorization given by the French state. The logic of anticipatory risk prevention that characterizes the precautionary principle seems to push in this direction. We believe, however, that this movement should be resisted. First, judges are generally not in a position to mandate that all the dimensions of the precautionary principle be deployed. They may be able to require that a certain practice be suspended. But their authority does not extend to requirements for further research, monitoring, labeling, public consultation and other practices we have described earlier. Yet if only partially implemented, the principle loses essential parts of its nature. It does not have the precautionary effects that are its raison d'\u00eatre. Second, in a context where politicians and the media persistently misuse the principle, an undue broadening of the precautionary principle would further denature it and spread wholesale fear of lawsuits. This would be the surest way to bring discredit on the principle. Where precaution plausibly applies to certain sectors of developing technology (e.g. nanotechnologies), it would be best to use it through procedures set out in law which oblige the industries involved to do exploratory research on potential dangers, as is currently the case in regulations concerning the marketing of new pharmaceuticals."}, {"section_title": "D. Bourg and K.H. Whiteside / Precaution and Science-Based Environmental Risk Management 100", "text": "As the precautionary principle became more widely known and accepted in the 1990s, it has generated considerable debate. Arguments against the principle must be taken into account -in part to dissipate misunderstandings, in part to refine the principle to make it as workable and effective as possible. Probably the most common charge against the precautionary principle is that it stems from an unreasonably generalized aversion to risk. For Fran\u00e7ois Ewald 3 , the precautionary principle forces us automatically to think in terms of a worst case analysis. The principle is accused of nourishing an unhealthy inclination for riskavoidance in general. We respond first by highlighting a moral distinction. People are free to gamble away their personal fortunes at the gaming table, if they wish. But they are not free to gamble with the life-conditions of hundreds of millions of human beings. The precautionary principle concerns matters of collective, not personal risktaking. The key point is that the precautionary principle's field of application is much more restricted than Ewald's argument implies. Certainly the precautionary principle has nothing to do with a quest for \"zero risk.\" Such a quest would require expending infinite resources -a \"solution\" that is by definition disproportionate. Another reason not to assimilate the precautionary principle to the elimination of risk is that it involves only a certain type and degree of risk -\"serious\" risks that are attached to potentially irreversible damages. Finally, the principle is to be invoked only when it starts to become apparent that a product or process is potentially seriously harmful. This was the case, for example, with the humanly-caused accumulation of greenhouse gases. In such cases, late or after-the-fact awareness of the problem makes any prospect of eliminating risk completely absurd. The only thing that can be done is gradually to reduce the atmospheric concentration of these gases and thus to reduce the risk. Even when a danger appears to arise from an emerging technology, a requirement of zero risk is still impossible to meet. Such a requirement would itself presuppose omniscience and certainty. To guarantee complete safety in relation to a new technology, one would have to know all possible and future interactions surrounding this technology -which is impossible. A common error in the literature on the precautionary principle arises from confusing prevention and precaution [25]. Prevention applies to cases where a risk is well understood; precaution applies when a risk is not well understood and is surrounded with uncertainty. The risks of nuclear pollution stemming from nuclear power plants call for prevention. These risks have been extensively studied -and there have, unfortunately, been experiences with accidents, as in Three Mile Island and Chernobyl. Risks associated with long-term storage of nuclear waste, on the other hand, are poorly understood. By definition, we have no experience with them. Scientific uncertainty is unlike the statistical uncertainty in a game of heads-or-tails. There are cases where the science indicates a possible danger, without being able to affirm its existence. Precaution is therefore in order. Some critics object that the precautionary principle is tantamount to a prohibition on technological progress. It implies that \"Whatever it is you're doing, you've got to stop [26],\" as former U.S. Environmental Protection Agency head Christine Todd Whitman put it. This objection, too, caricatures the precautionary principle. All of the preceding discussion has indicated why. Precautionary policy might be simply labeling a product so that its usage and possible effects can be monitored. Precaution could favor, not total prohibition, but restrictions on a practice, for example, siting a potentially dangerous facility away from the habitat of some vulnerable species. Still, it would be wrong to claim that precaution never implies prohibition. The truth in the critics' charges is that prohibition or strict regulation may be necessary between the time when suspicions about an environmental danger are raised and the time when adequate precautionary measures can be put in place. If the precautionary principle is to have any meaning, this has to be the case. Proceeding without precaution while precautionary measures are being devised and carried out would negate the very purpose of the precautionary principle. It would mean that the product or process is already out there, uncontained, untraced, and perhaps doing irreversible damage. But the measures outlined above should make clear that the critics' equating precaution with prohibition is a straw man. The precautionary principle is about going forward -albeit cautiously."}, {"section_title": "Urban Areas and Climate Change", "text": "Urban areas are complex and dynamic systems and the geographical space where problems and contradictions within and among societies become evident in their daily operation and the type of urban space created. Now, at the beginning of the 21 st century, urban centers are burdened with many of the problems associated with growth, particularly in poor countries and emerging economies. Unemployment and underemployment, environmental degradation, deficiencies in urban services and housing, deterioration of existing infrastructure, problems in guaranteeing access to natural resources vital to urban life (water, energy, food, construction materials), and an alarming expansion of the violence associated with crime are some of the most visible problems common to these urban areas. Those problems are aggravated by the rapid growth of the population and of urban spaces, the unbalances in the urban structure, the accumulated deficit in construction, the expansion and operation of public services, and the economic and financial crises prevalent in those countries. The result has been the creation of fragmented urban spaces, of large spatial segregation that increases the social exclusion and deficiencies in the urban function [3][4] [5], and severe environmental problems [6]. The interactions between urban areas and climate change create a more complex perspective of the urban system than the one mentioned above. Traditional approaches of urban planning focus on the built environment and the urban economy neglecting other dimensions of the urban system [7][8][9] [10]. This fragmented vision of the urban system frequently is the result of simplifying the complex urban reality in order to facilitate the design and implementation of actions aimed at tending to immediate problems (public services, housing, transportation, urban economy, environmental pollution, etc.) and the technical exercise of planning [7] [11]. Unfortunately, that vision leaves out the wide range of multidimensional interactions (social, economic, political, cultural, and biophysical) of urban problems. Some improvement has been made through the promotion of urban sustainability as a guiding principle for urban planning. Concerns about the wellbeing of current and future urban inhabitants have promoted approaches to balance urban growth. The emphasis on urban sustainability during the last 15 years has sought to balance three critical functions of urban areas: as engines for economic growth, as locus for social well being, and as agents of environmental change. However, urban sustainability has been up to now more a normative ideal than an operational reality. Most of sustainability approaches support trends well established in urban development (the built environment) with an emphasis on the economic dimension (the generation of wealth) and traditional and limited attention to environmental protection and social well-being. A broader approach to urban sustainability needs to recognize that cities are complex and dynamic systems where interactions among socioeconomic, geopolitical, and environmental processes at local, regional, and global scales take place. This approach is essential to built better responses to climate change and it should be based on two important premises. The first is that the urban system is the result of alterations to the landscape through social processes expressed in the physical space by the built environment. Understanding those alterations is a key element in better understanding environmental problems in urban areas, environmental hazards, and urban and social vulnerability to climate variability and climate change. The impacts of the urban system on climate change or those caused by climate change to the urban space are different, depending on the type of space created and its use. For example, a highly urbanized area as opposed to a marginalized area with incomplete urbanization or the construction of the urban space in the natural drainage of water basins that help understand why those areas are flooded frequently. A better understanding of the vulnerability of urban areas to climate related disasters is essential in the design of adaptation to climate change. The second premise is the recognition of the bidirectional relation that exists between urban areas and the biophysical systems. Most of the international attention to these relationships has focused on how the urban system impacts the biophysical system. Greenhouse gas emissions of urban origin from the use of energy in transportation, industry, buildings, and services are clearly responsible for those impacts. Other responsible factors receiving less attention are the changes in land use and land cover directly or indirectly induced by the urban system, which impact the biophysical system. The demand for construction materials, food, energy, water, and other natural resources cause changes in land use and land cover. For example, the high demand for wood and other construction materials, food, water and energy in urban areas has caused deforestation with the associated increases in CO 2 gas emissions or alterations in the water cycle of large areas in the case of the demand for water. In the other direction, the biophysical system impacts the urban area. Natural hazards are one of the most visible examples of those impacts but there is a broad range of other impacts discussed below. Adaptation to those impacts is an important element in the future wellbeing of urban inhabitants. The bidirectional interactions between urban areas and climate change are not static or one-time events. They are a dynamic process with constant feedbacks between the urban and the biophysical systems. For example, extreme climatic event such as floods or droughts can aggravate migrations to urban areas that result in changes to land use and land cover. Those changes, in turn, can cause a new series of impacts on the biophysical system. The main interactions between urban areas and climate change can be summarized in two groups; climate change and land use and land cover change. Changes through the water cycle can also shape the form and growth of urban areas [14]. Most urban areas face already problems to secure their water supply. This situation can be aggravated by climate change, as water becomes a critical resource in the future [15]. Securing water supply to urban areas is just part of the problem. Access to water is very unbalanced in urban areas of poor countries aggravating social inequalities and poverty. Many of those urban areas have incomplete drinking water systems and only a small percentage of the local inhabitants have access to them. A large percentage of the inhabitants rely on informal markets to cover their demands of water. Access to water through informal water systems has a significant impact on the health, income, and livelihood of low-income inhabitants. An important component in the relationship between urban areas and climate is the creation of the Urban Heat Island effect and its consequences for the urban function [16] [17]. 2 Urban Heat Island effect is often aggravated by urban design and urban form, neglecting climatic conditions where urban centers are located [18] and the lost of green areas with a cooling effect [19]. These problems are particularly prominent in urban areas in poor countries located in the tropics. Current trends of urbanization in those countries together with the impacts of climate variability and climate change can aggravate stressed conditions caused by the heat island effect in urban areas. Unfortunately, many of the existing studies on urban heat islands have been conducted in temperate zones, and yet most of the future urban growth will occur in the global south. An increase in temperatures associated with climate change can aggravate the negative consequences of the urban heat island effect on health, the demand for energy, water, social life, and the urban economy. One of the most visible negative consequences of extreme climatic events is the growing number and magnitude of climate related disasters in urban areas during the last decades. The damage caused by hurricanes and other extreme climatic events has had a high, social, economic, and environmental cost and is often associated with unplanned and incomplete urban growth, often in risk prone areas, and strong modifications of the natural landscape [20] [21]. This set of factors has increased the number of inhabitants vulnerable to being negatively affected by the consequences of natural phenomena associated with climate (hurricanes and tropical storms, droughts, landslides, floods, fires, etc.). 3 The increasing frequency and magnitude of climate related natural hazards in urban areas during the past decade are some of the clearest indicators of the magnitude and significance of those impacts. The divergent rates and patterns of urbanization and the increase in poverty and inequality within and among countries associated with socioeconomic and geo-political regional and global processes are key elements in the rising vulnerability of urban areas to the negative consequences of climate change. A pertinent example is how the transformations of the global economy have triggered important changes in the urban dynamic of the largest cities in poor countries since the 1980s. These transformations are driven by domestic and local social processes and often by foreign direct investment, large-scale capital movements, and structural adjustment programs that tend to redefine the economic base of such urban areas and recast their territorial patterns. The outcome is an urban space highly segregated with extended urbanization in hazard prone areas and strong deficiencies in the provision of public services [23] [24]. 4 Urban areas prove to be highly vulnerable in crises and disasters: sudden supply shortages, heave environmental burdens or major catastrophes can quickly lead to serious bottlenecks or emergencies for a vast number of people, or exacerbate those of the socially weakest groups among the population [21]. Constraints and conflicts may acquire multiple dimensions, as they arise amid poorly coordinated administration and planning, the growing influence of an increased globalize economy, growing socioeconomic disparities and intensifying environmental burdens. Vulnerability to climate related hazards is therefore related to complex social processes aggravating the exposure to extreme climatic events. Unfortunately, annual lessons obtained from the impacts of natural hazards caused by extreme climatic events have not been translated in knowledge on vulnerability to those events and adaptation to their negative consequences in poor countries. Current trends of urban growth under increasing disparities in society predict an increase in the impact of natural hazards in urban areas [25]. One of the alarming prospects of climate change is its impact on sea level rise and its potential consequences for coastal urban areas. Coastal urban cities in Africa and Asia, two continents with the lowest share of population living in urban areas, have the greatest number of coastal urban dwellers [26]. A large number of current and future mega-cities are located in coastal areas, particularly in Asia, but a large number of small, medium, and large cities are also located on coastal areas around the world. One of the most evident impacts of sea level rise on those areas is flooding to at least part of urban areas, particularly when combined with extreme climatic events. Other impacts would include sea water intrusion in bodies of fresh water threatening critical resources used to supply water to urban areas; modifications of the landscape and ecosystems critical in the supply of ecological services and natural resources to urban areas (food, energy, building material, microclimate, and biodiversity). Sea level rise could also trigger new waves of migration to urban areas (environmental refugees). Among the most important consequences of climate change in urban areas are impacts on human health. Urban living conditions make urban residents, particularly in poor countries, sensitive to problems related to severe deficiencies in the supply and operation of public services, infrastructure, sanitation, and health service. Many of these urban areas already face environmental problems and their inhabitants suffer malnutrition, poor housing conditions and other problems associated with poverty and inequity. All these conditions play a role in aggravating the negative consequences of changes in biophysical processes in urban areas. Increases in temperature associated with the heat island in urban areas are aggravated by the heat waves that accompany climate variability, with significant consequences to morbidity and mortality (cardiovascular and respiratory diseases). The heat wave affecting Chicago in 1995 caused 437 deaths [27] and close to 30,000 in Europe in 2003 [28]. Higher temperatures can also aggravate existing air quality problems, increasing the problems of asthma and other respiratory diseases. This is a particularly troubling problem for a significant number of large cities that exhibit serious air-quality problems (tropospheric ozone or smog). Increases in temperature are also linked to vector transmitted diseases (dengue, malaria, yellow fever, encephalitis) [29] [30]. Recent studies have documented faster reproduction of the pathogens when temperature increases by a few degrees. There are also reports of modifications of the boundaries of the areas affected by these diseases common in tropical zones, as a consequence of climate variability [31]. The consequences on health caused by changes in temperature and precipitation mentioned above are aggravated by the deficient conditions of health and housing characteristic of large portions of the urban areas in poor countries and emerging economies. Deficiencies in solid-waste collection, one of the most common and visible problems in urban areas in poor countries, favor the reproduction of pathogens and their transmission vectors. Similar problems are caused by deficiencies in municipal storm drainage or sewage collection systems. Stagnant water resulting from frequent failures in those services (leaks), particularly in marginalized areas with incomplete urbanization or in low-income areas, creates ideal conditions for vector reproduction. Higher temperatures shorten vector reproduction time. The interactions between climate change and urban areas include myriad processes not considered within climate change. Some of those interactions do not have dramatic consequences like those associated to climate related disasters, but they still have significant consequences for urban life and functions. In the case of climate, some of those consequences are associated with social life within urban areas, the decline of economic activities, labor productivity, urban functions and urban livelihoods. For example, changes in average and extreme temperatures or in the intensity and length of seasons can have significant consequences for the importance of economic activities in some urban areas (e.g., tourism), the productivity of workers, the use of urban space for social interaction (comfort index within the urban area), water supply, distribution and quality, and energy demand. "}, {"section_title": "Land Use and Land Cover Change", "text": "The concentration of economic growth in urban areas is associated with rising incomes and consumption patterns. Both of these consequences of economic growth often lead to increasing demand for natural resources at the regional and global levels. Although urban processes may originate in an urban area, their impacts are usually not confined to the city boundaries. Urban processes have the potential to affect social, cultural, economic, and ecological functions and dynamics lands both close and distant from the urban core [32] [33]. Land use and land cover changes in those zones of influence are associated with the provision of ecological services and natural resources upon which urban systems rely [34][35] [36]. Peri-urban areas play a key role in this regard. Peri-urbanization refers to a highly dynamic process where rural areas, both close to but increasingly also distant from city centers become enveloped by, or transformed into, extended metropolitan regions [37]. These changes generally are not sudden, but rather piecemeal processes. In the most general sense, the development of peri-urban areas involves a complex adjustment of social and ecological systems as they become absorbed into the sphere of the urban economy. Peri-urban areas fulfill key functions for urban areas, from the supply of inputs (e.g., food, energy, water, building materials), to the provision of ecological services (e.g., wildlife corridors, microclimate, buffer areas protecting against flooding, recreational services, etc.). 5 They also suffer the negative consequences of urban areas (e.g., pollution, urbanization pressures and land use changes, degradation of natural resources). Peri-urban areas also function as a key interface between urban and rural areas through the provision of essential services to rural areas. The rapid rate of change in rural and peri-urban areas demand broader attention to how urban-rural land use dynamics will be affected by different levels of global environmental change and social responses to them. Globalization is a driving force in the growth of cities but at the same time facilitates that the area of influence often extends the near geographical space or national boundaries. There are studies on urban metabolism documenting fluxes of energy, water, food, construction materials, but with little attention to the locus of those resources and the local, regional, and global environmental and socio-economic consequences, including changes in the landscape induced by urban growth. The rapid transformation of rural and peri-urban areas could reduce opportunities for sustainability for urban areas and alternatives to reduce the negative consequences of global environmental change. Those areas are converted to urban or other land uses without considering their value and critical role for the urban areas and the earth ecosystem. Extended transformation of forests and wetlands have significant consequences at the local level (microclimate, the hydrological cycle, habitats and biodiversity, etc.) and affects basic biophysical processes at the regional and global level (the carbon and hydrological cycles, biodiversity)."}, {"section_title": "Vulnerability and Adaptation to Climate Change", "text": "There has been impressive attention to vulnerability during recent years. Vulnerability is often considered to comprise a number of components including exposure to impacts, 5 Natural hazards in urban areas are often associated to alterations to the landscape within the city and in its peri-urban area. sensitivity, and the capacity to adapt [38][39]. Adger's comprehensive review of research traditions of vulnerability to environmental change is a good reference to define a working definition of vulnerability [40]. This section reflects about potential obstacles and opportunities that the study of vulnerability offers to improve the role of urban planning in responding and adapting to climate change. A departing point for my reflections is the difference among research traditions in the study of vulnerability. Different conceptual traditions create different research results. It might be unwise to assume that all scientific studies of vulnerability can yield positive practical actions and policies leading to its reduction and enhancing opportunities for adaptation to climate change. One of the obstacles to reducing the vulnerability of urban areas to climate change is the trend to create models that would apply in diverse sets of conditions and societies. This might be a problem that perhaps has not received enough attention. Scientific research, like other creative processes, is prone to seek unique and universal contributions. While there is a clear value in those efforts, there is also a risk that those contributions become detached from a specific reality, a problem in the context of efforts oriented to understand and reduce vulnerability. Vulnerability, like urban planning, is time and site specific [40][41] and its study cannot be transformed into a blueprint to be used in different societies and conditions. 6 One-size-fit-all approaches could have unexpected and unintended negative practical and policy results. Vulnerability, like other popular concepts addressing social processes (development, sustainable development, decentralization), has been subject to diverse interpretations. The appeal of vulnerability is particularly strong in the current context of attention to global environmental problems (particularly climate change) and their connection to local environmental problems, social inequality, failing institutions, and the search of new paradigms to orient growth. Vulnerability may face a similar fate as development and sustainable development before; it can become overextended and used in all possible situations. Ambiguity in the use of analytical concepts transforms them in rhetoric rather than operational tools. As mentioned above, vulnerability is time-and-site specific and its study should reflect and address local conditions. An additional obstacle is the fact that scholars and urban planners tend to fragment or simplify complex problems in order to address them. Although these approaches have practical benefits, they inherit a risk of oversimplifying complex problems and losing key elements for building integrated perspectives leading to a better understanding of the problem. Many of these approaches are presented as 'technical solutions.' Vulnerability is a multidimensional phenomenon that requires interdisciplinary and trans-disciplinary approaches to address the interactions among its dimensions operating in multiple scales. However, it is not uncommon to find technical approaches to vulnerability among practitioners or decision-makers, often presented as emergency responses to environmental contingencies (flooding, landslides and other climate related extreme events). There is also a risk of reducing the study of vulnerability to methodological and rather mechanical approaches to the detriment of conceptual analysis of the interactions between social and biophysical processes behind the root causes for vulnerability. Vulnerability assessment could become a technical 6 O'Riordan and Jordan make similar remarks about sustainable development. It is time and site specific and models designed for a specific community cannot be transferred to others even in the same country and region, much less between rich and poor countries [42]. rather than analytical task. 7 The study of vulnerability requires addressing the balance between structural constraints limiting assets and access to resources in individuals and social groups and their agency to cope with the exposure to extreme events. The same can be said for the design of adaptation strategies. It is worth stressing the need for a better understanding of social processes in vulnerability. Approaches neglecting the understanding of those social processes could lead to incomplete or incorrect conclusions. Vulnerability is a useful analytical concept for identifying structural conditions of susceptibility to harm and risk, but perhaps with limitations to guide actions and urban policies to reduce both harm and risk. These limitations are due to the subject of analysis rather than deficiencies in the concept itself. Vulnerability is often associated with poverty, social inequality, and marginalization; thus, building actions to reduce vulnerability need to address equity issues outside the priorities of local and national decision-makers. Vulnerable people become visible to decision-makers when they become victims of extreme events, particularly, but not exclusively, in poor countries. Vulnerable people are also excluded from decision-making and from access to power [24] [48]. Efforts and actions to reduce vulnerability need to identify and address its root causes, often associated with social inequality, poverty, and marginalization. Climate change should be added to the list of factors aggravating social inequality by global, regional, and local socio-economic and geopolitical processes. O'Brien and Leichenko used the term \"double exposure\" to call attention to the interactions of climate change with economic globalization [49]. Adger et al. consider that risks from climate change are imposed on present-day society as a result of previous actions in perturbing the climate system and highlight the key role of underlying distributions of power within the institutions that manage resources that often create vulnerabilities [50]. For them, present-day adaptation actions reinforce existing inequalities and do little to alleviate underlying vulnerabilities and suggest that measures to reduce poverty and increase access to resources could reduce present-day vulnerabilities as well as vulnerability to climate variability and climate change. Thomas and Twyman highlight the fact that climate change does not occur independently of other processes impacting upon poor societies and call attention to how the interface of climate change and development processes can enhance existing inequalities [51]. The discussion of climate change in urban areas would benefit from connecting the concept of vulnerability with other concepts addressing actions to reduce harm and risk and open opportunities for social well-being. Adaptation is a natural choice for that purpose. Adaptation is associated with actions needed to reduce harm and risk to an extreme event or to evolve to a higher stage of social well-being in societies and provides an umbrella for the design and enforcement of actions intended to reduce 7 For example, Schoerter et al. [43] and Patt et al. [44] suggest methodological guidelines of eight steps. For them, vulnerability is not so much the development of new conceptual domains but the integration across three distinct uses of vulnerability: natural hazards, famine relief, and climate change. These authors fail to recognize that the differences among studies of vulnerability are not methodological (how studies consider single or multiple stressors), but conceptual. Why is this important? Because different conceptual frameworks in the study of vulnerability produce different research results. The emphasis of methods over concepts could reproduce fragmented perspectives common in environmental management where the environment is detached from sociopolitical and cultural dimensions from where the problems emerge [45][46] [47]. Attention to conceptual elements of vulnerability is particularly relevant in poor countries where drivers for vulnerability have different characteristics to those in rich countries (although Hurricane Katrina and New Orleans have shown that those characteristics are perhaps more frequently neglected than non-existent). vulnerability [39] [50]. Both concepts would also benefit from a connection to specific issues, problems, and opportunities for local development in the agenda of stakeholders, decision-makers and practitioners [52] [53]. The multidimensional perspective of vulnerability and adaptation is central to establish those connections and equity should be an important component. Several  [56]. The close association of vulnerability and equity is highlighted by contributions drawing attention to factors influencing individuals' or groups' capacity to anticipate, cope, resist, and recover from the impact of a natural hazard [24][41]. Adger and coauthors call attention to distributional issues of adaptation and to the balance between private and public costs and benefits of adaptation action [50]. Their efforts to identify criteria for success in adaptation recognize possible externalities at other geographical and temporal scales and the risk that actions effective for the adapting agent may produce negative externalities and spatial spillovers, potentially increasing impacts on others or reducing their capacity to adapt. Similar concerns have been expressed before about sustainable development in urban areas. Initiatives for sustainable development in a community can be in detriment of social well-being in other communities, even aggravating local social inequality, poverty, and marginalization. The importance of equity underlines the importance of including contradictions, conflicts, and imbalance within and among societies in the discussion of sustainable development, as well as in vulnerability and adaptation to climate change. Recent contributions highlight this issue. Tompkins and Adger propose that any response to climate change must be cognizant of wider development pressures as well as goals instead of focusing solely on single system management [57]. They highlight the relationships between assets, institutions and society and the role of cultural and regional differences among societies and the importance of public policy in responses to different hazards and different types of climate change. Here again, the relationship between vulnerability, adaptation, and urban development can be an effective way to broaden the scope of policy and actions to reduce vulnerability and facilitate adaptation to climate variability and climate change in urban areas. But that framework is prone to incorporate actions within the scope of local decision-makers and practitioners and not necessarily responsive to individual and groups agency. The reduction of vulnerability and opening opportunities to adaptation, development, or sustainable development depend on the balance between structural constraint and agency. Structural constraints to higher stages of social wellbeing for larger parts of society require institutional change and depend on complex politically negotiated processes. But it would be unrealistic to expect that those processes could make a difference by themselves. Agency (individual or social groups) is an important component of social change needed to reduce vulnerability, and open opportunities for adaptation. Incorporating agency has long been a challenge for urban planning and it will require institutional changes leading to democratic processes to take advantage of individual and community knowledge, skills, and resources. "}, {"section_title": "A Role for Urban Planning", "text": "Urban planning can play an important role in the responses to climate change, particularly on reducing social and urban vulnerability and on creating adaptation. Urban planning is considered a societal tool to create order among activities in the urban space, to reduce conflicts among them, and seeking the well being of their inhabitants [7]. This model of urban planning has prevailed since the early schemes of urban planning more than a century ago. However, a number of scholars have pointed out the limitations of that model and its difficulty ordering the complex urban system. Blair highlighted thirty five years ago the lack of capacity of urban planning to solve conflicts among economic, political, and socio-cultural priorities in the urban space. He stressed its mainly physical focus (the built environment) [7]. Blair called this approach the \"poverty of urban planning.\" He critized the techno-bureaucratic approach of urban planning addressing problems ad hoc, with little scientific knowledge, without self critic and a synoptic view of the problems, and without updating its methodological and conceptual frameworks and the way they operate in order to meet changes in urban society. Blair proposes an alternative approach to urban planning based on multidimensional and interdisciplinary perspectives. It is worth noting the similarities between Blair's multi-dimensional proposal for urban planning 35 years ago and the perspectives for multi-dimensional perspectives for vulnerability and adaptation mentioned above. By the same token, Simmie criticizes the techno-administrative function of urban planning incapable of controlling and orienting urban growth and the undesired consequences of concentrating the benefits of planning in some social groups and its negative costs on others [8]. Hogan highlights the failure of urban plans in the U.S. despite more than a century of progressive urban planning [9]. Bridge questions the assumption that urban planning would impose order to the inherent chaos of the city [10]. He criticizes the dominant assumption within urban planning that the city can be directed by an instrumental rationality. Urban planning is confronted by its limitations addressing the complex reality of urban areas. The first part of this chapter has illustrated how global processes like climate change aggravate local urban, social, economic, and environmental problems jeopardizing the social wellbeing of urban inhabitants and the function of urban societies. Urban areas need to create new multidimensional and multi-scale approaches to orient their growth. Institutions play a key role in this regard. International attention to climate change has begun to address the role of institutions (structure and operation) to meet global and regional challenges societies confront in the 21st century [42] [58]. Unfortunately, few changes have been achieved so far at the local, national, and international level in this direction, including institutional changes needed to meet the challenges of climate change. In the case of urban areas, a key question is the role of urban planning. Do planning institutions have the vision, capacity, and flexibility to update themselves and to guide future urban growth in order to meet the challenges of the 21st century? This is a relevant question because institutions, particularly public institutions, are reticent to change their operations and their structures. Public institutions are seldom self critical about their limitations and the steps needed to update and improve themselves. The situation is particularly critical for planning institutions in poor countries and emerging economies. Planning institutions in those countries have limited human, technical, and economic resources, and very limited or no capacity for research to create multidimensional perspectives of their urban problems. They are also prone to suffer limited support from mayors and local elected officials to mediate in the political negotiations among divergent interests of social groups in the urban space. Can urban planning institutions overcome those problems and limitations in order to have a more dynamic role orienting urban growth and designing and implementing adaptation responses to climate change? I argue in this chapter that one of the alternatives urban planning has to achieve a dynamic role in building adaptation to climate change is through the collaboration with the scientific community and other local stakeholders (private and social sector). Disciplinary studies have created significant knowledge about urban areas (urban economy, sociology, geography, climate, hydrology, etc.). The international debate of climate change has also produced an impressive array of knowledge and contributions from a diversity of disciplines and sectors during the last three decades. But attention to urban areas within that discussion is rather recent, particularly regarding the role of urban planning. A significant part of the literature addresses the role of urban areas reducing the emission of greenhouse gases reflecting the priority given by urban areas in industrialized countries to mitigation [59]. But recent contributions have begun to center their attention on adaptation and potential conflicts between adaptation and mitigation in urban areas. Some of those contributions highlight the importance of enhancing the role of urban planning in adaptation responses to climate change [60] [61]. Mirza and Pelling have addressed the challenge of adaptation to climate related disasters in urban areas [20] [21]. Satterthwaite and coauthors have stressed the importance of adaptation to climate change in poor countries and study the obstacles those countries face in such a task [62]. Other authors have addressed the role of urban planning in building adaptation responses to climate change in the U.S. [63], Europe [64], and Australia [65], describing the experience of particular case studies. These are valuable contributions that enhance our understanding and knowledge of local responses to climate change. However, less attention has been given to the discussion of operational alternatives to reduce urban and social vulnerability to climate change, the design of adaptation strategies, and the role of urban planning in those strategies. This chapter suggests some initial steps in this direction, particularly within the context of poor countries and emerging economies. Incorporating adaptation to climate change as part of the urban agenda in those countries requires breaking the misperception that the risks and impacts of climate change will occur in 50 or 100 years and do not require attention in the short term. Relating their local urban and environmental problems with climate change would be an effective resource to pull attention to this important issue. Biesbroek et al. suggest that placing the discussion of climate change within the context of sustainable development will result on more operational approaches to adaptation [66]. Although sustainable development is an attractive concept for urban stakeholders, it is a concept with limited operational capacity. Sustainable development is a normative concept often used with very diverse and sometimes contradictory interpretations that can reduce its operational potential to orient urban growth without a clear working definition. In order to facilitate the use of sustainable development as a framework to orient urban growth, the concept needs to be defined and used from a multidimensional perspective. It is within such a framework that urban planning can play a role connecting current local urban and environmental problems with climate change. It is also a suitable framework to attract the attention and interest of local urban planners, decision-makers, and stakeholders. It can be used as an effective tool to help them realize how short-term actions can have long-term benefits. Can urban planning contribute to implement a multidimensional perspective of sustainable development and climate change in urban areas? Criticism to urban planning mentioned above stress the limitations of planning to create multidimensional perspectives of complex urban problems. They also remark the lack of motivation and resources of many planning institutions to update and expand their focus in order to create multidimensional perspectives of their urban areas. Changing those institutions would be an important but a long-term project, particularly in poor countries and emerging economies [67]. However, building synergies and collaboration between planning institutions and local, national, and regional research institutions can achieve a positive step towards that goal. This approach has helped cities like London, New York, Chicago, Seattle, Mexico City, Toronto, Manizales, and other cities in Europe and the Americas and Australia in the design of strategies and actions for mitigation and adaptation to climate change. The potential impacts of climate change have fostered new approaches to build those responses. The lessons from those cities stress the importance of the following steps. First, it must be recognized that transferring scientific knowledge to local urban practitioners and decision-makers is difficult and not enough to build better responses to local urban and environmental problems and climate change. Rather, new useful knowledge could be constructed valuing the contributions from the domain of science and the contributions from the domain of practice (urban planners, decision-makers and stakeholders). The creation of a common space to these two domains of knowledge will facilitate the creation of useful knowledge [68] [69]. Second, the creation of a relationship among those actors should be based on trust and respect among participants. It is essential to build an understanding and collaboration among them. Third, leadership is critical building multidimensional and transdisciplinary approaches to urban planning and in the responses to climate change. Leadership can come from any of those actors and it should provide a multidimensional vision of the urban system and its interactions with climate change. The collaboration between scientists and urban planners, policy makers, stakeholders can yield contributions in two critical areas: in the assessment of urban and social vulnerability to climate change risks and impacts, and in the development of multidimensional and multi-scale perspectives of the urban system where adaptation to climate change is linked to current urban growth trends and problems. Universities and research institutions can be instrumental in identifying cumulative impacts and risks from climate change in urban areas. Scientists can provide and help interpret the results of climate models (global and regional) for local conditions in urban areas and the discussion of their uncertainty. Those are important variables in the identification of cumulative risks and impacts of climate change. Urban planners, decision makers and stakeholders would develop a different perspective of their urban areas once the potential impacts of climate change are taken into consideration. The impact of sea level rise, seasonal and extreme variations in precipitation and temperature, their consequences for health, the urban structure and functions, together with the risk of natural hazards (flooding, drought, landslides, heat waves, wind storms, fires), provide incentives to identify how urban areas can better adapt to those changing conditions. The development of multidimensional perspectives of urban areas and climate change through the collaboration among scientists, local planners, decision makers and stakeholders can provide solid basis to improve urban planning. Climate change is no doubt a challenge for urban planning but it is also an opportunity to raise political support and resources, achieve stakeholder participation, and the opportunity to update and improve the knowledge and praxis of planning. 8 This collaboration should also be regarded as a learning experience for the knowledge domain of science and the knowledge domain of practice with potential long-term benefits. The development of new approaches for urban planning can be supported by the broad and rich legacy of urban studies with a long tradition in diverse disciplines and sub disciplines mentioned above. There is also an impressive array of local case studies around the world under these approaches. Missing so far is a sustained effort to create integrated and multidimensional perspectives of urban areas, taking advantage of the accumulated knowledge under disciplinary studies. This is an approach also needed for the study of vulnerability and adaptation to climate change, and ultimately for operational strategies of sustainable development. The social, economic, cultural, political, environmental, ecological, and physical dimensions of urban life occur and interact at various geographic scales (local, national, regional, global) and through time. 9 Taking those interactions into consideration contributes to the construction of new theories and methods for the study of urban areas, as well as new management approaches. The multidimensional approach coincides with the efforts to conduct interdisciplinary [70] Breaking with the disciplinary culture of excessive specialization in favor of schemes that include interdisciplinary and trans-disciplinary thinking is not easy and requires time, but there is growing recognition of the need to complement the disciplinary vision with integrated multidimensional perspectives in the study and management of the current and future urban reality 10 . Explicit connections between vulnerability and adaptation to climate change with current urban problems can help constructing sustainable development strategies for urban areas. The advantage of this approach is to present an integrated and multidimensional vision of the urban area which stakeholders and decision-makers can relate to their daily life and areas of concern. Recent attention to the role of institutions in building sustainable development initiatives in urban areas provides a useful framework for this discussion [75] [76]. There are several research areas worth considering in this regard: continue improving the collaboration between the domain of science and the domain of policy and practice mentioned above; taking advantage of the challenge of climate change to foster changes in institutions to better respond to the needs of society in the 21 st century; the creation of governance processes that will 8 Crisis open windows of opportunity for structural changes in societies. Climate change could be an excellent opportunity to upgrade and improved planning institutions. An emphasis on multidimensional and multi-scale perspectives of the urban system constitutes a good framework for that process. 9 The geographic scale at the urban level should be considered as the point of liaison between the local and national, as well as regional and global levels. However, the study of urban and environmental aspects requires a finer level of analysis within the city. In order to understand environmental problems in urban areas, it is necessary to cover a gradient of scales, starting at the household level, continuing on to the neighborhood, district or delegation (set of neighborhoods), and finally ending the urban level [6]. For example, the problems associated with global biophysical processes (climate variability and climate change in the case of floods) have different consequences in different parts of the city. Even within the same neighborhood, some homes may be more vulnerable than others to the negative consequences caused by extreme precipitation and flooding. 10 In this regard, interesting progress has been made in the study of the landscape, as a unit of analysis capable of joining integrated multidimensional schemes [77]. These studies are based on the premise that interdisciplinary work is indispensable to understand the complex relation among ecological, biochemical, and social processes in the landscape, including the complex interaction of urban areas with their ecological surroundings. include a broader participation of a broad array of stakeholders in opening opportunities for urban sustainable development."}, {"section_title": "Final Thoughts", "text": "This chapter has stressed the importance of addressing urban systems within the framework of regional and global biophysical systems (climate change). It also highlights the need of new approaches orienting urban growth and the role of urban planning in that process. One critical message is the urgent need of stop considering urban growth only as the outcome of local forces. This perspective is common in urban planning and often leads to incomplete strategies seeking to address complex realities. Focusing on the vulnerability of urban areas to climate change and the strategies for adaptation to its negative impacts can help better deal with critical questions of urban growth. The size, form, structure, and function of urban areas and their future growth trajectories are critical elements to be considered in the discussion of climate change and the sustainability of societies. The study of urban and social vulnerability is an important element in the local responses to climate change and in orienting urban growth in poor countries and emerging economies. The chapter stated above the relevance of structure and agency in the study of social and urban vulnerability to climate change. The design of adaptation strategies must be cognizant of the balance between structure and agency in each urban community. Alternatives to address development pressures in urban areas of poor countries depend on that balance. Unfortunately, urban planning strategies are often based on a one-dimensional approach (the built environment) ill suited to deal with structure and agency. Urban planners recurrently neglect individuals and group agency. There are at least two reasons why agency should have a role in urban planning: the involvement of individuals and community organizations can be one of the best alternatives to secure the sustainability of urban development actions; agency can complement the scarce resources that local authorities in poor countries and emerging economies regularly have to face development pressures. However, incorporating agency has long been a challenge for urban planning and it will require institutional changes leading to democratic processes to take advantage of individual and community knowledge, skills, and resources. The collaboration among planners, stakeholders, scientists, and decision makers suggested in this chapter can contribute to that goal. Despite the importance of agency, structural issues have also to be addressed in strategies reordering urban growth and responding to climate change. The first part of the chapter mentioned a series of structural challenges of urban areas in poor countries. There are no easy solutions to those problems and many of those solutions are beyond the control and resources of local governments. They require the participation of national governments, and in some instances, of international organizations. A fundamental factor addressing structural constraints in societies is political will and local leadership. approaches orienting those strategies can prove to be an effective tool addressing structural conditions in society and adapting to climate change. They can also help urban communities improve their negotiations with their state, provincial, and national governments to enlist their support and participation in redefining their strategies to orient urban growth. The construction of those approaches should take advantage of decades of accumulated knowledge from disciplinary studies on urban issues and from the experiences and lessons of development programs in poor countries and emerging economies. Together, they can help avoid mistakes and shortcomings in the design and implementation of new strategies orienting urban growth and responding to climate change. Creativity can help put together a stock of low cost alternatives taking advantage of the array of currently affordable technologies in poor countries and make sound use of ecosystem services. Coordinating the participation and contributions from a broad range of actors is a complicated but an essential task in constructing responses to climate change and reorienting urban growth. Experiences of urban areas in rich and poor countries show the importance of creating that coordination at a high political level (the office of local mayors). Political engagement and support of local elected officials will be critical to achieve an efficient coordination. Urban planning can be a useful asset in this task using multidimensional approaches as suggested above. Planning offer three advantages in this direction: 1) many urban communities have already planning offices, even in poor countries; 2) the nature of planning implies seeking building consensus among stakeholders and planning offices have some degree of experience mediating among them; 3) the focus of urban planning on the built environment is a useful platform that need to be complemented with the social, economic, cultural, biophysical dimensions in order to create multidimensional perspectives. Current international and national capacity building programs designed to improve planers skills offer also the possibility to expand incorporate in them the dimension of climate change and how it relates to present development pressures in urban communities. However, it is worth maintaining realistic perspectives of the limitations and strengths of urban planning. A realistic perspective of urban planning can help create achievable expectations among stakeholders. The current timing offers a window of opportunity for those efforts. The international attention to climate change as a critical challenge for societies, together with the growing international and national recognition of the importance of adaptation, can be incentives to promote local responses to climate change. Support to those initiatives can come from a diversity of International organizations: the World Bank, diverse bodies of the United Nations (UNDP, UNEP, UNCHS), foreign aid organizations from industrialized countries, private foundations, the International Association of Local Governments among others. That support can be instrumental in developing new approaches to orient urban growth and expanding attention to climate change in poor countries and emerging economies. They can also help local governments raise financial and technical resources to support the study, design, and implementation of actions to reduce their vulnerability and enhance their adaptation to climate change. It is worth stressing the key role of building collaboration among national, state, and local governments, the business community, and urban stakeholders in those initiatives. They are particularly critical in medium and small urban areas of poor countries and emerging economies with few economic, technical, and material resources to change their path of growth. 11 Finally, it is worth stressing the urgency of building adaptation strategies to climate change in urban areas of poor countries and emerging economies. The life span of urban infrastructure is at least 50 to 70 years. Other elements of the urban structure have similar life span. This means that current and future investments in the built environment of those urban areas will function under different climatic conditions as those of today. Further delays incorporating climate change in the design of new urban constructions can reduce their functionality and aggravate the negative consequences of climate change. Many of the actions needed to reduce the social and urban vulnerability and enhance their adaptation to climate change strongly relate to their current development pressures. Efforts in this direction can make a difference in the livelihood of millions of present and future urban inhabitants in poor counties. Real problems are expected to arise if the sea level rises to such an extent that river water can no longer discharge into sea, leading to safety risks in large areas of the country. The flood protection policies for the rivers being developed by the Dutch government have recently shown a shift from building ever higher and stronger dikes towards nature development (habitat creation and repair) and giving rivers more space (the Room for the River programme), since a more natural river system is regarded as the best protection against climate change. The implementation of this major transformation in the area along and between the major Dutch rivers requires many different public authorities and private stakeholders to cooperate in such a way that their different values, beliefs, needs and interests merge into coordinated action. Attempts to realize the high policy ambitions for the area along the rivers have led to a regional, multi-stakeholder initiative. The underlying philosophy of this approach is governance, that is, coordinated action by actors representing the government, the business community and civil society to cope with complex societal problems. A Dutch project in the river basin of the Rhine -called Gelderse Poort-is used here as a case study to"}, {"section_title": "Living in the Delta: Below Sea Level and Between Large Rivers", "text": "The Netherlands is a relatively small country (approximately 42,000 square kilometres), and one of the most densely populated countries in the world (almost 16.5 million inhabitants). The country is situated in a delta where major European rivers like the Rhine, Meuse and Scheldt discharge into the North Sea. A large part of the Dutch territory is below sea level, and two thirds of the country would be regularly flooded by the sea or rivers if there were no dunes, dikes, dams and other protective structures. Dutch society is thus historically closely associated with water management. In fact, the relation between the Dutch and water is rather paradoxical. On the one hand there is a continuous fight between man and nature, which has been going on for centuries, to protect the land from being flooded by the sea and rivers. On the other hand, most of the Dutch population (nearly 11 million) are living in low-lying parts of the country, which is also where the heart of the Dutch economy is situated: Schiphol Airport, the Port of Rotterdam, the national capital Amsterdam, and the seat of government at The Hague. Approximately 65% of the country's Gross Domestic Product (GDP) is produced below sea level. It is thus an understatement to say that water fulfils an important role in Dutch society in terms of international trade, agriculture, industry, recreation and domestic use. The Netherlands also has international responsibilities to R. Corvers / Nature Development and 'Room for the River': A Governance Perspective 126 safeguard a rich natural environment, especially as regards wetlands. An internationally important region is the Wadden Sea, an area stretching along the northern coast of the Netherlands, via Germany to Denmark, and continually being contested by land and sea. The Wadden Sea is famous for its rich fauna, birdlife and flora, and today, large parts of the Wadden Sea are protected areas. Coping with both sides of the complex Dutch relationship between water and society demands a permanent effort to find compromise. The key question is how to manage water in such a way that it serves various societal purposes, without becoming a threat to society as a whole, particularly now that the climate is changing. It is absolutely crucial for the Netherlands to have coastal and river defences of the highest quality. The country's primary sea defences currently have a total length of around 700 km, including the world's largest flood protection works, the 'Delta works', while another 2,500 km of protective dikes are maintained along lakes and rivers. Despite these measures, there are problems due to construction activities, intensive land use and the continuing and increasing drainage works, resulting in subsidence of peaty lands in large parts of the country, which have locally subsided by as much as 4-5 m since the Middle Ages. This process will persist as long as the drainage works are required for societal purposes such as agriculture, infrastructure and housing in low-lying areas. Currently, the lowest point in the Netherlands is 6.76 m below sea level, in a polder that is paradoxically designated for large-scale urban expansion. And this situation is definitely not unique in the Netherlands. Many urban expansion projects, as well as other schemes like new business parks, shopping centres and infrastructure, are planned in low-lying areas, simply because this is where the economic heart of the country is. A consequence is that the gap between water levels at sea and in rivers and the ground level of the adjoining lands is continually widening, and salt water seepage from deep layers is threatening the quality of soils and groundwater in large areas of the country; a process of salination. Since the worldwide debate on climate change started, however, the Dutch have begun to realize (once again) that their country is vulnerable to flooding by the sea and rivers. The latest predictions for the Netherlands by the IPCC and the Royal Netherlands Meteorological Institute are that average temperatures will become higher, it will rain harder and more often, whereas there will be more droughts in the summer, the rivers will carry more water as a result of rainfall and melting snow upstream and, last but not least, the sea level will rise. The consequences of sea level rising for the Netherlands might be significant, but the scientific predictions are plagued by major uncertainties. Whereas sea levels rose by 20 cm during the last century, due to natural causes [7], the IPCC expects a further rise of 60 cm in the present century, due to anthropogenic climate change [4], and the Royal Netherlands Meteorological Institute expects a sea level rise of between 35 and 85 cm [7]. The Delta Committee (an independent state-appointed committee that advised the Dutch government in 2008 on how to keep the Netherlands safe and climate-proof for the next hundred years) concluded in its report that a sea level rise of 65 to 130 cm should be expected for 2100, and a rise of 2 to 4 m by 2200 [8]. The general impression is that the Netherlands will be able to cope with a sea level rise of 1 m without major problems, by building higher and stronger dikes and dumping sand to expand the coast seaward over the next century [8]. However, raising dikes to withstand floods is not always the best solution, as this further increases the gap between water level and ground level. Neither is it the only option to adapt to climate change. Real problems are expected to occur if sea level should rise by 1.5 m or more R. Corvers / Nature Development and 'Room for the River': A Governance Perspective 127 and the water in the rivers can no longer discharge into the sea, leading to a drastically increased safety risk in large areas of the Netherlands. More sustainable solutions are needed to increase safety, but also to safeguard the natural functions of rivers, coasts and wetlands. To prepare for the future risks of climate change, the Dutch government has launched a climate adaptation strategy, consisting of a national spatial planning and climate adaptation programme, the development of a climate-proofing checklist for spatial planning and criteria for climate-proof spatial designs, the identification of land to be designated as water storage reservoirs, side-channels or green rivers to reduce the threat of flooding, and the development of projects that show the value of climate-proof spatial planning. Climate adaptation has also become an issue at EU level. The EU has set out options for action in a Green Paper, indicating which sectors and areas are most vulnerable."}, {"section_title": "Floods and Flood Protection Policies", "text": "'God created the world, but the Dutch created the Netherlands' is a well-known saying referring to the historical Dutch successes in reclaiming land from the sea, rivers and lakes; their famous polders. Even the Dutch culture of negotiation and consensus building -the so-called polder model-is often associated with the historical need to cooperate in a collective fight against the water. For centuries, spatial planning in the Netherlands has been a matter of maintaining the separation between land and water. Safety was -and still is -the main objective, but societal views on how to create the greatest safety have varied in time and space. The inhabitants of the Netherlands have often had to cope with flood disasters [9]. In 1287, 'St. Lucia's flood' affected the Netherlands and Northern Germany, killing approximately 50,000 to 80,000 people. Large tracts of land were permanently flooded in what are now the Wadden Sea and Lake IJssel (previously known as Zuiderzee, when it had an open connection with the North Sea). Another famous flood is 'St. Elisabeth's Flood' in 1421, when a heavy storm on the North Sea coast caused the dikes to break in a number of places and the lower lying polders were flooded. A number of villages were swallowed by the flood and were lost, with between 2,000 and 10,000 casualties. Most of the area remained flooded for several decades. One part, the Biesbosch, evolved into what is now considered an internationally important wetland. In response to another flood in 1916, the government launched the so-called Zuiderzee works, and in 1932 the Afsluitdijk (a large dam) closed off the Zuiderzee, and it became Lake IJssel. In addition, large parts of the resulting lake were reclaimed for farming and housing, creating a new province called Flevoland. The last time the Dutch coastal area was flooded on a large scale was in 1953, when the fatal combination of a north-westerly storm and springtide resulted in the inundation of large parts of the provinces of Zeeland and South-Holland. Over 1,800 people died and the flood caused enormous damage to houses and property. Measures to prevent a repetition of the disaster were put forward by the government in the form of the Delta works project [10]. The dikes were raised to delta level (i.e. capable of withstanding storm surges as much as 1.5 m higher than that of 1953) and many innovative solutions were implemented, such as the Eastern Scheldt Barrier in 1986 (a movable storm surge barrier to protect the land against the sea without damaging the unique ecology of the estuary) and the Maeslant Barrier in 1997 (a moveable storm R. Corvers / Nature Development and 'Room for the River': A Governance Perspective 128 surge barrier to protect the Rotterdam region against the sea without impeding shipping and port activities). It took more than 40 years and billions of euros to complete the Delta works. In 1993 and 1995, the Netherlands once again had to contend with extremely high water levels, but this time in the rivers Meuse and Rhine. As a precautionary measure, the government evacuated 250,000 people from low-lying areas, and although the situation became critical at one stage, the dikes did not actually collapse. The government nevertheless concluded that large parts of the river were no longer safe. As early as 1995, the government announced its Delta Plan for the Major Rivers, and by 2000, when it was completed, 600 km of dikes along the major rivers had been raised and reinforced. Although this may look like a success story, there is a drawback. In the past centuries, the Dutch have time and again utilized land that used to 'belong to' the river, squeezing them in between high dikes. At the same time, the land behind the dikes continued to subside, the land was intensively used, the population was growing and prosperity was increasing. Combined with a changing climate, this has meant that the risk of flooding (in terms of probability multiplied by consequence) has increased significantly. More peak discharges in the rivers are expected to occur, making the lowlying areas even more vulnerable. Although it is possible to further raise the height of the dikes, which would reduce the likelihood of flooding, any floods that do still occur would then have very serious consequences."}, {"section_title": "How to Adapt to Climate Change: Innovative Ideas and Mainstream Policy", "text": "It will be clear from the above that large parts of the Netherlands are vulnerable to flooding because they are situated below sea level and located in the delta of major European rivers. Climate change is increasing the risk of flooding, and the ever growing population density and economic activities in low-lying areas are significantly increasing the safety risks (in terms of probability multiplied by consequence). To minimize the risk of flooding, a range of ideas have been put forward by scientists, policymakers, the business community, pressure groups and others. Some ideas involve proven approaches, while others are quite innovative or rather extreme in their consequences. The following list of examples is by no means exhaustive [11]: Higher dikes. Further raising and reinforcing dikes is an approach that has proved successful for many centuries. According to the chairman of the Dutch Union of Water Boards, higher and stronger dikes offer the best protection against higher water levels. Wider dikes. In a sense, higher dikes increase the safety risk, since the possibility that a dike collapses cannot be ruled out completely. Hence, the idea has been launched to build dikes that are so wide (approximately 300 m) and massive that there is virtually zero probability that they will fail. The top of such a wide dike can be used for purposes like housing, infrastructure, recreation or nature conservation. Room for the River. Although dikes along rivers protect the adjacent low-lying areas (polders) against flooding, they canalize the river system. As a result, the rivers now have significantly less space available to them, making it is difficult for them to cope with peak discharges in situations of high water level. Hence, the rivers should be given more space (as indeed they used to have before the dikes were built). This can be achieved with the help of various measures, such as removing obstacles from floodplains, constructing side-channels or green rivers, and repositioning the dikes further inland. Retention areas and overflow polders. In order to absorb high river discharges, it may be necessary to create retention areas that are allowed to be flooded temporarily, making flood protection more manageable. In situations of extremely high water levels, however, it might even be necessary to inundate specially designated 'overflow polders' to prevent flooding of other, more densely populated or economically vital areas; this airbag option is highly controversial, however. Floating constructions. Innovative constructions like floating houses, floating greenhouses and other floating utilities -various pilot projects are already being implemented in the Netherlands-do not limit the space available to water. According to the prize-winning proposal by a group of students, it would be technically possible to build a floating city, for example in Lake IJssel. Building on artificial mounds. Building farms and houses on artificial dwelling mounds (known as terpen in Dutch) are is an ancient Dutch tradition, dating back many centuries. Recent proposals suggest building entire new housing estates on mounds by adding a 5 m layer of sand on top of the soil at the construction site. The assumption is that the required sand can be extracted from the seabed and that the additional costs will only add a fraction to the cost of building a house. Moving towards higher areas. Risks might be spread by moving residents and economic activities from low-lying areas in the west of the country, where the current economic centre is (the area called Randstad, consisting of the major cities of Amsterdam, Rotterdam, The Hague and Utrecht), to higher areas in the east and south of the Netherlands. Not surprisingly, this idea is politically and socially extremely controversial. Construction of islands in the sea. Artificial islands in the sea in front of the Dutch coast could contribute to the protection of the hinterland and relieve the pressure on the available space in the west of the country. The islands can provide answers to pressing issues, such as finding new areas to live and work, energy production, or even the construction of a new airport. The political and societal responses to these ideas about flood protection depend on a range of factors, such as governmental decisiveness, cooperation with stakeholders and societal support for climate adaptation measures, but also on issues such as technological feasibility, economic affordability and scientific evidence. Mainstream politics has not incorporated all these ideas yet. The dominant strategy to secure the Netherlands against floods will most probably combine old, but proven approaches, such as higher and stronger dikes to strengthen the weak links in the coastal defence system and along the rivers, with the implementation of new concepts such as more room for the rivers, and experiments with very new ideas such as building with nature by dumping large quantities of sand in coastal areas to expand the coast seaward [7,11]. Other ideas, such as floating constructions and building on mounds will probably not be implemented on a large scale. Constructing artificial islands in the sea or moving residents and economic activities from low-lying areas towards higher areas are currently not being seriously considered. "}, {"section_title": "The Gelderse Poort Area: Nature Development and Room for the River", "text": "Climate adaptation policy in the Netherlands will involve a combination of national planning design and local implementation. This policy requires top-down approaches and bottom-up initiatives to move in tandem, but there are limitations to the traditional government model when addressing a complex societal issue such as adaptation to climate change. In the Netherlands, as in other modern societies, the government model, with its basic assumption that government exercises control over society, is beset by persistent problems, such as weak policy coherence and coordination, poor collaboration between different administrative levels, debatable competition between policy fields, lack of optimal fit between the problems and the administrative-legal framework that has to address them, problematic collaboration between public actors and other stakeholders, and, last but not least, high political ambitions whose realization is often insufficiently supported by public resources like funding, instruments and knowledge. A philosophy that offers an alternative to the government model is governance, with its basic assumption that governing is determined by cooperative action between stakeholders representing the government, the business community and civil society, with the aim of coping with complex societal problems. An important feature of governance is that the problem ownership is expanded downward from national government to regional and local authorities, as well as outward from government to the business community and civil society [3]. Governance can become manifest in area-specific approaches, usually called regional policy. The starting point of regional policy is that it relates specifically to the problems or characteristics of a particular geographically defined area (in the Netherlands a 'region' is typically an administrative unit situated between the administrative levels of provincial and local authorities). Area-specific or regional policy has some typical characteristics: regional coordination and integration of sectoral policies, debate and negotiations between public authorities and private stakeholders about policy objectives for the area, a tailor-made approach to planning and implementation, a tendency to focus more on the cooperative process than on the policy goals, important roles for project management and strategic planning and decentralization of national instruments, which may be necessary to support the regional process [5]. Area-specific policy reflects the transition from 'national policy for regions' to 'policy of regions'. The underlying steering philosophy can be regarded as an example of governance. In the Netherlands, this approach is being applied in the area between and around the large rivers. Over the centuries, the landscape of the area between and along the main Dutch rivers has changed dramatically. The construction of dikes meant that large areas were no longer subject to regular flooding, resulting in major changes to the character of the river and its accompanying flora and fauna. Large parts of the floodplains were confined by the dikes, and were taken into agricultural use. The construction of longitudinal embankments in the rivers created deep channels for shipping, and the rivers became important traffic routes for national and international trade. The presence of sand and clay in the areas along the rivers resulted in large-scale extraction. In the mid 1980s, the idea was launched to restore the natural processes associated with rivers, such as flooding, erosion and sedimentation. The basic assumption was that this would create favourable conditions for 'nature development': habitat creation and repair [6]. The 1990s saw major changes in Dutch nature policy, in terms of the ecological objectives and strategy advocated by the government [5]. After a period dominated by nature conservation and management of existing conservation areas, Dutch nature policy embraced the ambition to develop new habitats. Nature development is considered to be crucial to the process of creating the so-called National Ecological Network, which is part of Natura 2000 (the ecological network of protected areas in the European Union). The concept of nature development introduced a complex steering problem. In a period in which the controllability of society was increasingly being called into question, nature policy adopted the controllability of nature as a principle, although this seemed to go hand in hand with a change in views on how to conduct nature policy. Hierarchical steering with its top-down approach to nature policy and a central role for the national government was extended by a new strategy prompting the entire group of relevant stakeholders to adopt a cooperative policy approach; a shift from government to governance [5]. One of the geographical areas designated by the national government for largescale nature development was Gelderse Poort; an area situated between the towns of Arnhem to the north and Nijmegen to the south, where the river Rhine enters the Netherlands from Germany and splits up into the rivers Waal, Nederrijn and IJssel. To realize the policy ambitions in the Gelderse Poort area, the government set up an areaspecific project, whose strategic aim is habitat development in close relation to other functions of the area, such as clay and sand extraction and agricultural restructuring. Project partners include the national government, represented by various ministries (i.e. those responsible for housing, spatial planning and the environment; nature conservation and agriculture; and water management) and the provincial authorities. These partners are represented in the project's steering committee and project team. Other stakeholders involved in the project are local public and private actors, such as municipal authorities, water boards, businesses like clay and sand extraction companies, and various interest groups representing agriculture, nature conservation and recreation. These actors are consultation partners for the project partners and can participate in the project on a voluntary basis as feedback groups. Implementation of the project will take approximately 25 years (until 2015) and the costs are estimated at 50 million Euros [5]. Implementation of the strategic aim of the project means that various activities need to be carried out by many different public and private actors. The crucial activities are (4): Using clay and sand extraction in the floodplains to enable and fund nature development. Clay and sand extraction as economic driver for habitat development is a new concept. The policy objective is that extraction is done in such a way that it creates an optimal situation for spontaneous ecological development, rather than resulting in deep, lifeless lakes or restoring extraction sites as farming land. Despite the attractiveness of the idea, the project partners face some serious barriers in their attempts to control this process, such as old concessions for extraction without the obligation of habitat development targets, the autonomous clay market and opposition by farmers because of the loss of farmland in the area. It will be clear that public authorities can only realize their policy ambitions for the area if the necessary cooperation with private actors such as clay extractors and farmers becomes successful."}, {"section_title": "R. Corvers / Nature Development and 'Room for the River': A Governance Perspective 132", "text": "Separating agriculture from nature. In the past, nature conservation was usually related to agricultural policy and practices. The concept of nature development, however, advocates a spatial separation: natural developments are allowed in the floodplains between the dikes and agriculture on the land side of the river dikes. To separate nature from agriculture, the government needs to coherently deploy different policies and instruments, such as spatial planning, legal instruments, and funding to acquire farmland for habitat development. Again, the cooperation of private actors such as farmers is required, as the idea to give up farmland for nature development is based on voluntary cooperation (since land expropriation for the purpose of nature policy not practiced in the Netherlands). In addition, the cooperation of local authorities such as municipalities is needed, as they are responsible for the adjustment of their 'local spatial plan' to the new policy objectives of separating nature from agriculture (in the Netherlands the local spatial plan is the only legally binding plan for civilians). River management is a condition for habitat development in floodplains. The traditional aim of river management was to dispose of water, ice and sediment, to ensure the safety of the polders outside the river dikes, and to maintain reliable shipping routes. Nature development has now been added as new policy objective, and habitat development in floodplains will have consequences for river management. Natural processes such as the development of shrubs and forests in floodplains might obstruct the water discharge, and thus need to be compensated by measures that increase the discharge capacity of the river, such as removing man-made obstacles, creating parallel channels, lowering floodplains or repositioning dikes. The practical effects of these measures are hard to predict with precision. In addition, the implementation of some of these measures is hampered by the problem of contaminated floodplain soils (due to polluted river water in the past); in fact, it is legally prohibited to disturb seriously contaminated sludge. The policy process in the Gelderse Poort area can be characterized as cooperative. The project partners (ministries and provincial authorities) are generally united in their views on the objective of nature development, and advocate a joint approach. The conditions for habitat development in floodplains, however, are dictated by river management, which focuses on safety (avoiding floods). Local authorities and private actors are crucial for the implementation and realization of the objectives. The municipalities in the area are willing to cooperate, although local socio-economic situations play an important part in their position and support. Among the private actors, there is support by clay extractors, but they stress the autonomous operation of the clay market. Clay extraction plans imposed by the government can lead to a surplus of clay and therefore cause a price drop, which can jeopardize the idea of nature development by means of clay extraction. The regional farmers' interest group is worried about the future of farming in the area, though the attitude of individual farmers is more balanced. The project is supported by nature conservation groups and might be sympathetically viewed by the general public in the surrounding towns. The aim of the project, largescale nature development in the floodplains, is considered feasible in terms of the number of acres of natural land. However, what types of nature can be developed is less clear, due to restrictive conditions from river management, which currently seems to undergo a shift towards safety. An unexpected event with far-reaching implications for the Gelderse Poort project was the extremely high water levels in the major rivers in 1993 and 1995 [5]. Not only did this prompt acute reinforcements of river dikes, but it also became clear that a more sustainable form of flood protection was necessary. In view of the current climate change, extremely high river discharges are expected to occur more frequently in the future. To keep the Netherlands sufficiently safe, and ensure that it remains an attractive place to live, the Dutch government introduced a new concept in 2000, called Room for the River [12]. Instead of raising dikes, this approach tries to give the rivers more space by excavating the river forelands, widening riverbeds, removing obstacles, creating retention areas, returning previously reclaimed land to the river system, creating side-channels and repositioning dikes further inland. The main objectives of the national policy programme Room for the River are to increase protection against flooding by 2015 (increasing safety levels for 4 million people in low-lying areas along the major rivers), to improve overall environmental conditions in the area, and to ensure that the extra space that the rivers will need throughout the coming decades due to expected climate changes will remain available. Room for the River will require more space, but is expected to increase safety in return. To realize these policy objectives, the government has published the so-called Spatial Planning Key Decision Room for the River [12] which provides an institutional framework for the implementation, including an earmarked budget. Furthermore, Room for the River advocates a more integrated and participatory approach to spatial planning and water management in the area along the main rivers. The governance dimension of Room for the River is that it requires a multi-level and cross-sectoral approach requiring cooperative action by different actors representing the government, the business community and civil society. Since the extreme water levels in the rivers in the mid 1990s, flood protection and safety are back on the political agenda, and this has consequences for the idea of policy-driven nature development and area-specific projects such as the Gelderse Poort project. Obviously, ideas about spontaneous development of shrubs and forests in floodplains are now less popular, while flood channels -which might also be ecologically important-are geared to the need for quick water discharge. The concept of Room for the River has implications for policies and activities at regional and local levels, but also for the position and interests of the actors involved in area-specific projects such as Gelderse Poort. The position and interests of the ministry responsible for water management will become stronger, while the interest of the ministry responsible for agriculture and nature has become weaker, as it is unclear what types of habitat can be combined with greater water discharge. But the position of private stakeholders is also changing. Farmers see new opportunities, such as countryside stewardship by farmers in floodplains, whereby the land remains their property. As for the clay extractors, they face a completely new situation if large-scale extractions are necessary to lower floodplains. There is, however, a serious risk that clay prices might come under pressure if large quantities of clay are produced. Clay extraction for nature development might then become less popular."}, {"section_title": "Room for the River", "text": ""}, {"section_title": "R. Corvers / Nature Development and 'Room for the River': A Governance Perspective 134", "text": ""}, {"section_title": "R. Corvers / Nature Development and 'Room for the River': A Governance Perspective 135", "text": "Social Impact Assessment for Environmental Disaster Management Rauno SAIRINEN 1 "}, {"section_title": "University of Joensuu, Finland", "text": "Abstract. The problem which often lays over the disaster management practices is that social and community dimension of disasters are badly identified and assessed. This article discusses this problem and offers social impact assessment (SIA) as a tool for the uses of environmental disaster management. Here, the main questions concern the following: How can we understand and anticipate the consequences of environmental disasters and changes in the social and community level? What are suitable analytical concepts and methods for social impact assessment? This article introduces the concepts of social vulnerability, social resilience and community adaptation as central concepts in understanding the social nature of disaster. In addition, the article describes the kind of assessment experiences we have in this field. Keywords. social impact assessment, social resilience, community adaptation, natural disaster At the same time societal risks from natural hazards are constantly increasing in the current world. As Paton [2, p.3] has argued: \"Even if the probability and intensity of hazard activity remain constant, continuing population growth and economic and infrastructure development results in a concomitant increase in the potential magnitude and significance of loss and disruption associated with hazard activity, and consequently, risk\". The hazards that communities are facing have been and are changing over time. Environmental disasters always have a social dimension and, whatever their cause, their effects are invariably rooted in societal processes that render certain groups or individuals particularly vulnerable to their impacts. Paton [2, p.6] has described this fact quite concretely: \"Hazards impact on people, they affect communities, and they disrupt the community and societal mechanism that serve to organize and sustain community capacities and functions. When hazard activity results in significant loss or disruption to established social processes, functions, activities and interactions, it can be defined as a disaster. Disasters expose populations and social systems to demands and consequences that fall outside the usual realm of human experience.\" The starting point of this article is that the social dimension is often undermined in natural risk management. Wisner et al. [3, p.333] have stated that there is a noticeable bias towards the natural sciences and technocratic thinking in the risk assessment field. And when looking to the practices, it really seems to be true that risk assessment is too often seen synonymous with scientifically generated hazard mapping. This approach states that risk assessment process is complete when hazards are mapped in terms of their duration, location, frequency, severity, and impact characteristics. Wisner et al. argue that in the current situation \"the point needs to be made forcefully that if a concern to reduce risk from natural hazards is separated from social development or poverty reduction in a specific context, it is no exaggeration to state that it can put the entire local development at risk. Thus vulnerability reduction strategies have to be maintained at all costs and clear objectives are needed in order for this to occur.\" [3, p.330] When considering how people perceive risks and understand vulnerability it is important to remember that ordinary people already have knowledge and experience. This is why the mobilisation of knowledge and efforts at the community, neighborhood and village level is critical [3, p.332]. The starting point should be the achievements of ordinary people in living with floods, droughts, pest and volcanoes. Following this argumentation, there is a growing need for developing assessment methodologies for social risks, social vulnerability and social recovery and at the same time improve the community involvement in these matters. This article argues that the approaches of social and community impact assessment offers one possibility for this kind of developments."}, {"section_title": "What is Social Impact Assessment (SIA)?", "text": "Impact assessment (IA) approaches such as Environmental Impact Assessment (EIA) and Strategic Environmental Assessment (SEA) represent nowadays key tools of European and international environmental policy making. Impact assessment processes provide decision-makers with an indication of the likely consequences of their actions in the early stages of planning on the social and physical environment. EIA is mainly used at the project level (e.g. motorway, airport), while SEA seeks to identify the potential environmental consequences of strategic planning, programme and policy decisions to decision-makers. Assessment of the social impacts can be conducted through the related process of Social Impact Assessment (SIA). SIA refers to the process of assessing, predicting and managing the intended and unintended social consequences, both positive and negative, of planned interventions and any social change processes caused by those interventions [4]. So, SIA is made for example in order to understand how a proposed action or environmental change will effect the life of residents, communities and regions and what are the potential impacts for gender and various social, ethnic and age groups. Impact assessment is a process, which have the following steps: scoping the problem, identifying the problem, formulating alternatives, profiling the system, projecting effects, assessing impacts, evaluating outcomes, mitigating adverse impacts, verifying results, specifying who wins and who loses, and designing institutional arrangements and management. During recent decades, SIA has developed from technique and methods of prediction towards processes of public participation, impact mitigation, monitoring and management [5]. It has been emphasized that SIA should be integrated with EIA and SEA procedures, but the practices vary a lot. Based on the writings of several SIA practitioners and researchers we can identify following features characteristic to the SIA process [6,7,8]: SIA is relative to environmental impact assessment (EIA). It is done in advance during the planning phase in order to offer better knowledge-base for the decision-making processes and to alert various stakeholders to likely social change. It is a tool for developing mitigation, adaptation or compensation measures for the harmful social impacts. It is a tool for developing alternatives and determining the full range of consequences for each alternative. It helps communities benefit from the change that development may bring or recover from the negative developments such as disasters. Any general social theory for SIA does not exist. SIA uses a variety of research about social change to understand the consequences of a proposed action, environmental changes or disasters. So, SIA has links to various area-bounded social studies such as urban and environmental sociology, community studies, risk sociology, environmental psychology, rural studies, social policy, demographic studies and conflict analysis. SIA knowledge production is often integrated to planning process and the social variables have both qualitative and quantitative indicators. The potential methods of SIA include nearly all the usual methods of social sciences both quantitative and qualitative: such as community consultation, survey research, informant interviews, participatory group exercises, census data, geographical data (including maps), local and national statistics, local and oral histories, newspaper reports, and previous social science research. SIA explicitly acknowledges the importance of the social construction of reality and hence the value of investigating people's perception of risks as part of an assessment. Here risk is not seen as an objective fact but as a subjective experience felt by everyone and felt differently by different people. People's attitudes towards risk and behavioural responses to it are important indicators of their likely reaction to a project and in some situations will make it necessary to modify project design [9]. "}, {"section_title": "SIA and Natural Disaster Management", "text": "When thinking about SIA in a use of disaster management and assessment we have to think about various situations where the application could be possible or relevant and also what kind of approaches and concepts should be used. When assessing the social impacts of natural disasters we have to understand and take into account the difference between direct and indirect impacts, the questions of social vulnerability and resilience, and also the various phases of disaster development. Concerning the latter, we can talk about timescales (i.e. happenings before, during and after the disaster) and responses of different actors (capacities of adaptation, mitigation of adverse impacts, reconstruction). In addition, impact assessment must not be restricted itself to the description of direct or indirect impacts, but it should be developed also towards understanding the dynamics of social and community changes. Short-term social impacts during and after the disaster can include health impacts, social risks and loss of community members (death, affected); direct damage to people's property and other values (history, esthetics, neighborhoods, communities); increased levels of psychological, physiological and social stress (problems of individual, health, social and economic security); and lack/loss of basic shelter, services, connections, and transportation. Longer term social impacts after the disaster can include increased levels of psychological, physiological and social stress; changes in the community values (increasing commitment to community values is possible); lack/loss of employment, business and income; lack of housing (shelter), services, communication, transportation, recreation; changes of ownership and community development; changes in community identity; negative social consequences from the disaster management; and prolonged phases of 'transitional welfare'. The ProVention Consortium has produced guidebook Tools for Mainstreaming Disaster Risk Reduction [9] for use by development organizations. It includes a Guidance Note for Social Impact Assessment. The booklet also summarizes and represents the experience of many National Societies from around the world. According to this Guidance Note environmental hazards and related risks can be considered explicitly within the framework of social impact variables to be assessed during the SIA. Table 1 is based on a commonly used conceptual framework which divides social impacts into general categories. Table 1. Categories of social impact and relevant hazard/disaster issues [9]. How such changes affect different groups' exposure and vulnerability to hazards."}, {"section_title": "Category of social impact", "text": "Relevant hazard/disaster issues R. Sairinen / Social Impact Assessment for Environmental Disaster Management 140 influence daily life including attitudes, values, perceptions, social relationships and networks. perceptions of risk, health and safety. Community resources: patterns of land use, community services, tax base. Natural resource and land use; availability and quality of relevant services and facilities (e.g., health, police, fire, sanitation). Social justice: equity, human rights, participation. Social justice issues as factors in vulnerability. The social and cultural responses of individuals and groups to catastrophe alter in relationship to the problems that face both during the often lengthy evolution of disaster: through warning, impact, emergency, relief, recovery, and reconstruction. Some people will see disaster and reconstruction as an opportunity for major changes in the way things are done, to improve conditions both in the society and in their own individual life. On the other hand, many others want nothing more than to continue with the status quo, to reestablish a degree of consistency and continuity with the past. [10, p.133] The perspective of response means that disasters can be conceptualized also as a catalyst for change."}, {"section_title": "Disasters as a Social Phenomenon", "text": "Applying social impact assessment to disaster management requires that disasters themselves should be understood as a social phenomenon. Because this is not selfevident, it is needed to open-up the discussion in this respect. In the tradition of the original disaster studies, there has been a group who explicitly focused on social phenomena as the defining feature of disasters, within the context of social change [11, p.10]. Alan Barton [12,13] saw disasters as one collective stress situation arising when members \"of a social system fail to receive expected conditions of life from the system\". He created a matrix of four dimensions to understand disasters as a social phenomenon: scope of impact, speed of onset, duration of impact, and social preparedness. Like Barton, Quarantelli started to publish typologies for the disaster research already in the 1960's. He defines disasters in terms of variety of defining features [14, p.682]. They are (1) sudden-onset occasions, (2) seriously disrupt the routines of collective units, (3) cause the adoption of unplanned courses of action to adjust to the disruption, (4) have unexpected life histories designated in social space and time, and (5) pose danger to valued social objects. Quarantelli [15, p.345] has emphasized that disasters represent vulnerability, reflecting \"weaknesses in social structures or social systems\". There is also an approach that emphasizes cross-national and cross-cultural aspects of the phenomenon [11, p.11]. For Horlick-Jones [16, p.311] \"disasters are disruptions in cultural expectations\" that result in the perception that institutions cannot keep hazards in check. Anthropologist Anthony Oliver-Smith [17, p.186] sees disaster as an event that combines destructive agents with a vulnerable population disrupting \"social needs for physical survival, social order and meaning\". In closing, these authors share a conception of disasters that places the phenomenon firmly in social relations and social change. Many of these social authors agree that disasters stem not from the agent that causes the disruption, but from the social structure of norms and values, hence the protections [11, p.13]. Vulnerability, a part of many of the definitions, is to be found in social structure and disruption is the R. Sairinen / Social Impact Assessment for Environmental Disaster Management 141 outcome of vulnerability. According to Perry there is some consensus, that the magnitude of a disaster should be measured not in lives or property loss, but by the extent of the failure of the normative or cultural system. Some authors also emphasize the social constructivist features of disasters [10, p.73]. This is to say, that interpretations of disaster vary widely according to social and cultural circumstances and identity as well. However, to say that disasters are social constructs does not disembed them from the materiality of the world. The natural forces that create disasters exist as independent agents operating according to physical laws, but the perceptions of risk, vulnerability and even impact are mediated through linguistic and cultural grids. Perry [11, p.15] thinks that the work of defining disaster as a concept needs to be done more carefully by all disaster researchers. One needs to decide what disaster means. How is it physical or natural process and how social phenomenon. This means, that the task of defining disasters should not be treated as an unnecessary abstraction, but an elementary starting point for the empirical research and also for impact assessment. When thinking disasters as a social phenomenon, we can notice that the social vulnerability, resilience, and adaptation are central concepts in understanding the societal nature of disasters, their impacts and consequences and methods of dealing with the potential for loss."}, {"section_title": "Vulnerability", "text": "Vulnerability is a way of conceptualising what may happen to an identifiable population under conditions of particular risks and hazards [18]. Unlike hazard mapping, which can be computerized using geographic information systems or even satellite images, vulnerability cannot be seen from above. Vulnerability changes constantly, reflecting prevailing social, economic, cultural and political circumstances. Yet this same vulnerability can dramatically intensify the effects of a disaster. Similarly, the capacities of communities to cope with hazards and disasters will vary according to local conditions and perceptions. Cannon et al. argue that \"it is especially important to recognise this social vulnerability as much more than the likelihood of buildings to collapse or infrastructure to be damaged.\" [18] Social vulnerability is the complex set of characteristics that include a person's [18]. initial well-being (nutritional status, physical and mental health, morale; livelihood and resilience (asset pattern and capitals, income and exchange options, qualifications; self-protection (the degree of protection afforded by capability and willingness to build safe home, use safe site); social protection (forms of hazard preparedness provided by society more generally, e.g. building codes, mitigation measures, shelters, preparedness); social and political networks and institutions (social capital, but also role of institutional environment in setting good conditions for hazard precautions, peoples' rights to express needs and of access to preparedness). The following is a list of potential vulnerable groups of people [19, 20, p.91]: Aged (particularly the frail) being less mobile, often poor, often isolated."}, {"section_title": "R. Sairinen / Social Impact Assessment for Environmental Disaster Management 142", "text": "Very young, dependent on others, lacking the capacity to care for themselves. Disabled (mental and physical) requiring assistance from other people or agencies for normal daily support. Poor people with limited resources to meet essential needs, Nondominant language speakers who may have difficulty assessing information and services. Indigenous groups who may be socially marginalized and poor. Socially isolated who may lack support physically and emotionally. Physically isolated with difficulty accessing services and information. Seriously ill who require high levels of support just to meet daily needs. People dependent on technology-based life support systems who also require high-levels of daily support. Large families who have to manage multiple needs within one household. Single parent families with limited resources and low coping capacity. People with limited coping capacity who can be made highly vulnerable by the addition of small amounts of additional stress or loss. People with inadequate accommodation who are already in significant need. Those on holiday and traveling (particularly those in tent and caravan resorts) who are not familiar with local circumstances and assistance. Tourists from overseas who are not familiar with local conditions and who are far from their support networks. Not belonging to one of these groups does not mean that a person is not vulnerable in some circumstances. According to Cannon et al. economic and political factors often determine people's level of vulnerability and the strength of their capacity to resist, cope and recover [18]. Vulnerability is generally greater where poverty and/or inadequate social protection make people less capable of resisting hazards. On the other hand, disasters are a very significant factor in generating new poverty and worsening the predicament of those who are already poor. Cannon et al. emphasize that when disasters occur, the key point will be to ensure that relief and recovery is tied into the restoration and reinforcement of livelihoods, and also to the strengthening of self-protection and the reinforcement of social protection (e.g. through support to relevant institutions)."}, {"section_title": "Social Resilience and Community Adaptation", "text": "Resilience is a measure of how well people and societies can adapt to a changed reality and capitalize on the new possibilities offered [2, p.8]. This concept is important because a lack of resilience increases the likelihood of harm from unforeseen risks and indicates that the community is more vulnerable to the impacts of change. Assessing resilience (and/or vulnerability) involves understanding the community's risk factors in order to develop a strategy that benefits their wellbeing and livelihood, while respecting their culture, customs, beliefs and values. The term resilience is often used in a manner synonymous with the notion of \"bouncing back\". This reflects its derivation from its Latin root, resiliere, meaning \"to jump back\". The reality and implications of disaster are however something different than jumping back. \"The post-disaster reality, irrespective of whether it reflects the direct consequences of disaster or the recovery and rebuilding activities undertaken, will present community members with a new reality that may differ in several fundamental ways from that prevailing pre-disaster. It is the changed reality that people must adapt to.\" [2, p.7-8] Studies of resilience and vulnerability have often focused on the individual [21]. However, when thinking about disaster resilience and social impact assessment, the community level is usually more important; this means that the assessment should focus for example on families, neighborhoods, ethnic groups, parishes, villages, tribes, clans, social associations and organizations. Social groups and community networks possess many capacities and weaknesses that render them more or less susceptible. The definition of resilience used here embodies the notion of adaptive capacity [2, p.8]. Here, adaptation refers to actions that increase resiliency or reduce vulnerability in the face of natural disaster. There are three main modes of adaptation: Autonomous adaptation is essentially an unconscious process of system-wide coping, most commonly understood in terms of ecosystem adjustments. Reactive adaptation involves a deliberate response to a disaster and its impacts, in order to recover and prevent similar impacts in the future. Anticipatory adaptation involves planned action, in advance of disaster, to prepare for and minimize its potential impacts. For example enhancing the buffering capacities of natural systems in the face of climate extremes. Impact assessment can be seen as a tool for anticipatory adaptation. Community adaptability means the collective ability of residents in a community to respond to external and internal stresses; to create and take advantage of opportunities; and to meet the needs of residents, diversely defined. In addition, it refers to the ability of residents and community institutions, organizations, and leadership to meet local needs and expectations. Given that disaster strikes with no or very little warning, the foundation upon which adaptive capacity rests involves ensuring that the requisite knowledge and resources are organized in advance and can be used to good effect when disaster strikes [22, p.312]. The social dimension of adaptive potential and capacity can be classified into following types of human responses [23, p.62]: Coping strategies mobilize social networks to directly reduce the likelihood of negative impacts of a hazard event. Institutional modification aims to alter the institutional framework of a community using political influence to create political space for at-risk actors to argue their case. In general, resilience to risks and also the capacities of adaptation is determined by the following forms of \"capital\" as adopted by the sustainability approach [21]: Natural capital (water, land, rivers, forests and minerals); Financial capital (savings, income, pensions, credit, state transfers); Human capital (knowledge, skills, health, physical ability); Social capital (networks, affiliation, reciprocity, trust, mutual exchange); and Physical capital (infrastructure, shelter, transport, water, sanitation, energy). R. Sairinen / Social Impact Assessment for Environmental Disaster Management 144"}, {"section_title": "Examples of Disaster Social Assessments", "text": "Around the world we have different kind of examples of developing and using social (and community) impact assessment methods for the natural disaster situations. These applications can come from different backgrounds and they use different titles and concepts. But the basic principle is the same: to develop assessment techniques and processes which take into account social and community aspects and very often also local involvement. Vulnerability and Capacity Assessment (VCA). International Federation of Red Cross and Red Crescent Societies define VCA is an investigation that uses various participatory tools in order to understand the level of people's exposure to (and capacity to resist) natural hazards at the grass-roots level. It is an integral part (but not the only part) of disaster preparedness and can contribute to the creation of community based disaster preparedness programmes. As part of the process, it allows the people to identify and understand the risk they consider should have priority, even if these are not the natural hazards. VCA is a tool which enables local priorities to be identified and leads to the design of actions that contribute to disaster reduction. [24] Community Risk Assessment (CRA). According to Provention Consortium [25] Community Risk Assessment (CRA) uses participatory action research methods to place communities in the lead role for the assessment, active planning, design, implementation and evaluation of activities aimed at reducing the community's risk to disaster. CRA focuses on identifying the most vulnerable groups in a community, and explores what local capacities can be used to enhance the resilience of the community members. CRA forms part of community based disaster risk management (CBDRM). Once a community has assessed the risks it faces and an action plan has been developed, disaster risk reduction measures need to be taken. These measures might include practical disaster mitigation measures, such as building dams or dykes, forming emergency response committees, developing community based early warning systems and practicing response and evacuation, advocating at the local or national government level for policy change in favor of preventive action, or even measures to reinforce the livelihoods of the poorest in the community, hence their resources for self-protection. Community (Environmental) Assessment is a rapid appraisal guided by scoping of key potential impacts and issues [26]. It is applied to smaller projects than normal EIA or SIA; this can mean small household or community -level projects after the disaster (water supply, shelter, livelihoods) [2]. It is less detailed because of rapid timetable, it may recommend larger assessment if needed and community views and concerns largely drive the assessment. Community assessment includes (a) analysis of available documented information and observations from site visits (rather than exhaustive field work or comprehensive scientific studies); (b) participation of affected communities with specific attention to ensure equitable participation of women and men, local resource users (fishermen, hunters, medicine women) and other stakeholders in the project area, and (c) professional opinion of consulted experts and EIA team members."}, {"section_title": "Dynamics, Predictability and Risk", "text": "Assessment of Natural Hazards theory to describe and predict their evolution in spatial, temporal or energetic domains. At the same time, the weakness of deterministic relations in high dimensional processes does not imply an absence of order in governing rules. This is why for complex natural systems very large deviations from the mean (catastrophic extreme events) are not negligible and originate from system's inherent rules, not from chance. The most important features of complex systems are their ability to self-organize and the fractal distributions. For commonly limited natural scales it reveals itself in the form of memory or longrange dependence. According to the present understanding almost all important natural hazards are associated with such memory, scale invariant, close-to-critical state models, e.g. landslides with the sand-pile model, earthquakes with the sliderblock model, and forest fires with the forest-fire model. In spite of present difficulties related to the correct dynamical analysis of complex systems, it is accepted that predictability of natural disasters can be considered as a well-posed task. Thus, developing dynamical methods together with quantitative models needed to evaluate probabilistic hazard assessment is within our reach. This will"}, {"section_title": "Different Views on Predicting Extremal Phenomena", "text": "The main public expectation from prediction and predictive research is that, if a forecast is available and reasonably accurate, decision makers could use advanced information about potential hazards in their planning activities. People look at predictions to help them make decisions that can mitigate or avoid the impact of nature on society (and/or of society on nature). In doing so, we need to recognize that prediction has become a part of a complex decision-making process, a network of interrelationships that must function well across all of its connections if predictions are to serve society successfully. According to Pielke, [6] this integrated process involves: policy makers (who demand and fund predictions or prediction related activity), scientists (who carry out research and make, when possible, predictive conclusions), and decision makers (who use predictions for their practical purposes). In spite of such seemingly close practical interconnection between policy makers, decision makers and scientists, the matter of prediction is often understood in quite a different way. Society commonly views predictions as an immediate and quantitative product of scientific research (even when this has not been declared by researchers), and demand predictions from the scientific community. From the practitioner's perspective, prediction often ceases to be science, and is becoming a kind of technology [6,7,8]. This is not surprising in light of recent progress in understanding various aspects of disastrous natural processes [see e.g. 3,5,9]. In the meantime, new expectations have indeed been created. Based on modern science approaches, disaster predictions would quickly generate an array of applications. It was expected that immediate results of fundamental scientific research could critically affect the ability of different users to mitigate the high risks associated with the effects of natural disasters. Excessive predictive expectations have been partly produced because of the different understandings of prediction in science and in society. People often lack a framework for assessing when and if prediction is possible, and whether prediction may be achievable for reasonable spatial and temporal scales to help achieve practical goals, including decisions in planning for and responding to natural or anthropogenic hazards. When we speak about predictability from the scientific perspective, we mean the potential of the system itself to allow us to foresee its future evolution [2]. In other words, we assume that we deal with very specific inherent properties of a system which defines the extent to which its future evolution may be foreseeable. This deterministic prediction can be considered highly desirable, though rarely achievable for certain spatio-temporal scales of research. In most cases, because of inherent peculiarities, the promise of prediction consists not so much in the definition of the exact future state of the system, but in the narrowing of the range of the system's future possibilities through a decrease in predictive errors in order to support decision making based on an evaluation of the probability of extreme events. It is important to mention that regardless of the results of predictive activity, the scientific reason for investigation still consists of the uncovering of a system's inherent For example, responding to the strong societal demand in California, seismologists carried out scientific research and assigned a probability of 90% to their 1988 prediction of the Parkfield earthquake. But the earthquake occurred much later [10,11,12]. In this case, the prediction as a product of scientific research failed. However, the important scientific outcome was a better understanding of seismic processes, with inherently restricted predictive temporal and spatial scales. Thus, the indirect outcomes of scientific research, including classifying, describing, understanding, and searching for quantitative precursors before extreme events, have historically been the most important. And when possible, scientists can start to control complex natural processes."}, {"section_title": "The Extent to Which the System Can Be Predictable", "text": "Generally, a process in which the measured signal does not change, or changes periodically, is common to predict. The forecast of a completely random process is easy as well -the best prediction is the mean value. The natural processes in which we are interested are something in between. They are not periodic; but they are not purely random, since to some extent they are deterministic (dynamical structures, as termed next). They have characteristics which can be exploited and quantified to derive the best possible predictive conclusions [13,14,15]. At the same time, in spite of early optimism about such quantifying scientific methods, experience shows that the future to some degree is \"clouded\" and expectations in disaster predictions have seriously faded. Even the question of whether the problem of predicting complex natural systems' behavior is correctly posed, has arisen. On the other hand, it is clear that predictive cloudiness is variable. We can predict some events with skill; hence, the prediction task is sometimes resolved, but sometimes not. It has been demonstrated and proven many times that our predictive ability depends not only on our professional skills and methods employed, but on inherent peculiarities of the systems investigated. These peculiarities, or underlying rules, define allowable predictive spatio-temporal scales. According to the present understanding, it would be more correct to say that for a given accuracy (arbitrarily large but finite), it is always possible to indicate a time interval for which predictions cannot be made [13,14]. Moreover, a calculation of Lyapunov properties of a process enables to define time intervals below which prediction can be made [13,14,16]. Indeed 10-14 days as the limit of predictability for weather, and about six months for climate forecasts was established. Thus, we might say that deterministic prediction of natural disasters is almost always possible. The problem is whether predictive time scales have any practical sense. To be more precise, what one usually expects from a prediction is that it gives the value of some observable outcome at some specific time in the future. This is generally true for extreme events, too. But because of the mentioned spatio-temporal predictive restrictions, in such events the most important aspect is not exactly the precise value of the predicted event, but whether the value is above or below a given threshold [2]. Prediction error may be defined as the difference between the predicted value and the observed value of some predefined characteristic. Thus, the quality of predictions can be quantified by the average prediction error as an indication of the extent of the level of uncertainty. It must be stressed again that time precision of our predictions depends not only on choosing the reliable approach, or on just how much predictability (the extent of determinism) is present in the system. It is understandable that to foresee the system's future evolution for a certain time scale, we must know the current state (or initial conditions, as termed next) of the system with a given finite precision. At the same time, how this knowledge can be converted into a statement about how far into the future we could make a prediction with a given precision is still in question [2]. When deterministic prediction for practical time scales is not possible, the only solution is to find \"alternatives to prediction\". In such cases, results of scientific research aimed to clear up statistical and dynamical features of investigated processes may lead to decisions that are expected to reduce the impacts of future disasters, improving building codes and enforcement, insurance practices, and engineering designs. [e.g. 12]. Because of that, probabilistic predictions of future states exceeding a certain value may be used. According to Kantz et al., \"although probabilistic prediction is not what we really want, they anyway contain much more information than no prediction at all\" [page 82 in 2]. Hence, the lack of knowledge about a system prevents from generating deterministic predictions, but still allows to assign probabilities to the different possible future states. One of the tasks of a modern time series analysis is to extract this information from past data [13,14,15,17]. Thus, it can be said that the future behavior of any system can be (deterministically or probabilistic) predicted and, in general, the problem of the correctness of scientific prediction (at least for certain spatio-temporal scales), should not be questioned. It is worth mentioning here that predictive research may often reflect disciplinespecific scientific perspectives which can rarely provide \"answers\" to practitioners' problems compromising complex mixtures of facts and values. For example, hazard information provided in the seconds prior to an earthquake will not be considered relevant by society, which at best plans for time periods of years to decades. Although it is the result of increased scientific understanding of seismic processes [12]. Clear understanding of this reality is supported in the Hyogo Framework for Action, where the need for \"\u2026research, observe, analyze, map and where possible forecast natural and related hazards, vulnerabilities and disaster impacts,\" is underlined [page 8]. Thus, if analysis tools are properly selected, prediction may fail because of fundamental forecasting restrictions of natural processes. These restrictions arise from both inherent dynamical peculiarities and sensitive dependence on initial conditions, in short, on complexity."}, {"section_title": "Complexity of Systems and Predictability", "text": "Much has been heard about complexity in the scientific community during the past decade. Some authors [18,19] argue that complexity exhibits typical characteristics such as dispersed interaction among locally interacting heterogeneous agents in some space, no global controller that can exploit opportunities arising from these dispersed interactions, cross-cutting hierarchical organization with many tangled interactions, continual learning and adaptation by agents, and out of equilibrium dynamics. Examples of structural and dynamical complexity can be found in very different areas, such as atmosphere (climate and weather change), geophysics (tides, earthquakes, volcanoes, magnetic field variations), social systems (crowd behavior), medicine and biology (rhythms, physiological cycles, epidemics), economy (financial market behavior, exchange rates), engineering (friction, fracturing), and communication (electronic networks, internet packet dynamics). Though there is still not an agreement on the definition issue, it is obvious that a necessary but not sufficient condition of complexity is the nonlinearity of systems governing laws. Disregarding nonlinearity in the analysis of complex systems may lead to unwanted or even catastrophic results. In the conference proceedings What disaster response management can learn from chaos theory, an excellent example describes how a solely linear understanding of complex technological processes may lead to a catastrophic response [20,21]. The problem is tied to the tendency to think in terms of one-dimensional, linear event chains associated with aims, thus neglecting to take into account the feedback and amplification of side effects and exponentially accumulating processes. To achieve the urgently required cooling down and renewed stability of the Chernobyl nuclear plant reactor, the operators activated all eight pumps instead of the allowed maximum of six. While the operators acted in accordance with their onedimensional safety goal, the reactor went into a series of predetermined interconnected safety measures which proceeded along a very different rationale and laid outside the operator's control: operators and the system functioned according to different underlying theories, assumptions, principles, time scales, implicit rules and mechanisms. They were on a collision course that ended in catastrophe [21]. For general purposes, complexity can be defined as a property of systems which are fractal by their spatial distribution and fail to converge to either a point or a limit cycle by their temporal evolution (thus the systems are fractal in the sense of dynamics, too). Such untypical fractal behavior is usual for natural systems [14,15]. Indeed, often mathematics wants to compress dynamics out of the system and just determine the stable point [22]; but this is not the case for natural systems like atmosphere, earth, or economy. What we really observe in most of such systems is complex spatio-temporal behavior, expressing itself in characteristics measures of fractality. At present, the term complexity is mostly used correctly, not only by scientists but practitioners too. For instance, in the principal conclusions of the July 2001 Amsterdam Conference Challenges to changing earth it was said that \"\u2026the Earth system behaves as a single, self regulating system of physical, chemical, biological and human components. The interactions and feedback between the component parts are complex, and exhibit multi scale temporal and spatial variability.\" [23]. Thus, a forecast of the future depends upon an understanding of the complexity of systems' spatial and/or temporal behavior. It is necessary to note that, in many instances, efforts to understand complexity in order to reduce predictive uncertainty may look as having the opposite effect. Roger Pielke [6, p.117] provides an interesting example: in 1990, the Intergovernmental Panel on Climate Change (IPCC) projected a 1.5\u00ba to 4.5\u00ba C mean global temperature change for 2100. In 2001, after tens of billions of dollars of investment in global-change research, the IPCC projected a 1.4\u00ba to 5.8\u00ba C temperature change for 2100 [6]. Even as the IPCC has become more certain that temperature will increase, the uncertainty associated with its projections has also increased. Pielke humorously stated \"Ignorance is bliss because it is accompanied by a lack of uncertainty.\" Unfortunately, this statement does not help to predict the future. Actually, the trick with increased uncertainty is caused by the fact that there are many more scenarios of possible population change and energy use. It appears that the global ocean-atmosphere-biosphere system is much more complex than it was once thought. In short, natural systems are more complex than it was assumed by policymakers. As it was previously mentioned, complex dynamical systems may evolve in exceedingly complicated ways, being irregular and initially appearing to defy any rule. The next state of the system cannot be derived from the previous one. At the same time, for the purpose of prediction, all complex systems consist of two parts: a rule, which specifies how a system evolves in time, and an initial condition, from which the system starts. Indeed, according to Henri Poincare, the reason why dynamics of complex systems defy any rule does not lie only in the laws of how the system evolves, but also in specifying the initial conditions [24]. More exactly, complex dynamical systems are characterized by sensitive dependence on initial conditions. A result of the dependence on these initial conditions is that small changes in the initial conditions can subsequently lead to large differences in outcomes. In practice, knowledge of initial conditions is obtained with instruments that are subject to measurement errors. But even without such measurement errors, the simple act of rounding off a decimal can lead to vastly different outcomes. Popularized as the \"butterfly effect\", this is a fundamental characteristic of low dimensional complex systems (known as chaotic systems) have a limited predictability [25]. So, to make a prediction, we should know a system's temporal evolution. Generally, in order to introduce systems temporal evolution (dynamics), one needs equations of motion. Such equations might be purely deterministic, like Newtonian equations of motion, or they might be stochastic, e.g. Langevin equations. It is appropriate to mention here that for real data analysis purposes, calculations can be carried out not on the states themselves, but on the probabilities of finding the system in a given state at a given time (Fokker-Planck equations) [2,14,26]. In spite of whether an equation of motion is defined or not (and often an equation of motion cannot be defined clearly) predictability of any process presumes the presence of a nonrandom dynamical structure. Under dynamical structure, we mean the presence of some extent of determinism in systems' evolution laws, which for complex natural systems not always is easy to observe (or more precisely is restricted to certain scales). The principal difference between random and complex processes is the presence of some dynamical structure [2,14]. Complex processes are regarded to be highdimensional, but still non random. In general, we need to quantify the existence of internal structures of investigated (high-dimensional) processes that, when possible, enable us to know something about the future of a system [27]. Thus, extreme events or disasters are phenomena that occur in systems with complex high-dimensional dynamics (though, in principle, systems revealing extreme behavior may look as quite simple, being described by deterministic equations). Hence, in trying to predict we search for internal (and external, as some authors assume [2]) dynamic mechanisms that cause a system to move extremely far from its usual state. Despite a huge body of knowledge about dynamics, accumulated mainly over the past three decades, extreme disastrous events have only rarely been the focus of such complexity studies. This is not difficult to explain, because of the above-mentioned problems of quantifying dynamical systems evolution. Thus far, it is not clear whether natural processes under consideration are completely random, or obey any deterministic rules. So the wrong assumption of extreme events -catastrophes-as randomly generated may be derived. First of all, it should be stated that they occur in systems which are complex both from a structural and dynamical perspective. Such systems, far from a state of equilibrium, usually are close to a so-called critical condition, where the system's variability (not its mean values) and collective effects (not its individual aspects) are dominant [1,4]. Universal dynamic mechanisms characterizing the generation of disastrous events is still not known; but the number of potential mechanisms is recognized as relatively small [4]. Several possible scenarios, presently known, for the mentioned transformations in complex systems are the concepts of theory of large deviations, selforganized criticality (SOC), chaos, and fully developed turbulence. SOC, for instance, suggests that a system reacts to a sequence of perturbations by transforming itself into a close-to-critical state, for which power law distribution functions of the relevant observables is typical. For a critical state, huge fluctuations are the rule rather than the exception. And most importantly, transition to this state does not require external tuning [1,28,29]. For instance, the Gutenberg-Richter law of earthquake magnitude distribution can be reproduced by suitable SOC models."}, {"section_title": "Long Tail Distributions, Memory and Predictability", "text": "As previously mentioned, predictability of extreme disastrous events depends on many factors, ranging from correctly selected and measured data sets of targeted processes, to our capability to reveal and quantify their dynamical structures, or to modeling ability. In any case, the predictability of a system's future is closely related with understanding its statistical, and dynamical, features. Recent progress in complex systems and disaster sciences has somewhat shattered the views that general laws governing complex systems cannot be known. General rules of the origination of disordered behavior from ordered states of complex systems have been established [3,13,14]. Scholars from various disciplines now observe pertinent similarities rather than differences, what Armin Bunde and colleagues called \"universal anatomy of disaster\" [3]. The reason they provided is that there exist some general features of complex systems which are characterized by very large deviations from the mean (catastrophes). To explain the situation some words about data and types of distributions should be said. According to Henry Abarbanel [13] the \"very first job\" of scientists is to find a signal. Next, but not less importantly, is correct measurement (quantification) of the signal found. The fact is that the underlying reality of any theory is measured data, which constitute a firm base from which scientific reasoning can start, and to which it must always return in order to test its validity. So, without data there is no understanding of a process, and no prediction of a system's future evolution. By data, we mean a sequence of measurements forming either an equidistant, or unevenly formed, time series [14,16]. It is well known that the quality of data is like the Achilles' heel of real time series analysis. Indeed, there are a multitude of practical problems with measured time series [14,15,16]. For instance, measured data commonly lack stationarity. Since there are currently no good theoretical concepts for handling non-stationarity, violation of stationarity is often ignored in practice [14]. At the same time, one has to bear in mind that non-stationarity might lead to a future evolution of a given system that is very different from the evolution that can be predicted from the past [2]. Another serious problem is the amount of data, which is often too restricted for a meaningful analysis."}, {"section_title": "T. Matcharashvili et al. / Dynamics, Predictability and Risk Assessment of Natural Hazards 155", "text": "These problems are also typical for data series of disastrous processes, and using extreme value statistics is often very useful [30; 38]. For disastrous extreme events, statistical conclusions can not be drawn through mean values. Rather, the deviations from the mean and the distribution function of the extreme values are required. Thus, in studying the extreme value statistics of the corresponding time series, one wants to learn about the distribution of the extreme events, i.e., the maximum values of the signal within time segments of fixed duration and the statistical properties of their sequences. Many interesting results on extreme value statistics have been obtained in the past years [30,31,32,38]. Most of these results, however, hold only in the limit when the time segment tends toward infinity, and are based on statistically independent values of the time series. Both assumptions are not strictly valid in practice. Since observational data are always finite, predictions for finite time intervals are required, and most importantly, correlations between data cannot be disregarded. In recent years there has been growing evidence that many natural records exhibit long-term persistence [3]. Prominent examples include seismological, hydrological, meteorological, and climatic data [3,9,33]. At the same time, the independent and identical character of distribution is mostly necessary for statistical analysis. The most trivial is normal (Gaussian) distribution of independent, identically distributed, random quantities (Figure 1). For this kind of distribution, the number of fluctuations rapidly decreases when the size of fluctuations increases. Compared to standard deviation, the probability of large fluctuations is very low, so they can be ignored. Exponential distribution is also commonly used for statistical analysis of natural catastrophes. In this case, the distribution probability of large deviations decreases more slowly when compared to normal distribution. One of the most interesting types of distributions for natural catastrophes is the self similar power-law type or Pareto distributions: 0 , , ) ( . Self-similarity of distribution means that frequency of event-occurrence does not depend on the scale of observation. Figure 1. a) Probability of large deviations from the mean value is negligible for normal (G) distribution (of independent, identically distributed, random quantities), while for power-law distribution (P) probability decreases more slowly and large deviations, extreme events, cannot be neglected. b) In the logarithmic scale, power law dependences acquire the form of a straight line (the sum of the independent, identically distributed, random quantities)."}, {"section_title": "T. Matcharashvili et al. / Dynamics, Predictability and Risk Assessment of Natural Hazards 156", "text": "For the power-law Pareto type, the distribution number of fluctuations decreases much more slowly when the size of fluctuations increases. Thus, probability of large deviations is much higher than for Gaussian or exponential distributions. For 1 > \u03b2 condition, such distributions are often referred to as heavy or long tail distributions (Figure 1). The examples of self-similar power-law distribution in natural disastrous events (such as tornadoes, floods, hurricanes, and earthquakes) are abound [34,35]. Thus, power-law distributions describe the general feature of disastrous natural processes -the capability to generate large deviations, or catastrophes, with small but non-zero probability. At present it is not easy to answer the question where do power statistics come from? This big question is partly answered by the paradigm theory of self-organized criticality [1, 28,]. The general feature of self-organized systems in close-to-critical state conditions is the emergence of long cause-effect relations (so-called long-range correlations LRC). In LRC systems, one event may lead to a second, a third, and then an avalanche of changes affecting the whole system. A sand pile is a popular simple physical model demonstrating this kind of behavior [28]. The statistics for a sand pile proves to be a power-law type. Studies of complex systems demonstrating self-organized criticality have shown that such systems, on their own, seek a critical state, which is possible with avalanches of any scale [36]. However, it is not quite clear whether systems with power-law distribution may be random or may have any deterministic structure. At the same time, recent developments in critical systems analysis show that avalanches can not be generated randomly by any influences [1,37]. This is in good accordance with the mentioned assumption that natural processes cannot be regarded as completely random. Catastrophes are not usually generated as if someone were throwing the dice, but instead by the system which is governed by equations of motion that propagate the actual state of the system forward in time [2]. Correlation and other temporal structures appear in the time series of such systems as fingerprints of the hidden dynamical structures. Hence, somewhat correlated, long-term persistent behavior is in most cases, but not always, a property of systems with long tailed power-law distributions [3,38]. Some authors identify this as the two components of predictability: the static part comes from the probability distribution of all possible future events, and the dynamical part comes from temporal correlations [14]. Thus, it can be said that power-law type long tail distributions and elements of long range memory properties of complex natural systems exclude their complete randomness, and provide a strong theoretical basis for state-of-the-art predictive research."}, {"section_title": "The Probabilistic Assessment of Seismic Hazard for the Caucasus", "text": "In order to make a prediction, we need to quantify the existence of dynamical structures of a system of interest. However, as it follows from the above overview, in many cases such predictions are not a realistic goal. Causes are multitude and include the absence of long arrays of valid and reasonably accurate data describing the different aspects of processes of interest, the lack of data analysis methods reliable for high-dimensional processes, and the lack of paradigm theory."}, {"section_title": "T. Matcharashvili et al. / Dynamics, Predictability and Risk Assessment of Natural Hazards", "text": "Nevertheless, when disasters and catastrophes are considered, much weaker predictions are already very useful, such as the probability of an observable exceedance of a given threshold during a certain time interval. From a practical point of view, it will be useful to forecast the probability of the future state of a system, or of the future value of a specific event. If desired and useful, the predicted probability distribution can be converted into a specific value for the observable of interest by computing its mean. In this case the prediction is optimal in the sense of the maximum likelihood principle [2,14,16]. As an illustrative example of the usefulness of a probability approach for practical purposes, we present here some results of the probabilistic assessment of seismic hazard for the Caucasus (Figures 2 and 3). The probabilistic assessment procedure is based on selected modern, state-of-theart approaches, which at their core include a range of alternative model formulations. Experience in assessing seismic hazard has shown that depending on the frequency of interest, and on the rheological properties of the Earth's crust, earthquakes can be felt and cause substantial damaging effects at distances as far as 300 km, or sometimes even more. For the purpose of this study, the overall geographical area of interest extends from 38 to 53 degrees longitude and 35 to 45 degrees latitude, thereby ensuring that the distance from the boundary of the study to any point in Armenia, Azerbaijan or Georgia is at least approximately 200 km. The seismic hazard maps in terms of the probability of exceeding a fixed value of shaking during different times of exposure have been constructed for the studied territory. The computer program SEISRISK III, which was developed by Bender and"}, {"section_title": "T. Matcharashvili et al. / Dynamics, Predictability and Risk Assessment of Natural Hazards 158", "text": "Perkins [39] and based on the Cornell Approach, was used for calculating the set of maps for intensity (MSK scale) and peak ground acceleration. Intensity and peak ground acceleration (PGA) values were calculated on a 0.09\u00ba by 0.09\u00ba grid (about 10 km for longitude and 9 km for latitude). Seismic zones were defined for the wider region in order to take into account border zones, whose seismicity can affect seismic hazard in the territory under study. According to the computer program, three different models can be used for seismic source zones: point, linear and area source models. We have used linear and zone models, as we assume this is more reasonable from the point of view of earthquake source mechanics. For each seismic source zone, the seismic rate of earthquakes above the threshold magnitude was estimated. The above noted b values and M max were used for calculating of seismic rate of each magnitude range (from M threshold =2.8 to M max by steps of 0.3 units)."}, {"section_title": "What is Emergency Planning?", "text": "To begin with, several contexts and time-frames are involved (Figure 2). Permanent emergency planning involves creating a master document that must continually be updated and tested. When a crisis is imminent, and there is sufficient forewarning to make advance preparations, contingency planning can be invoked in order to ensure that the preparations are effective, roles and competencies are assigned, and resources are positioned. Finally, when an emergency occurs or disaster strikes, strategic and tactical planning can be used to allocate resources, form task forces, assign tasks, and guarantee the efficient use of resources according to peculiarities and changes in the evolving situation. 2 The following account will concentrate on permanent emergency planning, as this is the dominant form, and as it gives shape and direction to both emergency operations and the other forms of planning. Emergency planning should be a process, rather than an end in its own right. The plan should be a living document that is given frequent attention in order to ensure that it is efficiently maintained, updated, improved and disseminated. While a single authority should take charge of the plan, it should be considered the common property of all participant organisations and their members, who should all be responsible for contributing to it and drawing attention for the need to updates. In the modern age an emergency plan should be generic, which means that it should be adaptable to the widest possible range of hazards and threats. The creation of a plan for any single hazard runs the risk, first that the next event may be something entirely different, and secondly that multiple hazards (for example, an earthquake that causes a flood by breaching a dam) may require the activation of separate plans that create more conflict than harmony in the relief operations. Generic plans should have a set of simple, robust provisions that can be activated when unpredictable events occur as well as chapters devoted to the predictable hazards that threaten the area of its jurisdiction. Thus the plan for a city located on flat land around a major river should have a chapter that deals with the response to flooding, while a city located in a seismic zone should have one or more chapters on the response to earthquakes. In these, ample use should be made of scenarios, as argued in the next section. The four elements of emergency management are planning, procedures, protocols and improvisation. Logically, if a particular need can be foreseen in advance of an emergency situation, it should be provided for in prior plans and procedures, rather than tackled by improvising a response during the heat of the crisis, which is unlikely to lead to maximum efficiency. As all emergencies contain an element of uniqueness, improvisation cannot entirely be ruled out, but it should be reduced to a necessary minimum, as any excess above this is a sign of inefficiency in prior preparedness. A good analogy is to regard procedures as the scores used by individual musicians and the plan as the written music for the entire orchestra that enables it to play a symphony in a fully co-ordinated, harmonious way. Whereas procedures should specify how actions are performed, and protocols should provide guidelines and rules for action, an emergency plan should be a set of specifications that determines how participants and the organisations to which they pertain share and divide up responsibilities, apportion tasks and interact in particular emergency situations. The plan is thus the blueprint for action, but it should always be focussed on the general perspective of operations (i.e. the management and integration of forces) and leave the specific details of how they are carried out to the procedures. There is a distinct difference between plans, procedures and protocols. An emergency procedure is a specification of how to carry out certain actions in order to respond to the crisis. Typically, procedures are designed at the level of particular organisations, agencies and units. There is a hierarchy of decision making that extends from the political and ethical level through the strategic, tactical and operational levels. Procedures tend to be tactical and operational, whereas emergency plans should contain elements of strategic thinking. In fact, one of the most important functions of an emergency plan is to predispose conditions so that organisations work efficiently together. This is a particularly acute need when the organisations are not used to collaborating, or at least not under the unusual conditions that prevail during emergencies. Emergency protocols are agreements on common procedures, for example in search and rescue, communications, mutual aid and decision making. It is worth remembering General Eisenhower's famous observation that \"plans are worthless but planning is indispensable\". Interpreted in modern civil protection terms, this means that not all elements of the emergency can be predicted, but those that can be foreseen should be treated in such a way as to provide the guidelines and mental orientation for the rational, adaptive management of any particular emergency situation. In broad, general terms, emergency planning must integrate the work of different organisations, levels of administration and jurisdictions. A very significant part of the problem is geographical, and is a question of ensuring that resources are in the right place at the right time. This is one of the reasons why emergency planning tends to be analogous to urban and regional planning. First, there are the direct connections--refuge and assembly areas, evacuation routes, and so on--which must be worked out on a territorial basis. Secondly, both disciplines require study of local conditions, including the cultural and urban geography, connectivity and economic conditions of the area of jurisdiction. Thirdly, both processes are prescriptive and require periodic revision to cope with changed circumstances. At the world scale it is surprising how little connection is usually made between urban planning and emergency planning. It has frequently been observed [2,3] that there would be distinct advantages in making the two processes compatible. These include interdiction on the urbanisation of dangerous areas, maintenance of lifelines and vital routeways, and advance preparation of areas to receive post-disaster shelter. "}, {"section_title": "Scenario Construction as the Basis of Emergency Planning", "text": "The Oxford English Dictionary defines 'scenario' as \"a postulated sequence of imagined (usually future) events\". Some of the least effective emergency plans are mere collections of generic procedures. Plans should instead be firmly based on scenarios of what is likely to happen in the areas which they cover. If an event can be foreseen to any extent, then it should be, as this will enable resources to be readied in the most effective and efficient manner. Generic procedures can be used for events that are unpredictable. However, most emergencies follow a pattern: the geographical and temporal distributions of natural hazards are generally known, and in some areas there is considerable scientific expertise on return periods, magnitudes, extents and physical consequences of floods, earthquakes, hurricanes and so on. Patterns can also be observed in industrial accidents, transportation crashes, episodes of chronic pollution and terrorism outrages, although the last of these is perhaps the most difficult to foresee. There are several justifications for basing plans on scenarios of what is likely to happen: If a contingency can be foreseen, it should be, as failure to make provision for predictable needs could be construed as negligence. Most natural hazards, and some anthropogenic ones, are repetitive and occur in definable geographical areas. Although the magnitude, distribution, recurrence interval and effects of such events cannot be foreseen with absolute precision, usually the scientific basis of prediction is sufficiently clear to enable contingency plans to be made. One of the principal tasks of an emergency plan is to match urgent needs with available resources. This can only be done efficiently if some attempt is made to foresee these needs and prepare in advance to match them. Finally, the creation of scenarios for known hazards can help one to explore the consequences of impacts and response actions. There may be subtle ramifications and implications that nonetheless will have serious consequences if they are not tackled. When creating an emergency plan for a specific geographical area the first task is to assess the hazards that are present in the local territory. Ideally, a process of microzonation should be used in order to gain a synoptic vision of the \"hazardousness of place\"--i.e. the collocation of the potential impact of different hazards at significant locations throughout the jurisdiction covered by the plan [4]. If the dominant hazard is, for example, seismic, then a scenario should be constructed for the impact of an earthquake [5]. Scenarios should also be constructed for other significant hazards in the area wherever these can be foreseen. The basis of the scenario should be a reference event. Most natural hazards are recurrent, and those of meteorological origin tend to be cyclical, perhaps seasonal. Earthquakes and other geological hazards are also recurrent, but for volcanic eruptions the cycles can be long enough to defy integration with the periods of validity of emergency plans. For a considerable number of years there has been a significant debate concerning what size of event to plan for [6]. The magnitude-frequency rule tells us that small events tend to be frequent while large ones are rare. It is not feasible to tie up resources in planning to meet the needs generated by a very large event with a recurrence interval of perhaps once in a millennium. On the other hand, if plans are tailored to events that occur annually or biennially, they may prove inadequate when an In many cases, the reference event is predetermined by the past history of hazards in the local area. For instance, although the last major earthquake may not necessarily be representative of the next one, it may be the only such event for which data are available on the physical magnitude and social consequences. In the social category it is worth noting that not all hazardous events are disasters. In the case of a mass gathering or demonstration the objective may be to prevent harm and keep the participants secure, but the event must be planned for and managed in the same way that it would be if it were a disaster. The planning scenario should consist of a systematic, logical exploration of what is likely to happen in a major event and what arrangements are needed in order to manage it. When constructing the scenario it is appropriate to use the formal logic of systems theory in order to ensure a modicum of rigour (Figure 3). The reference event is taken as the starting point and adapted to current conditions in the local area. The scenario is taken forward on the basis of a logical unfolding of what is likely to happen in such an event. It is usually appropriate to consider the scenario as a form of simulation and to run it for several sets of circumstances, such as daytime and night-time, a working day and a holiday, and so on. The scenario used for emergency planning should be significantly different from the analogous product created by members of the scientific community. Their aims are usually to explain the pattern of impacts in physical terms, although increasingly they may make reference to vulnerability. The emergency planner needs to use the scenario to gain an idea of where physical impacts are likely to occur, and where they will be most highly concentrated, as well as how they will interact with the vulnerability of human systems and the built environment. However, he or she particularly needs to know how impacts will generate the need for particular resources and forms of organisation. Hence the emergency planning scenario should progress from physical impact to human vulnerability, and thereafter to matters of emergency response. The main aim is to anticipate the needs and problems associated with the provision of assistance in foreseeable emergency situations. In this context one of the most basic considerations is to ensure that emergency resources are not put at risk: for example, that operations centres and assembly areas are not floodable, or are not threatened by structural collapse, and vital routeways remain functional or alternative routes can be found. The sequel to the construction of emergency scenarios is to conduct a resource audit (Figure 4) [7]. In simple terms, emergency resources can be subdivided into manpower (including specialist professionals), vehicles, supplies (including fuel for vehicles), equipment, services, institutions and organisations (including the associated physical infrastructure). These resources can usually be supplemented by additions from other levels of organisation (e.g. supplied by regional and national government to local authorities), from military forces, and through mutual aid pacts. The latter involve some delicate problems that must be sorted out well before emergencies occur. No authority likes to commit its own resources if it is likely to be left without cover should the emergency spread. Moreover, there are questions of who pays for mutual assistance and sometimes also of legal liability in 'foreign' jurisdictions. These can be sorted out by careful negotiation. In some cases it is appropriate to set up a multilateral conference for mutual aid rather than formulate bilateral agreements. This may spread the load with respect to commitments. There are five particular drawbacks to the use of scenarios for planning emergency response: 1. Chains of causality. In the highly complex environments of the modern world the interaction of natural and technological hazards can lead to long series of interactions between risks and effects. For example, the effect of the January 1995 earthquake on the port of Kobe in Japan was not merely a question of seismic damage but led to loss of competitivity, economic decline and loss of jobs. 2. Interaction between hazards and risks. For example, the safety of a reservoir dam may be affected by a range of potential interactions between earthquakes, floods, landslides and snow avalanches. Overtopping of the dam, and consequent flooding, could occur if a water wave is caused by a seismicallyactivated fall of rock debris. 3. Secondary hazards. For instance, seismic damage to a factory may cause toxic leakages, fires, risks of explosion or dangerous malfunctions of machinery. If the building has been constructed according to anti-seismic principles, the consequent hazards may be more serious than earthquake damage itself. The solution is to include fault trees in industrial emergency plans. 4. Collateral vulnerability. Some effects of hazards and disasters can be very subtle. In the case of a terrorist attack, for example, economic vulnerability may be greatest with respect to the disruption caused and the public's negative perceptions of particular places rather than the direct effects of the attack. 5. Coincidence. Although it is technically impossible to plan for, coincidence plays a significant and consistent role in certain kinds of disaster, notably transportation crashes. Despite the difficulty of taking these five problems into consideration when constructing a scenario, much can be achieved with the careful use of imagination. It teaches us, for example, not to ignore the plight of prisoners, pets and farm animals in disaster [8]. It induces us to consider in detail the aggregate patterns of human activity, both of the routine kind, as interrupted by crisis, and in emergency mode."}, {"section_title": "Creating an Emergency Plan", "text": "The emergency planning procedure can be subdivided into five parts. The first is research, in which the raw material of the plan is collected through study and the accumulation of data. This will involve close liaison with the scientific community and all who are responsible for monitoring hazardous phenomena. In the writing phase, a draft is created of the plan and its annexes and appendices. Here, the level of detail is critical. As a rule the plan itself should not be so complex that the details obscure the overall architecture. Hence a tripartite plan is recommended: in the main document the broad pattern of arrangements should be clear. Details and procedures should go into annexes and appendices. Finally, it is often useful to have summaries (as posters or laminated cards) to act as an aide memoire for the provisions of the plan. The third phase involves publicity, or the dissemination of the plan to its potential users. In general, emergency plans should be energetically publicised. It is vital that the users feel they have a stake in the plan and appreciate their role in it. Currently, there is a debate about the levels of secrecy in emergency planning. Secrecy has been promoted by the counter-terrorism lobby under the assumption that making the provisions of an emergency plan public will expose civil protection organisations to attack. In this context it is true that terrorists have used double bombs and booby traps to create mayhem among rescue forces, but despite that, there is no evidence that terrorists have actively studied emergency plans in order to refine their strategies. In fact, such is not necessary. Secrecy easily becomes a cloak for malpractice, as if the provisions of the plan cannot be disclosed, then it is difficult to detect negligence and inefficiency. There are legal, institutional and ethical questions regarding confidentiality in emergency planning, so the issue is not a simple one. However, in general the more people are aware of the provisions of an emergency plan, and the more they know about them, the more likely it will be that there is a good response to the emergency. People, especially members of the public, do not make informed, rational decisions appropriately in the absence of vital information about what to do. Hence, we can regard emergency planning as a socially inclusive process. The fourth phase is operational. Plans need to be tested with field and table-top simulation exercises. At the very least, a panel of experts needs to evaluate the provisions of a plan. In the fifth and last phase, the plan needs to be updated frequently. It is a good idea to build a mechanism for periodic revision into the plan itself so that the process becomes routine. Many changes will occur in institutional arrangements and the urban environment. Knowledge of hazards will increase, and patterns of vulnerability will change. A plan that has not been adapted to these needs is dangerous, as it may lead automatically to malfunctioning in relief efforts, for example after changes in personnel, telephone numbers and equipment."}, {"section_title": "Integration and Sustainability of Emergency Plans", "text": "The bedrock level of emergency planning is the local authority level, for this is always the theatre of operations, no matter how large the emergency is [9]. The role of assistance imported into a disaster area should be to support and augment local efforts and resources, not supplant them, as that would lead to weakening of the local response. Hence, the local emergency plan is very much the point of reference for other types of contingency planning. Furthermore, the municipal civil protection and emergency operations centre is the logical home of such a plan. Other plans should use the local authority as the leading point of reference ( Figure 5). As emergency plans are analogous to the orchestral conductor's score, they must seek to integrate the actions of different services, functions, jurisdictions and levels in the hierarchies of command and public administration. Moreover, they must be compatible with legislation, not only in the emergency management field, but also in other areas, such as health and safety at work and environmental protection. In public administration, plans, like services, are usually arranged in hierarchies from national down to the local levels, with cascading flows of command, control and information sharing [10]. Compatibility can be a thorny problem, but fortunately it is often merely a question of making a comparative study of the different instruments in order to ensure that inconsistencies are eliminated or at least minimised. The compatibility of plans is crucial to ensuring that emergency response work can be carried out in harmony between the organisations charged with it, which in large disasters may be very numerous. Standardisation is important here and the 2000s are a period in which standards are beginning to appear with increasing frequency [11,12]. If they are well constructed, standards can facilitate compatibility and interoperability; if they are not, they can obstruct these qualities. The questions of integration and standardisation go hand in hand with sustainability. While the last of these is well-established in environmental thinking, it is not so common in emergency management [13]. However, let us remember that progress can be negative as well as positive, especially if sources of funding and political support dry up and policies are allowed to lapse. In essence sustainable emergency management has the following qualities. It is: based on plans and planning, well-rooted at the municipal level (probably as a direct responsibility of the mayor or other municipal chief executive), supported by the local population, democratic in its aims and methods, it is capable of acquiring a proven record of solving crisis-related problems, and treated as a fundamental and essential public service. Each of these attributes is a form of insurance against reversal of progress and in favour of increasing safety and security. Finally, emergency planning can be applied to the community level [14]. It was estimated that in the Kobe (Japan) earthquake of 1995 between 70 and 90 per cent of 30,000 people rescued from the rubble and flames of the city were brought out by local people. In areas of high hazard is imperative that the public be involved in disaster preparedness, and hence also in planning, and preferably at the neighbourhood level [15,16]. It is also important that plans cover the activities of volunteer groups. The level of voluntarism varies from country to country, and so does the degree of organisation, training and equipment of volunteer groups and associations [17]."}, {"section_title": "D. Alexander / Principles of Emergency Planning: Standardisation, Integration and Sustainability 171", "text": "However, in many countries volunteer groups are an indispensable part of the civil protection system and hence must be covered by emergency action plans."}, {"section_title": "How Post-Disaster Reconstruction Works", "text": "The immediate goals of recovery are to restore the area's economic functions and to replace lost housing. Human settlements are places where people live and work, and, when those systems are disrupted, homes and livelihoods need to be restored as quickly as possible. The central value of recovery is money: a city is expensive to build, and it is equally expensive-and especially challenging-to rebuild it all at once. The recovery process, then, is a battle for scarce financial resources, between various entities and their competing agendas. The planning process is a means of managing these competing interests and attempting to spend the funds as efficiently, equitably, and effectively as possible. The main challenge of recovery is time. Even if sufficient funds are available, rapidly rebuilding a city that took years to evolve is difficult. The challenges are both physical and social. The physical act of reconstruction -gathering materials, designing, and building-takes time to accomplish. But it also involves organizing (and sometimes training) labor. Furthermore, people need to pursue their livelihoods and occupy temporary homes while all this is transpiring. Finally, the post-disaster environment is stressful for individuals, families, and organizations. During and after disasters people lose family members, homes, jobs, and social networks. They have financial problems, mental health problems, and short tempers. Thus, the constraint of time poses challenges for recovery in innumerable ways. Thus, urban planning -difficult to accomplish even in normal times, with competing demands for resources, disputes between neighbors, environmental constraints, and insufficient funds-is even more difficult under the time and financial stresses following disasters. Post-disaster recovery can be viewed as a problem of management under stress. Research shows that bureaucratic government organizations are poorly suited to the stresses of post-disaster recovery. Bureaucratic procedures are too slow and inflexible, and recovery requires organizations to be nimble and creative. As a result, new organizations always emerge following disasters -both neighborhood organizations and community-wide nonprofits-and they are, in fact, critical to the success of a recovery process. The most appropriate role of government is to encourage and support such organizations, sometimes by means of creating new governmental entities to facilitate coordination and cooperation."}, {"section_title": "Opportunities for Betterment", "text": "Despite all the challenges and stresses of post-disaster recovery, human societies always strive for improvement, even after terrible calamities. After every disaster I have studied, virtually everyone poses the question, \"If we are going to so much trouble and expense to rebuild, why should we simply reproduce what we had before? Why can't we build something better?\" Indeed, post-disaster reconstruction provides a great opportunity to improve buildings and infrastructure, correct economic inequities, reinvent governance, and modernize economies. In particular, following a natural disaster, the most obvious improvement would be to minimize the chances of a similar disaster when the next flood, earthquake, or other natural force strikes again. This could be by means of building resistant buildings, elevating buildings above expected flood levels, rearranging land uses within a community, or relocating settlements to safer locations. Indeed, improvements always occur in post-disaster reconstruction. Although research shows that cities tend to rebuild themselves much as they were before the disaster [5], disasters always result in some physical changes to the urban environment. Catastrophic disasters can obliterate entire cities or districts, and cities change after disasters, often for the better. But significant change is difficult to achieve, because the political and administrative environments resist it, and because the historic evolution of the city reflects the deep-seated desires of its inhabitants. Still, physical changes do occur -usually in limited parts of a city-and they sometimes are able to bring about social and economic improvements. The challenge for planners is to learn how to maximize the limited opportunity for positive post-disaster change."}, {"section_title": "Obstacles to Mitigation", "text": "It is tempting to think of a disaster-affected community as a \"blank slate\" upon which a new, improved, disaster-resistant community can arise, under the guidance of rational planning. In fact, actual post-disaster situations are much more complex, and, although there are forces that facilitate the opportunity for positive change, there are at least an equal number of countervailing forces resisting such change. First, a disaster-affected community is never a blank slate. Even if the land is swept clean of human improvements, it still contains property boundaries and memories of people's lives. In people's minds, everything is still there as it was before. For example, in Banda Aceh, after the 2004 tsunami washed away entire towns, community planning processes enabled neighbors to negotiate in order to jointly agree where their vanished property boundaries should be re-established. [6] R.B. Olshansky / The Challenges of Planning for Post-Disaster Recovery 177 Second, disaster victims are traumatized. Their lives have already been changed, and most yearn to regain approximately what they had before. Although in principle they would agree that some form of improvement is desirable, most victims are eager to rebuild their homes and communities as they were before. Furthermore, most forms of betterment involve either changes in construction technology or changes in physical layout of the community, either of which would require residents to change accustomed practices. Third, completely re-planning a community is difficult to do after a disaster. Planning to make significant change in a community requires considerable data, widespread stakeholder involvement, and time. To the extent that a community has plans in place beforehand, however, post-disaster change is more feasible. Fourth, rational planning, focused on a limited set of issues (such as mitigation) is not readily possible. The notion of planning as a science, exercised by experts, has become obsolete, as we now appreciate the ways in which collective decisions are actually made. Certainly, a dictatorship could declare that all floodplain residents must move, but such an action would come with great social costs. Significant mitigation actions are difficult to accomplish after a disaster, for all the above reasons. Paradoxically, however, mitigation is often easier to accomplish after a disaster has occurred than prior to disaster. This is because awareness of the risk is at a peak shortly after a disaster, opening a \"window of opportunity\" for change [7,8]. In practice, some changes -including mitigation-occur after disasters; and, although mitigation may be easiest to perform after disasters, it is still difficult to accomplish on a significant scale."}, {"section_title": "Relocation as a Form of Mitigation", "text": "One of the most obvious means of physical mitigation after a natural disaster is relocation: out of floodplains, away from coastal high hazard areas, or off of unstable hillslopes. But it is also extremely difficult to accomplish. It is impossible to successfully relocate communities without the voluntary involvement of residents. Even with their participation, however, it is highly difficult to do. Individuals are reluctant to move, and such moves are also disruptive of social networks and economic livelihoods. In many cases, livelihoods depend on the hazardous location. For example, after the 2004 Indian Ocean tsunami, coastal settlements in Tamilnadu, India, have been relocated approximately one kilometer inland. However, these fishing communities depend on proximity to the sea. As a result, most residents have maintained their coastal homes and chosen not to move to the new communities [9]. Arguably, being separated from beach access poses a higher risk to the health of individuals and of the community than does a potential tsunami or cyclone. In New Orleans, shortly after Hurricane Katrina flooded 80% of the city in 2005, preliminary plans called for relocating residents out of the lowest parts of the city [10,11]. But residents rebelled, because their homes had been in these areas for generations. Furthermore, most of these were low-income, African-American neighborhoods, and they claimed that powerful Anglo business leaders were trying to drive them out of the city. As a result, scattered rebuilding is going on throughout the city, some of it elevated above flood levels. Along with strengthened levees, the city is now incrementally safer than it was before. From a physical planning point of view, this is not an ideal solution, but it is the best solution that is consistent with the social needs of the community."}, {"section_title": "How to Maximize Opportunities for Post-Disaster Improvement", "text": "At the heart of the recovery process is the tension between speed and deliberation: the need to rebuild housing and jobs as quickly as possible competes with the need to carefully plan the renewed communities so they can be better and safer places. There is no perfect answer to managing this tension, but experiences from recent disasters provide some insights. Although it is difficult to accomplish betterment (and, specifically, mitigation) after disasters, some improvements always occur, albeit always less than proponents hoped for. The challenge is to find ways to increase the chances for such improvements. Following are some principles on how to optimally manage recovery and reconstruction processes, based on recent research by the author and colleagues."}, {"section_title": "Create New Institutions to Use Information to Coordinate Recovery Actions", "text": "Recovery is a fast-paced process, with many actors simultaneously making decisions in an information-poor environment. The best way to help this process to move quickly and make informed decisions is to create new institutions, or adapt existing institutions, to collect, maintain, and distribute information. Such information could include: damage assessment, costs, sources of financing, physical progress of reconstruction, and actions taken by various recovery entities. The best way to coordinate recovery actions is to provide actors with sufficient information about all the other recovery actors. Communication is critical, in order to facilitate both speed and deliberation. Organizations need to share information and brainstorm collectively. For example, councils of recovery agencies can meet regularly to exchange information. This should include both governmental and nongovernmental organizations. Governments also can establish information clearinghouses readily accessible by agencies actively involved in recovery activities. Stated another way, intelligent, information-rich systems, can lead to more intelligent decisions. If local institutions are overwhelmed, then higher levels of government (or outside assistance) can help to create such communication mechanisms or coordinating institutions. Communication is not just needed for recovery agencies, but is also important for the most common type of recovery actor: individuals. Individual residents, property owners, and business owners need to be as well informed as possible so that they can make intelligent decisions regarding when and how to rebuild. In the absence of information, and under the stress of the post-disaster environment, rumors of the worst sort (and of people's worst fears) can fill the information vacuum: rumors of developers coming to take individuals' property, of bank failures, of dangerous ethnic groups, of evil government agents. Thus it is critical to provide honest, trustworthy information and to quickly counteract rumors before they spread. "}, {"section_title": "Remove Restrictions and Encourage Flexibility", "text": "Bureaucratic procedures have great value in normal times, but they can be impediments to post-disaster recovery. Existing programs for urban redevelopment can be convenient starting points, but to be effective for post-disaster reconstruction, they need to be streamlined. This can be done by creating post-disaster procedures before a disaster occurs. Alternatively, a recovery coordinator can be empowered to reduce \"red tape\" in order to facilitate reconstruction appropriate to the situation. In general, new post-disaster organizations should be designed to be flexible, and staff should be rewarded for innovation and creativity."}, {"section_title": "Don't Stop Building in Order to Plan", "text": "Planning is vital, in order to ensure efficiency, equity, and public safety. But if it takes too long, it will be ineffective, because individuals start to rebuild on their own. Haas et al [3] tell the story of Managua, where downtown rebuilding was halted until a plan could be completed. But when the plan was done, the functions of downtown had been already reconstructed elsewhere, leaving the old downtown as an empty shell of its former self. The solution is to plan and build at the same time. Individual agencies will concentrate on rebuilding as quickly as they can. If an effective communication mechanism is in place, as described above, they can coordinate in real time. Such a system will maximize the chances of all the agencies achieving as many of their goals as possible. Each agency will have its own plan. To the extent that each can be aware of the others' plans, each will be more effective. Previously existing plans can greatly reduce post-disaster conflicts and uncertainties. The existence of community consensus regarding difficult issues will ease post-disaster decision-making. In particular, if a community has resolved mitigation goals -such as relocation policies and procedures-ahead of time, it can more easily implement them after a disaster."}, {"section_title": "Use Extensive Public Involvement, Especially for Housing Recovery", "text": "Housing recovery involves rebuilding, redesigning, or relocating people's homes. In order to do so, broad public participation is vital. Those who participate in housing reconstruction are more likely to be satisfied with their homes, live in their new homes, not migrate elsewhere, and not protest or cause political discomfort for officials. If relocation is needed, research shows that people will not move unless they are involved in the decision to move and in the design of their new homes [9,12]."}, {"section_title": "Build Equity into the Recovery Process from the Start", "text": "Those who are better integrated into economic and social networks will recover faster. Conversely, those with the fewest resources get less attention from aid organizations, and get it later in time. This means that the smallest businesses and the lowest-income residents-those least well equipped to survive for a few months without homes or businesses-are the last to be helped, unless proactive measures to help them are in place. A recovery process that leaves these populations even further behind undermines the goal of post-disaster improvement. Furthermore, those with the least R.B. Olshansky / The Challenges of Planning for Post-Disaster Recovery 180 resources are often those who are most vulnerable to disaster -in unsafe buildings, in unsafe locations, in marginal health, and with fewer resources to aid their survival. Thus, promoting equitable recovery is also one of the most effective strategies to increase mitigation."}, {"section_title": "Concluding Remarks", "text": "Post-disaster recovery is a complex social, economic, and political process. In some ways it provides opportunities for hazard mitigation and social and physical betterment. But many characteristics of the post-disaster environment impede intelligent planning and community improvement. Improved understanding of how recovery actually occurs can help to guide us in maximizing the chances for achieving betterment after future disasters."}, {"section_title": "The Switch Approach to Ecological Cities", "text": "UNESCO-IHE carries out a European Union supported 'Switch' project on ecological cities, where sustainability is defined as the process and the ecological city as the result. Global changes such as climate change, urbanization and industrialization, population growth, urban sprawl, and rural-urban migration put pressure on cities. A sustainable urban water system is a basic feature of an ecological city, but is it enough? Box 1 gives a broader concept of a sustainable city. Kenworthy [3] lists ten dimensions for sustainable city development in the Third World, which give a good impression of the issues at stake. His list is very comprehensive, however, and expresses a preoccupation with transport and roads. Kenworthy [3] considers that a sustainable city is characterized by: A compact, mixed urban form protects the natural environment, biodiversity and food-producing areas. The natural environment permeates the city's spaces and embraces the city, while the city and its hinterland provide a major proportion of its food needs. Freeway and road infrastructure is de-emphasized in favor of transit, walking and cycling infrastructure, with a special emphasis on rail. Car and motorcycle use are minimized. There is extensive use of environmental technologies for water, energy and waste management -the city's life support systems become closed loop systems. The central city and sub-centres within the city are human centres that emphasize access and circulation by modes of transport other than the automobile, and absorb a high proportion of employment and residential growth. The city has a high quality public culture, community, equity and good governance. The public realm includes the entire transit system and all the environments associated with it. The physical structure and urban design of the city, especially its public environments are highly legible, permeable, robust, varied, rich, and visually appropriate and personalized for human needs. The economic performance of the city and employment creation is maximized through innovation, creativity and the uniqueness of the local environment, culture and history, as well as the high environmental and social quality of the city's public environments. Planning for the future of the city is a visionary debate and decide process, not a predict and provide computer-driven process. All decision-making is sustainability-based, integrating social, economic, environmental and cultural considerations as well as compact, transit-oriented urban form principles. Such decision-making processes are democratic, inclusive, empowering and engendering of hope. The Switch project intends to improve water governance and to translate scientific innovations into improvements of day-to-day management of urban water and sanitation. The approach is very much focused on closing the urban water cycle (see Figure 1), defined as the link between the resource, its use for drinking water and the eventual reuse to allow the water to flow back into the resource. The innovation in this project is that learning alliances are set up in the cities concerned. This group of interested citizens, officials and researchers functions as a platform where strategic directions for research are identified and the results discussed. The strategic directions for Accra -to let it develop towards a more ecological city-, were identified and their content is currently determined by the researchers and some members of the learning alliance. What is needed is adaptive water management in cities, integrated in existing urban governance structures. Such adaptive management methods can use the tools for urban management listed in [4]. It would allow managing the transition to adaptive water management as argued for example by the Newater project 2 . This EU funded interdisciplinary project developed new methods for Integrated Water Resources Management (IWRM), taking into account the complexity of the issues to be managed and the influence of factors like climate change. The project argues that a transition is necessary from the currently more rigid regimes of water management to more integrated, adaptive approaches of river basin management to be able to cope with increasing uncertainties generated for example by climate change. The Switch program intends to generate new efficiencies from an integration of actions across the urban water cycle in order to improve the quality of life in cities. 3 It also promotes urban agriculture projects, as part of the integrated approach to water use and reuse. The Switch approach has three characteristics: It relates storm water to drinking water and water treatment It emphasizes a more ecological approach, and It emphasizes a more integrated approach to the different water related issues. Integration could take place in the framework of urban management. Issues discussed in [4] are the integration of the different sectoral interests, the role of planning and management, the importance of economic, financial, social and environmental criteria (and how to combine them), who are the decision makers, and how do we deal with the strict and the loose meaning of sustainable urbanization. In the strict sense it would mean that no resources can be used up which can not be renewed. In the weak sense they can be used if alternatives are developed (solar energy, or alternative building materials for example). Part of the Switch research is in developed and part in developing countries. If we compare the problems of Third World versus western cities we note that in the context of a Third World city a number of additional factors are contributing, which make the solution of some issues more difficult. In western cities the political system may help to find the solutions, by changing the guards regularly through elections and because of a solid revenue basis. Also local networks of NGOs, businesses and government may have achieved certain robustness. In a Third World context such an approach is more complicated because of the acuteness of problems like pollution, rapid urbanization and social and economic inequality, in a situation where the governance structure is often not fully developed and decentralization has been introduced only recently and partially. Ecological initiatives can be adopted at three levels. In the first place at the level of the city and, secondly, we find all kinds of ecological neighborhoods jumping up. Finally, individual initiatives can be identified, spontaneously or triggered by incentives or price increases. There are a number of Chinese eco-city initiatives at the city level, which are summarized in Box 2. Box 2. Chinese eco-city initiatives. There is a large number of similar initiatives, ranging from introducing simple water and sanitation technologies for the western part of the country (through a project financed by The Netherlands) to sophisticated ecological projects in the framework of the Olympic Games in Beijing in 2008. Shanghai plans to build -on an island at the mouth of China's Yangtze river-the city of the future (The Economist 23-9-2006 and Financial Times 15-9-2006). The idea is that the city will be self-sufficient in energy and water and will generate almost no carbon emissions. Petrol and diesel vehicles will be banned in favor of solar-powered boats and fuel-cell-driven buses, according to The Economist. The city should count around 500,000 inhabitants in 2040 and will also house an agro park of 27 km 2 to grow food in a sustainable way 4 . Finally, the Financial Times describes the energy conservation at the household level and the use of water conservation (rain water harvesting), and indicates that houses will use only one third of the energy consumed by a normal house, while the energy will be renewable, for example through wind mills. The project receives a lot of attention and press coverage, but the question is what happens to diminish pollution in the neighboring Shanghai city, with 20 million inhabitants and a lot of polluting industries. The Chinese authorities have a preference for large modern high tech solutions; even if they know they cannot always manage the technology properly. They are less willing to pay for management support, training or software; while, given the high energy use per unit of Gross Domestic Product (GDP) and the huge water consumption per capita, there is scope for improvement of the system efficiency through better management. Other initiatives at the neighborhood level are illustrated in Box 3. The Wuhan project concerns ten 8-floor buildings high. The project would receive a 30 percent subsidy if energy saving techniques are to be used. One of the conditions was that the project would include grey water recycling. Energy saving is based on doubleglazing and the use of underground (or geothermal) heat pumps. The system uses pipes absorbing the latent heat from the ground and transferring it to the central heating and hot water system. The Taiyue-Jinhe (Tai) project consists of an ecological residential area with low energy consumption and a water recycling system. It is located in Jinyin Hu district, a suburb of Wuhan. Because there are two big lakes: Jin lake and Yin lake, the district is called Jinyin Hu (meaning lake). The Jinyin Hu district was an agricultural district 20 years ago, which mainly produced rice. Presently, the Jinyin Hu district has been developed as a residential area and an ecological park. The Tai project falls under the \"China 10 energy saving program\" promoting energy saving measures and buildings with greywater recycling systems. This program is coordinated by the Chinese ministry of construction. The same ministry issues permissions to build the water recycling system. The Tai project began in 2006 and the residential buildings were completed and sold in 2007. However the water recycling system has not yet been completed. In total, the Tai project covers an area of 6970 m 2 with 1162 households and around 3253 residents. All buildings are equipped with energy saving facilities. Half of the area is designed for residential buildings, green areas and a lake, which account for 35%. Due to financial problems only 10 buildings have water recycling systems, serving 228 households and around 1140 people."}, {"section_title": "Achieving sustainable urban development", "text": "Sustainable development is a normative concept. In 1987 the World Commission on Environment and Development of the United Nations provided a definition of sustainability that is still often used. Brundtland [6] defines sustainable development as the development that meets the needs of the present generation without compromising the needs of future generations 5 . Achieving sustainable urban development may also be phrased in terms of considering water and sanitation as an integral part of urban infrastructure planning. The Switch vision emphasizes unique aspects, briefly explained below: A systemic approach in terms of interrelated components (system engineering), The emphasis on a more ecological approach to sustainable urbanization, and The emphasis on a more integrated approach to different water related issues. Part of the first approach would be developing indicators to constantly monitor where we are regarding the aquatic urban environment, and to take corrective actions if certain variables reach threshold levels. Modelling the system and emphasizing decision support systems is inherent to this vision, highlighting the interrelated nature of these issues. A more ecological approach to sustainable urbanization implies moving from traditional environmental technologies to more ecosan options (sanitary solutions with ecological characteristics) in the ecological city of the future [8]. It will be necessary to also focus more research on the topic of ecological cities, to study certain phases in the process of becoming more environmentally conscious and how to interest some of the major urban actors in these issues. However, the importance of a coordinating role of local governments and urban managers should not be underestimated. In fact it is their task to coordinate a multiplicity of actors. Such is the essence of urban management: participatory, inclusive and with all actors concerned with objectives such as promoting equality, protecting the environment and stimulating economic development. Concerning a more integrated approach to urban management, it needs to be clear what will be integrated, how and by whom. Integrated urban water management (IUWM) can be achieved in each of the Switch cities if we work towards a plan. Urban management should help to take steps towards more ecological cities. Our definition of a more ecological approach to urban development would be a strategy combining: Integrated water resources management: closing the water cycle, Energy management, reducing the greenhouse gases, Waste minimization and integrated waste management, Integrated transport policies, Justice and equality, and Integration in the framework of urban management, while also managing the urban risks. There are definitional problems with sustainability as shown in the literature [9]. One can find very idealistic, sectoral, or issue-based definitions of ecological cities, and sometimes values play a role, such as in the case of the distributional issue: should priority be given to achieving urban sustainability or to stimulating rural development?"}, {"section_title": "A Classification of Risks", "text": "There are different kinds of risks for cities and they have been classified in different ways. In this contribution we will identify some of the major risks cities are involved in, and identify strategies to deal with these risks. A distinction should be made between collective and individual risks. If one builds a house in a low lying area one runs an individual risk of inundation, independently from the collective risks of flooding, which applies for that region. The risk may be high, but the impact of an individual case may be relatively small. The risk for the collective neighborhood or city may be small, but the impact (the total damage) may be huge. For that reason in The Netherlands house owners are not encouraged to build in low lying areas, however the collective risk be small with a 100-year return period.  Table 1 provides some examples of risks for cities in the Third World and how they could deal with these risks. There are several instruments for dealing with risks, also in most developing countries: Capacity building is important: adjustment of training methods to the new needs of the water industry, Support water supply schemes through both the Poverty Reduction Strategy Paper (PRSP) and a multi-sector decentralised infrastructure fund, Municipal strategies concerning access to drinking water and sanitation for all, Set up a Water Resources Development Fund to facilitate decentralisation reform Use micro credit to finance water connections: to organize micro savings and to provide micro loans to connect people to drinking, and Improve urban service delivery. Looking at urban water supply, flooding and sanitation usually requires reforms in the sectors concerned in order to reduce the risks. There is no blueprint, but there is certainly a menu for reforms. Table 2 summarizes suggested reforms for water utilities, as an agenda, allowing the choice of relevant combinations of improvements. The challenge is to find the best combination of reforms, fitting the local situation and addressing the pertinent issues in that particular city. Depending on the local situation a combination of these measures would have to be selected as the appropriate answer to the issue. In the table a distinction is made between improved internal functioning and efforts made to improve the relations with customers, suppliers and different levels of government. Some reforms are related, or imply a sequence. Once a business plan has been established the implication is that a certain financial autonomy is required to be able to implement the plan. Finally, certain reforms have a different meaning if applied within the company, or if it concerns the relations with other actors (benchmarking for example)."}, {"section_title": "M.P. van Dijk / Urban Water Governance as Part of a Strategy for Risk Mitigation", "text": "189 Table 2. Agenda of suggested reforms for water utilities [4]. Improve internal functioning Improvements in relation with the context in which the utility functions "}, {"section_title": "Decision Making Structures", "text": "Urban management is defined as an integrated way of dealing with the risks cities are constantly facing. After identifying some of the major risks cities are involved in we need to identify strategies to deal with these risks. Given urban management provides an integrated approach to the issues identified by the urban stakeholders, it may opt for a comprehensive approach to manage urban risks. In a Third World context such an approach is complicated because of the acuteness of problems like pollution, rapid urbanization and social and economic inequality. However, urban management goes beyond physical planning because the adagio is to get things done with the stakeholders. They will be involved to agree on solutions in a context of consensus pursuit. In this case action and strategic planning approaches are highly relevant. What is the essence of urban management? It is reduced to an integration of the issues identified as important by the urban stakeholders. However, we have to be careful with the many meanings of integration. This could mean for example: Cities and regions are more and more integrated in the global economy and compete with each other, Urban management provides a framework to deal with the more important Millennium Development Goals (MDGs) in an integrated way, and A good urban manager is someone who, via an integrated approach based on a strategic plan, makes his/her city or region more competitive. This requires dealing with social problems and developing a pro-poor urban and regional development strategy that can include a different way of supplying urban services.  The results of research on risks, undertaken in the framework of Switch, need to be digested by a decision-making structure. Such a structure needs to be adapted to the city studied, where each city will have a different history. The process can be illustrated in Figure 3, where the proposed governance structure receives inputs from the modeling people, after getting advice from the socio-economic and institutional experts. Then it is passed on to the managers implementing the decisions. The link between the modeling and the implementation can take three paths, as illustrated in Figure 3. One, the learning alliance could advise directly the authorities, or an independent expert group (for example a Water Board in The Netherlands) could be used for that purpose. Finally, it is possible to work with the municipal council as the body that would eventually decide on the actions to be undertaken by the urban managers implementing the decisions."}, {"section_title": "Results of risk modelling efforts", "text": "Learning alliance"}, {"section_title": "Expert group", "text": "Implementation of policy"}, {"section_title": "Through the municipal council", "text": "Context more urban risks  We are focusing on water and sanitation as examples of basic urban services and as potential risks for the urban authorities. There are a number of institutional and financial constraints in their provision in the country. Secondly, the importance of water and sanitation is clear in the achievement of the Millennium Development Goals (MDGs) in Africa. In 2002, 70% of urban and 46% of rural dwellers in Ghana were covered by safe water supply; and 45% of urban and 20% of rural dwellers used safe wastewater disposal systems [10]. To meet the United Nations MDGs on water and sanitation, Ghana needs to radically reform service delivery agencies and, in addition, spend in total about $1.6 billion towards supplying 85% urban population and 80% rural population with safe water by 2015; and $1.1 billion towards providing 84% of urban population and 76% of rural population with adequate sanitation by 2020 [11]. A key issue is the shortage of water for most families. Either they are not connected to the public water system or the system is delivering only once a week. It is not just the slum dwellers and the poor who lack regular water supply. Even relatively affluent Ghanaians with water meters in their homes are often forced to buy from private water sellers because their taps have run dry or only spurt water one or two days per week. Water vendors, who enjoy a low social status, sell from tanker trucks in the street or storage tanks and wells in their backyard, charge up to 1,000 cedis (11 US cents) per bucket for the precious liquid -10 times more than what the state-owned Ghana Water Company Limited (GWCL) asks its customers. A common remark heard, translating the job stigma of private water vendors, is: \"You lose a lot of respect when you do this job\" (a woman carrying water at the market for women who are cooking food) [12]. This implies people will not easily take up such a job. The quality of water is also a big issue. Water from the tap is not very healthy, because when there is no pressure dirty water may enter the system and contaminates the treated water. Also, overflowing pit latrines is a problem causing contamination of the storm water, going through the usually open drains to the sea."}, {"section_title": "Different Approaches to Overcome the Problems", "text": "The Environmental Sanitation Policy of the government of Ghana, released in 1999, emphasizes the role of local governments in planning and managing sanitation services. However, the policy acknowledges the need for further work on how to harmonize the activities of various central government agencies involved in sanitation management with those programmes of local governments [13]. Ghana aims to provide piped water to numerous new homes, besides restoring a regular water supply to existing customers who spend most of their time staring at dry taps. The government also aims to establish more public standpipes for people living in poor suburbs where single houses do not have their own water connection. In order to achieve these goals, the government has written off US$100 million of debt owed by the Ghana Water Company and has raised US$120 million for new investments. There are many actors in the water and sanitation sector. In his PhD dissertation, Laryea-Adjei [14]  currently responsible for sanitation in Accra, and the Environmental Protection Agency (EPA) monitors industrial discharges. Both organizations are part of the same ministry, which makes it difficult for the EPA to be very critical. The Ghana Water Company Limited (GWCL) had the mandate to provide, distribute, and maintain public water supply for domestic and industrial purposes in the major cities. There is a mission and a vision, but this vision mainly concerns the provision of drinking water to a limited number of towns at a reasonable price. The organization has so far not been able to achieve its mission. Nyarko [15] discusses interventions in small towns separately, just like for the rural activities, where the Community Water and Sanitation Agency (CWSA) -which was separated from GWLC in 1994-, is the relevant institution. At the district level CWSA works with district teams, and is quite successful in supporting the district authorities. In fact their approach to water supply is more original, enabled by foreign donors who are the main funders of their activities. Eventually the donors stopped to put money into GWCL, awaiting its reorganization. Contrary to GWCL, CWSA is a small organization employing about 40 people at headquarters in Accra and other 160 employees in the ten regions of Ghana. At the local level CWSA can introduce Community Operated and Managed (COM) schemes, and may also involve private operators in at least a small town at the moment [15]. GWCL had suffered from years of poor management and the lack of investment, having huge losses. It was no longer able to serve its existing customers properly, let alone take on new ones. Officials said half of its daily supply of 120 million gallons was lost through leaks, unpaid bills and administrative inefficiency. The GWCL is currently being restructured as an autonomous private limited liability company under a management contract by a private firm. The country's PURC has a regulatory role, particularly with regard to tariff setting [11]. A more detailed account of the privatisation process can be found in Box 4. On 13 January 2005 Ghana announced it had embarked on the partial privatisation of its ailing water company with the help of a US$103 million loan from the World Bank. Most of this money was used to repair leaking water pipes in the country's main towns and lay new ones. The fiveyear Urban Water Supply Project aims to provide a more reliable water supply for more than eight million people in Ghana's main towns. The government aims to improve the situation by injecting fresh cash into Ghana Water to finance investment, and by placing the Ghana Water Company Limited (GWCL) under private management to improve its efficiency. Most of this new money is coming from the World Bank, which signed a loan agreement for the project. \"After many years of discussion, I am happy that we can now move from talk to action,\" the World Bank's country director for Ghana, Mats Karlson, said at the signing ceremony. \"We have prepared well and the digging and laying of new pipes should start as soon as possible.\" In exchange for this cash injection, the World Bank is demanding that the government improve the efficiency of GWCL by placing it under private management. An international tender was launched in December 2004 to find a contractor willing to take over management of the company for five years in exchange for a monthly fee. The contractor will qualify for a bonus payment if it exceeds agreed performance targets, but will be subject to financial penalties if it fails to meet them. \"Its baseline fee payment at the end of each month will be reduced as a form of punishment if its operations fall below standards set in the contract,\" Emmanuel Nkrumah, the director of the Urban Water Supply Project, told IRIN. \"However, should it perform above par, it will be paid a bonus.\" Nearly half the 4,600 employees of GWCL are likely to lose their jobs as the new private sector contractor seeks to streamline operations. However, there is financial provision within the water privatisation project to compensate those made redundant. \"Negotiations have already started. We have earmarked US$10 million for the retrenchment exercise,\" said Samuel Lamptey, the managing director of GWCL. \"What we have to do now is to detail how much each retrenched worker gets.\" But not everybody thinks privatisation is a good idea. Critics worry that it will lead to a sharp increase in water prices which Ghanaians on meagre salaries can ill afford. They also fear that water provision for the country's poorest people will be neglected as a privately managed GWCL focuses on serving those customers who are in the best position to pay for its services. \"Let us open a national debate on this private participation in our water delivery systems,\" said Ernest Tay Awoosah, the deputy executive director of the Integrated Social Development Centre (ISODEC), an advocacy group. \"Only then can we find out how best we can raise up that amount The privatization program is only a first step towards meeting Ghana's needs for clean drinking water. It will benefit less than half of the country's 20 million population, focusing on the 8.4 million people who live in its main towns. The government estimates it will require US$ 800 million of investment to bring clean water to all Ghanaians by 2015, in line with the UN Millennium Development Goals for improving living standards. At present only half the population has access to an improved water supply. The rest depends on rivers and untreated wells."}, {"section_title": "Develop Strategic Directions for Urban Water Management in Accra", "text": "To sum up, the institutional context for the water sector in Ghana is characterized by fragmentation. Information is scarce and spread over different institutions and no coordinated approach is followed. A more strategic approach requires a decision on the system boundaries. Do we take the narrow ones of just drinking water and sanitation, or the broader ones of the whole water cycle, including the problem of the resources and the factors influencing the quality of water? This means applying the basic principles of IUWM, such as: to consider all parts of the water system (natural and constructed, surface and sub-surface) and recognize them as an integrated system, consider all requirements for water, including human, industrial and agricultural consumption, look at it in a local context, include all stakeholders, and strive for sustainability. Van Dijk [4] suggests to put the borders at the level of the city and to deal with the issues as part of an approach to urban management, where related issues as energy use, transport planning and concern for the physical environment at large also deserve a place (see Figure 4). (needed for investment) instead of getting a private operator. It is the government's duty to ensure that water gets to everybody\", he stressed. But Finance Minister Yaw Osafo-Maafo said the talking had already gone on for too long. \"This government cannot afford the luxury of waiting for more debates on the issue,\" he told reporters. \"We all have a common objective to deliver regular and safe water at an affordable cost to the poor in our society.\" \"Let us rather use the PURC, the statutory regulatory body charged to regulate water tariffs in the country, to ensure affordable tariffs for the poor,\" the Finance Minister said.   On the basis of this list of issues we derived the main strategic directions for urban water management in Accra. In fact they are suggested by the learning alliance of the Switch project in May 2008, but I used three criteria for reducing them to 10 strategic directions. The issues should be: researched by the Switch project, a real problem in Accra, and solutions should be innovative. On this basis the following ten strategic directions were identified and will now be discussed in somewhat more detail: Promote rainwater harvesting, Stimulate urban agriculture, Generate the relevant data for IUWM, Go for an integrated approach to solid waste, Promote natural systems or an ecosan approach, Argue in favour of a different approach to sanitation, Stimulate a different approach to drinking water, Achieve attitudinal changes through awareness raising, Build on stakeholder participation, and Consider the health implications of watsan solutions."}, {"section_title": "Promote Rainwater Harvesting", "text": "There are several reasons to promote rainwater harvesting. In the first place most people are usually not connected to the net and certainly do not receive water during 24 hours and 7 days per week. Secondly, rainwater harvesting would bring down the demand for GWCL water and hence allow the company to serve other customers better. Finally, the water may also be used for agriculture purposes and, hence, could have a higher value for society, then when used only for flushing the drain and then running off to the sea, which is currently the case in Accra."}, {"section_title": "Stimulate Urban Agriculture", "text": "There are many arguments to involve in urban agriculture. The most important ones from a water perspective are that it absorbs water, it greens the city and provides the population with affordable fruits and vegetables. From a broader perspective urban agriculture provides employment and creates a transition zone between rural and urban areas."}, {"section_title": "Generate the Relevant Data for IUWM", "text": "It was noticed that a lot of data concerning IUWM are missing and a more systematic effort should be made to show, for example, the relations between water and health problems and the risks of spreading diseases and causing floods or environmental hazards. For that reason suggestions will be made to generate the relevant data for IUWM in a more systematic way."}, {"section_title": "Go for an Integrated Approach to Solid Waste", "text": "There is currently a properly engineered sanitary dumpsite in Accra, but inhabitants living close to the designated place have refused to accept this new reality and managed to stop the construction process. However, that would imply that there is no good place for collecting solid waste. A second problem is that the municipality has a problem paying the private waste collection firms. It claims waste collection requires almost half of its budget and the municipal authorities usually pay only when the funds are received from the national level, or half a year later [17]."}, {"section_title": "Promote Natural Systems or an Ecosan Approach", "text": "GWCL is no longer responsible for wastewater, while AMA finds it difficult to collect the money necessary for investments. In fact only 5 percent of the population in Accra is connected to the sewerage system and most people have to solve their problems themselves. There are, however, lots of individual and collective toilets in the private and the public sector, and private solutions can be encouraged."}, {"section_title": "Argue in Favour of a Different Approach to Sanitation", "text": "It is important to manage sanitation better and closing open drains may have a positive effect on the health of the urban population. However, many small scale operators are also active in this sector and deserve more positive attention."}, {"section_title": "Stimulate a Different Approach to Drinking Water", "text": "GWCL is currently only able to supply one third of all inhabitants of Accra [18]. Even these customers do not receive good quality drinking water for the whole day and week. This means the majority of the population depends on private solutions: they buy water from private vendors, dig wells or fetch the water in some local stream. With this reality, there are strong arguments to facilitate life for two thirds of the urban population by promoting small scale operators, hoping piped water will eventually become available. The advantage of such an enabling approach would be that less water will be demanded from GWCL, meaning it would have more water for other customers. Secondly, the government could monitor the price and quality of the water sold and, in this way, help poor households. Finally, once a different approach is successful Ghana could even use some of the water for urban agriculture. "}, {"section_title": "Achieve Attitudinal Changes through Awareness Raising", "text": "A real improvement in adopting an ecological approach (or achieving eco-efficiency) requires a fundamental change in culture, structure (institutions) and technology. Switch intends to develop, apply and demonstrate a range of scientific, technological and socio-economic solutions that will be tested to determine their contribution to the achievement of sustainable and effective urban water management schemes. It implies a multidisciplinary approach in Switch, i.e., the integration of the technological means, socioeconomic aspects, environmental concerns, and health considerations 6 ."}, {"section_title": "Build on Stakeholder Participation", "text": "It is important to involve the whole range of stakeholders in the urban system. The learning alliance is one way of doing this."}, {"section_title": "Consider the Health Implications of Watsan Solutions", "text": "Water and sanitary innovations may have important implications for the health conditions of the urban population. More research is undertaken in the framework of Switch and may be useful for elaborating this point."}, {"section_title": "European Spatial Development Policy: an Uncertain Playground", "text": "Spatial planning is often considered as an important tool to address the challenges related to natural hazards. Policy initiatives in the field of spatial development at European level also have been used in this respect. This may not be surprising as natural hazards often exceed the territorial boundaries of individual states and as the underlying risk factors often are of transnational, European or even global scale. A considerable number of positive evolutions in relation to addressing natural hazards from a European-wide territorial perspective have taken place over the last decade. The policy initiatives in the field of European spatial development address natural hazards in an evolving way. The respective knowledge base has also become more solid due to applied research projects that, among others, the ESPON Programme enables. In spite of these evolutions, however, the extent to which European spatial development policies may offer a strategy for mitigation and adaptation of natural hazards has to be further developed. In order to understand the possibilities for using European spatial development policies as a strategy for mitigation and adaptation to natural hazards three elements can be considered. The first element that sets the framework for using spatial development policy as a tool for addressing natural hazards deals with the position and status that spatial planning and territorial development policy have within the European institutional context. The European Commission has, until today, no formal competence in spatial planning or territorial development which explains the informal character of European spatial policy initiatives. The introduction of territorial cohesion as a third pillar of cohesion policy in the Treaty of Lisbon might offer the European Commission a shared competence with the Member States on territorial issues in the near future, given that all Member States accept to ratify the Treaty. However, traditional spatial planning policy, including land use, remains a competence of the Member States. The institutionalisation process of spatial development policy at European level knows a long and complex history [4]. The (informal) European collaboration in the field of spatial policy started in the late 1980s encouraged by various treaties establishing the Common Market and the European Monetary Union and transferring policy competences in the field of, for instance, environment and transport to the European level [5]. Although ministers and civil servants responsible for spatial planning together with representatives from the European Commission meet on a regular basis and have undertaken various explorative actions since the late 1980s [5] it took more than a decade before a first integrated policy document, the European Spatial Development Perspective (ESDP) was adopted [6]. In the years after the adoption of the ESDP, actions were employed to implement the principles laid down there [7]. The ESDP influenced spatial policy in many Member States and regions and set the framework for cooperation projects in the framework of INTERREG 2000INTERREG -2006 Programmes. Nevertheless it was soon felt that the ESDP was to be given a new impulse because of policy developments in the wake of the enlargement of the European Union and the need for the creation of jobs and economic growth as outlined by the Lisbon Strategy. Also the upcoming Treaty of the European Community introducing \"territorial cohesion\" as a third pillar of European cohesion policy and a shared competence of the European Commission and the Member States in this respect demanded a new policy elaboration. The Member States used this momentum to also introduce a more evidence based approach towards European spatial development policy by producing an evidence-based document under the title Territorial State and Perspectives of the European Union that should be guiding the way towards a new policy document [8]. In May 2007, the ministers responsible for spatial planning and development adopted the policy document Territorial Agenda of the European Union: Towards a More Competitive Europe of Diverse Regions (TA) [9] followed half a year later by an Action Programme (AP) [10] in order to implement the TA. In the meanwhile the European Commission set its mind on the elaboration of the concept of territorial cohesion and the definition of their future territorial competences. The European Commission outlined a first framework in its Green Paper on Territorial Cohesion [11] that is to launch the debate on this point. The Green Paper will eventually be followed by a White Paper that will offer a first policy outline by the European Commission. Overlooking all these developments it can be concluded that after a slow start it has become somewhat crowded in terms of policy initiatives in the field of European spatial planning and territorial development. In the forthcoming years it might become clear how territorial policies at European level will really precipitate and who will take the lead. The second element that sets the framework for using spatial development policy as a tool for addressing natural hazards is the extent and the way the management of risks due to natural hazards is being dealt with by European territorial policies. The European Spatial Development Perspective [6] introduces the territory as a new dimension of European policy and defines a spatial approach at European level. This perspective is made up of three policy guidelines for spatial development promoting polycentric and balanced urban development, strengthened urban rural relationships, integrated transport and communication concepts and development and conservation of the natural and cultural heritage through wise management. The ESDP describes in a general way the territorial challenges related to natural hazards. It focuses in particular on territorial risk factors for natural hazards like the destruction of soil and inadequate land use. These challenges are positioned as a theme within an integrated perspective for the future development of the territory of the European Union. Referring to the policy guidelines, it is stated that excessive use of open space for settlement purposes must be fought. Although a series of natural hazards is mentioned, emphasis is put on flood prevention and water management and the potentials for combining measures in this respect with nature development. The policy options include references to instruments like INTERREG projects and Territorial Impact Assessment. The European Commission supported the follow-up of the ESDP by enlarging the INTERREG Programme with a transnational strand using the policy orientations of the ESDP. The Territorial Agenda [9] builds further on the ESDP taking into account the enlargement of the European Union, policy development as the Lisbon and Gothenburg Strategies, and territorial cohesion. It also introduces the notion of territorial diversity and new policy challenges such as climate change. The consequence is that the TA approaches the management of risks due natural hazards from a more European and territorial perspective than the ESDP did. The TA seeks territorial differentiated adaptation strategies and mentions different territorial typologies, such as coastal zones, river basins and mountain areas, which can be relevant from a European perspective. The direct link to the global challenge of climate change puts the natural hazards on a higher level of both scales as well as within the thematic ranking. The high ranking of climate change and natural hazards on the European spatial development policy agenda became clear when, together with the adoption of the Action Programme for the implementation of the TA, as a first action the \"Contribution by the Ministers responsible for spatial planning and development\" to the on-going public discussion on the Green Paper Adapting to climate change in Europe -options for EU actions [12] was adopted. The ministers demonstrate in this contribution the role spatial planning can play in relation to mitigation of and adaptation to natural hazards. They commit themselves to undertake several actions to better fine-tune climate change related issues to spatial policy and territorial development at all levels. On April 1 st 2009 the European approach to climate change adaptation has evolved a step further by the publication of the White Paper Adapting to climate change: Towards a European framework for action [13], which proposes a framework that defines concrete actions and respective instruments. Regional development plays an important role in several of the proposed adaptation strategies. The European Commission also became an active player concerning the relation between territorial development and natural hazards. In particular the Directorate General for Environment and the Directorate General for Research were very active but also the Directorate General for Regional Policy opened up for investment in environmental improvements under Structural Funds. The Green Paper on Territorial Cohesion [11] is to lay the basis for a future European territorial development policy and in particular the initiatives that will be deployed by the European Commission. The Green Paper shows a general perspective for the territorial development of the European Union. It includes a short phrase on the possible spatial dimension and influence on land use planning of environmental policy regulations but does not address natural hazards as such. This may be a sign that the responsible Directorate General for the Regions is leaving the topic to the colleagues responsible for the environment. The institutional and content development of European spatial development policy leaves a considerable uncertainty with respect to the question up to what extent these policies can play a role as strategy for mitigation and adaptation to natural hazards in the near future. The elaboration of the policy approach is most probably sufficiently mature. The question is rather who will take the lead. For the moment it seems that the European Commission considers natural hazards as an environmental issue although the Member States clearly expressed the demand for an integrated territorial approach also at European level. The third element that sets the framework for using spatial development policy as a tool for addressing natural hazards deals with the state of affairs regarding available knowledge that can be used for policy making. The following parts of this contribution will show that the institution that takes the lead in integrating climate change and natural hazards into European spatial development policies can count on a substantial evidence base. The ESPON 2006 Programme carried out important work in this respect."}, {"section_title": "P. Schmidt-Thom\u00e9 et al. / Achievements and Challenges of Integrating Risk Management 204", "text": "In particular the projects on natural hazards, offering an applied thematic territorial indepth analysis, and the project on scenarios, integrating natural hazards into a more comprehensive territorial forecast, will be discussed."}, {"section_title": "Natural Hazards Affecting the European Territory", "text": "It is often perceived that natural hazards in Europe could be roughly divided into two main areas, i.e. Mediterranean Europe would be mostly affected by earthquakes, volcanoes, droughts and forest fires, meanwhile central and northern Europe are affected by floods, storms and coastal storm surges. It is certain that the European territory is not equally threatened by natural hazards and in fact it is the European natural, meteorological and geological diversity that leads to regionalised, characteristic hazard patterns but there is no simple North-South divide. Seismic hazards and volcanoes are mainly found in the Central and Eastern Mediterranean, the Balkans and along some active fault lines in Central Europe, as well as in the EU's overseas territories. But droughts, heat waves and forest fires are not restricted to Southern Europe as they can occur, certainly in varying magnitudes, all over the continent. Storms and storm surges on the other hand are mainly restricted to coastal zones and hinterland areas, and are climatically more imminent along the North Sea and Baltic Sea coasts than elsewhere in Europe. Floods occur along almost all large rivers, and even though there is a high concentration of floods in Central and Eastern Europe, this hazard is certainly relevant for the entire continent. Flash floods and landslides occur mainly in mountain areas, and avalanches in snowy alpine-type mountain areas [1]. Figure 1 shows the aggregated, spatially relevant natural hazards in Europe. Since not all natural hazards can be mitigated by spatial planning policies (e.g. meteorite impacts), the ESPON Hazards project developed a methodology to define spatially relevant natural hazards. Fleischhauer [13] used risk schemes developed by the German Advisory Council [15] to develop a spatial filter, which enabled the identification of spatially relevant natural hazards. The natural hazards represented in Figure 1 are avalanches, droughts, extreme temperatures, earthquakes, floods, forest fires, landslides, storms, storm surges, tsunamis and volcanoes. To aggregate the hazards into one map the relative importance of these hazards from a European perspective was determined by a weighting process [16]. The map shows that many areas in Europe are in fact affected to a high degree by natural hazards, especially areas with the highest population density and GDP per capita in Europe. Despite the fact that some regions have a higher natural exposure towards certain natural hazards, it has to be taken into account that natural hazards only pose a threat to human beings and their assets but not to nature itself. It is thus a matter of the vulnerability of human settlements that in fact lead to disasters [17]. In the following, a couple of natural hazards and their extent over the European territory are presented exemplarily. A more detailed analysis can be found from Schmidt-Thom\u00e9 and Kallio [1]. into rivers is no longer delayed by natural soil retention. Floods are perceived as the most important natural hazard in Europe, and the greatest number of large flood events between 1987 and 2002 are concentrated in North-Western Romania, South-Eastern France, Central and Southern Germany and the east of England [1]. The 2003 drought and heat wave in Europe accounted for almost one third of the economic losses caused by natural hazards in that year [19]. There are several different definitions for droughts, none of which is reasonably applicable to the entire continent. Certainly, the Mediterranean region has longer dry spells (periods without rain) than Central Europe and the natural vegetation systems were adapted to these climatic factors -before humans started to alter them. Droughts also occur in Western and Central Europe, even if the definition of a drought here is different from a Southern European one. The effects of droughts in, e.g. the UK are not comparable to those in Spain as such, but they are still droughts that have a local impact. Droughts occur mostly in the Mediterranean region, but it has to be taken into account that the manmade impact on droughts is considerable. There are several examples of water resource mismanagement in relation to the overexploitation of aquifers, restriction of groundwater recharge and climatically inappropriate agricultural practices. Eastern European countries, apart from having experienced a high number of floods over the last 15 years, have also experienced great problems with droughts in the last hundred years [1]. Concerning storms and storm surges, coastal zone management has helped to protect the North Sea coast of the Netherlands and Germany from disasters related to storm surges since 1950's and 60's. Both countries had experienced dramatic storm surge disasters throughout their history and it was coastal protection that prevented further disasters. In fact, storm surges occurred in the 1970's and later were even stronger than those in the 50's and 60's, but they still did not lead to similar disasters [1]. Rising sea levels might make it necessary to redefine coastal protection plans in some areas in the future because it is not possible to raise sea walls endlessly. The discussion on this topic has already started in some cities (see below). Tectonic hazards (earthquakes, volcanoes and tsunamis) cannot be mitigated as such, but it is possible to adapt to them by building codes (earthquakes) and zoning (volcanoes and tsunamis). It must be considered, though, that many of the oldest settlements of Europe, e.g. in the Mediterranean Region, are located in some of the areas with highest seismic activities. Humans in Europe have thus always lived with earthquakes, which is also the deadliest hazard in Europe. The only possibility to lessen the risk is to ensure building codes (it is not possible to avoid structural damages but the total collapse of buildings can be hindered). Several European coastal settlements have experienced tsunamis, fortunately no catastrophic one since 1908. Since tectonic hazards that lead to disasters tend to occur very seldom in Europe, other mitigation measures than building codes would be very difficult to impose. It is also questionable if it would make sense to propose zoning of areas with restricted land use, e.g. in potentially tsunami prone areas. In the case of these hazards it is therefore extremely important to ensure public hazard education and warning systems, as well as appropriate disaster response networks. Also the site selection for relief operations (rescue teams, hospitals, etc.) should therefore have a high priority. Since a couple of years it can be observed that natural hazard mitigation strategies experience a shift from purely technological solutions, such as dams for flood protection towards hazard adaptation [20]. Since natural hazards cannot be fully mitigated, the aim of hazard mitigation seems to also include adjusting land use forms, i.e. creating space for natural hazards. Once the spatially relevant natural hazards are identified and assessed for a given area, appropriate adaptation measures can be developed."}, {"section_title": "Climate Change Affecting Natural Hazards", "text": "The current discussion on the emerging hazards and risks caused by climate change in fact calls for an analysis of potential future changes in hazard patterns. Climate change is expected to influence weather variables such as extreme events in temperature, precipitation (including snow and ice cover) and wind. The Southernmost areas of Europe face the highest increase in the lengths of dry spells as an effect of climate change. A change of wind patterns or an increase in extreme events may lead to a higher hazard from winter storms [2]. The effects of increased precipitation on landslide and avalanches will probably cause effects at local level. An increase in landslides and rock falls can also be already observed in alpine areas due to thawing of permafrost. But it has to be taken into account that climate change impacts on natural hazards are to some degree still uncertain. Especially the impacts of climate change on storm frequency and magnitude are still unclear.. Over the last few years the EU has financed several research projects 2 on regional climate modeling and impact assessment, some of which produced maps representing the projected changes in climate variables as well as projected impacts. In its Green Paper Adapting to climate change in Europe -options for EU action [11], the Commission uses various existing project results to present those European areas that are most vulnerable to climate change. On that basis it becomes clear, that all of Europe has been and will continue to be affected by climate change, even though by different types of impacts, and with a very diverse geographical distribution on the European territory. Therefore, the Commission strongly advocates timely adaptation measures, for which a \"flexible four-pronged approach\" is suggested. Climate change has recently been incorporated in spatial planning in European countries. Several cities in the Baltic Sea Region have taken first climate change adaptation initiatives [21] and the importance of climate change in territorial development is constantly growing, e.g. in the Territorial Agenda of the European Union (2007), as outlined above. Several national strategies call for the integration of climate change in decision making processes. Finland already moved forward from a national climate change adaptation strategy towards a national climate change programme for the years 2006-2010. Ireland published its first National Climate Change Strategy in 2000 and released a second one for the period 2007-2012. The Danish Government's Strategy for Climate Adaptation [22] acknowledges that \"\u2026ad hoc adaptation to the effects of climate change is not the most optimal approach for society\u2026\" which is why a long-term process is initiated involving public authorities, industry and individuals. The strategy includes a targeted information initiative, a research strategy focusing more on adaptation, as well as the establishment of a crossministerial coordination group that should ensure coordination of efforts between public authorities. Likewise, the Netherlands, Germany and Romania, inter alia, adopted strategies for adaptation to climate change. In this context, the Partnership for European Environmental Research (PEER) launched a comparative study in 2007 on national adaptation strategies that should serve to identify knowledge gaps and formulate policy recommendations. On local/regional level, a positive trend is that several cities or regions are starting to take their own initiatives on climate change impacts. In that respect, Peltonen et al. [23] present a series of recommendations on integrating climate change adaptation into urban planning. A range of territorial cooperation projects, addressing natural hazards, regional vulnerability and/or risk mitigation, were carried out in the framework of the INTERREG III Programmes. However, a joint INTERACT-ESPON study [24] recommended that future projects of territorial cooperation should \"\u2026work on strategies reaching towards the root causes of risks (e.g. land use), and to involve decision makers who can develop mitigation plans\u2026\" rather than purely focusing on the avoidance of hazards and risks with the help of technological solutions. The current INTERREG IV Programmes continue to look at climate change and issues related to natural hazards and a number of projects have been approved in that respect 3 . One problematic aspect about climate change and hydro-meteorological hazards is that the often discussed potentially increasing magnitude and frequency of hazards in the future does not actually help in the assessment of current risks. In other words, as it is often stated that natural hazards will increase with climate change (over 100 years or so), it appears that with climate change the threat by hazards would turn into something really bad in the future, thus supposing that the current situation would be really good. But, unfortunately, this is not the case, as natural hazards continuously strike, causing even more damages. It also has to be taken into account that the sharp increase in damages caused by natural hazards in the last decades cannot be linked directly to climate change but is mainly related to the fact of more valuable insured assets, more buildings in hazardous areas as well as economic growth in general. In fact, it would certainly be possible to amend many risks that natural hazards pose to the society already now, but often such solutions would be comparatively radical and rather costly. But there is no doubt that human beings have the knowledge and the technical feasibility at hand to reduce current risk patterns. The effects of climate change should in fact be calculated on top of the current risks in order to come up with appropriate solutions (acceptable risk) now. Once these interactions are understood, planning can take action in order to steer future territorial development and at least try to prevent a strong increase of current risks. One example for such an approach is the city of Espoo (Finland) that has recently changed the delineation of marine flood prone areas in order to prevent future buildings from storm surges [21]."}, {"section_title": "European Risk Management", "text": "Natural hazards by definition occur seldom. It has been shown throughout human history that humans are willing to take certain risks, sometimes despite better knowledge, and settle in hazardous areas because other site factors seemly justify taking the risk. When discussing the potential effects of natural hazards, it is thus impossible not to discuss vulnerabilities and risk.. Risk is a function of the intensity of a hazard and the potential extent of damage -always from the human perspective. The key task is to influence the main driving forces behind risk. Concentration of population in threatened areas leads to vulnerabilities. Since the European economy is constantly growing, the combination of natural and man-made factors is the main cause behind the rapidly increasing losses caused by natural hazards in Europe. Natural hazards turn into risks for human beings and socio-economic systems where settlements or infrastructures are potentially affected, which is very often the case in densely populated areas in Europe. Experience has shown that natural hazards cannot be fully mitigated, thus the most appropriate strategy would be to reduce vulnerability. Such a process has started in some areas, but a European approach to vulnerability reduction, including effects of climate change on natural hazards, is still missing. The Territorial Agenda of the European Union [9] is probably a first step in this direction. The risk a region is ready to take plays a major role in the discussion on vulnerability. History has shown that larger settlements have in fact never been relocated from naturally hazardous areas [17]. Thus areas affected by natural hazards should start to define an \"acceptable risk\", which might be defined differently over European regions. Here it should be taken into account that socio-cultural aspects and adaptability to hazards influence the perception of risk. Currently different hazard and risk assessment methods exist for different hazard types. Since hazards seldom occur as single isolated events, it would be more appropriate to take decisions in a multi-hazard setting, particularly in territorial dimensions of risk. A more homogenised and interdisciplinary perspective than currently in practice is needed for the assessment and management of hazards and risks [17], [25], [26]. Most disasters caused by natural hazards could in fact be mitigated to a certain extent with the help of appropriate spatial planning. There are certainly always remaining risks as not all potential hazards can be mitigated, but the extent of damage and the amount of losses we experience today could in fact be lessened to a great extent. The question that has to be addressed in any case is what the price of appropriate measures might be. It is thus a matter of cost/benefit analysis to determine whether risks are actually to be taken or mitigated. An overview on different national planning responses to natural hazards in Europe is compiled by Fleischhauer et al. [3]. Schmidt-Thom\u00e9 and Greiving [27] analyse the hazards that affect Europe and give an outlook on how hazard and risk assessment could be further developed and applied in European spatial planning in the future. Schmidt-Thom\u00e9 and Greiving stress that risk management should in fact be an integral and explicit part of EU Cohesion Policy and call for a better coordination at all spatial scales. Polycentric development could be engaged to balance the current patterns of vulnerability in Europe including goals and procedural rules related to vulnerability reduction and risk management. The triangle resistance -resilience -retreat, developed by Greiving [25] should be respected when discussing vulnerabilities and policy approaches. Here, resistance is the \"protection against (all) hazards by means of structural measures\" and resilience the \"minimisation of the risk to life and property when a hazardous event occurs\"; meanwhile retreat is the most radical proposed solution, i.e. the abandonment of risky areas [27]. Since relocation has hardly ever been an option for larger settlements throughout human history, such an approach is certainly not very likely to be applied in Europe. There are only very few examples of parts of towns and villages that were given up due to natural hazards. Apart from historical and cultural values, the sheer costs (including compensations) of relocation can be expected to be beyond the financial frame of any state or city that would propose such a solution as part of a development programme. The only currently imaginable exception is that parts of coastal areas might become uninhabitable in case of sea level rise. In situations where inhabited land is permanently inundated, retreat might in fact be the only viable solution. For most of all other cases it can be expected that relocation because of natural hazards will not be an option -at least not for planning. It could be imaginable that some settlements or houses might be given up due to high costs or other reasons. However, it could well be the case that once a certain settlement is given up, planning might be able to formulate stricter land use options and, e.g. prevent re-settlement of hazardous areas once an area has been affected. Schmidt-Thom\u00e9 and Greiving state that the main elements of a disaster response by spatial planning would have to go further than the current state of the art approaches in Europe [3]. A more modern approach would give spatial planning possibilities to influence decision making to such an extent that areas would be spared from development in order to avoid natural hazards (e.g. landslides) or to make room for hazards, e.g. natural flood prone areas. Furthermore, planning could allow certain land uses in hazard prone areas, such as recreational activities in flood retention areas. An example for this is in fact part of the flood mitigation plan in Wroclaw, Poland. Also, it could be considered that planning may have a say in the structure of legally binding building permissions, e.g. minimum construction height of buildings above ground. An example for such a planning decision can be found in several cities in Finland where it was decided to change the official flood prone area delineation on the Baltic Sea coast and to raise the minimum construction height above current sea level. The decision is based on calculation of current extreme floods and the development of future storm surges in case of sea level rise. The background document for these decisions is a detailed flood prone area map of the Uusimaa Regional Council [28]. Therefore, planning can be actively employed in shaping land use to avoid hazards, i.e. using reforestation to minimise or prevent landslide and avalanche hazards. Such approaches are not new, but it would be innovative to give planning a more active and important role in the process of decision making for disaster prevention. Some of the described approaches certainly require further modifications and research before they can be applied on national and European level. In fact, many of the above described approaches are only found in isolated case studies and are not applied at national scales. But the current trends of increasing costs incurred by natural hazards have shown that such initiatives are of growing importance."}, {"section_title": "Spatial Scenarios for Europe", "text": "Scenarios are, as a tool, particularly well suited to the investigation of the likely impacts of alternative policy approaches, among others also the impacts on regional vulnerability to natural hazards. In the framework of the ESPON 2006 Programme a cross-thematic research project was devoted to the development of a number of contrasting spatial scenarios investigating the likely territorial impacts of the most important territorial challenges (including climate change, globalisation, increasing energy prices) that Europe is confronted with, but also anticipating the territorial effects of profoundly different policy approaches. The integrated scenario analysis of various hypothesis and elements relevant for territorial development allows, among other things, an outlook on the potential natural hazards that the European territory might be confronted with depending on the policy orientation chosen. The project resulted in three integrated scenarios, one baseline and two prospective policy scenarios. The latter two were conceived in a deliberately extreme way in order to reveal the likely footprints of strongly opposing policy orientations. In addition, around 20 scenarios deal with some of the main driving forces in nine thematic fields, one of which is climate change. All scenarios were conceived with a time horizon of 2030. All integrated scenarios were set up in the way that various key driving forces for Europe's development up to 2030 were analysed. Some of these driving forces might be the result of conscious policy decisions, some are not. The impact of these driving forces differs geographically. Climate change stands out as one of four driving forces that are and will become more important for Europe's regions [29]. In the following, an overview is given on the two prospective policy scenarios, based on two extremely diverging policy orientations 4 . Each extreme scenario focuses on a policy approach that aims to foster European competitiveness by self-regulation of the market. The other extreme scenario assumes a more cohesion oriented policy approach aiming at creating competitiveness within a framework of strong regulatory forces. Looking at the different possible territorial futures resulting from these scenarios enables learning about the likely effects profoundly different policy approaches can have on the frequency and scale of natural hazards. This, in turn, might give some hint on the impacts of natural hazards on Europe's socio-economic development. Against this backdrop, a better informed reflection on the desired territorial future of Europe can take place, resulting in respective policy decisions. 4 Table 1. Overview of the hypotheses of the three prospective scenarios (unless otherwise stated, the hypotheses for the baseline scenario are also valid for the two other scenarios) [29]."}, {"section_title": "Competitiveness-oriented Territorial Scenario for 2030", "text": "This scenario takes up the general objective of stronger European competitiveness in an ever more globalised economy in which Europe's position needs to be strengthened. The determinants of the respective policy approach applied in this context are stronger liberalisation of the economy, export-oriented economic development, the reduction of public expenditure and the re-orientation of public support to the sectors and regions that contribute most to European competitiveness. Even though climate change is recognised as a major problem in this policy approach, relevant adaptation measures are principally taken at global/international level. Mitigation measures limiting the territorial impacts of climate change are considered as too costly and not sufficiently profitable in the short term. However, in the wake of natural disasters some countries decide to impose tougher standards, even though the respective measures are often of a short-term or specifically focused (e.g. anti-flooding) character. The consequences of this policy approach for the European territory by 2030 in comparison to the baseline scenario can be summarised by the following main elements: Stronger population growth and greater demographic imbalances with metropolitan areas and large cities being clearly favoured by demographic development. More expansive but spatially concentrated economic growth with those regions that already had a good endowment of knowledge society-related resources benefiting most. Increasing disparities in terms of economic development and employment opportunities, both within countries as well as across the EU as a whole. Increasing traffic flows on North-South axes and corridors and less favourable accessibility to GDP in all non-metropolitan regions. Metropolitan regions benefiting more of the diversification of energy supply systems. A less polycentric settlement system favouring metropolitan areas and large agglomerations to the detriment of medium-sized or small cities. Growing dichotomy between well-off and less developed rural regions. Greater pressure on the environment of rural areas due to intensive agriculture, accelerating urban sprawl, abandonment of less-favoured rural areas and a more serious level of environmental damage due to increasing frequency of natural hazards. Altogether, a policy approach with a clear focus on fostering European competitiveness would lead to immediate higher global economic wealth on the one side, while entailing higher social and environmental costs which, in turn, are likely to result in long term economic and financial drawbacks. Furthermore, the impacts of natural hazards (drought, fires, and floods) resulting from this scenario are more intense than in the baseline scenario."}, {"section_title": "Cohesion-oriented Territorial Scenario for 2030", "text": "This scenario takes its starting point from the primary policy goal of maintaining a high level of economic, social and territorial cohesion in Europe as an answer to global territorial challenges. Nevertheless, this approach does not exclude measures for the improvement of European competitiveness. But in cases of incompatibilities between cohesion and competitiveness, priority would be given to cohesion. Some of the relevant policy elements in this context are greater equity, more internalised economic development including more economic protection, and long-term prevention measures. \"The environment is viewed as one of the main pillars of European solidarity\" in this policy approach [29]. Environmental improvement and protection in less favoured areas are given much attention and receive significant funding from the Structural Funds and Rural Development Policy. Environmental considerations also play a bigger role in the transport sector and industry. Finally, the protection and enhancement of the natural and cultural heritage is devoted more attention. The consequences of this policy approach for the European territory by 2030 in comparison to the baseline and the competitiveness-oriented scenario can be summarised by the following main elements: More regionally balanced population structure. Less expansive and more diffuse territorial pattern of economic growth with the epicentre of growth having moved towards South-Eastern Europe and the winning regions generally being non-metropolitan regions. Divergent territorial impacts of the new energy paradigm, making it more favourable for less developed rural regions. Dynamics of medium-sized towns counter-balance metropolitan growth. More prosperous and balanced rural areas. Stronger control of environmental impacts of agriculture and by stronger rural development policies in peripheral and remote rural areas. Less strong negative impacts of climate change on rural regions in Southern Europe due to stronger adaptation measures in agricultural production, forestation, and the preservation and development of cultural landscapes. Generally, the cohesion-oriented policy mix is more likely to produce a significant amount of added value in terms of reduction of territorial imbalances, greater demographic revival, socio-cultural integration, lower damages related to natural hazards and less negative impacts on rural regions. Even though the overall economic and technological performance will probably be lower than that of a competitivenessoriented or even an unchanged policy mix, this policy approach nevertheless also contributes to competitiveness."}, {"section_title": "Comparison of the Two Scenarios", "text": "The comparison of the two scenarios revealed that a more sustainable policy framework, putting a stronger focus on cohesion than on competitiveness, is more likely to contribute to the reduction of risks by natural hazards. Taking up the policy guidelines for spatial development as laid down in the Green Paper on Territorial Cohesion, the TA and the ESDP, therefore appears as the most sensible policy approach to be recommended for the long-term future in order to respond to the challenges posed by natural hazards and climate change. Better integrated transport concepts, for instance, could contribute to a reduction in greenhouse gases which might, in the long-term, alleviate climate change impacts and consequently the frequency and scale of natural hazards. In that respect, additional policy action may be required to react upon socio-economic and territorial shortcomings, e.g. the effect of climate change on municipalities and regions might have to be assessed in detail to dispose of a basis for decision on investments in adaptation measures."}, {"section_title": "Conclusion and Relevant Future Research Activities in the Framework of the ESPON 2013 Programme", "text": "Spatial development strategies can be an important tool in a process addressing the challenges related to natural hazards and climate change. A number of positive developments in relation to addressing both issues from a European perspective have taken place over the last decade. Policy documents at European level like the ESDP [6], the Territorial Agenda [9] and the related First Action Programme for the Implementation of the Territorial Agenda [10] have acknowledged the significance to respond to natural hazards and climate change. By the same token, national strategies have been developed to adapt to climate change, which also implies finding a way to deal with natural hazards that may occur more frequently and on a larger scale due to a globally changing climate. At the same time, the knowledge base in the field has improved considerably. The ESPON 2006 Programme has contributed to this improvement with applied research projects looking, inter alia, into the spatial effects of natural hazards and developing scenarios on likely territorial futures of Europe under different, profoundly diverging policy regimes. The ESPON project on natural and technological hazards in Europe delivered a first integrated approach on mapping all spatially relevant hazards, and covered almost the entire European continent. The ESPON 2013 Programme will continue to extend the existing knowledge base and deliver new evidence regarding territorial development opportunities and the effect of major challenges on European competitiveness and cohesion. The main goal of the ESPON 2013 Programme is to support policy development in relation to territorial cohesion and a harmonious territorial development. It will do so by providing comparable information, evidence, analyses and scenarios on territorial structures and dynamics and by revealing territorial capital and development opportunities in support of competitiveness of regions and larger territories. Account will be taken throughout the programme period of the challenges with territorial impact Europe is confronted with, climate change and new hazard patterns related to that change. In fact, \"Climate change, environment, natural resources, hazards and risk prevention\" were already included in the ESPON 2013 Operational Programme [30] as indicative themes/territorial issues for applied research projects in the 2007-2013 programme period. Due to the specific relevance of this thematic field for European territorial development, the ESPON Monitoring Committee decided that one of the first applied research projects in the ESPON 2013 Programme should address climate change and its territorial effects. Furthermore, climate change has been mainstreamed as a theme in a number of other ESPON projects, comprising the relations between climate change and migration, the likely impacts of climate change on different types of rural areas, or analysing potential directions for territorial development in order to create favourable preconditions for energy efficiency and sustainable use of energy. In its Green Paper Adapting to climate change in Europe -options for EU action [12] the European Commission indicated that more research is needed to address the gaps in understanding global warming and its potential impacts on the environment. By the same token, the IPCC concludes in its 4 th Assessment Report that studies disaggregated to the regional and even local scale are urgently required. Against this backdrop, the ESPON 2013 Programme will in the first term of 2009 launch an applied research project on Climate change and territorial effects on regions and local economies 5 . This project shall analyse, inter alia, the degree of vulnerability of different types of European regions to climate change, the adaptive capacities of these regions and possibilities to enhance them, territorial potentials for the mitigation of climate change in European regions, the effect of climate change on different sectors of regional and local economies as well as infrastructure, and potential new development opportunities for regions in the wake of climate change. In order to receive some more focused and detailed information, a limited number of well targeted case studies will be included in the project on the development opportunities and threats of those types of regions that are most vulnerable to climate change. Interim results of this project will probably be available by the end of 2009. Furthermore, in the framework of the ESPON 2013 Programme, some applied research projects will be conducted on the ex-ante assessment of territorial impacts of European sector policies. At this moment, an exploratory project is underway in this respect to develop a tool that can generally be applied irrelevant of the policy that should be analysed. The results coming out of these projects can be extremely valuable in discussions on potential policy approaches to take and can therefore also serve reducing the risks caused by natural hazards and climate change."}, {"section_title": "Legislative and Organizational Framework for Disaster Management", "text": "Traditionally, in France, primary government policies about risk and disaster management strictly distinguished between natural risks (e.g. floods, landslides, fires, volcanic activity, and earthquakes) and technological risks involving industry, agriculture, and transportation. While such a distinction seems convenient; it also has proved unrealistic. In fact, when disruption happens, no matter what the source of occurrence is, it may lead to other risks and inter-related events in a domino effect. Godart, Henry, Lagadec and Michel-Kerjan [1] argue that it would be much more accurate to manage a set of complex risks as a whole, seen as a system associated to an area. Under EU pressure and as a result of several different disaster incidents during the past twenty years, French policy evolved from disaster-specific risk management approach into a complex risks approach, filling the artificial gap between natural and technological risks. Until the beginning of the 1970s, there was a \"zero risk\" dogma in French public policy that was centered around the idea that, with sufficient money invested in risk mitigation, it was possible to live in an \"all safe\" universe. Such a Promethean attitude was based in part on a self-confidence rooted in a post-World War II technical advancement and demagoguery to gain votes in what could be called \"safety mongerism\". Once again, EU directives combined with the reality of numerous disasters (mainly floods) altered French policy [2]. The end of an incredibly prosperous period when there was money galore for everything, which was cut short by the mid 1970's oil crisis, accelerated this evolution [3]. Another revolution in French risk and disaster management has focused on the idea that disasters cannot always be avoided, and it is important to specify what risks and what risk levels are acceptable and to build disaster recovery plans around the accepted risks. Therefore, we will analyze the evolution of French disaster risk management policies in two sections: first, a brief history of natural hazards policies, followed by a brief history of technological hazard policies. These two different sections will show how the government moved from a no-risk approach to acceptable risks approach [4]. Present roles and responsibilities in disaster recovery will then be exposed, taking into account complex risks linked to specific domains, instead of specific risks -whether natural and technological-with no linkage to any domain at all."}, {"section_title": "Recent Changes in the Current Legislative Framework", "text": ""}, {"section_title": "Natural Risk Policies", "text": "Natural hazards affect more than 50% of French territory. Every single year they cause dozens of deaths and require several billion Euros in recovery. Increasing damages can be noted over the last 50 years due to greater exposed wealth in dangerous areas and poor risk consideration in sustainable local planning. Simultaneously the prevention policies were developed based on the following four spheres: Identification of the risk and localization prior to developing a zoning strategy, Consideration that natural risks must be part of urban and land planning regulations and documents, Eliciting input from residents themselves, and Setting up a survey and emergency system in case of disaster. Between 1935 and 1994, a large number of zoning instruments designed to control urbanization appeared. This was a recurring theme in French policy [5]. They were conceived and adopted without coordination and without cohesiveness. The complexity and the inconsistencies between the procedures made their implementation a very difficult task. A new law issued in February 1995, called \"Loi Barnier\", replaced all those discordant instruments by a Plan de Pr\u00e9vention des Risques Majeurs -PPR (Major Risks Prevention Plan). It covers all types of natural risks including avalanches, hurricanes and storms, forest fires, floods, landslides, earthquakes, volcanic eruption, etc. Moreover, this plan was supposed to be flexible in order to adapt to the needs of local, communal and river basin authorities. PPRs make possible the prevention of new construction and activities in so-called dangerous areas or regulation of them in less exposed ones. Thus, limitations on agriculture spreading to diminish surface water runoff and minimal first-story heights are required to mitigate flood effects. Conditioning any building authorization in concerned areas to comply with the local PPR achieves a compromise between preservation and development imperatives. Unfortunately there is no deadline on PPR's local approval. Political local actors often put a brake on document's validation since it imposes additional limitations to urban and land planning [6]. Communes (the smallest French territorial division for administrative purposes) which combine several natural risks in the same place are frequently associated with an approved PPR: 26% of the communes affected by 4 types of risks have a plan versus 6% of those affected by just one risk. In addition, the geographical distribution of PPRs is unequal. It evolves inversely proportional with a commune's population: 35% of all the 20.000 to 100.000 inhabitants' communes are associated with a PPR, this proportion falls down to 6% of those with 100 to 500 inhabitants and 3% of those with less than 100 inhabitants. Admittedly, one can interpret this imbalance as the more urbanized a commune is, the more drastic casualties and material damages will be when a disaster prevails [7]. Disparities "}, {"section_title": "Technological Risks Policies", "text": "Fifty years ago, as in natural hazard risks, technological hazard risk policy principally consisted of limiting construction in exposed areas. However, thirty years later -in the beginning of the eighties-the dangerous industrial installations located in densely inhabited urban places were evident to everyone [8]: These areas may be located in the 19th century big old industrial sites. They were already urbanized long before zoning, when the plants attracted a multitude of workers who settled nearby. Concerned dangerous installations may answer to specific local urban needs (train stations, gas retailers, local power transformer, etc.). As such, they have to be installed within the urban fabric. Concerned areas -initially on the outer edge of the city-may be caught up with urban sprawl. Implementing effective zoning is not an easy task. One of the many difficulties is the necessity to periodically reassess risk acceptability and area vulnerability, and to modify procedures along with the area's evolution [9]. Furthermore, technological risks management in France has been guided by EU directives and policy since the end of the seventies. The commotion caused in Europe by the Seveso disaster -accidental massive dioxin emission in 1976 near the Italian commune of Seveso-provoked early attention to prevention of industrial risks, concretized in a 1982 EU directive, called COMAH (Control of Major Accident Hazards) also known as the Seveso Directive. It requires EU member countries to specify an inventory of all their industrial risks and to register all their dangerous industrial sites. Next, they have to develop a zoning policy and develop a document named a Danger Study which explains how to face any possible disaster in each defined zone. COMAH exerts a big influence over French technological risks policy. Since 1976, in France, plans for activities with high risk and possible damages on the environment or health are submitted beforehand for administrative authorization. The ability to cope with possible disasters or to mitigate them has to be established. These dangerous sites are called Installations Class\u00e9es pour la Protection de l'Environnement ICPEs (Classified Installations for Environmental Protection). After 1982, the more dangerous ICPEs (like chemical or nuclear plants) must comply with COMAH. COMAH was modified on several occasions, gradually enlarging its competencies. On February 3, 1999 a new directive -COMAH 2 (96-82-CE) known as Seveso 2replaced COMAH. Controls on long-term urbanization and extension of the COMAH directive to address activities such as dangerous waste disposal and agrochemical storage were part of the new document. It also strengthens prevention and mitigation plans, provides provisions on land use and constructions, specifications on disaster recovery logistics, offers improvement in Danger Study content, and enhancements to inhabitants' information and participation processes. The new directive introduced a clause whereby consequences of an installation's accident on neighboring installations must be examined carefully. Co-operation between adjacent dangerous installations (exchange of information, common and coordinated emergency plans) is thus required by local authority within a Danger Study [10]. civil protection deployment; road, railway, and airways blockading. But, as much as short-term management of the crisis was effective, long-term disaster recovery was somewhat a failure: nothing had been planned."}, {"section_title": "Disaster feedback and policy adjustments", "text": "Disaster feedback and policy adjustments in France gradually lead to three observations: (1) it is necessary to work on complex risks without dissociating them as natural and technological, since they interact; (2) standard procedures are inefficient, they must be differentiated enough as to be adapted to local conditions; and (3) disaster and post-disaster recovery should be clearly defined and fully operational. Out of these observations a new risk and disaster management device was created in law on July 30, 2003. It centers on French communes, the smallest French territorial division for administrative purposes. It gives a commune's mayor authority over risk prevention, risk mitigation, alarm, and emergency, whatever the risks can be, with the help of a local document called Plan Communal de Sauvegarde -PCS (Safeguard Communal Plan). Amongst other things, this plan details what measures to apply in case of emergency as well as post-disaster recovery actions. In case of a major and extended risk, it may be necessary to unify the PCSs of all the affected communes: an inter-commune PCS which covers the whole area is then decreed [11]. When the local means and plans such as PPR, PCS, ICPE or DICRIM are not sufficient to avoid or mitigate a disaster, the Plan ORSEC -ORganisation des SECours (Rescue Organization Procedure) -is the French generic emergency plan. The Orsec plan is for widespread or long lasting disasters such as floods, storm, earthquakes or major industrial disaster (e.g. the explosion of the AZF factory in Toulouse). This civil security procedure -carried out by gendarmerie, fire departments and police departments under joint authority of the prefect and mayor-organizes population evacuation and relief operations, medical assistance, technical interventions to address the causes of disasters and reduce its consequences. It articulates two levels: (1) a standard one, applicable under any circumstances and in any place; and (2) a specific one adapted for the local context at French d\u00e9partement level. Many other particular emergency procedures can parallel ORSEC fundamental organization: Plans Particuliers d'Intervention -PPI (Specific Intervention Plans)-to deal with highly localized danger sources like ICPEs installations; Plans de Secours Sp\u00e9cialis\u00e9s -PSS (Special Emergency Plans)-to deal with diffuse danger sources like flood, accident involving transportation of hazardous materials, tankers oil spills, etc. During the last 30 years, French risks and hazards management has evolved from nationwide standardized procedures discriminated according to the type of risk (natural or technological), into a differentiated strategy based on local territories but taking into account simultaneously, all potential risks in one area (i.e. complex risks approach). Furthermore, procedures have become more integrative: today, they cover the whole sequence from risk prevention to disaster recovery. In this, they can be considered as part of local sustainable development public policies. "}, {"section_title": "Vulnerability as a Conceptual Framework", "text": "Vulnerability is a term that crosses many academic disciplines without consensus on its definition [12,13,14,15,16]. It is most simply defined as the potential for loss [12]; however, various definitions are applied depending on the disciplinary area of study and epistemological orientation [17]. The existing literature has illustrated these differences carefully [e.g., 12,14,15,18,19,20], and for this reason and space limitations, we do not spend additional time reviewing disciplinary differences concerning the definition of vulnerability. However, the broad range of definitions, conceptualizations, terminologies, and theoretical frameworks for vulnerability become problematic when applied in an interdisciplinary setting, such as climate change research [20,21]. For the research presented here, we chose to employ the categorization of vulnerability as a function of exposure, sensitivity, and adaptive capacity [13,14,15,22,23,24,25]. Exposure refers to hazard proximity of an object, sensitivity refers to differential degrees of potential loss among objects due to this exposure, and adaptive capacity refers to the ability of an object or system to adjust to hazards and impacts. This categorization of vulnerability is most evident in the natural hazards and global change literatures and, therefore, fits the present research well. The foundations for hazard-related vulnerability research can be traced to Barrows [26] and his focus on society's adjustment to environmental stressors and to Gilbert White and colleagues at the University of Chicago whose research reshaped United States flood management policy [27,28,29,30,31]. Prior to this work, hazard studies emphasized physical aspects of extreme events and engineering solutions with little to no discussion of human exposure and adaptation. White and others focused on human exposure to hazards and discussed how exposure was a complex issue involving human contestation with the physical environment for space. Research also focused on why this contestation existed (e.g., why people chose to live in flood hazard zones), offering the notion that modifying human action and implementing engineering options could both be viable solutions to limiting exposure to hazards [30]. Building on these foundations, subsequent research has explored the premise that behavior modification by some portions of society may not be possible due to lack of resources or coping abilities [e.g., 12,32,33,34,35,36]. These differences in resource access create variations in hazard exposure and sensitivity where segments of a society are disproportionately affected by disasters [37,38]. The \"hazards of place\" model contends that place vulnerability is the integration of biophysical indicators of geographic context and socioeconomic indicators of social fabric [31,39]. F\u00fcssel [20] adds to this framework by stating that vulnerability results from exposure to external biophysical and socioeconomic stressors (e.g., an extreme physical event, national policies) and from internal characteristics of a system (e.g., local environmental conditions, household incomes, social networks) that influence the extent of the stressors' impacts on the system. The vulnerability of people or groups in an area is typically described by a series of indicators [40] that depend on the researcher's conceptualization of vulnerability [20]. These indicators include infrastructure, social capital, economic well being, access to resources, and physical location to name a few [24,33,40,41] . The study of vulnerability continues to evolve with research attention shifting from simply understanding the concept of vulnerability to developing analytical methods for assessing vulnerability [17,29,31,39,42,43]. Many contend that vulnerability indicators and their assessment have meaning only in reference to a particular place or situation [20,43,44]. In contrast, others argue that efforts to quantify place vulnerability should be abandoned in favor of a focus on select variables or components and specific stressors [20,45]. We support the focus on place in vulnerability assessments [24,25,31,46,47], but see a need for specific indicators unique to hazard type and geographic location to replace traditional vulnerability indicators that are too general to form a comprehensive assessment. An assessment based on a contextual framework that fails to consider all internal and external components that contribute to a place's vulnerability would be incomplete and could thus fall short in guiding SLR-related hazard mitigation and adaptation strategies. Therefore, we adopt the vulnerability assessment framework reviewed in F\u00fcssel [20] to consider social, biophysical, internal, and external indicators in our research. The framework presented by F\u00fcssel [20] categorizes vulnerability into four broad dimensions-the system (e.g., economic sector), the attribute of concern (e.g., human lives), the hazard, and the temporal reference. We extend this framework by assessing vulnerability as specific not only to particular hazards and places, but also to the multiscalar aspects (e.g., internal vs. external) inherent in F\u00fcssel's system dimension. We respond to calls for greater integration of internal and external factors in climatechange-related vulnerability research [20,43,48] by examining the theoretical concept of inter-and intra-community geospatially dependent vulnerability, defined here as vulnerability that is diminished or intensified depending on the spatial proximity of traditional vulnerability indicators. For example, the vulnerability of a community with no health care facility is linked to the vulnerability of the nearest community with a health care facility thereby creating a dependent connection for the first community. We propose that multi-scalar indicators (e.g., electrical power grid, water systems, natural gas distribution networks, roads and bridges, etc.) have a great influence on geospatially dependent vulnerability and should be integral to comprehensive vulnerability assessments related to climate-change hazards [20,49]. We assess multi-scalar aspects of vulnerability by coupling geospatial analysis with multi-criteria collaborative decision-support methods. In our work, geospatial analysis involves the use of geographic information system (GIS) tools to integrate modeled physical data delineating potential contemporary and SLR-enhanced storm surge inundation zones with socioeconomic data characterizing coastal development. Multi-criteria collaborative decision-support methods involve the use of focus groups to validate and expand GIS-based results with local expert knowledge [50,51,52,53,54] and to include value-based human dynamics of geospatially dependent vulnerability, population growth, and development. Our integrated approach ensures a comprehensive vulnerability assessment by providing a method for integrating traditional and non-traditional infrastructure components that are internal and external to the system. This approach supports the development and advancement of systemlevel mitigation strategies that increase community and regional resilience."}, {"section_title": "Use of GIS to Assess Vulnerability to SLR-enhanced Storm Surge", "text": "Assessing vulnerability to SLR-related hazard impacts requires knowledge of local physical factors (e.g., bathymetry, topography) and socioeconomic factors (e.g., population demographics, economic well being). To date, however, assessments have measured impacts at broad regional scales [55,56,57,58,59,60,61] that are too general for practical use in local hazard mitigation efforts [62,63]. To support local planning efforts, there is a need to model SLR and potential hurricane storm surge on much smaller regional or, if possible, local scales in conjunction with community vulnerability assessments. From the hurricane-hazard perspective, the Sea, Lake and Overland Surges from Hurricanes (SLOSH) model output provided by the United States National Oceanic and Atmospheric Administration (NOAA) has grid-spacing at a relatively fine regional scale (approximately 3.2 km) that can be useful for local vulnerability assessments [9,64,65,66]. An early example of an effective use of NOAA's SLOSH model for vulnerability assessments was a flood insurance study completed by Mercado [64] to determine the 100-and 500-year return period for stillwater elevation in Puerto Rico and the United States Virgin Islands. The utility of NOAA's SLOSH model for local vulnerability assessments, however, has limitations (traditionally plus or minus 20 percent error) because several of its empirical coefficients (including wind drag, eddy viscosity, and bottom slip) are universally set as best fits constraints derived from historical storm events and do not take into account the specific geography of the modeled area. In spite of these limitations to the SLOSH model, the exactness of its output is still more than adequate for our study given our primary research goals. Other storm surge models exist, such as The Arbiter of Storms (TAOS) [67] and the NOAA Advanced 3D Circulation Model (ADCIRC) [68]; however, the outputs of these models are not available for many United States coastal locations. The National Hurricane Center (NHC) in conjunction with NOAA has divided the United States coasts into 38 elliptical basins for SLOSH modeling, each consisting of hundreds of grid cells. NHC SLOSH simulations consisting of hundreds of hypothetical hurricanes of various Saffir-Simpson categories were performed to determine at-risk areas for storm surge for the United States coasts. These hypothetical hurricane simulations consisted of a broad range of forward speeds, landfall directions, and landfall locations for each of the 38 elliptical basins and were used to generate envelopes of water reflecting the maximum surge height obtained in each grid cell for each model run. After all model runs were completed, a composite of MEOWs or Maximum Envelopes of Water were formed for each grid cell. Maximum surge heights for each gridded cell correlated with various hurricane storm intensities and tracks are contained within each MEOW. The Maximum of MEOWs (MOM) is also calculated by SLOSH and represents the maximum surge height for each cell for any hurricane regardless of storm track, land-falling direction, or Saffir-Simpson category [69,70]. We employ the output from the SLOSH model that consists of five gridded layers corresponding to storm-surge levels for hurricanes of category 1-5 intensity on the Saffir-Simpson scale for our analysis. The use of GIS in understanding societal vulnerability to hurricane storm surge varies and has included heuristic tools to support local mitigation planning [71], critical facility and evacuation impacts [72], and population demographic analysis [31,73]. Cutter et al. [31] used GIS to integrate social and biophysical indicators of vulnerability in spatial terms and demonstrated that biophysical vulnerability does not always intersect with social vulnerability, thereby showing the importance of place in vulnerability assessments. With regards to the influence of sea level rise on altering future hurricane hazards, Wu et al. [8] and Kleinosky et al. [9] used GIS to produce contemporary and future vulnerability analyses for coastal communities (Cape May, New Jersey and Hampton Roads, Virginia, respectively) and echoed the Cutter et al. [31] findings of the importance of social and biophysical components in place vulnerability. In addition to static assessments of contemporary hazards, these studies included dynamic aspects (as phrased by F\u00fcssel, [20]) of vulnerability by modeling SLR. Wu et al. [8] was one of the first efforts to use GIS tools to estimate the impacts of SLR-enhanced storm surge on coastal communities by adding 30, 60, and 90 cm of SLR to SLOSH model outputs. Rygel et al. [17] and Kleinosky et al. [9] extended this work by considering the affect of 30, 60, and 90 cm of SLR on vulnerability in the 16county Hampton Roads metropolitan area. Rygel et al. [17] specifically investigated social components of Hampton Roads' vulnerability using a principal components analysis and a novel Pareto ranking scheme. Our research extends and adapts the work by Wu et al. [8], Rygel et al. [17], and Kleinosky et al. [9] in several ways. First, we incorporate recently modified projections that suggest sea level will rise by 0.8 to 2.0 m by 2100 [58,60,74,75]. Second, we include a GIS-based method from Wood et al. [46] to determine which societal components are located within the various risk zones. Finally, we incorporate information gathered via stakeholder interaction to complete a comprehensive vulnerability assessment."}, {"section_title": "Stakeholder Interaction", "text": ""}, {"section_title": "Collaborative Decision-making", "text": "Every day, individuals and organizations face spatial decisions. Individuals make spatial decisions --e.g., which route to take to work, where to shop--typically without formal analysis because the consequences of incorrect choices are usually not dire. Organizations, however, are responsible for making spatial decisions that affect larger groups of individuals --e.g., where to site new water treatment facilities, proposed residential and commercial development, or road and street infrastructure--and thus have a need for formal analysis in their decision-making process. Collaborative spatial decision-making (CSDM) involves discussions and negotiations among a group of stakeholders, decision makers, and technical specialists to address spatially relevant issues [76,77]. The role of stakeholder interaction in long-range comprehensive planning is well documented and growing [50,54,76,77,78,79,80,81]. The desire to increase stakeholder involvement has grown out of the realization that those affected by public decisions should have more input in the CSDM process [76,77]. Stakeholder involvement in research that has profound societal impact (e.g., climate change) also provides local participants the opportunity to improve their understanding of this scientific research, which serves to validate and confirm the science in the minds of nonscientists [50,51,52,54,82]. When community issues and plans have a high degree of complexity, uncertainty, and conflicting values, community members often respond with a stance of \"not in my backyard\" to a potential solution. This situation can be avoided if a more diverse group of stakeholders are brought into a CSDM process to reflect the varied domain expertise, political agendas, and social interests inherent in any community [76,79,80,83,84]. Increased collaboration and stakeholder involvement in group decision-making, however, is not problem-free and can lead to overly social or emotional attachments to issues, to judgments made before adequately defining the problem, and to pressure felt by subordinates that often serve to inhibit creativity [76,77,85,86]. Potential organizational issues include meetings that are disorganized, inconclusive, and contain redundant or digressive conversation [76,77,78,80,85,86]. To minimize the conceptual and organizational issues related to CSDM, Jankowski and Nyerges [76] developed the Adaptive Structuration Theory and the subsequent Enhanced Adaptive Structuration Theory (EAST2) as ways to explain how decisions on the micro stage (e.g., local) influence and are influenced by decisions on the macro stage (e.g., global). These theories focus on describing group stability versus group change and the human-computer-human interaction that incorporates advanced technology for group interaction. A primary goal is to reduce the complexity of the decision problem in order to lighten the cognitive workload of participants [76]. The as the basis for a participatory decision strategy (Table 1) [76,77]. Our research incorporates Jankowski and Nyerges' macro-micro framework with F\u00fcssel's internal and external conceptual framework for vulnerability to create a macro-micro vulnerability assessment. The Florida case study detailed later in this chapter utilizes a hybrid method of focus groups and participatory mapping to complete phases A and B of Jankowski and Nyerges' Macro-Micro, Participatory Decision Strategy. Ideally a CSDM session would be completed prior to the implementation of any mitigation strategies. It was, however, not the intention of this research to complete a CSDM session but only to determine if climate modeling could be used by local stakeholders to arrive at spatial decisions that could be incorporated into long range comprehensive plans. Subsequent research by this team will complete the CSDM for our study site."}, {"section_title": "Focus Groups and Participatory Mapping", "text": "Successful application of vulnerability assessments requires local knowledge gained through stakeholder interaction [50,51,52,53,54,87,88,89]. To involve stakeholders in our case study, we use focus groups and a participatory mapping exercise. The use of focus groups for stakeholder interaction began as a market research technique first cited by Bogardus in 1926, and later refined by Merton and his research team in the 1940s to study participant reactions to wartime propaganda [90]. Focus groups themselves are effective for developing a deeper, more nuanced, and more contextualized understanding of the kinds of value-based human dynamics involved in decision-macro-micro framework (much like F\u00fcssel's internal and external indicators) can serve making than the knowledge one gains from quantitative models alone [91,92,93,94]. Decision-making policy concerning climate change often relies heavily on information collected through focus group research [95]. Participatory mapping relies on stakeholder familiarity with a place to elicit intimate knowledge of local surroundings in a spatial context [89,96,97,98,99]. Local knowledge that is provided by stakeholders who are intimately familiar with their communities that is captured on workshop maps can be coupled with expert information that is supplied by scientific research teams to produce a comprehensive understanding of community issues. In participatory mapping sessions, stakeholders provide information by collaboratively drawing on study-area maps and, in doing so they validate scientific research through personal familiarity with their community [100]. Our case study follows a sequential explanatory mixed-methods strategy of inquiry as the research model. This model involves a sequential data collection process that starts with quantitative data (e.g., GIS-based analysis) and follows with qualitative data collected in hybrid session of focus groups, and participatory mapping complemented by semi-structured interviews. Research emphasis can be placed on either the quantitative or qualitative data or both. Most often with this model, and as evidenced in our research, the qualitative data are used to explain or strengthen the quantitative data. Quantitative data or analysis can guide the project, while qualitative procedures obtain broader, more-diverse perspectives that inform the narrower results of the quantitative analysis [101]."}, {"section_title": "Case Study", "text": "This case study is part of a larger body of research that has an overall goal of increasing community resilience to future hurricane storm surge through developing a collaborative decision support system. For this chapter, we provide an overview of the study area, a geospatial approach for delineating hazards and assessing variations in community exposure, and methods for involving stakeholders in a participatory mapping exercise."}, {"section_title": "Study Area", "text": "This study focuses on Sarasota County, located on the west-central coast of Florida, and on the 27 incorporated cities within the county that have land prone to hurricane storm-surge inundation (Figure 1). Due to its desirable coastal location and subtropical climate, the county has experienced significant growth in recent years, with a population increase of 17% from 1990 to 2000 [102]. According to Sarasota County's historic preservation plan [103], public officials face challenges of how to balance increasing population growth and development with the need to lower community vulnerability to natural hazards. Faced with the continual storm-surge threats posed by hurricanes and the potential for significant changes in the current physical landscape given future sea-level-rise scenarios, Sarasota County is a prototypical place where growth and development will likely intersect with SLR to increase vulnerability to hurricane storm surge."}, {"section_title": "Hazard Assessment", "text": "We based hurricane storm-surge hazards on SLOSH model outputs for hurricanes Category 1 through Category 5. The maximum surge height for hurricanes of a particular Saffir-Simpson category was calculated for each grid cell using high-tide model runs and then compared to elevation values. After matching the vertical datum (National Geodetic Vertical Datum or NGVD) of the SLOSH model to a Digital Elevation Model (DEM), we mapped those areas where storm-surge heights were greater than elevation values for each hurricane category. Because high-elevation barriers can prevent the propagation of floodwaters, we excluded any low-lying area appearing to be at risk of flooding but surrounded by higher, non-flooded land in the atrisk zone. Because the available SLOSH output is based on an older sea-level datum, contemporary maximum surge height estimates could be lower than they would be with an up-to-date datum. We present conservative estimates of maximum surge heights because we did not account for the effect of wind-driven waves, which can magnify the effective height of a storm surge [104]. To delineate the hurricane storm-surge hazards enhanced by SLR, we raised the base level of the Category 1 through Category 4-5 storm surges by 30, 60, 90, and 120 cm using techniques described in Wu et al. [8] and Kleinosky et al. [9]. We projected these values onto the DEM, thereby estimating the spatial coverage of the storm surges given higher sea levels. The scenarios range from the lower to upper bounds of IPCC estimates of SLR by 2100 [74,75,105]. "}, {"section_title": "Vulnerability Assessment", "text": "To assess variations in community exposure to current and future storm-surge inundation from hurricanes, we applied GIS-based methods described in Wood et al. [46] to integrate data characterizing coastal hazards, populations, land cover, businesses (including critical and essential facilities), and tax-parcel values. The number and demographic characteristics (e.g., ethnicity, age, gender, tenancy) of residents in the various hazard zones were determined using demographic data from census blocks of the 2000 United States Census [102]. Land-cover data from NOAA's Coastal Change Analysis Program [106] was used to determine the kinds of land-use and land-cover types are found in the various hazard zones, with specific attention given to developed classes (e.g., greater than 25 percent impervious cover). County taxparcel data were acquired to determine the amount and percentage of a municipality's tax base that is located within the various hazard zones. To assess potential impacts on economic vitality and overall community resilience [15,107,108], we extracted georeferenced business data from the 2006 infoUSA Employer Database, which includes information of total employees, total sales volume, and the North American Industry Classification System (NAICS) code for each business. These data allowed researchers to determine the type of and number of businesses in the risk zones as well as the sales volume and number of employees for each business. Previous work by Wood et al. [46] concerning exposure to tsunami hazards highlighted the number of employees working in the risk zones to assist in evacuation planning, and to determine potential income disruption should a tsunami occur. The current case study primarily used employee information to determine potential income disruption that has been shown to be important for short-and longterm recovery [108]. Facilities considered critical for short-term response (e.g., national security facilities, fire and police stations, water and sewer treatment facilities, gas and electric companies, hospitals, nursing homes, daycares, etc.) or essential for long-term recovery (e.g., banks, gas stations, grocery stores, government offices, etc.) were also extracted from the employer database."}, {"section_title": "Stakeholder Involvement", "text": "Stakeholder involvement for this case study consisted of a focus-group workshop where participants considered the implications of various hazard overlay scenarios on a map showing planned land use and land cover (LULC) for Sarasota County in the year 2050. For the purpose of our research, a scenario is a sequence of plausible, hypothetical future events developed in conjunction with stakeholders to inform decision-making. In much of the literature, the terms scenario and alternative futures are used interchangeably, but, methodologically speaking, there are distinct differences between the two terms. Alternative futures refer to a possible end state, whereas scenario is a means of reaching that state [109]. Scenarios in this research are used to examine the uncertainties of future events based on collaborative assumptions and expert opinions rather than facts. To elicit expert opinions from local stakeholders, we conducted a one-day focus group session with 33 local participants from varied domain expertise traditionally critical to community preparedness and mitigation efforts. The focus group began with an initial morning plenary session to discuss the research project and to present the GIS-based, storm-surge modeling results. The participants were divided into five breakout subgroups based on the following domain expertise: Planning, including city, county, and regional planning officials; Government, including city managers, mayors, county commissioners, and sustainability officers; Business, including representatives from local chambers of commerce, insurance companies, restaurants, tourist accommodations, and retail trade; Environmental sector, including estuary program coordinators and marine researchers; and Emergency management and infrastructure, including public works managers, county health officials, recovery planners, and county emergency managers. The decision to divide the groups by domain expertise resulted in each group approaching the scenario from their particular expertise. We believed that five groups with mixed domain expertise would result in five similar responses to the scenario. Dividing the groups by domain expertise ensured that the perspective of each knowledge domain was captured. Each group was instructed to review a map showing SLOSH-modeled storm surge inundation and 2050 LULC for Sarasota County and to determine if and how they would reallocate land use based on the contemporary storm surge modeling results [110]. Group members were asked to document on their maps any concerns, changes, or suggestions related to future land use. A transparent overlay grid was provided to allow participants to be more numerically precise in proposing changes. After the breakout sessions and before the ensuing plenary sessions, the maps from each group were collected and posted to provide the opportunity for everyone to view all subgroup maps. A spokesperson from each group presented the group's map and discussed their land use decisions. The plenary mapping session allowed for integration of information along various knowledge domains. In the afternoon, the procedure for both the breakout and plenary mapping sessions were repeated in a further round of exercises with an alternative scenario map showing the SLOSH storm surge output of a category 3 hurricane enhanced with 30, 60, 90, and 120 cm of SLR."}, {"section_title": "Results", "text": "The research presented in this case study is ongoing with full project results not yet realized. A preliminary map of potential storm-surge zones enhanced by SLR projections for a category 4-5 hurricane ( Figure 2) nonetheless indicate that SLR could significantly increase hazard zones, thereby putting larger numbers of population and development at risk. We offer examples of how SLR affects population number ( Figure 3a) and population percentage (Figure 3b) in the SLOSH hazard zone of a category 4-5 hurricane enhanced by 90 cm of SLR. The category 4-5 surge zone in Sarasota County contains 184,148 residents or approximately 56 percent of the county's total population. When the surge zone for a category 4-5 storm is increased by 90 cm of SLR, these numbers increase to 221,511 residents or approximately 68 percent of county totals. The addition of SLR to this surge zone translates to six municipalities (Englewood, Laurel, Longboat Key, Nokomis, Osprey, Siesta Key, Vamo, and Warm Mineral Springs) joining Plantation and Venice Gardens as municipalities with 100% of their residents in the hazard zone. We expect subsequent research results to indicate that the number of Sarasota County residents located within the hazard zone will continue to increase with higher levels of SLR. amount of tax parcel value exposure for unincorporated county land also significantly increased in this example from $11 billion to $14 billion. The percentage of a community's total tax base also increased significantly for several jurisdictions with the addition of 90cm of SLR (Figure 4b). Several communities (e.g., Lake Sarasota, Kensington Park, Bee Ridge, South Gate Ridge, and the Meadows) have zero percent of their tax base in storm-surge zones under current conditions but could have varying levels of exposure once the effects of SLR are included. The inclusion of SLR effects on storm-surge hazards would result in several communities (e.g., Englewood, Laurel, Longboat Key, Nokomis, Osprey, Siesta Key, South Sarasota, South Venice, Vamo, Venice, and Warm Mineral Springs) having 100 percent of their tax base in hazard zones. When these and other storm-surge modeling results were presented to focus groups in Sarasota County, participants from each knowledge domain saw the need to revise the county's 2050 land-use plan and documented potential adaptation strategies on workshop maps ( Figure 5). Examples of proposed revisions include increasing housing density in areas not exposed to storm surge, revising proposed plans to widen Interstate 75 (and instead, using the money to build an alternative road outside the risk zone), and altering the county's urban growth boundary that currently (and unintentionally) restricts growth to within the risk zones. Figure 5. Example of a participatory map used in the Sarasota focus groups to capture adaptation strategies for dealing with SLR-enhanced storm-surge hazard zones. Stakeholders also saw the need to move from focusing on events at a municipal or county level to working as a region to solve problems associated with SLR and storm surge. Focus group participants indicated regional vulnerability assessments are needed that take into account internal and external vulnerability components to provide a more accurate assessment of community vulnerability. For example, several multi-scalar indicators drew considerable attention such as the location of critical and essential facilities, the affect of transportation network problems on regional evacuation, and the need to address the lack of connectivity among the county's various water systems. County response and redevelopment officials noted that the city of Sarasota should deliver potable water to southern portions of the county if SLR hurricane scenarios were realized because a significant portion of the city's wells are located outside the risk zones. County response and recovery officials were concerned, however, because City of Sarasota waterlines are not compatible with those used in municipalities in southern portions of the county. This incompatibility of waterlines demonstrates a geospatially-dependent vulnerability for portions of southern Sarasota County. Sarasota city and county officials discussed the need to remedy this lack of connectively by suggesting the need to work at city, county, and regional levels to develop a more unified regional infrastructure package. Participants thus acknowledged the need for a macro/micro multi-criteria collaborative spatial decision support system to integrate this and other infrastructure components."}, {"section_title": "InSAR and LiDAR as Emergent Observation Technologies", "text": "InSAR is a coherent methodology for measuring ground movements based on phase shift of the signal received from radar sensors mounted on ground, aerial, or satellite platforms. The conventional InSAR combines two SAR images of a given area to form an interferogram that contains an amplitude and phase content. While the amplitude corresponds to the intensity of the radar signal reflected back to the sensor from a given ground target, the phase content contains the differences between phases of corresponding pixels in the pair of co-registered SAR images. Phase values correspond to the component of relative displacement of the ground surface along the satellite line-of-sight (LOS) allowing displacement measurements of centimeter or millimeter accuracy according to the technique employed and characteristics of the study area. Conventional InSAR, differential InSAR (DInSAR), corner reflector InSAR (CRInSAR), persistent scatterer interferometry (PSI), and polarimetric interferometry (Pol-InSAR) are different implementations of InSAR, each being useful in detecting, monitoring, and evaluating various geologic hazards. Depending on the nature of the event to be investigated, characteristics of the geographic area, technical specifications and availability of specific satellite data, topography, and atmospheric and weather conditions, one or more of these techniques may be more applicable. These techniques, associated requirements, and limitations are briefly discussed next (see also Table 1): Conventional InSAR and DInSAR techniques process the phase differences between image pairs for all backscattered signal data. The success of these methods depends on the effect of spatial and temporal decorrelation of the signal, geometry of the observation, and the availability of high resolution digital elevation models (DEMs) which are needed to create radar interferograms. While conventional InSAR methods use backscattering signals from all reflecting objects, PSI uses data only from high reflectance objects (e.g., permanent scatterers) such as dams, pipelines, buildings, highways, and exposed rocks. A sufficiently large and well-distributed population of targets, such as a few hundred per square kilometer, can produce data to accurately model atmospheric heterogeneity. PSI enables development of geospatial products, such as displacement maps, with ground displacement accuracy on the order of millimeters. CRInSAR is useful in situations where neither coherent natural targets nor persistent scatterers are available. The CRInSAR technique uses stable \"targets\" or corner reflectors (CR), which are coherent radar targets in the field that are unaffected by radar acquisition geometry and temporal decorrelation. These natural and artificial structures display reliable phase information as clearly distinguishable in all images and do not vary in their electromagnetic properties. Phase differences are processed only at discrete locations where these targets exist. Pol-InSAR is based on comparing a pair of complex SAR images that have a specific polarimetric signature. This could be a correlation between two images that each have similar or different cross or parallel polarization. The technique often uses polarimetric and frequency combinations for mapping deformations in areas where other InSAR techniques are limited by variable scattering due to variations in vegetation coverage and density. The technique has been validated for a few cases of volcanic studies in tropical environments [13].  Table 1. Advantages and limitations for DInSAR, CRInSAR, PSI, and Pol-InSAR techniques."}, {"section_title": "Advantages", "text": "Potential for detecting surface deformations in vegetated terrains. Potential of detecting textural variation correlated to surface deformations."}, {"section_title": "Limitations", "text": "Full polarimetric data modes are very limited in satellites data acquisition: No full coverage. Coherence is often limited by complex surface and volume scattering phenomena.\nAs with CRInSAR, PSI can provide only point displacement information for each location of a permanent scatterer. The data coverage depends on the number of scatterers within the area of interest. A large number of SAR scenes (i.e., greater than 25) are needed for the technique, which can significantly increase the cost of a project. Due to the complexity of the method, PSI is more difficult to implement than the DInSAR or CRInSAR.\nCorner reflectors may require periodic maintenance. Installation of corner reflectors may not be practical or suitable for all geologic locations due to site accessibility, orientation, ground condition, and theft/vandalism.\nDInSAR, using SAR C-band datasets, has had limited success in vegetated environments. CRInSAR and PSI could overcome this limitation. Typical ground displacement accuracy is on the order of centimeters. Displacement accuracy is dependent on the quality of DEM used in the interferometric process. The quality of the analysis is also degraded by atmospheric heterogeneity and/or temporal decorrelation of the pair of radar datasets. These factors can result in phase ambiguities that are of a magnitude equal to the ground displacements anticipated LiDAR is an acronym for light detection and ranging (analogous to radar, but with laser light as the energy source). It is an exciting development in remote sensing that can provide very high resolution imagery of Earth's surface, vegetation, and buildings by measuring the time it takes for a laser pulse to travel roundtrip from the laser source to a target and back to a sensor ( Figure 2). Traditionally LiDAR has been employed from satellites and aircraft, but it can also be employed from a fixed station on the ground (examples are provided in Section 2.3.1). A critical parameter describing the size of laser sampling area is the LiDAR footprint, which varies with the scanning geometry and the local topography [14]. Medium and small footprint sizes (i.e., 5 m and smaller) are most appropriate for natural hazard applications (examples are provided in Section 2.1.2). Figure 2. Some of the basic principles of LiDAR. After DESDYnI [17]. LiDAR can operate in a waveform or discrete-return mode. In the waveform mode, a LiDAR system collects the returned energy in continuous way, usually in a large footprint, whereas in a discrete-return mode a LiDAR system records one or a few echoes usually from a small footprint. The former mode is widely used in high resolution terrain and tree canopy mapping [15,16]. Successful removal of vegetation and human construction effects through data processing can yield a bare-earth DEM. Landslide mapping, flood plain assessments, slope stability in mines and road cuts, and coastal erosion are just a few hazard-related applications that have used this remote sensing technology."}, {"section_title": "Pol-InSAR Advantages", "text": "If archival data are available, motion history over a decade or more is possible to determine. Typical ground displacement accuracy is on the order of millimeters."}, {"section_title": "PSI Advantages", "text": "Measurements are obtained at the exact required location. The method can be applied if no data or little archival data are available; the first measurement results can be generated with only three images. Deformation rates can be measured with a vertical precision of 1 mm/year."}, {"section_title": "CRInSAR Advantages", "text": "Relatively straightforward technique that can provide useful results using a small number of SAR images. Provides relatively quick results if the geometry of a satellite InSAR system is within appropriate limits. Provides surface displacement information throughout the boundaries of SAR images."}, {"section_title": "Examples of InSAR and LiDAR Remote Sensing Observational Tools Applied to Natural Hazards", "text": "InSAR and LiDAR can provide a systematic framework for scientific knowledge that is the basis for an improved understanding of physical processes on the solid Earth. Measurement of deformation related to earthquakes and volcanic activity is essential to understanding and mitigating these natural hazards [18]. Regional and localized hazards, impacting the land surface and affecting human livelihood, include earthquakes, landslides, debris flows, permafrost melting, and land subsidence or collapse due to natural or human removal of subsurface material or fluids. For each of these hazards, InSAR has proven useful in assessing damage after the events and in evaluating the risk of future events by understanding and monitoring the processes involved. LiDAR is also an extraordinarily effective observational tool useful for assessing a variety of natural hazards and for scientific studies of the solid Earth. The great value of airborne LiDAR data lies in their high spatial resolution and its utility when mapping topographic variability or surface roughness, when producing slope maps, and in the capability to derive from it other critical morphometric parameters. The number of case studies incorporating these emerging remote sensing technologies is dramatically increasing each year. For brevity, we will highlight only a few."}, {"section_title": "Volcanoes", "text": ""}, {"section_title": "InSAR", "text": "The U.S. Geological Survey (USGS) Volcano Hazards Program operates several volcano observatories, including those in Hawaii, Alaska, and the Cascades, and collaborates with federal, state, and local government agencies; universities; and the private sector to reduce the risk from volcanic activity. Staff members at these observatories conduct intensive programs of seismic, gas, ground-deformation, geochemical, and observational monitoring, often applying InSAR and LiDAR technologies. Magma (molten rock) intrusion into the shallow crust is a major cause of groundsurface displacement or volcanic unrest. Rising magma typically causes swelling or subsidence of a volcano's summit or flanks. In the past, simple geodetic techniques or tiltmeters were used to monitor this deformation. Increasingly, continuous global positioning system (GPS) measurements are being made at active volcanoes to detect magma moving toward the surface and to improve our warning capabilities. The deformation source may be estimated by the direction in which the benchmarks move and by their rates of movement. For example, if magma rises to a shallow level beneath a volcano, the ground surface above it will swell, causing benchmarks around the center of the intrusion to move horizontally and vertically away from the source. The location, depth, and amount of magma intruded may even be estimated by careful interpretation and modeling of the pattern of displacement. At present, modern geodetic technologies such as InSAR offer an unprecedented ability to provide both spatial and temporal coverage of ground-surface displacement. Early work applying InSAR to volcanic regions includes studies at Mount Etna, Sicily [19], and Kilauea in Hawaii [20]. An area of uplift near the cluster of volcanoes in central Oregon known as the Three Sisters was unexpectedly detected by conducting systematic InSAR analysis. This deformation was in an area where the most recent eruption occurred 1,500 years ago. Uplift of the ground surface began in 1997 and reached approximately 15 cm by 2001 [21]. The InSAR pattern places the depth of magma intrusion at 6-7 km. Subsequent GPS and seismic monitoring continues to observe the area of unrest [22]. If inflation continues and shallow earthquakes start to occur, an eruption may soon follow. If inflation ceases, continued monitoring is essential to gain insights into noneruptive volcanic processes. The combination of GPS and InSAR is especially powerful because the two data sets complement one another's strengths and weaknesses.\nDeformation rate assessment, including relative movements over large regions and local displacements associated with slip on specific active faults, is increasingly used in earthquake hazard assessment. Resulting data are used as the basis for quantifying the likelihood, recurrence, and magnitude of earthquakes on active fault systems. Spaceborne InSAR was first used for the 1992 Landers earthquake [28] and lately ha been used extensively for a wide variety of earthquakes worldwide. Examples include the 1999 Hector Mine earthquake [29 -39]; the 1999 Izmit earthquake [40 -47]; the 1999 Chi-Chi earthquake [48,49]; and the 2003 Bam earthquake [50 -55]."}, {"section_title": "M. Necsoiu and D. Hooper / Use of Emerging InSAR and LiDAR Remote Sensing Technologies 251", "text": "Mattioli, et al. [23] applied GPS geodesy to measure surface deformation during the incipient stages of the volcanic crisis at Soufri\u00e8re Hills volcano on the Caribbean island of Montserrat ( Figure  3). From October 6, 1995, to July 1, 1997, during initial dome growth and gravitational collapse, their data show nonaxially symmetric horizontal displacements, and decreasing subsidence as a function of radial distance from the former topographic high of the volcanic edifice. Forward modeling suggested that surface deformation was caused by a shallow (<3 km), expanding vertical dike, coupled with a deflating Mogi source at about a 6 km depth. These inferred source parameters were in good agreement with independent observations of regional dike widths and preeruption magma storage depth. SAR data were not available at the initial stages of this eruption, but this study would have benefited from the spatial distribution of surface deformation derived from InSAR. Figure 3. Ashfall coats a global positioning system (GPS) station on the island of Montserrat after a phreatic eruption from Soufri\u00e8re Hills volcano generated a base surge on October 30, 1995. Hooper and Mattioli [24] describe kinematic modeling of pyroclastic flows produced by gravitational lava dome collapse at this volcano."}, {"section_title": "LiDAR", "text": "LiDAR imaging can play an important role in monitoring active volcanoes by enhancing measurements made using other techniques, such as InSAR or ground-based methods. Airborne laser altimetry helps provide accurate spatial and temporal mapping of lava and pyroclastic flows, thus enabling the calculation of flow volume and effusion rate to aid understanding of dynamic magma processes. Hofton, et al. [25] used the National Aeronautics and Space Administration's (NASA) Laser Vegetation Imaging Sensor (LVIS) to estimate lava flow volume and average effusion rate for Arenal volcano (Costa Rica) from 1998 to 2005. Their results show that repeated topographic imaging of an active volcano is possible using a medium footprint LiDAR. Davila, et al. [26] used LiDAR topographic coverage to recognize morphological changes in the drainage system of Colima volcano, Mexico. This use of LiDAR was critical for producing a hazard map for lahars (volcanic mudflows). s of At Mount Etna in Sicily, the Istituto Nazionale di Geofisica e Vulcanologia R (INGV) commissioned overflights of the volcano in 2005 and 2007 to acquire LiDA data for morphological and volcanological analysis. Neri, et al. [27] concluded that LiDAR surveys are more accurate than earlier aerophotogrammetric surveys and that LiDAR technology has a greater capability for observing portions of the crater interior that are obscured by the gas plume.\nGlenn, et al. [110] used LiDAR to examine the surface morphology of two canyon-rim landslides in southern Idaho. Their high resolution topographic data were used to calculate surface roughness, slope, semivariance, and fractal dimension. These data were combined with historical movement data (GPS and laser theodolite) and field observations for the currently active landslide. They concluded that high resolution topographic data have the potential to differentiate failure zones within a landslide and provide insight into material type and movement. Van Den Eeckhaut, et al. [12] examined large, deep-seated landslides in the Flemish Ardennes of Belgium. They tested the potential of LiDAR images for mapping landslides because most of these old (>100 years) landslides are located under forest cover and aerial photographic interpretation is not an appropriate landslide mapping method. Another unique aspect of this study was the use of expert elicitation for analyzing landslide inventories. They concluded that for hilly regions affected by old landslides, high-quality landslide inventory maps can be obtained by combining the analysis of LiDAR-derived maps in a GIS environment and detailed field checking."}, {"section_title": "Earthquakes", "text": ""}, {"section_title": "Case Study: 1992 Landers Earthquake -The Newberry Springs Fault Zone", "text": "The 1992 Landers earthquake serves as the type example for InSAR analysis of earthquake-related ground deformation. InSAR investigations of the Landers displacement pattern include analysis of coseismic deformation [28, 33, 56 -67]; and post-earthquake deformations [32, 68 -78]. The Landers earthquake (Mw=7.3) occurred April 24, 1992 in the southern Mojave Desert (Figure 4). Field investigations showed that maximum right-lateral strike-slip displacement on the Landers surface ruptures were 4 m and 6 m, respectively, measured at locations 10 km and 40 km north of the epicenter [79,80]. This event demonstrated that earthquakes can trigger subsequent earthquakes beyond the immediate aftershock area and that faults seemingly unconnected at the surface may be connected at depth. The Landers earthquake was important for several reasons. It is widely believed that the Landers earthquake in Southern California remotely triggered earthquakes as far away as Yellowstone National Park in Wyoming [81,82]. The large magnitude of the Landers earthquake suggests the earthquake occurred along a single fault at depth rather than along multiple faults. Previous geologic maps showed multiple faults that were not connected at the surface, which led to the prediction smaller earthquake magnitudes [83,84]. The fact that a series of seemingly disconnected fault segments at the surface may be linked at depth and be capable of producing large magnitude earthquakes has also been recognized on segmented normal faults [85] and is considered important in assessing seismic hazards. Understanding characteristics of ground ruptures associated with seismic fault slip is of growing importance to seismic hazard assessment and probabilistic fault displacement hazard assessment. Ferrill, et al. [67] presented a detailed study of single-event fault ruptures, and explored the potential of DInSAR for mapping small displacements for the Newberry Springs Fault Zone (NSFZ): an area 16-25 km northeast of the northwestern termination of the Landers rupture. This fault zone, which had not been recognized prior to the 1992 Landers earthquake, ruptured coevally with the Landers earthquake. InSAR-derived displacement gradient mapping (i) confirmed the timing of rupture formation, (ii) extended the field-based interpretations by independently confirming overall rupture network morphology and displacement values for two ruptures that were previously mapped but for which displacement was not measured, (iii) revealed evidence for previously unmapped ground ruptures, and (iv) demonstrated that it is capable of mapping small-displacement (~2 cm) ruptures in remote areas in the absence of direct field measurements ( Figure 5).  "}, {"section_title": "Emerging Trends in Remote Sensing in the Next Decade", "text": "Industry demand for data with high geospatial lateral and vertical accuracy data continues to grow, and Phase IV of the American Society for Photogrammetry and Remote Sensing (ASPRS) \"10-Year Remote Sensing Industry Forecast\" [111] highlights the progress that data suppliers have made in closing the previously identified gaps between elevation data and demand. For example, high resolution DEMs are increasingly available from LiDAR and InSAR. In particular, NASA and National Geospatial-Intelligence Agency (NGA) made a significant contribution to the global remote sensing community by processing and openly distributing Shuttle Radar Topography Mission (SRTM) Level-1 data having nominal post spacing (i.e., DEM cell size) of 90 m. Level-1 and Level-2 data (nominal post spacing of 30 m) were made selectively available to U.S. government-approved users. These datasets include highly accurate InSAR-based DEM data covering approximately 80 percent of Earth's land mass between the latitudes of 60 degrees north and 56 degrees south [112]. Airborne and satellite InSAR and LiDAR systems, combined with integrated observational and modeling procedures (see Section 3.3.), could enable a comprehensive and coordinated approach to the study and assessment of natural hazards. In the following sections we briefly examine the global availability of these data, the major international collaborations and data-sharing partnerships, and data interpretation and dissemination."}, {"section_title": "Global availability of high resolution SAR and LiDAR satellite data", "text": "In the data supplier sector, SAR satellite data have been available for commercial use since the launch of the first European Remote Sensing (ERS) satellite by the European Space Agency (ESA) in the early 1990s. Long-term acquisition intervals required in some of the InSAR studies are therefore possible by using C-Band SAR data collected by ERS 1-2 [113], RADARSAT-1 [114], and ENVIronmental SATellite (Envisat) [115]. reduction. The United States outlines the progress of coordinating U.S. and international Earth observation efforts in a recently published report [121]. Another major international collaboration that will provide information in a variety of areas, including natural hazards and emergency response, is Kopernikus (formerly known as the Global Monitoring for Environment and Security, or GMES program). Kopernikus, a European Union-led initiative in partnership with ESA, will provide data access from 40 or more satellites carrying radar and high-resolution optical and medium-resolution multispectral imagers, as part of its space-based infrastructure [122]. In the commercial sector, European countries such as Italy, France and Germany successfully established data-sharing arrangements for their optical and SAR satellite data. These cost-effective partnerships are exclusive because each member nation shares its resources, but has knowledge only of its own encrypted telemetry and downlink activities [112]. Another example of successful international cooperation in the development of radar satellites is the Canadian and European partnership [115]. A successful data sharing effort is the Western North America Interferometric SAR Consortium (WInSAR). Although WInSAR started as a U.S.-led initiative involving U.S. universities and research laboratories, it is now become multinational. Members of this consortium are granted access to SAR data according to the policies of the data providers (i.e., ESA for ERS-1, ERS-2, and ENVISAT; CSA for Radarsat-1; and JAXA for ALOS PALSAR data). A successful WInSAR model could be extended into other parts of the world. Amelung [123] discussed efforts to extend the WInSAR approach to new research laboratories from Central America and Southeast Asia; IGOS Geohazard or UNAVCO would be responsible for data distribution and usage according to the policies of data providers."}, {"section_title": "New Methods in Data Interpretation", "text": "Advances in remote sensing are likely to come not only from advances in sensors themselves but also from novel ways of using sensors, combining sensor information, and deriving knowledge from that information [124]. As an example, maps displaying interferometric correlation may reveal evidence of the wide range of processes that disturb the scattering surface. Correlation measures the similarity of two radar echoes and is governed by several properties and parameters related to the system and reflecting surface. It is conceivable that decorrelation, like displacement, may be cumulative over time. A planned multimission constellation of SAR satellites could significantly minimize temporal baselines, so that the occurrence of multiple (and therefore indistinguishable) disturbance events could be avoided. The preservation of correlation over time can also be used to infer surface stability, such as for undisturbed soils [125] or floodplain zones that escape flood damage [126]. Similarly, Nolan and Fatland [127] argue that all previously identified sources of phase variation (e.g., vegetation, atmospheric anomalies, topographic residuals, surface roughness) were insufficient to explain certain phase patterns over a 10-month time series for cultivated and uncultivated terrain. Much of this region does not contain soils susceptible to clay swelling, and changes in penetration were hypothesized to be the primary signal source. They propose that the underlying theory behind penetration depth source pertains to changes in soil moisture that affect soil permittivity. Penetration depth decreases with wetter soils, but this relationship with soil moisture is nonlinear. Zebker and Chen [128]  correlation measurements resulting in significantly more accurate estimates, so that inverse models of surface properties are more useful. Their approach derives the underlying mathematical model that relates correlation to fringe rate. Then they developed an inverse method to correct estimation biases for the presence of interferometric fringes. These are examples of \"stability studies\", representing an area of research that is still largely unexplored [129]."}, {"section_title": "Improved Data Dissemination", "text": "InSAR and LiDAR can provide the foundation for informed decision making when assessing natural hazards. To fully realize the benefits gained from Earth observation satellites and other space technologies to collect disaster-related information, data must be disseminated through effective warning systems and networks with products tailored to the needs of the end user. There is an obvious need for timely and accurate data dissemination amongst researchers, civil authorities, and emergency response teams, but the public must also be included because they experience the direct effects of natural hazard events. The public, therefore, has an inherent level of interest and engagement in the underlying science. The U.S. Strategic Plan for an Integrated Earth Observations System [121] provides guidance for agencies contributing to hazard mitigation efforts (including research and development) and may represent the beginning of a more integrated, end-to-end disaster reduction framework. However, a major obstacle for exploiting available or future satellite observations related to natural hazards may be demonstrated by the following dichotomy: Decision makers in hazard management and emergency planners may not be fully aware of existing or planned sensors and the potential and relevance of acquired data for hazard detection and mitigation. In many cases, geoscientists and engineers may not be regularly updated with problems that their mission and sensors could help solve. As remote sensing data become more commonly applied in the earth sciences, an increasing number of researchers will have some experience with remote sensing data products. This growing familiarization will increase researcher's use within their own fields and the potential for further innovative developments and applications in the realm of remote sensing. The rapid evolution of Internet geospatial and location-based services will make communicating and sharing geoscience information easier [124]. Through Internet geospatial portals and geographic search engines, information related to natural hazards is now \"at our fingertips,\" following the trend set by such systems as Google Earth\u2122 or Microsoft \u00ae TerraServer SM ."}]