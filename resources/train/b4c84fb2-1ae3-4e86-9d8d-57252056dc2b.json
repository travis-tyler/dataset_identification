[{"section_title": "I. INTRODUCTION", "text": "Few social programs seem to enjoy the widespread popular support of Head Start.\n1 Poor children represent a sympathetic target population for social programs [Mayer, 1997] . The powerful correlation between the socio-economic status of a child's family and their long-term life chances raises concerns about the fairness of American society as well as the social costs associated with outcomes such as school dropout or criminal behavior [Holzer et al., 2007] . And the fact that the educational deficits of poor children show up very early in the life course, even well before children start kindergarten, provides a powerful logic for intervening early [Knudsen et al., 2006] . Head Start's impacts on poor children seems particularly urgent given that the program is up for re-authorization this year in the U.S. Congress.\nThis essay reviews what is known about the value of Head Start. Our bottom line is that the best available evidence suggests Head Start passes a benefit-cost test. While there remain some important limitations to the available evidence on Head Start, we believe the weight of the evidence points in this direction. In principle there might be ways to increase the cost-effectiveness of current Head Start funding, including changes to Head Start's design or funding alternatives such as state pre-K programs. However the benefits of such changes remain uncertain and they entail some downside risk.\nOur essay seeks to develop five main arguments that lead us to these conclusions.\nFirst, much of the debate about Head Start stems from confusion about how to judge the magnitude of program impacts. We argue that the most appropriate standard for judging the program's success is benefit-cost analysis.\nSecond, over the past several years new evidence has been accumulating about the long-term impacts of Head Start on early cohorts of program participants, as well as about the short-term program impacts on more recent cohorts of children. Research on Head Start's long-term impacts suggests the program passed a benefit-cost test during the first few decades of operation [Currie and Thomas, 1995; Garces, Thomas and Currie, 2002; Ludwig and Miller, 2007] . These findings counter the view that only very intensive (and expensive) early childhood interventions can generate long-term benefits, and also run counter to the perception that Head Start has been a failure from its inception. However these results are not directly informative about whether today's version of Head Start passes a benefit-cost test, since Head Start and the counterfactual developmental environments poor children would otherwise experience are both changing over time. This is a generic challenge to understanding the long-term impacts of contemporaneous government programs -we can only estimate long-term impacts for people who participated in the program a long time ago.\nThe best evidence currently available on Head Start as it operates today comes from a recent randomized experimental evaluation of Head Start's impacts measured within one year of random assignment, which was sponsored by the federal government and carried out by Westat [Puma et al., 2005] . Public discussions of the experimental results have typically focused on the effects of being assigned to the experiment's treatment group rather than the control group, known in the program evaluation literature as the \"intent to treat\" (ITT) impact. These impacts are presented by Westat separately for 3 and 4 year old program participants and are usually in the direction consistent with some beneficial impact of Head Start on children's short term outcomes, but are often not statistically significant.\nThe third objective of our paper is to provide some benchmarks for how large these short-term impacts would need to be in order to believe that any long-term benefits generated by today's Head Start program will be enough to justify the program's costs.\nThis exercise is complicated by the fact that there is currently limited evidence about how the cognitive and non-cognitive skills of young children translate into long-term life outcomes. With this caveat in mind, the evidence that is available suggests that given Head Start's costs (around $7,000 per child on average), the program would pass a benefit-cost test if the short-term impacts on achievement test scores were equal to around .1 to .2 standard deviations, or maybe even much smaller still. programs. There is in our view some uncertainty about both the short-and long-term benefits associated with these changes. There are also downside risks, particularly if one recognizes that there is some opportunity cost associated with the resources required to implement some of the proposed changes to Head Start. Given available evidence the expected net value of changing Head Start is ambiguous."}, {"section_title": "II. THE BENEFITS OF BENEFIT-COST ANALYSIS", "text": "The argument that we should judge the magnitude of Head Start's impacts by how the dollar value of these benefits compare to the cost of the program will not seem like a new idea to economists and policy analysts. Yet much of the public debate about the value of Head Start reflects some basic confusion on this point.\nOne benchmark that has been used to gauge the size of Head Start's impacts is relative to the scale of the social problem that is being addressed. For example Besharov [2005] reviews the Westat report and argues \"these small gains will not do much to close the achievement gap between poor children (particularly minority children) and the general population. We should expect more of a program that serves almost 900,000\nchildren at a cost of $9 billion a year.\"\nBut the right standard of success for a public program is not the elimination of a social problem. Consider, for example, that mortality rates from lung cancer in the U.S.\nin 2003 remain quite high -equal to 71.9 deaths per 100,000 people for males and 41.2 deaths per 100,000 for females [Thun and Jemal, 2006, p. 346] . The fact that thousands of Americans continue to die each year from lung cancer does not mean that the large decline in tobacco smoking observed during the last half of the 20 th century should be considered a public health \"failure,\" particularly since diverting smokers from smoking appears to make them happier as well as healthier [Gruber and Koszegi, 2002; Gruber and Mullainathan, 2002] .\nPsychologists and education researchers often use the typology offered by Jacob Cohen [1977] , who argues that an \"effect size\" (that is, program impact expressed as a share of a control group standard deviation) of .2 should be considered \"small,\" while effect sizes of .5 should be considered \"medium\" and those of .8 or more are \"large.\" Lipsey [1990] conducts a meta-analysis that draws on results from 6,700 studies in education and other related areas and finds that the empirical distribution of estimated effect sizes roughly corresponds to Cohen's categorization [see also Bloom, 2005] . This is the convention adopted by Westat in their report on the short-term results of the recent randomized Head Start experiment."}, {"section_title": "4", "text": "Yet any assessment of what a program accomplishes should take into account not just the program's benefits but also its costs, which necessarily requires conversion of both into some common metric -that is, benefit-cost analysis. A program that improved test scores by .8 standard deviations -\"large\" in Jacob Cohen's [1977] scheme -but cost a total of $10 trillion per year would be difficult to support, since undertaking such an early childhood intervention would absorb the majority of the nation's gross domestic product with very little left to house, clothe, feed and protect the nation's child (and adult) population. At the other extreme a program that generated impacts on the order of Taken together, these impact estimates suggest that Head Start as it operated in the 1960s through 1980s generated benefits in excess of program costs, with a benefitcost ratio that might be at least as large as the 7-to-1 figure often cited for model early childhood programs such as Perry Preschool. Currie [2001] notes that the short-term benefits of Head Start to parents in the form of high-quality child care together with medium-term benefits from reductions in special education placements and grade on African-American participants is the average arrest rate for the siblings of these children, which does not seem to be reported in the study.\nretention might together offset between 40 and 60 percent of the program's costs. Ludwig and Miller's [2007] estimates imply that each extra dollar of Head Start funding in a county generates benefits from reductions in child mortality and increases in schooling attainment that easily outweigh the extra program spending. 7 In addition Frisvold [2007] provides some evidence that Head Start might reduce childhood obesity.\nThese findings run counter to the common view that only very intensive and expensive early childhood interventions are capable of generating long-term benefits.\nThe origin of this conventional wisdom is itself not entirely clear, since there is no logical reason that lower-cost programs will necessarily have lower benefit-cost ratios compared programs [Vinovskis, 2005] , including roles as classroom teachers and aides. But for poor children in the 1960s through 1980s, the evaluation studies described above imply that the environments Head Start children would have experienced if not enrolled in the 7 Ludwig and Miller [2007] estimate the impact of an additional $400 per four year old in Head Start funding in a county. The dollar value of the decline in child mortality is equal to around $120 per four year old in the county. They also estimate an increase in schooling attainment of around one-half year per child. Card [1999] suggests an extra year of schooling increases earnings by 5 to 10 percent. We conservatively assume the extra $400 in Head Start funding raises lifetime earnings by 2 percent per child, which Krueger [2003] shows is worth at least $15,000 in present value using a 3 present discount rate (even assuming no productivity growth over time). The benefits would be even larger if we accounted for the fact that increased schooling also seems to reduce involvement with crime [Lochner and Morretti, 2004] , and that the costs of crime to society are enormous -perhaps as much as $2 trillion per year [Ludwig, 2006] .\nprogram were less developmentally productive than Head Start.\nOne implication of this last point is that the effects of Head Start on poor children may be changing over time in ways that are difficult to predict, and so the long-term impacts of Head Start on previous cohorts of children may not represent the long-term effects of the program on today's participants. Over time the Head Start program has improved in quality, but arguably so has the alternative to Head Start for poor children since parent educational attainments and real incomes have increased since the 1960s and state-funded pre-school programs have been introduced. It is not clear which environment is improving more rapidly in this horse race.\nFortunately the federal government has recently sponsored the first-ever randomized experimental evaluation of Head Start, the Head Start National Impact Study (HSNIS, hereafter \"the randomized Head Start experiment\"), with first-year results that are now available from Westat, the evaluation sub-contractor [Puma et al., 2005] .\nStarting in 2002 nearly 4,700 three and four year old children whose parents applied for Head Start were randomly assigned to a Head Start treatment group or a control group that was not offered Head Start through the experiment, but could participate in other local preschool programs if slots were available. The 84 Head Start centers participating in the experiment were selected to be representative of all programs in operation across the country that had waiting lists.\nThe experiment seems to have been done well -randomization was implemented properly, and careful assessments were made of a wide variety of children's cognitive and non-cognitive outcomes, and parents were also studied. Response rates for both the child and parent assessments were usually around 10 percentage points lower for the control than treatment group. Currie and Thomas [1995] , p. 345, footnote 10, note the PIAT math results are not statistically significant, but that version of the study does not report the math point estimates themselves. However an earlier version of the study, Currie and Thomas [1993] , reports results for PIAT math, PIAT reading and PPVT scores but not results interacted with age, so we cannot recover short-versus long-term effects. However the overall impacts for whites for PIAT math scores are about half as large as the PPVT results, and PIAT reading scores are about 15% of the PPVT impacts. 12 Currie and Thomas [1995, Table 4 ] do find some evidence that Head Start might reduce grade retention for white children who participated in the program in the 1980s or earlier. 13 For example Duncan et al. [2005] do not find much evidence that non-cognitive outcomes measured during early childhood (aside from attention skills) predict later test scores, although other correlational studies have found that socio-emotional outcomes, notably aggressive behavior, do seem to contribute to children's achievement trajectories [Hinshaw, 1992; Jimerson, Egeland, and Teo, 1999; Miles and Stipek, 2006; Tremblay et al., 1992] . 14 These correlational data of course have important limitations in illuminating the causal relationships of early childhood outcomes with later outcomes. For example suppose that most parents read to their children, but what really distinguishes the most scholastically motivated parents from their peers is that the former try to impact math skills to their children even during the early childhood period. In this case the relatively strong correlation between early math and later scores could simply be a stand-in for the influence of parent motivation to help their children learn, and so an increase in early math skills induced by some intervention would yield longer-term impacts that are smaller than Duncan et al.'s correlations would suggest. Alternatively one can also imagine that children with early childhood socio-emotional"}, {"section_title": "IV. SHORT-TERM BENCHMARKS FOR LONG-TERM SUCCESS", "text": "The fact that early childhood programs like Head Start achieve long-term behavioral impacts despite \"fade out\" of initial achievement test score gains suggests that lasting program impacts on non-cognitive skills might be the key drivers of long-term program impacts on outcomes such as school completion or employment [see for example Carniero and Heckman, 2003] . But it is possible that short-term boosts in academic skills are a key mechanism for improving non-cognitive skills such as motivation and persistence by for instance increasing children's confidence in school [Barnett, Young and Schweinhart, 1998 ]. partial fade-out of test score impacts, Perry Preschool shows large long-term impacts on schooling, crime and other outcomes measured through age 40 [Schweinhart et al., 2005] .\nThe dollar value of Perry Preschool's long-term benefits (in present dollars) range from nearly $100,000 calculated using a 7 percent discount rate to nearly $270,000 using a 3 percent discount rate [Belfield et al., 2006, p. 180-1] .\nSuppose that short-term test score impacts are proportional to the dollar value of long-term program benefits. In this case, even if we used a conservative 7 percent discount rate Head Start's short-term impacts would need to be at most around 7 percent as large ($7,000 / $100,000) as those of Perry Preschool (that is, around .08 and .05 standard deviations for vocabulary and nonverbal performance, respectively) to generate benefits that are large enough to outweigh Head Start's costs of around $7,000 per child.\nIf we use a 3 percent discount rate instead, the necessary short-term impacts may be more on the order of .03 and .02 standard deviations, respectively.\nOf course it might be possible that long-term gains are not strictly proportional to short-term impacts. For example, it could be the case that some minimum short-term impact is necessary in order to generate lasting cognitive or non-cognitive benefits. It could also be the case that the behavioral consequences of achievement impacts on the low-IQ sample of Michigan children in Perry Preschool are different from those arising from similar-sized impacts on a more representative Head Start population. But, at a minimum, the Perry Preschool data raise the possibility that \"small\" short-term impacts might be sufficient for a program with the costs of Head Start to pass a benefit-cost test."}, {"section_title": "B. The Value of Increasing Early Childhood Test Scores", "text": "15 Currie [2001] cites Perry costs of $12,884 per child in 1999 dollars.\nAnother way to think about how large Head Start's short-term impacts would need to be in order for the program to pass a benefit-cost test is to measure directly the value of a 1 standard deviation increase in early childhood test scores. Because few studies have followed people from early childhood all the way through adulthood, this exercise is necessarily subject to some uncertainty. But the evidence that is available suggests that short-term effect sizes of .15 to .2 might be more than enough for Head\nStart to pass a benefit-cost test, consistent with the evidence from the previous section.\nThe British National Child Development Study (NCDS) is one of the few datasets available for this purpose, and includes achievement test scores measured at age 7 and earnings measured at age 33 for a sample of people born in the U.K. in 1958. Krueger [2003] argues that analyses of these data suggest that an increase in early childhood test scores in either reading or math of 1 standard deviation might plausibly be associated with higher lifetime earnings of about 8 percent.\n16 If Krueger's argument is correct, then the short-term impacts on reading or math that would be needed to generate $7,000 in benefits from increased future earnings would be on the order of around .07 (using a 3 percent discount rate and assuming no productivity growth). 17 If we assume productivity growth of 2 percent, then the short-term impact on reading or math scores necessary to generate $7,000 in benefits could be as little as .04 standard deviations.\n16 Krueger [2003] notes that Currie and Thomas' [1999] analyses of these data imply that a 1 standard deviation increase in test scores increases lifetime earnings by around 8 percent. This impact is smaller than what has been estimated for a 1 standard deviation increase in test scores measured during adolescence for more recent US samples, which typically suggest earnings gains of around 20 percent. The difference is presumably due as Krueger notes to some combination of differences in the time period studied, the US vs UK labor markets, the fact that Currie and Thomas control for both reading and math scores simultaneously while most US studies examine one type of test score at a time in their effects on earnings. 17 Krueger [2003] reports increased lifetime earnings from a .2 standard deviation increase in test scores using a 3 percent discount rate and assuming no productivity growth of $15,174 in 1998 dollars, equal to around $18,800 in current dollars. So the effect size required to generate $7,000 in benefits is equal to ($7,000 / $18,800)*.2 = .37*.2 = .07. On the other hand, the calculations presented above assume that the only benefit from increased early test scores is higher adult earnings. But anything that increases early childhood test scores and subsequently future earnings could affect other outcomes as well. Crime is one of the most important of these other outcomes, given that the social costs of crime might be on the order of $2 trillion per year [Ludwig, 2006] . In the Perry Preschool experiment, around two-thirds of the total dollar-value of the program's benefits came from crime reductions [Belfield et al., 2006] . "}, {"section_title": "V. HOW LARGE ARE HEAD START'S CURRENT SHORT-TERM IMPACTS?", "text": "The best available evidence on current Head Start's impacts on children comes from the Head State National Impact Study carried out by Westat for the U.S.\nDepartment of Health and Human Services, which we will refer to for convenience as \"the randomized Head Start experiment.\" The results of this experiment have been characterized as \"disappointingly small\" [Besharov, 2005, p . 1], although much of the public discussion of these findings seems to confuse the intent to treat effects emphasized in Westat's report on the experimental results with the effects of Head Start participation per se (that is, the effects of treatment on the treated. The short-term impacts of Head Start participation are usually equal to or greater than the .1 or .2 standard deviation benchmark that is necessary for Head Start to pass a benefit-cost test. While many of the point estimates that Westat calculates separately for 3 and 4 year old program participants are not statistically significant, our calculations suggest that pooling data for 3 and 4 year olds leads impact estimates for almost all of the main cognitive outcome measures emphasized in the Westat report's Executive Summary to be statistically significant. But more importantly the expected value of the program is positive."}, {"section_title": "A. Intent-to-Treat Effects vs. the Effects of Head Start Participation", "text": "One common source of confusion about the recent randomized Head Start distribution in first grade will on average be at the 27 th percentile of the distribution in 12 th grade.\nexperiment stems from the fact that the main results, particularly those in the executive summary to the several-hundred-page report, are not intended to reflect the effects of actual Head Start participation. The executive summary and most of the tables in the body of the report itself focus on the causal effects of offering children the chance to participate in Head Start by assigning them to the Head Start experimental group -that is, the intent to treat impact. These results are often discussed as if they represent the effects of Head Start participation. They do not.\nIn practice not everyone who is offered the chance to participate in Head Start will actually enroll -parents, for example, might decide that Head Start will not meet their own or their children's needs or better alternative opportunities might present themselves. If some people assigned to the experimental treatment group do not participate in the program, and, relatedly, if some people assigned to the control group enroll in Head Start on their own, then the effects of Head Start participation (the effect of treatment on the treated) can be different -sometimes quite different -from the effects of treatment-group assignment.\nThe problems of drawing inferences about Head Start participation from the effects of treatment-group assignment can be easily seen by imagining an example in which everyone assigned to the treatment group participates in Head Start ... but because of their own efforts, so does everyone in the control group. If the average quality of the Head Start programs experienced by children in the treatment and control groups were the same, the effects of treatment group assignment (the intent-to-treat estimate) would be equal to exactly zero. It would obviously be incorrect to infer from these estimates that Head Start does nothing to improve the life chances of participating children. The central point is that if Head Start participation rates are less than 100% among children assigned to the treatment group or greater than 0% among those in the control group, or both, then the effects of actual Head Start enrollment (the effect of treatment on the treated) will be larger than the estimated effect of being assigned to the treatment group (the intent-to-treat effect).\nIn the Head Start experimental data we see that around 86% of 4 year olds assigned to the experimental treatment group enrolled in Head Start, while 18% of 4 year olds assigned to the control group wound up in Head Start on their own [p. 3-7, Puma et al., 2005] . 19 The body of the report does mention that the intent-to-treat estimates will understate the effects of actually participating in Head Start. But the report's description of how it tries to convert the intent-to-treat estimates into something like an estimate for the effect of Head Start participation is confusing and the actual approach they employ might be misleading. In any case these results are relegated to one of the appendices and perhaps as a result seem to have been largely ignored in public discussions compared to the intent-to-treat estimates included in the Executive Summary."}, {"section_title": "20", "text": "More than 20 years ago, Howard Bloom [1984] proposed a method for translating intent-to-treat effects into estimates for the effects of treatment on the treated. He noted that under some conditions we can learn about the effects of treatment participation -in this case, Head Start enrollment -by scaling differences in the treatment and control 19 The figures for 3 year olds assigned to the treatment and control groups equal 89% and 21%, respectively. 20 The report describes the Bloom [1984] procedure for handling \"no shows\" in the treatment group, but does not use this procedure to handle the problem of control group members who wind up in Head Start on their own [p. 4-29, 4-35] . Instead the report seems to drop control group families who wind up in Head Start on their own and then re-weight the remaining control group members; see pp. 6 . The report mentions the Bloom [1984] approach we use to calculate TOT impacts accounting for compliance rates in both the treatment and control groups on p. 4-36 but notes only that Westat will explore how findings from this procedure compare to their default procedure in future reports. groups in average outcomes by the difference in the treatment and control groups in treatment participation rates. This procedure assumes random assignment is in fact random, and that treatment group assignment has no effect on children who do not participate in Head Start. 21 In addition, the Bloom procedure assumes that everyone who would participate in Head Start if assigned to the control group would also participate if they had been assigned to the treatment group instead. It further assumes that the average quality of the Head Start programs attended by children assigned to the treatment versus control groups is comparable. This latter assumption may be more problematic, but even fairly large differences in Head Start program quality between Head Start enrollees in the treatment and control group would impart relatively modest bias to the estimates derived from Bloom's procedure.\nWhy focus on the effects of actually participating in Head Start rather than the intent-to-treat estimates? One answer is that the effect sizes for the Head Start A more important reason for focusing on estimates for the effects of actually participating in Head Start (treatment on the treated) is to avoid confusion in conducting a benefit-cost analysis of Head Start. In public discussions about Head Start's costs, the 21 Stated differently, the latent propensity to participate in Head Start if assigned to the treatment group is assumed to be equivalent for children who were, in fact, assigned to the treatment and control groups. This should be true if random assignment was in fact random, since the propensity to participate in Head Start -focus is always on the costs per actual enrollee. The benefit measure that should be compared with this cost is then the dollar value of the benefits per enrollee -that is, the dollar-value of the gains from actually participating in Head Start.\nIt is possible that Westat's report on the Head Start experiment focuses more on intent-to-treat impacts than on the effects of treatment on the treated because either\nWestat or the U.S. Department of Health and Human Services might be uncomfortable with presenting treatment-on-the-treated estimates that do require imposing some additional assumptions on the data beyond those necessary to calculate the intent-to-treat effects. Our own view is that even if some of the assumptions for calculating the treatment-on-the-treated impacts are not strictly true (for example if there is some difference in program quality for children enrolled in Head Start in the experiment's treatment versus control groups), the treatment-on-the-treated estimates still provide more useful approximations for the effects of actually enrolling in Head Start, and help avoid confusion along the lines described above.\nReaders who are uncomfortable with the assumptions required for the treatmenton-the-treated calculations can conduct their own benefit-cost analysis using the intentto-treat impact estimates, but must then be careful to adjust the cost side of the equation appropriately. If the difference in Head Start enrollment rates between the Head Start experiment's treatment and control groups equals (86% -18%) = 68%, then the right \"cost\" for comparison to the intent-to-treat \"benefit\" would equal the average Head Start cost per child assigned to the HSNIS treatment group minus the average Head Start cost like all other baseline characteristics -will be equally distributed between treatment and control groups (subject to sampling error).\nper child assigned to the control group. This cost figure equals 68% * $7,000 = $4,760."}, {"section_title": "22", "text": ""}, {"section_title": "B. Head Start's Short-Term Impacts", "text": "In Table 1 we show the ITT impacts on each of the cognitive outcome domains reported in the Executive Summary of Westat's report for the first-year findings of the Head Start experiment [Puma et al., 2005] . While the published Westat report did not show standard errors for impact estimates, Ronna Cook at Westat has very generously made these available to us. In Table 1 we present point estimates and standard errors that are converted into effect size terms (i.e. expressed as a share of the control group standard deviation for that outcome measure).\n23 Table 1 also presents our own estimates for the effects of actually participating in\nHead Start (the effects of treatment on the treated) derived using Bloom's approach together with information about Head Start enrollment rates in the experiment's treatment and control groups. In the Head Start experiment, the difference in Head Start participation rates between the treatment and control groups is around 68 percentage points and so, using the Bloom procedure, we would estimate that the effects of Head Start enrollment on children are about 1.5 times as large as the intent-to-treat effects that are commonly misinterpreted to represent the effects of Head Start participation. These 22 It is easy to see that since both the costs and benefits of the ITT calculation are proportional to the TOT calculations by the treatment-control difference in Head Start enrollment rates, evidence for benefits in excess of costs for the ITT approach implies the same must be true with the TOT approach and vice versa. The important thing is to avoid comparing the dollar value of the ITT impact estimates with the costs per Head Start enrollee. 23 In the body of the report Westat presents a series of different impact estimates for each outcome domain, including those that do not adjust for baseline characteristics, those that adjust for baseline sociodemographic characteristics only, and those that also adjust for fall outcome measures in looking at spring test scores. Because the fall outcome measures are collected mostly by mid-November (collected over the period October to December), in principle controlling for these measures could understate Head Start's impacts due to program effects that arise during the early parts of the academic year. Table 1 presents Westat's own preferred regression-adjusted point estimates and standard errors, based on Westat's examination of whether there is any evidence of program gains between the beginning of the school year and when the fall outcome measures are collected.\nresults are best interpreted as providing a range within which the \"true\" effects of Head Start likely fall. If the average Head Start program quality is somewhat higher for the treatment than control groups then our Bloom-style estimates for the effects of treatment on the treated might be biased upward somewhat.\nNote also that our estimates for the effects of Head Start participation also assume that the 10 percentage point difference in response rates between the Head Start experiment treatment and control groups [Puma et al. 2005, p. 1-18] do not impart any bias to the basic intent-to-treat estimates. Of course if there is selective sample attrition that biases the basic intent-to-treat estimates, this would represent a more fundamental problem with the Head Start experiment that cannot be solved by focusing on the intentto-treat effects rather than the effects of treatment on the treated. Table 1 shows that at least for cognitive skills all of the Head Start impact estimates point in the direction consistent with beneficial program impacts, although many of these point estimates are not statistically significant and in general the point estimates are larger (both absolutely and in relation to their standard errors) for 3 year olds than 4 year olds. For rhetorical convenience we focus on the effects of treatment on the treated estimates because we believe they are likely to be much closer approximations of the true effect of Head Start participation per se than are the intent-to-treat estimates.\nNevertheless, it should be understood that the true impact is probably somewhere in between the ITT and TOT estimates. A different concern that has been raised about these impact estimates comes from the ability of the available assessments to detect reliable impacts of this size in young children. One criterion we have for cognitive or non-cognitive assessments is that they are reliable -that is, they generate similar results when applied on different occasions. A standard concern is that assessments of very young children may not be very reliable, for reasons that will be obvious to anyone who has ever been the parent of a young child (short attention span, variability in temperament and willingness to cooperate, and so on).\n24 Rock and Stenner [2005, p. 21] note that for the Early Childhood Longitudinal Study of the Kindergarten Class of 1998-99 (ECLS-K) parent reports of children's social competence and skills have not proven reliable, with \"the main concern [being] that parents often have little basis for determining whether behavior is age appropriate.\" Analogous concerns could in principle apply to parent reports about Reliability scores for achievement tests administered to adolescents are usually on the order of .8 to .9 [see for example Murnane et al., 1995] . Westat shared with us the reliability scores for the cognitive outcomes used in the Head Start experiment and these are typically on the same order but sometimes a bit lower. They are also lower for measures of non-cognitive skills compared to cognitive outcomes [see also Rock and Stenner, 2005] ."}, {"section_title": "25", "text": "If the limitations of available assessments simply introduce random noise into children's outcome scores, then the dependent variables in the Head Start experimental analysis will suffer from classical measurement error and the result would simply be less precise estimation of Head Start impacts (i.e., larger standard errors). This concern would provide a candidate explanation for why so many of the Head Start experimental impact estimates are not statistically significant, but does not pose a threat for interpretation of those impact estimates that are statistically significant."}, {"section_title": "C. Statistically Insignificant Impact Estimates", "text": "For policy purposes what we want to know is whether Head Start passes a benefitcost test. Most of the estimates for the effects of Head Start participation presented in Knudsen et al. [2006] ), it further reduces statistical power. Perhaps more importantly, while scientific convention is to ignore estimates that are not statistically significant at the usual 95 percent cutoff (that is, assume they are zero), we believe that a more productive way to proceed for policy purposes is to focus on the expected value of the program benefits and costs, as suggested by Cook and Ludwig [2006] . The reason is that following the course of action associated with the null hypothesis of no statistically significant impact is itself a policy decision that winds up being overly privileged if we only follow through on point estimates that meet the usual standard for statistical significance.\nTo see the difference, we revisit the hypothetical program we introduced in Section II above, which we assume increases children's test scores by .2 standard deviations at a cost of just a nickel per child. Suppose that a randomized experimental evaluation of this intervention yielded a point estimate for a treatment effect of .2 standard deviations, but that the standard error was somewhat large and so the p-value for this estimate was equal to .8. While no referee worth her salt would endorse a scientific manuscript that claimed that this intervention \"works,\" at the same time she would surely wish that her own child's school district jumped at the chance to adopt this program.\nThis sort of expected value framework suggests that Head Start as it currently operates is likely to pass a benefit-cost test. There are good reasons to believe that shortterm impacts on reading and math scores on the order of .1 to .2 standard deviations, and perhaps much smaller than that, would be large enough for Head Start to generate benefits in excess of costs. Table 1 shows that most of the point estimates for Head Start's effects on cognitive skills for both 3 and 4 year olds are of about this magnitude, even when these estimates are not statistically significant for the two samples."}, {"section_title": "VI. HEAD START ALTERNATIVES", "text": "The fact that the current incarnation of Head Start seems to pass a benefit-cost test does not rule out the possibility that there could be even more cost-effective ways of deploying Head Start resources. One possibility that has figured prominently in debates about Head Start is to make the program more academically oriented, rather than focused on providing a broad range of academic, health, nutrition, and social services to disadvantaged children. The assumption is that focusing a greater share of children's time in the program on academic instruction will generate stronger achievement outcomes. Some observers point to larger impact estimates that have been reported from recent studies of new universal state pre-K programs, which are more narrowly focused on instructional activities. They suggest that we should make Head Start operate more like those programs, particularly with respect to the state pre-K requirements that teachers have four-year college degrees, or even divert funding from Head Start to the state programs. These proposals hold some intuitive appeal. However the benefits associated with these changes in practice are uncertain, plus there is some downside risk, and so the expected value of these proposed changes to Head Start remain unclear at the present time. A third candidate explanation for the difference in impact estimates for state universal pre-K programs and Head Start is the possibility of bias within the recent evaluations of state pre-K programs. While these recent state pre-K studies are major improvements over anything that has been done to examine such programs in the past, they are nonetheless all derived using a research design that may be susceptible to bias of unknown sign and magnitude. Specifically, these recent studies all use a regression discontinuity design that compares fall semester tests for kindergarten children who participated in pre-K the previous year and have birthdates close to the cutoff for having enrolled last year with fall tests of children who are just starting pre-K by virtue of having birthdates that just barely excluded them from participating the previous year. One identifying assumption here is that the selection process of children into pre-K is \"smooth\" around the birthday enrollment cutoff, but this need not be the case since there is a discrete change at the birthday threshold in terms of the choice set that families face in making this decision.\nFor instance, suppose that among the children whose birthdays just barely excluded them from enrolling in pre-K during the previous year, those with the most motivated parents wound up being sent the previous year to private programs that are analogous to the public pre-K program and are then enrolled in private kindergarten programs in the fall semester that the pre-K study outcome measures are collected. This type of selection would reduce the share of more motivated parents among the control group in the pre-K studies and lead them to overstate the benefits of pre-K participation.\nMoreover the pre-K evaluations that have been done to date focus on those states that are leaders in this area. The experiences of pre-K programs in these states may or may not reflect the average pre-K effect we would observe if we made a wholesale shift of resources from Head Start to pre-K.\nThe critical policy question is whether such a shift would create the possibility of greater benefits or of harm. Presently, this is an unanswerable question. The recent Head Start experimental evaluation, as well as the on-going evaluation of Early Head Start, have pointed in the direction of beneficial impacts on both cognitive and non-cognitive outcome domains (e.g., social, emotional, and health outcomes), even if not all of the impact estimates are statistically significant. Previous studies have also found beneficial Head Start impacts on health outcomes and on crime reduction [Garces et al., 2002; Ludwig and Miller, 2007; Frisvold, 2007] . Changing Head Start's design to make the program more academic, or to look more like existing universal state pre-K programs, or even to shift Head Start funding to state programs that sometimes rely on mixed delivery represents an average of half-and full-day students.\nsystems could potentially generate improved academic outcomes, but the possible impacts on these other important domains of development remain unknown. While evaluations of high-quality, intensive early childhood interventions have found positive short-and long-term impacts on social-emotional outcomes, studies focusing on community-based child care have found some unfavorable social outcomes with greater participation especially in center-based care [Magnuson, Ruhm and Waldfogel, 2004; Zaslow, 2006] . Studies of state-funded universal pre-K programs have not yet reported findings for social-emotional outcomes. As a result policy actions that would shift or withdraw resources from Head Start are risky.\nIt is important to recognize that a different kind of risk from changing Head Start comes from the fact that the resources required to implement some of the proposed changes have some opportunity cost, since the funding in question could in principle have been devoted to other uses, including other social programs. For instance, an increasingly common proposal is to require Head Start teachers to hold 4 year college degrees. This change would require higher salaries to recruit and retain more highlyeducated teachers, which would require either more spending for the Head Start program as a whole or else reductions in other parts of the Head Start budget. Even knowing that requiring BA-level teachers leads to improved student outcomes would not be sufficient to endorse this policy from an economist's perspective. We would want to know how these gains compare to what could be achieved from devoting those extra resources to other uses such as further reducing class sizes in Head Start, 27 expanding the program's coverage to more eligible low-income children, or improving pre-natal health and outreach services to low-income women. Given these downside risks, it is possible to determine whether alternative uses of Head Start funding that have been proposed have positive or negative expected value."}, {"section_title": "VII. CONCLUSIONS", "text": "There is credible evidence that Head Start generates long-term benefits and passes a benefit-cost test, at least for children who participated during the first few decades of We certainly do not mean to claim that Head Start is a perfect program that cannot be improved. It is possible that modifying the program in some of the ways that have been discussed in recent years, such as increasing the program's academic focus to better target those skills that predict later literacy [Zaslow, 2006] , or requiring teachers to hold a four-year college degree, could make the program more effective or even more 27 Currie and Neidell [forthcoming] suggest that redirecting resources to increase teacher qualifications and salaries within the existing Head Start budget at the expense of small class sizes would on net lead to worse -36 -cost-effective. But there is some uncertainty about the benefits that would be achieved by such changes, and there is some downside risk associated with each of these proposals -particularly when one recognizes that the resources required to implement them entail some opportunity cost.\nIn sum, the available evidence suggests to us that the Head Start program as it currently operates probably passes a benefit-cost test. Changing the program in various ways that have figured prominently in recent policy discussions may not make the program any better, and could make things worse. student outcomes. First and third columns reproduce ITT impact estimates for all cognitive outcomes reported in Westat's Executive Summary of the first year findings report from the National Head Start Impact Study, reported as effect sizes, i.e. program impacts divided by the control group standard deviation (Puma et al., 2005) . Standard errors are shown in parentheses also in effect size terms; these were not included in the Westat report but were generously shared with us by Ronna Cook of Westat. Second and fourth columns are our own estimates for the effects of treatment on the treated (TOT) derived using the approach of Bloom (1984) , which divides the ITT point estimates and standard errors by the treatment-control difference in Head Start enrollment rates. For 3 year olds the adjustment is to divide ITT by (.894 -.213) = .681, for 4 year olds adjustment is to divide ITT by (.856 -.181) = .675 (see Exhibit 3.3, Puma et al., 2005, p. 3-7) . * = Statistically significant at the 5 percent cutoff."}]