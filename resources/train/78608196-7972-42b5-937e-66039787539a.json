[{"section_title": "Abstract", "text": "Population imaging markedly increased the size of functional-imaging datasets, shedding new light on the neural basis of inter-individual differences. Analyzing these large data entails new scalability challenges, computational and statistical. For this reason, brain images are typically summarized in a few signals, for instance reducing voxel-level measures with brain atlases or functional modes. A good choice of the corresponding brain networks is important, as most data analyses start from these reduced signals. We contribute finely-resolved atlases of functional modes, comprising from 64 to 1024 networks. These dictionaries of functional modes (DiFuMo) are trained on millions of fMRI functional brain volumes of total size 2.4TB, spanned over 27 studies and many research groups. We demonstrate the benefits of extracting reduced signals on our fine-grain atlases for many classic functional data analysis pipelines: stimuli decoding from 12,334 brain responses, standard GLM analysis of fMRI across sessions and individuals, extraction of resting-state functionalconnectomes biomarkers for 2,500 individuals, data compression and meta-analysis over more than 15,000 statistical maps. In each of these analysis scenarii, we compare the performance of our functional atlases with that of other popular references, and to a simple voxel-level analysis. Results highlight the importance of using high-dimensional \"soft\" functional atlases, to represent and analyse brain activity while capturing its functional gradients. Analyses on highdimensional modes achieve similar statistical performance as at the voxel level, but with much reduced computational cost and higher interpretability. In addition to making them available, we provide meaningful names for these modes, based on their anatomical location. It will facilitate reporting of results."}, {"section_title": "Introduction", "text": "Population imaging has been bringing in terabytes of high-resolution functional brain images, uncovering the neural basis of individual differences (Elliott et al., 2008) . While these great volumes of data enable fitting richer statistical models, they also entail massive data storage (Poldrack et al., 2013; Gorgolewski et al., 2017) and challenging high-dimensional data analysis. A popular approach to facilitate data handling is to work with image-derived phenotypes (IDPs), i.e. low-dimensional signals that summarize the information in the images while keeping meaningful representations of the brain (Miller et al., 2016) . While brain atlases originated in characterizing the brain's microstructure (Brodmann, 1909) , today they are widely used to study functional connectomes (Sporns et al., 2005; Varoquaux and Craddock, 2013) and for data reduction in functional imaging (Thirion et al., 2006; Craddock et al., 2012) . For these applications, the choice of brain regions conditions the signal captured in the data analysis. To define regions well suited to brain-imaging endeavors, there is great progress in building atlases from the neuroimaging data itself (Eickhoff et al., 2018 ). Yet, most functional atlases describe the brain as parcellations, locally-uniform functional units, and thus do not represent well functional gradients (Huntenburg et al., 2018) .\nFor functional imaging, brain structures delineated by an atlas should capture the main features of the functional signal, e.g. the functional networks (Smith et al., 2011) . In a nutshell, there are two approaches to define well-suited structures. These can strive to select homogenous neural populations, typically via clustering approaches (Goutte et al., 1999; Bellec et al., 2010; Craddock et al., 2012; Thirion et al., 2014; Schaefer et al., 2017) . They can also be defined via continuous modes that map intrinsic brain functional networks (Damoiseaux et al., 2006; Varoquaux et al., 2011; Harrison et al., 2015) . These functional modes have been shown to capture well functional connectivity, with techniques such as Independent Component Analysis (Kiviniemi et al., 2009; Pervaiz et al., 2019) or sparse dictionary learning (Mensch et al., 2016b; Dadi et al., 2019) .\nHigh-resolution atlases can give a fine-grained division of the brain and capture more functionally-specific regions and rich descriptions of brain activity (Schaefer et al., 2017) . Yet, there is to date no highly-resolved set of \"soft\" functional modes available, presumably because increasing the dimensionality raises significant computa-tional and statistical challenges (Mensch et al., 2016a; Pervaiz et al., 2019) . In this paper, we address this need with high-order dictionaries of functional modes (DiFuMo) extracted at a large scale both in terms of data size (3 million volumes of total data size 2.4TB) and resolution (up to 1024 modes). For this, we leverage the wealth of openlyavailable functional images (Poldrack et al., 2013) and efficient dictionary-learning algorithms to fit on large data. This is unlike ICA which is hard to use for a high number of modes (Pervaiz et al., 2019) .\nContributions. We provide Dictionaries of Functional Modes 1 \"DiFuMo\" that can serve as atlases to extract functional signals, e.g. provide IDPs, with different dimensionalities (64, 128, 256, 512, and 1024) . These modes are optimized to represent BOLD data well, over a wide range of experimental conditions. They are more finelyresolved than existing brain decompositions with continuous networks. By providing validated fine functional atlases, our goal is to streamline fMRI analysis with reduced representations, to facilitate large-cohort and inter-studies work. Through thorough benchmarking over classic data analysis tasks, we show that these modes gives IDPs that ground better analysis of functional images. Finally, we provide a meaningful label to each mode, summarizing its anatomical location, to facilitate reporting of results."}, {"section_title": "Methods:", "text": "data-driven fine-grain functional modes\nWe describe in this section the models and methods underlying our definition of brain structures to extract IDPs."}, {"section_title": "Context: Image Derived Phenotypes", "text": "While analysis of brain images has been pioneered at the voxel level (Friston et al., 1995) , image-derived phenotypes (IDP) are increasingly used in the context of population imaging. Trading voxel-level signals for IDPs has several motivations. First and foremost, it greatly facilitates the analysis on large cohorts: the data are smaller, easier to share, requiring less disk storage, computer memory, and computing power to analyze. It can also come with statistical benefits. For instance, in standard analysis of task responses, e.g. in mass-univariate brain mapping, the statistical power of hypothesis test at the voxel level is limited by multiple comparisons (Friston et al., 1995) , while working at the level of IDPs mitigates this problem (Thirion et al., 2006) . For predictive modeling, e.g. in multi-variate decoding (Mour\u00e3o-Miranda et al., 2005) , the high-dimensionality of the signals is a challenge to learning models that generalize well-a phenomenon known as the curse of dimensionality in machine learning (Hastie et al., 2009 ). Finally, for functional connectomes, working at voxel-level is computationally and statistically intractable 1 https://parietal-inria.github.io/DiFuMo as it entails modeling billions of connections. The standard approach is therefore to average signals on regions or networks (Varoquaux and Craddock, 2013) .\nFunctional neuroimaging is currently largely dependent on neuroanatomy for mapping function to structure (Destrieux et al., 2010; Devlin and Poldrack, 2007) . Some anatomical structures support well a direct mapping to specific functions (Brett et al., 2002; Rademacher et al., 1993) , e.g. the primary visual areas. Yet other functional units are not simply defined from anatomical features, for instance in high-level regions such as the default mode, which is defined from functional data (Leech et al., 2011; Greicius et al., 2003) ."}, {"section_title": "Methods for data-driven functional atlases", "text": "Compared to anatomical atlases, defining regions from the functional signal can lead to a better explanation of behavioral outcomes (Dadi et al., 2019) , as they capture the functional structure of the brain. Clustering of fMRI timeseries has been heavily used to define brain parcellations (Goutte et al., 1999) , or for data reduction in predictive models (Michel et al., 2012) . Reference functional brain parcellations have been defined with various clustering algorithms on resting-state fMRI (Bellec et al., 2010; Yeo et al., 2011; Craddock et al., 2012) . Another class of approaches seeks modes of brain activity, decomposing the signal as a product of spatial maps and corresponding time-series ( Figure 1) . The most popular model in neuroimaging is independent component analysis (ICA, Hyv\u00e4rinen and Oja, 2000) , which optimizes spatial independence between extracted maps. It has been extensively used to define resting-state networks (Kiviniemi et al., 2003; Beckmann et al., 2005; Calhoun et al., 2001) and implicitly outlines soft parcellations of the brain at high order (Kiviniemi et al., 2009; Varoquaux et al., 2010b) . ICA-defined networks are used to extract the official IDPs of UK BioBank, the largest brain-imaging cohort to date; these have been shown to relate to behavior (Miller et al., 2016) .\nWe rely on another decomposition model, dictionary learning (Olshausen and Field, 1997) , that enforces sparsity and non-negativity instead of independence on the Voxels Time = k spatial maps Time\nx Figure 1 : Linear decomposition model of fMRI time-series for estimating brain networks: The fMRI time series X are factorized into a product of two matrices, D wich contain spatial modes and A temporal loadings of each mode. p -number of features, nnumber of volumes in fMRI image, k -number of dictionaries. spatial maps. While less popular than ICA in neuroimaging, sparsity brings the benefit of segmenting well functional regions on a zeroed-out background (Lee et al., 2010; Varoquaux et al., 2011) . For our purposes, an important aspect of sparse models is that they have computationallyscalable formulations even with high model order and on large datasets (Mensch et al., 2016a (Mensch et al., , 2018 . Functional modes defined from sparse dictionary learning have been used to predict Autism Spectrum Disorder (Abraham et al., 2017) , or mental processes (Mensch et al., 2017) .\nRest and task fMRI. Most functional brain atlases have been extracted from rest fMRI (Bellec et al., 2010; Power et al., 2011; Craddock et al., 2012; Yeo et al., 2011; Miller et al., 2016; Schaefer et al., 2017) . Brain networks can also be extracted from task fMRI data (Calhoun et al., 2008; Lee et al., 2010) , and segment a similar intrinsic largescale structure (Smith et al., 2009) . In our work, we build functional modes from datasets with different experimental conditions, including task and rest. Our goal is to be as general as possible and capture information from different protocols. Indeed, defining networks on task fMRI can help representing these brain images and predicting the corresponding psychological conditions (Duff et al., 2012) ."}, {"section_title": "DiFuMo extraction: model and data", "text": "We consider BOLD time-series from fMRI volumes, resampled and registered to the MNI template. After temporal concatenation, those form a large matrix X \u2208 R p\u00d7n , where p is the number of voxels of the images (around 2 \u00b7 10 5 ), and n is the number of brain images, of the order of 10 6 in the following. To extract DiFuMos, each brain volume is modeled as the linear combination of k spatial functional networks, assembled in a dictionary matrix D \u2208 R p\u00d7k . We thus assume that X approximately factorizes as DA, where the matrix A \u2208 R k\u00d7n holds in every column the loadings \u03b1 i necessary to reconstruct the brain image x i from the networks D. The dictionary D is to be learned from data. For this, we rely on Stochastic Online Matrix Factorization 2 (Mensch et al., 2018, SOMF) , that is computationally tractable for matrices large in both directions, as with high-resolution large-scale fMRI data. SOMF solves the constrained 2 reconstruction problem\nwhere \u03bb is a regularization parameter that controls the sparsity of the dictionary D, via the 1 and positivity constraints. Encouraging sparsity in spatial maps is key to obtaining well-localized maps that outline few brain regions. The parameter \u03bb is chosen so that the union of all maps approximately covers the whole brain.\n2 Available at: https://arthurmensch.github.io/modl/ Input fMRI data. We build the input data matrix X with BOLD time-series from 25 different task-based fMRI studies and 2 resting state studies, adding up to 2 192 functional MRI recording sessions. We gather data from OpenNeuro (Gorgolewski et al., 2017) - Table A4 lists the  corresponding studies while Table A5 gives their dataacquisition parameters. We use fMRIprep (Esteban et al., 2019) for minimal preprocessing: brain extraction giving as a reference to correct for head-motion (Jenkinson et al., 2002) , and coregistration to anatomy (Greve and Fischl, 2009 ). All the fMRI images are transformed to MNI template space. We then use MRIQC (Esteban et al., 2017) for quality control.\nMulti-dimensional DiFuMo atlases. We estimate dictionaries of dimensionality k \u2208 {64, 128, 256, 512, 1024}. This is useful as the optimal dimensionality for extracting IDPs often depends on the downstream data analysis task. The obtained functional modes segment well-localized regions, as illustrated in Figure 2 ."}, {"section_title": "Extracting signal on functional modes", "text": "The functional modes take continuous values (we refer to them as soft) and can have some overlap -though in practice this overlap is small. As a consequence, signal extraction calls for more than averaging on regions. The natural formulation is that the extracted signals (the IDPs) should best approximate the brain image x \u2208 R p as a linear combination \u03b1 \u2208 R k of the set of modes in the dictionary D \u2208 R p\u00d7k . This is solved by linear regression:\nwhere\nFor atlases composed of non-overlapping regions, such as classic brain parcellations-e.g. BASC (Bellec et al., 2010) or normalized cuts (Craddock et al., 2012)linear regression simply amounts to averaging the images values in every cluster of D. For overlapping modes as the ones of DiFuMo or the ICA maps used in UKBB (Miller et al., 2016) , the linear regression formulation caters for the overlap and softness of the regions."}, {"section_title": "Region names: relation to anatomical structures", "text": "Relating IDPs to known brain structures facilitates interpretation and discussion of results. Though the Di-FuMo atlases are defined from functional signal, we choose to reference their regions by their anatomical location, as it is a common and well-accepted terminology in neuroscience. For each resolution, we match the modes with regions in references of brain structure: the Harvard-Oxford atlas (Desikan et al., 2006) DiFuMo atlases are extracted from a massive concatenation of BOLD time-series across fMRI studies, using a sparsity inducing matrix factorization algorithm. We compute the DiFuMo atlases at different resolutions, up to 1024 components. We assess our atlases in 4 benchmarks that measure suitability to classic fMRI analyses. Those are performed on reduced and non-reduced data, with different atlas sizes and a comparison between atlases. The easiest way to view and download DiFuMo atlases is via the online interactive visualizations: parietal-inria.github.io/DiFuMo. it most overlaps with. When the overlap was weak, a trained neuroanatomist (AMS) looked up the structure in standard classic anatomy references (Henri, 1999; Schmahmann et al., 1999; Rademacher et al., 1992; Ono et al., 1990; Catani and de Schotten, 2012) . Appendix F gives more details on the naming of the brain areas."}, {"section_title": "Brain-image analysis on functional modes", "text": "We use the reduced representations (IDPs) introduced above for various functional-imaging analytic tasks: standard mass-univariate analysis of brain responses ( \u00a73.2); decoding of mental processes from brain activity ( \u00a73.3); prediction of phenotypes from functional connectomes ( \u00a73.4); finally, we measure the quality of signal reconstruction after the dimension reduction, with an illustration on metaanalyses ( \u00a73.5)."}, {"section_title": "Benchmarking several functional atlases", "text": "To gauge the usefulness of the extracted IDPs, we compare each analysis pipeline across several functional at-lases: DiFuMo and reference atlases are used to compute functional IDPs. We use the same signal-extraction function (1), but vary the spatial components D. As a baseline, we also perform the voxel-level analyses, though it entail significantly larger computational costs.\nWe consider other functional atlases that are multiresolutions, accessible to download, and volumetric (Table 1): ICA maps with k \u2208 {21, 55} components, extracted on large-scale rs-fMRI from UKBB (Miller et al., 2016) ; bootstrap analysis of stable clusters (BASC) built with hierarchical clustering on rs-fMRI, with various number of clusters (Bellec et al., 2010) ; spatiallyconstrained clustering on rs-fMRI, with k \u2208 {200, 400} clusters (Craddock et al., 2012) ; k = 333 cortical areas derived from rs-fMRI using a local gradient approach (Gordon et al., 2014) ; k \u2208 {90, 499} functional regions covering cortical and subcortical gray matter with ICA and Ward clustering (Shirer et al. (2012 ), Altmann et al. (2015 ); and brain parcellations derived with gradient-weighted Markov Random Field, with resolutions similar to ours (Schaefer et al., 2017, k up Table 1 : Functional atlases that we benchmark; they define IDPs for brain-images. analysis 3.2. Mapping brain response: standard task-fMRI analysis Standard analysis in task fMRI relates psychological manipulations to brain activity separately for each voxel or region. It models the BOLD signal as a linear combination of experimental conditions-the General Linear Model (GLM, Friston et al., 1995) . The BOLD signal forms a matrix Y \u2208 R n\u00d7p , where p is the number of voxels. With data reduction, we use as input the reduced signal\nis the design matrix formed by q temporal regressors of interest or nuisance and \u03b5 is noise (Friston et al., 1998) . In our experiments, we use the Nistats library 3 .\nWith reduced input Y red , we obtain one signal per region, as \u03b2 \u2208 R q\u00d7k . The full \u03b2-maps can then be reconstructed by setting \u03b2 rec = \u03b2D \u2208 R q\u00d7p . We transform the reconstructed \u03b2-maps into z-maps z \u2208 R q\u00d7p using base contrasts, before thresholding them with Benjamini and Hochberg (1995) FDR correction for multiple comparisons. We then compare the z-maps obtained using voxels as input, and z-maps using reduced input and reconstructed \u03b2maps, using the Dice (1945) similarity coefficient. We also perform an intra-subject analysis detailed in Appendix D.\nData. We consider the Rapid-Serial-Visual-Presentation (RSVP) language task of Individual Brain Charting (IBC) (see Pinho et al., 2018, for experimental protocol and preprocessing) . We model six experimental conditions: complex meaningful sentences, simple meaningful sentences, jabberwocky, list of words, lists of pseudowords, consonant strings. \u03b2-maps are estimated for each subject using a fixed-effect model over 3 out of the 6 subject's sessions. We randomly select 3 sessions 10 times to estimate the variance of the Dice index across sessions. As a baseline, we evaluate the mean and variance of the Dice index across z-maps when varying the sessions used in voxel-level GLM."}, {"section_title": "Decoding experimental stimuli from brain responses", "text": "Decoding predicts psychological conditions from taskrelated z-maps (Haynes and Rees, 2006) . The validity of a decoding model is evaluated on left-out data (following 3 https://nistats.github.io/ Varoquaux et al., 2017), e.g. left-out subjects for intersubject decoding (Poldrack et al., 2009) . We use linear decoding models: ridge regression for continuous target and Support Vector Machine (SVC, Hastie et al., 2009) for classification. For each study, we separate sessions (for intra-subject decoding) or subjects (for inter-subject decoding) into randomly-chosen train and test folds (20 folds with 30% test size), and measure the test accuracy. We compare the performance of predictive models using the voxel-level z-maps or using the data reduced with functional atlases."}, {"section_title": "Data.", "text": "We use 6 open-access task fMRI studies. We perform inter-subject decoding in the emotional and sensitivity to pain experiences from Chang et al. (2015) , and in three studies from HCP900 (Van Essen et al., 2012) : working memory, gambling (Delgado et al., 2000) , and relational processing (Smith et al., 2007) . We perform intra-subject decoding using the several sessions of left and right button press responses in IBC (ARCHI protocol, Pinel et al., 2007) . The unthresholded z-maps used in the decoding pipeline are either obtained from Neurovault (Gorgolewski et al., 2015) , or computed with the GLM following \u00a73.2. Details are reported in Appendix B.1."}, {"section_title": "Predicting phenotype from functional connectomes", "text": "Resting-state fMRI can be used to predict phenotypic traits (Richiardi et al., 2010) . For this, each subject is represented by a functional connectivity matrix that captures the correlation between brain signals at various locations. Our functional-connectome prediction pipeline comprises three steps: 1) we extract a reduced representation of the BOLD signal, projecting voxel-level data onto a functional atlas as in \u00a73.2; 2) we compute a functional connectome from the reduced BOLD signals; 3) we use it as input to a linear model. We compute a connectome from activations with the Ledoit and Wolf (2004) covariance estimator as Varoquaux and Craddock (2013); Brier et al. (2015) . We then derive single-subject features from covariance matrices using their tangent space parametrization (Varoquaux et al., 2010a; Barachant et al., 2013; Pervaiz et al., 2019) . Those are used to fit an 2 -penalized logistic regression for classification and a ridge regression for continuous targets.\nWe assess predictive performance with 20 folds, random splits of subjects in train and test sets, with 25% test size.\nData. We use 7 openly-accessible datasets with diverse phenotypic targets, as summarized in Table A3 . We predict diagnostic status for Alzheimer's disease on ADNI (Mueller et al., 2005) "}, {"section_title": "Quality of image reconstruction", "text": "The signals extracted on a brain atlas can be seen as a compression, or simplification, of the original signal. Indeed, a full image can be reconstructed from these signals. We quantify the signal loss incurred by this reduction. For this, we project a brain map x onto an atlas (solving Eq.\n(1)), and compute the best reconstruction of x from the loadings \u03b1, namelyx = D\u03b1 \u2208 R p . We compare original and reconstructed images through the R 2 coefficient,\nwherex \u2208 R is the spatial mean of map x. The R 2 coefficient is averaged across all images. Higher R 2 coefficients means that the reduced signals (IDPs) explain more variance of the original images, where R 2 = 1 corresponds to no signal loss. The larger the number of signals used, the easier it is to explain variance; it is therefore interesting to compare this measure across atlases with similar number of components.\nData. We use NeuroVault (Gorgolewski et al., 2015) , the largest public database of statistical maps. To avoid circularity, we exclude maps derived from the studies used to extract the DiFuMo atlases, along with maps that fail semiautomated quality inspection (filtering out thresholded or non-statistical maps), resulting in 15,542 maps.\nMeta-analysis of contrasts maps. Ideally, the extracted IDPs should allow to compute meta-analytical summaries of brain activity maps. In this setting, a single map, corresponding to a certain cognitive concept, is computed from many z-maps across different studies, associated to conditions that involve this cognitive concept. We compare the summaries obtained at voxel-level, i.e. averaging the maps {x}, with the ones obtained using reconstructed images, i.e. averaging the maps {x} used in Eq.\n(2). We use maps from our curated subset of NeuroVault annotated with terms motor, language and face recognition."}, {"section_title": "Results: comparing atlases for analyses", "text": "We report benchmarking results on the analytic tasks listed in the previous section. 4.1. Brain mapping: standard task-fMRI analysis Figure 3 reports the results of standard analysis of task fMRI (GLM), comparing analysis at the voxel-level with analyses on signals extracted from functional atlases. Best correspondence is obtained at highest dimensionality, as the regions are finer. Notably, analysis with DiFuMo of dimensionality 1024 is markedly closer to voxel-level analysis than using the largest alternative, the 1000-dimensional Schaefer parcellation. In addition, the Dice index relative to the voxel-level gold standard is comparable to the Dice index between runs of voxel-level GLM estimated across folds. We note that using soft functional modes from only 55 ICA components shows excellent results, comparable to those obtained using the 1000 components Schaefer atlas. This stresses the benefit of continuous functional modes for the analysis of task responses. Overall, standard task-fMRI analysis on signals derived from 512 Figure 5 : Decoding maps of the working memory task, face versus rest, showed for Voxel-level analysis, DiFuMo, and Schaefer. The maps are highly interpretable with high-dimensional soft modes (DiFuMo 1024) compared to voxel-level analysis. Brain areas important in the visual working memory task -fusiform gyrus and lateral occipital cortex-are clearly visible. Figure A4 gives a full view of decoding weights across atlases and resolutions.\nlevel gold standard (Figure 3 shows that the maps are also qualitatively similar). Figure A6 shows similar trends while comparing intra-subject explained-variance maps, both qualitatively and quantitatively. Dimension reduction have the additional benefit of alleviating the burden of correcting for multiple comparisons. Figure 4 shows the impact on decoding performance of reducing signals with various functional atlases. It reports the performance relative to the median across methods for each of the 6 tasks. These results clearly show the importance of high-dimensional functional modes for decoding. Indeed, the higher the atlas resolution, the better the predictions. Predicting traits from functional connectomes Figure 6 : Impact of the choice of atlas for predictions based on functional connectomes. Each data point gives the prediction accuracy relative to the median for one of the 7 phenotypic prediction targets, i.e. each point a dataset. The thick line shows the median over the datasets. While the results are noisy, the optimal dimensionality seems to lie around 300 nodes, and the best-performing atlas is DiFuMo k = 256, followed by Craddock k = 400 and BASC k = 444. Figure A5 report absolute results for each prediction problem."}, {"section_title": "Decoding mental state from brain responses", "text": "gives the best performance. In addition, as these functional atlases segment sufficiently-fine regions, prediction from the corresponding signals tends to outperform voxellevel prediction. Indeed, applying multivariate models to a larger number of signals with a limited amount of data is more prone to overfitting-data reduction acts here as a welcome regularization. Qualitatively, brain maps containing decoding weights can be reconstructed. With highdimensional atlases, they are interpretable and capture information similar to voxel-level analysis ( Figure 5 ). Figure 6 shows the impact of the choice of functional atlas when predicting phenotypes from functional connectomes. It reports the relative prediction accuracy for 7 different prediction problems (each composed of a dataset and a target phenotype); the lines give the median across the prediction problems. Here, we do not report a voxellevel baseline, as it requires to compute covariance matrices of dimensions around 100, 000 \u00d7 100, 000 and is therefore computationally and statistically intractable. Unlike with the previous results, high-resolution atlases do not provide the best performance, likely because the complexity of the statistical models increases with the square of the number of nodes. The best prediction overall is achieved using DiFuMo k = 256, followed by Craddock k = 400 and BASC k = 444 atlases. Different outcomes have different optimal dimensionality, consistently across atlases ( Figure A5 ): k \u223c 150 for age prediction; k \u223c 300 for Autism Spectrum Disorder, PTSD, or IQ prediction; and k \u223c 50 for Alzheimer's Disease and drug use prediction. 7 Figure 7 : Image reconstruction quality. Left: Quantitative comparison on 15542 statistical images. The R 2 loss between the true and recovered images after compression with brain atlases of multiple resolutions. In general, higher-order atlases capture more signal. Right: Metaanalysis summaries for the motor task. High R 2 score (left) correspond to better capturing fine structures of images, as visible on the qualitative images. DiFuMo atlases better capture the gradients and smooth aspects of the original images than hard parcellations, as BASC. Reduced with BASC 4.4. Fraction of the original signal captured Figure 7 (left) displays the R 2 scores summarizing the loss of information when data are reduced on an atlas and reconstructed back to full images. Unsurprising, reducing the images with lower-order dimensions (atlases with fewer regions) yields a high loss of information across all methods. DiFuMo k = 1024 captures 70% of the original voxel-level signal. Qualitatively, the benefits of functional modes can be seen by comparing the meta-analytic maps related to motor tasks (Figure 7 right)- Figure A7 shows additional meta-analysis on other topics. The DiFuMo have clear visual benefits over brain discrete parcellations, such as BASC, as they better capture gradients."}, {"section_title": "Predicting traits from functional connectomes", "text": ""}, {"section_title": "Discussion", "text": "This paper introduces brain-wide soft functional modes, named DiFuMos and made of a few hundreds to a thousand of brain sub-divisions. They are derived from BOLD time-series across many studies to capture well functional images with a small number of signals. In the context of population imaging, these signals are known as image-derived phenotypes (IDP, Miller et al., 2016) and are crucial to easily scale statistical analysis, building a science of inter-individual differences by relating brain signals to behavioral traits (Dubois and Adolphs, 2016). Reducing the dimensionality of the signals not only come with a 1000\u00d7 gain in storage, but also with 100\u00d7 computational speed-up for the analysis (Table A1 ). Even small-scale studies may need functional nodes, e.g. for computing functional connectomes (Zalesky et al., 2010; Varoquaux and Craddock, 2013) . There already exist many functional brain atlases; yet DiFuMos have the unique advantage of being both soft and highly resolved. These features are important to capture gradients of functional information.\nGrounding better image-derived phenotypes. Signals extracted from a functional atlas should enable good statistical analysis of brain function. We considered quantitative measures for typical neuroimaging analytic scenarii and compared the fitness of extracting signal on Di-FuMo with using existing functional brain atlases. The biggest gains in analysis come from increasing the dimensionality of brain sub-divisions, aside for functional connectome studies where an optimal is found around 200 nodes. Choosing the number of nodes then becomes a tradeoff between complexity of the representation and analytic performance. Importantly, the gains in analytic performance continue way beyond the dimensionality typically used for IDPs (e.g. 55 components from Miller et al., 2016) . These results extend prior literature emphasizing the importance of high-dimensional parcellations for fMRI (Abou Elseoud et al., 2011; Thirion et al., 2014; Arslan et al., 2017; Sala-Llonch et al., 2019) . To foster good analysis, the second most important aspect of a parcellation appears that it be soft, i.e. continuously-valued. For a given dimensionality, soft modes tend to outperform hard parcellations, whether they are derived with ICA or dictionary learning.\nModes well-adapted to the EPI signal. The functional modes are optimized to fit well a large number of EPI images: 2,192 sessions across 27 studies. As a result, they form a division of the brain well adapted to the signal. For instance, they define regions larger in the white matter and in the CSF than in the grey matter ( Figure A1) . A large dataset is needed to capture such implicit regularities of the signal with high-dimensional spatial decompositions. Indeed, running the same model on less data extracts modes with less spatial regularity ( Figure A2 ). The combination of high dimensionality and large dataset leads to significant computational demands. The extraction of DiFuMos was possible thanks to fast algorithms for huge matrix factorization (Mensch et al., 2018) , and gathering data representative of a wide variety of scanning protocols via openfMRI (Poldrack et al., 2013) .\nWe did not limit the DiFuMo modes to gray matter, as measures outside gray matter can be useful in subsequent analysis, for instance to remove the global signal (Murphy and Fox, 2017) . In addition, distributed modes extracted from full-brain EPI can separate out noise -such as movement artifacts-and help rejecting it in a later analysis (Perlbarg et al., 2007; Griffanti et al., 2014; Pruim et al., 2015) . Some DiFuMo modes indeed segment ventricles or interfaces. Depending on the application, practitioners can choose to restrict signal extraction to a grey-matter mask.\nThe functional modes are sharp and anatomically relevant. To extract structures defined by brain anatomy or microstructure, atlasing efforts have used anatomical or multimodal imaging (Mori et al., 2005; Desikan et al., 2006; Eickhoff et al., 2007; Glasser et al., 2016) . The DiFuMo atlases capture a different signal: brain activity. Yet, thanks to the sparsity and non-negativity constraint, they are made of localized modes which often have a natural anatomical interpretation. Consequently, we have labeled the modes with a unique name based on the most relevant anatomical structure, following Urchs et al. (2019) who also give anatomical labels to functional regions. Indeed, using a common vocabulary of brain structures is important for communication across the neuroimaging community. As visible on Figure 8 , the modes are well anchored on anatomical structures such as the putamen. They are however not constrained to contain only one connected region. Smaller dimension DiFuMos indeed capture distributed networks, often comprising bilateral regions. As the dimensionality increases, the networks progressively separate in smaller networks which eventually form single regions. For instance, the left and right putamen appear in the same mode at dimension 64, and are first sub-divided along the anterio-posterior direction, and later the left and right putamen are separated (Figure 8 ). Dimension choice is data driven: it should best explain the functional signal."}, {"section_title": "Conclusion", "text": "We provide multidimensional atlases of functional modes that can be used to extract functional signals: parietal-inria.github.io/DiFuMo. They give excellent performance for a wide variety of analytic tasks: GLMbased analysis, mental-process decoding or functionalconnectivity analysis. Their availability reduces computational burdens: practitioners can readily perform analyses on a reduced signal, without a costly ROI-definition step. In addition, working on common functional modes across studies facilitates comparison and interpretations of results. To help communication, we have labeled every functional mode to reflect the neuroanatomical structures that it contains. To date, these are the only highdimensional soft functional modes available. As they have been extracted from a variety of data (more than 2,000 sessions across 27 studies, 2.4TB in size) and improve many analytic tasks, the rich descriptions of neural activity that they capture is well suited for a broad set of fMRI studies."}, {"section_title": "Acknowledgments", "text": "This project has received funding from the European Union's Horizon 2020 Research and Innovation Programme under Grant Agreement No. 785907 (HBP SGA2) and No 826421 (VirtualBrainCloud). The work of Arthur Mensch has been supported by the European Research Council (ERC Grant Noria). This work acknowledges the support of ANR NeuroRef and ERC-StG NeuroLang.\nWe also thank Pierre Bellec and Vincent Frouin for their helpful discussions on the experimental work, the neuroimaging community for giving access to fMRI datasets, and open-source contributors on the packages we build upon (including nilearn, fMRIprep, and MRIQC ).\nData collection and sharing for this project was funded by the Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: Abraham, A., Pedregosa, F., Eickenberg, M., Gervais, P., Mueller, A., Kossaifi, J., Gramfort, A., Thirion, B., Varoquaux, G., 2014.\nMachine learning for neuroimaging with scikit-learn. Frontiers in neuroinformatics 8.\nAltmann, A., Ng, B., Landau, S.M., Jagust, W.J., Greicius, M.D., 2015. Regional brain hypometabolism is unrelated to regional amyloid plaque burden. Urchs, S., Armoza, J., Moreau, C., Benhajali, Y., St-Aubin, J., Orban, P., Bellec, P., 2019. MIST: A multi-resolution parcellation of functional brain networks. MNI Open Research 1.\nVan Essen, D., Ugurbil, K., Auerbach, E., Barch, D., Behrens, T., Bucholz, R., Chang, A., Chen, L., Corbetta, M., Curtiss, S., Della Penna, S., Feinberg, D., Glasser, M., Harel, N., Heath, A., Larson-Prior, L., Marcus, D., Michalareas, G., Moeller, S., Oostenveld, R., Petersen, S., Prior, F., Schlaggar, B., Smith, S., Snyder, A., Xu, J., Yacoub, E., 2012. The human connectome project: A data acquisition perspective. NeuroImage 62, 2222-2231.\nVan Essen, D.C., Smith, et al., 2013 . The wu-minn human connectome project: an overview. Neuroimage 80, 62-79.\nVaroquaux, G., Baronnet, F., Kleinschmidt, A., Fillard, P., Thirion, B., 2010a. Detection of brain functional-connectivity difference in post-stroke patients using group-level covariance modeling, in: MICCAI.\nVaroquaux, G., Craddock, R.C., 2013. Learning and comparing functional connectomes across subjects. NeuroImage 80, 405.\nVaroquaux, G., Gramfort, A., Pedregosa, F., Michel, V., Thirion, B., 2011. Multi-subject dictionary learning to segment an atlas of brain spontaneous activity, in: Inf Proc Med Imag, p. 562.\nVaroquaux, G., Raamana, P.R., Engemann, D.A., Hoyos-Idrobo, A., Schwartz, Y., Thirion, B., 2017. Assessing and tuning brain decoders: cross-validation, caveats, and guidelines. NeuroImage 145, 166.\nVaroquaux, G., Sadaghiani, S., Pinel, P., Kleinschmidt, A., Poline, J.B., Thirion, B., 2010b. A group model for stable multi-subject ICA on fMRI datasets. NeuroImage 51, 288.\nVerstynen, T.D., 2014. The organization and dynamics of corticostriatal pathways link the medial orbitofrontal cortex to future behavioral responses. J Neurophysio 112, 2457.\nXue, G., Aron, A.R., Poldrack, R.A., 2008. DiFuMo atlases capture well the EPI signal Figure A1 : Region volume (cm 3 ) of modes on the brain with 1024 dictionary of DiFuMo. The volume of the modes tends to be larger corresponding to white matter when compared with the cortical gray matter. This justifies the adaptation of DiFuMo atlas to the fMRI signal. Figure A2 : 1024 components trained on two different sizes of the input set of fMRI images. The components trained on the full data have more spatial regularity, while the components trained on 100 volumes have more overlap in some regions of the brain. The additional spatial regularity shows the benefit of large-scale training size in learning a data-driven based functional atlas."}, {"section_title": "Appendix A. Performance of DiFuMos", "text": "As discussed in \u00a75, we report how DiFuMOs components are well adapted to the fMRI EPI signal in Figure A1 . Figure A2 qualitatively compare components obtained training on the whole data corpus and training on a fraction of it. Better component regularity is obtained with more data. Finally, Table A1 reports the computational speed-ups obtained using DiFuMos IDPs instead of voxel in the decoding experiment. Similar speed-ups are observed in the other validation pipelines."}, {"section_title": "Appendix B. Details on stimulus decoding", "text": "We provide additional details for the decoding pipeline, to complete the description in \u00a73.3. Appendix B.1. Input data and pre-processing pipelines The decoding pipeline classifies input unthresholded statistical maps. Table A2 summarizes the task-based studies used to obtain these statistical maps.\nPre-encoded maps downloaded from Neurovault.org. We download maps related to emotion and pain (Chang et al., 2015) using Neurovault, querying the collections 503 and 504. We use the \"Rating\" & \"PainLevel\" labels as predictive targets. We predict emotion using ridge regression, and pain-level over 3 classes using Linear SVC. The supervised learning pipeline, that includes cross-validation and linear models is implemented with Python based scikitlearn (Pedregosa et al., 2011) . We use nilearn (Abraham et al., 2014) to download maps from Neurovault.org interface (Gorgolewski et al., 2015) . The data acquisition parameters, preprocessing details and estimation of statistical maps are described in Chang et al. (2015) .\nStatistical maps encoded using the GLM. We compute zmaps from HCP900 (Van Essen et al., 2012) and IBC (Pinho et al., 2018) studies, that comprise high-qualiy task-fMRI experiments. Figure A3 : Decoding prediction scores for each brain atlas and target: Each marker denotes the mean performance of using a certain brain atlas; error bars are the standard deviation of the prediction scores for this atlas. Decoding from high-order dictionaries, and especially from DiFuMos, perform similarly or better than decoding from voxels.\nHCP. We download fMRI data from the HCP900 release; those are already preprocessed using HCP pipelines (Glasser et al., 2013) . We use MNINonLinear-based registered data as input for the GLM, that outputs one zmap per condition per subject. We consider three taskbased studies, namely: for Working Memory, we con-sider z-maps based on condition: \"0-back faces\", \"2-back faces\", \"0-back places\", \"2-back places\". Similarly, for Gambling (Delgado et al., 2000) , we consider z-maps for the conditions \"loss\" and \"reward\"; finally, on Relational processing, we consider z-maps for the conditions \"relational processing\" and \"matching\". For each study, we use Linear SVC on encoded z-maps to predict psychological conditions. The predictive model therefore perform a 2-class or 4-class classification. The experimental protocol and data acquisition parameters are detailed in Van Essen et al. (2012) .\nIBC. We consider the Archi Standard (Pinel et al., 2007) motor task, where subjects are asked to press \"left\" and \"right\" button press based on audio and visual instructions. We perform within-subject classification between left and right button press, using z-maps corresponding to each repetition of the instruction. For each of the 13 available subjects, a linear model is trained on the z-maps from all but one session and prediction is performed on the left-out session. Each subject provides 80 encoded z-maps across 4 sessions. We use data preprocessed following the pipelines of Pinho et al. (2018) .\nGLM specification. For both datasets, the input zmaps are estimated from the raw fMRI data by fitting a GLM. We use Nistats 4 , a Python package for the statistical analysis of fMRI data. The temporal regressors of the model are specified according to the timing of stimulus presentations convolved with hemodynamic models (spm + derivative). We use polynomial model to capture the low-frequency drifts in the data."}, {"section_title": "Appendix B.2. Detailed results", "text": "To complete the summarizing Figure 4 , we report the raw prediction scores separately for each decoding tasks in Figure A3 . Prediction accuracy increases with the size of functional atlases. Using 1024 atlases allows to match or pass the performance of voxel-based prediction. In terms of interpretation, the weights are much smoother and blobs are clearly visible in the weight classification maps obtained using DiFuMo. This is illustrated on Figure A4 for face-versus-place decoding in the working-memory HCP study."}, {"section_title": "Appendix C. Details on biomarker prediction", "text": "We consider multiple datasets to account for the diversity of prediction targets in biomarker prediction problem. We report datasets, prediction groups and prediction targets in Table A3 ."}, {"section_title": "Appendix C.1. Input data and prediction settings", "text": "The connectivity features built from functional atlases predict various clinical outcomes (neuro-degenerative and neuro-psychiatric disorders, drug abuse impact) and psychological traits. Table A3 : Resting-state fMRI datasets used in the pipeline described on \u00a73.4 for predicting phenotypic labels from functional connectomes. In CamCAN, age is predicted using ridge regression. The groups from other datasets are predicted using logistic regression. IQ -Fluid intelligence, PTSD -Post Traumatic Stress Disorder, MCI -Mild Cognitive Impairment.\nCognitive Impairment (MCI) group on ADNI. We discriminate between post-traumatic stress disorder (PTSD) and healthy individuals on ADNIDOD. We use data from the Center for Biomedical Research Excellence 6 (COBRE Calhoun et al. (2012) to predict schizophrenia diagnosis of individuals. We classify autism and healthy individuals on Autism Brain Imaging Data Exchange database (ABIDE, Di Martino et al. (2014) , Finally, we consider data from Addiction Connectome Preprocessed Initiative 7 (ACPI), where we discriminate Marijuana consumers versus control subjects.\nPsychological traits. We first stratify individuals from HCP900 release (Van Essen et al., 2013) into groups of high and low IQ, and perform binary classification on these. The details about the stratification into these groups are described in Dadi et al. (2019) .\nAge regression. We use Cambridge Center for Ageing and Neuroscience (CamCAN) dataset (Taylor et al., 2017) to study brain ageing. This study comprises wide range of age groups spanning from 24 -86. We use ridge regression to predict age on this dataset. Appendix C.2. Data acquisition parameters and preprocessing pipelines The data acquisition details for ADNI, ADNIDOD, COBRE, ABIDE, ACPI and HCP are described in Dadi et al. (2019) ; those for CamCAN in Taylor et al. (2017) . We pre-process individuals from CamCAN, ADNI, AD-NIDOD and COBRE. All rs-fMRI acquistions are preprocessed with standard steps, described in Dadi et al. Predicting phenotypes from functional connectomes Figure A5 : Connectome prediction scores for each brain atlases and target: Each marker denotes the mean performance of using a certain brain atlas; error bars are the standard deviation of the prediction scores for this atlas. BASC and DiFuMo-based atlases give good prediction scores up to k = 256 ROIs.\n(2019). The other considered datasets provide preprocessed data. We report the total number of subjects included in the analysis in Table A3 , after excluding for severe scanning artifacts, head movements with amplitude larger than 2 mm and individuals who have more than one clinical diagnosis,\nConfound removal and temporal signal pre-processing. The strategy we use for cleaning temporal signals is the same as in Dadi et al. (2019) . We brieftly outline these steps here. We regress out 10 CompCor (Behzadi et al., 2007) components on the whole brain and six motion related signals which are provided in the ADNI, ADNIDOD, COBRE, CamCAN datasets. We do not perform any additionnal preprocessing steps on ABIDE, ACPI and HCP. For all datasets, the signal of each region is normalized, detrended and bandpass-filtered between 0.01 and 0.1Hz. All these steps are done with nilearn (Abraham et al., 2014).\nAppendix C.3. Detailed results Figure 6 summarizes the impact of the brain atlases and ROIs in predicting diverse targets on rs-fMRI images. Figure A5 shows the absolute prediction scores for each target separately. DiFuMo-based predictions are on par with those using UKBB ICA components, Craddock et al. (2012) and BASC atlases."}, {"section_title": "Appendix D. Intra-subject encoding", "text": "In \u00a73.2, we compare group-level z-maps computed at the voxel-level and on reduced data using the DICE similarity coefficient. We also performed an intra-subject, across sessions, standard analysis. We consider the Rapid-Serial-Visual-Presentation (RSVP) language task of Individual Brain Charting (IBC) (see Pinho et al. (2018) for details on experimental protocol and data pre-processing).\nEncoding model. In this setting, we fit a GLM on the several acquisition sessions of each subject considered separately. That is, we compute a single \u03b2-map per session and condition, forming a set of maps \u03b2 \u2208 R q\u00d7p . \u03b2 is either computed directly at the voxel-level or using functional atlases, in which case we set \u03b2 = \u03b2 red D , with \u03b2 \u2208 R q\u00d7k .\nWe then use a leave-one-session-out cross-validation scheme to compare the observed, single-session, time series Y \u2208 R n\u00d7p to the reconstructed time-series\u0176 = X\u03b2, where\u03b2 are the average \u03b2-maps across the 5 training sessions. We obtain R 2 -maps, where each voxel holds the proportion of variance explained by the model\nwhere y i is the univariate time-series in R n associated to voxel i and\u0233 i is its temporal mean. We finally average Figure A6 : Intra-subject univariate prediction of brain response in the language task protocol of the IBC dataset. We compare R 2 -maps obtained using voxel based and functionalatlas based encoding models. Encoding models based on high-order atlases better explain the variance of an unseen session. The comparison is made for a single subject; results are similar across subjets.\nR 2 scores across leave-one-session-out folds, and threshold non-positive values. The resulting R 2 -maps provides information on how much encoded \u03b2-maps are able to predict univariate voxel activation on new sessions. A value close to 1 means that the voxel activation is well predicted by the encoding model, while a 0 value means that the voxel activation cannot be predicted. We compare the R 2 -maps across the various data-reduction methods for estimating \u03b2.\nValidation. To measure the difference between R 2 maps R computed from voxels and R 2 mapsR computed from DiFuMos, we report correlation coefficients \u03c1 between R andR, and the slope s predicting the activationsR from the activations R. This slope indicates a form of signal loss due to using functional atlases. We expect it to be smaller than 1, in part because projection on functional atlases have a noise reduction effect.\nResults. Figure A6 , using higher order DiFumo atlases leads to a loss of explained variance R 2 of only 6% compared to working directly with voxels, which may imputed to a denoising effect. Qualitatively, the R 2 maps are much comparable. DiFuMo (k = 1024) is therefore suitable for intra-subject encoding tasks; they make these much less costly. Using lower-order atlases yield stronger signal loss.\nAppendix E. Extra meta-analysis maps Figure A7 shows the meta-analysis summary images for two additional cognitive topics: language and face. We compare non-reduced images with reduced images using DiFuMo (k = 1024) and BASC (k = 444). The images reduced with DiFuMos are easier to interpret than the ones reduced with BASC for both topics. Quantitatively, we recall that Figure 7 shows the better performance of Di-FuMos for image compression."}, {"section_title": "Appendix F. DiFuMos naming details", "text": "A measure of overlap with a reference anatomical atlas allows to match each DiFuMo component with a specific anatomical region, e.g. \"postcentral gyrus\". Where there are more than one component for each anatomical region, the functional atlas region are further characterized by an anatomical spatial descriptions, e.g. \"postcentral gyrus inferior\". Finally, we append the localisation of the region in the left or right hemisphere, e.g. \"postcentral gyrus inferior RH\". Some of the nodes from DiFuMo atlases overlaps a fraction of several regions in the anatomical atlas-those are named by a trained neuroanatomist. Increasing the atlas dimension splits those networks into different components Figure A8 : Interpretation of higher-dimensional modes of DiFuMo: The putamen segmentation is refined as dimension of DiFuMos increases. A single mode contain the left and right putamen in lower dimension (a), when higher order atlases holds separate components for them. Larger atlases model the detailed organization within the sub-structures, which may be crucial in discriminative tasks."}]