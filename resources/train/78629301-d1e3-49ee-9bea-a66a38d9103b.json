[{"section_title": "Abstract", "text": "Accurate measurement of longitudinal changes of brain structures and functions is very important but challenging in many clinical studies. Also, across-subject comparison of longitudinal changes is critical in identifying disease-related changes. In this paper, we propose a novel method to meet these two requirements by simultaneously registering sets of longitudinal image sequences of different subjects to the common space, without assuming any explicit template. Specifically, our goal is to 1) consistently measure the longitudinal changes from a longitudinal image sequence of each subject, and 2) jointly align all image sequences of different subjects to a hidden common space. To achieve these two goals, we first introduce a set of temporal fiber bundles to explore the spatial-temporal behavior of anatomical changes in each longitudinal image sequence. Then, a probabilistic model is built upon the temporal fibers to characterize both spatial smoothness and temporal continuity. Finally, the transformation fields that connect each timepoint image of each subject to the common space are simultaneously estimated by the expectation maximization (EM) approach, via the maximum a posterior (MAP) estimation of the probabilistic models. Promising results have been obtained in quantitative measurement of longitudinal brain changes, i.e., hippocampus volume changes, showing better performance than those obtained by either the pairwise or the groupwise only registration methods.\n\u00a9 2011 Elsevier Inc. All rights reserved.\nLongitudinal study of human brains is important to reveal subtle structural and functional changes due to brain diseases (Crum et al., 2004; Thompson, 2001, 2003; Zitov\u00e1 and Flusser, 2003) . Although many state-of-the-art image registration algorithms (Ashburner, 2007; Beg et al., 2005; Christensen, 1999; Rueckert et al., 1999; Davatzikos, 2002, 2003; Thirion, 1998; Vercauteren et al., 2009; Wu et al., 2010) have been developed, most of them, regardless of feature-based or intensity-based methods, tend to register serial images independently when applied to longitudinal studies. However, such independent registration scheme could lead to inconsistent correspondence detection along the serial images of the same subject, and thus affect the accuracy of measuring longitudinal changes, especially for the small structures with tiny annual changes (e.g., development of atrophy in hippocampus due to aging; Cherbuin et al., 2009; Chupin et al., 2009; Leung et al., 2010; Scahill et al., 2002; Schuff et al., 2009; Shen and Davatzikos, 2004) .\nSeveral methods have been proposed to capture temporal anatomical changes. For instance, in order to consistently segment hippocampus on a sequence of longitudinal data, Wolz et al. (Wolz et al., 2010) extended the 3D graph-cut to 4D domain and achieved more consistent segmentation results on ADNI dataset. In image registration area, Shen and Davatzikos Shen and Davatzikos, 2004) proposed a 4D-HAMMER registration method to cater for the longitudinal application. The 4D-HAMMER approach adopts the 4D attribute vector to establish the correspondences between the 4D atlas and the 4D subject. Also, it incorporates both spatial smoothness and temporal smoothness terms in the energy function to guide the registration. Recently, Qiu et al. (Qiu et al., 2009 ) extended LDDMM to time sequence dataset by first delineating the within-subject shape changes and then translating the within-subject deformation to the template space via parallel transport technique. These methods have demonstrated the capability of detecting consistent structural changes in hippocampus, and achieved better results than the conventional pairwise registration method. However, one limitation of these methods is that the specific template is required in registration, which may introduce bias in longitudinal data analysis. The second limitation of these methods is that "}, {"section_title": "Introduction", "text": "Longitudinal study of human brains is important to reveal subtle structural and functional changes due to brain diseases (Crum et al., 2004; Thompson, 2001, 2003; Zitov\u00e1 and Flusser, 2003) . Although many state-of-the-art image registration algorithms (Ashburner, 2007; Beg et al., 2005; Christensen, 1999; Rueckert et al., 1999; Davatzikos, 2002, 2003; Thirion, 1998; Vercauteren et al., 2009; Wu et al., 2010) have been developed, most of them, regardless of feature-based or intensity-based methods, tend to register serial images independently when applied to longitudinal studies. However, such independent registration scheme could lead to inconsistent correspondence detection along the serial images of the same subject, and thus affect the accuracy of measuring longitudinal changes, especially for the small structures with tiny annual changes (e.g., development of atrophy in hippocampus due to aging; Cherbuin et al., 2009; Chupin et al., 2009; Leung et al., 2010; Scahill et al., 2002; Schuff et al., 2009; Shen and Davatzikos, 2004) .\nSeveral methods have been proposed to capture temporal anatomical changes. For instance, in order to consistently segment hippocampus on a sequence of longitudinal data, Wolz et al. (Wolz et al., 2010) extended the 3D graph-cut to 4D domain and achieved more consistent segmentation results on ADNI dataset. In image registration area, Shen and Davatzikos Shen and Davatzikos, 2004) proposed a 4D-HAMMER registration method to cater for the longitudinal application. The 4D-HAMMER approach adopts the 4D attribute vector to establish the correspondences between the 4D atlas and the 4D subject. Also, it incorporates both spatial smoothness and temporal smoothness terms in the energy function to guide the registration. Recently, Qiu et al. (Qiu et al., 2009 ) extended LDDMM to time sequence dataset by first delineating the within-subject shape changes and then translating the within-subject deformation to the template space via parallel transport technique. These methods have demonstrated the capability of detecting consistent structural changes in hippocampus, and achieved better results than the conventional pairwise registration method. However, one limitation of these methods is that the specific template is required in registration, which may introduce bias in longitudinal data analysis. The second limitation of these methods is that the longitudinal registration is performed independently across different subjects, instead of simultaneous groupwise registration of all 4D subjects.\nDavis et al. (Davis et al., 2007) use the kernel regression method to construct the atlas over time. It is assumed that human brains are distributed on a Riemannian manifold (see Fig. 1(a) ). In this way, a weighted average image can be computed at any time point by registering all other images to the space of that particular time point and adaptively measuring their contributions according to the distance metric defined on the manifold. However, the subject-specific longitudinal information is never considered in this method, and the registration of each time-point image is independently performed, regardless of its temporal consistency with respect to other time-point images.\nDurrleman et al. (Durrleman et al., 2009 ) presented an interesting spatial-temporal atlas estimation approach to analyze the variability of longitudinal shapes, as demonstrated in Fig. 1(b) . Their method does not require the subjects to be scanned at the same time points or have the same number of scans. To obtain the longitudinal information, they first infer the shape evolution within each subject (as indicated by the solid curves in Fig. 1(b) ) by a regression model. Then, spatial-temporal pairwise registration is performed between each subject sequence and the atlas sequence, mapping not only the geometry of evolving structure but also the dynamics of shape evolution by using the time-related diffeomorphism. Finally, the mean image as well as its shape evolution can be constructed after aligning all subjects to the template space. They have tested their method on 2D human skull profiles and the amygdale of autistics, but no result reported on real human brain. Also, one limitation of this method is that an explicit template is still required in the registration.\nRecently, groupwise registration becomes more and more popular due to its attractiveness in unbiased analysis of population data (Balci et al., 2007; Jia et al., 2010; Joshi et al., 2004; Wang et al., 2010; Wu et al., in press ). Compared to the traditional pairwise registration algorithm, groupwise registration aims to simultaneously estimate the transformation fields of all subjects without explicitly specifying an individual subject as the template, in order to avoid any bias introduced by the template selection for the subsequent data analysis (Fox et al., 2011; Thompson and Holland, 2011; Yushkevich et al., 2010) . Metz et al. proposed the B-Spline based nD+t registration method (Metz et al., 2011) which combines the groupwise and longitudinal registrations together. Thus, more accurate and consistent registration results can be achieved on 4D-CT data of lung and 4D-CTA data of heart. However, their method only investigates the temporal motion for one subject.\nWith the increasing number of longitudinal dataset, e.g., ADNI project (ADNI), the disease-related longitudinal studies become popular to discover the subject-specific anatomical patterns due to longitudinal changes (Davatzikos et al., 2011; Driscoll et al., 2009 ) and inter-group structure differences in hippocampus (Wolz et al., 2010) or through cortical thickness (Li et al., in press ). Meanwhile, the research on young brain development is an area of intense interest since last decade (Knickmeyer et al., 2008) . In these studies, all the images (from a series of longitudinal image sequences) need to be mapped to the common space, with each subject-specific longitudinal change well delineated. Motivated by these requirements, we propose a novel groupwise image sequence registration method to simultaneously register longitudinal image sequences of multiple subjects, each of which can have a different number of longitudinal scans. Taking all the images as a whole, our method is able to simultaneously map them to the hidden common space by establishing the spatial correspondences between each image and the mean shape/image defined in the hidden common space. Then, for each subject, its subject-specific spatial-temporal consistency is modeled by the temporal fiber bundles (as shown by the dashed curves in Fig. 1(c) ), which are constructed by mapping the mean shape to each image domain. It is worth noting that the temporal fiber bundles we proposed here are totally different from the fibers in DTI image (Mori and Zijl, 2002) . Our proposed temporal fiber bundles over time are artificially constructed by the spatial transformation fields from the mean shape, and they are used to embed the temporal smoothness for each subject. In this way, both inter-subject spatial correspondences and intra-subject longitudinal changes can be considered jointly in our proposed registration framework.\nThe spatial correspondences used to map each image to the common space are established by taking the mean shape as reference. However, instead of establishing the correspondence between each image and the mean shape for each voxel, only a small number of voxels, called driving voxels (Shen and Davatzikos, 2002) , are used to identify their correspondences since they are more reliable to determine the correct correspondences than other voxels. Other non-driving voxels only follow the transformations of those driving voxels in the neighborhood. Therefore, the procedure of estimating correspondences between each image and the mean shape in the hidden common space consists of two steps. In the first step, we only select a small number of driving voxels to identify the correspondences toward the mean shape by themselves. Here, both shape and appearance similarities are considered in the matching criteria: 1) the shape of deformed driving voxel set should be as close as possible to the mean shape, and 2) the appearances of all a) Davis et al [20] b) Durrleman et al [21] c) our method (Davis et al., 2007) and Durrleman et al. (Durrleman et al., 2009) are shown in (a) and (b), respectively. Our method is illustrated in (c). In (a), kernel regression is performed to construct the atlas at any time point. However, the longitudinal information from the same subject is not considered. The method in (b) explicitly estimates the shape evolution in each subject (as indicated by the solid curves) and then registers subject sequences to the atlas sequence (at the bottom of (b)). For our approach, all the images are simultaneously mapped to the hidden common space and the temporal consistency is also well preserved by the implicit temporal fibers (as displayed by the dashed curves).\ndeformed subjects should be as similar as possible in the common space after registration. In the second step, we employ thin-plate splines (Bookstein, 1989; Chui and Rangarajan, 2003) to interpolate the dense transformation fields based on the sparse correspondences established on the driving voxels. With the progress of registration, more and more voxels will be qualified as the driving voxels by simply relaxing the driving-voxel selection criterion. By iteratively repeating these two steps, all image sequences will be gradually aligned to the common space. Modeling the temporal change or motion is a challenging issue in both computer vision and computational anatomy. In Jojic et al., 2000) , the authors use the transformed hidden Markov model to measure the temporal dynamics of the entire transformation fields in video sequences. However, these methods can only deal with some predefined transformation models such as translation, rotation, and shearing. Miller (Miller, 2004) proposed a large deformation diffeomorphic metric mapping (LDDMM) (Beg et al., 2005) method for modeling growth and atrophy, in order to infer the time flow of geometric changes. This method is mathematically sound, but it considers only the diffeomorphism between two separate time points and is computationally expensive in solving the partial differential equation. In contrast, our idea here is to model the temporal continuity within each subject by using temporal fiber bundles, rather than entire transformation fields. Specifically, non-parametric kernel regression is used for regularization on each fiber (Davis et al., 2007) . Therefore, our method is efficient and data-driven, without using any prior growth model (Miller, 2004) , and thus more generalized.\nWe formulate our registration method with an expectation maximization (EM) framework by building a probabilistic model to regularize both spatial smoothness and temporal continuity along the fiber bundles. The final registration results are obtained by the maximum a posterior estimation (MAP) of the probabilistic model. Our groupwise longitudinal registration method has been evaluated in measuring longitudinal hippocampal changes from both simulated and real image sequences, and its performance is also compared with a pairwise registration method (Diffeomorphic Demons; Vercauteren et al., 2009 ), a 4D registration method (i.e., 4D-HAMMER; Shen and Davatzikos, 2004) , and a groupwise-only registration method (i.e., our method without temporal smoothness constraint). Experimental results indicate that our method can consistently achieve the best performance among all four registration methods.\nIn the following, we first present our registration in Method section. Then, we evaluate it in Experiments section by comparison with pairwise, 4D, and groupwise registration methods. Finally, we conclude the paper in Conclusion section."}, {"section_title": "Method", "text": "Given a set of longitudinal image sequences, I = {I s, t |s = 1, \u2026, N, t = 1, \u2026, T s } where I s, t represents the image acquired from subject s at time point t, our goal is to achieve: 1) Unbiased groupwise registration, i.e., map all W = \u2211 N s = 1 T s images to a common space C by following the transformation fields F = {f s, t |s = 1, \u2026, N, t = 1, \u2026, T s }, where f s, t = {f s, t (x)|x = (x 1 , x 2 , x 3 ) \u2208 C, and C \u2208 R 3 }; 2) Spatial-temporal consistency, i.e., preserve the warping consistency from I s, 1 to I s, T s in the temporal domain for each subject s.\nHere, we use \u03c4 as the continuous variable of time and then \u03c4 s, t denotes the discretely-sampled time of subject s being scanned at time point t. It is worth noting that different subjects might have different numbers of scans T S in our method. Also, for each subject s, the time span between two consecutive scans is not required to be equal."}, {"section_title": "The framework of our groupwise longitudinal registration method", "text": "The scenario of our groupwise longitudinal registration algorithm on sets of longitudinal image sequences of different subjects is demonstrated in Fig. 2 . For all the images, their transformation fields to the hidden common space (blue curves in Fig. 2 ) are simultaneously estimated by the unbiased groupwise registration strategy. Meanwhile, the temporal evolution of anatomical structures of each subject, i.e., due to aging or neural diseases, is jointly modeled and required to be smooth over time in our method.\nThe key to achieve the above two goals is to tackle the registration problem in both spatial and temporal domains. A simple scheme is to first determine the spatial correspondence for all the images and then perform the temporal smoothing for each subject separately. However, the major disadvantage of such scheme is the error propagation effect in the registration. More specifically, the possible false spatial correspondence will be propagated to the procedure of temporal smoothing and then the errors will turn back to undermine the spatial correspondence detection in the next iteration.\nIn this paper, we propose a novel probabilistic model to jointly consider both spatial smoothness and temporal continuity constraints for determining the correspondence of each image to the common space. The probabilistic model is built upon the fiber bundles in each subject (see the dashed curves in Fig. 3 for examples of the fiber bundles). Inspired by Chui et al. (2004) , the shape of each registered image I s, t in the common space can be represented by a set of sparse points which are generated from a Gaussian mixture model (GMM). The centers of GMM, called mean shape in this paper (as shown in the top row with the red box in Fig. 3 ), are denoted as Z ={z j |z j \u2208 R 3 , j =1, \u2026, K}, where each z j denotes the position of the j-th point of the mean shape in the common space, and there are totally K points on the mean shape. Then, for each z j , its transformed positions in the space of subject s along different time points t can be regarded as the landmarks in a continuous temporal fiber \u03c6 s j (\u03c4), where \u03c6 s j (\u03c4 s, t )=f s, t (z j ) at the scanning time \u03c4 s, t .\nThus, \u03c6 s j (\u03c4) can be considered as a continuous trajectory function of time \u03c4 in subject s, which maps the j-th point of mean shape z j to the subject space at arbitrary time \u03c4. We will make it clear in the next section that the constraint of temporal continuity is deployed along these temporal fibers. As shown in Fig. 3 , the mean shape Z in the common space will be first mapped to each individual image's space I s, t by the corresponding deformation field f s, t (solid curves in Fig. 3) . Next, the longitudinal changes within each subject s are captured by the temporal fiber bundles \u03a6 s ={\u03c6 s j (\u03c4)|j =1, \u2026, K} (i.e., dash curves with different colors for different subjects in Fig. 3 ). Therefore, given the mean shape Z, all the images within each subject s(i.e., I s, 1 , \u2026, I s, T S ), are artificially connected by the embedded temporal fibers \u03a6 s , i.e., deformed instances f s, t (Z) shown in the middle row of Fig. 3 . In order to establish the anatomical correspondences between each image I s, t and the mean shape Z in the common space, only the most distinctive voxels, called driving voxels X s, t ={x s, t i |i =1, \u2026, M s, t }, are used to establish correspondence between each image I s, t and the mean shape Z by robust feature matching, where M s, t denotes the number of the driving voxels selected in the image I s, t . Examples of the driving voxels are shown at the bottom of Fig. 3 as the red points, overlaid on the brain slices. As we will make it clear later, each transformation field f s, t is entirely steered by the sparse correspondences determined between f s, t and Z by TPS interpolation (Bookstein, 1989) . Accordingly, the spatial and temporal domains are unified by the mean shape Z defined in the common space. All z j s in the mean shape Z are regarded as hidden states, while the driving voxels X s, t of all images are the observations. On one hand, by mapping Z to each image space I s, t , the transformation field I s.t of each I s, t is steered by the spatial correspondences of Z w.r.t the driving voxels X s, t . On the other hand, given a set of estimated f s, t of each subject s, temporal fiber bundles \u03a6 S can be set up to afford the exploration on temporal continuity along these fibers.\nIn the rest of the section, we will first propose the probabilistic models for capturing both shape and appearance information contained in the driving voxels during registration, and also the spatial-temporal heuristics (based on the kernel regression technique) for the fiber bundles to construct a unified probabilistic model for registration of longitudinal sequence sets in The framework of our groupwise longitudinal registration method section. Then, we will present an approach to estimate the optimal model parameters based Fig. 2 . The illustration of our groupwise longitudinal registration algorithm on subject image sequences. In our algorithm, all images (from different subjects with different number of scans) will be simultaneously aligned to the common space by their respective transformation fields (as shown by the blue solid curves). Meanwhile, the temporal consistency of each subject will be preserved during the registration by temporal fiber bundles (as shown by the red dashed curves). Fig. 3 . The schematic illustration of the proposed method for simultaneous longitudinal and groupwise registration. For each image, its driving voxels X s, t (highlighted in red color on the brain slice, with the enlarged views shown in the bottom) will be used to steer the estimation of the transformation fields f s, t by establishing their correspondences with the mean shape Z in the common space (as shown in the top row). Meanwhile, the temporal consistency within each longitudinal sequence can be regulated along the temporal fiber bundles, as displayed by the dash curves in the middle row (with different colors for different subjects)."}, {"section_title": "Mean shape", "text": "on the maximum a posterior (MAP) estimation for these probabilistic models in Probabilistic model for registration of longitudinal image sequences section. The whole method is finally summarized in Simultaneously estimating the transformation fields for longitudinal image sequences section. Before we introduce the probabilistic models in the next section, important notations used in this paper are summarized in Table 1 . Hereafter, we use (s, t) to denote the subject s at scan time point t, while (s ', t ') is used to denote all possible subjects and scan time points in the image dataset."}, {"section_title": "Probabilistic model for registration of longitudinal image sequences", "text": "Our registration algorithm aims to simultaneously minimize the anatomical variabilities of all images after registration, while at the same time preserve the temporal continuity within the longitudinal sequence of each subject. In general, the transformation field f s, t (defined in the common space) is used to pull each image I s, t from its own space to the common space. The bending energy (Bookstein, 1989; Chui and Rangarajan, 2003) is used as the smoothness term to regularize each f s, t . In this paper, the thin-plate splines (TPS) (Bookstein, 1989 ) are adopted as it is efficient to give the optimal transformation field f s, t with minimal bending energy. In the following, we will use the operator L S (f s, t ) to denote the bending energy of each transformation field f s, t in the spatial domain, which is defined as:\nIt is clear that the bending energy term L S (f s, t ) is the sum of the squared second order derivatives in the direction of axes x 1 , x 2 , and x 3 (Chui and Rangarajan, 2003) .\nAttribute vectors have been widely used as morphological signatures to guide image registration (Shen and Davatzikos, 2002; Xue et al., 2004) . Without loss of generality, we follow the method in Shen and Davatzikos (2002) to calculate the attribute vector \u21c0 a x; I s;t \u00c0 \u00c1 at each location x \u2208 R 3 of each image I s, t . Specifically, the attribute vector \u21c0 a x; I s;t \u00c0 \u00c1 consists of image intensity, edge type, and the geometric moment invariants on whiter matter (WM), gray matter (GM), and the cerebrospinal fluid (CSF). It is worth noting that other image features, such as local histograms (Shen, 2007) and S\u03b1S filters (Liao and Chung, 2008) , can also be used here to establish the correspondence. According to the prior knowledge on brain anatomy (Shen and Davatzikos, 2002) , a small set of driving voxels X s, t (displayed in the bottom of Fig. 3 ) with the most distinctive attribute vectors in the image I s, t can be first selected to drive the registration procedure. The advantage of only using the driving voxels to guide the registration process in the early stage is that they can provide more reliable anatomical correspondences between images and thus reduce the risk of being trapped at local minima during the registration. It can be observed that they are generally located at the most salient positions in the brain, e.g., gyral crowns, sulcal roots, and ventricular boundaries. We will further demonstrate in the following sections that our registration method gains a lot of benefits from the use of the driving voxels for establishing reliable correspondences and thus making the registration procedure efficient and effective.\nShape model on the driving voxels Here, we consider each driving voxel X s, t i selected from subject s at time t as a random variable drawn from the Gaussian mixture model with its centers located at a deformed point set f s, t (Z), which is the map of the mean shape Z warped from the common space C to the individual image domain I s, t . We then introduce the hidden variables m s, t i \u2208 {1, \u2026, K} (where K is the number of temporal fibers) to indicate the spatial assignment of a specific GMM center in generating x s, t i .\nHereafter, we use m = {m s,\ndenote the collection of all hidden variables m s, t i . The probability density function of x s, t i can thus be given by:\nwhere \u03bc z = f s,t (z j ) and \u03a3 z = \u03b7 j 2 \u00b7 Id 3 \u00d7 3 denote the mean and the covariance matrix of the normal distribution N x i s;t ; \u03bc z ; \u03a3 z , respectively. Id 3 \u00d7 3 denotes the 3 \u00d7 3 identity matrix since we deal with 3D image. For sake of simplicity, the isotropic covariance matrix \u03a3 z is assumed, as widely used in the field of image/point-set registration."}, {"section_title": "Appearance model on the driving voxels", "text": "In this paper, the appearance information of each driving voxel is represented by its corresponding attribute vector, which embeds rich anatomical information around the driving voxel. Given the association m s, t i between x s, t i and z j , the attribute vector \u21c0 a x i s;t ; I s;t of the driving voxel x s, t i can also be regarded as the random variable generated from the Gaussian mixture model (GMM), where the centers of this GMM are the collection of attribute vectors \u21c0 a f s\n, with association of a particular z j \u2208 Z. Given the latest estimated z j and f s ' , t ' , the goal of our appearance model is to maximize the similarities between the underlying \u21c0 a x i s;t ; I s;t and all its counterparts \u21c0 a f s\nTo simplify the problem, we here assume that all elements in the attribute vector are independent with the standard deviation \u03c1 j . Then, given F, z j and the corresponding assignment m s, t i , the conditional probability of attribute vector \u21c0 a x i s;t ; I i s;t on the driving voxel x s, t i is defined as: Table 1 Summary of important notations."}, {"section_title": "Symbol Description", "text": ""}, {"section_title": "I", "text": "All images acquired from all subjects s at all time points t; I={I s, t |s=1, \u2026 N;\nThe transformation field of each image I s, t toward the hidden common space C F The collection of transformation fields f s, t ; F={f s, t |s =1,\nThe discrete scanning time of subject s at time point t \u03c6 s j (\u03c4) The trajectory function representing a particular temporal fiber in subject\nThe temporal fiber bundles in subject s;\nThe collection of all M s, t driving voxels in image I s, t ; X s, t ={x s, t i |i =1, \u2026, The collection of all m s,\nThe bending energy of transformation field f s, t L T (\u03c6 s j (\u03c4)) The residual energy after performing kernel regression on a particular\nBy denoting the conditional probability of m s, t i as P(m s, t i = j| f s, t , z j ), the posterior probability of x i s;t ; \u21c0 a x i s;t ; I s;t (given m s, t i , the transformation fields F, and the mean shape Z) can be formulated as:\nAs we will make it clear in Simultaneously estimating the transformation fields for longitudinal image sequences section, \u03be(x s, t i , z j ), termed as the local discrepancy, indicates the likelihood of the particular driving voxel x s, t i being the correspondence of z j , which consists of both shape and appearance discrepancies. In the implementation, we set \u03b7 j =1.0 and \u03c1 j =1.0.\nSpatial-temporal heuristics on the fiber bundles The shape and appearance models proposed for the driving voxels above are aimed to establish reliable correspondence between the mean shape and each image. However, the longitudinal information existing within each subject is not clear so far. It is clear that the time-varying variables in our method are the association m s, t i and the transformation field f s, t . Note that the transformation field f s, t here is equipped only with the information of the spatial correspondences to map each image I s, t to the common space C, with no piece of temporal information considered yet.\nAlthough it is challenging to describe the overall temporal motion from f s, t to f s, t + 1 , the motion on particular fiber can be easily modeled as the kernel regression problem (Wand and Jones, 1995) where the objective is to fit the continuous motion trajectory (temporal fiber \u03c6 s j (\u03c4)) based on the known landmarks at \u03c6 s j (\u03c4 s, t ) (recalling that \u03c6 s j (\u03c4 s, t )=f s, t (z j )\nin Table 1 ). Therefore, the energy function of temporal smoothness on particular fiber \u03c6 s j (\u03c4) is formulated as:\nwhere \u03c8 is the regression function and in this paper we use the Gaussian kernel with bandwidth \u03c3 \u03c4 . In principle, L T (\u03c6 s j (\u03c4)) measures the residual energy after performing temporal smoothing on each position of one fiber, which accounts for the smoothness in temporal domain. Hereafter, we call\u03c6 j s \u03c4 \u00f0 \u00de as the fibers after temporal smoothing. It is worth noting that more sophisticated kernel-based regression methods (Comaniciu et al., 2003; Davis et al., 2007) are also applicable here."}, {"section_title": "Unified probabilistic model for registration of longitudinal image sets", "text": "Considering h = (Z, F, {\u03a6 s }, m) as the model parameters and\ns;t ; I s;t n o as the observations, the joint probability P(h, v) is given by:\nIt is clear that P(h, v) consists of four terms. The first term denotes the prior probability on the mean shape Z, where P(z j )=1/K since no prior knowledge is known on z j . The second term measures the conditional likelihood probability P m; x i s;t n o ; \u21c0 a x i s;t ; I s;t n o jF; \u03a6 s f g; Z given the transformation fields F and the temporal fibers {\u03a6 s }. The last two terms are the probability functions of spatial transformation field P(f s, t ) and the temporal fiber bundles P(\u03c6 s j (\u03c4)| f s, t , Z), which are defined as:\nwhere \u03bb 1 and \u03bb 2 are the scales used to control the smoothness of the spatial transformation field f s, t (Chui and Rangarajan, 2003) and the temporal fiber bundles \u03a6 s (Wand and Jones, 1995) , respectively. In all our experiments, we set both \u03bb 1 and \u03bb 2 to 1. It is worth noting that m s, t i is considered as the hidden variable, which guides the correspondence detection in registration. More details will be given in the next section. Now our registration problem is converted to the problem of inferring the model parameters h which can best interpret the observation v:\nWe will present the solution to\u0125 below."}, {"section_title": "Simultaneously estimating the transformation fields for longitudinal image sequences", "text": "Here, we follow one of the variational Bayes inference approaches, called \"free energy with annealing\" (Frey and Jojic, 2005) , to formulate the energy function of statistical model in Eq. (8) as (see Appendices I and II for details):\nwhere r is the temperature which decreases gradually in the annealing scenario. The term Q(m s, t i =j) denotes for the approximated discrete distribution of probability P(m s, t i = j) in Eq. (6), which measures the likelihood of correspondence between z j and driving voxel x s, t i . It is obvious that the first term in Eq. (9) describes the cost in correspondence detection, while the second and third terms represent the smoothing constraints on the deformation fields and the temporal fibers, respectively. Furthermore, the first term in Eq. (9) has been similarly defined in (Chui and Rangarajan, 2003; Shen, 2009; Wu et al., 2010) that minimizes the weighted discrepancy \u03be on each driving voxel x s, t i with respect to the mean shape point z j and the associated correspondence likelihood Q(m s, t i = j). The entropy term Q(m s,\nmeasures the fuzziness on correspondence assignments of x s, t i to all possible z j s. Thus, the small degree of this entropy term encourages the exact binary correspondence between each x s, t i and all z j s in registration.\nOn the contrary, multiple correspondences are allowed when the entropy term is large. As we will see below, the temperate r dynamically controls the correspondence assignment from fuzzy to binary, which is very important to achieve the robust registration as demonstrated in Chui and Rangarajan (2003) , Shen (2009), and Wu et al. (2010) . Next, we will give the solution to optimize the energy function Eq. (9). "}, {"section_title": "Optimization of energy function", "text": "It is clear that \u03be(x s, t i , z j ), defined in Eq. (4), acts as the potential energy which indicates the likelihood of establishing correspondence between x s, t i and z j . As mentioned in Eq. (9), r denotes the temperature in the annealing system, which will gradually decrease to encourage the assignment changing from fuzzy to binary. Notice that the variable r is the denominator of the exponential function in Eq. (10). Therefore, at the beginning stage of the registration, when the degree of r is very high, although the discrepancy \u03be(x s, t i , z j ) (the nominator of the exponential function in Eq. (10)) between z j and x s, t i is large, that x s, t i still might have the chance to contribute in calculating the correspondence of z j in image I s, t . As the registration proceeds, the specificity of correspondence will be encouraged to increase the registration accuracy by decreasing the temperature r. Finally, only the x s, t i with the smallest discrepancy will be considered as the correspondence of z j . The remaining optimization on F, Z, and {\u03a6 s } can be solved in two relatively simple sub-problems. Recall that \u03c6 s j (\u03c4 s, t )=f s, t (z j ) is the particular landmark on the temporal fiber \u03c6 s j (\u03c4) at time \u03c4 s, t , our idea is that we first minimize E(Q, F, {\u03a6 s }, Z) w.r.t \u03c6 s j (\u03c4) by regarding \u03c6 s j (\u03c4) as a whole, then find thef s;t and\u1e90 which achieve the optimal\u03c6 j s \u03c4 s;t \u00c0 \u00c1 by solving the fitting problem. In this way, we have a relationship\nThen the objective functions in the two sub-problems (SP 1 and SP 2 ) are given as:\nSP 2 : min\nSP 1 aims to solve the correspondence at time \u03c4 s, t for a particular fiber \u03c6 s j (\u03c4) as well as to estimate the longitudinal continuous fiber\u03c6 j s \u03c4 \u00f0 \u00de by kernel regression (Wand and Jones, 1995) . SP 2 is the groupwise registration problem where we need to interpolate the dense transformation field f s, t (to simultaneously deform each image I s, t to the common space C) and the update of mean shape Z. The solutions to SP 1 and SP 2 are explained below."}, {"section_title": "SP 1 : Estimation of longitudinal continuous fibers", "text": "To this point, we are facing two coupled optimization problems in Eq. (14). One is the correspondence determination problem on z j s and the other is the estimation of longitudinal continuous fiber \u03c6 s j (\u03c4), which boils down to the kernel regression problem. The combination of these two optimization problems is difficult to solve, however, the optimal solution to the correspondences at \u03c6 s j (\u03c4 s, t ) is much easier to compute if the entire fiber \u03c6 s j (\u03c4) is fixed. Here, we adopt an alternative optimization scheme as the solution. First, the spatial locations of the landmark points {\u03c6 s j (\u03c4 s, t )|t =1, \u2026, T s } in fiber \u03c6 s j can be obtained by optimizing the first term in Eq. (11) w.r.t. \u03c6 s j (\u03c4 s, t ) as:\nObviously, \u03c6 s j (\u03c4 s, t ) is the weighted mean location of all driving voxels in image I s, t . After that, the continuous fiber\u03c6 j s \u03c4 \u00f0 \u00de can be calculated by minimizing the energy L T (\u03c6 s j (\u03c4)) defined in Eq. (5), which is known as the Nadaraya-Watson estimator (Nadaraya, 1964 ):\nHere, the adaptive kernel-based smoothing is performed along each fiber of each subject, to preserve the temporal smoothness as well as minimize the residual error between \u03c6 s j (\u03c4 s, t ) before regression and \u03c6 j s \u03c4 s;t \u00c0 \u00c1 after regression. In general, large value of \u03c3 results in the smoother result at the expense of registration accuracy. In our implementation, we dynamically set the value of \u03c3 in the hierarchical way. In the beginning, \u03c3 is relatively high (e.g., \u03c3 = 2.0) to roughly determine the correspondences. With the progress of registration, we gradually decrease the value of \u03c3, in order to achieve better registration accuracy.\nSP 2 : Groupwise registration In this step, by considering {z j } as the source point set and\u03c6 j s \u03c4 s;t \u00c0 \u00c1 n o as the target point set, TPS (Bookstein, 1989; Chui and Rangarajan, 2003 ) is used to efficiently interpolate the dense transformation field f s;t , which satisfiesf s;t z j \u00c0 \u00c1 =\u03c6 j s \u03c4 s;t \u00c0 \u00c1 and achieves the minima of L s (f s, t ) (see Eq. (1)).\nFinally, by minimizing the energy function in SP 2 with respect to z j , each point z j in the mean shape Z is updated as:\ns;t is the inverse transformation field off s;t (the calculation of inverse transformation field can be referred to Christensen and Johnson, 2001) . It is worth noting that we use the driving voxels x s, t on a particular image I s, t , with the overall minimal distance to all other images, as the initialization of the mean shape Z."}, {"section_title": "Summary of our method", "text": "Our method is briefly summarized as follows:\n1. Calculate the attribute vector (Shen and Davatzikos, 2002) "}, {"section_title": "Experiments", "text": "The ultimate goal of our groupwise longitudinal registration algorithm is to consistently reveal the subtle anatomical changes for facilitating the diagnosis (or early prediction) of brain diseases, i.e., dementia. The proposed method is evaluated on both simulated and real datasets in this paper. For the simulated dataset, three subjects with simulated atrophy in hippocampus are used. For the real dataset, 9 elderly brains with manually-labeled hippocampi at year 1 and year 5 and also the longitudinal ADNI dataset (10 normal controls and 10 AD patients imaged 3 times over 12 months). All the subjects in all experiments have been linearly aligned using the method described in before conducting the non-rigid image registration process. The proposed method is also compared with three other approaches: 1) Diffeomorphic Demons registration method to the individual baseline image and then register all baseline images to the template); 2) 4D-HAMMER registration method (a feature-based registration method to align the subject sequence with the template sequence) ; and 3) Groupwise-only registration method (i.e., our whole method without temporal smoothing step) to simultaneously align all images to the common space."}, {"section_title": "Experiments on simulated data Experiment setup", "text": "In this experiment, all the images are T1-weighted MR images, with image size of 256 \u00d7 256 \u00d7 124 and voxel size of 0.9375\u00d7 0.9375 \u00d7 1.5 mm 3 . Three subjects with manually labeled hippocampus regions at year 1 are used as the baseline data (t = 1) to simulate atrophy on their hippocampi. It has been reported in (Henneman et al., 2009 ) that the annual hippocampus atrophy ratio is 4.0 \u00b1 1.2% for AD patient. Thus, we use a simulation model (Karacali and Davatzikos, 2006) to simulate b5% shrinkage on hippocampi from the current time point image (t =1) and thus generating a simulated image with hippocampus atrophy as the second time point image (t = 2). By repeating this procedure, we finally obtain 3 sets of longitudinal data with hippocampal volume shrinking at an annual rate of b5% through the five time points. Considering the possible numerical error in simulation, the total simulated atrophy is 15.71% within the five years. All three baseline subjects and their followups are shown in Fig. 4 , with the simulated atrophy ratio on hippocampi (w.r.t. the baseline image) displayed on the top of each follow-up image.\nWe first apply our groupwise longitudinal registration method to these 5 \u00d7 3 images to simultaneously estimate their transformation fields from their own spaces to the hidden common space. In order to compare the accuracy in measuring longitudinal changes, we also employ Diffeomorphic Demons, 4D-HAMMER, groupwise-only registration method, and our registration method on these 15 images. For the groupwise-only registration method and our method, all 15 images will be mapped to the common space; but the common space estimated by the groupwise-only registration method might be not necessarily the same as the one estimated by our method. For the Diffeomorphic Demons and 4D-HAMMER, we need to first specify the template before registration. For Diffeomorphic Demons, we use the median image of three baseline images as the template, which has the overall minimal SSD in terms of intensity w.r.t. all other images. For 4D-HAMMER, we repeat the selected median baseline image as 5 different time-point images to construct a template sequence with 5 time points . In the following, we evaluate the performance of these four different registration approaches."}, {"section_title": "Result 1: Quantitative measurement of the hippocampal volume change", "text": "Since there is no template used in the groupwise-only registration method, we need to vote the hippocampus mask as the reference and then map it back to each individual space to measure the subjectspecific longitudinal changes. For all four registration methods, we quantitatively measure the hippocampus volume loss for each subject in two steps: 1) vote a hippocampus mask by majority voting strategy either in a particular template space (for Diffeomorphic Demons and 4D-HAMMER) or in the common space (for the groupwise-only registration method and our method), based on the observation of all aligned hippocampus images; 2) map the voted hippocampus mask back to each individual subject space. Fig. 5(a) shows the curves of the estimated hippocampus volume loss in a typical subject (i.e., subject 1 shown in Fig. 4) by Diffeomorphic Demons, 4D HAMMER, groupwiseonly registration method, and our groupwise longitudinal registration method in black, blue, green and red, respectively. The ground truth of hippocampus volume loss is also displayed with pink solid curve in Fig. 5(a) . The averaged hippocampus volume losses estimated by the four methods are also shown in Fig. 5(b) , with the same legend of Fig. 5(a) . The final estimated mean and standard deviation of hippocampus volume loss is 7.50% \u00b1 1.03% by Diffeomorphic Demons, 15.26% \u00b1 0.55% by 4D-HAMMER, 14.59% \u00b1 0.82% by groupwise-only registration method, and 15.67% \u00b1 0.51% by our method.\nHere, the procedure of measuring hippocampus volume change for each registration approach consists of two steps. First, we need to vote a reference hippocampus mask by using the majority voting strategy, based on the already aligned hippocampus labels. Since we only have the manual labeled hippocampus in year 1 and year 5 for all 9 subjects, the reference hippocampus mask is voted among these 2 \u00d7 9 = 18 warped hippocampus regions after we align all images to the same space. Second, we apply the inverse transformation fields to map the voted hippocampus mask back to each individual image space. Next, we measure the annual hippocampus volume changes subject-by-subject. Since we have the manually labeled hippocampus area at year 1 and year 5 for each subject, we can calculate the average percentage of hippocampus volume loss during these 5 years, which is 5.65 \u00b1 1.58% by manual labeling. For the four different registration methods, the estimated average hippocampus atrophy and standard deviation detected in 5-year span is 2.60% \u00b10.67% by the Diffeomorphic Demons, 5.23% \u00b10.42% by 4D-HAMMER, 4.39% \u00b10.59% by the groupwise-only registration method, and 5.38%\u00b10.35% by our groupwise longitudinal registration method. The curves reflecting the averaged percentage of hippocampus volume changes w.r.t. the baseline, estimated by these four methods, are also shown in Fig. 9 , where curves in black, blue, green, and red are used to represent the results estimated by Diffeomorphic Demons, 4D-HAMMER, the groupwise-only method, and our groupwise longitudinal registration method, respectively. "}, {"section_title": "Discussion 1", "text": "It is clear that our method achieves the highest accuracy in measuring of anatomical changes, albeit the result by the 4D-HAMMER method is comparable with ours. Both of these two longitudinal methods outperform the Diffeomorphic Demons and groupwise-only registration method since they do not have the constraint on temporal smoothness. It is worth noting that the estimated hippocampus volume loss ratio (15.26%) by 4D-HAMMER is slightly different from that (15.9%) reported in since different template image sequences are used.\nSince all voxels are equally considered in Diffeomorphic Demons and only the image intensity is used for registration, the deformation on hippocampus areas might be dominated by their surrounding large but uniform anatomies, which leads to the inaccurate registration on hippocampus and thus inaccurate longitudinal measurement on hippocampus volume loss. On the contrary, the other three registration methods use the attribute vector to establish the anatomicallymeaningful correspondence. Also, the driving voxels help reduce the ambiguity in registration by letting the voxels with distinctive features to drive the deformations of other less-distinctive voxels. All these explain why the performance in measuring shrinkage of tiny hippocampus volume by Diffeomorphic Demons is much worse than the other three methods.\nIn this experiment, we only report the estimated atrophy ratio between time point 1 and time point 5 since we have only the manuallylabeled hippocampi at these two time points. Compared with the atrophy ratio (5.65%) measured by manual raters, the results estimated by both 4D-HAMMER (5.23%\u00b10.42%) and our groupwise longitudinal registration method (5.38%\u00b1 0.35%) are closer than other two methods. In terms of temporal continuity, the estimated curves of annual hippocampus atrophy by 4D-HAMMER and our groupwise longitudinal registration method are also much smoother than those of other two methods. spaces are different in these four different registration methods. Therefore, the registered images shown in Fig. 10 might be different. However, the registration accuracy can be evaluated for each registration method by inspecting registration result of each subject across time. Therefore, in Fig. 10 , we focus on the intensity transition on the three points: \u2460 the interface point between brain and background in vertical line A (denoted by '\u0394'); \u2461 the intersection of vertical line A and horizontal line B (denoted by '\uf00a'); and \u2462 the ventricle boundary in horizontal line B (denoted by '\u25cb'). All through Figs. 10(a)-(d) , the 1d + t results of line A and B are shown in the right hand, with the horizontal representing the view along the line and the vertical denoting for the time (from year 1 in the bottom to year 5 in the top).\nIn general, the registration approaches with temporal smoothness constraint (4D-HAMMER (Fig. 10(b) ) and our groupwise longitudinal registration method (Fig. 10(d) )) outperform their counterparts (Diffeomorphic Demons (Fig. 10(a) ) and groupwise-only registration method (Fig. 10(c) )), as designated by the blue arrows."}, {"section_title": "Result 2: Evaluation of temporal continuity", "text": "Next, we will observe the performance of the proposed method in preserving temporal continuity within the same subject, by visually inspecting the fiber bundles and quantitatively measuring the velocity along fibers. Taking one subject as the example, Fig. 6(a) shows one cross section slice, overlaid with the remaining part of hippocampus after 5-years shrinkage (red color) and the shrinkage part of the hippocampus during the 5 years (green color) compared to the baseline data. Figs. 6(b)-(i) visually demonstrate the temporal fibers by the four registration methods, where the x 1 , x 2 , and x 3 axes denote the 3D coordinate system. Since our method explicitly uses the temporal fiber bundles to achieve spatial-temporal continuity, it is straightforward to display the temporal fibers \u03c6 s j in Figs. 6(h) and (i) whose z j s happened to be located in the color region (i.e., hippocampal area at that cross-section view) in Fig. 6(a) . To distinguish the temporal order in Fig. 6 (h), we display the landmarks on these selected temporal fibers with pink 'x' for year 1, cyan 'o' for year 2, green '\u0394' for year 3, red '+' for year 4, and blue '*' for year 5, respectively. Fig. 6 (i) shows these temporal fibers by connecting the landmarks of consecutive years in Fig. 6 (h) with different color (pink for the fiber segment between year 1 and year 2, cyan for the fiber segment between year 2 and year 3, green for the fiber segment between year 3 and year 4, and red for the fiber segment between year 4 and year 5), according to the time order. It can be observed that all the fibers across the color regions in Fig. 6 (a) are smooth and the temporal orders are well preserved as expected by our method. Similarly, we investigate the temporal smoothness by the Diffeomorphic Demons, 4D-HAMMER, and the groupwise-only registration method by mapping the same mean shape Z in our method to the domain of each image, according to the transformation field produced by these three methods, since neither of them used the concept of temporal fibers during registration of all subjects to the template (by the Diffeomorphic Demons and 4D-HAMMER) or the common space (by the groupwiseonly registration method). The pseudo temporal fibers with the same z j s by Diffeomorphic Demons, 4D-HAMMER, and the groupwise-only registration method are shown in Figs. 6(b)-(c), (d) -(e), and (f)-(g), respectively. It can be observed that, since no temporal continuity within each subject is considered during the registration, the temporal landmarks produced by Diffeomorphic Demons and groupwise-only registration method, from year 1 to year 5, have no time order information as shown in Figs. 6(h) and (i). However, 4D-HAMMER enforces temporal smoothness in its energy function and results in temporal trajectory almost as smooth as our method.\nGiven the temporal fibers, we can further quantitatively measure the temporal smoothness by calculating the magnitude of the changing velocity along each fiber. Figs. 7(a)-(d) show the velocity magnitude along fibers (with the associated z j s located in the color region of Fig. 6(a) ), produced by Diffeomorphic Demons, 4D-HAMMER, groupwise-only method, and our groupwise longitudinal registration method, respectively. Since the simulated data has only 5 time-point scans, we can calculate the velocity magnitudes for 4 segments. The yellow lines in Figs. 7(a)-(d) denote the average evolution curves of the velocity magnitudes by the four methods. As shown in Fig. 7 , the changes of velocity magnitude among all the fibers obtained by 4D-HAMMER in (b) and our method in (d) are much more consistent over time than Diffeomorphic Demons in (a) and the groupwise-only method in (c)."}, {"section_title": "Discussion 2", "text": "With explicit constraint of temporal continuity, our groupwise longitudinal registration method and 4D-HAMMER are able to achieve better performances over the Diffeomorphic Demons and groupwiseonly registration method, in terms of registration consistency along time.\nSince the intensity contrast is very poor in hippocampal area, the 1d + t images shown in Fig. 10 seem not consistent across time in the uniform regions (due to partial volume effect) along either line A or line B. Hence, we have to inspect the consistency only on the 3 transition points in Fig. 10 . Although 4D-HAMMER has the comparable performance in delineating the subject-specific anatomical changes, our longitudinal groupwise registration method achieves better performance in the next experiment in measuring the registration accuracy when considering all longitudinal sequences as a whole."}, {"section_title": "Experiments on real elderly brain data", "text": ""}, {"section_title": "Experiment setup", "text": "Nine elderly subjects, each with annual MR scans in 5 years, are used in this experiment and shown in . The actual ages of 9 subjects when taking the MR scan are shown in Table 2 . For each subject, we have the manually labeled hippocampus only for year 1 and year 5. For the Diffeomorphic Demons registration method, we first select a median image of all baseline images that has the overall smallest distance to other images as the template (as pointed by the red arrow in Fig. 8 ). For 4D-HAMMER, we use the selected median image to repeat it as 5 different time-point images for constructing the template sequence with 5 time points , to which the subject sequence is registered. For the other two methods (the groupwise-only method and our groupwise longitudinal registration method), all 45 images will be simultaneously deformed to the common space."}, {"section_title": "Result 3: Quantitatively measure the registration accuracy", "text": "The registration performance can be further evaluated by computing the overlap ratio on different types (WM, GM, and VN (ventricles)) of brain tissues. Considering that the pairwise based method has the template during registration while the groupwise based method does not, we use a very strict overlap measurement strategy by calculating the overlap ratios between all possible pairs of aligned images, for each tissue type. Here, the Jaccard Coefficient metric (Jaccard, 1912 ) is used to measure the overlap of two regions with the same tissue type. For the two registered regions A and B, its overlap ratio is defined as:\nBefore non-linear registration, the average overlap ratio of WM, GM, CSF is 46.7\u00b1 8.8%, 37.4 \u00b1 8.3%, and 40.9 \u00b1 15.5%, respectively. Then, by considering all 45 aligned images together, the average overlap ratios of WM, GM and VN are 59.6 \u00b1 5.5%, 49.6 \u00b1 5.3%, 71.8 \u00b1 5.5% by Diffeomorphic Demons, 60.6\u00b1 4.9%, 50.7 \u00b1 4.6%, 72.3 \u00b1 5.6% by 4D-HAMMER, 63.8 \u00b1 4.9%, 51.2\u00b1 5.3%, 71.2 \u00b1 5.0% by the groupwise-only registration method, and 65.6 \u00b1 5.1%, 52.5 \u00b1 5.4%, and 73.9 \u00b1 5.2% by our groupwise longitudinal registration method, which are all reported in Table 3 . Furthermore, we perform the two-sample t-test (paired and two tailed) between the overlap ratios of our groupwise longitudinal registration method and all other three registration methods, which shows that our method achieves significant improvement in all three tissue types with p b 0.01.\nNext, by measuring the tissue overlap for the 5 aligned images of the same subject and then averaging across 9 subjects, the mean and standard deviation of the tissue overlap ratios are 78.3 \u00b1 1.9%, 66.5 \u00b1 2.9%, 82.2 \u00b1 3.6% by the our method on WM, GM, and VN, respectively, compared to 70.8\u00b1 3.0%, 60.1% \u00b1 2.4%, 77.4 \u00b1 3.5% by Diffeomorphic Demons, 76.0 \u00b1 2.4%, 64.7 \u00b1 2.4%, 78.3 \u00b1 2.9% by 4D-HAMMER and 77.2\u00b1 2.3%, 66.0\u00b1 2.7%, 79.7 \u00b1 3.5% by the groupwise-only registration method. The lower quartiles, medians, and upper quartiles of the tissue overlap ratios on WM, GM, and VN are also shown in Figs. 11(a)-(c) , respectively, for the four different registration approaches."}, {"section_title": "Discussion 3", "text": "Our method consistently outperforms the other three methods in accurately aligning all 45 images to the common space (Table 3) , as well as better preserving the registration consistency among each subject (Fig. 10) . Although we propose to simultaneously register all images to the common space, the alignment of particular longitudinal subject is very important in many clinical applications. Therefore, we further evaluate the registration results (i.e., the overlap ratios on WM, GM, and VN by the four methods in Fig. 11 ) by considering longitudinal data of each subject as the group, where our method also achieves the best overlap ratios on all tissue type over the other three methods.\nAlthough 4D-HAMMER has the similar performance with our groupwise longitudinal registration method in measuring the longitudinal subject-specific hippocampus changes, the tissue overlap ratio of all aligned images in the template domain is worse than our method because 4D-HAMMER registers the subject sequence only with the template sequence and does not consider the matching of all aligned subject sequences. On the contrary, our method jointly considers all images during registration and aligns them to the hidden commons space that is close to every image. Accordingly, the overall overlap ratio of every possible pair of aligned images by our method is much higher than 4D-HAMMER."}, {"section_title": "Experiments on ADNI data Experiment setup", "text": "In this experiment, we use the MR images from ADNI (Alzheimer's Disease Neuroimaging Initiative) project to demonstrate the application of our longitudinal groupwise registration method in the early detection of Alzheimer's disease (AD) by tracking the longitudinal volume change of hippocampus. It has been reported in (Schuff et al., 2009 ) that the AD patients usually have greater hippocampus volume loss over time than normal subjects. Thus, we select 10 typical longitudinal sequences from AD (Alzheimer's Disease) group and another 10 from the normal control (NC) group. Since the goal of this experiment is to demonstrate the registration performance, we consider the hippocampus mask provided by the ADNI dataset as the ground truth.\nAll images were acquired from 1.5T scanner, with image size 256 \u00d7 256 \u00d7 256 and voxel size 1 \u00d7 1 \u00d7 1 mm 3 . Each sequence has 3 time points, i.e., baseline, 6 and 12 months (0-6-12 months) with the hippocampus masks provided. For Diffeomorphic Demons, we choose the baseline image of one subject as the template, which has the minimal overall intensity difference to all other images. Then all followup images in each longitudinal sequence will be aligned with its baseline image. Next, the baseline image of each longitudinal sequence will be registered with the selected template image. The final deformation is the composition of the deformation fields in these two steps. For 4D-HAMMER registration method, we first construct the template sequence by repeating the selected 3D template as different time-point images . The 4D-HAMMER method will be performed to align each longitudinal sequence with the constructed template sequence. For the groupwise-only method and our groupwise longitudinal method, all the images will be simultaneously registered to the common space, while the temporal smoothness is only enforced and encoded in the temporal fibers of our method."}, {"section_title": "Result", "text": "After registration by four registration methods, we first vote a hippocampus mask by majority voting in the common/template space as the reference. Then we map the voted hippocampus mask back to each subject space at each time point. Considering the hippocampus masks given in the ADNI dataset as the ground truth, the ground-truth hippocampus volume shrinkage ratios (compared to the baseline image) of AD and NC groups are shown in Fig. 12(a) . The estimated hippocampus volume shrinkage ratios by Diffeomorphic Demons, 4D-HAMMER, groupwise-only, and our longitudinal groupwise registration method are displayed in Figs. 12(b) -(e), respectively. The red lines denote for the results of AD group and blue lines for the NC group. The black line in each panel of Fig. 12 represents the mean change from 6 months to 12 months in each group. The statistics (lower quartiles, medians, and upper quartiles) of the hippocampus shrinkage ratios on AD and NC group by four registration methods are also shown in Figs. 13(b) -(e), with statistics of ground truth displayed in Fig. 13(a) . It is obvious that the result by our method is closer to the ground truth and also the temporal smoothness is better maintained than all other three methods.\nThe estimated hippocampus shrinkage ratios by Diffeomorphic Demons, 4D-HAMMER, groupwise-only, and our groupwise Fig. 14 corresponds to the hippocampus shrinkage ratios for each subject, with red and blue denoting the results for the AD subject and normal-control subject, respectively. Since we performed 4 experiments as mentioned, we have 4 estimated hippocampus shrinkage ratios for each subject, as represented by the four curves in each panel. The mean and standard deviation of the shrinkage ratios between time points #1 and #3 can be computed, and they are (0.092\u00b1 0.30)%, (0.035\u00b10.18)%, (0.088\u00b1 0.35)%, (0.038\u00b10.060)% by Diffeomorphic Demons, 4D-HAM-MER, groupwise only registration, and our groupwise longitudinal registration method, respectively."}, {"section_title": "Discussion", "text": "In this experiment, we use the ADNI dataset to demonstrate the potential application of our method in longitudinal study. As shown in Figs. 12(a) and 13(a), hippocampus volumes generally decrease over time. However, we found some abnormal cases (i.e., the hippocampus volume increases over time) by Diffeomorphic Demons and groupwise-only registration method, since both methods do not consider the temporal heuristics during the registration. The results by the 4D-HAMMER and our longitudinal groupwise registration method are better in keeping temporal continuity, due to the use of temporal smoothness constraint in the registration. Compared with the ground-truth data, the estimated hippocampus shrinkage ratios by our method are closer to those by the 4D-HAMMER.\nSince the groupwise-only method and our groupwise longitudinal registration method are not biased by the template selection and also estimate the deformation fields of all images simultaneously, the estimated hippocampus shrinkage ratios are consistent across all 4 experiments as expected. (Note that the groupwise-only method has the same result across different experiments and the results by our groupwise longitudinal registration method are very close to each other. Therefore, we only observe one curve in Figs. 14(c) and (d)). On the contrary, the Diffeomorphic Demons and 4D-HAMMER need to specify a certain image as the template. For example, Diffeomorphic Demons needs to first align images in time points #2 and #3 to the time point #1 for the intra-subject longitudinal registration. Thus, when the image in time point #1 is changed in the experiment, the final registration results could also change, as indicated by the inconsistent estimated hippocampus shrinkage ratios shown in Fig. 14(a) . 4D-HAMMER also needs to explicitly initialize the temporal correspondence between two neighboring time points by a pairwise registration algorithm before the sequence-to-sequence registration, thus obtaining inconsistent results across 4 different experiments as shown in Fig. 14(b) . In summary, these results have demonstrated the capability of our groupwise longitudinal registration method in capturing unbiased estimation for hippocampus atrophy."}, {"section_title": "Experiments on ADNI test/retest dataset Experiment setup", "text": "In ADNI, each subject was scanned twice at each time point, in order to obtain both MP-RAGE and repeat MP-RAGE data. Also, one of these two scans has been further processed by ADNI with their developed image processing pipeline, including intensity bias correction and hippocampus segmentation (Yushkevich et al., 2010) . For performing test-retest experiment, we regard those two originally-acquired MP-RAGE images and the one post-processed image as three different images (acquired at the same time point) for the same subject. For the hippocampus, since its label mask is given only for the post-processed image, we map it, respectively, to the two MP-RAGE images (by rigidly registering the post-processed image with the two MP-RAGE images) to achieve the ground-truth segmentations for the two MP-RAGE images as well. Particularly, we select 1 AD subject and 1 normal-control subject from ADNI dataset, and construct 4 different image sequences for each subject by randomly ordering its respective three images. Table 4 shows details on how we construct 4 image sequences for each subject. Then, at each experiment, we perform image registration method upon these 2 randomly constructed image sequences (one AD and one NC). Consequently, we repeat this procedure for 4 times with the image sequence constructed w.r.t. Table 4 at each experiment."}, {"section_title": "Computation time", "text": "Here we report the computation time of Diffeomorphic Demons, 4D-HAMMER, groupwise only and our groupwise longitudinal registration method in Table 5 . All the experiments are run on our DELL computation server with 2 CPUs (4 cores, 2.0 GHz) and 32 G memory. It is clear that our groupwise longitudinal achieves similar computation time The estimated hippocampus volume shrinkage ratios by Diffeomorphic Demons, 4D-HAMMER, groupwise-only method, and our longitudinal groupwise registration method in the four repeated experiments. In each panel, the red curves denote results for the AD subject, while the blue curves denote for the normal subject. The meaning for each red (or blue) curve is explained in Table 4 ."}, {"section_title": "Table 5", "text": "The computation time by Diffeomorphic Demons, 4D-HAMMER, groupwise-only method, and our groupwise longitudinal registration method. Diffeomorphic Demons~1.5 h~4 h~8 h 4D-HAMMER~4 h~18 h~40 h Groupwise-only registration method~2\n.5 h~8.5 h~12 h\nGroupwise longitudinal registration method~2\n.5 h~8.5 h~12 h with groupwise only registration method, but much faster than 4D-HAMMER."}, {"section_title": "Conclusion", "text": "In this paper, we have presented a novel method for groupwise registration of serial images. The proposed method adopts both the spatial-temporal heuristics and the groupwise registration strategy for registering a group of longitudinal image sequences. More specifically, the spatial-temporal continuity is achieved by enforcing the smoothness constraint along fiber bundles within each subject. Moreover, we simultaneously estimate all the transformation fields which map all the images to the hidden common space without explicitly specifying any template, thus avoiding the introduction of any bias to the subsequent data analysis.\nFuture work includes 1) investigating more powerful kernel regression methods to regulate the temporal smoothness along the temporal fiber bundles; 2) integrating our groupwise longitudinal registration method in consistent labeling of longitudinal dataset under the framework of our previous developed 4D tissue segmentation algorithm (CLASSIC (Xue et al., 2006) ); 3) testing our method in clinical applications, e.g., measuring longitudinal brain changes in mild cognitive impairment (MCI) study (Petersen, 2007) ."}, {"section_title": "Appendix I", "text": "It is usually intractable to optimize h directly according to P(h, v) in Eq. (8) since the dimension of h is high. Therefore, the actual inference of h in our method is the MAP estimation on the posteriori distribution P(h| v). One of the variational Bayes inference approaches, called \"free energy with annealing\" (Frey and Jojic, 2005) , is used to obtain the optimal parameter h by minimizing the distance between P(h|v) and P(h, v), which bounds for maximizing the likelihood of the observation P(v).\nHowever, the posteriori distributions of some variables (i.e., F, {\u03a6 s }, and Z) are hard to compute. Instead, we estimate F, {\u03a6 s }, and Z by maximizing their expectations w.r.t. the maintained posteriori distributions of hidden variables {m s, t i }, which falls to the EM principle.\nFollowing the notation in (Frey and Jojic, 2005) , the Q-distribution approximating the real posterior function P(h|v) is: \nIn order to achieve robust registration result, the free energy with annealing (Frey and Jojic, 2005 ) is defined as:\nwhere r is the temperature gradually decreasing from high to low in the annealing scenario. By substituting P(h, v) (in Eq. (6)) and Q(h) (in Eq. (17)) to Eq. (19) and discarding some constant terms, we obtain the free energy for our registration algorithm, as in Eq. (9). (Please see Appendix II for the derivation of Eq. (9).)"}, {"section_title": "Appendix II", "text": "The energy function in Eq. (9) is obtained from free energy in Eq. (19) by substituting Q(h) in Eq. (17) where \u03b5 = r \u22c5 (K + W + KW) \u2212 2 denotes the constant. Hereafter, by omitting the constant \u03b5 and regarding the variable r as the temperature in the annealing system, we obtain the energy function of our groupwise longitudinal registration algorithm, which is defined in Eq. (9)."}]