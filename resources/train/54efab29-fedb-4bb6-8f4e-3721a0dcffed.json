[{"section_title": "List of Figures", "text": ""}, {"section_title": "List of Tables", "text": ""}, {"section_title": "Introduction", "text": "What Is PIAAC? The Program for the International Assessment of Adult Competencies (PIAAC) is a cyclical, large-scale study of adult skills and life experiences focusing on education and employment. Nationally representative samples of adults between the ages of 16 and 65 are administered an assessment of literacy, numeracy, and problem solving in technology rich environments, as well as survey questions about their educational background, work history, the skills they use on the job and at home, their civic engagement, and sense of their health and well-being. The results are used to compare participating countries on the skills capacities of their workforce-aged adults and to learn more about relationships between educational background and employment and other outcomes. PIAAC is coordinated by the Organization for Economic Cooperation and Development (OECD) and developed by participating countries with the support of the OECD. PIAAC was first administered in 2011-12 in the United States and 23 other countries. 1 What Is the U.S. PIAAC National Supplement? The U.S. PIAAC National Supplement is the second PIAAC data collection in the United States. Conducted from August 2013 through April 2014, the National Supplement's household data collection surveyed 3,660 adults from three key U.S. subgroups of interest: unemployed adults (age 16 to 65); young adults (age 16 to 34); and older adults (age 66 to 74). In addition to a household data collection, the National Supplement also surveyed 1,319 respondents from a target population defined as adult inmates (age 16 to 74) detained in federal and state prisons in the United States. 2 The second round of U.S. PIAAC household data collection repeated the same procedures, instruments, and assessments that were used for the first round of data collection (called the \"2012 PIAAC Main Study\") in the same sampled areas (or primary sampling units). However, while the first round collected data from a nationally representative sample of 5,010 adults, the second round collected data from 3,660 adults from only the three targeted (or oversampled) subgroups of interest. Together, the two rounds of U.S. PIAAC household data collection provide a nationally representative sample of 8,670 noninstitutionalized adults in the United States between the ages of 16 and 74. It is important to note, however, that the second round of data is, by design, an oversample to supplement the first round of data collection and, hence, can only be used together with the first round of data."}, {"section_title": "Why Was the National Supplement Conducted?", "text": "The National Supplement was conducted for two reasons. First, augmenting the U.S. PIAAC sample permits more in-depth analyses of the cognitive and workplace skills of the U.S. population, in particular of the three key U.S. subgroups listed above. Second, the additional information on adults age 66 to 74 and incarcerated adults makes PIAAC data comparable with data collected by NCES in the 2003 National Assessment of Adult Literacy (NAAL). This in turn makes it possible to analyze change in adult skills over the decade between the two studies. What Does PIAAC Measure? PIAAC is designed to assess adults in different countries over a broad range of abilities, from simple reading to complex problem-solving skills, and to collect information on individuals' skill use and background. PIAAC defines four core competency domains of adult cognitive skills that are seen as key to facilitating the social and economic participation of adults in advanced economies: literacy, reading components, numeracy, and problem solving in technology-rich environments. All participating countries and regions are required to assess the literacy and numeracy domains, but the reading components and problem solving in technology-rich environments domains are both optional. The United States assessed all four domains. For a list of the subject experts who contributed to the development of the PIAAC assessment, see appendix A. For a more detailed description of the four domains, see appendix B. Tasks developed for PIAAC's four domains are authentic, culturally appropriate, and drawn from real-life situations that are expected to be important or relevant in different contexts. Tasks are intended to reflect adults' daily lives across cultures, even if not every adult is necessarily familiar with every task. PIAAC is not designed to provide individual scores, but rather to measure how groups of adults perform on the domains. In order to be as efficient as possible with participants' time, each respondent receives only a portion of the assessment items (see the Data Collection section of appendix C for more detail)."}, {"section_title": "Literacy", "text": "The primary goal of PIAAC's literacy assessment is to measure everyday literacy, which is defined by the PIAAC framework as \"understanding, evaluating, using and engaging with written text to participate in society, to achieve one's goals and to develop one's knowledge and potential \" (OECD 2012)."}, {"section_title": "Reading components", "text": "The primary goal of the PIAAC reading components measure is to provide information about the literacy skills of adults at the lower end of the literacy spectrum-specifically, whether they have the foundational skills to develop the higher literacy and numeracy abilities necessary for functioning in society. The reading components assessment focuses on elements of reading that are comparable across the range of languages in the participating countries: reading vocabulary, sentence comprehension, and basic passage comprehension. Note that results for this domain are not shown in this report."}, {"section_title": "Numeracy", "text": "The primary goal of PIAAC's numeracy assessment is to evaluate basic mathematical and computational skills that are considered fundamental for functioning in everyday work and social life. Numeracy in the PIAAC framework is defined as \"the ability to access, use, interpret, and communicate mathematical information and ideas, to engage in and manage mathematical demands of a range of situations in adult life \" (OECD 2012).\nThe primary goal of PIAAC's numeracy assessment is to evaluate basic mathematical and computational skills that are considered fundamental for functioning in everyday work and social life. Numeracy in the PIAAC framework is defined as \"the ability to access, use, interpret, and communicate mathematical information and ideas, to engage in and manage mathematical demands of a range of situations in adult life \" (OECD 2012). The PIAAC numeracy domain is built on previous large-scale assessments of this domain, schooloriented assessments, and a review of requirements of workplace skills, adult learning, and mathematics and statistics education. The tasks that measure this domain involve managing a situation or solving a problem in a practical context-in home, work, or community settings. These tasks ask respondents to work with numbers, proportions, measurements, and statistical concepts, and then call for participants to compute, interpret, and communicate the results and mathematical content. The situations and problems presented in these tasks involve objects or pictures, text, numbers, graphs, and technology-based displays. They also require basic mathematical skills in computation, proportions and percentages, an understanding of measurement concepts and procedures, and working with simple formulas. Respondents also encounter more complex items that require using models to predict future needs, and an understanding of basic statistical concepts and displays. In addition, PIAAC numeracy assessment items are set in authentic and culturally appropriate contexts; measure different levels of ability; and use the standard measuring systems of the participating country or region. Numeracy tasks include items in paper-and-pencil and computer-based delivery modes that cover a range of difficulties-low, middle, and high-to present a comprehensive picture of the level of adult numeracy skills in each country or region. Exhibit B-3. Description of PIAAC proficiency levels on the numeracy scale Proficiency levels and cut scores for numeracy"}, {"section_title": "Problem solving in technology-rich environments", "text": "PIAAC represents the first attempt to assess problem solving in technology-rich environments on a large scale and as a single dimension in an international context. PIAAC defines problem solving in technology-rich environments as \"using digital technology, communication tools, and networks to acquire and evaluate information, communicate with others, and perform practical tasks \" (OECD 2012)."}, {"section_title": "Skill use and the background questionnaire", "text": "In addition to the skills assessment, PIAAC's background questionnaire surveys adults about their educational background; work history; their intrapersonal, interpersonal, and professional skills; and their use of those skills on the job and at home."}, {"section_title": "Reporting Results", "text": "The purpose of this report is to present selected results from the first and second rounds of the U.S. PIAAC household data collection (PIAAC 2012/2014). 3 PIAAC results are reported in two ways: (1) as scale scores (estimated on a 0-500 scale) in the three domains of literacy, numeracy, and problem solving in technologyrich environments, 4 and (2) as percentages of adults reaching the proficiency levels established for each of these domains. PIAAC reports five proficiency levels for literacy and numeracy (Below level 1, Level 1, Level 2, Level 3, and Level 4/5) and four levels for problem solving in technology-rich environments (Below level 1, Level 1, Level 2, and Level 3). The OECD provides detailed descriptions of the types of skills that can be performed at each level. For example, adults at Level 1 in literacy can \"read relatively short\u2026texts to locate a single piece of information that is identical to or synonymous with the information given in the question or directive\" and can \"enter personal information onto a document\" when \"[l]ittle, if any, competing information is present.\" However, adults at Level 1 typically are not successful performing skills at the higher levels (e.g., \"compare and contrast or reason about information requested\" or \"navigate within digital texts to access and identify information from various parts of a document,\" both of which are Level 2 literacy skills). Appendix B provides the OECD's detailed descriptions of these levels along with examples of assessment items at each level. This report follows OECD reporting conventions by combining the top two proficiency levels (Levels 4 and 5) for the literacy and numeracy scales (OECD 2013). Across all countries, only 2 percent or less of adults performed at Level 5 in literacy and numeracy. This report also provides an international average for scale scores and proficiency levels for variables that are internationally comparable. The international averages in figures 3, 4, 5, 6, and 8 represent the averages for all participating countries and regions shown in this report and may differ slightly from the international averages reported in the 2012 NCES First Look (Goodman et al., 2013) (see below for details). (Goodman et al., 2013) released in October 2013 presented data from the 2012 PIAAC Main Study. It focused on adult skills in the United States compared to the average of countries that participated in PIAAC in 2012 (the PIAAC international average), by major demographic characteristics. This First Look report presents the U.S. PIAAC 2012/2014 data, which supports more detailed and precise estimates. 5 This First Look report updates some of the comparisons in the previous report, but also presents new results for unemployed adults, young adults, and older adults, which can now be analyzed because a larger sample is available to reliably estimate performance for these groups."}, {"section_title": "NCES's 2012 PIAAC First Look", "text": "The PIAAC international averages in the 2012 PIAAC First Look report were calculated using the U.S. 2012 data and restricted-use data for Australia and Canada. However, data from Australia and Canada are not available because of national restrictions on the use of their data. Thus, the PIAAC international averages in figures 3, 4, 5, 6, and 8 in this report were calculated (a) without Australian data, (b) with Canada's publicly available PIAAC data, and (c) with the U.S. PIAAC 2012/2014 data. Differences in the international averages calculated for the 2012 PIAAC First Look and those calculated for this report are very small but, on account of them, some estimates round differently."}, {"section_title": "How Does this First Look Report Differ from the 2012 PIAAC First Look?", "text": "The percentage distribution of the population by key reporting variables is displayed in table 1 for all U.S. adults age 16-65, unemployed adults age 16-65, young adults age 16-34, and older adults age 66-74. Readers are cautioned not to draw causal inferences from results presented in this report. Many of the variables examined in this report may be related to one another, but the complex interactions and relationships among them have not been explored. The variables examined here are also just a few of the variables that can be examined in these data; they were selected to demonstrate the range of information available from the study. The release of this report is intended to encourage more in-depth analysis of the data using more sophisticated statistical methods. All statistically significant differences described in this report are significant at the .05 level. No statistical adjustments to account for multiple comparisons were used. Differences that are statistically significant are discussed using comparative terms such as \"higher\" and \"lower.\" Differences that are not statistically significant are either not discussed or referred to as \"not measurably different\" or \"not statistically significant.\" In this case, failure to find a difference as statistically significant does not necessarily mean that there was no difference. It could be that a real difference cannot be detected by the significance test because of a small sample size or an imprecise measurement in the sample. If the statistical test is significant, this means that there is convincing evidence (though no guarantee) of a real difference in the population. However, it is important to remember that statistically significant results do not necessarily identify those findings that have policy significance or practical importance. See appendix C for more information about statistical testing. A Brief History of PIAAC PIAAC's development was based upon the pioneering work of national adult literacy assessments undertaken by the United States and Canada. In the United States, the first national assessment of literacy was the 1985 Young Adult Literacy Study (YALS), which was followed in 1992 by the National Adult Literacy Survey (NALS) and in 2003 by the National Assessment of Adult Literacy (NAAL). U.S. participation in international adult literacy assessments began in 1994 with the International Adult Literacy Survey (IALS), followed in 2003 by the Adult Literacy and Lifeskills Survey (ALL). Drawing on the knowledge and experience gained from these earlier national and international largescale adult literacy assessments, PIAAC improves on these studies' content frameworks, design, and methodologies to provide better measurement. PIAAC also extends the definitions of literacy and numeracy used by IALS and ALL; however, to ensure continuity with these previous studies and permit measurements of trend, PIAAC includes items from both IALS and ALL. Besides building on these earlier national and international studies, PIAAC includes various innovations that set it apart from these earlier studies. For example, PIAAC is the first large-scale assessment to be adaptive and administered on laptop computers to respondents in their homes. PIAAC provides more information about individuals with low levels of literacy by assessing reading component skills. To assess adults' knowledge and skills for the digital age, PIAAC developed a new problem-solving domain with an emphasis on skills used in digital or technology-rich environments."}, {"section_title": "Selected Findings", "text": "Overall summary for adults age  In literacy, the U.S. average score (272) was not measurably different than the PIAAC international average score (273) (see figure 1-A). Compared with the PIAAC international average distribution of literacy skills, the United States had a larger percentage of adults performing at both the top and the bottom of the distribution (13 versus 12 percent at Level 4/5, and 18 versus 16 percent 6 at Level 1 and below, see figure 2-A). In numeracy and problem solving in technology-rich environments, the United States performed below the PIAAC international average. In numeracy, the U.S. average score was 12 points lower than the PIAAC international average score (257 versus 269, see figure 1-B), and in problem solving in technology-rich environments, the U.S. average score was 9 points lower than the international average (274 versus 283, see figure 1-C). Compared with the international average distributions for these skills, the United States had \u2022 \u2022 a smaller percentage at the top (10 versus 12 percent at Level 4/5 in numeracy, and 5 versus 8 percent at Level 3 in problem solving in technology-rich environments, see figures 2-B and 2-C), and a larger percentage at the bottom (28 versus 19 percent 6 in numeracy, and 64 versus 55 percent 6 in problem solving in technology-rich environments at Level 1 and below). Overall summary for U.S. adults age 16-74 by age 7 The U.S. distribution of skills in each of the three domains for adults age 16-74, by age, suggested a relationship between age and performance. In literacy, the percentages of adults performing at the top proficiency level (4/5) were larger for adults age 25-34 and 35-44 than for adults at the other 10-year age intervals. In numeracy, the percentages of adults performing at the top proficiency level (4/5) were larger for those age 25-34 and 35-44 than those age 55-65 and 66 and older. For adults in the youngest age interval (16-24), the percentages at the top proficiency levels (4/5 for literacy and numeracy and 3 for problem solving in technology-rich environments) were consistently smaller than for adults age 25-34 (see figures 10-A, 10-B, and 10-C)."}, {"section_title": "Overall summary for U.S. adults age 16-65 by employment status", "text": "In literacy, 15 percent of employed adults age 16-65 performed at the top proficiency level (4/5), while in numeracy 12 percent of employed adults reached this level. In both cases, the percentage of employed adults at the top proficiency level was larger than that of unemployed adults (7 percent in literacy and 4 percent in numeracy) and adults who were out of the labor force (9 percent in literacy and 6 percent in numeracy) (see figures 3-A and 3-B). Similarly, across all three domains, a larger percentage of adults age 16-65 who were unemployed and out of the labor force performed at or below Level 1 compared with adults who were employed (see figures 3-A, 3-B, and 3-C)."}, {"section_title": "Overall summary for unemployed adults age 16-65", "text": "About 75 percent of unemployed U.S. adults age 16-65 had a high school credential or less education. Roughly a third of these adults performed at Level 1 or below in literacy (26 to 38 percent) and about half performed at Level 1 or below in numeracy (47 to 58 percent) (see figures 4-A and 4-B). The relationship between age and performance that was noted above among all U.S. adults differed for unemployed adults. Instead of the percentage of adults at the top proficiency level being smaller at older ages, among unemployed adults there was no measurable difference at the top proficiency level (4/5) in literacy and numeracy between those age 55-65 and age 25-34 (8 versus 6 percent in literacy and 5 versus 4 percent in numeracy) (see figures 5-A and 5-B). Comparing internationally, among unemployed adults age 16-65, larger percentages of both males and females in the United States performed at the bottom of the proficiency distribution (Level 1 or below) in numeracy and problem solving in technology-rich environments than is the case, on average, across the participating PIAAC countries (see figures 6-B and 6-C). Among unemployed U.S. adults age 16-65, larger percentages of unemployed White adults performed at the top proficiency level in all three domains (4/5 for literacy and numeracy and 3 for problem solving in technology-rich environments) than Black and Hispanic adults (12 versus 1 and 2 percent in literacy, 7 versus 1 and 2 percent in numeracy, and 5 versus 1 percent each in problem solving in technologyrich environments)(see figures 7-A, 7-B, and 7-C)."}, {"section_title": "Overall summary for young adults age 16-34", "text": "Among young adults age 16-34, the U.S. distribution of skills in each of the three domains by educational attainment suggested a relationship between education and performance. In general, the higher the level of education completed, the larger the percentages of young adults at the top proficiency levels (4/5 for literacy and numeracy and 3 for problem solving in technology-rich environments) and the smaller the percentages at the bottom (Level 1 and below) (see figures 8-A, 8-B, and 8-C). Comparing internationally, among young adults age 16-34 whose highest level of education was high school or less, larger percentages in the United States performed at the bottom of the proficiency distribution (Level 1 or below) in all three domains than is the case, on average, across the participating PIAAC countries (see figures 8-A, 8-B, and 8-C). In the United States, smaller percentages of Black and Hispanic young adults age 16-34 performed at the top proficiency level (4/5) in literacy (4 and 5 percent) than their peers who reported their race/ ethnicity as White or Other (20 and 17 percent) (see figure 9-A)."}, {"section_title": "Overall summary for older U.S. adults age 66-74", "text": "In literacy and numeracy, there were no measurable differences in the percentage of older U.S. adults age 66-74 who performed at the highest proficiency level (4/5) between those who had a graduate or professional degree and those who had a bachelor's degree as their highest educational attainment (19 versus 19 percent in literacy and 18 versus 15 percent in numeracy) (see figures 11-A and 11-B). This differed from the pattern among young adults described above. Among older U.S. adults age 66-74, a greater percentage of those employed compared with those out of the labor force performed at the highest proficiency level (4/5) in numeracy (10 versus 4 percent) (see figure 12-B). Older U.S. adults age 66-74 who reported that their health status was \"fair\" had a larger percentage at the bottom of the proficiency distribution (Level 1 and below) in literacy and numeracy than their peers who reported that their health status was \"good,\" \"very good,\" or \"excellent\" (see figures 13-A and 13-B).  "}, {"section_title": "Tables and Figures", "text": ""}, {"section_title": "Adults age 16 to 65", "text": "1 Data for all countries are from 2012, except for the United States which are the U.S. PIAAC 2012/2014 data. 2 PIAAC 2012 international average based on all countries and regions that participated in PIAAC 2012 as reported in the 2012 NCES First Look (Goodman et al., 2013). Country-and region-specific results are available at http://nces.ed.gov/surveys/piaac/results/makeselections.aspx. NOTE: Countries and regions are listed in descending order determined by their unrounded average scores. Apparent differences between estimates may not be statistically significant. Some population groups did not have enough sample size to meet the minimum reporting standards.  G e r m a n y A u s t r i a C y p r u s P o l a n d I r e l a n d F r a n c e S p a i n I t a l y Score is signi cantly higher than the U.S. average score Score is not signi cantly di erent from the U.S. average score Score is signi cantly lower than the U. S.  average score  296 288 284 279 278 276 275 274 274 273 273 273 272 272 271 270 269 269 267 267 262   252 250   0   50   100   150   200   250   300 Scale score 500 J a p a n F i n l a n d Figure 1-C. Average scores on the PIAAC problem solving in technology-rich environments scale for adults age 16 to 65, by participating country and region: 2012 and 2014 1 1 Data for all countries are from 2012, except for the United States which are the U.S. PIAAC 2012/2014 data. 2 PIAAC 2012 international average based on all countries and regions that participated in PIAAC 2012 as reported in the 2012 NCES First Look (Goodman et al., 2013). Country-and region-specific results are available at http://nces.ed.gov/surveys/piaac/results/makeselections.aspx. NOTE: Countries and regions are listed in descending order determined by their unrounded average scores. No countries or regions scored significantly lower than the United States. Apparent differences between estimates may not be statistically significant. Some population groups did not have enough sample size to meet the minimum reporting standards. Not all countries chose to assess the problem solving in technology-rich environments domain. In countries that did, the percentage of respondents who completed the assessment varied widely from country to country but was less than the percentage that completed the literacy and numeracy domain because the assessment was only offered on computer. In the United States, approximately 15 percent of respondents chose not to take the assessment on computer or were unable to do so (see appendix C for more detailed information).   1 United States data are the U.S. PIAAC 2012/2014 data. 2 PIAAC 2012 international average based on all countries and regions that participated in PIAAC 2012 as reported in the 2012 First Look (NCES 2013-008). Country-and region-specific results are available at http://nces.ed.gov/surveys/piaac/results/makeselections.aspx. NOTE: Detail may not sum to totals because of rounding. Apparent differences between estimates may not be statistically significant. Some population groups did not have enough sample size to meet the minimum reporting standards. Not all countries chose to assess the problem solving in technology-rich environments domain. In countries that did, the percentage of respondents who completed the assessment varied widely from country to country but was less than the percentage that completed the literacy and numeracy domain because the assessment was only offered on computer. In the United States, approximately 15 percent of respondents chose not to take the assessment on computer or were unable to do so (see appendix C for more detailed information).    1 United States data are the U.S. PIAAC 2012/2014 data. PIAAC international average is calculated from the U.S. PIAAC 2012/2014 data and international data from 2012 for all other countries shown in this report. Country-and region-specific results are available at http://nces.ed.gov/surveys/piaac/results/makeselections.aspx. NOTE: Percentages of adults age 16 to 65 by employment status appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information). The unemployed comprise all persons above a specified age who during the reference period were in the following categories: without work, that is, were not in paid employment or self-employment during the reference period; currently available for work, that is, were available for paid employment or self-employment during the reference period; and seeking work, that is, had taken specific steps in a specified recent period to seek paid employment or self-employment.  # Rounds to zero. \u2021 Reporting standards not met. Sample size insufficient to permit a reliable estimate. 1 United States data are the U.S. PIAAC 2012/2014 data. PIAAC international average is calculated from the U.S. PIAAC 2012/2014 data and international data from 2012 for all other countries shown in this report. Country-and region-specific results are available at http://nces.ed.gov/surveys/piaac/results/makeselections.aspx. 2 The PIAAC international average results for below level 1 of proficiency on the PIAAC literacy and numeracy scales are not available for unemployed adults age 16 to 65 whose highest level of education attainment is graduate or professional degree. NOTE: Percentages of unemployed adults age 16 to 65 by highest level of educational attainment appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information). Detail may not sum to totals because of rounding. Apparent differences between estimates may not be statistically significant. Some population groups did not have enough sample size to meet the minimum reporting standards.   Unemployed adults age 16 to 65 Country-and region-specific results are available at http://nces.ed.gov/surveys/piaac/results/makeselections.aspx. NOTE: Percentages of unemployed adults age 16 to 65 by 10-year age intervals appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information). Detail may not sum to totals because of rounding. Apparent differences between estimates may not be statistically significant. Some population groups did not have enough sample size to meet the minimum reporting standards.  2  20  41  30  8  3  19  41  31  6   21  42  25  7   20  43  27  6  8  21  31  31  8  4  20  40  29   1 United States data are the U.S. PIAAC 2012/2014 data. PIAAC international average is calculated from the U.S. PIAAC 2012/2014 data and international data from 2012 for all other countries shown in this report. Country-and region-specific results are available at http://nces.ed.gov/surveys/piaac/results/makeselections.aspx. NOTE: Percentages of unemployed adults age 16 to 65 by gender appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information). Detail may not sum to totals because of rounding. Apparent differences between estimates may not be statistically significant. Some population groups did not have enough sample size to meet the minimum reporting standards.    to 65 by race/ethnicity appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information     2  11  43  44  #  2  16  50  32  #  3  29  51  17  #  2  12  39  37  10  6  24  42  24  4  2  11  34  38   to 34 by race/ethnicity appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information  Black 14White (59) 1 6  29  44  20  3  21  46  26  4  7  20  40  28  5  2  11  31  39  17  2  11  34  38   to 74 by 10-year age intervals appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information). Detail may not sum to totals because of rounding. Apparent differences between estimates may not be statistically significant.  # Rounds to zero. \u2021 Reporting standards not met. Sample size insufficient to permit a reliable estimate. NOTE: Percentages of U.S. adults age 66 to 74 by highest level of educational attainment appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information). Detail may not sum to totals because of rounding. Apparent differences between estimates may not be statistically significant. Some population groups did not have enough sample size to meet the minimum reporting standards.   14High school credential 53Associate's degree 6Bachelor's degree 14Graduate or professional degree 13 14High school credential 53Associate's degree 6Bachelor's degree 14Graduate or professional degree 13  # Rounds to zero. \u2021 Reporting standards not met. Sample size insufficient to permit a reliable estimate. NOTE: Percentages of U.S. adults age 66 to 74 by employment status appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information). The unemployed comprise all persons above a specified age who during the reference period were in the following categories: without work, that is, were not in paid employment or self-employment during the reference period; currently available for work, that is, were available for paid employment or self-employment during the reference period; and seeking work, that is, had taken specific steps in a specified recent period to seek paid employment or self-employment. Out of the labor forces comprise all persons not classified as either employed or unemployed. Detail may not sum to totals because of rounding. Apparent differences between estimates may not be statistically significant. Some population groups did not have enough sample size to meet the minimum reporting standards.  Sample size insufficient to permit a reliable estimate. NOTE: Percentages of U.S. adults age 66 to 74 by self-reported health status appear in parentheses. The percentage distribution for problem solving in technology-rich environments scale includes only those adults who took the problem solving in technology-rich environments assessment. Approximately 15 percent of the U.S. sample chose not to take the assessment on computer or were unable to do so and therefore did not take the problem solving in technology-rich environments assessment (see appendix C for more detailed information). Detail may not sum to totals because of rounding. Apparent differences between estimates may not be statistically significant. Some population groups did not have enough sample size to meet the minimum reporting standards.   (14)  5  13  31  39  12  3  14  43  32  8  7  21  39  26  7  17  30  34  16  At this level, tasks may require the respondent to search for and integrate information across multiple, dense texts; construct syntheses of similar and contrasting ideas or points of view; or evaluate evidence-based arguments. Application and evaluation of logical and conceptual models of ideas may be required to accomplish tasks. Evaluating reliability of evidentiary sources and selecting key information is frequently a requirement. Tasks often require respondents to be aware of subtle, rhetorical cues and to make high-level inferences or use specialized background knowledge."}, {"section_title": "Level 4 (326 -375)", "text": "Tasks at this level often require respondents to perform multiple-step operations to integrate, interpret, or synthesize information from complex or lengthy continuous, non-continuous, mixed, or multiple type texts. Complex inferences and application of background knowledge may be needed to perform the task successfully. Many tasks require identifying and understanding one or more specific, non-central idea(s) in the text in order to interpret or evaluate subtle evidence-claim or persuasive discourse relationships. Conditional information is frequently present in tasks at this level and must be taken into consideration by the respondent. Competing information is present and sometimes seemingly as prominent as correct information.\nTasks at this level require the respondent to understand a broad range of mathematical information that may be complex, abstract or embedded in unfamiliar contexts. These tasks involve undertaking multiple steps and choosing relevant problem-solving strategies and processes. Tasks tend to require analysis and more complex reasoning about quantities and data; statistics and chance; spatial relationships; and change, proportions and formulas. Tasks at this level may also require understanding arguments or communicating well-reasoned explanations for answers or choices."}, {"section_title": "Level 3 (276 -325)", "text": "Texts at this level are often dense or lengthy, and include continuous, non-continuous, mixed, or multiple pages of text. Understanding text and rhetorical structures become more central to successfully completing tasks, especially navigating complex digital texts. Tasks require the respondent to identify, interpret, or evaluate one or more pieces of information, and often require varying levels of inference. Many tasks require the respondent to construct meaning across larger chunks of text or perform multi-step operations in order to identify and formulate responses. Often tasks also demand that the respondent disregard irrelevant or inappropriate content to answer accurately. Competing information is often present, but it is not more prominent than the correct information.\nTasks at this level require the respondent to understand mathematical information that may be less explicit, embedded in contexts that are not always familiar and represented in more complex ways. Tasks require several steps and may involve the choice of problem-solving strategies and relevant processes. Tasks tend to require the application of number sense and spatial sense; recognizing and working with mathematical relationships, patterns, and proportions expressed in verbal or numerical form; and interpretation and basic analysis of data and statistics in texts, tables and graphs."}, {"section_title": "Level 2 (226 -275)", "text": "At this level, the medium of texts may be digital or printed, and texts may comprise continuous, non-continuous, or mixed types. Tasks at this level require respondents to make matches between the text and information, and may require paraphrasing or low-level inferences. Some competing pieces of information may be present. Some tasks require the respondent to cycle through or integrate two or more pieces of information based on criteria; compare and contrast or reason about information requested in the question; or navigate within digital texts to access and identify information from various parts of a document.\nTasks at this level require the respondent to identify and act on mathematical information and ideas embedded in a range of common contexts where the mathematical content is fairly explicit or visual with relatively few distractors. Tasks tend to require the application of two or more steps or processes involving calculation with whole numbers and common decimals, percents and fractions; simple measurement and spatial representation; estimation; and interpretation of relatively simple data and statistics in texts, tables and graphs."}, {"section_title": "Level 1 (176 -225)", "text": "Most of the tasks at this level require the respondent to read relatively short digital or print continuous, non-continuous, or mixed texts to locate a single piece of information that is identical to or synonymous with the information given in the question or directive. Some tasks, such as those involving non-continuous texts, may require the respondent to enter personal information onto a document. Little, if any, competing information is present. Some tasks may require simple cycling through more than one piece of information. Knowledge and skill in recognizing basic vocabulary, determining the meaning of sentences, and reading paragraphs of text is expected.\nTasks at this level require the respondent to carry out basic mathematical processes in common, concrete contexts where the mathematical content is explicit with little text and minimal distractors. Tasks usually require one-step or simple processes involving counting, sorting, performing basic arithmetic operations, understanding simple percents such as 50%, and locating and identifying elements of simple or common graphical or spatial representations."}, {"section_title": "Below Level 1 (0 -175)", "text": "The tasks at this level require the respondent to read brief texts on familiar topics to locate a single piece of specific information. There is seldom any competing information in the text and the requested information is identical in form to information in the question or directive. The respondent may be required to locate information in short continuous texts. However, in this case, the information can be located as if the text were non-continuous in format. Only basic vocabulary knowledge is required, and the reader is not required to understand the structure of sentences or paragraphs or make use of other text features. Tasks below level 1 do not make use of any features specific to digital texts. Level 1: Generic medicine (Item ID: C309A321) Difficulty score: 219 The stimulus is a short newspaper article entitled \"Generic medicines: Not for the Swiss\". It has two paragraphs and a table in the middle displaying the market share of generic medicines in 14 European countries and the United States. The test-taker is asked to determine the number of countries in which the generic drug market accounts for 10 percent or more of total drug sales. The test-taker has to count the number of countries with a market share greater than 10 percent. The percentages are sorted in descending order to facilitate the search. The phrase \"drug sales\", however, does not appear in the text; therefore, the test-taker needs to understand that \"market share\" is a synonym for \"drug sales\" in order to answer the question.\nTasks at this level require the respondents to carry out simple processes such as counting, sorting, performing basic arithmetic operations with whole numbers or money, or recognizing common spatial representations in concrete, familiar contexts where the mathematical content is explicit with little or no text or distractors. Exhibit B-5. Description of PIAAC proficiency levels on the problem solving in technology-rich environments scale Proficiency levels and cut scores for problem solving in technology-rich environments Problem solving in technology-rich environments task descriptions At this level, tasks typically require the use of both generic and more specific technology applications. Some navigation across pages and applications is required to solve the problem. The use of tools (e.g., a sort function) is required to make progress towards the solution. The task may involve multiple steps and operators. The goal of the problem may have to be defined by the respondent, and the criteria to be met may or may not be explicit. There are typically high monitoring demands. Unexpected outcomes and impasses are likely to occur. The task may require evaluating the relevance and reliability of information in order to discard distractors. Integration and inferential reasoning may be needed to a large extent."}, {"section_title": "Below Level 1: Election results (Item ID: C302BC02)", "text": "Difficulty score: 162 The stimulus consists of a short report of the results of a union election containing several brief paragraphs and a simple table identifying the three candidates in the election and the number of votes they received. The test-taker is asked to identify which candidate received the fewest votes. He or she needs to compare the number of votes that the three candidates received and identify the name of the candidate who received the fewest votes. The word \"votes\" appears in both the question and in the table and nowhere else in the text. B-5"}, {"section_title": "Numeracy task descriptions", "text": "Level 5 (376 -500) Tasks at this level require the respondent to understand complex representations and abstract and formal mathematical and statistical ideas, possibly embedded in complex texts. Respondents may have to integrate multiple types of mathematical information where considerable translation or interpretation is required; draw inferences; develop or work with mathematical arguments or models; and justify, evaluate and critically reflect upon solutions or choices."}, {"section_title": "Level 2 (291 -340)", "text": "At this level, tasks typically require the use of both generic and more specific technology applications. For instance, the respondent may have to make use of a novel online form. Some navigation across pages and applications is required to solve the problem. The use of tools (e.g., a sort function) can facilitate the resolution of the problem. The task may involve multiple steps and operators. The goal of the problem may have to be defined by the respondent, though the criteria to be met are explicit. There are higher monitoring demands. Some unexpected outcomes or impasses may appear. The task may require evaluating the relevance of a set of items to discard distractors. Some integration and inferential reasoning may be needed."}, {"section_title": "Level 1 (241 -290)", "text": "At this level, tasks typically require the use of widely available and familiar technology applications, such as e-mail software or a web browser. There is little or no navigation required to access the information or commands required to solve the problem. The problem may be solved regardless of the respondent's awareness and use of specific tools and functions (e.g., a sort function). The tasks involve few steps and a minimal number of operators. At the cognitive level, the respondent can readily infer the goal from the task statement; problem resolution requires the respondent to apply explicit criteria; and there are few monitoring demands (e.g., the respondent does not have to check whether he or she has used the appropriate procedure or made progress towards the solution). Identifying content and operators can be done through simple match. Only simple forms of reasoning, such as assigning items to categories, are required; there is no need to contrast or integrate information."}, {"section_title": "Below Level 1 (0 -240)", "text": "Tasks are based on well-defined problems involving the use of only one function within a generic interface to meet one explicit criterion without any categorical or inferential reasoning, or transforming of information. Few steps are required and no sub-goal has to be generated. As described by PIAAC Technical Standard 4.3.3, a completed case contained at least the following: responses to key background questions, including age, gender, highest level of schooling, and employment status; and a completed Core instrument 1 (i.e., the interviewer asked the respondent all Core questions or the Core instrument was not completed for a literacy-related reason [e.g., because of a language difficulty] or because the respondent was unable to read or write in any of a country's PIAAC official languages); or responses to age and gender for literacy-related nonrespondents to the background questionnaire/ Job Requirements Approach. The overall weighted response rate for the household sample was 67.8 percent. For respondents who did not complete any tasks on any of the literacy scales, no information is available about their performance on the literacy items. Completely omitting these individuals from the analyses would have resulted in unknown biases in estimates of the literacy skills of the national population because refusals cannot be assumed to have occurred randomly. For respondents who answered the background questionnaire but refused to complete the assessment for reasons other than language issues or a mental disability, proficiency values were imputed based on the covariance information from those who completed the survey. The final household reporting sample (combined U.S. 2012 and 2014 sample)-including the literacyrelated nonrespondents to the background questionnaire-consisted of 8,670 respondents. These 8,670 respondents are the 8,490 respondents who completed the background questionnaire, plus the 180 respondents who were unable to complete the background questionnaire for literacy-related reasons. Of the roughly 8,490 respondents who completed the background questionnaire, about 1,450 were unemployed (age 16 to 65), 3,170 were not unemployed (age 16 to 34), 3,130 were not unemployed (age 35 to 65), 10 had unknown employment status (age 16 to 65), and 730 had unknown employment status (age 66 to 74). The sample was subject to unit nonresponse from the screener, background questionnaire, assessment (including reading components), and item nonresponse to background questionnaire items. The screener and background questionnaire stages had unit response rates below 85 percent and thus required an analysis of the potential for nonresponse bias according to NCES statistical standards. 1 For a full description of the Core instrument, see the section on Data Collection. C-3"}, {"section_title": "Nonresponse Bias", "text": "The nonresponse bias analysis of the household sample revealed differences in the characteristics of respondents who participated in the background questionnaire compared with those who refused. In a bivariate unit-level analysis at the background questionnaire stage, estimated percentages for respondents were compared with those for the total eligible sample to identify any potential bias owing to nonresponse. Multivariate analyses were conducted to further explore the potential for nonresponse bias by identifying the domains with the most differential response rates. The three samples (Main Study, National Supplement area sample, and National Supplement list sample) were analyzed separately to inform the separate nonresponse weighting adjustments for each sample. For the Main Study, these analyses revealed that the subgroup with the lowest response rates for the background questionnaire had the following character istics: (1) Hispanic, (2) age 26 and older with no children in the household, and (3) reside outside the Northeastern United States in areas with low levels of linguistic isolation (a low percentage who have some difficulty speaking English) and with unemployment rates exceeding approximately 5 percent. For the National Supplement area sample, the lowest response rates to the background questionnaire were for persons with the following characteristics: (1) age 25 to 34 or older than 55, (2) sampled as not unemployed (age 16 to 34) or older (age 66 to 74), (3) no children in the household, (4) reside in the Northeastern United States in a census tract with an employment rate exceeding approximately 65 percent and in which more than approximately 2 percent of the population is foreign born. For the National Supplement list sample, the subgroup with the lowest background questionnaire response rate corresponded to the following: (1) female with no children in the household, (2) reside in a Metropolitan Statistical Area in the Western or Northeastern United States, and (3) reside in a census tract in which less than approximately 29 percent of the population has a high school education. In general, persons with children in the household were found to be more likely to participate, as were persons in areas with a high percentage of the population below 150 percent of poverty. However, the variables found to be significant in the multivariate analysis-those used to define areas with low response rates-were used in weighting adjustments in an effort to reduce bias."}, {"section_title": "Data Collection", "text": "Whenever possible, interviewers administered the background questionnaire and assessment in a private setting (e.g., home or library). Using the computerized interview and assessment software provided by the PIAAC Consortium, 2 the interviewer read the background questionnaire questions from a laptop and entered all responses directly into the laptop. Skip patterns and follow-up probes for contradictory or out-of-range responses were programmed into the interview software. At the completion of the background questionnaire, the participant was administered the computer-based Core or the paper-andpencil based Core if the participant could not or would not use the computer. Upon the completion and scoring of the Core tasks, the respondent was routed to the computer-based assessment (CBA), the paper-based assessment (PBA) of literacy and numeracy, or the paper-based reading components. The background questionnaire and the assessment took approximately two hours to complete; however, the time varied by the respondent. The number of assessment items also varied based on the respondents' performance on the Core and the adaptive routing implemented in the automated portion of the assessment. abilities of selection were not identical for all respondents. For the household sample, the sampling weights were further adjusted for nonresponse to the screener and background questionnaire, extreme weights were trimmed, and weights for all respondents were calibrated to the U.S. Census Bureau's 2012 American Community Survey population totals for those age 16 to 74. Since literacy-related nonrespondents to the screener, the background questionnaire, and the assessment are similar in proficiency, the weights of the literacy-related nonresponse cases were not adjusted during the screenerlevel nonresponse adjustment. Instead, the background questionnaire weights for the background questionnaire and assessment literacy-related cases were adjusted to account for the literacy-related screener nonrespondents. This adjustment was necessary primarily to allow the literacy-related background questionnaire and assessment nonrespondents to represent the literacy-related screener nonrespondents in the calibration procedure. All population and subpopulation characteristics based on the PIAAC data used sampling weights in their estimation. The statistics presented in this report are estimates of group and subgroup performance based on a sample of respondents, rather than the values that could be calculated if every person in the nation answered every question on the instrument. Therefore, it is important to have measures of the degree of uncertainty of the estimates. Accordingly, in addition to providing estimates of percentages of respondents and their average scale scores, this report provides information about the uncertainty of each statistic in the form of standard errors on the U.S. PIAAC website at http://nces.ed.gov/surveys/piaac/results/summary.aspx. Because the assessment used clustered sampling, conventional formulas for estimating sampling variability (e.g., standard errors) that assume simple random sampling and hence independence of observations would have been inappropriate for this report. For this reason, the PIAAC assessment used a paired jackknife replication approach (sometimes referred to as JK2) to estimate standard errors (Rust and Rao 1996)."}, {"section_title": "Changes in Population Totals from 2012 Main Study", "text": "For the 2012 data collection, weights for all respondents were calibrated to the U.S. Census Bureau's 2010 American Community Survey population totals for those age 16 to 65. The 2010 American Community Survey population totals were derived from 2000 U.S. Census projections because the full 2010 U.S. Census population results were not yet available. Once the 2010 U.S. Census population results were finalized, the U.S. Census refreshed its entire time series of estimates going back to the previous census each year using the most current data and methodology. One result of this refresh is a shift in the proportion of the population with more education. A comparison of the population totals used to calibrate the 2012 Main Study data with those used to calibrate the composite 2012 and 2014 data reveals that the percentage of the U.S. population age 16 to 65 with college experience (some college or a college degree) increased by 3 to 4 percent and the percentage of the population age 16 to 65 with less than a high school diploma decreased 4 percent. This change has no effect on PIAAC's measurement of skills in the United States, but it does mean that the proportions of the population with higher skills have been found to be larger than previously estimated for the 2012 Main Study."}, {"section_title": "Scaling", "text": "Information on scaling in the PIAAC assessment can be found on the OECD PIAAC website at http://www.oecd.org/site/piaac/."}, {"section_title": "Statistical Testing", "text": "The statistical comparisons in this report were based on the t statistic. Statistical significance was determined by calculating a t value for the difference between a pair of means or proportions, and comparing this value with published tables of values at a certain level of significance, called the alpha level. The alpha level is an a priori statement of the probability of inferring that a difference exists when, in fact, it does not. Findings from t-tests are reported based on a statistical significance (or alpha level) set at .05, without adjustments for multiple comparisons."}]