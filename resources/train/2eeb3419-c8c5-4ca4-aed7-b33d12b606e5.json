[{"section_title": "Introduction", "text": "The Federal government has recently taken a central role in promulgating standards-based education reform through the No Child Left Behind (NCLB) Act of 2001. In particular, NCLB has introduced explicit requirements for student testing as well as consequences for schools that fail to make \"adequate yearly progress\" towards specific achievement goals. The implementation of this landmark legislation continues to unfold at the state level as the 2013-14 deadline for raising all students to academic proficiency approaches (Olson 2005). A question of particular interest about these ongoing standards-based reforms is whether they will be able to close the achievement gaps that contribute to the persistence of poverty and economic inequality. However, many states have long-standing experiences with standards-based reform. In particular, the so-called \"first wave\" of education reform began approximately 30 years ago as several states began to introduce standardized tests that students were required to pass in order to graduate. In addition to these \"exit exams,\" a second, distinguishing feature of the first-wave reforms was the introduction of state-level requirements that students pass an explicit number of core academic courses in order to graduate. The adoption of state-level \"course graduation requirements\" accelerated in the 1980s after they were a featured recommendation in the influential report, \"A Nation at Risk\" (National Commission on Excellence in Education 1983). Nearly all states now have explicit requirements for how many core academic courses that high school graduates must complete. And, currently, twenty states require high school graduates to pass an exit exam. Seven other states plan to introduce such requirements within the next seven years (Sullivan et al. 2005). Furthermore, in several of the states with long-standing graduation requirements, the required exit exam has evolved from \"minimum competency tests\" that require relatively modest skills to more rigorous tests linked to state academic standards. However, these pervasive reforms have been the subject of little rigorous empirical scrutiny. The literature that is available provides contradictory evidence on the fundamental consequences of these state initiatives. In this study, we present new empirical evidence on how these state reforms -exit exams, in particular -influenced educational attainment and early labor market experiences. This study makes three broad contributions to the extant literature. One involves the analysis of more recent data sets (i.e., data from the 2000 Census and the NCES' Common Core of Data) and state policy changes. A second contribution is the use of research designs that are robust to potential confounding factors and that allow us to synthesize our findings with the prior literature. Third, we directly examine how the effects of these policies may have varied by race, gender, and ethnicity and assess what these findings suggest about the effects of first-wave reforms on children in poverty. This study is organized as follows. Section 2 provides background on the first-wave reforms and discusses the prior literature. Section 3 presents new evaluation results based on data from the 2000 Census. Section 4 presents complementary evidence based on dropout data from the Common Core of Data (CCD). Section 5 concludes with a discussion of what these results suggest about the effects of ongoing standards-based reforms."}, {"section_title": "\"First Wave\" Education Reforms", "text": ""}, {"section_title": "Conceptual Framework", "text": "In the 1970s, there was a growing perception that the quality of public schools was in decline and that the high school diploma, in particular, was no longer a meaningful credential that vouched for a student's skills and motivation (e.g., Popham 1981). These concerns were often voiced most prominently by local business leaders concerned with the quality of the entering workforce. Nearly every state responded to these concerns by instituting testing programs designed to assess students' basic skills (Pipho 1978). The intent of most of these new testing programs was to identify low-performing students and provide them with sources of remediation. However, a number of states also began to require that students pass a performance threshold in order to graduate. 1 These exit exams (EE), particularly in their earliest incarnations, typically required that students demonstrate math and reading skills at only an 8 th or 9 th grade level. Furthermore, students often began taking these exams as early as 8 th or 9 th grade and were typically given multiple re-testing opportunities so that they could graduate. Nonetheless, the failure rates on these exams often proved politically unacceptable and states would sometimes lower their cut scores or adjust their exemptions in response (e.g., Catterall 1989). In addition to these test-based standards, states also began introducing a particular type of \"process\" standard over this period: requirements that high school graduates complete explicit numbers of courses, particularly in core academic areas. These reforms accelerated after \"A Nation at Risk\" decried \"cafeteria-style\" curricula and recommended that the adoption of a \"New Basics\" curriculum that included 4 years of English and 3 years of social studies, science, and mathematics. Only a few states adopted the \"New Basics\" requirements but virtually every state introduced or increased its course graduation requirements (CGR) over the last three decades. The public discourse that accompanied the adoption of these policies focused on encouraging the academic effort of students and reinvigorating the high school diploma as a meaningful education credential. However, these reforms could conceivably influence student outcomes in several distinct and sometimes contradictory ways. For example, the most obvious potential consequence of exit exams is to elicit increased academic effort from students. The potential education benefits of exit exams could also extend beyond the marginal student from whom they might encourage additional effort. In particular, Bishop (1999) discusses how the higher and external standards implied by exit exams might limit the \"nerd harassment\" and peer pressure that encourages high-ability students to shirk educational effort. However, the introduction of exit exams could also have unintended, pejorative consequences for the effort and achievement of particular students. For example, the existence of a testing requirement could retard the academic engagement of very low-performing students who see little chance of passing the exam. A related concern, based on the phenomenon known as \"stereotype threat\" (Steele 1997(Steele , 1998, suggests that exit exams could exacerbate minority achievement gaps. Stereotype threat occurs when a student perceives that they will be viewed through the lens of a negative stereotype (e.g., a minority student taking a standardized test). Experimental evidence indicates that stereotype threat can occur in testing environments and that it can lower academic engagement and achievement. It has also been suggested (e.g., Philips and Chin 2001) that standards like exit exams could reduce performance among high-achieving students by prominently signaling relatively low public expectations. In fact, the authors of \"A Nation at Risk\" voiced this concern, suggesting that minimum competency tests would become maximum standards and lower the expectations for high-ability students. Another conjectured benefit of exit exams is that their high-stakes consequences will promote student achievement by improving the performance of schools and teachers. For example, the \"effective schools\" literature has identified several characteristics associated with successful schools. These critical traits include clearly defined objectives, a common mission, continuous monitoring of student performance, and appropriate remediation for under-achieving students (Purkey & Smith, 1983;Purkey & Smith, 1985;Stringfield & Teddlie, 1988). This literature suggests that the introduction of exit exams could make schools more effective through establishing clear objectives and providing student-specific assessments. Exit exams may also encourage (and facilitate) the targeting of remediation efforts to the neediest students and in a manner that reduces minority achievement gaps. On the other hand, exit exams could also harm school and teacher performance. For example, high-stakes exit exams could lead to the use of more narrow teaching styles and curricula (i.e., \"teaching to the test\") that are less effective at fostering intellectual engagement and higher-order critical skills (Murnane and Levy 2001, Airasian 1987, Koretz and Barron 1998, Jacob 2005. Indeed, there is strong evidence that high-stakes educational accountability policies lead to strategic placement of low-achieving students into special education or bilingual programs to avoid testing (Jacob 2005, Figlio and Getzler 2002, Cullen and Reback 2006. Of course, provisions of NCLB that require nearly all students to take the exams is intended to mitigate this concern. However, there is even evidence that accountability may lead teachers and administrators to manipulate student exam scores in order to falsely improve student performance (Jacob and Levitt 2003). As noted above, one of the key motivations for the first-wave education reforms was to ensure that a high school diploma was a signal that a student had mastered important skills. This suggests that the other potentially important consequences of exit exams involve their effects on employer perceptions. More specifically, exit exams may have changed the signaling value of a high school diploma by changing the composition of workers at different education levels. Proponents generally argue that stricter graduation requirements will increase the benefit of a high school diploma because employers will know that high school graduates have mastered certain skills. What is less often realized, however, is that the introduction of stricter graduation requirements may also enhance the \"signal\" conveyed by not completing high school. Consider the simplest case in which case the new standards have no incentive effects, and merely reduce the fraction of those able to obtain a diploma. In this case, the average ability level of the graduate group will increase because the lowest-achieving students who received diplomas under the old standard no longer receive diplomas under the new-standard. However, the average ability level among dropouts will also increase because the students who were pushed into the dropout group under the new standard are higher-achieving than those who were already in the dropout group under the old standard. The \"sorting\" induced by the new requirements will therefore improve the labor market outcomes for both dropouts and graduates (Betts and Costrell 2001)."}, {"section_title": "Prior Literature", "text": "The prior discussion indicates that the likely effects of the first-wave standards on student outcomes should be viewed as an open, empirical question. However, despite the prominence of standards-based reforms, these long-standing state-level experiments have actually been the subject of relatively little empirical scrutiny. The evidence that does exist is generally mixed and unsatisfactory. This is largely due to two issues: the lack of consistent and reliable data on outcomes such as achievement or educational attainment, and the difficulty of differentiating between effects due to the exit exams and effects due to other related policies or conditions in the state at the time. In this subsection, we review several recent studies, highlighting the two difficulties described above. 2 Several studies conducted a cross-sectional analysis of educational attainment and labor market performance using nationally representative data sets such as High School and Beyond (HS&B) and the National Educational Longitudinal Survey (NELS88). In a cross-sectional analysis of NELS88, Jacob (2001) finds that exit exams only increase dropout probabilities for low-ability students. Bishop and Mane (2001) find similar results with the NELS88 -namely, course graduation requirements reduced the probability of graduating high school and state exit exams increased dropout rates for students with below-average grades, but increased GEDs and time in high school on average. Lillard and DeCicca (2001) present evidence that course graduation requirements, but not state exit exams, increase dropout rates. This analysis is based both on state-year panel data and individual-level data from HS&B and NELS88, although the exit-exam effect is based exclusively on cross-sectional comparisons and does not separately examine lower-achieving students. Using a later wave of data from NELS88, Warren and Edwards (2005) find that high school examination requirements are not associated with increased chances of leaving school without a diploma or GED, even among low-SES and low-achieving students. A significant limitation of these studies is that they have a limited ability to control for state-specific factors that may be correlated with student outcomes as well as the adoption of EEs or CGRs. For example, one might be concerned that states adopt stricter graduation requirements in response to a decline in student performance, in which case cross-sectional estimates of EE or CGR would likely be biased toward finding negative policy effects. While the papers cited above attempt to control for state-specific factors such as employment rates, per pupil expenditures and other things that might influence student outcomes, one might still be concerned about the type of trend described above, or some other unobservable state factor. Moreover, analyses based on NELS88 cannot provide information on cohorts other than those expected to graduate in 1992. Dee (2003) uses data from the 1990 Census Public-Use Microdata Sample (PUMS) to address several of these concerns. The PUMS is a five percent sample from the Census that includes a variety of information on individuals including age, race, gender, state-of-birth, highest grade completed, employment and earnings. Using age and state-of-birth (which serves as a proxy for the state in which the one attended secondary school), Dee determines whether individuals would have been subject to CGRs or EEs as adolescents. He then employs a difference-in-difference strategy that involves comparing the outcomes of individuals within the same state who experienced different policies due to their age and the timing of when the policies were introduced. By controlling for fixed effects for state-of-birth, he is able to control for any time-invariant state characteristics that might be correlated with policy adoption and student outcomes. Dee (2003) finds that EEs reduced the probability of completing high school, but only for black males. However, he also found that exit exams created passive labor market rewards for black males in the form of increased employment in their twenties, an outcome consistent with the hypothesis that these testing regimes changed the signals associated with dropping out and graduating. 3 Finally, several recent studies have utilized state-level data on enrollment and completion rates to examine this issue. The studies find mixed results. Amrein and Berliner (2002) find that 3 Dee (2003) considers part-time as well as full-time employment, and (in some specifications) includes controls for whether the respondent was enrolled in school (presumably college) at the time of the interview. At the time of the interview, all respondents would have been at least 20 years of age. Moreover, he finds that exit exams have no impact on the likelihood that Black males enroll in college. Together, these facts suggest that the employment effects are not driven by the fact that high school dropouts are more likely to be employed than enrolled students. While these results are consistent with a scenario in which the implementation of an EE changes the composition of dropouts and graduates, the findings are also consistent with a scenario in which the implementation of the exam changed the actual skills acquired by students (dropouts as well as graduates). However, Dee (2003) also found that exit exams were associated with reductions in core academic course taking. EEs increase dropout rates; Carnoy and Loeb (2002), Green and Winters (2004), , and Marchant and Paulson (2005) find no effect on completion rates. As outlined in  and , this recent work has several serious methodological shortcomings: information about EEs is often inaccurate; the state-level completion rate measures have important flaws; and many of these studies fail to account for unobserved heterogeneity across states. A recent study by  addresses these measurement and specification issues. More specifically, the authors utilize state-level panel data on high school completion rates from 1975 to 2002, and examine three dependent variables: (1) a status dropout measure that treats high school diplomas and GED certificates as equivalent. This measure is derived from CPS data on 16-19 year olds not enrolled in school & without a diploma or GED; (2) a high school completion measure that uses data from the Common Core of Data (CCD). This measure is defined as the ratio of the number of high school completers (which is available for each state and year over many years) to the number of ninth graders enrolled three academic years earlier, after adjusting for interstate migration; and (3) the percent of 16-19 year olds in a state who take the GED. They find that exit exams are associated with lower completion rates and higher rates of GED test-taking, and that these relationships are stronger in states with more difficult exams, higher poverty levels, and more racial-ethnic minorities. The authors note that CPS-based state-level high school dropout rates have substantial limitations, but choose to report results on this measure for comparison with prior research. Warren et al.'s (2005) preferred measure is their estimated high school completion rate. An analysis by  suggests that this measure is not biased by interstate migration, grade retention or changes in the size of incoming high school cohorts. However, they note that this measure is modestly biased by international migration and student retention in the 8 th grade. From the perspective of evaluating the effects of exit exams, this study has two more substantive shortcomings. One is that the aggregate state-year completion rates make it more difficult to examine the important question of how the effects of exit exams may have varied by race, gender, and ethnicity. Second, this study does not address the issue of whether exit exams have had their conjectured effects on subsequent labor market outcomes. A recent study by Martorell (2004) applies a novel research design to the dropout question. The author examines the impact of the exit exam in Texas utilizing a regression discontinuity design in which he compares students who barely pass and barely fail the test. He finds two particularly interesting results. First, he finds no evidence of a discouragement effect. That is, students who barely fail the exam in 10 th or 11 th grade are no more likely to drop out than students who barely pass the exam in these grades. Second, the exam does ultimately reduce the likelihood of graduation. Students who barely fail the final exam have significantly lower chances of holding either a diploma or a GED, and are less likely to attend post-secondary schooling, than those who barely pass. The author estimates that roughly one percent of Texas students do not graduate because they cannot pass the test, which implies a relative effect of roughly 5 percent (relative to the mean dropout rate). 4 The most recent studies of high school exit exams provide mixed evidence on the basic question of whether they increased the likelihood of dropping out of high school. This study contributes to this literature in several distinct ways: (1) We use the most recently available data, which allows us to assess whether the more recent (and generally more rigorous) exit exams uniquely influenced educational attainment; (2) Unlike several of the prior studies, we also focus on the important question of whether these reforms had unique effects by race, gender or ethnicity; (3) Our study examines the effects of exit exams on subsequent labor market outcomes, not just educational attainment."}, {"section_title": "Evidence from the 2000 Census", "text": "In this section, we present new evidence on the impact of EEs and CGRs using data from the 2000 Census Public Use Microdata Sample (2000 PUMS). The PUMS data offers several other advantages relative to the CPS and CCD data used in the analyses described above. First, the large number of respondents in the PUMS allows one to precisely identify very small policy effect, and a better ability to detect race-specific responses to educational policies. Second, the background information on race and gender allows one to examine the impact of educational policies across important demographic subpopulations. Third, the self-reported data on educational attainment avoids some of the problems associated with the high school completion measures used by  and others. Also, because PUMS respondents report attainment as of 1999, for most birth cohorts the data will allow an individual who takes longer than four years to finish high school to be counted as completing. Finally, the PUMS provides information on other interesting and important outcomes such as college attendance, employment and earnings. On the other hand, the PUMS has several important limitations. First, because of interstate mobility, state-of-birth is an imperfect proxy for the state in which a child attended secondary school. This measurement error will tend to attenuate the effects of the state-level education policy variables such as EE and CGR. Second, respondents may systematically misreport educational attainment or employment. If this misreporting is (conditionally) random with respect to relevant characteristics, it will simply increase the residual variation in our models, and thus decrease the precision of our estimates. On the other hand, if an individual's tendency to misreport his or her educational attainment is correlated with the existence of an EE or CGR, the misreporting may introduce bias into our estimates. A third and related problem is that the PUMS questionnaire does not distinguish between conventional high school graduates and GED completers. In light of the possibility that EEs encourage students to drop out but also complete a GED (e.g., , this Census coding convention implies that our results will understate the true policy-induced reductions in the likelihood of graduating from high school."}, {"section_title": "Data", "text": "The 2000 PUMS consists of approximately 14 million respondents (5 percent of the population) who completed the long form questionnaire to the decennial Census (U.S. Bureau of the Census 2003). The PUMS includes a host of information on respondents, including age, race, gender, state-of-birth, current state-of-residence, educational attainment and labor market performance. One particularly useful feature of the PUMS is that, because it contains individuals from multiple birth cohorts within each state, one can exploit within-state variation in EE and CGR instead of the cross-state variation to estimate the effects of these policies. Our extract from the PUMS data consists of the 2,925,005 white (non-Hispanic), Hispanic and Black respondents who were aged 18 between 1980 and 1998 and born in one of forty-nine states (Ruggles et al. 1997). 5 Two of the outcome variables defined for each respondent identify educational attainment, a binary indicator for high school graduation and another for college entrance. 6 We limited the sample to those who were at least 18 by 1998 because of the biases that could be generated by state-specific trends in the \"incomplete spells\" of high school completion and college entrance among cohorts that were younger at the time of the Census interview (Angrist and Evans 1999). The other dependent variables reflect the labor market experiences of each PUMS respondent. One is a binary indicator for employment participation, which is defined for all respondents. 7 The other is the natural log of average weekly wages, which is only defined for 2,429,250 respondents. This wage variable is the ratio of pre-tax wage and salary income reported for the previous calendar year and the corresponding number of weeks worked. Using the respondents' birth year and state-of-birth, we determine whether each individual was subject to an EE or CGR. Specifically, we assign each respondent the EE and CGR policies that applied to the high school graduating class in his or her state of birth when the respondent was 18 years old. For example, a 27-year-old respondent born in Virginia would have been 18 years old in 1991, and thus assigned the policies in place for the graduating class of 1991 in Virginia. Table A1 presents data on EE by state and year. Here year refers to a graduating class rather than a calendar year. For example, when we say that Virginia had an EE in 2000, we mean that the high school graduating class of 2000 in Virginia was subject to the exam. 6 College entrants are those whose highest reported educational attainment was \"Some college, no degree\" or higher. It should be noted that this sample, of course, includes students who attended private schools. However, their inclusion is arguably appropriate since it is possible that students may switch schools to avoid the consequences of stricter standards. 7 Those who report that they are not in the labor force are defined as unemployed to avoid omitting discouraged workers. However, the exclusion of these respondents does not substantively alter the subsequent results. Following , we distinguish between more and less difficult exit exams based on the difficulty of the material included in the exam. Specifically, if any component of a state EE assessed material that was first presented during the high school years (i.e., in ninth grader or later), the EE is referred to as a more difficult exam. Information on the grade level of the material assessed in an EE was gathered from a variety of sources, including official reports published by state departments of education as well as newspaper accounts of the EE. 8 Note that this definition has several shortcomings. Because districts may introduce material at different grade levels, it is difficult to determine whether this measure is comparable across states. In addition, states can alter the difficulty of an exam by adjusting the required passing score, so that it is possible that an exam containing \"less difficult\" material may actually be more difficult to pass relative to an exam covering more difficult material. The second dummy identifies whether the state had a high, academically focused CGR in effect for that graduating class. A \"high\" CGR is defined here as a required high school curriculum that includes at least 3 Carnegie units in English, 2 in social studies, 1 in science and 1 in mathematics. 9 A \"very high\" CGR is defined here as a curriculum that requires the following: 4 Carnegie units in English, 3 in social studies, 2 in math and 2 in science. Table 1 presents summary statistics for our sample. Roughly 87 percent of respondents graduated high school and 57 percent attended at least some college. About 14 percent of the sample is Black and 3 percent is Hispanic. 10 Over 75 percent of respondents were employed at the time of the survey. Approximately 32 percent of state-year observations have an EE, but only 5 percent have a more difficult EE. Rigorous CGR are more common, with 75 percent of state-years requiring at least 3 units of English, 2 units of social studies and 1 unit of math and science and 25 percent requiring 4, 3, 2 and 2 or more."}, {"section_title": "Empirical Strategy", "text": "The basic specification used for regression models based on these data is: ( where ist Y is the dependent variable for respondent i in state-of-birth s and birth cohort t, and the matrix X includes observed, individual-level traits. In most models, the individual covariates simply include binary indicators for race and gender. In the models for labor market outcomes, we also estimate models that control for measures of educational attainment (i.e., separate dummy variables for high school graduates, those with some college and those with bachelor degrees) and a dummy variable for whether the respondent attended school within the last year. 11 We discuss the estimates from the reduced form as well as the more complete models in the next section. The terms s u and t \u03b1 represent fixed effects specific to each state of birth and year of birth. The term\u03b5 is a mean-zero random error. We report Huber-White heteroscedasticconsistent standard errors, which allow for arbitrary correlation of errors within each state-of- 10 The proportion of Hispanics is lower than the national average since we exclude all respondents who were foreign-born. 11 The school attendance variable is meant to control for the fact that those respondents still in school over the last year would have had limited labor market experiences. This specification is similar to those used by Bishop and Mane (2001). birth (Bertrand et al. 2004). For specifications with dichotomous outcome variables, we estimate Probit models; for other specifications, we estimate OLS models. The matrix Z includes determinants that were specific to the birth cohorts within each state. These determinants include the two independent variables of interest: dummy variables that reflect the state EE and CGR policies in place for each birth cohort at age 18. These and other state-year controls were matched to the respondents by their state-of-birth and year-ofbirth. As noted earlier, the measurement error introduced by relying on state-of-birth will lead to attenuation bias in these state-level variables, suggesting that the reported estimates can be interpreted as lower bounds on the true effects. 12 As suggested earlier, the identification strategy embedded in this model makes a potentially important contribution to our understanding of the consequences of EE and CGR because it removes the possible biases due to unobserved time-invariant state-level determinants of educational attainment and labor market performance. The inclusion of state fixed effects means that we are effectively comparing the differences among cohorts in the \"treatment\" states before and after the introduction of new standards to the contemporaneous cross-cohort changes in the \"control\" states. We present some evidence on the empirical relevance of relying on within-state versus cross-state comparisons by comparing the results of models that do and do not include the state fixed effects. As a further, ad-hoc check on the validity of this specification, in some models we include an additional predictor variable -namely, the number of state executions that took place in a respondent's state-of-birth when the respondent was 18 years of age as a predictor (e.g., Dee 2003). Insofar as one believes that state executions should not have had a large and statistically significant effect on educational attainment, for example, the finding of such effects would suggest the presence of specification error. One virtue of using state executions for this type of \"falsification exercise\" is that there was considerable variation over this period both within states and across states in the number of state executions. In the preferred specifications, which include state fixed effects, the Therefore, we also include a measure of cohort size based on the natural log of the U.S. Census Bureau's estimate of 18 year-olds in the respondent's state of birth at age 18. We also include a measure of the real costs of postsecondary tuition based on the in-state rate at \"lower-level\" state colleges and universities when the respondent was 17 years old (Card andLemieux 2001, Kane 1994). 14 As a control for within-state changes in socioeconomic priors, we also matched each respondent to the poverty rate in their state when they were 17 years old. Finally, we include one additional measure of related educational accountability policies in the state at the time the respondent was 18 years of age: a binary variable indicating whether the state issued report cards for individual schools. Table 2 shows the marginal effects evaluated at the mean derived from Probit models predicting the likelihood of graduating high school."}, {"section_title": "Results", "text": "Column 1 presents what might be described as the baseline specification, which includes individual demographics (i.e., indicators for Black and female) along with state and year fixed effects. There is no significant relationship between the likelihood of dropping out and the existence of either an EE or CGR. In column 2, we see that adding controls for time-varying state variables (in column 2) does not change the results. The standard errors on the EE and CGR variables imply that our analysis has the power to detect effects of roughly +/-0.4 percentage points, which translates into roughly 3 percent if one uses average dropout rate of 12.7 percent as a baseline. The specification shown in column 3 includes separate indicators for more and less difficult EEs and CGRs, but does not find effects that are significant at conventional levels. It is also possible that the impact of EE or CGR evolve over time, as students, parents and teachers become more familiar with the new requirements. In results not shown here, we test for an interaction between the existence of a less difficult EE and the number of years it has been required, but do not find any significant results. 15 Column 4 serves as a specification check. In this specification, we include the number of state-year executions in the model as a predictor. Since we do not think that the number of executions could have any causal impact on the contemporaneous high school completion rate, if this variable is a significant predictor, then we might be concerned that we have omitted an important time-varying state characteristic that influences educational outcomes and might bias our estimates. Indeed, we find that the number of state executions is a positively associated with the high school graduation rate, which raises concern about our previous specification. In an effort to more completely account for time-varying state characteristics that might confound our analysis, in column 5 we include a series of division-specific time trends. Specifically, we interact a cubic term in the year since 1979 with indicators for each of the nine different census divisions, for a total of 27 additional covariates. These covariates control for any factors that may have been changing over time in different parts of the country, including such things such as economic conditions we do not pick up with the unemployment rate, social norms or public policies that pertain to educational attainment, or other factors. In column 5, we see that once we control for these time trends, the coefficient on state executions drops dramatically and is no longer significant. Turning to the estimates of the education policy variables in column 5, we see that both more and less difficult exams are negatively associated with the likelihood that a student completes high school. Specifically, the easier EEs are associated with a 0.5 percentage point reduction in the likelihood of completion, which translates into a 4 percent increase in the probability of dropping out. More difficult exit exams are associated with a 0.7 percentage point or 5.5 percent increase in the probability of dropping out. In contrast, neither the moderately nor the very rigorous CGRs appear to be associated with changes in high school completion. Table 3 shows the results for high school completion separately by race and gender. The specification includes division-specific time trends, and thus is comparable to column 5 in Table   2, with the exception that the models are estimated separately by race and gender which allows all of the coefficients to vary across groups (i.e., a completely unrestricted model). As discussed above, one would expect more rigorous graduation requirements to have a larger negative impact on lower-achieving students, which we proxy for with race and ethnicity. Consistent with this hypothesis, we find that EEs reduce the likelihood of high school completion for Black students by twice as much as they do for white students. It is also possible that schools with predominantly Hispanic populations were more effective in responding to the policies. As discussed above, the expected effect of EE and CGR on college attendance is unclear. On the one hand, if some of the students prevented from graduating high school because of the requirements would have attended college, we would expect the policies to reduce attendance. On the other hand, if the requirements lead other students to be better prepared for college (or to believe that they are better prepared for college), then one would expect the policies to increase postsecondary enrollment. In practice, it seems likely that one would expect to find a negative relationship at the very bottom of the ability distribution, but perhaps find a somewhat positive relationship at somewhat higher points on the ability distribution. In general, however, it seems unlikely that we would expect to find any effect among moderately or high ability students, for whom the requirements were probably not a binding constraint. The results for postsecondary enrollment shown in Table 4 suggest that EEs do not have a significant influence on college attendance. One notable exception is for Hispanic females who faced a more difficult EE. These students were considerably more likely to enroll in college than their counterparts who did not face a difficult EE. The evidence presented thus far is largely consistent with the concerns sometimes raised by critics of standards-based reforms -namely, higher requirements may reduce educational attainment among disadvantaged groups. Moreover, the findings shown in Tables 2-4 are consistent with our earlier work (Jacob 2001, Dee 2003. As noted earlier, however, a full evaluation of these policies should consider the impact of more rigorous graduation standards on labor market performance. An examination of the labor market effects is also interesting insofar as business leaders frequently express concern with the quality of their work force, and were often instrumental in the adoption of the EEs and CGRs. Indeed, higher standards may benefit students by inducing greater effort in high school, which is later rewarded in the labor market. They may also influence the relative returns of a high school degree by changing the signal associated with the diploma, although, as discussed above, it is not clear whether this will improve the earnings of high school graduates relative to dropouts since student sorting alone would suggest higher standards would raise the ability level of both graduates and dropouts. \nInterestingly, the results in Table 8 are quite similar across specifications that condition on the fixed-effects interactions. And these interactions have considerable explanatory power, increasing the R 2 by approximately 50 percent. However, the results reported in Table 9 explore the robustness of these findings further by examining specifications based only on the dropout rates from more similar (i.e., closer) grades. The corresponding reductions in sample size implied by this check reduce the precision of the estimates. However, the estimates themselves are generally quite similar across these different samples. These results suggest that year effects unique to particular grades are not a source of confounding biases in these evaluations. The remaining results, which are based on the data from all four grades, examine how the grade-specific effects of the BST requirement varied by a variety of observable district traits. The results in the first panel of Table 10 are based on dividing the observed school districts into quartiles based on their pre-reform position in the distribution of the percent of students who were black or Hispanic. It should be noted that, there are relatively few minority students in Minnesota (i.e., roughly 5 percent of students were black and 2 percent Hispanic), even in the districts in the top quartile of this distribution. Therefore, these estimates should be understood as identifying the effect for the average student in these districts rather than the effect for a minority student per se. 30 Nonetheless, the results in Table 10 suggest that the dropout effects of the BST requirement differed noticeably across these districts. For example, in the districts with higher concentrations of minorities, the BST led to particularly large increases in the 12 th grade dropout 30 Because the PUMS analysis suggested that the effects of exit exams differed for black and Hispanic students, we also considered more disaggregated measures of minority students. However, the results based on these data were quite similar. Among other things, this could reflect that the Hispanics observed in the CCD files include both native and foreign-born students. rate (e.g., 0.69 to 0.92 percentage points). However, these results also indicate that the BST led to relatively large reductions in the grade 10 and 11 dropout rates. 31 Interestingly, the BST requirement had small and statistically insignificant effects in the districts with the lowest concentration of minority students. The results in the next panel are based on dividing districts into quartiles based on their 1995 position in the state distribution of the percent of children in poverty. The results based on the high-poverty districts tend to be statistically imprecise. However, the point estimate for the 12 th grade dropout effect is approximately twice as large as that based on the full sample. Interestingly, these results indicate that the reductions in 10 th and 11 th grade dropout rates were concentrated in the lower-poverty districts. In fact, in the lowest-poverty districts, the BST requirement was also associated with reductions in the 12 th grade dropout rate. The next specification attempts to refine these comparisons by focusing on the observations from districts in the top halves of the state distributions of percent minority students and percent of children in poverty. These results suggest that the BST led to increased dropout rates across all four grades with a particularly large and statistically significant effect on the 12 th grade dropout rate. The final set of results in Table 10 examines the unique effects associated with a district's urbanicity. Interestingly, the BST requirement led to a particularly large increase in the 12 th grade dropout rate in urban districts (i.e., over 3 percentage points) and, to a lesser extent, in rural districts. In contrast, the beneficial effects of the BST requirements (i.e., reductions in 10 th and 11 th grade dropout rates) were largely concentrated in suburban school districts. In sum, the evidence from Minnesota's experience with exit exams is consistent with several of the claims made by both proponents and critics of these policies. For example, these results indicate that the BST requirement was actually associated with reductions in the dropout rates for earlier high school grades. This result is consistent with the hypothesis that Minnesota's exit exam improved student effort and/or school performance. Mapping these results into an implied change in the high school graduation rate is not straightforward, in part because these data are based on \"event\" dropouts who may later reenroll. However, assuming that event dropouts do not return to school and using the pre-reform dropout rates as a base, the full-sample results (i.e., reductions in the dropout rate in grades 9-11 and an increase in grade 12) imply that the overall high school graduation rate increased by approximately one half of a percentage point (i.e., a increase of approximately 0.5 percent given an implied graduate rate of 89.2 percent). However, critics of exit exams would not be surprised to find that these improvements were concentrated in lower-poverty and suburban districts. In contrast, the increased dropout rates were found in urban districts and those with higher shares of minority students and children in poverty. In fact, calculations based on these point estimates indicate that the implied changes in the high school graduation rates for these districts were consistently negative. For example, in urban districts during the 1993-1995 period, the implied high school graduation rate was 75.1 percent. The results in Table 10 imply that this rate fell to 72.7 percent as a result of the BST requirement, a decrease of approximately 3.2 percent."}, {"section_title": "Evidence from the Common Core of Data (CCD)", "text": "The evaluation results based on the 2000 Census indicate that exit exams, particularly the most difficult ones, reduced the probability of completing high school among white males and black students. However, there are a number of reasons to be concerned that these estimates may understate the true effects of exit exams on the probability of completing high school. For example, the use of state-of-birth to match PUMS respondents to their state exit-exam requirement could introduce measurement error. To the extent this measurement error promotes attenuation bias, the true effect of exit exams on educational attainment would be understated. A second issue that would also lead our results to understate the true effect of exit exams on the probability of completing high school is that the PUMS survey did not distinguish high school completers from GED completers. 16 A third issue is that, because the PUMS data provide \"status\" data on educational attainment (i.e., the total share meeting a definition at a given point in time), they do not identify precisely when exit exams may have increased the probability of dropping out. In other words, this evidence does not identify whether most students dropped out after failing their initial attempts (i.e., early in high school) or persisted with re-tests through 12 th grade. The design of improved remediation for the dropout risk ostensibly created by exit exams could benefit from evidence of such grade-by-grade risks. A fourth and more general concern is that the empirical evidence based on an alternative identification strategy would provide useful evidence on the robustness of the Census results. This section addresses several of these concerns by presenting different evidence on whether (and when) exit exams increased the probability of dropping out of high school. This analysis is based on unique, district-level dropout data that the National Center for Education Statistics (NCES) began collecting in the early 1990s through the Common Core of Data (CCD). 17 Generally, the NCES has only reported these data from states that used dropout definitions that conformed to their standard, which is described below. 18 Fortunately, over the last 15 years, the number of states that have chosen to conform to their definition has increased. However, because of the limited overlap between states that have consistently reported these dropout data and states that introduced exit exams over this period, we focus on the experiences within one particular state, Minnesota."}, {"section_title": "Graduation requirements in Minnesota", "text": "In the early 1990s, the Minnesota Legislature and the State Board of Education expressed their intention to develop \"results-oriented\" high school graduation requirements for the state's public school students. As in many other states, the motivation for these requirements came from business and community leaders concerned that students did not have the basic skills necessary for productive employment and responsible citizenship. The subsequent graduation rules required that students pass \"Basic Skills Tests\" (BST) in math, reading, and writing in order to graduate. Passing scores on the math and reading tests were first required of the graduating class of 2000 (i.e., 9 th graders during the 1996-97 school year). The requirement that public high school graduates achieve a passing score on the writing test was delayed until the graduating class of 2001. 19 Another prominent component of Minnesota's new high school graduation requirements was that students demonstrate higher-order understanding through complex and highly controversial, performance-based assessments known as the \"Profile of Learning.\" These standards became effective somewhat later (i.e., beginning with students entering 9 th grade during the 1998-1999 school year). While there is some evidence that the unpopular \"Profile\" influenced classroom practice, its implementation was highly uneven (Avery, Beach, and Coler 2003). After several years of legislative wrangling, the state effectively transferred control over these standards to local school districts. 20 Then, shortly after our study period (i.e., in 2003), the \"Profile\" was abolished entirely. Unsurprisingly, we found that the Profile had no distinct effects on dropout rates separate from those of the BST requirement. Nonetheless, a caveat about our reduced-form results is appropriate because the timing of these policy changes overlapped  -Tribune 1996). And these initial passing rates were substantially lower among minority and low-income students (Smith and Duchesne 1996). 22 However, the ultimate effect of the BST requirement on dropout rates could be attenuated by a number of factors. For example, relative to other states with exit exams, Minnesota provided an unusually high number of re-test opportunities (i.e., eleven). Like most other exit-exam states (Gayler et al. 2004, Table 10), the state also required school districts to develop individualized remediation plans for each student who failed a BST in 8 th or 9 th grade. The state also provided flexibility and testing accommodations for students with disabilities and those who were English language learners (ELL). For example, students with an IEP could have their BST cut scores lowered by their local IEP team. And ELL students who had been enrolled for fewer than three 20 See Avery, Beach, and Coler (2003) for details. 21 However, it should be noted that the grade-specific heterogeneity in our BST results is clearly consistent with exit-exam effects but less plausibly related to the Profile. 22 Interestingly, the gaps in pass rates among white and minority students are larger in Minnesota than in other states (Gayler et al. 2004, page 37). years in a school where the primary instructional language was not English were exempted from the graduation requirements. 23 The BST in math and reading were administered in grades 8 through 12 while the writing test was first taken in grade 10. The first cohort required to pass the BST in math and reading took these exams for the first time as 8 th graders in the spring of 1996. The cohort required to pass the BST in writing took this test for the first time as 10 th graders in the spring of 1999. The implementation of the BST requirements attracted relatively little public notice, especially relative to the more controversial \"Profile of Learning\" standards. One exception occurred in 2000 when scoring errors led to some students being mistakenly told they failed the test, including about 50 seniors who were denied diplomas (Bakst 2000). There were also two incidents of teachers being accused of stealing copies of the high-stakes exams (Associated Press, 2001). Interestingly, during the summer of 2005, which is after our study period, the Minnesota legislature enacted legislation to replace the BST with tests geared to higher level grade content and aligned to state content standards (Sullivan et al. 2005, Table 3)."}, {"section_title": "Common Core of Data (CCD)", "text": "The National Center for Education Statistics (NCES) collaborates annually with state education agencies to organize a variety of data on all public schools and school districts (e.g., staffing, enrollments, and finances) into the Common Core of Data (CCD). The data items collected by the CCD are based on consistent definitions that have been developed by the NCES and state representatives over several decades. Beginning in the early 1990s, the CCD included district and grade-level data on dropouts from a growing number of states (including Minnesota) whose reporting practices conformed to the NCES definitions. The CCD uses an \"event\" dropout definition. More specifically, a student is designated as a dropout for a particular school year if he was enrolled at some time during the school year and met several explicit criteria as of October 1 in the next school year. These criteria are that the student in question was not enrolled, had not graduated or completed an approved educational program (e.g., GED), had not transferred and was not absent due to death or a school-recognized illness or suspension. The CCD reports dropout rates which are based on these dropout data and specific to each district and grade. These rates were constructed by dividing the number of NCES-defined event dropouts for each district and grade by its corresponding enrollment base for that school year. 24 The grade-specific dropout rates in the CCD are not perfect measures. Most notably, it would be preferable to separate GED completers from conventional graduates. Furthermore, a problem with any event measure is that it will not reflect subsequent re-enrollment by a student who drops out except through a change in the enrollment base. However, as noted earlier, these data also have several unique benefits. For example, relative to the PUMS data, individuals attending public schools can be matched without measurement error to their high school graduation requirements. Furthermore, because these dropout rates accommodate both grade retention and student mobility, they are not subject to the concerns that have been the focus of studies using state-year high school completion rates based on adjusted enrollment data (e.g.,"}, {"section_title": "Warren 2005). 25", "text": "Another unique feature of these grade specific dropout rates is that they facilitate a somewhat unusual empirical strategy for identifying the effects of Minnesota's high school graduation requirements on educational attainment. That strategy, which is described below, relies on the fact that within each district and year, we observe the dropout rates in grades, some of which are constrained by Minnesota's exit-exam policies and some of which are not. The unit of observation for this analysis is the dropout rate for each unique district-grade-year observation over the nine school years from 1994-95 to 2001-2002. We applied several edits to the pooled CCD files to create a data set suitable for this analysis. For example, we deleted school districts that were regional service agencies or state or Federal agencies providing services to specialneeds populations as well as districts without students. We also deleted districts that did not serve students in a grade from 9 th through 12 th . We also deleted a small number of observations where the dropout rate was either negative or greater than 100. However, the results presented here are similar when these observations are included with imputed dropout rates of 0 or 100 percent. We also applied an imputation to correct a coding convention used for the Minnesota data for the 1994-95 and the 1996-97 school years. Specifically, in most years, roughly a quarter of the district-by-grade observations for Minnesota had no dropouts. However, for the 1994-1995 and 1996-1997 school years, only one grade-district observation had a dropout rate of zero. Instead districts in these years with positive enrollments had missing or not applicable for dropout rates that should have been zero. We have imputed zero to these observations but checked that the results are similar without this imputation and when data from these two school years are omitted. As noted earlier, an issue of particular interest is whether exit exams have unique effects among high-poverty students or those who are racial or ethnic minorities. To address these issues, we matched the Minnesota school districts to 1995 data on the percent of children in poverty within the district and to 1993-94 data aggregated from the school-level CCD files on the racial and ethnic composition of the district's students. The grade-level dropout data in the CCD are actually defined by race, ethnicity and gender over this period. However, we use district-level data on minority composition because the relevant enrollment bases for the CCD's race and ethnicity-specific dropout data were not collected. Specifically, the school-level CCD only started collecting grade-specific enrollments by race, ethnicity and gender in the 1998-99 school year. Our final, analytical sample omits the observations that could not be matched to these poverty and demographic data. An examination of these observations indicated that they largely consisted of administrative school districts that had been incorrectly flagged in the CCD and school districts, largely charter schools, which had been created during the sample period. 26 The final data set consists of an unbalanced panel of 10,502 grade-level dropout rates for the approximately 350 districts observed in each of nine academic years."}, {"section_title": "Specifications", "text": "Our approach to evaluating the effects of Minnesota's BST requirement on dropout rates exploits the variation generated by the fact that the exit exam was first required of the graduating class of 2000. State exit exams were often first tied to a specific graduating class while the cohort was in 8 th or 9 th grade in order to avoid the perceived unfairness and possible court challenges associated with subjecting those already in high school to a requirement they could not have anticipated. This sort of phased introduction creates potentially useful variation in policy exposure both across grades and within grades over time. For example, the first high school cohort subject to the new exit exam requirements was in 9 th grade during the 1996-97 school year. However, the cohorts in grades 10 through 12 during that year did not have to pass the BST but did share the determinants of dropout rates common to their district and year. In the subsequent school year, the grades constrained by the BST requirement expanded to include both 9 th and 10 th graders, and, by the 1999-2000 school year, the students in all four grades. The shaded areas in Table 8 identify the grade-year observations subject to the BST requirement during the school years for which we have CCD dropout data. The variation in BST exposure ( gdt X ) across grades and within grades over time implies that the effect of this policy ( \u03b2 ) on dropout rates ( gdt y ) can be identified conditional on fixed effects unique to each grade ( g \u00b5 ), district ( d \u03b1 ) and year ( t \u03bb ): (2) . (3) . The standard errors reported for these specifications are clustered at the grade-district level. Clustering at this cross-sectional level leads to the more conservative (i.e., larger) standard errors and is consistent with concerns about the possible influence of serial correlation (Bertrand et al. 2004). 27 27 Specifically, we found that these standard errors were larger than those that were uncorrected and those calculated using the conventional White procedure. We also found basically similar results in WLS specifications when the enrollment base was the weight. However, the WLS estimates did indicate that the 12 th grade dropout rate is larger than that based on OLS. We suspect that this reflects the heterogeneous effects of Minnesota's exit exam by district traits (e.g., in larger urban districts), an issue we examine directly in our analysis. The conditional means in Table 7 illustrate how the dropout rates in Minnesota's public high schools varied across grades and over time while the BST requirement was implemented. Casual \"difference in differences\" comparisons based on these means can illustrate the basic logic of this identification strategy. For example, the dropout rate for 10 th graders fell by 0.13 percentage points (i.e., 5 percent) in the 1997-98 school year, which was when 10 th graders were first subject to the BST requirement. Over that same time period, but in the higher grades not subject to the requirement (grades 11 and 12), the dropout rates increased by at least 0.18 percentage points. These simple comparisons suggest that the BST requirement reduced the 10 th grade dropout rate in Minnesota. OLS estimates based on equations (2) and (3) generalize such basic comparisons. 28 However, they also provide a framework for identifying whether the effects of BST requirements varied by grade. For example, as noted earlier, if these exit exams had a strong discouragement effect, we might expect to find that they led to particularly large increases in the 9 th and 10 th grade dropout rates. Alternatively, these exit exams could increase the dropout rate more substantially among 12 th graders if students remain in school and persist in attempting to pass the BST despite earlier failures. We examine this issue by evaluating the reduced-form effects associated with interactions between a BST dummy variable and grade-specific dummy variables. The basic panel-data research design outlined here (i.e., exploiting the policy variation within grades over time) has not, to our knowledge, been utilized elsewhere. Therefore, this approach may provide a useful complement to more conventional panel-data evaluations like that presented in Section 3. However, like any empirical evaluation, this approach also turns on implicit, maintained assumptions that may not, in fact, be valid. In particular, this approach implicitly assumes that the common shocks to dropout rates in a particular year have a similar effect across all four grades. However, violations of this assumption could reasonably occur and perhaps bias these results. For example, suppose that, during the economic expansion of the late 1990s, the dropout rates of 12 th graders (who were generally not subject to exit exams) grew relative to the contemporaneous dropout rates for the earlier grades (which often were subject to exit exams). This pattern would occur if 12 th graders were particularly likely to leave high school as Minnesota's unemployment rate fell during the late 1990s. Similarly, the later increases in Minnesota's unemployment rate (i.e., during 1999, 2000, and 2001) could have led to particularly large reductions in the dropout rate of 12 th graders, just as 12 th graders were also being required to pass the BST. Under this particular scenario, our reduced-form estimates would have a negative bias because of unrelated year effects unique to a particular grade. While it is not possibly to address these important concerns definitively, we can examine their empirical relevance through selective adjustments to the groups of grades included in our evaluations. For example, the assumption that there are common grade-year shocks is more likely to be valid when comparing only near grades (e.g., just 11 th and 12 th grades). We present evidence on how these sample restrictions influence our results. As an additional approach, we also examined specifications that allowed us to condition on grade-year fixed effects by using contemporaneous dropout data from the neighboring states (i.e., North Dakota and Iowa), which were well represented in the CCD dropout data over this period and did not introduce exit exams. 29 The point estimates from these specifications were basically similar to those described below (i.e., negative effects in earlier grades and a positive effect in the 12 th grade). However, these point estimates were also more imprecise and their values were somewhat sensitive to which of the two control states was included. More disturbingly, we found that the dropout rates in Minnesota had pre-reform trends that differed significantly from Iowa and North Dakota, which suggests that the identifying assumptions for these specifications were not valid. Table 8 presents the basic evaluation results based on the full sample of district-gradeyear observations. The initial specifications (i.e., columns 1 and 2) condition only on grade, year, and district fixed effects. However, the subsequent models (i.e., columns 3 through 8) introduce district-grade and district-year fixed effects. These results indicate that, overall, the introduction of the BST requirement was associated with small and statistically insignificant reductions in the dropout rates. However, these estimates consistently indicate that the assumption of a common BST effect across grades obscures heterogeneous effects across grades. More specifically, these estimates indicate that the introduction of an exit exam reduced the dropout rate in both grades 10 and 11 by approximately 0.3 percentage points (i.e., 9 to 16 percent) but increased the dropout rate in the 12 th grade by a similar amount (i.e., approximately 8 percent). These findings suggest that Minnesota's exit-exam policy improved student and school performance in the earlier high-school grades and did not discourage students from remaining in school. However, these results also indicate that the existence of the BST requirement constrained students who could not pass the exam after repeated attempts. A recent study based on longitudinal data from Texas (Martorell 2005) similarly found that exit exams increased the dropout rate through their effect on students sitting for their \"last chance\" exam."}, {"section_title": "Conclusions", "text": "The notion that high school graduates should meet high academic standards has a universal appeal. The increasing importance of cognitive skills for economic success in recent years adds a sense of urgency to standards-based reforms in high school. However, some doubt whether binding standards can effectively improve student or school performance. There are also concerns about whether standards-based reforms may exacerbate economic inequality by harming the students most at risk of academic failure. This study attempts this broader debate by presenting new evidence on the educational and economic consequences of the earliest, standards-based reform: mandatory exit exams for high school students. Our results, based on data from the 2000 Census, indicate that exit exams led to particularly large increases in the dropout rates of black students. Similarly, our analysis of Minnesota's recent exit exam, based on the NCES' Common Core of Data (CCD), indicates that this graduation requirement increased the dropout rates in school districts with relatively large concentrations of minority students as well as in urban and high-poverty school districts. Furthermore, Minnesota's exit exam also reduced the dropout rates in suburban and low-poverty school districts. Taken at face value, these findings imply that these standards-based reforms have exacerbated both poverty and inequality. However, a number of factors suggest that the implications for poverty reduction of our state-level experiences with exit exams are not quite so straightforward. For example, our analysis of data from the 2000 Census provided some evidence that exit exams improved longerterm outcomes (e.g., college matriculation, labor-market outcomes) for Hispanic females and blacks. These changes could reflect both the signaling and the incentive effects of exit exams. The possible incentive effects of standards-based reform were also suggested by our evidence that exit exams reduced the early high-school dropout rates in some of Minnesota's school districts. These ambiguities suggest a number of possibly fruitful directions for further research. For example, as states continue to both introduce exit exams and simultaneously develop richer, longitudinal data on student achievement, it should become possible to identify how the incentive effects of exit exams may have changed the distribution of cognitive achievement. Second, the evidence that exit exams reduced the dropout rates in some districts (e.g., lowpoverty districts) suggests it would be useful to learn more about the mediating factors that may have facilitated these improvements. Third, it would be useful to develop further evidence on whether exit exams generally encourage students to drop out during 12 th grade and to identify the implications of this pattern for both targeted remediation and reform. Various sources (in effect for the high school graduating class in the respondent's state-of-birth in the year that the respondent was 17 years old; covers material at below 9 th grade level) 0 1 0.317 0.465 1.000 0.000 0.000 0.000"}, {"section_title": "More difficult EE", "text": "Various sources (covers material at 9 th grade level or higher 0 1 0.053 0.224 0.000 0.000 1.000 0.000 Moderately rigorous course graduation requirements (CGR) Various sources (at least 3 English, 2 social studies, 1 math, 1 science) 0  More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science. Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth. State-year controls include the unemployment rate, the natural log of the number of 18 year olds, the poverty rate, the average teacher salary and the average student:teacher ratio, and an indicator for whether the state issued report cards for K-12 schools. The marginal effect evaluated at the mean is shown in each cell. Standard errors shown in parentheses are adjusted to account for clustering of errors within state-of-birth. *=significant at the 10 percent level. **= significant at the 5 percent level. More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science. Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth, a cubic division-specific time trend, and the following state-year controls: the unemployment rate, the natural log of the number of 18 year olds, the poverty rate, the average teacher salary and the average student:teacher ratio, and an indicator for whether the state issued report cards for K-12 schools. The marginal effect evaluated at the mean is shown in each cell. Standard errors shown in parentheses are adjusted to account for clustering of errors within state-of-birth. *=significant at the 10 percent level. **= significant at the 5 percent level. More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science. Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth, a cubic division-specific time trend and the following state-year controls: the unemployment rate, the natural log of the number of 18 year olds, the poverty rate, the average teacher salary and the average student:teacher ratio, and an indicator for whether the state issued report cards for K-12 schools. The marginal effect evaluated at the mean is shown in each cell. Standard errors shown in parentheses are adjusted to account for clustering of errors within state-of-birth. *=significant at the 10 percent level. **= significant at the 5 percent level. More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science. Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth, a cubic division-specific time trend, and the following state-year controls: the unemployment rate, the natural log of the number of 18 year olds, the poverty rate, the average teacher salary and the average student:teacher ratio, and an indicator for whether the state issued report cards for K-12 schools. The marginal effect evaluated at the mean is shown in each cell. Standard errors shown in parentheses are adjusted to account for clustering of errors within state-of-birth. *=significant at the 10 percent level. **= significant at the 5 percent level. The unit of observation is the individual. The data comes from the 2000 PUMS. The sample includes individuals age 20-38 on census day. Residents from Nebraska and the District of Columbia are excluded. Only individuals indicating race as white, Black or Hispanic are included. More difficult exit exams are those in which the tested material is at the ninth grade level or higher. Rigorous course graduation requirements are defined as a requirement that students earn at least 3 Carnegie units in English, 2 in social studies, 1 in math and 1 in science. Very rigorous course graduation requirements are defined as those which require at least 4 units in English, 3 in social studies, 2 in math and 2 in science. All models include individual demographic controls (binary indicators for female and Black), fixed effects for state-of-birth and year-ofbirth, a cubic division-specific time trend, and the following state-year controls: the unemployment rate, the natural log of the number of 18 year olds, the poverty rate, the average teacher salary and the average student:teacher ratio, and an indicator for whether the state issued report cards for K-12 schools. Standard errors shown in parentheses are adjusted to account for clustering of errors within state-of-birth. *=significant at the 10 percent level. **= significant at the 5 percent level. The unit of observation is the grade (9-12) within a school district in a given school year (n = 10,502). The sources of these data are the annual Common Core of Data (CCD) universe surveys. The shaded areas identify grade-year combinations, which were required to pass Minnesota's Basic Skills Tests (BST). The unit of observation is the grade (9-12) within a school district in a given school year (n=10502). The sources of these data are the annual Common Core of Data (CCD) universe surveys from 1993-94 to 2001-2002. Standard errors, adjusted for clustering at the grade-district level, are reported in parentheses. *=significant at the 10 percent level. **= significant at the 5 percent level. The unit of observation is the grade (9-12) within a school district in a given school year (n = 11,740). The sources of these data are the annual Common Core of Data (CCD) universe surveys. All models condition on district-year and district-grade fixed effects. Standard errors, adjusted for clustering at the grade-district level, are reported in parentheses. *=significant at the 10 percent level. **= significant at the 5 percent level. The unit of observation is the grade (9-12) within a school district in a given school year (n = 10502). The sources of these data are the annual Common Core of Data (CCD) universe surveys. All models condition on district-year and district-grade fixed effects. Standard errors, adjusted for clustering at the gradedistrict level, are reported in parentheses. *=significant at the 10 percent level. **= significant at the 5 percent level."}]