[{"section_title": "Abstract", "text": "Abstract-Coronavirus disease 2019 (COVID-19) is an infectious disease with first symptoms similar to the flu. COVID-19 appeared first in China and very quickly spreads to the rest of the world, causing then the 2019-20 coronavirus pandemic. In many cases, this disease causes pneumonia. Since pulmonary infections can be observed through radiography images, this paper investigates deep learning methods for automatically analyzing query chest X-ray images with the hope to bring precision tools to health professionals towards screening the COVID-19 and diagnosing confirmed patients. In this context, training datasets, deep learning architectures and analysis strategies have been experimented from publicly open sets of chest X-ray images. Tailored deep learning models are proposed to detect pneumonia infection cases, notably viral cases. It is assumed that viral pneumonia cases detected during an epidemic COVID-19 context have a high probability to presume COVID-19 infections. Moreover, easyto-apply health indicators are proposed for estimating infection status and predicting patient status from the detected pneumonia cases. Experimental results show possibilities of training deep learning models over publicly open sets of chest X-ray images towards screening viral pneumonia. Chest X-ray test images of COVID-19 infected patients are successfully diagnosed through detection models retained for their performances. The efficiency of proposed health indicators is highlighted through simulated scenarios of patients presenting infections and health problems by combining real and synthetic health data."}, {"section_title": "", "text": "Abstract-Coronavirus disease 2019 (COVID-19) is an infectious disease with first symptoms similar to the flu. COVID-19 appeared first in China and very quickly spreads to the rest of the world, causing then the 2019-20 coronavirus pandemic. In many cases, this disease causes pneumonia. Since pulmonary infections can be observed through radiography images, this paper investigates deep learning methods for automatically analyzing query chest X-ray images with the hope to bring precision tools to health professionals towards screening the COVID-19 and diagnosing confirmed patients. In this context, training datasets, deep learning architectures and analysis strategies have been experimented from publicly open sets of chest X-ray images. Tailored deep learning models are proposed to detect pneumonia infection cases, notably viral cases. It is assumed that viral pneumonia cases detected during an epidemic COVID-19 context have a high probability to presume COVID-19 infections. Moreover, easyto-apply health indicators are proposed for estimating infection status and predicting patient status from the detected pneumonia cases. Experimental results show possibilities of training deep learning models over publicly open sets of chest X-ray images towards screening viral pneumonia. Chest X-ray test images of COVID-19 infected patients are successfully diagnosed through detection models retained for their performances. The efficiency of proposed health indicators is highlighted through simulated scenarios of patients presenting infections and health problems by combining real and synthetic health data.\nIndex Terms-image detection, radiology, X-ray, COVID-19."}, {"section_title": "I. INTRODUCTION", "text": "COVID-19, initially named 2019-nCoV, appeared first in China and very quickly spreads to the rest of the world causing then the 2019-20 coronavirus pandemic. To date (April 5th 2020), there have been 82,602 highly controversial confirmed cases in China, more than 500,000 confirmed cases in Europe and 1,226,644 confirmed cases all around the world 1 . 1 Online map of COVID-19 Global Cases by the CSSE center at Johns Hopkins University: https://coronavirus.jhu.edu/map.html In many cases, this disease causes pneumonia. Characteristics of such an infection can be observed by radiologists. Also, deep learning methods can be helpful for operating deep analysis on query radiography images. Thanks to artificial intelligence, early stage and precision diagnosis can be done.\nIn this pandemic, the effective screening of COVID-19 is an arduous task in practice. Standard screening test kits called Reverse Transcription-Polymerase Chain Reaction (RT-PCR) are often unavailable. Moreover, the RT-PCR test is highly sensitive. It was found that deep-based Computed Tomography (CT) images analysis could be more reliable than RT-PCR test in early-stage diagnostic [1] - [3] . Notably, where RT-PCR test can turn out negative, deep CT image analysis can already predict true positives in certain cases. False negatives to RT-PCR test can lead to non-negligible propagation of this disease.\nAt this time, American College of Radiology recommendations for the use of chest radiography and CT for Suspected COVID-19 infection [4] point that generally, the findings on chest imaging in COVID-19 are not specific, and overlap with other infections, including influenza, H1N1, SARS and MERS. Notably, being in the midst of the current flu season with a much higher prevalence of influenza in the U.S. than COVID-19, further limits the specificity of CT. Besides, the use of radiography equipment requires high disinfection needs after each use which can make massive tests laborious and timeconsuming. In practice, for hygienic reasons, chest X-rays are often frontally taken with patients on a stretcher or bed, lying down or at best sitting. Such constraints often conduct to chest X-rays with poor quality and real issues in term of analysis.\nNevertheless, CT images of lung and chest X-ray images offer additional data for screening COVID-19. Notably, AI technology is already deployed in China for radiography examination and radiomics-like analysis from CT images [5] . AI technology can also facilitate remote operations and help to face the lack of expert radiologists. At this date, many AI tools and radiography image datasets are private resources. The access to publicly open COVID-19-related sets of lung CT images towards conducting deep learning experiments is relatively limited. Some open access X-ray image sets of chest are publicly available.\nThe goal of this paper is twofold: i) to present deep learning models tailored for detecting pneumonia infection cases such as viral cases towards screening COVID-19, ii) to propose easy-to-apply health indicators for evaluating detected pneumonia infection cases with an estimator of infection and predictions of patient status. This case study is presented with the aim of supporting radiologists and other clinicians. In no case this preliminary study could be substituted to a medical advice.\nThe remaining of the paper is organized as follows. The next section gives an overview of related works. Section 3 presents some investigated deep learning based image detection architectures and analysis strategies. Section 4 shows a set of experiments to evaluate the performance of the considered architectures and section 5 concludes the paper."}, {"section_title": "II. RELATED WORK", "text": "Image analysis and machine learning techniques already have extensive applications in precision health. Currently, multiple and varied COVID-19-related studies are conducted in order to highlight proof of concepts and scientific truths about this misunderstood disease. Some image detection, evaluation and making-decision techniques related to COVID-19 and radiography examinations are described hereafter.\nIn [2] , Xu et al. present a case study that deals with the COVID-19 screening from CT images. They mention that the COVID-19 manifests its own characteristics that differ from other types of viral pneumonia, such as Influenza-A viral pneumonia. The study aims to establish an early screening model for COVID-19 by automatically analyzing collected pulmonary CT images of COVID-19, Influenza-A viral pneumonia and healthy cases (618 transverse-section CT samples before data augmentation). The overall accuracy of the deep learning models were 86.7% for these three groups. First CT images were preprocessed for extracting effective pulmonary regions. Second, a 3D Convolutional Neural Network (CNN) model was used to segment multiple candidate regions (patches). In particular, the VNET [6] based segmentation model VNET-IR-RPN [7] trained for pulmonary tuberculosis purpose was used to separate candidate patches from viral pneumonia. Third, a classification model (e.g. based on ResNet [8] ) categorizes each patch amongst three types: COVID-19, Influenza-A-viral-pneumonia, and irrelevant-to-infection; and assign an infection probability. The overall analysis report for one CT sample was calculated using the Noisy-or Bayesian function.\nIn [9] , Shan et al. present a method to automatically segment and quantify infection in CT scans of COVID-19 patients. The collected dataset was composed of 549 CT images. To accelerate the manual delineation of CT images for training, a Human-In-The-Loop (HITL) strategy is adopted. A manual delineation step is operated by a medical staff for delimiting infected regions on original COVID-19 chest CT images. This permits to generate and to enrich a training set that is given as input to an artificial intelligence engine which operates to an automatic segmentation step over the COVID-19 infected region. The process loops these steps from this autocontoured regions to assist radiologists for their annotation refinements. The proposed system yielded Dice similarity coefficients of approximately 91.6% between automatic and manual segmentations, and a mean Percentage Of Infection (POI) estimation error of 0.3% for the whole lung on the validation dataset. Moreover, compared with the cases of fully manual delineation that often requires 1 to 5 hours, the HITL strategy drastically reduces the delineation time to 4 minutes after 3 iterations of model updating.\nThe pulmonary infections can be more directly visible in CT images than in chest X-Ray images [10] . Nevertheless, detection of COVID-19 from chest X-ray images is also investigated since they represent widespread resources that are often analyzed upstream of CT scans.\nIn [11] , a deep learning architecture named COVID-Net is proposed for the detection of COVID-19 cases from chest radiography images. The authors notably exploits the Chest X-Ray Images (Pneumonia) open dataset 1 and the COVID-19 Image Data Collection open dataset [12] . Their derived chest radiography dataset named COVIDx is composed of 5941 posteroanterior chest radiography across 2839 patient cases. Their study targets the prediction of 4 image classes, namely normal, bacterial infection, non-COVID viral infection, and COVID-19 viral infection. In this sense, their dataset contains 1203 patient cases as normal, 931 patient cases with bacterial pneumonia, 660 patient cases with non-COVID-19 viral pneumonia and only 68 radiography images collected from 45 COVID-19 patient cases. The distribution of inter-class images amongst their training sets and amongst their test sets are highly unbalanced in view of the quantity of collected COVID-19 images. The authors exploit residual architecture design principles [13] pointing that they show time and again to enable reliable neural network architectures that are easier to train to high performance. They leverage generative synthesis [14] as the machine-driven design exploration strategy for generating the final COVID-Net network architecture that obtains a global test accuracy of 83.5%. However, this accuracy has been obtained including a small data sample corresponding to only 10 COVID-19 cases. "}, {"section_title": "III. PROPOSED APPROACH FOR PNEUMONIA ANALYSIS A. CNN-based detection and evaluation of infected patients", "text": "In [15] [16] , authors emphasized that the COVID-19 is a viral disease and not a bacterial one. Respectively, an efficient classifier is designed to automatically detect if a query chest X-ray image is Normal, Bacterial or Viral by assuming that a COVID-19 infected patient, tested during an epidemic period, has a high probability to be a true positive when the classification output is Virus (see Fig. 1 ). Nethertheless, it is worth mentioning that a severe viral respiratory infection can lead to a secondary pneumonia of bacterial nature [17] . For this reason, our classifier aims to be useful at early stage of COVID-19 pulmonary symptoms.\n1) Tailored CNN models: A set of tailored models based on CNNs have been designed to take three set of image categories (e.g.; normal case, viral pneumonia case and bacterial case) as input and output the predicted probability for each of the categories. The trained models exploit the CNN backbones ResNet34, ResNet50 and DenseNet169 through the fastai library and a fully connected head, with a single hidden layer, as a classifier.\nBesides, a trained model exploits the CNN reference backbone VGG-19. In addition, a dual use model (Inception ResNetV2 -RNN) is prepared for i) characterizing categories of input split images by getting a hidden layer output of a fin-tuned Inception ResNetV2 architecture, ii) predicting final categories of split images (image blocks) using a bidirectional Long Short-Term Memory (RNN-LSTM) architecture. For these last ones, a Keras and TensorFlow workflow is used.\nSpecifically, the prediction stage of the dual-use model operates at a second level analysis of the data. A sequence of sub-images is first generated while entirely covering the images by directly positioning a regular grid onto the original query chest X-ray images. Precisely, the image is split into a set of image blocks that correspond to grid cells (see Fig. 2 ). This operation enhances the size of the training set while limiting the loss of image details. This loss often occurs when the original images are resized for fitting inputs of standard deep learning architectures. Then, each image block is given as input to the RNN for providing a set of local predictions (matrix of contamination) towards estimating health indicators such as a CNN-based infection ratio (a use is described in section III-B). The grid discretization should be tuned according to the obtained predictive performance of the considered architecture. 2) Data preparation and model inputs: For our experiments, we exploited Chest X-ray images from the Chest XRay Images (Pneumonia) dataset 1 . This dataset is related to the paper [18] on the identification of medical diagnoses and treatable diseases by image-based deep learning. This dataset contains 5,863 children X-Ray images divided in two categories, namely Normal and Pneumonia. The Pneumonia category is composed of pneumonia images that are labeled either bacterial or viral (see illustrations in Fig. 6 of [18] ).\nThe Chest X-Ray Images (Pneumonia) dataset is reorganized into three classes; into normal, bacterial pneumonia and viral pneumonia (see samples in Fig 3a, Fig. 3b and Fig. 3c , respectively). Each training set contains 1345 images and each test set contains 148 images. Since this dataset was composed of pulmonary images having heterogeneous and large sizes; and to deal with reasonable computational times during the CNN training experiments, all the images were resized to a unique dimension and rescaled into smaller images (e.g.; size 310 \u00d7 310) to fit with standard inputs of tailored architectures. For the last tailored model using RNN, a preliminary split of the original image precedes the resizing step.\nRegarding the tests, we added a test set (blind test) that is composed of a single class containing 145 chest X-ray images of COVID-19 infected patients (see sample in Fig. 3d ). This test set has been constituted by filtering the heterogeneous COVID-19 Image Data Collection dataset [12] ; folder containing a mix of CT and X-ray images with a variety of infection types. At this time, we consider that this quantity of available COVID-19 is still too limited for building a reliable detector that can discern between Non-COVID-19 viral pneumonia and COVID-19 viral pneumonia. The 145 chest X-ray images are specifically used as a test set towards ideally detecting them as viral pneumonia. As previously mentioned, we assume that a COVID-19 infected patient, tested during an epidemic period, has a high probability to be a true positive when the classification output is viral pneumonia (Fig. 1) ."}, {"section_title": "B. Estimation of CNN-based health indicators", "text": "Based on statistical tools (logistic regression and statistical tests) and realistic data, studies on COVID-19-related death risk factor have been proposed in [19] , [20] . In this paper, we sketch a simple measure to provide to health professionals an estimator for evaluating the chance of a patient to survive COVID-19 considering risk factors; namely age, comorbidity and the infection rate indicator (Fig.2) . For each risk factor, we associate a score which represents a penalty (a large value decreases the chance of a patient to escape fatality). The proposed measure F is the addition of scores divided by a critical threshold T . Beyond T , there is no chance to be recovered. Formally, F is expressed as follows:\nwhere S1 measures the risk due to the patient's age, S2 measures the risk related to the CNN-derived infection rate measured from the X-ray chest image of a patient, S3 measures the risk associated with comorbidities (additional diseases) of a patient that can lead to the development of complications. More precisely, let us give an example to concretely compute the measure F . First, we point out that the scoring system used hereafter must be adjusted by health professionals to match with reality.\nIn this example, we use the values of fatality risk-ratio during COVID-19 epidemic in Hubei, China [21] . Proportionally to these values, we define penalty scores (S 1 ), see Table I .\nThen, we define the scores (S 2 ) related to the infection rate of X-ray image. S 2 can be the probability of the concerned class that is directly provided by the used CNN. A more refined formulation of S 2 is proposed to scrutinize the Xray image. Each image is divided in n sub-images where n = 9 (value for which our RNN effectively performs). After analysis, each sub-image will be in status virus, bacteria or normal (see Fig.2 ). A score equal to 100 is assigned to the X-ray image when the n sub-images are infected by a virus. Proportionally, the infection rate of the image is:\nwhere N is the number of the virus infected sub-images.\nThe third risk factor (S 3 ) is related to diseases of a patient in addition to COVID-19. We associate a penalty 100 to serious diseases, as complicated hypertension, coronary artery disease, heart surgery, chronic renal failure on dialysis, cancer on treatment. The health professional can define a list of moderated diseases which may complicate the patient's recovering. He may assign to a moderated disease score a penalty value proportional to the score of serious diseases. In this article, we attribute the value 10 to one moderated disease. In this example, we set the critical threshold T to 200, then beyond this limit, one cannot escape fatality. The measure F can be used as follows. If F \u2265 1 then the hope to escape fatality is null. Varying F from 0 to 1, the patient gradually moves away from the hope of recovering.\nThe value 200 assigned to T is obtained by taking reference a patient having a serious additional disease and aged over 80 years. We assume that such a patient cannot fight against COVID-19. Therefore, a person having COVID-19 which reaches the score 200 cumulates too many factors to overcome the illness.\nFinally, we point out that the measure F can also be extended by slightly modifying the term S 2 for taking into account time factor. Indeed, a serie of X-ray images is observed for each COVID-19 inpatient pointed in [10] [22] [23] . Accordingly, S 2 can be measure at two timely spaced X-rays t 1 and t 2 to take into account the time kinetics of symptom onset and disease progression for the infected patient. For this latter case, the infection rate can be redefined as follows:\nwhere f (t) = (100/n)\u00d7N (t) is the infection rate of the chest X-ray image captured at a moment t, N (t) is the number of detected viral sub-images at a moment t, t1 is inferior to t2, \u03b4 is threshold fixed to 20, bonus and malus are a gain and a penalty fixed to (\u221220 \u00d7 f (t2))/100 and (20 \u00d7 f (t2))/100, respectively."}, {"section_title": "IV. EXPERIMENTAL STUDY", "text": "A. Performance of tailored CNN models Table II presents performance for classification of normal and infection cases by using tailored CNN-based architectures. The DenseNet169 architecture has reached best performance with an average classification accuracy of 95.72% from the Chest X-Ray Images (Pneumonia) dataset 1 . The classification accuracies are 97.97%, 96.62% and 92.57% for the class bacterial, virus and normal, respectively (see Table III ). The associated confusion matrix is shown in Table IV . The performance of our DenseNet model is competitive with performances obtained by [18] in average classification accuracy of bacterial and viral cases 90.7%.\nHowever, our RNN-based architecture is particularly sensitive to pneumonia cases with the blind COVID-19 test set since it detects pneumonia for 99.3% using default setting. Also, it promisingly detects viral infection for 60.64% considering majority voting in sequences. We stress the fact that the 145 COVID-19 images which have been extracted from [12] are highly heterogeneous. Notably, these extracted images come from at least 24 different hospitals over the world. The RNN output results show a particularly robust pneumonia detection of COVID-infected patients and satisfying viral detection in view of the diversity of exploited radiography sources.\nIn [12] , a histogram shows that significant image quantity has been acquired during the first week of the start of symptoms or hospitalization. Since the quasi-totality of pneumonia are detected, our models should be able to operate at an early detection stage.\nAlso, a histogram shows a significant image distribution in term of age in between 20 and 80 years old. Since the Chest X-Ray Images (Pneumonia) dataset 1 is principally collected from children (5,232 chest X-ray images) and since the quasitotality of pneumonia are detected, models trained on children chest X-ray image database may be relevant for detecting pneumonia from adult chest X-ray images. Table V shows the RNN-derived infection rates S 2 estimated from real pairs of successive X-ray images for 5 COVID-19 infected patients. Table VI details examples of F calculated for 9 patients from synthetic data."}, {"section_title": "B. Projection with the CNN-based health indicators", "text": ""}, {"section_title": "V. CONCLUSION", "text": "A bench of deep learning tailored models have shown promising performances. Indeed, they have all exceeded 84% of average accuracy on pneumonia detection cases for the Pneumonia reorganized dataset 1 . Hence, a patient that has a pneumonia during the epidemic context has a high probability to be detected by these models. In particular, the InceptionResNetV2 model has detected the minimum of false negatives to the pneumonia on the blind test set (0.7%). Moreover, we have shown in our experiments that the transfer of knowledge from pediatric chest X-ray training towards infection screening of adults can be efficient. Additionally, an attempt based on realistic scenarios is done to provide easy-to-apply health indicators for evaluating infection rate and aggravation risk to the COVID-19 pneumonia. Future works may exploit our models to discern between COVID-19 viral and non-COVID-19 viral pneumonia once chest X-ray images of COVID-19 will be accessible in sufficient quantity. This should permit to specifically identify COVID-19 infected patients even in a non-epidemic context. Furthermore, reliability of proposed models must be cross-checked by RT-PCR tests and clinical tests before deployment. [18] . Image pairs f (t 1 ) Elapsed days f (t 2 ) Observations S 2 (t2 \u2212 t1) (1,3), Fig. 5 of [10] 9/9 7 9/9 elderly man f (t 2 ) \"improvements\" (1,2), Fig. 1 of [22] 1/9 5 2/9 67-y-old woman f (t 2 ) \"wires, attenuation\" (1,3), Fig. 2 of [22] 5/9 8 5/9 36-y-old man f (t 2 ) \"death\" (1,2), case 1, Fig. 5 of [23] 6/9 1 9/9 \"worse status\" f (t 2 )+malus "}, {"section_title": "Accuracy (%) h h h h h h h h h h h h", "text": ""}]