[{"section_title": "Abstract", "text": "Nonlinear registration of 2D histological sections with corresponding slices of MRI data is a critical step of 3D histology reconstruction algorithms. This registration is difficult due to the large differences in image contrast and resolution, as well as the complex nonrigid deformations and artefacts produced when sectioning the sample and mounting it on the glass slide. It has been shown in brain MRI registration that better spatial alignment across modalities can be obtained by synthesizing one modality from the other and then using intra-modality registration metrics, rather than by using information theory based metrics to solve the problem directly. However, such an approach typically requires a database of aligned images from the two modalities, which is very difficult to obtain for histology and MRI.\nHere, we overcome this limitation with a probabilistic method that simultaneously solves for deformable registration and synthesis directly on the target images, without requiring any training data. The method is based on a probabilistic model in which the MRI slice is assumed to be a contrast-warped, spatially deformed version of the histological section. We use approximate Bayesian inference to iteratively refine the probabilistic estimate of the synthesis and the registration, while accounting for each other's uncertainty. Moreover, manually placed landmarks can be seamlessly integrated in the framework for increased performance and robustness.\nExperiments on a synthetic dataset of MRI slices show that, compared with mutual information based registration, the proposed method makes it possible to use a much more flexible deformation model in the registration to improve its accuracy, without compromising robustness. Moreover, our framework also exploits information in manually placed landmarks more efficiently than MI, since landmarks inform both synthesis and registration -as opposed to registration alone. Finally, we show qualitative results on the publicly available Allen atlas, in which the proposed method provides a clear improvement over mutual information based registration."}, {"section_title": "", "text": "1. Introduction"}, {"section_title": "Motivation: human brain atlases", "text": "Histology is the study of tissue microanatomy. Histological analysis involves cutting a wax-embedded or frozen block of tissue into very thin sections (in the order of 10 microns), which are subsequently stained, mounted on glass slides, and examined under the microscope. Using different types of stains, different microscopic structures can be enhanced and studied. Moreover, mounted sections can be digitised at high resolution 1 Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (http://adni.loni. usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: adni.loni.usc.edu/wp-content/uploads/how_ to_apply/ADNI_Acknowledgement_List.pdf.\n-in the order of a micron. Digital histological sections not only enable digital pathology in a clinical setting, but also open the door to an array of image analysis applications.\nA promising application of digital histology is the construction of high resolution computational atlases of the human brain. Such atlases have traditionally been built using MRI scans and/or associated manual segmentations, depending on whether they describe image intensities, neuroanatomical label probabilities, or both. Examples include: the MNI atlas (Evans et al., 1993; Collins et al., 1994) , the Colin 27 atlas (Holmes et al., 1998) , the ICBM atlas (Mazziotta et al., 1995 (Mazziotta et al., , 2001 , and the LONI LPBA40 atlas (Shattuck et al., 2008) .\nComputational atlas building using MRI is limited by the resolution and contrast that can be achieved with this imaging technique. The resolution barrier can be partly overcome with ex vivo MRI, in which motion -and hence time constraintsare eliminated, enabling longer acquisition at ultra-high resolu-tion (\u223c100 \u00b5m), which in turns enable manual segmentation at a higher level of detail (Augustinack et al., 2005; Yushkevich et al., 2009; Iglesias et al., 2015; Saygin et al., 2017) . However, not even the highest resolution achievable with ex vivo MRI is sufficient to study microanatomy. Moreover, and despite recent advances in pulse sequences, MRI does not generate visible contrast at the boundaries of many neighbouring brain structures, the way that histological staining does.\nFor these reasons, recent studies building computational brain atlases are using stacks of digitised histological sections, which enable more accurate manual segmentations, to build atlases at a superior level of detail. Examples include the work by Chakravarty et al. (2006) on the thalamus and basal ganglia; by Krauth et al. (2010) on the thalamus; by Adler et al. (2014 Adler et al. ( , 2016 on the hippocampus; our recent work on the thalamus (Iglesias et al., 2017) , and the recently published atlas from the Allen Institute (Ding et al., 2016) 2 ."}, {"section_title": "Related work on 3D histology reconstruction", "text": "The main drawback of building atlases with histology is the fact that the 3D structure of the tissue is lost in the processing. Sectioning and mounting introduce large nonlinear distortions in the tissue structure, including artefacts such as folds and tears. In order to recover the 3D shape, image registration algorithms can be used to estimate the spatial correspondences between the different sections. This problem is commonly known as \"histology reconstruction\".\nThe simplest approach to histology reconstruction is to sequentially align sections in the stack to their neighbours using a linear registration method. There is a wide literature on the topic, not only for histological sections but also for autoradiographs. Most of these methods use robust registration algorithms, e.g., based on edges (Hibbard and Hawkins, 1988; Rangarajan et al., 1997) , block matching (Ourselin et al., 2001) or point disparity (Zhao et al., 1993) . There are also nonlinear versions of serial registration methods (e.g., Arganda-Carreras et al. 2010; Pitiot et al. 2006; Chakravarty et al. 2006; Schmitt et al. 2007 ), some of which introduce smoothness constraints to minimise the impact of sections that are heavily affected by artefacts and/or are poorly registered (Ju et al., 2006; Yushkevich et al., 2006; Cifor et al., 2011) .\nThe problem with serial alignment of sections is that, without any information on the original shape, methods are prone to straightening curved structures, a problem known as \"z-shift\" or \"banana effect\" (since the reconstruction of a sliced banana would be a cylinder). One way of overcoming this problem is the use of fiducial markers such as needles or rods (e.g., Humm et al. 2003) ; however, this approach has two disadvantages: the tissue may be damaged by the needles, and additional bias can be introduced in the registration if the sectioning plane is not perpendicular to the needles.\nAnother way of combating the banana effect is to use an external reference volume without geometric distortion. In an early study, Kim et al. (1997) used video frames to construct such reference, in the context of autoradiograph alignment. More recent works have used MRI scans (e.g., Malandain et al. 2004; Dauguet et al. 2007; Yang et al. 2012; Ebner et al. 2017) . The general idea is to iteratively update: 1. a rigid transform bringing the MRI to the space of the histological stack; and 2. a nonlinear transform per histological section, which registers it to the space of the corresponding (resampled) MRI plane. A potential advantage of using MRI as a reference frame for histology reconstruction is that one recovers in MRI space the manual delineations made on the histological sections, which can be desirable when building atlases (Adler et al., 2016) .\nIncreased stability in histology reconstruction can be obtained by using a third, intermediate modality to assist the process. Such modality is typically a stack of blockface photographs, which are taken prior to sectioning and are thus spatially undistorted. Such photographs help bridge the spaces of the MRI (neither modality is distorted) and the histology (plane correspondences are known). An example of this approach is the BigBrain project (Amunts et al., 2013) .\nAssuming that a good estimate of the rigid alignment between the MRI and the histological stack is available, the main technical challenge of 3D histology reconstruction is the nonlinear 2D registration of a histological section with the corresponding (resampled) MRI plane. These images exhibit very different contrast properties, in addition to modality-specific artefacts, e.g., tears in histology, bias field in MRI. Therefore, generic information theory based registration metrics such as mutual information (Maes et al., 1997; Wells et al., 1996; Pluim et al., 2003) yield unsatisfactory results. This is partly due to the fact that such approaches only capture statistical relationships between image intensities at the voxel level, disregarding geometric information."}, {"section_title": "Related work on image synthesis for registration", "text": "An alternative to mutual information for inter-modality registration is to use image synthesis. The premise is simple: if we need to register a floating image F A of modality A to a reference image R B of modality B, and we have access to a dataset of spatially aligned pairs of images of the two modalities {A i , B i }, then we can: estimate a synthetic version of the floating image F B that resembles modality B; register F B to R B with an intra-modality registration algorithm; and apply the resulting deformation field to the original floating image F A . In the context of brain MRI, we have shown in Iglesias et al. (2013) that such an approach, even with a simple synthesis model (Hertzmann et al., 2001) , clearly outperforms registration based on mutual information. This result has been replicated in other studies (e.g., Roy et al. 2014) , and similar conclusions have been reached in the context of MRI segmentation (Roy et al., 2013) and classification (van Tulder and de Bruijne, 2015) .\nMedical image synthesis has gained popularity in the last few years due to the advent of hybrid PET-MR scanners, since synthesising a realistic CT scan from the corresponding MR enables accurate attenuation correction of the PET data (Burgos et al., 2014; Huynh et al., 2016) . Another popular application of CT synthesis from MRI is dose calculation in radiation therapy (Kim et al., 2015; Siversson et al., 2015) . Unfortunately, most of these synthesis algorithms are based on supervised machine learning techniques, which require aligned pairs of images from the two modalities -which are very hard to obtain for histology and MRI.\nA possible alternative to supervised synthesis is a weakly supervised paradigm, best represented by the recent deep learning method CycleGAN (Zhu et al., 2017) . This algorithm uses two sets of (unpaired) images of the two modalities, to learn two mapping functions, from each modality to the other. CycleGAN enforces cycle consistency of the two mappings (i.e., that they approximately invert each other), while training two classifiers that discriminate between synthetic and real images of each modality in order to avoid overfitting. While this technique has been shown to produce realistic medical images (Chartsias et al., 2017; Wolterink et al., 2017) , it has an important limitation in the context of histology-MRI registration: it is unable to exploit the pairing between the (nonlinearly misaligned) histology and MRI images. Another disadvantage of CycleGAN is that, since a database of cases is necessary to train the model, it cannot be applied to a single image pair, i.e., it cannot be used as a generic inter-modality registration tool."}, {"section_title": "Contribution", "text": "In this study, we propose a novel probabilistic model that simultaneously solves for registration and synthesis directly on the target images, i.e., without any training data. The principle behind the method is that improved registration provides less noisy data for the synthesis, while more accurate synthesis leads to better registration. Our framework enables these two components to iteratively exploit the improvements in the estimates of the other, while considering the uncertainty in each other's parameters. Taking uncertainty into account is crucial: if one simply tries to iteratively optimise synthesis and registration while keeping the other fixed to a point estimate, both components are greatly affected by the noise introduced by the other. More specifically, misregistration leads to bad synthesis due to noisy training data, whereas accurate registration to an poorly synthesised image yields incorrect alignment.\nIf multiple image pairs are available, the framework exploits the complete database, by jointly considering the probabilistic registrations between the pairs. In addition, the synthesis algorithm effectively takes advantage of the spatial structure in the data, as opposed to mutual information based registration. Moreover, the probabilistic nature of the model also enables the seamless integration of manually placed landmarks, which inform both the registration (directly) and the synthesis (indirectly, by creating areas of high certainty in the registration). We present a variational expectation maximisation algorithm (VEM, also known as variational Bayes) to solve the model with Bayesian inference, and illustrate the proposed approach through experiments on synthetic and real data.\nThe rest of this paper is organised as follows. In Section 2, we describe the probabilistic model on which our algorithm relies (Section 2.1), as well as an inference algorithm to compute the most likely solution within the proposed framework (Section 2.2). In Section 3, we describe the MRI and histological data (Section 3.1) that we used in our experiments (Section 3.2), as well as the results on real data and the Allen atlas (Section 3.3). Finally, Section 4 concludes the paper."}, {"section_title": "Methods", "text": ""}, {"section_title": "Probabilistic framework", "text": "The graphical model of our probabilistic framework and corresponding mathematical symbols are shown in Figure 1 . For the sake of simplicity, we describe the framework from the perspective of the MRI to histology registration problem, though the method is general and can be applied to other intermodality registration task -in any number of dimensions.\nLet {M n } n=1,...,N and {H n } n=1,...,N represent N \u2265 1 MRI image slices and corresponding histological sections. We assume that each pair of images has been coarsely aligned with a 2D linear registration algorithm (e.g., using mutual information), and are hence defined over the same image domain \u2126 n . M n and H n are functions of the spatial coordinates x \u2208 \u2126 n , i.e., M n = M n (x) and H n = H n (x). In addition, let K n and K h n represent two sets of L n corresponding landmarks, manually placed on the n th MRI image and histological section, respectively:\n..,L n , where k nl and k h nl are 2D vectors with the spatial coordinates of the l th landmark on the n th image pair; for reasons that will be apparent in Section 2.2 below, we will assume that every k nl coincides with an integer pixel coordinate. Finally, M h n represents the n th MR image after applying a nonlinear deformation field U n (x), which deterministically warps it to the space of the n th histological section H n , i.e.,\nwhich in general requires interpolation of M n (x). Each deformation field U n is assumed to be an independent sample of a Markov Random Field (MRF) prior, with unary potentials penalising large shifts (their squared module), and binary potentials penalising the squared gradient magnitude:\nwhere \u03b2 1 > 0 and \u03b2 2 > 0 are the parameters of the MRF (which we group in \u03b2 = {\u03b2 1 , \u03b2 2 }); Z n (\u03b2 1 , \u03b2 2 ) is the partition function; and B(x) is the neighbourhood of the pixel located at x. We note that this prior encodes a regularisation similar to that of the popular demons registration algorithm (Vercauteren et al., 2007; Cachier et al., 2003) . Moreover, we also discretise the deformation field to a set of values (shifts) {\u2206 s } s=1,...,S , i.e., U n (x) \u2208 {\u2206 s }; we note that these shifts do not need to be integer (in pixels). While this choice of deformation model and regulariser does not guarantee the registration to be diffeomorphic (which might be desirable), it enables marginalisation over the deformation fields {U n } -and, as we will discuss in Section 2.2 below, a more sophisticated deformation model can be used to refine the final registration. Application of U n to M n and K n yields not only a registered MRI image M h n (Equation 1), but also a set of warped landmarks K h . When modelling K h , we need to account for the error made by the user when manually placing corresponding key-points in the MR images and the histological sections. We assume that these errors are independent and follow zero-mean, isotropic Gaussian distributions parametrised by their covariances \u03c3 2 k I (where I is the 2\u00d72 identity matrix, and where \u03c3 2 k is expected to be quite small):\nFinally, to model the connection between the intensities of the histological sections {H n } and the registered MRI images {M h n }, we follow Tu et al. (2008) and make the assumption that:\nThis assumption is equivalent to adopting a discriminative approach to model the contrast synthesis. While this discriminative component breaks the generative nature of the framework, it also enables the modelling of much more complex relationships between the intensities of the two modalities, including spatial and geometric information about the pixels. Such spatial patterns cannot be captured by, e.g., mutual information, which only models statistical relationships between intensities (e.g., a random shuffling of pixels does not affect the metric).\nHere we use a regression forest (Breiman, 2001) , though any other discriminative regression could have been utilised. We assume conditional independence of the pixels in the prediction: the forest produces a Gaussian distribution for each pixel x separately, parametrised by \u00b5 nx and \u03c3 2 nx . Moreover, we place a (conjugate) Inverse Gamma prior on the variances \u03c3 2 nx , with hyperparameters a and b:\nWe use \u03b8 to represent the set of forest parameters, which groups the selected features, split values, tree structure and the prediction at each leaf node. The set of corresponding hyperparameters are grouped in \u03b3, which includes the parameters of the Gamma prior {a, b}, the number of trees, maximum depth, and minimum number of samples in leaf nodes. The intensity model is hence:\nwhere W(x) is a spatial window centred at x, and N represents the Gaussian distribution. Given the deterministic deformation model (Equation 1), and the assumption in Equation 4, we finally obtain the likelihood term:\nWe emphasise that, despite breaking the generative nature of the model, the assumption in Equation 4 still leads to a valid objective function when performing Bayesian inference. This cost function can be optimised with standard inference techniques, as explained in Section 2.2 below."}, {"section_title": "Inference", "text": "The final goal is to estimate the registrations {U n }. To do so, we use Bayesian inference to \"invert\" the probabilistic model described in Section 2.1 above. If we group all the observed variables into the set O = {{M n }, {H n }, {K n }, {K h n }, \u03b2, \u03b3, \u03c3 2 k }, the problem is to maximise the posterior probability of the registrations given the available information, i.e., p({U n }|O). Computing such probability distribution requires marginalizing over the intensity model, which leads to an intractable integral:\nTo solve this problem, we make the standard approximation that the posterior distribution of the parameters \u03b8 given the observed data O is strongly peaked around its mode\u03b8, i.e., we use its point estimate. The intractable integral in Equation 7 then becomes:\nwhere the point estimate is given by:\nIn this section, we first describe a VEM algorithm to obtain the point estimate of \u03b8 using Equation 9 (Section 2.2.1), and then address the computation of the final registrations with Equation 8 (Section 2.2.2)."}, {"section_title": "Computation of point estimate\u03b8 Applying Bayes's rule on Equation 9", "text": ", and taking the logarithm, we obtain the following objective function:\nExact maximisation of Equation 10 would require marginalizing over the deformation fields {U n }, which leads (once again) to an intractable integral due to the pairwise terms of the MRF prior (Equation 2). Instead, we use a variational technique (VEM) for approximate inference. Since the Kullback-Leibler (KL) divergence is by definition non-negative, the objective function in Equation 10 is bounded from below by:\nThe bound J[q({U n }), \u03b8] is the negative of the so-called free energy: \u03b7 represents the entropy of a random variable; and q({U n }) is a distribution over {U n } which approximates the pos-\n, while being restricted to have a simpler form. The standard mean field approximation (Parisi, 1988) assumes that q factorises over voxels for each field U n :\nwhere q nx is a discrete distribution over shifts at pixel x of image n, such that q nx (\u2206 s ) \u2265 0,\nRather than the original objective function (Equation 10), VEM maximises the lower bound J, by alternately optimizing with respect to q (E-step) and \u03b8 (M-step) in a coordinate ascent scheme. We summarise these two steps below. E-step. To optimise the lower bound with respect to q, it is convenient to work with Equation 11. Since the first two terms are independent of q, one can minimise the KL divergence between q and the posterior distribution of {U n }:\nwhere E is the expected value. Building the Lagrangian (to ensure that q stays in the probability simplex) and setting derivatives to zero, we obtain:\nThis equation has no closed-form solution, but can be solved with fixed point iterations, one image pair at the time -since there is no interdependence in n. We note that the effect of the landmarks is not local; in addition to creating a very sharp q nx around pixel at hand, the variational algorithm also creates a high confidence region around x, by encouraging neighbouring pixels to have similar shifts. This is illustrated in Figure 2 (a,d). The spatial location marked by red dot number 1 is right below a manually placed landmark in the histological section, and the distribution q nx is hence strongly peaked at a location right below the corresponding landmark in the MRI slice. Red dot number 2, on the contrary, is located in the middle of the cerebral white matter, where there is little contrast to guide the registration, so q nx is much more more spread and isotropic. Red dot number 3 lies in the white matter right under the cortex, so its distribution is elongated and parallel to the white matter surface.\nM-step. When optimizing J with respect to \u03b8, it is more convenient to work with Equation 12 -since the term \u03b7[q] can be neglected. Applying the chain rule of probability, and leaving aside terms independent of \u03b8, we obtain:\nMaximisation of Equation 14 amounts to training the regressor, such that each input image patch H n (W(x)) is considered S times, each with an output intensity corresponding to a differently shifted pixel location M n (x+\u2206 s ), and with weight q nx (\u2206 s ). In practice, and since injection of randomness is a crucial aspect of the training process of random forests, we found it beneficial to consider each patch H n (W(x)) only once in each tree, with a shift \u2206 s sampled from the corresponding distribution q nx (\u2206) -fed to the tree with weight 1. The injection of additional randomness through sampling of \u2206 no only greatly increases the robustness of the regressor against misregistration, but also decreases the computational cost of training -since only a single shift is considered per pixel. We also note that this sampling strategy still yields a valid stochastic optimiser for Equation 14, since q nx is a discrete probability distribution over shifts. Such stochastic procedure (as well as other sources of randomness in the forest training algorithm) makes the maximisation of Equation 14 only approximate; this means that the coordinate ascent algorithm to maximise the lower bound J of the objective function is no longer guaranteed to converge. In practice, however, the VEM algorithm typically converges after \u223c5 iterations.\nCombined with the conjugate prior on the variance p(\u03b8|\u03b3), the joint prediction of the forest is finally given by:\nwhere g t is the guess made by tree t; T is the total number of trees in the forest; and where we have dropped the dependency of \u00b5 nx and \u03c3 nx on {H n ,\u03b8} for simplicity. A sample output of the forest is shown in Figure 2 (b,c). Areas of higher uncertainty, which will be downweighted in the registration, include the horizontal crack on the histological image and cerebrospinal fluid regions; the latter may appear bright or dark, depending on whether they are filled with paraformaldehyde, air or Fomblin (further details on these data can be found in Section 3.1)."}, {"section_title": "2.2.2.", "text": "Computation of optimal deformation fields {\u00db n } Once the point estimate\u03b8 (i.e., the optimal regression forest for synthesis) has been computed, one can obtain the optimal registrations by maximizing p({U n }|\u03b8, {M n }, {H n }, {K n }, {K h n }, \u03b2, \u03c3 2 k ). Using Bayes's rule and taking the logarithm, we obtain:\nwhich can be solved one image pair n at the time. Substituting the Gaussian likelihoods into Equation 16, switching signs and disregarding terms independent of U n yields, for each image pair, the following cost function for the registration is obtained:\nThanks to the discrete nature of U n , a local minimum of the cost function in Equation 17 can be efficiently found with algorithms based on graph cuts (Ahuja et al., 1993) , such as Boykov et al. (2001) . We note that the result does not need to be diffeomorphic or invertible, which might be a desirable feature of the registration. This is due to the properties of the deformation model, which was chosen due to the fact that it easily enables marginalisation over the deformation fields with variational techniques. In practice, we have found that, once the optimal (probabilistic) synthesis has been computed, we can obtain smoother and more accurate solutions by using more sophisticated deformation models and priors. More specifically, we implemented the image and landmark terms of Equation 17 in NiftyReg (Modat et al., 2010) , which is a fast, powerful registration package, instantly getting access to its advanced, efficiently implemented deformation models, regularisers and optimisers. NiftyReg parametrises the deformation field with a grid of control points combined with cubic B-Splines (Rueckert et al., 1999) . If \u03a8 n represents the vector of parameters of the spatial transform x = V(x; \u03a8 n ) for image pair n, we optimise:\nwhere E b (\u03a8 n ) is the bending energy of the transform parametrised by \u03a8 n ; E l (\u03a8 n ) is the sum of squares of the symmetric part of the Jacobian after filtering out rotation (penalises stretching and shearing); E j is the Jacobian energy (given by its logdeterminant); \u03b2 b > 0, \u03b2 l > 0, \u03b2 j > 0 are the corresponding weights; and \u03b1 > 0 is a constant that scales the contribution of the image term, such that it is approximately bounded by 1: \u03b1 \u22121 = 9|\u2126 n |/2, i.e., a value of 1 is achieved if all pixels are three standard deviations away from the predicted mean.\nNote that this choice for the final model also enables comparison with mutual information as implemented in NiftyReg, which minimises:\nwhere MI represents the mutual information. We note that finding the value of \u03b1 that matches the importances of the data terms in Equations 18 and 19 is a non-trivial task; however, our choice of \u03b1 defined above places the data terms in approximately the same range of values."}, {"section_title": "Summary of the algorithm and implementation details", "text": "The presented method is summarised in Algorithm 1. The approximate posteriors q nx (\u2206) are initialised to 1/S , evenly spreading the probability mass across all possible shifts (i.e., maximum uncertainty in the registration). Given q nx , Equation 14 is used to initialise the forest parameters \u03b8. At that point, the VEM algorithm alternates between the E and M steps until convergence is reached. Convergence would ideally be assessed with \u03b8 but, since these parameters vary greatly from one iteration to the next due to the randomness injected in training, we use the predicted means and variances instead (\u00b5 nx , \u03c3 2 nx )."}, {"section_title": "Algorithm 1 Simultaneous synthesis and registration", "text": "Initialise \u03b8 with Eq. 14 (random forest training) while \u00b5 nx , \u03c3 2 nx change do E-step: for n = 1 to n = N do Compute \u00b5 nx , \u03c3 2 nx , \u2200x \u2208 \u2126 n with Eq. 15 while q nx changes do Fixed point iteration of q nx (Eq. 13) end while end for M-step: Update \u03b8 with Eq. 14 (random forest retraining) end whil\u00ea \u03b8 \u2190 \u03b8 for n = 1 to n = N do Compute final \u00b5 nx , \u03c3 2 nx , \u2200x \u2208 \u2126 n with Eq. 15 Compute\u00db n with Eq. 17 or Eq. 18 end for\nIn the E-step, each image pair can be considered independently. First, the histological section is pushed through the forest to generate a prediction for the (registered) MR image, including a mean and a standard deviation for each pixel (Equation 15). Then, fixed point iterations of Equation 13 are run until convergence of q nx , \u2200x \u2208 \u2126 n . In the M-step, the approximate posteriors q of all images are used together to retrain the random forest with Equation 14. When the algorithm has converged, the final predictions (mean, variance) can be generated for each voxel, and the final registrations can be computed with Equation 17, or with NiftyReg (see details below).\nInjection of randomness is a crucial aspect of random forests, as it increases their generalization ability (Criminisi et al., 2011 ). Here we used bagging (Breiman, 1996) at both the image and pixel levels, and used random subsets of features when splitting data at the internal nodes of the trees. An additional random component in the stochastic optimization is the sampling of shifts \u2206 to make the model robust against misregistration (see Section 2.2.1). While all these random elements have beneficial effects, these come at the expense of giving up the theoretical guarantees on the convergence of the VEM algorithm -though this was never found to be a problem in practice, as explained in Section 2.2.1 above.\nFor the final registration, we used the default regularisation scheme in NiftyReg, which is a weighted combination of the bending energy (second derivative) and the sum of squares of the symmetric part of the Jacobian. We note that NiftyReg uses \u03b2 j = 0 by default; while using \u03b2 j > 0 guarantees that the output is diffeomorphic, the other two regularisation terms (E b , E l ) ensure in practice that the deformation field is well behaved."}, {"section_title": "Experiments and results", "text": ""}, {"section_title": "Data", "text": "We used two datasets to validate the proposed technique; one synthetic, and one real. The synthetic data, which consists only of MRI images, enables quantitative comparison of the estimated deformations with the ground truth fields that were used to generate them. The real dataset, on the other hand, enables qualitative evaluation in a real histology-MRI registration problem."}, {"section_title": "Synthetic MRI dataset", "text": "Since obtaining MRI and histological data with perfect spatial alignment is very difficult, we used a synthetic dataset based solely on MRI to quantitatively validate the proposed approach. These synthetic data were generated from 676 (real) pairs of T1-and T2-weighted scans from the publicly available ADNI dataset. The resolution of the T1 scans was approximately 1 mm isotropic; the ADNI project spans multiple sites, different scanners were used to acquire the images; further details on the acquisition can be found at http://www.adni-info.org. The T2 scans correspond to an acquisition designed to study the hippocampus, and consist of 25-30 coronal images at 0.4\u00d70.4 mm resolution, with slice thickness of 2 mm. These images cover a slab of tissue containing the hippocampi, which is manually oriented by the operator to be approximately orthogonal to the major axes of the hippocampi. Once more, further details on the acquisition at different sites can be found at the ADNI website.\nThe T1 scans were preprocessed with FreeSurfer (Fischl, 2012) in order to obtain skull-stripped, bias-field corrected images with a corresponding segmentation of brain structures (Fischl et al., 2002) . We simplified this segmentation to three tissue types (gray matter, white matter, cerebrospinal fluid) and a generic background label. The processed T1 was rigidly registered to the corresponding T2 scan with mutual information, as implemented in NiftyReg . The registration was also used to propagate the brain mask and automated segmentation; the former was used to skull-strip the T2, and the latter for bias field correction using the technique described in Van Leemput et al. (1999) . Note that we deform the T1 to the T2 -despite its lower resolution -because of its more isotropic voxel size.\nFrom these pairs of preprocessed 3D scans, we generated a dataset of 1000 pairs of 2D images. To create each image pair, we followed these steps: 1. Randomly select one pair of 3D scans; 2. In the preprocessed T2 scan, randomly select a (coronal) slice, other than the first and the last, which sometimes display artefacts; 3. Downsample the T2 slice to 1 \u00d7 1 mm resolution, for consistency with the resolution of the T1 scans; 4. Reslice the (preprocessed) T1 scan to obtain the 2D image corresponding to the downsampled T2 slice; 5. Sample a random diffeomorphic deformation field (details below) in the space of the 2D slice; 6. Combine the deformation field with a random similarity transform, including rotation, scaling and translation; 7. Deform the T2 scan with the composed field (linear + nonlinear). 8. Rescale intensities to [0, 255] and discretise with 8-bit precision.\nTo generate synthetic fields without biasing the evaluation, we used a deformation model different from that used by NiftyReg (i.e., a grid of control points and cubic B-Splines). More specifically, we created diffeormorphic deformations as follows. First, we generated random velocity fields by independently sampling bivariate Gaussian noise at each spatial location (no x-y correlation) with different levels of variance; smoothing them with a Gaussian filter; and multiplying them by a window function in order to prevent deformations close to the boundaries; we used exp[0.01D(x)], where D(x) is the distance to the boundary of the image in mm. Then, these velocity fields were integrated over unit time using a scaling and squaring approach (Moler and Van Loan, 2003; Arsigny et al., 2006) to generate the deformation fields. Sample velocity and deformation fields generated with different levels of noise are shown in Figure 3 .\nFinally, we synthetically generated spatially spread landmarks using the following procedure. First, we calculated the response to a Harris corner detector (Harris and Stephens, 1988) . Then, we iteratively selected the pixel with the highest response x max , and multiplied the Harris response by a complementary Gaussian function centred at x max , i.e.,\nwith standard deviation \u03c3 equal to 1/10 of the image dimensions. We then applied the deformation field to the landmarks, and corrupted the output locations with Gaussian noise of variance \u03c3 ADNI is a joint effort by coinvestigators from industry and academia. Subjects have been recruited from over 50 sites across the U.S. and Canada. The initial goal of ADNI was to recruit 800 subjects but ADNI has been followed by ADNI-GO and ADNI-2. These three protocols have recruited over 1,500 adults (ages 55-90) to participate in the study, consisting of cognitively normal older individuals, people with early or late MCI, and people with early AD. The follow up duration of each group is specified in the corresponding protocols for ADNI-1, ADNI-2 and ADNI-GO. Subjects originally recruited for ADNI-1 and ADNI-GO had the option to be followed in ADNI-2."}, {"section_title": "Real data", "text": "To qualitatively evaluate our algorithm on real data, we used the Allen atlas, which is based on the left hemisphere of a 34-year-old donor. The histology of the atlas includes 106 Nisslstained sections of the whole hemisphere in coronal plane, with manual segmentations of 862 brain structures. Due to the challenges associated with sectioning and mounting thin sections from complete hemispheres, artefacts such as cracks are present in the sections, which make registration difficult (see for intance Figure 2a ). The sections are 50 \u00b5m thick, and digitised at 1 \u00b5m in-plane resolution with a customised microscopy system -though we downsampled them to 200 \u00b5m to match the resolution of the MRI data (details below). We also downsampled the manual segmentations to the same resolution, and merged them into a whole brain segmentation that, after dilation, we used to mask the histological sections. The histology and associated segmentations can be interactively visualised at http://atlas.brain-map.org, and further details can be found in Ding et al. (2016) . No 3D reconstruction of the histology was performed in their study.\nIn addition to the histology, high-resolution MRI images of the whole brain were acquired on a 7 T Siemens scanner with a custom 30-channel receive-array coil. The specimen was scanned in a vacuum-sealed bag surrounded by Fomblin to avoid artefacts caused by air-tissue interfaces. The images were acquired with a multiecho flash sequence (TR = 50 ms; \u03b1 = 20\n\u2022 , 40\n\u2022 , 60\n\u2022 , 80\n\u2022 ; echoes at 5.5, 12.8, 20.2, 27.6, 35.2, and 42.8 ms), at 200 \u00b5m isotropic resolution. Once more, the details can be found in (Ding et al., 2016) . In this study, we used a single volume, obtained by averaging the echoes corresponding to flip angle \u03b1 = 20\n\u2022 , which provided good contrast between gray and white matter tissue, as well as great signal-to-noise ratio. The combined image was bias field corrected with the method described in (Van Leemput et al., 1999) using the probability maps from the LONI atlas (Shattuck et al., 2008) , which was linearly registered with NiftyReg . A coarse mask for the left hemisphere was manually delineated by JEI, and used to mask out tissue from the right hemisphere, which is not included in the histological analysis. Sample coronal slices of this dataset are shown in 2a (histology) and 2b (MRI).\nTo better assess the quality of the reconstruction as a whole (rather than on a single slice), Figure 9 shows the propagated segmentations in the orthogonal views: sagittal (Figures 9a, 9b ) and axial (Figures 9c, 9d) . The proposed method produces reconstructed segmentations that are smoother and that better follow the anatomy in the MRI scan. In sagittal view, this can be easily observed in subcortical regions such as the putamen (Tag 1 in Figure 9b ), the hippocampus (Tag 2) or the lateral ventricle (Tag 3); and also in cortical regions such as the premotor (Tag 4), parahippocampal (Tag 5) or fusiform temporal (Tag 6) cortices. The improvement is also apparent from how much less frequently the segmentation leaks outside the brain when using our algorithm. Similar conclusions can be derived from the axial view; see for instance the putamen (Tag 1 in Figure 9d ), thalamus (purple region, Tag 2), polysensory temporal cortex (Tag 3) or insular cortex (Tag 4)."}, {"section_title": "Experimental setup", "text": "In the synthetic data, we considered three different levels of Gaussian noise (\u03c3 v = 10, 20, 30 mm) when generating the velocity fields, in order to model nonlinear deformations of different severity. The standard deviation of the Gaussian smoothing filter was set to 5 mm, in both the horizontal and vertical direction. The random rotations, translations and log-scalings of the similarity transform were sampled from zero-mean Gaussian distributions, with standard deviations of 2\n\u2022 , 1 pixel, and 0.1, respectively. We then used NiftyReg with mutual information and our method to recover the deformations, using different spacings between control points (from 3 to 21 mm, with 3 mm steps) to evaluate different levels of model flexibility. Otherwise we used the default parameters of the package: three resolution levels, 64 bins in mutual information, and regularisation parameters \u03b2 b = 0.001, \u03b2 l = 0.01, and \u03b2 j = 0. The standard deviation of the manual landmark placement was set to \u03c3 k = 0.5 mm (equivalent to 0.5 pixels).\nThe rest of model parameters were set to: \u03b2 1 = \u03b2 2 = 0.02 (equivalent to a standard deviation of 5 mm); a = 2, b = 25 2 a (equivalent to 4 pseudo-observations with sample standard deviation equal to 5); and {\u2206 s } being a grid covering a square with radius 10 mm, in increments of 0.5 mm. Finally, the random forest regressor consisted of 100 trees, using Gaussian derivatives and location as features. The Gaussian derivatives were of order up to three, computed at three different scales: 0, 2 and 4 mm. We grew the tree until a minimum size of 5 samples was reached at leaf nodes. We tested 5 randomly sampled features at each node. Bagging was used at both the slice and pixel levels, using 66% of the available images, and as many pixels per image as necessary in order to have a total of 25,000 training pixels. We tested our algorithm in two different scenarios: running it on all image pairs simultaneously, or on each image pair independently (i.e., with N = 1); the latter represents the common case that a user runs the algorithm on just a pair of images. In this case, we used 66% of the pixels to train each tree.\nIn the real data, we compared mutual information based registration with our approach, using all slices simultaneously in the synthesis. In order to put the MRI in linear alignment with the histological sections, we used an iterative approach very similar to that of Yang et al. (2012) . Starting from a stack of histological sections, we first rigidly aligned the brain MRI to the stack using mutual information. Then, we resampled the registered MR to the space of each histological section, and aligned them one by one using a similarity transform combined with mutual information. The registration of the MRI was then refined using the realigned sections, starting a new iteration. Upon convergence, we used the two competing methods to nonlinearly register the histological sections to the corresponding resampled MR images. We used the same parameters as for the experiment with the synthetic data, setting the control point spacing to the optimal values from such experiments (6 mm for the proposed approach, and 18 mm for mutual information; see Section 3.3.1 below); note that, for the manual landmarks, \u03c3 k = 0.5 mm was equivalent to 2.5 pixels at the resolution of this dataset."}, {"section_title": "Results", "text": ""}, {"section_title": "Synthetic data", "text": "Figures 4, 5 and 6 show the mean registration error as a function of the control point separation and the number of landmarks for three different levels of noise deformation: 10, 20 and 30 mm, which correspond to mild, medium and strong deformations, respectively. The mean error reflects the precision of the estimation, whereas the maximum is related to its robustness. When using mutual information, finer control point spacings in the deformation model yield transforms that are too flexible, leading to very poor results (even in presence of control points); see example in Figure 7 . Both the mean and maximum error improve with larger spacings, flattening out at around 18-20 mm.\nThe proposed method, on the other hand, provides higher precision with flexible models, thanks to the higher robustness of the intramodality metric. The two versions of the method (estimating the regressor one image pair at the time or from all images simultaneously) consistently outperform mutual information in every scenario. An important difference in the results is that the mean error hits its minimum at a much smaller control point spacing (typically 6 mm), yielding a much more accurate registration (see example in Figure 7) . Moreover, the maximum error has already flattened at that point, in almost every tested setting.\nIn addition to supporting finer control points spacings, the proposed method can more effectively exploit the information provided by landmarks. In mutual information based registrations, the landmarks guide the registration, especially in the earlier iterations, since their relative cost is high. But further influence on the registration (e.g., by improving the estimation of the joint histogram) is indirect and very limited. Our proposed algorithm, on the other hand, explicitly exploits the landmark information not only in the registration, but also in the synthesis: in Equation 13, the landmarks create a very sharp q distribution not only at pixels with landmarks, but also in the surroundings, thanks to the MRF (e.g., as in Figure 2d , Tag 1). Therefore, very similar shifted locations of these pixels are consistently selected when sampling for each tree of the forest, greatly informing the synthesis. This is reflected in the quantitative results: the gap in performance between the proposed method and mutual information widens as the number of landmarks N l increases.\nWhen no landmarks are used and image pairs are assessed independently, the proposed algorithm can be seen as a conventional inter-modality registration method. In that scenario, the results discussed above still hold: our method can be used at finer control point spacings, and provides average reductions of 11%, 22% and 15% in the mean error, at \u03c3 v = 10, \u03c3 v = 20 and \u03c3 v = 30, respectively. We also note that, as one would expect, our method and mutual information produce almost identical results at large control point spacings.\nFinally, we note a modest improvement is observed when image pairs are considered simultaneously -rather then independently. Nevertheless, the joint estimation consistently yields (d) and (e), the control point spacing was set to 6 mm. We have overlaid on all five images a manual outline of the gray matter surface (in red) and of the ventricles (in green), which were drawn using the T1 scan (b) as a reference. Note the poor registration produced by mutual information in the ventricles and cortical regions -see for instance the areas pointed by the yellow arrows in (d).\nhigher robustness at the finest control point spacing (3 mm), and also produces smaller errors across the different settings when the deformations are mild (Figure 4) . We hypothesise that, even though the simultaneous estimation has the advantage of having access to more data (which is particularly useful with more flexible models, i.e., finer spacing), the independent version can also benefit from having a regressor that is tailored to the single image pair at hand. Figure 8 shows a representative coronal section of the data, which covers multiple cortical and subcortical structures of interest (e.g., hippocampus, thalamus, putamen and pallidum). Comparing the segmentations propagated from the histology to the MRI with the proposed method ( Figure 8d ) and mutual information (Figure 8e) , it is apparent that our algorithm produces a much more accurate registration. The contours of the white matter surface are rather inaccurate when using mutual information; see for instance the insular (Tag 1 in the figure), auditory (Tag 2), or polysensoral temporal cortices (Tag 3); or area 36 (Tag 4). Using the proposed method, the registered contours follow the underlying MRI intensities much more accurately. The same applies to subcortical structures. In the thalamus (light purple), it can be seen that the segmentation of the reticular nucleus (Tag 5) is too medial when using mutual information. The same applies to the pallidum (Tag 6), putamen (Tag 7) and claustrum (Tag 8). The hippocampus (dark purple; Tag 9) is too inferior to the actual anatomy in the MRI. Once more, the proposed algorithm produces, qualitatively speaking, much improved boundaries."}, {"section_title": "Discussion and conclusion", "text": "In this article, we presented a novel method to simultaneously estimate the registration and synthesis between a pair of corresponding images from different modalities. The results on both synthetic (quantitative) and real data (qualitative) show that the proposed algorithm is superior to standard intermodality registration based on mutual information, albeit slower due to the need to iterate between registration and synthesisespecially the former, since it requires nested iteration of Equation 13. Our Matlab implementation runs in 2-3 minutes for images of size 256 2 pixels, but parallelised implementation in C++ or on the GPU should greatly reduce the running time.\nThe quantitative experiments demonstrated that our algorithm supports much more flexible deformation models than mutual informations (i.e., smaller control point spacing) without compromising robustness, attributed to the more stable intramodality metric (which we have made publicly available in NiftyReg). Moreover, the experiments on synthetic data also showed that our algorithm can more effectively take advantage of the information encoded in manually placed pairs of landmarks, since this can be exploited in both the registration and synthesis, which inform each other in the model fitting. The more landmarks we used, the larger the gap between our method and mutual information was -however, we should note that, in the limit, the performance of the two methods would be the same, since the registration error would go to zero in both cases.\nWe must note that, in the experiments with synthetic data, the relative contributions of the data terms in Equations 18) and 19 are slightly different, since computing the value of \u03b1 that makes these contributions exactly equal is very difficult. However, the minor differences that our heuristic choice of \u03b1 might introduce do not undermine the results of the experiments, since the approximate effect of modifying \u03b1 is mildly shifting the curves in Figures 4-6 to the left or right -which does not change the conclusions.\nOur method also outperformed mutual information when applied to the data from the Allen Institute, which is more challenging due to the more complex relationships between the two contrast mechanisms, and the presence of artefacts such as cracks and tears. Qualitatively speaking, the superiority of our approach is clearly apparent from Figure 9 , in which it produces a much smoother segmentation in the orthogonal planes. We note that we did not introduce any smoothness constraints in the reconstruction, e.g., by forcing the registered histological sections to be similar to their neighbours, through an explicit term in the cost function of the registration. Such a strategy would produce smoother reconstructions, but these would not necessarily be more accurate -particularly if one considers that the 2D deformations fields of the different sections are independent a priori, which makes the histological sections conditionally independent a posteriori, given the MRI data and the image intensity transform. Moreover, explicitly enforcing such smoothness in the registration would preclude qualitative evaluation through visual inspection of the segmentation in the orthogonal orientations.\nThe proposed algorithm is hybrid in the sense that, despite being formulated in a generative framework, it replaces the likelihood term of the synthesis by a discriminative element. We emphasise that such a change still yields a valid objective function (Equation 10) that we can approximately optimise with VEM -which maximises Equations 11 and 12 instead. The VEM algorithm alternately optimises for q and \u03b8 in a coordinate descent scheme, and is in principle guaranteed to converge. In our method, we lose this property due to the approximate opti- misation of the random forest parameters, since injecting randomness is one of the key elements of the success of random decision trees. However, in practice, our algorithm typically converges in 5-6 iterations, in terms of changes in the predicted synthetic image (i.e., in \u00b5 nx and \u03c3 2 nx ). Our approach can also be used in an online manner, i.e., if data become progressively available at testing. For example, the random forest could be optimised on an (ideally) large set of images, considering them simultaneously in the framework. Then, when a new pair of images arrives, one can assume that the forest parameters are fixed and equal to\u03b8, and proceed directly to the estimation of the synthetic image \u00b5 1x , \u03c3 2 1x and deformation field\u00db 1 . An alternative would be to fine tune \u03b8 to the new input, considering it in isolation or jointly with the other scans. But even if no other previous data are available (i.e., N = 1), the registration uncertainty encoded in q prevents the regression from overfitting, and enables our method to still outperform mutual information. This is in contrast with supervised synthesis algorithms, which cannot operate without training data.\nFuture work will follow four main directions. First, integrating deep learning techniques into the framework, which could be particularly useful when large amounts of image pairs are available, e.g., in a large histology reconstruction project. The main challenges to tackle are overfitting and avoiding to make the algorithm impractically slow. A possible solution to this problem would be to use a pretrained network, and only update the connections in the last layer during the analysis of the image pair at hand (e.g., as in Wang et al. 2017) . A second direction of future work is the extension of the algorithm to 3D. Albeit mathematically straightforward (no changes are required in the framework), such extension poses problems from the practical perspective, e.g., the memory requirements for storing q grow very quickly. A third avenue of future work is the application to other target modalities, such as optical coherence tomography (OCT). Finally, we will also explore the possibility of synthesizing histology from MRI. This a more challenging task that might require multiple input MRI contrasts, depending on the target stain to synthesise. However, synthetic histology would not only provide an estimate of the microanatomy of tissue imaged with MRI, but would also enable the symmetrisation of the framework presented in this article; by computing two syntheses, the robustness of the algorithm would be be expected to increase.\nThe algorithm presented in this paper represents a significant step towards solving the problem of aligning histological images and MRI, by exploiting the connection between registration and synthesis within a novel probabilistic framework. We will use this method to produce increasingly precise histological reconstructions of tissue, which in turn will enable us to build probabilistic atlases of the human brain at a superior level of detail."}]