[{"section_title": "Abstract", "text": "Abstract: Change in a quantitative trait is commonly employed as an endpoint in two-wave longitudinal studies. For example, early phase clinical trials often use two-wave designs with biomarker endpoints to confirm that a treatment affects the putative target treatment pathway before proceeding to larger scale clinical efficacy trials. Power calculations for such designs are straightforward if pilot data from longitudinal investigations of similar duration to the proposed study are available. Often longitudinal pilot data of similar duration are not available, and simplifying assumptions are used to calculate sample size from cross-sectional data, one standard approach being to use a formula based on variance estimated from cross sectional data and correlation estimates abstracted from the literature or inferred from experience with similar endpoints. An implicit assumption of this standard approach is that the variance of the quantitative trait is the same at baseline and follow-up. In practice, this assumption rarely holds, and sample size estimates by this standard formula can be dramatically anti-conservative. Even when longitudinal pilot data for estimating parameters required in sample size calculations are available, sample size calculations will be biased if the interval from baseline to follow-up is not of similar duration to that proposed for the study being designed. In this paper we characterize the magnitude of bias in sample size estimates when formula assumptions do not hold and derive alternative conservative formulas for sample size required to achieve nominal power."}, {"section_title": "INTRODUCTION", "text": "Quantitative traits are commonly employed as endpoints in phase II clinical trials. In Alzheimer's disease, recent efforts have focused on changes in biomarkers as a means of studying disease progression and drug efficacy, and as an aid to diagnosis and early decision-making in the evaluation of clinical interventions for chronic, debilitating and degenerative disease [1] [2] [3] [4] . The ongoing process of identifying and validating biomarkers for use as surrogate endpoints, and more generally the quality and informativeness of research outcomes derived from the analysis of such endpoints, require that these trials be adequately powered.\nPower and sample size calculations for two-wave (baseline and one follow-up) designs using quantitative endpoints are straightforward if pilot data from longitudinal investigations of similar duration to the proposed study are available. In this case the variance of change scores, 2 d(t), can be estimated from pilot *Address correspondence to this author at the Biostatistics Division, Dept. of Family and Preventive Medicine, Professor, Dept. of Neurosciences, University of California, San Diego, 8900 Gilman Dr., La Jolla, CA 92098, USA; Tel: 858-246-1250; Fax: 858-246-1287; E-mail: sedland@ucsd.edu Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.ucla.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.ucla.edu/wpcontent/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf data, and supplied to the usual two-sample normal approximation formula for calculating sample size requirements for a t-test of no treatment effect against a non-directional alternative hypothesis:\nwhere nt is the number of subjects required per study arm for a trial of duration t,\nis the within-group variance of the change in measurements from baseline to follow-up for a study of duration time t, -1 (p) is the quantile function of the standard normal distribution, and are the Type I and Type II error rates, and (t) is the magnitude of the between-group difference in mean change from baseline to follow-up time t that the investigator wishes to be able to detect with probability 1 -.\nLongitudinal pilot data are required to estimate the variance term, \nand the value obtained from equation (2) can then be used in place of\n, that is, if there is compound symmetry of the covariance matrix of the baseline and follow-up (time t) measurements, then equation (2) reduces to:\nAs was the case with equation (2), the result of equation (3) can be substituted directly into equation (1) , but this is valid only when\nEquation (3) is presented, for example, in Meinert [5] (equation 9.14), Lachin [6] , Overall and Doyle [7] , and Overall & Starbuck [8] . In all cases the formula is presented with no discussion of what the assumption that 2 (t) = 2 (0) implies about the data generating process, or of the consequences of making this assumption in error. This is potentially problematic, because applying equation (3) when compound symmetry does not hold can lead to dramatic underestimation of the required sample size. For chronic progressive disease in particular, persons tend to progress at different rates, so that trajectories of progression tend to fan apart and the variance of measurements of disease severity increase as the cohort is followed over time [9] . If the interval from baseline to follow-up is sufficient, there may be a substantial increase in variance from baseline to followup and a substantial underestimation of required sample size by equation (3).\nA similar danger arises when the researcher has direct access to longitudinal pilot data or is able to abstract relevant parameters from a published longitudinal study, but the duration t of the planned trial exceeds the duration, s say, of the available pilot data. Here, again, if longitudinal trajectories fan apart, then In this paper we illustrate analytically and by way of example the potential magnitude of underestimation in sample size calculations by naively applying equation (3) when the assumption that 2 (t) = 2 (0) does not hold (Section 2). We also demonstrate that even when longitudinal pilot data are available for estimating parameters used in sample size calculations, these estimates and resulting sample size calculations can be biased if the interval from baseline to follow-up is not of similar duration to that proposed for the trial (Section 3). Section 3 will also derive conservative upper bounds on required sample size useful for sensitivity analyses when adequate pilot data are not available for planning a future trial."}, {"section_title": "BIAS IN SAMPLE SIZE CALCULATIONS WHEN THE 2 (t) = 2 (0) ASSUMPTION DOES NOT HOLD", "text": "Letting nt represent the true required sample size per arm for a study of length t and denoting the estimate obtained using equation (3) as nt (3) , for a given effect size and Type I and Type II error probabilities, the extent to which nt (3) underestimates nt, expressed as a percentage of the true required sample size is given by:\nNote that 2 (0t) -1 1, so that the numerator terms in equation (4) are always greater than zero, and hence nt (3) underestimates the true required sample size,"}, {"section_title": "Example", "text": "To illustrate, we present examples of sample size calculations for a hypothetical phase II clinical trial in Alzheimer's disease. Longitudinal data excerpted from the Alzheimer's Disease Neuroimaging Initiative (ADNI) cohort study are used to inform power calculations. ADNI is a joint government, private pharmaceutical, and non-profit initiative to determine promising markers of early AD progression and aid researchers and clinicians in developing effective therapies. The ADNI cohort is a longitudinal observational study that is by design representative of subjects eligible for recruitment to Alzheimer's disease treatment trials [10] . Baseline and 12-month follow-up data were accessed from this publically available dataset [10] [11] ), two potential endpoints for a phase II trial of an Alzheimer's disease treatment, are summarized in Table 1 . Subjects with an Alzheimer diagnosis at baseline and data at both baseline and 12-month time points were included in the calculations. The variance is larger at follow-up than at baseline for both outcomes, as expected for longitudinal measurements of a chronic progressive disease. The parameter estimates in Table 1 were used to calculate sample size to obtain 80% power to detect (t) equal to a 25% reduction of ventricular enlargement relative to that observed in the ADNI cohort placebo condition pilot data, and likewise to calculate sample size to obtain 80% power to detect a 25% slowing of rate of progression on the ADAS-cog relative to placebo, using both the na\u00efve but biased estimate of 2 d(t) (equation (3)) and the appropriate estimate of 2 d(t) (equation (2)). Sample size estimates resulting from naively using equation (3) (1) would lead us to conclude that a sample size of 96 per arm would be sufficient to ensure power = 0.8 to detect a 25% reduction in the rate of ventricular volume increase, whereas the actual required sample size, derived using equation (2) , would be 195 subjects per arm. For the ADAS-cog data, these values are 356 and 719, respectively. These sample calculations are for illustrative purposes only. Power calculations for an Alzheimer treatment trial involve additional considerations, including but not limited to calculating bootstrap confidence intervals about sample size estimates acknowledging the uncertainty in population parameters supplied to the power formula [12, 13] ."}, {"section_title": "POTENTIAL BIAS WHEN PILOT DATA ARE INCONSISTENT WITH PLANNED TRIAL DESIGN", "text": "If researchers have access to pilot data or summary statistics from a study of comparable duration to the planned trial, a valid estimate of the required sample size can be determined using equation (2) \nWhile the specification of conditions that are both necessary and sufficient for equation (5) to take values greater than zero is somewhat more involved than was the case with equation (4), it can be shown, for example, that nt [s] will be anti-conservative for data (3); %Underestimation = underestimation of the required sample size per arm by use of equation (3), expressed as a percent. generated by the familiar mixed effects model with linear trajectories fanning apart over time and i.i.d. residual error, or whenever both: 1)\nand 2) 0 (0t) (0s) (Appendix).\nLacking pilot data consistent with the planned trial, there are several alternative approaches. If longitudinal data with more than two waves of observation are available, then power calculations can be performed under the assumption of a linear mixed effects model with correlated random intercepts and slopes [12] , a flexible yet parsimonious analytic framework for longitudinal data that is well-suited to situations where variances are expected to increase (and correlations are expected to decrease), as the study duration is extended. However, if only two-wave pilot data are available and the duration of pilot data observation is different (typically shorter than), the duration proposed for the planned trial, the variance components from the correlated random intercepts and slopes variant of the linear mixed effects model are not identifiable, and calculation of the required sample size per arm is not possible. Nonetheless, the linear mixed effects model can still be relied upon to motivate solutions for the required sample size per arm that are guaranteed to be conservative under certain conditions. We offer here two power formulas that provide conservative overestimates of required sample size when the duration of pilot data is less than the duration of the planned trial."}, {"section_title": "Conservative Formula 1", "text": "Under the linear mixed effects model, the variance of change from baseline to follow-up \nFor t > s, the second term is greater than or equal to zero, and therefore:\nis an overestimate of 2 d(t), and power calculations by equation (1) with\nwill be conservative overestimates of required sample size to achieve power (1 -)."}, {"section_title": "Conservative Formula 2", "text": "Alternatively, under the linear mixed effects model, the variance of change from baseline to follow-up \nFor ab > 0 and t > s the final term is greater than or equal to zero, and therefore:\nis an overestimate of 2 d(t), and power calculations by equation (1) with\nwill yield conservative overestimates of required sample size to achieve power (1 -) . Note that the solution is exact, i.e.,\nSince both equation (7) and equation (9) yield exact or conservative solutions for required sample size under the linear mixed effects model assumption when the covariance of the random intercept and slope coefficients is non-negative, the smallest sample size estimate of the two calculated sample sizes, i.e., the one using min [\n, is to be preferred under these conditions."}, {"section_title": "DISCUSSION", "text": "Considerable costs can be incurred when time and resources are allocated to an otherwise well conceived but underpowered study. Investigators may therefore wish instead to opt for a conservative solution to the problem at hand, i.e., one that results in a trial with greater than nominal power. In the absence of longitudinal pilot data, there is little information and little recourse for powering longitudinal trials. We recommend against using equation (3) however, and rather suggest using equation (2) to estimate the variance for sample size calculations when balanced two-wave pilot data is available, because equation (2) requires you to explicitly acknowledge the unknown parameters and therefore provide estimates for these parameters to the sample size formula. For the case where longitudinal pilot data of length s < t are available, we have provided conservative formulas for sample size calculation for trials of length t that are valid under the modest assumption that the data derive from a mixed effects model with linear longitudinal trajectories that are fanning apart. Anti "}, {"section_title": "Leads to AntiConservative Sample Size Estimation", "text": ""}, {"section_title": "When Data are Generated by a Linear Mixed Effect Model", "text": "We begin by introducing notation for two-wave data generated by the mixed effects model commonly applied to longitudinal data from clinical trials and cohort studies. Let y i be observations on some random variable of interest that follow the linear mixed effects model with bivariate normal random intercept and slope coefficients and i.i.d. residual error: \nHere and represent the fixed intercept and slope terms (rather than the Type I and Type II error probabilities), respectively, ai and bi are their random counterparts for subject i, and the e i are i.i.d. residual error terms specific to subject i at time . For two-wave data, will typically only take on two values by design, e.g., zero at baseline and t at follow-up for a trial of length t, or zero at baseline and s at follow-up for a trial of length s. It follows from equations (A1) and (A2) that for any : To show that equation (5) is greater than zero, and hence that nt we need to prove that the numerator of equation (5) "}]