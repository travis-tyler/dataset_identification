[{"section_title": "Abstract", "text": "Abstract-Many brain disorders and diseases exhibit heterogeneous symptoms and imaging characteristics. This heterogeneity is typically not captured by commonly adopted neuroimaging analyses that seek only a main imaging pattern when two groups need to be differentiated (e.g., patients and controls, or clinical progressors and non-progressors). We propose a novel probabilistic clustering approach, CHIMERA, modeling the pathological process by a combination of multiple regularized transformations from normal/control population to the patient population, thereby seeking to identify multiple imaging patterns that relate to disease effects and to better characterize disease heterogeneity. In our framework, normal and patient populations are considered as point distributions that are matched by a variant of the coherent point drift algorithm. We explain how the posterior probabilities produced during the MAP optimization of CHIMERA can be used for clustering the patients into groups and identifying disease subtypes. CHIMERA was first validated on a synthetic dataset and then on a clinical dataset mixing 317 control subjects and patients suffering from Alzheimer's Disease (AD) and Parkison's Disease (PD). CHIMERA produced better clustering results compared to two standard clustering approaches. We further analyzed 390 T1 MRI scans from Alzheimer's patients. We discovered two main and reproducible AD subtypes displaying significant differences in cognitive performance."}, {"section_title": "Fig. 1. (a) The problem setting:", "text": "is the reference distribution and is the patient distribution. (b) Our model assumption:\nis transformed into a distribution covering the distribution , by a set of different transformations.\nold and young subjects [2] , for describing brain development, by comparing subjects of different ages [3] , amongst many other studies. Statistical group analyses are ubiquitous throughout studies using diverse types of images, including functional MRI [4] , structural MRI [5] - [7] , and diffusion tensor imaging [8] .\nMost of the group analyses assume that the members of a group share a common imaging pattern that differentiates them from the other group. For example, they assume that there is a unique disease effect that is found by comparing patients and controls. However, various clinical studies have highlighted the heterogeneity of pathological phenotypes presented by many diseases, such as Alzheimer's disease [9] , Schizophrenia [10] , Autism spectrum disorder [11] , Attention-deficit hyperactivity disorder [12] and Cancer [13] , [14] . Current approaches, by ignoring the heterogeneity of the disease phenotype, miss crucial information when modeling disease effects.\nDisease heterogeneity can be addressed by partitioning the population of patients with clustering methods [15] - [18] . However, direct clustering of patient images puts emphasis on the similarities/distances between individuals, rather than on heterogeneity of the disease effect itself. Hence, they produce clusterings reflecting the largest contributors of data variability such as brain sizes, participant sex, and scanner/protocol discrepancies, and may fail to cluster the individuals according to their pathology subtypes.\nIn this work, we propose to address this issue with a novel, regularized, clustering method based on mapping of statistical distributions. We assume that there is a reference distribution, such as normal controls, cognitively stable, normal brain development, etc., and that there is a patient distribution caused by heterogeneous effects that we would like to describe: heterogeneous disease effects, or pathologies leading to cognitive decline, deviations from normal brain development, etc. As shown in Fig. 1 , we model the heterogeneous effects as a set of transformations from the reference to the patient distribution, where each transformation corresponds to one pathology subtype. The transformations are found by matching patient and reference distributions while taking covariates such as age, sex, scanner, etc. into account. (Which exactly covariates are to be used depends highly on the specific application/study.) Specifically, given that a 70-year-old male Alzheimer disease patient would have been a 70-year-old male control had he been spared from the disease, the transition between these two states is considered to be the disease effect. This covariate-informed matching reduces the confounding influence of the covariates, which leads to a better description of the disease effects.\nThe remainder of this paper is organized as follows. In Section II, we explain how our clustering method CHIMERA was derived from the Coherent Point Drift algorithm [19] and how the proposed objective can be optimized in an Expectation-Maximization framework [20] , [21] . The method was first validated by carrying out simulations and then used for processing two large clinical datasets (317 and 390 T1 MRI scans). The results presented in Section III demonstrate the superiority of CHIMERA, compared to -means, hierarchical clustering and two of their variations. The subtypes of AD revealed by our method using a large collection of Alzheimer's Disease MRI data are discussed in Section IV, along with discussion of the merits and limitations of CHIMERA for the study of complex brain diseases."}, {"section_title": "II. METHOD", "text": "Let us assume that the dataset contains normal control (NC) samples and patient samples . Let us assume that the samples are described by two sets of features: a set of -dimensional imaging features:\n; and a set of -dimensional covariate features (these are known variables, such as age, sex, tumor type, treatment type):\n. For the sake of simplicity, we will denote the samples in the compact vector forms:\n, . We adopt a generative probabilistic framework. Considering the samples as points in the imaging space (Fig. 1) , the pathology can be viewed as the difference between (patient) and (NC) point distributions. Here, we model the pathological transition between the two groups as a transformation from NC to patient distribution. When enough NC points have been collected for describing the NC population, we could assume that the estimated anatomy of patients, had they been spared of the disease, is covered by the NC distribution. Assuming that all the patients can be associated with NCs and that, conversely, the transformed NC points cover the entire set of patients, the transformation is found by matching patient and NC distributions. Covariates are introduced into the distribution matching criteria by combining imaging and covariate-specific distances in a multi-kernel way [22] .\nThe maximum a posteriori(MAP) optimization of the model leads to minimize the following energy :\nwhere denotes the parameters of our model, such as transformations that are applied to for generating , the log-likelihood of the distributions and given the parameters and a regularization/penalty improves the stability/reliability of the estimation. These two parts are presented in detail in the next two sections."}, {"section_title": "A. Log-Likelihood Term", "text": "Due to the heterogeneity of the effects of a given disease, the pathological transition might take several directions. Therefore, consists of multiple possible transformations, each of them representing a pathological direction of imaging change. The transformed NC samples are denoted as , where the imaging feature is transformed to and the covariate feature remains the same.\nBased on the hypothesis that the origins of patient samples are covered by the NC sample space, we assume that if we apply the pathological process to the NC samples , the transformed NC point distribution will cover the patient point distribution , as shown in Fig. 1(b) .\nThe matching of distributions and is found by a variant of Coherent Point Drift [19] . Each point is considered as a centroid of a spherical Gaussian cluster. All the clusters are assumed to have the same variance that is optimized by the method. Points are treated as i.i.d. data generated by a Gaussian Mixture Model (GMM) with equal weight for each cluster. The similarity between the two distribution is measured by the data likelihood of this mixture model, as presented in (3) .\nIn order to take covariate features into account, we adopt a multi-kernel setting. The distance between two points are measured by RBF kernels, where the kernel size of covariate features is times larger than the kernel size of the imaging features. As a result, the likelihood of data generated by centroids can be described as follows:\nDuring our experiments, was determined by the ratio of total variance of these two features. We assume that there are pathology directions for a given disease. We define the transformation for one NC point to the patient space as: (4) Ideally, if the disease subtypes were distinct, should take value 1 for the transformation corresponding to the disease subtype that affects , and value 0 otherwise. In this work, we as-sume that patients with different pathologies might correspond to the same point in the space of NC distribution and we relax the variable to sum up to 1 for each . This relaxation leads us to consider the transformation for each NC point as a convex combination of all possible transformations .\nFor the , linear transformations were chosen, in order to derive analytical solutions for the distribution matching. Each was described by a pair of parameters :\nwhere and for all . During our experiments, three different kinds of matrices were chosen: (1) full matrices (CHIMERA-affine), (2) diagonal matrices, in order to restrict the transformations to the combinations of scaling and translations (CHIMERA-duo) and (3) the identity, in order to consider only the translations (CHIMERA-trans).\nIntroducing this definition of the into (3) leads to the following expression for the log-likelihood of the data:"}, {"section_title": "B. Model Regularization", "text": "In an imaging feature space of dimension , the dimension of parameter space of CHIMERA-affine is to the order of , while for CHIMERA-duo and CHIMERA-trans to the order of . In the low sample size settings that are typically observed in medical imaging studies, this large dimension yields ill posed problems. This issue is commonly mitigated by regularizing/penalizing the parameters of the transformations [23] , [24] . We have adopted this approach, which improves also the generalization and the robustness of our model. In order to derive an analytical solution, we have chosen to penalize the Frobenius norm of and the norm of , where is an identity matrix. This regularization, is equivalent to posing Gaussian priors for the parameters. Beside the explicit regularization term , our model can also be considered as being \"implicitly\" regularized. Instead of focusing on the points at the border between the different groups, like support vector machine [25] and relevance vector machine [26] , our model always consider the entire point distributions. We aim, in that way, to reduce the sensitivity of clustering produced with respect to the individual subject variability.\nThe next section describes the MAP estimation strategy that was adopted for optimizing our model."}, {"section_title": "C. Optimization", "text": "In this work, we have used an Expectation-Maximization algorithm [20] , [21] for optimizing the parameters of our model, where and . The algorithm introduces latent variables indicating the posterior probability of data point for each mixture component,\n. By doing so, it provides a lower bound of the log-likelihood [21] . (8) The energy is minimized via an iterative scheme. In each iteration , the algorithm alternates calculating the expected value of with respect to parameter obtained in last iteration in E-step, and updating by minimizing the objective function ( (10)) in M-step.\nDuring our experiments, at the initialization, the parameters was set to the mean distance between dataset and , to be uniform distributed for each , each to be identity matrix , and the translation term was sampled from a normal distribution\n. The E-step and M-step were performed as follows."}, {"section_title": "1) E-", "text": "Step: Using parameters evaluated in previous M-step, (8) was optimized at :\n2) M-Step: We constructed our objective energy function as an upper bound of our energy function . The minimization of leads to the minimization of , which is proved in [27] . (10) subject to\nThe objective function is not globally convex but jointly convex in each parameter. Hence we propose an iterative procedure by minimizing the objective sequentially with respect to , , and . We derived closed form solution for , and by setting derivative of objective function to zero. was optimized using an advanced projected gradient descent algorithm that preserves the sum of the [28] . The detailed parameter updating procedures are presented in Appendix A.\nDuring our experiments, we stopped the iteration when the objective difference between two iterations reached a predefined tolerance, that was set to 0.01. Because the EM algorithm only guarantees a local minimum solution, we ran the optimization several times and we kept the solution with the smallest energy value.\nThe next section explains how a clustering can be derived from the coefficients and the posteriors found during the optimization, and how a new sample can be assigned to these clusters."}, {"section_title": "D. Clustering", "text": "The coefficients can be considered as the probability, for the NC sample , to undergo the transformation . Let be the likelihood of a patient sample to be associated with . Then, the likelihood of a given patient sample, , to have been generated by the transformation can be estimated by: (11) Because the posteriors are proportional to , with a common denominator for each ( (9)), they can be used for partitioning the patient samples according to their main transformation, by choosing for each patient the label corresponding to the largest likelihood: (12) As long as the are stored, the label can be estimated for a novel data by: (1) computing the likelihood based on distances between the novel sample and the transformed controls , (2) computing and obtaining the label . This strategy was adopted for clustering clinical data during our experiments."}, {"section_title": "III. EXPERIMENTS AND RESULTS", "text": "This section presents the experiments that were conducted for validating our approach. We compared first our approach with two standard clustering methods, -means [15] and hierarchical Ward clustering [17] , and two variants of these methods, on synthetic data and a real dataset of dementia patients with known subtypes. The promising results obtained incited us to analyze a clinical dataset where the ground truth is unknown.\nWe used CHIMERA for clustering a population of AD patients extracted from the ADNI dataset 1 . Our analysis revealed two stable/reproducible subtypes that are strongly specific of AD according to prior clinical studies, while exhibiting distinct imaging patterns and clinical profiles, as if they were corresponding to distinct pathological trajectories. Detailed investigations that are outside the scope of this paper will be carried out in the future for elucidating all the medical implications of this finding."}, {"section_title": "A. Simulated Data", "text": "Our method was first validated using synthetic data simulating the effect of age and disease on brain volume.\nThe brain was divided into 20 regions (ROIs), where the atrophy was described by a normalized volume between 0 (the most serious atrophy) and 1 (largest possible ROI volume).\nThe simulated data was generated as follows: 1) 1000 samples were generated independently. For each sample, 20 ROI volumes were sampled randomly from a normal distribution, . In addition, each sample was associated with a random age, sampled from a uniform distribution between 55 and 85. 2) Age effect was introduced for each ROI volume and every sample, by subtracting the atrophy volume. The ROI volume atrophy was simulated by a normal distribution , where is the age. This simulation corresponds to a linear volume decrease with age of slope 0.01 per year ; and a variance increase of slope 0.005 per year.\n3) The samples were randomly separated into two 500-sample groups, a control group and a patient group. The patient group was further divided into two sub-groups of 250 samples. In each patient group we introduced an atrophy pattern induced by a 15% decrease in volume in pre-selected regions. Some of the regions selected were common across the subgroups while some others were distinct. This was done to simulate the effect of two distinct but overlaping variants of a same neurodegenerative disease. The two atrophy patterns are presented in Fig. 2 . 4) The ROIs volumes were then normalized independently, by scaling them between 0 (the most atrophied sample ROI volume) and 1 (the largest sample ROI volume). The simulated data with age effect is plotted in Fig. 3 . For both groups, the normalized total volume decreases as age increases. Patient group has smaller total volume due to the disease effect. But as the variance increases, the disease effect is overwhelmed by the age effect.\nWe compared our model with -means [15] clustering and Ward hierarchical clustering [17] . However, standard clustering methods do not have access to the information of control group as CHIMERA does. For fair comparison, we considered therefore two supplementary variants of these clustering methods. Similar to pattern-based morphometry [29] , we computed a \"profile\" for each patient subject: we computed the difference vector between each patient point and its Euclidean nearest neighbor in the control group. These profiles were clustered instead of the original patient data. In these analysis, a general linear regression(GLM) [30] was performed on the imaging features for removing the age effects prior to the clustering. The three variants of our method were applied to the synthetic data. We set model parameters as follows, CHIMERA-affine:\n; CHIMERA-duo: ; CHIMERA-trans: . The simulation was repeated 100 times independently. All the methods were applied on each simulated data set, with . The Dice score [31] of overlap between the ground truth and the clustering labels were generated for each run, and the box plots for different methods are presented in Fig. 4 . Given that the dice score is 0.5 when the labels are assigned randomly, our method performs better than clustering methods and their profile-based variations. CHIMERA-duo outperformed the other CHIMERA variants. This result indicates that CHIMERA-duo model contains enough degrees of freedom for capturing the differences between patient and control groups that cannot be expressed as a pure translation. In the meantime, the model is much smaller than the affine model, that is hard to regularize. "}, {"section_title": "B. Dementia Dataset", "text": "Before using our method for exploring unknown heterogeneous imaging patterns, we validated our approach on a dementia dataset containing patients suffering from different diseases generating distinct imaging patterns. We used a dementia clinical dataset of 317 T1 structural MRI scans corresponding to 148 Alzheimer's Disease (AD) patients, 91 Parkinson's Disease (PD) patients and 78 Normal Controls (NC). The images were skull-stripped, co-registered and Multi-Atlas ROIs were generated [32] , [33] . The volumes of 80 ROIs were calculated, as well as the volume of brain lesions that they contain [34] . Age and gender of each subject were utilized as covariate features.\nThe performances of the seven methods described in Section III-A were estimated by performing one hundred 10-folds cross-validations on the dataset. For each cross-validation, the patient samples were partitioned randomly into 10 folds. For each fold, the clustering was first established by using normal control samples and the remaining 90% patients. The 10% test samples of the fold were then assigned clustering labels. For -means and Hierarchical clustering, the assignment was based on the distance to cluster centers; for our approach, the assignment procedure is explained in Section II-D. After this assignment, the dice score between the known subtype labels and the labels produced by the clustering methods was computed for the samples of the fold. A dice score for the entire cross-validation was obtained by averaging the dice scores obtained for the ten folds. Running the cross-validation one hundred time with different partitions of the patient data produced the distribution of dice scores shown in Fig. 5 . There is a significant performance gap between our approach and standard clustering methods. CHIMERA-duo and CHIMERA-trans worked comparably well, while the performance of the CHIMERA-affine model were a little lower.\nThis experiment confirms that our approach can identify distinct imaging patterns corresponding to clinically heterogeneous populations using real imaging data. We finally used CHIMERA for investigating the existence of subtypes of Alzheimer's Disease. We used CHIMERA-duo for this task, because this variant has the best trade-off between model complexity and generalization performances. 6 . Reproducibility measured by the average Adjusted Rand Index [35] , for all the number of cluster tested, and all the sparsity parameter . The median average ARI corresponding to a same were connected for improving the visualization of the trends."}, {"section_title": "C. Alzheimer's Disease Dataset", "text": "We analyzed the heterogeneity of Alzheimer's Disease by applying CHIMERA-duo to ADNI dataset of 390 T1 structural MRI scans with 177 AD patients and 213 Normal Controls. Similar to the preprocessing in Section III-B, the volumes of 80 ROIs were calculated. Age and gender information were utilized as covariate features.\nThe model parameters, (number of sub-clusters) and , (parameters of the regularization term), were selected according to the reproducibility and data fit of the clustering outputs. We observed that when the ratio between and is too large, the transformations are relatively unconstrained, which leads to poor convergence. Small ratio, on the contrary, let the transformation degenerate into a pure translation, which is not desirable either. We empirically fixed this ratio as follows:\n. The reproducibility was measured by the Adjusted Rand Index(ARI) [35] (Appendix B), which were extensively cross-validated. We ran experiments for ,3,4 clusters, and 35. For each combination of and , 100 runs of leave-10%-out clusterings were performed. During each clustering, a random subset of 90% of the patient samples and all the normal control samples were used for generating the transformations and defining the patient clusters. The remaining 10% patient samples were assigned to the group found, based on their proximity with the transformed control, as explained in the Section II-D.\nWe measured the ARI between all the pairs of the 100 clusterings obtained for each parameter value, and averaged the ARI for each clustering. The complete results are shown in Fig. 6 . When increases, more transformation parameters are required ( ). Small s lead to ill-conditioned optimization that do not converge. This is for instance the case when and . On the other hand, large result in null/small transformations that are close to the identity, which is not desirable. For these reasons, smaller are preferable when the reproducibilities are comparable.\nWe finally selected ( , ), a set of parameters corresponding to a high reproducibility for a reasonable good data fit. In order to analyze the subtypes found by our method in detail, we selected the clustering providing the highest sum of ARI with the other clusterings, among the hundred clusterings associated with this set of parameters. This clustering is the medoid of the clusterings produced, and therefore the most reliable.\nIn this clustering, 177 AD patients are clustered into two subgroups: subgroup 1 with 91 subjects and subgroup 2 with 86 subjects. In order to reveal detailed disease signatures, we performed ROI-wise -test for each subgroup against the control group, as well as the subgroups against each other. In Fig. 7 , the -stats for the ROIs are displayed in a heat map, thresholded at level of FDR adjusted -value 0.01. Red color indicates when the first group has more volume than the last group. The opposite is indicated with blue color. The correspondence between the ROIs' names and labels is displayed in Table I [33] .\nAs shown in Fig. 7 row (a) and (b), both patient subgroups present brain volume loss compared to normal controls, in regions including the temporal and limbic lobe, which are typical atrophy regions observed in Alzheimer's disease [36] - [39] . Also, both subgroups have larger ventricle volumes as compared to the control group. However, as shown in row (c), these two subgroups present significant between group differences in the following regions: 1) Subgroup 1 has more gray matter atrophy in limbic lobe including amygdala and hippocampus (5, 6, 15, 16) , and frontal insular regions (52,67). This atrophy pattern has been related to AD by many clinical studies, such as [39] . 2) Subgroup 2 exhibits unique parietal and occipital gray matter atrophy on both lateral and medial structures (59-62,74-77). These atrophy patterns have also previously been noted in the literature [38] - [40] . Some reports have linked posterior cingulate and precuneous atrophy to early onset AD [41] , [42] . 3) Subgroup 1 exhibits unique deep gray matter atrophy in basal ganglia (3, 4, 8, 9, (21) (22) (23) (24) , a region that was also related to AD, for instance by Teipel et al. [43] . We performed a Voxel-Based Morphometry [44] on gray matter for each subgroup against the control group using the RAVENS maps that were generated during the co-registration [32] . RAVENS maps measure the tissue density of a brain with respect to a template [45] , [46] . The -stats map thresholded by FDR adjusted -value 0.01 are presented in Fig. 8 . We have circled out the significant different regions as discussed.\nA statistical analysis was carried out for determining if the two subgroups exhibit different clinical cognitive performance. We used MMSE score [47] , ADAS-cog 11 score and ADAS-cog 13 score in this analysis. The score distributions, that are not Gaussian, were compared by a rank sum test [48] . The results are displayed in Table II . The subgroup 1 performed significantly worse than subgroup 2 in ADAS-cog test. The difference is less noticeable for the MMSE test. We performed a rank sum test for comparing the age distribution in the two groups. Subgroup 1 appeared to be slightly older than subgroup 2, but the test does not reach significance at the . Table I . These findings indicate that our method has extracted distinct patterns of atrophy that have been previously implicated in Alzheimer's disease. Interestingly, the posterior cingulate/precuneous atrophy has been previously hypothesized to relate to early rather than late onset AD [41] , which might imply that our identified 2 clusters also differentiate early vs. late onset patients. "}, {"section_title": "IV. DISCUSSION", "text": "We have proposed a new approach, CHIMERA, for identifying disease subtypes of heterogeneous diseases. Our approach relies on a point distribution mapping, while allowing the to reduction of the influence of nuisance covariates. The approach adopted overcomes several methodological limitations of existing methods for the analysis of disease heterogeneity. We discuss here three main aspects that have not been presented in detail in the previous sections. We also discuss a way to address the main limitation of our current framework.\nFirst, the soft assignment performed by our model provides a rich information about the pathology. Each normal/control point is transformed with a probability distribution by all possible transformations. This notion implies that a healthy subject might transition to a diseased state via various pathological patterns/processes. The clustering of patients is based on the posterior probability and . Instead of a hard assignment for clustering outputs, our approach produces probability soft assignment which might better describe the disease effects.\nSecond, the framework is modular. In this work, we have used a linear transformation with scaling and translation that has degrees of freedom. Since the sample sizes of most neuroimaging studies are relatively small, we might improve the performance of the model by choosing a more constrained transformation. For instance, the transformation could be represented by the displacement of a few reference samples [19] . Such transformation would exhibit much fewer degrees of freedom, which would improve the robustness of the optimization/clustering. Hierarchical transformations could also be implemented, similarly to [32] , for reducing the computational burden and/or better constraining the transformation.\nThirdly, we integrate the covariate features in a multi-kernel way. Our framework does not make explicit assumption on the effect of covariates where GLM assumes that covariates have a linear relationship with the imaging features. With this strategy, our framework mitigates the effect of covariates softly, rather than a hard threshold in stratification which is an alternate way of solving this issue.\nThe large dimension of the transformations involved in our current framework constitutes its main limitation. The optimization instability induced was partially addressed by penalizing the transformations. However, this approach would not be suitable for high dimensional data such as voxel-level image maps [45] or voxel-wise transformations. The use of sparser transformations, as explained above, will help reducing the dimension of our model. Stricter penalties, such as and penalties, can be investigated in the future. However, we think that dimensionality reduction will probably remain necessary, in order to maintain the stability of the optimization and reduce the number of local optima. Another limitation of our current linear transformation formulation is that it doesn't take into account the covariance structure of the data, such as covariation between left and right side of the brain. Though we already got symmetric results in Fig. 7 , it might be beneficial to introduce this constraint into the framework. Lastly, the Euclidean distance adopted in the framework implicitly treats features with the same weight. This limitation could be addressed by introducing Mahalanobis distance. These aspects will be further investigated in the future."}, {"section_title": "V. CONCLUSION", "text": "In this paper, we have presented a novel clustering framework, CHIMERA, that addresses some of the challenges raised by the heterogeneity of many diseases, especially neurodegenerative and neuropsychiatric diseases. In our approach, patients and controls are treated as point distributions and disease effects are represented by a set of transformations applied to them, each transformation standing for a different pathology subtype. Another critical contribution of our work is the integration of covariates. Our framework performs a matching between patients and controls based on these covariates in addition to the imaging features, by combining multiple distance/kernels. This matching mitigates potentially confounding effects of covariates that might not be relevant to the disease effect.\nCHIMERA was validated on simulated data and on a clinical dataset where different dementia were mixed. The promising results obtained incited us to explore the heterogeneity of a patient group extracted from the ADNI database. CHIMERA recognized two patient groups, corresponding to distinct pathological brain atrophy patterns. These groups were found to present distinct cognitive abilities. This result illustrates the potential of our method for helping to refine the phenotyping of neurodegenerative diseases, and could potentially reflect early vs. late onset AD subtypes. "}, {"section_title": "APPENDIX", "text": "2) The updating rule for each , , When is arbitrary matrix:\nWhen is diagonal matrix:\nWhen is identity matrix, skip optimizing for . 3) The updating rule for each , is:\n4) To update , we use a projected gradient descent scheme. First we move for with Newton's method: (17) Then we projected the new vector back to the feasible set ( simplex) using method proposed in [28] ."}, {"section_title": "APPENDIX B DEFINITION OF ADJUSTED RAND INDEX", "text": "The Adjusted Rand Index was proposed by Hubert and Arabie [35] . Suppose that a set of sample was labeled/clustered twice, and let denote the two labelings with , . The matrix is defined, where is the number of subjects labeled in and in . With the following notations and , the Adjusted Rand Index(ARI) is calculated as: ACKNOWLEDGMENT ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California."}]