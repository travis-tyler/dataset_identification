[{"section_title": "List of Tables", "text": ". Total number of public school teachers and percentage distribution of public school teachers, by race/ethnicity and selected school characteristics: 2015-16 ......................................................................................................."}, {"section_title": "Introduction", "text": "The 2015-16 National Teacher and Principal Survey (NTPS) is a nationally representative sample survey of public 1 K-12 schools, principals, and teachers in the 50 states and the District of Columbia. This report presents selected findings from the Public School Teacher Data File of NTPS. NTPS is a redesign of the Schools and Staffing Survey (SASS). SASS was conducted on behalf of the National Center for Education Statistics (NCES) on a 4-year cycle, beginning with the 1987-88 school year and ending in the 2011-12 school year. NTPS maintains the same focus on schools, teachers, and administrators that was traditionally held by the SASS; however, it has a different structure and sample than previous administrations of SASS and operates on a 2-year survey cycle. NTPS collects data on core topics including teacher and principal preparation, classes taught, school characteristics, and demographics of the teacher and principal labor force. It is developed by the NCES of the Institute of Education Sciences within the U.S. Department of Education and conducted by the U.S. Census Bureau. This report represents the initial results of the first collection of NTPS. The purpose of NTPS is to collect information that can provide a detailed picture of U.S. elementary and secondary schools and their staff. This information is collected through school, principal, and teacher surveys, and information can be linked across all three surveys. The 2015-16 NTPS uses a school-based sample of public schools. Because of this school-based design, principals associated with public schools were included in the sample. Teachers associated with a selected school were sampled from a teacher list provided by the school, collected from school websites, or purchased from a vendor. The selected samples include about 8,300 traditional and charter public schools and public school principals, and 40,000 public school teachers. The samples were drawn to support estimates by geography, grade span, and charter school status. The reader is referred to the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming) for details about these estimation domains and their precision criteria. The data were collected via mailed questionnaires and internet instruments with telephone and in-person field follow-up. The first questionnaires were mailed in September 2015, and data collection ended in August 2016. The weighted unit response rate was 67.8 percent for public school teachers. For detailed information about response rates, bias analysis results, methodology, and design of the 2015-16 NTPS, please see the technical notes of this report in appendix B or the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming). The purpose of this First Look report is to introduce new data through the presentation of tables containing descriptive information. Selected findings chosen for this report demonstrate the range of information available on the 2015-16 NTPS Public School Teacher Restricted-Use Data File. The selected findings do not represent a complete review of all observed differences in the data and are not meant to emphasize any issue. This First Look report highlights findings from the NTPS public school teacher survey. Findings from the school and principal surveys will be presented in two companion First Look reports: \u2022 Characteristics of Public Elementary andSecondary School Principals in the United States: Results From the 2015-16 National Teacher andPrincipal Survey First Look (NCES 2017-070); and"}, {"section_title": "\u2022 Characteristics of Public Elementary and Secondary Schools in the United States: Results", "text": "From the 2015-16 National Teacher andPrincipal Survey First Look (NCES 2017-071). The tables in this report contain frequencies and percentages demonstrating bivariate relationships. All results have been weighted to reflect the sample design and to account for nonresponse and other adjustments. Comparisons drawn in the selected findings have been tested for statistical significance at the .05 level using Student's t statistics to ensure that the differences are larger than those that might be expected due to sampling variation. While the selected findings include only statistically significant findings they do not include every statistically significant comparison. No adjustments were made for multiple comparisons. Many of the variables examined are related to one another, and complex interactions and relationships have not been explored. Statistical Analysis Software (SAS 9.4) and SUDAAN (11.1) were used to compute the statistics for this report. Tables of standard errors are provided in appendix A. Detailed information about the survey methodology is provided in appendix B. Appendix C contains a description of the variables used in this report. More information about NTPS can be found at https://nces.ed.gov/surveys/ntps."}, {"section_title": "Selected Findings", "text": "\u2022 In the 2015-16 school year, there were an estimated 3,827,100 teachers in public elementary and secondary schools in the United States. About 3,608,600 taught in traditional public schools and about 218,500 taught in charter schools. About 80 percent of all public school teachers were non-Hispanic White, 9 percent were Hispanic, 7 percent were non-Hispanic Black, and 2 percent were non-Hispanic Asian (table 1). \u2022 Among public school teachers, 77 percent were female and 23 percent were male. In addition, relatively more women were teachers in primary schools (89 percent) than in middle schools (73 percent), combined schools (70 percent), and high schools (59 percent) (table 2). \u2022 On average, public school teachers had about 14 years of experience. In addition, teachers in traditional public schools had relatively more teaching experience on average (14 years) than teachers in public charter schools (10 years) (table 3). \u2022 The largest percentage of public school teachers listed a master's degree as their highest degree earned (47 percent), followed by a bachelor's degree (41 percent). Relatively more teachers in traditional public schools listed a master's degree as their highest degree (48 percent) than those in public charter schools (38 percent) (table 4). \u2022 On average, regular full-time teachers in public schools spent 53 hours per week on all school-related activities, including 27 hours that they were paid to deliver instruction to students during a typical full week. Public school teachers were required to work an average of 38 hours per week to receive their base pay (table 5). \u2022 In 2015-16, the average base salary 2 of regular full-time teachers in public schools was $55,100. Among public school teachers reporting earnings from their school system for extracurricular or additional activities during the school year, the average amount was $2,600. Similarly, the average amount earned from jobs outside the school system by public teachers reporting this income source was $5,100 (table 6). \u2022 Among teachers in self-contained classrooms, the average class size was 21 students in primary schools, 14 students in middle schools, 15 students for high schools, and 16 students for combinedgrade schools. Among departmentalized teachers, the average class size was 27 for primary and middle schools, 26 for high schools, and 22 for combined-grade schools (table 7). \u2022 Among all public schools teachers who took graduate or undergraduate courses before their first year of teaching, about 79 percent had any courses on lesson planning, 76 percent had any courses on learning assessment, 74 percent on classroom management techniques, 70 percent on serving students with special needs, 64 percent on serving students from diverse economic backgrounds, 53 percent on using student performance data to inform instruction, and 38 percent on teaching students who are limited-English proficient or English-language learners (table 8). \u2022 Among all public school teachers, 84 percent thought they had any influence 3 on establishing curriculum, 82 percent thought they had any influence on determining the content of in-service programs, 81 percent thought they had any influence on setting performance standards for students at their school, 74 percent thought they had any influence on setting discipline policy, 60 percent thought they had any influence on hiring new full-time teachers, 53 percent thought they had any influence on deciding how the school budget would be spent, and 49 percent thought they had any influence on evaluating teachers (table 9). \u2022 About 98 percent of all public school teachers reported that they had any control 4 over evaluating and grading students, selecting teaching techniques, and determining the amount of homework to be assigned. In addition, about 97 percent of teachers responded that they had any control over disciplining students, 85 percent on selecting content, topics, and skills to be taught, and 84 percent on selecting textbooks and other instructional materials (table10). 7   Table 1. Total number of public school teachers and percentage distribution of public school teachers, by race/ethnicity and selected school characteristics: 2015-16 840,100 8.0 80.7 6.9 2.0 0.3 0.5 1.5 75 or more 1,061,200 16.0 65.9 12.9 3.0 0.2 0.5 1.5 School did not participate in free or reduced-price lunch program 124,500 6.9 85.5 3.8 2.6 \u2021 0.3 ! 1.0 ! Interpret data with caution. The coefficient of variation (CV) for this estimate is between 30 percent and 50 percent (i.e., the standard error is at least 30 percent and less than 50 percent of the estimate). \u2021 Reporting standards not met. The coefficient of variation (CV) for this estimate is 50 percent or greater (i.e., the standard error is 50 percent or more of the estimate) or the response rate is below 50 percent. NOTE: Black includes African American and Hispanic includes Latino. Teachers include both full-time and part-time teachers. Detail may not sum to totals because of rounding and because some data are not shown. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Teacher Data File,\" 2015-16.   Higher than a master's degree is defined as a teacher who completed any of the following: an educational specialist or professional diploma, a certificate of advanced graduate studies, or a doctorate or first professional degree. NOTE: Teachers include both full-time and part-time teachers. Detail may not sum to totals because of rounding. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Teacher Data File,\" 2015-16. 1 Excludes time spent planning and monitoring students outside of class. 2 Includes hours spent during the school day, before and after school, and on weekends. NOTE: A regular full-time teacher is any teacher whose primary position in a school is not an itinerant teacher, a long-term substitute, a short-term substitute, a student teacher, a teacher aide, an administrator, a library media specialist or librarian, another type of professional staff (e.g., counselor, curriculum coordinator, social worker) or support staff (e.g., secretary), or part-time teacher. Detail may not sum to totals because of rounding and because some data are not shown. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Teacher Data File,\" 2015-16. Table 6. Among regular full-time public school teachers, average base salary and earnings from all sources, percentage of teachers with earnings from various salary supplements, and among those teachers, the average amount earned from the supplement during the current school year, by selected school characteristics: 2015-16 19.3 6,500 ! Interpret data with caution. The coefficient of variation (CV) for this estimate is between 30 percent and 50 percent (i.e., the standard error is at least 30 percent and less than 50 percent of the estimate). \u2021 Reporting standards not met. The response rate is below 50 percent. 1 Average earnings from all sources is defined as the weighted mean of the amount that regular full-time teachers earned from all sources during the school year. It does not include summer income or income from a retirement pension. NOTE: For average base salary, teachers who reported zero are excluded from the table. Summer earnings are not included. A regular full-time teacher is any teacher whose primary position in a school is not an itinerant teacher, a long-term substitute, a short-term substitute, a student teacher, a teacher aide, an administrator, a library media or librarian, another type of professional staff (e.g., counselor, curriculum coordinator, social worker) or support staff (e.g., secretary), or a part-time teacher. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Teacher Data File,\" 2015-16. 30.6 ! Interpret data with caution. The coefficient of variation (CV) for this estimate is between 30 percent and 50 percent (i.e., the standard error is at least 30 percent and less than 50 percent of the estimate). \u2021 Reporting standards not met. The response rate is below 50 percent. NOTE: Self-contained classes are defined as instruction to the same group of students all or most of the day in multiple subjects, and departmentalized instruction is defined as instruction to several classes of different students most or all of the day in one or more subjects. Among all public school teachers, 26 percent teach self-contained classes in primary schools, 1 percent in middle schools, 1 percent in high schools, and 1 percent in combined schools; 7 percent teach departmentalized classes in primary schools, 14 percent in middle schools, 25 percent in high schools, and 4 percent in combined schools; 15 percent teach other types of classes, such as elementary subject specialist classes, team-taught classes, and \"pull-out\" or \"push-in\" classes in primary schools, 3 percent in middle schools, 3 percent in high schools, and 1 percent in combined schools. Detail may not sum to totals because of rounding. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Teacher Data File,\" 2015-16.  is below 50 percent. NOTE: Response options included \"no influence,\" \"minor influence,\" \"moderate influence,\" and \"a great deal of influence.\" Teachers who reported \"minor influence,\" \"moderate influence,\" or \"a great deal of influence\" were considered to have reported having \"any influence.\" SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Teacher Data File,\" 2015-16. 95.9 95.5 \u2021 Reporting standards not met. The response rate is below 50 percent. NOTE: Response options included \"no control,\" \"minor control,\" \"moderate control,\" and \"a great deal of control.\" Teachers who reported \"minor control,\" \"moderate control,\" or \"a great deal of control\" were considered to have reported having \"any control.\" SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Teacher Data File,\" 2015-16.     "}, {"section_title": "Estimate Tables", "text": ""}, {"section_title": "A-3", "text": ""}, {"section_title": "A-4", "text": ""}, {"section_title": "A-5", "text": ""}, {"section_title": "A-6", "text": ""}, {"section_title": "A-7", "text": "Table A-6. Standard errors for table 6: Among regular full-time public school teachers, average base salary and earnings from all sources, percentage of teachers with earnings from various salary supplements, and among those teachers, the average amount earned from the supplement during the current school year, by selected school characteristics: 2015-16     "}, {"section_title": "A-8", "text": ""}, {"section_title": "A-9", "text": ""}, {"section_title": "A-10", "text": ""}, {"section_title": "A-11", "text": ""}, {"section_title": "Overview of the NTPS Teacher Survey", "text": "The National Teacher and Principal Survey (NTPS) is sponsored by the National Center for Education Statistics (NCES) of the Institute of Education Sciences within the U.S. Department of Education and is conducted by the U.S. Census Bureau. NTPS is a nationally representative sample survey of public K-12 schools, principals, and teachers in the 50 states and the District of Columbia. This is the first year of NTPS. The 2015-16 NTPS consisted of questionnaires for three types of respondents: public schools, public school principals, and public school teachers. The information can be linked across teachers, principals, and schools. There is a separate data file for each type of respondent (school, principal, and teacher). For the content of the questionnaires, see https://nces.ed.gov/surveys/ntps/question1516.asp. NTPS was designed to produce national estimates for public elementary and secondary schools, principals, and teachers, including national estimates for public charter schools and the principals and teachers within them. Additionally, the teacher survey was designed to produce national estimates of teachers by subject matter taught and by full-time or part-time status. 1-4 (Goldring et al. 2017). To access additional general information on NTPS or for electronic copies of the questionnaires, go to the NTPS home page (https://nces.ed.gov/surveys/ntps)."}, {"section_title": "For additional information on the specific NTPS-related topics discussed in this appendix, consult the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming) or the User's Manual for the 2015-16 National Teacher and Principal Survey, Volumes", "text": ""}, {"section_title": "Sampling Frames and Sample Selection", "text": "Teachers were defined as staff members who teach regularly scheduled classes to students in any of grades K-12. Teacher Listing Forms (i.e., teacher rosters) were collected from sampled schools, by mail and online. When this failed, Teacher Listing Forms were obtained, where possible, via clerical look-up or vendor purchase and compiled at the Census Bureau. This compilation was done on an ongoing basis throughout the roster collection period. Along with the names and e-mail addresses of teachers, sampled schools were asked to provide information about each teacher's teaching status (full or part time) and subject matter taught (special education, general elementary, math, science, English/language arts, social studies, vocational/technical, or other). Sampling was done on an ongoing basis throughout the roster collection period. Prior to allocating teachers to strata, the Census Bureau first allocated an overall number of teachers to be selected. An average of six to eight teachers were selected per school, depending on the school's grade range, urbanicity, and poverty status. Within each sampled school, teachers were stratified by subject, as follows: math, science, English/language arts, social studies, and everything else. No oversampling was performed. Teachers within a school domain and teacher stratum were sorted by the subject matter taught and the teacher line number code. The teacher line number is a unique number assigned to identify the individual within the teacher list. Within each teacher stratum in each school, teachers were selected systematically with equal probability. The maximum number of sampled teachers per school was set at 20, in order to avoid overburdening a school by sampling too large a proportion of its teachers. An average of six to eight teachers were sampled per school. About 16 percent of the eligible public schools did not provide teacher lists that could be used for sampling teachers. For the remaining 84 percent of the eligible public schools, teacher lists B-3 were obtained either by a clerical look-up operation or a list purchased from a vendor. About 40,000 public school teachers were sampled. Teacher Listing Forms were collected from schools in the 2015-16 NTPS public schools sampling frame. The starting point of this sampling frame was the preliminary 2013-14 Common Core of Data (CCD) Nonfiscal School Universe data file. 1 The sampling frame was adjusted from the CCD to fit the definition of a school eligible for NTPS. To be eligible for NTPS, a school was defined as an institution or part of an institution that provides classroom instruction to students, has one or more teachers to provide instruction, serves students in one or more of grades 1-12 or the ungraded equivalent, and is located in one or more buildings apart from a private home. It was possible for two or more schools to share the same building; in that case, they were treated as different schools if they had different administrators (i.e., principal or school head). This definition is unchanged from the Schools and Staffing Survey (SASS). The 2015-16 NTPS universe of schools is confined to the 50 states plus the District of Columbia and excludes the other jurisdictions, Department of Defense overseas schools, and CCD schools that do not offer teacher-provided classroom instruction in grades 1-12 or the ungraded equivalent. This last group includes schools that are essentially administrative units that may oversee entities that provide classroom instruction or may only provide funding and oversight. Although Bureau of Indian Education-funded (BIE) schools are included in NTPS, these schools were not oversampled and the data do not support separate BIE estimates. The NTPS definition of a school is generally similar to the CCD definition, with some exceptions. NTPS allows schools to define themselves. During SASS collection, Census Bureau staff observed that in situations where two or more schools have the same administration, these schools were reported separately on CCD but generally reported as one entity for SASS. Thus, CCD schools with the same location, address, and phone number were collapsed during the frame building on the assumption that the respondent would consider them to be one school. Due to similarities with SASS, NTPS also followed the same type of collapsing procedure. A set of rules was applied to determine in which instances school records should be collapsed together. When school records were collapsed together, the student and teacher counts, grade ranges, and names as reported to CCD were all modified to reflect the change. Finally, since CCD and NTPS differ in scope and their definition of a school, some records were deleted, added, or modified to provide better coverage and a more efficient sample design for NTPS. For a detailed list of frame modifications, see the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming). After deleting, collapsing, and adding school records, the NTPS public school sampling frame consisted of about 87,600 traditional public schools and 6,500 public charter schools. NTPS uses a systematic, probability proportionate to size (PPS) sample (for an explanation of PPS sampling, see Cochran 1977). Unlike SASS, NTPS did not stratify schools prior to sampling. Rather, some types of schools were oversampled based on specific characteristics such as the following: \u2022 School grade level (primary, middle, high, combined); \u2022 Collapsed urbanicity (city, suburban, town, rural); and \u2022 Charter status. In addition to oversampling based on specific school characteristics, sample sizes were inflated for schools in the six states with the smallest number of schools: Alaska, District of Columbia, Hawaii, Rhode Island, Vermont, and Wyoming. 1 For more information about CCD, see https://nces.ed.gov/ccd/."}, {"section_title": "B-4", "text": "Prior to sampling, schools were sorted by the following: \u2022 charter status; \u2022 school grade level (four categories); \u2022 urbanicity (four categories); \u2022 poverty status (four categories); \u2022 school size category (based on full-time equivalent [FTE] teachers; two categories for middle and combined charter schools, three categories for all other schools); \u2022 school type for noncharter schools (four categories); \u2022 state; and \u2022 the number of FTE teachers. These sampling procedures resulted in a total public school sample of about 7,130 traditional public schools and 1,170 public charter schools."}, {"section_title": "Data Collection Procedures", "text": "In 2015-16, NTPS employed a combined mail-based and internet survey approach, with subsequent telephone and in-person follow-up. Data collection included the Teacher Listing Form (TLF), the Principal Questionnaire, the School Questionnaire, and the Teacher Questionnaire. This report focuses on the Teacher Questionnaire. In preparation for school-level data collection, advance letters were mailed to the sampled schools in June 2015 to verify their addresses. Initial school packages were mailed in September 2015. 2 Next, schools were telephoned using a computer-assisted telephone-interviewing instrument to verify school information, establish a survey coordinator, and follow up on the TLF if the school had not already provided an electronic teacher list. Teacher questionnaires were mailed to schools on a flow basis as teachers were sampled on an ongoing basis from the data provided on the TLF or electronic teacher list. The in-person follow-up period was preceded by phone calls from the telephone centers to remind the survey coordinators to have staff complete and return all forms. Nonresponding teachers were also called from the telephone centers and asked to complete the questionnaire by phone. Data collection ended in August 2016. One of the main goals of the data collection plan for the 2015-16 NTPS was to target the schools that presented a challenge to data collection during previous administrations of SASS. These \"known difficult\" schools have resulted in poor response rates for certain school types (e.g., large schools in urban areas). Sampled schools that have a known large impact on weighting were targeted, as well. These schools were identified during sampling, and their data collection priority flag was set accordingly. Contact strategies that were more proactive during the early phases of data collection were employed during 2015-16 NTPS data collection to mitigate potential low response rates for these cases. Survey coordinators also were utilized during data collection. The role of the survey coordinator was to be the primary contact person at the school. A survey coordinator's duties included facilitating data collection by passing out questionnaires to the appropriate staff, reminding the staff to complete their questionnaires, and collecting the questionnaires to return. The data collection follow-up strategies for schools with a survey coordinator were different from schools without a survey coordinator, with the more proactive approach taken for those schools without a survey coordinator."}, {"section_title": "B-6", "text": "of the response rate to two stages: the TLF and the teacher questionnaire. 7 The weighted overall response rate using the initial base weight for public school teachers was 57.2 percent. Unit nonresponse bias analysis. Because the NCES Statistical Standards (4-4) require analysis of nonresponse bias for any survey stage with a base-weighted response rate less than 85 percent, the NTPS teacher file was evaluated for potential bias. National-level estimates were first examined for potential bias. The base-weighted 8 unit response rate was calculated. The following frame characteristics were used for the Public School Teachers Data File: \u2022 Charter status: noncharter, charter \u2022 Enrollment: less than 200, 200 to less than 500, 500 to less than 750, 750 to less than 1,000, 1,000 or more \u2022 Percent of enrollment with race other than White: less than 5 percent, 5 to less than 10 percent, 10 to less than 20 percent, 20 to less than 30 percent, 30 to less than 50 percent, 50 percent or more \u2022 Percent free or reduced-price lunch eligible: less than 35 percent, 35 to less than 50 percent, 50 to less than 75 percent, 75 percent or more \u2022 Community type (locale): city, suburb, town, rural \u2022 Pupil-teacher ratio: less than 10, 10 to less than 15, 15 to less than 20, 20 or more \u2022 Grade level: primary, middle, high, combined \u2022 Region: Northeast, Midwest, South, West \u2022 Number of teachers: less than 10, 10 to less than 25, 25 to less than 50, 50 to less than 75, 75 or more \u2022 Title I status: Title I program, Title I noneligible, Title I eligible but no Title I program \u2022 Teacher status: full-time, part-time, not reported \u2022 Subject taught: special education, general elementary, math, science, English/language arts, social studies, vocational/technical, other, not reported As shown in table B-1, the weighted response rate using the initial base weight for the Teacher Listing Form (TLF) was 84.4 for public schools. The weighted questionnaire response rate using the initial base weight for the teacher survey was 67.8 percent for public school teachers. For the teacher survey, nonresponse can occur both at the school level and at the teacher level. Some schools did not provide a TLF and teachers could not be sampled from schools for which a list was not obtained. Some sampled teachers from schools that provided a TLF did not participate in the survey. To reflect this, national estimates were examined for potential bias at the school level and at the teacher level. For the TLF, the school base-weighted distribution of TLF respondents was compared to the baseweighted distribution of eligible schools through t tests to find any school groups with potential bias prior to TLF nonresponse adjustments. Table B-2 presents national-level school groups with a statistically significant difference in base-weighted percentages between the eligible cases and respondents. 7 For the formula used to calculate the overall response rate, see 2012 Revision of NCES Statistical Standards: Final (NCES 2014-097). 8 Unit nonresponse bias analysis was conducted using the base weight, defined as the product of the initial base weight (the inverse of the probability of selection) and the sampling adjustment factor. The sampling adjustment factor is an adjustment that accounts for circumstances that affect the school's probability of selection that are identified after the data collection has begun, such as a merger, duplication, or incorrect building-level collapsing (e.g., a junior high school and a senior high school merge to become a junior/senior high school). Additionally, the base-weighted unit response rate for TLF of each school group was compared to the overall base-weighted unit response rate through a t test, and the base-weighted distribution of TLF respondents and the base-weighted distribution of nonrespondents were compared through a likelihood ratio chi-square test to find any groups that would have been over-or under-represented by the respondents without nonresponse adjustment. The results from each set of tests were mostly consistent with the results presented in table B-2. The respondents and nonrespondents had different distributions by each frame variable with a school group showing potential bias before TLF nonresponse adjustments. Each school group with evidence of potential bias before TLF nonresponse adjustment had a significant difference in response rate from the overall response rate, except the school group with 50-75 teachers. The response rate for combined schools was different from the overall response rate, but the school group did not show a significant difference in base-weighted percentage between the eligible cases and respondents. Nonresponse adjustments were designed to reduce or eliminate nonresponse bias. The nonresponseadjusted comparisons to the eligible schools shown in table B-2 reflect the nonresponse adjustment. This table shows that nonresponse adjustments eliminated most but not all evidence of potential bias for the TLFs. Evidence of potential bias remains after TLF nonresponse adjustments for the following nationallevel items included in the analysis: \u2022 Enrollment, for schools with 1,000 or more students; \u2022 Number of teachers, for schools with 10 to less than 25 teachers and with 75 or more teachers; \u2022 Percent free or reduced-price lunch eligible, for schools with 50 percent to less than 75 percent of students were eligible for free or reduced-price lunches; \u2022 Pupil-teacher ratio, for schools with a pupil-teacher ratio of 15 to less than 20; and \u2022 Title I status, for schools that are eligible for Title I but are not Title I schools. Similar analyses were conducted for the teacher questionnaire. The weighted distribution of teacher respondents was compared to the weighted distribution of eligible teachers through t tests to find any school or teacher groups with potential bias prior to teacher weighting adjustments. Table B-2 presents national-level school and teacher groups with a statistically significant difference in weighted percentages between the eligible cases and respondents. This analysis used a particular set of weights that are equal to B-9 the base weights of the teacher's school, multiplied by the TLF nonresponse adjustment factors of the teacher's school and divided by the teacher's selection probability within the school. Additionally, the base-weighted response rate for the teacher questionnaire of each school and teacher group was compared to the overall base-weighted unit response rate through a t test and the base-weighted distribution of teacher respondents and the base-weighted distribution of nonrespondents were compared through a likelihood ratio chi-square test to find any groups that would have been over-or under-represented by the respondents without weighting adjustment for teachers. The results from each set of tests were mostly consistent with the results presented in table B-2. Each school and teacher group listed with evidence of potential bias before teacher weighting adjustment had a significant difference in response rate from the overall response rate. The respondents and nonrespondents had different distributions by each frame variable with a school/teacher group showing potential bias before weighting adjustments for teachers, except the Title I status variable. Weighting adjustments for teachers were designed to reduce or eliminate nonresponse bias and to reduce the variance introduced due to sampling by adjusting the sample estimates to known totals from the frame. The final-weighted comparisons to eligible cases shown in table B-2 reflect the effect of weighting adjustment. This table shows that weighting adjustments eliminated some but not all evidence of potential bias and introduced potential bias for some items. Evidence of potential bias remains after weighting adjustments for the following national-level items included in the analysis: \u2022 Enrollment, for teachers in schools with 200 to less than 500; \u2022 Community type, for teachers in city schools, town schools, and rural schools; \u2022 Pupil-teacher ratio, for teachers in schools with a pupil-teacher ratio of 15 to less than 20; \u2022 Region, for teachers in schools in the Northeast region, in the Midwest region, and in the West region; \u2022 Teacher status, for full-time teachers, part-time teachers, and teacher with no reported status; and \u2022 Subject taught, for teacher with a main subject of special education, math, vocational/technical, and other. Evidence of potential bias formed after nonresponse adjustments for the following national-level for teacher items included in the analysis: \u2022 Charter status, for teachers in charter schools and noncharter schools; \u2022 Pupil-teacher ratio, for teachers in schools with a pupil-teacher ratio of 10 to less than 15; \u2022 Region, for teachers in schools in the South region; and \u2022 Title I status, for teachers in Title I schools that are not eligible for Title I. For further information on unit response rates and nonresponse bias analysis, see the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming). Item response rates. The item response rate indicates the percentage of respondents who answered a given survey question or item. The weighted NTPS item response rate is calculated by dividing the weighted number of respondents who provided an answer to an item by the weighted number of respondents who were eligible to answer that item. 9 Table B-3 provides a summary of the weighted item response rates. For the public school teacher data, ten of the survey items included in this report have item response rates less than 85 percent. Those items were: (1) question 2-13d[8], number of students from the eighth subject the teacher reported teaching; (2) and (3) question 2-13d[9], the ninth subject the teacher reported teaching and the number of students for the subject; (4) and (5) question 2-13d[10], the tenth subject the teacher reported teaching and the number of students for the subject; (6) question 4-3c[2], grade range of teaching certificate; (7) and (8) question 4-3e[1] additional content area and its grade range certification; (9) question 8-1b-[1] whether summer earnings working a non-teaching job came from current school; and (10) question 8-8 amount of retirement pension check from a teacher retirement system. For further information on item response rates and bias analysis, see the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming). "}, {"section_title": "Weighting", "text": "The general purpose of weighting is to scale up the sample estimates to represent the target survey population. The base weight for teacher sampling is generated by taking the base weight for school sampling (representing the reciprocal of the probability of selection of the school), adjusted for sample schools for which a TLF is not obtained, and multiplying this by the reciprocal of the probability of selection of the teacher within the school (from the TLF). Teacher samples are only drawn from schools for which a TLF is obtained, so adjustment needs to be made for schools for which TLFs are not obtained. The teacher sample is drawn from the TLF in a probability sample. Next, a nonresponse adjustment factor for teacher nonresponse is calculated and applied based on a weighting cell adjustment. Weighting cells for teacher nonresponse are developed using tree search algorithms. These cells are selected to be homogeneous in response propensity within cells and heterogeneous in response propensity across cells (response propensity is the underlying \"chance\" that a particular sample unit will respond by completing the questionnaire: its individual response rate). The adjustment is the inverse of the weighted teacher response rate within each cell, and each respondent in the cell receives this adjustment. Nonrespondents are given weights of zero: the respondents are reweighted to represent the nonrespondents. The variables examined for potential bias were the same as those used by the tree search algorithms. All subgroups that showed potential bias as given in table B-2 above were used as cell generators by the tree search algorithms, as well as other subgroups which are related, and may show differential response conditional on other subgroups (i.e., they may be chosen as cell generators by the tree search algorithm within particular branches). For the Public School Teacher Data File, a raking factor is calculated and applied to the sample to adjust the sample totals to CCD frame totals for FTE teachers, so that the sum of the weights within each of the specified cells is equal to the corresponding CCD frame total for the cell. These cells are defined based on school level, urbanicity, and percentage of students eligible for free or reduced-price lunch. The first dimension combines school level and the percentage of students eligible for free or reduced-price lunch. The second dimension combines school level and urbanicity. The weights are adjusted to these frame totals by an iterative process, referred to as raking, until the weights simultaneously aggregate to be equal to each set of frame totals. In some cases, extreme weights may be trimmed back to a cutoff value. This all improves the precision of survey estimates. The product of these factors is the final weight for each NTPS respondent, which appears as TFNLWGT on the NTPS Public School Teacher Data File."}, {"section_title": "B-11", "text": "The counts in table 1 (in the Estimate Tables section) do not necessarily match the frame counts because some cases in the frame were found to be ineligible (i.e., out of scope)."}, {"section_title": "Variance Estimation", "text": "In surveys with complex sample designs, such as NTPS, direct estimates of sampling errors that assume a simple random sample typically underestimate the variability in the estimates. The NTPS sample design and estimation include procedures that deviate from the assumption of simple random sampling, such as sampling with differential probabilities. One method of calculating sampling errors of complex sample designs is jackknife replication. Jackknife replication methods involve dropping a small portion of the sample from the full sample and computing the statistic of interest for the retained and reweighted sample (the jackknife replicate). The sum of squares of the replicate estimates around the full sample estimate provides an estimate of the variance of the statistic. The NTPS teacher data file includes a set of 200 replicate weights designed to produce variance estimates. The set of replicate weights for each file should be applied to the respondents in that file. The replicate weights for NTPS respondents are TREPWT1-TREPWT200 for teachers."}, {"section_title": "Reliability of Data", "text": "NTPS estimates are based on samples. The sample estimates may differ somewhat from the values that would be obtained from the universe of respondents using the same questionnaire, instructions, and field representatives. The difference occurs because a sample survey estimate is subject to two types of errors: nonsampling and sampling. Estimates of the magnitude of sampling error for NTPS data can be derived or calculated. Nonsampling errors are attributed to many sources, including definitional difficulties, the inability or unwillingness of respondents to provide correct information, differences in the interpretation of questions, an inability to recall information, errors made in collection (e.g., in recording or coding the data), errors made in processing the data, and errors made in estimating values for missing data. Quality control and edit procedures were used to reduce errors made by respondents, coders, and interviewers."}, {"section_title": "Comparability to SASS", "text": "NTPS is a new survey that is strongly based on SASS. However, care must be taken in estimating changes over time in data elements that both surveys have in common because some of the change measured may not be attributable to a change in the education system. Some of the change may be due to changes in the sampling frame, changes in the questionnaire item wording, or other changes. Additionally, NTPS is a different survey than SASS and pulls data from a larger variety of sources and timeframes than SASS did. While SASS collected data on student race/ethnicity, special programs, and high school graduation, the 2015-16 NTPS gets this information from external sources. Data on student gender and race/ethnicity are taken from the 2014-15 CCD, while graduation rates come from the 2014-15 EdFacts data and information on special programs 10 came from the 2013-14 Civil Rights Data Collection."}]