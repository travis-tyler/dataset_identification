[{"section_title": "Abstract", "text": "Disease progression modeling (DPM) of Alzheimer's disease (AD) aims at revealing long term pathological trajectories from short term clinical data. Along with the ability of providing a data-driven description of the natural evolution of the pathology, DPM has the potential of representing a valuable clinical instrument for automatic diagnosis, by explicitly describing the biomarker transition from normal to pathological stages along the disease time axis. In this work we reformulated DPM within a probabilistic setting to quantify the diagnostic uncertainty of individual disease severity in an hypothetical clinical scenario, with respect to missing measurements, biomarkers, and follow-up information. We show that the staging provided by the model on 582 amyloid positive testing individuals has high face validity with respect to the clinical diagnosis. Using follow-up measurements largely reduces the prediction uncertainties, while the transition from normal to pathological stages is mostly associated with the increase of brain hypo-metabolism, temporal atrophy, and worsening of clinical scores. The proposed formulation of DPM provides a statistical reference for the accurate probabilistic assessment of the pathological stage of de-novo individuals, and represents a valuable instrument for quantifying the variability and the diagnostic value of biomarkers across disease stages."}, {"section_title": "Introduction", "text": "Neurodegenerative disorders (NDDs), such as Alzheimer's disease (AD), are characterized by the progressive pathological alteration of the brain's biochemical processes and morphology, and ultimately lead to the irreversible impairment of cognitive functions (Brookmeyer et al., 2007) . The correct understanding of the relationship between the different pathological features is of paramount importance for improving the identification of pathological changes in patients, and for better treatment .\nTo this end, ongoing research efforts aim at developing precise models allowing optimal sets of measurements (and combinations of them) to uniquely identify pathological traits in patients. This problem requires the definition of optimal ways to integrate and jointly analyze the heterogeneous multi-modal information available to clinicians (Young et al., 2013; Mwangi et al., 2014; Lorenzi et al., 2016) . By consistently analyzing multiple biomarkers that to date have mostly been considered separately, we aim at providing a richer description of the pathological mechanisms and a better understanding of individual disease progressions.\nDisease progression modeling (DPM) is a relatively new research direction for the study of NDD data (Fonteijn et al., 2011; Jedynak et al., 2012; Donohue et al., 2014; Younes et al., 2014; Bilgel et al., 2015; Schiratti et al., 2015; Guerrero et al., 2016; Marinescu et al., 2017) . The main goal of DPM consists in revealing the natural history of a disorder from collections of imaging and clinical data by: 1) quantifying the dynamics of NDDs along with the related temporal relationship between different biomarkers, and 2) staging patients based on individual observations for diagnostic and interventional purposes. Therefore, this research domain is closely related to the exploitation of advanced statistical/machine-learning approaches for the joint modeling of the heterogeneous and information available to clinicians: imaging, biochemical, and clinical biomarkers. Differently from the several predictive machine-learning approaches proposed in the past in NDD research, disease progression models aim at explicitly estimating the temporal progression of the biomarkers from normal to pathological stages, to provide a better interpretation and understanding of the natural evolution of the pathology. For this reason it represents a very appealing modeling approach in clinical settings.\nThe main challenge addressed by DPM consists in the general lack a well-defined temporal reference in longitudinal clinical dataset of NDDs. Indeed, age or visit date information are biased time references for the individual longitudinal measurements, since the onset of the pathology may vary across individuals according to genetic and environmental factors (Yang et al., 2011) . This is a very specific methodological issue requiring the extension and generalization of the analysis approaches classically used in time-series analysis.\nTo tackle this problem, it is usually assumed that individual biomarkers are measured relatively to an underlying disease trajectory defined with respect to an absolute time axis describing the natural history of the pathology (Jedynak et al., 2012) . Each individual is thus characterized by a specific observation time that needs to be estimated in order to assess the individual pathological stage. According to this statistical setting, we therefore aim at estimating a group-wise disease model defined with respect to an absolute time scale, along with individual time re-parameterisation relative to the group-wise progression. This modeling paradigm has been implemented in a number of approaches proposed in the recent years, either by assuming continuous temporal trajectories of the biomarkers (Jedynak et al., 2012; Donohue et al., 2014; Younes et al., 2014; Bilgel et al., 2015; Schiratti et al., 2015; Guerrero et al., 2016; Marinescu et al., 2017) , or by modeling the disease progression as a sequence of discrete events (Fonteijn et al., 2011; Young et al., 2014) .\nFor example, in (Donohue et al., 2014) the authors proposed to model the temporal biomarker trajectories through random effect regression, building on the theory of self-modeling regression (Kneip and Gasser, 1988) , while the authors of (Schiratti et al., 2015) re-frame the random effect regression model in a geometrical setting, based on the assumption of a logistic curve shape for the average biomarker trajectories.\nContinuous progression models have been recently extended to the modeling of brain images based on the time-reparameterization of voxel/ mesh-based measures (Younes et al., 2014; Bilgel et al., 2015; Marinescu et al., 2017) .\nThe use of disease progression models for diagnostic purposes is instead less investigated. Predictive models of patient staging were proposed within the setting of the Event Based Model (Fonteijn et al., 2011) , or still through random effect modeling (Guerrero et al., 2016) . However, the Event Based Model relies on the coarse binary discretization of the biomarker changes, and does not account for longitudinal observations, while the predictive models proposed in (Guerrero et al., 2016) and (Schmidt-Richberg et al., 2015) require cohorts with known disease onset, and therefore lack flexibility while being prone to bias due to mis-diagnosis and uncertainty of the conversion time.\nFurthermore, these methods are generally not formulated in a probabilistic setting, which makes it difficult to account for uncertainties in biomarker progressions and diagnostic predictions. Indeed, the quantification of the variability associated with the biomarkers trajectories, as well as the assessment of the diagnostic uncertainty in de-novo patients, are crucial requirements for decision making in clinical practice (Shinkins and Perera, 2013).\nNonetheless, the ensemble of this research offers a sight of the potential of these approaches in representing a novel and powerful diagnostic instrument: in this study we thus aim at assessing the ability of DPM in providing a statistical reference for the transition from normal to pathological stages, for probabilistic diagnosis in the clinical scenario. To this end, we reformulate classical DPM within a Bayesian setting in order to allow the probabilistic estimate of the biomarker trajectories and the quantification of the uncertainty of predictions of the individual pathological stage. The resulting probabilistic framework is exploited in an hypothetical clinical scenario, for the estimation of the pathological stage in a de-novo cohort of testing individuals, by assessing the influence of missing observations, biomarkers, and follow-up information.\nThe manuscript is structured as follows. Section 2.1 formulates DPM based on Bayesian Gaussian Process regression (Rasmussen, 2006) , while Section 2.2 illustrates the validation of our model on clinical and multivariate imaging measurements from a cohort of 782 amyloid positive individuals extracted from the ADNI database."}, {"section_title": "Methods", "text": ""}, {"section_title": "Statistical setting", "text": "This section highlights the statistical framework employed in this study, based on the reformulation of self-modeling regression withing a Bayesian setting. This achieved by 1) defining a random effect Gaussian process regression model to account for individual correlated time series (section 2.1.1); 2) modeling individual time transformations encoding the information on the latent pathological stage (section 2.1.2); and 3) introducing a monotonicity information in order to impose a regular behaviour on the biomarkers trajectories (section 2.1.3). We finally illustrate in section 2.1.4 how the proposed framework leads to a probabilistic model of disease staging in de-novo individuals, naturally accounting for missing information. Further details on model specification and inference are provided in the Supplementary Section Appendix A.1, while the experimental validation on synthetic data is reported in Supplementary Section Appendix A.2."}, {"section_title": "Gaussian process-based random effect modeling of longitudinal progressions", "text": "In what follows, longitudinal measurements of N b biomarkers fb 1 ; \u2026; b Nb g over time are given for N individuals.\nWe represent the longitudinal biomarker's measures associated with each individual j as a multidimensional array \u00f0y j \u00f0t 1 \u00de; y j \u00f0t 2 \u00de; \u2026; y j \u00f0t k j \u00de\u00de \u22a4 sampled at k j multiple time points t \u00bc ft 1 ; t 2 ; \u2026; t k j g. Although different biomarkers may be in reality sampled at different time-points, for the sake of notation simplicity in what follows we will assume, without loss of generality, that the sampling time is common among them. The observations for individual j at a single time point t are thus a random sample from the following generative model: .\nFixed effect process. The covariance function \u03a3 G describes the biomarkers temporal variability, and is represented as a block-diagonal matrix\nwhere each block represents the within-biomarker temporal covariance expressed as a negative squared exponential function Individual random effects. The random covariance function \u03a3 S models the individual deviation from the fixed effect, and is represented as a blockdiagonal matrix\nwhere each block \u03a3 j b corresponds to the covariance function associated with the individual process \u03bd j b \u00f0t\u00de. Thanks to the flexibility of the proposed generative model, any form of the random effect covariance \u03a3 S can be easily specified in order to model the subject-specific biomarkers' progression. In what follows we will use a linear covariance form\nwhere t is the average observational time for individual j, when more than 4 measurements are available, and i.\nwhen 2 or 3 measurements are available, while assigning it to 0 otherwise (thus by accounting only for the observational noise \u03c3 2 b ). This choice is motivated by stability concerns, in order to keep the model complexity compatible with the generally limited number of measurements available for each individual."}, {"section_title": "Individual time transformation", "text": "The generative model (1) is based on the key assumption that the longitudinal observations across different individuals are defined with respect to the same temporal reference. This assumption may be invalid when the temporal alignment of the individual observations with respect to the common group-wise model is unknown, for instance in the typical scenario of a clinical trial in AD where the patients' observational time is relative to the common baseline, and where the disease onset is a latent event (past or future) which is not directly measurable. This modeling aspect is integrated by assuming that each individual measurement is made with respect to an absolute time-frame \u03c4 through a time-warping function t \u00bc \u03d5 j \u00f0\u03c4\u00de that models the time-reparameterization with respect to the common group-wise evolution. Model (1) can thus be reparameterized as\nThe present formulation allows the specification of any kind of time transformation, and in what follows we shall focus on the modeling of a linear reparameterization of the observational time \u03d5 j \u00f0\u03c4\u00de \u00bc \u03c4 \u00fe d j . This modeling assumption is mostly motivated by the choice of working with a reasonably limited number of parameters, compatibly with the generally short follow-up time available per individual (cfr. Table 2 ). Within this setting, the time-shift d j encodes the disease stage associated with the individual relatively to the group-wise model."}, {"section_title": "Monotonic constraint in random-effect multimodal GP regression", "text": "Due to the non-parametric nature of Gaussian process regression, we need an additional constraint on model (3) in order to identify a unique solution for the time transformation. By assuming a steady temporal evolution of biomarkers from normal to pathological values, we shall assume that the biomarker trajectories described by (3) follow a (quasi) monotonic behaviour. This requirement can be implemented by imposing a prior positivity constraint on the derivatives of the GP function. Inspired by (Riihim\u20ac aki and Vehtari, 2010), we impose a monotonicity constraint by assuming a probit-likelihood for the derivative measurements m\u00f0t\u00de associated with the derivative process _ f\u00f0t\u00de \u00bc df\u00f0t\u00de dt at time t:\nThe quantity \u03bb > 0 is an additional model parameter controlling the degree of positivity enforced on the derivative process, with values approaching zero for stronger monotonicity constraint. In what follows, the monotonicity of each biomarker is controlled by placing 10 derivative points equally spaced on the observation domain, and by fixing the N b derivative parameters f\u03bb bk g Nb k\u00bc1 to the value of 1e-6. The position of the derivative points was updated at each iteration, according to the changes of the GP domain.\nBy following a similar construction, we could equally enforce a monotonic behaviour to the random effects associated with the individual trajectories. This additional constraint would however come with a cumbersome increase of the model complexity, since it would introduce an additional layer of virtual derivative parameters (with associated location) per individual. Moreover, while we are interested in modeling a globally monotonic biomarker trajectory on the fixed parameters, we relax this constraint at the individual level, since some subjects may be characterized by non strictly monotonic time-series due to specific clinical conditions.\nModel likelihood and parameters. Given the sets of individual biomarker measurements y \u00bc f\u00f0y\nfor the progression of each biomarker b k , the random effect GP model posterior is:\nDue to the non-Gaussianity of the derivative term \u03a6, the direct inference on the posterior is not possible due to its analytically intractable form. For this reason, we employ an approximate inference scheme based on classical approaches to Gaussian process with binary activation functions (Nickisch and Rasmussen, 2008) \nresented by the fixed effects and noise \u03b8 G \u00bc f\u03b7 bk ; l bk ; \u03b5 bk g N b k\u00bc1 , by the individual random effects parameters \u03b8 j G \u00bc f\u03c3 In what follows, the optimal parameters are obtained by maximising the approximated log-marginal likelihood derived from the posterior (5) through conjugate gradient descent, via alternate optimization between the hyper-parameters \u03b8 G and \u03b8 j G , and the individuals' time-shifts d j . Regularization is also enforced by introducing Gaussian priors for the parameters \u03b8 G and \u03b8 j G ."}, {"section_title": "Prediction of observations and individual staging", "text": "Gaussian processes naturally allow for probabilistic predictions given the observed data. At any given time point t \u00c3 , the posterior biomarker distribution has the Gaussian form p\u00f0f \u00c3 jt \u00c3 ; y; t; m; t'\u00de $ N \u00f0f \u00c3 j\u03bc \u00c3 ; \u03a3 \u00c3 \u00de:\nwhere the matrix \u00f0\u03a3 joint \u00fe\u03a3 joint \u00de is the joint covariance resulting from the inference scheme detailed in Supplementary Section Appendix A.1 (Rii-him\u20ac aki and Vehtari, 2010). We also derive a probabilistic model for the individual temporal staging given a set of biomarker observations y \u00c3 , thanks to the Bayes formula: p\u00f0t \u00c3 jy \u00c3 ; y; t; m; t'\u00de \u00bc p\u00f0y \u00c3 jt \u00c3 ; y; t; m; t'\u00dep\u00f0t \u00c3 \u00de=p\u00f0y \u00c3 jy; t; m; t'\u00de;\n(8) which we compute by assuming an uniform distribution on t \u00c3 , and by noting that p\u00f0y \u00c3 jt \u00c3 ; y; t; m; t'\u00de $ N \u00f0\u03bc \u00c3 ; \u03a3 \u00c3 \u00fe \u03a3 \u03b5 \u00de. In particular, the covariance form \u03a3 G \u00f0f\u00f0t \u00c3 \u00de; f\u00f0t \u00c3 \u00de\u00de can be specified in order to account for incomplete data, and thus generalizes the GP model for predictions in presence of missing biomarker observations. The posterior distribution (8) quantifies the confidence of the model about the individual disease staging, and thus is a valuable information about the precision of the diagnosis. We will also compute the expectation of the distribution p\u00f0t \u00c3 jy \u00c3 ; y; t; m; t'\u00de, which provides a scalar value that can be used in subsequent classification methods."}, {"section_title": "Meterials and methods", "text": ""}, {"section_title": "Study participants", "text": "Data used in the preparation of this article were obtained from the ADNI database (http://adni.loni.usc.edu). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial magnetic resonance imaging, positron emission tomography, other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of MCI and early AD. For up-to-date information, see www.adni-info.org."}, {"section_title": "Data processing", "text": "We collected longitudinal measurements for the ADNI individuals with baseline values of cerebrospinal fluid (CSF) A\u03b2 amyloid lower than the nominal value of 192 pg/ml. The information was extracted from the ADNIMERGE 2 R package (R Core Team, 2015) (MEDIAN field of the UPENNBIOMK_MASTER table) . This preliminary selection is aimed to validate the model on a clinical population likely to represent the whole disease time-span.\nThe model was trained on a group of 200 randomly selected individuals including healthy volunteers, mild cognitive impairment subjects converted to AD (MCI conv), and AD patients having at least one measurement for each of the following biomarkers: volumetric measures (hippocampal, ventricular, entorhinal, and whole brain volumes), glucose metabolism (average normalized FDG uptake in prefrontal cortex, anterior cingulate, precuneus and parietal cortex), brain amyloidosys (average normalized AV45 uptake in frontal cortex, anterior cingulate, precuneus and parietal cortex), and functional, neuropsychological and cognitive function measured by common scores (ADAS13, RAVLT learning, and FAQ). 3 The testing set was composed of the remaining 582 subjects, including a subgroup of MCI non converted to AD during the observational time (MCI stable). The image-derived measures used in the study (volumetric MRI and average uptake values for AV45-and FDG-PET) were the scalar estimates reported in the ADNIMERGE package (adnimerge table). The volumetric measures were scaled by the individual total intracranial volume, and all the biomarkers measurements were converted into quantile scores (0-1 for normal to abnormal values), with respect to the biomarkers distribution of the training set. This latter modeling precaution is aimed to avoid spurious correlation between training and testing data due to the combined normalization of the values.\nThe modeling results were evaluated with respect to the baseline diagnostic information reported in the ADNI database, assessed according to the WMS and NINCDS/ADRDA AD criteria (McKhann et al., 1984) . Conversion to MCI or AD was established according to the last follow-up information. Moreover, the MCI group was composed by 138 individuals with baseline diagnosis of early MCI, assessed through the Wechsler Memory Scale Logical Memory II. Among these subjects, 14 of them were in the training group (26% of the total MCI training set size), while the remaining 124 were in the testing set (35% of the total MCI testing set size). Table 1 shows baseline clinical and sociodemographic information of the individuals used respectively in training and testing set, while in Table 2 we report the average follow-up time and the ratio of missing data of the pooled sample. Supplementary Section Appendix A.2.6 reports the R code used for data pre-processing."}, {"section_title": "Longitudinal modeling of Alzheimer's disease progression", "text": ""}, {"section_title": "Model training", "text": "The model was applied in order to estimate the temporal biomarker evolution and the disease stage associated with each individual in the training set. The plausibility of the model was assessed by group-wise comparison of the predicted time-shift, and by correlation with respect to the time to AD diagnosis for the MCI individuals subsequently converted to AD. For sake of comparison we also correlated the progression modelled with our approach with respect to the one estimated with the method proposed in (Donohue et al., 2014) . The method was applied to the training data by using the standard parameters defined in the R package GRACE 4 (see Supplementary Material Appendix A.2.2 for further details)."}, {"section_title": "Model testing on de-novo individuals", "text": "The estimated probabilistic disease progression model provides a valuable clinical reference, as it can be used to predict an individual pathological stage, as well as to quantify the biomarkers predictive value, or the influence of missing data. To this end, we estimated the predictive performance of the model in assessing the individual pathological stage with respect to follow-up assessments and missing biomarkers. This was done by estimating the predictive accuracy of the group-wise separation obtained via increasing thresholds of the estimated temporal progression."}, {"section_title": "Results", "text": ""}, {"section_title": "Model plausibility", "text": "The estimated biomarker progression ( Fig. 1-A) shows a biologically plausible description of the pathological evolution, compatible with previous findings in longitudinal studies in familial AD (Bateman et al., 2012) , and with the hypothetical models of AD progression Frisoni et al., 2010) . The progression is defined on a time scale spanning roughly 20 years, and is characterized at the initial stages by high-levels of AV45, followed by the abnormality of ventricles volume, of FDG uptake, and of the whole brain volume. These latter measures are however heterogeneously distributed across clinical groups, and with rather large variability. The evolution is further characterized by increasing abnormality of the volumetric measures (especially hippocampal volume), and by the steady worsening of neuropsychological scores such as FAQ. The model thus shows that the transition from normal to pathological levels is essentially characterized by increase of hypo-metabolism, followed by the pronounced temporal brain atrophy. Moreover, the worsening of the neuropsychological and functional scores closely (almost linearly) follows the progression in the advanced clinical stages. The joint visualization of the temporal progression of the biomarkers with temporal derivative of the modelled average trajectories is shown in Supplementary figure A10 . The illustration confirms that ADAS13 and FAQ are characterized by very similar longitudinal profiles, and show the largest changes in the latest stages of the pathology (peak of the derivative at t > 0). On the contrary, the change in hippocampal volume is more strongly associated with the earlier stages of the pathology. AV45 and ventricles volumes are the least informative and are associated with the lowest changes. Fig. 1-B (top) shows the posterior time-shift distributions associated with the individuals. The distributions denote the confidence of the model in associating to each individual a temporal staging with respect to the global pathological progression. The boxplot of Fig. 1-B (bottom) reports the group-wise expectation of the individual time-shifts. Healthy individuals (blue) are associated with the early stages of the pathology in both training and testing data, while MCI (purple) and AD patients (red) are characterized by respectively intermediate and late predicted progression stages. The group-wise comparison between the expected timeshifts was statistically significant between each group pairs (ANOVA, p < 1e-6). Moreover, the time to conversion to AD in the MCI group was significantly correlated with the disease staging quantified by the expectation of the individual time distributions (R 2 \u00bc \u00c00:4, p \u00bc 3:8e \u00c0 4).\nFinally, when applying (Donohue et al., 2014) to the training data we measured a strong agreement between the resulting progression and the one obtained with our method, resulting in a correlation between the corresponding individual time-shifts of 0.94 (p < 1e-6) (Supplementary Material Appendix A.2.2)."}, {"section_title": "Assessing diagnostic uncertainty in testing data: an illustrative example", "text": "This section illustrates the use of the model represented in Fig. 1 for the quantification of diagnostic uncertainty in testing individuals. We consider the hypothetical scenario where the baseline values for different biomarkers are measured for a given patient, namely FAQ, hippocampal and ventricle volumes. We assume that the biomarkers values correspond to the 20th percentiles with respect to the biomarkers distribution of the training set (i.e. FAQ \u00bc 1, normalized Hippo \u00bc 5e-3, normalized Ventr \u00bc 1.7e-2). Fig. 2 (left) shows the disease staging prediction obtained with formula (8) based on the value of each biomarker. We note that FAQ and hippocampal volume lead to similar posterior Gaussian distributions of disease staging, with expectation of respectively t FAQ \u00bc -6 and t hippo \u00bc -5.6 (indicated by the vertical lines in the figure), and standard deviation of sd FAQ \u00bc 6.3 and sd hippo \u00bc 5.9. The prediction associated with ventricles volume is wider and associated with higher uncertainty, with mean and standard deviation of respectively t ventr \u00bc -3.8 and sd ventr \u00bc 6.1.\nWe now suppose that for the same patient we acquire a follow-up measurement for each biomarker at year 1, with values corresponding to the 50th percentiles of the distribution of the training set (i.e. FAQ \u00bc 5, normalized Hippo \u00bc 4.3e-3, normalized Ventr \u00bc 2.7e-2). The right hand side of Fig. 2 shows the new prediction based on the joint baseline \u00fe follow-up information. For each biomarker the posterior distributions indicate an increase of the predicted disease stage with respect to the baseline scenario, while the prediction uncertainty is generally lower. Although the expectation for the 3 biomarkers is very similar (t FAQ \u00bc-2.5, t hippo \u00bc -3.5, and t Ventr \u00bc -3.2), we notice that FAQ leads to the highest diagnostic confidence (sd FAQ \u00bc2.6), followed by hippocampal volume (sd Hippo \u00bc3.8), and finally by ventricles volume (sd Ventr \u00bc5.7). Further assessment of the relationship between biomarker variability and model prediction is provided in supplementary Section Appendix A.2.3.\nThis illustrative example shows that the proposed probabilistic (0) 3.3 (0) 1.9 (0) 1.6 (0) Testing data 3.4 (11) 3.4 (11) 3.4 (11) 3.4 (11) 3.9 (0) 3.9 (0) 3.9 (0) 3.8 (43) 3 (19) framework represents a valuable instrument for the assessment of the diagnostic value and uncertainty associated with different biomarkers, and can faithfully track the pathological progression of testing individuals along the modelled trajectories, from normal to pathological levels."}, {"section_title": "DPM for probabilistic diagnosis in ADNI", "text": "We now assess the predictive results of the model when applied to the testing ADNI cohort. Fig. 3 shows the individual posterior predictive distributions associated with the testing individuals, and the boxplot of the expected time-shift when using the model as statistical reference through formula (8). The figure reports the two different modeling scenarios based on baseline information only ( Fig. 3-1) , and on the complete set of baseline and longitudinal measurements ( Fig. 3-2 ). We first note that the group-wise differences between the expected time-shifts are compatible for both scenarios, as shown by the similar boxplot distributions across groups (Fig. 3-1b vs 3-2b) . The consistency of the predictions is further illustrated in Figure A .9, where it is shown that the group-wise distribution and ordering of the predicted time-shifts in the testing data are compatible with those estimated in the training one.\nHowever, the joint use of baseline and follow-up information largely reduces the uncertainty of the predictions (Fig. 3-1a vs 3-2a) . Indeed, the time distributions predicted when using baseline and follow-up information are narrower as compared to the wider confidence margins obtained by using the baseline information only. Therefore, adding followup measurements importantly improves the confidence of the model in determining the individual pathological stage.\nAs with the training case, for both scenarios the group-wise distribution of the expected time-shift shows a significant separation between the clinical groups according to the increase of the pathological stage (ANOVA, p < 1e-4). Interestingly, the temporal positioning of the non converting MCI lies between controls and MCI converters, and is on average lower than the one of healthy individuals subsequently converted to cognitive impairment. Fig. 4 reports the classification results based on the baseline information only, and on increasing thresholds of the progression time course. Although the model is not optimized to explicitly classify the clinical groups, the simple thresholding based on the model predictions generally shows high face validity with respect to the clinical diagnosis. For all the considered scenarios, the highest accuracy is reached in a time window around the point t \u00bc 0, while the area under the ROC curve is 0.99, 0.88 and 0.83 for NL vs AD, MCI converters vs MCI stable, and NL converters vs NL stable, respectively.\nWe further tested the model in presence of missing information, by computing the predictions when only one baseline biomarker is available (Fig. 5) . The predictive outcomes show important variations depending on the considered biomarker, while the confidence bounds for the predictions are usually large, to denote increased uncertainty. We also note that FAQ, ADAS13, and hippocampal volume are the biomarkers leading to the largest group-wise separation, along with the lowest prediction uncertainty. This aspect is quantified in Table 3 , reporting the discrimination results with respect to the nominal cut-off point of t \u00bc 1:65, corresponding to the 15th percentile of the distribution of the expected timeshift in the training AD group, as well as the area under the receiving operating characteristic curve (AUC). Although the highest discriminative results are consistently obtained when the biomarkers are used jointly, we note that the neuropsychological tests generally lead to the best predictive performance in identifying AD patients with respect to healthy individuals, followed by brain hypo-metabolism (FDG-PET), and temporal atrophy (Entorhinal and Hippocampal volume). This is related to the lower uncertainty of the modelled progressions, which leads to a more accurate identification of the individual staging along the pathological trajectory. The scenario sensibly changes in the other comparison scenarios (MCI conv vs stable and NL conv vs stable), where the sensitivity of the neuropsychological scores shows an important drop, while the other biomarkers (especially hippocampal and entorhinal volumes) provide comparable or even better discriminative performances.\nThese figures were similar when considering the single biomarkers within the longitudinal setting, where the neuropsychological tests still Adding the follow-up information leads to increased estimates of the disease staging and to generally lower prediction uncertainty. Although the distributions associated with different biomarkers generally lead to similar expectations, FAQ and hippocampal volume lead to the lowest diagnostic uncertainty. Vertical lines: expectation for each posterior distribution.\noutperformed the other biomarkers in discriminating the clinical groups ( Supplementary Figure A11) .\nFor the sake of comparison we finally benchmarked the predictive results provided by the disease progression model with respect those obtained by the classification analysis performed with standard statistical tools, such as a random forest classifier. We note that the comparison of the classification performance obtained on the heterogeneous data considered in this work is generally challenging, since the proposed DPM 1) accounts for missing data and non-fixed number of time points per individuals, and 2) is formulated in order to consistently handle both longitudinal and cross sectional measurements, either for training and prediction. To date there is not a consensus on the optimal approach to adopt to tackle these important modeling constraints, while the comparison between the classification performance obtained with complex machine learning methods is currently matter of scientific debate and investigation .\nFor this reason we restricted the random forest classification task to a standard statistical setting, in order to essentially provide a reliable benchmark for the classification performance of the proposed disease progression. To this end we trained the random forest on the classification between healthy individuals and AD patients based on the baseline measurements of the training group, while the missing entries in the testing data were imputed via nearest neighbour search, based on the available biomarkers. The classification results are reported in Supplementary Table A5 .\nThe performance of the random forest classifier is generally inferior to the one obtained with the proposed approach, as witnessed by the consistently lower AUC obtained for all the comparisons. The difference becomes more evident for the more challenging classification problems, such as the identification of conversion in MCI and healthy individuals. This result is indicative of the reliability of the classification results obtained by the proposed disease progression model, especially when considering that the random forest classifier is explicitly optimized to maximize the separation between groups, while the accuracy results reported in Table 3 are based on the empirical choice of a reference threshold in the training population."}, {"section_title": "DPM staging and chronological age", "text": "We finally compare the relationship between the predicted disease staging in training and testing set and the individual chronological age. We first note that both training and testing clinical groups were matched by age, with the exception of the 5 training healthy subjects converted to MCI (or AD) that were slightly older with respect to the reference training healthy population (p \u00bc 0.02).\nNevertheless, when comparing the estimated time shift with respect to the chronological age of each individual we didn't report any significant correlation between these measures. Interestingly, the same lack of association is also quantifiable in the testing group (Fig. 6 ). This result, in association with the strong relationship between time shift and clinical condition reported in Section 3.3, let us conclude that the model is describing the biomarker's variation essentially related to the pathological progression, which is orthogonal to the effect of healthy aging quantified by the chronological age. This result points to the effectiveness of the proposed approach in capturing significant effects related to the specific temporal progression of the disease."}, {"section_title": "Discussion", "text": "This study explores the use of DPM for probabilistic diagnosis and uncertainty quantification in an hypothetical clinical scenario. The proposed approach is based on the reformulation of DPM through a novel probabilistic approach aimed at leveraging on the longitudinal modeling of disease progression for prediction and quantification of the diagnostic uncertainty in neurodegeneration, by optimally combining the information provided by the several biomarkers into a biologically plausible and intelligible score quantified by the time shift. This work thus extends the previous contributions by proposing DPM as a probabilistic tool for diagnostic purposes, which can be used to quantify staging and predictive uncertainty of de-novo individuals in clinical trials. The disease progression model itself thus can be seen as a novel biomarker of pathological progression. We also note that the time shift is a relative measure of disease progression accounting for the biomarker variability observed in the training population. Thus, the point 0 is generally not associated with the conversion to AD, as it is relative to the data initialization (in this case the study baseline).\nWe illustrated the use of DPM as benchmarking tool for the statistical comparison of biomarkers. The model allows the quantification of the variability associated with the single biomarkers, by identifying the related uncertainty in characterizing the progression from normal to pathological levels. The proposed model can be thus used as a reference for screening and enrichment purposes in clinical trials (Lorenzi et al., Fig. 3 . Posterior prediction for the individual time shift in testing data by using i) only the baseline information (1a-b), and ii) the baseline \u00fe follow-up information available for each testing subject (2a-b). Healthy individuals are generally displaced at the early stages of the pathology, while the predictions for MCI and AD patients are associated with respectively intermediate and late progression stages. The results are similar for both scenarios, although by adding the follow-up information we largely reduce the uncertainty in the prediction of the individual's pathological stage (subfigure 1a vs 2a). NL: normal individuals, MCI: mild cognitive impairment, AD: Alzheimer's patients. 2010; Yu et al., 2014; Hill et al., 2014) .\nThe modelled progression showed that neuropsychological tests generally lead to lower uncertainty for identifying the individual clinical stage, and to the higher separation power between healthy and AD groups. This finding is compatible with the results reported by previous disease progression models applied to ADNI, such as (Jedynak et al., 2012) and (Young et al., 2014) . In this latter study ADAS13 consistently appeared among the first events distinguishing the normal disease stages from the pathological ones. Furthermore, our analysis further showed that volumetric measures such as hippocampal and entorhinal volumes provide equivalent if not superior diagnostic performances when tested on the more challenging problem of detecting conversion to dementia from healthy and MCI stages, especially in terms of improved AUC. Nevertheless, some care should be taken in drawing conclusions from the present analysis. Our model was based on the standard volumetric measures provided in the ADNI database, and we cannot exclude that a more precise quantification of morphological brain changes would lead to even better performance of volumetric biomarkers (Wolz et al., 2010; Cash et al., 2015) . Furthermore, the proposed model was not optimized in order to maximize the classification accuracy between clinical groups. For example, the results reported in Table 3 are based on the choice of the temporal threshold corresponding to the reference value of the 15th percentile of the AD distribution. This cut-off was not optimized to maximize the predictive outcome of the biomarkers, but was rather chosen based on heuristics aimed at illustrating the use of the model for predictive purposes. We thus cannot exclude that the optimization of the temporal threshold would lead to different figures for the classification task. The reported results are therefore indicative of the effectiveness of the model in faithfully representing the clinical spectrum of the disease. We note also that the reported figures are in line with those provided by state-of-art methods in AD classification, without requiring complex parameter optimization procedures, which would introduce additional levels of cross-validation and expose the results to selection bias and generalization issues . Thanks to the probabilistic formulation we showed that the use of longitudinal information is important for reducing the uncertainty of the prediction, and thus allowing one to better identify the disease status associated to an individual. This important aspect is in agreement with the generally higher statistical power reported in previous Alzheimer's studies comparing longitudinal measurements to baselines ones (Henneman et al., 2009; Frisoni et al., 2010; Xu et al., 2014) .\nIn this work we focused on the modeling of the progression of amyloid positive individuals. This choice was motivated by the interest in assessing the model performance on an homogeneous clinical population likely to be representative of the Alzheimer's evolution. While the absence of pathological amylod levels seems indicative of non-Alzheimer's pathophysiology (Gordon et al., 2016; Mormino et al., 2016) , there is currently an active debate on the mechanisms of neurodegeneration not related to brain amyloidosis (Jack et al., 2016) . The investigation of these aspects goes beyond the scope of the present work, and future extensions of disease progression modeling will aim at identifying differential progressions underlying sub-pathologies, for example by reformulating the proposed random effect regression within the realm of Gaussian process mixture models (L azaro-Gredilla et al., 2012; Ross and Dy, 2013) . Analogously, the MCI population used for model training was composed exclusively by MCI individuals subsequently converted to AD, in order to train the model on a homogeneous data most likely to include the largest representation of individuals effectively affected by Alzheimer's disease. Although the inclusion of MCI stable could provide additional information on the intermediate pathological stages, this choice may probably lead to larger variability in the training set, as stable MCI are generally characterized by larger heterogeneity, either cross-sectionally and longitudinally, and higher diagnostic uncertainty. This modeling choice was also motivated by practical reasons since, thanks to the adopted data selection scheme, we were able to validate the model on a large and independent set of testing individuals including an important sample of MCI individuals across different clinical stages, thus providing a thorough and stringent assessment of the predictive qualities of the proposed approach."}, {"section_title": "Methodological considerations", "text": "From the methodological perspective, we proposed a novel probabilistic approach based on Gaussian process regression for disease progression modeling from time-series of biomarker measurements enabling novel applications beyond the state-of-art, such as the probabilistic prediction of disease staging in testing individuals. Furthermore, the model naturally accounts for missing data, and provides uncertainty quantification of the biomarker evolutions. Similarly to (Donohue et al., 2014) , in this work we focused on the modeling of disease staging represented by a time shift, although the proposed framework can naturally account for more complex time transformations, provided that a sufficient number of time points is available for each individual.\nFrom the methodological point of view, the proposed model extends current approaches to GP-regression by consistently integrating timereparameterization and monotonic constraints within a random effect regression framework. Monotonic GPs were introduced in (Riihim\u20ac aki and Vehtari, 2010) as a principled regularization solution to improve the plausibility of modeling results. For example, the strength of such a regularization approach in biomedical applications has been illustrated in survival analysis (Joensuu et al., 2012) . Our approach extends this framework by consistently integrating a latent time variable parameter within a random effect model formulation.\nThe idea of estimating a time transformation in a GP regression framework has been previously used by (Liu et al., 2010) to account for uncertain measurement times to a microarray dataset of mRNA. However, in that work the estimation of the time uncertainty was subject to a strong prior constraint based on the assumption that the unknown biological time must be similar to the measured one. In the application proposed in our work such an assumption is no longer valid and would ultimately lead to implausible estimations. On the contrary, the proposed GP regression is able to recover the underlying time transformation thanks to the proposed monotonicity regularization.\nFinally, thanks to the flexibility of the proposed Gaussian process framework, further extensions of the model will enable to consistently integrate a spatio-temporal covariance model, such as the efficient Kronecker form of (Lorenzi et al., 2015) , to provide a unified framework for jointly modeling time series of images and scalar biomarkers data in a coherent fully Bayesian setting."}, {"section_title": "Conclusions", "text": "This work proposes an extension of DPM for the accurate quantification of the diagnostic uncertainty in Alzheimer's disease. The proposed application shows that DPM provides at the same time a plausible description of the transition from normal to pathological stages along the natural history of the disease, as well as remarkable diagnostic performances when tested on de-novo individuals. The model used in this study can account for any missing data patterns (longitudinal or across biomarkers), and allows to directly quantify the uncertainty related to the missing information. It thus represents a novel and promising tool for the analysis of clinical trials data."}, {"section_title": "Further information", "text": "The open-source code as well as the proposed predictive model trained on ADNI data will be available at the author's web-page: https:// team.inria.fr/asclepios/marco-lorenzi/. The realization of this study required about 1.5kWh of computing power."}]