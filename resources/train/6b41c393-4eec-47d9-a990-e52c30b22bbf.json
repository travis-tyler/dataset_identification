[{"section_title": "Abstract", "text": "Multi-atlas segmentation is a powerful approach to automated anatomy delineation via fusing label information from a set of spatially normalized atlases. For simplicity, many existing methods perform pairwise image registration, leading to inaccurate segmentation especially when shape variation is large. In this paper, we propose a dynamic tree-based strategy for effective largedeformation registration and multi-atlas segmentation. To deal with local minima caused by large shape variation, coarse estimates of deformations are first obtained via alignment of automatically localized landmark points. The dynamic tree capturing the structural relationships between images is then employed to further reduce misalignment errors. Evaluation based on two real human brain datasets, ADNI and LPBA40, shows that our method significantly improves registration and segmentation accuracy.\nOnce the tree is built, registration between a pair of images in the tree can be achieved using the root atlas A r as the bridge (Fig. 3) . Specifically, we use the following steps to warp an image I s to another image I t : (1) determine the path that connects I s and A r ; (2) perform pairwise registration between adjacent images along this path from I s to A r ; (3) concatenate Zhang et al."}, {"section_title": "Introduction", "text": "Multi-atlas segmentation is an automated approach to delineating anatomical structures of a target image by borrowing complementary information from multiple pre-annotated atlases. Segmentation labels from multiple atlases that are registered to the target image are combined to obtain the ultimate segmentation result. This approach avoids not only timeconsuming manual annotation but also potential bias introduced by segmentation with only one single atlas. Due to its promising results, it has been widely used in medical image analysis to segment the brain (Aljabar et al., 2009; Asman and Landman, 2013) , heart (I\u0161gum et al., 2009; van Rikxoort et al., 2010; Bai et al., 2015) , and abdominal organs (Wolz et al., 2013) .\nAlthough much effort has been dedicated to improving the accuracy of label fusion, much less emphasis has been put on image registration. Most of the existing multi-atlas segmentation methods merely perform simple pairwise registration (Asman and Landman, 2013; Bai et al., 2015) by aligning each atlas independently to the target image. This approach fails to consider the correlation between atlases and thus leads to inconsistency among the atlases when labeling the same anatomical structure. Simple pairwise registration also does not take advantage of the structural similarity between images to help overcome registration related problems such as local minima. Such problem occurs quite often when images from different populations (i.e., patients and healthy controls) vary dramatically in anatomical structures.\nThere have been some recent attempts to overcome the above problems by using more sophisticated registration strategies. For example, Hoang Duc et al. (Hoang Duc et al., 2013) attempted to establish the relationship across atlases and the target image by iteratively registering them to an evolving group mean image (Rohlfing et al., 2004) . However, this only works well when images in the group can be registered reasonably well. Also, the mean image is sensitive to registration outliers and may be unstable in case of large shape variation. A better approach described in (Jia et al., 2012) links images according to their similarity using a tree and performs a series of registration of adjacent images. This breaks down the complex registration process into a number of simpler ones and helps reduce local minima.\nIn this paper, we describe a registration scheme for multi-atlas segmentation under large deformation. Similar to (Jia et al., 2012) , a tree is used for robust registration. The registration outcome is then applied for multi-atlas segmentation of either a single image or a group of images. Our work differs from (Jia et al., 2012) in three major aspects. First, images with similar intensity values are not necessarily similar in anatomy. Hence, in contrast to (Jia et al., 2012) , we propose to construct the tree using shape similarity evaluated based on the distance of points localized at structure boundaries in different images. Second, unlike the affine registration based initialization as used in (Jia et al., 2012) , we use the localized landmark points to initialize image registration. Good initialization has been shown to be able to significantly improve registration accuracy, particularly when dealing with large shape variation (Zhang et al, 2010; Zhang and Cootes, 2011; Zhang and Cootes, 2012; Zhang et al, 2012b; Wu et al, 2011) . Finally, we propose to utilize a dynamically updated tree, as opposed to the fixed one used in (Jia et al., 2012) . This is to ensure connections between images to be progressively refined to reduce misalignment."}, {"section_title": "Methodology", "text": "Our goal is to label one or more target images using a set of atlases, each with an intensity image and a segmentation image obtained by manually labeling some regions of interest (ROIs). Each target image is only an intensity image and does not have any label. To simultaneously register all atlases and target images for consistent segmentation, we use the following steps: (1) seek corresponding points among atlases and target images (Section 2.1); (2) perform initial registration using a tree generated by connecting all images using the corresponding points (Section 2.2); (3) iteratively update the tree and registration results (Section 2.3). Label fusion (e.g., weighted voxel-based fusion (Jia et al., 2012) and patchbased fusion (Zhang et al, 2012a) ) can then be carried out for segmentation of the target images using the registered atlases. Each step is described in details below."}, {"section_title": "Localization of corresponding landmark points", "text": "We follow the method described in (Han et al., 2014) to detect landmark points on an image. A set of landmark points is first generated for each atlas in a semi-supervised manner. These points, together with the atlases, are then used to train a series of point detectors, one for each landmark, using regression forests (Criminisi et al, 2012) . For a target image, each trained detector is finally applied for landmark localization. These steps are described briefly below. The interested reader is referred to (Han et al, 2014) for more details.\nTo generate the landmark points for each atlas, we randomly choose one atlas as the reference and break it down into a large number of patches (i.e., 30 \u00d7 30 \u00d7 30). For each patch, we use a method similar to (Wu et al., 2013) to generate landmark point candidates. To remove the candidates within flat regions, we further compute the gradient magnitude of each candidate and rule out those below a user-defined threshold. The left landmark points are then propagated from the reference atlas to the rest of the atlases via non-rigid registration of segmented images (as well as manually annotated images if needed). Examples of the generated landmark points are shown in Fig. 1 . Note that the generated landmark points are not always on the boundary. Here we only show some good ones for illustration purpose.\nBy using the landmark points in the atlases, we train a detector for each landmark point to predict its position from Haar-like features of nearby voxel neighborhood. We systematically sample a number of voxels around each landmark point, record their displacements to the landmark point and their Haar-like features computed in the neighborhood (Viola and Jones, 2001) . Repeating this process for the corresponding landmark points in the other atlases leads to a set of displacement-feature pairs that can be used to train the detector to predict the displacement of the landmark point from each voxel based on its Haar-like features. To learn such highly non-linear relationship, we use the regression forest (Criminisi et al., 2012) .\nA regression forest consists of a collection of binary decision trees, each trained individually using a random subset , where represents displacement vectors and \u210b denotes image samples. For each tree, the training involves splitting the subset by passing it through a series of tests starting at the root until each sample in the set reaches a leaf of the tree (Fig.  2 ). The node that performs a specific test is called a split node, which distributes the incoming samples to its left or right child node based on the result of the test. The leaf node stores an empirical conditional probability distribution p(\u03b4|h), over the displacement \u03b4 given the samples h The test at split node t is usually realized by maximizing the following information gain Zhang et al. Page 3 Comput Med Imaging Graph. Author manuscript; available in PMC 2017 September 01."}, {"section_title": "Author Manuscript", "text": "\nAuthor Manuscript\nwhere IG t is the information gain, is a set of displacements associated with the incoming samples, L/R represents the left/right child of the current node, is a subset of displacements associated with the samples sent to a child, and S measures the consistency of a set of displacements. p(\u03b4|h) is approximated by a Gaussian distribution and thus each leaf node only stores the mean and covariance of the displacements associated with the samples reaching that node. The trained regression forest is used as a point detector. Note that the decision trees here are only used for regression and should not be confused with the tree built for image registration, which will be detailed in Section 2.2.\nTo predict \u03b4 for a given voxel, the sample h is passed to the detector until it reaches a leaf node of each tree. Although the final \u03b4 can be computed by averaging the mean displacement stored at each leaf node, this scheme is sensitive to large local anatomical variations. A \"point jumping\" technique and a multi-resolution strategy are used instead for robust prediction (see Han et al. (2014) for details).\nAuthor Manuscript\nAuthor Manuscript\nOnce we have computed the connection appropriateness of each target image, we can select a subset of target images with the best connections to the tree. This can be achieved by ranking all the target images by the appropriateness and choosing the top ones. Let be the set of atlases, the selected subset of target images, and the rest of the target images. We repeat the following steps until , or no new tree can be generated:\nAuthor Manuscript\nAuthor Manuscript Overall Dice ratios of 54 ROIs of the LPBA40 dataset after sparse patch based label fusion. "}, {"section_title": "Tree construction and initial registration", "text": "Once the landmark points for all atlases and target images have been localized, we use them to build a tree connecting images that are similar in anatomy for initial registration. Based on (Jia et al., 2012) , we utilize the atlases to build a tree, onto which each target image is progressively attached. This helps avoid having to rerun the registration, whenever a new image needs to be segmented.\nAn adjacency matrix is first generated based on the Euclidean distance between the corresponding landmark points of each pair of atlases. Based on the adjacency matrix, a minimum spanning tree is then generated using Prim's algorithm. Each edge of the tree connects a pair of atlases and encodes their distance. In the tree, any pair of atlases are connected by a unique path (i.e., a set of edges). An atlas with the least sum of distances to all other atlases is chosen as the root of the tree. This root is fixed throughout the whole registration process.\nTo attach the target images to the tree, we repeat the following steps: (1) choose an unlinked target image, find out an atlas that is closest to it and record their point-to-point distance; (2) group such distances across the set of unlinked target images; (3) select the unlinked target image that has minimum of such distance; (4) connect it to its closest atlas. Note that once a target image is attached to the tree, it is treated as an atlas when adding other unlinked target images to the tree. As a result, a target image may be connected to either an atlas or another target image in the final tree.\nthe resulting deformation fields to obtain the deformation field from I s to A r , denoted as ; (4) repeat the above three steps to obtain the deformation field from I t to A r , denoted as ; (5) estimate the inverse of , denoted as ; (6) compute the deformation field from I s to I t ,\n, by concatenating , and , i.e., , where \u2218 is a composition operator. In the current work, registration between adjacent images is performed using diffeomorphic Demons (Vercauteren et al., 2009) .\nThe above process is repeated to register all atlases to each target image. The resulting deformation fields are then used to warp the segmentation images associated with the atlases to target images for segmentation via label fusion.\nAlthough we use corresponding landmark points to encourage connections between images of similar anatomy in the initial tree construction, some target images may be still inappropriately connected to the tree due to the simple Euclidean distance for similarity, thus introducing more local minima to registration. This is especially the case when registering images under large deformation. To reduce local minima caused by large shape variation, here we propose two solutions: one is to initialize the registration with the corresponding points, which can be achieved by thin-plate spline (TPS) interpolation, and the other is to reconnect target images that are inappropriately connected, which will be detailed below."}, {"section_title": "Iterative registration with dynamic tree", "text": "As it is difficult to know whether a target image is appropriately connected to the tree without carrying out registration, we introduce a feedback loop after initial registration to find out those poorly connected target images. Since their links to the tree may keep changing through iterations, the tree is dynamic, not fixed any more.\nTo determine the appropriateness of the connection of a target image to the tree, we warp the landmark points of an atlas onto the target image by linearly interpolating the deformation field between the two images. We then average the distances between all warped points and their corresponding counterparts on the target image. We repeat this process for all atlases and finally obtain an overall average landmark distance that can be used to tell how well the given target image is connected to the tree. A smaller overall distance indicates better connection.\nAs the landmark points only cover the brain sparsely, the above metric merely gives a coarse indication of the appropriateness of the connection. For more localized sensitivity, we also (1) warp the segmentation images of the atlases onto the target image, (2) estimate a segmentation image for the target image using the set of warped segmentation images via a weighted label fusion method (Jia et al., 2012) , (3) warp the resulting segmentation image back onto each atlas, and (4) compute the Dice ratio between the segmentation image of each atlas and the warped segmentation image of the target image. We use the overall Dice ratio, computed by averaging the ratios across ROIs and atlases, as another metric for evaluation of connection appropriateness. This segmentation-based metric is combined with the above landmark-based metric via weighted averaging to form a combined metric after normalizing both to have a zero mean and a unit variance. Zhang et al. Page 5 Comput Med Imaging Graph. Author manuscript; available in PMC 2017 September 01."}, {"section_title": "1.", "text": "Rebuild the connections of the images in to the tree by recursive attachment as described in Section 2.2. Note that the images in are treated as atlases and their links to the tree will not be changed in this process. The combined metric, instead of the landmark distance, is used to guide the reattachment process."}, {"section_title": "2.", "text": "Run registration with the new tree. As the images in are well linked to the tree, the deformation fields between those images and atlases are likely to be reliably estimated. Hence, we can use these deformation fields to guide the registration between a pair of images, I s and I t , as follows ( Fig. 4) : (i) find its most recent ancestor node in for target image ; (ii) estimate the deformation field from the ancestor to I t ; (iii) concatenate the resulting deformation field with that from I s to the ancestor; (iv) use the composite deformation field to initialize the registration from I s to I t ."}, {"section_title": "3.", "text": "Extend by adding the images in whose connection appropriateness improves after registration. If not enough images are added, we rank all images in by the connection appropriateness and choose the top ones as before. This is to ensure that the whole registration completes in a few iterations for efficiency. We require at least a fixed portion (i.e., 10%) of the targeted images to be added to at each iteration."}, {"section_title": "Experiments", "text": "We demonstrate the efficacy of our method on two real datasets: the ADNI dataset 1 and the LPBA40 dataset (Shattuck et al, 2008) . For each dataset, FLIRT (Jenkinson and Smith, 2001; Jenkinson et al., 2002) was used to align all the images via affine transform to a common space. These images were then used for all subsequent experiments.\nThe segmentation images in the two datasets were used for evaluation. Segmentation of the LPBA40 dataset was carried out by experts. Only 54 out of the 56 labels were used for evaluation, by excluding the cerebellum and brainstem. Segmentation of the ADNI dataset into gray matter (GM), white matter (WM), cerebrospinal fluid (CSF), and ventricle (VN) was done using FAST (Smith et al., 2004; Zhang et al., 2001) .\nEach point detector was trained at 4 different image resolutions, at each of which 10 trees were trained, amounting to a total of 40 trees. To train a detector, we sampled 6000 voxels around the landmark point and computed their Haar-like features based on the intensity image of each atlas. The number of samples is proportional to the reciprocal of the distance between the landmark point and the sampled voxels. For each tree in the regression forest, the maximum depth was set to 12 and the input of each leaf node was required to be at least 10 sampled voxels.\nWe compared our method with the method proposed by Jia et al. (2012) (MABMIS for short), which builds a fixed tree based on image intensity difference to guide the registration for multi-atlas segmentation. The code is available at http://www.nitrc.org/projects/mabmis. The comparison is to show the advantage of the use of shape similarity for tree construction, corresponding landmark points for registration initialization, and the dynamic tree registration scheme for registration correction. Although it is interesting to compare our method with pairwise registration, a detailed comparison has already been done in (Jia et al., 2012) , where the results clearly show that the tree-based registration works much better than pairwise registration. Hence, we decided not to carry out that comparison in this work. The reader is referred to (Jia et al., 2012) for detailed results.\nWe computed the Dice ratio of the segmentation image of each target image with respect to the segmentation image of each atlas after warping to the space of the target image. Averaging the Dice ratios across atlases for each target image and then across target images leads to an overall Dice ratio that was used for quantitative evaluation of the methods. Note that diffeomorphic Demons (Vercauteren et al., 2009 ) was used to register adjacent images in all the experiments throughout this paper."}, {"section_title": "ADNI dataset", "text": "We randomly selected 150 baseline images from the dataset: 50 from healthy controls, 50 from mild cognitive impairment patients, and 50 from Alzheimer's disease patients. All of the selected images were then preprocessed using the following steps: (1) Anterior commissure/posterior commissure alignment correction; (2) Inhomogeneity correction using the N3 algorithm (Sled et al, 1998) ; (3) Skull stripping using Brain Surface Extractor (Shattuck and Leahy, 2002) and Brain Extraction Tool (Smith, 2002) ; (4) Intensity normalization via histogram matching.\nWe randomly chose 10 images from each group as the atlases and used the rest as the target images that need to be segmented, leading to 30 atlases and 120 target images. Using an atlas as the reference, we generated over 500 landmark points covering the whole brain and propagated them to other atlases. The landmark detectors, trained using these landmark points, were applied to localize landmark points in each target image.\nThe landmark points were used to build a \"point\" tree (p-Tree) and based on this tree the images were registered as described in Section 2.2. To demonstrate the effectiveness of the p-Tree in image registration, we built an \"intensity\" tree (i-Tree) using the intensity differences between images, as in MABMIS. The overall Dice ratios shown in Table 1 indicate that, compared with the i-Tree, the p-Tree improves registration accuracy. Since both i-Tree and p-Tree follow the same construction procedure, the improvement suggests that the shape similarity helps link images that are truly similar to each other and thus leads to a better tree than the tree built with intensity similarity.\nThe registration between adjacent images in the above p-Tree was initialized by the identity deformation field. Since we have corresponding landmarks, we can use them to estimate a better deformation field for initialization using thin-plate spline (TPS) interpolation, leading to p-Tree+TPS. Table 1 shows that such initialization can remarkably improve the final registration accuracy, indicating that careful initialization is very important for registration. Further improvements can be obtained using the dynamic tree registration strategy described in Section 2.3 to correct the poorly connected target images in the p-Tree, i.e., disconnecting them from the old nodes and then linking them to the new ones to form better registration paths. The improvement given by the dynamic tree based method is statistically significant (two-tailed t-test, p < 0.01) when compared with each of the other methods. For example, the improvement is 0.8%, 1.8% and 2.2% within the VN, GM and WM, compared with the MABMIS method."}, {"section_title": "LPBA40 dataset", "text": "The above experiment was repeated for the LPBA40 dataset. Specifically, 8 out of the total 40 images were used as atlases. This was also the portion of atlases used for the ADNI dataset. Fig. 4 indicates that, compared with i-Tree, the p-Tree + TPS is similar or significantly better for most ROIs. In fact, the accuracy is increased by more than 1% for 29 out of 54 ROIs, with the largest improvement given by the left postcentral gyrus (5.6%). Fig.  5 also shows that the results are further improved by the dynamic tree based strategy. In particular, 26 out of 54 ROIs show over 1% improvement in accuracy, compared with the result from the p-Tree + TPS. The maximum improvement is given by the right postcentral gyrus (2.4%). Averaging the overall Dice ratios over all 54 ROIs leads to 67.4%, 68.6%, and 69.6%, respectively, for the three methods shown in the figure.\nWe further demonstrate the advantages of our method using multi-atlas segmentation with the sparse patch based label fusion method described in (Zhang et al., 2012a) . Fig. 6 shows that our method gives significant improvement over MABMIS. Compared with MABMIS, p-Tree+TPS leads to 27 out of 54 ROIs with more than 1% improvement in segmentation accuracy. The maximum improvement is given by the left postcentral gyrus (3.3%). The segmentation accuracy is further improved by the dynamic tree based registration, with more than 1% improvement for 22 out of 54 ROIs, compared with p-Tree +TPS. The left cuneus\ngives the largest improvement (3.4%). The averaged overall Dice ratios for the three methods are 73.0%, 73.8%, and 74.7%, respectively, for the three methods shown in the figure."}, {"section_title": "Conclusions and future work", "text": "We have described a method that can accurately register a set of atlases to a set of target images for multi-atlas segmentation. Our method deals with large-deformation registration by using landmark points in a dynamic tree-based image registration strategy. Local minima caused by large shape variation can be reduced by (1) encouraging the registration between images with comparable anatomy, (2) good registration initialization, and (3) dynamic reconnection of images to the tree.\nTo localize the corresponding landmark points, we train a number of detectors using regression forests. Although it will be worth fine-tuning parameters (i.e., number of decision trees, and the depth of each tree) for better localization accuracy, this is not practical at the moment due to long training time (i.e., days). For registration, we use a multi-resolution strategy to register all the images in the initial tree for accuracy, while we only perform registration at the original scale when dynamically correcting links of poor target images for efficiency.\nExperiments show that our method is able to achieve good results on two real datasets. We show that our method is superior to a tree based image registration (Jia et al., 2012) . It can not only further improve registration accuracy, but also greatly help label fusion for better segmentation. This clearly demonstrates the importance of accurate image registration for multi-atlas segmentation. In the future, we will investigate a more advanced approach to using the landmark points for both tree construction and registration initialization. Examples of the generated landmark points. Note that some landmarks reside in difference slices and might not be visible. Illustration of training a binary decision tree. A random subset is fed into the root node (red) of the tree. After a specific test, the root node sends each sample in the subset to one of its children. This process is repeated by splitting nodes (brown) until each sample reaches a leaf node (green), which stores empirical conditional probability distribution. A possible path through which a sample may go is highlighted by a set of red lines ending with a red arrow. Zhang et al. Page 12 Comput Med Imaging Graph. Author manuscript; available in PMC 2017 September 01."}]