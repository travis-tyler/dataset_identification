[{"section_title": "Introduction", "text": "In shallow water hydrodynamics, especially in coastal regions, channels and overland flows, bottom stress induced by surface roughness heavily influences flow behavior. Bottom stress is typically parameterized using the Gauckler-Manning-Strickler formula which relates average cross-sectional velocity, hydraulic radius, and the channel bed slope [1,2,3,4,5] and includes a coefficient that depends on the specific characteristics of the bottom surface according to standard definitions. In this paper, we use Manning's formula to describe bottom stress and focus on the determination of the so-called Manning's n coefficient, which is a spatially dependent field variable. Additionally, we investigate the indirect determination of the Manning's n coefficient from observations on the state of water elevation and momentum, where Manning's n coefficient is connected to wave motion through a deterministic shallow water model. This is an example of an inverse problem whose solution provides the basis for scientific inferences for a deterministic, physics-based model. The goal is to predict unobserved behavior of a system using the mathematical model fed by input data and parameters that characterize the physical properties of a given state of the system. However, it is often infeasible or prohibitively expensive to experimentally observe all of the important input quantities that characterize the physical properties of a given state. Rather, the available data tends to be on observable aspects of the state of the system itself. Moreover, the set of observable quantities is generally different than the set of quantities to be predicted because of physical limitations in what, where, and when data can be collected. In Fig. 1, we illustrate the abstract process of solving an inverse problem for a physics-based model in order to provide the input for scientific inferences based on model predictions. The physics-based model is given as a set of differential equations whose solution produces a map between the space of input data and parameters to the solution space. A set of functionals form a map from the solution space to the space of observable quantities, while another set of functionals map the solution space to the space of quantities we wish to predict. These are illustrated by the red arrows. Note that the observation and prediction functionals can be physically different transformations or they can be the same set of transformations but evaluated at different times and locations. To solve the prediction problem, we first solve the inverse problem for the map from the space of input data and parameters to the observation space obtained by composing the observable functionals with the solution of the physics-based model. We then solve the model \"forward\" with those data and parameter values and apply the prediction functionals to the solution(s) to produce the prediction. This flow is illustrated with black arrows. The determination of Manning's n for a model of coastal hydrodynamics provides a concrete example. Manning's n characterizes the momentum loss due to bottom friction that affects bottom stress in a hydrodynamics model in Manning's formula for drag. The Gauckler-Manning-Strickler formula was originally developed for open-channel flow in a fullyturbulent fairly regular unvegetated domain [1,2,3,4,5,6]. For open-channel flow that meets these assumptions Manning's coefficient may be determined indirectly from field or laboratory measurements of flow characteristics or from a sampling of the diameters of roughness elements [7,8,9,10]. Arcement and Schneider [11], along with Chow [12], and Barnes [8] have provided guides for selecting Manning's coefficient that extend the original domain of application to flood plains, vegetated water ways, and channels with irregular boundaries. These guides supply tables [12], photographic guides [8], and a combination thereof [11]. Furthermore, Manning's formula, although extremely useful, is not the correct model of momentum loss due to vegetation in natural waterways as Manning's formula models bottom friction not the complex form drag of flexible vegetation [13,14,15]. However, complex hydrological models require some representation of momentum loss due to a combination of bottom friction, vegetation, bed-forms, and the porous media-like structures that occur in coastal estuaries [16,17,18]. Detailed field measurements can be used to determine Manning's coefficient through hydraulic calibration for a specific geographical location [19]. Unfortunately, it would be extremely cost prohibitive to use field measurements to estimate Manning's n for these conditions at a fine detail over a large physical domain. One set of observation data that is available in coastal hydrodynamics is the maximum water surge heights at various fixed observation stations. We aspire to leverage the land cover and classification data collected by the NCLD and CCAP projects to estimate Manning's coefficient for these types of computational modeling problems [20,21,14,22]. This sets up the problem of determining the Manning's n values from the maximum surge height data by solving the inverse problem for the shallow water hydrodynamics model. A related prediction problem is then to use the computed Manning's n to predict inundation at certain critical points in the domain, e.g. near physical barriers intended to reduce the effects of flooding. The inverse problem for prediction is complicated by two issues. First, the map from the data and parameter space to the observable space generally reduces the dimension, i.e. it is a \"many-to-few\" map. This means that the inverse problem has set-valued solutions, i.e. there is a set of possible data and parameters values corresponding to each observation data point. Second, all of the available data is subject to natural variation as well as experimental/ observational error so the solutions of the inverse problem for parameter determination and the forward prediction problem are described in terms of probability measures. Both of these issues can be addressed directly by measure theory, which provides a very natural framework for the formulation, solution, and numerical approximation of the inverse problem for scientific inference [23,24,25,26]. Measure theory is fundamentally based on the notion of an inverse of a map, and so the measure theoretic description of the stochastic inverse problem given below is universal in nature. There are other ways to formulate inverse problems for determining parameters in models. For example, the most common deterministic approach alters the inverse problem through \"regularization\" to obtain a new problem that has a unique solution. Numerically, the solution is often formulated as the solution of an optimization problem that is then solved approximately [27]. There are other techniques for solving stochastic inverse problems, e.g. Bayesian approaches [28,29,30] and Kalman filtering [31]. However, outside of our solution approach, we do not know of any stochastic solution methods that clearly adhere to the structure of the inverse problem, i.e. set-valued solutions, of the original model. It may be that they are in fact either solving a different inverse problem (as is the case when a parameterized distribution is assumed for the solution) or have altered the original problem (Bayesian approaches often implicitly involve regularization). In the following, we let Q denote the map formed by the composition of the observable functions with the solution operator of the model, \u039b denote the domain of input values for Q, and \u2254 Q(\u039b) denote the range. This Q should not be confused with the quantities Q x and Q y in the shallow water equations."}, {"section_title": "Description of the model and the Manning's n parameter field", "text": "Assuming hydrostatic pressure and domains with large horizontal length scales relative to vertical length scales, the shallow water equations (SWEs) are used to model the hydrodynamic system. The SWEs can be derived by depth integration of the incompressible Navier-Stokes equations or directly from the integral form of the fundamental equations of fluid dynamics, resulting in a coupled system of equations consisting of a first-order hyperbolic continuity equation for water elevation and momentum equations for horizontal depth-averaged velocities. Let \u03b6 denote the free surface elevation relative to the geoid, then the continuity equation is given by (2.1) and the momentum equations for depth-averaged x-and y-velocities (denoted by U x and U y , respectively) are given by Here, h is bathymetric depth relative to the geoid, H = \u03b6 + h is the total water column height, f is the Coriolis parameter, P s is the atmospheric pressure at the free surface, \u03c1 0 is the reference density of water, and \u03b7 is the Newtonian equilibrium tide potential. Letting x i = x or x i = y, then Q x i = U x i H is the flux per unit width in the x i direction, M x i is the verticallyintegrated lateral stress gradient, D x i is the momentum dispersion, and B x i is the verticallyintegrated baroclinic pressure gradient. Finally, \u03c4 sx i are the imposed surface stresses and \u03c4 bx i are the bottom stress components. In regions where water depths are quite shallow; e.g., low-lying coastal areas, tidal flats, channels, etc., the bottom stress components \u03c4 bx i are more sensitive to Manning's coefficent (Eq. 2.2). These are defined using a linear or quadratic drag law through the coefficient K slip , We utilize a quadratic drag law, so K slip = C f |U|. The constant C f is determined using the Manning's n formulation, (2.2) where n denotes the Manning's n coefficient of roughness. Note that for H sufficiently small C f is set to a fixed constant to prevent division by zero."}, {"section_title": "Numerical solution of the hydrodynamic model and quantities of interest", "text": "We use ADCIRC to solve a hydrodynamic model that depends on 16 parameter fields, including bottom stress, bathymetric depth, and surface stress, using finite element methods on unstructured triangular meshes discretizing the spatial domains and using finite difference schemes in time. In ADCIRC, the continuity equation, Eq. (2.1), is replaced by a second-order, hyperbolic generalized wave continuity equation (GWCE) [32,33] to reduce spurious oscillations that can occur in numerical solution of the form of the SWEs discussed above [34]. The steps for obtaining the GWCE are: (1) a multiple, \u03c4 0 \u2265 0, of the continuity equation is added to the time derivative of the continuity equation, (2) bathymetric depth is assumed constant in time, i.e., \u2202H/\u2202t = \u2202\u03b6/\u2202t, and (3) substitute the momentum equations into the continuity equation. The interested reader can find all details of these equations, their derivation, and numerical implementation in ADCIRC in [35]. The ADCIRC model has undergone extensive verification and validation, e.g., using hindcast studies with data from hurricanes over the last five decades including including Hurricanes Betsy (1965), Ivan (2004), Dennis (2004), Katrina (2005), Rita (2005), Gustav (2008), and Ike (2008) [36,37,16,17,38]. ADCIRC has also been used to generate tidal constituent databases for the eastern coast of the conterminous U.S. [39]. The verification and validation studies of ADCIRC have consistently shown that the maximum water heights obtained from the model are in excellent agreement with those observed in the field by fixed observation stations. Therefore, in this work, we consider the quantities of interest as the maximum heights at a given set of locations."}, {"section_title": "Formulation and solution of the stochastic inverse problem", "text": ""}, {"section_title": "Measure theory and inverse problems", "text": "Probability is introduced when we assume stochastic models for the natural variations and experimental error in data. However, this also introduces measure theory because rigorous probability is described in terms of measure theory [40]. Measure theory is based on the concept of inverse problems, hence a rigorous probabilistic description of the inverse problems for parameter determination in the presence of stochastic variation has a very specific mathematical formulation. There are features of this formulation that must inform any approximate solution technique for the original stochastic inverse problem for a deterministic model. There are other ways to formulate inverse problems for parameters in a model and solution techniques that involve altering the original stochastic inverse problem. We give brief descriptions of examples below at appropriate places. To our knowledge, a systematic comparison of different inverse problems for parameter determination has not been carried out. Below, we summarize the ingredients of measure theory briefly, and then express the relevant results about inverse problems and probability measures in terms of iterated integrals in several dimensions. The expression of probability measures in terms of integrals is key to all stochastic or deterministic approximate solution methods. In this way, we present a technically correct, numerically relevant description of the consequences of rigorous measure theory that is accessible to a wide technical audience. We then describe how we exploit these results to produce a numerical solution technique. The ingredients of measure theory are: (1) a domain; (2) a \u03c3-algebra; and (3) a (probability) measure. After specifying the domain of interest (\u039b), a \u03c3-algebra (\u212c \u039b ) is the class of subsets in the domain for which it makes sense to compute the (probability) measure. In the case of a probability measure, the sets in \u212c \u039b are called events. The pair (\u039b, \u212c \u039b ) defines what is called a measurable space. A measure can only be defined once a domain and a \u03c3-algebra are specified (i.e., once a measurable space is defined). There are typically many possible measures on a given measure space. The notion of a \u03c3-algebra is often presented as an abstract construction involving infinite sequences of set operations, e.g., intersections, unions, complements, beginning with simple sets. However, this construction is actually grounded in practical numerical approximation. Many natural probability questions lead to the need to compute the probability measure of very complex events. This is carried out by approximating complex events by collections of simpler sets, e.g. generalized rectangles when \u039b \u2282 \u211d m , and then computing a piecewise constant approximate probability measure with respect to the approximating sets. The central theoretical foundation of measure theory insures this approach works. Another key ingredient of measure theory is the concept of measurable function, or random variable in the case of a probability measure. In particular, measurable functions such as probability densities are those functions which can be integrated over measurable sets. A measurable function is defined in terms of the behavior of its inverse with respect to the \u03c3 \u2212algebras on its domain and range. Specifically, if the preimage (inverse) of any set in the output \u03c3-algebra is a set in the input \u03c3-algebra, then the function is said to be measurable. Examples of measurable functions include the physics-based maps from input parameters to observable data and probability densities which map the measurable spaces into the nonnegative real numbers. Given a measure/probability on a measurable space, a measurable function on this space induces a measure/probability on the output space of the measurable function in terms of the inverses of measurable sets. Thus, measure theory is ideal for both the formulation and solution of the inverse problem for scientific inference using deterministic models even in cases where the inverse of the measurable map is set-valued."}, {"section_title": "The generalized contours of an inverse problem", "text": "In the most idealized case, a map Q : \u039b \u2192 assigns distinct output values to distinct input values, so the inverse of the map is defined as a pointwise map from to \u039b. However, this ideal case is far too restrictive in general. In particular, physics models often have the property that the domain has higher dimension than the range of the observable outputs defining the map Q, which makes it impossible to assign distinct input values to distinct output values. In some mathematical fields, such maps are referred to as \"non-invertible\" and the inverse problem is said to be \"ill-posed.\" However, the inverse of any map is a well defined concept. The inverse of a map is generally a set-valued function that does not map the range back to \u039b in a pointwise sense. Rather the inverse of a map sends to a new space \u2112 whose points consist of sets (preimages) in \u039b. When the map Q is piecewise differentiable, these set-valued inverses exist as lower dimensional manifolds that we refer to as generalized contours. This is a generalization to higher dimensions of the familiar concept of a contour map for elevations. We show an example in Fig. 2, where we plot some of the contours of the map from \u211d 2 to \u211d 1 , For a map between \u039b \u2282 \u211d m and \u2282 \u211d d with m > d > 1, the generalized contour is a manifold of dimension m \u2212 d embedded in \u039b. For the problem of determining Manning's n, a point in the space \u2112 simply represents all the possible Manning's n fields producing the same maximum water height. Moreover, we can decompose \u039b as a union of generalized contours corresponding to the points in \u2112 (see Fig. 2). Notions such as continuity and well-posedness for the inverse map must be phrased with respect to points in \u2112, not with respect to points in \u039b. For example, the condition or degree of near-ill-posedness of the inverse map is determined by how well the map distinguishes different generalized contours from each other. The concept of condition is explored in more depth in Section 6. The map Q has a natural restriction Q \u2112 to \u2112 since we can evaluate Q \u2112 on a generalized contour by evaluating Q at any point on the contour. It follows that Q \u2112 : \u2112 \u2192 is a bijection, so is invertible, and it is possible to identify each generalized contour by the unique corresponding value in (see Fig. 3). Contours in a contour map are usually indexed by the altitude. However, it is also possible to find manifolds in \u039b that can serve as an indexing set for the generalized contours in \u2112 (see Fig. 3 and 4) in the sense that each generalized contour corresponds to a unique point of the indexing set. We call such an indexing set a transverse parametrization (TP) 1 . In the context of the Manning's n problem, a TP simply identifies a way to distinguish which sets of Manning's n fields produce distinct water heights. We choose any TP to serve as a representation of \u2112, and abusing notation, we call this TP \u2112. With this choice, we obtain a new (nonlinear) \"coordinate system\" for the original \u039b. Any point \u03bb \u2208 \u039b can be written as \u03bb = [x \u2112 ; x ], where x \u2112 \u2208 \u2112 indicates the unique generalized contour \u03bb passing through \u03bb and x \u03bb is the unique point in \u03bb that distinguishes \u03bb from the other points in \u03bb (see Fig. 3). We note that it is possible to numerically approximate all of these manifolds in the setvalued solution of the inverse problem ( [23,24,25,26]). However, this is computationally intensive and it is not necessary for solving the stochastic inverse problem."}, {"section_title": "Solving the stochastic inverse problem in the space of generalized contours", "text": "If the generalized contours are available, then the solution of the stochastic inverse problem into \u2112 is conceptually simple since Q \u2112 is a bijection. A probability distribution on corresponds to a unique induced probability distribution on \u2112. We let P denote the given probability measure on , which means that if B is any event in , then the probability of B is P (B). The induced inverse probability measure P \u2112 on \u2112 is given by (4.2) for any event A \u2282 \u039b. This is the \"natural\" solution of the stochastic inverse problem since it involves minimal assumptions. Given a probability density \u03c1 on , there is a unique induced inverse probability density function \u03c1 \u2112 on \u2112 such that The induced probability density on the TP from Fig. 3 corresponding to a uniform probability measure on is shown in Fig. 4. To interpret the solution of the inverse problem in the space of generalized contours \u2112, we note that an event in \u2112 corresponds to a set of generalized contours in \u039b, which we call a contour event. We illustrate a contour event in Fig. 5 where a probability measure on \u2112 provides the means to compute the probability of sets in \u039b comprised of generalized contours. For the Manning's n problem, this means that we can use a probability density on maximum water height data to determine the probability density on events defined by all possible Manning's n fields that can generate this data."}, {"section_title": "Solving the stochastic inverse problem in the original domain", "text": "The formulation of the parameter domain \u039b is an important ingredient in the construction of a physics model. Parameter values correspond to physical conditions that determine model behavior and, generally, different points and events in \u039b correspond to different physical conditions even when they result in the same model output. Many important scientific and engineering applications of a model require the ability to explore differences between various sets of parameter values in \u039b. The solution of the stochastic inverse problem in the space of generalized contours provides the means to answer questions in \u039b that are formulated in terms of contour events. We can identify arbitrary events A and B in \u039b by the smallest contour events containing A and B, i.e., by Q \u22121 (Q(A)) and Q \u22121 (Q(B)), respectively. However, without further assumption, we cannot use the solution of the stochastic inverse problem in \u2112 to assign different probabilities to different events A and B in \u039b when Q(A) = Q(B) (see Fig. 5). In the deterministic inverse problem, the model cannot be used to distinguish between different points on the same generalized contour. However, there is a reasonable assumption that allows assigning probabilities to individual events in \u039b that are in the same contour event in the case of the stochastic inverse problem. To explain this, we formulate the probability computations in the common form as integrals involving probability densities. Consider any probability distribution P \u039b that is given on \u039b in terms of a probability density \u03c1 \u039b , so that for any event A \u2282 \u039b, We introduce notation to exploit the coordinate system induced by the generalized contours. We fix a TP representing \u2112 in \u039b. For an event A \u2282 \u039b, we let \u03c0(A) \u2282 \u2112 denote the event in \u2112 corresponding to the contour event determined by A. (We can compute \u03c0(A) as the unique event in \u2112 determined by Q \u22121 (Q(A))). For a point x \u2112 \u2208 \u2112, we let \u03c0 \u22121 (x \u2112 ) be the generalized contour corresponding to x \u2112 (see Fig. 6). Changing to the new coordinates, we obtain the iterated integral, where we abuse notation to let x denote the coordinates along the generalized contour = \u03c0 \u22121 (x \u2112 ) corresponding to x \u2112 . Moreover, the density \u03c1 \u039b on \u039b can be decomposed as (4.6) where \u03c1 \u2112 is a probability density function on \u2112 and \u03c1 (x ; x \u2112 ) is a conditional probability density conditioned on the generalized contour \u03c0 \u22121 (x \u2112 ). Substituting, we obtain, We note that when \u03c1 \u039b is given, then \u03c1 \u2112 is obtained by restriction of \u03c1 \u039b to \u2112 and \u03c1 is obtained by restriction of \u03c1 \u039b to the generalized contours corresponding to points in \u2112. Vice versa, if we specify \u03c1 \u2112 and \u03c1 , then \u03c1 \u039b is determined uniquely. We emphasize the great theoretical and computational importance of the iterated integral (4.7) for any probability measure on \u039b. Roughly speaking, (4.7) states the intuitive fact that the probability of an event A in \u039b can be computed as the product of the conditional probability of A considered as an event in the probability space of the contour event \u03c0(A) and the probability of that contour event. However, (4.5) and (4.6) are not obvious from a mathematical point of view. Technical issues potentially arise because \u2112 and the generalized contours are lower dimensional structures in \u039b and so have measure zero in the volume measure of \u039b 2 . We now return to the stochastic inverse problem. As discussed above, (4.3) determines \u03c1 \u2112 uniquely from the inverse of the model and the imposed probability density \u03c1 on . However, the model gives no information about the conditional probability \u03c1 in each generalized contour. In the context of the Manning's n problem, the probability density of water height data uniquely determines the probability density \u03c1 \u2112 but provides no information about the possible conditional probability \u03c1 which would distinguish between different Manning's n values that give the same height. At this point, we make an assumption. There is a branch of probability that deals with the assignment of probabilities when there is no information about probabilities of events. In the case of a discrete space, the Principle of Insufficient Reason 3 , going back to Bernoulli and Laplace, states that if there is no reason to assume that one outcome is favored over any others, we should assign equal probabilities to all outcomes. The analog in continuous probability is to assign the uniform probability distribution in the situation in which we have no reason to believe that there is nonuniform behavior in the probability. Thus, we assume that \u03c1 is the uniform probability density on each generalized contour (4.8) With this assumption, (4.7) gives a unique solution of the stochastic inverse problem as a probability density on \u039b. The conditional density \u03c1 varies with the generalized contour (see Fig. 6), which has a complicated effect on the resulting probability density on \u039b (see Fig. 7). In particular, suppose two events A 1 and A 2 have equal measure in \u039b and events \u03c0(A 1 ), \u03c0(A 2 ) \u2282 \u2112 have equal probability P \u2112 (\u03c0(A 1 )) = P \u2112 (\u03c0(A 2 )) in \u2112. If \u03c0(A 1 ) has greater volume than \u03c0(A 2 ), then P \u039b (A 1 ) < P \u039b (A 2 ). This is evident in Fig. 7. We emphasize that any assumed conditional probability density \u03c1 determines a unique probability distribution on \u039b, and our computational methods work equally well with any assumed density. However, note that any non-uniform density imposes additional geometric structure on the problem that is not determined by the model. For example, assuming a Gaussian distribution on each generalized contour requires specifying a point in each generalized contour as the mean of the Gaussian. The model itself cannot distinguish a specific point in a generalized contour, so we have imposed an additional geometric feature in the problem. For further discussion of the assumption, see [26]."}, {"section_title": "Comparison to other formulations of stochastic inverse problems", "text": "Modern research on the approximate solution of inverse problems is dominated by Bayesian and regularization approaches, and it is impossible to list all the relevant references here. Below, we describe the differences in our approach to some recent work using other approaches in the determination of Manning's n. For more information, the interested reader should review the cited work and the literature cited therein. In [41], the optimization approach of [27] is generalized and regularization is used to determine Manning's n from noisy water height measurements using a shallow water equation model. In the stated inversion algorithm of [41], the inverse problem is formulated as finding a Manning's n field that minimizes a misfit functional. This requires the specification of a regularization parameter and the objective is to find a specific Manning's n field for the specified misfit functional. This is a completely different formulation of the inverse problem where the physical map defining the observable data of water heights is used in part to define a separate mapping (the misfit functional) over the parameter space. Regularization approaches such as this have proven useful in identifying a specific input to a model whose corresponding output values are a reasonable match, in some norm, to the observable data. However, the misfit functional, by design, has a completely different contour structure from the physical map we consider in order to produce a so-called \"unique\" answer to the inverse problem. In [29,30], Bayesian approaches are used to determine posterior distributions of Manning's n from noisy water elevation data. Both of these works discuss methods for using and accelerating MCMC to sample form the posterior distribution and deal with the so-called hyperparameters defining prior distributions. The posterior distribution is defined as a conditional probability density using a likelihood and prior that, under certain assumptions, has an implicit connection to regularization [42]. Furthermore, the likelihood involves the treatment of the physical deterministic map Q as a statistical map where a probability density is implicitly defined over \u039b by considering discrepancies in the map Q from observed data. This is fundamentally different than imposing uncertainty in the form of a probability density on the range of Q. The contours of a probability density defined by discrepancies are entirely dependent on the form of the specified density not on the actual physics defining the map Q. Moreover, the posterior is treated typically as an \"update\" to prior information (e.g., see Fig. 9 in [29] and Figs. 14-16 in [30]). This is often done for the same purpose as regularization approaches, which is to identify a single parameter maximizing the density (corresponding to a minimization of a misfit functional). As with regularization, Bayesian approaches have proven extremely useful at identifying specific input parameters with desired characteristics that explain specific sets of observable output data. However, the contours of the posterior distribution have a completely different interpretation than the contours of the physical map on which we build a non-parametric probability distribution. We note one consequence of the set-valued nature of the inverse of the forward map is that there are an infinite number of probability structures that will give the same output [23]. Consequently, using the output to quantify the accuracy of a computed inverse solution is a relatively weak metric in comparing these different methods. Further complicating direct comparisons of solutions obtained by these approaches is the fact that the underlying mathematical formulations are fundamentally different leading to solutions with different interpretations."}, {"section_title": "Numerical approximation of the inverse probability distribution in \u039b", "text": "We now adopt (4.8) in the iterated integral (4.7). Formally, this means that we compute P \u039b (A) for any event A in \u039b by evaluating (4.7). In this section, we review the numerical aspects of this computation and refer to [23,24,25,26] for more details. We finish with an interpretation of the computational algorithm in the context of the Manning's n problem. There are two key aspects to approximating an iterated integral over a set, namely dealing with the geometry of the set and evaluating the integrand. We can handle both simultaneously using the standard measure theoretic technique of simple function approximations which are defined as piecewise constant functions on a specified collection of measurable sets. Generally, evaluating any iterated integral over a set with a non-Cartesian geometry is difficult. Evaluating (4.7) is made more complicated by the generally complex geometries of the TP representing \u2112 and the generalized contours, even assuming those structures have been approximated. Moreover, a number of applications involving use of an inverse probability distribution require computing the probability of a large number of events. A way to deal with these issues is to use the fact that an integral of a function f over \u039b can be written as a sum of integrals, over a (discretization) partition of \u039b consisting of a collection of subdomains that form a nonoverlapping partition of \u039b, i.e. \u039b = \u222a j j and i \u2229 j = \u2205 for i \u2260 j. We note that each j is a measurable set. With a partition of \u039b in hand, we can formally evaluate (4.7) for any event A as a sum of integrals over . We can deal with complicated geometries by approximating (4.7) using either the (outer) sum over the collection of subdomains { j : A \u2229 j \u2260 \u2205} or the (inner) sum over the collection { j : j \u2282 A}, provided that the integrals over the subdomains are easier to evaluate and the differences between A and these collections have small measure. The second aspect of computing (4.7) is evaluating the integrand, which entails evaluating the inverse density function \u03c1 \u2112 on \u2112 defined through the inverse and the uniform probability density function \u03c1 along each generalized contour . Since these functions are complicated in general, we use piecewise constant approximations defined with respect to partitions of small cells over which the densities are not expected to vary much. These observations suggest that it might be necessary to construct a number of partitions, namely for \u039b, \u2112, and each of the generalized contours. Fortunately, we can construct partitions of \u039b that can be used to approximate sets in \u039b, \u2112, and each generalized contour event simultaneously. This is based on the fact that any open set in \u211d n can be approximated arbitrarily well (in measure) by a collection of generalized rectangles defining \"boxes\" [40] (see Fig. 8). Further considerations are required for the numerical evaluation of \u03c1 \u2112 in the part of the integral (4.7) along \u2112 and the uniform probability density function \u03c1 along each generalized contour . Recall that \u03c1 \u2112 is defined as the density induced by the map Q through (4.3), so that evaluating \u03c1 \u2112 formally involves computing integrals \u222b Q(A) \u03c1 (y) dy for events A \u2282 \u2112. To do this numerically, we also construct a discretization partition of and compute approximations of the associated probabilities p k = \u222b D k \u03c1 (y) dy. This yields the approximations such as, We approximate \u222b \u2229A dx on a given generalized contour by using the ratio of the measure of the cells j that intersect \u2229 A to the measure of the cells that intersect . Finally, we touch on an important computational point. The approximation of open sets by collections of boxes is theoretically important in any finite dimension, but is computationally important only in low dimensions. The reason is that the number of cells required to partition the unit cell in \u211d n increases exponentially with the dimension n, which is a form of the well known \"curse of dimensionality\". The classic way to deal with this dimension dependence is to use a Monte Carlo approximation since the choice of the random sample points is not tied to a Cartesian geometry. However, for the solution of the stochastic inverse problem, it is essential to tie Monte Carlo approximations of integrals to the approximation of events in \u039b. This connection is provided in stochastic geometry [43,44], which studies the properties of stochastic partitions of a domain based on collections of randomly chosen points in \u039b. A collection of points in \u039b determines a Voronoi tessellation [43] . This is the collection of cells whose sides are, roughly speaking, determined as segments that lie equidistant between neighboring points \u03bb (j) and \u03bb (i) (see Fig. 9). A fundamental approximation result is that we can approximate events in \u039b using such collections. However, constructing Voronoi tesselations in high dimensions is also prohibitively expensive. So the key for practical numerical computations is to construct approximations that exploit the approximation properties of the tesselations implicitly but do not require explicit construction of the cells. We summarize the numerical approximation for the inverse probabilities in Algorithm 1. With the approximate probabilities {\u03c1\u0302\u039b ,j }, we can construct approximate density plots for the inverse density and compute approximations, for example the inner sum, We can also search for regions of highest probability."}, {"section_title": "Algorithm 1", "text": ""}, {"section_title": "Numerical Approximation of the Inverse Density", "text": "Choose points implicitly defining the partition of \u039b. Assign values Q j = Q(\u03bb (j) ) for points \u03bb (j) , j = 1, \u2026 N. Choose a discretization partition of . Compute approximations p i \u2248 \u222b I i \u03c1 (y) dy, i = 1, \u2026, M. Let V j be an approximate measure of j , j = 1, \u2026, N."}, {"section_title": "end", "text": "In the context of the Manning's n problem, the first step of Algorithm 1 corresponds to choosing a set of possible Manning's n fields. The second step involves solving the model to determine the maximum water heights associated with each of these Manning's n fields. The third and fourth steps involve computing an approximation to a prescribed probability density on the maximum water height data. The specification of i and j corresponds to determining the approximating set of all Manning's n fields that map to the same set of water height data. The for-loop uses these approximations to compute the probability associated to each sample of a Manning's n field and its implicitly defined Voronoi cell."}, {"section_title": "Defining the parameter domain \u039b", "text": "We stress the importance of precisely defining the relevant parameter domain \u039b. This is generally more complicated than it might first appear, since it involves consideration of physical properties of the system. After presenting an example to illustrate the importance, we discuss the choice of domain for the Manning's n parameter field. We first consider the simple model (4.1) plotted in Fig. 2. The model is valid on all of \u211d 2 , and on \u211d 2 , the model has the property that the lengths of the contours increases monotonically as the distance from a fixed set containing (.5, .5) and (1.5, 1.5) increases. However, when we restrict the model to \u039b = [0, 2] \u00d7 [0, 2], the effect is to \"cut off\" parts of the longer contours, and after some critical distance away from , the length of the contours contained in \u039b actually decreases as the distance from increases. This leads to the increase in the probability density in \u039b near the corners (0, 2) and (2, 0) evident in Fig. 7. This is an example of the complicated effect that the specification of \u039b can have on the inverse probability distribution P \u039b . In general, defining the appropriate domain \u039b is a critical part of formulating the stochastic inverse problem 4 .\nThe available data for Manning's n consists of empirically determined intervals of values for common land (bottom type) classifications, e.g., see Table 1. The ranges are assigned to individual cells in a pixelated version of a high resolution image such as Fig. 10. Ranges for values at pixel cells corresponding to underwater locations cannot be observed by such images and may be determined by expert opinion. A typical mesoscale cell in the Manning's n representation encompasses several pixel cells. To obtain a range for the nodal value of the representation at a mesoscale grid point, a convex average is employed, see [47,46]. At each node in the mesoscale mesh, we define a rectangle using the maximum and minimum planar coordinates of the centroids of the mesoscale triangles sharing that node, see Fig. 11. We compute the nodal Manning's n value as the average Manning's n value within the grid scale based on the land classification pixels. Hence, the Manning's n value at the jth node in the mesh is (5.1) where a i is the number of pixels (outlined in green in Fig. 11) within the grid scale at the jth node for the ith land classification, \u03bb i is the Manning's n value associated with land type i, m is the number of land types, and . This spatial averaging process is a convex linear map from the Manning n values associated with each of the m land classification types to the mesoscale Manning's n field. Given bounds for each \u03bb i , we obtain the domain \u039b. We describe a computationally useful parameterization of the mesoscale Manning's n field over \u039b in Sec. 7."}, {"section_title": "A mesoscale representation of Manning's n", "text": "Manning's n is a field that varies spatially with the land type and physical conditions. High resolution images, see Fig. 10, show the fine scale changes of land type in a typical coastal region. Since the changes in land type are discrete at a sufficiently fine scale, Manning's n can be represented in terms of coefficients with respect to a basis for a finite dimensional space of functions. Upon substitution of a chosen representation for Manning's n into a hydrodynamic model (Eq. 2), the coefficients in the representation define the finite dimensional set of parameters input into the model. In this formulation of the forward model (Eq. 2.2) Manning's n is time-invariant and constant with respect to the flow characteristics within a particular simulation. However, a pointwise accurate representation of Manning's n generally requires a very high number of degrees of freedom. In fact, Manning's n typically varies on a spatial scale that is much finer than the scale of the cells that can be used for numerical discretization of a hydrodynamic model. In other words, a typical discretization cell for a numerical solution of the model contains a variety of land types. Consequently, representations of Manning's n typically are defined using an upscaling procedure that employs local averaging. We employ a standard representation. We construct a triangulation of the spatial domain for the model, consisting of a collection of triangles that form a nonoverlapping partition of \u03a9, i.e. \u03a9 = \u222a j T j and T i \u2229 T j = \u2205 for i \u2260 j, and represent Manning's n as a continuous piecewise linear function on \u03a9 that is linear on each triangle T j . If we employ the nodal basis \u03d5 j for the continuous piecewise linear functions on the triangulation, we may then define Manning's n in terms of the set of M nodal values or equivalently as the vector n \u2208 \u211d M . It is quite common to encounter computations in which the triangulation used to represent Manning's n is the same triangulation used to discretize the hydrodynamic model. However, this choice introduces both significant theoretical and computational issues with respect to formulating and solving the hydrodynamic model. Roughly speaking, unless the spatial discretization is sufficiently fine so as to resolve the variation in Manning's n pointwise, we significantly change the hydrodynamic model being solved with each change of the spatial discretization mesh. One consequence is that it is impossible to carry out convergence studies. We illustrate with a numerical example below in Sec. 8. Hence, we fix the mesocale triangulation used to represent the Manning's n field. Moreover, we refine the mesoscale triangulation to construct the discretization triangulation used to compute numerical solutions of the hydrodynamic model. This provides both computational efficiency in evaluating the Manning's n parameter in solving the hydrodynamic model and predictable numerical behavior in the computed hydrodynamic solutions."}, {"section_title": "Characterizing the condition of the stochastic inverse problem", "text": "In this section, we investigate characteristics of the quantities of interest for the stochastic inverse problem that impact the accuracy of numerical solutions. Recall that in the solution of a linear square system of equations, there is a unique solution when the matrix is invertible. However, the accuracy of a numerical solution generally depends on the condition number of the matrix. Analogously, the difficulty in computing accurate numerical solutions of the stochastic inverse problem depends on a \"skewness\" property of Jacobian of Q that plays the role of a condition number for the stochastic inverse problem."}, {"section_title": "Geometrically distinct quantities of interest", "text": "We first consider the abstract stochastic inverse problem. Recall that the generalized contours exist as manifolds of dimension m \u2212 d in \u039b under suitable conditions on the map Q : \u039b \u2282 \u211d m \u2192 \u2282 \u211d d . These conditions are discussed in more detail below. To explain the idea, we first consider an example of a linear map Q represented by a d \u00d7 m matrix. If Q has full rank d, so the rows of Q are linearly independent, then the generalized contours exist as m \u2212 d dimensional hyperplanes in \u039b \u2282 \u211d m . On the other hand, suppose Q does not have full rank, say the last row is a linear combination of the other rows. Then, each generalized contour is a hyperplane of dimension m \u2212 d + 1 and we may as well consider the map Q\u0303 obtained by deleting the QoI defined by the last row of Q. Thus, we assume that the chosen QoI form a linearly independent set of functionals. Extending this idea to nonlinear maps is based on local linearization: This implies that the map obtained by linearizing Q at a point has linearly independent rows. Under this assumption, we can prove that the generalized contours exist as m \u2212 d dimensional manifolds and the TP exists as a d dimensional manifolds [26]."}, {"section_title": "Condition of the numerical solution of the stochastic inverse problem", "text": "As with the property of geometrically distinct, the condition of the inverse problem with respect to Q is an issue involving the dependencies among the d vectors comprising Q. In this section, we fix a TP for \u2112 and restrict Q to \u2112 to get the invertible map Q \u2112 from \u2112 to . We begin by reviewing the relation between determinant and measure (volume). Assume that a set of d-dimensional vectors \u03c5 1 , \u22ef, \u03c5 d is given. If we consider the linear transformation from \u211d d to \u211d d defined by the matrix V whose columns are the vectors {\u03c5 1 , \u22ef, \u03c5 d }, then (6.1) for any cube A \u2282 \u211d d , where V A denotes the image of A under V and \u03bc is the Lebesgue measure (volume) in \u211d d . We relate this to the degree of skewness introduced by the map V. We use \u03bc(Pa(\u03c5 1 , \u03c5 2 , \u22ef, \u03c5 i )) to denote the measure (volume) of the parallelepiped as an idimensional object. Then, det V = \u03bc (Pa(\u03c5 1 , \u03c5 2 , \u22ef, \u03c5 d ) We note that if , then the image of a generalized cube is a parallelepiped that is significantly skewed in a direction perpendicular to , see Fig. 12. Returning to (6.1), the map V can decrease volumes both by simple scaling and by inducing skewness. Scaling does not affect the numerical solution of the inverse problem, but skewness does. For this reason, we define a measure of skewness."}, {"section_title": "Definition 6.2-For vector \u03c5 i , we define", "text": "where the definition is independent of the particular representation (6.2). Then we define By induction, we can find vectors and such that The interpretation is that there exists a generalized rectangle with orthogonal sides of length , |\u03c5 d | having the same measure as Pa(\u03c5 1 , \u03c5 2 , \u22ef, \u03c5 d ), see Fig. 12. We can order the vectors so For simplicity of exposition, we consider the situation in which the quantities of interest almost fails the assumption of geometrically distinct in the sense q 1 is almost linearly dependent on q 2 , \u22ef, q d . To be precise, Assumption 1-We assume skew (Q \u2112 ) = skew (Q \u2112 , q 1 ) \u226b skew (Q \u2112 , q 2 ) and \u03bc(Pa(q 2 , \u22ef, Roughly speaking, the image of a generalized cube under V is a parallelepiped with a relatively \"fat\" base and a small height caused by severe skewness. We set \u03b5 = (skew (Q \u2112 , q 1 )) \u2212 Note that the dimension of the sides of the generalized cube cells in a discretization of must be much smaller than to avoid a poor set approximation of , see Fig. 13. Thus, we assume that the cells in a discretization of have size \u03b3\u03b5|q 1 |, where 0 < \u03b3 \u226a 1. The measures of such cells is This implies that the number of sample values required to compute the inverse distribution is proportional to (6.4) We conclude that the number of samples required increases dramatically as the skewness of the map Q \u2112 increases. In the nonlinear case, we first partition \u2112 into a cover of nonoverlapping cells { i } such that on i , Q \u2112 (\u03bb) \u2248 J Q \u2112 (x i )\u03bb, for some point x i \u2208 i . We then apply the linear result to J Q \u2112 (x i ) to find that a discretization of i requires the number of cells to be proportional to The conclusion is that the number of samples implicitly defining the cells partitioning \u039b in Algorithm 1 is proportional to This arises entirely from the skewness induced by the map Q \u2112 . We illustrate this argument with a simple example. Consider the linear map Q with matrix (6.5) where 0 < \u03b5 \u2264 2, applied on the domain \u039b = [0, 1] \u00d7 [0, 1] \u00d7 [0, 1]. The map Q is full rank, but it becomes closer to being deficient as \u03b5 approaches zero. The range of Q is the parallelepiped in \u211d 2 defined by the nodes {(0, 0), (1, 1), (0, \u03b5), (\u22121,\u22121 + \u03b5)}, see Fig. 14. As \u03b5 decreases, the map Q increasingly skews the image of a cube. The inverse problem Q\u03bb = q has solutions consisting of line segments in \u039b that are perpendicular to the coordinate plane (\u03bb 1 , \u03bb 2 ). We can take \u2112 = [0, 1]\u00d7[0, 1] in the coordinate plane (\u03bb 1 , \u03bb 2 ). On \u2112, Q reduces to the matrix Evaluating (6.4), we conclude that the number of samples required in Algorithm 1 of the stochastic inverse problem is proportional to \u03b3 \u22122 \u03b5 \u22121 ."}, {"section_title": "Condition of the forw ard prediction problem", "text": "The measure of the range of the output of the forward prediction model depends on the measure of the domain of possible input values. In general, a range with larger measure corresponds to a large range of possible outcomes, and hence less precision in predictions of the outcome. In the scientific inference problem, the measure of the domain of possible input values, determined by the stochastic inverse problem, also depends on the skewness of the model. If the model for the stochastic inverse problem has large skewness, then det J Q \u2112 is small. This implies that is large, for any small cell B in , where the Jacobian is evaluated at a point in B. Thus, even if the observed values for the output of the model are confined to a range of small measure, the corresponding set of inverse values has large measure. This in turn implies that the measure of the corresponding range of the predication may be large."}, {"section_title": "Computational issues", "text": "We fix the mesoscale representation of Manning's n field with M nodes in the mesh and assume there are m land classification types. We use n to denote the values of the mesoscale representation at the nodes. We define m linear \u211d m maps from a value associated with each land classification type in the domain to the mesoscale Manning's n field, so that (7.1) Thus, b i defines the relative contribution of the Manning's n value associated to land classification i at each node in the mesoscale mesh. Eq. (5.1) implies that the jth component of b i is equal to a i /N, where a i is the number of pixels for the ith land classification type within the grid scale of the jth node, and N is the total number of pixels within the grid scale of the jth node. This implies that defines a parameterization of the mesoscale Manning's n field n in (5.1). Fig. 15 shows an example of the parameterization vectors for three land types with \u03bb 1 = 0.142, \u03bb 2 = 0.161, and \u03bb 3 = 0.012 for an inlet domain. We construct the parameterization vectors with a Python wrapped version of GridData [47]. We developed the Python packages PolyADCIRC [49] and BET [50] to sample \u039b efficiently either on regular grids, with uniform random sampling, or adaptively. Specifically, PolyADCIRC runs batches of P(arallel)ADCIRC simulations, where the number of simulations per batch and number of processors is user determined. Load balancing is handled automatically. The BET package then processes the results using Algorithm 1 to compute the approximation to P \u039b and provide visualizations of results. See Appendix Appendix A for more details."}, {"section_title": "Numerical experiments", "text": "In the following set of experiments, we investigate the selection of \"effective\" quantities of interest for determining the Manning's n parameters in a hydrodynamic model based on observations of maximum water elevations from a number of possible observation stations."}, {"section_title": "The physical domain", "text": "We consider an idealized inlet with sloped bathymetry, see "}, {"section_title": "Input parameters", "text": "We consider two cases. We first fix the length of the earthen jetty to be y = \u22121050 [m]. Therefore, \u039b = [0.07, 0.15] \u00d7 [0.1, 0.2] is defined by \u03bb 1 and \u03bb 2 for the parameterization vectors of the Manning's n field shown in Fig. 15. In the second case, we also allow the length of the earthen jetty in the y-direction to vary in [\u22121500, 1500] (m), giving \u039b = [\u22121500, 1500] \u00d7 [0.07, 0.15]\u00d7 [0.1, 0.2], where we let \u03bb 1 denote the length in the y-direction of the earthen jetty and \u03bb 2 and \u03bb 3 denote the Manning's n values for land classification types 1 and 2, respectively."}, {"section_title": "The potential quantities of interest", "text": "We construct the QoI vector with components given by the maximum elevation recorded at a selection of 2 from 12 possible observation stations shown in Fig. 16. The condition of the resulting QoI depends strongly on the physical locations of the stations in the pair and the purpose of the experiment is to investigate the condition of the QoI for various choices. For simplicity, we always fix the first component of the various QoI to be the maximum elevation q 1 at station 1 and allow the second component to vary among stations 2 -12."}, {"section_title": "Resolution of the Manning's n representation and numerical solution", "text": "As mentioned, a mesoscale representation of Manning's n is often defined on the finite element mesh. Since we are modeling the flows at a scale where both the assumptions justifying the validity of the SWE and the finite element mesh has adequately resolved variability in parameters, significant numerical errors can arise with this choice. In our approach, we use a finite element mesh obtained by refinement of the mesoscale mesh, see Fig. 16. The resulting QoI maps are noticeably smoother than those obtained using the common choice, see Fig. 17. Using the refined finite element mesh results in QoI values shifted by approximately 0.5 [m] throughout the entire parameter domain, and the slopes of the contours are substantially different. The unrefined finite element mesh does not sufficiently resolve the earthen jetty nor the varaiblity in the parameters which is on a similar physical scale as the earthen jetty. Refining the finite element mesh aqdeuately resolves these features.  [51]. A PADCIRC simulation of a single sample \u03bb \u2208 \u039b running on a single node with four MPI tasks takes about 90 seconds to run to completion."}, {"section_title": "Results for a fixed jetty length", "text": "Inverse problem-In Fig. 18, we show representative plots of \u2254 Q(\u039b) = (q 1 (\u039b), q k (\u039b)) for k = 2 and k = 6. Recalling Fig. 14, the left plot shows an example of a badly conditioned QoI map relative to the well-conditioned QoI shown in the right plot. The QoI for k = 1 and 3 are similarly ill-conditioned while the QoI for the rest are more or less well-conditioned. We define and solve a total of 6 stochastic inverse problems for different \u03c1 determined from the three choices of reference QoI values and the two QoI maps shown in Fig. 18. For each problem, we choose \u03c1 to be a piecewise constant function with support on small rectangles centered at the reference QoI values. We solve the inverse problem to obtain p\u0302\u039b ,j for the Voronoi cells defined by regular sampling of the QoI map. We use kernel density estimation to smooth the resulting density approximation. Figures 19-21 show the resulting approximate probability densities \u03c1 \u039b and marginals for each of the stochastic inverse problems. We see that using the better conditioned QoI map results in densities with smaller support in \u039b, which can have a large effect on the precision of predictions. We note the similarities in the contours of the densities resulting from inverting \u03c1 for Q = (q 1 , q 2 ) to the contours of the map defined only by q 1 seen in the righthand plot of Fig. 17. Since q 2 coincides very closely with q 1 , the resulting inverse densities appear as if the geometric information contained in the generalized contours of only q 1 (or q 2 ) exclusively was used to construct the inverse density. In Fig. 22, we show the inverse density and marginals resulting from an inversion using only Q = (q 1 ) where the density \u03c1 was defined by the projection of the density used for the map Q = (q 1 , q 2 ) with reference parameter \u03bb = (0.107, 0.106). Comparing Fig. 22 to Fig. 19, we observe that the addition of QoI q 2 fails to significantly change the inverse density obtained by inverting q 1 .  Fig. 16). An interesting and important forecasting problem is to determine the time of inundation of critical physical locations within the domain, e.g. the time of inundation near or on physical barriers. With the same model setup, we consider the goal of predicting the time of inundation of points near the bottom of the earthen jetty. Specifically, we consider predicting the time of inundation at two points located at (x 1 , y 1 ) = (1593.75, \u22121087.5) and (x 2 , y 2 ) = (1593.75, \u22121012.5) corresponding to the nearest nodal points of the finite element mesh to the right of the earthen jetty and equally spaced below and above the bottom of the jetty."}, {"section_title": "Predictions-", "text": "We consider the predicted times of inundation for the Manning's n parameters defining the regions in \u039b containing the largest density values accounting for 95% of all the probability. We also forecast the time of inundation using the reference parameter value. We summarize the results in Table 2 where the time is written as hours:minutes:seconds referenced to the initial model run time. We see that using the better conditioned QoI map for determining an inverse density results in prediction intervals substantially smaller than the poorly conditioned QoI map. At (x 1 , y 1 ) and (x 2 , y 2 ) the prediction intervals from the poorly conditioned QoI map are approximately 126% and 794% larger, respectively, than for the better conditioned QoI map."}, {"section_title": "Results for varying jetty length", "text": "We let Q = (q 1 , q 5 ). As before, we define \u03c1 D as a uniform density on a small rectangular box centered at a reference QoI value associated with the reference parameter \u03bb = (\u2212600.0, 0.073, 0.119). The marginal density plots are shown in Fig. 23. All of the QoI maps are poorly conditioned, yielding density plots almost identical to those shown in Fig. 23. For example, using Q = (q 1 , q 5 , q 2 ) produces what appears to be a 2-D manifold embedded in the set defined by q 1 (\u039b) \u00d7 q 5 (\u039b) \u00d7 q 2 (\u039b). In other words, it appears that q 2 can be written as a function of q 1 and q 5 implying it adds almost no useful information for the inverse problem. Since the QoI map is 2-D while \u039b is 3-D, the generalized contours are now 1-D curves embedded in the 3-D parameter space. We observe the affects of the generalized contour geometry on the density plots where any increase in the support of a marginal density is a consequence of the increased dimension for the parameters. The QoI map appears to be most sensitive to the length of the earthen jetty given the shape of the marginal densities (i.e., the normalized tangent vectors of the 1-D generalized contour curves have smallest component in the \u03bb 1 direction). This is not surprising since the length of this jetty has the greatest affect on restricting the flow of water that reaches station 5 (and thus the value of q 5 , see Fig. 16)."}, {"section_title": "Conclusions", "text": "We formulated and numerically solved a stochastic inverse problem involving spatially heterogeneous Manning's n fields using maximum water elevation data obtained from the ADCIRC model. A novel measure-theoretic framework and computational algorithm was used based on the author's previous work [23,24,25,26]. However, this previous work did not address the condition of the inverse problem defined in terms of the skewness of contour events. This issue was explored thoroughly in this work. In Section 6, a numerical analysis demonstrated how poor conditioning leads to more samples in Algorithm 1 in order to accurately estimate events in the parameter space. In the numerical experiments, the condition of the inverse problem was explored in the context of the effect on the scientific inference problem. Specifically, poorly chosen quantities of interest lead to a solution of the inverse problem such that predictions based on this solution have reduced precision."}, {"section_title": "Future work", "text": "We have demonstrated the utility and highlighted some of the challenges of solving the stochastic inverse problem for quantifying uncertainty in Manning's n coefficients with ADCIRC within a measure-theoretic framework. We plan to develop goal-oriented adaptive sampling techniques to obtain reasonable estimates of P \u039b as we progress to higher dimensional probability spaces. Since many computational models are also computationally expensive another goal of the adaptive sampling is the produce reasonable estimates of P \u039b for specific events of physical importance given limited samples. This will require sampling strategies that utilize computed estimates of skewness to optimally place samples within specified events. We also are investigating algorithms for determining the optimal sets of QoI from large data sets (e.g. as results from time series data) using skewness metrics. We plan to apply these mesure-theoretic parameter estimation techniques to a hurricane simulation using a subdomain implementation of ADCIRC on a complex physical domain. We will focus on coastal areas vulnerable to hurricanes (e.g. Southern Louisiana, Southeastern Texas, or the New York and New Jersey coasts). Hurricane simulations on meshes fine enough to resolve inundation are computationally expensive. Thus, we plan to employ a recently available subdomain implementation of ADCIRC [52,53,54] to reduce simulation time and allow us to focus on specific areas of interest rather than on the significantly larger domain required for hurricane simulations. The basic flowchart for the BET and polyADCIRC packages. The BET package handles every step in Algorithm 1 while using the polyADCIRC package to efficiently interface to the ADCIRC computational model. The BET package (on the right-hand side in Figure A.24) is divided into four subpackages (1) sampling, (2) loadBalance, (3) calculateP, and (4) vis. The sampling subpackage provides the tools to sample the parameter space uniformly, adaptively, or at a set of user-defined samples. The sampling subpackage provides modules to efficiently sample the forward model and can take into account the most recent QoI values to adaptively choose new batches of input parameters. The loadBalance class allows the user the option to create an interface that is specific to the model and/or HPC infrastructure in order to implicitly construct the maps from parameter samples to the associated QoI, e.g. as we do with PADCIRC using the PolyADCIRC package described below and illustrated on the left-hand side of Figure A.24. Once the data sets containing parameter and QoI values are obtained, they are post-processed using the calculateP subpackage to obtain the approximate probability measure using Algorithm 1. Within calculateP is a module named simpleFun used to create simple function approximations to P that are inverted according to Algorithm 1. The calculateP subpackage provides several options for approximating the volume of the Voronoi cells { i } associated with each parameter sample including using various Monte Carlo approximations or more accurate approximations based on triangulations of the Voronoi cells. The vis subpackage can be used to visualize the approximate probability measure; the approximate data domain, , as in Fig. 18; and the parameter domain. The PolyADCIRC package is divided into three subpackages (1) run_framework, (2) pyGriddata, and (3) pyADCIRC. The run_framework subpackage is a prototype of the lb_ADCIRC class and will inherit from the loadBalance class. The run_framework subpackage provides the framework to simultaneously run PADCIRC simulations with varying Manning's n and bathymetry fields. The pyGriddata subpackage provides various methods and classes to create the parametrization vectors shown in Fig 15 using a slightly modified version of GridData (Griddata_v1.32.F90) to map the land classification contributions to the computational mesh. GridData is a FORTRAN program originally developed by Seizo Tanaka and C.H.Lab at the University of Notre Dame [47]. The pyADCIRC subpackage provides the methods and data structures used to interact with and alter PADCIRC formatted files. In the numerical examples shown, pyADCIRC creates the necessary formatted input files for ADCIRC based on the mesh parameter values returned by pyGriddata. Following completion of the model simulations for each batch of parameter samples, pyADCIRC reads in the formatted output files and returns the requested QoI values. The PolyADCIRC package was originally developed to execute parameter sweeps of Manning's n fields and simple bathymetry alterations; however, it can easily be adapted to handle other ADCIRC input parameters such as the location of a canopy or eddy viscosity. The PolyADCIRC package was originally developed for TACC HPC systems, but it can be easily adapted to run on other Linux based HPC systems."}, {"section_title": "Highlights", "text": "\u2022 A physically relevant inverse problem is solved using a measure-theoretic framework. \u2022 Uncertainties in Manning's n field for a shallow water equation model are quantified. \u2022 A new notion of \"condition\" for the inverse problem is defined and analyzed. \u2022 We use the condition in the determination of effective output quantities of interest. The input space of data and parameters are mapped by the physics-based model to the solution space. Generally, different sets of functionals map solutions to quantities we can observe and to the quantities we wish to predict. Parameters and data for the model are obtained from observable data by solving an inverse problem for the model+observable functionals. Information on parameter space is then used to make predictions by \"forward\" computation. The left plot shows a map from \u039b \u2282 \u211d 2 to an interval and corresponding contour curves in \u039b corresponding to unique points in . The right plot shows the decomposition of \u039b into a set of contour curves. The left plot shows a standard indexing of the set of generalized contours by the corresponding output values of the map. The middle plot shows the contours indexed by distance along a TP representing \u2112. The profile of the map along the TP is shown in Fig. 4. The right plot shows the nonlinear coordinate system induced by the contours and TP, where x \u2112 is the distance along the TP and x is the distance along the contour corresponding to \u03bb. The left plot is of the profile of the map along the TP from Fig. 3. The right plot shows the inverse density along the TP corresponding to a uniform density on . The left plot shows the inverse density along the TP corresponding to a uniform density on . The probability of the contour event shown in red is the integral of the inverse density over the event on the TP determining the contour event shown in a darker shade. The right plot shows four events in \u039b defining the same contour event and hence are assigned the same probability by the density on the TP. Plots of the inverse density in \u039b corresponding to the example shown in Figures 2, 3, 4, and 5 under the standard assumption of uniform probabilities along generalized contours. Events in \u039b are discretized using a Cartesian set of cells. This collection simultaneously approximates events in \u039b, \u2112, and the generalized contours . We show approximations of an event A, \u03c0(A) in \u2112, and the intersection of a contour with A. We compare approximations of an event A constructed using a Cartesian set of cells and a Voronoi tessellation corresponding to a set of randomly chosen points. NOAA C-CAP land coverage (http://www.csc.noaa.gov/crs/lca/gulfcoast.html) [45]. The mesoscale triangles sharing the common node (drawn in red) are displayed with black lines. The corresponding rectangle used for averaging is displayed as a red dashed rectangle. The centroids of the triangles are shown in blue. The pixel cells holding the intervals for the land types are outlined in gray and green.  Skewness affects the size of the cells that can be used to discretize . An enlargement shows the part of not covered by the set approximation.   Left: Bathymetry (top plot) of the physical domain \u03a9 (with finite element mesh shown on the bottom plot) in Eq. (2) with observation stations marked by circles. Right: The x, ycoordinates of observation stations in \u03a9 for observing QoI. Observations of a QoI from the ith observation station are denoted q i (\u03bb). We examine particular subsets of all the possible QoI maps, e.g., Q(\u03bb) = (q 1 (\u03bb), q 5 (\u03bb), q 12 (\u03bb)) or Q(\u03bb) = (q 1 (\u03bb), q 7 (\u03bb)). The map Q(\u03bb) = q 1 (\u03bb) of the maximum elevation measured at station 1 computed on a finite element mesh defined by the mesh used for the mesoscale representation of Manning's n (left) and on the refined finite element mesh shown in Fig. 16 (right). Note that scales, smoother response, and change in geometry of the contours resulting from using the refined finite element mesh. The estimated output domain : = Q(\u039b) = (q 1 (\u039b), q k (\u039b)) for k = 2 (left) and k = 6 (right). Comparing to Fig. 14, we see that the left plot indicates a \"bad\" condition for the inverse problem and the right plot indicates a \"good\" condition for the inverse problem. Three reference QoI values associated with (\u03bb 1 , \u03bb 2 ) = (0.107, 0.106), (0.075, 0.121), and (0.0781, 0.168) are marked on each plot. Plots of \u03c1 \u039b (left) and marginals \u03c1 \u03bb 1 (middle) and \u03c1 \u03bb 2 (right) inverting \u03c1 using Q = (q 1 , q 2 ) (top) and Q = (q 1 , q 6 ) (bottom). Here, \u03c1 is defined as a uniform density on a small rectangular box centered at the reference QoI values associated with \u03bb = (0.107, 0.106). The reference value and its components are illustrated by a black circle in the \u03c1 \u039b plots and vertical lines in the marginal plots. Plots of \u03c1 \u039b (left) and marginals \u03c1 \u03bb 1 (middle) and \u03c1 \u03bb 2 (right) inverting \u03c1 using Q = (q 1 , q 2 ) (top) and Q = (q 1 , q 6 ) (bottom). Here, \u03c1 is defined as a uniform density on a small rectangular box centered at the reference QoI values associated with \u03bb = (0.075, 0.121). The reference value and its components are illustrated by a black circle in the \u03c1 \u039b plots and vertical lines in the marginal plots. Plots of \u03c1 \u039b (left) and marginals \u03c1 \u03bb 1 (middle) and \u03c1 \u03bb 2 (right) inverting \u03c1 using Q = (q 1 , q 2 ) (top) and Q = (q 1 , q 6 ) (bottom). Here, \u03c1 is defined as a uniform density on a small rectangular box centered at the reference QoI values associated with \u03bb = (0.0781, 0.168). The reference value and its components are illustrated by a black circle in the \u03c1 \u039b plots and vertical lines in the marginal plots. Plots of \u03c1 \u039b (left) and marginals \u03c1 \u03bb 1 (middle) and \u03c1 \u03bb 2 (right) inverting \u03c1 using Q = (q 1 ). Here, \u03c1 is defined as a uniform density on a small interval defined by projecting the rectangular box used to \u03c1 for Q = (q 1 , q 2 ) centered at the reference QoI values associated with \u03bb = (0.107, 0.106). The reference value and its components are illustrated by a black circle in the \u03c1 \u039b plots and vertical lines in the marginal plots. "}]