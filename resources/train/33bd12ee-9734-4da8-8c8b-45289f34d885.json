[{"section_title": "Abstract", "text": "Abstract: Medical image analysis is the science of analyzing or solving medical problems using different image analysis techniques for affective and efficient extraction of information. It has emerged as one of the top research area in the field of engineering and medicine. Recent years have witnessed rapid use of machine learning algorithms in medical image analysis. These machine learning techniques are used to extract compact information for improved performance of medical image analysis system, when compared to the traditional methods that use extraction of handcrafted features. Deep learning is a breakthrough in machine learning techniques that has overwhelmed the field of pattern recognition and computer vision research by providing state-of-the-art results. Deep learning provides different machine learning algorithms that model high level data abstractions and do not rely on handcrafted features. Recently, deep learning methods utilizing deep convolutional neural networks have been applied to medical image analysis providing promising results. The application area covers the whole spectrum of medical image analysis including detection, segmentation, classification, and computer aided diagnosis. This paper presents a review of the state-of-the-art convolutional neural network based techniques used for medical image analysis."}, {"section_title": "Introduction", "text": "Deep learning (DL) is widely used in research domains such as computer vision, natural language processing and speech analysis. This method is suited particularly to areas where large amount of data needs to be analyzed and human like intelligence is required. The use of deep learning as a machine learning and pattern recognition tool is also becoming an important aspect in the field of medical image analysis and is evident from the recent special issue on this topic [1] . The key purpose of this special issue is to investigate the initial impact of deep learning in medical imaging domain. According to MIT technological review, deep learning is among the top ten breakthroughs of 2013 [2] .\nMedical imaging has been a diagnostic method in clinical practices for a long time. The recent advancements in hardware design, safety procedures, computational resources and data storage capabilities has greatly benefited the field of medical imaging. Currently, the major application areas of medical image analysis involve segmentation, classification, and abnormality detection in images generated from a wide spectrum of clinical imaging modalities. A taxonomy of the key medical imaging modalities is shown in Fig. 1 . The complete breadth of the current imaging methods is difficult to be shown in a single image and indicates the wide utility and the amount of clinical imaging data that is being currently generated.\nMedical image analysis aims to aid radiologist and clinicians to make diagnostic and treatment process more efficient. The computer aided detection (CADx) and computer aided diagnosis (CAD) relies on affective medical image analysis making it crucial in terms of performance, since it would directly affect the process of clinical diagnosis and treatment. Therefore, high performance in terms of accuracy, F-measure, precision, recall, sensitivity, and specificity is crucial and most desirable in medical image analysis. The availability of digital images dealing with clinical information is growing at a steady pace, a method that is best suited to big data analysis is required in medical image analysis. The state-of-the-art in data centric areas such as computer vision shows that deep learning methods could be the most suitable candidate for this purpose. Deep learning possesses various machine learning algorithms which aim to model high level abstractions in data by employing deep architectures composed of multiple non-linear transformations [3] . Deep learning mimics the way human brain works [4] , with a deep architecture similar to the way information is processed in human brain using multiple layers of transformation [5] .\nA good knowledge of the underlying features in a data collection is required to extract the most relevant features. This could become tedious and difficult when a huge collection of data needs to be handled efficiently. A major advantage of deep learning methods in their capability to directly learn feature representations by allowing the system to learn complex features from raw images. This allows us to define a system that does not rely on hand crafted features, which are mostly required in other machine learning techniques. Deep learning techniques are known for compact extraction of information from medical images and have achieved improvement in performance, when compared with traditional methods without learning [1] . Also, a deep convolutional neural network (DCNN) was presented for the classification of 1000 different categories having more than a million images and won the image-net classification task [6] .\nThese properties have attracted attention for exploring the benefits of using deep learning in medical image analysis. The advancements in deep learning techniques are now considered as a key factor for the future medical applications. Here, we present a detailed review of the current state of the art in terms of deep learning techniques as applied to medical image analysis. A summary of the key performance parameters having clinical significance achieved using deep learning methods is also presented. The rest of the paper is organized as follows. In Section 2, a brief introduction to the field of medical image analysis is presented, highlighting the key areas such as segmentation, detection and classification, computer aided diagnosis and retrieval. The parameters used to evaluate such a system is also presented. In Section 3, a summary of deep learning methods is presented, followed by their application to medical image analysis. Some of the key contributions are used and discussed as examples showing the efficacy of DL methods in Section 4, followed by conclusion."}, {"section_title": "Medical Imaging Modalities", "text": "Computed Tomography (CT)"}, {"section_title": "Fig. 1 Typology of Medical Imaging Modalities", "text": ""}, {"section_title": "Medical Image Analysis", "text": "Medical imaging includes those processes that provide visual information of the human body. The purpose of medical imaging is to aid radiologists and clinicians to make the diagnostic and treatment process more efficient. Medical imaging is a predominant part of diagnosis and treatment of diseases and represent different imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), positron emission tomography (PET), ultrasound, X-ray and hybrid modalities [7] . These modalities play a vital role in the detection of anatomical and functional information about different body organs for diagnosis as well as research [8] . A typology of medical imaging modalities used for different body organs is given in Fig. 1 . Medical imaging is an essential aid in the modern healthcare and computer aided diagnosis (CADx) systems. Machine learning plays a vital role in CADx with its applications in medical image analysis, tissue or cancer detection and classification, image guided therapy, medical image annotation and medical image retrieval [9] [10] [11] [12] [13] ."}, {"section_title": "Segmentation", "text": "Segmentation is a process of dividing an image into multiple non-overlapping regions based on a specific criteria i.e., set of pixels or some intrinsic features such as color, contrast and texture [14] . The interesting property of segmentation is that it reduces search area in an image i.e., by dividing original image into two classes such as object or background. The key aspect of image segmentation is to represent the image in a meaningful form such that it can be conveniently utilized and analyzed. Generally, segmentation is useful in image processing based applications like biometrics [15, 16] , contour detection [17] , object matching [18] and object recognition [19] . In literature, several image segmentation algorithms have been proposed, which are based on thresholding [20] , region growing [21] , clustering [22] , edge detection [23] , active contour models [24] , graph cut [25] and mean shift [26] . In recent studies, segmentation has been applied on different types of images [27] [28] [29] for applications such as satellite images [30, 31] , tomographic maps [32] and medical images [33, 34] .\nThe meaningful information extracted using segmentation in medical images involves shape, volume, relative position of organs and abnormalities detection [35, 36] . In [37] , an iterative 3D multi-scale Otsu thresholding algorithm is presented for medical image segmentation. To eliminate the effects of noise and weak edges, images are represented at multiple levels. In [38] , a hybrid algorithm for automatic segmentation of ultrasound images is proposed that combines features from spatial constraint based kernel fuzzy clustering and distance regularized level set (DRLS) function based edge features. The performance is evaluated by conducting various experiments on synthetic and real ultrasound images. A segmentation approach for 3D medical images is presented in [39] , in which the system is capable of assessing and comparing the quality of segmentation. The approach is mainly based on the statistical shape based features coupled with extended hierarchal clustering algorithm and three different datasets of 3D medical images are used for experimentation. A recent brain tumor segmentation algorithm using cascaded deep CNN is presented in [40] while another method for segmentation of glioma tumor using deep CNN is presented in [41] , two co-centric patches are extracted from input images for training while the presented approach was experimented and evaluated using two datasets i.e. BRATS 2013 and BRATS 2015."}, {"section_title": "Detection and Classification of Abnormality", "text": "Abnormality detection in medical images is the process of identifying a certain type of disease e.g., tumor. Traditionally, experts detect abnormalities but it requires a lot of human efforts and is time consuming. Therefore, automated systems for detecting abnormalities is gaining importance. Different methods have been proposed in literature for abnormality detection in medical images. In [42] , an approach is presented for detection of brain tumor using MRI segmentation fusion namely potential field segmentation (PFS). The performance of these type of systems are tested on a publicly available MRI benchmark known as brain tumor image segmentation (BRATS). A particle swarm optimization (PSO) based algorithm is presented in [43] for detection and classification of abnormalities in mammographic images using texture features and support vector machine (SVM) classifier. In [44] , a method for detection of myocardial abnormalities is presented using cardiac magnetic resonance imaging. Recently a CNN based method is presented for the classification of Alzheimer disease in MRI images having multiple classes [45] , two networks i.e. GoogleNet and ResNet are trained on ADNI database. In [46] , an artificial intelligence based method is presented for the smart diagnosis of Alzheimer disease and mild cognitive impairment."}, {"section_title": "Computer Aided Diagnosis (CADx)", "text": "The computer aided detection (CADe) or computer aided diagnosis (CADx) system is used in radiology that assists the radiologist and clinical practitioners in interpreting the medical images. The system is mainly based on functions of machine learning, computer vision and medical image processing. In clinical practice, a typical CADe system serves as a second reader in making decisions that provides more detailed information about the abnormal region. It helps in producing accurate pathology reports but cannot be a permanent replacement for pathologist [47] . The main components of any CADe systems consists of the following stages i.e., pre-processing, feature extraction, feature selection and classification [47] . The detection and segmentation of brain tumor is an example of such system [48] . A CADx system for detection of fatty liver using kurtosis ultrasound images is presented in [49] . A review of computer vision techniques and there application in CADx systems can be found in [50] . A review of CADx system for diagnosis of prostate cancer using texture features from histopathological images is presented in [47] . A CADx system for dry eye diagnosis is proposed in [51] , which is based on tear film maps. In [52] , a CADx system for diagnosis of Alzheimer disease based on complex wavelet transform is presented. An adaptive CADx system for classification of breast tumors based on tumor sizes in screening ultrasound is presented in [53] . A review of CADx systems for breast cancer diagnosis using cytological images can be found in [54] . A CADx system based on multiple instance learning for diagnosis of gastric cancer using dual energy CT images is presented in [55] ."}, {"section_title": "Medical Image Retrieval", "text": "Recent years have witnessed broad use of computers and digital information systems in hospitals. The picture archiving and communication systems (PACSs) are producing large collections of medical images [56] [57] [58] . The hospitals and radiology departments are producing large number of medical images, ultimately resulting in huge medical image repositories. To add uniformity in the production and to manage such large databases, automatic medical image classification and retrieval system is required. A specific medical image retrieval system can assist the examiners in making critical decision about a specific disease e.g., by using similar cases the doctors are able to make more accurate and timely decision about patient's disease, its stage, and diagnosis [59] . To address these issues medical image classification and retrieval systems are required.\nText based and content based image retrieval (CBIR) methods have been commonly used for medical image retrieval systems. Text based retrieval methods are initially proposed in 1970s [56] where images are manually annotated with text description. In case, the textual annotation is done efficiently, the performance of such systems is fast and reliable. The drawback of such systems is that they cannot perform well in unannotated image databases. Image annotation is not only a subjective matter but also a time taking process [60] . The history of CBIR methods started in early 1980s [61] . In these methods, the images are searched and retrieved from large collections based on features such as texture, color, and shape.\nA CBIR system based on line edge singular value pattern (LESVP) is proposed in [62] . In [63] , a CBIR system for skin lesion images using reduced feature vector, classification and regression tree is presented. In [59] , an approach based on bag of visual words (BoVWs) using scale invariant feature transform (SIFT) is presented for brain MRI retrieval for the diagnosis of Alzheimer disease. In [64] , a supervised learning framework is presented for biomedical image retrieval, which uses predicted class label from classifier for retrieval. It also uses image filtering and similarity fusion as basis and multi-class support vector machine (SVM) classifier. The use of class prediction eliminates the irrelevant images and results in reducing the search area in large databases for similarity measurement [65] ."}, {"section_title": "Evaluation Metrics for Medical Image Analysis System", "text": "A typical medical image analysis system is evaluated by using different key performance measures such as accuracy, F1-score, precision, recall, sensitivity, specificity and dice coefficient. Mathematically, these measures are calculated as,\nwhere, TP (true positive) represents number of cases correctly recognized as defected, FP (false positive) represents number of cases incorrectly recognized as defected, TN (true negative) represents number of cases correctly recognized as non-defected and FN (false negative) represents number of cases incorrectly recognized as non-defected. In Eq. 7, P denotes the prediction as given by the system being evaluated for a given testing sample and GT represents the ground truth of the corresponding testing sample."}, {"section_title": "Deep Learning", "text": "Deep learning is a branch of machine learning, which possess different algorithms that attempts to model high level abstractions present in data by exploring deep architectures of multiple processing layers having linear and non-linear transformation functions [66] . Deep learning algorithms can be applied to both supervised and unsupervised learning tasks. Recent studies have reported that deep learning based methods are successfully applied to many real-world applications e.g., image classification [6, 67] , video classification [68] , visual tracking [69] , speech recognition [70] and natural language processing [71] . The history of deep learning started in 1965 [72] but has recently seen some major advances. This is due to the availability of improved computational capabilities, nonlinearities which allow for deeper networks [73, 74] , and better ways to initialize the deep network [75] . Deep learning is based on artificial neural networks, which attempts to mimic the way human brain works. The standard back propagation algorithm popularized in 1980 is yet an effective way of training neural networks [4] . There are numerous deep learning techniques e.g. auto-encoders, stacked auto-encoders, restricted Boltzmann machines (RBMs), deep belief networks (DBNs) and convolutional neural networks (CNNs). In recent years CNN based methods have gained more popularity in vision systems and as well as medical image analysis domain. Therefore, inspired by such popularity of CNNs, we aimed at deeply investigating applications of CNNs for various medical image analysis tasks. A detailed discussion about CNNs is given in next subsection."}, {"section_title": "Fig. 2 Convolutional Layer [76] 3.1 Convolutional Neural Network", "text": "Convolutional neural networks (CNNs) are biologically inspired variants of multi-layer perceptrons (MLPs). They tend to recognize visual patterns, directly from raw image pixels. In some cases, a minimal pre-processing is performed before feeding images to CNNs. These deep networks look at small patches of the input image, called receptive fields, by using multiple layer neurons and use shared weights in each convolutional layer. CNNs combine three architectural ideas for ensuring invariance for scale, shift and distortion to some extent. The first CNN model (LeNet-5) that was proposed for recognizing hand written characters is presented in [77] . The spatial local correlation is exploited by using local connections of patterns between the neurons of adjacent layers of CNN i.e., the inputs from hidden units of layer are taken as a subset of units in layer \u2212 1, units having spatially adjacent receptive fields [76] . Additionally, in a CNN each filter \u210e is replicated around the whole visual field. These filters share bias and weight vectors to create a feature map. The gradient of shared weights is equal to the sum of gradients of the shared parameters. When convolution operation is performed on sub-regions of whole image, a feature map is obtained. The process involves convolution of the input image or feature map with a linear filter with the addition of a bias followed by an application of a nonlinear filter. At a given layer the \u210e filter is denoted symbolically as \u210e , and the weights and bias determine their filters. The mathematical expression for obtaining feature maps is given as, \u210e = tanh ( ( * ) + ) ,\nwhere, tanh represents the tan hyperbolic function, and * is used for the convolution operation. Fig. 2 illustrates two hidden layers in a CNN, where layer \u2212 1 and has four and two features maps respectively i.e., \u210e 0 and \u210e 1 named as 1 and 2 . These are calculated from pixels (neurons) of layer \u2212 1 by using a 2 2 window in the layer below as shown in Fig. 2 by the colored squares. The weights of these filter maps are 3D tensors where one dimension gives indices for input feature maps, while the other two dimensions provides pixel coordinates. Combining it all together, represents the weight connected to each pixel of \u210e feature map at a hidden layer with \u210e feature map of a hidden layer \u2212 1 and having coordinates , .\nAnother important concept in convolutional neural networks is max pooling, which basically performs nonlinear down sampling. Max pooling divides the input image into non-overlapping rectangular blocks and for every sub-block local maxima is considered in generating the output. Max pooling provides benefits in two ways, i.e., eliminating minimum values reduces computations for upper layers and it provides translational invariance. Concisely, it provides robustness while reducing the dimension of intermediate features maps smartly. Fig. 3 shows a CNN architecture like LeNet-5 for classification of medical images having classes accepting a patch of 32 \u00d7 32 from an original 2D medical image. The network has convolutional, max pooling and fully connected layers. Each convolutional layer generates a feature map of different size and the pooling layers reduce the size of feature maps to be transferred to the following layers. The fully connected layers at the output produce the required class prediction. The number of parameters required to define a network depends upon the number of layers, neurons in each layer, the connection between neurons. The training phase of the network makes sure that the best possible weights are learned, that would give high performance for the problem at hand."}, {"section_title": "Medical Image Analysis using Convolutional Neural Network", "text": "The advancement in deep learning methods and computational resources has inspired medical imaging researchers to incorporate deep learning in medical image analysis. Some recent studies have shown that deep learning algorithms are successfully used for medical imaging applications [78] [79] [80] [81] . In [82] , a multi scale CNN based approach for automatic segmentation of MR Images is presented that classifies voxel into brain tissue classes. A total of five databases are used having T1 and T2 weighted images at a different postmenstrual age (PMA). In [83] , a tri-planar CNN is used for segmentation of tibial cartilage in knee MRI images. Three 2D CNNs are integrated together for classification of a voxel in 3D images. In [84] , segmentation of isointense brain tissue is presented through a CNN using multimodal MRI dataset by training the network on three patches that are extracted from the images. A deep learning based approach has been presented in [85] , in which the network uses a convolutional layer in place of fully connected layer to speed up the segmentation process. A cascaded architecture has been utilized, which concatenates the output of first network with the input of succeeding network. The network presented in [86] uses small kernels to classify pixels in MR image. The use of small kernels decreases network parameters, allowing to build deeper networks, without worrying about the dangers of over-fitting. Data augmentation and intensity normalization have been performed in pre-processing step to facilitate training process. Another CNN for brain tumor segmentation has been presented in [87] . The architecture uses dropout regularizer to deal with over-fitting, while max-out layer is used as activation function. A two path eleven layers deep convolutional neural network has been presented in [88] for brain lesion segmentation. The network is trained using dense training method using 3D patches. A 3D fully connected Conditional Random Field has been used to removes false positives as well as to perform multiple predictions. The CNN based method presented in [89] deals with the problem of contextual information by using a global based method, where entire MRI slice is taken into account in contrast to patch based approach. A re-weighting training procedure has been used to deal with data imbalance problem. A 3D Convolutional Network for brain tumor segmentation for the BRATS challenge has been presented in [90] . The network uses two path approach to classify pixel in a MR image.\nThe training strategies of a CNN for medical image analysis are presented in [91] including full training and layer-wise fine tuning by using a dataset of 40 short colonoscopy videos that are later divided into frames for detection of polyp. The performance comparison of a pre-trained CNN and a CNN trained on medical images from scratch is presented, showing consistent results for three medical applications including detection, classification, and segmentation by using three distinct medical imaging modalities. In [92] , a CNN based deep learning framework is presented for detection of mitosis in histopathology breast cancer images using crowd based learning on a publicly available dataset, MICCAI-AMID13 having histology images of 23 patients. In [93] , a large scale deep learning framework is presented for detection of lesion in computer aided diagnosis of mammographic lesions. A comparison is also performed between the mammographic CADe systems based on handcrafted features and a CNN.\nA deep learning based method for classification of lungs diseases using convolutional neural networks is presented in [78] that uses two databases of interstitial lung diseases (ILDs) and CT scans each having dimension of 512 \u00d7 512. The network is trained by using 14696 image patches derived from the original scan with a classification accuracy of 85.5%. A method based on convolutional classification restricted Boltzmann machine for lung CT image analysis is presented in [94] . Two different methods are presented for lung texture classification and airway detection. Two different CT lungs datasets are used for lung tissue classification and airway center line detection. The network is trained on image patches of size 32 \u00d7 32 voxels along a gird with a 16-voxel overlap, a patch is kept if it has 75% of voxel belonging to the same class. In [95] , a framework for body organ recognition is presented based on two-stage multiple instance deep learning. In the first stage, discriminative and non-informative patches are extracted using a CNN, while in the second stage the network is fine-tuned on extracted discriminative patches. The experiments are conducted on classification of synthetic dataset as well as body part classification of 2D CT slices. In [96] , a locality sensitive deep learning algorithm called spatially constrained convolutional neural networks (SC-CNN) is presented for the detection and classification of nucleus in histological images of colon cancer. A novel neighboring ensemble predictor (NEP) is proposed for accurate classification of nuclei and is coupled with a CNN. A large dataset having 20,000 annotated nuclei of four classes of colorectal adenocarcinoma images is used for evaluation purposes.\nThe application of deep learning specifically deep CNN for CAD systems is presented in [97] , which highlights three important aspects of a CNN i.e., different CNN architectures, dataset scale, and transfer learning. A CNN is used for detection of thoracoabdominal lymph node (LN) using CT images and ILD detection using 2D CT slices. The study presented in [98] aims at improving computer aided detection using a CNN and random view generation. A global 2.5D image decomposition strategy is proposed for representing images for a CNN and a novel random aggregation method using CNN based classification for CAD systems. Table 1 gives a comparison of different techniques used for lung pattern classification in ILD disease. It can be seen from Table 1 that the CNN based method outperforms different feature extractors and classifiers in major performance indicators. Table 2 also shows a comparison of the performance of a CNN based method and other state-of-the-art computer vision based methods for body organ recognition. It is evident that the CNN based method achieves a significant improvement in key performance indicators.\nDespite the ability of deep learning methods to give better or higher performance as compared to state-of-the-art, there are still a few limitations of the deep learning techniques regarding their application in clinical domain. First, these techniques require large amounts of training data and computational power. Lacking in computational power will lead to a need for more time to train the network depending upon the size of training data being used. Secondly, most of the deep learning techniques e.g., convolutional neural network requires labelled data for supervised learning and it is quite difficult to label medical images manually. These limitations are being overcome with every passing day due to the availability of more computation power, improved data storage facilities, increasing number of digitally stored medical images and improving architecture of the deep networks.\nThe potential applications of convolutional neural network for four major tasks in medical image analysis are highlighted in Table  1 -4. By these tables we conclude that CNN has been successfully applied to various tasks in medical image analysis domain by providing promising results in almost every case. Table 1 gives highlights about the usage of CNN for segmentation task in medical images, the baseline dataset widely used for brain segmentation task is BRATS dataset that focuses on brain tumor segmentation and contains MRI scans. These images/scans have unpredictable appearance and shape of brain tumor that makes the segmentation more difficult. Table 2 gives highlights for the CNN applications for detection and classification task in medical images, it can be seen that CNN has been successfully applied to various modalities with high performance. Also, CNN has addressed different applications areas like recognition, classification, and detection with high accuracy. Widely used performance metrics for evaluation of such systems are classification/detection accuracy, precision, recall, specificity and sensitivity and form table it can be concluded that CNN has provided high performance in detection and classification task of medical image analysis. Table 3 , is highlighting applications of CNN for computer aided diagnosis, any system that is design for computer aided detection can be a part of a computer aided diagnosis system. The Table 3 illustrates the application of CNN for three diagnosis issues i.e. thyroid nodule diagnosis, breast cancer diagnosis and diabetic retinopathy along with the dataset used for each application. The performance metrics used for evaluation of computer aided diagnosis are same as discussed before. Also, a subjective performance measure can also be incorporated to access ability of such systems for diagnosis decision. Table 4 , is illustrating use of CNN for medical image retrieval, it can be seen that CNN has given high performance in both applications i.e. for multimodal image retrieval and radiographic image retrieval. Widely used performance metrics for retrieval systems are accuracy, precision, recall, sensitivity and specificity. From Table 1 -4, it can be concluded that CNN has been applied to broad range of applications in medical image analysis domains and it has given promising results in almost every case. Looking at these successes of CNN in medical domain it seems that CNN will play a crucial role in future medical image analysis systems. In Table 5 and 6, a comparison of the methods using convolutional neural network based methods with other state-of-the-art methods are presented. In table 5, different methods are summarized for infectious lungs disease (ILD) classification. It is clearly observed that methods that combine state-of-the-art features and classifiers are outperformed by a CNN based method giving a significant improvement in F average and accuracy. In table 6, different methods are compared for the task of body organ recognition. The CNN based approach remarkably outperforms the computer vision based methods with state-of-the-art classifiers in all performance measures including precision, recall and F1 score. These comparisons further add credence to the fact that a careful application of deep learning techniques to a vast variety of medical image analysis applications could result in a significant improvement in results and performance. "}, {"section_title": "Conclusion", "text": "In this paper, a detailed review of the deep learning techniques and its application in the field of medical image analysis is presented. It can be concluded that convolutional neural network based deep learning methods are finding greater acceptability in all sub-fields of medical image analysis including classification, detection, and segmentation. This success would ultimately translate into improved computer aided diagnosis and detection systems. Further research is also required to adopt the method to those modalities where these techniques are still not applied. The recent success indicates that these deep learning techniques would greatly benefit the advancement of medical image analysis."}]