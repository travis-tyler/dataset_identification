[{"section_title": "Abstract", "text": "We introduce a novel personalized Gaussian Process Experts (pGPE) model for predicting per-subject ADAS-Cog13 cognitive scores -a significant predictor of Alzheimer's Disease (AD) in the cognitive domain -over the future 6, 12, 18, and 24 months. We start by training a population-level model using multi-modal data from previously seen subjects using a base Gaussian Process (GP) regression. Then, we personalize this model by adapting the base GP sequentially over time to a new (target) subject using domain adaptive GPs, and also by training subject-specific GP. While we show that these models achieve improved performance when selectively applied to the forecasting task (one performs better than the other on different subjects/visits), the average performance per model is suboptimal. To this end, we used the notion of meta learning in the proposed pGPE to design a regressionbased weighting of these expert models, where the expert weights are optimized for each subject and his/her future visit. The results on a cohort of subjects from the ADNI dataset show that this newly introduced personalized weighting of the expert models leads to large improvements in accurately forecasting future ADAS-Cog13 scores and their fine-grained changes associated with the AD progression. This approach has potential to help identify at-risk patients early and improve the construction of clinical trials for AD."}, {"section_title": "Introduction", "text": "Alzheimer's disease (AD) is the most common form of dementia, usually associated with the elderly population (over 65 years of age). AD had a worldwide prevalence of around 33.9 million cases by 2011, with predictions suggesting an increase to about 100 million by 2050 (Barnes and Yaffe, 2011) . Recently, the view on AD diagnosis has shifted towards a more dynamic process in which clinical and pathological markers evolve gradually before diagnostic criteria are met. The AD Assessment Scale-cognition sub-scale (ADAS-Cog) (Mohs et al., 1997) is the most widely used general cognitive measure in clinical trials of AD (Skinner et al., 2012) . While it was developed as an outcome measure for dementia interventions, its primary purpose was to be an index of global cognition in response to antidementia therapies. The ADAS-Cog assesses multiple cognitive domains including memory, language, praxis, and orientation (Skinner et al., 2012) . Because ADAS-Cog has proven important for target clinical assessments, in this paper we focus on a machine learning method that can The population model is first trained using all visits data of N training subjects (x T R are the input features and y T R are the corresponding ADAS-Cog13 scores), where the time difference between two visits is 6 months. The model personalization to the target (previously unseen) subject (N + 1) is then achieved by sequentially adapting the model predictions of the future ADAS-Cog13 scores y t+1:t+4 (using the posterior distribution of GPs -f GP ), informed by the visits data up to time step t, in the personalized GP (pGP) model. We also train the subject-specific modeltarget GP (tGP) -using only the past data of the target subject. The shaded fields in the output vector represent the time points for which we aim to predict ADAS-Cog13 scores. The proposed pGPE performs a regression-based weighting of the experts' pGP and tGP using meta-weights (\u03b1), estimated using a GP regression model (GP). In this way, the optimal weights are trained for each subject and his/her future visit, leading to large improvements over the individual experts (pGP and tGP) in the target task.\nsuccessfully forecast the future values of this score for target subjects. Specifically, we use the modified ADAS-Cog 13-item scale (Mohs et al., 1997) , which is scored on a 85 point scale, where higher scores indicate greater severity. One of the main challenges in the clinical assessment of subjects at risk of developing AD is the ability to accurately predict subjects' future cognitive scores. Such predictions can play an important role in subject selection during the design of AD clinical trials. For this, an automated approach that could forecast future cognitive scores, such as ADASCog13, would be of great value during assessment procedures, and could potentially improve clinical trial design and early detection of at-risk subjects. For example, out of hundreds of clinical trials, costing billions of dollars, fewer than 1% have proceeded to the regulatory approval stage and none have managed to prove a disease-modifying effect (Marinescu et al., 2017; Cummings, 2006) . Previously, it has been suggested that the low success rate of pharmaceutical AD clinical trials could be due to the inclusion of study populations that were too heterogeneous (Falahati et al., 2014) . More successes depend on an improved ability to accurately identify subjects at early ages of the disease where treatments are most likely to be effective. Thus, developing models with improved ability to automatically predict subjects' future AD-related metrics indicating disease progression -and to do so as early as possible, especially before the emergence of clinical symptoms -is an important step towards this end. Furthermore, accurate prediction of symptom onset in the time window of 6 to 24 months is critical to participant selection and formation of clinical trials. Thus, having access to accurate future estimates of the progression of cognitive scores such as ADAS-Cog13 within this time frame is of great importance.\nIn this paper, data from the Alzheimer's Disease Neuroimaging Initiative (ADNI) were used, and, specifically, the dataset processed for the TADPOLE Challenge (Marinescu et al., 2017) . These data are highly heterogeneous and multi-modal, and include imaging (MRI, PET), cognitive scores, CSF biomarkers, genetics, and demographics (e.g. age, gender, race). Although the heterogeneous nature of this dataset lends itself to building powerful, informative multi-modal models, the dataset itself is very sparse, with different combinations of features missing for different subjects. Partial records are also missing for roughly 80% of the subjects (Campos et al., 2015) . Moreover, given the wide variability in available data per subject, inherent per-person differences, and the slowly changing nature of the disease, accurate forecasting of cognitive decline and related measures of disease progression is a significant and difficult challenge. To tackle these challenges, we focus on machine learning models that can easily adapt to each subject when forecasting his/her cognitive scores. More specifically, we investigate the effects of the model personalization for the forecasting task using the framework of Gaussian Processes (GP) (Rasmussen and Williams, 2006) . This non-parametric probabilistic framework offers great modeling flexibility for not only predicting future cognitive scores but also uncertainty in their predictions. This, in turn, provides a principled approach for model adaptation to target subjects via posterior distribution of GP (Peterson et al., 2017) . Moreover, GP are well-suited for forecasting tasks where data are noisy time series with many missing values (Futoma, 2018) , as in ADNI.\nTo this end, we used a cohort of subjects from the ADNI dataset (see Sec. 4) to predict future ADAS-Cog13 scores of target subjects using data from each subject's previous visits. A subject's visit is defined as data collected at a single time point (a subject visit) during ADNI. We start by training a population-level model using multi-modal data of previouslyseen (source) subjects using the base GP regression (sGP). Then, this model is adapted sequentially over time to a new (target) subject using the notion of domain adaptive GPs (Liu and Vasconcelos, 2015; Eleftheriadis et al., 2017) . We extend this personalization approach, denoted as pGP (Peterson et al., 2017) , for the forecasting task of predicting the ADASCog13 scores at 6, 12, 18 and 24 months in the future. We also compare this approach with the subject-specific GP model, trained only on the data of the target subject (tGP). While we show that these models achieve good performance when selectively applied to the forecasting task (one performs better than the other for certain subjects/visits), their individual (average) performance is suboptimal. To this end, we propose a novel weighting scheme for the GP experts based on the notion of meta-learning (Vanschoren, 2018) . The main idea of meta-learning is to observe how different machine learning approaches perform on a wide range of learning tasks, and then learn from this experience, or meta-data, to learn new tasks more effectively. Following this approach, we designed a regression-based weighting of these expert models in the proposed personalized GP experts (pGPE) model, where the expert weights are optimized for each subject and his/her future visit using data-derived meta-features (see Sec. 3.3) . Our results show that this newly introduced personalized weighting of the expert models leads to large improvements in accurately forecasting future ADAS-Cog13 scores for each target subject, while also outperforming traditional weighting schemes for expert models (e.g. by simply averaging the model predictions or using the GP-variance-based weighting), and the standard models for time-series forecasting tasks."}, {"section_title": "Related Work", "text": "We briefly review here the related work on forecasting of cognitive scores and clinical status for AD assessment, with the focus on the ADNI dataset. Most existing approaches, e.g., Gavidia-Bovadilla et al., 2017) , focus on modeling subjects based on their clinical status (CS): cognitively normal (CN), mild cognitive impairment (MCI) and Alzheimer's Disease (AD). Additionally, the majority of these model biomarkers at the population level; for instance, estimating typical trajectories of markers over the full course of the disease to estimate current disease progress and progression rate . Guerrero et al. used mixed effects modeling to derive global and individual biomarker trajectories for a training population, which was later used to instantiate subject-specific models for unseen subjects. Some of the modeling techniques Schmidt-Richberg et al., 2015 require cohorts with known disease onset and are prone to bias due to the uncertainty of the conversion time.\nWhen it comes to forecasting clinical status, several authors attempted predicting target scores for longer time windows. For example, several recent works have explored the use of multiple, multi-modal predictors in combination with various machine learning techniques (e.g. SVMs, neural nets, GPs, etc.) to predict conversion from MCI to AD for various future time periods, e.g. from 1-5 years after baseline assessment (Long et al., 2017; Minhas et al., 2017) . Likewise, the BrainAGE framework has been proposed for predicting MCI-AD conversion within 3 years of follow-up (Gaser et al., 2013) . In addition, to predict conversion within time windows of up to 2 years (short-term converter) and 2-4 years (longterm converter), (Pereira et al., 2017) proposed a stepwise learning approach, where the learned model first predicts whether a subject converts to dementia, or remains stable, and then predicts the more likely progression window (short-term or long-term conversion). More recently, (Grassi et al., 2018) evaluated different machine learning models in order to develop an algorithm for a 3-year prediction of conversion to AD in MCI and PreMCI subjects based only on non-invasive and effectively collectible predictors.\nMost of these works attempted forecasting the changes in subjects' CS, which deals with a limited number of future outcomes (i.e. either binary or a three-class). By contrast, we aim to forecast ADAS-Cog13, defined on a more fine-grained scale (85 levels), which poses a more challenging machine learning problem. While recent work investigated forecasting of ADAS-Cog13 (Peterson et al., 2017) , along with other cognitive scores from the TADPOLE challenge, using the GP framework, their forecasting horizon was limited as it only predicted one time step ahead (6 months). In this work, we attempt forecasting of ADAS-Cog13 up to 24 months ahead. While recent work in (Utsumi et al., 2018) has shown that a simple combination of personalized GP models leads to better prediction accuracy of the target cognitive scores, to the best of our knowledge, no prior work has proposed a principled approach for combining this expert knowledge. In this paper, we do so using the notion of meta learning to design an optimal weighting scheme for personalized GP models."}, {"section_title": "Methodology", "text": "Notation. We consider a supervised setting, where X = {X (s) , X (t) } represent the input features to our model, and superscripts l = {s, t} refer to the data of source (i.e., training) (s) and target (t) subjects, respectively. Similarly, the ADAS-Cog13 scores we aim to forecast are stored in\nn=1 , where N s and N t are the numbers of the source and target subjects, respectively. Furthermore, x = [x 1 , . . . , x t , . . . , x T ] are the input features (predictors) for each time step of the subject's data 1 , and T \u2264 13 is the maximum number of visits per subject over the period of 10 years, which varies largely per subject. Each x t is a vector containing the features as\nt , y t ] T , where T is the transpose operation, and m i=1,...,6 denotes the features from each data modality. We also add the current cognitive score y t \u2208 (0-85) as a predictor since we found that it is a strong predictor of the future scores. The scores that we forecast are stored in\n, and as y = [y 1 , . . . , y t , . . . , y T ]. Here, each y t contains the scores in the forecasting window of four steps ahead, and is given by y t = [y t+1 , . . . , y t+4 ] T . Thus, the goal of the forecasting models proposed here is to learn an efficient mapping: X \u2192 Y . As many subjects in ADNI missed certain visits and not all biomarkers were recorded at every visit, we fill in subjects' missing values using their nearest available past visit; however, no data of future visits are used. 2"}, {"section_title": "Population-level GPs", "text": "We first build the population-level forecasting model using data from the source subjects\nTo this end, we use the GP framework (Rasmussen and Williams, 2006) to train the following forecasting function:\nwhere\nadditive Gaussian noise, which variance \u03c3 2 s is estimated from the training data. In this framework, central to learning of the forecasting function f (\u00b7) is the GP prior that is placed over the function space, leading to the marginal likelihood of\n, where the elements of the kernel matrix are given by\n) and I is the identity matrix. The choice of the kernel function k(\u00b7, \u00b7) is at the heart of GPs as it encodes the relationships in our data. To this end, we use the standard radial basis function (RBF) kernel. Specifically, we investigate two types of the RBF kernel: isotropic (iso) and automatic relevance determination (ard) (Rasmussen and Williams, 2006) . The latter assigns different weights (length-scales) to each feature (in our case, each data modality), effectively doing feature selection.\nThe kernel parameters \u03b8 are optimized by minimizing the negative log-marginal likelihood: \u2212 log p(Y (s) |X (s) , \u03b8) using conjugate gradient method. Then, given the data from the visit at time t of a new subject, x * = {x t , y t }, the GP predictive distribution provides 1. The subscript t refers to time and is different from superscript (t) that refers to the target subject. 2. To tackle this, more advanced approach based on auto-encoders can be used, e.g., see (Campos et al., 2015) , and we leave this for the future work.\nthe mean and variance forecasts of the cognitive scores y * as:\nwhere k * = k(X (s) , x * ) and k * * = k(x * , x * ). We use the mean of this predictive distribution for the point estimate of target outputs, denoted as \u00b5 (s) * = \u00b5 (s) * (x * ) for notational convenience. Note that we use the shared covariance function for simultaneous forecasting of the four future scores in y * . Consequently, the model assigns the same variance (V * ) to the forecasting window. We refer to this setting as the source GP (sGP)."}, {"section_title": "Personalized GPs (pGP and tGP)", "text": "We use the notion of domain adaptive GPs (DA-GP) (Liu and Vasconcelos, 2015; Eleftheriadis et al., 2017) to personalize the population GP model to target subjects. This is achieved by sequentially adapting the GP posterior for the test subject using the data of his/her past visits, to forecast the future ADAS-Cog13 scores y. This is achieved by using the obtained posterior distribution of the source (population) data as a GP prior for the GP of the ADASCog13 scores of the target subject at time t, given by p(y\n. Assuming that we have already observed the data of the target subject, up to time t\u22121, we use the data pairs {x 1:t\u22121 ), where (t|s) denotes the conditioning order. For exact derivation, see (Liu and Vasconcelos, 2015) . Given this prior and a test input x * = x (t) t , the correct form of the adapted posterior after observing the target subject data at visit t represents the predictive distribution of the personalized GP (pGP):\nwhere (4) (5) show that final forecast by the pGP is the combination of the population-model forecast, plus a correction term. 3 The latter shifts the mean toward the distribution of the target subject and improves the model's confidence by reducing its predictive variance as more data of the target subject is observed. The inference in pGP is efficient as it uses the kernel parameters of the sGP, thus, no further training is employed.\nWe also form the target-subject-specific GP (tGP) model using only the observed data of the target subject up to time t, i.e., the same data we used for the adaption in pGP. However, since this data set is of insufficient size to train the GP parameters -the GP would easily overfit -we use the kernel parameters of sGP. Unlike sGP, which has a fixed covariance matrix (trained using the source subjects), tGP continually updates its covariance matrix as more past data (up to t) of a target subject become available. Nevertheless, the inference procedure is the same, and for x * = x (t) t , the predictive distribution of tGP is given by:\nwhere k * = k(x (t) 1:t\u22121 , x * ), k * * = k(x * , x * ), and K (t)\n1:t\u22121 ). Note that the kernel matrix here increases in size after each visit of a target subject."}, {"section_title": "Personalized GP Experts (pGPE)", "text": "After obtaining the pGP and tGP expert models, an optimal weighting scheme is learned to combine these two models within the proposed pGPE approach. We introduce a novel weighting scheme based on meta-learning that assigns the optimal weights to the expert models for each subject and his/her visit. More formally, recall that the predictive distribution of each expert's forecasts for the time window ahead is given by:\n, and tGP:\nUsing the expert distributions, we obtain the forecasts y (g) by the pGPE model as:\nIn this work, we consider only the point predictions, defined as the mean of the predictive distribution defined above. To find an optimal weight \u03b1 for each subject and his/her visit, we solve the following optimization problem:\nwhere \u03b1 opt = [\u03b1 opt 1 , . . . , \u03b1 opt N ], and N = N s \u00d7 T is the total number of training samples from the training subjects and their visits. Since we seek to optimize one \u03b1 for each data sample, Eq.10 is a convex optimization problem with a closed form solution given by:\nThese optimal weights are used for further learning in the proposed approach. While we are able to learn these weights for the training data, it is unclear how to generate those weights for the target subjects and their visits since the future scores are unknown. To solve this, we first derive the following feature vector for each visit of the training subjects:\nwhere m t contains the four predictions per expert, pGP (y (p) ) and tGP (y (t) ), obtained by evaluating the pre-trained expert models on the data of the training subjects' visits t = 1, . . . , T . We also include their ground truth score for the current visit, y t . However, we do not use the data of the target subjects. Finally, the expert weights for the new data point at which we aim to forecast the future ADAS-Cog13 are obtained as:\nwhere the function f (\u00b7) is trained using a GP regression model with the RBF-ard kernel function and training data pairs {M , \u03b1 opt }, where M = {m i=1,..,N } T . Note that the feature vector was centered by subtracting the mean of its elements. Also, we applied the quadratic expansion of such feature vector followed by the element-wise normalization with the norm of the expanded feature vector, resulting in a 55-dim feature vectors. This allowed the GP to capture the underlying relationships between these meta-features and optimal weights for the target experts. We also experimented with other feature types (e.g., using the input features, the prediction uncertainty, and the optimal weights from previous visits of the target subject), but the ones reported here achieved the best performance in the task."}, {"section_title": "Results", "text": "Data used in this paper come from the ADNI database (adni.loni.usc.edu). We downloaded the standard dataset processed for the TADPOLE Challenge (Marinescu et al., 2017) ; this dataset represents 1,737 unique subjects and was created from the ADNIMERGE spreadsheet, to which regional MRI (volumes, cortical thickness, surface area), PET (FDG, AV45, AV1451), DTI (regional means of standard indices) and cerebrospinal fluid (CSF) biomarkers were added. From this data, we excluded: the PET data, because of their sparsity, the cognitive scores other than ADAS-Cog13, as well as the clinical status (CS) and normalized ventricle volumes (ICVn) 4 , to construct a multi-modal feature set containing: demographics (6 features), genetics (3 features), CSF (3 features), MRI (365 features), and DTI (229 features), thus 606 input features in total. Furthermore, we selected a cohort of subjects with at least 10 visits, and whose records were not missing more than 82.5% of the subject data (from all modalities/visits), resulting in 100 subjects, 48 of whom were diagnosed with AD. We performed a 10-fold subject-independent cross-validation (i.e., each fold contained data of 10 subjects). 5 The input features were z-normalized (zero mean, unit variance).\nTo measure the models' performance, we report \u00b5 \u00b1 \u03c3 of mean absolute error (MAE) for the 10-folds. To form the forecasting window of four consecutive visits (6, 12, 18 and 24 months), we imputed the ADAS-Cog13 scores for the missing visits using the scores of the past visits. However, the reported evaluation metrics were computed using the scores for the existing visits only. We evaluated three types of GP models: (i) population-level (sGP), (ii) personalized (pGP and tGP), and (iii) personalized experts (pGPE). The settings for these models are as follows:\n\u2022 Population-level GPs. To forecast the future ADAS-Cog13 scores, we trained the sGP models using the input features for the visits up to time t and the corresponding ADAS-Cog13 score (y t ). We employed two kernel functions: sGP(RBF-iso) and 4. In the TADPOLE Challenge, ADAS-Cog13, CS and ICVn are treated as target outputs, so in this work we excluded the latter two from the predictors in our model. 5. The models were trained using data from 9 folds, and tested on data of the remaining fold. This was repeated for each of 10 folds. sGP(RBF-ard) (Rasmussen and Williams, 2006) , where the latter learns a separate length-scale parameter for each data modality used, and y t , i.e., \u03bb i=1:6 . We also report the performance of the sGP(RBF-iso) model when only y t from the current visit (VIS) is used as a predictor of the future scores, effectively doing the label smoothing. We denote this model as sGP(VIS).\n\u2022 Personalized GPs. We also report the performance by the pGP and tGP models (Sec. 3). The former performs the adaptation of the sGP to the new subject using the subject data up to time t, while the latter builds a new kernel matrix using only the data of the new subject (however, it uses the hyper-parameters of the sGP(RBF-ard) model). We used the sGP(RBF-ard) model described above to derive the pGP and tGP models, since it achieved the best performance among the population-level GPs.\n\u2022 Personalized GP Experts. As described in Sec. 3.3, we used the pGP/tGP models as experts in the proposed pGPE approach. Below we describe different weighting schemes, including the proposed meta-weighting, we applied to these experts. W prior : derived by inspecting the average performance of the pGP/tGP models and by applying the best performing model per visit/forecasting step (see Fig.2 ). W f req : derived based on the frequency of pGP outperforming tGP per visit and per subject for each forecasting step. The weights range from 0 to 1, and represent the normalized sum over the columns (subjects) depicted in Fig.3 . W ave : derived by averaging the forecasts by pGP and tGP, as in (Utsumi et al., 2018) . W var : the variance-based weighting (Deisenroth and Ng, 2015) of pGP/tGP. W reg : the proposed regression-based meta-weighting of pGP/tGP (Sec. 3.3) W opt : the optimal weights obtained by applying Eq. (11) to the target data.\nWe also include the baseline comparisons with non-GP models, commonly used for forecasting tasks, and usually applied to the ADNI dataset. Specifically, we compare to Lasso Regression (LassoR), Support Vector Regression (SVR) with RBF(iso), and Long ShortTerm Memory (LSTM) (Hochreiter and Schmidhuber, 1997) . In relation to the GP models evaluated, LassoR can be seen as our sGP with linear kernel and l 1 regularization, and SVR as a sparse version of our sGP. However, SVR does not provide probabilistic outputs, and, thus, it lacks a principled way for model adaptation, as done in our personalized GP models via their posterior distribution. The optimal regularization parameter and kernel width of LassoR and SVR, respectively, were selected on the held-out subjects from the training set (10/90). As input to LSTM, we tried a sliding window of the size n = 1, .., 5, containing observations from the past visits. We used again the held-out dataset to select the optimal window size (n = 2), and the number of the LSTM output states (h = 64). This was followed by a fully-connected linear layer (64 \u00d7 4). During the model training, we applied a dropout (0.3) to prevent the model overfitting. Lastly, we report the results obtained by a model-free approach, denoted as Base (y t ), where the score from the current visit (y t ) was used as a forecast of the four steps ahead. Table 1 compares the evaluation metrics for the model settings described above. By comparing different population-level GP models, we note that simple smoothing of the previous ADAS-Cog13 score (y t ) using sGP(VIS) is quite effective. We attribute this to the fact that the target scores from the consequent visits are highly correlated. Compared to the model free approach, Base (y t ), which forecasts by \"carrying forward\" the current score, we note that sGP(VIS) takes advantage of the GP's smoothing property, effectively leveraging the labels (i.e. ADAS-Cog13 scores) from the training population. This results in average error reduction of 0.32 over the four time steps. However, the data-informed sGP(RBF-ard) model (that performs the smoothing of the input features) achieved the best performance overall. By learning the separate length-scale parameters for each modality, this model was able to successfully combine different data types -something that cannot be achieved with RBF-iso, resulting in the adverse performance by the sGP(RBF-iso) model. Next, we compare the personalized models (pGP and tGP) that use the sGP(RBF-ard) as the base model. It is evident that using the domain adaptive GPs to personalize the population-level model to each subject (pGP) helps to reduce MAE, the difference being more pronounced in later time steps. On the other hand, the tGP model outperforms the population-level sGP/pGP only at step t + 3. Yet, as can be observed from Fig. 2 , tGP outperforms these models at certain visits, even though this is not reflected in its MAE.\nThe bottom half of Table 1 shows results obtained from different weighting schemes that we devised to compare with our regression-based pGPE approach (pGPE(W reg )). First, note that the weighting of the pGP/tGP models based on the heuristics derived by looking at the models' scores per-visit/subject leads to similar or better performance compared to the pGP model alone. Specifically, frequency-based weighting (W f req ) is slightly more effective than W prior as it is not biased by the amplitude of the per-subject MAEs when deriving time-steps where one of the expert models dominates over the other. This is used to derive prior weights (W prior ) for the pGPE approach by selecting the optimal model (on average) for each visit and across the four forecasting time steps. Note that after the fifth visit, the subjects in ADNI were seen on a yearly basis.\nthe weights. This is because some subjects had much higher MAE than the others, which, evidently, did not translate well to test subjects when applying this binary model selection encoded by W prior . Interestingly, averaging the two experts (pGP/tGP) via W ave further reduces MAE. As this model outperforms both the pGP and tGP alone, this also signals that the two models have very different performance per subject/visit, also evidenced by Figs. 2&3. Thus, by simply averaging their predictions, this model reduces the prediction biases of the pGP/tGP models. We also explored the predictive variance of the pGP/tGP experts to assign different weights to the models based on their confidence in the target predictions (Deisenroth and Ng, 2015) . While this approach improved the performance of tGP alone, it hurt the overall performance of pGP. By looking into the estimated variances, we found that tGP tended to overestimate the prediction variance, due to the small amount of data (only the target subject visits' data were used to construct the kernel). The proposed regression-based weighting outperforms the compared weighting schemes by large margin, as can be seen from the per-time-step and overall results. This is consistent for the whole forecasting horizon. Note that, apart from the variance-based weighting, the other weighting approaches apply the same and fixed expert weights across all subject. This is suboptimal. The benefit of learning the subject-and visit-specific weights, as introduced here, is clear from the results obtained. This further shows that the optimal weights vary largely across subjects/visits (see Fig. 3) ; however, the proposed meta-weighting using GP was able to effectively learn those changes. To confirm this interpretation, we applied random weights sampled from the learned GP. This resulted in performance significantly lower than that obtained by the population-based models. We also included the results obtained Figure 3 : Plots depicting the best performing personalized model for each subject and his/her visit. For pGP, this is shown in white (-1), and for tGP this is shown in black (+1). When there is no visit data available, this is shown in gray (0). Note that the pGP always outperforms tGP at t+1, while for the later time steps, the models exhibit largely heterogeneous performance.\nFigure 4: The graphs showing the ADAS-Cog13 scores for each visit (averaged across subjects) by the proposed regression-based pGP expert model (pGPE(W reg )) -predicted-and ground-truth scores. Each graph shows these scores along with their standard deviation across the subjects, where the subjects were separated based on their clinical status: cognitively normal (CN), those who converted at one point from CN to mild-cognitive impairment (MCI) (CN\u2192MCI), those who stayed at MCI, and those who were diagnosed initially or converted to AD.\nwith the optimal weights (W opt -see Sec. 3.3) that show the lower-bound on MAE that can be achieved with the proposed pGPE approach. By looking at the performance achieved by the baselines, we note that LassoR, typically used in clinical settings because of its interpretability, outperforms the GP and SVR population models with non-linear mappings (RBF-iso). This evidences that a simple linear model can be useful in this context, however, like SVR that is commonly used in prediction tasks in ADNI, it does not provide a probabilistic output. On the other hand, due to the probabilistic nature of GPs, pGP can easily adapt to the target subjects, which result in lower average MAE. While LSTMs have shown great performance in various clinical time series forecasting tasks, in our experiments on the ADNI data, it underperformed. We attribute this to the highly heterogenous and irregularly sampled data, which, evidently, negatively affects the ability of LSTM to leverage its memory properties. Fig. 4 shows the graphs depicting the predicted ADAS-Cog13 scores for each visit (averaged across subjects) by the proposed pGPE(W reg ) that we plot against the ground-truth scores. Each graph shows these scores along with their one standard deviation across the subjects, where the subjects were separated based on their clinical status (not used as input in the models): 25 cognitively normal (CN), 20 who converted at one point from CN to mild-cognitive impairment (MCI) (CN\u2192MCI), 7 who stayed at MCI, and 48 who were diagnosed initially or converted to Alzheimer's Disease (AD) in one of their visits. Note that the proposed approach can accurately forecast the trend in changes of the target scores. As can be seen, the subjects who were diagnosed with AD or converted to AD at one of the visits have a large deviation from the ADAS-Cog13 scores for the other three types of clinical status, with this difference being more pronounced towards later visits, as expected. While we show here that the proposed approach matches well the distributions of the cognitive scores at the sub-group level, the proposed approach can be used to predict the trend of the cognitive changes for each target subject, and associate it with future changes in his/her clinical status (e.g. to detect subjects that will rapidly progress over a period of 2 years). We plan to investigate the feasibility of such approach in our future work."}, {"section_title": "Conclusions", "text": "Accurate forecasting of changes in the biomarkers of AD is challenging, mainly because of the highly heterogeneous, noisy and missing nature of the clinical data available for this task, but also due to the highly pronounced individual differences in such data. As a step forward, this work developed a novel personalized approach for accurate forecasting of ADAS-Cog13, a significant biomarker of AD, up to two years in the future. The proposed personalized GP framework for time series forecasting uses the notion of meta learning to determine an optimal weighting scheme for individual expert models based on personalized GP models. We showed on a sub-cohort of ADNI subjects that this approach brings significant improvements over population-level GP models. Furthermore, we showed that the proposed personalized experts alone cannot generalize well enough across all the subjects and their visits. By contrast, the introduced personalized meta-weighted GP framework enables accurate forecasting of changes in ADAS-Cog13, outperforming the existing personalized GP models, and traditional models commonly used for forecasting of time-series clinical data. We also showed that the newly introduced meta-weighting is more effective than the standard weighting schemes for GP expert models. In the future, we plan to extend our meta-weighted GPE framework so that it can handle more than two experts and forecast more than one biomarker of AD simultaneously. For this, we will investigate the notion of multi-task GPs and reinforcement learning, for actively learning to select the optimal experts for each subject/visit. We also plan to employ techniques for filling in the missing data in order to increase the cohort of the subjects from ADNI for evaluation of our models. This automated approach for forecasting of cognitive changes in AD could augment and assist clinicians by providing them with intelligent data summarization and decision support tools for early identification of at-risk subjects and construction of informative clinical trials."}]