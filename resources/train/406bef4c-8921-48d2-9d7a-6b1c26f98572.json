[{"section_title": "", "text": "be both a mechanism for ensuring equal opportunity to upward mobility and a means of raising the acumen and contributions of the populace at large. Horace Mann tabbed the common school as the \"great equalizer,\" suggesting that its establishment would drive down poverty and crime while equipping an intelligent populace to develop the natural and material resources to benefit society as a whole (Cremin, 1957(Cremin, /1979. But, if education were to operate today as an equalizer that affords every citizen an opportunity through academics, then providing equal access to course sequences that chart a path to college would seem to be an approach without controversy. However, a long and historical debate over whether high schools should provide the same \"college preparatory\" curriculum to all students, as opposed to a curriculum tailored to students' individual interests, abilities, and needs, complicates the issue (Mirel, 2006). Nowhere is this debate more evident today than in the controversy surrounding mathematics instruction in secondary schools in the United States. The sequence and level of mathematics courses taken in secondary school are critical factors that influence access to higher education. Algebra in particular has been identified as a key factor in academic trajectory, mainly for its perceived role as a \"gatekeeper\" course into higher education (National Mathematics Advisory Panel, 2008;Walston & McCarroll, 2010). Research findings support this notion of gatekeeper as being more than just rhetoric; when taken in eighth grade, algebra has been shown to be associated with positive long-term outcomes for students, including increased mathematics test scores (Attewell & Domina, 2008;Gamoran & Hannigan, 2000); enrollment in advanced high school mathematics and science course-taking sequences (Paul, 2005;Stein, Kaufman, Sherman, & Hillen, 2011); and greater rates of college application, acceptance, and attendance (Atanda, 1999;Spielhagan, 2006). Both access to the algebra course and the grade in which it is taken are important factors in shaping a student's academic trajectory. Taking algebra in the eighth grade is crucial in order to allow students the time to complete a 4year, college preparatory sequence in high school (Loveless, 2008), which in turn enhances their chances of college acceptance (Attewell & Domina, 2008), and subsequent entrance into potentially high paying science, technology, engineering, and mathematics (STEM) fields (Evan, Gray, & Olchefske, 2006). The potential benefits of algebra enrollment in eighth grade, combined with past racial and socioeconomic disparities in access to algebra courses (Adelman, 2006;Silva, Moses, Rivers, & Johnson, 1990;Stein et al., 2011) have fueled major initiatives proposing early algebra-for-all students. The central idea is that providing the opportunity for all students to take algebra in eighth grade will ensure that they are not excluded from college opportunities by course sequences that fall short of college admission policy requirements (Liang, Heckman, & Abedi, 2012). There is some evidence that nationally, placement into algebra is far less likely if a student is Black or Hispanic, low SES, male, or from a single-parent household (Walston & McCarroll, 2010). Although the \"top-down\" approach to mathematics equity by requiring all students to acquire the same content has been criticized as lacking relevance to the everyday lives of marginalized students (Martin, 2003), some policy advocates have identified mathematics access as a civil rights issue, suggesting that mathematics proficiency is a necessary component of literacy in the computer age in order to fully participate in society (Moses, 1995;Moses & Cobb, 2001). In this study, we compare students who performed poorly in eighth-grade algebra to students who passed a lower-level, eighth-grade mathematics course, and examine the academic and psychological and motivational factors associated with success and failure. Such comparisons can be problematic due to a myriad of factors that may contribute to a given student's success or failure in a course. For that reason, in our analyses, we utilize propensity score matching to simulate random assignment and to reduce possible selection bias on several demographic factors that may influence student outcomes. Specifically, our analyses address the following research questions: 1. How does the algebra proficiency level of students who took algebra in the eighth grade and failed (defined in this study as receiving a grade of \"F\" or \"D\") compare to that of students who took a lower-level mathematics course in eighth grade and passed (receiving a grade of \"C\" or higher)? 2. How does the mathematics identification of students who failed algebra in the eighth grade compare to the mathematics identification of those who passed a lower-level, eighth-grade mathematics course? 3. How does the mathematics utility value (perceived usefulness) of students who failed algebra in the eighth grade compare to the mathematics utility value of those who passed a lower-level, eighth-grade mathematics course? 4. How does the mathematics interest of students who failed algebra in the eighth grade compare to the mathematics interest of those who passed a lower-level, eighth-grade mathematics course? 5. What is the relationship between eighth-grade course enrollment and eleventh-grade \"college readiness\"?"}, {"section_title": "Overview of the Literature", "text": "As a result of recent policy changes and initiatives, secondary students are enrolling in advanced mathematics at levels never before seen in U.S. public education. An examination of national longitudinal transcript data revealed an in-crease in the number of mathematics courses taken from 2.7 total credits in 1982 to 3.6 credits in 2004 (Dalton, Ingels, Downing, & Bozick, 2007, p. iv). Over that same period, there was a threefold increase in the number of students taking precalculus and calculus, and a 50% drop in the number of students finishing high school with Algebra I or less as their highest course taken (p. 12). Data from the Early Childhood Longitudinal Study (ECLS-K) reveal that by the 2006-07 school year, 39% of the study cohort was taking Algebra I or higher in the eighth grade (Walston & McCarroll, 2010). In California, the percentage of eighth graders enrolled in algebra increased from 32% in 2003 to 59% by 2011, following the implementation of policies designed to ensure that all eighth graders take algebra (Liang et al., 2012). Moreover, there is some evidence that groups previously underrepresented in higher mathematics courses have started to make inroads as a result of the mandates in many urban districts requiring all students to be enrolled in algebra in the eighth grade. A study of academic curricular intensity using transcript data from the National Educational Longitudinal Study (NELS:88) found that Asians and Whites were taking the most demanding curricula overall. However, once SES and prior performance were controlled, results revealed that traditionally underperforming Black and Hispanic students had begun to take a more demanding curriculum than White students (Attewell & Domina, 2008). The shift towards increased student access to higher mathematics courses is not without criticism. Significant debates have ensued among policymakers and educators about the benefits and consequences of increasing early algebra readiness and course-taking (Allensworth, Nomi, Montgomery, & Lee, 2009;National Council of Teachers of Mathematics, 2008;Rosin, Barondess, & Leichty, 2009). Allensworth and colleagues examined outcomes from a Chicago initiative mandating universal college preparatory coursework and framed the debate in terms of a continuum, which has \"constrained curriculum\" advocates at one end and \"social efficiency\" supporters on the other. Proponents of a social justice approach to curriculum (a position that Allensworth and colleagues term \"the constrained curriculum\") contend that all students should experience a rigorous curriculum that prepares them equally as well for both the workforce and higher education. On the other end of the continuum, the social efficiency argument suggests that, because students have different intellectual capacities, skills, and aspirations, \"schools have a duty to sort and match students to their future places in the social and economic system\" (p. 368). The social efficiency position seems to redefine the role of public education as the \"great sorter\" rather than the \"great equalizer.\" But from a social justice perspective, an important issue is whether this sorting is based on academic merit as opposed to other factors."}, {"section_title": "Placement Factors and Algebra I Outcomes", "text": "Although more students are now being enrolled in higher-level mathematics courses, some critics argue that all students might not be best served by taking Algebra I early. Loveless (2008) maintains that the impetus for universal eighth-grade algebra is an equity focus rather than one based on empirical evidence. However, some empirical evidence suggests that certain groups have not received the same access to algebra, even when their academic proficiency would seem to have predicted otherwise. An examination of course placement practices utilizing Early Childhood Longitudinal Study (ECLS-K) data revealed significant disparities in algebra course placements for Black students (Faulkner, Stiff, Marshall, Nietfeld, & Crossland, 2014). High achieving Black students' odds of being placed in algebra were two-fifths lower than their White peers. An earlier examination of the ECLS-K revealed that even though schools were more likely to place their students with the strongest mathematics skills into courses leading to algebra by the eighth grade, only 35% of Black students who scored in the highest two nationally normed quintiles on a fifth-grade mathematics test were placed into algebra in the eighth grade, compared to 63% of Whites, 68% of Hispanics, and 94% of Asians (Walston & McCarroll, 2010). Higher achieving male students moved on to eighth-grade algebra at lower rates than female students (56% vs. 70%). In every quintile, students placed in algebra had higher subsequent mathematics test scores than their counterparts placed in lower mathematics courses, although the difference in the lowest quintile was not statistically significant. An earlier study by Stone (1998) revealed that high SES students in a large urban district who scored in the upper quartile on a standardized test of academic ability were three times more likely to be enrolled in Algebra I than their low SES counterparts scoring in the same quartile. The disparity in algebra access for high achieving students raises a question as to whether mathematics ability should be the sole determinant of access to college preparatory coursework. Stereotypes and perceived abilities may play a role in placement decisions that are not consistent with demonstrated performance. Welldocumented disparities in African American disciplinary actions, as well as their overrepresentation in \"judgment categories\" of special education (T. C. Howard, 2010, p. 20), point to possible social and behavioral factors contributing to evaluations of competence. The influence of such nonacademic factors in placement decisions cannot be completely dismissed, especially for groups of students whose test scores do not correlate with their opportunities. Evaluations of mathematics competence have also been found to be related to language proficiency levels, which can be exacerbated by placement into tracked courses (Mosqueda, 2010). For English language learners, bilingualism could be utilized as a resource as some have suggested (T\u00e9llez, Moschkovich, & Civil, 2011), rather than a barrier to access. In an examination of National Assessment of Educational Progress (NAEP) data, Loveless (2008) highlighted the lack of correlation between enrollment in advanced courses and NAEP test scores, as well as a small decline in scores for students in advanced courses over a period when more students were being granted access to algebra. From among the students placed in advanced courses, he examined the characteristics of the bottom 10% of participating students in terms of performance on the NAEP (extrapolated to represent approximately 120,000 students nationwide) whom he refers to as the \"misplaced\" students. He found that a large percentage of these students were poor minorities, with parents who did not graduate from college, and who had less qualified teachers while attending large urban schools. He also noted that the large urban schools tended to shun tracking practices in their course assignments, suggesting that such sentiments led to the misplacement of these low-achieving students in the name of equity. Based on his analyses of the students performing at the very bottom, he appeared to call for putting the brakes on the algebra-for-all thrust: Research exists showing that knowledge of algebra is essential for entry into occupations earning middle class wages. No evidence exists that it matters whether algebra is learned in eighth grade or later, and some students may need more than a year to learn the subject. (p. 12) One can hardly argue with the assertion that students who are several years behind grade level and enrolled in advanced courses are misplaced, especially if they are given no support beyond that received by students performing at grade level. Policies that place students into courses for which they are underprepared certainly do not serve the ends of social justice, but rather potentially set up the students for failure and make the work of teachers and other students more difficult. However, a possible limitation in this argument is that the policy is being judged based on the characteristics of a group of students that represented the lowest performing 120,000 out of approximately 4.2 million eighth-grade students nationwide. By contrast, high achieving students who are denied access to Algebra I when other similarly proficient students are granted access are arguably misplaced as well (Walston & McCarroll, 2010). In both cases, it appears that the students are not being well served by their placements. Course placement decisions that are not consistent with students' demonstrated content knowledge give rise to policies designed to ensure each student has access to courses of critical importance. However, in the case of universal algebra access, the policy must be judged by its effects on all student groups. The research is mixed on whether low-performing students benefit from being placed in higher mathematics courses. Data from the NELS:88 revealed that students at all levels of performance benefitted from taking algebra in the eighth grade; however, those in the lowest quintile benefitted the least (Gamoran & Hannigan, 2000). Achievement scores of ninth-grade Chicago students were unaffected following the enforcement of a policy mandate that required low-ability students to be enrolled in Algebra I; however, over the long term, students in the lowest ability groups were more likely to earn credits for upper-level mathematics courses than they did prior to the implementation of the policy (Allensworth et al., 2009). A review of 44 studies published from 1995 onward provides some indication as to the causes for differential access; Stein and colleagues (2011) concluded: \"Our data suggest two major reasons for these demographic imbalances: underpreparedness and subjective placement factors\" (p. 460). The fact that many students are not prepared to take on algebra in eighth grade supports some critics' argument that simply placing students in higher-level mathematics courses without changing their K-7 educational experiences is a recipe for failure (Liang et al., 2012;Schmidt, 2004;Williams, Haertel, Kirst, Rosin, & Perry, 2011). Nonetheless, when students are among the highest achievers in their respective courses and still find themselves denied access to this gatekeeper course, questions of equity in terms of course placements naturally arise."}, {"section_title": "Failure Associated with Raising the Bar", "text": "Another major criticism of universal access mandates is the potential for increased failure rates as a byproduct of moving students into algebra irrespective of their proficiency levels. A mandate requiring all Chicago ninth-graders to take Algebra I resulted in increased failure rates among students moved into algebra as a result of the mandate (Allensworth et al., 2009). Dropout rates, however, did not increase and mathematics scores on proficiency tests taken at the end of ninth grade were unaffected. Increased algebra enrollment rates have been found to be associated with higher rates of failure in those, and subsequent mathematics courses, as well as higher dropout rates later in high school (Silver, Saunders, & Zarate, 2008;Waterman, 2010). An examination of U.S. census data for individuals who graduated between 1980 and 1999 found that in states where mathematics and science course graduation requirements were mandated, dropout rates increased for all groups except Hispanics, although Black and Hispanic male students were most severely impacted. The dropout rate increase overall was less than a percentage point (0.82%), but the increases for Black (1.88%) and Hispanic (2.58%) male students were the greatest (Plunk, Tate, Bierut, & Grucza, 2014). These course graduation mandates were also associated with a decrease in the likelihood for Black women and Hispanic men to enroll in college, but no statistically significant impact to college enrollment was observed on the overall sample. Given that placing more students into a higher, more difficult mathematics course results in more students failing the course, some have suggested placing lower achieving students on a slower path (Liang et al., 2012;Loveless, 2008). However, increased access to algebra has also resulted in more students scoring proficiently on algebra knowledge measures, potentially leaving the gate open for college access. For example, in California, the proportion of eighth-grade students enrolled in Algebra I increased from 32% to 57% between 2003 and 2010, as did the proportion of students scoring \"proficient\" or higher on the Algebra I California Standardized Test (CST) (39% to 46%) over that same period (Williams et al., 2011). Many students are taking advantage of the chance to succeed provided by policy-mandated Algebra I access. The difficult decision arising from these circumstances is determining whether a policy designed to afford every student with an opportunity for college access should be scrapped despite the advantages it provides to many students. Conversely, a policy requiring all students to take algebra despite data indicating that many are not prepared to succeed at it is difficult to defend from a social justice perspective. If universal access to algebra, regardless of prior achievement, is used as a vehicle to ensure college preparation opportunities, some authors have contended that it should include additional supports to scaffold learning for low achievers, as well as support for teachers in learning how to handle heterogeneous student-ability groupings. Nomi (2012) found the lack of these additional supports in the Chicago algebra-for-all policy to be a \"critical limitation\" in its implementation (p. 501). She asserted that such supports were instrumental in a somewhat successful \"doubledose\" approach employed by Nomi and Allensworth (2009). In that approach, ninth graders with lower test scores from the previous year were enrolled in both a regular algebra course and an algebra support course. Nomi suggested, as an alternative, homogeneous groupings could be used while providing additional instruction time for struggling student groups. In either grouping option, the additional support does not necessarily need to be in the form of more time utilizing the same teaching methods. Technology-based supports have shown promise in supporting underlying basic mathematics skills in the context of a traditional mathematics classroom setting (K. E. Howard, 2012) and can be utilized for those students who demonstrate a need for them. Addressing universal access with homogeneous groupings has been viewed as problematic by critics who allege that lower achievers may be placed in courses that are algebra in name only, providing a watered down curriculum that does not prepare students as purported (Schneider, 2009). In that scenario, the same subjective placement factors that have caused potentially algebra-ready students to be placed in lower-level mathematics courses (Stein et al., 2011) may continue to limit opportunities to learn for capable students. In addition, given the negative academic con-sequences and unequal access that have been associated with tracking practices in the past (Mosqueda, 2010;Oakes, 2005), policies that separate students solely on the basis of achievement levels have fallen out of favor. Conversely, mixed-ability groupings present their own set of equity issues. Although such groupings may address the needs of capable students who would have been denied access to algebra under previous policies, inclusion of lower-achieving students, particularly those at the lowest levels, may restrict the pace of education for higher achieving students. Research is mixed as to the impact that heterogeneous ability groupings have on the most advanced students. Some researchers' findings have suggested that the performance of higher achieving students is compromised by de-tracking lower performing students into more advanced courses (Allensworth et al., 2009;Loveless, 2009;Nomi, 2012), presumably due to the need for teachers to slow the instructional pace or otherwise adjust content delivery for a wider range of proficiency. Other researchers suggest that not only do lower-achieving students benefit from detracked courses, but also higher-achieving students have been found to achieve at even higher levels in mixed-ability groups than in high-level tracked groups (Boaler, 2011). However, as discussed next, there is some evidence that not all students in higher achieving homogeneous classrooms benefit from this arrangement. Comparing data across two Chicago initiatives, Nomi and Allensworth (2014) found that although test scores were higher on average when course enrollments were sorted by student skill levels, grades and pass rates in high-skill courses actually declined. Nomi and Allensworth suggested that these declines were due to grading practices (e.g., on a curve), higher demands, and high-achieving students finding themselves below average compared to their classroom peers. Consequently, students with skills near the bottom of their respective courses had higher failure rates. On the other hand, low-skilled students' mathematics scores declined slightly after sorting when no changes were made to curriculum, but increased considerably, along with grades and pass rates, when more classroom time and teacher professional development resources were provided. In addition, low-skilled students were more likely to experience disruptive classroom environments due to more behavioral problems when sorted by skill level. Whether students are sorted by skill levels or placed in mixed-ability groupings, raising the bar on the difficulty level of eighth-grade courses will likely result in increased failure rates in the short term, especially when the structure of the preceding K-7 instruction has not yet been adequately redesigned to better prepare students for the increased demands (Schmidt, 2004). If students, for whatever reason, find themselves unprepared to pass algebra in the eighth grade, would it be better to place those students in a lower-level mathematics course instead? Are there academic benefits to at least exposing eighth graders to algebra regardless of their preparedness, even if they fail the course? In other words, can we find a measure of success associated with course failure? What about the psychological and motivational implications of such an approach? Research indicating the relationship between higher-level course-taking and higher levels of mathematics achievement has not often examined the impact of failure in comparison to successfully completing a lower-level course, nor has it specifically focused on the psychological outcomes associated with success and failure. A comparison of proficiency rates among Californian, ninth-grade students who failed (scored less than proficient) the previous year's Algebra I CST to those who passed the CST for General Mathematics in eighth grade (scored proficient or above) revealed stark differences in the two groups: the students who had failed the Algebra I CST had 69% less of a chance of passing it in the ninth grade than those who had passed the General Mathematics CST in the eighth grade (Liang et al., 2012). At first glance, this would seem to support placing more students in General Mathematics courses; however, upon closer examination only 27.5% of the students in General Mathematics passed the CST in the eighth grade (as opposed to a 41.8% pass rate for Algebra I). The group of students who passed the General Mathematics CST likely included some misplaced students, who may have scored well enough to be placed in algebra but were sorted out by subjective factors previously discussed. Nonetheless, the high rate of repeated failure (5 out of 6) for those who had failed the Algebra I CST the previous year cannot be ignored. This rate indicates that the vast majority of students repeating algebra did not benefit enough from the previous year's exposure to score proficiently the second time around. An alternative explanation is that many were not motivated enough to fully apply themselves either time they took the course, which may be the case for students who have chronically failed mathematics during their short K-8 experience but continued to advance due to social promotion practices (Zinth, 2005)."}, {"section_title": "The Psychology of Failure", "text": "Examining the impacts of failing algebra or passing a lower-level course, all other factors being equal, is an essential element to assessing the wisdom of an algebra-for-all policy. The direct academic impacts of such a policy may include lower test scores and the narrowing of the window available for completion of a college preparatory course sequence. Possible indirect psychological impacts are less obvious, but can be just as detrimental to students' future academic success. These psychological effects may include identifying less with the mathematics domain, having a lower perceived value for mathematics, and experiencing a decline in overall interest in mathematics (Crocker, Major, Schmader, Spencer, & Wolfe, 1998;Keller, 2007;Spencer, Steele, & Quinn, 1999). Several psychological theories have addressed identification with mathematics among underrepresented groups by illuminating coping responses to stigmatiza-tion and societal stereotypes (Major & O'Brien, 2005;Steele & Aronson, 1995). Socially stigmatized groups have exhibited patterns of underperformance when group membership was made salient in testing environments-a phenomenon referred to as \"stereotype threat\" (Steele, 1997). The effects of stigma, or an attribute or identity that is devalued or undesirable in a social context, can impact the psychological, educational, and social outcomes of stigmatized group members through confirming negative stereotypes associated with group membership (Steele, 2003;Steele & Aronson, 1995), disengagement or \"disidentification\" , and distancing one's identity from the target domain (Crocker, Major, & Steele, 1998). If disidentification with the mathematics domain were to occur following failure in eighth-grade algebra, it would likely influence the students' psychological dispositions towards mathematics courses in subsequent years, offering some explanation for the observed repeated failure rates. Identifying with a domain is not, in and of itself, sufficient to motivate students to engage in the work necessary to excel in that domain. Wigfield and Eccles examined children's mathematical beliefs through their expectancy-value theory (Wigfield, 1994;Wigfield & Eccles, 2000), and posited that expectancy and task value are the two most influential predictors of achievement behavior. The expectancy component refers to a student's beliefs as to whether they are able to perform a task (expectation level for success), whereas the value component addresses their beliefs about why they should perform the task at all (Pintrich & Schunk, 2002;Schunk, Pintrich, & Meece, 2008). The influence of negative stereotypes on student expectancy has been demonstrated as early as middle school with Black, Latina/o, and low SES students (K. E. Howard & Anderson, 2010), the very groups that have been found to be most frequently represented among the lowest performing students in advanced courses (Loveless, 2008). The value students ascribe to the mathematics domain is an important marker of student engagement insofar as it is a strong predictor of whether students decide to apply themselves to their mathematics courses. In the expectancy-value model, the value component has two subcomponents (among others) that may be affected by failing a course: intrinsic value and utility value (Schunk et al., 2008). Intrinsic value is the student's subjective interest or enjoyment in doing a task, which is influenced by past performance in that task or domain (Eccles & Wigfield, 2002). Utility value is the perceived usefulness of a task in helping the student to meet his or her future goals; these goals can be adjusted downward as a result of selfregulatory processes following failure (Schmitz & Perels, 2011). These two subcomponents of task value are of particular interest in this study as they may help to illuminate possible indirect effects of universal access policies that may not be evident in immediate academic outcomes. Understanding how these variables are im-pacted by placement decisions, as well as by subsequent success or failure, can clarify the wisdom and consequences of enacting particular course-taking policies. It has been said that a society can be judged by how it treats its most vulnerable members. Policymakers must weigh the impacts of a mandate that requires all students to follow a particular curriculum against those of a policy that does not, particularly on students whose futures are impacted most severely as a result. Thus, research is needed to examine the impact of failure on students' longitudinal mathematics achievement and attitudinal outcomes, and to determine if higher-level course placements benefit students from all levels of attainment. This study is an examination of the impact of eighth-grade mathematics course enrollment and success and failure on subsequent algebra proficiency, college readiness, and psychological and motivational dispositions."}, {"section_title": "Methods and Data", "text": "A nationally representative sample was used for this study (Ingles et al., 2014; National Center for Education Statistics, 2011) to examine the relationships among mathematics course success, failure, and achievement outcomes, as well as to examine the levels of domain identification, utility, and interest associated with students who fail eighth-grade Algebra I. The High School Longitudinal Study of 2009 (HSLS:09) was conducted by the U.S. Department of Education National Center for Educational Statistics. We examined base-year student data, which were collected from ninth graders during the fall of the 2009-10 school year, and the first follow-up wave of data collected in 2012 when most of the students were in the spring semester of eleventh grade. The HSLS:09 data were derived from a sample consisting of more than 21,000 students from 944 public, charter, and private schools in the United States. Each wave of data collection included a mathematics assessment of algebraic reasoning and a computer-based survey addressing various psychological and motivational constructs (Ingels, Dalton, Holder, Lauff, & Burns, 2011;Ingels et al., 2014)."}, {"section_title": "Data Sources", "text": "All of the analyses in this article were based on data obtained from the student-level public use files for the HSLS:09 (base year) and the HSLS:12 (first follow up) data sets. The HSLS:09 variable identifying the highest course each participant took in the eighth grade (S1M8) includes nine self-reported options, including courses more advanced than Algebra I. We were only interested in comparing students who took a version of Algebra I with those who took a lower mathematics course; therefore, we initially filtered the 21,444 cases in the complete data set to include only the students who reported taking Algebra I (including IA and IB; n = 6,675) in Group 1, and those who reported taking Math 8, Advanced/Honors Math 8 (not including Algebra), or Pre-algebra (n = 12,254) in Group 2. The HSLS:09 variable identifying the self-reported grade each participant received in their highest level mathematics course taken in the eighth grade (S1M1GRADE) was used to filter Group 1 to only include the students who received a grade of \"D\" or \"F\" in Algebra I, which resulted in 337 students (5.1%). Group 2 was filtered to include only the students who received a grade of \"C\" or higher in a course lower than Algebra I (i.e., Math 8, Advanced or Honors Math 8, or Pre-algebra), which totaled 11,000 (89.8%). Finally, both groups were trimmed to exclude any cases which had missing data for any of the variables being considered, which resulted in a Group 1 total of 274 and a Group 2 total of 8,504."}, {"section_title": "Propensity Score Matching Procedures", "text": "Given that our data were compiled from non-randomized cases, propensity score matching was utilized to achieve balance on several observed covariates (Stuart, 2010) and to reduce the impact of treatment-selection bias in the estimation of treatment effects. Our final data set (before matching) contained 274 cases of students who received a D and/or F in their respective Algebra I course, and 8,504 cases of students who received an A, B, or C in their lower level mathematics course in eighth grade. The covariates selected for generating the propensity scores were the HSLS:09 student-level data file variables for students' sex (X1SEX), race (X1RACE), language status (X1DUALLANG), locale (X1LOCALE), region (X1REGION), socioeconomic status quintile (X1SESQ5), along with a dummy variable for participant's test date. The language status variable identifies the participant's first language as either English, non-English, or equally English and a non-English language. The locale variable identifies the participant's address as city, suburb, town, or rural. The region variable identifies the participant's location in the country as northeast, midwest, south, or west. The SES quintile variable is a composite variable derived from the parent/guardians' education, occupation, and family income. The test date variable identifies the date when the study-administered test of algebraic reasoning was completed. The tests were administered on three dates during the 2009-10 school year, providing participants with different levels of exposure to their ninth-grade curriculum prior to taking the test. This variable was included in the matching procedure to control for the amount of time elapsed between the date when the participants received their letter grade in the eighth grade and the date when they took the test in the ninth grade. The propensity score matching procedure was conducted in SPSS 21, using an \"R\" plugin, which allows estimation of propensity scores using logistic regression (R Development Core Team, 2008). The propensity scores represent the probability that a person or case will land in the treatment condition given the values on all of the co-variates. In this study, the propensity scores represent the probability that a student would fail Algebra I, given the values on the seven included covariates. Once the propensity scores are computed, the program utilizes three \"R\" packages to perform the procedure: \"MatchIt\" (Ho, Imai, King, & Stuart, 2007), \"RItools\" (Bowers, Fredrickson, & Hansen, 2010), and \"cem\" (Iacus, King, & Porro, 2009). The matching technique utilized in this study was 1:1 nearest neighbor matching (without replacement), meaning each \"treated\" participant was matched to a single \"untreated\" participant who had the propensity score that was closest to an exact match. We used a caliper of .2 of the standard deviation of the logit of the propensity score to ensure good matches (Thoemmes & Kim, 2011). The caliper defines the maximum allowable difference in estimated propensity scores for matches. Cases outside of the common support area (region of distribution in which cases from both groups are observed) were discarded for the larger (untreated) group only, in order to maintain a sufficient sample size for subsequent statistical analyses. After propensity score matching, the treatment and control groups each consisted of n = 274 students. An overall imbalance measure (Hansen & Bowers, 2008) was not significant, X 2 (7) = 1.35, p = .99, indicating good balance after matching. The histograms of the standardized differences depicted in Figure 1 illustrate greatly improved covariate balance after matching as compared to the unmatched sample. The matched sample histogram is heavily centered on zero, indicating no systematic differences existed after matching. Figure 2 depicts the standardized mean differences for each of the covariates before and after matching, illustrating that the magnitude of the standardized differences overall were greatly improved after matching. The standardized mean differences of all covariates were close to 0 after matching.  "}, {"section_title": "Measures", "text": ""}, {"section_title": "Algebra Proficiency", "text": "An online mathematics test of algebraic reasoning was completed by each of the HSLS:09 participants during the fall semester of the ninth grade and during the spring semester of the eleventh grade. The instrument used to measure algebra proficiency was developed and validated by the American Institutes of Research (Ingels et al., 2011). The test and item specifications addressed six algebraic content domains (the language of algebra; proportional relationships and change; linear equations, inequalities, and functions; nonlinear equations, inequalities, and functions; systems of equations; and sequences and recursive relationships) and four algebraic processes (demonstrating algebraic skills; using representations of algebraic ideas; performing algebraic reasoning; and solving algebraic problems). Item analyses were conducted to compile a pool of optimally performing items, including differential item functioning (DIF) statistics to detect potential racial/ethnic and gender biases. Base year. The base year assessment administered to the participants contained 40 items and employed an adaptive design. There were 72 unique items used to compile all of the variations of the test. The item response theory (IRT) estimated reliability of the base year instrument was 0.92 after applying sample weights (Ingels et al., 2011). The HSLS:09 base year variable X1TXMSCR represents an IRT-based estimate of the score for each participant on the full set of 72 items. Each participant completed the assessment on one of three different test dates during the fall term of his or her ninth-grade school year (September 2009, October 2009, or January 2010. The HSLS:09 base year theta score variable X1TXMTH is an ability estimate score based on the same metric as the IRT item-level difficulty parameters. It provides a summary measure appropriate for longitudinal analyses to measure growth in achievement over time. First follow-up. A second algebra assessment addressing the previously listed six algebraic content domains and four algebraic processes was administered during the spring semester of the study cohort's junior year. The follow-up theta score variable (X2TXMTH) was used to compare participant scores over both waves as the common items between waves allowed for equating the IRT scores across waves. The follow-up assessment contained a 69-item pool, including 23 common items across the two waves. This item pool also included 20 new items that were field tested and added to include higher difficulty items and guard against a ceiling effect. The IRT-estimated reliability of this follow up assessment was 0.92 after sample weights were applied (Ingels et al., 2014).\nTo examine for algebra proficiency differences between to two eighth-grade course conditions (failing algebra or passing lower-level course) and any longitudinal differences, a mixed between-within subjects analysis of variance was conducted. The participants' theta scores on the test of algebraic reasoning were compared across the two waves of data. There was no significant interaction between condition and time: Pillai's Trace = .002, F(1, 457) = .80, p = .37, partial \u03b7\u00b2 = .002. As expected, there was a significant main effect for time: Pillai's Trace = .32, F(1, 457) = 218.50, p < .001, partial \u03b7\u00b2 = .32. Both groups showed statistically significant increases in scores over time. The main effect comparing the two course conditions was not statistically significant: F(1, 457) = .92, p = .34, partial \u03b7\u00b2 = .002. Whereas both groups significantly increased their mean theta scores from the base year to the follow-up data collection, there were no statistically significant differences in scores between the two groups."}, {"section_title": "Psychological and Motivational Scales", "text": "Several scales were created for the HSLS:09 and included in the field-testing for the algebra proficiency variables (Ingels, Herget, Pratt, Dever, & Copello, 2010). Three of those scales were examined as part of our analyses over both waves of data. All of the data for the scales were reported in the HSLS:09 in standardized form (with a mean of 0 and a standard deviation of 1) to allow for combining variables with different scales during analyses. A threshold of .65 was used for inclusion of each of the scales as an adequate measure of internal consistency and each of the scales performed above this threshold in both waves of data collection. Table 1 provides coefficients of reliability for each of the scales examined over each wave of data (Ingles et al., 2011;Ingels et al., 2014). Mathematics identity. The HSLS:09 mathematics identity scale score was used to measure students' mathematics identity during both waves of data collection (X1MTHID/X2MTHID; Cronbach's Alpha .84 and .88, respectively). This scale measures the participant's level of agreement from 1 (strongly agree) to 4 (strongly disagree) on two statements: \"You see yourself as a math person\" and \"Others see me as a math person,\" with higher values indicative of higher mathematics identity. Mathematics utility. The HSLS:09 mathematics utility scale score was used in both waves of data collection to measure participants' beliefs in the utility value of learning mathematics (X1MTHUTI/ X2MTHUTI; Cronbach's Alpha .78 and .82, respectively). This scale measures the participant's level of agreement from 1 (strongly agree) to 4 (strongly disagree) on three statements about the importance of mathematics for their future: \"My math class will be useful for college\"; \"My math class will be useful for everyday life\"; and \"My math class will be useful for a future career.\" Higher values indicate higher mathematics utility. Mathematics interest. The HSLS:09 mathematics interest scale score was used for both waves of data collection to measure participants' interest in their current mathematics course (X1MTHINT/X2MTHINT; Cronbach's Alpha .75 and .69, respectively). This scale includes two questions inquiring as to the students' favorite and least favorite (wave 1 only) school subjects, followed by four statements about their current grade mathematics course assessing their level of agreement from 1 (strongly agree) to 4 (strongly disagree): \"You are enjoying this class very much\"; \"You think this class is a waste of your time\"; \"You think this class is boring\"; and \"You really enjoy math.\" Higher values indicate higher mathematics interest. The first year follow-up instrument for mathematics interest was revised to eliminate a question asking for the student's least favorite subject, but still showed adequate internal consistency."}, {"section_title": "College Readiness Variables", "text": "Three variables measuring college readiness were examined by group and compared to the entire HSLS:12 sample. Each variable corresponds to a single question that was part of the questionnaire in the follow-up data collection in the fall semester of the participants' eleventh-grade school year. Community college. The HSLS:12 variable S2REQ2YR corresponds to the question \"By the summer of 2013, do you think you will have met the minimum requirements needed for admission to a 2-year community college?\" The response options were: Yes, No, and Don't Know. Typical four-year college. The HSLS:12 variable S2REQTY4YR corresponds to the question \"By the summer of 2013, do you think you will have met the minimum requirements needed for admission to a typical 4-year college?\" The response options were: Yes, No, and Don't Know. Selective college. The HSLS:12 variable S2REQSEL4YR corresponds to the question \"By the summer of 2013, do you think you will have met the minimum requirements needed for admission to a highly selective 4-year college such as Harvard University?\" The response options were: Yes, No, and Don't Know."}, {"section_title": "Results", "text": ""}, {"section_title": "Descriptives", "text": "Statistical analyses were performed on the final base-year set of 548 participants, split evenly between students who took and failed algebra in eighth grade and those who took and passed a lower-level mathematics course in eighth grade. As illustrated in Table 1, the groups were well balanced through propensity score matching on gender, race, language status, and socioeconomic status. The balance on these important variables was maintained for the participants in the matched group who provided responses in the follow-up data collection. There was a response rate of 83.8% (n = 459) for the follow-up wave mathematics assessment for this group of participants, which compared favorably to the overall unweighted follow-up response rate of 84.3%. Little's MCAR statistic (SPSS Missing Values 22.0) revealed that the missing data met the assumption of MCAR, \uf063 2 (39) = 52.84, p = .07. There were no systematic patterns of missing data when compared to the observed values for all of the matched covariates, the prior mathematics assessment and psychological measure scores, and the college-bound variables. "}, {"section_title": "Psychological and Motivational Outcomes", "text": "The study participants were measured on psychological and motivational scale variables of interest at each of the two waves of data collection. Repeatedmeasures MANOVA analyses revealed a significant multivariate effect for coursetaking group: Pillai's Trace = .03, F(3, 362) = 3.86, p = .01, \u03b7\u00b2 = .03; and a significant interaction effect between course assignment and time: Pillai's Trace = .03, F(3, 362) = 3.37, p = .02, \u03b7\u00b2 = .03. Univariate tests revealed significant interaction effects between course assignment and time for mathematics identity F(1, 364) = 7.05, p < .01, \u03b7\u00b2 = .02; mathematics interest F(1, 364) = 4.86, p = .03, \u03b7\u00b2 = .01; and mathematics utility F(1, 364) = 4.11, p = .04, \u03b7\u00b2 = .01. These were small effect sizes. To further examine the interaction effects, the data set was split and MANO-VAs were performed for each wave of data (Time 1 in ninth grade; Time 2 in eleventh grade) separately. There was a statistically significant difference between the groups on the combined dependent variables for the base year data: F (3, 544) = 14.38, p < .001; Pillai's Trace = .07; partial \u03b7\u00b2 = .07. The eta squared of .07 indicates a medium effect size (Cohen, 1988). The difference on each of the three dependent variables reached statistical significance when the data were separately analyzed. The students who took Algebra I and failed reported lower ratings in the ninth grade on mathematics identity F(1, 546) = 23.44, p < .001, partial \u03b7\u00b2 = .04; mathematics interest F(1, 546) = 24.17, p < .001, partial \u03b7\u00b2 = .04; and mathematics utility F(1, 546) = 31.88, p < .001, partial \u03b7\u00b2 = .06 than students who had passed a lower-level, eighth-grade mathematics course. The mean scores for the differences by group are displayed in Table 2, along with the weighted mean scores for students who passed Algebra I in the eighth grade. The effect sizes for mathematics identity and mathematics interest were small, whereas the effect size for mathematics utility was moderate (Cohen, 1988). Note. Scale values were standardized to a mean of 0 and standard deviation of 1. a No statistical comparison analyses were performed using the \"Passed Algebra\" group due to unequal sample sizes; statistics for this group are provided only for reference purposes. b Cases weighted by base year student weight (w1student) to adjust for oversampling of specific subgroups. c This group was matched on covariates, therefore no filtering of the data occurred for these students. Data from the second wave were examined on the same variables. The missing/non-response levels for mathematics identity, interest, and utility in the followup wave of data were 18.1%, 32.3%, and 18.8%, respectively. The non-response level for interest was higher due to the fact that interest in current mathematics course did not apply to all respondents (i.e., this item was skipped for any student who was not enrolled in any mathematics course at the time). Although the missing data were found to be non-systematic in the MCAR analysis previously noted, response rates under 80% fail to meet researchers' recommended acceptance levels of ignorable missing data (Sterner, 2011;Vriens & Melton, 2002). For such instances, imputation methods represent a more favorable approach than traditional methods such as deletion (casewise or pairwise) or mean substitution (Acock, 2005). Imputation allows the researcher to analyze a complete data set and prevents the loss of statistical power that results from the elimination of data. The missing values in this data set were replaced using multiple imputation. The analyses were performed us-ing the original data set, but were repeated using the imputed data sets for confirmation purposes. One-way between-groups multivariate analyses of variance (MANOVAs) were performed on both the original data (with casewise deletion) and on the full imputed data sets to examine the group differences on the psychological and motivational scale variables of interest for the second wave of data collection. For the original (non-imputed) data set, there was no statistically significant difference between the groups on the combined dependent variables: F(3, 362) = .84, p = .47; Pillai's Trace = .01; partial \u03b7\u00b2 = .007. Summary mean statistics of the five complete data sets generated using multiple imputation also revealed no statistically significant differences in the two groups: F(3, 546) = 1.74, p = .20; Pillai's Trace = .02; partial \u03b7\u00b2 = .009. Figures 3, 4, and 5 visually depict the changes in students' mathematics identity, interest, and utility from the base year data collection in ninth grade to the first follow-up wave in eleventh grade using the original data set. Whereas students who failed Algebra I in eighth grade exhibited lower scores on psychological and motivational scale variables than those who passed a lower course in wave 1 (ninth grade), these differences were no longer present by the second wave (eleventh grade).   "}, {"section_title": "College Readiness Data Analyses", "text": "Data from the follow-up survey were examined to determine whether there were differences between course enrollment groups in their expected college qualification rates. The nonresponse rate for the three college readiness variables ranged from 18.2% to 19.3%. Chi-square tests of independence were performed to examine the relation between eighth-grade course enrollment and reported on-track status for meeting college requirements in the second semester of eleventh grade. The relation between course enrollment and meeting requirements for a 2-year college was not statistically significant: \uf063 2 (1, N = 548) = .01, p = .93, phi = -.01. The relation between course enrollment and meeting requirements for a typical 4-year college was statistically significant: \uf063 2 (1, N = 548) = 7.52, p < .01, phi = -.12. Students who failed eighth-grade algebra were less likely to report being on track for meeting the requirements to attend a typical 4-year college by the end of their senior year than students who passed a lower-level, eighth-grade course. The relation between course enrollment and meeting requirements for a selective 4-year college was not statistically significant: \uf063 2 (1, N = 548) = 1.2, p = .27, phi = .06, although relatively few students from either group are represented in this category. Table 3 displays the percentages (by college type) of each group that expected to meet college requirements by the end of their senior year. The same statistics are provided for students who passed Algebra I in the eighth grade, as well as for the entire HSLS:09 sample. Note. Cases weighted by first follow-up student weight (w2student) to adjust for oversampling of specific subgroups. a This group was matched on covariates; therefore, no filtering of the data occurred for these students."}, {"section_title": "Discussion and Implications", "text": "The HSLS:09 data show that students who failed Algebra I in eighth grade did not score significantly differently in ninth grade on a test of algebraic reasoning from students who passed a lower-level mathematics course in the eighth grade, when matched on several covariates. When compared to the matched sample, the students who failed Algebra I in the eighth grade did not demonstrate any immediate proficiency benefits from their exposure to Algebra I content. This finding is consistent with previous studies' findings that enrollment in college preparatory mathematics courses did not impact academic test outcomes (e.g., Loveless, 2009). Some prior research suggests that residual benefits from exposure to algebra content may not become evident until after subsequent algebra course-taking has occurred. For example, Gamoran and Hannigan (2000) observed achievement growth between grades 8 and 10 from exposure to algebra, and Attewell and Domina (2008) found an advanced high school curriculum to be associated with higher test scores in the twelfth grade. However, the participants in this study who had been enrolled in eighth-grade algebra did not demonstrate any residual performance benefits by the eleventh grade, as they did not perform statistically differently from those who had been enrolled in a lower eighth-grade mathematics course. It should be noted that, without having access to performance data for our sample prior to the eighth grade, we could not state definitively that the groups did not differ in proficiency level prior to receiving their failing or passing grades. Nonetheless, their measured proficiency rates did not differ in the ninth and eleventh grades. Although the students' exposure to eighth-grade Algebra I did not affect test scores, failing the course was associated with lower levels of mathematics identity, interest, and utility in the following year as compared to students who passed the lower-level course. However, by the second half of eleventh grade when the second wave of data was collected, these two groups were no longer statistically different on these psychological measures. Although it might be encouraging to attribute this outcome to resiliency on the part of the failing students, an examination of the univariate outcomes suggest that this inference is only partly accurate. Whereas the mathematics identity scores for the failing students rebounded to be statistically at the same level as those who had passed a lower course, the attenuation of the gap in scores for interest and utility was more the result of declines on the part of the students who had passed the lower level course. It is important to note that it cannot be inferred that the more negative psychological scores were necessarily caused by the failing grades. It is feasible that the students failed because they already had more negative dispositions toward mathematics, or conversely that negative dispositions emerged following the failure. Regardless of the direction of causality (if any), the existence of more negative dispositions towards mathematics indicates that psychological dispositions are somehow associated with mathematics performance in the eighth grade, and placing these students in advanced mathematics courses without addressing these dispositions may be inadequate in terms of the support they may need. The results also provide an argument against placing students in the same course the year following a failure without attempting to address the motivational characteristics that may have contributed to their failure. One interpretation for these findings is that the misplacement of students in eighth-grade Algebra I may have detrimental psychological effects on underprepared students (Loveless, 2008). This interpretation has implications for policy and practice, especially considering the fact that there does not appear to be any academic advantage gained by such placements after enduring the adverse psychological effects. Rationale for placing students in courses in which they are (might be) unable to pass would need to be weighed against the possible impact of failure on future interest in mathematics, and ultimately on mathematics performance. To that point, the higher mathematics utility and interest ratings for the students enrolled in lower mathematics courses did not persist, but rather declined to a level not statistically different from the students who failed Algebra I by the time they reached eleventh grade. A possible silver lining is that with respect to mathematics identity, any impact from failure does not appear to be permanent as the failing Algebra I students recovered by the time the second wave occurred. On the critical issue of college readiness the results were somewhat mixed. The groups did not differ statistically in terms of being on track to meet the requirements of a 2-year college, which generally speaking, usually equates to having a high school diploma or equivalent (College Board, 2012;Learn.org, 2015). Over 70% of students from each group reported meeting the requirements to attend a 2year college. In contrast, students who failed Algebra I were significantly less likely than those who passed a lower mathematics course to be on track for meeting the requirements of a typical 4-year college by the end of their senior year. The students in this study were the highest performing among those placed in lower mathematics courses and the lowest performing of those placed in Algebra I. These results are consistent with Nomi and Allensworth's (2014) findings of better college readiness for students just below the cut-score for sorting into different courses, as opposed to those just above it. The results of this study are also consistent with the gatekeeper notion that exiting eighth grade without passing Algebra, whether due to a failing grade or nonenrollment in the course, negatively impacts one's chances for meeting the requirements for admission into college (Atanda, 1999;Spielhagan, 2006). The higher college readiness rates for students who passed a lower-level course would seem to provide some support for putting underprepared eighth-graders on a slower path (Liang et al., 2012;Loveless, 2008), except for the fact that in both cases they fell far short in college readiness of both the national average and the students who passed Algebra I. Whereas passing the lower course provides better odds than failing Algebra I, it seems to represent a band-aid solution for a much larger issue-inadequate preparation for the required intellectual demands of algebra during these students' K-7 experiences. It apparently does matter whether algebra is learned in the eighth grade or later. Moreover, to engage in practices or enact policies that delay the acquisition of content that predicts college readiness is to, in effect, build inequality into the educational structure. In urban schools with large populations of African American, Latina/o, and lower SES students, perceptions about ability may lead well-intentioned policymakers to give students the \"gift of time\" by delaying their entry into algebra, but the end result of such a gift may be a life trajectory absent of higher education and all the benefits that accompany it. The results on the psychological and motivational scales do not appear to support the idea of placing some students on a slower track as a long-term solution either. The differences between the groups on these measures all but dissipated by the time they reached eleventh grade, and neither group approached the college readiness rate that students passing Algebra I attained. Given that eighth-grade Algebra I success equates to significantly better odds of college readiness, an approach systematically denying some students access by building slower paths into the educational structure is not supported by our findings, especially when others have found increased access to result in more students passing algebra (Williams et al., 2011). The focus in this study has been placed on the Algebra I students who failed, but we must keep in mind that 95% of the students taking Algebra I reported passing the course, putting them among the group that reported a 4-year college readiness rate of 80%. A limitation that must be acknowledged in this study is the fact that the propensity score matching technique utilized only accounts for the selection bias on variables observed in the HSLS data set, but not for any unobserved variables that may have influenced the outcomes analyzed. In addition, our focus on those students who self-reported failing their courses severely limited our sample size to a fraction of the overall study sample. As a result, the impact of failing algebra observed for this subsample on subsequent measures cannot be generalized to the vast majority of students who were not analyzed in this study. It is plausible, and even likely, that psychological measures for students who passed their courses would be impacted differently had these students experienced failure in the course, especially if course failure is not something they have encountered previously. These limitations notwithstanding, in order for policymakers to respond to critics that point to increased failure rates and the resulting psychological effects as justification for eliminating universal algebra access policies, understanding the possible impacts of these failures is critical. In addition, understanding the effect that placing struggling students in lower mathematics courses can have on college-readiness informs decisions on whether to support universal access for all students. The algebra-for-all policies that have been implemented in recent years appear to have arisen from the hope that providing access to this important course will move our educational system a little closer to Horace Mann's notion of great equalizer for some of our most vulnerable students. Given the results of this study and others, it would appear that the most prudent approach to attaining such a goal is a multifaceted one. A policy that moves students into a higher-level course at eighth grade would likely have a much better chance for success if it were implemented over multiple years, starting with changes in the curriculum prior to eighth grade. Moreover, if policymakers find it imperative to implement such a policy at a given point in the education path (i.e., eighth grade), an indispensable component should be mandated additional support for students who do not handle the shift to higher ground with the same proficiency. In the final analysis, students in this study who were assigned to Algebra I in eighth grade did not fare as well as students taking a lower mathematics course in terms of 4-year college readiness by the eleventh grade, but readiness for 2-year and selective 4-year colleges did not differ significantly. More importantly, neither group fared well in comparison to the national average nor compared to those who passed Algebra I. We submit that the best solution may not be to figure out where it is best to place underprepared students, but rather to address the lack of preparedness in a systematic manner throughout students' elementary and middle school experiences. To do otherwise would be to resign to the position that some students cannot or will not acquire prerequisite knowledge by eighth grade that has been proven to be instrumental to college access."}]