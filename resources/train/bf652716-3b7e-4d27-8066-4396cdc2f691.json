[{"section_title": "Introduction", "text": "The focus of this research is to illustrate how to incorporate weights in the framework of generalizability theory (Brennan, 1992a;Cronbach, Gleser, Nanda, and Rajaratnam, 1972;and Shavelson and Webb, 1991) when it is applied to large-scale studies such as national surveys and educational assessments. Chris W. T. Chiu is a Research Scientist, Psychometrics Group, Law School Admission Council (LSAC), 661 Penn Street, Newtown, PA 18940. Email: cchiu@lsac.org, Ronald S. Fecso is Chief Statistician, National Science Foundation (NSF). This work was partially supported by the American Statistical Association (ASA) through a grant from NSF, Division of Science Resources Statistics (grant number: SRS-0004192). A portion of the research was conducted while Chris Chiu was a professor at the University of Pittsburgh. The authors thank Robert Brennan, Neil Timm, and Loan Tran for their suggestions and comments. Information in this article represents the opinions of the authors and is not NSF, the ASA, the University of Pittsburgh, and the LSAC. This research is important because educational researchers need to determine variance components and reliability coefficients to accurately reflect measurement errors in statewide or nationwide assessment programs, which often test only a sample of students for accountability purposes. Generalizability theory is a well-known method in educational and psychological research, but today, no one has examined the effect of sample survey data on the method. In addition, survey researchers can use such knowledge to understand, monitor, and improve survey quality. If a weighting scheme was used but researchers ignored the weights in generalizability studies (G studies), as is often the case with such a model, the estimated errors will be biased (Rosenbaum, 1987). In addition, the standard error of the variance component estimates will be inappropriate. A very popular model in generalizability theory is the two-facet crossed model, which is frequently used in monitoring measurement errors (e.g., , Brennan, 2000bChiu and Wolfe, 2002;Lane et al., 1996) when human judgments are involved. The model can partition error variances into specific sources so that researchers can determine which error source(s) is/ are most in need for reduction. For example, one can determine the score consistency in high-stake examinations where test-takers respond to a set of test questions scored by a group of raters (i.e., a person x item x rater two-facet model). Alternatively, one can use a two-facet crossed model (i.e., respondent x item x coding method) to determine the coding consistency in survey analysis where survey responses are coded using different schemes (e.g., self-report versus objectively coded responses). Despite the common applications of the generalizability theory in survey studies (Adam and Ujwal, 1999;Johnson and Bell, 1985;Shipper, et al., 1986), we did not find references discussing how one could incorporate weights into G studies -we searched monographs on G theory (Brennan, 1992a;Brennan, 2001b;Chiu, 2001;Cronbach, et. al., 1972;Fyans, 1983;Shavelson and Webb, 1991) and on variance estimations and Wolter, 1985) using the five major modes of searching: footnote chasing, consultation, searches in subject indices, browsing, and citation searchers (White, 1994). Also, we contacted experts in G theory (Brennan, 2001b;Cronbach, 2000) and searched journal articles and electronic databases (PSYINFO, 1887(PSYINFO, -2001ERIC, 1966ERIC, -2001MEDLINE, 1966MEDLINE, -2001JSTOR, 1887JSTOR, -1996Sociological Abstracts, 1963). In the current study, we first reviewed the purposes and importance of survey weights followed by a summary of the traditional variance component estimation procedures. Second, we discussed the concepts and essential steps of a new weighting method in G studies (i.e., the Chiu-Fecso G -method, denoted CFG hereafter). Specifically, we used two examples to illustrate the method. The first example was a hypothetical dataset with a context in educational assessment and the other was an operational dataset from a large-scale survey used for research on science and engineering education. (The Survey of Doctorate Recipients is a longitudinal survey administered by the Division of Science Resources Statistics (SRS) at the National Science Foundation (NSF). Details of the survey can be found in the homepage of SRS: http://www.nsf.gov/sbe/srs). We intentionally used a simple case in the first example to demonstrate the computational procedures of the new method. The example was simple enough for hand calculation. The second example, based on an operational dataset from a national study, was used to show the capacity of the method for a real data set. Given the wide applications of the twofacet crossed model, we focus our discussions on the two-facet model throughout the manuscript."}, {"section_title": "Basic Concepts of G Theory and Weighting", "text": "An extension of the Classical Test Theory (Crocker and Algina, 1986) and the Analysis of Variance (ANOVA) methods, G theory has been applied to examine the reliability and validity of measurement procedures in educational assessments, psychological measurement, program evaluations, and survey analysis. As Shavelson and Webb (1991) stated: \"The strength of G theory is that multiple sources of error in a measurement can be estimated separately in a single analysis. Consequently, in a manner similar to the way the Spearman-Brown 'prophecy formula' is used to forecast reliability as a function of test length in classical test theory, G theory enables the decision maker to d etermine how many occasions, test forms, and administrators are needed to obtain dependable scores. In the process, G theory provides a summary coefficient reflecting the level of dependability, a generalizability coefficient that is analogous to classical test theory's reliability coefficient.\" (p. 2) Brennan (1992aBrennan ( , 1992bBrennan ( , and 2000a and Shavelosn and Webb (1991) provided a succinct treatment of the essential features of G theory. Chiu (1999aChiu ( , 2001) developed a subdividing method to estimate variance components in largescale performance assessments with missing observations. Brennan (2000a) discussed the misconceptions about the theory. Brennan and Johnson (1995) and Cronbach, Linn, Brennan, and Haertel (1997) covered basic concepts in G theory. Brennan (1997) and Shavelson and Webb (1981) summarized the history of the G theory. Despite the popularity of G theory, all of the aforementioned studies assumed that simple random sampling was used. Traditionally, G theory assumes less than or equal to simple random sampling (Bell, 1985;Brennan, 1992a;Cronbach et al., 1972), only that every person has the same probability of being sampled from a population or, that every element is assigned a unit weight. Such an assumption is not viable in national studies where complex sampling procedures (e.g., disproportionate sampling of smaller demographic groups) are used. To create representative estimates in such cases, variable probabilities of selection or variable weights are needed. Another purpose of weighting is to adjust for the effects of non-respondents (Kish, 1995;Lee, Forthofer, and Lorimer, 1989;and Sarndal, 1980). Bailar, Bailey, and Corby (1978) summarized the purposes and compared some adjustment and weighting procedures (e.g., reweighting, substitution, regression) that were actually used at the US Bureau of the Census, for survey data. The National Science Foundation provided a concise summary of using survey weights, for the Survey of Doctorate Recipients (SDR) -a longitudinal panel survey of individuals who have received their doctorates mainly in the sciences or engineering fields (the data of this survey is used as an example in subsequent sections): Sampling weights were defined as the reciprocal of the probability of selection for each sampled units, and the weights were adjusted by using weighting class or poststratification adjustment procedures. The final adjusted sampling weights become the analysis weights [also called Final Survey Weights], which have been added to each individual's record in the survey database. (Author, 2002) Instead of making available multiple weights to researchers, survey developers create a single composite weight also called the final survey weight (e.g., in the Survey of Doctorate Recipients) for analysis. Designed as a proxy for all the weighting factors in the survey, the Final Survey Weights may be the only weighting information available in the survey data. In this paper, we first derived the methodological adjustments to incorporate such a composite weight on G theory estimation. We then applied the methodology in the context of a large-scale survey to examine the impact of the methodological change and substantively the occupational stability in the engineering profession of the United States. The methodology developed here can be used directly in any crossed design with two facets. The three principles of the weighting method discussed in this paper, however, can be used for other designs with any number of facets. However, our intention is to focus on a two facet crossed design, which has a variety of applications in measurement."}, {"section_title": "Methodology Detecting Measurement Errors and Estimating Variance Components", "text": "Many have contributed to the methods in monitoring measurement errors and in estimating variance components. In the survey research context, Biemer and Fecso (1995), Sitter (1997), andReiser, Fecso, andChua (1992) discussed methods to characterize measurement errors. In the statistics and educational assessment context, Brennan (1992a), Chiu (1999aChiu ( , 1999b, Chiu and Wolfe (1997), Corbeil and Searle (1976), Millman andGlass (1967), andSearle, Casella, andMcCulloch (1992) among others, provided indepth discussions on variance component estimation methods. Brennan (1992a) offered an extensive treatment on the topic geared toward generalizability theory. Also, he used synthetic datasets to illustrate the computational steps for variance component estimations. Instead of repeating the details, we summarized the general procedures below and used the summary as building blocks to develop a weighted variance component method based on G theory discussed in the subsequent sections. In G theory, variance component estimates can be obtained by solving a set of Expected Mean Square (EMS) equations (Brennan, 1992a, chapter 2 and 3; appendices A through B) relating the variance components and mean squares. In the sections that follow, we used a fully crossed two-faceted design (Brennan, 1992a) as an example. Unless stated otherwise, the universe of admissible observations contains person (p), item (i), and rater (r). The EMS equations can be expressed in the following matrix formula, where C is an f x f upper-triangular matrix of coefficients for the variance components estimated, and f = 1,2, \u2026, 7 represent the seven variance component estimates in a two faceted design. The column vector 2 a is a set of mean squares for the effects observed in the data (Brennan, 1992a). One can also explicitly write out the elements in C and 2 a as follows. 111 ()00()()01 111 0)0()0()1 ( 111 00()0()()1 1 000)001 (  1  0000 The mean squares vector 2 a , in the above, can be estimated by dividing the set of \"sum of squared means\" by their corresponding degrees of freedom (Brennan, 1992a, p. 36). We represented such computations using Equation (3), whose elements are explicitly shown in Equation (4). (1)(1) 000000  The elements of the D matrix in equations (3) and (4) are the sample sizes (n p , n i , n r ) involved in the seven variance components of the two faceted crossed design. The \"sum of squared mean\" denoted f T is computed for each facet and for the . The rightmost side of equations (3) and (4), t , can be computed by summing individual scores, taking the average, squaring the mean, and multiplying the squared mean by the number of levels in the facet(s) other than the facet for which the sum of squared mean is computed. See equation 5  Conceptual Framework of the Chiu-Fecso G -Method One limitation of the traditional method is that it assumes that every person carries the same weight in an analysis. This assumption is often violated in sample surveys where persons typically receives a different weight as a result of complex sampling and valid response adjustments discussed earlier (See Basic Concepts of G Theory and Weighting). The Chiu-Fecso method enables such a weight (a composite weight supplied to analysts by survey developers and statisticians) to be incorporated in generalizability studies. See Equation (5) for the \"sum of squared mean\" shown in the t vector. Prior to a thorough treatment in computing the weighed sum of squared means, we introduced three fundamental principles used in the Chiu-Fecso G-method."}, {"section_title": "Multiplication Principle", "text": "The summations in Equation (5) simply add up individual scores, assuming that each score occurs once in the data. For example, the total of a set of scores {2, 1, 3, 4} is obtained by 1\u20222 + 1\u20221 + 1\u20223 + 1\u20224 = 10. This approach, assuming that each score received a unit weight, is used in the traditional framework of G theory (Brennan, 1992a(Brennan, , 1992b, discussed in the previous section. The Chiu-Fecso approach relaxed such assumption by allowing each score to have a different weight. This difference is critical when incorporating survey weights for computing the \"sum of squared means\" because the idea of using survey weights is equivalent to replicating an observed value by the number of times specified in the weights. Rosenbaum (1987) called such weighting approach \"direct adjustment.\" He pointed out that direct adjustment has two attractive properties: (a) it does not require explicit modeling of the stratification in the sampling design and (b) it produces parallel adjustments in the original statistical procedures so that only little modifications are needed in adapting the original procedures. Consistent with Rosenbaum (1987), Lee, Forthofer, and Lorimor (1989) advocated the use of weights, which they called the weights \"expansion weights,\" to compute unbiased estimates for means and sums. However, they did not develop a method for variance components. This limitation motivates the current study. To begin, we review the expansion weights. First, assume that the first two scores {2, 1} in the previous example came from a minority group, and each received a composite weight of 49. Further assume that the last two scores came from a majority group and thus received a unit composite weight. The total became 49\u20222 + 49\u20221 + 1\u20223 + 1\u20224 = 154. In the following two sections, we modified the \"expansion weight\" to obtain the adjusted degrees of freedom (using the Adjustment Principle) and the weighted mean (using the Relative Weighting Principle). These two quantities serve as the building blocks for the weighted variance components discussed in the subsequent section (Computational Equation of the Chiu-Fecso Method)."}, {"section_title": "Adjustment Principle", "text": "The goal of inferential statistics is to determine the extent to which we can infer the results from a sample to a target population. A crit ical factor in making correct inferences is to determine the correct degrees of freedom reflecting the sample size. In the previous example, a sample size of 4 was collected and each person received a weight assigned by survey developers, statisticians, or policy makers. As shown earlier, if we were to apply the multiplication principle directly, we would obtain a total of 154 (49\u20222 + 49\u20221 + 1\u20223 + 1\u20224 = 154). However, this approach is problematic because it assumes that a sample of 100 was collected (49+49+1+1). Put differently, this approach erroneously expanded the degrees of freedom. To correct for this problem, we use an adjustment principle so that the weights reflect the actual sample size (n = 4) and also the correct degrees of freedom. Such adjustment is accomplished through dividing each weight in the vector of weight w = [49 49 1 1] by the mean of the weights ( \u03a3w p /n). After the adjustment, the \"adjusted expansion weights\" became w / (\u03a3 w p / n) = [49 49 1 1] / 25 = [1.96 1.96 0.04 0.04]. Note that the total of the adjusted expansion weights matches the sample size (n = 4) and the ratio between the first and third cases remains 49 to 1. In general, the ratios among all the cases remain unchanged."}, {"section_title": "Relative Weighting Principle", "text": "One way to obtain the weighted mean for a set of values is to add up all the weighted scores in a set and then divided the total by the total weight or the number of scores in the set, ( \u03a3wx/\u03a3w). An alternative is to multiply each unique value of a set of scores by its relative frequency and then add up the products (i.e., \u03a3f(x)\u2022x). For instance, the weighted average of the previous example is 0.49\u20222 + 0.49\u20221 + 0.01\u20223 + 0.01\u20224 = 1.54, where 0.49 was obtained by dividing the sampling weight for the first case by the total weight of the four cases (i.e., 49 / 100). Hereafter we referred to f(x) as the relative frequency. With the multiplication principle, the adjustment principle, and the relative weighting principle, we have computed the adjusted total, adjusted degrees of freedom, and adjusted means in the above sections. Next we introduce the CFG method to analytically compute the weighted variance component estimates."}, {"section_title": "Computational Equation of the Chiu-Fecso Method", "text": "An assumption and three steps are involved in our modification of the G theory. We assume that a set of composite weights is given and stored in a row vector w. With this set of weights, we first compute the adjusted expansion weights (using the adjustment principle). Second, we compute the relative weights based on the adjusted expansion weights (using the relative weighting principle). Third, we apply two decision rules to determine when and how to use the two sets of weights obtained in steps 1 and 2. Step 1: Compute Adjusted Expansion Weights In general, a row vector of the adjusted expansion weights (w p ) is obtained by dividing each of the weights in w by the mean of all the weights. That is, Step 2: Compute Relative Weights The relative weights, denoted w f(p) , are obtained by dividing each of the adjusted expansion weights above by the sum of these weights. That is, Since the sum of all the adjusted expansion weight equals to the sample size, an alternative is: Step 3: Apply Decision Rules"}, {"section_title": "Rule #1:", "text": "When finding the weighted sum in a facet of interest, we pre-multiply the adjusted expansion weighting vector ( p w , a row vector) to a set of scores ( s, a column vector), resulting in p w \u2022 s."}, {"section_title": "Rule #2:", "text": "When finding the weighted average score in the facet of interest, we pre-multiply the vector of relative weights to the column vector of scores (i.e., w f(p) \u2022 s). How do we apply the two decision rule s to the theory of generalizability? We replace all p \u2211 in Equation 5with p \u2211 w p when the facet of interest involves the weighting facet (in this case, the Object of Measurement, person); otherwise, we replace p \u2211 in Equation 5with p \u2211 w f(p) . For example, the first entry in t of Equation (5) is the Object of Measurement (p), which is also the weighting facet, so we insert w p to p \u2211 , resulting p \u2211 w p . In the second entry of t of Equation 5, the facet of interest involves item (i) and does not involve the weighting facet (p), so we replace p \u2211 with p \u2211 w f(p). By the same token, we apply the same rule to the remaining entries in t of Equation 5  where w p is the adjusted expansion weight for person p and w f(p) is the relative weight for person p. With the updated \"sum of mean scores\" in Equation (6), we obtained the weighted variance component estimates using the following steps. First, compute the weighted \"sum of mean scores\" vector ( () w t ) as shown in Equation (6). Second, . In summary, we estimate the weighted variance component estimates using: The standard error of the weighted variance components can be obtained by substituting the weighted means squares () w j MS , their coefficients j c , and degrees of freedom j df into Equation 8. Brennan (1992a) and Chiu (1999a) provided an in-depth discussion for the unweighted standard error equations. Chiu (2001, p. 127, Equations 34 through 40) expressed the standard errors in terms of variance components and the number of levels in each facet. Brennan (1992a, p. 101, equation 6.2.1) provided the general form of the equation. We modified the general equation to incorporate the composite weights as follows: One cautious note to Equation 8is the distinction between the subscripts f and j. The former denotes the f th variance component and the latter denotes the j th Mean Square term for the f th variance component. As shown in Equation (2), each variance component estimate involves a different number of Mean Square terms and for this reason, J, the total number of mean square terms varies for each variance component estimate. For simplicity and consistency with the G theory literature, we use a single subscript notation j as opposed to the double subscript notation j f , although they are interchangeable in this context."}, {"section_title": "Results", "text": ""}, {"section_title": "Validation of the Weighted Method", "text": "Being able to incorporate weights in generalizability studies are particularly important when the weights differ greatly among the samples. We used a published data set with 10 hypothetical cases and purposely assigned highly disproportionate weights to the data set (one case received a weight of 10 while the rest received a unit weight). As a result, the ratio of the weighted and unweighted variance component estimates was between 0.3459 and 2.9865, for the seven components, indicating that the weighted estimates could be almost three times larger or three times lower than the unweighted estimates (See Appendix B). Such a result reminds researchers that weighted estimates could be different from their unweighted counterparts when extreme values appear in the weights. The extent to which the two types of estimates would become drastically different depends on the weighting scheme provided in the survey. We purposely chose an extreme example to contrast the weighted and unweighted results. Such an example is realistic because when applying a two-facet model where test items or tasks are involved, researchers may desire to explore the effect of assigning a much larger weight to one important item -a 300 word essay requiring 45 minutes of testing time may be weighted as much as 10 times more than a multiple -choice question requiring lower than two minutes of testing time. The aforementioned example (discussed fully in Appendix B) also served as a benchmark comparison between the Chiu-Fecso method and the traditional unweighted method (Brennan, 1992a). Appendix B shows that the unweighted method was a special case of the weighted method because when the weights were set to unity, the CFG method yielded identical varia nce component estimates to the traditional method."}, {"section_title": "Example 1: Performance Assessment", "text": "Performance assessment has been popular in the recent decades (Bejar and Braun, 1999;Bennett and Sebrechts, 1996;Braun, Bennett, Frye, and Soloway, 1990;Brennan, 2000b;Chiu, 2001;Clauser, 2000). Many educational and professional testing programs employ constructedresponse items to assess performance (e.g. the National Assessment of Educational Progress, the Texas Assessments of Academic Skills, and the United States Medical Licensing Examination). Generalizability analysis is one of the popular techniques to examine the quality of test scores and it can provide guidance regarding the potential to reduce measurement error (Brennan, 2000b;Clauser, 2000). Of the many models in G theory, the two-facet crossed model (Brennan, 2000;Chiu, 2001) is frequently used. Utilizing a two-faceted model, the following hypothetical data set (3 items x 2 raters) demonstrates the computational procedures of the Chiu-Fecso method. As shown in the data matrix X, each of the four persons has six scores arranged in a row. Columns one through three represent the scores on the three items judged by the first rater; Columns four through six represent the scores on the same three items judged by the second rater. The gap between the third and forth columns is intended to visually separate the scores for the two raters. Assume that a final survey weight is derived by survey developers and it is the only weighting information available in the data given to the analyst. Further assume that the weights for the four persons are stored in a row vector [2 3 4 1] which is given to the analyst. We then obtained the adjusted expansion weights and relative weights as follows. w p = [0.8 1.2 1.6 0.4] = [2 3 4 1] / ( (2 + 3 + 4 +1) / 4 ) and w f(p) = [0.2 0.3 0.4 0.1] = [0.8 1.2 1.6 0.4] / ((0.8 + 1.2 + 1.6 + 0.4) ). With the w p and w f(p) computed, we used Equation (6) to obtain () w t as shown below (see Appendix A for the step-by-step illustrations).  By using n p = 4, n j = 3, and n r = 2, and equation 4, we post-multiplied () w t to D . The product became the weighted mean square vector "}, {"section_title": "000000", "text": "(3) 3000000 2)(2000000 1)(1(  12. Note that negative variance component estimates occurred in the hypothetical example because we used a randomly generated hypothetical data set, which had only a small sample (n p = 4). Also, for simplicity, no distribution assumptions were specified in generating the data. In practice, one may not obtain negative estimates. Cronbach et. al. (1972) and Brennan (1992a) discussed the causes of negative variance components and developed methods to avoid negative variance component estimates. Those methods include Algorithm 2 (Brennan, 1992a) and Bayesian procedures (see Box and Tiao, 1973;Searle, et al., 1992   Respondents were given a list of 126 job codes and were asked to choose the most appropriate title for their principal jobs (i.e., selfreported job codes). In addition, the respondents also reported their employment history and background information (e.g., sector of employment, work activities, number of people supervised directly). Such information was used to derive a second measure of occupational title, which was called the \"best codes\" of occupational titles. The best codes were derived using employment history, job activities, and such. Comprehensive discussions of the best coding process can be found in Hardy and Eisenhower (1994), McGuinness (1997), Rak, Chen, and Gray (1997). Due to complex sampling and adjustment of nonresponse rate, respondents were selected with a different probability and thus a weighting scheme was used to ensure the representativeness of the sample. The average weight for Engineers was 21.29 (SD = 9.71; median = 22.98; minimum = 1.05; maximum = 46.72). We conducted a generalizability study with a crossed design (G study, Brennan, 1992a;1992b) to measure occupational changes. Specifically, we employed the p x y x m design (person x year x method) in which all survey respondents (p) provided their occupational title in all four survey years (y). Whether or not one was classified as an Engineer was determined by two methods ( m), namely the best and self coded methods. The universe of admissible observations (UAO, Brennan, 1992a), therefore, contains 50,832 doctorate recipients who were ever employed in the Engineering profession between 1993 and 1999. For any particular survey year, an Engineer received a value 1 if s/he was employed in Engineering and a 0 otherwise. The generalizability analysis allowed one to determine the extent to which (1) the professionals were employed the same number of years in Engineering; (2) the Engineering occupation employed a similar number of Ph.D.s across the survey years; (3) survey respondents reported their occupations as consistently a s the objectively derived occupation; and (4) the interactions of these three factors. Similar to Example 1, we estimated seven variance components (p, y, m, py, pm, ym, pym,e). Table 1 shows the estimates for the seven variance components and their corresponding standard errors. Both the weighted and unweighted methods yielded very similar results in the point estimate and the standard error of the variance components. For example, the ratio between the unweighted and weighted standard errors of the person effects was close to one because 0.00299 / 0.00296 = 1.0102 (i.e.,  Note: \"Ratio\" is the ratio of the unweighted estimates to the weighted estimates. The ratios were computed before the estimates were rounded to four decimal places. Table 2 shows the percent contribution for each of the variance component estimates. The largest component was 2 py \u03c3 (0.098), which contributed to approximately 44.6% of the total variance in measuring occupationa l changes. Such results suggested that one can differentiate those who worked in the Engineering occupations for the same number of year by their job-switching patterns, where a job-switching pattern is characterized by the survey years in which a Ph.D. was employed in the Engineering profession as well as the years the doctorate was employed in other non-Engineering occupations (we summarize job switching patterns below and Chiu and Fecso, under review, offer an in-depth discussion). For example, two Ph.Ds. can be considered to have a different job-switching pattern even though they were both employed in an Engineering occupation for only one of the four survey yearshypothetically speaking, person A could work in an Engineering profession in 1993 but in a nonengineering profession in the subsequent years (the occupation pattern for person A would be [0 0 0 1], where the first, second, third, and fourth entries are binary variables for an Engineering employment in 1999Engineering employment in , 1997Engineering employment in , 1995Engineering employment in , and 1993; person B could work in an nonengineering profession prior to becoming an Engineer in 1999 (person B would have an occupation pattern [1 0 0 0]). Indeed, among the 487 doctorate recipients employed in Engineering for only one of the four survey years, 212 were employed in an Engineering occupation in only 1993; 90 were in only 1995; 61 were in only 1997; and 124 were in only 1999. The aforementioned differential job-switching pattern explained the relatively large 2 py \u03c3 . \u03c3 , which indicated that, on average across all survey years and measurement methods, some Engineers had been employed in the profession for a longer duration than the others and the difference in duration accounted for approximately one third (30%) of the total job change variation. Comparing the number of professionals employed in Engineering in different years can shed light in the stability of the occupation -having a similar number of Engineers across different years can provide some evidence of stability whereas having a drastically different number of Engineers can provide some evidence of instability. The result that 2 y \u03c3 accounted for only 0.1% of variation of the total job change suggested that the profession employed a similar number of Engineers in the survey years. \u03c3 as an interaction between the variations due to person and method. It showed that the two occupational-determining methods were slightly more consistent for some survey respondents than the others but such differential consistency was rela tively small comparing to the other sources of variation. The person-by-year-by-method with any systematic and unsystematic variability 2 , pyme \u03c3 accounted for 21.7% of the total variation, suggesting that about one fifth of the job change variability in Engineering was due to: (a) the observation that Engineers changed jobs differentially in different survey years and the extent to which such a differential change occurred depends on which method was used to measure occupational titles; (b) any systematic variability such as the possibility that Engineers in some geographical regions were more mobile; and/ or (c) any unsystematic variability that was not measured."}, {"section_title": "Conclusion", "text": "The goal of incorporating sampling or survey weights into the framework of generalizability is to ensure that variance component are correctly estimated. The Chiu-Fecso method is designed for this purpose. In practice, the CFG method can be applied to educational assessment, psychological measurement, professional testing, and survey research where generalizability studies are called for to examine desirable variations and undesirable variations (measurement errors). Regardless of its dependence on sampling, the traditional G Theory framework assumes that simple random sampling is used. Indeed, national surveys and large-scale assessment programs use a variety of disproportional sampling techniques to ensure sample representations and account for nonresponses. To this end a composite weight (final survey weight) is provided to analysts. Given that the composite weight is frequently the only weighting information available to analysts, the current study extended the capacity of the G theory so that it can allow weights to be used. In this article, we first introduced three principles in deriving the weighting method by showing how to estimate means and sums correctly. We then used the same principles to illustrate how to estimate variance components. Rules and step-by-step procedures were discussed. We validated the method using a published data set. The validation study suggested that weighted and unweighted variance component estimates can differ drastically if some cases receive a weight differ drastically from the others. Also, we showed that the traditional generalizability analysis is a special case of the weighted generalizability analysis. Two examples were provided to illustrate the applications of the weighting method in performance assessment and survey analysis. The weighted and unweighted variance component estimates of a large-scale operational data set yielded very similar conclusions. Although the object of measurement, person, was the weighting facet in the two examples, this is not necessary to be the case. In practice, the weighting facet can be any facet in a crossed-two-faceted design (the main effect facets or the interaction effect facets). For instance, in standardized psychological or educational testing programs, researchers may desire to designate the item facet to be the weighting facet. This can be useful in examining the reliability of test scores when examinees do not respond to all items within the standard time. In the event that speededness happens, researchers can assign a lower weight to \"not reached\" items (those presented in the end of the test) than items presented in the beginning. Reese (1999) found that the true ability of low performing examinees is overestimated and that of high performing examinees is underestimated, when items are \"locally dependent\" or not reached by examinees (e.g., due to fatigue). The CFG method discussed in the current paper can be used to assign lower weights to not reached or locally dependent items. Future research can further investigate the extent to which different weights will change the reliability of test scores. Due to the page limits, it is not our intention to examine this topic in the current study. Sometimes researchers are interested in assigning weights to multiple facets. For example, in educational assessment, one might be interested in oversampling minority students from the target population (i.e., weighting is used to adjust for the design effect). The weights to oversample minority students can be incorporated into a G study by assigning them to the facet related to persons (i.e., the object of measurement, Brennan, 1992a). In addition to assigning weights to the object of measurement, one can also weight the person-by-item facet. This can allow items to be weighted differently for individual students. Such an adaptive weighting mechanism can enable psychometricians to take into consideration the \"opportunity to learn\" when deciding the importance of an item on the test score. For example, one might assign a lower weight to an item when it is responded by a student whose school does not emphasize the learning objective of the item than when it is responded by another student who came from a school with a strong emphasis on the same item. Similarly, in survey analysis, statisticians may desire to assign one set of weights to the sample of respondents and a completely different set of weights to the measurement methods. By doing so, survey statisticians could put a stronger emphasis on one measurement method (e.g., objective method) than the other (e.g., selfreported method) in evaluating quality of survey data. The aforementioned goal can be accomplished by developing a method to incorporate weighting schemes into multiple facets of a generalizability study (e.g., person and person-by-item). Future pursuit in developing a multifacet weighting scheme can apply the three principles discussed in the current study. power. Using the new operator, the aforementioned cumbersome notation can be simplified as follows. f (p) xx1 e 2 . In summary, X e 2 = Xe X. -In each of the following equations, the first line shows the summation notation of the sums of squared means and the second line shows the matrix notation of the same quantity.  Variance Component Estimates p 0.1667 0.055 0.0658 0.0753 0.0732 0.0661 0.0677 0.0561 0.0398 y 0 0.001 0.0002 0 0 0 0 0.0157 0.0203 m 0 0.0003 0.0003 0.0007 0.0008 0.0013 0.0015 0.0002 0.0002 py 0.0833 0.0848 0.0805 0.0943 0.0865 0.0973 0.0972 0.1314 0.1528 pm 0 0.0022 0.0029 0.0029 0.0064 0.0076 0.0067 0.001 0.0056 ym 0 0.0002 0.0001 0.0006 0.0011 0.0013 0.0015 0.001 0.0025 pym,e 0 0.0332 0.044 0.0509 0.0525 0.0523 0.0475 0.0425 0.0348 p: person, y: year, m: method; py = person by year; pm: person by method, ym: year by method, pym,e: person by year by method and other errors. "}]