[{"section_title": "Abstract", "text": "Abstract The prevalence of Alzheimer's disease (AD) and other forms of dementia is increasing with the aging population, both in the United States and around the globe. The inability to cure these conditions results in prolonged and expensive medical care. Early detection is critical to potentially postpone symptoms and to prepare both healthcare providers and families for patients' future needs. Current detection methods are typically costly or unreliable, and much stands to benefit from improved recognition of early AD markers. Electronic patient records provide the potential for computational analysis and prediction of complex diseases like AD. Prior work on this problem has focused mainly on structured data (e.g. test results), whereas this study aims to integrate structured and unstructured (e.g. clinical notes) data, obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI)*, for classification of subjects' dementia status. Prediction based on unstructured data alone performs with accuracy similar to that of prediction based on structured data that exclude cognitive markers. Integration of the structured and unstructured models provides performance improvements over either in isolation. Additionally, we provide insights into which structured features were more useful for classification of AD, supporting previously observed trends, while also highlighting the potential for computational methods to discover new clinical markers."}, {"section_title": "Introduction", "text": "Dementia is an increasing problem for the US and global aging population. Approximately 35 million people worldwide suffer from some form of dementia, and this number is expected to double by the year 2030 [13] . It is the 6th leading cause of death in the US [1] . Alzheimer's disease in particular has no cure, and treatments are limited, making management of symptoms the main focus of clinical care. Accordingly, there is a high cost associated with dementia care, expected to total 214 billion dollars in the US for the year 2014 [1] . Early detection is critical for potential management of symptoms, and for allowing families to adjust and adequately plan for the future. Despite this importance, current detection methods are costly, invasive, or unreliable. Consequently, most patients are not diagnosed until their symptoms have already progressed. Improved understanding and recognition of early warning signs of dementia would greatly benefit the detection and management of the disease, as well as facilitate appropriate allocation of resources for healthcare organizations' provision of care.\nWith the advent of electronic health records (EHRs) comes the potential for large-scale computational analysis of patients' clinical data to understand or discover warning signs of the progression of medical conditions. In this context, the data can be considered either structured or unstructured. Examples of structured data include patient demographics, such as age, sex, or ethnic background, as well as test results collected during their visits, such as brain volume measurements or routine blood tests. When a patient presents readily observable symptoms of dementia, there is a battery of biological and cognitive tests that can be applied to confirm the diagnosis. However, it would be useful to identify early warning signs that can point towards future dementia development. Intelligent decision-support models that could detect such cases would be very helpful for healthcare providers. Moreover, while certain clinical tests are used in daily operations for dementia diagnosis, other early biophysical or behavioral markers may be undiscovered. Here we explore a range of features in a machine learning context to identify useful features for classifying a patient's dementia status.\nWe are also are interested in understanding the roles of different types of medical data in a prediction process, especially since prior work has focused primarily on structured information. Accordingly, we explore what potential role unstructured data can play in data mining for dementia prediction. Unstructured data refers to text entries, such as patient histories, impressions, visit summaries, discharge summaries, or other broader or narrower categories.\nWritten clinical text presents a potentially rich source of information that embeds useful clinical knowledge from the professionals who wrote them. Insights mined from natural language data may be quite straightforwardly interpretable by humans, and written texts may provide opportunities to capture distinct types of information (e.g. as related to behavioral wellness or social lifestyle patterns), compared to structured entries. Additionally, some form of text is present in nearly all patient records, whereas many of the relevant structured data may be absent if the patient has not already been identified as being at-risk for a given condition. Thus, we examine ways in which unstructured data may supplement a diagnostic model based on structured data. Specifically, we integrate models based on each data type to improve performance over either in isolation.\nA computational model based on either or both these data types could be used in an automated screening system to identify and flag potentially problematic patients for further assessment by clinicians, making operations more efficient. Additionally, identification of useful features from classification experiments may improve understanding of important markers in early dementia and Alzheimer's disease detection."}, {"section_title": "Related Work", "text": "The potential of electronic medical records for data mining has been recognized for some time. Importantly, deducing data-driven patterns based on structured data has been the basic approach in the prediction of dementia. Biomarkers from cerebrospinal fluid (CSF), as well as brain volume measurements from magnetic resonance imaging (MRI) and positron emission tomography (PET), have been useful in predicting conversion from mild cognitive impairment (MCI) to Alzheimer's disease (AD) within the ADNI dataset [15] . Cognitive tests may be useful to this end as well, in the absence of other biophysical tests [7] or in combination with them [4] . However, such tests are not typically applied until after symptoms of MCI or dementia have already been observed.\nAlthough the use of structured data has been successful in dementia and AD prediction, unstructured text data may provide additional benefits for modeling purposes. Natural language processing (NLP) and statistical text mining (STM) techniques that have been applied to medical texts in the past have focused on extracting known disease markers, obtained from medical knowledge sources, for machine learning purposes. Examples include mapping terms to a medical ontology to predict post-operative complications [10] , and using tools like MedLEE or SymText to extract and codify terms for identifying cases of colorectal cancer [17] , suspicious mammogram findings [9] , adverse events related to central venous catheters [12] , and bacterial pneumonia from chest X-rays [5] . For the scope of this paper, we examine the utility of bag-of-words modeling for capturing important linguistic units in unstructured text data, with an eye towards integrating more sophisticated topic modeling in future work."}, {"section_title": "Dataset", "text": ""}, {"section_title": "Subjects", "text": "The dataset used here was obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). The ADNI was launched in 2003 by the National Institute on Aging (NIA), the National Institute of Biomedical Imaging and Bioengineering (NIBIB), the Food and Drug Administration (FDA), private pharmaceutical companies and non-profit organizations, as a $60 million, 5-year public-private partnership. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimer's disease (AD). Determination of sensitive and specific markers of very early AD progression is intended to aid researchers and clinicians to develop new treatments and monitor their effectiveness, as well as lessen the time and cost of clinical trials. The methods used in this paper represent a secondary use of the data for a purpose that is in line with general goal of identifying dementia markers.\nThe Principal Investigator of this initiative is Michael W. Weiner, MD, VA Medical Center and University of California San Francisco. ADNI is the result of efforts of many co-investigators from a broad range of academic institutions and private corporations, and subjects have been recruited from over 50 sites across the U.S. and Canada. The initial goal of ADNI was to recruit 800 subjects but ADNI has been followed by ADNI-GO and ADNI-2. To date these three protocols have recruited over 1500 adults, ages 55 to 90, to participate in the research, consisting of cognitively normal older individuals, people with early or late MCI, and people with early AD. The follow up duration of each group is specified in the protocols for ADNI-1, ADNI-2 and ADNI-GO. Subjects originally recruited for ADNI-1 and ADNI-GO had the option to be followed in ADNI-2. For up-to-date information, see www.adni-info.org."}, {"section_title": "Dataset Preparation and Processing", "text": "Data from the ADNI are split across multiple files, each containing different related clinical and biomarker data. The structured data used here are obtained from a subset of the available files in the adnimerge package, listed and described in the top of Table 1 . Each of the over 11,000 entries contained in these files represents one visit for one subject, with many subjects having multiple visits. Entries are aggregated by subject ID such that all data fields for a given subject are contained in one vector, resulting in a collection of 1,736 subject vectors, each containing 22 structured data fields. Each data field of a given subject's vector is equal to the mean of the available values for that field over all of that subject's visits. While none of these files contain any unstructured data, a number of other ADNI data files do contain an optional field for text notes. The list of subject IDs is used to extract text notes from four other files (see bottom of Table 1 ), which were selected both because they contained substantial amounts of text entries and because their content seemed potentially useful for this study. The notes from all visits for a given subject are concatenated and treated as one document for that subject.\nMild cognitive impairment (MCI) is a diagnostic category regarded as a precursor to Alzheimer's disease (AD). Over the course of the ADNI data collection phases, three different fine-grained levels of MCI have been used: early MCI (EMCI), MCI, and late MCI (LMCI). All three are combined here into one class label, MCI, to mitigate data sparseness and class imbalance issues. Additionally, another encoding category used in the ADNI dataset is significant memory complaint (SMC). As SMC is generally thought distinct from MCI and AD, it is grouped with cognitively normal subjects under the class label NL. The group of Alzheimer's subjects are left as-is, with the class label AD. Each subject is assigned a class label from this 3-class scheme based on their most recent diagnostic state, as some had changed over the course of the ADNI collection period. As seen in Figure 1 , this labeling scheme results in a 50% majority for MCI, which we consider as a baseline for comparison."}, {"section_title": "Handling Missing Values", "text": "In general, visit entries in the ADNI dataset contain many missing values for data fields, since not all tests are administered during every visit.\nThese missing values present a problem for the classification experiments we wish to perform. Before subject aggregation, a total of 3,329 visit entries have missing values for all tests; we exclude these in our dataset. Figure 2 shows a histogram of the fraction of the 22 structured data fields that are missing for the remaining 8,036 visit entries (across the 1,736 subjects). As expected, most visits are missing most available tests. To deal with this, missing values are replaced by imputation using Amelia II [8] , a package in the R programming language.\nThe missing values are obtained by calculating log likelihood and using the EMB algorithm which combines the EM algorithm with bootstrapping on a subset of observed values. Amelia II performs multiple imputations, which reduces bias and increases efficiency of the missing data. A set of five different imputed datasets is generated, the mean of which is used to create one dataset without missing values. As for the unstructured data, only one of the subjects has an empty text field, which is replaced with a special empty token."}, {"section_title": "Text Processing and Normalization", "text": "Text pre-processing includes lowercasing, punctuation removal, and stop-listing of frequent tokens, such as grammatical function words (e.g. the). Text normalization procedures are also performed to deal with variation in linguistic and orthographical representations of numbers, dates, ages, abbreviations, and multiword expressions. In particular, dates and ages are represented in many different forms, Number of subjects which are dealt with by matching and tagging with a uniform replacement string. For example, the strings 70-year old, 70 yo, 70 years-old, and 70 y/o, etc. would all be replaced with the tag AGE 70. This helps with the problem of different representations of the same semantic unit not being recognized in the model, and can also allow for generalizations such as AGE senior to be explored. The techniques applied here appear to cover the vast majority of ambiguities and variations present in the data. Additionally, the most frequent lexical content bigrams and trigrams (i.e. after stop-listing) in the dataset are extracted and treated as multiword expressions (MWEs) to be replaced as unigrams in the texts by concatenating the words with underscores (e.g. blood pressure becomes blood pressure, gall bladder becomes gall bladder, etc.). Potential errors in this list are removed manually. This latter text preprocessing step is done because of the expected high number of MWEs in the medical domain, and to help disambiguate meaning and aid interpretation of useful text features. Finally, the file BLCHANGE (changes since baseline visit) contained a few common phrases regarding subjects' diagnostic status (e.g. remains mci, normal control ), which are removed to prevent trivial identification of class labels."}, {"section_title": "Predictive Modeling Approach", "text": "We report on classification models trained on features of the structured and unstructured data in isolation, and additionally provide a technique for integrating the two models. In all cases, the goal is to predict a subject's diagnostic state, according to the label assigned in Section 3.2, using features of their structured or unstructured data. All experiments utilize 10-fold cross-validation of a logistic regression classifier (with L1 penalty), implemented in Python using the scikit-learn machine learning library [11] . This implementation of logistic regression uses a one-vs-all approach to handle this multi-class problem."}, {"section_title": "Structured Features", "text": "The structured data fields for each subject already contain numerical values that can be used as features without further processing. In addition to the whole collection of structured data features, we also experiment with a subset which excludes all three cognitive tests: Alzheimer's Disease Assessment Scale (ADAS), Clinical Dementia Rating (CDR) memory score, and the Mini Mental State Exam (MMSE). The reason for this is that while cognitive tests are powerful tools for diagnosing dementia and Alzheimer's disease, they are typically only administered in response to readily observable dementia symptoms, rather than being used for early screening. It is thus interesting to examine their impact on classification, which is accomplished by performing additional experimentation that excludes them from consideration."}, {"section_title": "Unstructured Features", "text": "A standard bag-of-words model is constructed on the unstructured dataset and the word tokens are used as features for classification. As described earlier in Section 3.2.2, frequent content word bigrams and trigrams were treated as individual tokens in the texts to preserve meaning of common multiword expressions, therefore this is not just a plain unigram model. The features are treated as boolean values indicating the presence or absence of the token in the texts for each subject."}, {"section_title": "Integration of Models", "text": "We also investigate classification performance when integrating the structured and unstructured models. For each subject, a logistic regression model will compute posterior probabilities for each of the three class labels (diagnostic states) and select the most likely candidate. If we assume that the posterior probabilities from each of two models are independent, then Equation 1, below, can be leveraged to make a final decision in an integrated model.\nHere, X s and X u represent the input feature vectors for the structured and unstructured models, respectively, and C k represents a class label (with p(C k ) being the prior probability of the class within the dataset). The class label with the highest probability is selected as the output. As with the structured modeling experiments, we train two integrated models: one including cognitive features and one excluding them."}, {"section_title": "Results and Discussion", "text": "Performance metrics for each experiment are shown in Table 2 , averaged over all folds. As shown earlier in Figure 1 , the majority class baseline is 50%, represented by the MCI class. All models clearly perform well above this baseline. As expected, the inclusion of the features obtained from cognitive tests markedly improves classification performance for the structured modeling. Importantly, the unstructured model slightly outperforms the structured model without cognitive features. In many cases, such features may not be available and thus relying on their inclusion could cause brittleness when translating models into clinical practice. As expected, the probabilistic integration of structured and unstructured models produces additional performance gains over either in isolation. As before, the inclusion of the cognitive markers results in greater performance in integration.\nIn general, the AD class achieved lower precision and recall, possibly due to the small class size. One potential source of confusion may be the decision to combine the three more fine-grained subcategories (EMCI, MCI, and LMCI) into one coarser-grained class label. Thus, it is possible that EMCI and LMCI, which represent the respective peripheries of the MCI continuum, could tend to be confused with NL and AD, respectively; this will be examined in future work. "}, {"section_title": "Structured Feature Analysis", "text": "Logistic regression is a linear classification algorithm whose decision function consists of coefficients on each feature input, and whose output corresponds to a class. The magnitude of a coefficient corresponds to how much influence its feature has on the overall decision, and the sign indicates which class a higher value of the feature favors. In this section we inspect these coefficients to gain insights into which features are more influential in deciding a subject's diagnostic state. We are dealing with a multi-class problem: AD vs. MCI vs. NL, but given our primary interest in understanding indicators of Alzheimer's disease (AD), we focus on the features and coefficients of the AD class alone. 1 . The L1 norm penalty imposed in the algorithm aids in feature analysis by forcing many coefficients to zero, indicating that the corresponding features are not used in the decision. Structured features whose coefficients were significantly different than zero (p < 0.05) are shown in Table 3 in descending order of significance. As expected, all three of the cognitive markers -Clinical Dementia Rating memory score (CDMemory), Mini Mental State Exam (MMSE), and Alzheimer's Disease Assessment Scale (ADAS13) -played a significant role in discriminating between subjects who had or did not have Alzheimer's disease (AD). The Tau biomarker was also significant, verifying results in the literature [16] . As discussed earlier, it would be beneficial to accurately identify at-risk patients who are in need of receiving cognitive tests. Therefore we perform the same feature analysis again, excluding the cognitive markers (see Table 4 ), which resulted in an interesting list of other useful structured features. Again, Tau is among the most significant, along with it's counterpart PTau (phospho-tau), which has been linked to neurodegenerative diseases like AD [6] ."}, {"section_title": "Conclusions", "text": "In this paper we aimed to explore both structured and unstructured data of subject records collected as part of the Alzheimer's Disease Neuroimaging Initiative (ADNI), using machine learning approaches. We experimented with each data type to classify a condensed version of subjects' diagnoses as either cognitively normal (NL), mild cognitive impairment (MCI ), or Alzheimer's disease (AD). A system like this would be useful for intelligent early screening to identify subjects who may need more attention for dementia testing. The accuracy of our models were well above the majority class baseline held by the MCI subjects, with mostly comparable results for precision and recall. Arguably, high recall (e.g. in the case of AD, the fraction of subjects with AD who were correctly classified as such) is of more importance due to the higher cost of type II errors in this diagnostic context; future work may involve optimizing the modeling for achieving higher recall. Integrated models based on probabilistic output of the structured and unstructured models improved classification performance over either in isolation. This is important due to the fact that many of the tests from the structured data will not be present for patients until their dementia symptoms have progressed, but nearly everyone will have text notes in their medical record. These texts may also allow us to capture or discover other forms of markers (e.g. as related to a patient's behavioral health or social-psychological experiences). In addition to the integration, analyzing the structured features that played a greater role in classification revealed useful features that had been identified in the past, as well as highlighted the potential of new discovery through computational methods.\nUltimately, we hope to use topic modeling [3] to infer more complex linguistic relationships in the unstructured data. Initial topic modeling experiments on the ADNI texts did not produce viable results. We relate this in part due to the heterogeneity of language usage enforced by the specific goals and screening processes of this dataset's collection experiments. In the future, we plan to explore general electronic health records (EHRs) with the expectation that the full scope of typical medical visits will prove more fruitful for topic modeling.\nAdditionally, we would like to explore a more sophisticated way of combining the structured and unstructured models to improve predictive power. It is possible that one may be more suited than the other under particular circumstances, and a model that more effectively combines both could be useful. To achieve this, we will explore both the boosting technique [2] , which combines multiple base classifiers to achieve better overall prediction accuracy, as well as a recent mathematical optimization algorithm that evaluates and ranks multiple alternatives in a group decision-making process [14] ."}]