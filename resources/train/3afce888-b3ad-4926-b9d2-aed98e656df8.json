[{"section_title": "Abstract", "text": "Abstract-Machine learning methods have successfully been used to predict the conversion of mild cognitive impairment (MCI) to Alzheimer's disease (AD), by classifying MCI converters (MCI-C) from MCI nonconverters (MCI-NC). However, most existing methods construct classifiers using data from one particular target domain (e.g., MCI), and ignore data in other related domains (e.g., AD and normal control (NC)) that may provide valuable information to improve MCI conversion prediction performance. To address is limitation, we develop a novel domain transfer learning method for MCI conversion prediction, which can use data from both the target domain (i.e., MCI) and auxiliary domains (i.e., AD and NC). Specifically, the proposed method consists of three key components: 1) a domain transfer feature selection component that selects the most informative feature-subset from both target domain and auxiliary domains from different imaging modalities; 2) a domain transfer sample selection component that selects the most informative sample-subset from the same target and auxiliary do-"}, {"section_title": "I. INTRODUCTION", "text": "A LZHEIMER'S disease (AD) is characterized by the progressive impairment of neurons and their connections, which results in loss of cognitive functions. In 2007, a report published by Ron et al. indicated that there were 26.6 million AD sufferers worldwide, and forecasted that 1 in 85 people will be affected by 2050 [1] . As the prodromal stage of AD, mild cognitive impairment (MCI) can be further categorized into MCI converters (MCI-C) and MCI nonconverters (MCI-NC). Specifically, MCI-C patients will likely progress to AD, while MCI-NC patients will not convert to AD. Existing research has suggested that the individuals with amnestic MCI tend to progress to the probable AD at a rate of approximately 10% to 15% per year [1] . Thus, the accurate diagnosis of AD, especially in the early stage (i.e., MCI), is very important for timely therapy, disease modifying drug development, and possible delay of the disease. Nowadays, many machine learning methods have been proposed to recognize AD patients [2] - [10] . Recently, an increasing number of studies on AD research begin to address classification of MCI conversion (MCI-C) and MCI nonconversion (MCI-NC) patients based on the high-resolution brain imaging data [4] , [7] , [11] - [24] .\nOne challenge for MCI-C prediction is that the number of MCI-C and MCI-NC subjects available for training is generally very small, while the dimensionality of data is often very high, which makes it very challenging to train an accurate classifier. Thus, many advanced machine learning methods have been proposed to address this issue [2] , [3] , [7] , [11] , [22] , [23] , [49] - [51] , [57] . For instance, in [3] , a multitask learning method achieved an accuracy of 73.9% on 43 MCI-C and 48 MCI-NC patients using multimodality data such as MRI, fluorodeoxyglucose positron emission tomography (FDG-PET), and cerebrospinal fluid (CSF). In [7] , a manifold harmonic transform method using cortical thickness data achieved a sensitivity of 63% and specificity of 76% on 72 MCI-C and 131 MCI-NC patients, and in [11] , a morphological factor method using MRI data achieved an accuracy of 72.3% on 20 MCI-C and 29 MCI-NC patients. In [22] , an orthogonal partial least square to latent structures was used to diagnosis of MCI-C and achieved prediction accuracy of 75.4% and 68% for those MCI subjects converting to AD by 24 and 36 months, respectively. This performance was reported on 162 MCI Alzheimer's disease neuroimaging initiative (ADNI) patients. In [23] , a Gaussian process approach that combined several multimodality data sources (i.e., MRI, PET, CSF, and APOE genotype) was used for classification and achieved an accuracy of 74.1% on classification between 47 MCI-C and 96 MCI-NC patients. In all these referenced studies, the size of dataset is small and also only one domain (i.e., MCI-C and MCI-NC) of subjects is used for training the classification models.\nIt is worth noting that MCI cohorts are heterogeneous, consisting of MCI-C (that will convert to AD) and MCI-NC (that will remain stable). Because of the characteristic of MCI cohorts, several studies proposed a hypothesis that the MCI-NC subjects are more healthy-like, while the MCI-C subjects are more AD-like, which is consistent with the contention that discrete disease states are an approximation to a continuous disease spectrum [23] , [40] , [56] . In the literature, several studies have treated AD as MCI-C, and NC as MCI-NC, and then used AD and NC subjects to train a support vector machine (SVM) for MCI-C prediction [23] - [25] . It demonstrates that the task of classifying MCI-C and MCI-NC subjects is related to the task of classifying AD and NC subjects. On the other hand, in machine learning community, transfer learning has been developed to better deal with the problem involving multiple domains (including target domain and auxiliary domain) of data [26] - [28] , where it does not assume that the auxiliary data have exactly the same distribution as the target data. Recently, in our preliminary work [29] , transfer learning has been introduced into medical imaging analysis. Specifically, in [29] a domain transfer support vector machine (DTSVM) was used to classify MCI-C and MCI-NC patients (i.e., target data) with the help of AD and NC patients as the auxiliary data, showing a great performance improvement. However, in [29] , it did not use a feature selection step to identify the most discriminative features from imaging data. Also, in [29] , all the patients in the auxiliary domain were used for training, without a step to select the most informative samples in the auxiliary domain (i.e., AD/NC subjects) for further improving the classification performance between MCI-C and MCI-NC patients.\nTo address the aforementioned limitations, we propose a novel domain transfer learning framework for MCI-C prediction. Specifically, we first develop a domain transfer feature selection (DTFS) method by using both the auxiliary (AD/NC) and target (MCI-C/MCI-NC) domains to select a subset of discriminative features, common to both domains. Then, using the instance-transfer approach, a cross-domain kernel is constructed for transferring the auxiliary domain knowledge. To improve the quality of the source data in the cross-domain kernels, a domain transfer sample selection (DTSS) method is further developed using the multitask least absolute shrinkage selection operator (Lasso) kernel-based method to select the most informative sample subset. Finally, all selected samples are classified by a DTSVM using adaptive SVMs and multikernel learning. The proposed method is evaluated using MRI, FDG-PET, and CSF data of 202 subjects from the ADNI, and experimental results show that the proposed method can recognize MCI-C patients from MCI-NC ones with 79.4% accuracy by using the aid of additional domain knowledge learned from AD and NC."}, {"section_title": "II. MATERIALS AND METHODS", "text": "The data used in our experiments came from the ADNI database. The ADNI was launched in 2003 by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, the Food and Drug Administration, private pharmaceutical companies, and nonprofit organizations, as a U.S. $60 million, five-year public-private partnership. The primary goal of ADNI has been to test whether the serial MRI, PET, other biological markers, and clinical and neuropsychological assessments can be combined to measure the progression of MCI and early AD. Determination of sensitive and specific markers of very early AD progression is intended to aid researchers and clinicians to develop new treatments and monitor their effectiveness, as well as lessen the time and cost of clinical trials.\nADNI is the result of efforts of many coinvestigators from a broad range of academic institutions and private corporations, and subjects have been recruited from over 50 sites across the U.S. and Canada. The initial goal of ADNI was to recruit 800 adults, aged 55 to 90, to participate in the research (approximately 200 cognitively normal older individuals to be followed for three years, 400 people with MCI to be followed for three years, and 200 people with early AD to be followed for two years). The research protocol was approved by each local institutional review board and the written informed consent is obtained from each participant."}, {"section_title": "A. Subjects", "text": "In the ADNI database, there are totally 202 subjects with three modality data (i.e., MRI, PET, and CSF), including 51 AD patients, 99 MCI patients (including 43 MCI-C and 56 MCI-NC), and 52 normal controls. During the 24-month follow-up period, 43 MCI subjects converted to AD and 56 remained stable. It is worth noting the subject size used in our experiments is very similar to that used in many previous studies [2] , [3] , [29] , and thus is sufficient to compare our proposed method with other methods. In general, the inclusion/exclusion criteria are listed below, and "}, {"section_title": "B. MRI, CSF, and PET Biomarkers", "text": "A detailed description on how the MRI, CSF, and PET datasets were acquired can be found in the public ADNI website. In general, structural MR scans were acquired from 1.5 or 3.0-T scanners. Raw DICOM MRI scans were downloaded from the public ADNI website reviewed for quality, and automatically corrected for spatial distortion caused by gradient nonlinearity and B1 field inhomogeneity. PET images were acquired 30-60 min postinjection, averaged, spatially aligned, interpolated to a standard voxel size, intensity normalized, and smoothed to a common resolution of 8 mm full width at half maximum. CSF data were collected in the morning after an overnight fast using a 20-or 24-gauge spinal needle, frozen within 1 h of collection, and transported on dry ice to the ADNI Biomarker Core laboratory at the University of Pennsylvania Medical Center. In this study, amyloid \u03b2 (A\u03b2 42 ), CSF total tau (t-tau) and tau hyperphosphorylated at threonine 181 (p-tau) are used as features."}, {"section_title": "C. Image Analysis", "text": "The MRI and PET images are preprocessed to extract ROIbased features, by following the pipeline in [2] . Specifically, we first perform an anterior commissure (AC)-posterior commissure (PC) correction on all MRI and PET images using MIPAV software [30] . The AC-PC corrected images are resampled to 256 \u00d7 256 \u00d7 256, and the N3 algorithm [31] is then used to correct the intensity inhomogeneity. For the MR images, the skull is stripped using the method described in [32] , followed by manual editing and cerebellum removal. Next, we use FAST in the FSL package [33] to segment the human brain into three different types of tissues: gray matter (GM), white matter (WM), and CSF. For a given brain image with three segmented tissues (i.e., GM, WM, and CSF), we then nonlinearly register it to a template with 93 manually labeled regions-of-interests (ROIs) [35] , by using a widely used high-dimensional elastic warping tool (i.e., HAMMER [34] ). Finally, we use the volumes of GM tissue of the 93 ROIs, which were normalized by the total intracranial volume (which is estimated by the summation of GM, WM, and CSF volumes from all ROIs), as features for a given subject. For PET image, we first align it to its corresponding MRI image of the same subject through affine transformation, and then compute the average intensity of each ROI in the PET image as features. In addition, three CSF biomarkers are also used in this study, namely CSF A\u03b2 42 , CSF t-tau, and CSF p-tau. As a result, for each subject, we have 93 features derived from the MRI image, 93 features generated from the PET image, and three features obtained from the CSF biomarkers."}, {"section_title": "D. Domain Transfer Learning for MCI-C Prediction", "text": "The system diagram illustrated in Fig. 1 outlines the steps and components used in our proposed classification framework. In general, it contains four components, i.e., image preprocessing, DTFS, DTSS, and DTSVM. At first, all MRI and PET images are preprocessed to get the extracted features as described in Section II-C. Then, for both MRI and PET features, the DTFS component identifies a subset of features (corresponding to brain regions) that are relevant to the disease under study. Next, the DTSS component uses the multimodality features found by the DTFS component, as well as the CSF features, to compute cross-domain kernels that simultaneously select the most informative cross-domain sample subset. Finally, in the DTSVM component, the auxiliary domain and cross-domain kernels are combined to train the ultimate classifier for classifying MCI-C and MCI-NC patients. In what follows, we will provide the technical details of these three components (i.e., DTFS, DTSS, and DTSVM)."}, {"section_title": "1) Domain Transfer Feature Selection:", "text": "In traditional singledomain learning, we can employ sparse logistic regression (SLR) [43] for learning weight vectors w A and w T from the auxiliary and target domains, respectively. Then, we can use weight vectors w A and w T for feature selection. Although using single-domain sparse learning can achieve better performance for MCI-C prediction [44] , it cannot acquire knowledge from cross domain. Since the task of classifying MCI-C and MCI-NC patients is related to the task of classifying NC and AD patients, we combine these two learning domains for learning a common weight matrix W that can select a common feature subset, as done in our proposed DTFS model which will be explained below.\nSpecifically, the proposed DTFS model jointly considers two learning domains: 1) AD and NC classification as the auxiliary domain, denoted as A = {x where\nis the weight matrix whose row vector w i is the coefficient vector associated with i-th feature across two different learning domains, and\nis the intercept for the classification task both in the auxiliary (t = A) and target (t = T ) domains. Also, \u03b2 > 0 is a regularization parameter that controls the relative contributions of the two terms, and the symbol denotes the transpose of a matrix. According to the optimization algorithm of the literature [36] for solving the optimization problem of (1), we can get the sparse matrix W, where all nonzero row vectors w i correspond to features that will be selected, indicating that they are essential for classification both on auxiliary and target domains.\n2) Domain Transfer Sample Selection: After performing DTFS, we have obtained the most informative features in both auxiliary and target domains. In what follows, we will compute the cross-domain kernel matrix K for implementing the knowledge fusion both on auxiliary and target domains. Here, the instance-transfer approach [37] , [38] is used to join the auxiliary domain data (i.e., AD and NC subjects, which are more separable than MCI-C and MCI-NC subjects in the reduced feature space via DTFS) to the target domain data (i.e., MCI-C and MCI-NC subjects).\nTo be specific, we first define the kernel matrices from the auxiliary domain and the target domain as:\nare samples in the auxiliary and target domains, respectively, in the reduced feature space via DTFS. Also, as defined before, N A and N T are the numbers of samples in the auxiliary and target domains, respectively. Then, we define the cross-domain kernel matrices from the auxiliary domain to the target domain and also from the target domain to the auxiliary domain as\nThen the crossdomain kernel matrix K can be computed as\nwhere N = N A + N T . In our study, from (2), three cross-domain kernel matrices are obtained, which correspond to three modalities (i.e., MRI, PET, and CSF), denoted as K (M RI) , K (PET) , and K (CSF) , respectively. Moreover, to remove the noisy samples and seek out the most informative samples from multimodal cross domain, we present a sample selection framework via a multitask Lasso-based kernel learning, namely DTSS. Specifically, in our proposed DTSS model, we first employ the kernel learning technique to map sample set from the original space to the kernel space, where multitask Lasso is then performed for sample selection. Fig. 2(b) gives the illustration of the proposed DTSS method. From Fig. 2(b) , DTSS learns a common weight ma-\n, and v (CSF) are the learning weight vectors corresponding to MRI, PET, and CSF modalities, respectively, and is to solve the following objective function:\nwhere is the cross-domain kernel matrix for the m-th modality, i.e.,\n, and K (CSF) , respectively, which can be seen as the similarity between pairwise samples in the cross domain for the m-th modality. In our study, the widely used Gaussian kernel function is used, which is defined as follows:\nwhere \u03c3 is the bandwidth. Due to the use of \"group sparsity\" (i.e., L 2 /L 1 -norm) regularization, many of the rows of V will be zeros, and thus, all samples corresponding to nonzero row vectors will be selected. In this paper, the SLEP package [39] is used for solving the optimization problems in DTFS and DTSS. \nwhere k (m ) denotes the kernel function over the m-th modality, and C m denotes the weight on the m-th modality. From (5), we can achieve the ultimate auxiliary domain kernel matrix K A,A and cross-domain kernel matrix K, i.e.,\n. To find the optimal values for weights c m , we constrain them so that m c m = 1, 0 \u2264 c m \u2264 1, and then adopt a coarse-grid search through cross validation on the training samples, which has been shown effective in our previous work [2] , [3] , [6] . Then, we adopt the adaptive SVMs method in [26] to learn the ultimate classifier f (s). This ultimate classifier f (s) is first learned from the auxiliary domain classifier f A (s), which is implemented by adding a delta function for cross domain in the form of \u0394f (s) = h \u03a6 (s) on the basis of f A (s)\nwhere \u03a6 (s) is a kernel-based nonlinear mapping function, and h is the weight vector of cross-domain classifier. Also, h denotes the transpose of h.\nTo learn the weight vector h in (6), we use the following objective function, similar to the SVM:\nwhere l is the l-th sample in the cross-domain training\nN T represents the total number of samples in z, and \u03b6 l is the slack variable that represents the prediction error of objective function of (7), thus it can be used for nonlinear classification. The parameter C balances contributions between auxiliary classifier and cross-domain training examples. According to [26] , we can solve this objective function (i.e., (7)) to obtain the solution for the weight vector h. Then, we can obtain the final solution for f (s). In this study, f A (s) is trained by SVM using the auxiliary domain kernel matrix K A,A , and \u0394f (s) is solved by (6) using the cross-domain kernel matrix K = [k (s, s )], and k (s, s ) = \u03a6 (s) , \u03a6 (s ) ."}, {"section_title": "III. RESULTS", "text": ""}, {"section_title": "A. Experimental Settings", "text": "In this study, we use a 10-fold cross-validation strategy to evaluate the performances of different methods. Specifically, the set of subjects in the target domain (i.e., 99 MCI subjects) are partitioned into ten subsets (each subset with a roughly equal size), and then one subset is successively selected as the test dataset and the remaining subsets are used to train the classifiers. This process is repeated ten times, and the classification performance is evaluated by the average sensitivity, specificity, accuracy, and area under curve (AUC) measures.\nIn our experiments, traditional SVM (denoted as SVM) and other methods with the SVM algorithm for classification (i.e., DTSVM and our proposed methods) are implemented using the LIBSVM toolbox [41] with a linear kernel. For DTFS and DTSS components, sparse learning is performed using the SLEP package [39] , and regularization parameters \u03b2 and \u03bb are learned using another 10-fold cross-validation strategy on the training data. In DTSS component, the similarity function bandwidth parameter \u03c3 is also learned using the 10-fold cross-validation strategy on the training subsets. Specifically, a hierarchical optimization based grid search is employed for searching the optimal parameters. In our experiments, we first optimize the reg- Finally, we use the grid search to find the optimal weights c m in multikernel learning. The performance of the proposed method was compared with the Laplacian SVM (LapSVM) [42] . The "}, {"section_title": "LapSVM classifier uses a linear kernel function and its graph", "text": "Laplacian is constructed by using the k-nearest neighbor algorithm, where k (1 \u2264 k \u2264 10) is learned through 10-fold cross validation on training data. In addition, we use another similar hierarchical optimizationbased grid search to search the optimal parameters (including k and c m ). Specifically, we first find the optimal value for the nearest neighbor k with fixed values for weights c m (i.e., c MRI = 0.4, c CSF = 0.3, c PET = 0.3), and then determine the optimal weights c m in multikernel learning through cross validation. Multimodality and single-modality biomarkers are used for testing the classification performance of the proposed method, and a multikernel learning method is used to combine multimodality biomarkers (i.e., MRI, CSF, and PET) for all classification methods. In particular, multikernel learning implement a grid search with range from 0 to 1 and step size 0.1 on the training subsets. It is worth noting that for optimization of all parameters, it is performed on the training subset by an inner 10-fold cross validation. In addition, the same feature normalization scheme as in [2] is used in our experiments."}, {"section_title": "B. Classification Results for Recognizing MCI-C and MCI-NC Patients", "text": "To investigate the effectiveness of the proposed method, we first evaluate the classification performance of our method for recognizing MCI-C and MCI-NC patients using both multimodality and single-modality biomarkers. Table II shows the classification performance of five different methods, including SVM (traditional SVM), SVM + SLR, DTSVM [29] , LapSVM [42] , and the proposed method (i.e., DTFS + DTSS + DTSVM). We also perform DeLong's method [53] on the AUC between the proposed method and each of other four comparison Table II . Note that DeLong's test is a nonparametric statistical test for comparing AUC between two ROC curves, which can be employed to assess statistical significance via computing z-scores for the AUC estimate [54] , [55] . Here, SLR denotes a sparse feature selection method with logistic regression loss function [43] , and \"SVM + SLR\" represents the method that first applies SLR for feature selection and then adopts SVM for classification. Note that each value in Table II is the averaged result of the 10-fold cross validation, which was performed ten different times. In addition, we plot the ROC curves achieved by different methods in Fig. 3 .\nAs can be seen in Table II and Fig. 3 , the proposed method consistently outperforms SVM, SVM + SLR, DTSVM, and LapSVM in terms of the classification accuracy, sensitivity, and AUC measures. Also, Table II indicates that both the proposed method and DTSVM significantly outperform SVM and SVM + SLR methods, while LapSVM is only slightly better than SVM. Moreover, statistical test measures via DeLong's method [53] (i.e., p-value) demonstrate the superiority of the proposed method over other comparison methods. These results imply that using knowledge learned from auxiliary domain (i.e., AD/NC classification) can effectively improve the performance of MCI-C/MCI-NC classification. These results also suggest that transfer learning is more suitable than semisupervised learning for the case of data coming from different domains.\nOn the other hand, to investigate the relative contributions of the three components (i.e., DTFS, DTSS, and DTSVM) in our proposed method, we compare our method with its three variants, i.e., DTSVM, DTSS + DTSVM, and DTFS + DTSVM, with experimental results shown in Table III . It is worth noting that DTSS + DTSVM is based on DTSVM classifier using only the DTSS sample selection method, and DTFS + DTSVM is also based on DTSVM classifier using only the DTFS feature selection method. For using CSF biomarkers, feature selection was not performed because there are only three features in CSF. In Fig. 4 . ROC curves of different variants of our proposed method. Fig. 4 , we also plot the ROC curves achieved by different methods using both multimodality and single-modality biomarkers, respectively. In addition, we also report the p-values, which are computed by DeLong's method [53] on the AUC between the proposed method and its other three variants methods in Table III . From Table III and Fig. 4 , each component can boost the classification performance compared with SVM. It is worth noting that, according to Fig. 4 and statistical significance assessment in Table III , the MRI features (as opposed to PET and CSF biomarkers) are most benefited from the proposed method as compared with other individual components (DTSVM, DTSS, and DTFS). This observation shows that using MRI features in the auxiliary domain can more efficiently capture those discriminative features between MCI-C and MCI-NC patients, than using PET or CSF features. Also, it indicates that the structural In general, our proposed method that integrates all the three components together achieves the best performance."}, {"section_title": "C. Discriminative Brain Regions Detection", "text": "To evaluate the efficacy of our proposed DTFS method for detecting the discriminative brain regions, we compare our proposed DTFS method with the commonly used single-domainbased feature selection methods including paired t-test and SLR [43] . It is worth noting that in the feature selection step, both paired t-test and SLR methods only use data from target domain (i.e., MCI-C/MCI-NC), while DTFS uses data from both target and auxiliary (i.e., AD/NC) domains. In addition, we also compare our method with a baseline method where all features are used (i.e., no feature selection). For evaluating the performances of different feature selection methods including DTFS, paired t-test, SLR, and baseline, the classifier DTSVM is used for subsequent classification after feature selection. Table IV shows results achieved by different feature selection methods. Here, each value in Table IV is the averaged result of 10-fold cross-validation strategy in ten independent runs. In addition, we also compute the p-value on the AUC between the DTFS method and other three methods via DeLong's method [53] , which is shown in Table IV . As can be seen from Table IV , for MRI biomarker, there is no statistical significance between the DTFS and SLR (P = 0.054), and also for PET biomarker, there is no statistical significance between the DTFS and the baseline method (P = 0.063). In general, in most cases, our proposed DTFS method outperforms the other three methods, which suggests that the combination of auxiliary and target domains may provide complementary information for seeking out the most discriminative brain regions.\nFurthermore, we list all selected brain regions with the highest frequency of occurrence by DTFS on MRI and PET images in Table V . Here, to get these features (i.e., brain regions), we count the frequency of each feature and selected across all folds and all runs (i.e., a total of 100 times for 10-fold cross validation with ten independent runs), and then regarded those features with frequency of 100 (i.e., always selected in all folds and all runs) as selected stable features. On the other hand, in the supplementary Tables S1 and S2 , we also listed all selected stable brain regions by paired t-test and SLR methods on MRI and PET images, respectively. Finally, Fig. 5 visually shows the selected brain regions with the highest frequency of occurrence by DTFS, paired t-test, and SLR on MRI and PET images, respectively. As can be seen from Fig. 5 , our proposed DTFS method successfully finds out the most discriminative brain regions (e.g., hippocampal, amygdala, temporal lobe, precuneus, and insula) that are known to be related to AD [3] , [4] , [44] , [45] ."}, {"section_title": "IV. DISCUSSION", "text": "In this paper, we propose a domain transfer learning framework to recognize MCI-C and MCI-NC patients by using AD and NC subjects as auxiliary domain. We evaluated the performance of our method on 202 baseline subjects from ADNI database, and the experimental results show the proposed method can consistently and substantially improve the classification performance, with an overall MCI-C and MCI-NC classification accuracy of 79.4%."}, {"section_title": "A. Domain Transfer Learning", "text": "Domain transfer learning is a recently developed machine learning technique, which is able to learn a set of related models from the target domain and its related auxiliary domain for improving the classification performance in target domain [26] - [28] , [38] , [46] . Different from conventional machine learning methods, domain transfer learning does not require target and auxiliary domains having the same data distribution [38] , [46] , and it can effectively use data from auxiliary domain for improving the performance in the target domain [26] - [28] , [38] , [46] . However, to the best of our knowledge, there are few studies using domain transfer learning for neuroimaging-based diagnosis of brain diseases [29] , [47] . It is worth noting that in our preliminary study [29] , domain transfer learning is performed only on the classification stage (i.e., DTSVM). To further improve the performance, we implement domain transfer learning throughout the whole process including DTFS, DTSS, and domain transfer classification (i.e., DTSVM). Our experimental results have validated the efficacy of the proposed domain transfer learning method for recognizing MCI-C and MCI-NC patients.\nRecently, many studies in early diagnosis of AD focus on predicting the conversion of MCI to AD, i.e., identifying the MCI-C from MCI-NC [3] , [4] , [7] , [13] , [15] , [17] , [20] , [23] - [25] , [45] , [48] - [51] . Several studies adopted the correlated domain knowledge to design classifiers, or feature selection methods for predicting the conversion from MCI to AD [3] , [49] , [50] . The regression-based biomarkers and multiple clinical variables (MMSE and ADAS-Cog scores) were used as auxiliary domain knowledge for feature selection in the literatures [3] , [49] . Liu et al. in [50] proposed an improved multitask feature selection method for finding discriminative brain regions using multimodality data (MRI and PET). Different from the above studies, our method adopts more informative auxiliary domain knowledge (i.e., AD/NC learning task) for feature selection. For the validity of using AD/NC learning task as auxiliary domain, we applied the method of [3] , [49] on our used dataset (i.e., 99 MCI, and their corresponding MMSE and ADAS-Cog scores), and achieved an accuracy of 71.7% and an AUC of 0.766 using the three modalities data (i.e., MRI, PET, and CSF). Also, we apply the method of [50] on the dataset used in this study, and achieve an accuracy of 67.8% and an AUC of 0.696 with two modalities data (i.e., MRI and PET). Especially, our method achieve an accuracy of 79.4% and an AUC of 0.848 with three modalities data (i.e., MRI, PET, and CSF), and achieve an accuracy of 77.3% and an AUC of 0.842 with two modalities data (i.e., MRI and PET). This result further validates our assumption that using AD and NC subjects as auxiliary domain can significantly improve the performance of MCI-C/MCI-NC classification.\nIn addition, our current study uses only AD and NC subjects as auxiliary domain. However, according to the principle of domain transfer learning, multiple auxiliary domain knowledge can also be utilized, as long as these multidomain learning tasks are related to the target-domain learning task. Therefore, other relevant learning tasks, e.g., data of other dementia type, could be utilized to further promote the learning performances of our proposed methods."}, {"section_title": "B. Validation and Optimizing", "text": "To evaluate the performance of our proposed domain transfer learning method, the 10-fold cross-validation strategy was adopted. Besides the outer 10-fold cross validation, we further perform an inner 10-fold cross validation on the training data to find the optimal parameters. Our proposed method is evaluated on 43 MCI-C and 56 MCI-NC subjects, which include 93 MRI features and 93 PET features extracted from the original MR and PET images, as well as three CSF features. To overcome the potential overfitting problem caused by the issue of small sample size (i.e., the sample size is considerably smaller than the feature dimensionality), we propose a DTFS method to select the most discriminative features. Similar to several studies in early diagnosis of AD [3] , [13] , [44] , [49] - [51] , [58] where many machine learning methods were developed for selecting discriminative brain regions, our proposed method can also be used for detecting discriminative brain regions from a larger number of brain images on the clinical application. In addition, according to our experimental results, we found that the overfitting issue rarely occurs because of the following two possible reasons. First, the number of samples is comparable to the number of features after feature selection (DTFS). Second, instead of simply concatenating multimodal features into a long vector, the multikernel SVM [2] we adopted can compute kernel matrices using feature subsets from individual modalities, which helps avoid the overfitting problem.\nIn this paper, a hierarchical optimization-based coarsegrid search is employed for searching optimal parameters (i.e.,\u03b2, \u03bb, \u03c3, and c m ). Using this optimization strategy, it cannot guarantee the joint optimality of parameter values. For addressing this problem, we further design an iterative optimization algorithm to find the optimal parameters jointly. Specifically, we first perform a grid search to find the optimal parameters \u03b2 and \u03bb. With determination of these parameters, we then optimize other parameters (i.e., \u03c3 and c m ). Afterwards, the above procedures are reported iteratively. In Fig. 6 , we plot the change of the classification accuracy with respect to different iterations using the iterative optimization algorithm.\nAs shown in Fig. 6 , the accuracy first rises with the increase of iteration number, and then keep stable when the iteration number is larger than 3. However, it is very time consuming to perform such iterative optimization algorithm. We plan to adopt such iterative optimization strategy to find the optimal parameters in the future for further boosting the classification performance."}, {"section_title": "C. Predicting the Conversion of MCI to AD", "text": "As mentioned above, many studies in early diagnosis of AD focus on predicting the conversion of MCI to AD using multimodality data [3] , [4] , [10] , [22] , [23] , [50] , [52] . Accordingly, we report some representative results as follows.\nIn [3] , a multitask feature selection method achieved an accuracy of 73.9% and an AUC of 0.797 on 43 MCI-C and 48 MCI-NC ADNI subjects by using multimodality data (MRI, FDG-PET, and CSF). The method proposed in [4] , which combines statistical analysis and pattern classification methods, achieved an accuracy of 62% and an AUC of 0.734 on 69 MCI-C and 170 MCI-NC ADNI subjects by using multimodality data (MRI and CSF). Also, Hinrichs et al. in [10] proposed a multikernel pattern classification method, achieving an AUC of 0.791 on 119 MCI ADNI subjects with multimodality data (including MRI, FDG-PET, CSF, and APOE). Westman et al. in [22] proposed a multivariate data analysis method and achieved an accuracy of 68.5% and an AUC of 0.76 on 81 MCI-C and 81 MCI-NC ADNI subjects with multimodality data (i.e., MRI and CSF). In [23] , a Gaussian process classification method was proposed and achieved an accuracy of 74.1% and an AUC of 0.795 on 47 MCI-C and 96 MCI-NC ADNI subjects with multimodality data (i.e., MRI, FDG-PET, CSF, and APOE). By using the data employed in this study, we apply the Gaussian process classification method proposed in [23] , and achieve an accuracy of 72.1% and an AUC of 0.797. In [50] , an intermodality relationship constrained multitask feature selection method was proposed, which achieved an accuracy of 67.8% and an AUC of 0.696 on 43 MCI-C and 56 MCI-NC ADNI subjects with MRI and FDG-PET data. Trzepacz et al. [52] used a statistical analyses method and achieved an accuracy of 76% on 20 MCI-C and 30 MCI-NC ADNI subjects by using MRI, FDG-PET, and PIB-PET data. As shown in Section IV, our proposed domain transfer learning classification method achieves an accuracy of 79.4% and an AUC of 0.848 with three modalities (i.e., MRI, FDG-PET, and CSF)."}, {"section_title": "D. Extension for Recognizing MCI and AD/NC", "text": "To further investigate the efficacy of our proposed domain transfer learning method, besides recognizing MCI-C and MCI-NC, we also apply our method for recognizing MCI and AD/NC. Specifically, we have two new classification tasks, i.e., MCI versus NC classification and MCI versus AD classification. It is worth noting that AD subjects are regarded as the auxiliary data for MCI versus NC classification, and NC subjects are regarded as the auxiliary data for MCI versus AD classification. In the appendix, we show the experimental results by comparing different methods with both multimodality and single-modality biomarkers for MCI versus NC classification and MCI versus AD classification in Tables S3 and S4, respectively. As we can see from Tables S3 and S4 , our proposed method achieves consistently better performance than other methods in terms of four performance evaluation measures. Specifically, for multimodality case, our proposed method achieves the classification accuracy of 86.4%, sensitivity of 92.8%, specificity of 73.8%, and AUC of 0.924 in MCI versus NC classification; and the classification accuracy of 82.7%, sensitivity of 89.2%, specificity of 69.6%, and AUC of 0.906 in MCI versus AD classification.\nIn addition, we also list the results achieved by different variants of our proposed method in Tables S5 and S6 in the appendix.  Tables S5 and S6 indicate that our method that integrates all the three components together achieves the best performance. These results further validate the efficacy of our proposed domain transfer learning method that uses data from auxiliary domain for aiding the classification in the target domain."}, {"section_title": "E. Limitations", "text": "The current study is limited by several factors. First, our proposed method is based on the single auxiliary domain data (i.e., AD and NC) from the ADNI database. In the future work, we will investigate whether using data from more auxiliary domains (e.g., fMRI or PIB-PET data, or even the related disease data, e.g., vascular dementia) can further improve the performance. Second, our current method cannot deal with subjects with incomplete multimodality of data (i.e., missing of some modalities of data) and, thus, used only 202 subjects with all three modalities of data in ADNI. It is interesting to extend our current method for dealing with subjects with missing modalities of data for further improvement of performance, which is also one of our future works. Finally, in the current study, we computed the total PET signal from each ROI, but did not perform any partial volume correction based on the segmented tissues from MR image. For further performance improvement in our future work, we will address the issues of partial volume effect and different point spread functions between modalities."}, {"section_title": "V. CONCLUSION", "text": "In this paper, we propose a general domain transfer learningbased framework that consists of DTFS, DTSS, and DTSVM, for MCI conversion prediction. Here, the main idea of our domain transfer learning-based method is to exploit the auxiliary domain data (AD/NC subjects) to improve the classification between MCI-C and MCI-NC in the target domain. To the best of our knowledge, our study is among the first in neuroimaging to use and transfer the knowledge learned from the auxiliary task with multimodal data (i.e., AD versus NC classification) for guiding the target task (i.e., MCI-C versus MCI-NC classification). We have validated the efficacy of our proposed method using 202 subjects from the ADNI database with multimodality data (including MRI, FDG-PET, and CSF). The experimental results show that our proposed method achieves significantly better performance than the traditional methods for MCI conversion prediction by effectively adopting the extra domain knowledge learned from AD and NC."}]