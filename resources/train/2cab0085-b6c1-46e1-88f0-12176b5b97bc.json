[{"section_title": "Abstract", "text": "Explored is the utility of modelling brain magnetic resonance images as a fractal object for the classification of healthy brain images against those with Alzheimer's disease (AD) or mild cognitive impairment (MCI). More precisely, fractal multi-scale analysis is used to build feature vectors from the derived Hurst's exponents. These are then classified by support vector machines (SVMs). Three experiments were conducted: in the first the SVM was trained to classify AD against healthy images. In the second experiment, the SVM was trained to classify AD against MCI and, in the third experiment, a multiclass SVM was trained to classify all three types of images. The experimental results, using the 10-fold cross-validation technique, indicate that the SVM achieved 97.08% \u00b1 0.05 correct classification rate, 98.09% \u00b1 0.04 sensitivity and 96.07% \u00b1 0.07 specificity for the classification of healthy against MCI images, thus outperforming recent works found in the literature. For the classification of MCI against AD, the SVM achieved 97.5% \u00b1 0.04 correct classification rate, 100% sensitivity and 94.93% \u00b1 0.08 specificity. The third experiment also showed that the multiclass SVM provided highly accurate classification results. The processing time for a given image was 25 s. These findings suggest that this approach is efficient and may be promising for clinical applications.\nThe problem of distinguishing Alzheimer disease (AD) from mild cognitive impairment (MCI), and MCI from healthy conditions in brain magnetic images (MRI), has received increasing attention in recent years. For instance, Chincarini et al.\n[1] sampled the brain with seven relatively small volumes that were filtered to give intensity and textural MRI-based features. Each filtered region was analysed with a random forest classifier to extract relevant features that were fed to a support vector machine (SVM) for classification. The system's performance was evaluated on the classification of 144 patients with AD, 322 with MCI and 189 controls (healthy). Using receiver operating curve analysis and 20-fold cross-validation, the result was 0.97 area under curve (AUC) for discriminating the AD images from the normal ones, with 89% sensitivity and 94% specificity. In addition, the classification of controls against MCI converters (patients with MCI who progressed to clinically probable AD) achieved an AUC of 0.92, with 89% sensitivity and 80% specificity. As for the classification of MCI converters against MCI non-converters, the results indicated an AUC of 0.74, with 72% sensitivity and 65% specificity. Zhang et al.\n[2] proposed a multimodal data fusion and classification method based on features extracted from structural MRI, functional imaging, and cerebrospinal fluid (CSF). The three modalities were used to measure brain atrophy, quantify hypo-metabolism and specific proteins linked to AD, respectively. Ninety-three volumetric features were extracted from 93 regions of interest (ROI) and automatically labelled by an atlas warping algorithm. The linear SVM was used to evaluate the classification accuracy using 10-fold cross-validation. The result of classifying 51 AD against 52 normal controls yielded a classification accuracy of 93.2%, with 93% sensitivity and 93.3% specificity. In the case of 99 MCI against 52 healthy controls, the SVM achieved a classification accuracy of 76.4% (with 81.8% sensitivity and 66% specificity) with the multimodal approach, and only 72% using the best individual modality (biomarkers). Moreover, the sensitivity of the multimodal approach indicated that 91.5% of 43 MCI converters and 73.4% of 56 MCI non-converters were classified correctly. Liu et al.\n[3] presented a random patch-based subspace ensemble classification system where local patches are"}, {"section_title": "Introduction:", "text": "The problem of distinguishing Alzheimer disease (AD) from mild cognitive impairment (MCI), and MCI from healthy conditions in brain magnetic images (MRI), has received increasing attention in recent years. For instance, Chincarini et al. [1] sampled the brain with seven relatively small volumes that were filtered to give intensity and textural MRI-based features. Each filtered region was analysed with a random forest classifier to extract relevant features that were fed to a support vector machine (SVM) for classification. The system's performance was evaluated on the classification of 144 patients with AD, 322 with MCI and 189 controls (healthy). Using receiver operating curve analysis and 20-fold cross-validation, the result was 0.97 area under curve (AUC) for discriminating the AD images from the normal ones, with 89% sensitivity and 94% specificity. In addition, the classification of controls against MCI converters (patients with MCI who progressed to clinically probable AD) achieved an AUC of 0.92, with 89% sensitivity and 80% specificity. As for the classification of MCI converters against MCI non-converters, the results indicated an AUC of 0.74, with 72% sensitivity and 65% specificity. Zhang et al. [2] proposed a multimodal data fusion and classification method based on features extracted from structural MRI, functional imaging, and cerebrospinal fluid (CSF). The three modalities were used to measure brain atrophy, quantify hypo-metabolism and specific proteins linked to AD, respectively. Ninety-three volumetric features were extracted from 93 regions of interest (ROI) and automatically labelled by an atlas warping algorithm. The linear SVM was used to evaluate the classification accuracy using 10-fold cross-validation. The result of classifying 51 AD against 52 normal controls yielded a classification accuracy of 93.2%, with 93% sensitivity and 93.3% specificity. In the case of 99 MCI against 52 healthy controls, the SVM achieved a classification accuracy of 76.4% (with 81.8% sensitivity and 66% specificity) with the multimodal approach, and only 72% using the best individual modality (biomarkers). Moreover, the sensitivity of the multimodal approach indicated that 91.5% of 43 MCI converters and 73.4% of 56 MCI non-converters were classified correctly. Liu et al. [3] presented a random patch-based subspace ensemble classification system where local patches are extracted from relevant regions to capture spatial consistency by uniformly dividing the tissue density maps into patches of a fixed size without overlapping. Then, these local patches were randomly sampled to construct a feature subspace for designing each classifier in the ensemble system. Finally, the classifiers were combined for AD classification. The presented sparse representation-based classifier (SRC) was evaluated on 652 T1-weighted MR brain images that included 198 images with AD, 225 with MCI and 229 normal images. The SRC classifier achieved an accuracy of 90.8% and an AUC of 94.86% for AD classification, and an accuracy of 87.85% and AUC of 92.90% for MCI classification. Zhang and Shen [4] proposed a multimodal multi-task learning system to jointly predict multiple variables from multimodal data composed of clinical and categorical variables. The approach was based on a multi-task feature selection that selects the common subset of relevant features for multiple variables from each modality, and a multimodal support vector regression used to fuse features from all modalities to classify multiple variables. The proposed system was tested on a set of 1.5T MRI, PET and CSF data obtained from 45 AD patients, 91 MCI patients and 50 healthy controls. Using 10-fold cross-validation, the SVM regression achieved an accuracy of 93.3% in the classification of AD against healthy images, and 83.2% in the classification of MCI against healthy images. In [5] , Cuingnet et al. evaluated the performance of ten different approaches (five voxel-based methods, three methods based on cortical thickness and two methods based on the hippocampus) for the classification of 509 1.5T MRIs that include 162 healthy brains, 137 with AD, 134 with MCI and 76 MCI-converters within 18 months. The whole-brain methods (voxel-based or cortical thickness based) achieved the highest accuracies in the classification of AD against healthy images (with up to 81% sensitivity and 95% specificity). For the detection of prodromal AD (healthy against MCI), the obtained sensitivity was substantially lower; all methods reached a specificity over 85%, but the sensitivity ranged between 51 and 73%. Finally, in the problem of classifying MCI non-converters against MCI converters, the thickness-based approach reached 32 to 57% sensitivity and 62 to 91% specificity, and the Hippocampus-based volume approach distinguished MCI converters from MCI non-converters with 62% sensitivity and 69% specificity.\nAlthough the previous methods were proved capable of distinguishing AD, MCI and healthy images, this was achieved at the cost of complex architectures and less than perfect performance, leaving the door open for alternative approaches and improvements. For instance, the system presented in [1] was based on identifying multiple ROI, using numerous filtering protocols and extracting a large feature set to prune for the most suitable features. The works presented in [2] [3] [4] used sophisticated multimodal or ensemble systems that require several preprocessing steps, with only average classification accuracy at the end, as is also the case in [5] .\nIn this exploratory study, we investigate a simpler and potentially more effective algorithm to distinguish: (i) AD from MCI images; and (ii) MCI from healthy brain MRIs. The system is based on fractal multi-scale analysis (MSA) [6] to estimate the Hurst's exponent (HE) of a MRI at different scales of analysis. HE evaluates the self-affinity of a signal, i.e. how it can be made self-similar by an anisotropic, affine transformation (a self-similar image is one whose whole is similar to its parts). We make the hypothesis that a healthy brain biological tissue exhibits more self-affinity than a diseased brain tissue, and that this remains true for one or more levels of analysis. Intuitively, this is similar to saying that the pixel distribution of a healthy brain MRI shows more regularity (i.e. is less rough or rugged) than in that of a brain with AD or MCI. Based on this assumption, the HE extracted at different scales of analysis could help distinguish the three types of MRI.\nComputing it via MSA offers the advantage of combining sensitivity to any type of signal dependence with a high computational efficiency because of the relatively simple algorithm [6] .\nA SVM [7] is used to classify a given image based on the estimated HEs. This approach has already been found to be effective to classify healthy brain MRIs against those with AD [8] . In the study by Lahmiri and Boukadoum [8] , perfect classification accuracy was obtained for a database of 51 healthy brain MRIs and 42 AD MRIs, using MSA, a SVM classifier and the leave-oneout method of validation. This Letter extends the work in [8] with three types of experiments. The first one addresses the classification of AD against MCI. The second experiment tests the algorithm on the classification of healthy images against MCI. Finally, the third experiment investigates the ability of the algorithm to classify all of AD, MCI and healthy MRIs using a multiclass SVM.\nThis Letter is organised as follows: Section 2 presents the fractal MSA, the SVM, and the metrics used for performance evaluation. The experimental results are presented in Section 3 and Section 4 concludes the work."}, {"section_title": "Methods:", "text": "The overall approach is described in the block diagram of Fig. 1 . It consists of the following four-step sequence:\n1. The brain MRI is converted to a one-dimensional (1D) signal by row concatenation. This operation carries the risk of introducing artefacts in the obtained 1D signal, as the black pixels located outside the brain region of the MRI may create a pseudo regular component in the 1D signal. However, the impact on the estimated HEs may not be significant given the large size of the obtained 1D signal (256 2 pixels), which preserves the efficiency of the regression estimates. 2. The MSA is employed to estimate the HE of the 1D signal at six different analysis scales to analyse the signal at different levels of granularity. 3. The obtained HE values form the components of a feature vector that is fed to the SVM for classification. 4. Finally, the classification performance is evaluated.\nThe MSA, SVM and performance measures are presented in the next subsections."}, {"section_title": "Fractal", "text": "where \nIf Kq(d ) and d satisfy a linear relationship in log-log scale for a given order q, the HE H(q) can be estimated by running a linear regression of log(Kq(d)) against log(d). The generalised HE H(q) describes the long-memory dependence or persistence in the signal s(t). The multi-scaling structure of signal s(t) is related to different the orders q of H(q). In general, when H(q) > 0.5, the signal fluctuations related to order q are persistent. When H(q) < 0.5, the signal fluctuations related to order q are anti-persistent. Finally, the signal fluctuations are those of a random walk if H(q) = 0.5 [9] . Notice that H(q = 2) corresponds to the classic HE [6] . In this Letter, the range of q is arbitrarily fixed to the interval from 1 to 6. These moments are considered because they were found to be effective in [8] . To determine H(q), the original MRI is transformed first into a 1D signal by row concatenation. Then, the HEs H(q) for q = 1, \u2026, 6 are estimated by applying the MSA algorithm. As mentioned above, the resulting six-component feature vector forms the input of the SVM classifier to classify the MR images. [7] , the SVM classifier is based on the statistical learning theory. It implements the principle of structural risk minimisation and has excellent generalisation ability as a result, even when the data sample is small. The SVM performs a classification task by constructing an optimal separating hyper-plane that maximises the margin between the two or more nearest data points belonging to two separate classes. Given a training set {(x i , y i ), i = 1, 2, \u2026, m}, where the input x i \u2208 R d , and class labels y i \u2208 { +1, \u22121}, the separation hyper-plane for a linearly separable binary classification problem is given by"}, {"section_title": "Support vector machines: Introduced by Vapnik", "text": "where w is a weight vector and b is a bias, both determined from the training set. For a nonlinearly separable binary classification problem, the optimal discriminant function between the two classes is given by\nwhere \u03b1* is the optimal Lagrange multiplier, \u03a6 is a kernel function and K(x i , x j ) = \u2329\u03a6(x i )\u00b7\u03a6(x j )\u232a is used to map the training points to a high-dimensional feature space where linear separation can be possible.\nIn this Letter, a polynomial kernel was used for the SVM. As a global kernel, it allows data points that are far away from each other to also have an influence on the kernel values contrary to a radial basis kernel alternative. The general polynomial kernel is given by\nwhere d is the order of the polynomial. It was varied from two to four in this study, with higher orders ignored because of the higher computational burden with no substantial gain in classification accuracy from our experience.\nExtending the binary classifier defined in (4) to a multiclass SVM with k classes can be done by either building k one-against-all SVM or k\u00b7(k \u2212 1) one-class-against-another SVMs [10]."}, {"section_title": "Experimental results:", "text": "We used a collection of 33 axial, T2-weighted, MR brain images of size 256 \u00d7 256 pixels, downloaded from the Harvard Medical School webpage [11] . The set consisted of equal numbers of healthy, MCI and AD magnetic resonance images. We had no indication regarding image depth, the AD stage and MCI type: conversion or no conversion to AD as would be provided in more structured databases such as ADNI [12] . However, this was not an issue in this position work (a more comprehensive study using ADNI [12] and OASIS [13] MRI databases is under planning). Figs. 2-4 show examples of the magnetic resonance images of healthy brains, brains with MCI and brains with AD used in our experiments.\nThe validation of all experiments was conducted with the 10-fold cross-validation method, after which the average and standard deviation of the correct classification accuracy rate, sensitivity and specificity were computed to evaluate the SVM performance.\nAll the experiments were implemented on a 1.6 GHz CPU with 1 GB of RAM, running under the Windows XP operating system and using Matlab \u00a9 R2009a [14] . The average processing time of an image was 25 s, regardless of type.\nThe boxplots of the estimated HEs of MCI, AD and healthy control images at scales 1-6 are presented in Figs tests. The first one tested the null hypothesis of equal means for the HE values of healthy, MCI and AD data based on the F-statistic of an analysis of variance (ANOVA) test [15] . The second test checked the null hypothesis of equal distribution variances based on the Brown-Forsythe statistic [16, 17] . The results of the two tests are provided in Tables 1 and 2 , and they reject the two hypotheses at the 5% level of significance for all scales of analysis, since the obtained p-values were all inferior to 0.05. We conclude from these results that the distributions of HEs among healthy, MCI and AD are statistically different and, therefore, these fractal measures are potentially discriminative to distinguish healthy, MCI and AD images.\nThe experimental results based on 10-fold cross-validation indicate that for the classification of healthy against MCI, the SVM achieved 97.08% \u00b1 0.05 correct classification rate with 98.09% \u00b1 0.04 sensitivity and 96.07% \u00b1 0.067 specificity. On the other hand, for the classification of MCI against AD, the results were 97.5% \u00b1 0.04 correct classification rate, 100% sensitivity and 94.93% \u00b1 0.08 specificity. Table 3 compares the performance of our approach to the results obtained by other works in the literature in the case of classifying healthy controls against MCI. As the table shows, our presented system outperforms recent studies [1] [2] [3] [4] [5] in terms of accuracy, sensitivity and specificity. However, it should be noted that the comparison is based on databases of different sizes. Moreover, we did not consider the problem of classification of MCI non-converters against MCI converters as in [1, 5] . In this respect, our result should only be considered promising before further investigation with a larger database with more modalities.\nThe results of the third experiment using the multi-class SVM approach are provided in the confusion matrix shown in Table 4 . They were obtained with a polynomial kernel of order three for the SVM. As indicated, all AD images were correctly classified. On the other hand, One MCI image was misclassified as healthy and one healthy image was misclassified as AD. This translates to a 100, 91 and 91% correct classification rate, respectively. Notwithstanding the relatively small database, these finding indicate that MSA-based fractals may also be suitable features for a multiclass automated diagnosis system. 4. Summary and conclusion: An algorithm for the classification of AD, MCI and healthy brain magnetic resonance images was presented. It uses MSA to obtain HE at various scales to characterise the brain MRI, and a SVM is used to classify the resulting exponents. The obtained preliminary results indicate that the proposed algorithm is highly accurate with a relatively low processing time that can be shortened further with a faster processor. More notably, our approach appears to outperform the works reported in the literature regarding the classification of healthy against MCI images. This preliminary evidence of the effectiveness of our approach suggests that it might be interesting for clinical applications, should a larger database of MR image such as ADNI [12] confirm the present findings. In addition, the method should be extended to 3D brain magnetic resonance images to follow the current trend for even more comprehensive analysis and diagnosis tools. [2] multimodal data fusion + SVM 76.4% accuracy 81.8% sensitivity 66% specificity [3] local patches + ensemble classifier 87.8% accuracy [4] clinical and categorical variables + SVM regression 83.2% \u00b1 0.1 accuracy [5] comparative study of ten different methods accuracy not mentioned \u226585% specificity 51-73% sensitivity our approach multi scale HE + SVM 97.1% \u00b1 0.1 accuracy 98.1% \u00b1 0.0 sensitivity 96.1% \u00b1 0.1 specificity"}, {"section_title": "References", "text": ""}]