[{"section_title": "Abstract", "text": "The aim of this study is to determine the level of achievement of students participating in Programme for International Student Assessment (PISA) 2003 and PISA 2012 tests in Turkey according to questions in the mathematical literacy test. This study is a descriptive survey. Within the scope of the study, the mathematical literacy test items were classified as multiple-choice, complex multiple-choice and constructed response items according to the different question types. The ratio of correct and partially correct and incorrect response given to each question type has been determined. Findings show that the achievements of students differ according to different types of questions. While the question type with the highest success average in the PISA 2003 test was multiple-choice, students got the highest scores from complex multiple-choice questions in the PISA 2012 test. The questionnaire with the lowest success average was found to be complex multiple-choice questions in the PISA 2003 test while students got the lowest scores from constructed response items in the PISA 2012 test. According to the constructivist education approach effectuated in [2005][2006] academic year, it is expected to observe a rise in constructed response question type; however, findings of the study reveal that the success of constructed response questions is decreased according to the application years."}, {"section_title": "INTRODUCTION", "text": "Based on the learning outcomes in the curriculum, measurement and evaluation are applied to determine the level of learning realized during the education process. Measurement and evaluation are carried out with the aim of assessing the effectiveness of the curriculum and the teaching methods, identifying and completing learning deficits, determining the interests and abilities of the students, directing them to relevant fields and determining student achievement [1] . Many national and international examinations taken by numerous students are held with the aim of identifying the efficiency of the implemented education system and making educational decisions accordingly, comparing the system with other countries and preparing new education policies according to the obtained results. Large-scale exams are applied when the number of candidates entering the examination is high with regards to national and international examinations. Large-scale exams consist of more than one sub-test or dimension, and are the types of examinations applied on a large group of students in order to measure their knowledge and skills [2] .\nIn Turkey, large-scale exams are implemented by the Ministry of National Education (MEB) and the Assessment Selection and Placement center (\u00d6SYM). The large-scale examinations prepared and implemented by the Ministry of National Education include examinations such as the Examination for Determining Student Success (\u00d6BBS) and the Examination for Transition from Primary to Secondary Education (TEOG). Among the large scale exams applied by the \u00d6SYM are the Public Personnel Selection Examination (KPSS), the Transition to Higher Education Examination (YGS), the Academic Personnel and Post-Graduate Education Entrance Examination (ALES) and the Foreign Language Examination (YDS).\nBesides national examinations, Turkey also participates in international exams to determine its place on the international stage and to see its progress in reference to a specific reference point and to identify the deficiencies that need to be addressed. These exams include the Programme for International Student Assessment (PISA), the Progress in International Reading Literacy Study (PIRLS), and the Trends in International Mathematics and Science Study (TIMMS). TIMSS is a survey study conducted by the International Association for the Evaluation of Educational Achievement (IEA) at four-year intervals to assess the knowledge and skills of students in the fourth and eighth grades in the fields of mathematics and science [3] . PIRLS is a large scale examination containing subjects such as reading skills and habits of 4th grade students (9-year-age group), and whether teaching materials and methods used by teachers to teach reading skills to students are adequate as well as the contributions of parents to their reading skills determined through national and international tests and surveys and compared with other countries to reveal the similarities and differences [4] .\nThe PISA is the biggest educational study survey organized by the Organization for Economic Cooperation and Development (OECD), aiming at collecting information on the mathematics, science and reading skills of students in the 15 year age group and their level of motivation to learn these subjects, their opinions about themselves, their learning methods, the school environments and the families. Held every three years since 2000, the PISA exam seeks to assess how much of the basic knowledge and skills the students have. PISA results are used by policy makers around the world to compare the knowledge and skill levels of students in their countries with those in other countries participating in the project and to set standards to raise quality in education and identify the strengths and weaknesses of their education systems [5] . First introduced in 2000, the PISA test contained questions from three fields, with a primary focus on questions measuring literacy skills but Turkey was not a part of the program. Turkey joined the program for the first time in 2003, when the focus of the test shifted to assessing students' mathematical skills. In 2006, the focus was on natural sciences questions. All these three tests represented the first evaluation period of the PISA test. The second evaluation period of the PISA was completed in 2009 with a reading test, in 2012 with a mathematical test and with science tests in 2015 [5] . Regular review of PISA data by years is important both for monitoring the progress in education and assessing the efficiency of newly introduced policies [6] .\nVarious measurement tools are included in the PISA test. One of these is the student questionnaire which contains many aspects gauging the interest of the students in the weighted field tested and their selfbelief, as well as their attitude toward the school and their sense of belonging.\nAnother is the open-ended school survey, which provides information about the structure and resources of the school, evaluates the school's curriculum, and determines the school's educational policies. Another measurement tool used in the PISA test are cognitive tests assessing reading, science and math literacy to measure the academic success of the student. The questionnaires and cognitive tests are intended to evaluate the student in a multidimensional way. The question types used in PISA cognitive tests are multiple choice, complex multiple choice, open ended, semi structured and short answer questions [5] .\nWhen the related literature was examined, we found studies examining the performance levels of students with regards to different types of questions on the basis of gender [3] , [7] - [9] . We also found out that performance levels with regards to different question types were examined by different disciplines and by academics from different fields [10] - [21] . These studies show that student success rates with multiple choice questions are four times higher in comparison to other question types. It is also seen that there are studies examining the psychometric aspects of different question types [22] - [24] and studies on the positive contributions of the constructivist teaching approach to academic achievement [11] , [25] , [26] . Previous researcher [27] "}, {"section_title": "RESEARCH METHOD 2.1. Research Design", "text": "As the study was repeated based on quantitative and OECD data as the study analyzes statistical data with regards to mathematical literacy test results of students in Turkey in the PISA 2003 and PISA 2012 tests, the study is an example of a secondary analysis study. The success rate of the students in the sample was investigated in depth through tests. Hence this study is a descriptive study."}, {"section_title": "Population and Sample", "text": "The study includes students in the 15-year-age group who received formal school training in Turkey in the years 2003 and 2012. The PISA 2003 cognitive tests and questionnaires were applied on 4,855 students from 12 primary schools and 147 high schools randomly picked in May from seven geographical regions [28] . The PISA 2012 cognitive tests and questionnaires were applied on 4,848 students from 170 schools randomly chosen by the PISA International Center after classification according to school types [5] . Cognitive test results obtained from these tests were used in the study."}, {"section_title": "Data Collection", "text": "The [30] , [31] . The distribution of questions in PISA 2003 and PISA 2012 mathematics literacy tests by item types is given in Table 1 . When Table 1 is examined, it is seen that structured response questions form the majority of questions in both tests, followed by multiple choice questions and complex multiple choice questions."}, {"section_title": "Analysis of the Data", "text": "The PISA 2003 and PISA 2012 mathematics literacy test items used as data collection tools were classified as multiple choice, complex multiple choice and structured response questions on the basis of the types of questions to be examined. A database containing cognitive test items has been accessed using the international database published by the OECD. First of all, data from other countries have been deleted and expunged from this database. The obtained text file has been converted into Excel format. During the file conversion, attention has been paid to what the data in each column refers to by considering the cognitive test code book published by the OECD. As the variables made meaningful by the columns differed, lines were drawn between the data and the conversion process was completed. Data other than those on mathematical literacy were deleted and removed from the columns in the Excel file to give the database its final shape 51. 4 ,848 students in response to 84 mathematical questions. The column with the question codes was added to the top of the student answers by the investigators according to the order in the code book. For each question, fully correct, partially correct, incorrect and unanswered questions have been calculated by using the Excel \"COUNTIF\" command. In order to find out the number of questions answered by each student, data on the fully correct, partially correct and empty columns were collected. The following formula has been used to calculate the total score. otal Score = (Fully correct\u00d7 2) + (Partially correct \u00d7 1) + (Incorrect\u00d7 0). As clearly stated in the formula, the point for each complete answer was 2, the score for each partially correct answer was 1, and the point for false answers was 0. The answers were scored based on the 2-1-0 system used in the PISA system. The total score was divided by the number of attending students to find the average score. Since each correct answer was scored as 2, the average scores obtained are based on correct answers being scored as 2. The average scores obtained when calculating the success percentages have been multiplied by 50. Subsequently, same question types were grouped among themselves and average scores and general average scores were calculated on the basis of question types. Table 2 were created following the application of the aforementioned steps to PISA 2012."}, {"section_title": "RESULTS AND ANALYSIS", "text": "In this part of the study, PISA 2003 and PISA 2012 Turkey data were analyzed by question types. Using the data sources obtained, we got results on the study problem and the sub-problems. Interpretations of the findings are below.\nTo find an answer to the first sub-problem of 'What is the success percentage distribution of students in the PISA 2003 mathematics literacy test by the question types?', the percentage and frequency distributions of student responses were examined by types in the PISA 2003 test. A detailed analysis of all item types is given in Annex Table 1 and their summary illustration is presented in Table 2 . When Table 2 is examined, it is seen that the item type in which the percentage of success is the highest (44.63%) is \"multiple choice\" questions whereas the question type in which the percentage of success is the lowest (31.49%) is \"complex multiple choice\" questions. The students scored the highest on \"multiple choice\" questions (29.4%) and the lowest on \"structured response\" questions (24.5%). The highest number of completely correct answers (44.9%) were obtained with \"multiple choice\" questions and the least (31.7%) with \"complex multiple choice\" questions. The highest number of incorrect answers (65.8%) were given for \"complex multiple choice\" questions and the least (51.9%) for \"multiple choice\" questions. The type of question most left unanswered (3.3%) were \"structured response\" questions and the type of question least left unanswered (2.5%) were \"complex multiple choice\" questions.\nTo Table 2 and their summary illustration is presented in Table 3 . When Table 3 is examined, it is seen that the question type in which the percentage of success is the highest (50.05%) is \"multiple choice\" questions. whereas the question type in which the percentage of success is the lowest (32.35%) is \"structured response\" questions. The students scored the highest on \"complex multiple choice\" questions (29.97%) and the lowest on \"structured response\" questions (27.44%). The highest number of completely correct answers (51.33%) were obtained with \"multiple choice\" questions and the least (32.79%) with \"structured response\" questions. The highest number of incorrect answers (65.1%) were given for \"structured response\" questions and the least (49.3%) for \"multiple choice\" questions. The type of question most left unanswered (1.02%) were \"structured response\" questions and the type of question least left unanswered (0.406%) were \"complex multiple choice\" questions.\nIn order to find an answer to the third sub-problem of 'How do student success rates in the PISA 2012 mathematical literacy test. an output of constructivism that first began to take adopted during the 2005-2006 academic year. compare to the PISA 2003 mathematical literacy test according to question types?'. percentage (%) values of the data generated by comparing the data from the first two tables were presented in Table 4 . Table 4 reveals varying student responses in Turkey to the PISA 2003 and PISA 2012 mathematics literacy tests. There are four common student reactions that are noteworthy in these tests: (1) In both tests. students gave the highest number of completely correct answers in the category \"multiple choice\" questions. Fifty-six (2) In both tests. the least incorrectly answered questions were \"multiple choice\" questions. (3) In both tests. the question type left blank the most were \"structured response\" questions. (4) In both tests. students got the highest scores on \"multiple choice\" questions. As a general result of the study. it is seen that student success is higher in multiple choice questions in both PISA tests. Over the years. the percentage of success in multiple-choice and complex multiple-choice questions has increased. while the percentage of success with \"structured response\" types has decreased. Looking at the general average. the results of the PISA 2003 and PISA 2012 tests seem to be similar. "}, {"section_title": "DISCUSSION", "text": "This study aimed at evaluating student success rates in Turkey according to different types of questions in PISA 2003 and PISA 2012 mathematics literacy tests. For this purpose. questions in the mathematical literacy test were first classified according to different types of questions taking into account the code booklet and the technical reports. In the second stage. the answers of students who participated in the PISA tests from Turkey were examined in detail and the rates of completely correct. partially correct and incorrect answers were determined.\nWhen the PISA 2003 test is examined according to the different types of questions in the mathematical literacy test. it is seen that the highest number of completely correct answers (44.9%) and the lowest number of incorrect answers (51.9%) are with multiple choice questions. 28 .6% of students gave correct responses to complicated multiple-choice questions that provide students with one or more correct answer options in some cases. The question type for which students gave the least completely correct answers (31.7%) and the most incorrect (65.8%) answers are also complex multiple choice questions. Students scored the lowest points on structured response questions (%24.5). In this question type. there are partially correct answers as well as completely correct answers and incorrect answers. Two point four% of student answers to structured response questions were partially correct. The highest number of questions (3.3%) left blank was from the question type \"structured response questions\". When success rates by question types were examined for the study problem. the highest success rate was achieved on multiple choice questions (44.63%) and the lowest success rate was achieved on complex multiple choice questions (31.49%).\nWhen the PISA 2012 test is examined according to the different types of questions in the mathematical literacy test. it is seen that the highest number of completely correct answers (51.3%) and the lowest number of incorrect answers (49.3%) were given to multiple choice questions. A higher number of correct responses were given to complex multiple choice questions than other question types (29.97%). whereas the rate of correct answers to structured response questions is 27.44%. The least number of completely correct answers (32.79%). the highest number of incorrect answers (65.1%) and the highest number of blank responses (1.02%) were given to structured response questions. When examined in terms of success percentages. multiple-choice questions come first. followed by complex multiple-choice questions and structured response questions.\nWhen success rates are compared according to question types in the relevant tests. an increase from 44.63% to 50.05% is seen for multiple choice questions and an increase from 31.49% to 42.71% for complex multiple choice questions. while a decrease from 38.70% to 32.35% is seen in structured response questions. While a higher success rate was expected with structured response questions in answering which students are required to build their own unique answers according to the constructivist teaching approach introduced in the academic year [2005] [2006] . the opposite occurred. While the results obtained are compared with the similar studies in the literature. it is observed that the results are overall consistent. The study by [27] and [32] is an example of these studies. [36] examined how different measurement-evaluation approaches such as multiple choice tests. written examinations and performance tasks affected achievement in science classes. For this purpose. he used data collection tools measuring the same achievements. developed by the investigator. He found that 59 students performed higher on multiple-choice tests than written exams and performance task. Considering that the questions examined are derived from teacher-made tests. it is noteworthy that they show a similar distribution to achievement rates on the question types in the PISA test.\n[27] investigated student achievement rates according to different types of questions on the basis of all sub-fields in the PISA 2003 and PISA 2006 tests. He found that students achieved the highest scores with multiple choice questions in the sub-fields of reading skills and science. which is consistent with the results obtained within the scope of the study. However. the types of questions where students have been the most successful in the sub-field of mathematical literacy over the years are semi-structured and multiple-choice questions. respectively. This difference may be due to the fact that [27] detailed the question types differently from the types of questions discussed in this study. and that the PISA 2006 test was primarily focused on measuring science literacy. All open-ended. semi-structured. and short-answer questions were categorized as structured response questions under a single heading in this study. This may be attributed to the PISA 2003 Cognitive Test Code Booklet and the PISA 2012 Technical Report. published by the OECD. The overall outcome of the study is that student achievement rates are higher in multiple choice questions than in other types of questions. This finding is supported by many other studies. [8] , [10] , [15] , and [18] compared success rates on the basis of question types used in mid-term or final exams for different disciplines of health studies. According to the results of the study. students had more success with multiple choice questions than with open-ended questions. [12] , [20] and [33] aimed to determine the success rate of students in different disciplines such as nursing. chemistry and physics according to different types of questions and investigate the effect of different types of questions on academic achievement. For this purpose. students were asked In a study conducted by [34] open-ended and 60 multiple-choice tests were compared in evaluating the reading comprehension skills of 8th grade students in primary education. According to the findings of the study. the students were more successful with multiple choice questions than open-ended questions when it came to measuring their reading skills. which is consistent with the results obtained within the scope of the study. [9] investigated the tenets of the constructivist teaching approach adopted as today's education model in his study and presented them with a critical point of view. The investigator has focused on the implications of this approach in the field of application. Introduction of the constructivist teaching approach to our country's education system by looking at successful outcomes achieved by other countries without really understanding what it is. what it entails and what it seeks to achieve. has only served to change the curriculum content and nothing more. Moreover. the fact that the constructivist teaching approach has been adopted without training teachers on application methods and techniques and offering them to chance to practice has led to practical challenges and inefficiencies. which in turn decreases the efficiency levels in education. The study results are consistent with the results obtained within the scope of this study. The greatest indicator of such inefficiencies are success rates falling from 38.70% to 32.35% over the years between PISA 2003 and 2012when in fact quite the contrary was expected.\nSome researcher [11] , [24] and [26] conducted empirical studies to investigate the effect of the constructivist teaching approach on student success in different disciplines such as geography and science teaching. Analyses show that constructivist teaching generates higher academic achievement than traditional methods of teaching. This suggests that constructivist teaching promotes the cognitive levels of students in comparison to traditional methods. The study results are inconsistent with the results obtained within the scope of this study. When one looks at the structured response questions in PISA 2003 and PISA 2012 tests and the general success rate, it is seen that there is a decrease in success rates when in fact higher academic achievements were being expected following the introduction of the constructivist teaching approach. This indicates that constructivist teaching does not have an impact on a wide-ranging test such as the PISA test done on an international scale."}, {"section_title": "CONCLUSION", "text": "It can be concluded that student achievements differ according to the years when the tests were taken and the types of questions. The question type with the highest percentage of success are multiplechoice questions in both PISA tests. The type of question that has the lowest percentage of success are the complex multiple-choice questions in the PISA 2003 test and structured response questions in the PISA 2012 test. According to the constructivist education approach effectuated in 2005-2006academic year, it is expected to observe a rise in constructed response question type; however, findings of the study reveal that the success of constructed response questions is decreased according to the application years."}]