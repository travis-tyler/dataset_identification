[{"section_title": "Impact ofAccotntability on Racial and Socioeconomic Equity", "text": "widen the achievement gaps by rewarding advantaged, high-performing students and their schools and punishing disadvantaged ones. Studies show that assessment and accountability policies have imposed changes in schools with little or no support over the long haul and that this unfunded mandate has created problems (\"Quality counts 2001 (\"Quality counts ,\" 2001 Levin, 2001; Smith, Heinecke, & Noble, 1999) .3 As the researchers whose studies showed the positive impact of accountability on equity often acknowledged, lower class sizes and increased, more equitable funding in Texas have created a context in which the accountability system could increase equity (Grissmer, Flanagan, Kawata, & Williamson, 2000; Skrla, Scheurich, Johnson, & Koschoreck, 2004) . Inequity may be exacerbated when educationally irrelevant factors such as race and *socioeconomic status filter institutional support for schooling. Faced with institutional racism, educational policies that appear to be racially neutral may have unintended negative consequences for racial minorities (House, 1999) . 4 The case that drew the most attention was Texas, where the evidence on the effects of high-stakes testing on equity was mixed and often contradictory (Grissmer & Flanagan, 1998; Haney, 2000) .\nThis policy debate, however, tends to polarize between the extremes and suffers from a lack of generalizable empirical evidence. Regardless of the merits of each argument, the actual impact of state accountability policies on academic excellence and equity may turn out to be contingent upon the level of support available to schools, teachers, and students. There is a dearth of empirical studies on the extent to which different racial and socioeconomic groups benefit from accountability policies, with or without adequate support for schooling conditions and resources.\nTo better understand the impact of educational accountability policy on equity, it is necessary to address the following questions: Did states actually shift their accountability practices from inputs to outcomes? If states did so because of an alleged input failure, did new state accountability policy bring about any changes in educational resource allocations? If their assertion of failure is misguided, what are the consequences of state policy shifts for equity? Did performance-driven accountability bypass the issue of disparities in schooling resources and opportunities for low-income, minority students? If states ignored equity issues, were they still able to narrow the persistent racial and socioeconomic achievement gaps?\nIn light of these questions, we systematically examined the nature and variations of extemal, performance-driven educational accountability policies across 50 states and the relationships of these policies with the racial and socioeconomic distribution of key school resources and academic achievement. Our objective was to investigate changes in the provision of educational support by strong accountability states during the 1990s and to explore those states' policy impact on improving and equalizing mathematics learning outcomes for disadvantaged minority students. In the midst of a keen policy debate about the impact of high-stakes testing and accountability initiatives on equity, our study has implications for contemporary national and state policy efforts, as mandated by the NCLB, to close the achievement gap."}, {"section_title": "Theoretical and Analytical Framework", "text": "Accountability often has multiple meanings and purposes, and there are several models of educational accountability (see Darling-Hammond, 1989; Adams & Kirst, 1999; Linn, 2003) . The issue of who holds whom accountable and for what purpose has been contentious in the history of educational accountability (Dom, 1998) . Despite the historical debate, an accountability model that is performance-driven, test-driven, measurable, and statistical in nature came to dominate current policy and practice. The logic of performance-driven accountability policy appears to draw upon rationalistic and behavioristic views of human behavior by positing that holding schools, teachers, and students accountable for academic performance, with incentives provided (i.e., rewards and sanctions), will inform, motivate, and reorient the behavior of schooling agents toward the goal (Benveniste, 1985; Wise, 1979 ; also see Shafritz & Ott, 2001 , for more general organizational theories on these issues).\nPrevious studies on the impact of high-stakes testing and accountability policies showed the effects of policy on academic motivation and behaviors, including changes in students' course taking (Shiller & Mueller, 2003) , student motivation (Roderick & Engel, 2001) , and teacher motivation (Kelley, Heneman, & Milanowski, 2000) . Some states or school districts' larger achievement gains in the 1990s were attributed to more rigorous testing and stronger accountability policy (Bishop, Mane, Bishop, & Moriarty, 2001; Clotfelter & Ladd, 1996; Carnoy & Loeb, 2002; Grissmer & Flagnan, 1998; Raymond & Hanushek, 2003) . The cost of test-based accountability was deemed so small that it held out the hope of greater cost-effectiveness (Hoxby, 2002) . 5 However, some studies challenge simple, rationalistic approaches to performance-driven accountability policy and identify contingencies for policy success. Some show that the effects of high-stakes testing and accountability policy on student achievement are largely indeterninate or mixed (Amrein & Berliner, 2002; Jacob, 2001; Lee, 1998; Lee, 2004b) . 6 Some studies suggest that extemally set standards and tests may serve as extrinsic motivations for academic press, but that their ultimate effects on academic performance depend on school capacity and social support (Newmann, King, & Rigdon, 1997; Lee & Smith, 1999) . Recent work on the impact of high-stakes testing in Chicago suggests that the additional resources provided to at-risk students, such as reduced class sizes, after-school tutoring, and summer school programs, enhances achievement gains (Roderick, Bryk, Jacob, Easton, & Allensworth, 1999) .\nState policy approaches to accountability tend to favor either a primary emphasis on input guarantees as a mechanism for achieving equal access to learning or a primary emphasis on performance guarantees (Elmore & Fuhrman, 1995) .7 The advocates of opportunity-to-learn (OTL) standards argue that every student must have equal access to high-quality learning by specifying key inputs (per-pupil spending, textbooks, teacher training, and the like) in the form of binding standards. The achievement gaps among racial and socioeconomic groups were found to be relatively small in states with more equitable distribution of school resources and classroom OTL Impact ofAccountability on Racial and Socioeconomic Equity (Wong & Lee, 1998) . In contrast, the critics of OTL standards argue that input standards of any kind create constraints on how educators respond to the leamning problems of students. While the critics argue that holding schools and students accountable for performance creates incentives for schools to find out which practices work most effectively, there is no guarantee that performance measures automatically lead to increased equality in the distribution of student leaming (O'Day & Smith, 1993) .\nIndeed, the two approaches are not mutually exclusive, and combining them can be the most successful path. Bartman (2002) argued that most successful refonns have relied on assessments, disaggregating data by race, and investing in teacher training. Bartman observed that this kind of success can be seen in combined judicial and legislative efforts in Kentucky and Texas, which have been successful in increasing access to quality education for minority students. Valencia et al. (2004) also argued that to shift from an \"inputs-driven\" to a \"results-driven\" accountability model is misguided; rather, a tripartite structure with equal attention to input, process, and output is needed. Fiske and Ladd (2000) , in their analysis of the implementation of market-oriented educational reform in New Zealand, proposed that there is a need to delineate the linkages in a \"tight-loose-tight\" policy system.\nThis article examines whether states that attempted to hold schools, teachers, and/or students accountable for academic performance (a perfonnancedriven approach) accomplished that goal, with or without fulfillment of their own responsibility to increase the availability of adequate resources overall and equalize the allocation of resources (an input-driven approach). More specifically, did strong performance-driven-accountability states in the 1990s provide support for school resources and address racial and socioeconomic disparities in access to resources? And were those strong accountability states, with or without such support, able to improve the achievement of disadvantaged minority students and narrow the achievement gaps during the 1990s? Figure 1 shows the analytical framework for this study. The broken arrows show hypothesized relationships among resources, achievement, and background variables that have been evidenced by previous studies.\n8 First, three key school resource variables (per-pupil expenditures, class size, and teacher quality) are expected to positively affect academic achievement (mathematics). Second, race and socioeconomic status (SES) variables are expected to affect both school resources and student achievement. In this study, the relationship between race/SES as independent variables and resources/achievement as dependent variables is examined at different levels: between-district disparities for per-pupil expenditures, between-school disparities for class size and in-field teaching, and between-student gaps for math achievement. These different levels of inequity for different outcomes simply reflect our analytical choices with available data sets, but they all converge to form a larger picture of statewide educational inequity.\nIn addition, the solid arrows in Figure 1 show hypothesized effects of state-level accountability policy on the distributions of school resources and math achievement. There are four effects (policy-outcome paths) of primary Perfornmance-driven approach interest to be tested at the state level under this framework. The four effects follow from the following two approaches:\n* Input-driven approach: Path A (policy effect on improving average school resources) + Path B (policy effect on reducing racial and socioeconomic disparities in resources). * Perforrnance-driven approacb: Path C (policy effect on improving average math achievement) + Path D (policy effect on narrowing racial and socioeconomic gaps in achievement).\nThese four effects can be classified by the nature of the outcome variables: effects on resources (A and B) and effects on math achievement (C and D). The same effects may also be classified into two different types by the nature of effects: average effects versus equity effects. Equity-related policy effects include effects on resource inequalities (B) and effects on achievement gaps (C). It is hypothesized that both effects A and B may not be significant if there were shifts of accountability policies in the 1990s, with their exclusive emphasis on performance outcomes and disregard of resource allocation issues. It is also hypothesized that effects C and D may be significant but marginal at best if there was a lack of support for school improvement and limited attention to achievement gap issues.\nThe time frame for these analyses is the 1990s, when changes in school resources and math achievement could have occurred as a result of state 802 Impact ofAccountability on Racial and Socioeconomic Equity accountability policy initiatives. Fifty states' accountability policies were measured with data from three surveys collected in 1996, 1999, and 2000. The 1996 policy survey is expected to capture state accountability policies enacted mostly during the first half of the 1990s. In addition, 1999 and 2000 surveys may pick up new developments in the second half of the 1990s. The schooling condition and student achievement measures are taken at least twice, presumably one prior to policy adoption and another after policy adoption. The time window for pretest measures of schooling conditions is 1988-1990; for posttest measures it is 1998-2000. The time window for math achievement measures is 1990-1992 for pretest and 2000 for posttest. The choice of pretest and posttest timing for outcome variables was made in relation to the time frame of accountability policy variables. However, looking for policy effects beyond the 1990s was also limited by the availability of data sources for outcome variables. There is some possibility that this study's analytical time frame may underestimate the policy effect if any states' policy effects occurred outside the study period, that is, before 1988-1990 or after 1998-2000 . Our choice of data sets for each policy and outcome measure is explained in the following section."}, {"section_title": "Data and Methods", "text": ""}, {"section_title": "State Policy Measures", "text": "This research investigates state accountability policies with survey data collected in the mid-to-late 1990s from three sources (see Appendix A): (a) 1995-1996 data from the North Central Regional Education Laboratory (NCREL) and the Council of Chief State School Officers (CCSSO) (NCREL/ CCSSO, 1996) ; (b) 1999 data from the Quality Counts (QC) report (\"Quality Counts '99,\" 1999); and (c) 1999-2000 data from the Consortium for Policy Research in Education (CPRE) report (Goertz & Duffy, 2001) .\nPolicy index scores were calculated for each state by summing the number of policies adopted and in place by the state at the time of survey. The NCREL/CCSSO policy index ranges from zero to 16 (M= 6.5, SD= 4.2) . The reliability of this 26-item 1995 NCREL/CCSSO accountability policy index is very high (alpha = .85). The QC policy index ranges from zero to 6 (M= 3.0, SD = 1.8). The reliability of this 6-item 1999 QC accountability policy index is high (alpha = .77). Finally, the CPRE policy index was constructed by Camoy and Loeb (2002) and it ranges from zero to 5 (M= 2.1, SD= 1.4). The CPRE policy index was more interpretive in nature since it used subjective criteria; interrater reliability was reported to be high (Carnoy & Loeb, 2002) .\nOut of these three related policy measures, we created a composite factor of state activism in accountability policy during the 1990s. 9 This factor analysis classified 50 states into three groups: those with strong accountability systems (12 states in the top quartile), those with moderate accountability systems (25 states in the middle half), and states with weak accountability systems (13 states in the bottom quartile "}, {"section_title": "School Resource Measures", "text": "This research created three key measures of school resources-per-pupil expenditures, class size, and in-field teaching-and examined the status of and changes in the levels and distributions of those measures (see Appendix B). Per-pupil expenditure data was collected and analyzed from the 1990 and 1998 Common Core of Data (CCD) with the School District Finance Survey (F-33). Both class size and teacher qualification data were collected from the 1988 and 2000 Schools and Staffing Survey (SASS). The CCD and F-33 data sets provide a census of all school districts in every state, while the SASS provides a representative sample of public schools and teachers in every state. Since we wanted to examine changes in the distribution of school resources throughout the 1990s, we selected the earliest and latest available data sets for each outcome variable within that time frame.\nTo examine the relationship of school resources with accountability policy and math achievement at the state level, we also created a composite factor of school resources, combining the above three types of measures at the aggregate state level.\n10 This school resources factor is not correlated with the accountability policy factor (r = -.03), implying that state activism in accountability has nothing to do with the level of school support. This factor analysis also classified 50 states into three groups: high support (top quartile), medium support (middle half), and low support (bottom quartile)."}, {"section_title": "Mathematics Achievement Measures", "text": "We chose to focus on one subject area, mathematics, for the analysis of student achievement outcome for several reasons: (a) mathematics is one of the core subjects on which state education reform has focused during the 1990s; (b) mathematics achievement is more likely to be influenced by schooling environment; and (c) the earliest NAEP state assessment data is available in mathematics. Data from the 1990, 1992, 1996 , and 2000 NAEP State Assessment in eighth-grade mathematics were analyzed to show the relationship between state accountability policies and changes in student achievement.'\"\nTo analyze the racial achievement gap on NAEP mathematics assessment, the achievement of Black and Hispanic students was compared with the achievement of White students. Although the NAEP data set includes Asian and Native Americans as well, our study focuses on the achievement of Blacks and Hispanics relative to their White counterparts. To analyze the socioeconomic achievement gap, comparisons were made with three SES background variables: availability of reading materials, eligibility for free"}, {"section_title": "Impact of Accountability on Racial and Socioeconomic Equity", "text": "or reduced-price lunch, and level of parental education. The school lunch variable became available in 1996 in the NAEP and thus was not used in previous years."}, {"section_title": "Multilevel Analyses of Policy Effects on Resources and Achievement", "text": "Relationships among the measures of accountability policies, school resources, and math achievement were examined through correlation and regression analyses. Simple correlation analyses were conducted to look at the association of state activism in accountability policy with school resources and math achievement. These correlation analyses were done with aggregate measures of resources and achievement outcomes at the state level. Building on the results of correlation analyses, multilevel, multiple regression analyses were conducted with appropriate statistical controls for confounding variables and holding constant initial differences prior to policy adoption. Hierarchical linear models (HLM) were used to examine interstate variations in the racial and socioeconomic distributions of school resources and math achievement over the last decade (see Raudenbush & Biyk, 2002) .\nAs shown in our analytical framework in Figure 1 , we attempted to test four major policy effects: improving average school resources (A); reducing racial and socioeconomic disparities in those resources (B); improving average math achievement (C); and narTowing racial and socioeconomic gaps in math achievement (D). These hypothesized policy effects were explored through HLM analyses; equity-related policy effects were tested through cross-level interactions between race/SES and accountability policy variables.\nSince there were four outcome variables (school funding, class size, infield teaching, and math achievement), we ran 2-level HLM analyses separately for each outcome variable (see Appendix C for model specifications). At Level 1 (district, teacher, or student level, depending on outcome variable), racial and socioeconomic background characteristics were used as predictors of a given outcome variable. These estimated racial and socioeconomic effects on outcome variables were assumed to vary randomly among states. At Level 2 (the state level), state activism in accountability policy was used as one of the major predictors to account for these interstate variations. All Level-2 predictors, including the accountability policy variable, were centered and standardized (M = 0, SD = 1), and semi-standardized Level-2 coefficients were reported for effect sizes. Of particular interest were the cross-level interaction effects of accountability policy and race/SES on resource disparities and achievement gaps."}, {"section_title": "Analytical Issues and Strategies", "text": ""}, {"section_title": "Classification of Strong and Weak Accountability", "text": "Since our classification and labeling of \"strong\" and \"weak\" accountability states was created in a purely relative sense, with reference to the distribution of actual state policy measures, a more meaningful comparison of the Lee & Wong two groups of states would need substantive definition of strong accountability states and descriptions of their actual adopted policies. It is possible that even the strongest accountability system in the distribution might be fairly weak when we consider what the hypothetical ends of an accountability continuum might be. Strong accountability systems are often defined as those in which states have in place and can use all of the following policy instruments: report cards and ratings of schools, rewards for successful schools, and reconstitution or major alteration of failing schools (see Finn & Kanstoroom, 2001; Walberg, 2003) . What is missing in this definition of strong accountability is adequate assistance and support to schools-the key component of shared responsibility. Our norm-referenced classification of strong and weak accountability turns out to be largely consistent with this sort of criterion-referenced classification by Finn and Kanstoroom (2001) . States that have different classifications are Louisiana and New Jersey (classified as weak accountability by Finn & Kanstoroom) .1 2 Figure 2 shows the percentages of states in our strong-versus-weak accountability categories that had adopted selected accountability policies as of 1999. Although most weak accountability states also had state assessment, and some even had report cards for schools, none of them provided direct incentives to schools in the form of performance ratings, rewards, assistance, and sanctions. In contrast, most strong accountability states turned out to have these key elements of accountability policy in place. Some states in the "}, {"section_title": "I E Strong E Weak", "text": "Impact ofAccountability on Racial and Socioeconomic Equity top quartile of our accountability scale did not adopt all major policies. If strong accountability states are expected to have all of these in place to maximize policy effects, then only five states would meet that expectation. All of the statistical analyses, including correlations and regressions reported in this article, used the original policy index score or composite factor score as a continuous variable. The dichotomous grouping of strong and weak accountability was used basically for illustrating the group mean differences on selected outcome variables."}, {"section_title": "Timing of Policy and Outcome Measures", "text": "Although accountability policy measures in this study indicate how strong or intense each state's accountability policies were at certain times, they may obscure differences between states that have had the same accountability policies in place for a while and states that joined the policy bandwagon more recently. The three policy surveys that were used simply reported whether given policies were in place at the time of survey, but there was no information on when the states adopted accountability policies and when they began to implement them. To gather this information, we conducted our own survey of 50 states' educational accountability or assessment offices (Lee, 2002b) . The results showed variations among states in the timing of accountability policy initiatives and variations among different types of policies within the same state (e.g., student accountability versus school accountability policies). Among the policies examined, it was found that student accountability (high school exit exam) has the longest history, dating back to the minimum competency testing era in the 1970s and 1980s. Among school accountability policies, school performance reporting tends to be relatively old. For example, Texas began school performance reporting in the 1980s, and North Carolina began the practice in the 1970s. For school awards and recognition, policy implementation began mostly in the 1990s, with variation from state to state (e.g., 1990 in Texas, 1993 in Illinois, 1996 in Maryland, 2000 . Accountability policies that have more serious consequences for schools, such as probation and school takeover, are a relatively recent phenomenon dating to the mid-1990s (e.g., 1993 in Maryland and Texas, 1995 in Alabama, 1996 in North Carolina, 2000 .\nThere are also some caveats regarding interpretation of the results because of the timing of policy variables. One might expect that early states in accountability reforms would have greater impact than later states, because longer experience may facilitate policy implementation through mutual adjustment and midcourse corrections. If early and late policies have different effects on the outcomes, then the coefficients for the accountability measure can be downwardly biased. Moreover, policy effects may take a long time to materialize locally, and it may be unrealistic to expect to find mid-to-late 1990s policies generating results by 2000. It should be noted that the mid-to-late 1990s is the time frame of the survey, but in most cases actual policy adoption could have occurred before the survey period. As our own survey shows,"}, {"section_title": "807", "text": "lee & Wong some states adopted the policies in the early 1990s. Moreover, policy effects may occur simply with the threat of sanctions or the prospect of rewards, even before actual consequences may apply to failing or successful schools. Therefore, it is not totally unreasonable to include and explore the effects of policies adopted during late 1990s by assuming that policy effects may occur immediately after policy adoption or before policy is fully implemented. To address this timing issue, we conducted supplementary HLM analyses using early and late policy measures separately for possible comparison of their effects; this was done in addition to using the composite factor of early and late policy measures for exploration of cumulative policy effects."}, {"section_title": "Influences of Extraneous Variables", "text": "Strong accountability states are likely to be different from weak accountability states in terms of their demographic composition of student population, particularly racial and socioeconomic characteristics that might have resulted in different outcomes. Any causal inferences drawn from our analyses of policy effects are not warranted because of the possibility of extraneous variables that may confound our results. Prior to their policy adoption, strong accountability states tended to have poorer student outcomes. The initially lower achievement level of strong accountability states may be explained by the fact that they had larger minority populations and relatively unfavorable social and family conditions for children's education, as shown in their lower median household income and lower educational attainment among the total population. Variables including the proportions of Black and Hispanic populations, educational attainment levels, and poverty rates are controlled for when we look at the policy effects.\nA related critical question is whether accountability policy contributes to the widening or narrowing of racial and socioeconomic gaps, or whether the change in racial and socioeconomic gaps reflects a process already in motion prior to policy adoption. Despite their lower average achievement status, strong accountability states did not have significantly larger or smaller achievement gaps prior to policy adoption. The correlations of accountability policy with the gap between Whites and Hispanics and the gap between Whites and Blacks were very weak. Likewise, accountability policy is not significantly related with the achievement gaps among groups of students whose parents have a different level of education as well as the gap between poor students (eligible for free or reduced-price lunch) and non-poor (ineligible) students. Strong accountability states also had a highly equivalent degree of school funding disparities among districts. Likewise, strong accountability states were not different from weak ones in terms of racial and socioeconomic gaps in class size and in-field teaching rate. These results indicate that strong accountability states were neither better nor worse in schooling conditions and student outcomes with regard to racial and socioeconomic equity prior to policy adoption, and that the possible threat of changes due to a regressionto-the-mean artifact is not serious."}, {"section_title": "808", "text": ""}, {"section_title": "Impact ofAccountability on Racial and Socioeconomic Equity", "text": "Finally, statewide, standards-based, systemic education reform efforts may also confound the effects of accountability policies. The development of curriculum standards, curriculum-assessment alignment, teacher certification standards, and professional development efforts constitute a broader context of standards-based (content-driven) education reform in which accountability policies may have been embedded. Such measures of standards-based education reform were constructed earlier by Lee (1997) and by Swanson and Stevenson (2002) . These standards-based reform policy measures had moderate correlations with our accountability policy measures. Therefore, an attempt was made to sort out the effect of accountability by controlling for related policy covariates in the HLM analyses.\nperiod in terms of overall in-field teaching and the effects of school poverty and racial compositions on in-field teaching\nshows that there was no discernable negative effect of accountability on minority or low-income students' achievement and that accountability did not widen their achievement gaps. This can be good news in light of many concerns raised about potentially negative effects of accountability on equity. However, pointing out the fact is not a compliment to states; rather, it is a challenge, given the fact that existing educational resource disparities remain significant and the resulting achievement gaps are unacceptably large.\nIt appears that state activism in accountability policy did not bring about any significant improvements in key educational resources, including perpupil expenditures, class size, and qualified teachers. Although improving the adequacy or equity of educational resources was not at all the goal of external accountability policy, it was expected that states would play a stronger role in giving all schools and students adequate and fair support commensurate with the enormous pressure and uneven threats that the policy change involved. While accountability policy did not hurt adequacy or equity in schooling conditions, very limited progress was reported. Furthermore, state activism in accountability policy did not bring significant changes in the distribution of student achievement outcomes. Although there is some indication that strong accountability states improved the achievement of Hispanic students during the late 1990s, once we control for the effect of socioeconomic status, there is no evidence for such improvement.\nAlthough our study found no evidence that accountability policy brings about any significant progress or setback toward equity in educational resources and student outcomes, the policy's long-term effect remains to be examined. The long-term effect of accountability on equity may be different from its short-term effect. Our study focused on changes throughout the 1990s, but some policies may still be too recent to have taken effect. Student accountability polices may have more immediate impact, such as making academic promotion or graduation dependent on test performance. School accountability policies may take longer. States' reports on school performance may not translate immediately into real sanctions. Rather, there may be sanctions after 3-5 years of failing performance. In other words, accountability systems vary in the actual and immediate application of \"high stakes\" measures. Systems designed for long-term purposes would not be likely to show effects in our study.\nThe findings of our study have implications for the design and implementation of accountability policy to improve both academic excellence and equity. The research findings inform us that the accountability policy of the 1990s added another layer of fiscally neutral regulation to the existing input regulations with no added support. State activism in adopting high-stakes testing policies was not related to changes in the racial and socioeconomic achievement gaps or to changes in the equality of resource allocations. In the midst of growing national concems and policy efforts to close the achievement gap, the study makes us more aware of stagnancy in the progress toward racial and socioeconomic equity and the limitations of past accountability policy to address this problem. This study is limited by its aim of linking state policy (policy adoption at the state level rather than attempts at policy implementation at the district and school levels) with changes in the achievement gap. Our evidence from large-scale data analyses with primary focus on the state-level comparison of policy effects needs to be balanced with findings from the case studies of policy implementation and outcomes at the district, school, and classroom levels. To fill the chasm between what transpires at the state level and what ultimately takes shape as achievement gaps at the student level, subsequent research needs to take into account key school and classroom factors that can influence such multilevel policy-outcome linkages. Particularly, the interaction of accountability policy and school support is of interest and needs further investigation.\nFindings from this study of state accountability policy from experiences in the 1990s may not be directly applicable to the present and future because of dramatic changes brought by the NCLB of 2001. The results might have been different if schools had, in the past, faced the stronger federal incentives embodied in the NCLB (in addition to pressure from states only). Greater progress toward equity might have occurred if the past state accountability had been aimed at closing the achievement gaps among different racial and socioeconomic groups of students. Moreover, the results might have been quite different if the performance standard used in the past had been significantly higher or lower than the current performance standard adopted under new testing systems in many states. Nevertheless, the bottomline issue remains germane. Current accountability policies should maintain a proper balance between pressure and needed support if they are to successfully address inequity. Racial and socioeconomic equity should be at the center of accountability reforms. Because the NCLB requires reporting disaggregated achievement data by racial and socioeconomic subgroups, it is equally critical to do the same for schooling resources.1 5 APPENDIX A\n(%Hispanic)j is the percentage of Hispanic students in state j.\n( 0 /oPoverty)j is the percentage of students in poverty in state j.\n(%HS Graduate)j is the percentage of high school graduates in the adult population in the state j.\nclimate (\"Quality Counts '99,\" 1999) . Moreover, racial and socioeconomic disparities among schools in their key resources were not reported. This implies that the adequacy and equality of educational resources and opportunities were not considered in evaluating school performance for accountability. "}, {"section_title": "Results", "text": ""}, {"section_title": "Effects of Accountability Policies on Per-Pupil Expenditures", "text": "Nationally, per-pupil education expenditures increased little over the past 10 years: The U.S. average annual rate of increase in per-pupil expenditures, adjusted for inflation (1991) (1992) (1993) (1994) (1995) (1996) (1997) (1998) (1999) (2000) (2001) , was only 1.1%. Variation among states in this expenditure gain rate ranges from -.8% to 3.2%. While the overall increase was very marginal, some states increased education spending significantly more than others (Wong & Shen, 2001) . In fact, the small gain in school funding was attributable to a limited increase in a state's own efforts to improve school resources. Between 1992 and 2000, the state share of education funding increased about 5% on average, varying among states from -7% to 48%. States' targeting of funds to poor districts also varies among states, and change in this targeting score between 1992 and 2000 ranges from -0.42 to 0.91 (more negative numbers indicate greater progress in targeting poor districts).' 3 The correlations were very low between states' activism in accountability policies and states' school funding improvement or equalization efforts over the last decade (see Table 1 ). Increases in the state share of funding tended to be even somewhat lower among strong accountability states.\nFurthermore, an analysis of variation in the adjusted per-pupil education expenditures among districts within states shows that school districts that are relatively poorer and have larger proportions of Black or Hispanic students in the population tend to spend less on education. However, school funding also tended to increase relatively more among those high-poverty and predominantly minority districts over the 1990-1998 period. While this pattern is observed in both strong and weak accountability states, the coinparison also shows that the disadvantaged, predominantly minority districts in weak accountability states gained more state funding than those in strong accountability states. Indeed, strong accountability states hardly increased funding above the baseline year status on average. Once we control for the states' racial and socioeconomic composition of students and their initial level of per-pupil expenditures, the observed differences between strong and weak accountability states turns out to be insignificant. The results of the HLM analysis of 1990-1998 gains in school funding are shown in Table 2 . Although there was very little increase in adjusted current per-pupil education expenditures across the nation during this time period, school districts that initially had a relatively lower level of funding tended to gain more (lO = -. 37). At the same time, school funding increased significantly more among poorer school districts (P 20 = 11.68), but less among districts with predominantly Hispanic students (300 = -4.62). The HLM analysis also shows that any changes in school funding were not significantly related to state activism in performance-driven accountability policies. Relatively strong accountability states that were about one standard deviation above the mean accountability gained $253 less than relatively weak accountability states, which were about one standard deviation below the mean (2 Po = -253.16). However, there were no substantial differences between strong and weak accountability states in terms of their equalization of school funding."}, {"section_title": "Effects of Accountability Policies on Class Size", "text": "From 1990 to 2000, the average pupil-teacher ratio in the United States decreased by only 1.2. Among states, the change in the pupil-teacher ratio ranged from -4.5 to 1.4. The change in the pupil-teacher ratio was not associated with state activism in accountability policies; the correlations were very low at the state level (see Table 1 ). At the same time, the average class size for teachers in self-contained elementary classes was also reduced marginally: The average class size was 24.2 in 1991 and 21.2 in 2000.\nThe results of the HLM analysis of 1988-2000 class size data are shown in Table 3 . The average class size tended to be relatively larger in predominantly Black schools (120 = .09), and this gap increased somewhat over the period (060 = .04). In contrast, the average class size was relatively smaller in poorer schools (l3o = -.03), and this trend persisted further over the same period (P5I = -.05). It appears that relatively strong accountability states, one SD above the mean, barely had larger class sizes than their weak counterparts (2 Po, = .52). The HLM analysis reveals that there were no significant differences between strong and weak accountability states in terms of changes in average class size and racial and socioeconomic distributions of class size over the 1988-2000 period."}, {"section_title": "Effects of Accountability Policies on In-Field Teaching", "text": "The rate of in-field teaching-the percentage of teachers with an undergraduate or graduate major and subject matter certification in the subject they teach-also increased marginally between 1988 and 2000 (National Center for Education Statistics, 2002) . In middle-level education, the rate remained largely unchanged (31.2 to 33.2 in math and 44.4 to 44.5 in English). At the high school level, the increase was marginal, 73.7 to 75.6 in English, 70.4 to 73.1 in mathematics. At the state level, the gain in in-field teaching rate was barely associated with state activism in accountability policies; the correlation tended to increase with relatively more recent policy measures (see Table 1 ).\nThe results of the HLM analysis of 1988-2000 in-field teaching data are shown in Table 4 . As can be seen in the table, there were some in-field teaching gaps related to the poverty level of schools. Teachers in schools with a relatively larger percentage of students who were eligible for free or reducedprice lunch tended to be less qualified for teaching the subjects of main assignment (fl 3 = -.012). Once school poverty was controlled for, there were no significant racial gaps among schools in in-field teaching rate. While the in-field teaching rate increased over the period (P40 = .32), there were no significant changes in the racial and socioeconomic distributions of qualified teachers. The HLM analysis also shows that there were no significant differences between weak and strong accountability states over the 1988-2000 Note. Standard errors for coefficients appear in parentheses. Model (1) includes only Level-1 predictors without any Level-2 predictors. Model (2) adds accountability policy as a Level-2 predictor, along with other possible confounding state-level variables. Model (2) shows the partial effect of accountability policy after controlling for its correlates, induding state activism in standards-based (content-driven) reform, racial and socioeconomic characteristics of the state populations, and the initial status of corresponding outcome variables. Coefficients for these policy correlates are not reported herein because they were used primarily for statistical control purposes. The data are from the 1988 and 2000 Schools and Staffing Survey, National Center for Education Statistics.\n.. p < .01. *** p < .001. Note. Standard errors for coefficients appear in parentheses. Model (1) includes only Level-I predictors without any Level-2 predictors. Model (2) adds accountability policy as a Level-2 predictor, along with other possible confounding state-level variables. Model (2) shows the partial effect of accountability policy after controlling for its correlates, including state activism in standards-based (content-driven) reform, racial and socioeconomic characteristics of the state populations, and the initial status of corresponding outcome variables. Coefficients for these policy correlates are not reported herein because they were used primarily for statistical control purposes. The data are from the 1988 and 2000 Schools and Staffing Survey, National Center for Education Statistics. *** p < .001."}, {"section_title": "Effects of Accountability Policies and School Resources on Math Achievement", "text": "Nationally, Black-White math achievement gaps have remained the same over the past decade. The average Black-White test score gap for eighth graders increased from 32.9 in 1990 to 39.1 in 2000, but that increase was not statistically significant. The average Black-White gap for fourth graders was Although the racial achievement gaps did not significantly change in most states over the 1990-2000 period, there were some variations among states. For example, the amount of change in states' 1990-2000 Black-White eighthgrade math test score gaps ranges from -5.9 to 9.4 (M= 2.4 SD = 4.8), and Hispanic-White eighth-grade math test score gaps ranges from -21.4 to 5.6 (M = -3.0, SD = 6.8). Very little of this variation seems to be explained by state activism in accountability policies, as is shown consistently by low correlations in Table 1 and similar racial achievement gap trajectories between strong and weak accountability states in Figures 3 and 4 . There were some indications from the analysis of correlations and trend patterns that the math achievement gaps between Hispanics and Whites may have narrowed more in strong accountability states. However, that relationship turned out to be very tenuous in the HLM analysis, which took into account states' demographic factors and other policy correlates.\nNationally, the achievement gap in NAEP eighth-grade math between students who have no reading material at home and those who have 3-4 types of reading material at home (such as newspaper, encyclopedia, magazines, and more than 25 books) remained unchanged: The gap was 28 in 1990 to 27 in 2000. Likewise, the achievement gap in NAEP eighth-grade math between students whose parents did not graduate from high school those whose parents graduated from college did not change: The gap was 33 in 1990 and 31 in 2000. Finally, the achievement gap between students who were eligible for free or reduced-price lunch and those who were not also remained unchanged in the late 1990s: 27.2 in 1996 and 29.5 in 2000. There were variations among states in the amount of change in the gap between students whose parents did not graduate from high school and students whose parents graduated from college (M = 1.4, SD= 4.2) and in the gap between students who were eligible for free or reduced-priced lunch and those who were not eligible (M= 0.8, SD = 4.0). As with racial achievement gaps, the socioeconomic achievement gaps were very weakly related to state activism in accountability policies (see Table 1 ). HLM analysis was conducted to test the effects of accountability policies on racial and socioeconomic achievement gaps simultaneously. Table 5 shows the results of the HLM analysis of 1992-2000 eighth-grade mathematics achievement. There were significant racial and socioeconomic achievement gaps in 1992 (31o = 7.70, 320 = 5.73, 30 = -29.32, f40 = -24.87), and those gaps did not change significantly across states over time by 2000 (160 = .02, 70 = .02, o80 -.04, P9o = .30). Analysis of random effects showed significant interstate variations both in initial status and in changes in those achievement gaps. By and large, state activism in accountability policies was not significandy related to the initial status and changes of racial and socioeconomic gaps. The only exception was a change in the parental education effect for which the semi-standardized coefficient of accountability policy (161) was -.12. This implies that the math test score gaps among students whose parents had different levels of education may have narrowed about 2.4 points more over the past decade in the states scoring one SD above the mean of account- ability policy than in the states scoring one SD below the mean, 10 (2 161) 2.4. Although this difference was statistically significant at the .05 level, it was practically too small, considering the fact that the SD of the NAEP test scores was about 35. At the same time, the average math achievement of all eighth graders increased significantly over the 1992-2000 period across states, and the average amount of gain per year was slightly less than one point (P50 = .81). The size of the math achievement gain varied significantly among states, and it was significantly positively related to state activism in accountability policies (P51 = .63). If the average gain is .81, and states with strong accountability gain .63 more than an average state, that suggests that the average student in a strong accountability state is gaining eight times as much as a student in a weak accountability state: 1.44 for a strong accountability state, one SD above the mean accountability score (.81 + .63 = 1.44), as opposed to .18 for a weak accountability state, one SD below the mean (.81 -.63 = .18). The (2) shows the partial effect of accountability policy after controlling for its correlates, including state activism in standards-based (content-driven) reform, racial and socioeconomic characteristics of the state populations, and the initial status of corresponding outcome variables. Coefficients for these policy correlates are not reported herein because they were used primarily for statistical control purposes. The data are from the National Center for Education Statistics, 1992 Statistics, , 1996 , and 2000 National Assessment of Educational Progress, state assessments of eighth-grade math. ** p < .01. *** p < .001."}, {"section_title": "50-", "text": "expected amount of difference in total gain between strong and weak accountability states over the last decade would amount to 12 points. Although this estimate of the cumulative accountability policy effect has a practical import (about a third of a standard deviation in the NAEP math scores), it remains subject to change. The policy effect turned out to be statistically insignificant when we ran the HLM analysis replacing the composite policy factor score (a combination of the 1996 NCREL/CCSSO, the 1999 Quality Counts, and the 2000 CPRE policy indexes) with the earliest policy index (1996 NCREL/CCSSO). Moreover, there were possible unknown cohort differences between the NAEP assessment years that may have confounded the results on policy effect. The effect of accountability also turned out to be insignificant in quasi-longitudinal analysis of the same cohort group's math achievement gain: (a) the gain from 1992 fourth grade to 1996 eighth grade, and (b) the gain from 1996 fourth grade to 2000 eighth grade. Therefore, further investigations are needed for an attribution of math achievement gain to accountability policy. On the other hand, states' average math achievement is significantly associated with school resources (o02 = 1.86). The school resources variable was the composite factor of three key resource variables: per-pupil expenditures, class size, and in-field teaching at the state level. If states were classified into three groups based on this factor score (high, medium, and low support for schooling), an increase of two standard deviations in the school resources measure, which is equivalent to moving from low to high support status, would bring about a 3.8 point increase in math achievement. The gain of 3.8 is about a ninth of a standard deviation in the NAEP math scores. Although school resources were weakly related to achievement gain (352 = .24), further investigation is needed to determine whether and how the level of school support facilitates the accountability policy impact. Finally, school resources had a significantly positive effect on the change in the Hispanic-White achievement gap (192 = .37 ). This coefficient implies that the Hispanic-White math test score gaps narrowed about 7.4 points more over the past 10 years in high support states than in low support states, 10 (2 192) = 7.4 14"}, {"section_title": "Conclusion", "text": "Our study focused on extemal, performance-driven accountability that relies on state-imposed high-stakes testing along with the use of rewards and sanctions based on test results as indicators of student, teacher, or school performance. Although this type of accountability has been popular among states during the last decade and may become a national prototype of accountability in the advent of the NCLB, it is very limited in its nature and design and leaves many questions unresolved, particularly with regard to equity. Although accountability policies appear to have shifted to a performance-driven approach, their function has been largely \"regulatoly\" rather than \"supportive,\" relying more on mandates and sanctions than on capacity building and rewards. Accountability and systemic reform also tend to define support somewhat narTowly, focusing on technical assistance and professional development for curTiculum and instruction. Professional development and technical assistance can have greater effects when the resources and environment, including favorable class size and qualified teachers, are already adequate. Does accountability boost achievement for low-income, minority students and narrow their achievement gap? Our analysis of the 1990s data sets"}, {"section_title": "State Accountability Policy Surveys", "text": "The three policy surveys used in this study differ in terms of their coverage of accountability policy types. The NCREL/CCSSO survey is the most comprehensive and covers student assessments, student accountability (testing for promotion, awards/ recognition, and graduation), teacher accountability (certification gain/loss, financial rewards/penalties, probation), and school accountability (funding gain/loss, accreditation loss, awards/recognition, performance reporting, probation/waming, takeover/ dissolution). The QC survey covers only student assessments and school accountability (report cards, ratings, rewards, assistance and sanctions). The CPRE survey covers student assessments and student and school accountability policies (school/ district sanctions or rewards, high school exit test).\nHere are some sample questions and response options from the NCREL/ CCSSO survey:\n1. What uses are made of the results of the assessment for student accountability? (1) Student awards or recognition, (2) Promotion, (3) Honors diploma, (4) Endorsed diploma, (5) Graduation."}, {"section_title": "What uses are made of the results of the assessmentfor student accountability?", "text": "(1) School awards or recognition, (2) School performance reporting, (3) High school skills guarantee, (4) School accreditation.\n3. Does this assessment have consequences for schools? (1) Funding gain, "}, {"section_title": "APPENDIX B", "text": ""}, {"section_title": "Description of School Resources Variables", "text": ""}, {"section_title": "Per-Pupil Education Expenditures", "text": "A variable for per-pupil educational expenditures was constructed from the 1989-1990 and 1997-1998 F-33 data. The districts' per-pupil education expenditures were calculated with the following adjustments (\"Quality counts 2001,\" 2001): (a) adjusting each district's current expenditure for regional cost differences by using a \"geographic costof-education index\" retrieved from the NCES website (http. //wwvw.nces.ed.gov/edfin! prodsurv/data.asp) ; (b) estimating the number of poor students by multiplying the child-poverty rate by the district's fall enrollment; (c) adjusting the district's fall enrollment by multiplying the estimated number of poor students by 1.2 and the number of special education students by 2.3; and (d) dividing the district's adjusted current spending by its adjusted enrollment. Here the use of weighting in (c) recognizes that all students are not alike in their need for education. It is more costly to educate students with special needs, such as students living in poverty and students receiving special education. To devise an equitable weighting plan for need equalization, it is necessary to have an accurate determination of the program costs for special categories of students relative to the program costs for normal students (Guthrie, Garms, & Pierce, 1988) . As we do not yet have an agreed-upon weighting scheme, we rely on the weights used by the U.S. General Accounting Office analysis of school funding (U.S. General Accounting Office, 1997). The weight of 2.3 for special education students is based on the estimated ratio of educational costs for special needs as opposed to normal children. The weight of 1.2 for children in poverty stems from an estimate based on the average Title I allocation per student divided by average funding per student."}, {"section_title": "Class Size and In-Field Teaching", "text": "Variables for class size and in-field teaching were constructed from the 1987-1988 and 1999-2000 SASS public school teacher data. Class size was measured by averaging the number of students in all classes that each elementary or secondary public school teacher taught at the time of survey. In-field teaching was measured by whether public school teachers who taught Grades 7-12 in English, math, science, and social studies had an undergraduate or graduate major and a certificate in their main assignment field. For example, math teachers were classified as having a college or graduate major in the field if they reported having a degree in any one of these fields: mathematics, math education, physics, engineering, or statistics (see NCES, 2002 , for operational definitions of in-field teaching in other subject areas)."}, {"section_title": "APPENDIX C", "text": ""}, {"section_title": "Specification of the HLM Model", "text": "In this HLM analysis, we are interested in the effects of accountability policy on changes in schooling conditions and mathematics achievement for different racial and socioeconomic groups of students during the 1990s. We pose models below in which accountability policy is a predictor of several outcome variables."}, {"section_title": "Per-Pupil Expenditures", "text": "For the pooled HLM analysis of school funding data in 1990 and 1998 F-33, the sample size used was 9,646 school districts (Level 1) in 50 states (Level 2). The outcome variable was the 1990-1998 gain in adjusted current per-pupil education expenditures."}, {"section_title": "Level-i Model (District Level):", "text": "Yi! = sol + x 1 j (PPE90)%, + c 2 ,j (Poverty)Aj + iT 3 i (Black)II + it 4 l (Hispanic),, + eii Yij is 1990-1998 gain in adjusted current per-pupil education expenditures of district i in state j.\n(PPE90)ij is 1990 adjusted current per-pupil education expenditures of district i in state j.\n(Poverty)ij is 1990 percentage of children below poverty level in district i in state j.\n(Black)q, is 1990 percentage of Black children in district i in state j.\n(Hispanic)ij is 1990 percentage of Hispanic children in district i in state j.\ne,, is a Level-1 random effect that represents the deviation of district ij's adjusted per-pupil expenditures from the predicted value based on district-level model. ito 0 is state j's 1990-1998 funding gain, adjusted for baseline funding status, racial and socioeconomic compositions of the student population."}, {"section_title": "Level-2 Model (State Level):", "text": "x2j is the effect of district poverty on funding in state j.\nit 31 is the effect of district Black population on funding in state j. (Accountability)j is the measure of state j's activism in accountability policy during the 1990s (a composite factor score).\n(Standards)j is the measure of state j's activism in standards-based (content-driven) education reform as developed by Swanson and Stevenson (2002) .\n(%Black)j is the percentage of Black students in state j.\nPi (Accountability)j + jP2 (School Resources)j + p3 (Standards), + fp4 (%Black); + fP 5 (%Hispanic), + Pj6 (%Poverty)j + Ip7 (%HS Graduate)j + rpj where p = 0, . . ., 9\n(School Resources)j is the measure of state j's support for schooling resources (a composite factor score of per-pupil expenditures, class size, and in-field teaching).\nThe other state-level predictors are the same as the ones used earlier for per-pupil expenditures.\nNotes 'The new accountability policy tended to focus on schools rather than individuals. Between 1985 and 1995, the number of states that used student assessment results for school accountability (school awards/recognition, performance reporting, or accreditation) increased from 26 to 39. During the same period, the number of states that used the test results for student accountability (student awards/recognition, promotion, or graduation) increased slightly from 22 to 25 (Goertz, 1986; NCREL, 1996) .\n2 Unlike the state's own assessment, the NAEP state reading and mathematics results for Texas revealed that the achievement gaps between White and minority students did not narrow significantly during the last decade (Klein et al., 2003) . Even when some other states were cited as examples of successfully narrowing the racial and ethnic test score gaps on NAEP (see Haycock, Gerald, & Huang, 2001) , the reported gap reductions were restricted to a particular grade or subject for a limited time period and often were statistically insignificant.\n3 According to the \"Quality Counts 2001\" report (2001), 49 states had statewide academic standards, 50 states had statewide testing, and 27 states held schools accountable for results. Among the 27 states that held schools accountable, only 7 provided extra funding for all low-performing schools. Of the 18 states that required high school exit examinations at that time, only 9 were found to help subsidize remediation for failing students. Of the 42 states that provided some money for professional development, only 24 earmarked professional development funds specifically for every local school or district. For instance, a new state assessment in Arizona came without state support for teacher training, and ceding that responsibility to districts produced disparities in staff development (Smith, Heinecke, & Noble, 1999) . This kind of problem was also observed in some other countries where additional funding to support similar reforms in schools was limited and little attention was given to the reallocation of resources (Levin, 2001) . This implies that the accountability movement was not reciprocal. In other words, state legislators and state education agencies themselves were not accountable for providing needed support and assistance while holding schools accountable for the results. 4 This view of racism suggests that Americans will support policies (e.g., using standardized tests for retention) that are harmful to minorities but would not tolerate such policies if they were applied to majority populations (House, 1999) . Critical race theory and racial interest convergence theory, in particular, also suggest that White elites will tolerate or encourage racial advances for Blacks and other people of color only when they also promote White self-interest (see Bell, 1980; Delgado, 1995) . 5It was estimated that the cost of accountability, including paying for tests, publishing the results, and writing and publishing the standards by which the tests are graded, is about $5 per student on average (Hoxby, 2002) . In strong accountability states the costs tend to be higher because of more testing: The estimated cost of accountability was $18 per student in Kentucky and $20.30 in Texas. These estimates, however, included the costs of testing and reporting only-the most basic parts of an accountability system-ignoring the likely costs of identifying, monitoring, assisting, rewarding, and/or punishing the target population according to their test results and other related information.\n6Some studies gave indirect evidence of accountability policy in North Carolina and Texas by showing that the 1990-1996 NAEP gains cannot be explained by changes in levels or allocations of the major educational resource variables (Grissmer, Flanagan, Kawata, & Williamson, 2000; Grissmer & Flanagan, 2001 ). However, it was also noted that accountability policies were not fully in place until 1996, whereas the gains continued a pattemn that had begun before 1990 and could reflect the effects of educational resources and professional development invested in those states in earlier years (Darling-Hammond, 2000; Rothstein, 2001) .\n7Input-guarantee means not simply specifying key inputs (well-trained teachers and high-quality curricular materials) but also assuring that schools meet desired levels of such inputs. Likewise, performance-guarantee means not only monitoring student/school progress toward desired performance standards but also assuring that schools attain them through adequate incentives and support. Actual policies adopted by the states, however, appear to be closer to \"regulation\" than \"guarantee.\" 8The effects of school resources on academic achievement have been well demonstrated (see Finn & Achilles, 1990; Greenwald, Hedges, & Laine, 1996; Ferguson, 1991) . Studies also suggest that the effects of resources on achievement may be uneven because disadvantaged minority students may benefit more from school resources; for example, class size reduction helped to narrow the Black-White achievement gap in the past (Krueger & Whitmore, 2001) . At the same time, the effects of race and socioeconomic status (SES) on school resources were also evidenced by many studies on disparities in school funding and school and teacher qualities. Low-income and minority student receive fewer dollars for education (Brennan, 2002) . Instructional resources in predominantiy minority, high-poverty schools are less than adequate (Berne, 1994) . Black students tend to learn in larger classes than their White peers (Boozer & Rouse, 1995) . The more impoverished and racially isolated the school, the greater the likelihood that students in the school are taught by uncertified and out-of-field teachers (Darling-Hammond & Post, 2000; Hanushek, Kain, & Rivkin, 2001; Ingersoll, 1996; Lankford, Loeb, & Wyckoff, 2002) . 9 The 1995 NCREL/CCSSO policy index is moderately correlated with the other measures from more recent surveys of accountability policies, including the 2000 CPRE accountability index (r= .59) and the 1999 Quality Counts accountability index (r= .63). The correlation between the CPRE and QC policy indexes is similar (r= .61). Combining the three data sources may enhance the validity of policy measures and better capture any changes in accountability policy throughout the 1990s. One factor is retained through principal component analysis of the three state-level policy index variables with high factor loadings: the '95 NCREL/CCSSO policy index, .85; the '99 Quality Counts policy index, .87; and the 2000 CPRE policy index, .85. The factor has an eigen value of 2.2 and explains 74% of the combined variance.\n10 One factor is retained through principal component analysis of the three state-level school resource variables with moderate-to-high factor loadings: the 2000 state average class size, -.57; the 2000 state in-field teaching rate, .68; and the 2000 state average perpupil expenditures, .85. The factor has an eigen value of 1.5 and explains 50% of the combined variance.\n\"In 2000, students were assessed both with and without accommodations, and we used data from assessments in which accommodations were not permitted. Recent NAEP results from 2002 (reading) and 2003 (reading and math) permnit accommodations and do not enable direct comparison with earlier NAEP results from the 1990s that did not permit accommodations and thus excluded many students with disabilities and LEP. Therefore, the analysis of NAEP is restricted to the 1990-2000 period. The analysis of achievement gains over time is made through comparisons of successive cohort groups. Lagged policy effect is presumed: The effect on achievement of state accountability policies, if any, will be more evident in the latest state cohort group. Although high school data may better capture any effect of student accountability policies (e.g., high school exit exams) on achievement, eighth grade is the highest grade available in the NAEP state assessment. 1 2 According to Finn and Kanstoroom (2001) , some strong accountability states have shaky foundations or inferior academic standards. The Finn-Kanstoroom criteria (clear, measurable, comprehensive, and rigorous) for assessing the quality of curriculum standards may be debatable, but their relevance to assessing the impact of accountability on achievement outcomes remains to be examined. 13 The targeting score is derived by using multiple regression techniques to determine the extent to which district property wealth influences state aid, controlling for other factors that influence state funding, including student enrollment, physical size of districts, and the number of students in low-income families or in special education (see U.S. General Accounting Office, 1997).\n14 Since the racial gap was calculated and reported in negative numbers (i.e., Hispanic average score minus White average score), the positive effect of school support on this negative Hispanic-White math test score gap means that increased schooling support leads to an increase in Hispanics' achievement relative to Whites' (i.e., a narrowing of their achievement gap).\n' 5 Measures of schooling conditions and resources tend to be missing in the school report card. Among the 36 states that reported having an annual report card on each of its schools as of 1999, only half provided information on teachers, resources, and school"}, {"section_title": "824", "text": ""}, {"section_title": "Class Size", "text": "For the pooled HLM analysis of class size data in 1988 and 2000 SASS, the sample size used was 43,952 public school teachers (Level 1) in 50 states (Level 2). The data were weighted to represent the population of teachers within sampled states. The outcome variable was each teacher's average class size in a \"head count\" unit."}, {"section_title": "Level-1 Model (Teacher Level):", "text": "Yij = 7t 0 + Zji (Poverty)ij + it2j (Black)j 1 + i3j (Hispanic)ij + it4j (Time)ij + it 5 j (Time*Poverty)ij + 7t6j (Time*Black),j + iT7j (Time*Hispanic)ij + e, Yij is the average class size of teacher i in state j.\n(Poverty)j; is the percentage of students who are eligible for free/reduced-price lunch in teacher ij's school.\n(Black)jj is percentage of Black students in teacher ij's school.\n(Hispanic),j is percentage of Hispanic students in teacher ij's school. (Time*Poverty)jj is the product of (Time)ij and (Poverty)ij variables.\n(Time*Black)ij is the product of (Time),j and (Black)ij variables.\n(Time*Hispanic)ij is the product of (Time),j and (Hispanic)jj variables. eij is a Level-i random effect that represents the deviation of teacher qi's class size from the predicted size based on the teacher-level model. The state-level predictors are the same as the ones used for per-pupil expenditures."}, {"section_title": "Level-2 Model (State Level", "text": ")"}, {"section_title": "In-Field Teaching", "text": "For the pooled HLM analysis of teacher qualification data in 1988 and 2000 SASS, the sample size used was 22,771 public school teachers (Level 1) in 50 states (Level 2). Since the outcome variable was dichotomous (1 for in-field and 0 for out-of-field), a nonlinear HLM model was employed. Thus we have E (Yijlpij) = pii and Var (Yijlp,i) = pij (1 -p,), where pij is the underlying latent probability of in-field teaching. At Level 1, the log-odds of in-field teaching, r jj = log {p,, / (1 -p,g)}, is modeled as a linear function of the same set of variables for class size. Predictors at Level 2 for in-field teaching are also the same as ones used for class size."}, {"section_title": "Math Achievement", "text": "The sample size used for the pooled HLM analysis of math achievement in 1992, 1996, and 2000 NAEP was 198,587 public school eighth graders (Level 1) in 31 states (Level 2); those states participated in all three waves of the NAEP state assessment. The relation between individual student characteristics (race and SES variables) and achievement outcomes comprise the Level-I model; and the variation among states is represented in the Level-2 model. The Level-2 model includes the composite school resource factor variable as well as the composite accountability policy factor variable. The data were weighted at the student level to address disproportional sampling probability among students within each state. The outcome variables were five plausible values for each sampled student, resulting from five random draws from the conditional distribution of proficiency scores. The parameter estimates from the HLM analyses were based on the average parameter estimates from separate HLM analyses of the five plausible values."}, {"section_title": "level-1 Model (Student Level):", "text": "Y i j = 2 oj + m,l (Parental Education)ij + mT,j (Home Environment)ij + it 3 j (Black)j, + tC4j (Hispanic)jj + 7t5j (Time),j + IT6j (TimesParental Education) 1 , + tc7j (Time*Home Environment),j + 7t8j (Time*Black)ij + It 9 j (Time*Hispanic)ij + ej Yij is the mathematics achievement of student i in state j including five plausible values.\n(Parental Education),j is the level of student ij's parental education (1 for no high school; 2 for high school; 3 for some education after high school; 4 for college graduate).\n(Home Environment)jj is the availability of reading materials at student ij's home (1 for 0-2 types; 2 for 3 types; 3 for 4 types).\n(Black),j is an indicator of being Black for student ij's race (1 for Black; 0 for others).\n(Hispanic)jj is an indicator of being Hispanic for student ij's race (1 for Hispanic; 0 for others). (Time*X)ij is an interaction term to capture change in the effect of racial or socioeconomic background variable X, the product of (Time)ij and (X),j variables.\neij is a Level-I random effect that represents the deviation of student ij's math achievement from the predicted value based on student-level model."}]