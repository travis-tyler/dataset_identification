[{"section_title": "Abstract", "text": "Abstract The hippocampus has become the focus of research in several neurodegenerative disorders. Automatic segmentation of this structure from magnetic resonance (MR) imaging scans of the brain facilitates this work. Segmentation techniques must be evaluated using a dataset of MR images with accurate hippocampal outlines generated manually. Manual segmentation is not a trivial task. Lack of a unique segmentation protocol and poor image quality are only two factors that have confounded the consistency required for comparative study. We have developed a publicly available dataset of T1-weighted (T1W) MR images of epileptic and nonepileptic subjects along with their hippocampal outlines to provide a means of evaluation of segmentation techniques. This dataset contains 50 T1W MR images, 40 epileptic and ten nonepileptic. All images were manually segmented by a widely used protocol. Twenty five images were selected for training and were provided with hippocampal labels. Twenty five other images were provided without labels for testing algorithms. The users are allowed to evaluate their generated labels for the test images using 11 segmentation similarity metrics. Using this dataset, we evaluated two segmentation algorithms, Brain Parser and Classifier Fusion and Labeling (CFL), trained by the training set. For Brain Parser, an average Dice coefficient of 0.64 was obtained with the testing set. For CFL, this value was 0.75. Such findings indicate a need for further improvement of segmentation algorithms in order to enhance reliability."}, {"section_title": "Introduction", "text": "Both the natural process of aging and several neurodegenerative and lesional conditions affect the brain. The study of the shape and tissue characteristics of brain structures provides us with the means to monitor changes over time and to shed light on the nature of clinical progression. Magnetic resonance (MR) imaging is widely used as the medium of choice because of its resolution and the ability to assess the intrinsic nature of defined components. Select areas may be outlined on sequential images and studied by 3D segmentation. Manual segmentation, however, is both tedious and time-consuming; hence, automatic segmentation algorithms are preferred.\nNumerous automated segmentation techniques have been proposed. Comparison is difficult as each proposed technique uses its own unique algorithm upon a different set of images. On the other hand, the creation of individual sets of training and testing samples would burden the development of automatic techniques as it would require the outline of select structures and, moreover, consideration of the appearance of the site as it might be defined by contrast, signal-to-noise ratio (SNR) and head position.\nCommonly, analyses are performed on relatively few subjects and may be biased towards those upon whom it may be more suited.\nA publicly available online dataset of MR images with a sequential outline of a select structure such as the hippocampus would provide a validation tool for all segmentation algorithms for comparison. In this work, we have provided such a dataset of images and have used it to compare two published algorithms, Brain Parser (Tu et al. 2008) and Classifier Fusion and Labeling (CFL) (Aljabar et al. 2007) .\nVariations in the volume and architecture of the hippocampus have been observed in a variety of neurological disorders including schizophrenia (Lawrie and Abukmeil 1998) , epilepsy (Cendes et al. 1993 ) and Alzheimer's disease (Jack et al. 1992) . Manual outline of the hippocampus in standard T1-weighted (T1W) MR images is difficult and varies among publications (Geuze et al. 2005) . Two major factors are responsible for this variation:"}, {"section_title": "Manual Segmentation Protocol", "text": "The hippocampal border is not comprehensively defined in human brain atlases. The manual protocol for drawing the outline on MR images varies as a consequence. Reviews of current protocols provide an excellent overview of methodologies (Geuze et al. 2005; Konrad et al. 2009 ). Based upon such a comprehensive review (Geuze et al. 2005 ), a protocol for segmentation of the whole hippocampus was adopted for this study that provided clear guidelines for outlining the structure."}, {"section_title": "Image Quality", "text": "Lack of sufficient quality of the MR image will impede accurate definition of the hippocampal border and introduce subjectivity into the process once the protocol is fixed. Image quality depends on resolution (i.e., pixel size and slice thickness), contrast, SNR and is subject to motion artifact. When definition is not sufficiently clear, external landmarks are used although these may vary in location depending upon the angle between the hippocampal main axis and the imaging plane (Konrad et al. 2009) . A partial volume effect (PVE) adds further to the difficulty in low resolution images. This problem is pronounced in the hippocampal tail where the hippocampus curves medially with respect to the coronal plane and, in the hippocampal head where the hippocampus is convoluted and blends with the amygdala. Representative coronal slices of the hippocampal head with different resolutions and acquisition by two MR imaging scanners with field strengths of 1.5T and 3.0T illustrate the difficulties encountered in this location because of PVE (Fig. 1) . A similar problem can be illustrated in the same fashion with the hippocampal tail (Fig. 2) . The border between the hippocampal tail and pulvinar becomes indistinguishable rendering its definition highly subjective. The fimbria, the output tract of the hippocampus, is not very clear in low resolution images either. The temporal horn of the lateral ventricle and the gray matter may occasionally have similar intensities due to the PVE also.\nTo train an automated segmentation algorithm, a set of MR images with valid hippocampal outlines is required. Such a dataset must be publicly available and two brain MR image datasets with hippocampal outlines are currently provided: (i) the Internet Brain Segmentation Repository (IBSR, http://www.cma.mgh.harvard.edu/ibsr/) and (ii) the LONI Probabilistic Brain Atlas (LPBA40, http://www.loni. ucla.edu/Atlases/LPBA40/) (Shattuck et al. 2008) . The IBSR contains T1W MR images of 18 neurologically intact nonepileptic subjects with expert segmentation of 43 bilaterally defined structures including the hippocampi. The voxel size of these images is 0.84\u00d70.84\u00d71.5 mm 3 . The LPBA40 contains T1W MR images of 40 neurologically intact nonepileptic subjects with expert segmentation of 56 structures including the hippocampi. The voxel size of these images is 0.86\u00d70.86\u00d71.5 mm 3 . The Alzheimer's Disease Neuroimaging Initiative (ADNI, http://www.adniinfo.org/) is another source of hippocampal outlines, but the outlines have been generated semi-automatically using a software tool called SNT (Medtronic Surgical Navigation Technologies, Louisville, CO) and edited manually.\nBoth of the above datasets contain images of unaffected subjects. In practice, hippocampal segmentation may be problematic due to the shape changes caused by neurological disorders. For instance, in mesial temporal lobe a b epilepsy (mTLE), atrophy is often observed in the epileptogenic hippocampus. Automatic segmentation of an atrophic structure is a challenging task as its dimensions and shape will differ from those in the training images of nonepileptic subjects. Comparable images in a segmentation algorithm would provide useful indicators of the extent of change encountered both in regards to shape in different planes and overall volume. Other practical problems such as motion artifact and low SNR are issues that might be dealt with by more rigorous application of the actual imaging protocol. The IBSR dataset does include a few samples with motion artifact."}, {"section_title": "Amygdala", "text": ""}, {"section_title": "Hippocampus Hippocampus", "text": "The average hippocampal volume calculated from the IBSR label maps is significantly higher (left side 3,637 mm (Jafari-Khouzani et al. 2010 ). This appears attributable largely to the inclusion of white matter (i.e., alveus and fimbria) and neighboring nonhippocampal tissues in the IBSR segmentations. The alveus is a white matter tract containing axons from hippocampal and subicular neurons that enter the fimbria (Duvernoy 2005) . Figure 3a -b shows the coronal section of the hippocampal head in slice Number 65 of IBSR_07_ana. img in the IBSR dataset with the manual hippocampal segmentation provided by the IBSR. The alveus and part of the amygdala are included in the hippocampal segmentation. Figure 3c shows the outline that is used in the present scheme drawn with a thickness smaller than the pixel size to better identify the real boundary. The sectional anatomy of the hippocampal head in a similar slice provided by another source (Duvernoy 2005 ) is presented in Fig. 4 and illustrates a distinctive border between the hippocampus and amygdala. Unfortunately, because of a PVE, this distinction is not usually observed in standard T1W MR images.\nThe LPBA40 hippocampal segmentation protocol is significantly different from other protocols in the literature. Figure 5 shows the hippocampal outlines in representative slices of subject S01 from the LPBA40 dataset. The majority of the hippocampal tail is not included in the segmentation (Fig. 5a ), whereas part of the amygdala is included (Fig. 5b) . The average hippocampal volume calculated from the LPBA40 label maps are 4,120 mm 3 and 3,907 mm 3 for the left and right sides, respectively. Some researchers use their own segmented set of images to avoid these discrepancies but are unable to evaluate their algorithms against a separate set of images. Most are forced then to use different combinations of the available images as training and testing sets; hence, the reliability of their approach remains uncertain.\nIn this paper, we introduce a publicly available dataset of T1W MR images (http://www.radiologyresearch.org/ HippocampusSegmentationDatabase/) with hippocampal outlines for the validation of automated hippocampal segmentation algorithms. Advantages of this dataset include the following:\n1. Training and testing sets are separate. The researchers are encouraged to submit their segmentation results on the testing set to evaluate their algorithms. systems with different field strengths and thus have different resolutions and contrasts. Twenty of the images have a higher resolution and are acquired with a 3.0T MR imaging system. 3. Special care has been taken to minimize the PVE in the manual drawings. The sagittal view and neighboring coronal slices are used to reduce the segmentation inaccuracy due to the PVE. 4. Forty of the images belong to patients with medically intractable temporal lobe epilepsy. The hippocampal outline commonly differs in these circumstances making the segmentation challenging. This provision allows an evaluation of the proposed segmentation algorithm under practical considerations. Figure 6 shows the slices of a few samples from this dataset under various practical adversities such as atrophy, motion artifact, poor SNR, the presence of a lesion and field inhomogeneity. The latter confounds automated skull-stripping and co-registration."}, {"section_title": "Hippocampal tail", "text": "We have evaluated two segmentation algorithms, namely Brain Parser (Tu et al. 2008 ) and CFL (Aljabar et al. 2007 ), using the above dataset."}, {"section_title": "Materials and Methods", "text": ""}, {"section_title": "Subjects", "text": "Fifty subjects comprising 40 patients (13 males, 27 females) with mesial (m)TLE, age range 15-64, (39\u00b112, mean\u00b1SD) and ten nonepileptic subjects (five males, five females), age range 19-54 (34\u00b113) were included. A number of patients had hippocampal atrophy. The nonepileptic subjects were drawn from an archive of control subjects in a sleep research project. The 50 subjects were randomly selected and also reflect practical problems such as motion artifact, low SNR and head tilt."}, {"section_title": "MR Imaging", "text": "Thirty of the subjects, including 20 epilepsy patients and ten nonepileptic subjects, had their MR images acquired with a General Electric 1.5T Signa system (GE Medical Systems, Milwaukee WI). These subjects underwent coronal T1W MR study using a spoiled gradient-echo (SPGR) , matrix size \u00bc 256 \u00c2 256, pixel size \u00bc 0:78 \u00c2 0:78mm 2 , slice thickness= 2.00 mm \u00f0voxel size\u00bc0:78 \u00c2 0:78 \u00c2 2:00mm 3 \u00de, bandwidth= 25 KHz and scanning time of 5 min and 45 s. The remaining twenty subjects, all epilepsy patients, had their MR images acquired with a General Electric 3.0T system (GE Medical Systems, Milwaukee WI). These subjects underwent coronal T1W MR study using a SPGR sequence with TR/TE/TI= 10.4/4.5/300 ms, flip angle=15\u00b0, FOV \u00bc 200 \u00c2 200mm 2 , matrix size \u00bc 512 \u00c2 512, pixel size \u00bc 0:39 \u00c2 0:39mm 2 , slice thickness=2.00 mm \u00f0voxel size \u00bc 0:39 \u00c2 0:39 \u00c2 2:00mm 3 \u00de and scanning time of 6 min.\nThe images were converted to ANALYZE (Mayo Clinic Analyze 7.5) format. For privacy protection, all images were de-identified before conversion. Furthermore, the subject's face was manually removed from each image."}, {"section_title": "Segmentation Protocol", "text": "A single investigator (KJ) outlined all coronal hippocampal contours (usually 20 slices/case) using Eigentool, an inhouse software (http://www.radiologyresearch.org/eigentool. htm). These were then verified by two other investigators (KE and SP). All images were segmented in the coronal plane although the other two planes were used to help find landmarks. All outlines were converted to label maps in ANALYZE format.\nManual hippocampal segmentation protocols vary notably among investigators (Geuze et al. 2005; Konrad et al. 2009 ). Some protocols exclude the hippocampal tail or head. In others, the extent of inclusion of the hippocampal tail and head vary. The amygdalohippocampal complex may be measured as a single entity. The anatomical boundaries of the hippocampus vary among protocols. An inability to adequately distinguish the gray matter of the hippocampus from the neighboring cerebrospinal fluid of the temporal horn compromises even the delineation of its lateral border. Konrad et al. (2009) hippocampal outlines are provided in Fig. 7 . The alveus is used as a landmark separating the amygdala and hippocampus (Fig. 7d) . The amygdala and temporal horn of the lateral ventricle are not included in the segmentation whereas the subiculum is included. The most anterior coronal slice is taken where, in high quality images, the alveus is still detectable as the head of the hippocampus tapers below the amygdala. Otherwise, any remaining anterior boundary is estimated based on experience and with the help of the sagittal view. The hippocampal tail is included to the point where it narrows and curves medially towards the crus. The gray-white matter interface is used as the inferior and lateral border. This interface may become smooth in some slices due to the PVE. The sagittal view and neighboring coronal slices are used to reduce the segmentation inaccuracy attributable to the PVE. We also limited the use of arbitrary lines and, instead, estimated the hippocampal border using intensity information as well as neighboring slices in cases where the border was not clear. As outlines were drawn in the coronal plane, care was taken to avoid jagged boundaries in other views (Fig. 8) ."}, {"section_title": "Data Dissemination", "text": "Twenty-five sets of images consisting of 20 from epilepsy patients, ten taken with the 1.5T scanner and ten with the 3T scanner, and five from nonepileptic subjects were randomly selected as training samples and were provided with hippocampal label files. The remaining 25 sets of images, similar in distribution as that of the training set, were provided as testing samples but without label files. The users may use the training samples to train their algorithms, submit the outcome of their segmentation algorithms on the testing images and receive the results based on a number of metrics listed below."}, {"section_title": "Segmentation Metrics", "text": "Using a manually segmented image as our gold standard, an automatic segmentation may be evaluated by the calculation of segmentation similarity metrics. If X and Y represent the manual and automatic segmentation label sets, respec- \nis the Euclidian distance, and \u2202 is the boundary operator."}, {"section_title": "Hausdorff 95 distance d H95 (X,Y) is similar to d H (X,Y)", "text": "with the difference that 5% of the outliers are removed before calculation. R o o t M e a n S q u a r e D i s t a n c e :\nwhere |X| is the size of set X, D and increase with increasing quality of segmentation. For a perfect segmentation, metrics 1-5 equate to unity and metrics 6-11 equate to zero. Although there is redundancy among these outcome measures, the intent here is to provide a comprehensive listing of metrics from which authors may select those they feel to be most suitable for publication."}, {"section_title": "Reliability of Manual Segmentation", "text": "To test the reliability of manual segmentation, ten subjects were randomly selected from the entire group to undergo outlining of the hippocampus. Eight subjects were epileptic, four of whom were imaged with the 1.5T scanner and four with the 3T scanner. Two subjects who were not epileptic were imaged with the 1.5T scanner. In order to avoid reproducibility through familiarity with the initial exercise, 6 months were allowed to elapse before repetition by the same investigator (KJ). This experiment resulted in the following outcome metrics: Jaccard Index Testing Two Segmentation Algorithms\nWe tested two segmentation algorithms, namely Brain Parser (Tu et al. 2008 ) and CFL (Aljabar et al. 2007 ) using Fig. 8 Sagittal view of hippocampal outlines of three patients. As shown, jagged boundaries have been avoided. Grainy boundaries are attributed to a slice thickness that is larger than the pixel dimension the dataset. Both algorithms were trained by the training set and tested on the testing set."}, {"section_title": "Brain Parser", "text": "Brain Parser software (Tu et al. 2008 ) segments regions of interest based on a training set of data and generates label volumes. The software comes pretrained on a provided dataset but can be retrained to work with desired regions of interest. This software was trained using the training images put forward in the current work. One set of training images of good quality (HFH_021) was selected as a template to which all other training images were then coregistered using an affine transformation. Brain Extraction Tool (BET) (Smith 2002 ) was used for skull-stripping and FLIRT (Jenkinson and Smith 2001) for affine coregistration. For subjects with poor BET outcome, manual skull-stripping and correction was applied."}, {"section_title": "Classifier Fusion and Labeling (CFL)", "text": "In this method, multiple atlases were coregistered to the query image and their labels propagated to give a segmentation of the query image. The propagated labels were used as classifiers and combined to yield the label volume (Aljabar et al. 2007) . In this approach, all training images (i.e., atlases) were skull-stripped using BET and coregistered to a reference image, the MNI single subject image (Cocosco et al. 1997 ) with an affine transformation using FLIRT. The query image was also coregistered to the reference image using an affine transformation. Similarity between the coregistered atlases and the query image was calculated using normalized mutual information (Studholme et al. 1999 ) over the hippocampal region. The atlas images were ranked based on their similarity with the query image. The top-ranked 15 images were selected as classifiers and coregistered nonrigidly to the query image using a free-form deformation model (Rueckert et al. 1999) . The labels were then propagated from the selected classifiers to the query image and fused using the vote rule (Rohlfing et al. 2004 ).\nResults Table 1 shows the average evaluation metrics using both Brain Parser and CFL algorithms on the testing dataset. Using Brain Parser, the average Dice coefficient was 0.64 for the testing set while, for CFL, it increased to 0.75. Relatively high sensitivity with Brain Parser segmentation method indicates the likelihood that the automated versions enclose the manually segmented version. The actual hippocampal volumes determined by Brain Parser segmentation algorithm are indeed significantly higher compared to that obtained by manual segmentation (Table 2) . High specificity is due to the small size of the hippocampus compared to that of the whole image. Visual comparisons of hippocampal outlines achieved by automated methods and those manually generated illustrate the distinctions between the two (Fig. 9) . The coarse outline in both automated versions is due to reslicing of the images to a voxel size of 1 mm 3 before segmentation and mapping the generated labels back to the original images. Whereas distinct white matter borders, such as the alveus, were used in the manually segmented images to demarcate the hippocampal border, this was not the case for either Brain Parser or CFL. Both include the alveus in their outlines (Fig. 9d) . Neither of the automated segmentations appreciated the hippocampal folds which characteristically define its anterior appearance (Fig. 9c ). An accurate automated segmentation of the hippocampus in such locations is somewhat challenging due to the PVE.\nTo further study the capabilities of automated segmentation algorithms, several examples of hippocampal deformation were selected (Figs. 10, 11) . The presence of an extrinsic lesion, in particular, may be shown to produce sufficient local hippocampal distortion to significantly affect outcome using an automated approach (Fig. 10a) . This is made apparent in the case of both Brain Parser (Fig. 10c) and CFL (Fig. 10d) using such an example. Hippocampal deformation by an intrinsic anomaly seems equally likely to affect a poor outcome with either Brain Parser (Fig. 11c) or CFL (Fig. 11d) ."}, {"section_title": "Discussion", "text": "In addition to IBSR and LPBA40, there are other publicly available datasets for the validation of segmentation (Shen and Davatzikos 2002) and FreeSurfer (Fischl et al. 2002) , provide labels for multiple brain structures and the same might be provided here. An algorithm's performance may vary for different structures and the provision of corresponding manually segmented brain structures in the current dataset would be useful for the validation of automated segmentation algorithms of these structures. As the hippocampus has received the highest attention in the literature, we have provided a more comprehensive standard for this structure, in particular.\nIn the current dataset, the training and testing sets contain five nonepileptic subjects each. The subjects were scanned using a 1.5T MRI scanner with 0.78\u00d7 0.78\u00d72.00 mm 3 resolution. Populating the dataset with greater numbers of similar cases and with higher resolution studies would provide for increasingly more accurate human brain imaging atlases. Improvements in field The presence of an extrinsic lesion in the basal left temporal lobe has caused a poor automated segmentation outcome in both applications; even more, in the case of CFL strength of scanners with resultant higher image resolution would promote such development over time also. The time spent in the manual segmentation of greater numbers of available images would be rewarded by the improved boundary definition of individual structures. Public availability of a sufficiently large dataset of high resolution MR images will be the substrate upon which automated algorithms may reliably function with the extraction of optimal metrics. Automated segmentation algorithms are optimized for segmentation of a structure, such as the hippocampus, free of any local distortion by proximate or intrinsic lesions. Furthermore, the images have highly anisotropic voxels which makes segmentation even more challenging. The availability of a dataset that includes such structural anomalies and anisotropies provides a means for identifying such cases and establishing the extent to which any automated method is able to approximate the correct volume.\nAlthough a separate test set provides a means of comparing the applicability of algorithms using a challenging format, repeated uploading of results may bias the algorithms toward the test set. In other words, the test set becomes a means of training. This problem may be alleviated by providing a second set of test images for algorithms that have already been evaluated using the original test images. The users need only to submit their results once."}, {"section_title": "Conclusion", "text": "We have provided a publicly available MR image dataset of nonepileptic subjects and epilepsy patients with hippocampal outlines for validation of segmentation algorithms. The dataset was divided into training and testing sets. Only the hippocampal outlines of the training set are provided. Investigators may use the training images and their outlines to train their algorithms and then apply their algorithms to the testing set. The segmentation outcomes for the testing set may be submitted for evaluation based on 11 metrics. We evaluated Brain Parser and CFL segmentation algorithms using the dataset. The experiments suggest that the segmentation algorithms require modification in order to better accommodate structural deformation of the hippocampus under a variety of circumstances that befall patients with different neurological disorders."}, {"section_title": "Information Sharing Statement", "text": "The dataset is available at http://www.radiologyresearch. org/HippocampusSegmentationDatabase/. The users are required to register in order to log in and download the dataset. Information about how to submit the segmentation outcomes for the testing set and receive the table of metrics is available online."}]