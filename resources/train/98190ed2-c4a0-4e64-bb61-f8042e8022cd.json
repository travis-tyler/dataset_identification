[{"section_title": "Abstract", "text": "Abstract : Analysis of structural and functional connectivity (FC) of human brains is of pivotal importance for diagnosis of cognitive ability. The Human Connectome Project (HCP) provides an excellent source of neural data across different regions of interest (ROIs) of the living human brain. Individual specific data were available from an existing analysis (Dai et al., 2017) in the form of time varying covariance matrices representing the brain activity as the subjects perform a specific task. As a preliminary objective of studying the heterogeneity of brain connectomics across the population, we develop a probabilistic model for a sample of covariance matrices using a scaled Wishart distribution. We stress here that our data units are available in the form of covariance matrices, and we use the Wishart distribution to create our likelihood function rather than its more common usage as a prior on covariance matrices. Based on empirical explorations suggesting the data matrices to have low effective rank, we further model the center of the Wishart distribution using an orthogonal factor model type decomposition. We encourage shrinkage towards a low rank structure through a novel shrinkage prior and discuss strategies to sample from the posterior distribution using a combination of Gibbs and slice sampling. We extend our modeling framework to a dynamic setting to detect change points. The efficacy of the approach is explored in various 1 arXiv:1811.00724v1 [stat.AP] 2 Nov 2018 simulation settings and exemplified on several case studies including our motivating HCP data."}, {"section_title": "Introduction", "text": "Functional connectomes play a critical role in determining how the brain responds to everyday tasks and life's challenges (Glasser et al., 2016a; Jbabdi et al., 2015; Park and Friston, 2013) . In recent years, there has been an abundance of literature focusing on understanding the variation of functional connectomes in healthy and diseased people and their relationships to various covariates and phenotypes (Finn et al., 2015; Smith et al., 2015; Zhang et al., 2018) . Such interests are inspired and propelled by large scale neuroimaging studies, such as the Human Connectome Project (HCP) (Glasser et al., 2016b; Van Essen et al., 2013) , the Alzheimer's Disease Neuroimaging Initiative (ADNI) (Weiner et al., 2010) and the UK Biobank (Miller et al., 2016) . In this article, we focus our attention to functional connectome (FC) inferred from functional magnetic resonance imaging (fMRI) data that measures the blood oxygen level dependent (BOLD) contrast signals of each brain voxel. As opposed to the anatomical axon connections (also referred as structural connectome), FC quantifies functional dependences between brain regions through correlations or covariances of BOLD signals. Conventional FC is often represented as a covariance or correlation matrix of fMRI data over a long recording time (Friston, 2011; Hutchison et al., 2013a) , where the matrix size equals the number of ROIs being considered.\nWhile FC is assumed to be fixed or static over time in earlier studies, there is an abundance of evidence (Hindriks et al., 2016; Hutchison et al., 2013a; Monti et al., 2014) in recent studies showing that FC is a dynamic process. The dynamic FC (dFC) is represented as a time series of short-term FCs which are calculated using functional MRI data over small time intervals. The goal of this paper is understand and infer on the structure of dFC and detect change points in the dFC as the subjects perform a specific action. We first model the short-term FC using a scaled Wishart distribution and then generalize the static model to a hierarchical model of a time series of covariance matrices. Our final goal is to detect and compare individual specific change points along the dFC based on this hierarchical model.\nAs argued before, a first step towards change point detection is to model a population of covariance matrices. This is entirely different from covariance matrix estimation from multivariate data, which is a well-studied problem; see (Daniels and Kass, 1999; Leonard et al., 1992; Pati et al., 2014) as some representative examples of Bayesian inference for covariance matrices and (Pourahmadi, 2011) for a more comprehensive review. In the covariance estimation context, the observational data vectors are directly available and the goal is to characterize the dependence amongst the different variables in the data from multiple independent and identically distributed samples. On the other hand, our observational units are covariance matrices corresponding to different individuals observed over time, which we shall henceforth refer to as covariance-valued data. To the best of our knowledge, there is no previous work on the theoretical development of probabilistic modeling for such data and associated inferential techniques.\nIn this paper, we develop a suite of hierarchical modeling techniques for covariance-valued data to provide insight into the structural connectivity of human brains. We use a scaled version of the Wishart distribution to model the covariance-valued observations. While the Wishart distribution is commonly used as a prior distribution on inverse-covariance or precision matrices in Bayesian inference, its usage as a likelihood is novel to best of our knowledge. The presence of a modest number of observations further necessitates structured modeling of the center of the Wishart likelihood, which itself is a covariance matrix. Based on empirical evidence of low effective ranks of the data matrices, we modeled the center of the Wishart model using an orthogonal factor model type decomposition and encouraged shrinkage towards a low rank structure through the development of a novel shrinkage prior. We developed an efficient Markov chain Monte Carlo algorithm to sample from the posterior distribution, and en route, developed an algorithm to sample from a new class of distributions on the Stiefel manifold.\nOur primary objective is to explore the dynamic nature of FC between different brain regions during performances of certain tasks. A dynamical FC model provides an overall architecture of how the brain functions as the individual perform certain tasks. An important scientific goal is to identify change points (Barry and Hartigan, 1993) in the time series of covariances that split the data into contiguous segments. Difference in the change points across individuals are indicative of behavioral and cognitive differences (Dai et al., 2017) . To address this, we extend our hierarchical model to accommodate a single or multiple change points in a fully Bayesian framework. A novel combination of existing MCMC algorithms renders sampling from the joint posterior distribution tractable. The change point model is then implemented on both the HCP and the ADNI datasets to extract scientifically meaningful conclusions. For the HCP dataset, we studied the change point pattern during the motor task and discovered the primary FC change point occurs when people switch the movement from hand and foot to the tongue. For the ADNI dataset, we compared FCs in two groups of older people ( supernormal subjects and normal controls) and found that supernormal subjects have higher strength of connectivity within posterior regions or between posterior and anterior regions of their brain."}, {"section_title": "Data description", "text": "We utilize functional MRI data from two large datasets, ADNI (Weiner et al., 2010) and HCP (Van Essen et al., 2013) to illustrate the proposed method. ADNI was initiated by National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, the Food and Drug Administration, and some private pharmaceutical companies and non-profit organizations. ADNI assesses clinical, imaging, genetic and bio specimen biomarkers through the process of normal aging to early mild cognitive impairment, to late mild cognitive impairment, to dementia or Alzheimer's disease (AD). Participants were recruited across North America to participant in three phases of the study: ADNI1, ADNI GO and ADNI2. A variety of imaging and clinical assessments were conducted for each participant. Results were then shared by ADNI through the Laboratory of Neuro Imaging's Image Data Archive (https://ida.loni.usc.edu/). In our study, we focus on a subset of healthy subjects that were previously identified in (Lin et al., 2017a) . These subjects were AD free but were clustered in two groups. The first group is called supernormals who exhibited excellent episodic memory and executive function. The other group is age-matched healthy control subjects. All their resting-state fMRI data were collected using a 3.0 Tesla Phillips MRI with an echo-planar imaging sequence (spatial resolution = 3 \u00d7 3 \u00d7 3 mm 3 ). Structural images were obtained using an MPRAGE sequence (spatial resolution 1 \u00d7 1 \u00d7 1 mm 3 ), which were then used for registration during preprocessing. Across individuals, the first 10 volumes were discarded to avoid potential noise related to the equilibrium of the scanner and participant's adaptation process. The remaining 130 volumes were preprocessed using slice time correction and head motion correction. The images were then registered to each individual's own structural image, normalized to the Montreal Neurological Institute (MNI) standard space and spatially smoothed using a Gaussian kernel (FWHM = 4 mm). We utilized the automated anatomical labeling (AAL) (Tzourio-Mazoyer et al., 2002) to percolate the whole brain into 116 regions of interest (ROIs).\nThe HCP project aims at characterizing human brain connectivity in > 1, 000 healthy adults and to enable detailed comparisons between brain circuits, behavior and genetics at the level of individual subjects. The HCP raw and preprocessed data can be easily accessed through ConnectomeDB (http://www.humanconnectome.org). The high-quality imaging data and the easy accessibility make it an ideal data set for this paper. Majority of the HCP fMRI data were acquired at 3T with a 2 \u00d7 2 \u00d7 2 mm 3 resolution. Preprocessing steps using the HCP pipeline (Glasser et al., 2016b (Glasser et al., , 2013 were performed before any data analysis, e.g., removing spatial distortions, realigning volume to compensate for subject motion, registering the fMRI to the structural MRI, reducing the bias field, normalizing the 4D image to a global mean, masking the data with the final brain mask and aligning the brain to a standard space. Figure 1 provides an overview of the preprocessing steps. The Destrieux atlas (Destrieux et al., 2010) regions into 74 nodes per hemisphere. Similar to Dai et al. (2017) , for the fMRI BOLD signal in each ROI, we first calculate a mean time series, and then we utilize a sliding window method to calculate a covariance trajectory {S it } k\u2208 [K] i\u2208[n],t\u2208 [T ] for subject i at t-th window based on selected ROIs. Therefore, S it is a p\u00d7p covariance matrix representing the short time functional connectome, where p denotes number of ROIs."}, {"section_title": "Hierarchical Modeling for Covariance Data Set", "text": "Since the covariance matrices are observed for multiple individuals and time points, a natural course of action is to build a parsimonious model that borrows strength across all observational units. We first discuss an independence model for covariance-valued data that serves as the basic building block for the forthcoming extensions. Motivated by a pattern we observe in the functional connectivity data, the mean structure of the independence model is encouraged to shrink towards low rank matrices via a parsimonious shrinkage prior. We develop an MCMC algorithm to fit the independence model to data and show its efficacy in a simulation study. Next, the independence model is extended to a Bayesian hierarchical model to incorporate multiple individuals, allowing for subject specific deviations from a common mean structure. Fitting the hierarchical model requires sampling from a non-standard distribution on the Stiefel manifold, which we nevertheless show can be sampled efficiently using a novel algorithm. The hierarchical model leads to our eventual goal of detecting subject specific change points in the functional connectivity data."}, {"section_title": "Independence Model", "text": "We begin by describing the details of the independence model. Let {S j } N j=1 be a collection of independent and identically distributed p \u00d7 p covariance matrices. We probabilistically model the S j s using a Wishart distribution, which is arguably the most recognized distributional family for covariance matrices. We shall use the standard W p (\u03bd, V ) notation to denote the Wishart distribution on the space of p \u00d7 p positive definite matrices, with degrees of freedom \u03bd > p \u2212 1 and a p \u00d7 p positive definite scale matrix V . The density\nSpecifically, we use a scaled Wishart distribution W p (\u03c6, \u03c6 \u22121 \u2126) to model the S j s,\nThe introduction of the parameter \u03c6 in the scale matrix is to decouple its presence in both the mean and covariance. For S 1 \u223c W p (\u03c6, \u2126), one has\nThus, in the parameterization we work with, \u2126 is the population mean. We henceforth fix \u03c6 at (p + 1) and focus attention on modeling the mean \u2126. An unstructured p \u00d7 p covariance matrix has p(p + 1)/2 free elements, (e.g. in the HCP dataset, p = 10 leading to a total number of 55 parameters and in the ADNI dataset, p = 7 in the present case leading to 28 parameters). Given that we only have a modest number of time points, it is important to make meaningful structural assumptions on \u2126 to reduce the effective number of parameters to be estimated. We conducted an exploratory analysis to find patterns in the data matrices that could direct us towards a parsimonious model. The data matrices and their inverses did not contain any obvious sparsity pattern. Next, we investigated the effective ranks of the data matrices. For a p \u00d7 p positive definite matrix A with eigenvalues s 1 (A) \u2265 s 2 (A) \u2265 s p (A) \u2265 0, its effective or intrinsic rank (Vershynin, 2012) ,\nis the ratio of its trace and largest eigenvalue. The effective rank satisfies 1 \u2264 r e (A) \u2264 rank(A), so that it always provides a lower bound to the actual rank. Further, the effective rank is a smooth function of its argument. For example, consider the class of matrices\nfor \u03bb > 0 and u a p-dimensional vector of unit length. The matrices M \u03bb increasingly get close to being rank deficient as \u03bb \u2193 0, however, this is not captured by the rank as rank(M \u03bb ) = p for any \u03bb > 0. On the other hand, r e (M \u03bb ) = 1 + (p \u2212 1)\u03bb/(1 + \u03bb), which smoothly decays to 1 as \u03bb \u2193 0. These features render the effective rank a suitable measure to capture the intrinsic dimensionality of a matrix and indicate potential near rank-deficiencies. Figure 2 shows boxplots of the effective ranks of the data matrices across the 26 time points for 50 randomly selected individuals from motor task of HCP data set. It is evident that the 10 \u00d7 10 data matrices have low effective rank, with the bulk of the empirical effective rank distribution between 1.5 and 3. This observation motivated us to consider an orthogonal factor model type decomposition for \u2126 to exploit the near low-rank structure as\nwhere V \u2208 R p\u00d7r * for some r * \u2264 p is a semi-orthogonal matrix satisfying V T V = I r * , and D = diag(d 1 , . . . , d r * ) is a diagonal matrix with non-negative diagonal entries. Such a decomposition readily satisfies the positive definiteness constraint on \u2126. We operate in a Bayesian framework to perform inference based on the posterior distribution of the model parameters. Before proceeding to describe our prior specifications, it is important to discuss the role of r * in what follows. In a fully Bayesian framework, one may treat r * as a parameter which designates the effective rank of \u2126 and assign it a prior distribution; the discrete uniform distribution on {1, . . . , p} being a default choice. Under this prior, the posterior distribution of r * is proportional to the marginal likelihood of the data given r * , which is intractable in the present context. While it is possible to sample r * inside a larger trans-dimensional MCMC algorithm such as the reversible jump MCMC (RJMCMC), its implementation remains computationally challenging, especially when considering extensions to the hierarchical modeling setup later on. Moreover, the effective rank does not have a clear biological interpretation in our real application and is purely a modeling device to induce parsimony. Based on these considerations, we undertake a shrinkage approach rather than explicit selection of the rank. Specifically, we set r * to a conservative upper bound, with p being a default choice, and encourage a subset of the diagonal entries of D to shrink towards zero. If A \u2282 {1, . . . , p} denotes the active subset, that is, the subset of diagonal entries of D that are left unshrunk, then V DV\nA , where V A denotes the p \u00d7 |A| sub-matrix of V corresponding to the columns in A, and D A denotes the corresponding |A| \u00d7 |A| diagonal sub-matrix of D. This leads to an approximately low rank decomposition under the posterior, which is sufficient for our purpose. In the factor modeling context, Bhattacharya and Dunson (2012) considered a shrinkage prior on the factor loadings matrix rather than placing a prior on the number of factors, e.g., as in Lopes and West (2004) . We have a very different shrinkage mechanism as our shrinkage operates on the diagonal matrix D.\nFixing r * , the unknown parameters in our model are (V, D, \u03c3 2 ) with parameter space V p,r * \u2297 D r * \u2297 R + , where V p,r * denotes the Stiefel manifold of p \u00d7 r * semi-orthogonal matrices, and D r * the collection of r * dimensional diagonal matrices with non-negative entries. The likelihood function for the parameters is given by\nWe now discuss prior choices on the parameters. For computational convenience, we reparameterize to (V,D, \u03c3 2 ) whereD = D/\u03c3 2 , so that \u2126 = \u03c3 2 (VDV T + I p ). We place a uniform prior on V supported on the Stiefel manifold V p,r * , and an inverse-gamma IG(\u03b1 \u03c3 , \u03b2 \u03c3 ) prior on \u03c3 2 . To set up our sparsity favoring shrinkage prior on the diagonal entriesd h s ofD, first decompos\u1ebd\nIn (4), \u03c4 plays the role of a global shrinkage parameter while the \u03bb h s allow for coordinate specific deviations, much in the spirit of the global-local shrinkage priors popularly used in regression (Carvalho et al. (2010) ). We place independent half-Cauchy priors on the \u03bb h s, \u03bb h ind.\n\u223c Ca + (0, 1), with density proportional to 1/(1 + t 2 ) I 0,\u221e (t). The half-Cauchy prior is a popular choice as a prior distribution of shrinkage parameters due to its positive density at zero and heavy tails (Polson and Scott (2012) ; Carvalho et al. (2010) ). We complete the prior specification by placing a halfCauchy prior truncated to (0, 1) on \u03c4 . Truncating the prior on the global parameter leads to better identifiability and is recommended by van der Pas et al. (2014) in the context of the horseshoe prior. The multiplicative prior on thed h s can also be interpreted as an additive one-way ANOVA type decomposition in the logarithmic scale,\nwith grand mean \u00b5 and main effects \u03b2 h s. The posterior computation is also conveniently carried out in the logarithmic scale, which we describe next.\nWe develop a fully automated and easy to implement Markov chain Monte Carlo algorithm to sample from the joint posterior distribution of (V,D, \u03c3 2 ) given the data. Specifically, we use a combination of Gibbs sampling with slice sampling and Metropolis-within-Gibbs to iteratively sample from the full-conditional distribution of each parameter block given the rest. The sampler iterates through the following steps; the derivations are deferred to the Appendix (section A).\n\u2022 Sample V from its matrix Bingham(S N , \u03c6E \u22121 /2\u03c3 2 ) full-conditional distribution. The matrix Bingham(A, B) distribution has a density with respect to the uniform distribution on the Stiefel manifold given by\nwhere A and B are symmetric and diagonal matrices, respectively. In our case, S N (= N j=1 S j ) is a symmetric matrix by definition and E = (D \u22121 + I r * ) The matrix Bingham distribution is conveniently sampled using the R package rstiefel (Hoff, 2013) .\n\u2022 Update the {\u03b2 h }s from their independent full conditional distributions using slice sampling.\n, and set \u03b2 j = (1 \u2212 w h )/(w h \u00b5).\n\u2022 To sample \u00b5, propose \u00b5 * \u223c N (\u00b5, s 2 ) and compute the Metropolis ratio\nwhere \u03a0(\u00b5 | \u2212) denotes the full-conditional of \u00b5. Accept \u00b5 * with probability min{\u03b1(\u00b5, \u00b5 * ), 1}.\n\u2022 Sample \u03c3 2 from its inverse-gamma full conditional distribution as\nwhere\nWe observed good mixing and convergence of the above MCMC sampler based on standard MCMC diagnostics. Although not our primary motivation, one can estimate the effective rank based on a simple post-processing step of the MCMC samples for the {d h }s. As in Bhattacharya et al. (2015) ; Li and Pati (2017a) at each MCMC iteration, we cluster the {d h }s into two groups using 2-means clustering and save the size of the group having the larger mean. The mode of these numbers across the MCMC iteration is then used as an estimate of the effective or intrinsic rank. We find that this approach performs well in our simulation and real examples. A more nuanced approach for post-processing was proposed by Li and Pati (2017b) , which can also be used in the present context."}, {"section_title": "Simulation Study for Independence Model", "text": "We conduct a detailed simulation study to illustrate the performance of the independence model in terms of recovering the true parameters. We fixed p = 50 and varied N \u2208 {100, 250, 500, 750, 1000}. The true intrinsic rank of the data generating mechanism was fixed at 3 to mimic the observation in Figure 2 . We set \u03c6 = p + 1, the true \u03c3 2 0 = 0.25, the trueD 0 = {1.25, 2, 1.55} and considered V 0 from a uniform distribution on Stiefel manifold V p,r * . 100 independent datasets have been generated from the model (1). We denote the true covariance matrix \u03c3 2 0 (V 0D0 V T 0 + I p ) by \u2126 0 . For model fitting, we set r * = 10. The inverse-gamma hyperparameters \u03b1 \u03c3 and \u03b2 \u03c3 were elicited in an empirical Bayes approach. Specifically, we used a method-of-moments type estimator for these hyperparameters. We ran our MCMC algorithm for 10,000 many iterations, discarding the first 5000 many iterates as burn-in. Letting \u2126 B denote an estimate of the posterior mean based on the retained MCMC samples, we provide boxplots of the scaled Frobenius norm difference \u2126 B \u2212 \u2126 0 /p across the 100 replicates for the different values of N in Figure 3a . Here, and elsewhere, A = tr (A T A) denotes the Frobenius norm of a matrix. As expected, both the center and spread of the boxplots tend to decrease with increasing N , implying the consistency of the posterior mean in recovering the population mean. Figure 3b shows density plots of the posterior samples of \u03c3 2 which increasingly concentrate around the true value, \u03c3 2 0 = 0.25, with increasing N . Next, we compare the performance of the posterior mean \u2126 B with the sample mean \u2126 s = N \u22121 N j=1 S i , which is an unbiased estimator of \u2126 0 . We consider three different norms between covariance matrices (Ian L. Dryden and Zhou, 2009 ) listed in Table 1 . \n; summary measures are tabulated in Table 2 and Table 3 for p = 50 and p = 100 respectively. We scaled the distances except the Riemannian norm by p for tabulation; the Riemannian norm is scale-invariant. Boxplots of the distances (in their original scale) across the 100 replicates are provided in Figure 4 . It is evident that the posterior mean overall provides a substantial improvement over the sample mean, especially in higher dimensional situations.\nFinally, we illustrate the performance of the post-processing step outlined in the previous subsection to estimate the effective rank. We only consider N = 100 and 2 different settings ofD, (i) {1.25, 2, 1.55} and (ii) {0.75, 1.25, 2, 1.55}. Setting (ii) has a weaker signal strength compared to (i). Following the discussed methodology and setup, we provide the rank estimates under different Table 3 : Same setting as in Table 2 with p = 100. scenarios in Figure 5 which shows high probability mass at 3 and 4 in Figure 5a and 5b respectively. In different simulation settings, our proposed method is able to recover the true ranks."}, {"section_title": "Hierarchical Covariance Model", "text": "In this subsection, we extend the independence model to a hierarchical modeling framework encompassing all the individuals. Our hierarchical modeling framework lets the different individuals to share common parameters while allowing for subject specific deviations, striking a balance between pooling of information across different individuals while retaining flexibility. Letting S it denote the . Lines on the bars shows the standard errors of probability for each point across replicates. The probability is defined as average posterior probability across replicates for each point. (5a) Left panel plot provides the rank estimate for setting (i)D = {1.25, 2, 1.55} which indicates high probability mass at 3. (5b) Right panel plot provides the rank estimate for setting (ii)D = {0.75, 1.25, 2, 1.55}. There is a moderately high probability mass at 4 and a significant amount of mass at 3 because of existence of a weak signal. observed covariance matrix for individual i at time t, we let\nThe first line of (5) posits the same scaled Wishart model as in the previous subsection with individual specific mean \u2126 i . As discussed earlier, we only have data on T = 26 time points for each individual. On the other hand, there are a relatively larger number of individuals in the study. For this reason, rather than separately fitting the independence model for each individual, we consider a structured decomposition of \u2126 i that lets D i and \u03c3 2 i vary across individuals, while keeping V fixed. This is akin to an expansion of the \u2126 i s in terms of a fixed dictionary V , with subject specific loadings. This fixed dictionary expansion vastly reduces the number of model parameters and allows one to borrow information across individuals to estimate the common dictionary V . We later conduct model validation to show that model (5) provides an adequate fit to the data compared to separately fitting the independence model.\nWe continue to use the uniform prior on the Stiefel manifold for V . After reparameterizing toD i , we place independent copies of the shrinkage prior introduced earlier on theD i s, and independent inverse-gamma priors on the \u03c3 2 i s."}, {"section_title": "Posterior computation", "text": "We extend the MCMC algorithm for the independence model to the hierarchical setting. The updates forD i and \u03c3 2 i proceed independently across i exactly along same lines as before. However, since V is common to all individuals, its full conditional no longer remains a matrix Bingham distribution. We show in the Appendix (section B) that the full-conditional distribution of V is given by\nwhere\nWe develop a sampler for this non-standard density below. Write V as\n} where z \u2208 R r * \u22121 has unit length, z = 1, and N is an p \u00d7 (r * \u2212 1) orthonormal basis for the null space of\nChikuse (2003), the conditional density of z given V [,\u22121] can be derived as\nWe iterate through the steps 1-4 below for each j \u2208 {1, . . . , r * }:\n3) Sample z j from a vector Bingham(H j ) density using the package rsteifel. 4) Set v j = N z j ."}, {"section_title": "Simulation study for Hierarchical Covariance Model", "text": "We conduct a replicated simulation study to illustrate the operating characteristics of the hierarchical model. We set n = 100, T = 26 and p = 50 for our simulations. The true V 0 is generated uniformly on the Stiefel manifold. Also, for each i, the diagonal entries of the true D 0i are generated uniformly between 0 and 5, while the \u03c3 2 i s are generated uniformly between 0.25 and 0.50. We generate 100 independent simulation replicates as above.\nWe fit the hierarchical model using the MCMC outlined in the previous subsection. We set r * = 10 and use a modification of the empirical Bayes procedure to elicit the hyperparameters \u03b1 \u03c3 and \u03b2 \u03c3 . As metrics of parameter recovery, we considered\nwhere \u2126 i and \u03c3 2 i are the posterior means of \u2126 i and \u03c3 2 i for i = 1, . . . , n. d\n\u03c3 is an individual specific measure of the distance of the posterior mean from the truth, while d \u2126 and d \u03c3 are average measures over all the individuals.\nAs a point of comparison, we also fit the independence model in the previous subsection separately for each individual. Figure 6 shows boxplots of {d\naveraged over the simulation replicates for the hierarchical and independence model. The tighter spread of the boxplot for the hierarchical model indicates the gains from borrowing information across subjects. The hierarchical The true ranks across individuals shown in a heat map of the binary matrix R = (r ih ), with r ih = 1 if the data matrix for individual i has rank h, and 0 otherwise. The middle and right panels correspond to the estimated ranks by the hierarchical and independence models respectively.\nWe conducted a second set of simulations by varying n \u2208 {100, 200, 300, 400, 500} and p \u2208 {50, 100, 150, 200, 250}. A summary is presented in Figure 8 . In the top left panel, we provide the boxplot of d \u2126 across the 100 simulation replicates for the different values of n keeping p fixed, while the bottom left panel provides the same for varying p and fixed n. As expected, the estimation performance improves for larger n and smaller p. We observe similar pattern in the density plots of d \u03c3 w.r.t. increasing n, fixed p (Figure 8b ) and fixed n, increasing p (Figure 8d )."}, {"section_title": "Real Data Analysis for ADNI data set", "text": "In this case study, we utilize 18 subjects' resting-state fMRI data from ADNI. Half of them are from supernormal (SN) subjects who possess excellent (Lin et al., 2017a,b) , and the other half are healthy control (HC) subjects. Each group contains 9 individuals with its resting state fMRI data at baseline preprocessed. From previous literature, we identified seven interesting ROIs, left occipital cortex, left occipital cortex, left precuneus, left superior temporal cortex, right middle frontal gyrus, right parahippocampus, right thalamus (indexed as ROI 1, 2, ..., 7), that are potentially linked to cognition, emotional regulation and memory. After preprocessing, we obtained a mean BOLD signal within each ROI and then applied a sliding window method to obtain a 7 \u00d7 7 \u00d7 24 covariance matrix time series. We applied our proposed hierarchical model on this data set for different group of individuals and obtained Bayes estimates of individual specific covariance matrix \u2126 i for i = 1, .., 9. (Note that in Section 5.4 we have validated that there is no change point in these covariance trajectories.) To compare the functional connectivity between ROIs across SN and HC, we look at all the off-diagonal elements of \u2126 i (i = 1, . . . , 9) for both SN and HC using an overlaid histogram in Figure  9 . The overlaid histograms clearly show than on an average the FC for the SN individuals is higher. In addition, it is also important to know which one out of the 21 pairs of regions accounts for the maximum separation in \u2126 i between SN and HC. A simple multiple comparison test reveals that the FC difference between SN and HC for the ROI-pairs (2, 3) and (3, 6) are statistically significant (pvalues 0.038 and 0.013), where (2,3) represents a posterior regions' connection and (3,6) represents an anterior-posterior connection. This finding is in line with the literature (Lin et al., 2017a) : SN group has higher strength of connectivity within posterior regions or between posterior and anterior regions. Box plots for ROI-pairs in Figure 10 clearly show that the FC for SN is higher than HC for both the ROI-pairs. Next we compare overall functional connectivity between supernormals and healthy controls through corresponding magnitudes of FC between different ROIs. Figure 11 represents the heat map of matrices associated with hierarchical posterior estimate of \u2126 and sample mean. Each element in the associated matrix represents the mean difference of absolute values of off-diagonal elements of \u2126 in Figure 11a and the sample mean in Figure 11b . These off-diagonal elements represent individual specific FC between different ROIs. The difference is slightly more evident for the posterior estimate in Figure 11a than the sample mean in Figure 11b . "}, {"section_title": "Hierarchical Change point Model", "text": "Although a majority of previous works on modeling functional connectivity assumes stationarity (Friston, 2011; Hutchison et al., 2013b) , recent developments in Dynamic Connectivity Regression Cribben et al. (2013) suggest the necessity of incorporating non-stationary modeling of the time series of covariance matrices. It is reasonable to assume that different parts of brains will react distinctly under the effect of external stimuli, so assuming a common mean for the Wishart distribution in (5) is not warranted unless the subjects are in a resting state. Moreover, in presence of multiple subjects, it becomes necessary to borrow information across multiple subjects white retaining some commonality features. Preliminary time series models based on sliding window technique (Lindquist et al., 2014) and asymptotic tests are based on a single subject and do not naturally extend to the case when multiple subjects are concerned.\nIn the following, we extend our hierarchical model in (5) to include the most simple departure from stationarity, which is accommodating a single change point in the mean of the Wishart distribution.\nFocussing on one action, the hierarchical change point model across individuals is\nwhere c i represents the change point specific to subject i. We used scaled Wishart distribution with different individual specific means \u2126 1 i and \u2126 2 i to before and after the change points respectively. A similar orthogonal factor model type decomposition (discussed in (2)) is proposed on \u2126 1 i and \u2126 2 i .\nObserve that the orthogonal matrices V 1 and V 2 are fixed across individuals and thus viewed as a common dictionary on which individual specific loadings D 1 i and D 2 i act on to create subject specific deviations. We place independent uniform prior distributions Stiefel manifold for V 1 and V 2 along with independent global-local prior onD 1 andD 2 exactly as in \u00a73.1. Independent inversegamma priors are chosen on the \u03c3 2 1 i and \u03c3 2 2 i\n. We assumed that apriori any time point is equally probable to be a change-point, i.e., c i \u223c Discrete-Uniform({1, . . . , T}).\n(10)\nA highly efficient Gibbs sampler is developed mimicking \u00a73.1 with an additional step to update the change-points c i , i = 1, . . . , n. A detailed calculation of the steps is provided in the Appendix (section C)."}, {"section_title": "Simulation Study for Hierarchical Change point Model", "text": "To demonstrate the the hierarchical change point model (8) on simulated datasets, we consider n = 100, p = 50 and T = 26 with n 2 = 40 individuals having change-points c 0i \u2208 {2, . . . , T \u2212 1} and the remaining individuals with size n 1 = 60 having no change points. For simplicity and to develop a simulation scenario analogous to the HCP dataset, we assume all the individuals are observed at the same time points and the boundary points cannot be considered as a candidate for a change-point. For clarity of exposition, any parameter with subscript \"1\" correspond to the pre-change-point regime (deemed as Group 1) and the ones with subscript \"2\" corresponds to the post-change-point (Group 2). True individual specific ranks are generated from discrete uniform distribution spanning over {1, . . . , r * = 10}. The true values of the diagonal matrices {D 01 i } n i=1 and {D 02 i } n 2 i=1 are generated from unifrom(0, 5) to include a wide range signal strengths. {\u03c3 2\nare generated from uniform(0.25, 0.50). Using these values, \u2126 1 and \u2126 2 are constructed using the equation (9) and we set (\u03c6 1 , \u03c6 2 ) = (p + 1, p + 1). 100 replicated data sets are then generated from (8).\nThe MCMC is run for 5,000 iterations leaving a burn-in sample of 5,000. Subject-specific change point estimates\u0109 i are obtained from the posterior mode of c i . Since the focus of this section is correct detection of change-points, we only display the estimated change-points corresponding to the n 2 = 40 individuals in Figure 12 . Our proposed model is successful to recover individual specific change points. The ranks corresponding to the covariance matrices across individuals are also estimated correctly in all the cases as presented in Figure 13 .\nTo demonstrate consistency of the estimate of \u2126 ji , j = 1, 2; i = 1, . . . , n with increasing sample size, we consider another simulation setting where p is fixed at 50 and n takes values in the range {100, 200, 300, 400, 500} with n 2 \u2208 {40, 80, 120, 160, 200}. Figure 14 presents the summary of the variability of the parameters (\u2126 1i , \u03c3 2 1i , \u2126 2i , \u03c3 2 2i ) appropriately summarized for the n individuals using the metrics d \u2126 and d \u03c3 over 100 simulated replicates. It is evident that on an average d \u2126 1 ( Figure  14a ) and d \u2126 2 (Figure 14c ) decreases with a smaller spread with increasing n and n 2 respectively. Similarly the density plots of d \u03c3 1 (Figure 14b ) and d \u03c3 2 (Figure 14d ) become more concentrated as n increases. "}, {"section_title": "Real Data Analysis for HCP Data Set", "text": "In this section, we consider the HCP dataset (Van Essen et al., 2013) as discussed in \u00a72. Time series of covariance matrices describing the connectivity were acquired from each subject while they were performing different tasks involving different neural systems, under resting state or external stimuli. A quick exploratory analysis of the data set shows the wide variation in the range of values of the covariance matrices. For the change point model (8) to be applicable, we scale each covariance matrix by the lowest singular value of that matrix as a simple variance stabilizing transformation. Based on empirical validation from Figure 2 on small effective ranks of the covariance matrices, we applied the hierarchical change point model (8). Task-specific summary of findings is provided below. "}, {"section_title": "Case study for Motor Task", "text": "The HCP motor task experiment was set up by Buckner and colleagues (Buckner et al., 2011) . Participants are presented with visual cues that ask them to either tap their left or right fingers, or squeeze their left or right toes, or move their tongue to map motor areas. In the experiment, there are 13 blocks, with 4 hand movements, 4 foot movements, and 2 tongue movements. In addition, there are 3 15-second fixation blocks between different tasks. We identified ten cortical ROIs related to the motor control around the motor strip area, including left and right postcentral gyrus, precentral gyrus, and central gyrus, and generated a 10 \u00d7 10 covariance matrix time series with 26 time points. The proposed hierarchical change point detection model is then applied and detects 39 individuals with corresponding change points. Figure 15a shows 39 labeled individuals with their corresponding most dominant change points. The histogram in Figure 15b displaying the pattern of the change points across the individuals shows that most of the individuals have change points at time point 23. In the experiment design, it corresponds to the time point of switching the movement from hand and foot to the tongue. We applied our methodology on the gambling task as well. A discussion on the findings is deferred to the Appendix (section D). One obvious limitation (8) is that it can only account for the most dominant change point. It is possible that there exists more than one change point for a specific individual under a certain task. In the following, we extended the methodology to enable detection of multiple change points. "}, {"section_title": "Multiple Change point Analysis", "text": "Our hierarchical change point model detects the most dominant change points along the time frame. We adapted a standard sliding window approach to detect multiple change points for different individuals. Denote by c i (1 < c i < T ) the first most dominant change point in the interval {1, . . . , T } for individual i which is detected through the hierarchical change point model. We slide our time window before and after the most dominant change point c i . We note here that applying our change-point model over a time window containing c i recovers the c i as the most dominant change point. Hence we consider the windows {1, . . . , c i \u2212 1} & {c i + 1, . . . , T } for further detection of the next dominant change points. Suppose, there is a change point c * i in the interval {1, . . . , c i \u2212 1}. Then we again split the time window into {1, . . . , c * i \u2212 1} & {c * i + 1, . . . , c i \u2212 1} and apply the change point detection method to the two intervals separately. Same procedure is followed on the time window {c i + 1, . . . , T }. Figure 16 shows the individuals specific multiple change points under the motor task where we considered individuals with at least 2 change points. W detected 16 individuals with multiple change points under motor task which is shown in Figure  16 . There is no individual under motor task with more than 4 change points. "}, {"section_title": "ADNI Data Set", "text": "We applied the hierarchical change point model on the previously described ADNI data set, where the subjects are believed to be at a resting state. As anticipated, our model did not detect any change points in the data set for both supernormals and health control groups. To test for model adequacy, we calculated the WAIC values for ADNI data set with respect to the independence model (1), hierarchical covariance model (5) and the change point model (8) Table 4 : WAIC values for ADNI data set w.r.t. 3 models which are defined in (1), (5) and (8) respectively. Reported WAIC values are in scale of 10 2 ."}, {"section_title": "Model Validation", "text": "In the following, we first consider an adhoc graphical summary measure of the posterior to justify the extension to hierarchical covariance model from the independence model for the HCP dataset. To understand the variation of the posterior distribution of the maximum eigen value of the covariance matrix and \u03c3 2 across different individuals fitted using the independence models, we obtain posterior density plots of the quantities in Figure 17 .\nAnother important modeling assumption in (5) that requires empirical justification is the use of common semi-orthogonal matrix V across all the individuals as opposed to having individual specific semi-orthogonal matrices in the independence model. In the following, we develop a simple diagnostic to this effect. First we fit the independence model separately for each individual and\nFigure 17: Here we have fitted the the independence model separately to HCP data set and this are the density plots of variation in maximum eigen value and \u03c3 2 across individuals.\nfor each i we calculate the Karcher mean (Marks, 2012 ) of posterior samples of {V i } n i=1 to obtain individual specific posterior estimate of the semi-orthogonal matrices, denoted {V 1 i } n i=1 . For each i, variability of the estimate of the semi-orthogonal matrix is measured as d(V 1 i ,V ) whereV = Karcher mean of {V 1 i } n i=1 and d(U, W ) =|| P U \u2212 P W || where P U = U U T . In Figure 18 , \"Different V\" shows the histogram of {d(V 1 i ,V )} n i=1 describing the variability for the individual specific semiorthogonal matrices. We generated data from (1) with individual specific \u2126 i set asVD iV T +\u03c3 2 i I for all individuals i = 1, . . . , n whereD i and\u03c3 i are the individual specific posterior estimates from the independence model. We then refit the independence model to this new dataset and acquired individual specific posterior estimates of the semi-orthogonal matrices = {V 2 i } n i=1 . Variability of these semi-orthogonal matrices is measured as d(V 2 i ,V ) for each i(= 1, . . . , n). \"Same V\" in Figure 18 denotes the histogram of {d(\n. Figure 18 clearly indicates a reduction in the variability of semi-orthogonal matrices if only a single semi-orthogonal matrix is considered across all individuals.\nAfter fitting a complex Bayesian model, it is important to compare its predictive accuracy with other models, both simple and complex (Geisser and Eddy, 1979; Hoeting et al., 1999; Vehtari et al., 2012) . Cross-validation and information criteria are two approaches to estimate out-ofsample predictive accuracy using within-sample fits. DIC has gained in popularity in recent years, in part through its implementation in the graphical modeling package BUGS, but it is known to suffer from issues from not being fully Bayesian. The Watanabe-Akaike information criterion Figure 18 : \"Different V\" indicates the variation in V i s which are obtained from fitting independence model separately for each individual and measured the deviation of V i s fromV which is karcher mean of individual specific V i s. Later we have simulated a data withV , estimatedD and estimated \u03c3 2 and measured the variation in similar fashion which is represented with \"Same V \". Here deviations are measured as d(U, W ) =|| P U \u2212 P W || where P U = U U T .\n(WAIC) (Watanabe, 2010) Table 5 : WAIC values for 3 models which are defined in 1, 5 and 8 respectively for HCP data set under motor task. Reported WAIC values are in scale of 10 3 .\nmost complex change point model."}, {"section_title": "Discussion", "text": "To discover patterns within the connectivity matrix of human brain as subjects perform specific tasks, we start with a simple Wishart distribution with an approximate low rank structure on the mean for modeling the covariance valued data. The methodology allows straightforward extension to a hierarchical model of multiple subjects where covariance valued time series is available for each subject. Another important extension is to develop a method for detecting a single change point in the covariance time series. Applying the methodology to the HCP data for the motor task reveals that the change point is associated with a particular regime switch of the experimental design. Also, the application to the resting state individuals in the ADNI study does not reveal any change point, which is in accordance with the expert opinions.\nAnother interesting application related to the HCP dataset is where the subjects are performing psychometric tasks and the goal is to understand how the connectivity evolves over time and whether a particular patten in the time series motif is associated with the subjects \"intelligence\" or mental ability. In this case, the goal is to understand how the connectivity changes with time and it is important to allow more complex time varying structure in the evolution of the covariance matrix. Such applications also call for development of joint model of the mental ability scores and the connectivity matrices and is an interesting topic for future research.\nFor simplicity, we focused on a single Wishart distribution as a model for the covariance value data. A more flexible alternative beyond the Wishart family is to consider a mixture of Wishart distributions, particularly to allow for departures that are not captured by a single scale parameter. However, this comes with an additional burden of identifying and interpreting the component specific mean parameters that are required to be properly regularized to get a meaningful inference. The full conditional distribution of V is a Bingham(S N , E \u22121 /2\u03c3 2 ) distribution.\n\u2022 Slice Sampler of \u03b2 h :\nConsider M = V T SV and a transformation w h = (1 + \u03b2 h \u00b5) \u22121 for h = 1, . . . , r * . Now the full conditional of \u03b2 h is provided below. -(w h |u h , \u2212) \u223c Gamma(shape= (N \u03c6/2)\u22121, rate = \u03c6M hh /2\u03c3 2 )I[w h > {1+ (1/u h ) \u2212 \u00b5 2 } \u22121 ].\n\u2022 MH Sampler of \u00b5 :\nThe full conditional and sampling steps of \u00b5 are described as follows.\n(1 + \u03b2 h exp(\u00b5)) (2\u00b5) where c h = \u03c6M hh /(2\u03c3 2 ). To apply metropolis hastings algorithm, proposal density is taken as \u00b5 * \u223c N (\u00b5, s 2 ). Now we accept \u00b5 * with probability min{\u03b1(\u00b5, \u00b5 * ), 1} and \u03b1(\u00b5, \u00b5 * ) = \u03a0(\u00b5 * | \u2212) \u03a0(\u00b5 | \u2212) .\n\u2022 Full conditional of \u03c3 2 : where Q = (VDV T + I p ) \u22121 V T .\n(\u03c3 2 | \u2212) \u223c Inverse-Gamma(\u03b1 \u03c3 \u2212 1 + N p\u03c6/2, \u03b2 \u03c3 + tr (QS N )/2)."}, {"section_title": "B Computations under Hierarchical Covariance Model", "text": "\u2022 Likelihood :\n)."}, {"section_title": "C Derivations under Hierarchical Change Point Model", "text": "\u2022 Full conditional of Change Points :\n(1 +d 1 ij )\n(1 +d 2 ij )\nS it ."}, {"section_title": "D Case study for gambling task of HCP data set", "text": "A detailed description of gambling task corresponding to HCP is in Delgado et al. (2000) . We applied our hierarchical change point model on scaled data which detects 70 individuals with change points under Gambling task. In Figure D .1 we labeled the 70 individuals with their corresponding change points. Figure D. 1a consists of 70 individuals with their most prominent change point detected through the hierarchical model. Figure D .1b shows the overall pattern of the most prominent change points across all the individuals. The histogram in Figure D .1b shows that more than 10% individuals have change points at 21. Next we extended our study to detect multiple change points under gambling task. We applied the methodology discussed in section 5.2 on individuals under gambling task and detected multiple change points for different individuals. In Figure D .2, we listed the individuals with at least 2 change points and their corresponding change points. "}]