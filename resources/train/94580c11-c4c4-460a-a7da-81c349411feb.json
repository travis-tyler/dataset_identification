[{"section_title": "Abstract", "text": "Longitudinal reproducibility is an essential concern in automated medical image segmentation, yet has proven to be an elusive objective as manual brain structure tracings have shown more than 10% variability. To improve reproducibility, longitudinal segmentation (4D) approaches have been investigated to reconcile temporal variations with traditional 3D approaches. In the past decade, multi-atlas label fusion has become a state-of-the-art segmentation technique for 3D image and many efforts have been made to adapt it to a 4D longitudinal fashion. However, the previous methods were either limited by using application specified energy function (e.g., surface fusion and multi model fusion) or only considered temporal smoothness on two consecutive time points (t and t+1) under sparsity assumption. Therefore, a 4D multi-atlas label fusion theory for general label fusion purpose and simultaneously considering temporal consistency on all time points is appealing. Herein, we propose a novel longitudinal label fusion algorithm, called 4D joint label fusion (4DJLF), to incorporate the temporal consistency modeling via non-local patch-intensity covariance models. The advantages of 4DJLF include: (1) 4DJLF is under the general label fusion framework by simultaneously incorporating the spatial and temporal covariance on all longitudinal time points. (2) The proposed algorithm is a longitudinal generalization of a leading joint label fusion method (JLF) that has proven adaptable to a wide variety of applications. (3) The spatial temporal consistency of atlases is modeled in a probabilistic model inspired from both voting based and statistical fusion. The proposed approach improves the consistency of the longitudinal segmentation while retaining sensitivity compared with original JLF approach using the same set of atlases. The method is available online in open-source."}, {"section_title": "Introduction", "text": "An essential challenge in volumetric (3D) image segmentation on longitudinal medical images is to ensure the temporal consistency while retaining sensitivity. Many efforts have been made to incorporate the temporal dimension into volumetric segmentation (4D). One family of 4D methods is to control the longitudinal variations during pre/post-processing [1] . Another family is to incorporate the longitudinal variations within segmentation methods [2] . In the past decade, multi-atlas segmentation (MAS) has been regarded as de facto standard segmentation method in 3D scenarios [3] [4] [5] . To improve the performance of 4D MAS for longitudinal data, several previous avenues have been explored [6] [7] [8] . However, these methods are restricted on surface labeling application, availability of multi-modal data, or only considering two consecutive time points ( and +1) while assuming the l1-norm sparsity of fusion weights. When more than two longitudinal target images are available, the more comprehensive strategy is to consider the spatial smoothness on all time points (Fig. 1) .\nIn this paper, we propose a novel longitudinal label fusion algorithm, called 4D joint label fusion (4DJLF) to incorporate the probabilistic model of temporal performance of atlases to the voting based fusion. Briefly, we model the temporal performance of atlases on all time points in a probabilistic model and incorporate the leading and widely validated joint label fusion (JLF) framework. "}, {"section_title": "Theory", "text": ""}, {"section_title": "Model Definition", "text": "A target image be represented by , \u2208 1,2, \u2026 , . 4DJLF considers all available longitudinal target images, , , \u2026 , where represents a target image. First, all longitudinal target images are registered to the first-time point using rigid registration [9] . pairs of atlases (one intensity atlas and one label atlas)\n, , \u2026 , are used in the MAS. Then, we register the intensity atlases to longitudinal target images to achieve registered pairs of atlases. For mathematical convenience, we concatenate all registered atlases (based on the sequence in ) to derive registered intensity atlases set and registered label atlases set as\nwhere the superscripts \" \u2022 \" indicate to which target image that atlas was registered. Fig. 2 . The 4DJLF framework. First, the same set of atlases are registered to the longitudinal target images (3 time points in figure) . Then, the \u03a6 matrices are calculated using Eq. (9). Finally, the spatial temporal performance of all atlases are model by Eq. (10), which leads to the final segmentations (\"Seg.\"). Note that the upper right 3 3 matrix is identical to Eq. (11). The original JLF estimates the block diagonal elements of the generalized covariance matrix (highlighted in magenta, green, and yellow) which would result in independent temporal estimates.\nThe longitudinal target images provide registered atlases, where each atlas corresponds to one time point (target image). The consensus segmentation \u0305 for voxel on target image is \u0305 \u2211 \u2022 ,where , , \u2026 , are spatially varying weights restricted by \u2211 1 . Adopting [10] , the error made by atlas on target image in the binary segmentation is , where is the hidden true segmentation. 0 indicates the right decision is made, while 1 or 1 means the wrong decision is made. Then, our purpose is to find a set of voting weights for each target image that minimize the total expected error between the automated labeled image \u0305 and hidden true , given by the following energy function\nwhere is the transpose of vector at voxel . is a pairwise dependency matrix that , 1| , \u2026 , , , \u2026 , .Finally, the estimated weights , which is our target, is derived by arg min"}, {"section_title": "JLF-Multi", "text": "As a baseline, we consider to use simple temporal model (JLF-Multi) to perform the 4D label fusion. We assume that each target image in contributes equally to the label fusion for target . In this case, , is can be approximated as\nwhere the \u03a3 improves the spatial smoothness by adding multiple voxels in a patch neighborhood (e.g., 2 2 2 by default), and the non-local patch searching is conducted within a search neighborhood (e.g., 3 3 3 by default)."}, {"section_title": "4DJLF", "text": "In JLF-Multi, each longitudinal target image contributes equally to the 4D label fusion. However, this assumption is not always valid. Herein, we propose the new dependency matrix , by adaptively evaluating the longitudinal raters' performance on any target image patches using a probabilistic model ,\nwhere the new dependency matrix , not only evaluates the similarity between atlases and target images but also considers the longitudinal similarities between target images. The \" \" and \" \" indicate which atlases that and were registered to and the value of and are derived from Eq. (1). Then, probability of using the raters (atlases) from and given target is modeled in a conditional probability\nby assuming and are conditionally independent, we have\nwhere is a sensitivity coefficient and is empirically set to 100 in the experiments."}, {"section_title": "Relationship between 4DJLF to JLF", "text": "The proposed 4DJLF theory is a generalization of JLF. If the is set to a large number, the , will be large for atlases from other time points, but still equals to 1 for the atlases from the target image itself. Therefore, the weights of the atlases from other time points will be close to zero and essentially only the atlases registered to the target time are considered. In that case, 4DJLF degenerates to JLF. To see the relationship in Fig. 2 , we redefine the right side of Eq. (5).\nThen, we define a matrix \u03a6 , as the following\nwhere 1 1 and 1 1. For simplify, we assume three longitudinal target images are used and the first time point is the target image (upper row in Fig. 2) . We rewrite the as to visualize the at the first time point ( 1 and the subscript is omitted for simplicity).Since 1, the is further simplified to\nwhere is identical to the upper right matrix in Fig. 2 .Note that \u03a6 1,1 is the same as the in JLF [10] , which demonstrates the relationship between 4DJLF and JLF."}, {"section_title": "Experimental Methods and Results", "text": "Six healthy subjects with 21 longitudinal T1-weighted (T1w) MR scans (mean age 82.3, range:72.5~90.2) were randomly selected from Baltimore Longitudinal Study of Aging (BLSA) [11] . Each image had 170 256 256 voxels with 1.2 1 1 mm resolution. 15 pairs of atlases from BrainCOLOR (http://braincolor.mindboggle.info/protocols/) were employed. The intensity atlases had 1mm isotropic resolution and the label atlases contained 132 labels. In order to evaluate the sensitivity, one randomly selected T1w image from a healthy subject (age 11) in ADHD-200 OHSU dataset (http://fcon_1000.projects.nitrc.org/indi/adhd200/) was used in the robustness test. The 21 longitudinal target images were first affinely registered to the MNI305 atlas. Then, the spatially aligned longitudinal atlases , , \u2026 , were derived by rigidly registering each target image to the first time point. Then, 15 atlases were non-rigidly registered [12] to all target images to achieve the intensity and label atlases in Eq. (1) (performed 15 21 non-rigid registrations). The same preprocessing was also deployed to the one ADHD-200 target image.\nJLF was deployed on all 21 longitudinal target images independently using default parameters. The longitudinal reproducibility of JLF, JLF-multi and 4D JLF were evaluated by calculating the Dice similarity coefficients between all pairs of longitudinal images (Fig. 3a) Wilcoxon signed rank test and Cohen's d effect size were performed on JLF-Multi vs. JLF and 4D JLF vs. JLF. The \"*\" indicated the difference satisfied (1) p<0.01 in Wilcoxon signed rank test, and (2) d>0.1 in effect size. The temporal changes on volume sizes of whole brain, gray matter and white matter were shown in Fig. 4 . Fig. 5 shown the qualitive results from subject 5 in Fig. 4 .\nSecond, a robustness test was conducted to evaluate the sensitivity of JLF, JLF-Multi and 4DJLF. We combined the previously mentioned ADHD-200 image to each target image to formed 21 dummy longitudinal pairs. This test simulated the large temporal variations since the two images in each pair were independent and collected from different scanners. Then, the 4D segmentation methods were deployed on such cases to see if the 4D methods can maintain the sensitivity compared with JLF. The Fig. 3b indicated the 4DJLF had \"trivial\" changes on reproducibility (effect size <0.1) compared with JLF, while JLF-Multi had large differences compared with JLF. "}, {"section_title": "Conclusion", "text": "We propose the 4DJLF multi-atlas label fusion strategy by modeling the spatial temporal performance of atlases. The proposed theory incorporates the ideas from the two major families of label fusion theories (voting based fusion and statistical fusion) by generalizing the JLF label fusion method to a 4D manner. The results demonstrated that the proposed method was not only able to improve the longitudinal reproducibility (Fig. 3a, 4 and 5) but also reduces the segmentation errors compared with traditional 3D JLF (Fig. 5) . Meanwhile, the 4DJLF did not significantly change the segmentation reproducibility when performing on dummy longitudinal pairs of images (Fig 3b) . "}]