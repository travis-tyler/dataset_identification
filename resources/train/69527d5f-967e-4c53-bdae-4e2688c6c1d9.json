[{"section_title": "Introduction", "text": "Hurricanes are among the most destructive natural phenomena on earth. They form over warm tropical and subtropical oceans during summers or early fall. Upon making landfall, hurricanes can cause significant property damage, and loss of life [1]. Timely analyses and forecasts of track, intensity and wind structure can help authorities raise warnings, evacuate high-risk regions, estimate expected losses, and minimize mortalities. Due to the limited availability of direct measurements, satellite images of hurricanes throughout their life cycles have been analyzed for the past several decades. One of the earliest methods for tropical cyclone (TC) intensity estimation is the Dvorak technique [2], which is a manual method that characterizes a TC based upon the cloud structure seen in an image. To reduce the reliance on human experts, the Objective Dvorak Technique [3] was proposed in 1989 for automatic intensity estimation based on rules similar to the original Dvorak technique. More sophisticated rules were introduced in the Advanced Dvorak's Technique [4], which resulted in an improvement in prediction accuracy. However, human involvement was still required and the method could not be automated completely. Since then, many studies have been carried out to help automate the process for improvement in speed and reduction in need for human intervention. A brief description of several of such studies is presented below. Pi\u00f1eros et al. [5] proposed a method based on the variance of the deviation angle of brightness temperature values in infrared (IR) images. Their method was built on the premise that the lower the variance in the histogram of deviation angles, which is inversely proportional to TC organization, the higher would be intensity of the TC. A sigmoid curve was fit to use variance of deviation angles for intensity estimation. In their study, Pi\u00f1eros et al. used IR images from the GOES-12 satellite for hurricanes in years 2004-2009 in the North Atlantic Basin. Their method gives a root-mean-squared error (RMSE) of 14.7 knots when evaluated over a randomly selected set of hurricanes over the period [2004][2005][2006][2007][2008]. The same model, when trained over data from 2004 to 2008 and tested over TC IR images from year 2009, produced an RMSE of 24.8 kt. An improved version of their technique was presented by Ritchie et al. [6]. That study added some additional constraints to the existing technique and re-trained it after removing low-intensity (\\ 34 kt) TC images from data and using data from an additional year (2010). This resulted in an RMSE of 12.9 kt. The Deviation Angle Variation technique was used to estimate the intensities of TCs in the north Pacific ocean in a 2013 study [7] with an RMSE of 14.3 kt. [8] proposed a k-nearest neighbor-based algorithm for TC intensity estimation. Their algorithm estimated the intensity based on the intensity of the 10 most similar images to the query image. In a study carried out by Jaiswal et al. [9] brightness temperature histograms in the radial and angular directions were computed and histogram matching was used for intensity predictions. Their study used TC data collected using satellites GOES-8 and -12 from 2000 to 2005 from the HURSAT database [10]. The method yielded an overall RMSE of 15.5 kt. The study by Zhao et al. [11] presents a multiple regression-based method using deviation angle and radial profiles in IR images for intensity estimation. The method was tested on hurricane data from northwestern Pacific Ocean over the years 2008 and 2009, and an RMSE of 12.1 kt was reported. The objective of our study is to develop a machine learning-based automated system that can predict intensity of a hurricane when given its satellite infrared (IR) image. The workflow of the proposed system is illustrated in Fig. 1. The proposed system computes statistical and deviation angle-based features for an input IR image. For prediction, the features are passed to a machine learning model that has been trained using existing data comprising of satellite images of previous hurricanes with known intensity. In this paper, we present details of our proposed method. The dataset, feature extraction and machine learning models are described in Sect. 2, results are presented in Sect. 3 and conclusions are summarized in Sect. 4."}, {"section_title": "Methods", "text": "In this section, we present the details of the dataset, feature extraction technique, machine learning models and the experimental setup employed in our study. The primary task of the proposed technique is to use machine learning for predicting the maximum sustained wind speed or intensity of a hurricane (in knots or kilometers per hour) from infrared satellite images of the hurricane. Section 2.1 provides a description of the dataset used for training and evaluation of the machine learning model. In Sect. 2.2, we explain feature extraction methods. Analysis of feature importance is presented in Sect. 2.3. Different machine learning models analyzed in the study are described in Sect. 2.4. Post-processing and experimental setup used for performance evaluation are explained in Sects. 2.5 and 2.6, respectively."}, {"section_title": "Dataset", "text": "Our study used infrared images from the publicly available HURSAT-B1 (version-05) dataset [10] of different hurricanes. The original dataset contained hurricane season data for years 1978-2009 and included imagery from multiple satellites including SMS-2, GOES-1 to 13, Meteosat-2 to 9, GMS-1 to 5, MTSAT-1R, MTS-2 and FY2-C/E. HUR-SAT-B1 contains both visible and IR window channel imagery. Some example satellite infrared images from the dataset are shown in Fig. 2 in false coloring. A pixel value corresponds to temperature at a certain location as captured by the satellite with higher temperatures shown in red and lower ones shown in blue. The spatial resolution of the data are about 8 km/pixel (4.32 nautical miles per pixel), i.e., a single pixel represents the average temperature in an 8 km 9 8 km region on the Earth's surface. The dataset contains images from a number of hurricanes taken every 3 h for each hurricane. Images in the dataset are centered on the TCs. Information about the intensity of a given image of a hurricane was taken from IBTrACS (International Best Track Archive for Climate Stewardship) [12]. The intensity of a hurricane at a given time is defined as the maximum sustained surface wind speed (in knots) of the hurricane at a height of 10 m from the surface of the Earth over a period of 1 min (60 s). Based on the maximum sustained surface wind speed (in knots), a tropical storm can be classified into five categories. IBTrACS stores the intensity of the hurricane based on a consensus of automated, semi-automated and aircraft reconnaissance data. In line with previous studies, the best track data were linearly interpolated to match the temporal resolution of the image data. We used the intensity in knots as our target or output value. We restricted our study to hurricane data collected by GOES-12 satellite in the North Atlantic Basin from years 2004 to 2009. Only infrared (IR) window channel imagery was used in our study. Images taken after a TC made landfall were removed from the dataset for our experiments. The subset used in the study included a total of 4552 images. Details about the intensity distribution of the sample are presented in Table 1."}, {"section_title": "Feature extraction", "text": "In satellite IR images, high-intensity TCs present themselves as well-organized low-temperature circular cloud structures. For low-intensity TCs, the cloud structure becomes less organized. This phenomenon is shown in Fig. 2. It can be seen that as the intensity increases, the cloud structure becomes more symmetric and the organization of the clouds increases. This relationship was also the basic premise of the deviation angle technique described earlier. We use the above-mentioned phenomenon to extract features for intensity estimation of TCs. That is, the region around the center tends to exhibit a more uniform lowtemperature circular structure in high-intensity TCs in comparison with low-intensity TCs. Therefore, we compute statistical features around the center to characterize the TC structure. To compute these features, we first divided each image into five circular bands of eight pixels   Katrina (2005). It can be seen that the cloud gets organized to a circular structure as the intensity increases each (equivalent to 64 km or 34.56 nautical miles) around the center. For each band, mean, standard deviation (SD), entropy, minimum and maximum are computed. Division of images into bands is illustrated in Fig. 3. Formulae for computation of statistical features are listed in Table 2. The correlation of these features with hurricane intensity is shown in Fig. 4 as discussed in the next section. In addition to the statistical features, we used variance of the deviation angle histogram as another feature for TC intensity estimation. The idea was motivated from the approach proposed by Pi\u00f1eros et al. [5]. Deviation angle at a pixel is defined as the angle between the gradient vector and the line joining the hurricane center and that pixel. For well-organized circular structures, most of the deviation angles around the center are zero or near to zero. The concept is illustrated in Fig. 5a-c. Since high-intensity TCs exhibit more circular structures, most of the deviation angles in their images would be small and the histogram of these angles will have a low variance. We have used variance of deviation angle histogram for 81 9 81 pixel window (equivalent to 648 9 648 km or 350 9 350 nautical miles) centered at the center of an image as another feature."}, {"section_title": "Analysis of importance of features", "text": "To assess the effectiveness of statistical features around the center for intensity estimation, we plotted the features against intensity values for hurricane Rita (2005). The scatter plots are shown in Fig. 4. It can be seen that a high negative correlation exists for most of the features. For example, the mean temperature of bands 2-4 shows negative correlations with magnitude greater than 0.75 with TC intensity. Similarly, the standard deviation of IR values also shows a high inverse correlation. Thus, the mean IR intensities within 24-48 km (12.96-25.92 nautical miles) of the center of the TC and their uniformity are highly predictive of intensity. The entropy and maximum values of temperatures in various bands are also inversely correlated with intensity. These plots clearly show the efficacy of using these statistical features in our technique. The effectiveness of the Deviation Angle Variance feature in terms of correlation with true intensity values has also been measured for hurricane Rita (2005). The plot for deviation angle variance versus true intensity values is shown in Fig. 5d. It is worth mentioning here that simple statistical features such as mean, standard deviation, minimum and maximum temperatures for the third band produce comparable correlation values as the complex deviation angle variance-based feature. Hence, we deduce that the statistical features despite being simpler, are as informative as deviation angle variance feature and hence, may help improve hurricane intensity predictions."}, {"section_title": "Machine learning models", "text": "In this study, our goal is to develop a system that, given a TC image and a center position, can predict its intensity. We have modeled the problem of predicting the intensity of a hurricane at a given time as a regression problem. For this purpose, we consider a dataset of N example training images represented by their d-dimensional feature vectors x 1 ; x 2 ; . . .; x N corresponding to different infrared satellite images of hurricanes and their associated intensity values y 1 ; y 2 ; . . .; y N in knots. The objective of hurricane intensity prediction is to develop a machine learning prediction function f \u00f0x\u00de that can predict the intensity of the hurricane at a given time using a feature vector x corresponding to an image of the hurricane at that time. To choose the bestsuited machine learning model for this problem, we carried out detailed performance analysis and comparison over different regression techniques: Ordinary Least Square (OLS) [13], Support Vector Regression (SVR) [14] with Radial Basis Function (RBF) kernel, feed-forward backpropagation neural networks (BPNNs) [19] and gradient boosted tree (XGBoost) regression [20]. To establish if  these models are significantly effective in comparison with a na\u00efve prediction, we compared their results to a zeroorder baseline that uses the average intensity of the hurricanes in our dataset as a constant prediction. Multiple machine learning techniques were compared to identify the best suited one for this task and to analyze the effectiveness of features used in this work by studying the difference in prediction errors of these techniques. Low variation in performance across the techniques implies that the features are significantly informative and a difference in choice of machine learning model would not have a considerable impact on the accuracy of the system and that the deployed model will generalize well to unseen cases. Further details of performance comparison are presented in Results section. In the following sections, we present description of the various techniques used in this study."}, {"section_title": "Baseline method", "text": "To establish a baseline, we used the average intensity of TCs in the whole dataset as a zero-order intensity estimator for any given image."}, {"section_title": "Ordinary least square (OLS) regression", "text": "OLS is one of the simplest regression techniques. The principle of OLS is to find a linear function that minimizes the sum of squared errors between target and estimated values for a given dataset. The objective in OLS is to find parameters w and b of a linear function f x \u00f0 \u00de \u00bc w T x \u00fe b such that that the difference between the target value y i and f x i \u00f0 \u00de is minimized for all training examples i \u00bc 1. . .N. The OLS learning problem can be written as: The parameters estimated from training data are then used for estimation of values for independent cases. There are two shortcomings of using OLS for our problem. First, OLS is prone to over/under-estimation due to the presence of outliers, as its sole aim is to minimize the sum of squared errors [15]. Second, we were not sure if a linear function would successfully be able to model the relationship between the features we extracted and the corresponding intensity values. Therefore, we needed a method that was less sensitive to outliers, offered better generalization and could model nonlinear relationships. As a consequence, we used Kernelized Support Vector Regression [14]."}, {"section_title": "Kernelized support vector regression", "text": "Kernelized SVR is a variant of Support Vector Regression which, originally, is a linear regression technique, i.e., its prediction function can also be written as: f x \u00f0 \u00de \u00bc w T x \u00fe b. However, it can work for nonlinear estimation using kernel functions. For a given dataset, SVR finds a weight vector w such that the norm of w is minimized and the absolute difference between the actual and predicted values for all examples does not exceed a threshold e [ 0. The optimization problem in this case can be given as: min w;b w 2 such that f x i \u00f0 \u00de \u00c0 y i j j \\e for all i 2 1; 2; . . .; N f g . Minimization of the norm of the weight vector ensures that the weight values do not become large and small changes in the inputs do not cause a large variation in the output. This regularization helps improve prediction performance in high dimensional and noisy feature spaces. To allow some violations, a nonnegative slack variable n i is introduced for each example x i and the optimization problem can therefore be modified to min w;b;n<0 w . . .; N f g . This problem formulation ensures that the prediction errors are minimal, and the predictor is regularized. The hyper-parameter C controls the amount of penalty imposed for each constraint violation. It is important to note that SVR minimizes the absolute error and not the square-error function. This reduces the impact of outliers in comparison with OLS. An alternative representation of the SVR [14], allows nonlinear regression by using RBF kernel functions k a; b \u00f0 \u00de \u00bc exp \u00c0ca \u00c0 b 2 \u00c0 \u00c1 and changing the prediction function to , [17]. This kernelized formulation of the SVR learns parameters a i while enforcing regularization and error minimization over training data. The kernel function k a; b \u00f0 \u00de is a symmetric positive definite function that essentially measures the degree of similarity between examples. We have used SVR with RBF kernel for our experiments as RBF has the ability to model spaces of very high dimensionality effectively [18]. The hyperparameters c and C are set using nested cross-validation."}, {"section_title": "Backpropagation neural networks", "text": "Neural Networks are function approximators inspired from the structure of human brain. They are composed of layers of small computational units called neurons. The output of  is the probability of v i based on its relative frequency or counts of occurrence. neurons in a layer is fed to the neurons in the next layer. Each neuron computes its output by applying an activation function over the dot product of its weights and inputs. The final output is computed in the last layer. During training, the objective is to minimize the error between output of the neural network and the target values. To fit a model using a BPNN, an example or a batch of examples from the training data is passed to the network and output is computed. The error is calculated and weights of the network are updated in a direction opposite to the gradient of error [19]. The process is repeated iteratively to minimize training loss. Since the error surface is not always convex, backpropagation may yield suboptimal solutions. For comparison with our methods, we have used a BPNN with two hidden layers, 64 neurons per layer, and rectified-linear unit (ReLu) activation functions with a single output layer neuron. The neural network has been implemented using Keras [21]."}, {"section_title": "XGBoost", "text": "XGBoost [20] is a random forest-based method that uses gradient boosted decision trees. A decision function that performs minimization of average regression loss is learned using gradient boosting on a set of decision trees trained in an iterative manner. The training in each increment is performed using residual error of the preceding step. Further details of the technique can be found in [20]. In our experiments, we used Python XGBoost v. 0.7 API for XGBoost regression."}, {"section_title": "Post-processing", "text": "Our model generates predictions using a single image. To reduce noise, a time-smoothing operation is performed after generating predictions for different images of a TC. For this purpose, we used a simple linear exponentially weighted averaging filter that, at a time step t, produces a weighted average of predicted intensities for current and previous time steps as follows: It is important to note that the coefficients of the filter sum to 1.0 and decrease exponentially with time. "}, {"section_title": "Experimental setup", "text": "We performed multiple experiments over features and regression models discussed earlier for the 2004-2009 sample. We have used root-mean-squared error (RMSE) [22] as the performance metric to evaluate and compare the efficacy of our methods with previously published works. Results for the experiments are presented and discussed in Sect. 3."}, {"section_title": "Leave one TC out cross-validation", "text": "For all TCs over the period 2004-2009, we left one hurricane out for testing and trained over the rest. RMSE scores for each of the test hurricanes were computed and then averaged. The experiment was performed for all of the regression techniques described in Sect. 2.4: OLS, SVR, Feed-forward BPNN and XGBoost.\nUsing the mean intensity (zero-order predictor) as the predicted intensity for a given image, gives an RMSE of 24.3 kt as shown in Table 3. This is the expected maximum error of any technique and is used as a baseline for comparison. For evaluation of our method, we used leave one hurricane out cross-validation model as described in Sect. 2.4.1. Mean RMSE values obtained using SVR, OLS, BPNN and XGBoost regression models are presented in Table 3. Using SVR, we obtained a mean RMSE of 11.2 kt. As expected, the proposed method performs much better than the zeroorder predictor. The error of SVR is much lower than other machine learning models. Furthermore, the post-processing smoothing step reduces these errors even further to 9.5 kt which is comparable to CIMSS satellite consensus (SAT-CON) intensity prediction error (9.1 kt) [23]. We have also performed leave one TC out cross-validation with a feed-forward backpropagation neural network. The average RMSE for the neural network is 12.0 knots which is marginally higher than RMSE of 11.2 knots obtained with support vector regression. We tuned different parameters of the neural network but no significant reduction in error was noted. We have also used XGBoost regression for this problem which gives an RMSE of 11.3 knots after optimization of various hyper-parameters such as the number of estimators and subsampling. Figure 6 shows a scatter plot of the true and SVR-predicted intensities for all images of all TCs. The overall Pearson correlation between true and predicted intensities is 0.91, whereas, the overall RMSE is 10.6 kt, which indicates the effectiveness of our approach. Figure 6 also shows RMSE errors for different TC stages. We hypothesize that the increased error at higher intensities is a consequence of the presence of relatively fewer training images at these intensities (see Table 1) and the nature of the error function (RMSE) being used. For a deeper evaluation of the performance of our method, we present plots of SVR-predicted versus actual intensities for hurricanes Katrina and Rita (2005) in Figs. 7 and 8, respectively. A high correlation can be observed for both the cases. It can be seen that, in contrast to most of the existing techniques, our method performs well even for low-intensity images."}, {"section_title": "Stratified error analysis", "text": "We have performed stratified error analysis of our method for different stages of TC development to get an idea of prediction accuracy for low versus high-intensity hurricanes using leave one TC out cross-validation.\n"}, {"section_title": "Comparison with deviation angle variance technique", "text": "To compare our method with the deviation angle variancebased method, we replicated the experiments carried out in [5]. Two experiments were performed in the study. The first experiment uses data from 2004 to 2008. The following hurricanes were left out for testing: Bonnie (2004), Earl In the second experiment, all TCs from 2004 to 2008 were used for training and data from 2009 were used for testing. We report the RMSE results for both OLS and SVR.\nResults of the two experiments replicated from [5] are given in Tables 4 and 5. The comparison of our approach with their results using the same experimental conditions show that all machine learning models used in this work outperform their approach in both the experiments. A major improvement has been seen in the second experiment (Table 5), where the TCs from years 2004 to 2008 were used for training and testing was performed on hurricanes in 2009. We obtained a mean RMSE of 13.4 kt compared to the previously reported 24.8 kt [5]. Postprocessing using temporal smoothing filter improves the results even further to 11.5 knots. It is important to note that the proposed scheme offers better accuracy than the recently published method by Zhao et al. [11] which gives an RMSE of 12.1 knots over typhoons in the northwestern Pacific Ocean in 2009 as well."}, {"section_title": "Leave-one-year-out cross-validation", "text": "In this experiment, we used the data for all years from 2004 to 2009. TCs from 1 year are left out for testing and training is performed over the rest. This experiment was performed to compare our method with the improved version of the DAV technique [5] proposed by [6]. Their experiment used long-range IR images from GOES-E satellite and used data of one additional year (2010). We report RMSE results for our data using the same leave-oneyear-out cross-validation method.\nIn this experiment, the aim was to compare our method with the improved version of the method proposed by [5] in [6]. They used TC data over the period 2004-2010. Our dataset comprised data over the period 2004-2009 obtained We have compared the performance of SVR, OLS, XGBoost and BPNN for leave-one-year-out cross-validation over all the images including both high and low intensity examples. The comparison is presented in   Katrina (2005). The RMSE values obtained for SVR predictions before and after filtering are 13.9 kt and 10.9 kt, respectively Table 6. As evident from the results, SVR gives better prediction accuracy (RMSE of 11.1 knots) in comparison with other machine learning models. For TC data with a minimum intensity of 34 kt, all machine learning models perform better than the DAV [5] and Improved DAV techniques [6] (Table 7). It can be seen that including the low intensity examples did not have much effect over the performance of our method. It can, therefore, be concluded that the proposed method is more robust and has a better performance than the previously published techniques.   "}, {"section_title": "Comparison with aircraft reconnaissance data", "text": "Aircraft reconnaissance data is available for several hurricanes and it gives very reliable estimates of hurricane intensity at certain times. We compared the predictions of the proposed model with aircraft measurements by performing leave one TC out cross-validation and restricting our error evaluation to only those times that were within 3 h of an aircraft pass.\nOn restricting our error evaluation to only those points in time that are within 3 h of an aircraft pass, we get a mean RMSE of 12.1 kts which is only slightly above the average RMSE for leave one TC out cross-validation (11.2 kts). This clearly illustrates the true generalization performance of the proposed scheme."}, {"section_title": "Center annotation error analysis", "text": "As the proposed scheme relies on center annotations for feature extraction, we also analyzed the effect of error in annotating the center of the hurricane on intensity estimation. For this purpose, we selected a single hurricane from every year at random for evaluation through leave one TC out cross-validation. The annotated center in IR images of a hurricane was shifted along both axes by a random amount within the interval \u00c0r; \u00fer \u00bd prior to feature extraction and intensity prediction. The magnitude of the shift, r, was varied from 0 to 10 pixels (corresponding to a maximum center position error of 80 km or 43.2 nautical miles) to model the effect of center annotation errors of existing center prediction methods [1]. This process is repeated five times for each hurricane to get reliable estimates. The prediction error of the proposed technique is then plotted against the magnitude of the shift in the annotated center for analyzing the effect of center annotation error on intensity prediction error.\nThe plot of prediction error in response to center annotation error is shown in Fig. 9. It shows that the proposed system undergoes graceful degradation in performance with an increase in center annotation error. Figure 9a shows the effects of random center shifts in hurricane RITA 2005 images, whereas Fig. 9b shows the change in prediction accuracy as a consequence of random center shifts for five different hurricanes. The average RMSE increases from 11.5 to 16.5 kts for these hurricanes as the pixel shift is varied from 0 to 10 pixels (corresponding to 80 km or 43.2 nautical miles). [24] showed that when only satellite data were available, the mean position uncertainty of tropical storms, hurricane, and major hurricanes was 29, 21 and 14 nautical miles, respectively. These roughly correspond to seven, five and three pixel displacements in Fig. 9. For hurricanes and major hurricanes, Fig. 9 suggests that the position uncertainty would only slightly degrade the intensity estimates. For tropical storms, the impact is larger. Tests with real-time position estimates are needed to assess the accuracy of our system for operations."}, {"section_title": "Analysis of images from other channels", "text": "The focus of this study has been to predict TC intensity from IR images. However, in order to assess the effectiveness of the features proposed in this work over data from other channels, we have also evaluated leave-oneyear-out cross-validation analysis over other available channels including: Visible channel observations (VSCHN), water vapor observations (IRWVP), near-infrared channel observations (IRNIR) [10].\nLeave-one-year-out cross-validation results using our proposed features over images from near-infrared (IRNIR), water vapor (IRWVP) and visible (VSCHN) channels through SVR, OLS, BPNN, and XGBoost machine learning models are presented in Tables 8, 9 and 10, respectively. The best mean RMSE values for the three channels are 12.3 kts (using XGBoost), 12.3 kts (using SVR) and 17.9 kts (using XGBoost), respectively. It is important to note that although these values are higher than the RMSE obtained using IR channel (11.1 knots with SVR), the relatively small decrease in accuracy for other channels, especially the near-IR and water-vapor channels, clearly indicates the effectiveness of the features proposed in this work. The poor performance in visible channel images can be attributed to the quality of these images being dependent upon lighting conditions."}, {"section_title": "PHURIE webserver", "text": "We have developed a freely available webserver called PHURIE (PIEAS HURricane Intensity Estimator) for the proposed method which accepts an IR image in NetCDF file format, extracts features, and generates a prediction from machine learning model. The center of the image input should correspond to the center of the hurricane. PHURIE uses a kernelized SVR model, since the SVR-based models had shown to generally outperform others in different experiments. Details of the performance comparison of different regression techniques are presented in the Results section. It is important to note that the webserver generates predictions using a single input image without any postprocessing. The websever has been developed using Python and scikit-learn and is available at the URL: http://faculty. pieas.edu.pk/fayyaz/software.html#PHURIE."}, {"section_title": "Results and discussion", "text": "In this section results for all the experiments performed under the setup discussed in the previous sections are presented and discussed."}, {"section_title": "Conclusions and future work", "text": "In this paper, we presented a support vector regressionbased technique for TC intensity estimation from satellite IR images. Since the shape of the cloud patterns helps in estimation of TC intensity in manual methods, we used several statistical features to characterize the structure in circular bands around the center of a hurricane image. These features included mean, minimum, maximum, standard deviation and entropy of bands. Apart from these features, variance of deviation angle histogram of an image Best results for each year are shown in bold was also used. The method proposed in this paper gives robust and state of the art performance on a number of different experiments and can be adapted for practical use. The features proposed in the study can also be employed for other prediction tasks related to hurricane IR imagery such as path-tracking. Although the main focus of this study was hurricane intensity prediction using infrared images, we have evaluated the proposed method on images from other channels including near-infrared, water vapor and visible channels. In the future, we plan on making a single machine learning method that can learn to predict both the center of a hurricane and its intensity. The results from this study show that the PHURIE intensity estimates are more accurate than other automated methods documented in published papers, and comparable to methods that use a consensus of several methods (such as the CIMSS SATCON). However, some assumptions such as the use of best track positions may inflate the accuracy of the estimates. The next step is to perform completely independent tests using only input that is available in real time. That will provide a true estimate of applicability of PHURIE for operational forecast centers.  Lowest RMSE values for each year are in bold Bold values represent the lowest RMSE for a given year Best results for each year are shown in bold Neural Computing and Applications (2020) 32:4821-4834"}]