[{"section_title": "Abstract", "text": "Abstract"}, {"section_title": "Introduction", "text": "Atlas-based segmentation has been widely applied in medical image analysis. This technique applies examplebased knowledge representation, where the knowledge for segmenting a structure of interest is represented by a prelabeled atlas. Through establishing one-to-one correspondence between a target image and an atlas image by imagebased deformable registration, the segmentation label can be transferred to the target image from the atlas.\nSegmentation errors produced by atlas-based segmentation are mostly due to registration errors. One effective way to reduce such error is to use multiple atlases. When multiple atlases are available, each atlas produces one candidate segmentation for the target image and the final segmentation is obtained through label fusion that integrates the results obtained from referring to different atlases. Recently, the label fusion technique has been applied in computer vision for segmenting natural images as well [19, 12] .\nMany label fusion methods are based on weighted voting, where each atlas contributes to the final solution according to a weight. For instance, majority voting [15, 9] applies equal weights to every atlas. The STAPLE algorithm [23, 14] is related to majority voting but is more advanced by taking the segmentation qualities into consideration for label fusion. One key limitation of these two methods is that they make decisions purely based segmentations and completely ignores the information conveyed by images. As recent studies have shown that, as a good indicator of registration accuracy, image similarity between the atlas and target should be included to improve voting weight assignment for more accurate label fusion. Among image similarity-based weighted voting methods, those that derive weights from local image similarity, and thus allow the weights to vary spatially, have been most successful in practice [1, 10, 16, 3, 25, 22] .\nOur key contribution is to identify and describe the pattern of a spatial bias produced by weighted voting based label fusion. Under mild assumptions, we show that due to the errors in deformable registration, label fusion via image similarity based weighted voting can be modeled as applying a spatial convolution operation to the ground truth spatial label posterior probability maps. The convolution kernel can be approximated by a function that combines the distribution of residual registration errors and the function transferring image similarities into voting weights. Due to this spatial bias, weighted voting based label fusion tends to produce segmentations underestimating the volumes of structures with convex shapes.\nTo reduce this bias, we apply standard spatial deconvolution to the fused label posterior maps after properly estimating the convolution kernel. In a brain image segmentation application that segments the hippocampus from magnetic resonance images (MRI), we demonstrate the spatial bias produced by majority voting and one recent similaritybased local weighted voting approach. The spatial bias is prominently reduced by the deconvolution method.\nTo improve multi-atlas segmentation, an alternative solution is to improve the accuracy of image-based registration. However, since it is almost impossible to produce error free image-based registration, the spatial bias induced by regis-tration error is inevitable. Hence, our results have utility regardless of how accurate the applied registration algorithm is. In our experiment, we used Symmetric Normalization (SyN) [2] , which was a top performer in a recent evaluation study [11] comparing 14 freely available deformable registration algorithms, and the spatial bias could still be clearly observed."}, {"section_title": "Label fusion by weighted voting", "text": "In this section, we briefly describe the weighted voting techniques used in label fusion. Let be a target image to be segmented and 1 = (  1 ,  1 ) , ..., = ( , ) be atlases, warped to the space of the target image by deformable registration. and denote the \u210e warped atlas image and manual segmentation. Each is a candidate segmentation for the target image. Label fusion combines these candidate segmentations to produce the final solution.\nMany label fusion methods are based on weighted voting. For instance, the combined votes for label are:\nwhere indexes through image locations.\u02c6( | , ) is the estimated label posterior for the target image. ( | , ) is the probability that votes for label at , with \u2211 \u2208{1,..., } ( | , ) = 1. is the total number of labels. Typically, for deterministic atlases that have one unique label for every location, ( | , ) is 1 if = ( ) and 0 otherwise.\nis a local weight assigned to the \u210e atlas, with \u2211 =1 = 1. The voting weights are typically determined based on the quality of registration produced by each atlas such that more accurately registered atlases are weighted more heavily in producing the final solution. To estimate this weight, similarity metrics typically employed by image-based registration such as sum of squared distance (SSD) and normalized cross correlation (NCC) can be applied. For instance, when SSD and a Gaussian weighting model are used [16] 1 , the weights can be estimated by:\nwhere is a model parameter.\n( ) defines a neighborhood around and ( ) is a normalization constant. In our experiment, we use a (2 + 1) \u00d7 (2 + 1) \u00d7 (2 + 1) cubeshaped neighborhood specified by the radius . For robust image matching, instead of using the raw image intensities, the intensity vector obtained from each local image intensity patch is normalized to have zero mean and a constant norm 1.\nWith the estimated posterior probability map for each label, the final solution is determined by selecting the label with the highest posterior at each voxel.\nRefining label fusion by local patch search. As recently shown in [21, 4] , the performance of atlas-based segmentation can be improved by applying a local search technique. This method also uses image similarities over local image patches as indicators of registration accuracy and remedies registration errors by searching for the correspondence that gives the most similar appearance matching, within a small neighborhood around the registered correspondence in each warped atlas. The locally searched optimal correspondence is:\n( ) is the location in \u210e atlas with the best image matching for location in the target image within the neighborhood \u2032 ( ). Again, we use a cubic neighborhood definition, specified by a radius . Given the set of local search correspondence maps { }, we estimate the label posterior"}, {"section_title": "Spatial bias induced by registration errors", "text": "In this section, we describe a spatial bias in weighted voting based label fusion and develop solutions to reduce this bias."}, {"section_title": "Residual spatial displacement errors resulted from image-based registration", "text": "Errors produced by atlas-based segmentation are mainly due to registration errors, i.e. the correspondence computed from registration is incorrect. Hence, characterizing the influence of the residual registration error is critical for understanding the bias in label fusion.\nLet be the residual spatial displacement error in the warped atlas such that the correct correspondence for location in is \u2212 in . Hence, we have:\nwhere is a random error caused by effects such as partial volume, errors and random variation in atlas segmentations. We use 1 norm to quantify the residual spatial displacement error, i.e.\nThe residual spatial displacement error can be modeled by a random variable, characterized by a distribution . When image-based registration is reliably performed, the expected residual spatial displacement error is small."}, {"section_title": "Bias induced by residual registration errors", "text": "As shown in recent studies, deriving voting weights from image similarities over local patches is one of the most effective weighted voting strategies. Our study starts with investigating how well the residual registration error correlates with the local image similarity. In this test, for each voxel within a manually label hippocampus in one image, we computed the SSD between the normalized image patch ( =2) extracted at this voxel and normalized image patches extracted at voxels within its neighborhood. The left figure shows the mutual information between spatial errors, i.e. the distance between the two voxels, and local image similarities at different spatial errors. Given a spatial error specified in the X-axis, the mutual information is computed using all pairs of local patches with distances no greater than the error. To quantify the entropy of local image similarities, we uniformly divide the image similarity value range [0,4] into 100 bins. The right figure plots the average local image similarity at different spatial errors (bars at \u00b11 s.d.). Note that when spatial errors are small (i.e. \u2264 4mm), spatial errors strongly correlate to local image similarities. This strong correlation quickly diminishes as the spatial error increases.\nStrong image similarities over small patches between two registered images do not necessarily indicate small spatial displacement errors. However, as shown in Fig. 1 , when spatial errors are small enough, image similarities over local patches are strongly correlated with spatial displacement errors, with high mutual information and less ambiguous relation between spatial errors and image similarities. Since most residual spatial errors are small after image-based registration, we can approximately represent the voting weight estimated from the local image similarity as a function of the residual registration error. Hence, we have:\nwhere approximates the local image similarity given the spatial error and is the weighting function that transfers local image similarities into voting weights. In fact, approximating spatial displacement errors by local image similarities has been applied by most image-based registration and similarity-based local weighted voting methods. An example of returns the average image similarity or the most likely image similarity given a spatial error. Since an ideal weighting function assigns smaller weights to poorly registered atlases, ( ( )) should be a decreasing function of \u2225 \u2225 1 . However, we do not make this assumption.\nBy substituting (4) and (5) into (1), we have:\nwhere \u2297 is discrete convolution and ( ) = ( ( )) ( ) is the convolution kernel, approximating the expectation of the voting weight given the residual registration error. (7) is obtained because the residual registration error produced by each atlas is a random sample from the residual registration error distribution . Due to the error in deformable registration, the estimated label posterior probability map produced by image similarity-based weighted voting can be modeled as applying spatial smoothing to the ground truth label posterior probability map (see Fig. 2 for an illustration). The convolution kernel is determined by the registration quality, , and the weighting function ( ). Hence, when different registration algorithms or different weighting functions are used, the convolution kernel may be different. In a special case, majority voting applies a constant function for ( ). Hence, the resulting convolution kernel is identical to . In the remaining of this paper, we focus our study on two weighted voting methods: majority voting and the Gaussian-based local weighted voting method (2) .\nIt is well known that spatial smoothing has stronger impacts near boundaries, resulting in under/overestimated label posteriors at edges for convex/concave shaped structures. Without correcting this spatial bias, weighted voting tends to produce less accurate results for thin (or highcurvature shaped) structures. Fig. 4 and Fig. 5 demonstrate such bias produced by majority voting and by Gaussianbased local weighted voting.\nTo reduce this spatial bias, we propose to estimate the convolution kernel and apply standard deconvolution to restore the unbiased spatial label posterior maps from the estimation obtained via weighted voting."}, {"section_title": "Characterizing the convolution kernel", "text": "The convolution kernel, , captures the relationship between the residual registration error and the expected voting weight received in weighted voting. Accurately estimating the kernel is difficult due to the difficulty in quantifying the residual registration errors. To obtain information on how to characterize the convolution kernel, we conducted empirical studies to measure the relationship between the lower bound of the residual registration error and the expected voting weight produced by Gaussian weighting 2 . To simplify our study and implementation, without enforcing any priors, we assume that the smoothing kernel is isotropic, i.e.\nThe assumption is particularly suitable for brain images, where most regions have homogenous intensities. Although the smoothing kernels may be less isotropic around regions with strong edges, the kernels are approximately isotropic averaging over large regions.\nWe conducted studies on the set of atlases used in our hippocampus segmentation experiments (data description in section 4). For one atlas = ( , ), we register another atlas to it and let = ( , ) be the corresponding warped atlases obtained from the registration. Under the assumption that the manual segmentations for both atlases are correct and correct correspondence exists, the manual segmentations provide information about the registration error. For example, if ( ) \u2215 = ( ) then the correspondence at is incorrect. Although retrieving accurate residual registration errors is still difficult, the shortest distance from to the regions with the same label of ( ) in defines a lower bound for the residual registration error at 3 . Similarly, the shortest distance from to the regions with the same label of ( ) in defines another lower bound for the residual registration error at . A more accurate lower bound can be determined by selecting the maximal value from the two estimations.\nApproximating the residual registration error by its lower bound, we collected the statistics of the joint occurrence of the residual registration error and the image similaritybased Gaussian weight by registering each pair of the atlases. With one pair of registered atlases ( , ), the accumulative voting weights received at one residual registration 2 Note that majority voting is a special case of Gaussian-based weighted voting, with \u2192 \u221e. 3 The longest distance from to regions with the same label of ( ) in defines a upper bound for the registration error at .\n2 / is the Gaussian weight assigned at location and defines the lower bound of the spatial displacement error at . 4 2 in (9) is derived because is a 3-dimensional kernel. To estimate the expected weight ( ) at the residual registration error , we normalize the accumulative weights received at \u2225 \u2225 1 = by dividing by 2 . Averaging over all pairs of the atlases, we obtain the expected voting weights with respect to the lower bound of residual registration errors. Fig. 3 shows empirical estimations obtained from using 20 atlases and a Gaussian weighting function with = 2, = 0.05, 0.1, respectively. In our study, the expected Gaussian weight and the lower bound of the residual registration error show an exponential relationship. Hence, we apply a generalized Gaussian function to model this empirical relationship. We have:\nwhere and are model parameters, which can be determined through least square fitting and gradient descent optimization. As Fig. 3 shows that generalized Gaussians fit very well to the empirical functions."}, {"section_title": "Estimating the convolution kernel", "text": "We found that applying the convolution kernel estimated using the lower bound of the residual registration error to reduce the spatial bias already improved the image segmentation accuracy produced by Gaussian-based weighted voting.\nHowever, since the lower bound may be significantly different from the actual residual registration error and the above empirical estimation does not consider the local search technique used for remedying registration errors, room is still left for further improving the kernel estimation accuracy. Assuming that the optimal convolution kernel can be modeled by a generalized Gaussian function as well, we estimate the optimal convolution kernel using the set of atlases in a leave-one-out fashion as follows.\nFirst, the spatial label posterior maps of each atlas is estimated using weighted voting from the remaining atlases. We determine the optimal parameters of the generalized Gaussian kernel by separately applying deconvolution using a range of parameter values specifying the kernel. The parameters producing the most accurate segmentation for all atlases are selected. Since in our empirical studies, the fitted generalized Gaussian function using the lower bound of the residual registration error all have 0 \u2264 , \u2264 1, we estimate the convolution kernel by selecting parameters from a discrete range , \u2208 {0.02, 0.04, ..., 1}."}, {"section_title": "Experiments", "text": "In this section, we apply our method to segment the hippocampus using T1-weighted MRI. The hippocampus plays an important role in memory function. Macroscopic changes in brain anatomy, detected and quantified by MRI, consistently have been shown to be predictive of Alzheimers disease (AD) pathology and sensitive to AD progression [17] . Accordingly, automatic hippocampus segmentation from MRI has been widely studied."}, {"section_title": "Imaging data.", "text": "We use the data in the Alzheimer's Disease Neuroimaging Initiative (ADNI, www.loni.ucla.edu/ADNI). Our study is conducted using 3 T MRI and only includes data from mild cognitive impairment (MCI) patients and controls. Overall, the data set contains 139 images (57 controls and 82 MCI patients). The images are acquired sagitally, with 1 \u00d7 1 mm in-plane resolution and 1.2 mm slice thickness.\nTo obtain reference segmentation, we first applied a landmark-guided atlas-based segmentation method [13] to produce the initial segmentation for each image. Each fullylabeled hippocampus was manually edited by a trained human rater following a previously validated protocol [8] .\nExperiment setup. For cross-validation evaluation, we randomly selected 20 images to be the atlases and another 20 images for testing. Each atlas was registered to each test image, as well as to each other atlas. Global registration was performed using the FSL FLIRT tool [18] from -5 to 5 in x, y and z). Deformable registration was performed using the ANTS Symmetric Normalization (SyN) algorithm [2] , with the cross-correlation similarity metric (with radius 2) and a Gaussian regularizer with = 3. The cross-validation experiment was repeated 5 times. In each experiment, a different set of atlases and test images were randomly selected from the ADNI dataset. The results reported below are averaged over the 5 experiments.\nTo test our method, first, majority voting (MV) and the Gaussian-based local weighted voting label fusion (2) (LWGaussian) were separately applied to produce the initial spatial label posterior maps for each of the test image. The parameters for LWGaussian are = 2, = 3, = 0.1. We then applied spatial deconvolution with the kernel estimated using the atlases for each label fusion method to reduce the bias in the estimated label posterior maps.\nAs discussed above, the optimal parameters of the generalized Gaussian function used for deconvolution were obtained by evaluating a range of values ( , \u2208 {0.02, 0.04, ..., 1}) using the atlases in a leave-one-out strategy as well. For deconvolution, we applied Wiener deconvolution [6] implemented in MATLAB, the deconvwnr function with a constant noise-to-signal power ratio 0.2. Table 1 presents the hippocampal volumes in control and MCI cohort obtained using different segmentation methods. As expected, both majority voting and similarity-based local weighted voting underestimated the hippocampal volume than the reference segmentation. The average absolute volume difference rates, "}, {"section_title": "Results.", "text": ""}, {"section_title": "| |auto|\u2212|reference| |reference|", "text": "|, produced by the two methods are 13.6% and 6.1%, respectively. Applying spatial deconvolution produced more accurate volume measurements for both label fusion methods. The corresponding Cohen's effect size [7] is also shown in Table 2 (computed as the difference of the sample means of the two cohort, divided by the pooled sample standard deviation). Larger values of Cohen's indicate greater effect, i.e., greater ability to tell cohorts apart based on hippocampal volume. The hippocampal volumes obtained from applying spatial deconvolution also have slightly more significant differences between the two population groups than those produced by the corresponding label fusion method, as indicated by the increased effect sizes. Since volume differences produced by automatic segmentation methods are all proportional to that of manual segmentation, the hippocampus volume measured using different methods show similar separability between the two population groups. Automatic algorithms yield slightly greater effect sizes than manual segmentation, likely due to reduced variance in volume estimation. Visualizing the spatial bias. To visualize and quantify the spatial bias produced by majority voting and LWGaussian across all subjects, we normalize the different hippocampus segmentations into a common coordinate space. Normalization is performed using a structurespecific shape-based normalization approach [24] . A geometrical model, known as the continuous medial representation (cm-rep), is fitted to each reference segmentation of the hippocampus, and the parametrization of this geometrical model is used to establish a one-to-one correspondence between the space inside and near the reference segmentation and a common reference space provided by a single template manual segmentation. Using these correspondence maps, we transfer both the reference segmentations and the automatic segmentations from subject space into the template space. We emphasize that since the same mapping is applied to both reference and automatic segmentations, the differences between these segmentations are maintained by the mapping. Averaging over all subjects across all crossvalidation experiments, we computed the spatial label distribution in the template space for the reference segmenta- tions and the automatic segmentations. These distributions are shown in Fig. 5 . Note that a cm-rep model fitted to a reference segmentation does not overlap it perfectly. Hence, the mean spatial label distribution of the reference segmentations in the template space is not a binary image. The plot of mean signed difference between the normalized reference and automatic segmentations in Fig. 5(c) clearly shows the strongest spatial bias of underestimation of the figure produced by majority voting and LWGaussian in the anterior and posterior regions of the hippocampus, which are the parts in the hippocampus with the largest curvatures. Such bias is prominently reduced after applying deconvolution with the estimated kernels, shown in Fig. 5(e) .\nNote that the quality of image-based registration usually varies at different locations. For regions with more distinctive image features, the image-based registration usually can be more reliably conducted than regions with less distinct image features. As a result, the approximated convolution kernel for one weighted voting method may vary at different locations as well. As shown in Fig. 5(e) , applying a single kernel to the entire image reduced most spatial bias, while the applied kernel is inadequate to reduce all the spatial bias. Hence, by spatially adapting the applied deconvolution kernel, one may further improve the performance."}, {"section_title": "Discussion and Conclusions", "text": "We described and demonstrated a spatial bias in similarity-based weighted-voting label fusion that may underestimate the volumes of convex structures. Due to registration errors, weighted voting imposes an effect that can be modeled as applying a spatial convolution operation to the ground truth label posterior maps. The convolution kernel combines the distribution of residual spatial displacement errors resulted from registration and the weighting function used to transfer local image similarities into voting weights. To reduce this spatial bias, we proposed to apply standard spatial deconvolution to the label posterior maps obtained from weighted voting.\nIn a hippocampus segmentation application, we demonstrated the spatial bias produced by majority voting and Gaussian-based local weighted voting label fusion. We also showed that the convolution kernel resulted from Gaussian local weighted voting can be modeled by generalized Gaussian functions. Fitting the deconvolution kernel using atlases in a leave-one-out fashion, we showed that applying spatial deconvolution effectively reduced the spatial bias produced by majority voting and Gaussian weighted voting.\nRelation to other bias reduction work in multi-atlas segmentation. In addition to the spatial bias described in this paper, weighted voting may produce other types of bias. For example, another source of bias is due to the redundancies in the atlases [22, 21] . For a simple example, suppose that a single atlas is duplicated multiple times in the atlas set. If voting weights are derived only from atlas-target similarity, the total contribution of the repeated atlas to the final solution will increase in proportion to the number of times the atlas is repeated, biasing the solution towards the repeated atlases. Since the two types of bias are complementary to each other, it is possible to apply spatial deconvolution on the spatial label posterior maps produced by [22, 21] to reduce both types of bias in weighted voting.\nAs shown in [20] , machine-learning techniques can be useful for reducing systematic errors produced by a segmentation approach. Our work suggests that when multiatlas segmentation with similarity-based weighted voting label fusion is applied as the host method, the estimated spatial label posterior maps contain meaningful information for learning how to correct the bias."}]