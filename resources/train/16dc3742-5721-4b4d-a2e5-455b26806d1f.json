[{"section_title": "", "text": "into broad categories and provide comprehensive descriptions of representative methods in each category. We aspire to give readers the ability to understand the baseline efforts and kickstart their work where others have left. Moreover, we aim to identify new trends and ideas to build a more robust and well-planned strategy in this war of our times. Figure 1 . A portrayal of current increase in research articles about coronavirus related research. Adapted from [1] .\nOur survey will include research papers in pre-print format due to time urgency imposed by this disease. It is not an optimal approach due to the risk of lower quality and work without due validation. Many of the works have not been put into clinical trial as it is time-consuming. Nevertheless, our intention here is to share ideas from a single platform while highlighting the computer vision community efforts. We hope that our reader is aware of these contemporary challenges.\nWe follow a bottom-up approach to describing the research problems that need addressing first. We start with disease diagnosis, discuss disease prevention and control, followed by treatment-related computer vision research work. Section 2 describes the overall taxonomy of computer vision research areas by classifying these efforts into three classes. Section 3 provides a detailed description of each research area, relevant papers and a brief description of representative work. Section 4 describes available resources including research datasets, their links, deep learning models and codes. Section 5 provides the discussion and future work directions followed by concluding remarks and references."}, {"section_title": "HISTORICAL DEVELOPMENT", "text": "The novel coronavirus SARS-CoV-2 (previously known as 2019-nCoV ) is the seventh member of the Coronaviridae family of viruses which are enveloped, non-segmented, positive-sense RNA viruses [33] . The mortality rate of COVID-19 is less than that of the severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS) coronavirus diseases (10% for SARS-CoV and 37% for MERS-CoV). However, it is highly infectious, and the number of cases has been increasing rapidly [62] .\nThe disease outbreak first reported in Wuhan, the Hubei province of China [33] , after several cases of pneumonia with unknown causes were reported on 31 December 2019. A novel coronavirus was discovered as the causative organism through deep sequencing analysis of samples of patients' respiratory tract at Chinese facilities on 7 January 2020 [62] . The outbreak was declared a Public Health Emergency of International Concern on 30 January 2020. On 11 February 2020, the World health organization (WHO)announced a name for the new coronavirus disease: COVID-19. It was officially being considered pandemic after 11 March announcement by WHO [75]."}, {"section_title": "TAXONOMY OF KEY AREAS OF RESEARCH", "text": "In this section, we describe the classification of computer vision techniques that try to counter the menace of COVID-19. For better comprehensibility, we have classified them into three key areas of research: (i) diagnosis and prognosis, (ii) disease prevention and control, and (iii) disease treatment and management. This taxonomy is shown in Figure 2 . In the following subsections, we discuss the research fields, the relevant papers, and present a brief representative description of related works. "}, {"section_title": "Diagnosis and Prognosis", "text": "An essential step in this fight is the reliable, faster and affordable diagnostic process that can be readily accessible and available to the global community. According to Cambridge dictionary [80] , diagnosis is \"the making of a judgment about the exact character of a disease or other problem, esp. after an examination, or such a judgment\" and prognosis is \"a doctor's judgment of the likely or expected development of a disease or of the chances of getting better\".\nCurrently, Reverse transcriptase quantitative polymerase chain reaction (RT-qPCR) tests are considered as the gold standard for diagnosing COVID-19 [71] . During such a test, small amounts of viral RNA are extracted from a nasal swab, amplified, quantified. Virus detection is then performed using a fluorescent dye. Although accurate, the test is time-consuming and manual, which limits its availability in large scales. Some studies have also shown false-positive PCR testing [10] ."}, {"section_title": "Computed Tomography (CT) scan", "text": "An alternative approach is the use of radiology examination that uses computed tomography (CT) imaging [3] . A chest CT scan is a non-invasive test conducted to obtain a precise image of a patient's chest. It uses an enhanced form of x-ray technology, providing more detailed images of the chest than a standard x-ray. It produces images that include bones, fats, muscles, and organs, giving physicians a better view, which is crucial when making accurate diagnoses.\nThere are two types of chest CT scan, namely the high-resolution and spiral chest CT scan [77] . The high-resolution chest CT scan provides more than a slice (or image) in a single rotation of the x-ray tube. The spiral chest CT scan application involves a table that continuously moves through a tunnel-like hole while the x-ray tube follows a spiral path. The advantage of the spiral CT is that it is capable of producing a three-dimensional image of the lungs. images is shown in figure 3 . As the identification of disease features is time-consuming, even for expert radiologists, computer vision can help by automating such a process."}, {"section_title": "Representative Work, Evaluation and Discussion", "text": "To date, various CT-scanning automated approaches have been proposed [3] [85] . To discuss the approach and performance of the computer vision CT-based disease diagnosis, we have selected some recent representative works that provide an overview of their effectiveness. It is worth noting that they have been presenting different performance metrics and using a diverse number of images and datasets. These practices make their comparison very challenging. Some of the metrics include Accuracy, Sensitivity, Specificity, Area Under Curve (AUC), Positive predictive value (PPV), Negative predictive value (NPV), and F1 score. A quick elucidation on their definition can be useful. The accuracy of a method determines how correct the values are predicted. The precision determines the reproducibility of the measurement or how many of the predictions are correct. Recall shows how many of the correct results are discovered. F1-score uses a combination of precision and recall to calculate a balanced average result.\nThe first class of work discussed here approaches diagnosis as a segmentation problem. Jun Chen et al. [11] has proposed a CT image dataset of 46,096 images of both healthy and infected patients, labeled by expert radiologists. It was collected from 106 patients admitted with 51 confirmed COVID-19 pneumonia and 55 control patients. The work used deep learning models for segmentation only so that it could identify the infected area in CT images between healthy and infected patients. It was based on UNet++ semantic segmentation model [86] , used to extract valid areas in the images. It used 289 randomly selected CT images and tested it on other 600 randomly selected CT images. The model achieved a per-patient sensitivity of 100%, specificity of 93.55%, accuracy of 95.24%, PPV (positive prediction value) of 84.62%, and NPV(negative prediction value) of 100%. In the retrospective dataset, it resulted in a per-image sensitivity of 94.34%, specificity of 99.16%, accuracy of 98.85%, PPV of 88.37%, and NPV of 99.61%. The trained model from this study was deployed at the Renmin Hospital of Wuhan University (Wuhan, Hubei province, China) to accelerate the diagnosis of new COVID-19 cases. It was also open-sourced on the Internet as to enable rapid review of new cases in other locations. A cloud-based open-access artificial intelligence platform was constructed to provide support for detecting COVID-19 pneumonia worldwide. For this purpose, a website has been made available to provide free access to the present model at (http://121.40.75.149/znyx-ncov/index).\nThe second type of work considered COVID-19 as a binary classification problem. Lin Li [40] proposed (COVNet), to extract visual features from volumetric chest CT using transfer learning on the RESNET50. Lung segmentation was performed as a pre-processing task using the U-Net model. It used 4356 chest CT exams from 3,322 patients from the dataset collected from 6 hospitals between August 2016 and February 2020. The sensitivity and specificity for COVID-19 are 90% (114 of 127; p-value\u00a10.001) with 95% confidence interval (CI) of [95% CI: 83%, 94%] and 96% (294 of 307; p-value\u00a10.001) with [95% CI: 93%, 98%], respectively. The model was also made available online for public use at https://github.com/bkong999/COVNet.\nThe diagnosis problem was also approached as a 3-category classification task: distinguishing healthy patients from those with other types of pneumonia and those with COVID-19. Song et al. [40] used data from 88 patients diagnosed with the COVID-19, 101 patients infected with bacteria pneumonia, and 86 healthy individuals. It proposed DRE-Net (Relation Extraction neural network) based on ResNet50, on which the Feature Pyramid Network (FPN) [43] and the Attention module were integrated to represent more fine-grained aspects of the images. An online server is available for online diagnoses with CT images at http://biomed.nsccgz.cn/server/Ncov2019. Due to limited time available for annotations and labelling, weakly-supervised deep learning-based approaches have also been developed using 3D CT volumes to detect COVID-19. Chuansheng Zheng [85] proposed 3D deep convolutional neural Network (DeCoVNet) to Detect COVID-19 from CT volumes. The weakly supervised deep learning model could accurately predict the COVID-19 infectious probability in chest CT volumes without the need for annotating the lesions for training. The CT images were segmented using a pre-trained UNet. It used 499 CT volumes for training, collected from 13 December 2019 to 23 January 2020, and 131 CT volumes for testing, collected from 24 January 2020 to 6 February 2020. The authors chose a probability threshold of 0.5 to classify COVID-positive and COVID-negative cases. The algorithm obtained an accuracy of 0.901, a positive predictive value of 0.840, and a high negative predictive value of 0.982. The developed deep learning model is available at https://github.com/sydney0zq/covid-19-detection. \nTo date, many deep learning-based computer vision models for X-ray COVID-19 were proposed. One of the most significant development is the model COVID-Net [23] proposed by Darwin AI, Canada. In this work, human-driven principled network design prototyping is combined with machine-driven design exploration to produce a network architecture for the detection of COVID-19 cases from chest X-ray. The first stage of the human-machine collaborative design strategy is based on residual architecture design principles. The dataset used to train and evaluate COVID-Net, is referred to as COVIDx [23] and comprise a total of 16,756 chest radiography images across 13,645 patient cases. The proposed model achieved 92.4% accuracy 80% sensitivity for COVID-19 diagnosis.\nThe initial network design prototype makes one of three classes: a) no infection (normal), b) non-COVID19 infection (viral and bacterial), and c) COVID-19 viral infection. The goal is to aid clinicians to better decide which treatment strategy to employ depending on the cause of infection, since COVID-19 and non-COVID19 infections require different treatment plans. In the second stage, data, along with human-specific design requirements, act as a guide to a design exploration strategy to learn and identify the optimal macro-and microarchitecture designs to construct the final tailor-made deep neural network architecture. The proposed COVIDNet network diagram is shown in Fig. 4 and available publicly at https://github.com/lindawangg/COVID-Net.\nEzz El-Din Hemdan et al. [31] proposed the COVIDX-Net based on seven different architectures of DCNNs; namely VGG19, DenseNet201 [82] , InceptionV3, ResNetV2, InceptionResNetV2, Xception, and MobileNetV2 [58] . These models were trained on COVID-19 cases provided by Dr Joseph Cohen and Dr Adrian Rosebrock, available at https://github.com/ieee8023/covid-chestxray-dataset [17] . Tthe best model combination resulted in F1scores of 0.89 and 0.91 for normal and COVID-19 cases. Similarly, Asmaa Abbas et al. [2] proposed a Decompose, Transfer, and Compose (DeTraC) approach for the classification of COVID-19 chest X-ray images. The authors applied CNN features of pre-trained models on ImageNet and ResNet to perform the diagnoses. The dataset consisted of 80 samples of normal CXRs (with 4020 x 4892 pixels) from the Japanese Society of Radiological Technology (JSRT) Cohen JP. COVID-19 image data collection, available at https://githubcom/ieee8023/covid-chestxray-dataset [17] . This model achieved an accuracy of 95.12% (with a sensitivity of 97.91%, a specificity of 91.87%, and a precision of 93.36%). The code is available at https://github.com/asmaa4may/DeTraCCOVId19.\nUncertainty-Aware COVID-19 Classification and Referral model was introduced by tBiraja Ghoshal et al. [27] with the proposed Dropweights based on Bayesian Convolutional Neural Networks (BCNN). In order for COVID-19 detection to be meaningful, two tyes of predictive uncertainty in deep learning were used on a subsequent work [20] . One of it is Epistemic or Model uncertainty accounts for the model parameters uncertainty as it does not take all of the aspects of the data into account or the lack of training data. The other is Aleatoric uncertainty that accounts for noise inherent in the observations due to class overlap, label noise, homoscedastic and heteroscedastic noise, which cannot be reduced even if more data were to be collected. Bayesian Active Learning by Disagreement (BALD) [32] , These are 3 chest radiographs selected out of the daily chest radiographs acquired in this patient. The consolidation in the right lower zone on day 0 persist into day 4 with new consolidative changes in the right midzone periphery and perihilar region. This midzone change improves on the day 7 film. Image adapted from [48] .\nis based on mutual information that maximises the information between model posterior and predictions density functions approximated as the difference between the entropy of the predictive distribution and the mean entropy of predictions across samples.\nA BCCN model was trained on 68 Posterior-Anterior (PA) X-ray images of lungs with COVID-19 cases from Dr Joseph Cohen's Github repository [17] , augmented the dataset with Kaggle's Chest X-Ray Images (Pneumonia) from healthy patients. It achieved 88.39% accuracy on the available dataset. This work additionally recommended visualisation of distinct features, as an additional insight to point prediction for a more informed decision-making 10/24 process. It used the saliency maps produced by various state-of-the-art methods, e.g. Class Activation Map (CAM) [59] , Guided Backpropagation and Guided Gradient, and Gradients to show more distinct features in the CSR images. \nThe use of masks or protective equipment to limit the virus spread was a strategy identified in the early stage of disease progression. Some countries, China being the most prominent example, implemented it as a control strategy. Computer vision-based systems greatly facilitated such implementation. Zhongyuan Wang et al. [74] proposed Masked Face Recognition approach using a multigranularity masked face recognition model, resulting in 95% accuracy on a masked face images dataset. The data was made public for research and provide three types of masked face datasets, including Masked Face Detection Dataset (MFDD) [83] , Real-world Masked Face Recognition Dataset (RMFRD) and Simulated Masked Face Recognition Dataset (SMFRD) [18] .\nInfrared thermography was also recommended as an early detection strategy for infected people, especially in crowns like passengers on an airport. A comprehensive review of medical applications of infrared thermography is provided by B.B. Lahiri [74] [39] , including fever screening. Somboonkaew et al. [63] proposed a mobile-platform for an automatic fever screening system based on infrared forehead temperature. Best practices for standardized performance and testing of infrared thermographs intended for fever screening are discussed by Ghassemi et al. [26] . Negishi T [47] proposed an Infection Screening System Using Thermography and CCD Camera with Good Stability and Swiftness for Non-contact Vital-Signs Measurement by Feature Matching and MUSIC Algorithm. Earlier for SARD spread control, Chiu et al. [15] proposed a computer vision systems help in fever screening, which was used in earlier outbreaks of SARS. From 13 April to 12 May 2003, 72,327 patients and visitors passed through the only entrance allowed at TMU-WFH where a thermography station was in operation. Additional miscellaneous approaches for prevention and control are also worth noting. An example is pandemic drones using remote sensing and digital imagery, which were recommended for identifying infected people. Al-Naji et al. [5] have used such a system for remote life sign monitoring in disaster management in the past. A similar application is to use vision-guided robot control for 3D object recognition and manipulation. Moreover, 3D modelling and printers are helping to maintain the supply of healthcare equipment in this troubled time. Joshua M. Pearce [52] discusses RepRap-class 3-D printers and open-source microcontrollers. The applications are relevant since mass distributed manufacturing of ventilators has the potential to overcome medical supply shortages. Lastly, germ scanning is an important step against combating COVID-19. Edouard A. Hay [30] have proposed a convolutional neural network for germ scanning such as the identification of bacteria Light-sheet microscopy image data with more than 90% accuracy. Over a period of one month, hundred and five patients or visitors were detected to have a thermographic fever detection Edouard A. Hay [30] convolutional neural networks for identification of bacteria: Github repository https://github.com/rplab/ Bacterial-Identification.\nLight sheet microscopy image data over 90% accuracy\nAn essential part of the fight against the virus is clinical management, which can be done by identifying patients that are critically ill so that they get immediate medical attention or ventilator support. A disease progression score is recommended to classify different types of infected patients in [29] . It is called corona score\" and is calculated by measurements of infected areas and the severity of disease from CT images. The corona score measures the progression of patients over time, and it is computed by a volumetric summation of the network-activation maps. Graeme MacLaren [45] supports that radiological evidence can also be an important tool to distinguish critical ill patients. Yunlu Wang [73] used depth camera and deep learning as abnormal respiratory patterns classifier that may contribute to large-scale screening of people infected with the virus accurately and unobtrusively. Respiratory Simulation Model (RSM) is first proposed to fill the gap between the large amount of training data and scarce real-world data. They proposed GRU neural network with bidirectional and attentional mechanisms (BI-AT-GRU) to classify six clinically significant respiratory patterns (Eupnea, Tachypnea, Bradypnea, Biots, Cheyne-Stokes and Central-Apnea) to identify critically ill patients. The proposed model can classify the respiratory patterns with accuracy, precision, recall and F1 of 94.5%, 94.4%, 95.1% and 94.8%, respectively. Demo videos of this method working in situations of one subject and two subjects can be accessed online (https://doi.org/10.6084/m9.figshare.11493666.v1).\nThe CoV spike (S) glycoprotein is a key target for vaccines, therapeutic antibodies, and diagnostics that can guide future decisions. The virus binds to host cells through its trimeric spike glycoprotein. Using biophysical assays, the Daniel Wrapp et al. [76] showed that this protein binds at least ten times more tightly than the corresponding spike protein of severe acute respiratory syndrome (SARS)-CoV to their common host cell receptor. These studies provide valuable information to guide the development of medical countermeasures for 2019-nCoV.\nQuantitative structure-activity relationship (QSAR) analysis has perspectives on drug discovery and toxicology [53] . It employs structural, quantum chemical and physicochemical features calculated from molecular geometry as explanatory variables predicting physiological activity. Deep feature representation learning can be used for QSAR analysis by incorporating 360\u00b0images of molecular conformations into deep learning. Yoshihiro Uesaw [68] proposed QSAR (Quantitative structure-activity relationship) analysis using deep learning based on a novel molecular image input technique. Such techniques can be used for drug discovery and can pave the way for vaccine development. Figure 8 . : Corona score that is calculated by measurements of infected areas and severity of disease from CT images. It can be used for identifying patients that are critical ill so that they get immediate medical attention. Image adapted from [29] . It is a combination of data provided by many parties: the Radiological Society of North America (RSNA), others involved in the RSNA Pneumonia Detection Challenge, Dr Joseph Paul Cohen, and the team at MILA, involved in the COVID-19 image data collection project for making data available to the global community.\n\u2022 ChestX-ray8 [72] -The chest X-ray is one of the most commonly accessible radiological examinations for screening and diagnosis of many lung diseases. A tremendous number of X-ray imaging studies accompanied by radiological reports are accumulated and stored in many modern hospitals' Picture Archiving and Communication Systems (PACS), available at https://nihcc.app.box.com/v/ChestXray-NIHCC).\nOther images . MFDD dataset can be used to train an accurate masked face detection model, which serves for the subsequent masked face recognition task. RMFRD dataset includes 5,000 pictures of 525 people wearing masks and 90,000 images of the same 525 subjects without masks. To the best of our knowledge, this is currently the world's largest real-world masked face dataset. SMFRD is a simulated masked face data set covering 500,000 face images of 10,000 subjects. These datasets are available at https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset.\n\u2022 Thermal Images Datasets -There is no dataset of thermals for high fever screening. However, a fully annotated thermal face database and its application for thermal facial expression recognition were proposed by Marcin Kopaczka [37] . Information on further ideas of related data that can be figured out by using such systems is available at https://www.flir.com.au/discover/public-safety/thermal-imaging-for-detecting-elevated-bodytemperature/."}, {"section_title": "X-ray Imagery", "text": "The drawback of using CT imaging is the need for high patient dose and enhanced cost [38] . It makes digital chest x-ray radiography (CXR) as the imaging modality with the lower cost and wider availability for detecting chest pathology. Therefore, automated diagnosis of COVID-19 features in CXR will make it a highly useful diagnostic tool against the disease. Digital X-ray imagery computer-aided diagnosis is used for different diseases, including osteoporosis [55] , cancer [4] and cardiac disease [66] . However, as it is really hard to distinguish soft tissue with a poor contrast in X-ray imagery, contrast enhancement is used as pre-processing step [36] [21] . Lung segmentation of chest X-rays is a crucial and important step in order to identify lung nodules and various segmentation approaches are proposed in the literature [54] [9] [19] [24] . CXR examinations have shown consolidation in COVID-19 infected patients. In one study at Hong Kong [48] , three different patients had daily CXR, two of them showed progression in the lung consolidation over 3-4 days. Further CXR examinations show improvement over the subsequent two days. The third patient showed no significant changes over an 8-day period. However, a similar study showed that the ground glass opacities in the right lower lobe periphery on the CT are not visible on the chest radiograph, which was taken 1 hour apart from the first study. However, CXR is still recommended alongside CT for better radiological analysis. Various CXR-related automated approaches have been proposed. The following section discusses the most salient work while Table 2 presents a more systematic presentation of such methods."}, {"section_title": "Prevention and Control", "text": "WHO has provided some guidelines on infection prevention and control (IPC) strategies for use when infection with a novel coronavirus is suspected [49] . Major IPC strategies to limit transmission in health care settings include early recognition and source control, applying standard precautions for all patients; implementing additional empiric precautions like airborne precautions for suspected cases of COVID-19; implementing administrative controls and using environmental and engineering controls. Computer vision applications are providing excellent support for the implementation of IPC strategies."}, {"section_title": "Clinical Management and Treatment", "text": "To date, there is no specific treatment for disease caused by the COVID-19 virus. However, many of the symptoms can be treated and therefore, treatment will depend on the patient's clinical condition. Clinical management practices can be improved with practices like classifying patients based on the severity of the disease and providing them with immediate medical care. Due to the multidisciplinary nature of computer vision, it has the potential to support various teams that are currently working on creating vaccination for the disease as well as clinical management."}, {"section_title": "CONCLUSION REMARKS", "text": "In this article, we presented an extensive survey of computer vision efforts and methods to combat the COVID-19 pandemic challenge and also gave a brief review of the representative work to date. We divide the described methods into three categories based on their role in disease control: Computed Tomography (CT) scans, X-ray Imagery, and Prevention and Control. We provide detailed summaries of preliminary representative work, including available resources to facilitate further research and development. We hope that, in this first survey on Computer vision methods for COVID-19 control with extensive bibliography content, one can find give valuable insight into this domain and encourage new research. However, this work can be considered only as an early review since many computer vision approaches are being proposed and tested to control COVID-19 pandemic at the current time. We believe that such efforts will be having a far-reaching impact with positive results to periods during the outbreak and post the COVID-19 pandemic."}]