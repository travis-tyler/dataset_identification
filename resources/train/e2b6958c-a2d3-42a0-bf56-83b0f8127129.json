[{"section_title": "Abstract", "text": "Reading comprehension in the content areas is a challenge for many middle grade students. Text structure-based instruction has yielded positive outcomes in reading comprehension at all grade levels in small and large studies. The text structure strategy delivered via the web, called Intelligent Tutoring System for the Text Structure Strategy (ITSS), has proven successful in large-scale studies at 4th and 5th grades and a smaller study at 7th grade. Text structure-based instruction focuses on selection and encoding of strategic memory. This strategic memory proves to be an effective springboard for many comprehension-based activities such as summarizing, inferring, elaborating, and applying. This was the first large-scale randomized controlled efficacy study on the web-based delivery of the text structure strategy to 7th-grade students. 108 classrooms from rural and suburban schools were randomly assigned to ITSS or control and pretests and posttests were administered at the beginning and end of the school year. Multilevel data analyses were conducted on standardized and researcher designed measures of reading comprehension. Results showed that ITSS classrooms outperformed the control classrooms on all measures with the highest effects reported for number of ideas included in the main idea. Results have practical implications for classroom practices."}, {"section_title": "", "text": "Reading comprehension is a cornerstone of academic and lifelong learning, economic independence, and civic engagement. Unfortunately, many middle schoolchildren fail to demonstrate mastery of reading comprehension as evidenced by both the National Assessment of Educational Progress (NAEP, 2013) and the Early Childhood Longitudinal Study-Kindergarten Cohort (ECLS-K; Reardon, Valentino, & Shores, 2012) . Over 60% of middle schoolchildren score at basic or below basic levels of proficiency in this important foundational skill (NAEP, 2013) . The continued poor performance of eighth graders on the NAEP tests shows reading comprehension to be a lingering challenge in the middle grades. Results from the ECLS-K show that students in middle grades have not shown any change in comprehension ability in 30 years and gaps between the socioeconomic groups are widening. The NAEP and ECLS-K results are troubling because over half of middle schoolchildren cannot proficiently learn by reading content curricula and this in turn pushes the comprehension burden into content area classrooms (Allington, 2011; Edmonds et al., 2009 ). The goal of this project was to intervene at the 7th-grade level to increase the likelihood of the students acquiring reading comprehension skills prior to entering their final year in middle school.\nText structure-based solutions to reading comprehension problems faced by early adolescent readers have shown positive results in upper elementary and middle-grades (Hebert et al., in press; Meyer et al., 2010; Wijekumar, Meyer, & Lei, 2012; Wijekumar et al., 2014) . Technology-supported delivery of interventions to children in middle grades has also shown promise for improved outcomes in reading comprehension (Slavin, Cheung, Groff, & Lake, 2008) . The Intelligent Tutoring System for the Structure Strategy (ITSS) combines the text structure strategy and webbased technologies to improve content area reading comprehension. ITSS has been tested in large-scale randomized controlled studies with 4th-and 5th-grade children (Wijekumar et al., 2012 (Wijekumar et al., , 2014 . With 7th-grade students, ITSS was examined using a pretest and posttest(s) design study, where students were randomly assigned to variations in ITSS adaptations (e.g., types of feedback; Meyer et al., 2010) . All three studies showed positive results favoring students using ITSS. Large-scale and methodologically rigorous randomized controlled trials that are effectively implemented to inform practice are needed in order to draw any causal conclusions about the ITSS intervention with 7th graders.\nThis article describes one such efficacy study that sought to strengthen the research base on improving 7th-grade students' reading comprehension by reporting on a recent large-scale multisite randomized controlled trial with 108 rural and suburban classrooms. ITSS uses a web-based interface shown in Figure 1 to deliver text structure intervention for students, teaching them how to create strategic memory about expository text. ITSS is designed to be delivered as a partial substitute to the language arts curriculum once a week for about 30 -45 min, contains over 100 lessons, and focuses on expository texts from science, social studies, current events, and sports with readability from 2nd-grade to 12th-grade levels. This study was powered to answer one primary confirmatory research question about reading comprehension outcomes using a standardized distal test and researcher designed proximal and distal measures. We conducted further analyses to answer five exploratory questions to see whether effects of intervention vary by gender, prior knowledge, and locale that are of interest to researchers and practitioners."}, {"section_title": "Causes for Reading Comprehension Problems and Potential Remedy", "text": "Comprehending content area texts is a difficult task that requires students to fluidly bootstrap a complex set of cognitive and metacognitive skills. Cognitive skills for middle-grade learners who need to read and comprehend content area texts include vocabulary knowledge, contextual and background knowledge, linguistic awareness, and strategies to select and encode ideas into memory structures that are well-associated, integrated with prior knowledge, and available for use in a multitude of activities (e.g., problem solving, writing, inferring, and elaborating; Kintsch, 1998; Pressley, 2000; van Dijk & Kintsch, 1983) . Metacognitive skills include awareness of and appropriate use of strategies, planning and monitoring of the comprehension process, and effective allocation of mental resources to the task at hand (Schellings & Broekkamp, 2011) .\nThere are three possible causes for the reading comprehension deficits facing middle-grade students relating to the reader, text, and task (Meyer, 1975) . First, a lack of comprehension component skills to master the content may hinder the reader's comprehension. Research has shown that children with poor comprehension skills engage in little to no planning before, during, or after reading (Mason, 2004) . They are unable to identify important elements of the text, summarize the text effectively, construct strategically organized recalls showing strong cohesion (Meyer, Brandt, & Bluth, 1980) , make inferences, and/or integrate their prior knowledge with the new information (McNamara, 2004) . Students also lack the ability to monitor their comprehension and exhibit low motivation and efficacy toward reading (Taboada, Tonks, Wigfield, & Guthrie, 2009) .\nA second possible cause for reading comprehension challenges facing middle-grade learners is novel or complex content, which requires effortful processing that is unfamiliar or unpracticed by the learners (Meyer et al., 1980) . Texts for middle-grade learners are often difficult to read and understand because they are complex and dense, low in cohesion requiring inferences and elaboration, and structurally unfamiliar (Caccamise, Friend, Groneman, Littrell-Baez, & Kintsch, 2014; Duke, 2010; . Middle-grade content may be uninteresting to the students and offer few choices to motivate and maintain interest in continued focused reading activities (Guthrie & Davis, 2003; Taboada et al., 2009) . There is also an assumption that middle-grade learners will have strong prior knowledge allowing them to read, understand, and connect to new information gathered from reading.\nFinally, concern has been expressed by researchers about the lack of a strong research base to support the instructional tasks (Slavin et al., 2008) included in textbooks and/or instructional materials and delivered by knowledgeable teachers at the middleschool level (Allington, 2011; Edmonds et al., 2009) . A recent review by Wijekumar, Meyer, Harris, Graham, and Beerwinkle (2016) shows how language arts instruction varies greatly based on the strategies taught and sometimes contradicts proven practices. Content area teachers often assume that students have completed the learning to read phase of reading instruction in elementary school, and, therefore, do not need additional instruction about comprehension in middle school (Allington, 2011; Pressley, 2000; Raudenbush, Rowan, & Cheong, 1993) . Additionally, middlegrade teachers are not typically trained to deliver comprehensionrelated instruction in a content area classroom (Allington, 2011) . This document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nThe focus of this study is to address these possible causes for reading comprehension challenges with 7th-grade learners by teaching them how to select and encode coherent strategic memory of text using five text structures: comparison, problem and solution, cause and effect, sequence, and description and nested text structures (e.g., comparison of solutions within the problem and solution text structure, Meyer, 1975; Meyer & Wijekumar, 2007; Wijekumar et al., 2012) . We focus on 7th-grade learners because of the importance of addressing reading comprehension difficulties with students prior to entering their final year in middle school. The academic rigor and complexity increases as students move to 8th grade and beyond to high school. Preparing the students at 7th grade may alleviate potential challenges as they move forward.\nThe second focus is on instruction framed by the five text structures to teach students to be strategic in reading and comprehending content area texts, support students with strong or weak prior knowledge, and provide a useful tool even when the text is unfamiliar or complex. Through repeated practice with multiple text structures and understanding the process of creating strategic memories, the learners may be able to impose structure to read and understand texts that lack cohesion and are dense. A web-based tutor was tapped to deliver consistent and high-quality instruction to all students.\nThe text structure strategy instruction begins with identifying signaling or linking words, classifying the text structures, summarizing with text structure-based scaffolds, encoding strategic memory structures, inferring, elaborating, applying, and writing. Specifically, the text structure approach used in this project is referred to as the text structure strategy and was developed by Meyer (1975) and systematically refined through multiple studies (e.g., Meyer et al., 1980; Meyer & Poon, 2001; Meyer & Wijekumar, 2007; Meyer et al., 2010) . The delivery of the text structure strategy in this project used a web-based intelligent tutoring system designed to increase the likelihood that 7th graders received modeling, practice tasks, assessment, and immediate and scaffolded feedback to improve their content area reading comprehension mitigating any teacher factors (Meyer & Wijekumar, 2007; Wheldall, 2005) . ITSS uses texts from science, social studies, current events, and sports so that disengaged learners may find some topics of interest (Guthrie & Davis, 2003) to practice the text structure strategy. Once students have become proficient in using the text structure to read, select, encode, and comprehend content area texts that are well-signaled they can extend the skills to real-life texts that may be poorly signaled, dense, and/or lack cohesion. ITSS uses well-signaled passages initially and transitions students to complex real-life texts to show students how to transfer their knowledge about the structure strategy to poorly signaled texts.\nText Structure-Based Reading Comprehension-Theory, Research, Practice, and Policy\nText structure-based instruction for comprehension has theoretical, empirical, and policy support. The theoretical basis for the text structure strategy grew out of research on linguistics, cognitive science, and educational psychology where a hierarchy of subordination of some ideas to others and discourse markers within expository texts were linked to memory representations of the text and improved outcomes on reading comprehension measures (Meyer et al., 1980) . Learning this strategy enables readers to strategically build mental representations similar in organization to the author's organization (Gernsbacher, 1996; Meyer, 1975) or centrality of connections (Goldman, Varma, & Cote, 1996) to a text's hierarchical organization of important ideas (Meyer et al., 1980) . The text structure strategy can be particularly helpful in unfamiliar domains of learning (Meyer, 1984; Voss & Silfies, 1996) and helps learners to begin building their knowledge base, a critical factor in learning to read content material (Alexander, 2005) . Consistent with Alexander's developmental model of learning in academic domains, the text structure strategy can be a useful tool when students are in the acclimation state of learning and have to acquire knowledge about one or more domains through reading.\nThe foundations of the text structure model of comprehension proposed by Meyer (1975) share many elements with the construction-integration (van Dijk & Kintsch, 1983 ) and landscape models (Taylor, Graves, & van den Broek, 2000; Yeari & van den Broek, 2011) . The shared foundations include the top-down processing, integration with prior knowledge, focus on memory structures, and interactions among reader, text, and task (e.g., BohnGettler & Kendeou, 2014; Meyer, 2003; Meyer & Rice, 1989) . The text structure-based strategic memory structure can been considered as an example of a type of situation model in the constructionintegration model, where prior knowledge and new information are integrated (Meyer & Poon, 2001; Stine-Morrow, Gagne, Morrow, & DeWall, 2004) . The variations of the approaches are mostly related to the implementation of these models during instruction about reading comprehension. For example, the implementations of the construction-integration model focus on summarizing, cohesion of text, and inferences; instruction often focuses on reading and rereading the text for summarizing with feedback given to scaffold the construction of effective summaries (e.g., Caccamise et al., 2014) and self-explanations (e.g., McNamara, 2004) . The text structure-based approach is more explicit, precise, and transparent in scaffolding the reader's attention to the most important elements of the text through the main idea patterns for each text structure. Instead of repeated efforts to read the text, children receive specific instruction to look for who was being compared with whom and on what basis they were compared if the passage compared two or more people (e.g., Comparison pattern: _____ and _____ were compared on ____, ____, and ____). The construction-integration model focuses on activation and repetition of words and cohesion (Halliday & Hasan, 1976) at the sentence level or paragraph level. In contrast, the text structure model relies on the five text structures and hierarchical nesting of these structures to provide cohesion among the ideas within the text. Again, both the construction-integration and text structure models encourage inferences, elaborations, and effective utilization of memory, but the nature of instruction varies. Specifically, the text structure strategy provides scaffolding for the learner to infer and elaborate based on text structures. The strategy supports construction and integration and explicates the contents of a coherent situation model allowing direct and indirect scaffolding of reading comprehension.\nThe text structure-based model is also similar to the automatic and strategic cognitive processes underlying text understanding described in the landscape model (Yeari & van den Broek, 2011 ). This document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nIn addition to bottom-up features, Yeari and van den Broek (2011) stated, Landscape Model considers the organization of a discourse structure and its constituent segments (such as sentences, clauses, and propositions) as they guide the comprehension processes, and the role of linguistic cues (including connectives such as \"therefore,\" \"because,\" \"after,\" \"next to\") as they direct the reader to maintain particular types of standards of coherence (Sanders, 1997). (p. 638) Similarly for the text structure model the five basic text structures and hierarchical nesting of these structures guide the reader to select and encode information.\nText structure-based reading comprehension has been recommended by experts (e.g., Mallette, Duke, Strachan, Waldron, & Watanabe, 2013; Pearson & Hiebert, 2015) , implemented in National and state policies, and included in textbooks (e.g., Scott Foresman Reading Street) as well as components of recent interventions (Vaughn, 2015) . Additionally, text structure-based reading comprehension skills are reflected in the new grade-level expectations for reading in the Common Core State Standards Initiative (CCSSI; Gewertz, 2011; e.g., Reading CCSS.ELALiteracy.RI.5.1 to RI.5.10) adopted by 42 states. Similarly, state standards (e.g., the Texas Essential Knowledge and Skills) also recommend the use of text structure at upper elementary and middle grades. However, there are important differences between the text structure strategy developed by Meyer and colleagues and these textbook and intervention approaches.\nThere are notable differences between the text structure strategy and most textbook uses of text structure (e.g., Foresman, 2007) or classroom interventions for reading comprehension, including those that add text structure to the instruction (e.g., Promoting Acceleration of Comprehension and Content Through Text, PACT; Vaughn, 2015) . The text structure strategy subsumes other reading comprehension approaches under the text structure umbrella, provides explicit, precise, and transparent scaffolding, and is efficient. Explained another way, the text structure strategy instruction for reading comprehension may share some constructs with other comprehension curricula but the organization and roles of the instructional strategies and activities are different.\nInterventions with a similar foci to the text structure strategy and designed to improve reading comprehension with middle grade learners include SERT (McNamara, 2004) Kim et al., 2006) , Learning Strategies Curriculum (LSC; Cantrell, Almasi, Carter, Rintamaa, & Madden, 2011) and PACT (Vaughn, 2015) . Summary Street, SERT, and iSTART are supplemental classroom interventions that trace their roots to the construction-integration model and focus on summarizing and self-explanations as the means to achieving deep comprehension. A series of interventions designed for struggling adolescent readers also present limited text structures as part of their curriculum (i.e., CACSR, LSC, and PACT).\nThe differences between the text structure strategy and these interventions and curricula are listed below.\n1. Overarching organization of language arts instruction using the five text structures as a guide to manage the selection of important ideas, encoding of strategic memory, and utilization of memory in writing summaries, generating inferences, extrapolating and extending knowledge structures, and writing. This allows the relationships between the ideas to become the organization structure and hierarchical and efficient memory guide. Other implementations of text structure present tasks such as summarizing separate from the text structure instruction.\n2. Scaffolded summary writing tasks based on the text structure. This is particularly useful to novice learners. The scaffolds can be gradually released when students become proficient.\n3. Scaffolded inference, elaboration, and comprehension monitoring based on the text structure-based relationships between the ideas."}, {"section_title": "Description of the Text Structure Strategy Intervention and Web-Based Delivery", "text": "The ITSS focuses on cognitive and metacognitive skills necessary to support the selection and encoding of important elements of the text into a coherent mental representation. The ITSS guides these activities as outlined below.\n1. Identifying the organization of the text as one of five text structures (individually or nested). The reader can use the authors' intended text structure if it is signaled or impose structure when no signals are present (e.g., authentic texts that are poorly signaled).\n2. Scaffolding the selection of the most important elements in the text to write a main idea. In the problem and solution text structure the goal is to highlight the problem(s) and solution(s). The problem and solution main idea scaffold is: \"The problem is ______ and the solution is _______________.\" Students can add as many blanks as needed to extend the main idea. For example, the passage about the problem with garbage shown in Figure  2 was used in the teacher professional development in the recent trials. The article was adapted from \"Howthingswork.com\" and provides a problem and multiple solutions to the problem. The main idea for this article using the text structure strategy is \"The problem is garbage and the solutions are recycling, using less resources, and incineration.\"\n3. Promoting the creation of a strategic cognitive structure for the passage using the main idea. If the student has some prior knowledge then their prior knowledge can be revised and updated to include the new information. Figure 3 presents one example of the reader's strategic memory representation developed through the main idea scaffolding/pattern.\n4. Supporting comprehension monitoring and checking memory structures using the text structure's organization (e.g., Do I remember the solutions to the problem?)\nThis document is copyrighted by the American Psychological Association or one of its allied publishers. This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nThis approach promotes a top-down process for reading comprehension that is strategic in processing, efficient due to chunking, and well-associated through the five text structure patterns and nested structures. For example, as the readers develop their memory structures for the problem(s) and solution(s), they can extend their memory to associate the cause(s) for the problem(s) thereby creating more linkages that prove to be well-associated. The learner can also be prompted to infer the causes to the problem with the question: \"Can you figure out possible causes for the problems based on what you know about garbage or what you can research?\" At this point the memory structure (see Figure 4) can be extended to include the causes for the problem. Figure 5 shows an elaboration of memory structures in Figure 4 where a comparison of solutions is nested within the problem and solution overarching structure. ITSS lessons included passages showcasing nesting of two, three, and four text structures.\nThe text structure strategy serves as a metacognitive approach prior to (e.g., planning to read), during (e.g., extraction of main ideas), and after reading (e.g., comprehension monitoring) as presented in a series of YouTube videos designed and developed by Wijekumar (2014a Wijekumar ( , 2014b . Prior to reading, the reader can plan to use text structures to impose top-down structure on their reading whether the passage is signaled or not. For example, after skimming the text or reading the heading, the reader can decide to use the problem and solution text structure. The reader can then approach the text strategically seeking information about the problem and solution and use that same approach to bring cohesion to the text. During comprehension, the text structure strategy's main idea patterns guide the selection and encoding of information in meaningful and associated chunks. Either during or after reading, children can monitor their comprehension by traversing the main idea based memory structures to confirm synthesis and understanding of the text. When reading about a problem, the reader can reflect back on the passage they read and check whether they remember the problem, solution(s), and cause(s) for the problem. This approach also allows students to detect and repair any inconsistencies or fill in missing information. These monitoring and Freudenrich (2000) . The amount of trash buried in landfills has doubled since 1960. This is a problem, because landfills are not designed to break down trash, merely to bury it. Trash put in a landfill will stay there for a very long time. Inside a landfill, there is little oxygen and little moisture. Under these conditions, trash does not break down very rapidly. In fact, when old landfills have been excavated or sampled, 40-year-old newspapers have been found with easily readable print. When a landfill closes, the site, especially the groundwater, must be monitored and maintained for up to 30 years! In many areas worldwide, landfill space is running out. This is due to people not wanting landfills near their homes. If changes aren't made, a landfill shortage crisis will happen within the next 10 years. There is a way for us, as consumers, to help out in the fight against pollution. One solution is that we can practice the three R's: Reduce, Reuse, and Recycle. Sometimes people throw out items that are expensive to get rid of that can be reused. For example, the cost of disposing one barrel of oil-based paint is $630 -$1,200 and the paint could be used by someone else. If people want to stop the landfill crisis before it begins, they should work harder to reduce garbage, donate items that can be reused by someone else, and recycle more. This document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nrevising/repairing activities may require further information seeking, inferences, or elaboration and can be scaffolded by the text structure.\nThe web-based delivery of the text structure strategy in ITSS supports learning through modeling of strategy use, practice tasks (e.g., writing a main idea using the pattern for a particular text structure, identifying texts that inform or persuade), assessment, and scaffolding feedback with different types of expository texts from different content domains. Immediate feedback with hints and further modeling of good levels of understanding show students how to set and maintain standards of coherence for understanding expository text in classroom learning settings. Thus, the text structure strategy serves to establish standards of coherence with learners who are most likely to overlook them due to a lack of prior knowledge, limited working memory, inability to maintain standards of coherence, and/or difficulty taking advantage of important linguistic cues in the text.\nITSS meets 11 of the 15 recommendations by Biancarosa and Snow (2006) (e.g., direct, explicit comprehension instruction, strategic tutoring, diverse texts, and technology component). An animated pedagogical agent, named I.T., initiates instruction, guides the learner with information on practice tasks, presents feedback, and supports the learner through multiple attempts at learning the text structure strategy. The ITSS platform also maintains extensive records of student progress allowing teachers to view reports and manage the classroom delivery of the approach. Typically, a student logs into the system and receives instructions from I.T. The student proceeds at his or her own pace by listening to and viewing I.T.'s model, reading texts on the screen, answering questions (with multiple trials), and getting hints and feedback from I.T. The narration may be turned off for higher grade level students if the teacher believes it is not necessary. The students read passages from science, social studies, sports, and current events of varying lengths and reading levels. Learners first receive instruction about the comparison text structure followed by the problem and solution and cause and effect text structures. They also receive instruction on combining or nesting text structures. Passages used in ITSS include those created by Meyer and authentic texts from real-life sources, such as newspapers, magazines, and online sites. There are over 100 lessons within ITSS and many versions of the lessons with easier passages for readers experiencing difficulty reading. ITSS provides direct and explicit comprehension instruction, diverse texts, well-tested technologies, ongoing formative and summative assessments, and 2-4 hours of professional development for teachers.\nITSS is designed to work as a partial substitute to the language arts curriculum and is typically delivered once a week for approximately 30 -45 min. Ideally, the system is used in concert with the teacher-managed reading comprehension instruction that takes place on days when the computer software is not used. The text structure strategy instruction delivered via the web-based ITSS has empirical support at the elementary-grade levels (e.g., Wijekumar et al., 2014 Wijekumar et al., , 2012 . In a pretest posttest design with equivalent forms of tests counterbalanced across testing times (Meyer et al., 2010) , 56 fifth and 55 seventh graders substantially increased their standardized reading comprehension test scores, use of the strategy, amount of information remembered from reading, and identification and recall of main ideas. For example, after 6 months (90 min/week) of this ITSS instruction with advanced feedback the average improvement for students reading below grade level was Figure 5 . Nested text structure memory-comparing solutions to the problem (estimates for costs). This document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\n2 grade equivalent levels for the 5th graders and 3.8 grade equivalent levels for the 7th graders (Meyer et al., 2010) . Lowerachieving readers in 7th grade showed the highest level of improvement from pretest to posttest (d \u03ed 1.85). The below gradelevel readers in 7th grade doubled their recall after ITSS instruction. ITSS has not been tested in a large-scale study at the middle grades but has been efficacious at 4th and 5th grade as evidenced by findings from two recently completed multisite cluster randomized controlled trials with approximately 260 classrooms at Grades 4 and 5 (Wijekumar et al., 2012 (Wijekumar et al., , 2014 . Results showed statistically significant and meaningful impacts on 4th and 5th-grade students reading comprehension on both the standardized Gray Silent Reading Test (GSRT; Wiederholt & Blalock, 2000) and researcher-designed measures. Fifth graders in ITSS classrooms on average scored 0.2 SDs (p \u03fd .05) higher on GSRT adjusted posttest scores and .42 SDs (p \u03fd .05) higher on comparison signaling posttest scores than 5th graders in control classrooms holding reading pretest scores, gender, and school locale constant. Also adjusted posttest scores were statistically significantly higher for 5th-grade students in ITSS classrooms than their control counterparts on all other researcher measures: main idea quality Effect Size (ES \u03ed 0.53), comparison total recall (ES \u03ed 0.32), and comparison competence (ES \u03ed 0.26; Wijekumar et al., 2014) . When 4th-and 5th-grade teachers implemented the text structures consistent with the ITSS approach, the results showed larger effects (Wijekumar, Meyer, & Lei, 2013) .\nITSS yielded more benefit on the standardized test of reading comprehension for below grade level 4th-grade readers with the greatest needs for improvement in reading comprehension. Due to teachers' concern about typing skills, the ITSS for 4th grade was truncated to focus on using the text structure strategy to construct strong main idea statements (about two sentences) after reading texts, rather than constructing both main ideas and recalls in the complete version of ITSS used with 5th graders and above. The main ideas in ITSS can be seen as situation models organized with text top-level structures (e.g., problem and solution) and focusing on macropropositions, rather than micropropostions within a sentence or between adjacent sentences. The Wijekumar et al. (2012) study provided support that 4th graders reading below-grade level can learn to write good main ideas using text structure to integrate important ideas across two paragraphs of expository text. Additionally this learning transfers to reading comprehension performance on a standardized test.\nIn studying students without ITSS instruction in a crosssectional design across grades four through nine, Meyer, Ray, and Middlemiss (2012) found that the largest growth across grades in understanding the comparison text structure was for average comprehenders and no improvements past 6th grade were found for low comprehenders. In the current study, we examined whether the ITSS intervention can increase understanding and use of the comparison text structure by 7th graders, including low comprehenders.\nFinally, in previous studies of ITSS exploratory analyses were conducted to study the effects of time on task and numbers of questions answered by the participants. At the fifth grade level students who answered more questions showed better performance on the outcome measures but average minutes used was not significantly related to GSRT posttest scores (Wijekumar et al., 2014) ."}, {"section_title": "The Current Study", "text": "Consistent and high quality instruction in reading comprehension may be difficult to achieve in large numbers of classrooms due to location and other challenges. Students attending rural or suburban schools may have access to different resources and may be socioeconomically different. Schools may also differ based on curricula, teacher quality, and student background. The web-based ITSS was designed to overcome these challenges and provide consistent modeling, practice tasks, assessment, scaffolding, and feedback to the learners.\nIn this large-scale randomized controlled efficacy study, we examined the effects on reading comprehension of 7th-grade students learning how to select, encode, and strategically organize text via the ITSS versus traditional 7th-grade reading comprehension instruction that focuses on activities that emphasize summarization, questioning, and highlighting of texts independent from the text structure framework. These activities were identified during a review of the curricula used in the schools. Based on the theory and supporting research studies, we hypothesized that 7th-grade students learning to read and comprehend expository texts using the ITSS will outperform their business as usual counterparts who do not use the ITSS.\nWe also conducted exploratory analysis of five factors that may affect the intervention's outcomes variably, such as initial skills (Stanovich, 1986) , gender (Halpern, 2006) , and school and time factors. Interventions often show larger effects for more skilled readers, where the rich become richer as described in the Matthew effect (Stanovich) . However, as noted earlier, Wijekumar et al. (2012) showed the opposite effect with below-grade level 4th-grade readers benefiting more from ITSS than more proficient readers. Low comprehenders by 7th grade may have experienced no growth in understanding how ideas can be related via text structures among sentences and paragraphs. Additionally, years of failure constructing useful memory representations after reading may have left them defeated with negative attitudes toward reading to learn. It is an important question to see whether different types of comprehenders benefit differentially from ITSS at the 7th-grade level. Concerning gender, Halpern (2006) explained stronger performances of females in comparison to males on some reading comprehension and writing tasks using complex prose as well as retrieval from long-term memory and writing lengthy responses. Finally, the amount of time spent on the web-based software and the numbers of questions completed by students have been shown to matter in previous studies. Therefore, we explored time on task and number of questions completed in this study as well."}, {"section_title": "Research Questions", "text": "This study was designed to answer the following primary research question. Do students in Grade 7 classrooms using the ITSS delivery of the text structure strategy as a partial substitute for the standard language arts curriculum outperform students in control classrooms on standardized and researcher-designed measures of reading comprehension?\nThe study also posed five secondary questions concerning whether the effect of ITSS delivered instruction about the text This document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nstructure strategy for reading comprehension varies depending on other factors, including reading skills, gender, schools, setting (i.e., rural vs. suburban), and time working in ITSS. The five secondary questions are as follows:\n1. Does the effect of ITSS on reading comprehension depend on students' initial reading level?\n2. Does the effect of ITSS on reading comprehension differ between male and female students?\n3. Does the effect of ITSS on reading comprehension vary across rural versus suburban areas?\n4. Does the effect of ITSS on reading comprehension vary across schools?\n5. Do students who used the ITSS system more in terms of time or number of answered questions perform better on the posttest than students who used it less?"}, {"section_title": "Method Design", "text": "This multisite cluster randomized efficacy study investigated the effects of a web-based tutoring system (ITSS) to deliver the structure strategy-based comprehension instruction to 7th-grade students in rural and suburban settings. A volunteer sample of 108 classrooms were stratified by school and randomly assigned to ITSS or business as usual control. Schools agreed to use the ITSS software as a partial substitute for the language arts period for 30 -45 min each week. During the intervention time, the ITSS classrooms used the web-based tutor delivered instruction with modeling, practice, assessment, and feedback for each student individually. The ITSS classroom teachers delivered the school's language arts curriculum for the rest of the language arts instructional time. The within-school random assignment of classrooms meant that the business as usual control teachers used the school's standard language arts curriculum for the total language arts instructional time.\nThe within-school random assignment of classrooms required fewer participating schools (compared with random assignment of schools) and provided curricular consistency between the ITSS and control classrooms. Schools were also eager to participate because they would build capacity to use the intervention, and control classrooms had the opportunity to use the software after the posttests were completed. The possibility of contamination was minimized by the password protected ITSS software for the students."}, {"section_title": "Participants", "text": "A team of laboratory-extension specialists from a large research university in the Northeast led by the project director recruited schools to participate in the study by sending letters of invitation to all schools within two states and following up with phone calls and regional presentations to school leaders. Requirements to participate in the study included the availability of computer labs with high bandwidth network connections to the Internet. All schools in both states met the requirements because of recent one-to-one computer initiatives and wide area networks. The research team completed site visits to all interested schools and verified the availability of the computers and bandwidth and received approval from the school administrators.\nThe recruitment effort resulted in a total of 25 schools (14 rural, 11 suburban) agreeing to participate in the research study. The recruitment was completed in two cohorts. These schools had an average student to teacher ratio of 14:1 in both rural and suburban settings based on school districts data reported on state websites. The average class size in the participating classrooms was 21. The average educational expenditure rate was $13,874 per student. The schools' student population was 8% racial/ethnic minorities and 42% socioeconomically disadvantaged (eligible for free and/or reduced priced lunch).\nIncentives to participate in the study included the professional development for teachers and the free use of the ITSS software for the study year as well as a second year. Teacher aides were recruited by the schools and paid by the research funds to assist in the setup of the computer labs and monitor usage during the intervention delivery.\nAll 7th-grade language arts teachers in the participating schools were invited to participate and none declined. Middle school language arts classes were organized with one teacher teaching multiple classes. The random assignment was done at the teacher level. As a result we had 59 classrooms in the ITSS group and 49 in the control group after random assignment of the teachers within each school. All the participating teachers (classrooms) were randomly assigned to the ITSS (intervention) or control conditions after students had been assigned to teachers in the schools. Teachers completed their consent forms at the professional development sessions or during the site visits by the study team. All students in the 7th grade of participating schools were invited to participate. Each school mailed parental consent forms to all students at the 7th-grade level prior to notification of random assignment. Student consent was obtained at the pretest sessions and 96% of students agreed to participate.\nThe analysis sample consisted of 2,489 7th-grade students from a total of 108 classrooms from 25 schools. Students who used the software for a total of 30 min or less throughout the year were excluded from the analysis. Many of these students were receiving pull-out special education services during the ITSS time. The determination was made by the schools. The special education students in the control classrooms also received pull-out instruction and did not participate in the study. About 48% of the student sample (48.2%; n \u03ed 1,200) was female, 56.9% (n \u03ed 1,415) were in the ITSS condition, and 53.2% (n \u03ed 1,325) came from rural districts."}, {"section_title": "Procedure", "text": "Measures of reading comprehension (standardized reading comprehension test followed by researcher-designed measures) were administered (to both ITSS intervention and control groups) during the pretest before training began. The testing sessions were conducted by members of the research team in the presence of the teachers in the school auditorium or cafeteria. Teacher professional development was delivered by the research team to the intervention teachers at the beginning of the academic year. The session This document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nlasted approximately 3 hours and provided the teachers with a description of the text structure strategy, showed how ITSS functioned, and described typical student interactions with the software. Schools agreed to allow the students to use the ITSS software for one or two sessions a week for 30 -45 min each week over a 6-to 7-month period during the school year as a substitute for the regular language arts curriculum. Teacher aides were hired by the research team to ensure the smooth implementation at each school. The teacher aides were present during the computer lab time and notified the research team of any computer, bandwidth, or implementation issues. At the beginning of each session, each student picked up their ITSS folder containing any instructions, username, password, and earphones and sat individually at the computer. The student opened a browser and logged in using their individual username and password. The ITSS software initiated the interactions with the student by starting the new session based on the last completed lesson and activity. Students interacted with the ITSS program at their own pace, listening to I.T., responding to questions (e.g., click on signaling words, write a main idea), and receiving feedback and help from I.T. At the end of the class period students logged out and their work was saved.\nThe ITSS instruction focused on how to (a) identify the text structure(s) (b) select and encoding information strategically when reading, (c) use the top-level structure to write a good main idea, and (d) use the five text structures and nested structures to remember the important text information and details. When students responded to questions the system assessed their response and selected appropriate responses from the database based on the score, attempt/try number, and type of question (e.g., on the second attempt for a main idea question type the learner may receive audio only feedback that says, \"You have only written who was being compared but need to add information about what they were compared on.\" If students move to a third or fourth attempt at the same question, they may see a pop-up window showing them more information that they should include when they revise their main idea.) The assessment system reviewed responses for nonsense words, blank answers, repeating the same answer, and words from the urban dictionary (using an application program interface) to detect gaming and notified the teacher about the activities by flagging those words in the reports.\nFidelity of the treatment was monitored by the research team through classroom observations and weekly review of ITSS computer logs. One classroom observation was conducted during the year in both intervention and control classrooms and noted the types of instructional activities, overall classroom atmosphere, and classroom organization (e.g., small group, teacher-led). The observations documented any use of text structure and other comprehension strategies in both the intervention and control classrooms and noted similarities and differences between the ITSS version of text structure versus other approaches (as described earlier). The observations also noted any possible contamination of the control classrooms.\nBiweekly progress reports were emailed to the teachers in the intervention group noting student progress and any gaming of the system by students. If students submitted nonsense or blank answers repeatedly or used language in the urban dictionary, the system flagged the interactions as gaming and teachers were asked by the research team to follow-up with the student(s). Alerting students that teachers would see their written responses along with teacher follow-up reduced off-task behaviors in the ITSS (Wijekumar et al., 2014) .\nPosttest measures on reading comprehension were administered at the end of the school year under the same conditions as the pretest. Posttests included the GSRT and researcher-designed measures. When students had to leave early from any testing session, the research team advised them to complete the standardized test and the signaling word task of the researcher designed measure prior to leaving."}, {"section_title": "Materials", "text": "Materials for this project included the web-based lessons described earlier and teacher professional development materials (i.e., PowerPoint description of text structure, video on how ITSS functions, and sample lessons). The measures administered at pretest and posttest are described below.\nReading comprehension outcome measures. Standardized and researcher designed measures for cognitive outcomes were administered at pre and posttest.\nStandardized test of reading comprehension. The GSRT (Wiederholt & Blalock, 2000) was used as the standardized distal measure of reading comprehension. There are two forms of the measure, forms A and B, and each uses 13 progressively longer and more difficult narrative texts with five multiple choice questions for each passage. The questions range from passage independent questions that rely on prior knowledge, locating information in passage, elaborative, cohesive, and knowledge-based inferences, and vocabulary dependent types. The ProEd (2015) website notes that \"reliability Coefficients Alpha are all at or above .97.\" We also studied test-retest, alternate forms-immediate, alternate forms-delayed, and scorer reliability. Cronbach's alpha for both forms of the GSRT was reasonably high (\u2423 \u03ed .88) . During this study the GSRT Form B was administered at pretest and Form A was administered at posttest. The pretest GSRT score was used as a covariate for data analyses when examining the effects of ITSS instruction on our dependent measures focusing on reading comprehension. The posttest GSRT score was the outcome for the primary research question.\nResearcher-designed measures of reading comprehension. Two equivalent test forms designed to measure student use of problem and solution and comparison text structures were created (Meyer et al., 2010) . One form was administered before the students started ITSS and the second immediately after completing the program. Each form had three passages: one using the problem and solution text structure, one short comparison text structure and one long comparison text structure passage. The problem and solution and short comparison texts were used in the randomized controlled trials conducted with fourth and fifth graders (Wijekumar et al., 2012 (Wijekumar et al., , 2014 . Top-level structure and competence were gathered for both the problem and solution and comparison passages. Signaling word identification was measured using the short comparison passage. Both short and long comparison passages have an additional variable on number of issues compared. The passages and measures are described next.\nThe comparison and problem and solution text structures were selected for measurement in this and previous studies. Both those This document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\ntext structures provide a rich platform for showcasing the power of text structure in selection and encoding of hierarchical memory structures. They are less frequently used in classroom instruction than the sequence and description structures that are less efficient in organization with fewer opportunities for being strategic and chunking (Meyer & Freedle, 1984) . Because this research was an efficacy study designed to test the ITSS system under optimal implementation conditions the comparison and problem and solution text structures matched the sequence of lessons within the ITSS system where 12 comparison text structure lessons were followed by 10 problem and solution lessons and another two review or extension lessons with both text structures. In an efficacy study the proximal measures should be closely aligned to the instruction, and as such, we also anticipated that it is most likely that students in the ITSS condition would have encountered instruction in these two text structures prior to the posttests. Problem and solution text structure passage. Two passages for the problem and solution structure were prepared: (a) rats (authentic newspaper article, see Meyer & Poon, 2001 ) and (b) dogs. The two equivalent passages had 98 words, 72 idea units, and equivalent scores on traditional measures of readability, text structure, and signaling (see Meyer, 2003) . Each text presented a relatively unfamiliar problem and its cause and a solution that eliminated the cause of the problem. Students were asked to recall all they could remember after reading each problem and solution text and placing it out of sight in an envelope. Dependent variables for the problem and solution texts included the top-level structure and competency of using the problem and solution to organize the recall."}, {"section_title": "Short-comparison passages (CO-Short).", "text": "Two short passages were also prepared for the comparison structure: (a) pygmy versus Emperor monkeys and (b) Adelie versus Emperor Penguins. Each comparison passage had 128 words, 15 sentences, and 96 idea units. There were three tasks for the comparison structure: (a) a fill-in-the-blanks cloze task to complete 4 blanks in the short comparison passage, called the signaling test, (b) a recall task like that used for the problem and solution set of articles, and (c) a comparison main idea task where the student was asked to write a two-sentence main idea with the text available for consultation. Dependent variables for the short-comparison texts included toplevel structure and competence similar to the problem and solution set of texts, and number of issues compared and signaling test scores.\nLong comparison passages (CO-Long). Two longer comparison text structure passages were also created and used at pretest and posttest, respectively: (a) Hagar Qim Stone Circles versus Stonehenge (text about Hagar Qim and Stonehenge adapted from Hammann, 2000) , and (b) Mt. Rushmore versus Easter Island. Each comparison passage had 527 words, 33 sentences, and 134 idea units. The same scales and procedures were used as for the short-comparison texts for recall: top-level structure, comparison competency, and number of issues compared."}, {"section_title": "Scoring", "text": "Scoring was done using computer algorithms for the signaling word responses and trained raters for the top-level structure, competence, quality, and number of issues compared measures. The short-comparison fill-in-the-blanks answers were scored by a computer algorithm and correct answers were given a score of 7 for each response with a maximum possible score of 28.\nComparison and problem and solution competence from the main idea and full recall tasks were scored by two trained raters supervised by a skilled researcher using manuals developed for two previous research projects (Meyer et al., 2010; Wijekumar et al., 2014) . Competency ratings for use of the problem-and-solution and comparison structures (proximal measure with scores from 1 to 8) were assessed to determine the degree to which a 7th-grade student proficiently used the text structure as outlined in the ITSS program (i.e., correct problem in the text with cause and its correct solution). These scores were based on the full recall of the text without the passage in view. For recalls from the comparison texts students presenting both elements compared, issues contrasted, and correct details of several of the issues contrasted received a score of 8. Students presenting some details without any organization received a score of 1. The same scoring was used for the comparison main idea task except that a 6-point competence scale was employed rather than 8-points scale. The short main idea required only two issues for the highest competence or quality score of 6; one issue could use words from the text insight during writing the main idea, such as \"feed on fruits,\" but a second issue required using a semantically superordinate category generated by the adolescent, such as \"diet of fruits.\" Any correct issue compared for the two elements/creatures received a score of 5. A complete breakdown of the different scores with examples are presented in Wijekumar et al. (2013) . Scoring was based on a propositional analysis of the ideas in text with interrelationships among ideas specified in a hierarchical content structure. At least 10% of the data from each of the measures were randomly selected from the conditions and time of testing to check interrater agreements. All scorers were blind to treatment conditions as well as factors of secondary interest in the study. Intensive training and mentoring were provided for pairs of educational psychology graduate students, who separately scored each protocol until they could independently score with at least 90% agreement. Then scorers were randomly assigned protocols to score, which included a randomly selected 10% of overlapping protocols for continuous weekly reliability checks. Weekly scoring checks for pairs of students were mentored and monitored by an experienced faculty researcher to prevent drifts in scoring and ensure high consistency and reliability in scoring. Most scorers had two to three years of experience with the research team. The longer comparison texts for 7th-grade students was new to the scoring team and was scored by the experienced faculty researcher and a school psychology graduate student; training was intensive and reliable. For example, the final 10% check for the posttest showed agreement between the scores of 95.30%, 95%, and 97.30%, respectively for top-level structure, comparison competence, and number of issues compared.\nThe percentages of agreements between scorers for competency scores ranged from 86.3% to 95.8%. Agreement for comparison main idea competence ranged from 96.9% to 99.5%. Percentage agreement for the number of issues compared ranged from 96.7% to 100%.\nRecalls of problem and solution texts were scored for top-level structure (correspondence between the organization of the recall and the problem and solution organization of the text). For examThis document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nple, a good top-level structure score (6 or higher on a 9-point scale) requires a problem part and a solution part (see Meyer et al., 2010, p. 80) , but the solution does not have to be the same solution as that posited in the text. Scores greater than six for top-level structure include use of signaling words for the problem part (7 points), the solution part (8 points), and both the problem part and the solution part (9 points). At the low end of the top-level structure scale students only provide a descriptive list of ideas about the text with no indication in any of the sentences about the problem and solution structure (2 points). A score of 4 is also a descriptive list of ideas, but one of the listed descriptions shows the relationship between a problem and a solution.\nAdditionally for the short and long comparison texts, scorers tallied the number of issues correctly contrasted between the two objects (e.g., Emperor vs. Adelie penguins). There was high interrater reliability for the measures collected for this measure of number of issues compared (88%-100%). Two students with only slightly better than average performances on the pretest main idea task included a) 7th-grade student one: \"the main idea is comparing the two monkeys and their differences,\" and b) 7th-grade student two: \"Pygmy, and Emperor monkeys are different from each other.\" Seventh-grade student one's main idea was scored as a top-level structure of 4 out of 9 points possible, indicating some knowledge about the comparison structure, but not using the structure strategy to contrast two creatures on at least one issue. The competence was scored 3 out of 8 because the names of the two creatures compared were not identified (i.e., Pygmy monkeys vs. Emperor monkeys). The number of issues compared was scored 0. Similarly, 7th-grade student two's main idea received a top-level structure of 4, competence score of 4 for correctly identifying the creatures compared, and a main idea number of issues score of 0. On the posttest student one wrote, \"Emperor penguins are larger than the Adelie penguin. They both live on Antarctica's pack ice\"; this student's posttest scores were 6 for top-level structure, 5 for competence (two issues were worded similarly as those found in the text, but there was no generation of a superordinate issue), and 2 for issues compared (size indicated by larger and where they live). On the posttest 7th-grade student two wrote, \"Emperor penguins are being compared with Adelie penguins by size, their growth, weight, appearance, diet, and where they live.\" This student received the maximum top-level structure and competence scores of 9 and 6, respectively. The number of issues compared were tallied for the main idea # of issues score; this student scored 6, one for each issue listed."}, {"section_title": "Data Analysis", "text": "Data analyses were conducted for each of the primary dependent variables (GSRT and researcher-designed measures of reading comprehension) using the HLM7 software program. Missing data was handled using listwise deletion at the time of analysis for each model to maximize the use of available data. Listwise deletion was used because missing at the classroomlevel was relatively small (one class, \u03fd1%, missed reading pretests; 10 classes, \u03fd10% and 5 from each experimental condition, missed only researcher-designed posttests) and missing was not significantly associated with any of the observed variables at the class level. Furthermore, there was no statistically significant differential attrition between treatment and control conditions at the class or student level.\nThe amount of missing data at the student level was somewhat larger. About 6.3% of students (n \u03ed 156) did not participate in the GSRT pretest, 9.7% (n \u03ed 241) did not participate in the posttest, and 9% (n \u03ed 224) did not participate in either pretest or posttest. As noted earlier, the students were asked to complete at least the GSRT and the signaling word task of the researcher-designed measures prior to leaving the testing session. For the other researcher-designed measures, 152-154 students (6.1%-6.2%) missed just pretest, 377-382 (15.1%-15.3%) missed just posttest, and 239 -240 (9.6%) missed both pretest and posttest scores (see Table 1 for the number of participants who completed each of the tests). Students missing reading posttest scores had slightly lower reading pretest scores, suggesting that missing might not be completely at random. However, reading pretest scores were included in all analysis models to mitigate the possible bias due to missing data (Graham, 2009) . Students in the middle grades have schedules that did not align with the testing window and some had to leave early, and others could not be tested altogether. As the sample sizes for complete-case analysis remained fairly large at both the student and class levels, loss of statistical power was not a great concern."}, {"section_title": "HLM Model Specifications", "text": "A series of three-level hierarchical linear models (HLM; Raudenbush & Bryk, 2002) , in which students were nested within classrooms within schools, were specified to address the primary and secondary research questions. An unconditional model (M0) was first estimated to gauge the outcome variability at each level. A main effect model was then estimated to answer the primary research question, in which there were predictor variables at each level. Student-level predictors included gender (1 \u03ed female, 0 \u03ed male; grand-mean-centered) and reading comprehension covariates. Reading comprehension covariates included group-meancentered pretest scores on GSRT and a researcher-designed measure (i.e., signaling for the GSRT posttest outcome, or the corresponding pretest for researcher-designed outcome measures). Treatment efficacy was tested at the classroom level using contrast codes for experimental conditions (i.e., [1/2] \u03ed ITSS, -[1/2] \u03ed control; these contrast codes were used such that unstandardized regression coefficient corresponded to the difference between the unweighted means of the experimental groups). Classroom-level covariates included grand-mean-centered class average pretest scores on GSRT and the corresponding researcher-designed pretest measures. Differences between rural and suburban schools were examined (1 \u03ed rural, 0 \u03ed suburban; grand-mean-centered) at the school level. Variance associated with each of the three levels was estimated. This three-level main effect model (M1) was used to address the primary research question of whether 7th-Grade ITSS classrooms outperformed control classrooms on reading comprehension after controlling for other relevant factors such as prior reading level, gender, and school locale.\nEach of the secondary research questions was addressed in a separate model by adding relevant interaction term(s) or random effects to M1. Specifically, cross-level interactions between treatment and each of the reading pretests (GSRT and corresponding researcher-designed pretest measure) were added to M1 by specThis document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nifying the Level-1 coefficients for the reading pretests as a function of treatment to examine the question of whether the effect of ITSS on reading comprehension depends on students' initial reading level (M2). Similarly, a cross-level interaction between treatment and gender was added to M1 to test whether the effect of ITSS on reading comprehension differed between male and female students (M3). Moreover, a cross-level interaction between treatment and school locale was added to M1 to address the question of whether the effect of ITSS on reading comprehension varied across rural/suburban areas (M4). Statistically significant interactions were followed up by plotting the pattern of interaction. To test whether ITSS had different effects in different schools rather than having a common effect across all schools, we estimated variability of treatment effect across schools by modeling the Level-2 coefficients for treatment as random effects (M5). Statistically significant random treatment effects were followed up by estimating the 95% plausible value range of treatment effect among schools.\nIn addition, we estimated effect sizes of ITSS as compared with the control based on the main effect model (M1). Specifically, we computed the effect size as a standardized mean difference by dividing the adjusted (for pretest scores and other covariates) group mean difference by the (unadjusted) pooled withintreatment-group student-level standard deviation of the pretest scores. The use of pooled within-treatment-group student-level standard deviation to standardize effect estimate was recommended by What Works Clearinghouse (WWC, nodate, p.45).\nLastly, we examined simple Pearson correlations between the GSRT posttest and each of the indicators of system usage (average minutes used per week and total number of ITSS questions answered) for the ITSS group. A significant positive correlation would indicate that students who used the system more performed better on posttest. Moreover, a three-level regression model was conducted on GSRT posttest scores to examine relative effects of these two indicators of system usage after controlling for GSRT reading pretest scores. This document is copyrighted by the American Psychological Association or one of its allied publishers. This article is intended solely for the personal use of the individual user and is not to be disseminated broadly."}, {"section_title": "Results", "text": "There was no statistically significant difference between ITSS and control groups on the pretests at the random assignment classroom level (ps \u03fe .10). This indicated that the ITSS and control classrooms were comparable in their reading level before the implementation of the experiment. Class-and student-level simple descriptive statistics by treatment condition for GSRT and researcher-designed reading comprehension measures are presented in Table 1 . Statistical test results of treatment effect from HLM analyses and effect sizes on GSRT, short comparison, long comparison, main idea, and problem and solution posttest scores are summarized in Table 2 . HLM analyses (M0 -M5) were conducted on each of the reading comprehension measures. However, for concern of space, we only present complete HLM results on the GSRT posttest (see Table 3 ). Effect estimates for ITSS presented in Table 3 were extracted from M1 for each of the outcome measures. Complete M1 estimates for all outcome measures are included in Table 3 . Results are discussed by research questions."}, {"section_title": "Primary Research Question", "text": "To address the question of whether Grade 7 classrooms using the ITSS delivery of the structure strategy as a partial substitute for the standard language arts curriculum outperformed control classrooms on standardized and researcher-designed measures of reading comprehension, we used results from HLM Model 1 (see Table  3 M1 column). Students in ITSS classrooms on average scored 2.12 points (or 0.18 standard deviations) higher on GSRT adjusted posttest scores and 1.69 points (or 0.20 standard deviations) higher on short comparison Signaling posttest scores (see Table 2 ) than students in control classrooms holding reading pretest scores, gender, and school locale constant. These differences were statistically significant at p \u03fd .05. Adjusted posttest scores were also statistically significantly higher for students in ITSS classrooms than their control counterparts on all other researcher-designed reading comprehension measures (see Table 2 ), with effect sizes ranged from 0.15 on short comparison competence to 0.92 on main idea number of issues contrasted. The effect size of 0.18 on the standardized GSRT test was considered small, and the effect size of 0.92 on the main idea number of issues contrasted was considered large. Effect sizes on comparison top-level structure scores for recall from the short and long comparison texts as well as the main idea task were in the small medium range of 0.33 to 0.46."}, {"section_title": "Secondary Question 1", "text": "Results from model M2 provided an answer to the research question on whether the effect of ITSS on reading comprehension depended on students' initial reading level. For the number of issues contrasted in the main idea and long comparison text as well as main idea top-level structure on the posttest, the interaction between the student-level GSRT pretest and ITSS was significant at the .05 level. This indicated that the effect of ITSS, adjusted for other covariates in the model, varied depending on students' initial reading level as shown in Figures 6 -8 . The positive effect of ITSS on main idea number of issues, number of issues on the long comparison text, and main idea top-level structure on the posttest tended to be larger for students who had higher GSRT pretest scores.\nThere was also a statistically significant interaction between ITSS condition and student-level short comparison number of issues pretest on the short comparison number of issues posttest (see Figure 9 ). Figure 9 shows that the positive effect of ITSS on short comparison number of issues contrasted tended to increase as students' pretest scores increased. There were no statistically sig- This article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nnificant interaction effects on other researcher-designed reading measures."}, {"section_title": "Secondary Questions 2 and 3", "text": "Models M3 and M4, respectively, addressed the research questions of whether the effect of ITSS on reading comprehension differed between male and female students and whether it varied across rural versus suburban areas. There was a statistically significant interaction between ITSS and gender on main idea number of issues contrasted and main idea top-level structure posttest scores. Figure 10 shows the similar pattern of interaction that the positive difference between ITSS and control groups on adjusted posttest scores for the number of issues compared (and main idea top-level structure) was slightly larger for female than for male students. The effect of ITSS did not appear to vary as a function of gender or school locale on any of the other reading outcomes that we examined. Holding reading pretest scores, research condition, and proportion of female students constant, suburban schools on average scored slightly higher than rural schools on main idea number of issues (0.22 point, p \u03fd .05), main idea top-level This article is intended solely for the personal use of the individual user and is not to be disseminated broadly. "}, {"section_title": "Secondary Question 4", "text": "The HLM model M5 addressed the question of whether the effect of ITSS on reading comprehension varied across schools. The estimated variance of adjusted ITSS effects across schools on the GSRT posttest and all researcher-designed reading measures was not statistically significantly different from zero at the .05 level. Difference in deviance between the random ITSS effect model (M5) and the fixed ITSS effect model (M1) was also not statistically significant on these measures (except main idea number of issues at p \u03fd .05 without correction for the number of tests). In other words, there was not sufficient evidence to suggest that adjusted ITSS effects (for the covariates) on the GSRT standardized test and researcher-designed measures differed significantly across schools. Therefore, the more parsimonious fixed-effects model was preferred."}, {"section_title": "Secondary Question 5", "text": "Finally, Pearson correlations between GSRT reading posttest scores and system usage measures were calculated to address the question of whether students who used the ITSS system for more time and who answered more questions performed better on the posttest. Average number of minutes used per week was not significantly related to GSRT posttest scores. However, the total number of questions answered demonstrated a positive and statistically significant correlation with GSRT (r \u03ed .19). Results from the three-level regression model also suggested that the total number of questions answered significantly predicted GSRT posttest scores above and over GSRT pretest and average number of minutes used per week (b \u03ed .028, SE \u03ed .006, z \u03ed 4.72, p \u03fd .001). In contrast, average number of minutes used per week became a negative predictor of GSRT posttest when both GSRT pretest and total number of questions answered were controlled for (b \u03ed \u03ea.111, SE \u03ed .046, z \u03ed \u03ea2.41, p \u03fd .05). These analysis results suggested that sheer time usage may not be a good indicator of fidelity. Students using extra time could be gaming the system rather than working on the lessons. The actual number of questions answered appeared to be a better indicator of fidelity as it indicated students' effort to learn the lessons. Questions refer to the requests I.T. made of the students within ITSS (e.g., write a main idea, write a recall, what is the cause?). As such, number of questions answered can be seen as a measure of student engagement within ITSS lessons.\nAs a sensitivity analysis, we also reanalyzed the fixed-effect model (M1) by adding affective pretest scores (computer attitudes, Figure 9 . Interaction between experimental condition and short comparison number of issues pretest level on short comparison number of issues posttest scores. This document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nreading self-concept, learning self-efficacy, and structure strategy self-efficacy) as covariates for the GSRT. Magnitudes of the adjusted ITSS effects on the standardized reading comprehension (GSRT) outcome measure remained about the same. Hence, detailed results of this analysis are not presented to conserve space. However, it might be worth noting that both student-and classroom-level learning self-efficacy and reading self-concept pretest scores were significant predictors (p \u03fd .05) for GSRT posttest scores holding reading pretest scores constant. In summary, ITSS appeared to have a nontrivial positive influence on reading comprehension outcome measures above and over increases that could be predicted by students' initial reading and affective levels. The positive effect of ITSS also seemed to be stronger for students with higher reading pretest levels on several researcher-designed measures (i.e., main idea number of issues, long comparison number of issues, main idea top-level structure, and short comparison number of issues). Moreover, the effect of ITSS was somewhat larger for female students than for male students on the main idea number of issues and main idea top-level structure tests."}, {"section_title": "Summary of Classroom Observations and Computer Logs", "text": "Students in the intervention classrooms used the ITSS system for approximately 29 min each week for 22 weeks. They completed approximately 27 lessons on average. Most students completed instruction about the comparison, problem and solution, and cause and effect text structures. They also completed lessons on nested text structures.\nThe research team compiled weekly emails from the teacheraides supporting the ITSS delivery and also summarized observations conducted in classrooms. Classroom observers were trained using video-taped segments created for the training. After training observers interrater reliability was 95%. Over 80% of the teachers did not participate in the computer lab time when ITSS was being used by the students with the support of the teacher-aides. Classroom observations focused on instructional foci and classroom organization. Observations showed that over 92% of teachers concentrated on literature and focused more on critiques, writing, and discussions. Less emphasis was paid to explicit text structure instruction and more focus was on implied text structure use (e.g., comparison of literary attributes). Due to budget and time limitations the team was unable to conduct observations in other content area classrooms, such as science."}, {"section_title": "Discussion", "text": "The purpose of this study was to examine the impact of ITSS used as a partial substitute for the language arts curriculum on 7th-grade students' reading comprehension. ITSS is a web-based intelligent tutoring system designed to teach 7th graders how to use the text structure strategy to read and comprehend expository texts by selecting and encoding strategic memory, summarizing, inferring, elaborating, and monitoring comprehension. The results showed that the text structure strategy delivered via the web-based ITSS had small but meaningful effects (.18) on the standardized reading comprehension (distal measure) and moderate to large effects on the proximal and distal researcher-designed measures of text structure competence, knowledge (i.e., signaling), and summaries (e.g., effect size of .91 on the main idea number of issues)."}, {"section_title": "Research Findings in Context", "text": "The GSRT provides a sound distal measure of transfer of text structure knowledge to a standardized test. The GSRT measure contains inference and elaboration questions and the results from this study present a link from the text structure instruction to a standardized measure of reading comprehension. The effects on the proximal measures about constructing a strong main idea and free-recall tasks were larger. The signaling word task was slightly more distal than the main idea and recall tasks because students learned how to click on a signaling word in a well-signaled passage during ITSS instruction, but filled in blanks for the Signaling word dependent measure. Students also found it difficult to understand that multiple words can be placed in one blank (e.g., the same as). Thus, the effect on the signaling word task was not as strong as those for main idea and number of issues contrasted.\nOverall in this study, effect sizes and outcomes were similar to those in recently published studies about ITSS at lower grade levels (Wijekumar et al., 2014 (Wijekumar et al., , 2012 and other reading comprehension interventions not focusing primarily on text structure instruction (Cantrell et al., 2011; Slavin et al., 2008; Slavin, Chamberlain, Daniels, & Madden, 2009 ). The effect size on the GSRT was smaller than the results at fifth grade (Wijekumar et al., 2014) , but stronger than for the fourth grade (Wijekumar et al., 2012) . Cantrell et al. (2011) found improvements with 6th graders, but not 9th graders. Findings from the current study may be showing similar patterns of developmental challenges related to middle school students and the possibility that these students are developing poor habits that are difficult to change. At fifth grade, children showed malleability in cognitive processes and were receptive to interventions (Wijekumar et al., 2014) . Findings from the current study and Cantrell et al. may signal a critical window of opportunity in upper elementary school for interventions to help students' improve their reading comprehension. These results may also be influenced by the schools choosing to provide their standard instruction to the poor readers and opting not to have most of them receive ITSS instruction. As noted in the introduction reading comprehension may be affected by the reader, text, and task variables. Students participating in this study may be affected by any one or more factors related to these areas. Further extensive qualitative and quantitative analyses of the ITSS computer logs may provide insight into the tasks that students completed and how students' online work within these tasks and subtasks affected the reading comprehension outcomes.\nResults from this study were more robust than the studies on middle-grade reading comprehension with computer assisted instruction reviewed by Slavin et al. (2008) , which showed a weighted mean effect size of \u03e9.10. The web-based ITSS appears to provide sound delivery, interactions, and learning environment for teaching the text structure strategy based on the weekly reports submitted by the teacher aides managing the ITSS rollout. The system has also shown stability in scaling up to larger numbers of users and is able to provide a meaningful, consistent, high quality alternative to relying solely on teacher delivery of instruction about the text structure strategy. This document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nStudents who scored at the highest levels at pretest showed the largest gains through using the ITSS. This finding was similar to results from a recent study on an intervention called the Reading Edge (Slavin et al., 2009) where similar interaction patterns for improvements were found for children reading below, at, or higher grade levels. However, the interaction pattern was different from findings using ITSS with students in Grades 4 and 5 (Wijekumar et al., 2014 (Wijekumar et al., , 2012 and results from the smaller study with 7th-grade learners (Meyer et al., 2010) . In these studies lower performing readers at the pretest (e.g., the GSRT) made greater gains after ITSS than stronger readers at pretest. The schedule limitations and pull-out instruction for special education in the middle schools may have contributed to this result. It was observed that students experiencing persistent reading difficulties in Grade 7 were receiving pull-out instruction during the ITSS times and thus missed receiving this intervention. Classroom observations showed that most teachers did not use the text structure strategy in the language arts classrooms. Teacher roles, their knowledge about text structure, and their fidelity of implementation with respect to consistency of instructions for the learners also may have contributed to the findings and should be carefully monitored in future studies.\nThe findings with 7th graders showed that most students could still benefit from text structure strategy instruction. They had not mastered the use of the text structure strategy by this grade level, and better readers clearly could benefit from the ITSS instruction as seen by organization of written recalls, generation of appropriate signaling words, quality of main ideas constructed, and increased ability to identify and contrast issues across paragraphs about different subtopics (i.e., different creatures of the same species in the shorter texts or different stone formations in the longer texts). It is unknown whether the greater jumps in performance after ITSS with below grade-level readers in the lower grades than in 7th grade resulted from more severe reading problems compounded by more years of failure or simply less opportunity to work in ITSS due to conflicts with pull out, remediation programs.\nIt is interesting to note that in the large randomized control trials with ITSS across 4th, 5th, and 7th grades, interactions between ITSS effects and gender varied from greater gains in males' ability to write good comparison mains ideas at Grade 4, to no interactions at Grade 5, and onto larger gains after ITSS for 7th-grade females than males on most experimenter-designed measures, but not the GSRT. This latter finding is compatible with Halpern's (2006) review that showed females to perform better than males when written responses are required rather than multiple-choice formats. Over all tested grades there were no interactions with ITSS and gender for posttest scores on the standardized, multiplechoice GSRT. Halpern (2006) also noted that males tend to comprise a greater proportion of students identified with severe to mild reading problems than females. In fourth grade, the lagging development-related reading skills for males in writing a main idea may have been particularly boosted by the heavily scaffolded ITSS instruction for writing a strong two-sentence main idea, a short writing task. In seventh grade, the greater gains for females may be due to a combination of dependent measures favoring writing tasks in which they can excel after text structure strategy instruction and less females with reading difficulties, which would result in fewer females missing ITSS due to pull out remediation sessions.\nA number of factors that may have affected students' responsiveness to the intervention include students getting conflicting instruction from the teacher (vs. ITSS), little to no application of the text structure strategy in the language arts and/or content area classrooms, selections of texts, and the age and developmental level of the students. Classroom observations showed that teachers rarely spent time with students during the computer lab time when ITSS was implemented and relied on the teacher aides to monitor the class. Further, teacher surveys administered at the professional development session prior to the study showed that over 82% did not use text structure as part of the 7th-grade language arts curricula and none of them knew about the text structure strategy. Schools were reluctant to include content area classroom teachers (e.g., earth science) in the professional development due to the time commitment, and the research project did not have funds to conduct observations in those classrooms to document any text structure use in the content area classes.\nA review of student responses presented some evidence about prior knowledge and practices impeding in the learning of the text structure strategy to improve reading comprehension. For example, one 7th-grade student wrote, \"article compares two penguins but we should not notice differences, they are all the same.\" During the pretest and posttests students in two rural schools engaged in disruptive behaviors (e.g., excessive talking, running around the classroom). Teachers noted that the students had \"given up\" on education and were likely to drop out before entering high school."}, {"section_title": "Theoretical Implications", "text": "At the outset we compared the construction-integration and landscape models to the text structure model of reading comprehension, and we also compared reading comprehension interventions to the text structure strategy approach. Based on previous studies on the text structure strategy (e.g., Meyer et al., 1980) , we reported that text structures and their direct and indirect scaffolds support the construction and integration of strategic memory from text. This strategic memory may be a representation of a coherent situation model identified in the construction-integration model of reading comprehension. Results from the current study provide further evidence in support of the text structure strategy in constructing strategic memories as evidenced by the 7th graders in ITSS producing stronger main ideas, organizing the main ideas using the centrality of connections, and utilizing the strategy when reading and responding to questions in a standardized test."}, {"section_title": "Practical Implications", "text": "A review of classroom observations and textbooks conducted by Wijekumar et al. (2013) showed that reading comprehension instruction at Grades 4 and 5 placed text structure as an independent and separate activity from summarizing, inferring, elaboration, and comprehension monitoring. At the 7th-grade level, observations showed there was even less emphasis on text structure and content area texts. Based on the accumulating evidence about the text structure strategy (current study; Wijekumar et al., 2014 Wijekumar et al., , 2012 , students may benefit from reorganizing instruction to align with the text structure strategy and place text structure as the organizing framework for reading comprehension activities such as summaThis document is copyrighted by the American Psychological Association or one of its allied publishers.\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\nrizing, generating inferences, elaborating, and monitoring comprehension.\nResults from the correlational analyses between the GSRT reading posttest scores and time on ITSS and the GSRT posttest scores and total questions answered also may provide insight into the use of web-based learning environments. These results suggested that students who focused their efforts on answering more questions about signaling words, writing main ideas and recall, and others ITSS tasks showed better performance on the GSRT posttest. Students spending extra time in this study may have been experiencing challenges in interacting with the system or gaming the system. Designers of computer-based interventions may take note and try to find approaches to encourage learners to actively engage in the practice lessons and their performance tasks."}, {"section_title": "Limitations", "text": "The findings from this study may be generalizable to the extent that the populations of interest are similar to the sample studied here. This study used a volunteer sample of schools that was randomly assigned to the research conditions. A description of the sample is provided for researchers and practitioners to guide their interpretation of the results. Further research with different populations of students is necessary to extend these findings and examine broader generalizability. The participating sample did not include 7th-grade students who were receiving pull-out instruction and further research needs to be conducted with those special populations in the future."}]