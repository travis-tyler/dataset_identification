[{"section_title": "Abstract", "text": "Recent machine learning based studies for early Alzheimer's disease (AD) diagnosis focus on the joint learning of both regression and classification tasks. However, most of existing methods only use data from a single domain, and thus cannot utilize the intrinsic useful correlation information among data from correlated domains. Accordingly, in this paper, we consider the joint learning of multi-domain regression and classification tasks with multimodal features for AD diagnosis. Specifically, we propose a novel multimodal multilabel transfer learning framework, which consists of two key components: 1) a multi-domain multi-label feature selection (MDML) model that selects the most informative feature subset from multi-domain data, and 2) multimodal regression and classification methods that can predict clinical scores and identify the conversion of mild cognitive impairment (MCI) to AD patients, respectively. Experimental results on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database show that the proposed method help improve the performances of both clinical score prediction and disease status identification, compared with the state-of-the-art methods."}, {"section_title": "Introduction", "text": "Alzheimer's disease (AD) is characterized by the progressive impairment of neurons and their connections, which leads to the loss of cognitive function and the ultimate death. It is reported that an estimated 700,000 older Americans will die with AD, and many of them will die from complications caused by AD in 2014 [1] . Thus, for timely therapy that might be effective to slow the disease progression, it is important for early diagnosis of AD and its early stage, i.e., mild cognitive impairment (MCI). Recently, many machine learning methods based on multimodal biomarkers have been used for early diagnosis of AD [2] [3] [4] [5] . These multimodal data include the structural brain atrophy measurements from magnetic resonance imaging (MRI) scans, brain of functional changes by using the fluorodeoxyglucose positron emission tomography (FDG-PET), and pathological amyloid depositions measured through cerebrospinal fluid (CSF). Existing studies have shown that fusing multimodal biomarkers can provide complementary information for learning models, which helps improve the performances compared to methods using single-modality biomarkers [2] [3] [4] [5] .\nIn the literature, rather than only identifying disease status in classification problems, several studies begin to predict continuous clinical scores from brain images [3, 6, 13] , such as Alzheimer's Disease Assessment Scale-Cognitive subscale (ADAS-Cog) and Mini-Mental State Examination (MMSE). It is worth nothing that, predicting clinical scores helps evaluate the stage of AD pathology and predict future progression [3, 13] . On the other hand, some recent studies have indicated that the tasks of identifying disease status and predicting clinical scores are highly correlated, and the joint learning of regression and classification tasks can help alleviate the small-sample-size problem [3, 7, 8] . In these methods, the tasks of identifying disease status and predicting clinical scores are considered as different learning tasks, and multi-task learning methods are used to combine those different learning tasks.\nHowever, most of existing studies on the joint learning of regression and classification only focus on using data from a single learning domain, and thus cannot utilize the intrinsic useful correlation information among data from different learning domains. In machine learning community, transfer learning provides an effective solution to deal with the problem involving multiple learning domains of data, and it assumes that the different learning domains have a certain correlation [15] . More recently, several studies have developed transfer learning-based methods for MCI converters (MCI-C) prediction, by treating AD/NC as auxiliary domain to help the learning problem in target domain of MCI-C/MCI non-converters (MCI-NC) [4, 9, 10] . Although these methods demonstrate that transfer learning methods yield better performance than conventional single-domain based methods, the underlying correlation among different domains is seldom considered in their learning models.\nInspired by the above problems, in this paper, we propose a novel multimodal multi-label transfer learning framework to jointly learn multi-domain regression and classification tasks by using multimodal data. Specifically, we first propose a Multi-Domain Multi-Label feature selection (MDML) method based on transfer learning and multi-label learning, which is used to select the most informative feature-subset from multi-domain data. Then, we employ the multi-kernel support vector machine (M-SVM) for classification and the multi-kernel relevance vector regression machine (M-RVR) for regression, which are used to identify MCI-C patients and to predict clinical scores, respectively. We validate the efficacy of our proposed method on both single-modality and multimodal data (including MRI, FDG-PET and CSF) from the ADNI database."}, {"section_title": "Method", "text": "In this section, we introduce our proposed multimodal multi-label transfer learning framework. Specifically, in Section 2.1, we first develop a multi-domain multi-label (MDML) feature selection method for selecting the most discriminative features. Then, in Section 2.2, we employ the multimodal regression and classification methods to predict clinical scores and identify the conversion of MCI to AD patients, respectively."}, {"section_title": "Multi-domain Multi-label Feature Selection", "text": "In the early AD diagnosis, it is very important to find discriminative brain regions from brain images (e.g., MRI and PET images). In the literature, Lasso-based sparse learning methods are widely used for feature selection to identify the most informa-tive multimodal biomarkers [11] , and have been shown effective in improving the classification performance. On the other hand, some studies suggest that the tasks of identifying disease status and predicting clinical scores are highly correlated. However, traditional Lasso-based methods cannot capture the intrinsic useful correlation information among different label groups (e.g., class labels and clinical score labels). For addressing that problem, we propose a sparse multi-label group Lasso model, by incorporating the underlying correlation information into the learning process.\nAssume we have a training set with N samples, where is a sample with features. Denote the label matrix for the training data as , \u2026 , , \u2026 , , where is the -th type of labels and is the number of label groups. In this study, there are three different label groups (\n3), including 1) class labels , 2) MMSE score labels , and 3) ADAS-Cog score labels . Let represent the weight matrix, with the row vector denoting the coefficient vector associated with f-th feature across different label groups. Then, our proposed sparse multi-label group Lasso model is formulated as follows:\nwhere the second term , \u2211 \u2211 , can select a discriminative subset of samples relevant self-label group, and the last term , \u2211 is a 'group sparsity' regularizer that is used to simultaneously select a common feature subset relevant to all label groups. In addition, and are two regularization parameters that control the relative contributions of those three terms in Eq. (1). Here, the term \u00b7 is the Frobenius norm of a matrix. By using a specific optimization algorithm [12, 14] for solving the optimization problem of Eq. (1), we can get the sparse weight matrix , where features corresponding to those non-zero coefficients in will be selected. In this way, we can find a common feature subset corresponding to all label groups.\nAlthough the sparse multi-label group Lasso model can extract useful correlation information among different label groups, it only addresses the issue of single-domain learning. In the single-domain learning, we separately adopt the sparse multi-label group Lasso model to handle the multiple related domain data and get the multiple weight matrices , . . . , , . . . , , where is the number of related learning domains with an index 1, , , thus it cannot utilize the intrinsic useful correlation information among multiple related learning domains. To join the multiple related learning domain data, we extend the sparse multi-label group Lasso model to a multi-domain multi-label learning (MDML) model, which is formulated as follows:\nwhere , , 0 are the regularization parameters that control the relative contributions of the four terms, and the last term , , 1 is adopted to keep the temporal smoothness of multi-weight vector , among multiple related learning domains [6] . We propose to solve the optimization problem of Eq. (2) by the accele-rated gradient method (AGM) [12] . In this study, there are two learning domains (i.e., 2, AD/NC subjects as the related learning domain, and MCI-C/MCI-NC subjects as the target domain)."}, {"section_title": "Multimodal Regression and Classification", "text": "After MDML feature selection on the multi-domain training data, we will employ the multimodal regression and classification methods for combining with multimodal features in the target domain. Similar to the works in [2, 3] , in our multimodal multi-label transfer learning framework, we use the multi-kernel learning method to combine multimodal features. Specifically, we adopt the multi-kernel support vector machine (M-SVM) [3] to identify the MCI-C patients and employ the multi-kernel relevance vector machine regression (M-RVR) [2] method to predict the clinical scores. Given M sets of data extracted from different modalities, we first compute the multimodal kernel matrixes , . . . , , . . . , . Then, we use the multi-kernel learning method to define a new integrated kernel function for two subjects in the mth modality (i.e., and ) as follows:\nwhere denotes the kernel function for the m-th modality, and denotes the weight for the m-th modality. From Eq. (3), we can achieve the integrated target domain kernel matrix \u2211 . To find the optimal values for weights , we constrain them so that \u2211 1, 0 1 and then adopt a coarse-grid search through cross-validation on the training data, which has been shown effective in extensive studies [2, 3] ."}, {"section_title": "Experiments", "text": "In this section, we evaluate the effectiveness of our proposed multimodal multi-label transfer learning framework on multimodal data (including MRI, PET and CSF) from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. In the following, we first introduce the experimental settings, and then show the experimental results and discussion."}, {"section_title": "Experimental Settings", "text": "In our experiments, the baseline ADNI subjects with all corresponding MRI, PET, CSF, MMSE, and ADAS-Cog data are included, which leads to a total of 202 subjects (including 51 AD subjects, 99 MCI subjects, and 52 normal controls (NCs)). For the 99 MCI subjects, it includes 43 MCI converters and 56 MCI non-converters. We use 51 AD and 52 NC subjects as related learning domain, and 99 MCI subjects as target domain. Similar to [3] , we adopt an image pre-processing procedure for all MRI and PET images to extract ROI-based features. In addition, three CSF biomarkers are also used in this study, namely CSF A\u03b2 42 , CSF t-tau, and CSF p-tau. As a result, for each subject, we have 93 features derived from MRI images, 93 features generated from PET images, and 3 features obtained from CSF biomarkers. To evaluate the performance of different learning methods, we use a 10-fold crossvalidation strategy and repeat this process 10 times to compute the average classification accuracy, sensitivity, specificity, and AUC (Area Under the ROC Curve) value. We also adopt the popular root-mean-square error (RMSE) and the correlation coefficient (CORR) as regression performance measures. In particular, for classifying MCI-C and MCI-NC, we use the 10-fold cross-validation on 99 MCI subjects, and we use the 10-fold cross-validation on all 202 subjects for regression. The SVM classifier is implemented using the LIBSVM toolbox (http://www.csie.ntu.edu.tw/~cjlin/libsvm/), with a linear kernel and a default value for the parameter ( 1) . The regularization parameters (i.e., , and ) can be chosen from the range of 1 by an inner 10-fold cross-validation on the training data. The RVM regression is implemented using Sparse Bayesian toolbox (http://www.miketipping.com/), with the Gaussian kernel with the width parameter selected from range {2 1 , 2 2 , 2 3 , 2 4 , 2 5 , 2 6 , 2 7 , 2 8 } that can be determined by an inner 10-fold cross-validation on the training data. In particular, the multi-kernel combination weights are determined via a grid search with range from 0 to 1 and step size 0.1 on the training data. In addition, we also perform the same feature normalization scheme as in [3] in our experiments."}, {"section_title": "Results", "text": "In the experiments of MCI-C vs. MCI-NC classification, we compare our proposed method with SVM/M-SVM, Lasso, ML-gLasso and Multi-task feature selection (MTFS) [3] methods by using both single-modality data and multimodal data, with results shown in Table 1 . It is worth noting that, SVM and M-SVM denote methods using SVM for single-modality and M-SVM for multimodal data without feature selection, respectively. At the same time, Lasso, ML-gLasso, MTFS and MDML denote methods using corresponding feature selection (i.e., Lasso, ML-gLasso, MTFS and MDML) algorithms and adopting SVM/M-SVM methods for classification. In Fig. 1 , we also present the ROC curves achieved by different methods for multimodal case. As we can see from Table 1 and Fig. 1, our proposed MDML method consistently achieves better results than SVM/M-SVM, Lasso, MTFS and ML-gLasso methods in terms of all performance measures, which validates the efficacy of our MDML method on using AD and NC subjects as related learning domain. Specifically, in multimodal case, our proposed MDML method can achieve a classification accuracy of 0.787, which is significantly better than M-SVM, Lasso, MTFS and ML-gLasso methods which achieve only 0.638, 0.673, 0.717 and 0.716, respectively. In addition, our proposed ML-gLasso method also achieves better results than SVM/M-SVM, and Lasso methods. It implies that multi-label learning can effectively utilize the intrinsic useful correlation information from multi-label groups. On the other hand, our proposed method can be used to predict the clinical scores. Accordingly, in the second group of experiments, we compare our MDML method with RVR/M-RVR, Lasso, mLasso and MTFS [3] methods for both single-modality and multimodal cases. It is worth noting that, for MDML method, without related learning domain can be used for the prediction of clinical scores. In addition, the mLasso feature selection is a variant of ML-gLasso, which has no L 1,1 -norm regularization term and only selects a common feature subset relevant to all label types. Table 2 shows their prediction performance for MMSE/ADAS-Cog scores using different modalities. so, mLasso, MTFS and MD RVR for single-modality a Note that RVR/M-RVR me ture selection for MMSE/A serve that our proposed M RVR/M-RVR, Lasso, mLas cy of our MDML method. Finally, in Fig. 2 , we vis thod with the highest fre images, respectively. Here frequency of each feature a times), and then regard tho our proposed MDML meth regions (e.g., hippocampal,"}, {"section_title": "Conclusion", "text": "This paper addresses the pr main data and multi-label g multi-label learning and tr feature selection (MDML) different learning domains port vector machine for cla regression, respectively. Ex cacy of our proposed metho Similar to the classification experiments, we first use L DML methods to perform feature selection, and then ad and M-RVR for multimodal for regression, respectiv ethods denote using RVR or M-RVR method without f ADAS-Cog scores prediction. From Table 2 , one can MDML method consistently achieves better results t sso and MTFS methods, which further validates the effi ved by timodal sually show the brain regions selected by our MDML m equency of occurrence by MDML on MRI and P , to get these features (i.e., brain regions), we count and selected across all folds and all runs (i.e., a total of ose features as stable features. As can be seen from Fig  hod successfully finds out the most discriminative br amygdala, temporal lobe, precuneus, and insula) [3, 11 roblem of jointly exploiting the use of related learning group information for early diagnosis of AD. By integrat ransfer learning, we develop a multi-domain multi-la ) for acquiring the useful correlation information amo and multi-label groups, and then employ multi-kernel s assification and multi-kernel relevance vector machine xperimental results on the ADNI database validate the e od. "}]