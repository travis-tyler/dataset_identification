[{"section_title": "Abstract", "text": "With the rapid growth of modern technology, many large-scale biomedical studies have been/are being/will be conducted to collect massive datasets with large volumes of multi-modality imaging, genetic, neurocognitive, and clinical information from increasingly large cohorts. Simultaneously extracting and integrating rich and diverse heterogeneous information in neuroimaging and/or genomics from these big datasets could transform our understanding of how genetic variants impact brain structure and function, cognitive function, and brainrelated disease risk across the lifespan. Such understanding is critical for diagnosis, prevention, and treatment of numerous complex brain-related disorders (e.g., schizophrenia and Alzheimer's disease). However, the development of analytical methods for the joint analysis of both high-dimensional imaging phenotypes and high-dimensional genetic data, referred to as big data squared (BD 2 ), presents major computational and theoretical challenges for existing analytical methods. Besides the high-dimensional nature of BD 2 , various neuroimaging measures often exhibit strong spatial smoothness and dependence 1 arXiv:1707.07332v2 [stat.ME] 6 Mar 2018 and genetic markers may have a natural dependence structure arising from linkage disequilibrium. We review some recent developments of various statistical techniques for the joint analysis of BD 2 , including massive univariate and voxel-wise approaches, reduced rank regression, mixture models, and group sparse multi-task regression. By doing so, we hope that this review may encourage others in the statistical community to enter into this new and exciting field of research."}, {"section_title": "INTRODUCTION", "text": "Despite the numerous successes of genome-wide association studies (GWAS), it has been difficult to unravel the genetic basis of many complex neurological diseases since each genetic variant may only contribute in a small way to disease risk and such a genetic basis can be very heterogeneous (Cannon and Keller, 2006; Marenco and Radulescu, 2010; Peper, et al. 2007 ). The additive and interactive effects of perhaps hundreds of risk genes and multiple environmental risk factors, each with small individual effects, may contribute to the abnormal developmental trajectories that underlie neurological and psychiatric disorders such as Alzheimer's Disease. Identifying such risk genes and environmental risk factors could transform our understanding of the origins of these conditions and inspire new approaches for urgently needed preventions, diagnoses, and treatments. Once such an identification has been accomplished, lifestyle and medical interventions can be applied to make a potential difference in the outcome.\nA promising approach to understanding the genetic basis of neurological disorders is through studies that integrate multi-scale data from genetic/genomic, multimodal brain imaging, and environmental risk factors (Hibar, et al., 2011; Thompson, et al., 2013; Hibar, et al., 2015) , so called imaging genetics studies.\nTo promote such studies, the Brain Imaging Clinical Research Program at the National Institute of Mental Health (NIMH) has called for the establishment of relationships between genetic variations and imaging and cognitive findings and phenotypes in adult mental disorders. To this end, a number of large-scale publicly available imaging genetic databases have been established, including the Human Connectome project (HCP) study, the UK biobank (UKbb) study, the Pediatric Imaging, Neurocognition, and Genetics (PING) study, the Philadelphia Neurodevelopmental Cohort (PNC), and the Alzheimer's Disease Neuroimaging Initiative (ADNI) study, among many others. The ADNI database in particular has been used extensively by statisticians working on the development of methods for the joint analysis of neuroimaging and genetic data, and this database serves as a good starting point for new researchers in the area.\nIn such studies, the data available for each subject may include multiple MRI images, such as structural MRI, diffusion tensor imaging (DTI), and functional MRI, cognitive assessments, and genomic data (e.g., SNP array and copy number variations (CNVs)). Jointly analyzing imaging genetics with clinical variables, however, raises serious challenges as existing statistical methods are rendered infeasible for efficiently analyzing large-scale imaging genetic data sets with many subjects. These challenges arise from a setting where the data involve high-dimensional imaging data \u00d7 high-dimensional genetic data -so-called Big Data squared (BD 2 ), complex correlation and spatial structures within both imaging and genetic data, and a potentially large number of subjects.\nFor many brain-related diseases, since changes in brain structure and function are very subtle, it is common to normalize multi-modal neuroimaging data to a common template (Xu, et al., 2003; Miller and Younes, 2001 ). After normalization, various imaging phenotypes are commonly calculated from structural and functional imaging data (Friston, 2009; Zhu, et al., 2007) . These normalized neuroimaging phenotypes are functional data measured at a very large number (10 4 \u2212 10 7 ) of grid points along space and/or time and network data measured among a large number (10 4 \u221210 6 ) of region of interest (ROI) pairs (Hibar, et al., 2011; Thompson, et al., 2013; Hibar, et al., 2015; Ge, et al., 2015a Ge, et al., , 2015b . See Figure 1 for a graphical depiction of potential Imaging Phenotypes (IPs).\nThe earliest methods developed for imaging genetics data analysis are either based on significant reductions to both data types, for example, restricting the analysis to a specific candidate ROI in the brain and/or a specific candidate genetic marker. This type of univariate analysis can be extended to handle full brain-wide genome-wide data based on the application of a massive number of pairwise univariate analyses, each based on a standard linear regression relating a given voxel/region to a given SNP. In this case the multiple testing problem can be on a very large scale and the resulting corrections very stringent, given the large number of tests involved. For example, in a full brain-wide genome-wide study involving 10 6 known genetic variants and 10 6 locations in the brain, this type of analysis will require 10 12 univariate analyses. Furthermore, the resulting p-values are not independent because of spatial correlation in the imaging data. Stein et al. (2010) are the first to consider such an analysis and these authors examined 448, 293 SNPs in each of 31, 622 voxels of the entire brain across 740 elderly subjects with 300 computational-cluster nodes used to carry out the required computations in parallel. Hibar et al. (2011) consider a similar analysis but reduce the number of tests by conducting the analysis at the gene rather than SNP level. In this case principal component analysis is used to summarize the SNP data for each gene, and the resulting 'eigenSNPs' are used in the massive univariate analysis.\nAs an alternative to the massive univariate approach, a voxel-wise approach continues to fit regression models separately at each location in the brain, but considers a set of genetic markers simultaneously rather than just a single genetic marker. Ge et al. (2011) develop such an analysis and examine a dataset that is similar to that considered in Stein et al. (2010) , but a key difference is the use of a multi-locus model based on least squares kernel machines (Liu et al., 2007) , which is used to combine the effect of multiple genetic variants and model their interaction. In addition, the spatial information in the images is accounted for through the use of random field theory as an inferential tool (Worsley, 2002) . This approach is extended in Ge et al. (2015) to allow for potential interactions between genetic variables and non-genetic variables such as disease-risk factors, environmental exposures, and epigenetic markers.\nAn alternative fast voxel-wise genome-wide association analysis (FVG-WAS) approach is that developed by Huang et al. (2015) where the authors focus on reducing the computational burden required for a full brain-wide gene-wide study. This objective is implemented in part by incorporating a global sure independence screening procedure along with inference based on the wild bootstrap. The resulting approach can implement a brain-wide genome-wide analysis in a relatively small amount of time utilizing only a single CPU.\nOne drawback of the massive univariate and voxel-wise approaches is that the relationship between the different neuroimaging phenotypes (e.g. at different regions of the brain) is not explicitly modelled, and therefore, potential efficiency gains arising from the borrowing of information across brain regions are not realized. An alternative approach is to base the analysis on a single large model, a multivariate high-dimensional regression model that is fit to the entire dataset. In this framework the scale of the data must necessarily be reduced, and it is common to summarize the entire image using a relatively moderate number of brain summary measures across some key ROIs. As an example, Table 1 describes a phenotype of dimension 56 that can be derived from an MRI image, and these data are considered in our example application.\nOne such regression model is the group-sparse multitask regression model proposed by where estimation of the regression coefficients in a multivariate linear model is based on penalized least squares. The penalty is chosen to induce a particular form of structured sparsity in the solutions based on two nested forms of group sparsity. The first is at the SNP level (grouping the regression coefficients of a given SNP across all phenotypes) and the second is at the gene level, which groups all SNPs within a given gene. More recently, Greenlaw et al. (2017) have extended this approach to the Bayesian setting which allows for inference and uncertainty quantification for the regression coefficients of the selected genetic markers.\nAn alternative multivariate approach is based on approximating the highdimensional regression coefficient matrix with a low rank matrix. Such an approach has been developed by Vounou et al. (2010) , who develop a sparse reduced-rank regression (SRRR) model which is applied to an imaging genetics study involving 111 anatomical ROIs and 437, 577 SNPs. Using simulation studies Vounou et al. (2010) show that their SRRR model has higher power to detect deleterious genetic variants compared with the massive univariate approach. Along similar lines, Zhu et al. (2014) also develop a low rank regression model with inference conducted in the Bayesian framework and they apply their approach to an imaging genetics study involving 93 ROIs and 1, 071 SNPs. Also in the Bayesian framework, Stingo et al. (2013) develop a hierarchical mixture model for relating brain connectivity to genetic information for studies involving functional magnetic resonance imaging (fMRI) data. The mixture components of the proposed model are used to classify the study subjects into subgroups, and the allocation of subjects to these mixture components is linked to genetic markers with regression parameters assigned spike-and-slab priors. The proposed model is used to examine the relationship between functional brain connectivity based on fMRI data and genetic variation.\nHuang et al. (2017) developed a functional genome-wide association analysis (FGWAS) framework to efficiently carry out whole-genome analyses of functional phenotypes. Compared with FVGWAS, FGWAS explicitly models the functional features of functional phenotypes through the integration of smooth coefficient functions and functional principal component analysis. Statistically, compared with existing methods for genome-wide association studies (GWAS), FGWAS can substantially boost the detection power for discovering important genetic variants influencing brain structure and function.\nIn more recent work, researchers have turned their attention to longitudinal imaging genetics studies where study subjects are followed over time with neuroimaging data collected over a sequence of time points during a follow-up period. With longitudinal MRI data, changes in the structure of the brain over time can be characterized, for example, by examining rates of brain deterioration, and these estimated rates of change can be related to genetic markers. Szefer et al. (2017) examine the presence of linear association between minor allele counts of 75, 845 SNPs in the Alzgene linkage regions and estimated rates of change of structural MRI measurements for 56 brain regions. The authors develop a bootstrap-enhanced sparse canonical correlation analysis to create refined lists of SNPs associated with rates of structural change over time. Lu et al. (2017) develop a Bayesian approach to perform longitudinal analysis of multivariate neuroimaging phenotypes and candidate genetic markers obtained from longitudinal studies. A low rank longitudinal regression model is specified where penalized splines are incorporated to characterize an overall time effect, and a sparse factor analysis model coupled with random effects is proposed to account for spatiotemporal correlations of longitudinal phenotypes. A useful feature of the proposed methodology is the allowance for interactions between genetic main effects and time.\nIn the remainder of the paper, Sections 2 -4 discuss in more detail some of the methods mentioned above, with emphasis placed on our own work. Section 5 presents an example application where data from the ADNI-1 database are used to examine the association between the 56 neuroimaging phenotypes presented in Table 1 and a collection of 486 SNPs from 33 genes belonging to the top 40 Alzheimer's Disease (AD) candidate genes listed on the AlzGene database as of June 10, 2010. Section 6 concludes with a discussion of some ongoing work in this area. 6 "}, {"section_title": "Mass Univariate and Voxel-Wise Approaches", "text": "Mass univariate approaches avoid the complication of jointly modelling all neuroimaging phenotypes and genetic markers and simply conduct a test for association at each possible pair of voxel and genetic marker. Voxelwise approaches are similar in that a separate model is fit independently at each voxel of the image, but these approaches may include multiple genetic markers in each model. The primary advantage of these approaches is that they make feasible a full brain-wide and genome-wide search for associations.\nWe assume that neuroimaging and genetic data are available on n subjects, where the imaging phenotype is denoted as y (v), for the numerical value of the brain image of subject , = 1, . . . , n, at voxel v, v = 1, . . . , V . We denote the set of genetic markers for subject l by x = (x 1 , . . . , x d )\nT , = 1, . . . , n, for a total of d markers, where x j \u2208 {0, 1, 2} is the number of copies of the minor allele for the j th SNP, which takes values x j = 0 (homozygotic major alleles), x j = 1 (heterozygote), and x j = 2 (homozygotic minor alleles). Finally, we let z = (z 1 , . . . , z p )\nT , = 1, . . . , n, denote a collection of non-genetic variables for subject l.\nStein et al. (2010) is the first voxel-wise genome-wide association study (vGWAS) examining genetic influence on brain structure. The authors consider neuroimaging and genetic data obtained from n = 818 subjects as part of the ADNI. The neuroimaging data are based on brain MRI scans that are processed using an approach known as tensor-based morphometry (TBM). TBM (Ashburner et al., 2000) is used to create images representing volumetric tissue differences at each of approximately 31, 000 voxels for each individual, where the value of the image in a given voxel is obtained by calculating the determinant of the Jacobian matrix of a deformation that encodes local volume excess or deficit relative to an image that is representative of the sample known as the mean template image. The analysis relates the value of the image at each voxel to each of 448, 293 SNPs.\nThe statistical methodology considered by Stein et al. (2010) is fairly straightforward, though the resulting computation is still extensive due to the total number of tests considered. At each voxel v, a linear regression is conducted with response y (v) (volumetric tissue difference relative to a mean template image at voxel v) and a separate regression model is fit relating this response to each SNP x j , assuming an additive genetic model. Additional independent variables age and gender are also included in the model,\nA standard p-value from this linear regression is obtained for each SNP-voxel pair (corresponding to a null hypothesis of \u03b1 = 0), and these p-values are computed at a given voxel as the model is fit repeatedly to all d SNPs.\nTo conserve memory, Stein et al. (2010) only save the minimum p-value at each voxel. Under the null hypothesis that the phenotype at a given voxel is not associated with any of the genetic markers, the minimum pvalue computed at each voxel is not uniform[0, 1], but it is shown to be approximately Beta(1, M ef f ), with M ef f < M , where M ef f is the effective number of independent tests conducted at each voxel, and M is the total number of genetic markers. The inequality M ef f < M arises as a result of linkage disequilibrium. 2011) is that it requires considerably less computational resources and is feasible to run on just a single CPU with reasonable processing time. The proposed approach is based on three main components: (1) a heteroscedastic linear model is specified at each voxel-locus pair; (2) a global sure independence screening procedure is incorporated to eliminate many noisy loci; (3) inference is based on wild bootstrap methods. The heteroscedastic linear model at voxel v and locus c takes the form\nand the model makes no strong assumptions on V ar[e (v)], in particular, it may vary across subjects. The hypothesis test of interest is A key aspect of these approximations is that a global sure independence screening procedure is used to eliminate many noisy loci. The global aspect of the screening procedure reduces the set of SNPs for all voxels simultaneously. The authors define a global Wald statistic W (c) for a given locus as the average of W (c, v) taken over all voxels in the image. If, for a given locus c, it is the case that H 0 (c, v) holds for all voxels v, then Huang et al. (2015) argue that W (c, v) asymptotically converges to a weighted \u03c7 2 distribution. The corresponding p-values are then computed for each locus c, and the top N 0 loci (e.g. N 0 = 1000) are selected as the candidate set.\nGiven the candidate set, a wild bootstrap approach is applied to determine significant voxel-locus pairs, or alternatively, significant cluster-locus pairs, where a cluster refers to a set of interconnected voxels each with test statistics exceeding a certain threshold. Allowing for cluster-wise inference in this way is an important advantage of this methodology over that proposed by Stein et al. (2010) and Hibar et al. (2011) , as the voxel-specific tests proposed in the latter two articles might miss spatially extended signals that do not achieve significance at any isolated voxel. In this sense Huang et al. (2015) take advantage of the spatial information in the 3D images. Ge et al. (2012) develop the first voxel-wise imaging genetics approach that allows for interactions between genetic markers. At each voxel the authors propose to fit a multi-locus model to associate the joint effect of several SNPs with the imaging trait at that voxel. The imaging traits are similar to those considered in Stein et al. (2010) though the model specified at each voxel is different. In particular, the semiparametric regression model specified at each voxel takes the form\nwhere h v (x ) denotes a nonparametric function of the SNPs and the errors are assumed to be normally distributed with mean 0 and standard deviation \u03c3 v . In this case the non-genetic covariates (e.g., age, gender, education, handedness, and total intracranial volume) are modelled parametrically and the effect of genetic markers is modelled nonparametrically using a least squares kernel machines (Liu et al., 2007) approach. The function space containing h v (\u00b7) is determined by an n \u00d7 n kernel matrix which is a function of the genetic data and must be positive definite. The (j, k) element of this matrix is a function of the SNP genotypes of subjects j and k, and Ge et al.\n(2012) specify the form of this kernel to be\nwhere IBS(x js , x ks ) denotes the number of alleles shared identical by decent by subjects j and k at SNP s and takes values 0, 1, or 2. In this case the null hypothesis of interest is H 0 (v) : h v (\u00b7) = 0, which examines the effect of multiple SNPs at each voxel. Importantly, the model is very flexible and allows for interactions between the genetic markers. Ge et al. (2012) exploit a connection between least squares kernel machines and linear mixed models to derive a score statistic based on the null model (the model with no SNPs) and argue that this statistic follows a mixture of chisquares under the null hypothesis. The score statistic has the advantage that its computation does not require the estimation of the function h(\u00b7). Using the Satterthwaite method, the distribution of this statistic under the null hypothesis is approximated by a scaled chi-squared distribution.\nApplying this technique at all voxels produces an image of score statistics and the authors assume that this statistic image behaves like a \u03c7 2 random field which facilitates inference using random field theory (Worsley, 1996) . Random field theory (RFT) produces FWE-corrected p-values for voxel-wise and cluster-wise inference by accounting for the volume and smoothness of the statistic image. As RFT requires fairly strong assumptions on the statistic image and these assumptions may not be satisfied, the authors also develop voxel-wise inference based on permutation procedures with a parametric tail approximation based on the Generalized Pareto Distribution.\nAlong with allowing for interactions among genetic variables the work of Ge et al. (2012) is the first to use RFT for inference in imaging genetics. Thus while correlation across voxels is not accounted for directly within a statistical model, the spatial structure of the imaging data is accounted for when computing FWE-corrected p-values using RFT.\nIn a subsequent paper, Ge at al. (2015) extend the least squares kernel machine approach of Ge et al. (2012) to allow for both interactions between SNPs and further allow interactions between SNPs and non-genetic variables such as disease risk factors, environmental exposures, and epi-genetic markers. The model specified is of the form\nwhere z are non-genetic variables with linear effect and w are non-genetic variables with nonlinear effect that may interact with the genetic markers. As before a kernel machine based method is used to represent the nonparametric effects. In their application, Ge at al. (2015) only consider a scalar phenotype derived through MRI, namely, the hippocampal volume averaged between the two brain hemispheres; however, combining the voxel-wise inference of Ge et al. (2012) with the more flexible kernel machine model of Ge et al. (2015) seems feasible for dealing with phenotypes comprising an entire 3D image. The mass univariate and voxel-wise approaches are appealing because of their simplicity and because the required univariate or multi-locus regression models are relatively easy to fit. Modelling the dependence between different voxels is avoided and this makes it feasible to perform large scale searches across many voxels of an image. Despite these advantages an important limitation is that these approaches do not exploit the spatial structure of phenotype-genotype associations. If a particular SNP is related to one voxel then it will likely be related to the neighbouring voxels as well, and these approaches do not allow us to borrow strength across voxels. This borrowing of strength can lead to higher power and is thus desired. Multivariate approaches are thus natural to consider, but these models typically require a significant reduction in the dimension of the neuroimaging phenotype by two orders of magnitude."}, {"section_title": "Multivariate Approaches", "text": "With multivariate approaches all of the neuroimaging phenotypes are included in a single large model that may account for the dependence structure across the different phenotypes while relating each of the phenotypes to all of the genetic markers. As a result, these approaches are typically not applied to imaging data at the voxel level as this is computationally intractable. A multivariate approach is typically applied to images reduced to a much coarser scale where each phenotype corresponds to a summary measure for an ROI in the brain. Table 1 provides an example of such summary measures for the 56 ROIs considered in our example.\nIn the work of Wang et al. (2012) an estimator based on group sparse regularization is applied to multivariate regression for relating neuroimaging phenotypes to SNPs, where the SNPs are grouped by genes and this grouping structure is accounted for in the construction of the estimator. Let y = (y 1 , . . . , y c )\nT denote the imaging phenotype summarizing the structure of the brain over c ROIs for subject , = 1, . . . , n. The corresponding genetic data are denoted by x = (x 1 , . . . , x d )\nT , = 1, . . . , n, where we have information on d SNPs, and x j \u2208 {0, 1, 2} is the number of minor alleles for the j th SNP. We further assume that each SNP can be associated with a gene so that the set of genes represents a higher level grouping of the SNPs. Thus the set of SNPs can be partitioned into K genes, and we let \u03c0 k , k = 1, 2, . . . , K, denote the set containing the SNP indices corresponding to the k th group and m k = |\u03c0 k |. This partitioning is used to allow for genewise association among SNPs. This is done through a regularization in which the coefficients of the SNPs within a gene, with respect to all of the imaging phenotypes, are penalized as a whole with an l 2 -norm, while the l 1 -norm is used to sum up the gene-wise penalties to enforce sparsity between genes. The latter is important because in reality only a small fraction of genotypes are related to a specific phenotype.\nIt is assumed that E(y ) = W T x , = 1, . . . , n, where W is a d x c matrix, with each row characterizing the association between a given SNP and the brain summary measures across all c ROIs. The estimator proposed by takes the form\nwhere \u03b3 1 and \u03b3 2 are regularization parameters weighting a G 2,1 -norm penalty 13 2007) , is added to allow for additional structured sparsity at the level of SNPs (the rows of W).\nThe estimator (1) provides a novel approach for assessing associations between neuroimaging phenotypes and genetic variations as it accounts for several interrelated structures within genotyping and imaging data. \nwith the coefficients corresponding to different genes assumed conditionally independent\nand with the prior distribution for each W (k) having a density function given\nBy construction, the posterior mode, conditional on \u03bb 2012) is the motivation for the model; however, generalizations that allow for a more flexible covariance structure in (2) can also be considered, and an extension of this model to allow for spatial correlation is discussed in Section 6.\nGreenlaw et al. (2017) develop a Gaussian scale mixture representation of this hierarchical model which allows for the implementation of Bayesian inference using a straightforward Gibbs sampling algorithm that is implemented in the R package 'bgsmtr' (Bayesian Group Sparse Multi-Task Regression) which is available for download on CRAN (https://cran.r-project.org/ web/packages/bgsmtr/). The selection of the tuning parameters \u03bb for this model is investigated in Nathoo et al. (2016) , where selection of these tuning parameters based on a fully Bayes approach with hyperpriors, an empirical Bayes approach, and the WAIC are compared. Vounou et al. (2010) propose an alternative strategy for multivariate regression modelling with imaging genetics data where the high-dimensional regression coefficient matrix is approximated by a low rank sparse matrix leading to a sparse reduced rank regression (sRRR) model. Suppose that X is the n \u00d7 d design matrix of genetic markers and Y is the n \u00d7 c matrix of imaging phenotypes. Beginning with the standard multivariate multiple linear regression model Y = XC+E, where C is the d\u00d7c matrix of regression coefficients, the approach proceeds by first imposing a rank condition on this matrix rank(C) \u2264 min(d, c) which leads to a decrease in the number of parameters that need to be estimated. In particular, if C has rank r then it can be expressed as C = BA where B is d \u00d7 r and A is r \u00d7 c such that rank(A) = rank(B) = r. The loss function for estimation is based on the weighted least squares criterion\nwhere \u0393 is a c \u00d7 c positive definite weight matrix. Vounou et al. (2010) consider sparse estimation of both B and A through penalized estimation incorporating l 1 -norm penalties. In particular, setting \u0393 to be the identity matrix we have\nwhere the first term on the RHS can be ignored as it does not depend on B or A. Assuming r = 1 and adding l 1 -norm penalization yields the following optimization problem arg min\nwhere a is 1\u00d7c corresponding to the phenotypes and b is d\u00d71 corresponding to the genetic markers. The sparsity of the solution depends on the values of \u03bb a and \u03bb b with the non-zero elements of\u00e2 selecting phenotypes and the non-zero elements ofb selecting genetic markers. While it is typical to set the dimension of the latent factor \u03b7 to be much smaller than , the approach followed in Zhu et al. (2014) is to choose a multiplicative gamma process prior for \u039b that shrinks increasingly the elements to zero as the column index increases, thereby avoiding the issue of choosing the number of factors (see also Bhattacharya and Dunson, 2011 ). The overall model for the imaging phenotype for a given subject can be written as\nand Gaussian shrinkage priors are adopted for \u03b4 j , u j , and v j , j = 1, . . . , r. 2014) offers several advantages including uncertainty quantification and a sparse latent factor model for the covariance matrix of the response. A disadvantage of the multivariate approaches, regardless of which is chosen, is that the imaging data must be substantially reduced to a summary measure over a reasonable number of ROIs (in the hundreds at most) while the mass univariate and voxel-wise approaches can be applied to tens of thousands of voxels."}, {"section_title": "Methods for Longitudinal Imaging Genetics Studies", "text": "Longitudinal imaging genetics studies such as the ADNI study can provide insight into different rates of brain deterioration and how change in the structure of the brain over time is related to genetics. Table 1 which we consider in our example analysis of the next session. A primary innovation in the analysis of Szefer et al. (2017) is to construct from longitudinal MRI data and linear mixed models a set of subject and region specific rates of change over time. These estimated rates of change are then related to genetic markers using sparse canonical correlation analysis. Szefer et al. (2017) also use inverse probability weighting to account for the biased sampling design of the ADNI study, an aspect that has not been considered in many previous imaging genetics studies.\nLet y (t) = (y 1 (t), . . . , y c (t)) T denote the imaging phenotype summarizing the structure of the brain over c ROIs for subject , = 1, . . . , n, and at time t, where, for the ADNI study considered by Szefer et al. (2017) t \u2208 {0, 6, 12, 18, 24} months following entry into the study. For the j th ROI, Szefer et al. (2017) fit the following standard linear mixed model with random intercept and slope for time\nwhere AD is an indicator for Alzheimer's Disease, MCI is an indicator for mild cognitive impairment, the \u03b2 terms denote fixed effects and the \u03b3 terms denote random effects. The estimated rate of change extracted from the fitted linear mixed model is\u03b2 3j +\u03b2 4j MCI +\u03b2 5j AD +\u03b3 2 j , and these estimates, which are region specific, are used as the imaging phenotypes in the second stage of their analysis after adjusting for population stratification using multidimensional scaling. The genetic markers are also adjusted for population stratification using the principal coordinates obtained from multidimensional scaling. A sparse linear combination of the SNP genotypes that is most associated with a linear combination of the imaging phenotypes (the estimated rates of change) is obtained using sparse canonical correlation analysis (SCCA). SCCA is a multivariate method for estimating maximally correlated sparse linear combinations of the columns of two multivariate data sets. The degree of sparsity in the coefficients of the genotypes is controlled by a regularization parameter, and Szefer et al. (2017) I{\u03b2 kb = 0}\nwhere B is the total number of bootstrap samples. These importance probabilities are then used to select important subsets of SNPs. An interesting aspect of the analysis performed by Szefer et al. (2017) is that their procedure is applied to an ADNI-1 training sample to obtain subsets of important SNPs, and the authors are then able to validate many of these priority SNPs using a validation set from ADNIGO/2. Moreover, the proposed model allows for gene-age interactions so that the genetic effects on ROI volumes can vary across time.\nLetting y j (t) denote the longitudinal imaging measure obtained from subject at ROI j and time t, the model takes the form\nwhere X contains the genetic markers; w (t) is a vector of time-varying covariates that may include interactions between genetic markers and time; \u00b5 j (t) is an overall temporal trend for the j th ROI; and b j is a vector of subject specific Gaussian random effects for ROI j corresponding to covariates z (t). Lu et al. (2017) represent the functions \u00b5 j (t) using penalized-splines, and as in Zhu et al. (2014) a low rank approximation is used to approximate the regression coefficient matrix. The errors j (t) are represented through a sparse factor model j (t) = \u039b\u03b7 (t) + \u03be (t) with priors similar to those adopted in Zhu et al. (2014) , including a multiplicative gamma process prior for \u039b. A Gibbs sampling algorithm is used to implement Bayesian inference.\nOverall, methods for longitudinal imaging genetics studies are just in their infancy, with very few published papers developing statistical methods to date. We believe there is significant scope for new work in this sub-area. Regarding the methods discussed here, a primary difference in the work of Lu et al. (2017) and that proposed by Szefer et al. (2017) is that the regression model on genetic markers in the latter case is built on estimated rates of change of the ROI volumes; whereas, Lu et al. (2017) link the genetic data directly to the mean of the ROI volumes. Both methods provide useful and complimentary techniques for analyzing longitudinal imaging genetics data."}, {"section_title": "Example Application", "text": "We provide an example application examining an imaging genetics dataset obtained from the ADNI-1 database. The analysis presented here is considered in greater detail in Greenlaw et al. (2017) ; however, our objective in this case is simply to provide the reader with a simple example illustrating the use of some of the methods discussed in our review.\nThe dataset includes both genetic and structural MRI data, the latter leading to the 56 imaging phenotypes presented in Table 1 . The data are available for n = 632 subjects (179 cognitively normal, 144 Alzheimer's, 20 309 mild cognitive impairment), and among all possible SNPs the analysis includes only those SNPs belonging to the top 40 Alzheimer's Disease (AD) candidate genes listed on the AlzGene database as of June 10, 2010 . The data presented here are queried from the most recent genome build as of December 2014, from the ADNI-1 data.\nAfter quality control and imputation steps, the genetic data used for this study includes 486 SNPs from 33 genes and these genes along with the distribution of the number of SNPs within each gene is depicted in Figure 1 . The freely available software package PLINK (Purcell et al., 2007) was used for genomic quality control. Thresholds used for SNP and subject exclusion were the same as in , with the following exceptions. For SNPs, we required a more conservative genotyping call rate of at least 95% (Ge et al., 2012) . For subjects, we required at least one baseline and one follow-up MRI scan and excluded multivariate outliers. Sporadically missing genotypes at SNPs in the HapMap3 reference panel (Gibbs et al., 2003) were imputed into the data using IMPUTE2 (Howie et al., 2009 ). Further details of the quality control and imputation procedure can be found in Szefer (2016) .\nThe MRI data from the ADNI-1 database are preprocessed using the FreeSurfer V4 software which conducts automated parcellation to define volumetric and cortical thickness values from the c = 56 brain regions of interest that are detailed in Table 1 . Each of the response variables are adjusted for age, gender, education, handedness, and baseline total intracranial volume (ICV) based on regression weights from healthy controls and are then scaled and centered to have zero-sample-mean and unit-sample-variance.\nWe fit the Bayesian model of Greenlaw et al. (2017) and also compute the group sparse multi-task regression and feature selection estimator of , both of which contain 56 \u00d7 486 = 27, 216 regression parameters. For the former approach, we select potentially important SNPs by evaluating the 95% equal-tail credible interval for each regression coefficient and select those SNPs where at least one of the associated credible intervals excludes 0. In total there are 45 SNPs and 152 regression coefficients for which this occurs. The 45 selected SNPs and the corresponding brain regions at which we see a potential association based on the 95% credible intervals are listed in Table 2 .\nThree SNPs, rs4311 from the ACE gene, rs405509 from the APOE gene, and rs10787010 from the SORCS1 gene stand out as being potentially associated with the largest number of ROIs. The 95% credible intervals for the coefficients relating rs4311 to each of the c = 56 imaging measures are Table 2 with bold font. The number 1 ranked (highest priority) SNP using this approach is SNP rs3026841 from gene ECE1. In Figure 3 we display the corresponding point estimates for this SNP along with the 95% credible intervals obtained from the Greenlaw et al. (2017) Bayesian approach, where again the credible intervals and point estimates are relating this SNP to each of the c = 56 imaging measures. Importantly, we note that all 56 of the corresponding 95% credible intervals include the value 0.\nThis result demonstrates the importance of accounting for posterior uncertainty beyond a sparse point estimate and illustrates the potential problems that may arise when estimation uncertainty is ignored, as in the approach of . The methodology of Greenlaw et al. (2017) compliments the estimator of by providing uncertainty quantification, and both approaches may be applied together for such analyses.\nWhile we have focussed on uncertainty quantification using credible intervals, the posterior distribution can be summarized through posterior probabilities of the form P r(|W ij | > \u03b4|Data) for known critical value \u03b4 > 0, or through kernel density estimation of the posterior density for certain regression coefficients. In the former case, adjustments for multiplicity can be made using Bayesian FDR procedures (Morris et al., 2008) ."}, {"section_title": "DISCUSSION", "text": "Imaging genetics is an emerging discipline that is based on combining two of the most important scientific fields where statistical research has made a major impact, genetics and neuroimaging. The resulting studies provide a number of big data challenges for statistical analysis. We have reviewed a variety of approaches for the analysis of such data focussing on mass univariate and voxel-wise approaches, multivariate approaches, and methods for longitudinal studies. Figure 5 summarizes these three approaches from a graphical perspective.\nOne class of methods that we have not discussed in our review is the class of predictive methods for imaging genetics. In this setting the dependent variable is a condition or health outcome (such as presence of Alzheimer's disease), and the imaging and genetic data are used as features for classification. These methods typically aim at detecting prognostic markers. Typically, regularization methods, boosting algorithms and deep learning methods are applied to such problems (see e.g., Zhang et al. 2014) . Within a Bayesian setting, a predictive model for imaging genetics with application to schizophrenia has been developed by Chekouo et al. (2016) .\nWhile our review is not an exhaustive review of existing methods for imaging genetics, our aim was to provide the reader with a sample of the existing work and a flavour of the challenges for data analysis in this area. Indeed, this is a relatively new area in statistics and there is much scope for improving the existing methods.\nFor example, one current avenue of interest is the extension of the methodology developed by Greenlaw et al. (2017) to accommodate a more realistic covariance structure for the imaging phenotypes. One approach for doing this is through a sparse latent factor model as considered in Zhu et al. (2014) and Lu et al. (2017) . An alternative approach that we are currently investigating is the use of spatial models based on Markov random fields for the regression errors. More specifically, for the data considered in Greenlaw et al. (2017) , our example in Section 5, and described in Table 1 , the MRI-based phenotypes will exhibit two forms of correlation: (1) spatial correlation between neighbouring ROIs on the same brain hemisphere; and (2) correlation between corresponding measures on opposite brain hemispheres (e.g., the volume of the left hippocampus will be highly correlated with the volume of the right hippocampus).\nConsidering the model formulation of Greenlaw et al. (2017) , we begin by rearranging the imaging phenotypes so that they occur in left-right pairs in the vector y \u2208 R c . Let\n,i ) T be the brain summary measures obtained at the i th ROI for both the left and right hemispheres. Then y = (y\nT is the imaging phenotype for subject with the elements rearranged so that left-right pairs are adjacent. The regression model is specified as y = W T x + e where a spatial model for e is based on a\nproper bivariate conditional autoregressive model (Gelfand and Vounatsou, 2013). We assume A is an adjacency matrix A ij \u2208 {0, 1} representing the spatial neighbourhood structure of ROIs on each hemisphere, with D A = diag{A i\u00b7 , i = 1, ..., c/2}. The conditional specification for the regression errors is given by\nwhere \u03c1 \u2208 [0, 1) characterizes spatial dependence and \u03a3 12 / \u221a \u03a3 11 \u03a3 22 \u2208 [\u22121, 1] characterizes the dependence in the phenotypes across opposite hemispheres of the brain.\nThe first level of the model can then be expressed as\nwith higher levels of the model including the shrinkage prior for W specified as in Greenlaw et al. (2017) with some minor modifications. To clarify, the neighborhood structure and resulting adjacency matrix is used in the model to represent spatial dependence between phenotypes on the same hemisphere of the brain, while \u03a3, a 2-by-2 matrix, is used to represent the correlation between the same phenotype on opposite hemispheres of the brain. For specification of such a model it is convenient to arrange the phenotypes into left-right pairs which is why the rearrangement is needed. With regards to computation for this model, Greenlaw et al. (2017) and the corresponding R package 'bgsmtr' make use of sparse numerical linear algebra routines as the full conditional distributions for W have sparse precision matrices under that model. This is essential in order for the Gibbs sampling algorithm to be scalable to imaging genetics data of even moderately large size. In the proposed spatial model, so long as the adjacency matrix A is sparse the model structure still results in sparse precision matrices where required for faster computation. This is an advantage of using the Markov random field model over some other possible spatial models. The additional parameters \u03c1 \u223c Unif(0, 1) and \u03a3 \u223c inv-Wishart(S, \u03bd) are easily added to the existing the Gibbs sampling algorithm. In addition to the use of Gibbs sampling, we are also developing a mean-field variational Bayes algorithm (see e.g., Nathoo et al., 2014) for the same model which should allow for greater scalability. We hope to report on results from this new model including a comparison of the different algorithms for Bayesian computation in a follow-up paper. The algorithms for fitting the new model will be available in the next version of the 'bgsmtr' R package. rsions of the tract. The second row shows the different candidates for is tract in the same test subject, based on using each atlas to decide hich fibers it should contain (Distance-based clustering section). The al result for this tract was obtained by applying the label fusion heme in Fiber label fusion section. It is not hard to see that the label sion process can help to eliminate outliers, and it can also add missing ers to a single candidate labeling of the tract. A manually edited gmentation result is also included for comparison (see the right ttom panel).\nFigs. 6 and 7 show the label fusion results for the 17 segmented acts in four randomly selected subjects. Despite individual variations, e overall tract shapes are consistent across the population. Fig. 8 ows the combined WM fiber clustering results for the four test subcts. The types of tracts and their colors are as in Fig. 2 . The average er number in our full set of clustering results is~40,000 per subject, roughly 1/10th of the fibers from the initial tractography. There are ree factors that affect how many fibers are included in the final results. rst, in this work, we mainly focused on 17 major anatomically wellown white matter tracts. Therefore, only those tracts are shown in g. 8. Many other less-known tracts are not shown and could be ded in future work, although it might be more challenging to reliably d smaller tracts in the mix of all the other major pathways. Second, reamline whole-brain tractography generates large numbers of false sitive fibers and those need to be removed for our ultimate goalpulation studies. Last, fiber clustering may show enormous individual riation when applied across a population. However, to perform an effective population study, we only included fibers whose shape shares the most common characteristics throughout the population for each tract. This was our intent when we built our manually constructed atlases. Clearly we would need to admit that some clinically interesting variation is missed by focusing on a set of standard tracts. But finding additional consistent tracts across subjects is challenging and runs the risk of including false positives."}, {"section_title": "Quantitative validation", "text": "To quantitatively evaluate the proposed framework, we converted each of the fiber tracts to a binary image, where voxels that the tracts cross were marked as 1, and 0 otherwise. Then we used the Dice coefficient to assessing the overlap or agreement between two tracts, defined as:\nwhere V() is the volume of the region that the tract penetrates. Due to the wide variability between different tracts, we need to tune the parameters of our algorithm to optimize its performance. We have two key parameters to adjust. One is the Hausdorff distance threshold used to select fibers for each tract per atlas (d cutoff in Eq. (4)), and the other is the percentage of fibers included in the final label fusion stage described in Fiber label fusion section. The 95% equal-tail credible intervals relating the SNP rs4311 from ACE to each of the c = 56 imaging phenotypes. Each imaging phenotype is represented on the x-axis with a tick mark and these are ordered in the same order as the phenotypes are listed in the rows of Table 1 , first for the left hemisphere and then followed by the same phenotypes for the right hemisphere. Figure 4 : The 95% equal-tail credible intervals relating the SNP rs3026841 from ECE1 to each of the c = 56 imaging phenotypes. Each imaging phenotype is represented on the x-axis with a tick mark and these are ordered in the same order as the phenotypes are listed in the rows of Table 1 , first for the left hemisphere and then followed by the same phenotypes for the right hemisphere. "}]