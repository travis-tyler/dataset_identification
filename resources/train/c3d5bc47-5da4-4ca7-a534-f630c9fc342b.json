[{"section_title": "Abstract", "text": "This study addresses missing links in \"college for all\" debates by investigating gaps between actual and desirable math achievement trajectories for students' college readiness. Linking multiple national data sets across P-16 education levels, the study estimates college readiness benchmarks separately for two-year and four-year college entrance and completion. The goals of the study are to compare performance standards, benchmarks, and norms for college readiness and to assess college readiness gaps among all students as well as gaps among racial and social subgroups. The results suggest that entrance into and completion of two-year versus four-year colleges require substantially different levels of math achievement in earlier education periods and that meeting national versus state proficiency standards leads to differences in postsecondary education outcomes and can mean the difference between bachelor's and associate's degree attainment. Persistent racial and social gaps in college readiness threaten the goal of getting all students academically ready for at least two-year college completion."}, {"section_title": "Background and Research Problems", "text": "In his speech to Congress (February 25, 2009 ), President Obama called on every American to commit to attending at least one year of college so that the country can reclaim its position as the best educated nation in the world. Echoing economic concerns that more occupations than ever require more than a high school diploma, Obama argued that the shrinking proportion of Americans with a college education and the growing high school and college dropout rates are a \"prescription for economic decline.\" While America's international edge in educational attainment was slipping, the policy of enhancing college readiness for all students was framed by supporters as an inevitable response to the demands of the 21st-century economy, requiring that even students who proceed directly to work after high school possess college-level skills (ACT, 2005; Haycock, Barth, Mitchell, & Wilkins, 1999) . However, critics questioned the value of this \"college for all\" policy for various reasons, including a narrow emphasis on market-driven vocationalism (Grubb & Lazerson, 2005) and an academically unprepared college student population (Arum & Rocksa, 2011) .\nWhat is often missing in this policy debate is empirical evidence on how well the nation is preparing all students through the P-12 education pipeline for different types and stages of postsecondary education. Even if at least one year of college education were worthwhile, affordable, and accessible for all students, one of the key questions is whether all students are academically ready for and thus can benefit from college education. Because achievement gaps start even before school entry and tend to widen over the course of K-12 schooling, it may be too late in high school to address college readiness gaps (Heckman & Lochner, 2000; \"Quality Counts 2007 . Substantial differences in college enrollment and completion remain when measured by family background characteristics, even when controlling for achievement test scores and high school grades (Ellwood & Kane, 2000) . However, previous studies of college access often examined the achievement gap at the high school level but did not trace back to earlier education periods.\nThere have been separate lines of research and policy discussion on elementary school readiness for preschool children (e.g., Clements & Sarama, 2009; Hair, Halle, Terry-Humen, Lavelle, & Calkins, 2006 ; V. E. Lee & Burkham, 2002; Pianta, Cox, & Snow, 2007) , middle and high school readiness for elementary school students (e.g., Eccles, Lord, & Midgley, 1991; MacIver & Epstein, 1991; Ravitch, 2003) , and college readiness for high school students (e.g., Adelman, 1999; Burkam & Lee, 2003; Conley, 2005; Kirst & Venezia, 2004; Rosenbaum, 2001) . The segmentation of these research efforts reflect the fact that K-12 education has been largely disconnected from both preschool education and from college education and that there has been fragmentation within the K-12 sector as well. There were efforts to interpret the National Assessment of Educational Progress (NAEP) results in terms of college readiness and other outcomes from linked data sets (National Commission on NAEP 12th Grade Assessment and Reporting, 2004; Pellegrino, Jones, & Mitchell 1999; Scott, Ingels, & Owings, 2007) . Conventional views of college readiness, on the other hand, have focused narrowly on students' first-year college placement or performance as predicted by college admissions tests, which remain to be separated from K-12 standards-based educational assessments (ACT, 2010; Zwick, 2006) .\nThe recent P-16 education policy movement seeks vertically aligned curriculum standards of learning across all levels of education, from preschool through postsecondary education (National Governors Association [NGA], 2007) . The NGA and the Council of Chief State School Officers (CCSSO) proposed the Common Core standards for K-12 education with an emphasis on college and career readiness standards (CCSSO & NGA, 2010) . Recent comparisons of the Common Core standards with aggregated state standards revealed a possible move toward greater rigor (Porter, McMaken, Hwang, & Yang, 2011) . However, it is unclear how new curriculum standards are translated into performance standards and what levels of achievement on existing or new tests are adequate for college readiness.\nThis study addresses missing links in the current P-16 education and college readiness debates by investigating gaps between students' actual and desirable math achievement trajectories for different college pathways. The study focuses on math achievement for several reasons. First of all, math achievement data are commonly available across state, national, and international assessments, and these test measures are also comparable across different data sets and grade levels. Second, high school math achievement reflects course-taking history in math, which is a strong predictor of college success, particularly among students who seek careers in STEM (science, technology, engineering, and mathematics) fields (Adelman, 1999) . What level of math achievement is required for what type and level of college education? Are the current national or state standards of math proficiency high enough for college readiness? What is the gap between desirable and actual levels of math achievement among different racial and social groups of students? How do the achievement gaps (relative to standards or norms) change over the course of P-12 education? This study addresses those questions by analyzing a broad array of nationally representative sample data sets, using curriculum-based achievement test data from preschool, elementary, and secondary education students rather than using college-bound high school students' college entrance exam data (SAT, ACT) to inform models of postsecondary education access and attainment. The goals of the present study are twofold: (a) to compare performance standards, benchmarks, and norms for college readiness and (b) to assess college readiness gaps among all students as well as among racial and social groups."}, {"section_title": "Method", "text": ""}, {"section_title": "Tracking Average Math Achievement Levels", "text": "Building upon prior research on national academic growth trajectories (J. Lee, 2010; J. Lee, Finn, & Liu, 2011) , this study used three national longitudinal data sets to track math achievement growth during P-12 education at the aggregate national level, including the Early Childhood Longitudinal Study-Birth Cohort (ECLS-B), the Early Childhood Longitudinal StudyKindergarten Cohort (ECLS-K), and the National Education\nLongitudinal Study of 1988 (NELS:88) . Doing so allows a single growth curve to be created from the different birth years of the various data set cohorts. To track the math achievement trajectory for the \"typical\" student, this study restricted the sample to students who entered school on time, made timely progression from one grade to the next, and had math achievement test scores available for all rounds of assessments. For ECLS-B, the analytical sample was restricted to children born in 2001 whose math knowledge and skills were assessed at both age 4 and in kindergarten; they entered kindergarten for the first time during either 2006 or 2007 (n = 6,051). For ECLS-K, typical refers to those students who spent one year in kindergarten and who entered Grade 1 the following year and Grade 3 two years later, and so on (n = 5,959); students who were repeating kindergarten in 1998 or who were not in kindergarten, Grade 1, Grade 3, Grade 5, and Grade 8 at the time of each spring follow-up assessment were not included in the analysis. Likewise, the NELS sample used for this study was composed only of students who were in Grade 8 for the first time in the fall of 1988 and who were in Grade 10 in the spring of 1990 and in Grade 12 in the spring of 1992 (n = 10,879).\nExamination of the longitudinal academic growth curve was carried out using the item response theory scale scores from math achievement tests in each of the respective surveys. ECLS-B, ECLS-K, and NELS:88 all used equating based on a common set of anchor items across different grade forms (Najarian, Pollack, & Sorongon, 2009 ; National Center for Education Statistics [NCES], 2010; Pollack, Atkins-Burnett, Rock, & Weiss, 2005; Rock & Quinn, 1995) . With appropriate panel weights, the study computed standardized measures of math achievement gain scores (in pooled standard deviation units) between successive grades. Once gains were computed between the successive waves of assessments available in the data sets (i.e., pre-K for age 4 and fall kindergarten in ECLS-B; fall kindergarten, spring kindergarten, and Grades 1, 3, 5, and 8 in ECLS-K; Grades 8, 10, and 12 in NELS:88), an interpolation method was used to impute math achievement for any missing interim grades. Equation 1 was used to compute an index g, cross-grade standard scores of cumulative math achievement (setting fall kindergarten school entry math achievement score as zero base), for all students and for student subgroups as classified by key background variables (i.e., race/ethnicity, parental education):\nwhere X -t is the mean of test score at time t, and s 2 t is the variance of test score at time t.\nUsing cross-grade standard scores from Equation 1, the ECLS-B curve (for pre-K to fall kindergarten), ECLS-K curve (for K-8), and NELS curve (Grades 8-12) were juxtaposed to show the full range of P-12 longitudinal growth trajectories at the aggregate national level; these national growth curves were combined by first adding ECLS-K K-8 gains on top of ECLS-B pre-K (age 4) to kindergarten gains, based on the fact that both cohorts were measured using comparable kindergarten math assessments.\n1 The curve was further extended by adding NELS 8-12 gains on top of ECLS-K K-8 gains, based on the fact that \nboth cohorts were measured using comparable Grade 8 spring math assessments. "}, {"section_title": "Estimating Math Achievement Benchmarks for College Readiness", "text": "A logistic regression method was used to examine desirable growth trajectory and to estimate age and grade-specific levels of math achievement for college entrance and completion. Using a \"contrasting groups\" method, this study estimated benchmark scores based on NELS 8th-, 10th-, and 12th-grade math test scores that best differentiated between students who attended two-year versus four-year colleges as their first postsecondary education institution and students who completed two-year versus four-year colleges (associate's degree vs. bachelor's degree holders). For this analysis, data were used from the NELS:88/2000 Postsecondary Education Transcript Study (Adelman, Daniel, & Berkovits, 2003) , which included transcripts from all postsecondary institutions attended after high school by the NELS:88 fourth follow-up study's respondent population. Specifically, this study examined four dichotomous outcome variables (Y): (a) two-year college attendance, (b) two-year college completion, (c) four-year college attendance, and (d) four-year college completion for the NELS:88 8th-grade cohort, with information on whether students attended or completed college and university during the period 1992-2000. After checking model fit and prediction accuracy, logistic regression results were used to estimate benchmark math achievement scores (X 50 ) and associated variance at the 50% chance level of Y occurrence (Kane, 1994; Livingston & Zieky, 1989) :\nwhere a is the intercept, and b is the slope of the logistic regression model that predicts college outcomes based on math achievement. A linear linking (scale concordance) method was used to convert NELS scores into the NAEP scale and then NAEP scores into the ECLS scale, based on the assumptions of test and population comparability. For the NAEP-NELS linkage, equating samples were composed of the main NAEP 1992 national sample of 12th graders and the NELS 1992 12th-grade cohort members (excluding dropouts and nonseniors; Scott et al., 2007) . For the NAEP-ECLS linkage, equating samples were composed of the main NAEP 2007 national sample of 8th graders and the ECLS-K 2007 8th-grade cohort members. Given the 19-year time gap between NELS and ECLS 8th-grade cohorts, information on the NAEP 8th-grade math achievement trend during 1990-2007 was utilized to adjust benchmark scores. The following linear conversion formula was used for converting scores on test X to the scale of test Y (Kolen & Brennan, 2004) :\nAfter the scale conversion, ECLS-K 8th graders were classified into two groups: students who were on track to colleges (i.e., at or above the corresponding NAEP 8th-grade benchmark scores for college readiness) and students who were not. Using this dichotomous grouping as a dependent variable, the same logistic regression method was used to estimate benchmark math achievement scores for grades kindergarten, 1st, 3rd, and 5th. With the ECLS-K fall kindergarten benchmark score, this score was converted into the ECLS-B scale. This linking depends on the assumption that the kindergarten math tests and student populations are comparable between 1998 and 2006-2007. Then, the same logistic regression method was used to estimate benchmark math achievement scores for determining college readiness among the ECLS-B pre-K (age 4). All of the estimated benchmark scores in the original scales were changed into z scores within grades after interpolation for missing grades, which in turn were combined with national average g scores from Equation 1 to obtain cross-grade standard scores."}, {"section_title": "Locating Existing Math Achievement Standards", "text": "This study also drew on performance standards from state assessments, from NAEP, and from the Trends in International Math and Science Studies (TIMSS); each of these assessments specify desired math proficiency levels based on curriculum standards (see the appendix for performance standard descriptions). National averages of students' math achievement levels were compared with state, national, and international math assessment standards for corresponding grades based on 2007 state, NAEP, and TIMSS test results, respectively. For the NAEP and TIMSS standards (i.e., \"proficient\" level in NAEP, \"high\" benchmark in TIMSS), given cut scores were converted into z scores based on the U.S. national mean and standard deviation of math achievement (X) within grades (Grades 4 and 8 in the 2007 NAEP and TIMSS; Grade 12 in the 2000 NAEP 3 ):\nFor state assessment standards, both test score distributions and cut scores were not available. Using states' reported percentages (representing the area above z) of students in Grades 3-11 whose math achievement were at or above target standards for No Child Left Behind accountability purposes, the study estimated z scores of individual states' proficiency standard cut scores based on the normal distribution table and then averaged z scores across states. 4 Once all of the state, national, and international standards of math proficiency were identified by within-grade z scores, these scores were then converted into cross-grade standard scores (within-grade z scores + national average g scores).\nThere are commonalities between NAEP and TIMSS that warrant linking the assessments for comparison of performance standards. First, both assessments were based on similar curricular frameworks; although the two assessments have no common items, content analyses of both assessments suggest similarities that sufficiently warrant linkage for global comparisons. NAEP and TIMSS assessments are sufficiently similar to warrant linkage for global comparisons but not necessarily good for detailed comparisons of areas of student achievement in subtopics (McLaughlin, , 1997; NCES, 2006) . Second, both assessments were administered to nationally representative samples of students at the same grade in the same year (Grades 4 and 8 in 2007) . A similar kind of linkage was made between NAEP and state assessments, because previous studies showed comparability of the two assessments in terms of content despite discrepancies in the rigor of performance standards (NCES, 2007) . Table 1 summarizes the results of logistic regression analysis including parameter estimates and model fit statistics by data set and grade. Using math achievement alone as a predictor explained about a 30% to 60% range of variance in the chance of being on track to college readiness (see column 3 in Table 1 ). The shorter the time gap between college outcomes and math achievement, the stronger the predictive validity; the end of high school math achievement at Grade 12 had slightly higher predictive validity than math achievement at 10th grade or 8th grade in terms of R 2 values, for all levels of college success. For example, the correlation between 12th-grade math achievement and four-year college completion was high (point-biserial r = .75; Nagelkerke R 2 = .37), whereas the correlation between 8th-grade math achievement and four-year college completion was relatively weaker (pointbiserial r = .68; Nagelkerke R 2 = .28). The same pattern was true for using elementary or middle school math achievement to predict the end of 8th-grade proficiency for college readiness; math achievement at the higher elementary or middle grade level was more predictive of outcomes. In addition, the accuracy of model prediction that differentiates postsecondary education pathways (i.e., the proportion of accurate classification) was high and well above the chance classification (see column 4 in Table 1 )."}, {"section_title": "Results", "text": ""}, {"section_title": "Expected P-12 Math Achievement Levels for College Readiness", "text": ""}, {"section_title": "5", "text": "Given the evidence of acceptable predictive validity and accuracy, the model parameter estimates were used to infer the minimum required knowledge and skills in preschool, elementary, and secondary education math achievement that (best predicts) students' successful college pathways. Specifically, Table 1 provides absolute (or criterion-referenced) and relative (or normreferenced) levels of math achievement that were generated to determine scores that are adequate for college readiness, as defined by entering and completing two-year or four-year colleges and universities. The logistic regression analysis estimated that the minimum NELS scale scores for four-year college completion with a bachelor's degree or above, at the 50% chance level, were 58, 54, and 46 at 12th, 10th, and 8th grade, respectively (see column 5 in Table 1 ). Corresponding NAEP-equivalent math scores were 320 for 12th grade (lower than the NAEP \"proficient\" cut score of 336) and 292 for 8th grade (close to the NAEP \"proficient\" cut score of 299). These scale scores were converted into within-grade z scores (column 6 in Table 1 ) and normal curve equivalent (NCE) scores (column 7 in Table 1 ). High school students who were on track for four-year college completion tended to perform around 0.6 standard deviation above the national norm (within-grade z score = .58 or .64) and thus performed better than about 60% of students across the nation (NCE score = 62 or 64). Similarly, the logistic regression analysis estimated that the minimum ECLS-K scale scores for four-year college completion with a bachelor's degree or above, at the 50% chance level, ranged from 33 in fall kindergarten to 141 in Grade 5. These scores also demanded similarly high levels of relative performance during elementary school as well as high school. Table 2 shows both actual and desired math achievement levels in cross-grade standard scores by grade. In addition, Figure 1 provides a visual display of the same values in Table 2 , connected across grades in a line graph format. Figure 1 and Table 2 allow researchers to compare the actual national average math achievement trajectory against desirable math achievement trajectories for two-year and four-year college entrance and completion based on the aforementioned logistic regression results in crossgrade standard scores; values from column 8 in Table 1 are repeated in columns 5-8 in Table 2 . 6 Figure 1 includes the national average P-12 math achievement trajectory, with cumulative gain scores from pre-K (age 4) through Grade 12 in standard deviation units across grades (based on column 1 values in Table 2 ). Using fall kindergarten as the baseline, there was a 1.24 \u03c3 gain from pre-K (age 4) to fall kindergarten, a 1.76 \u03c3 gain from fall kindergarten to spring kindergarten, a 3.64 \u03c3 gain from fall kindergarten to spring Grade 1, and so on. The aggregated national trajectory of math achievement shows the pattern of decelerating growth with a total gain of 8.4 \u03c3 over the entire course of K-12 education. International standards (TIMSS \"high\" benchmark) were as high as U.S. national standards (NAEP \"proficient\" standard), and both TIMSS and NAEP standards exceeded the national average scores (see Table 2 , columns 1-3). In contrast, the U.S. aggregated state standards were way below the national average (see Table 2 , columns 1 and 4). Moreover, gaps in rigor relative to NAEP and TIMSS standards were as large as 1 standard deviation or more (see Table 2 , columns 2-4)."}, {"section_title": "Actual Versus Desirable Math Achievement Trajectories", "text": "Desirable P-12 math achievement growth trajectories for college readiness diverged according to the college education outcomes (see Figure 1 and Table 2 , columns 5-8). The results suggest that entrance into and completion of different levels of postsecondary education (two-year vs. four-year colleges or universities) require substantially different levels of math achievement during P-12 education and that meeting national versus state proficiency standards may lead to differences in postsecondary outcomes and explain differences in bachelor's and associate's degree enrollment and completion. For successful completion of typical four-year colleges with a bachelor's degree, students needed to perform at or above the international test \"high\" benchmark (TIMSS) or at or above the national test \"proficient\" level (NAEP) in math, which was well above the national average. For Grade 8, the 95% confidence intervals (CIs) of math achievement benchmark g values were 7.92 to 8.40 for four-year college completion, 7.47 to 7.99 for four-year college entrance, 6.83 to 7.27 for twoyear college completion, and 5.96 to 6.6 for two-year college entrance. Both the NAEP standard (g = 8.13) and the TIMSS benchmark (g = 8.18) fell within the range of being on track for four-year college completion (95% CI = 7.92-8.40), while they were significantly above the other lower levels of college readiness criteria. For entrance into typical four-year colleges, student Note. All values are reported in cross-grade standard scores, using fall kindergarten national average math achievement score as zero baseline point. NAEP = National Assessment of Educational Progress; TIMSS = Trends in International Math and Science Studies."}, {"section_title": "FIGURE 1. National P-12 education math achievement trajectories for college readiness: actual (national average scores) and desirable (standards and benchmarks) levels in cross-grade g scores. ECLS = Early Childhood Longitudinal Study; NELS = National Education Longitudinal Study; TIMSS = Trends in International Math and Science Studies; NAEP = National Assessment of Educational Progress.", "text": "acceptable math performance was no less than the national average, the level in between the current national and state proficiency standards. For successful completion of typical two-year colleges with an associate's degree at least, students needed to meet the average state's math test proficiency standard, at minimum. For entrance into typical two-year colleges, acceptable math educational researcher 50 performance was as low as the bottom quartile of national achievement distribution, significantly below the average state proficiency standard."}, {"section_title": "College Readiness Gaps Among Racial and Social Groups", "text": "The study also revealed significant racial and ethnic gaps in terms of college readiness (see Figure 2) . Both White and Asian groups, on average, were on track for four-year college completion in early elementary grades, whereas Asian students gained a more competitive edge over White students during the middle and high school years. Hispanic students stayed on track for four-year college entrance up until Grade 3 but gradually fell to two-year college completion level. Black students fell progressively behind throughout P-12 education; their average math achievement was only good enough for two-year college completion until primary schooling but deteriorated down to two-year college entrance level during the middle and high school years.\nSimilarly, the study found significant gaps by parent education level (see Figure 3) . Students whose parents' highest education was a bachelor's degree or more were well on track for four-year college completion. Students whose parents had an associate's degree managed to stay on track for four-year college entrance. Students whose parents had a high school diploma or GED were on track for two-year college completion. Students whose parents did not complete high school were on track for two-year college completion until Grade 2, but these students gradually fell down to the two-year college entrance level."}, {"section_title": "Limitations and Caveats", "text": "This study made unprecedented linkages among multiple national data sets as well as among multiple sources of standards in order to provide both norm-referenced and criterion-referenced benchmarks of math achievement for college readiness across all grades in P-12 education and across all schools in the nation. 7 The study has limitations and requires caveats for interpretations and uses of its results.\nFirst, the underlying assumption of comparable math assessments among different national data sets needs careful validation. Particularly, there was only indirect linkage made between preschool or elementary school data and postsecondary education data. Therefore, interpretations of P-5 data in relation to college outcomes depend on the strength and validity of intermediate linking processes (both the NAEP-NELS linkage and the NAEP-ECLS linkage). For validation of the linking, the study verified the consistency of relative subgroup performance between original and converted scales for paired tests. However, until more direct evidence supports the linking of early childhood education and postsecondary education data, the estimates of benchmark scores for P-5 grades should be taken as tentative approximation.\nSecond, college readiness benchmark achievement levels were derived from empirical relationships between P-12 math achievement and college outcomes, as observed during different periods of data sets used for this study : NELS (1988 : NELS ( -2000 , ECLS-K (1998 ECLS-K ( -2007 , and ECLS-B (2005 ECLS-B ( -2007 . If the form and strength of those relationships change along with demographic and achievement trends over time, the benchmarks are likely to change as well. Supplementary analysis of the Education Longitudinal Study (ELS) of 2002 second follow-up data (applying the same logistic regression method as with NELS) estimated that the ELS 12th-grade math benchmark scores were 32.6 and 53.3 (in a NELS-equivalent scale 8 ) for two-year college entrance FIGURE 2. National P-12 education math achievement trajectories for college readiness by race/ethnicity: actual (subgroup average scores) and desirable (benchmarks) levels in cross-grade g scores.\nMarch 2012 51 and four-year college entrance, respectively. Those scores were slightly higher than corresponding NELS 12th-grade benchmark scores of 30.03 and 50.03, but the differences were not statistically significant at the 95% confidence level. The stability of college readiness benchmark results might be attributable partly to the trend of constant math achievement: The distributions of two high school senior cohorts' math achievement did not change significantly between NELS (M = 49, SD = 14) and ELS (M = 50, SD = 14), and this trend was consistent with the trend of NAEP results (NCES, 2001 (NCES, , 2005 , showing that both 12th graders' and 17-year-olds' math achievement remained largely constant during the same time period (1992) (1993) (1994) (1995) (1996) (1997) (1998) (1999) (2000) (2001) (2002) (2003) (2004) . One caveat about this comparison, however, is the difference in the time and duration of data collection between NELS and ELS; college entrance data from the ELS spans only a two-year period after high school graduation on average, whereas corresponding NELS data collection extends to an 8-year post-high school period.\n9 A study of national achievement trends demonstrated uneven academic growth patterns at different levels of the P-12 education system (J. Lee, 2010) . Therefore, the stability and change of college readiness norms and benchmarks deserve further study.\nMoreover, the nature of the tests used by this study (i.e., lowstakes tests without any direct consequences for students, teachers, or schools) may have influenced the results. The application of the same linking method to college entrance exam data (SAT, ACT) for the NELS cohort shows the comparability of math benchmark scores between different tests. 10 The NELS 12th-grade math benchmark score of 52 for four-year college entrance translated into 444 for SAT and 20 for ACT. The benchmark scores turned out to be close to median SAT and ACT scores of \"less competitive\" institutions based on Barron's selectivity index.\n11 Likewise, the NELS 12th-grade benchmark math score of 58 for four-year college completion translated into 505 for SAT and 22 for ACT; this score turned out to be same as ACT's own College Readiness benchmark, for which success is defined as a 50% or higher probability of earning a B or higher in the corresponding college course or courses (ACT, 2010) .\nThird, the study focused on math achievement and did not examine academic performance in other subjects or noncognitive skills that can influence college pathways simultaneously."}, {"section_title": "12", "text": "Because both college entrance and completion depend on many factors that are correlated with math achievement, the predictive validity of math achievement (as demonstrated in this study) may reflect not only its unique contribution but also the joint contribution of math achievement with other related factors.\nFourth, the study used college entrance and completion as key outcomes. Although these two variables determine the degree of college education attainment, it is also important to examine students' learning and performance results during their college education. Although there have been efforts to assess college learning (Arum & Rocksa, 2011; OECD, 2011; Pascarella & Terenzini, 2005) , national data with standardized measures of college learning have yet to be collected.\nLastly, this study examined only aggregate national patterns and ignored variations among postsecondary institutions beyond the two-year versus four-year distinction. Future studies might differentiate among four-year colleges and universities based on admissions selectivity or other institutional quality indicators (e.g., Carnegie classification). The study also did not differentiate between states in terms of the relative rigor of student performance standards. The discrepancy between NAEP and state assessment results is difficult to generalize due to variations educational researcher 52 among state standards; as such, the aggregated state standards depicted in this study characterize only typical state patterns."}, {"section_title": "Conclusion", "text": "Although the United States is arguably losing its international edge in terms of young adults' attainment of higher education, one underlying problem lies with college readiness gaps and racial/socioeconomic disparities. Notwithstanding the rhetoric of \"college for all\" and P-16 education policy initiatives, there is a dearth of empirical research to inform national educational policies and standards for college readiness. This study revealed large disparities between actual and desirable math achievement levels for college readiness at the national level. School math achievement was a good predictor of whether students in P-12 education stay on track toward two-year or four-year college education. The findings suggested that the typical state standard of math proficiency might be adequate only for typical two-year college completion, whereas the national proficiency standard (NAEP) or international benchmark (TIMSS) was high enough for typical four-year college completion. Comparison of actual versus desired achievement levels by student subgroups revealed that some disadvantaged minority groups, on average, were not on track for reaching the goal of at least two-year college completion. Specifically, the average Black student and a student whose parents had less than a high school education were at risk of failing to meet this goal.\nThe feasibility or utility of national standards and benchmarks may be questionable under a highly decentralized American higher education system where individual postsecondary institutions have the autonomy of setting admission and graduation standards. In fact, the variance in college readiness levels is reflected in the different threshold scores for admissions and in the criteria for course placement in selective institutions. Although such institution-specific definitions and practices of college readiness may serve the needs of particular groups of college-bound students, the national standard may function as the minimum threshold for all students, including those who may not pursue postsecondary education. In other words, institutional admissions data cannot provide a comprehensive picture of how well the nation as a whole is prepared for meeting the goal of college for all. Moreover, because college admission tests are not strategically aligned with national or state standards for school curriculum, college admission test scores are unable to inform educational policy and practice to improve college readiness for disadvantaged minority groups at critical earlier periods.\nMajor limitations of this study include aggregated nationallevel analysis, the use of outdated high school data, exclusive focus on math achievement as a sole predictor of college outcomes, and approximation of college readiness benchmarks by linking separate data sets. It is desirable to build a new integrated longitudinal national database for the same cohort that spans the entire course of P-16 education. A national P-16 education data tracking system cannot be built without common standards in place across all states. There is a potential gap between curriculumbased, consensus-driven K-12 performance standards and forward-looking, empirically derived college readiness benchmarks. This study has implications for setting and ensuring desired achievement levels on new assessments based on the national Common Core standards that have been developed through the synthesis of best practices and prior research in K-12 education (CCSSO & NGA, 2010) . What does the notion of \"proficient\" or \"on track\" mean in the context of an increasingly stratified higher education sector (Roksa, Grodsky, Arum, & Gamoran, 2007) ? Given the finding that students performing at or above the TIMSS high benchmark or NAEP proficient level are likely to directly enter a four-year college and successfully graduate, a new performance standard could be as high as the TIMSS or NAEP counterpart (in the approximate range of 60th-70th percentile ranks) for achieving the goal of a four-year college education and a bachelor's degree. At the same time, another national performance standard could be set at the level of typical state performance standards (in the approximate range of 30th-40th percentile ranks on national norms) if the goal is associate's degree attainment. In any case, these results may need periodic updates due to changes in the curriculum as well as in students (demographics and achievement). Furthermore, what should college readiness standards or benchmarks mean to off-track students without adequate learning opportunities and support? Future research on college readiness standards needs to address both adequacy and equity issues in terms of dynamic environmental factors that shape students' academic growth trajectory throughout P-16 education. [NCES] , 2010); the ECLS-B kindergarten item pool was a combination of items fielded as part of the preschool main study and items used with kindergartners in the ECLS-K.\n2 The ECLS-K and National Education Longitudinal Study of 1988 (NELS:88) 8th-grade tests have close alignment with each other, as both adopted similar assessment frameworks and test items (Najarian, Pollack, & Sorongon, 2009) . 3 The National Assessment of Educational Progress (NAEP) 12th-grade math standard changed in 2005. The 12th-grade math proficiency standard in this study is based on the pre-2005 cut score, and thus the cut score was compared with 12th-grade NAEP test results from 2000. 4 Aggregating information on individual states' percentages of students who meet or exceed standards for No Child Left Behind, the study ignores variations among states and focuses on the national average picture of state proficiency standards.\n5 For example, hit rates for models of predicting four-year college completion (bachelor's degree attainment) in NELS:88 are 76%, 75%, and 74%, respectively, for 12th grade, 10th grade, and 8th grade; these values are significantly greater than the chance classification rate of 56%. Hit rates for models of on-track to four-year college completion in ECLS-K range from 73% to 83% (greater than the chance classification rate of 55%). The corresponding hit rate for the model based on preschool math achievement in ECLS-B is 77%. 6 Cross-grade g-score values of benchmarks (column 8 in Table 1) were computed by adding within-grade z score values (column 6 in Table 1 ) to cross-grade national average standard scores (column 1 in Table 2 ).\n7 Although state-level efforts are under way (e.g., the Data Quality Campaign's 10 essential elements of a robust longitudinal data system), there is currently no single national data set that longitudinally tracks the same students over the entire course of P-16 education. Many students move from one state to another for transition into postsecondary education, so a state-specific student data tracking system cannot track students across states. 8 The NELS:88-equated item response theory estimated that number-right scores for mathematics are estimates of the number of items students would have answered correctly had they taken the NELS:88 exam and responded to all items in the mathematics items pool (Ingels, Pratt, Rogers, Siegel, & Stutts, 2005). 9 Given this difference in time frame, the average college entrance rate turned out to be higher for NELS than for the Education Longitudinal Study (ELS), particularly for two-year colleges, which many nontraditional students enter with some time lapse after high school graduation. This time factor may have influenced the selectivity of the college student population between the two data sets and resulted in slightly higher (albeit statistically insignificant) readiness benchmark scores for ELS than for NELS. The ELS third follow-up is planned for 2012, and once it becomes available, the data have potential to give more updated results and cross-cohort differences in both college entrance and completion as outcome measures. 10 The correlations between NELS 12th-grade math test scores and SAT/ACT math scores are very high (between NELS and SAT, r = .87; between NELS and ACT, r = .83); the strength of these relationships is comparable to the strength of relationship between SAT and ACT scores among NELS test takers (r = .85). "}, {"section_title": "APPenDix (continued)", "text": "educational researcher 54 11 According to Barron's College Admissions Selector Ratings, median SAT and ACT scores for less competitive institutions were below 450 and 21, respectively, in 1992; those scores rose to below 500 for SAT and remain same for ACT in 2008. 12 Math is more structured and sequential than other subjects, so it may be relatively easier to accomplish both horizontal linkage (across data sets) and vertical linkage (across grade levels within data set). Despite this constraint, subsequent studies need to consider other subjects and nonacademic factors (social and emotional skills) that influence college pathways and long-term career development."}]