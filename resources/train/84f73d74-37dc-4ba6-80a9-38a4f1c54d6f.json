[{"section_title": "Abstract", "text": "Brain imaging was regarded as an elective examination in patients with cognitive decline 15 years ago [1] . The practice parameters for diagnosis and evaluation of dementia defined by the American Academy of Neurology regarded computed tomography (CT) and magnetic resonance (MR) as 'optional' assessments [2, 3] . Over time, imaging in dementia has moved from a negative, exclusionary role to one that added positive diagnostic and prognostic information. In the late 1990s, the traditional exclusionary approach was abandoned in favor of the inclusive approach [4, 5] . Rapid advances in neuroimaging technologies such as PET, single photon emission CT, MR spectroscopy, diffusion tensor imaging and functional MRI have offered new vision into the pathophysiology of Alzheimer's desease (AD) [6] and, consequently, increasingly new powerful data-analysis methods have been developed [7] .\nSince the beginning of the 21st Century, the development of innovative techniques for region-of-interest-based volumetry, automated voxel-based morphometry, cortical thickness measurement, basal forebrain volumetry and multivariate statistics have emerged [7] [8] [9] and those measurements most feasible and accurate have started to be used in clinical settings. The availability to the neuroimaging community of large prospective image data repositories has led to the development of web-based interfaces to access data and online image analysis tools to assess longitudinal brain changes [10] [11] [12] [13] .\nWith the development of novel analysis techniques, the computational complexity of neuroimaging analysis has also increased signifi cantly. Higher spatial resolution images and longer time scans are being acquired so that more voxels will need to be processed for each acquisition. The same applies to the computational resources required by algorithms, since these have become increasingly central processing Neuroscience is increasingly making use of statistical and mathematical tools to extract information from images of biological tissues. Computational neuroimaging tools require substantial computational resources and the increasing availability of large image datasets will further enhance this need. Many efforts have been directed towards creating brain image repositories including the recent US Alzheimer Disease Neuroimaging Initiative. Multisite-distributed computing infrastructures have been launched with the goal of fostering shared resources and facilitating data analysis in the study of neurodegenerative diseases. Currently, some Grid-and non-Grid-based projects are aiming to establish distributed e-infrastructures, interconnecting compatible imaging datasets and to supply neuroscientists with the most advanced information and communication technologies tools to study markers of Alzheimer's and other brain diseases, but they have so far failed to make a difference in the larger neuroscience community. NeuGRID is an Europeon comission-funded effort arising from the needs of the Alzheimer's disease imaging community, which will allow the collection and archiving of large amounts of imaging data coupled with Grid-based algorithms and sufficiently powered computational resources. The major benefit will be the faster discovery of new disease markers that will be valuable for earlier diagnosis and development of innovative drugs. The initial setup of neuGRID will feature three nodes equipped with supercomputer capabilities and resources of more than 300 processor cores, 300 GB of RAM memory and approximately 20 TB of physical space. The scope of this article is highlights the new perspectives and potential for the study of the neurodegenerative disorders using the emerging Grid technology."}, {"section_title": "", "text": "Brain imaging was regarded as an elective examination in patients with cognitive decline 15 years ago [1] . The practice parameters for diagnosis and evaluation of dementia defined by the American Academy of Neurology regarded computed tomography (CT) and magnetic resonance (MR) as 'optional' assessments [2, 3] . Over time, imaging in dementia has moved from a negative, exclusionary role to one that added positive diagnostic and prognostic information. In the late 1990s, the traditional exclusionary approach was abandoned in favor of the inclusive approach [4, 5] . Rapid advances in neuroimaging technologies such as PET, single photon emission CT, MR spectroscopy, diffusion tensor imaging and functional MRI have offered new vision into the pathophysiology of Alzheimer's desease (AD) [6] and, consequently, increasingly new powerful data-analysis methods have been developed [7] .\nSince the beginning of the 21st Century, the development of innovative techniques for region-of-interest-based volumetry, automated voxel-based morphometry, cortical thickness measurement, basal forebrain volumetry and multivariate statistics have emerged [7] [8] [9] and those measurements most feasible and accurate have started to be used in clinical settings. The availability to the neuroimaging community of large prospective image data repositories has led to the development of web-based interfaces to access data and online image analysis tools to assess longitudinal brain changes [10] [11] [12] [13] .\nWith the development of novel analysis techniques, the computational complexity of neuroimaging analysis has also increased signifi cantly. Higher spatial resolution images and longer time scans are being acquired so that more voxels will need to be processed for each acquisition. The same applies to the computational resources required by algorithms, since these have become increasingly central processing Neuroscience is increasingly making use of statistical and mathematical tools to extract information from images of biological tissues. Computational neuroimaging tools require substantial computational resources and the increasing availability of large image datasets will further enhance this need. Many efforts have been directed towards creating brain image repositories including the recent US Alzheimer Disease Neuroimaging Initiative. Multisite-distributed computing infrastructures have been launched with the goal of fostering shared resources and facilitating data analysis in the study of neurodegenerative diseases. Currently, some Grid-and non-Grid-based projects are aiming to establish distributed e-infrastructures, interconnecting compatible imaging datasets and to supply neuroscientists with the most advanced information and communication technologies tools to study markers of Alzheimer's and other brain diseases, but they have so far failed to make a difference in the larger neuroscience community. NeuGRID is an Europeon comission-funded effort arising from the needs of the Alzheimer's disease imaging community, which will allow the collection and archiving of large amounts of imaging data coupled with Grid-based algorithms and sufficiently powered computational resources. The major benefit will be the faster discovery of new disease markers that will be valuable for earlier diagnosis and development of innovative drugs. The initial setup of neuGRID will feature three nodes equipped with supercomputer capabilities and resources of more than 300 processor cores, 300 GB of RAM memory and approximately 20 TB of physical space. The scope of this article is highlights the new perspectives and potential for the study of the neurodegenerative disorders using the emerging Grid technology. unit (CPU)-intensive. Unfortunately, many medical imaging facilities do not currently have the necessary computational resources -usually expensive and difficult to maintain -in order to satisfy the computational demand of the most advanced neuroimaging analysis. To exploit new neuroimaging algorithms, the current working paradigm is that scientists physically migrate with small personal datasets (of a few hundred images at most) to centers of excellence where they can find expertise and computational resources. Typically, a research fellow spends 3 months or more at an image analysis center where he/she learns the use of those algorithms on personal image data. Then he/she returns to the original research group where the procedure has to be installed in whole or in part and, finally, runs jobs either in house or remotely on the image analysis center servers and mainframes (Figure 1 ).\nThis scenario, which has so far been sustainable, will need to change radically in the near future when thousands of images will become available [13] [14] [15] [16] [17] . Under these circumstances, the neuroimaging community will need an efficient distributed infrastructure where high-performance computing and innovative customizable algorithms will be available, together with access to the large image datasets that are currently being collected worldwide (Figure 2 ) [18] [19] [20] .\nIn the following section, we will describe some of the advantages of Grid infrastructures and outline in detail the architecture and structure of an innovative infrastructure that is currently under development, neuGRID [101] , funded by the European Commission under the seventh Framework Programme. Finally, specific regard will be devoted to applications that might hugely benefit from Grid technology for the study of neurodegenerative diseases."}, {"section_title": "Recent decentralized neuroscientific infrastructures", "text": "A number of efforts at creating large image repositories exist worldwide and tools have been developed to manage the increasing wealth of image data with which biomedical scientists will soon need to cope. For example, in the USA, the largest ever project in the field of neurodegenerative disorders (the North American Alzheimer's Disease Neuroimaging Initiative [ADNI]) [21] assesses early AD patients every 6 months for 4 years with different imaging techniques, allowing the collection of over 5000 brain imaging studies. In Europe, the feasibility of the adoption of the ADNI platform has been evaluated in the Foresight Study for the Development of a European NeuroImage Repository (FP6 ENIR) [22] , in the data collection study pilot European ADNI [23] and in the Innomed-AddNeuroMed (FP6) [24] .\nAddNeuroMed has studied 900 persons at baseline, 3 and 12 months and facilitated the collection of 2500 brain imaging studies. Notably, these images are acquired using the ADNI protocol and, with the ADNI 5000 images, thus created a dataset of approximately 7500 brain imaging studies overall. Moreover, the ADNI data are public and access to that data will be granted to any scientist wishing to exploit it. The combination of larger datasets and larger scientific communities make research environments necessary with efficient archiving systems as well as powerful computational facilities.\nNeurobase is another initiative that aimed to promote the federation of distributed information databases in neuroimaging, based on a distributed architecture [25] . Interestingly, the clinical and imaging data of Neurobase is not open to the public but only reserved to partners.\nThe US-NIH MRI Study of Normal Brain Development (NIHPD) has produced a definitive database of normal child brain development images [26, 27] . Over 500 children from newborn to 18 years old were followed with repeated MRI and clinical/behavioral testing. Scientists physically migrate to imaging centers where they can find expertise and computational facilities (upper section of the panel). Distributed archive and distributed analysis will be available through the Grid infrastructures. Grids will bring the image analysis center in the laboratory for each individual neuroscientist (bottom section of the panel). [27] . Owing to its simplicity and reliability, it has been chosen as the foundation of the n euGRID database.\nIn parallel with these increasingly sophisticated neuroimaging datasets, some first rudimentary environments have been developed for the advanced management and use of large repositories of biomedical images. The project Towards a Grid Environment to Process and Share DICOM Objects (TRENCADIS) developed a software platform comprising a set of services as a solution for interconnecting, managing and sharing medical (DICOM) data for the development of training and decision support tools [28] . The Web Interfacing Repository Manager (WIRM) is an open-source toolkit that allows the creation of web applications that facilitate the acquisition, integration and dissemination of biomedical data over the web [29] . The system is able to support the collaboration of computer scientists, neuroscientists, radiologists and other clinical professionals, enabling them to share experimental data and work together on a distributed software system for the study of the brain. WIRM was funded by the US National Institute of Mental Health, it is a Perl-based application server running on the Linux, Apache, MySQL and Perl (LAMP) platform and its access is public.\nOther brain MRI datasets specific to the evaluation of the neuroimaging tools have been developed. The IBSR is a world wide web resource providing access to brain MRI data and segmentation results [102] .\nAs the interest in quantitative analysis of medical image data is growing, the need for the validation of techniques is increasing too. The BrainWeb portal contains a set of realistic MRI data volumes produced by an MRI simulator [30] . These data can be used by the neuroimaging community to evaluate the p erformance of v arious image-analysis tools.\nNotably, computing facilities are included in none of the aforementioned environments. Table 1 reports the initiatives mostly aimed at the management of neuroimaging data, but none of which offers computational facilities. Since 2001, many national institutions have started to fund projects to address the absence of advanced computing facilities available to neuroscience research, which has resulted in the NeuroGrid [31] , PsyGrid [32] , NeuroPsyGrid [33, 34] , NeuroLOG [35] and Bing [36] projects. All these initiatives, characterized exclusively by national extensions, were developed with the objective of validating small Grid-based networks, promoting data sharing and data combination via specific-domain ontology, exploiting new tools of analysis for different neuropathologies and defining new methodology of analysis.\nThe Biomedical Informatics Research Network (BIRN) is probably the best known of such efforts; BIRN aims to enable a software fabric for participating centers and to facilitate the collaborative use of domain tools and flexible At the University of California in Los Angeles (UCLA; LA, USA), the Laboratory of NeuroImaging (LONI) allows the specification and execution of complex pipelines utilizing existing processing and visualization tools onto given data sets. The LONI Pipeline project [39] has a powerful client-server architecture based on a Sun Grid Engine (SGE), which uses the Distributed Resources Management Application (DRMAA) that enables the sequencing and execution of heterogeneous software modules developed by numerous groups around the world. The execution can be performed locally or via connection to the LONI facilities. The graphical interface provides users with a simple, intuitive and flexible system. It handles all connections, conversions and other housekeeping between software modules. Finally, it connects to the LONI Image Data Archive (IDA), in which the ADNI dataset is stored, among others. Table 2 demonstrate that Grid-based solutions might be an a ppropriate answer to the archiving and c omputational needs of neuroscientists [40] [41] [42] . Indeed, Grid-based solutions to share data and carry out advanced computational analyses are spreading fast but very few have international capacity."}, {"section_title": "The initiatives reported in", "text": "NeuGRID [101] is the first e-infrastructure project at a European level including both European neuroimaging research centers and information technology (IT) companies (Figure 3 ). It aims to provide the European neuroscience community with services such as the collection/archiving of large amounts of imaging data paired with computationally intensive analyses. The neuGRID initiative takes a focused and centralized approach, which we hope will greatly increase the Grid's productivity. Rather than trying to connect existing disparate datasets and codebases together, a Gridwide, coherent database and image-processing structures are implemented, moving directly from the need of a neuroscience community. Biomedical scientists will be able to identify neurodegenerative disease markers through the analysis of 3D brain MRI via the provision of sets of both distributed medical and Grid services. Once this has been successfully accomplished, the infrastructure could be generalized to other medical application areas (designed from the specific to the general)."}, {"section_title": "NeuGRID's Grid", "text": "The neuGRID project started in February 2008 and will last for 3 years. The neuGRID infrastructure is designed to be expandable and it will be compliant with international standards for data collection [104] and data management. Three typical neuGRID scenarios are:\nn Clinical data/images collected from subjects considered to be specifically suited to enter in the neuGRID infrastructure (e.g., US-ADNI or AddNeuroMed data).\nn Clinical data/images previously collected in different research projects that will be archived in neuGRID (e.g., Pilot E-ADNI, Italian ADNI and other similar datasets acquired using the ADNI protocol).\nn Clinical data/images previously collected in different research projects that will be analyzed but not archived in neuGRID (e.g., projects founded by 'Big Pharma' or biotechnology industries to test the efficacy of new drugs in some trials of Phase II or III).\nfuture science group\nSpecial Report Redolfi, McClatchey, Anjum et al. NeuGRID NeuGRID aims to provide a user-friendly Grid-based research e-infrastructure enabling the European neuroscience community to carry out research required for the study of degenerative brain diseases.\nThe collection and archiving of large amounts of images will be paired with computationally intensive data analyses\nCBrain The CBrain goal is to develop a Canadian network of the five leading brain imaging research centers. The goal is to create a platform for distributed processing and exchange of 3D-4D brain imaging data. The expected result is a platform that will render the processing environment transparent to a remote user in order to apply complex algorithm 'pipelines' to large databases Grid infrastructures for computational neuroscience: the neuGRID example Special Report\nNeuGRID exploits the experience developed during the earlier FP5 MammoGrid project (this provided knowledge related to the middleware and upperware that allowed specific applications to 'talk' to the Grid while remaining independent) [43] [44] [45] [46] [47] [48] , and the AddNeuroMed study (the collection, archiving and retrieval of multicenter clinical data, biomedical images and computerized image analysis) from the FP6 InnoMed project.\nThe design philosophy underpinning neu-GRID is one that embodies the principles of reuse, flexibility and expandability. A layered and service-oriented approach (SOA) is followed to address these requirements. This approach enables a separation of concerns between the details of the application services (brain imaging) and the Grid deployment infrastructure. Different services will be delivered to satisfy the specific requirements of neuroscientists but will be designed and implemented to be flexible in nature and reusable in application. In this manner, a set of generic services will glue a wide range of user applications to available Grid platforms. This will result in the production of a system that addresses specific applications but that retains a large degree of underlying generality, thus being able to cope with the still rapidly changing Grid environment. A schematic diagram of this layered approach is shown in Figure 4 .\nNeuGRID's key research challenges are: the gridification of the most advanced neuroimaging algorithms starting from the Constrained Laplacian Anatomic Segmentation using Proximity (CLASP; cortical extraction software developed at Montreal Neurological Institute) cortical thickness extraction algorithm [49] [50] [51] as proof-of-principle (Figure 5) , the development of a middle layer of generic services to make the infrastructure expandable to a huge number of neuroimaging pipelines and the ability to offer a Grid-based easy-to-use set of tools with which scientists could transparently perform analyses and collaborate internationally.\nThe neuGRID infrastructure consists of two main levels (plus eventually one additional layer), each of which has a specific role (Figure 6 ).\nLevel 0: this is the upper level of the Grid, which hosts the two main nodes of the entire Grid: the Data Coordination Centre (DCC) and the Grid Core Centre (GCC). The DCC's primary functions are the deployment, development and maintenance of the applications inside neuGRID. It coordinates operations such as: the standardization of acquisition protocols, the development of quality control procedures, the monitoring of data consistency, and the use, performance, evaluation and validation of the image-analysis algorithms. The DCC takes care of coordinating and maintaining the different downstream Data Archiving Computing Site (DACS) of level 1. Towards a later phase, the DCC will also participate in the Grid, providing additional storage space and CPU resources to neuGRID. The DCC is physically located in Prodema Informatics facilities in Wil, Switzerland.\nThe GCC is in charge of hosting, maintaining and running the Grid middleware services. The information system service is the core component of every Grid. Thanks to the information system, it is possible to obtain updated information regarding the status of the Grid; to retrieve updated information regarding free space on storage elements or the number of free CPUs of a DACS computing element; to discover the closest computing element for a worker node of a DACS core laboratory or to search for the best computing element matching a particular users' job requests. These services are the cornerstones providing the inner mechanics of the distributed infrastructure. The GCC is installed in Maat GKnowledge headquarters in Archamps, France.\nLevel 1: the DACS primary functions are the coordination and quality control of data acquired at the level 2 sites; and the provision of Grid resources (storage space, CPU and expertise). All the Grid data will be stored and archived at the level 0 and level 1 nodes. The DACS have been strategically selected so that pre-existing supercomputing facilities can be bridged and then used by the neuGRID system, allowing the execution of large-scale computing intensive data analysis. Powerful brain analysis tools will be available for the analysis of large datasets of thousands of MRI. The DACS is situated at IRCCS Fatebenefratelli in Brescia, Italy, at the Karolinska Institute in Sweden and at the VU Medical Center in The Netherlands. Each node of this project is planned to be equipped with a Grid cluster and supercomputer capabilities characterized by at least 100 processor cores, 100 GB of RAM memory and up to 6 TB of physical space. In addition, each neuGRID node could be easily expandable by different orders of magnitude. The DACS number could rise over the course of the project with the inclusion of new centers, assuring a gradual and constant development of the neuGRID platform, which will result in augmented computing facilities and enlarged user communities. Central storage is expected to rapidly increase reaching a theoretical total storage capacity of some petabytes by the end of 2010. Grid infrastructures for computational neuroscience: the neuGRID example Special Report Beyond the level 0 and level 1 centers, there is one other potential level of the neuGRID platform: level 2. This would consist of the so-called Data Collection Sites (DCS), which should collect MR imaging sequences and nonimaging records. At this early stage of development the level 2 centers do not, as yet, belong to the neu-GRID platform. However, once the procedure of data acquisition in the level 2 sites begins then the data should be sent to the DACS through a secure internet connections (i.e., Secure File Transfer Protocol/Secure Socket Layer). Later, these data will undergo quality assurance control by level 1 centers, they will be included in the neuGRID database and then they will be made public for the entire neuroimaging community. When feasible in terms of IT infrastructure, DCSs may also act as the lowest computing resource satellites in the Grid.\nNeuGRID nodes exploit the G\u00c9ANT [105] EU Research Network. G\u00c9ANT provides neuGRID with the highest possible c apacity present today (through a bandwidth of up to 10 Gbps) and offers one of the widest g eographic coverage in the world. The Level 0 and level 1 of neuGRID sites have already been identified as relevant c andidates for G\u00c9ANT connectivity."}, {"section_title": "NeuGRID architecture", "text": "In computing, a SOA represents a method in which a loose coupling of functions between operating systems, programming languages and applications [52] can be achieved. A SOA separates functions into distinct units termed services [53] . The MammoGrid project proposed perhaps the first healthcare example of a Grid-based SOA [43] . The MammoGrid philosophy was to provide a set of services that were i ndependent both of the front-end clinician-facing software and of the back-end Grid-facing software. In other words, a threelayer service architecture was proposed and implemented where the clinician was protected and isolated from the choice of Grid technologies. NeuGRID has followed the MammoGrid philosophy in develop ing a platform based on a SOA [54, 55] , in order to enhance its flexibility and inter operability and to promote its r eusability, potentially across other medical applications. This a rchitecture will allow neu-GRID to be designed and i mplemented in such a way that its users do not require any advanced Grid know-how. This will be a great benefit since it has been shown that users often find it difficult to cope with the i nherent complexities of Grid infrastructures.\nThrough the SOA, the neuGRID services are designed to satisfy all the specific requirements of neuroscientists. During the first 12 months of the project, detailed user requirements have been investigated, identified, collected and described in the three DACS neuroimaging centers, Karolinska Institute, Fatebenefratelli and VU Medical Center. At present, in n euGRID the Grid services are implemented on the EGEE/gLite middleware [106] . gLite provides a framework for building Grid services by tapping into the power of distributed computing and storage resources across all the DACS. However, most of the services developed within the neuGRID infrastructure will have the peculiarity of being interoperable, reusable, extensible and scalable [56, 57] , in order to ensure the highest flexibility.\nThe defined services are divided into three main groups (Figure 4): n User-facing services n Generic distributed medical services n Grid-facing services"}, {"section_title": "NeuGRID user-facing services", "text": "The user-facing services include those services that are accessed by the user for day-to-day activities. One example of a user-facing service, in this case specific to the neuroscience community, is the LORIS service. LORIS, developed for the NIH MRI Study of Normal Brain Development [27] , is the clinical database on which neuGRID will be based. LORIS is a centralized system designed for the collection, management and processing of brain imaging data. It has been developed using a range of open source software such as Apache, PHP and MySQL and is characterized by an efficient database schema for storing brain images and their associated metadata. In neuGRID, LORIS database will be extended to a Grid model and it will be made suitable for distributed data storage and high performance computational analysis. The resulting LORIS system will be able to collect, store, analyze and disseminate 3D DICOM image and related data across an arbitrarily large Grid network of participating sites using the same database schema. This objective will be achieved through a specific implementation and technical integration of the Grid and LORIS systems. Extensive validation studies will be conducted. In fact, LORIS must function in a manner transparent to the end user, producing results identical to the centralized system but without its potential limitations upon computational speed or storage capacity. More concretely, the LORIS service will be responsible for the data acquisition, capturing, annotating, visualizing, tracking the acquired datasets and sharing them with other users and services. It will also carry out quality control and validation on the acquired images (QC traceability service) and will apply the necessary format changes to make them useful for the neuroimaging community. Finally, the LORIS database will harmonize the main neuroimaging datasets (e.g., US-ADNI, AddNeuroMed and pilot E-ADNI) that will be collected within neuGRID. At this early stage, the harmonization of the ADNI and Generic to all domains (can theoretically be fully reused)"}, {"section_title": "Grid infrastructures for computational neuroscience: the neuGRID example Special Report", "text": "AddNeuroMed protocols has already been completed. The harmonization was conducted by generating a specific neuGRID LORIS database schema. For this purpose a unified data dictionary was created. The data dictionary describes variables and data available for research that can be conducted through neuGRID. Specifically, it unifies the descriptions of the data acquired using the ADNI and AddNeuroMed protocols and results in an ontological mapping between the two projects."}, {"section_title": "NeuGRID generic distributed medical services", "text": "By abstracting Grid middleware specific considerations and customizations from clinical research applications, the neuGRID generic services provide functionality aimed at medical applications. These services will bring together sources of data and computing elements into a single view, making it possible to cope with centralized, distributed or hybrid data and to provide native support for common medical file formats. Lower-level services will hide the peculiarities of any specific Grid technology from the upper-service layers, thereby providing application independence and enabling the selection of 'fit-for-purpose' infrastructures. The generic services will glue a wide range of user applications to the available Grid platforms, creating a foundation of cross-community and cross-platform services. The generic medical services are not tied to a particular application or Grid middleware, they could be used in any application domain and can be deployed potentially on any Grid infrastructure. These services are designed in such a way that a variety of applications and Grid middlewares could be supported. This level of abstraction will be reached through the use of a so-called gluing service that adopts the Simple API for Grid Application (SAGA) standardized protocol [107] for a chieving middleware i ndependence and platform interoperability. The first group is the user-facing services. A user who belongs to the neuroimaging community could immediately exploit these well-known tools. The second group of services (generic services) can be used by any application and can be encapsulated in any Grid middleware. The third group of services always sits on the Grid middleware and will provide the necessary infrastructure to execute the workflows. These Grid-facing services are middleware specific and depend on the particular middleware being used to provide the distributed Grid infrastructure. NeuGRID is a highly generalized architecture, in fact gradually moving from the bottom to the upper part of the diagram, the Grid architecture shifts from a generic and flexible interface, reusable in many other projects, to a more highly specialized and specific user-facing interface regarding exclusively the field of neuroimaging analysis. IT: Information technology; LORIS: Online Research Imaging System; QC: Quality control.\nfuture science group Special Report Redolfi, McClatchey, Anjum et al.\nThe first of the generic services is the portal service [108] . This service has been designed to provide a single point of access in the neuGRID system. It will hide the complexity of the underlying lowlevel architecture. It will allow users to easily identify themselves, access the services, browse data, launch analyses, submit jobs and visualize results. The user can access most other supplied services through the portal service. The neuGRID portal architecture has a web Single Sign On (SSO). This is a mechanism that allows a user to share its authentication between all the different services. One of the most mature and widely used SSO technologies is the Central Authentication Server (CAS) [58] . CAS is an authentication system created by Yale University (CT, USA) to provide a trusted way for an application to authenticate a user. From the user's perspective, only one account is used to access all the neuGRID applications and one single login is required in order to access all the websites. The portal service has two components, one component provides the front-end interfaces and the second component links the back-end services (the other generic services) to the front-end. Before trying to access the back-end services through the portal, the user has to authenticate himself or herself through the n euGRID security interface.\nThe neuGRID platform is intended to handle a large quantity of sensitive data coming from heterogeneous sources. It is extremely important to ensure that medical information is not made available without appropriate ethical clearance. Such legal and ethical requirements mean that an efficient and common level of anonymization (anonymization service) must be used throughout the project. Anonymization should therefore be considered at two levels:\nn Pseudonymization: this is a procedure whereby the most personal-related data within a data record are replaced by artificial identifiers (e.g., hash values) that map one-to-one to a patient. The artificial pseudonym always allows tracking back of data to its origins (but only by the original treating physician)\nn Face scrambling: this is the process whereby a specific algorithm is applied so that the face is removed from an MRI, thus preventing the possibility of a subject being recognized. Face scrambling will be executed if subjects are acquired with high 3D MRI resolution.\nTo become a successful research infrastructure, it is clear that such issues will need to be addressed carefully. A Java applet and scrambling software will be implemented in neuGRID in order to perform the aforementioned tasks in accordance with the European Parliament Directive [109] and the Member States' regulations.\nThe workf low and pipeline specification service, commonly known as the pipeline service, constitutes one of the key elements in providing generic services for research analysis. Neuroimaging pipelines allow neuro scientists and clinicians to apply series of automated transformations and processes on brain images for decision support purposes using complex and nested workflows. These processes are very computer intensive and deal with large amounts of data. Grid-enabled neuroimaging pipeline services are either proprietary or under research and neuroscientists have to currently rely on command line scripts to design and execute their pipelines. This service will enable scientists to create and design workf lows in a user-friendly fashion, calling and combining automatically different algorithms (e.g., FMRIB Software Library, BrainSuite, FreeSurfer, MNI tools, Automated Image Registration, Analysis of Functional NeuroImages and many other programs) in a single environment. Once the inputs retrieved by LORIS and parameters specified by users have been declared, a main source of analysis can be drawn via this service. This service will enable researchers to plan and Grid-enable their pipelines for enactment over a Grid. The pipeline service is being designed to allow multiple workflow authoring tools to define standardized workflow specifications including the LONI pipeline workflow management system and other scientific workflow applications [59] (such as Kepler [60] ). In order to achieve a high level of abstraction and interoperability, a language-independent application programming interface (API) will be defined, representing the way by which the different workflow authoring tools will request the service. The authored workflows generated will be transformed into a common format that could be enacted in multiple execution environments. Furthermore, users will be able to download specific workflows to their workspace and edit them by modifying algorithms, changing input data sources and other settings. From within the portal service, the user has the opportunity to submit the workflow for enactment and visualize the results. NeuGRID final users will browse for available workf lows through the querying service. Finally, to execute the user-authored future science group Grid infrastructures for computational neuroscience: the neuGRID example Special Report pipeline in a Grid environment and to fully exploit the Grid capabilities, the pipeline will be optimally planned and transformed into a Grid-executable state. This transformation is often referred to as 'planning' or 'Grid-aware distribution'. In a Grid, multiple sites may deploy subsets of tasks while some other tasks may require specialized hardware requirements and may need to be staged to other sites. Some sites may be preferred for selection owing to input or output data location considerations, while others may be preferred due to availability of suitable computing resources. Hence, a number of decisions need to be considered before a workflow is enacted. All these tasks are addressed by the pipeline service.\nThe querying service is a general purpose browsing service that can query and browse data that are stored in a file or relational database. The querying service will provide an easy to use high level querying capability for the LORIS data store, provenance data and other Grid databases. The neuGRID querying service has been designed to provide a mechanism that facilitates users in obtaining meaningful results quickly and efficiently. The service has been implemented to query disparate data resources located in the three DACS distributed LORIS databases. The querying service will also be a point of contact to query the provenance as well as other databases in Grid. In order to access and query data through the querying service, the user in neuGRID has to invoke the neu-GRID access system, which may consist of either simple user/password declaration or via a public key infrastructure system. Users can also view results from previous job executions, can access the output data from the LORIS and provenance databases and can download this data into their workspaces.\nThe provenance service is a generic service that will capture, store and provide access to analysis data for improved decision making. The provenance service will also enable users to reconstruct their workflows and validate the final results as well as intermediate results.\nProvenance is the process of tracking the origins of data, their history, their reconstruction and validation, as and when required by the users. The provenance service will help the users by facilitating access to past executions or histories of their analyses before a new study set is initiated. The process of neuroimaging analysis will involve a number of steps; an execution failure at any stage may lead to undesired execution results. These may be caused by incorrect pipeline specifications, inappropriate links between pipeline components, execution failures owing to the dynamic nature of the Grid and other causes. The provenance service provides the means for capturing and maintaining workflow specifications and execution information in a provenance database. Users will be able to query in a transparent way, any provenance information including the specific software routines and operating systems that were used. Consequently, the provenance service allows to the neuroimaging community proper data interpretation, high fidelity r eplication and reuse.\nBefore any workflow is passed over to neu-GRID gLite environment, it is handed over the gluing service, which has an important role to play in the architecture before execution. The gluing service is a standard way of accessing Grid services without tying generic services and applications to a particular Grid middleware. This is a solution that extends and enhances the reusability of already deployed services across domains and applications. The gluing service hides the encapsulation of Grid-middleware complexities from the neuGRID services. Using the gluing service, the w orkflows, queries and other jobs can be submitted to any Grid environment that could be built upon gLite, Globus [110] , Unicore [111] or indeed any other kind of distributed middleware. In effect, the gluing service is the gateway that shields the services from being locked in to a particular Grid and makes them truly generic and reusable. The neuGRID gluing service aims to provide a mechanism to access any deployed Grid middleware in an easy-to-use manner and a simplified approach for enabling clients to 'gridify' their applications without installing and maintaining Grid-specific libraries."}, {"section_title": "NeuGRID services", "text": "Usually, once the gluing service passes over the workflow to a Grid middleware, it is managed and scheduled on the distributed resources for enactment. The common Grid services are an enactment service, computing service, storage service and some other Grid services that make it possible to exploit the computing power of Grid. Therefore, when a workflow has been specified, associated data elements have been identified and it has been transformed into an executable format and the workflow is ready for enactment. This enactment process has to be managed via the related enactment service, which deals with the execution of the future science group Special Report Redolfi, McClatchey, Anjum et al.\nuser-defined workflows on the Grid resources. The workflow enactment service takes a workflow specification as an input, queries the data that are required to run the workflow, mimics the Grid workf lows according to some performance or efficiency considerations and dispatches the workflows for enactment on the Grid environment. Finally, when a job or workflow is being enacted in a Grid-execution environment, its progress and corresponding input and output operations are being monitored and logged into the provenance database. Ultimately, the results of the workflow execution are stored both in the LORIS and in the provenance data stores and from there, they are handled through the output visualization of the user-facing service.\nThe neuGRID service architecture here depicted encompasses different levels connected to each other. The neuGRID architecture emphasizes the possible separation of the client application domain from the underlying Grid infrastructure. In this way, the neuGRID platform can be considered free-distribution aware and Grid agnostic (Figure 7 )."}, {"section_title": "NeuGRID performance tests overview", "text": "One of the highest expectations of this project is the gain in performance, scalability and flexibility from executing the powerful cortical thickness algorithm within the neuGRID computing infrastructure. Indeed, the Grid will not only provide a secure, distributed and efficient environ ment for running such complex computing and data intensive analysis, but it will also enable its execution on a larger dataset shared across the several DACS centers in Europe. As soon as the neuGRID deployment phase is finished, performance and feasibility tests will be extensively carried out with the aim to control the integration of the different system components, supporting the deployment of the platform over the physical infrastructure and c onducting extensive performance and v alidation tests throughout the different levels and sites infrastructure.\nThe neuGRID performance will be evaluated in simulations mimicking existing real-world hardware and networking infrastructures so that it will address potential pitfalls and bottlenecks such as bandwidth limitations between nodes, heterogeneous compute resources, different scenarios for data archiving, access and replication. Simulations of various job executions, scheduling scenarios, analysis of the system capacity to optimally handle the job frequency and various queuing and caching approaches will also be studied and evaluated. Moreover, to test the relevance of the selected models, neuGRID has planned data challenges as well as functional tests. Data challenges will make use of all the available ADNI volumetric images (more than 7500 T1-3D MP-RAGE scans) and the accessible neuGRID processing power, in order to conduct the largest and most complex possible analysis. These tests should drive the ongoing developments and will validate neuGRID's computing model and its gridified software (CIVET). It should also highlight neuGRID infrastructure's limitations, and give indications for the infrastructure's exploitation and sustainability. Subsequently, functional tests will illustrate how 'usable' the system is. In other words, data challenges will provide accurate measurements of the platform, infrastructure performance and possible limitations; while the functional tests series will validate the neuGRID services from the user standpoint.\nIt is clear by now that the execution and p erformance of complex and intensive p ipelines like the CIVET will be significantly improved according to the added value of the Grid t echnology: 'huge computing power resources serving severely time constrained simulations'."}, {"section_title": "NeuGRID limitations", "text": "Considering the interdisciplinary nature of the neuGRID project, in which the IT and n euroscientific fields are closely in touch, s everal risk factors could hinder the d evelopment of the Grid infrastructure. Therefore, the most p robable pitfalls consist of:\nn Poor network infrastructure. Initially, the I talian DACS connectivity was not suitable for exchanging large amounts of data (e.g., r eplication of MRI scans with an individual scan size of 400 MB) among the different nodes of the Grid. The problems faced were requesting an upgrade of the connection to the Italian Academic and Research Network (GARR) [112] and obtaining a bandwidth comparable with those used by the other n euGRID DACS centers.\nn Difficulties with making the algorithms Grid compliant. This is only a potential risk with low probability. However, once the t echnology evaluations have been performed, the potential problems would be identified and corrected.\nn CPU and storage resource usage exceeding neuGRID capacity. NeuGRID will be fully functional but it will have limited CPU and Grid infrastructures for computational neuroscience: the neuGRID example Special Report storage resources. Although this limit will not be saturated shortly it will be necessary to p rovide additional resources.\nn Results variation in the image processing a lgorithms as a function of different hardware, and possible discrepancy when these algorithms are running on or off the Grid. This is a very likely and well-known problem.\nThe variability due to differences in numerical precision has to be expected since different machines are present in neuGRID. In this case, the source of the problem should be identified, its impact assessed and, if possible, the problem addressed.\nn New user's difficulties: the neuGRID environment will require new skills for researchers. Scientists will need to learn how to work in new environments, conceiving and leveraging powerful new instruments. Even though n euGRID will develop user-friendly interfaces, scientists will, at least for the foreseeable future, operate on the cutting edge of what is possible. To address this problem, training activities will aim to provide neuroscientists and algorithm developers the necessary skills to access and run the infrastructure.\nn Grid infrastructure maintenance; strategic and financial sustainability will be addressed starting from the beginning of the third year of funding when the needs of the big p harmaceutical companies regarding imaging markers for neurodegenerative disorders or for precompetitive research and multicenter c linical trials will be surveyed. It is expected that industrial interests and support will c ontribute to long-term sustainability of this infrastructure. In the meantime, neuGRID will also look into other running projects and initiatives to identify potential strategic a lliances for enlarging its network and d eveloping strengths. Some efforts should be made with Montreal Neurological Institute, Laboratory of NeuroImaging (LONI), W orldwide ADNI initiatives (US-ADNI, Australian ADNI and Japanese ADNI), E uropean Alzheimer D isease Consortium (EADC), Dementia Research Group and many others.\nHowever, neuGRID applies a risk management method in order to identify and monitor risks that could have a large impact on the project and mitigation plans have been set up to reduce the risk probability and their impacts."}, {"section_title": "Grid applications in neuroscientific research", "text": "Grid infrastructures should enable a new research environment for the scientific community and future generations of researchers. It is critical for a service aimed to address global research needs, that the data included will be consistent with international standards [104] , allowing pooled analyses or comparative studies. Furthermore, thanks to the federation of the ADNI, AddNeuroMed and all the other datasets, it will be possible to constitute an unprecedented environment for the validation of imaging and biological markers for AD and other neurodegenerative disorders.\nA Grid application in clinical neuro science is represented in Figure 8 . A typical case is when a neuroscientist believes that a series of newly found biological markers assayed in blood could be more intimately related to the primary cause of Alzheimer's disease than any other known marker, such as tau, amyloid-b (Ab), or others. As a consequence, the new markers might be more effective for an early diagnosis of Alzheimer's disease and could be more accurate to track the efficacy of new drugs too. From the AddNeuroMed and US-ADNI consortia, the neuroscientist receives blood samples of many patients with early AD and some samples of healthy older persons, together with the usual recognized markers of neurodegeneration (neuropsychological tests, high resolution structural MR, fluorodeoxyglucose-PET, and cerebrospinal fluid tau and Ab). Through discriminant analysis, the neuroscientist finds that some of the new markers might be more accurate to separate diseased from nondiseased patients. At this point, the neuroscientist might contact one neuroimaging Grid platform to validate the power of the newly discovered markers throughout imaging indicators of disease progression and ad hoc time-consuming algorithms. Complex correlative analysis would then be carried out on the structural MRI scans of cortical thickness with the new biological markers found. A potential critical issue could be represented by the data consistency within neuGRID platform. The approximately 2500 high definition structural MRI scans of the AddNeuroMed project, as previously argued, will be consistent with the approximately 5000 images of the North American ADNI, allowing full interoperability of the two datasets and the consequent joint analysis. In this manner, all the data acquired and stored within neuGRID will be consistent with international standards, allowing pooled analyses or comparative studies. This will constitute an unprecedented environment for the validation of imaging and biological markers for Alzheimer's and other neurodegenerative disorders. In doing so, using the Grid capabilities in a few hours the neuroscientist could demonstrate that a new specific marker is more strictly related to cortical thickness than any other c lassical r ecognized marker.\nMore generally, neuGRID will meet the needs of the academic neuroscientists' community, deploying repositories with consistent clinical/imaging data and advanced computing facilities to be used in research and care applications. In addition, neu-GRID is particularly suitable to meet the needs of the scientific community for the expansion of research in the whole area of progressive brain diseases, focusing especially on those of old age. In fact, the availability of gridified algorithms widely accessible to the neuroscientific community will spur research lines aimed at elucidating the mechanism of action of a number of environmental and genetic factors putatively involved in accelerated brain aging, AD and other neurodegenerative diseases. This new research environment, capitalizing on new computing and communication technologies, will promote greater breadth and depth to new international collaborations amongst researchers. NeuGRID will also meet the needs of the pharmaceutical and biotechnology companies regarding the study and the characterization of new imaging markers for neurodegenerative disorders also improving the way in which they can gauge the efficacy of drug tests.\nAnother possible application of the Grid infrastructures is illustrated in Figure 9 . Biomedical algorithm developers could have a powerful test-bed as well as the opportunity to access a large community of neuroscientists that might exploit their products. Developers of new algorithms for brain analysis, able to extract information on brain features to be used as disease markers, could have a larger dataset to test the performance of their algorithm than the traditional ones currently available. Moreover, successful algorithms will be able to be used and exploited by clinical neuroscientists immediately, once algorithms have been tested and optimized. The assessment of reproducibility and the validation of accuracy of the results obtained with a new algorithm are of importance to developers, as well as researchers or clinical end users. Using the Grid platforms, the programmer is able to validate the algorithm against established standards, as well as test the sensitivity and inner behavior of the algorithm against normally occurring variations in input data using an imaging database of unprecedented size. Using the computational power of a Grid, the developer would rapidly, and in a highly structured fashion, carry out a series of experiments, which up until the appearance of Grid infrastructures, would not have been feasible. By optimizing the parameter values of the algorithm across the database accessible in the Grid environment, the developer could prove Grid infrastructures for computational neuroscience: the neuGRID example Special Report that the algorithm outperforms any pre-existing method and establish its utility as a tool in the study of neurodegenerative disease.\nBy exploiting Grid technology and focusing on the processing of information, neuGRID will also contribute to the building of a bridge between Grid IT technology and medical applications. This will effectively facilitate the transfer of the Grid power from computer science laboratories into the research world of medicine. The benefits that will follow include large increases in the peak capacity and the total computing power, as well as new ways for research and clinical communities to share and analyze very large data sets. NeuGRID should be considered as a concrete example of a novel shared use of computing and data resources across diverse technological applications and national domains. Even if the matter is still far from being completely solved, the current IT development is maturing quickly enough to support the emergence of this deployed e-infrastructure and, in the long term, its d issemination in the research community."}, {"section_title": "Conclusion & future perspective", "text": "The penetration of IT in medical sciences will undoubtedly continue to address clinical demands and to provide increasingly functionality [61] [62] [63] [64] [65] [66] . It is expected that the exploitation of Grids could thoroughly change the way in which neuroscience is carried out today. Scientists will no longer need to migrate to advanced image analysis centers as computational facilities will be readily accessible via a standard internet connection and large databases will not pose issues of space saturation, owing to the Grid connectivity. Grid-based infrastructures, such as neuGRID, will bring the image analysis center to the neuroscientist, as opposed to the other way round. Neuroscientists will find a virtual space where the world's largest brain MRI databases of individuals with memory disturbances and Alzheimer's disease will be stored together with pertinent clinical variables integrated with biological data. Neuroscientists will be able to take advantage of all the primary neuroimaging tools inside the platform and by exploiting a user-friendly graphical interface they will create and launch analytical workflows to test s cientific hypotheses.\nNeuGRID could become one of the most usable and accessible Grid infrastructure for computational neuroscience, providing a well managed, easy-to-use set of tools with which scientists can perform analyses with a considerable saving of time. If neuGRID lives up to its promise, these tools will provide seamless access to Grid resources, offering end users unprecedented power at their fingertips with the simplicity of a web service interface. Furthermore, Grid platforms can reduce the latency of obtaining results, increase researchers' productivity and speed up the discovery of new knowledge. Once neuGRID has been concluded, a Grid-based platform providing a consistent portfolio of services to different end-user communities such as clinical neuroscientists, brain image algorithm developers and, prospectively, pharmaceutical industries and non-neuroscience biomedical communities can be exploited.\nFuture perspectives relate to worldwide interoperability of the available e-infrastructures for neuroscientific analyses and initially involve the LONI's SUNs Grid Engine and MNI's CBR AIN. LONI's cranium Grid engine is already operational in the USA, while CBRAIN is presently under development. The interoperability of neuGRID with LONI will be facilitated by the clinical variable database structure of neu-GRID being that of ADNI. There remain some challenges in integrating LONI with neuGRID but these are currently being addressed. The interoperability of neuGRID with CBRAIN is facilitated by three critical technological circumstances: the a doption of a SOA in neuGRID, which promotes interoperability, the use of common database software (LORIS) in both neu-GRID and CBRAIN and the physical network connecting Europe to Canada being an ultra broadband link (CAnet4 [113] ) with the capacity of running computationally complex and dataintensive studies. Together, these technological choices should simplify and facilitate the interoperation of neuGRID with CBRAIN. Future efforts should be directed towards l aying the foundation for a large research and d evelopment initiative aimed at achieving full interoperability among these infrastructures. Only by calling into action all the major p layers of this field will it be possible to achieve a c ritical mass to effectively advance the ultimate diagnosis and treatment of n eurodegenerative diseases. "}, {"section_title": "Executive summary", "text": "Overview n The availability of image databases of unprecedented size and the spread of sophisticated central processing unit-intensive algorithm pipelines for image analysis encourage the development of scientific e-infrastructures.\nn These will foster the development of innovative instruments for the early diagnosis of highly prevalent and deadly diseases such as Alzheimer's and lead to the identification of markers that will facilitate the development of causative drugs.\nn NeuGRID is an EC-funded effort arising from the needs of the Alzheimer's disease imaging community aiming to become one of the most usable and accessible Grid infrastructure for computational neuroscience. NeuGRID will allow the collection and archiving of large amounts of imaging data paired with Grid-based algorithms and adequately powered computational resources."}, {"section_title": "Conclusion", "text": "n Grid infrastructures, such as neuGRID, will make sophisticated analysis techniques and imaging data available to a larger number of neuroscientists, drastically reduce the processing time of neuroimaging computation and allowing the querying of larger and more representative databases."}, {"section_title": "Future perspective", "text": "n Interoperability between European and international infrastructures should be sought in the future through large coordinated efforts. n Both basic research and the pharmaceutical industry will benefit from neuGRID in order to study markers for Alzheimer's disease and other neurodegenerative diseases."}]