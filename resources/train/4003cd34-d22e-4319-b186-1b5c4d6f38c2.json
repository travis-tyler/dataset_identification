[{"section_title": "Abstract", "text": "A wide range of systems exhibit high dimensional incomplete data. Accurate estimation of the missing data is often desired, and is crucial for many downstream analyses. Many state-of-the-art recovery methods involve supervised learning using datasets containing full observations. In contrast, we focus on unsupervised estimation of missing image data, where no full observations are availablea common situation in practice. Unsupervised imputation methods for images often employ a simple linear subspace to capture correlations between data dimensions, omitting more complex relationships. In this work, we introduce a general probabilistic model that describes sparse high dimensional imaging data as being generated by a deep nonlinear embedding. We derive a learning algorithm using a variational approximation based on convolutional neural networks and discuss its relationship to linear imputation models, the variational auto encoder, and deep image priors. We introduce sparsity-aware network building blocks that explicitly model observed and missing data. We analyze proposed sparsity-aware network building blocks, evaluate our method on public domain imaging datasets, and conclude by showing that our method enables imputation in an important real-world problem involving medical images. The code is freely available as part of the neuron library at http://github.com/adalca/neuron."}, {"section_title": "Introduction", "text": "Highly incomplete data are found in a wide variety of domains. Sensor failure, occlusions, or sparsity by design all lead to missing data. For example, LIDAR scan data, providing depth measurements in a variety of problems, yield sparse point clouds [5, 28, 47] . Our work is motivated by a challenging real world medical imaging problem. In many clinical settings, medical image scanning time is limited by cost and physical or patient care constraints, leading to severely under-sampled images [8, 9, 43] . For example, in original linear interp.\nsampling mask linear imputation ours Figure 1 . Preview of unsupervised imputation for MNIST and (crop of) brain MRI slice. We leverage a collection of images with missing pixels but common structure to successfully impute missing data in the presence of extreme sparsity.\nmany clinical settings, only every sixth 2D slice is acquired in a 3D MRI scan, resulting in 83% of the anatomical data being missing. Estimating the missing data can yield meaningful clinical insight and help with downstream tasks such as registration and segmentation. State of the art methods for imputation, or estimation of missing values, often use statistics learned across the entire dataset. Supervised methods that fill in missing values rely on datasets of full observations to learn relationships between present and missing data [2, 12, 14, 22, 52, 53] . For example, super-resolution methods which can be viewed as imputation of higher-resolution pixel data require high resolution data to learn image statistics [12, 14, 22] . In addition, super-resolution methods operate on a regular grid which is not applicable in many missing data settings. Image inpainting methods exploit statistical structure learned from images to impute a missing region, but often require densely observed regions of the existing images to learn image statistics [2, 52, 53] . Other subspace methods require fully observed data to learn a low-dimensional data representation, and then use these representations to impute missing information in sparsely observed data.\nHowever, in many problems, fully observed data is unavailable or difficult to acquire. In this work, we focus on the recovery of missing image data in an unsupervised setting where no full observations are available, but some common structure exists across the dataset. Unsupervised statistical imputation methods, spanning the literature from dictionary learning, factor analysis, manifold learning, and Principal Component Analysis (PCA) and its variants, often use linear subspace models to capture covariation across a dataset [3, 32] . These models assume each observed data point is a noisy, sparse observation of a lower dimensional linear subspace. They have been succesfully applied in areas such as network traffic flows [25] or collaborative filtering [45] , where the high dimensional data can often be well represented by a linear embedding. However, in many settings such as imaging, linear models are insufficient in capturing data representations [27, 40, 41] .\nIn this work, we propose a probabilistic model that frames high dimensional imaging data with very sparse pixel observations as being generated from a non-linear subspace. Starting from this model, we derive a variational learning strategy that employs developments in deep neural networks and variational inference. We introduce building blocks of sparsity-aware deep architectures, and present a data inference method, based on this learning model, that enables both conditional mean imputation and multiple imputation of missing data. We discuss connections and important differences with linear imputation methods, which can be viewed as linear instantiations of our model, with the variational auto encoder, and with deep image priors. We evaluate this approach on unsupervised imputation in several public datasets comparing several model variants and linear alternatives. We analyze individual building blocks, and show that our method enables imputation of medical images in a real-world problem. Finally, we provide a comparative analysis with deep image priors."}, {"section_title": "Related Works", "text": "Collaborative filtering systems include only a sparse observation of users preferences [30, 45] . Here, methods aim to learn from user preference to produce future recommendations. Often, these models build user representations using matrix completion methods, which share a goal with data imputation using linear embeddings. Recent methods have exploited convolutional neural networks for joint user representations with external information regarding content [29] . Other methods use shallow auto-encoders with sparse data and propose specific regularized loss functions [44, 46] . Similar to linear subspace models, these methods can be characterized as instantiations of our model.\nVariational Bayes auto-encoders (VAEs) and similar models have been used to learn probabilistic generative models, often in the context of images [23, 24, 42] . Similarly, deep denoising auto-encoders use neural networks to obtain embeddings that are robust to noise [49] . Our method builds on these recent developments to approximate subspaces using neural networks. Importantly, we show that a principled treatment of a sparsity model leads to important and intuitive differences from the VAE.\nDeep Image Priors (DIP) use a generative neural network as a structural prior, and can be used to synthesize missing data [48] . For each image independently, the method finds network parameters that best explain the observed pixels. However, as parameters are image specific, this method is not amenable to extreme sparsity where image structure is hard to learn from the few observations of that image. Below, we discuss how our method is similar to DIP, how it differs, and perform a comparison in our experiments.\nSeveral methods define sparse neural networks in other contexts that are not directly related to our task, but still share nomenclature. For example, spatially-sparse CNNs assume a fully observed input, but the content itself is sparse, such as thin writing on a black background [16, 17] . Faster sparse convolutions are proposed by explicitly operating on the pixels that represent content, with the focus of efficient computation. Other methods propose sparsity of the parameter space in neural networks to improve various metrics of network efficiency [18, 33, 50] .\nDuring the development of this work, several contemporaneous works have been shown to tackle related problems. Partial convolutions [34] have been developed to tackle image inpainting, where parts of the desired images are fully observed. A recent method uses adversarial training to guide a generator network to impute missing data, and introduces a discriminator hint mechanism to enable training [54] . Within the medical image analysis domain, a recent method takes advantage of the similarity of local structure between different acquisition directions to enable subject-specific supervised training and imputation [55] . Outside of imaging-specific methods, recent papers have also shown similar development based on deep generative models in for imputing tabular and time series data [4, 39] ."}, {"section_title": "Methods", "text": "In this section we first present a general generative probabilistic model for sparse data observations using a non-linear subspace, and describe the imputation procedure using this model. We then show a learning algorithm that employs a variational approximation using neural networks, and introduce sparsity-aware neural network building blocks that explicitly model observed and missing data. Figure 2 illustrates an overview of the method."}, {"section_title": "Model", "text": "We let y denote an image written as a vector of size D which we model as a high dimensional manifestation of a low-dimensional representation x of length d \u2264 D:\nwhere N (\u00b5, \u03a3) denotes the multivariate normal distribution with mean \u00b5 and covariance \u03a3, I D denotes the D \u00d7 D identity matrix, and f \u03b8 (\u00b7) is a (potentially non-linear) function parametrized by \u03b8 that maps data from the low dimensional subspace to a full observation. The variance parameter \u03c3 2 captures independent pixel noise. We adopt a Gaussian prior for the low dimensional representation:\nWe let O indicate the set of observed entries in data y, and y O the corresponding vector of observed values. The set O varies for each datapoint and is assumed to be small (representing high sparsity). The likelihood of an entire observed dataset Y O = {y i,O i }, where y i,O i are observed data points, is therefore:"}, {"section_title": "Imputation", "text": "We aim to infer the full data point y given a sparse observation y O using the posterior p(y|y O ):\nwhere we used Jensen's inequality in ( * ) and model (1) in the last line. To impute data, we use maximum-a-posteriori (MAP) estimation, and approximate it via the lower bound\nStatistical imputation of the form (4) is referred to as conditional mean imputation, which can underestimate the variance of downstream tasks [32] . It is sometimes desirable to be able to sample the posterior itself thus producing multiple imputations that give an indication of the variance captured by the model. Our method enables this process by sampling from the posterior approximation x k \u223c p \u03b8 (x|y O ), followed b\u0177\nThis process projects a sparse data point y O to a plausible representation x k , and then estimates a possible data point\u0177."}, {"section_title": "Learning", "text": "Unfortunately, computing the expectation (4) or sampling from p \u03b8 (x|y O ) is intractable. Building on recent methods in variational inference such as the VAE, we employ an approximate variational posterior probability q \u03c8 (x|y O ) \u2248 p(x|y O ) parametrized by \u03c8, and minimize the KL divergence with the true posterior [20, 21, 23, 24] :\nwhich is the negative of the variational lower bound of the model evidence [24] . We model the approximate posterior as a multivariate normal:\nwhere \u03a3 x|y is diagonal. This approximation enables efficient sampling, facilitating imputation usin\u011d\nwhere"}, {"section_title": "Learning via sparsity aware neural networks", "text": "The functions (\u00b5 x|y O (\u00b7), \u03a3 x|y O (\u00b7)) take only the observed entries of y and compute the subspace statistics. We estimate these using a neural network enc \u03c8 (y O ), parameterized by \u03c8. We similarly approximate the generating function f \u03b8 (\u00b7) by a neural network dec \u03b8 (x), parameterized by \u03b8. We jointly learn the parameters {\u03c8, \u03b8} by optimizing the variational lower bound (6) using stochastic gradient methods. Specifically, for each data point y i,Oi with observed data O i , the resulting loss is:\nwhere x k are samples from q \u03c8 (x|y i,O ), and K is the number of samples we draw for each input image. The first term encourages the observed entries of y i to be well recovered by the decoder. The second term encourages the subspace posterior q \u03c8 (x|y O ) to be close to the prior p(x). Since this posterior depends on only unobserved entries, below we introduce several sparsity-aware building blocks for neural networks that handle sparse inputs ( Figure 3 .\nloss on observed voxels loss on latent space Fully Connected Fully Connected (or dense) layers enable learning of broad correlations across pixels of a datapoint, and are extensively used in both imaging and nonimaging data. In general, a fully connected layer can be written as r = F y + \u00b5 r , where r is the output (response), y is the input, F is the weight matrix and \u00b5 r is a bias term. When the input is partially observed as y O , a naive computation of the output might involve the columns of F that correspond to the observed entries,\nThis is equivalent to filling in the missing y values with zeros. This approach, however, does not account for or exploit possible dependencies between entries of y. We propose an alternative strategy based on linear models for imputation [31] , where we adopt a linear model y = W r + \u00b5 y . Given observed y O , the response r can be computed as:\nwhere W O are the rows of W that correspond to the observed indices. We propose to use this formulation as a sparsity-aware fully connected layer, where W and \u00b5 y are now the layer parameters. We discuss the linear formulation to imputation, which motivated this layer, in the Subsection Comparison with Linear Subspace Models. In our experiments, we demonstrate that this layer more accurately computes linear projections of sparse data and leads to improved training compared to a traditional fully connected layer.\nConvolution For imaging data, hierarchical convolutional operations extract meaningful representations. Existing methods often fill in missing values with a constant, such as zero or the mean value at that pixel across the dataset, but these do not usually accurately estimate the existing image signal [47] . Given a sparse input image, we experiment with two convolutional approaches. In the first, we apply a weighted convolution, where the convolution kernel c is modified to vary with image location k by the binary observed mask m [47] . The new filter response r at location k is\nwhere N (k) indicates all the pixels neighboring k within some filter kernel size. This weighted filter uses only the existing information in computing a response. We then compute the mask to be used at a subsequent layer m :\nSince convolutional layers can be applied hierarchically, even very sparse data will often lead to a dense deep feature response. This sort of convolution was recently used to impute LIDAR depth data in a supervised context [47] .\nSince we focus on image data, linear interpolation provides a rough approximation for missing pixels. Therefore, in a second strategy, we first approximate the missing data with linear interpolation, and provide the first convolution layer with both the observation mask and the interpolated image, as two input channels."}, {"section_title": "Networks", "text": "Different architecture families are appropriate for different problems and datatypes. We focus on architectural design decisions that pertain to utilizing missing data and account for the image content type, rather than describing specific details about particular architectures.\n\u2022 Hierarchical convolutional layers are used to extract image-space features. We experiment with (sparsityaware) fully convolutional encoder and decoders.\n\u2022 In many domains, capturing covariation across a large image can provide useful structural information. We therefore explore encoders that use a (sparsity aware) fully connected layer following several convolutions, and a decoder that uses a fully connected layer followed by convolutions.\n\u2022 For large data, such as volumetric medical scans, both convolutional and fully connected layers capture important relationships, but the volumes are too large to employ the designs above. In these cases, we propose an architecture that replaces the fully connected layer by locally connected sparse layers, which affect separate subregions of the volume."}, {"section_title": "Connection to Other Models", "text": ""}, {"section_title": "Linear Subspace Methods", "text": "We show that linear subspace methods are a specific case of our model. Let f (x) = W x + \u00b5, where weight matrix W controls the model covariance and \u00b5 is the data mean. This yields the sparse model\nwhere W O selects the rows of W that correspond to observed entries in y. Using the proposed learning strategy (9) and the pseudo-inverse of W , we can choose the approximating posterior,\nwhere\nGiven learned parameters, we impute missing pixels using the expectation (4)\nIntuitively, computing Eq \u03c8 (x|y O ) [x] linearly projects the data point onto the low-dimensional subspace using only the observed pixels. The recovered data point is then computed by linearly projecting the estimated low-dimensional representation into a high-dimensional space. The parameters {W , \u00b5, \u03c3 2 } can be learned using the expectation maximization algorithm [32] . Extended linear subspace models, such as ones that regularize the weights W or include mixtures of Gaussians, can similarly be seen as instantiations of our model. We used these concepts in proposing novel sparsity-aware fully connected (or dense) neural network layers above."}, {"section_title": "Variational Auto Encoder", "text": "Our model and resulting learning strategy relate to the variational auto-encoder and other recent methods using approximations based on neural networks [23, 24, 42] . A key difference is that our generative probabilistic model explicitly captures missing data. Our focus is on describing how this aspect changes generative models, providing a principled derivation of the learning strategy in the presence of missing data, and introducing missing data aware network layers. Specifically, in (9) the posterior q \u03c8 (x|y i,O ) depends on only the observed entries of y i , leading to our network building blocks. The reconstruction term I E x k \u223cq log p(y i,O |x k ) is evaluated at only the observed voxels, enabling parameter learning in unsupervised settings. In our experiments, we investigate how different parts of these methodological differences affect imputation."}, {"section_title": "Deep Image Priors and Amortized Inference", "text": "Deep Image Priors [48] use a generative neural network g \u03c6y (\u00b7) as a prior for image y, such that y = g \u03c6y (x). Parameters \u03c6 y are optimized separately for each image. In the context of sparse data, this method can be used to synthesize missing pixels by first obtaining \u03c6 y = arg min \u03c6y ||(g \u03c6y (x)) O \u2212 y O || 2 for some fixed x, and then computing the full image y = g \u03c6 (x). This strategy requires enough observed pixels in each image y O to be able to infer image structure and thus the missing data, and has been demonstrated in the case of large natural images with half of the pixels missing.\nIn contrast, we focus on severe sparsity in each image, and leverage commonality across a dataset rather than the observed pixels in a single image. Our method learns a similar decoder network f \u03b8 (x) to be able to decode all images in a dataset, rather than learning an image-specific generative network. In this sense, our decoding model can be seen as a collection-wide global version of the Deep Image Prior, where the embedding x, estimated by the encoder p \u03b8 (x|y O ) specifies the instance to be recovered.\nIn addition, our model can be seen as amortized inference over a collection of images with missing pixels. The general decoder learned by our model, together with an image-specific embedding x, act as Deep Image Prior for the entire collection of images with common structure. "}, {"section_title": "Implementation", "text": "We implement our method as part of the neuron package [10] , which is available at http://github.com/adalca/neuron, using Keras [6] with a Tensorflow [1] backend."}, {"section_title": "Experiments", "text": "We provide a series of experiments evaluating the presented method and its utility in the context of unsupervised sparse datasets.\nWe first analyze the proposed sparse fully connected layer to illustrate the improvement over traditional strategies in the sparse setting. We then evaluate several models on different image datasets to shed light on how various approaches perform in different settings. We focus on comparing image imputation using linear subspaces with several variants of our non-linear subspace model. Our goal is to demonstrate the potential of straightforward use of our method, rather than proposing an optimized architecture for a specific task. We then show the utility of our model on a clinical image imputation task. Finally, we analyze our algorithm compared to Deep Image Priors."}, {"section_title": "Data", "text": "We use three datasets in our experiments. First, the MNIST dataset consists of small (28x28 pixels) 2D images of hand-written digits [26] . We create three variants: MNIST-2 which only consists of the digit 2, MNIST-all which refers to the original dataset, and MNIST-rot which contains all of the digits rotated at a random angle between 0 and 360 degrees. Second, we use the FASHION-MNIST dataset, which consists of 28x28 pixel images of 10 types of clothing items [51] . These have more structure in each image compared to MNIST digits. Finally, we use a large-scale, multi-site dataset of 7829 T1-weighted brain MRI scans, compiled from eight publicly available datasets: ADNI [38] , OASIS [35] , ABIDE [11] , ADHD200 [37] , MCIC [15] , PPMI [36] , HABS [7] , and Harvard GSP [19] . Acquisition details, subject age ranges and health conditions are different for each dataset. We performed standard pre-processing steps on all scans, including resampling to 1mm isotropic voxels, and affine spatial normalization for each scan using FreeSurfer [13] . We crop the final images to 192 \u00d7 176 \u00d7 224.\nIn our experiments, we simulate the patterns of missing pixels, which we then remove from the images. We split each dataset into 50%, 30%, and 20% for train, validation, and test sets respectively, all of which are sparse. The test set in each dataset is only evaluated once. We highlight, however, that our focus is on evaluating the models on the unsupervised task of imputing missing pixels. Below, 90% sparsity means 90% of the data is missing."}, {"section_title": "Fully Connected Layer", "text": "We first analyze the importance of the proposed sparse fully-connected layer using the FASHION-MNIST dataset (the other datasets result in comparable results). We compare several strategies for using fully connected layers with missing data, before activation and omitting the bias term.\nWe compute the linear projection of fully-observed images onto a low-dimensional subspace of size 10 with weights initialized using PCA, and treat this as the ground truth projection. We then randomly sub-sample the data at several sparsity levels. We compute several baselines that use a conventional fully connected layer: filling the missing image pixels with 1) zeros, 2) the average value at each pixel location, or 3) linearly interpolated values. Finally, we test our sparsity-aware fully connected layer.\nWe compare the sparse image projections of each method with the ground truth response using mean squared error. We also consider a setting where spatial consistency is missing, often found in other domains, by randomly permuting image pixels and repeating the experiment. Figure 4 (a,b) shows that using the sparsity-aware fully connected layer leads to a significantly improved projection followed by spatial interpolation. The random permutation dramatically affects the spatial interpolation baseline, but does not affect the other methods since they treat dimensions independently. In a second experiment, we learn a linear auto-encoder that uses the linear encoding methods described above, and a fully connected decoding layer. Figure 4(c,d) reports the validation loss (on observed pixels only), and final validation reconstruction error (on all pixels). The results show that using sparsity-aware fully connected layers leads to improved reconstructions, promising to improve network performance in the context of sparse input data."}, {"section_title": "Random Sparsity in Image Datasets", "text": "In this section, we simulate random missing pixels for sparsity factors of 75% and 90% in images from MNIST-2, MNIST-all, MNIST-rot, and FASHION-MNIST. In addition, to evaluate more complex covariance structure in images, we obtain random 2D 64x64 patches from the brain MRI dataset."}, {"section_title": "Baselines", "text": "In this section, our first baseline is the linear subspace model of (13) which is often used in sparse settings [32] . We implement both stochastic gradient descent (SGD) based optimization, as well as Expectation Maximization [32] . For small datasets and models we find the two implementations to behave comparably, but the expectation maximization becomes intractable for large datasets and models. We therefore report results from the SGD implementation. In addition, we implement a (linear) sparse dictionary learning method using a L0-norm to encourage a sparse latent representation."}, {"section_title": "Model Variants", "text": "We evaluate several variants of our method using sparsityaware implementations, from simpler filling strategies to our full model:\n\u2022 conv-zero fills missing image pixels with zeros and uses a normal convolutional encoder and the sparse loss (9) \u2022 conv-mean fills missing image pixels with the pixel-wise dataset mean and uses a normal convolutional encoder and the sparse loss\n\u2022 conv-interp linearly interpolates the missing pixels of an input image and uses a normal convolutional encoder and the sparse loss\n\u2022 conv-interp-wmask adds the incomplete data sampling mask as a model input channel to conv-interp\n\u2022 conv-sparse uses a sparsity-aware, fully convolutional encoder and decoder architecture, each consisting of five residual blocks of two sparse convolutions with 3x3 kernels, ReLu activations and a 2x2 max-pooling or upsampling layer, and uses the sparse loss\n\u2022 conv-FC-sparse adds a sparsity-aware fully connected layer to the end of the encoder and the start of the decoder, enabling covariances across the entire image. We use an encoding of size 10 for MNIST and FASHION-MNIST, and 100 for the MRI patches."}, {"section_title": "Results", "text": "Figures 5 and 6 illustrate the results. For the single digit, all methods, including the linear subspace are able to exploit covariation across the dataset, despite significant sparsity. However, as more variability is present in the full and rotated datasets, the linear subspace methods are unable to capture the image structure and properly impute the images. In contrast, non-linear subspace models are able to capture complex covariances, even in extreme sparsity situations. Using a sparsity-driven VAE after filling the missing pixels using linear-interpolation or mean-filling performs better than the linear models, and having explicit sparsity-aware convolutional encoder performs the best among all variants. In general, several design decisions are possible for a given method, including varying encoding size, noise parameters and architecture designs. Here, our goal is to illustrate that in various datasets and sparsity levels, our method promises to dramatically improve imputation by employing a non-linear subspace."}, {"section_title": "Brain MRI Slices", "text": "We demonstrate the utility of our method on sparse brain MRI acquisition. In many clinical settings, scanning time is limited, leading to severely under-sampled medical scans. For example, in many clinical settings, only every sixth 2D slice is acquired in the 3D MRI scan. Moreover, because of the variability in subject head positioning in the scanner, the sparsity patterns appear to have different angles. In this experiment we evaluate our method by using high resolution MRI data which we downsample to simulate the sparse acquisition protocol. Specifically, we simulate a sparse scan for each subject by removing five out of every six slices at an arbitrarily rotated angle, then rotate the subject back to the common reference frame. We extract the middle coronal slice of each subject, perpendicular to the acquisition direction, and carry out 2D imputation for the middle coronal slice. We evaluate the methods described in the previous experiment. Because of the size of the images and dataset, we use a subspace encoding of 200 for the conv-FC model. Figure 5 (right) summarizes reconstruction results across the entire test set, and Figure 7 illustrates example imputation of MRI slices. The spatial linear interpolation image introduces several artifacts. The reconstructions using the linear subspace is unable to reconstruct detailed anatomy. In contrast, the proposed variants achieve significantly better reconstruction, demonstrating the promise of using the proposed methods on clinical MR images."}, {"section_title": "Evaluation with Deep Image Priors", "text": "We evaluate our model, focusing on the conv-sparse variant, compared to the deep image priors (DIP) [48] . We applied both methods to sparse data, as described in Section 3.5. For a direct comparison, we use the same decoder architecture, described in our model variants, for both the proposed model and DIP. We use the MNIST-2 and FASHION-MNIST-1 datasets in various high sparsity scenarios, as well as the sparse brain MRI scans used in the previous section. Figure 8 summarizes the results. As the sparsity level increases (fewer pixels observed), the Deep Image Prior strategy lacks sufficient data in a single image to synthesize a reasonable image. In contrast, our method is able to leverage the entire dataset of sparse images with common structure to learn covariation within pixels, enabling better imputation of missing pixels. Our method requires 18.6 \u00b1 13.7 ms (since we only need to evaluate the network) to reconstruct an MRI brain slice. Deep Image Priors require learning network parameters, which took 36.5 \u00b1 0.2 seconds for images in our dataset 1 ."}, {"section_title": "Conclusion", "text": "In this paper, we introduce a general probabilistic model to characterize sparse high dimensional imaging data by a deep non-linear subspace. We provide a principled derivation of the learning strategy in the presence of missing data, and introduce missing data aware network building blocks. We describe how missing data changes existing subspace models like the VAE, and how our model can be seen as a global version of deep image priors. Given a learned nonlinear model, we describe how imputation can be achieved.\nIn our experiments, we demonstrate the importance of a novel sparsity-aware fully connected layer. We then show that our model exploits intra-image structure, as well as structure across a dataset, to yield superior imputation to fully convolutional architectures. Finally, we show the utility of our method using a real-world problem involving medical images."}]