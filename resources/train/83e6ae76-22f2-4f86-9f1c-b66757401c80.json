[{"section_title": "Abstract", "text": "We propose a method for recruiting asymptomatic Amyloid positive individuals in clinical trials, using a two-step process. We first select during a pre-screening phase a subset of individuals which are more likely to be amyloid positive based on the automatic analysis of data acquired during routine clinical practice, before doing a confirmatory PET-scan to these selected individuals only. This method leads to an increased number of recruitments and to a reduced number of PETscans, resulting in a decrease in overall recruitment costs. We validate our method on three different cohorts, and consider five different classification algorithms for the pre-screening phase. We show that the best results are obtained using solely cognitive, genetic and socio-demographic features, as the slight increased performance when using MRI or longitudinal data is balanced by the cost increase they induce. We show that the proposed method generalizes well when tested on an independent cohort, and that the characteristics of the selected set of individuals are identical to the characteristics of a population selected in a standard way. The proposed approach shows how Machine Learning can be used effectively in practice to optimize recruitment costs in clinical trials."}, {"section_title": "Introduction 1.Background", "text": "Amyloid plaques, together with neurofibrillary tangles, are one of the earliest signs of Alzheimer's disease (AD), appearing before any cognitive impairment and change in brain structure. 1, 2 They are thought to play an important role in the disease, by triggering a cascade of events leading to neuronal loss and cognitive impairment. [3] [4] [5] This Amyloid cascade hypothesis has been very influential in therapeutic research, as it is hoped that stopping the formation of the plaques will stop the cascade and hence the progression of the disease. Several molecules have been designed to target these plaques, by preventing the formation of the beta-amyloid (Ab) peptides, by clearing them or by stopping them from aggregating to form Amyloid plaques. 6 Several of these drugs, such as solanezumab 7 and bapineuzumab, 8 have been tested on individuals with dementia or with mild cognitive impairments, but did not result in a decrease of the cognitive decline. The focus of clinical trials is therefore now shifting towards pre-clinical and prodromal individuals, as in the A4 study (trial identifier: NCT02008357) and the clinical trial for CNP520 (identifier: NCT03131453). The Amyloid cascade is thought to be a long, progressive process. Slowing down the formation of Amyloid plaques at the beginning of the process, when individuals are not yet cognitively impaired, should have effects on the long run, 8, 9 whereas on symptomatic individuals cognitive damage has already occurred and might not be reversed.\nSetting up clinical trials targeting asymptomatic individuals with amyloid plaques can, however, lead to important recruitment costs than can be prohibitive, as it is necessary to ensure that all enrolled individuals have amyloidosis. 10, 11 The presence of amyloid plaques on the brain can be measured using Positron emission tomography (PET), or by measuring the concentration of Ab protein in the cerebral spinal fluid (CSF). PET scans are very costly (around E1000 in Europe, and $5000 in the USA) and require the injection of a radioactive compound, and CSF measurements require a lumbar puncture, which is an invasive procedure that cannot be considered for systematic screening. When recruiting amyloid positive (Ab\u00fe) individuals in a cohort of individuals with dementia, doing a PET scan to every possible individual can be a reasonable solution, as 90% are expected to be Ab\u00fe. 12 However, in an elderly asymptomatic population, only one-third of the individuals are Ab\u00fe. 12 This implies that in order to recruit a given number of Ab\u00fe individuals, three times as many individuals should be tested for amyloid positivity. Therefore, doing a PET scan to every recruited individual does not seem to represent a feasible solution for the large-scale recruitment of asymptomatic amyloid positive individuals. 13 We propose a method for recruiting asymptomatic Ab\u00fe individuals for clinical trials, which is composed of two steps, as presented in Figure 1 . In a pre-screening phase, we first identify a subpopulation with a higher prevalence of Ab\u00fe individuals than in the original cohort, before doing a PET scan to this sub-population only in a second phase. In order to identify individuals with a higher risk of being Ab\u00fe, we propose to use a classifier that has been optimized to minimize the recruitment cost."}, {"section_title": "Related works", "text": "Several methods have been proposed to automatically predict the amyloid status of Cognitively Normal (CN) individuals based on cognitive and socio-demographic information. Mielke et al. 14 used a logistic regression with a default threshold value, and evaluated their method by training and testing the algorithm on the same individuals. Insel et al. 15 used a Random Forest and optimized the threshold by maximizing the Positive Predictive Value (PPV) of the algorithm. Maximizing this value implies having a very high threshold value, hence being very selective and increasing the number of false negatives. A very large number of individuals then have to be recruited as input, as many positive individuals are discarded.\nOther methods focus on MRI features, such as Tosun et al. 16 who predict amyloidosis in subjects with a Mild Cognitive Impairment (MCI) using an advanced anatomical shape variation measure. Apostolova et al. 17 also included MRI features by using hippocampus volume and cognitive, APOE and peripheral blood protein information on MCI subjects using an SVM. Ten Kate et al. 18 used an SVM and tree-based feature selection to predict amyloidosis in CN and MCI subjects using cognitive, socio-demographic, APOE and MRI features. In this paper, we propose to take a cost-effective approach of the amyloidosis prediction, by comparing different methods in terms of cost reduction.\nAnother approach for reducing clinical trial costs consists in adapting clinical trial design using previous results. Several studies propose to assess treatment efficacy in a retrospective manner, using drug trial cohorts to identify a subgroup of patients responding to treatment. [19] [20] [21] On the other hand, other studies propose to do so in a prospective manner, adapting the clinical trial as it is ongoing, by using more advanced methods such as active learning. 22, 23 "}, {"section_title": "Contributions", "text": "Selecting amyloid positive subjects for cohort recruitment requires finding a balance between being very selective, hence discarding a large number of positive individuals on one hand, or being too permissive and doing unnecessary PET scans on the other hand. We propose to take this trade-off into account by optimizing the algorithm for the recruitment cost, which includes both the cost of recruiting a number R of individuals and the cost of doing a confirmatory PET scan to a number S of selected individuals. As R depends on the number of False Negative and S on the number of False Positive, both of these measures are taken into account when the cost is minimized.\nIn this study, we extend and evaluate more in depth the approach we proposed in 2017. 24 We will compare the performance obtained using different features sets, containing cognitive and imaging features at baseline or over a longitudinal follow-up, and compare performance for a variety of classification algorithms. All the algorithms will be cross-validated to maximize the area under the receiver operating characteristic (ROC) curve (AUC), and the threshold will be chosen to minimize the cost. We will validate our method on three different data sets, corresponding to different disease stages (pre-clinical or prodromal) or recruiting procedures. The performance will be assessed using two different validation procedures: by using cross-validation on each cohort; and by training the algorithm on a first cohort and testing it on a different one. We will then verify that the cohorts created with our method are unbiased, and can be used as inputs for clinical trials."}, {"section_title": "Materials and methods 2.1 Cohorts", "text": "We are interested in studying the performance of our method on different groups of individuals. To do so, we test the method on three cohorts, noted ADNI-MCI, ADNI-CN and INSIGHT.\nThe ADNI-MCI cohort contains MCI subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) study. It is an ongoing, longitudinal, multicenter American study carried out in North America, which provides biomarkers, imaging, cognitive and genetic data, for the early detection of AD. It started in 2004 with ADNI1, and two more phases are now available: ADNIGO and ADNI2. A diagnosis is given at each visit, among CN (Cognitively Normal), MCI or AD. MCI subjects have a Subjective Memory Concern (SMC) and an objective memory loss measured by education adjusted scores on Wechsler Memory Scale Logical Memory II, but do not have any impairment in the other cognitive domains, especially in activities of daily living. We only consider visits that have an associated Ab level, measured with the AV45 PET SUVr (Standardized Uptake Value Ratio) when available, or with the CSF biomarker when no PET scan was performed. Individuals that changed Amyloid status during the study are removed. We use the first available visit for each individual and a visit at a 12-month interval when studying the impact of longitudinal data. A total of 596 individuals were available in this cohort, among which 62.9% were Ab\u00fe.\nThe ADNI-CN cohort contains CN subjects from the ADNI study. These individuals were cognitively normal, showed no sign of dementia or of cognitive impairment, but they can have a SMC. Individuals and visits are selected and Ab values are taken as in the ADNI-MCI cohorts. A total of 431 individuals were available, among which 37.6% were Ab\u00fe.\nThe INSIGHT cohort contains individuals from the INSIGHT-preAD study. It is an ongoing, longitudinal, mono-centric French study carried out in Paris, France, which aims at studying changes appearing in healthy individuals over 70 years of age, in order to study the very early phases of AD. A total of 318 CN individuals, with normal cognition and memory but who have a SMC, are followed. Cognitive, imaging and genetic data is available for every annual visit. The AV45 PET SUVr is available for every individual and used as the Ab value. At the time of the analysis, only the first visit is available for each individual. 27.7% of the 318 individuals are Ab\u00fe (n \u00bc 88)."}, {"section_title": "Input features", "text": "Different sets of features are compared. For all experiments, socio-demographic features (age, gender, education) and APOE4 are used.\nAs cognitive assessments are different in ADNI and the INSIGHT-preAD study, different cognitive features are used. For the two ADNI cohorts, the Alzheimer's Disease Assessment Scale-cognitive subscale (ADAS-cog) is used. The 13 items are aggregated into four categories: memory, language, concentration and praxis. For the INSIGHT cohort, 112 available features, coming from SMC questionnaires and cognitive tests, are used. They target executive functions, behavior and overall cognitive skills.\nMRI extracted features are also used in order to evaluate their predictive power. The cortical thicknesses are extracted using FreeSurfer for both ADNI and INSIGHT subjects. The average thicknesses of 72 cortical regions are used, and divided by the total cortical thickness in order to get comparable measures across individuals. The hippocampus volume is extracted using FreeSurfer for the ADNI cohorts, and using SACHA, 25 an in-house hippocampus segmentation software, for the INSIGHT-preAD study.\nThe amyloidosis is measured using a PET scan when available and CSF measurements were used otherwise. The PET SUVr given by the ADNI and INSIGHT-preAD studies are extracted using different methods. An individual is considered Ab\u00fe when PET SUVr is above 1.1 26 for ADNI and 0.79 for the INSIGHT-preAD study, or when the concentration of Ab in the CSF is below 192 pg ml. 27 "}, {"section_title": "Algorithms", "text": "Different classification algorithms are used to make the prediction and their performances are compared for the different cohorts, in order to identify an algorithm that would outperform the others. The hyperparameters of all the algorithms are tuned using a cross-validation.\nFive algorithms are compared: (1) a Random Forest, 28 with validation of the number and the depth of the trees, (2) a logistic regression, 29 with validation of the threshold, (3) a linear Support Vector Machine 30 (SVM), with validation of the penalty parameter, (4) an adaptive logistic regression 31 (AdaLogReg), with validation of the learning rate and the number and depth of the learners, and (5) an adaptive boosting 32 (AdaBoost), with validation of the same hyperparameters as for AdaLogReg.\nThe performance of the algorithms is evaluated using repeated random sub-sampling validation: the data were repeatedly (50 times) separated into a training set (drawn without replacement) and a test set (corresponding to the data points not used in the training set). We use 70% of the data for training and 30% for testing. For each split, the algorithms are first tuned using a 5-fold validation on the training set to maximize the AUC, then trained on the whole training set with the selected hyperparameters, and applied on the test set in order to get a performance measure. Fifty performance measures are therefore obtained, and are used to get a mean performance and a standard deviation. The whole procedure is described in pseudocode in the Supplementary Materials (Algorithm 1)."}, {"section_title": "Performance measures", "text": "Different performance measures are used in order to evaluate different aspects of the methods.\nThe area under the ROC curve (AUC) is used to evaluate the performance of the prediction method. It is used to compare different algorithms, to tune them, and to evaluate the predictive power of different feature sets.\nThe minimal cost of recruiting 100 individuals is used to measure the practical effect of the method, and to find a balance between the number of recruited individuals and the number of PET scans. In order to compute this minimal cost, the ROC curve is built by changing the algorithm threshold (Figure 2 , left). For each point on the ROC curve, the corresponding number of individuals to be recruited (R) and the number PET scans (S) are computed ( Figure 2 , middle) as follow\nwhere TP stands for number of True Positive, FP for number of False Positive, and N is the total number of predictions that have been made. As the true positive rate (TPR) and false positive rate (FPR) depend on the number of True Positive and False Positive which are used to compute S and R, there is a direct match between each point of the ROC curve and the R versus S curve. Consequently, as for the FPR and TPR, R and S should be minimized together and a trade-off has to be made, which is reflected in the total cost. For each value of S and R, the corresponding cost can be computed, by making the hypothesis that recruiting a individual and getting genetic information and cognitive assessments costs E100, doing an MRI E400 and doing a PET scan E1000. When the cost curve ( Figure 2 , right) is built, the minimum is taken to get the minimal cost of recruiting 100 individuals, and the corresponding optimal values of S and R are hence known.\nIt is to be noted that the cost of recruiting 100 individuals in a cohort will depend on the proportion of amyloid positive individuals in the cohort, as the more positive individuals there are, the easier it is. This performance measure is hence useful to evaluate and compare the performance of different methods on one cohort, but it cannot be used to compare the performance of a method across different cohorts."}, {"section_title": "Statistical testing", "text": "Each experiment is performed 50 times with 50 train/test split, and 50 performance measures are obtained. When we compare two experiments, a two-tailed t-test is performed using the 50 performance measures of each experiment. A p-value is obtained, enabling us to test if the performance of the two experiments is significantly different at the 0.05 level."}, {"section_title": "Results", "text": ""}, {"section_title": "Algorithm and feature choice", "text": ""}, {"section_title": "Algorithm choice", "text": "In order to choose the algorithm most suited for this problem, different classification algorithms are tested on the three data sets. Their performance, measured using the AUC, is reported in Table 1 . These results show that there is no algorithm that outperforms all the others for all cohorts. It is, however, necessary to make a choice and use the same algorithm on all cohorts. The Random Forest is, for all data sets, among the best performing algorithms. It outperforms each other algorithm in one cohort: the Logistic Regresion in INSIGHT (p \u00bc 0.001), the SVM in INSIGHT (p \u00bc 0.0001), the adaptive logisitic regression in ADNI-CN (p \u00bc 0.03) and AdaBoost in ADNI-MCI (p \u00bc 0.045). No algorithm significantly outperforms it on any cohort. The Random Forest therefore represents the best algorithm for this classification task."}, {"section_title": "Feature selection for cognitive variables", "text": "In the INSIGHT cohort 112 cognitive features are available. Using all of them results in an AUC of 56.2% (AE7.5), which is significantly lower than the performance obtained on the other cohorts because of a less favorable ratio between number of features and individuals, as only 318 individuals are available. We therefore compare different dimension reduction and feature selection methods in order to solve this issue and improve the performance on this cohort."}, {"section_title": "Automatic methods", "text": "Principal Component Analysis (PCA) and Independent Component Analysis (ICA) using fastICA 33 are first considered, but both lead to an AUC under 52%, whatever the number of selected dimensions. LASSO feature selection is also considered. In the LASSO, a regularized regression using a l 1 penalty is used, setting some of the feature weights to 0, hence keeping only the most relevant features. A linear regression using LASSO is performed between the input features and the amyloid status in order to select from 5 up to 60 features. The selected features are then used to perform the classification, using a Random Forest. The evolution of the AUC with the number of selected features is presented in Figure 3 , showing that the best results are obtained using 15 features. Using the LASSO features selection leads to an AUC of 64.3% (AE5.2), which is significantly better than the performance obtained using all features (p < 0.0001)."}, {"section_title": "Using expert knowledge", "text": "In a last analysis, manual feature engineering is considered. Aggregates are formed for each cognitive test, using expert knowledge regarding the tests and the features which are most relevant for AD diagnosis. Twenty-six aggregates are hence built. Using them as input in place of the 112 original cognitive features leads to an AUC of 67.5% (AE5.5), which is significantly better (p < 0.005) than the performance obtained using automatic dimension reduction."}, {"section_title": "Use of MRI", "text": "We want to assess the prediction power of MRI-extracted features (cortical thicknesses and hippocampus volume) and compare it with the performance obtained using cognitive features. In all experiments, APOE genotype and socio-demographic features are also used as inputs.\nWe first compared the performance obtained by using only cognitive features on one hand, and only MRI features on the other. As the number of MRI features is large regarding the number of subjects, a LASSO feature selection if performed to select 12 variables. The results are presented on lines 1 and 2 of Table 2 . Using MRI features instead of cognitive scores leads to a significant decrease in the AUC for all cohorts (p < 0.001). These results show that the used cognitive features are a better predictor of amyloidosis than the chosen set of MRI features. Although they are less predictive than cognitive scores, using the MRI features as input along with cognitive scores could lead to better performance. We therefore train the algorithm using both MRI and cognitive features and compare its performance with the ones obtained using solely cognitive scores. The results, presented in line 1 and 3 of Table 2 , show that including MRI features in the inputs does not lead to a significant increase in the AUC. For the INSIGHT and ADNI-MCI cohorts, it does lead to non-significant increase in the AUC, but the resulting cost for recruiting 100 individuals is higher (for INSIGHT, E527,437 AE 36,332, instead of E291,325 AE 57,400), as the cost of doing an MRI to each recruited individual has to be added to the initial cost. For ADNI-CN including MRI features in the input leads to a significant decrease in the AUC (p < 0.01). In all the cohorts, including MRI features leads to an increase in cost."}, {"section_title": "Use of longitudinal measurements", "text": "Longitudinal measurements are available for individuals in the two ADNI cohorts. In order to evaluate the impact of using longitudinal measurements in amyloidosis prediction, the rate of change of the cognitive scores, computed using a 12-month visit, are included in the input features. The results, presented in line 4 of Table 2 , show that the AUC is significantly better than the one obtained using only socio-demographic information, APOE and cognitive scores at baseline, ADNI-MCI (p < 0.0001), and not significantly better for ADNI-CN (p \u00bc 0.06). Using longitudinal information overall leads to a better prediction.\nHowever, the cost of collecting such measurements has to be taken into account, since all individuals have to undergo cognitive assessments twice. Setting the cost of cognitive assessments for the second visit to E50 for each individual, the total cost of recruiting 100 individuals using longitudinal information is of E243,448 (AE 104,597) for ADNI-CN and E133,452 (AE22,140) for ADNI-MCI. This new cost is slightly lower than the one obtained using cross-sectional measurements in ADNI-CN (234,591 AE 23,106) and higher for ADNI-MCI (136,205 AE 3678). Therefore, although using longitudinal measurements leads to an increase in AUC, it does not lead to a decrease in recruitment cost. Table 3 presents the cost of recruiting 100 Ab\u00fe individuals in the different cohorts with the proposed method, as well as an estimation of the costs of recruiting these individuals with the current method, consisting in scanning all potential individuals. This estimated current cost depends on the proportion of Ab\u00fe in the data set. In order to find 100 Ab\u00fe individuals in the INSIGHT cohort for example, 100=0:277 \u00bc 361 individuals on average should be recruited and undergo a PET scan, which corresponds to a total cost of 397,111E. However, with the proposed method, about 832 individuals should be recruited and 208 PET scans would have to be done, leading to a cost of 291,325E on average for recruiting 100 Ab\u00fe individuals. The resulting savings would reach 106,174E for this cohort."}, {"section_title": "Proposed method performance", "text": ""}, {"section_title": "Cost reduction", "text": "The results presented in Table 3 show that the proposed method leads to a significant cost reduction when recruiting 100 individuals for all cohorts (p < 0.001), representing estimated savings of about 20%."}, {"section_title": "Age difference between groups", "text": "In the cohorts we used, the Ab\u00fe individuals are older than the Ab\u00c0 individuals, especially in the ADNI cohorts (see Table S1 in Supplementary Materials). One can therefore ask if the predictor is using this age difference, by simply predicting that older individuals are Ab\u00fe and younger individuals are Ab\u00c0, or by predicting the age of the individuals rather than their amyloid status. To confirm that it is not the case, we correct all the cognitive variables for age by using a linear regression and remove the age from the input features. After correction (results shown in line 5 of Table 2 ), the prediction performance is not impacted in INSIGHT and does not decrease significantly for ADNI-CN (p > 0.05). In the ADNI-MCI cohort, correcting for age leads to a significant decrease in AUC (p < 0.01) but results in a recruitment cost that is still significantly higher than doing a PET scan for all individuals (p < 0.01).\nThese results show that the prediction algorithm does not rely on the age difference between the groups and captures differences between amyloid positive and negative individuals that is not due to aging."}, {"section_title": "Training on a cohort and testing on a different one", "text": "The previous results are obtained by training and testing the method on distinct individuals from the same cohort. We want to confirm that these results would generalize well in a different setting, by verifying that they hold when the method is trained on a first cohort and tested on a different one. ADNI and INSIGHT-preAD are very different studies. They have been designed for different purposes, as INSIGHT aims at studying very early phases of AD by studying changes appearing in healthy individuals, and ADNI aims at defining the progression of Alzheimer's disease. The INSIGHT and ADNI-CN cohorts both include individuals who show no sign of dementia but with different inclusion criteria, and hippocampal measures have been extracted using different softwares. Hence, although these two cohorts can be compared, they are very different by design and purpose. In an ideal setup, cognitive features, socio-demographic information and APOE should be used as input; however, the cognitive assessments are different for ADNI and the INSIGHT-preAD study, hence they can't be used as inputs when using these two cohorts.\nWe therefore train the prediction algorithm on ADNI-CN using socio-demographic information, APOE and MRI features. We then test on INSIGHT the method trained on ADNI-CN in order to evaluate the generalization performance of our method. As the number of MRI features is large, LASSO feature selection was performed to select 12 MRI features. In order to have a fair comparison with training and testing on INSIGHT, the size of the selected training and test size are kept the same as the training and test set coming from INSIGHT. We therefore randomly select 318 \u00c3 0:7 \u00bc 223 from the ADNI-CN cohort to form the training set, and 318 \u00c3 0:3 \u00bc 95 from INSIGHT to form the test set. This operation, followed by the classification, is performed 50 times in order to get a mean performance and a standard deviation.\nThe results, presented in Table 4 , show that training on ADNI-CN and testing on INSIGHT gives similar performances to training and testing on the INSIGHT cohort."}, {"section_title": "Representativity of the selected population", "text": "For the selected individuals to be used as a clinical trial cohort, it is important to ensure that the selected population will be representative of the whole population of Ab\u00fe individuals that could have been selected. We therefore compare the individuals selected using the prediction method followed by a confirmatory PET scan with the Ab\u00fe individuals of the cohort.\nWe first pool together the test data set of the 50 cross-validation runs and look at the distribution of age, ADAS (for ADNI cohorts), MMSE, education, age and gender. The histograms obtained for ADNI-CN are presented in Figure 4 . We can see that these histograms are very similar for age, gender, education, and cognitive features, but the proportion of APOE4 carriers is higher in the group selected with the proposed method. Similar observations can be made for all cohorts. In order to evaluate if there is a significant difference for each of these features, we compare the selected populations of the 50 runs with the populations of Ab\u00fe individuals of the corresponding test sets. A statistical test is performed for each of the 50 runs and a p-value is obtained for each of them. The used statistical test is a t-test for the features with a normal distribution (age and ADAS), a binomial proportion test for binary features (presence of APOE4 alleles and gender) and a Mann-Whitney U test for the remaining features (MMSE and education). A p-value is obtained for each run, for each feature. Figure 5 presents the proportion of these p-values that are below 0.05, for each feature.\nThe main bias that can be seen across cohorts is a higher proportion of APOE4 carriers, which is statistically significant in 16% of cases for INSIGHT, 48% for ADNI-CN and 98% for ADNI-MCI. Although this bias is important, especially for the ADNI cohorts, it seems acceptable as many current recruiting procedures also have this bias or only recruit APOE4 carriers, such as in the Alzheimer's Prevention Initiative Generation study. 34 The proposed method leads to an unbiased cohort in terms of age, gender, and education, as well as cognitive scores in more than 94% of cases for the asymptomatic cohorts, and 82% for ADNI-MCI."}, {"section_title": "Building larger cohorts", "text": ""}, {"section_title": "Pooling data sets", "text": "Different cohorts can be pooled in order to create a bigger data set, containing a large number of individuals. However, this operation requires that the heterogeneity of the pooled cohort does not alter the performances of the method that is applied. In order to verify this hypothesis, we pool the ADNI-CN cohort with the INSIGHT cohort. We train and test the method on individuals coming from both of this cohort, using the same training and test size as in INSIGHT, in order to compare the performances with the one obtained by training and testing solely on INSIGHT. As in the generalization experiment, we use MRI features instead of cognitive features which are different in the two cohorts. The results presented in Table 4 show that the performances are not significantly different when the algorithm is trained and tested on the pooled cohort, which shows that the heterogeneity of pooled data sets does not alter the classification performances."}, {"section_title": "Effect of sample size", "text": "When learning on ADNI-CN and testing on INSIGHT to test generalization, we used the same training and learning size as in INSIGHT to have a fair comparison, hence using only 52% of the available data at each run. For the same reason, we used only 42% of the created cohort when we pooled the INSIGHT and the ADNI-CN cohort. We now want to measure the impact of increasing the cohort size by using the full cohort in each case, always keeping the same ratio for the size of the training and test data sets (70-30%). The results presented in Table 4 show that increasing the cohort size significantly increases the performances (p < 0.0005). This result shows the need to create large data sets, or pool existing ones, in order to create more accurate prediction tools. The algorithm benchmark shows that there is not one outstanding algorithm that would outperform all the others on all data sets. These findings support the ''No free lunch'' theorem, 35, 36 stating that different algorithms perform best on different problems. As a choice had to be made, we used the Random Forest which performed well on the three cohorts. It is not, however, a general recommendation. When working on a new classification problem, even similar to this one, one should always compare different algorithms to choose the most suited one. Because the number of features is large compared to the number of available subjects, using all the available features may result in a low performance. 37 The low performance we obtained on the INSIGHT cohort using all the available cognitive features is an illustration of this phenomenon, known as the curse of dimensionality. A typical way of solving this issue is using automatic methods for dimension reduction. We showed that, in our case, selecting features using expert knowledge gives better results. It corroborates the fact that when a large number of features and a small data set are available, feature engineering using domain knowledge is necessary. 38 Hypothetical models of AD suggest that neurodegeneration and changes in structural MRI appear earlier than cognitive decline. 2 This hypothesis is supported by findings from Bateman et al., 39 showing that, in autosomal dominant AD, brain atrophy occurs 15 years before AD diagnosis, five years before episodic memory decline and 10 years before changes in other cognitive domains. Studies by Ameiva et al. show that changes in several domains of cognition can be observed nine years before diagnosis, 40 and up to 16 years before diagnosis for individuals with higher education. 41 Overall, brain atrophy may appear before or at about the same time as cognitive decline, and one could expect using MRI would improve the prediction of amyloidosis, especially for cognitively normal individuals. Our analysis, however, suggests that it is not the case. This finding that clinical signs can allow for efficient pre-screening goes against the current purely biological definition of AD by NIA-AA. 42 We can suppose that memory decline has already started for individuals with a SMC, so that cognitive features are already slightly altered. It leads us to think that subtle cognitive changes appear in late preclinical AD, as hypothesized by Sperling Figure 5 . Proportion of runs with a significant difference between the groups for each feature, in each of the three cohorts. et al. in their three-stage model of pre-clinical AD. 43 The results can, however, depend on the choice of MRI features. In future studies, different neuroimaging features could be used to test this hypothesis that cognitive changes are anterior to substantial structural changes, in line with previous studies on optimal neuroimaging feature selection in pre-clinical AD. 44 Alternatively, a more advanced feature selection algorithm might be able to identify the most informative MRI features and therefore improve their performance, as proposed in other methods. 18 In the ADNI-CN cohort, adding the MRI features even leads to a decrease in AUC, whereas it leads to a slight increase for INSIGHT. A possible explanation for this difference between cohorts is that in ADNI, the number of cognitive features (4) is low compared to the number of MRI features (73), whereas the difference is smaller for INSIGHT (26 cognitive features for the same number of MRI features). In ADNI the cognitive scores can therefore be under-represented compared to the MRI features. This effect should be handled by the Random Forest that can give different weights to different features. It, however, requires the number of individuals to be large enough compared to the number of features, which is not the case here.\nOverall, we showed that with our method the best results are obtained without performing an MRI and without longitudinal features, but using only data that can be easily acquired. MRI should not be performed in the prescreening phase; however, performing an MRI at the end of the recruitment process will always be needed to exclude vascular lesions or tumors and as a reference for adverse event monitoring."}, {"section_title": "Method performance", "text": "We showed that using the proposed method as a pre-screening phase for individual recruitment in clinical trials leads to reducing the recruitment cost by about 20%. These findings are, however, based on cost hypothesis that can seem arbitrary. In particular, the cost of recruiting a new subject is the same whatever the number of subjects that have been recruited. In practice, because a large number of studies intend to recruit large numbers of subjects, the more subjects are recruited, the more difficult it is to recruit a new one. Having a non-constant cost could therefore represent an improvement of the proposed method and be closer to the difficulties encountered in practice.\nWe can expect the method to generalize well and give similar results when applied on any cohort of cognitively normal individuals because we showed that we obtain similar performances when training and testing on the same cohort or on two different ones. The cohorts we used for testing are slightly unbalanced, with Ab\u00fe individuals older than Ab\u00c0 individuals, but correcting for age gives similar cost reductions, so the same results should be obtained on cohorts that do not have the same unbalance. Comparing the selected Ab\u00fe individuals with all the Ab\u00fe individuals of the cohort shows that the subset selected with the proposed method is unbiased. The proposed method therefore leads to the recruitment of a representative cohort with a reduced cost.\nThe proposed approach is time efficient, as in the worst case the training phase may take few minutes, while testing a new subject could be done in less than a second. Therefore, computational time is not a limiting factor for using such methods in practice. Furthermore, since only clinical data may be used for good performance, the method could be easily deployed in the current clinical practice. Table 4 shows that pooling data sets does not alter the performance of the prediction, although it brings heterogeneity and that increasing the cohort size improves the prediction. This last finding is supported by the current machine learning literature, stating that gathering more data often yields an increase in performance greater than the increase one could obtain by improving the prediction algorithm. 38 It shows the importance of gathering more data in the medical field and more specifically related to dementia. While the largest cohorts widely available usually include less than 1500 subjects, creating larger cohorts could result in a significant increase of performance for predicting amyloidosis or for other predictive task, such as automatic diagnosis based on neuroimages. 45, 46 As long as larger cohorts are not available, we recommend pooling different cohorts in order to get a better prediction performance. For example, the preclinical cohorts presented by Epelbaum et al. 47 could be pooled to create a bigger cohort to train and validate our method."}, {"section_title": "Data set size", "text": ""}, {"section_title": "Comparison with existing methods", "text": ""}, {"section_title": "Univariate approaches", "text": "A standard approach for prediction is using univariate methods. As a comparison with our method, a Random Forest is trained and tested on each input variable separately. The best univariate results are obtained using APOE ( Table 2 , line 4). The AUC obtained using APOE is significantly lower (p < 0.0001) than the AUC of the proposed multivariate method, for all cohorts, with an AUC of 63.7 AE 4.6 instead of 67.5 AE 5.5 for INSIGHT, for example. The proposed method therefore outperforms its univariate equivalent."}, {"section_title": "Other multivariate approaches", "text": "We wanted to compare the performance of our method with that of other similar studies. Different cohorts and different performance measures have been used in these studies, the comparison is therefore not straightforward and the results should be interpreted with caution.\nIn the study of Mielke et al., 14 the studied cohort is composed of CN individuals from the Mayo Clinic Study of Aging. This cohort is comparable with the ADNI-CN cohort used in this work, as individuals from both cohorts are CN, and the ratio of Ab\u00fe individuals is close (34.9% in the Mayo Clinic Study of Aging cohort, 37.6% in ADNI-CN). A logistic regression is used with an a priori set and non-optimized threshold, and the performance measures were obtained by training and testing the algorithm on the same individuals. The resulting AUC, of 0.71, is significantly better than the AUC we obtain on ADNI-CN (69.1, p < 0.05), which is expected as training, and testing an algorithm on the same individuals generally gives better results than testing it on a different set of individuals.\nThe cohort used by Insel et al. 15 contains CN individuals, with a proportion of positive individuals of 40.8%, so the closest cohort is again ADNI-CN. The AUC is not provided in the study, so it cannot be used for comparison. The Positive Prediction Rate (PPR) and Negative Prediction Rate (NPR) are, however, given and, as shown in Supplementary Materials, they can be used to compute S and R. The normalized cost can therefore be computed, and is significantly lower (p < 0.0001) with our method.\nThe AUC we obtain on the MCI cohort is comparable to the ones obtained in other studies or slightly higher. [16] [17] [18] Ten Kate et al. 18 obtain a slightly better AUC for the prediction in CN subjects. This difference might be explained by the use of a different feature selection method."}, {"section_title": "Conclusion", "text": "We proposed a method for creating cohorts of Ab\u00fe individuals with a reduced recruitment cost. In a pre-screening phase, we use a classifier to identify a subpopulation of individuals who are more likely to be amyloid positive, based on clinical data. We then do a confirmatory PET scan to the individuals of this subpopulation only. The whole algorithm has been optimized so as to minimize the cost of the cohort recruitment. As such automatic methods are today limited by the number of subjects, future studies could be performed on a Phase 3 clinical trial cohort, as such cohorts often include more than 1000 participants. New screening technologies, such as blood-based biomarkers, 27, 48 could transform the recruitment process for clinical trials, which could also be facilitated by web-based cognition evaluation systems, such as the Brain Health Registry (trial identifier: NCT02402426)."}]