[{"section_title": "Abstract", "text": "Brain imaging genetics attracts more and more attention since it can reveal associations between genetic factors and the structures or functions of human brain. Sparse canonical correlation analysis (SCCA) is a powerful bi-multivariate association identification technique in imaging genetics. There have been many SCCA methods which could capture different types of structured imaging genetic relationships. These methods either use the group lasso to recover the group structure, or employ the graph/network guided fused lasso to find out the network structure. However, the group lasso methods have limitation in generalization because of the incomplete or unavailable prior knowledge in real world. The graph/network guided methods are sensitive to the sign of the sample correlation which may be incorrectly estimated. We introduce a new SCCA model using a novel graph guided pairwise group lasso penalty, and propose an efficient optimization algorithm. The proposed method has a strong upper bound for the grouping effect for both positively and negatively correlated variables. We show that our method performs better than or equally to two state-of-the-art SCCA methods on both synthetic and real neuroimaging genetics data. In particular, our method identifies stronger canonical correlations and captures better canonical loading profiles, showing its promise for revealing biologically meaningful imaging genetic associations."}, {"section_title": "Introduction", "text": "In recent years, brain imaging genetics becomes a popular research topic in biomedical and bioinformatics studies. Brain imaging genetics refers to the study of modeling and understanding how genetic factors influence the structure or function of human brain using the imaging measurements as the quantitative endophenotype [12, 11, 13] . Both the genetic factors, such as the single nucleotide polymorphisms (SNPs), and the imaging measurements such as the imaging quantitative traits (QTs) are multivariate. Therefore, discovering meaningful bi-multivariate associations is an important task in brain imaging genetics.\nEquipped with feature selection, sparse canonical correlation analysis (SC-CA) gains tremendous attention for its powerful ability in bi-multivariate association identification. There are many SCCA methods using different types of shrinkage techniques. The \u2113 1 -norm penalty and its variants are widely used, but they only pursuit individual level sparsity [16, 8] . In biomedical studies, the genetic biomarkers usually function simultaneously other than individually [14] . This is also the case for the imaging measurements. Therefore, the structure level sparsity, such as the group structure or the graph/network structure, is of great interest and importance in brain imaging genetics [14, 15] . To capture the high-level structure information, several different structure-aware penalties have been proposed. There are roughly two kinds of structured SCCA methods according to their different penalties [4] . The first kind of SC-CA methods consider the group information using the group lasso regularizer, which is an intra-group \u2113 2 -norm and intergroup \u2113 1 -norm [1, 6] . The group lasso tends to assign equal weights for those variables in a same group, and each group will be selected or not as a whole [18] . To our knowledge, this type of SCCA methods require the priori knowledge to define the group structure. This limits their applications as it is hard to obtain precise priori knowledge in real biological studies [4] . The second kind of SCCA methods rebuild the structure information via the graph guided or network guided penalty [3, 6, 2, 5, 4] . These SCCA methods can capture the structure information using any available priori knowledge. Moreover, they can also recover the structure information based on the input data [4] . Three types of graph guided penalties have been used: (1) the graph guided fused lasso penalty and its variants [3, 1, 7] , (2) the correlation sign based graph guided fused \u2113 2 -norm penalty [2] , and (3) the improved GraphNet based penalty [4] . Du et al. [4] has shown that the first two types of graph guided penalties could introduce estimation bias because of the sign of the correlations can be wrongly calculated. The reason could be that the sign of the correlations can be easily changed when removing a fraction of the data or perturbing the data as in bootstrap or subsampling. The improved GraphNet utilizes \u2113 2 -norm with respect to the structure penalty terms, which may not produce desirable sparse results at structure level.\nInspired by the success of group lasso in group selection, we consider a case where each group is made up of only two variables. Both variables will be extracted together with similar or equal weights. Interestingly, this novel group lasso can be used in data-driven mode where no priori knowledge is provided. We call it graph guided pairwise group lasso (GGL) which bridges the gap between the group lasso and graph guided penalties. We then propose a new graph guided pairwise group lasso based sparse canonical correlation analysis model (GGL-SCCA) with intention to recover the structure information automatically. The proposed SCCA method is sample correlation sign independent and it is robust to those existing SCCA methods using graph guided penalty. We also propose an efficient optimization algorithm to solve the problem. Besides, we also provide a quantitative upper bound for the grouping effect of our method to demonstrate its structure identifying ability. Compared with the state-of-art SCCA methods such as NS-SCCA [2] and AGN-SCCA [4] , GGL-SCCA can not only obtain higher or equal and more stable correlation coefficients than the competing methods, but also find out cleaner canonical loading patterns on both synthetic data and real imaging genetic data."}, {"section_title": "The Graph Guided Pairwise Group Lasso", "text": "Throughout this paper, we denote a vector as the boldface lowercase letter, and a matrix is denoted by a boldface uppercase one. The Euclidean norm of vector u is \u2016u\u2016. Let X = [x 1 ;\u2026; x n ] T \u2286 \u211d p and Y = [y 1 ; \u2026;y n ] T \u2286 \u211d q be the SNP data and the QT data from the same participants.\nWe have known that the group lasso tends to extract a subset of the features. However, it depends on the priori knowledge and there is no overlap between groups. The graph guided fused lasso overcomes this limitation, but it requires the sign of the sample correlations to be defined in advance. This will introduce undesirable estimation bias [17] . In this paper, we introduce the graph guided pairwise group lasso penalty by taking advantage of both group lasso and graph guided fused lasso. The GGL penalty is defined as, (1) where E is the edge set of the graph where those highly correlated features are connected.\nThe GGL penalty has the following two merits. First, if there is no priori knowledge, every pairwise term will be included to encourage |u i | \u2248 |u j | which is guaranteed by the pairwise \u2113 2 -norm. This holds for both positively and negatively correlated features, which will be demonstrated later in Theorem 1. Second, if some priori knowledge such as the pathway information about genetic markers is provided, the whole penalty will be guided by the pathway information. This will encourage |u d | = |u j | no matter whether they are positively or negatively correlated. Therefore, the two genetic markers have very high probability to be selected simultaneously. The same results hold for the imaging measurements if we have the brain connectivity pattern such as the human connectome."}, {"section_title": "Method", "text": ""}, {"section_title": "GGL-SCCA Model and Optimization", "text": "We then propose the GGL-SCCA model, (2) where \u03a9 GGL (u) and \u03a9 GGL (v) are the GGL penalty to assure structure information. Of note, we use \u2016Xu\u2016 2 \u2264 1 instead of \u2016u\u2016 2 \u2264 1 to accommodate the in-set covariance X T X which can improve the model performance [6] .\nIn order to solve this problem, we write the objective function of GGL-SCCA into matrix form using the Lagrange method, (3) We approximate the objective function by a quadratic function. Obviously, the first term u T X T Yv is bilinear and biconvex in u and v. We then show the quadratic expression of the GGL term. Let u t and u t+1 be the estimation at steps t and t + 1 respectively, the first-order Taylor expansion of term regarding is,\nwhere . From the point of view of optimization, the term C makes no contribution towards optimizing u i . 3 Then the GGL penalty can be simplified, (5) with C* being the sum of C across all pairwise penalty terms. Therefore, the GGL penalty is quadratically expressed. Now the objective function conveys to a quadratic function, and there exists a closed-form solution. Since GGL-SCCA is biconvex in u and v, we take the derivative with respect to them respectively. The solution to the Eq. (3) satisfies, 3 Each u i can be solved with u j 's (j \u2260 i) fixed (i.e., we use to approximate in C), thus u j 's do not contribute to the optimization of u i [9] . \nAlgorithm 1 The GGL-SCCA Algorithm\nRequire:\nCanonical loadings u and v. , and D 2 is a diagonal matrix with the k 2 -th element being . 4 Therefore, u and v have the closed-form updating expressions,\n4 Note that an element of diagonal matrix D 1 will nonexist if . We handle this issue by regularizing it as with \u03b6 being a tiny positive number. Then the objective function regarding u becomes . We can prove that \u2113(u) will reduce to the original problem (3) when \u03b6 approaching zero. Likewise, can be regularized by the same method. \nWe have known that GGL-SCCA model is biconvex with respect to u and v respectively. Then the Alternate Convex Search (ACS) method which is designed to solve the biconvex problem can be employed [10] . According to the ACS method, we address our SCCA model via alternative optimization by updating u and v alternatively. The procedure of the GGL-SCCA is shown in Algorithm 1. In every iteration, u and v are updated in turn till the algorithm converges or reaches a predefined stopping condition."}, {"section_title": "The Grouping Effect", "text": "In structured learning, a method that can estimate equal or similar values for a group of variables is more desirable [19, 4] . This is called grouping effect and of great importance.\nWe have the following theorem with respect to the grouping effects of the GGL-SCCA method."}, {"section_title": "Theorem 1.", "text": "Given two views of data X and Y, and the tuned parameters (\u03bb, 7). Let u* be the solution to our SCCA problem. For the sake of simplicity, we assume there are only two features, e.g. u i and u j , are connected on the graph. Let \u03c1 ij be their sample correlation. Then the optimal u* satisfies,\nProof.\n(1) We first prove the inequations when \u03c1 ij \u2265 0 indicating features being positively correlated. We have the following two equations,\nGiven u i and u j are the only connected features, we have . Then we arrive at (12) Subtracting these two equations, we have Du et \nInf Process Med Imaging. Author manuscript; available in PMC 2018 June 01.\nTaking \u2113 2 -norm on both sides, we arrive at\nUsing , \u2016Xu\u2016 \u2264 1, \u2016Yv\u2016 \u2264 1 and \u2212u T X T Yv \u2264 1, we obtain the upper bound (15) (2) If \u03c1 ij < 0, it is clear that sign(u i ) = \u2212sign(u j ). By adding both equations in Eq. (12) instead of subtracting them, we finally arrive at, (16) Note that GGL-SCCA model is symmetric about u and v, we can obtain the same upper bound of grouping effect for canonical weights v.\nThe Theorem 1 provides a qualitative theoretical description of the bound for both differences and sums of the coefficients. The bound between two coefficients directly depends on their correlation. If \u03c1 ij \u2265 0, a higher correlation between two variables makes sure a smaller difference between their estimated coefficients. If \u03c1 ij < 0, a smaller value assures a smaller sum between their coefficients. This implies that the two coefficients will be approximate in amplitude. Therefore, the GGL-SCCA is capable of capture structure information no matter whether those features are positively or negatively correlated."}, {"section_title": "The Complexity Analysis", "text": "In Algorithm 1, Steps 2-7 are repeated until convergence. In each iteration, Step 3 is easy to calculate as D 1 can be computed via matrix manipulation to avoid time consuming loop. This is the same case for Step 5.\nStep 4 and Step 6 are the key steps, and we compute them via solving a system of linear equations with quadratic complexity instead of computing the matrix inverse with cubic complexity. This can reduce the computation burden greatly.\nStep 8 is a rescale steps and very simple to calculate. Therefore, the algorithm runs fast and efficiently.\nIn this study, we terminate Algorithm 1 when either of the two conditions satisfies, max{|\u03b4| | \u03b4 \u2208 (u t+1 -u t )} \u2264 \u220a and max{|\u03b4| |\u03b4 \u2208 (v t+1 -v t )} \u2264 \u220a, where \u220a is a desirable estimation error.\nWe chose \u220a = 10 \u22125 empirically from experiments in this paper."}, {"section_title": "Experimental Study", "text": ""}, {"section_title": "Experimental Setup", "text": "We compare GGL-SCCA with two structure-aware SCCA methods. The first one is the network guided fused lasso based SCCA (NS-SCCA) which takes the sample correlation signs into consideration [2] . The second method is the AGN-SCCA which uses the absolute value based GraphNet to penalize those correlated variables [4] . These two methods are different in both modeling and optimizing techniques, and is deemed to be among the best structured SCCA methods by now.\nWe tune the parameters based on the following considerations to reduce time consumption.\n(1) According to Theorem 1, \u03bb i=1,2 and \u03b3 i=1,2 contribute to the grouping effect oppositely.\n(2) The grouping effect is more sensitive to \u03bb i=1,2 than to \u03b3 i=1,2 . Therefore, we fix \u03b3 i=1,2 to a moderate constant, and let \u03b3 i=1,2 = 10 in this paper. Finally, we have only two parameters \u03bb i=1,2 to be tuned and optimally tune them via a grid search from a moderate range 10 \u22122 to 10 2 through nested five-fold cross-validation to make sure efficiency. The parameters that generate the highest correlation coefficients are used."}, {"section_title": "Results on Simulation Data", "text": "Four different data sets with different properties are generated in this study. We also set the number of observations be smaller than the number of features to simulate a large p small n problem. The details of the data sets are as follows. Firstly, u and v are generated according to the predefined structure. Secondly, a latent variable z \u223c N(0, I n\u00d7n ) is generated. And thirdly, X is created by We apply GGL-SCCA, NS-SCCA and AGN-SCCA to all four data sets. The true and estimated canonical loadings u and v are shown in Fig. 1 . We observe that both GGL-SCCA and AGN-SCCA identify similar canonical loading profiles that are consistent to the ground truth across all data sets. NS-SCCA produces too many signals which are not so perfect to the ground truth. In addition, we also show the estimated correlation coefficients on both the training and testing sets calculated using the trained SCCA models in Table 1 (Left). The results show that GGL-SCCA obtains highest scores on both training and testing sets. Its testing result is only inferior to the NS-SCCA on the second data. The results implies that GGL-SCCA has better training performance and generalization ability than those benchmarks. The area under ROC (AUC) shown in Table 1 (Right) indicates the sensitivity and specificity. It reveals that GGL-SCCA outperforms the competing methods as it holds the highest values for the most times. In summary, the simulation results demonstrate that GGL-SCCA could identify not only stronger testing associations but also more better signals on these diversified data sets."}, {"section_title": "Results on Real Neuroimaging Genetics Data", "text": "The real imaging genetics data used in the preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). The ADNI was launched in 2003 as a public private partnership, led by Principal Investigator Michael W. Weiner, MD. One primary goal of ADNI is to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimers disease (AD). For up-to-date information, please refer to www.adni-info.org.\nWe use the genotyping and baseline amyloid imaging data (preprocessed [11C] Florbetapir PET scans) contributed by 567 non-Hispanic Caucasian participants. The amyloid imaging data used in this study are downloaded from LONI (adni.loni.usc.edu). Preprocessing is conducted to format this imaging data, and we finally generate 191 ROI level mean amyloid measurements in which the ROIs are defined by the MarsBaR AAL atlas [4] . The genotyping data includes 58 candidate SNP markers from the AD-related genes, such as the APOE gene. The aim is to evaluate the associations between the SNP data and the amyloid data, as well as which SNPs and amyloid measurements are correlated in this AD cohort.\nAll three SCCA methods are performed on the real neuroimaging genetics data. Shown in Fig. 2 are the canonical loadings obtained from the training data, where the relevant imaging measurements and genetic markers are exhibited. It is clear that GGL-SCCA identifies two relevant ROIs and one SNPs for easy interpretation due to the novel GGL penalty. The two strongest imaging measurements come from the right frontal region, which are positively correlated with SNP rs429358, a confirmed AD related allele in APOE e4. The AGN-SCCA identifies similar results to our method, which however has many interfering signals for the genetic markers. The NS-SCCA finds out too many imaging signals that are very hard to interpret. To give a clear view, we map the canonical loadings regarding the imaging measurements of GGL-SCCA onto the brain. Fig. 3 clearly shows that our method only highlights a small region of the whole brain. Moreover, we present the training and testing correlations in Table 3 . GGL-SCCA obtains the highest values on both training set and testing set. Although AGN-SCCA has the same mean on training data, its standard deviation is larger than GGL-SCCA. Moreover, GGL-SCCA obtains better testing results than both competing methods. This implies that GGL-SCCA is more stable and has better generalization ability than AGN-SCCA and NS-SCCA. The results on this real data demonstrate that GGL-SCCA has better bi-multivariate identification ability than the benchmark methods. The strong association between the frontal morphometry and the APOE in AD cohort, indicating GGL-SCCA's promising and potential power in identifying biologically meaningful imaging genetic associations."}, {"section_title": "Conclusions", "text": "We have proposed a novel graph guided pairwise group lasso (GGL) based SC-CA method (GGL-SCCA) to identify associations between brain imaging measurements and genetic factors. The existing group lasso based methods [1, 6] were dependent on the priori knowledge which was not always available. The graph/netwrok guided fused lasso based approaches [3, 6, 2, 5, 4] only focus on the positively correlated variables, or depended on the signs of the sample correlation which were sensitive to the partition of the data. Our SCCA method combines the merits of group lasso and the graph/network guided fused lasso, which is independent to not only the signs of the sample correlation, but also the priori knowledge. Moreover, our method can also incorporate the priori knowledge to recover specific structures.\nWe have compared GGL-SCCA with two state-of-the-art structured SCCA methods on both synthetic data and real imaging genetic data. The results on the synthetic data show that GGL-SCCA performs better than both NS-SCCA and AGN-SCCA across all data sets. The results on real data show that, GGL-SCCA not only reports better canonical correlation values than the competing methods, but also obtains more accurate and cleaner canonical loading patterns. GGL-SCCA finds out a strong associations between the superior frontal morphometry and the APOE e4 SNP, revealing its power in brain imaging genetics. In this paper, we merely use the graph guided pairwise group lasso penalty to induce structured sparsity. In the future work, we will incorporate lasso into the model to assure additional sparsity, and incorporate the priori knowledge to evaluate the performance of GGL-SCCA. Mapping averaged canonical loading v of GGL-SCCA onto the brain. "}]