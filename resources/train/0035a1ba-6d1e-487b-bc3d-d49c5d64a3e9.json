[{"section_title": "Abstract", "text": "Abstract-In this paper, we propose a general framework for performance improvement of the current state-of-the-art registration algorithms in terms of both accuracy and computation time. The key concept involves rapid prediction of a deformation field for registration initialization, which is achieved by a statistical correlation model learned between image appearances and deformation fields. This allows us to immediately bring a template image as close as possible to a subject image that we need to register. The task of the registration algorithm is hence reduced to estimating small deformation between the subject image and the initially warped template image, i.e., the intermediate template (IT). Specifically, to obtain a good subject-specific initial deformation, support vector regression is utilized to determine the correlation between image appearances and their respective deformation fields. When registering a new subject onto the template, an initial deformation field is first predicted based on the subject's image appearance for generating an IT. With the IT, only the residual deformation needs to be estimated, presenting much less challenge to the existing registration algorithms. Our learning-based framework affords two important advantages: 1) by requiring only the estimation of the residual deformation between the IT and the subject image, the computation time can be greatly reduced; 2) by leveraging good deformation initialization, local minima giving suboptimal solution could be avoided. Our framework has been extensively evaluated using medical images from different sources, and the results indicate that, on top of accuracy improvement, significant registration speedup can be achieved, as compared with the case where no prediction of initial deformation is performed.\nIndex Terms-Deformation prediction, fast image registration, principal component analysis (PCA), support vector regression (SVR)."}, {"section_title": "", "text": "respect to a common template, i.e., using atlas-based morphometry [1] [2] [3] or inter/intragroup difference comparison [4] [5] [6] .\nDeformable registration methods, regardless whether intensity-based [7] [8] [9] or feature-based [10] [11] [12] [13] [14] , mostly define an objective function that is optimized under various regularization constraints to estimate physically realistic deformations. Possible forms of regularization constraint include elastic energy [15] , [16] , viscous fluid [17] , [18] , biomechanical model [19] , and Laplacian term [11] , [12] . More recent methods have incorporated regularization based on statistical constraints [20] [21] [22] [23] [24] . However, due to significant template-subject structural shape differences and the high dimensionality of the objective function, determination of accurate template-subject deformations has been a long-standing problem. Accompanying problems include 1) long computation time arising from the need to estimate \"large\" deformations and 2) vulnerability to ambiguous matching due to structural variability."}, {"section_title": "A. Motivations", "text": "The goal of this paper is to propose a general registration framework to not only reduce the computation time and but also further improve the registration accuracy of the state-ofthe-art registration algorithms. To achieve this goal, we present a learning-based registration framework to learn the correlation between image appearances and their respective deformations. For each subject image, we generate an intermediate template (IT) , which is close in similarity to the subject image, based on a deformation field predicted from the learned correlation model. The need to only estimate the residual deformation field between the IT and the subject image is much less challenging for most of the existing registration methods. This way, a significant amount of computation time can be saved, and the registration accuracy can be improved since the risk of being trapped by local minima will be greatly reduced.\nSpecifically, our framework consists of three steps in the training stage. First, principal component analysis (PCA) is employed on a set of deformation fields to capture the principal modes of brain deformations using a finite set of parameters. A brain appearance model is then constructed, utilizing low-dimensional image features instead of the whole brain image. After obtaining the statistical models of deformation fields and brain image appearances, we train a deformation-appearance model through support vector regression (SVR), which will help bridge the intrinsic statistics of deformation fields and brain appearances.\nWhen registering a new subject onto the template in the application stage, the initial deformation field and the IT can be rapidly predicted by the trained SVR according to the appearance of the new subject image. Consequently, by requiring only the estimation of the residual deformation from the IT to the subject, the registration time can be greatly decreased. Another obvious advantage is that more reliable registration results can be achieved by our method since the structural difference of a subject from the IT is much smaller than that from the original template. To our knowledge, this paper presents the first attempt to combine, via SVR, statistics of deformation fields and image appearances for not only improving speed but also registration robustness.\nTo demonstrate the generality of the proposed registration framework, we selected five typical deformable registration algorithms, i.e., hierarchical attribute matching mechanism for elastic registration (HAMMER) [11] , [12] (feature-based registration), diffeomorphic demons [25] (intensity-based registration with diffeomorphism constraint), FNIRT [26] (an intensity-based registration algorithm with deformation model parameterized by B-splines), ART [27] (intensity-based registration by nonparametric vector fields, subject to regularity constraints), and SyN [28] (intensity-based registration with a symmetric diffeomorphic optimization) to demonstrate the registration performance before and after integration with our framework. It is worth noting that all these registration methods have been acknowledged as the state-of-the-art registration methods in [29] . As we will show in the experiment section, we are able to not only speed up their computation time but also improve their registration accuracy."}, {"section_title": "B. Related Works", "text": "Learning-based statistical models have been widely investigated to improve registration accuracy by imposing more realistic registration constraints. However, most works are limited in building learning models based on the deformation fields only. For example, Xue et al. [22] construct a statistical model on the wavelet coefficients of deformations to constrain the deformation field during registration. Similar works can be also found in [21] and [23] , where the authors build statistical models of B-spline coefficients by principal components analysis. Recently, Glocker et al. [20] proposed to hierarchically learn deformation by adaptively treating the control points into two groups, i.e., masters (to encode important information to drive more global deformations) and slaves (to be connected to the masters to estimate more local deformations). In addition, in order to improve the registration accuracy of femur bone computed tomography images, Albrecht et al. [24] presented a method for learning deformation statistics from noisy and incomplete data.\nThere are several other ways, other than the construction of deformation models, to improve registration accuracy. For example, the image similarity metric can be learned in order to increase the accuracy of correspondence matching for shape alignment in [30] and multimodality image registration in [31] and [32] . Wu et al. [33] also addressed the importance of determining the appropriate neighborhood sizes for image feature computation. This paper was later extended in [34] to a more general framework based on a boosting algorithm to select the best features and key points. Recently, Yeo et al. [35] have proposed an iterative machine learning framework to select the best parameters for an application-specific cost function. They demonstrated that, by improved alignment of cortical foldings, promising results in localizing the underlying cytoarchitecture and functional regions in the cerebral cortex can be obtained.\nUltimately, our learning-based registration framework shares the same motivation as the work of Yeo et al. , that is, to boost the performance of the existing registration algorithms. However, we approach this problem from a different perspective in which we attempt to predict an initial deformation field with the help of the correlation information learned between deformation statistics and image appearances. Our goal is to not only improve the registration accuracy but also reduce the computation time, which is of paramount importance to clinical applications.\nWe have previously developed a method called rapid alignment of brains by building intermediate templates (RABBIT) [36] , which is capable of generating the initial deformation fields and the corresponding ITs. The statistical deformation model is first built using a set of training samples by utilizing PCA to characterize the intrinsic warping modes. Then, several ITs are generated by parameterizing the PCA coefficient distribution as a Gaussian distribution and then by performing a uniform coefficient sampling. When registering a new individual subject onto the template, the algorithm automatically determines the most similar precomputed IT as the reference image to which the subject is registered. We note here that the IT is determined based on a simple similarity metric, i.e., the sum of squared difference (SSD), that might not be sufficient for adequately characterizing shapes in a very high-dimensional space. Uniform sampling, as the number of samples exponentially increases, is also inadequate [37] . Our method differs from RABBIT in which: 1) We jointly consider the statistical models of deformation fields and brain appearances and capture their relationship by SVR instead of selecting the IT based on a simple SSD measurement; 2) several individual subjects might end up with the same IT in RABBIT since they are predetermined by uniform sampling in eigenspace; our method, on the other hand, generates a unique IT for each individual brain adaptively according to its distinctive appearance via the trained SVR; and 3) the number of ITs is fixed in RABBIT, whereas our method can theoretically generate an unlimited number of different ITs. This paper is structured as follows. In Section II, we describe the proposed registration framework, followed by the details on the statistical models for both deformation and image appearance and also a regression model for correlating deformation and appearance, as well as the prediction of an initial deformation field. We show the experimental results on both real and simulated data in Section III. In Section IV, we conclude this paper."}, {"section_title": "II. METHOD", "text": "We propose a general framework for improving the registration performance of the existing algorithms by principled estimation of an initial deformation field, which will be discussed in Section II-A. We will explain our learning-based approach in Section II-B, where we apply SVR to learn the correlation between brain appearances and their deformation coefficients. With this learned knowledge, we can automatically determine a good initial deformation field for each individual subject, which we then use to generate a corresponding IT for registration refinement. We will detail each step of the prediction of the IT in Section II-C. Finally, we will summarize our learning-based registration method in Section II-D."}, {"section_title": "A. Framework for Fast Image Registration", "text": "The goal of a deformable registration algorithm is to estimate a dense transformation field for aligning subject image to template , where denotes the displacement of a point in the template image domain . On the other hand, inverse transformation field is used to warp the image in the template space to the subject space . Most registration algorithms initiate the registration with a null deformation field, i.e., . However, for our case, we decompose the overall deformation field into two parts: the estimated initial deformation field and the residual deformation field , i.e., , as illustrated in the top part of Fig. 1 . Here, denotes an IT. In our method, is automatically determined according to a regression model learned in the training stage, as shown in the bottom part of Fig. 1 . Five steps are involved in this training stage. In Step 1, a set of training subject brains is registered using a registration algorithm, such as HAMMER [11] , [12] , diffeomorphic demons [25] , FNIRT [26] , ART [27] , or SyN [28] to estimate the deformation field from the template to each subject , resulting in a set of deformations and the corresponding warped images . Here, denotes warping of an image using a transformation (or displacement field ). PCA is then employed in Step 2 to construct a statistical deformation model (called deformation PCA) of , giving us a deformation coefficient vector (as explained in Section II-B1) for each deformation field . Each is a -element column vector, where denotes the number of top-ranked eigenvalues after PCA. The aim of Step 3 is to solve the small sample problem, where we introduce some perturbations to the elements of each deformation coefficient vector to obtain a set of new simulated deformation coefficient vectors . By using both real and simulated deformation coefficient vectors, an enlarged set of (dense) deformation fields can be obtained. It is worth noting that since is reconstructed from the perturbed deformation coefficient vector , thus is not equal to . By applying the inverse of each to each warped image , a total of simulated training samples, , can be obtained, where denotes transforming an image to the subject image space by using the inverse transformation field . Although our framework does not explicitly impose diffeomorphism on the deformation field, in practice, deformations can be reasonably inverted using the method proposed in [38] .\nSteps 4 and 5 involve constructing the brain appearance model based on the data set . To build an efficient regression function with better generalization performance, we propose employing signature images that capture brain outlines and also the boundaries along the interfaces of white matter (WM), gray matter (GM), cerebrospinal fluid (CSF), and ventricular (VN) CSF of instead of directly using all voxels in . After calculating the eigenvalues and eigenvectors of by PCA (called signature PCA), we select eigenvectors with the largest eigenvalues to project to obtain their low-dimensional representations called signature vectors , where each column of is the signature vector of the corresponding . We will give a more detailed description of this in the next section.\nThe key of our approach is the use of a support regression machine to bridge the statistical deformation model with the brain appearance model, as shown in the middle part of Fig. 1 . We train support vector machines independently, and each of them will make its own regression between each deformation coefficient and the whole set of signature vectors . Therefore, when registering a new subject onto the template , its signature vector is first calculated according to its signature image. Then, through a set of trained support vector machines, we can predict a unique deformation coefficient vector for the subject , which can be, in turn, used to construct an and an initial deformation field . We note here that the shape difference between and is quite small, as illustrated by the right two brain images at the top part of Fig. 1 . Finally, many existing registration algorithms can be employed to estimate the rest of the deformation . The IT allows this to be done more efficiently by avoiding the direct subject-to-template registration."}, {"section_title": "B. SVR on Statistical Deformation and Image Appearance Models", "text": "Here, we will describe our learning-based framework (outlined at the bottom part of Fig. 1 ). We will describe how a PCA-based method is used to build the statistical models of both deformation fields (see Section II-B1) and image appearances (see Section II-B2), followed by how we train a set of SVR models to establish deformation-appearance correlation (see Section II-B3)."}, {"section_title": "1) Statistical Model of Deformation Fields:", "text": "Given a set of brain images , their respective deformation fields can be estimated by many existing registration algorithms such as HAMMER [11] , [12] , diffeomorphic demons [25] , FNIRT [26] , ART [27] , or SyN [28] . After arranging each deformation field into a vector representation, we apply PCA on these vectors and obtain a statistical deformation model that captures the statistical variations of these deformation fields . Specifically, the eigenvectors of covariance matrix of the deformation fields represent the principal modes of variation, and their eigenvalues indicate the magnitude of deformation variation in the direction of the corresponding eigenvector. Usually, only a small number of eigenvectors with the largest eigenvalues will be used to approximate the original data since they characterize the principal shape changes. For instance, by selecting eigenvectors after employing PCA on 50 deformation fields, we are able to represent almost 95% of the total energy of shape variations. The reconstructed deformation field of each with the largest eigenvectors can be formulated as (1) where denotes the mean deformation field, and and are the eigenvalues and eigenvectors of covariance matrix of deformation samples, respectively. Each deformation field is now represented by in a subspace (spanned by the largest eigenvectors) with a deformation coefficient vector , where . Note that is a -element column vector.\n2) Statistical Model of Image Appearances: Generating More Training Samples: We are often faced with the problem of having a limited number of training samples in . To remedy this, we simulate additional brain images based on the generated statistical model of with the hope of increasing the robustness of estimation of the brain appearance model. Unlike the simulation method used in RABBIT [36] , which parameterizes the distribution of as a Gaussian model and simulates new deformations by uniform sampling in a PCA-represented subspace (see [37, Fig. 1]) , we generate new deformation coefficient vectors by perturbing with . Specifically, is generated by randomly sampling around the location of vector in the -dimensional subspace. It is worth noting that since is the baseline of all . Therefore, the simulated deformation fields can be constructed using (2) 2 gives an illustration of the procedure we use in simulating brain samples. We assume that we have subjects, each with perturbations. After registration using HAMMER, diffeomorphic demons, FNIRT, ART, or SyN, these subjects are aligned onto the template (black circle) and are denoted as\n. In order to cover as much of the brain space as possible, we continue to generate new simulated deformation fields for each , according to (2) . There are, hence, deformations in total. As shown in Fig. 2 , we consider all the brains as nonuniformly distributed in the high-dimensional manifold. In order to cover as much as possible different image appearances, we apply all deformations to each real training sample, obtaining simulated images in total. In Fig. 2 , each blue circle denotes a set of simulated images of subject . Statistical Model of Image Appearances: Similar to the method presented in the previous section, the brain appearance model can be constructed based on an enlarged set of brain images [39] . However, in order to obtain a brain appearance model feasible for estimating the regression model described in the next section, we employ a number of strategies to reduce the dimensionality of before building the brain appearance model.\nFor each brain image , the uninformative background voxels will be first cropped away by computing a bounding box that covers the whole brain volume. The image will be then downsampled by a factor of 4 in each dimension, obtaining , as shown in the second column of Fig. 3 . To represent the shape variations of each brain image , we segment the images into four tissue types, i.e., WM, GM, CSF, and VN, and extract the brain outlines and boundaries along the interfaces between them as shape descriptors for constructing the signature image (see the third column of Fig. 3 ). Tissue classification consisted of two steps. First, we used the fast algorithm (FSL, http://www.fmrib.ox.ac.uk/fsl/) to segment the whole brain into WM, GM, and CSF. Second, we warp the ventricle label of the template to the subject space to label the subject ventricle. It is worth noting that our purpose of employing tissue classification here is not for accurate segmentation but for extracting boundary information. Therefore, other kinds of edge features can be also used here, e.g., Canny edge filter or even simple intensity gradient map. Next, we apply PCA (called as signature PCA) to whole signature images. Afterward, the signature PCA model is applied to each signature image to obtain a low-dimensional representation by a signature column vector (3) where denotes the mean shape of all signature images, and and are eigenvalues and eigenvectors of their covariance matrix, respectively. Only the top ranked eigenvectors, representing around 70% the sum of all eigenvalues, are selected (see the fourth column of Fig. 3 ) so that the appearance model is less sensitive to the less important shape deviations. By arranging all column vectors into a matrix, we obtain (see the rightmost part of Fig. 3 ). In the following section, we will describe how we train the SVR models to estimate the correlation between deformation coefficient vectors and signature matrix ."}, {"section_title": "3) Regression on Deformation-Brain Appearance Model:", "text": "An important part of our learning-based registration approach is the utilization of SVR models to learn the correlation between brain appearances and their corresponding deformation coefficients, and then use them to predict a set of deformation coefficients when given a new brain image for registration (as illustrated in Fig. 4 ). Specifically, we will train SVR models, each of them determining a nonlinear regression function between signature matrix (see Section II-B2) and each deformation coefficient from a respective row of matrix (see Section II-B2).\nNote that SVR [40] , [41] is a supervised learning technique for finding nonlinear mapping functions that correlate a number of input variables (features) with the values of a continuous \nwhere denotes the th SVR model in Fig. 4 . is the transpose of a -dimensional column vector with all zeros except the th element, which has a value of 1. An identical set of signature vectors is used as the features of all regression models, and the th row of deformation coefficient matrix is independently used as the target for the th regression model .\nWe select the Gaussian radial basis function as the kernel function due to its good performance in classification and regression [42] . In our method, we estimate the kernel size based on the distribution of each signature vector by computing the average of the distances from all possible pairs of . A recently proposed algorithm [41] , which uses an intensive loss function to achieve the global minimum with reliable generalization bound, has been used to determine for all SVR models. Parameter is used to control the width of the insensitive zone that penalizes the training data outside this zone. Constant determines the tradeoff between the flatness of and the tolerance to deviation larger than . The values of and can be calculated as [43] (5) (6) where is the standard deviation of distances between all pairs of , is an empirical constant, and is the number of signature vectors used as the features for regression. and are the mean and the standard deviation of overall deformation coefficients , respectively."}, {"section_title": "C. Predicting the IT and Initial Deformation Field", "text": "After training the regression models, the ITs can be predicted to facilitate the registration by achieving robust results in a significantly reduced time. For a new subject , its signature vector will be first computed by projection onto the top eigenvectors (see Section II-B2) after the affine alignment to the template by FSL FLIRT [44] . Deformation coefficients Fig. 5 . Illustration of the proposed registration algorithm in aligning (b) a subject image with (a) a template image. (c) An IT is estimated, onto which (b) the subject image can be registered. By concatenating the deformation fields from the template to the IT and from the IT to the subject, we can warp the template to the subject, as shown in (d), which is comparable to the results given by HAMMER, as shown in (e).\ncan be then predicted one by one through each trained SVR model (see the bottom part of Fig. 4) . Next, it is straightforward to obtain the initial deformation for the subject by (1). The IT for can be then generated by warping the template with respect to . Fig. 1 illustrates the whole procedure of registering template to subject with the proposed registration method. Unlike traditional registration algorithms, we simply need to estimate only the remaining deformation field from the IT to the subject, and this helps save a significant amount of computation cost and circumvent the error-prone approach of estimating large deformations from the original template to the subject. Upon estimating (by the existing registration method), deformations and can be concatenated. Fig. 5 shows images from each step of the proposed method for template (a) and subject image (b). First, an IT (c) is estimated. The IT is then registered to the subject image. By concatenating the deformations from the template to the IT and from the IT to the subject, we can warp the template to the subject, as shown in (d), which gives a result comparable to HAMMER (e)."}, {"section_title": "D. Summary of our Fast Registration Framework", "text": "Our registration method is capable of achieving robust registration results with much less computation time by predicting a good initial deformation field and an IT for a subject image under registration. The whole registration framework can be summarized in two stages, i.e., training and application stages. They are summarized below. "}, {"section_title": "Training Stage", "text": ""}, {"section_title": "Application Stage", "text": "a1) Calculate the signature vector for a new subject . a2) Predict the deformation coefficient through the learned SVR models. a3) Generate an initial dense deformation field according to by (1) and warp template image using to obtain an . a4) Use a deformable registration method (e.g., HAMMER, diffeomorphic demons, FNIRT, ART, or SyN) to estimate the remaining deformation field from the IT to the subject and then concatenate and for obtaining the final deformation field."}, {"section_title": "III. EXPERIMENTAL RESULTS", "text": "The accuracy, robustness, and speed of the proposed learning-based registration method are comprehensively evaluated in comparison with several typical deformable registration algorithms. We first validate the advantages of our registration framework by regarding the simulated deformations as the ground truth. Here, we take HAMMER as an example and demonstrate the superiority of the proposed framework over RABBIT [36] . Additional experimental results are reported on real elderly brains and the public data sets (nonrigid image registration evaluation project (NIREP) [45] and Laboratory of Neuro Imaging (LONI) [46] data set). Our registration framework can be easily integrated with a number of the existing registration algorithms for immediate improvement of registration performance. To show this, we use HAMMER (feature-based registration method), diffeomorphic demons [25] (intensity-based registration method with diffeomorphism constraint), FNIRT [26] (intensity-based registration method with deformation field parameterized with the B-splines), ART [27] (intensity-based registration by nonparametric vector fields, subject to regularity constraints), and SyN [28] (intensity-based registration with symmetric diffeomorphic optimization) as the example registration methods in the subsequent experiments. Note that these methods have been acknowledged as state of the art in a recent survey paper [29] ."}, {"section_title": "A. Experiments on Simulated Data", "text": "In the following experiment, we use the HAMMER registration algorithm as the baseline and compare the registration performance with RABBIT and our proposed method. It is worth noting that both RABBIT and our method use HAMMER to complete the estimation of the rest of the deformation field after predicting the initial deformation field."}, {"section_title": "Brain Images With Simulated Deformations:", "text": "We simulated a set of deformation fields using the algorithm proposed in [47] to serve as ground truth for evaluation. The baseline images are selected from the Baltimore Longitudinal Study of Aging (BLSA) [48] data set. Specifically, we simulated three groups of deformation fields (10 in each group) with different mean magnitudes of deformations, i.e., 2 mm (Group 1), 4 mm (Group 2), and 6 mm (Group 3). Fig. 6 shows, for each group, some typical images generated by warping the template with the simulated deformation fields. We then estimated the deformation field between the simulated subject and the template by HAMMER, RABBIT, and our method, respectively. By comparing the residual error (average of the voxel-wise Euclidean distances) between the estimated deformation fields with respect to the ground truth, we can quantitatively measure the registration accuracy. From the average residual errors shown in Table I , it is clear that our method outperforms original HAMMER and RABBIT, particularly for the simulated subjects with larger deformations, thus showing the robustness of our registration framework."}, {"section_title": "B. Experiments on Real Data", "text": "Real Elderly Brain Images: We used elderly magnetic resonance (MR) images randomly selected from the BLSA [48] data set for training and another 50 images for validation.\nEach image has a size of 256 256 124 and a resolution of 0.9375 mm 0.9375 mm 1.5 mm. The images were segmented into four tissue types, i.e., WM, GM, CSF, and VN, respectively. Before training, affine registration [44] was performed on all training samples to remove global translation, rotation, and scaling. We then estimated the deformation fields of all these images with respect to a template by using HAMMER. Applying PCA, we built a statistical deformation model with 49 modes from the 49 eigenvectors with nonzero eigenvalues, and each deformation field was represented by 25 PCA coefficients for covering 95% of the variability. For denser sampling of the deformation field space, we applied perturbations, thus giving us a total of deformation samples and simulated brain images by inverse deforming the 50 normalized images in the template space. We used half (i.e., 6250) of the deformation-image pairs (corresponding to 25 original MR brain images) for training and the other half for validation. We note here that a sufficient number of samples are important for training a robust statistical model. The samples used for training and validation can be considered independent since there is no overlap between the original MR images used for training and testing.\nThe results show that the average prediction error based on predicted deformation coefficients is 1.5% on the training data and 5.7% on the validation data. The prediction error was computed based on the ratio of the difference between the predefined deformation coefficients and their estimated ones. These results indicate that our model is able to predict very good initial deformations for the validation data, which can significantly help reduce computation cost and increase registration robustness, as reported in Section III-B. Since the validation data were not used for training, the error in estimating its deformation coefficients is larger than the training error, which is reasonable. To demonstrate the importance of using perturbation for generating sufficient samples, we further evaluated the performance of our statistical model without perturbation, and the average prediction error on the same validation data increases to 15.9%, which is more than two times higher than that using the deformation perturbation strategy.\nGiven a new image, we first align it linearly to the template space, and then construct its signature vector by downsampling, feature extraction, and dimensionality reduction, which we can finally use to predict the initial deformation. To evaluate the quality of the predicted deformation, we use other 50 images that have not been included in the training. Some test images are shown in Fig. 7(b) , and it can be observed that they are structurally very different from the original template shown in Fig. 7(a) . Fig. 7 LONI LPBA40 Data: Our framework is general enough to allow incorporation of different registration algorithms. To demonstrate this, we utilized HAMMER, diffeomorphic demons, FNIRT, ART, and SyN algorithms 1 for obtaining the deformation fields from the training samples, constructing the statistical deformation model, and estimating the residual deformation from the IT to the subject. Note that our intention here is not to compare the performance between HAMMER, diffeomorphic demons, FNIRT, ART and SyN, but to demonstrate the improvement that our framework can yield.\nThe LONI LPBA40 data set is used for this experiment. This data set consists of 40 subjects, each manually labeled with 54 regions of interest (ROIs). For the five registration methods under evaluation, we incorporated them into our learning-based registration framework. For each case, we randomly chose one subject as the template. For the remaining 39 subjects, we used 20 subjects for training and 19 subjects for testing. The Dice ratios, for all ROIs of the 19 subjects yielded by HAMMER, diffeomorphic demons, FNIRT, ART, and SyN, are compared for cases with and without our framework. The averaged Dice ratios over 54 ROIs by three registration algorithms before and after integration with our registration framework are listed in Table III . The improvement for all cases is statistically significant ( , two-sample -test). In Fig. 8 , we show the Dice ratio for each ROI, with blue for the original five registration methods on average and pink for the five methods after integrating with our registration framework. Our framework yields a noticeable increase in overlap ratios for most of ROIs."}, {"section_title": "C. Generalization", "text": "In all previous experiments, we all used a subgroup of the same data set for training and performed testing based on the remaining data. However, anatomical structures might differ from one group to another. For example, the images of elderly brains differ from those of younger brains because of aging. Here, we further evaluate the generalization performance of our proposed learning-based framework by training the correlation model using one data set and applying to it to another data set. Specifically, we used 40 images from the LONI LPBA data set for training and 16 images from the NIREP (with 32 Fig. 8 . Mean overlap ratios of 54 manually delineated ROIs given by five registration methods (i.e., HAMMER, diffeomorphic demons, FNIRT, ART, and SyN) on average with and without our framework. The LONI LPBA40 data set was used. manually labeled ROIs) for testing. We randomly chose one subject from the LONI data set as the template and employed HAMMER to generate the deformation fields for training. The images from NIREP are used for testing the registration performance. After registration, we computed the mean overlap ratio of ROIs between the template and each of the 16 aligned NIREP images. The averaged overlap ratio of each ROI of the 16 aligned images is shown in Fig. 9 . The overall Dice ratios in all 32 ROIs are 66.8% by the original HAMMER, and they are 67.4% after integration with our framework, indicating that the two methods have comparable accuracy while taking less computation time (see Section III-D).\nA similar experiment has been conducted using RABBIT reported in [36] , which achieves about 68% overlap ratio for NIREP data. However, the difference between their experiment and ours is that, in their experiment, all training images (Open Access Series of Imaging Studies database [50] ) are aligned to a template selected from the test data set (NIREP database). For comparison, we also performed the same experiment using our method and achieved 69.1%, which is better than RABBIT's result. Moreover, the computation time is also reduced by 25% compared to RABBIT (see Section III-C). In these experiments, it is worth noting that, although the training and testing sets come from different sources, the proposed method is still capable of yielding good performance. "}, {"section_title": "D. Speed", "text": "Less computation cost requirement is one of the key advantages of the proposed method. Upon the LONI LPBA40 data set (with a size of 220 220 184) used in the previous section, we compared the average computation cost of our proposed method incorporating HAMMER, diffeomorphic demons, FNIRT, ART, and SyN with that of the original counterpart. In Fig. 10 , we show the execution time for both before and after integration with our method. In addition, achieving better registration accuracy as described in Section III-B, our method takes only 4, 1.05, 13, 3, and 11 min after integrating HAMMER, diffeomorphic demons, FNIRT, ART, and SyN, respectively, with our framework. Without our framework, the original five methods need 42, 3.2, 40, 9, and 31 min, respectively. This implies a reduction in the computation time by 10-fold, 3-fold, 3-fold, 3-fold, and 2.8-fold for these five methods, respectively. It is worth noting that we used the same set of parameters for the same registration algorithm, with its binary codes downloaded from the respective website. For the prediction of the initial deformation in our method, it only takes 5 s on average. Therefore, the time cost of prediction is almost negligible, as compared to 5 min by RABBIT [36] . RABBIT also reported the computation time by integrating with HAMMER on the same data set, which completes the whole process in 9 min. Compared with nearly 4 min by our method [see Fig. 10(a) ], the computation time is further reduced."}, {"section_title": "IV. CONCLUSION", "text": "A fast deformable brain registration framework using a novel deformation prediction model has been presented. Specifically, regression models are trained to capture the correlations between brain appearances and their deformation coefficients. The learned correlation models are then used to rapidly predict a good initial deformation for any given image under registration. The IT is generated by warping the original template with the estimated initial deformation field. Since the shape difference between the IT and the given image becomes small, many existing registration methods (i.e., HAMMER, diffeomorphic demons, FNIRT, ART, or SyN), when incorporated into our framework, can perform much faster with comparable or slightly better registration performance. It is worth noting that our method can be applied to a wider range of images since it employs a parameter-free statistical model on both images and deformations."}]