[{"section_title": "Summary", "text": "As a growing number of states require kindergarten entry assessments (Stedron & Berger, 2010), more state and district administrators are becoming interested in how their peers use these assessments around the country (Center on Enhancing Early Learning Out comes, 2014; Early Childhood Education Research Alliance, 2012). Given this interest, state administrators participating in Regional Educational Laboratory Northeast & Islands Early Childhood Education Research Alliance generated the idea for this study as a source of information as they implemented plans for statewide assessments. Using nationally representative data from the Early Childhood Longitudinal Study, Kin dergarten Class of -11 (National Center for Education Statistics, 2011a, this study examined how many public schools used kindergarten entry assessments and for what pur poses, what types of public schools used kindergarten entry assessments, and whether the use of kindergarten entry assessments was correlated with student early learning assess ment scores in reading and math in spring of the kindergarten year. Findings from the study include: \u2022 Overall, 73 percent of public schools offering kindergarten classes reported using kindergarten entry assessments. \u2022 The most common purpose of kindergarten entry assessments was individualiz ing instruction, reported by 93 percent of public schools using them. Sixty-five percent of schools using kindergarten entry assessments reported that they used the assessments to identify students needing additional testing for learning prob lems. Schools also reported using the assessments for one or more purposes related to enrollment: to determine class placement (41 percent of schools using kinder garten entry assessments), to advise parents about delayed entry (24 percent), and to determine eligibility for students whose age fell below the cutoff (16 percent). \u2022 Most public schools using kindergarten entry assessments did so for multiple pur poses (80 percent). Fifty percent of schools using the asessments reported both instructional-and enrollment-related purposes; 60 percent used the assessments for both instructional purposes and screening to identify additional testing needs. \u2022 Schools' reported use of kindergarten entry assessments did not have a statistically significant relationship with students' early learning in reading or math in spring of the kindergarten year when the analysis controlled for student and school characteristics. This study provides states and schools with information about the use of kindergarten entry assessments nationwide and offers contextual information to state-level administra tors as they select, develop, and implement these assessments. As an exploratory analy sis, this study describes how schools say they use kindergarten entry assessments, without drawing conclusions about the effects of their use. Future research could examine the rela tionships between the nature and quality of the implementation of these assessments and student outcomes."}, {"section_title": "Contents", "text": ""}, {"section_title": "Summary i", "text": "Why this study? 1 What the study examined 2 What the study found 4 Seventy-three percent of public schools reported using kindergarten entry assessments 4 The use of kindergarten entry assessments was not correlated with school characteristics 4 Individualizing instruction was the most commonly reported purpose among public schools that used kindergarten entry assessments (93 percent), and 80 percent used the assessments for multiple purposes 4 None of the reported purposes of kindergarten entry assessments was correlated with student early learning assessment scores in reading or math in spring of the kindergarten year 5 Implications of the study findings 7 Individualizing instruction remains the most frequently cited purpose of kindergarten entry assessments 7 Schools may need guidance on appropriate uses of kindergarten entry assessments that do not result in denying entry to eligible children 8 Schools may need guidance on selecting and using appropriate instruments for different purposes as part of the kindergarten entry assessment process 8 Future research could examine variation in the fidelity and quality of kindergarten entry assessment implementation"}, {"section_title": "Figures", "text": "1 Individualizing instruction was the most commonly reported purpose among public schools that used kindergarten entry assessments, 2010/11 6 2 Most public schools that used kindergarten entry assessments did so for multiple purposes, 2010/11 6 Tables 1 Characteristics of public schools that did and did not administer kindergarten entry assessments, 2010/11 5 2 Relationships between school purposes of kindergarten entry assessments and student spring early learning assessment scores, 2010/11 7 B1 Measures used in the study B-2 C1 Sample exclusions, kindergarten class of 2010-11 C-1 C2 Student sample: Descriptive statistics, 2010/11 C-3 E1 Fixed effect coefficients for regression of spring early reading assessment score on use of kindergarten entry assessments for any purpose (model A), 2010/11 E-1 E2 Fixed effect coefficients for regression of spring early reading assessment score on use of kindergarten entry assessments for six purposes (model B), 2010/11 E-2 E3 Fixed effect coefficients for regression of spring early math assessment score on use of kindergarten entry assessments for any purpose (model C), 2010/11 E-4 E4 Fixed effect coefficients for regression of spring early math assessment score on use of kindergarten entry assessments for six purposes (model D), 2010/11 E-5 E5 Effect sizes for regression analyses of spring early learning assessment scores on use of kindergarten entry assessments, 2010/11 E-6 E6 Percentage of variance explained by regression analyses of spring early learning assessment scores on use of kindergarten entry assessments, 2010/11 E-7 Why this study? Child development research on the importance of early experiences for later life outcomes has underscored the need for effective early childhood education (Heckman, 2008;Rouse, Brooks-Gunn, & McLanahan, 2005). With the aim of providing high-quality education, many kindergarten programs use assessments at the time of entry to understand what stu dents know and can do. When such assessments are well-planned, appropriately designed, and implemented with fidelity, they can inform teaching and program improvement, and contribute to better student outcomes (Snow & Van Hemel, 2008). As the number of states that require districts to administer kindergarten entry assessments grows (Stedron & Berger, 2010), state and district administrators are interested in how their peers around the country use these assessments (Center on Enhancing Early Learning Outcomes, 2014; Early Childhood Education Research Alliance, 2012). Twenty-one states required some form of kindergarten entry assessment in 2010 (the year in which the data used in this study were collected; Stedron & Berger, 2010). That number had grown to 25 states by 2014 (Stedron & Berger, 2014), an increase of more than a third since 2000 (Saluja, Scott-Little, & Clifford, 2000). At the federal level the 2011 Race to the Top-Early Learning Challenge grant initiative made kindergarten entry assessments a focus area of investment and a competitive priority (U.S. Department of Education, 2011). In 2015 all 20 Race to the Top-Early Learning Challenge grant awardees in Phases 1-3 were piloting or implementing new or revised statewide assessments, with several states collaborating on common tool development (Early Learning Challenge TA Program, 2015). For a definition of kindergarten entry assessments, see box 1. With the aim of providing highquality education, many kindergarten programs use assessments at the time of entry to understand what students know and can do Box 1. What are kindergarten entry assessments? Historically, schools have administered many types of assessments to children at the start of kindergarten. The term \"kindergarten entry assessment\" (sometimes used interchangeably with the term \"kindergarten readiness assessment\") has been used to refer to a range of assessment activities, including formal standardized cognitive assessments, observational assessments of socioemotional skills, detailed diagnostic assessments of individual children's strengths and weaknesses in several areas, and initial screenings for potential developmental or learning disabilities (Saluja et al., 2000). Early childhood educators now recommend that kindergarten entry assessments be appropriate in content and format for young children, that they encompass multiple domains important to learning, and that they not be used to bar access to school. Some states provide one or more assessment instruments to districts, but only seven states required districts to use a specific instrument as of 2012 (Center on Enhancing Learning Outcomes, 2014). In the initial phase of the Race to the Top-Early Learning Challenge application, launched in 2011, the U.S. Department of Education used recommendations from early childhood educators to define kindergarten entry assess ment as an assessment that \"(a) is administered to children during the first few months of their admission into kin dergarten; (b) covers all essential domains of school readiness; (c) is used in conformance with the recommendations of the National Research Council reports on early childhood; and (d) is valid and reliable for its intended purposes and for the target populations and aligned to the Early Learning and Development Standards\" (U.S. Department of Education, 2011, p, 17). As defined by the Race to the Top-Early Learning Challenge Notice Inviting Applications, the domains of school readiness that may be tested include language and literacy development, cognition and general knowledge (including early math and early scientific development), approaches toward learning, physical well-being and motor development (including adaptive skills), and social and emotional development (U.S. Department of Educa tion, 2011). Schools represented in the data for this study, which were collected in spring 2011 prior to the first Race to the Top-Early Learning Challenge completion, may have used other definitions of kindergarten entry assessments. State-level decisionmakers participating in the Regional Educational Laboratory North east & Islands Early Childhood Education Research Alliance have prioritized research that examines components of comprehensive early childhood assessment systems. Tasked with choosing, developing, and implementing statewide kindergarten entry assessments, administrators in Early Childhood Education Research Alliance member states generated the idea for this study as a source of information as they implemented plans for statewide assessments, both with and without Race to the Top-Early Learning Challenge support. In particular, state administrators wanted to know why schools used kindergarten entry assessments (especially for two common purposes-informing instruction and identifying the need for additional testing related to learning problems), whether using kindergarten entry assessments in general or for specific purposes was associated with student outcomes in math and reading, and the extent to which schools administered kindergarten entry assessments for more than one purpose. Best practice guidelines for early childhood education assert the value of using data to guide instructional practice in general (Bredekamp & Copple, 2009;Hamilton et al., 2009), yet there is limited empirical research linking the use of kindergarten entry assess ment data with student learning outcomes (see appendix A for a brief literature review). This study seeks to contribute to the limited literature on the relationship between use of kindergarten entry assessments and student early learning outcomes. In addition, it aims to provide important information to decisionmakers in the field about the landscape of the use of these assessments, based on the most recent available nationally representative sample of U.S. public schools, collected in 2010/11."}, {"section_title": "What the study examined", "text": "The study addressed three research questions: 1. What percentage of public schools that offer kindergarten classes administer a kin dergarten entry assessment to children, and how does the percentage vary by school characteristics? 2. How are kindergarten entry assessments used in education decisionmaking at public schools, and how does the practice vary by school characteristics? 3. Is the use of kindergarten entry assessments-overall and for specific purposescorrelated with student assessment scores in early reading and math in spring of the kindergarten year? The study used data on public school students from the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, whose sample is nationally representative of schools offering kindergarten and students enrolled in kindergarten in fall 2010. The Early Child hood Longitudinal Study, which is conducted under the auspices of the National Center for Education Statistics, includes a survey of school administrators that asks them to report whether their school used kindergarten entry assessments for each of six purposes (Nation al Center for Education Statistics, 2011b). See appendix B for a description of all measures used in the analyses. This study seeks to contribute to the limited literature on the relationship between use of kindergarten entry assessments and student early learning outcomes and to provide important information to decisionmakers in the field about the landscape of the use of these assessments The first and second research questions were addressed using descriptive statistics. The third question was addressed using correlational multilevel regression analyses (see box 2 and appendixes C and D for more detail about the sample and methods). Although it is not possible to establish a causal link between use of kindergarten entry assessments and Box 2. Data and methods The Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, follows a nationally representative sample of 18,170 children at 1,310 schools and centers nationwide who were enrolled in kindergarten in fall 2010 (Tou rangeau et al., 2014). 1 Data on child development, early learning, and school progress, as well as school character istics, are collected from school enrollment records; surveys of parents, teachers, and school administrators; and early reading and math assessments administered as part of the study. The panel of students was followed through the 2015/16 school year. This analysis used a subset of the sample, limited to students attending public schools (including public charter schools), and excluding the 11 percent of public schools that did not provide information about use of kindergarten entry assessments, for a total of 9,370 students attending 640 schools. Results cannot be generalized beyond public schools offering kindergarten and their students (appendix C). The sample was not designed to be representative at the state level. To address the first and second research questions, the number and percentage of schools using kindergarten entry assessments overall and for six purposes reported by school administrators on a survey were estimated. The six purposes were listed in the survey as follows (National Center for Education Statistics, 2011b): \u2022 \"To determine eligibility for enrollment when a child is below the cutoff age for kindergarten.\" \u2022 \"To determine children's class placements.\" \u2022 \"To identify children who may need additional testing (for example, for a learning problem).\" \u2022 \"To help teachers individualize instruction.\" \u2022 \"To support a recommendation that a child delay entry for an additional year.\" \u2022 \"Other uses.\" The survey stated the six purposes as worded in the bullets above without additional description and did not ask about any other forms of assessment used with kindergarten students later in the school year. Use of kindergarten entry assessments overall, as well as use for each specific purpose, was compared and sta tistically tested for differences related to the following school characteristics: urban, rural, or other location; enrollment size; whether the school offered full-day kindergarten; cutoff age for kindergarten enrollment; percentage of students who are racial/ethnic minority students; and percentage of students eligible for the federal school lunch program. To address the third research question, a series of multilevel regression models were estimated to test whether the use of kindergarten entry assessments (overall and for the six specific purposes) was associated with scores on early learning assessments in reading and math administered to all students as part of the Early Childhood Longitu dinal Study, Kindergarten Class of 2010-11, in the spring of the kindergarten year, after the analysis controlled for the school characteristics listed previously as well as several student characteristics (prior reading and math scores on early learning assessments administered in the fall, age at time of these fall early learning assessments, age difference between fall and spring early learning assessment administrations, gender, race/ethnicity, family socio economic status, English learner status, and whether the student was a first-time kindergarten student). Separate models were used to examine these relationships for reading and math. Combinations of kindergarten entry assess ment purposes (for example, both for individualizing instruction and for identifying testing needs) were tested as well by entering terms representing the interaction between two purposes. In addition, interactions were tested between use of kindergarten entry assessments and student and school characteristics, to probe for any differences in the relationship between use of kindergarten entry assessments and learning based on those characteristics. See appendix B for a description of the measures used in the analyses, appendix C for additional detail about the sample exclusions and missing data, and appendix D for an explanation of analytic methods used. student outcomes using these observational data, the analyses were intended to identi fy relationships that might be explored further with other datasets using a more rigorous experimental design."}, {"section_title": "What the study found", "text": "For the first and second research questions, descriptive analyses illustrated the character istics of public schools that reported using kindergarten entry assessments, overall and for specific purposes. The correlational analyses examined the relationships between use of kindergarten entry assessments and student early learning in reading and math. Seventy-three percent of public schools reported using kindergarten entry assessments The finding that 73 percent of schools in the study sample use kindergarten entry assess ments corroborates the widespread implementation of entry assessment policies reported in state administrator surveys (Shepard, Taylor, & Kagan, 1996;Stedron & Berger, 2010). However, by 2010/11 the proportion of public schools using kindergarten entry assessments had not increased much from the 69 percent reported in the Early Childhood Longitudi nal Study, Kindergarten Class of 1998-99 (Prakash, West, & Denton, 2003). The use of kindergarten entry assessments was not correlated with school characteristics Schools using kindergarten entry assessments had characteristics similar to those of schools that did not (table 1). No statistically significant differences in overall use of the assessments were found based on school characteristics. This finding indicates that the widespread adoption of kindergarten entry assessments was happening across diverse dis trict environments-urban and rural, higher and lower income-and was not limited to schools in any particular type of environment. Individualizing instruction was the most commonly reported purpose among public schools that used kindergarten entry assessments (93 percent), and 80 percent used the assessments for multiple purposes Almost all public schools that administered kindergarten entry assessments reported using them to individualize instruction (93 percent). Identifying students who needed additional testing was the second most commonly selected purpose (65 percent). Users of kindergar ten entry assessments also said that they used them for one or more purposes related to enrollment: to determine class placement (41 percent), to advise parents about delayed entry (24 percent), and to determine eligibility for students whose age fell below the cutoff (16 percent; figure 1). Most public schools used kindergarten entry assessments for multiple purposes (figure 2). Eighty percent of schools using the assessments reported more than one purpose: 61 percent said that they used assessments for two or three purposes, and 19 percent said that they used assessments for four to six purposes. Users of kindergarten entry assessments combined the most common purpose-individualizing instruction-with other goals: 60 percent reported both identifying testing needs and individualizing instruction, and 50 percent reported using assessments for both enrollment decisionmaking and individu alizing instruction. Note: Percentages were estimated using sampling weights and accounting for the complex sampling struc ture of the survey (see appendix D). Unweighted sample size is reported, rounded to the nearest 10 to avoid disclosure of confidential information. Public schools not providing information about use of kindergarten entry assessments (10.5 percent of public schools) were excluded. The associations between each school charac teristic and the use of the assessments were not statistically significant at the p < .05 level. Source: Authors' analysis based on data from the National Center for Education Statistics Early Childhood Longitudinal Study, Kindergarten Class of 2010-11. None of the reported purposes of kindergarten entry assessments was correlated with student early learning assessment scores in reading or math in spring of the kindergarten year After the analysis controlled for student characteristics such as race/ethnicity and family socio economic status and school characteristics such as enrollment size and urban or rural location, use of kindergarten entry assessments overall was not correlated with students' spring early learning scores in either reading or math on an assessment administered as part of the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11. Furthermore, none of the six specific purposes of the entry assessments was correlated with these student outcomes. The size of the average difference in scores between students attending schools that used kinder garten entry assessments and other students was small-5 percent of a standard deviation or Percent Note: n = 470. Percentages were estimated using sampling weights and accounting for the complex sampling structure of the survey (see appendix D). Unweighted sample size is reported, rounded to the nearest 10 to avoid disclosure of confidential information. Public schools not providing information about use of kindergarten entry assessments (10.5 percent) were excluded. Respondents could select more than one purpose.  Percent Note: n = 470. Percentages were estimated using sampling weights and accounting for the complex sampling structure of the survey (see appendix D). Unweighted sample size is reported, rounded to the nearest 10 to avoid disclosure of confidential information. Public schools not providing information about use of kindergarten entry assessments (10.5 percent) were excluded. a. Enrollment decisions include determining class placement, advising delayed entry, and determining eligibil ity below cutoff age. Source: Authors' analysis based on data from the National Center for Education Statistics Early Childhood Longitudinal Study, Kindergarten Class of 2010-11. less-and was not statistically significant for use of kindergarten entry assessments overall or for any specific purpose (table 2). As a point of reference, the academic achievement gap between children in the top and bottom 10 percent of the income distribution has been esti mated at approximately 125 percent of a standard deviation (Reardon, 2011). Combinations of purposes (for example, for individualizing instruction as well as for identi fying testing needs) did not demonstrate a correlation with student outcomes. No differenc es in the relationships between each purpose and student outcomes were found to be related to students and schools that had different characteristics-that is, no statistically significant interactions between student or school characteristics and purpose were identified."}, {"section_title": "Implications of the study findings", "text": "The findings from this study indicate that nearly three-quarters of public schools use kin dergarten entry assessments. The study gives administrators a high-level view of how their peers across the country report using the assessments. However, several questions remain for further research regarding the validity and quality of kindergarten entry assessments and the contexts in which the assessments are used. Individualizing instruction remains the most frequently cited purpose of kindergarten entry assessments This study confirms individualizing instruction as the most commonly stated purpose of entry assessment, as previously reported by states and schools (Prakash et al., 2003;  Note: This table displays the standardized coefficients from four multilevel regressions of student spring early learning assessment scores on use of kindergarten entry assessments and a set of control variables. The outcome in models A and B is spring early reading assessment score; the outcome in models C and D is spring early math assessment score. Models A and C compare schools that use kindergarten entry assessments for any purpose with schools that do not use kindergarten entry assessments. Models B and D include six indica tor variables for six purposes. Coefficients are expressed in standard deviation units of the outcome. They are conditional on eight student-level control variables (prior reading and math scores on early learning assessments administered in the fall, age at time of these fall early learning assessments, age difference between fall and spring early learning assessment administrations, gender, race/ethnicity, family socioeconomic status, English learner status, and whether the student was a first-time kindergarten student) and seven school-level control variables (urban, rural, or other location; enrollment size; whether the school offered full-day kindergarten; cutoff age for kindergarten enrollment; average fall early learning assessment score for the sampled students; per centage of students who are racial/ethnic minority students; and percentage of students eligible for the federal school lunch program), not shown in the & Berger, 2010). Although actual practices within schools may vary, at a minimum these findings signal to early childhood education administrators that most schools are pursuing the goal of assessment-informed instruction at the start of the kindergarten year. However, school administrators surveyed as part of the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, may have interpreted \"individualizing instruction\" in different ways. There is no universal consensus among educators around the meaning of the term, and the survey instrument did not provide a definition, nor did it ask about any ongoing assessment taking place after the start of the year. Teachers vary widely in their training in and experience with differentiating instruction, as well as their understanding of the content and teaching methods that are developmentally appropriate for kindergar ten students (Goble, Horm, Atanasov, Williamson, & Choi, 2015;Tomlinson et al., 2003). A future study could examine the guidance and training that schools give teachers for using kindergarten entry assessment results, how teaching practices change in response to assessment data, and how these practices relate to student outcomes. Schools may need guidance on appropriate uses of kindergarten entry assessments that do not result in denying entry to eligible children Delaying kindergarten entry for eligible children has been linked to negative consequenc es for their learning (Bassok & Reardon, 2013), and the Race to the Top-Early Learn ing Challenge grant application cautions against using kindergarten entry assessments to prevent children's entry into kindergarten (U.S. Department of Education, 2011). This study found that 24 percent of schools reported using kindergarten entry assessments to support a recommendation that a child delay entry for an additional year. Although the specific practices at these schools are unknown, when states and districts develop poli cies for using kindergarten entry assessments, they may consider educating schools about appropriate uses of the assessment results during the enrollment process. Schools may need guidance on selecting and using appropriate instruments for different purposes as part of the kindergarten entry assessment process Among public schools that used kindergarten entry assessments, the majority (80 percent) indicated that they did so for two or more purposes. Because school administrators who were surveyed as part of the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, were limited to selecting among six purposes with no explicit definitions or addi tional detail for each purpose, it is not possible to ascertain how schools in the study actu ally used kindergarten entry assessments in their classrooms. The instruments employed, instrument quality, and the fidelity of implementation across schools may have varied. Because most schools are attempting to meet multiple objectives through their use of kin dergarten entry assessments, district and state administrators may want to provide guide lines and training to ensure the appropriate use of assessment instruments. These findings could be further explored by studying the extent to which schools use assessment instruments appropriately. In surveys conducted in the 1980s and 1990s, some state administrators reported making kindergarten entry, placement, and instruction deci sions based on instruments that were designed for a different purpose, such as screening for learning problems or capturing overall school readiness of a cohort of students (Shepard et al., 1996). Assessments designed to take a snapshot of general school readiness may not provide enough detail about a student's specific strengths and needs to inform tailored instruction (Cosner, 2011). Some members of the Early Childhood Education Research Alliance have also observed that some schools in their states rely on a single kindergarten entry assessment, regardless of the range of purposes for which it is used. In the absence of more detailed data in the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, it is not possible to determine the prevalence of such practices. Future research drawing on more specific teacher and school data could investigate which assessment instruments schools use, which domains they assess, and what policies differentiate the use of separate instruments for distinct purposes. Future research could examine variation in the fidelity and quality of kindergarten entry assessment implementation In theory the impact of kindergarten entry assessments on student achievement depends on several components working together successfully. The assessment must provide valid, reliable information about the student's strengths and weaknesses; it must be administered correctly; teachers must interpret the results accurately; teachers must continue to monitor student progress throughout the year to track the rapid, often nonlinear development typical of young children; and teachers must respond to the results of entry and subsequent assessments with appropriate, effective instruction and interventions. In practice schools operate at varying levels of quality in each link in this chain. As states roll out new assessment systems, many educators struggle with putting them into practice (Stedron & Berger, 2010). Early childhood educators report that mastering new technologies, as well as finding the time to administer and use the assessments, can pose barriers (Tumblin, 2011;Zweig, Irwin, Kook, & Cox, 2015). Studies of how teachers actual ly use data in practice have found that when training does not include hands-on practice with administering and interpreting assessments, teachers may simply choose not to use them or may use them incorrectly (O'Connor & Steuerwalt, 2008). Given that implemen tation data are not included in the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, future studies could gather information about the fidelity and quality of kindergarten entry assessment administration, interpretation, and use of data. Further information about the presence or absence of a comprehensive assessment system in each state would provide important context for results According to best practice guidelines in the field, kindergarten entry assessments work best as part of a comprehensive system that includes clearly articulated standards, mea sures of specific content areas within those standards, practices that respond to assessment findings, and monitoring of progress on achieving the standards (Center on Enhancing Early Learning Outcomes, 2014; Snow & Van Hemel, 2008 "}, {"section_title": "Limitations of the study", "text": "These findings should be understood in the context of three limitations. First, because the study design is correlational, not experimental, causal relationships between use of kindergarten entry assessments and student outcomes cannot be inferred. Schools that administer kindergarten entry assessments may differ from those that do not in ways that were not captured in this dataset. If these unmeasured characteristics are also related to student early learning outcomes, the estimates of the relationships between learning and use of kindergarten entry assessments found in this study could be biased. Second, the information available on use of kindergarten entry assessments was limited to self-reports by school administrators and lacked detail on the type of assessment, domains assessed, timing of administration, and extent and type of professional development pro vided to teachers for their use. The respondents may have interpreted the terminology in different ways; for example, \"individualizing instruction\" might mean using a comprehen sive formative assessment system to one administrator or simply creating student ability groups to another. Schools reporting no use of kindergarten entry assessments may never theless use other forms of assessment during the kindergarten year. Finally, 11 percent of public schools were excluded from the analysis because they did not report on whether or how they used kindergarten entry assessments. Although statistical ly similar to excluded schools for most available measures, included schools had smaller enrollments on average (see appendix C for more detail). Furthermore, if excluded schools differ systematically from included schools in ways that could not be measured in this dataset, those differences may introduce bias into the results."}, {"section_title": "Because the study design is correlational, not experimental, causal relationships between use of kindergarten entry assessments and student outcomes cannot be inferred", "text": "This appendix provides an overview of research on kindergarten entry assessments, their purposes, and their effectiveness."}, {"section_title": "Context", "text": "As part of the larger accountability movement in the No Child Left Behind era, states are in various stages of developing early learning guidelines and assessments of early learning (Daily, Burkhauser, & Halle, 2010). These investments reflect the importance of addressing school readiness at an early age as one strategy for closing racial/ethnic and socioeconomic achievement gaps (Heckman, 2008;Reardon, 2011;Rouse, Brooks-Gunn, & McLanahan, 2005). Because poverty places children at risk through a range of mechanisms, includ ing reduced opportunities for cognitive enrichment, exposure to stress, and inadequate nutrition, many lower income students start school at a disadvantage in cognitive and socioemotional development (Barton & Coley, 2009;Dearing & Taylor, 2007;Hart & Risley, 1995;Shonkoff et al., 2012;Yeung, Linver, & Brooks-Gunn, 2002). Recognizing that such gaps at the time of school entry have implications for later academic progress, states have invested in defining readiness, assessing it, and addressing identified needs in early childhood education programs. All 50 states have definitions of school readiness in place (Scott- Little, Kagan, Frelow, & Reid, 2008), and the Common Core State Standards define expectations for kindergarten students in English language arts and math across participating states."}, {"section_title": "Prevalence of kindergarten entry assessments", "text": "Twenty-one states required some form of kindergarten entry assessment in 2010, the year in which the data used in this study were collected (Stedron & Berger, 2010). That number had grown to 25 states by 2014 (Stedron & Berger, 2014), an increase of more than a third since 2000 (Saluja et al., 2000). As a further incentive at the federal level, the 2011 Race to the Top-Early Learning Challenge grant initiative made kindergarten entry assessments a focus area of investment and a competitive priority (U.S. Department of Education, 2011). Regardless of federal and state policy, the practice has been widespread at the school level for more than a decade: Most public schools (69 percent) reported conducting kindergar ten entry assessments in 1999 (Prakash et al., 2003)."}, {"section_title": "Purposes of kindergarten entry assessments", "text": "Purposes of kindergarten entry assessments have changed over time, with an earlier focus on mandatory standardized tests that served as a gate to entry (now deemed developmen tally inappropriate) having gradually given way to diagnostic assessment intended to guide instruction (Saluja et al., 2000). The most common purpose in recent decades has been to inform instruction, cited by 59 percent of public school principals in 1999 (Prakash et al., 2003) and state early childhood administrators in 18 states in 2010 (Stedron & Berger, 2010). Policymakers may use aggregated data from kindergarten entry assessments to gauge statewide school readiness levels, compare readiness among student subgroups, and sub sequently guide policy and resource allocation (Daily et al., 2010). Schools also use the assessments for initial identification of students needing additional testing for learning problems (Prakash et al., 2003). Some schools administer entry assessments before the start of classes to guide decisionmaking during the enrollment process. Although federal grant initiatives and best practice guidelines in the field have discouraged the use of tests to bar children from starting kindergarten because of evidence of negative consequences for chil dren (Bassok & Reardon, 2013; U.S. Department of Education, 2011), entry assessments may be used to inform decisions about early entry for children younger than the school's cutoff age or in response to a parent's request for delayed entry. Finally, some schools use assessment results to inform class placement (Prakash et al., 2003). However, little is known about practices at the school level in detail, particularly how schools and teachers respond to assessment results in their placement, screening, and instructional processes. If used as part of a comprehensive system, entry assessments can provide teachers with diagnostic information about each child's strengths and needs for specific content areas within a set of readiness standards and lead to more individualized instruction responsive to those student profiles (Snow & Van Hemel, 2008). Likewise, early identification of students for additional testing can connect students who have learning dis abilities with appropriate interventions. Research evidence is limited on how well schools implement the full process from administration of assessments to programmatic response and on how widely they conduct those activities within a coherent framework. Survey research in the 1980s and 1990s pointed to widespread use of kindergarten entry assess ments in ways that ran counter to their designs and intended purposes. A 1988 nationwide survey of state early childhood administrators estimated that as many as 10-50 percent of children experienced delayed entry based on readiness test scores (Gnezda, Garduque, & Schultz, 1991). For example, schools might use a single high-stakes assessment to make decisions about whether a student could start kindergarten or use assessments intended for learning disability screening and service referral to make decisions about school entry or placement. Subsequent research in the mid-1990s found a reduced incidence of such practices (for example, only 13 states mandated screening of all incoming kindergarten students) but still found occasional reports of misuse (Shepard et al., 1996). Furthermore, teachers face barriers to using entry assessments and other student data for instruction. A study of data use by teachers in Chicago elementary schools found that assessments of a broad readiness domain, rather than specific content areas, made the results too general for the purpose of instruction (Cosner, 2011). Logistical barriers also play a role; a qualitative study of use of student data in urban preschools found that unre liable technology and lack of time to administer assessments posed additional barriers for educators (Zweig et al., 2015). Likewise, early childhood educators in Massachusetts listed time to conduct assessments as a very large challenge for using a kindergarten entry assessment for instruction (Tumblin, 2011). Appropriate professional development also is essential; surveys of New York City K-3 teachers implementing an early literacy assessment indicated that the training provided was inadequate to prepare them for using the instru ment correctly and lacked the opportunities for hands-on practice that teachers wanted (O'Connor & Steuerwalt, 2008)."}, {"section_title": "The effectiveness of kindergarten entry assessments", "text": "Schools implement kindergarten entry assessments on the assumption that having more information about students when they enter school will facilitate improved student out comes. In theory if educators gather diagnostic information about each student's strengths and needs, they can use it to differentiate instruction and thereby improve student outcomes. Likewise, early identification of learning difficulties allows schools to connect students with needed services. Grounded in this understanding of assessment, best practice guidelines for early childhood education assert the value of using data to guide instructional practice (Bredekamp & Copple, 2009;Hamilton et al., 2009). Research has demonstrated links between teacher use of data and elementary student achievement (Faria et al., 2012). In the kindergarten context a randomized controlled trial found superior learning outcomes among students of kindergarten teachers implementing an individualized reading instruction program based on progress monitoring of assessed student performance throughout the year, com pared with teachers who did not use the program (Al Otaiba et al., 2011). However, little research was identified that explored the relationship between using data specifically from kindergarten entry assessments and student learning outcomes. One exception was a ran domized controlled trial analyzing the effect of screening children for reading difficulties in the fall at entry rather than later in the year, which found no evidence of a benefit to earlier assessment (Santi, York, Foorman, & Francis, 2009). The following measures were used in the descriptive and correlational analyses."}, {"section_title": "Outcome", "text": "As part of the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, data collection, a direct cognitive assessment of early reading and math skills was administered to kindergarten students in the fall and spring. The reading domains assessed included basic skills such as letter recognition and print familiarity, vocabulary knowledge, and reading comprehension. In math the domains spanned conceptual knowledge, procedur al knowledge, and problem-solving, including specific areas such as number sense, spatial sense, and measurement. The assessment consisted of two stages, so that a subset of assess ment items could be targeted to the student's level of ability. One scale score was derived for reading, and one for math, using item response theory-a method that uses the pattern of students' responses to estimate the probability of a correct response on each item, in relation to the item's difficulty and discrimination levels, and adjusted for the possibility of guessing. This method allows for different sets of items to be administered to different students. Scale scores ranged from 0 to 83 in reading and 0 to 75 in math. See Najarian, Tourangeau, Nord, and Wallner-Allen (forthcoming) for more detail."}, {"section_title": "Use of kindergarten entry assessments", "text": "The main predictor of interest, use of kindergarten entry assessments, was measured by school administrators' responses to a survey administered in spring 2011. Administrators were asked to respond \"yes\" or \"no\" indicating whether their schools used kindergarten entry assessments for each of six purposes (National Center for Education Statistics, 2011b): \u2022 \"To determine eligibility for enrollment when a child is below the cutoff age for kindergarten.\" \u2022 \"To determine children's class placements.\" \u2022 \"To identify children who may need additional testing (for example, for a learning problem).\" \u2022 \"To help teachers individualize instruction.\" \u2022 \"To support a recommendation that a child delay entry for an additional year.\" \u2022 \"Other uses.\" Because the survey instrument did not provide respondents with any further definition of these terms, their individual interpretations of this set of items may have varied."}, {"section_title": "Covariates", "text": "Covariates for the correlational analyses were selected based on the research literature about factors associated with student achievement in the kindergarten and elementary school years. Student characteristics. Score on the kindergarten fall early learning reading or math assessment (corresponding to the subject area of the outcome in the model) was included to account for pre-existing differences in cognitive skills at the time of kindergarten entry. Age at the time of the fall early learning reading and math assessment and the difference in age from the fall to spring early learning assessment administrations were included to control for differences in achievement associated with development over time and addi tional exposure to schooling (Murnane, Willett, Bub, & McCartney, 2006). The follow ing student characteristics were included based on their documented relationship with learning outcomes: gender (Chatterji, 2006;Robinson & Lubienski, 2011), race/ethnicity (Elliott, Jung, Kim, & Chowa, 2010;Zhan, 2006), family socioeconomic status (Berliner, 2006;Chatterji, 2006;Sirin, 2005;Yeung et al., 2002), English learner status (Kieffer, 2008;Reardon & Galindo, 2007), and whether the student was a first-time kindergarten student (West, Meek, & Hurst, 2000)."}, {"section_title": "School characteristics.", "text": "The following school characteristics were included based on their known association with student achievement: location in urban, rural, or suburban or town areas (Durham & Smith, 2006); total enrollment size (Prakash et al., 2003); whether full-day kindergarten was offered (Cannon, Jacknowitz, & Painter, 2011;Cooper, Allen, Patall, & Dent, 2010); cutoff age for kindergarten enrollment (Murnane et al., 2006); aggregate fall early learning reading or math scores (corresponding to the subject area of the outcome in the model) for the analytic sample of students; percentage of students who are racial/ethnic minority students; and student body poverty level as measured by the percentage of students eligible for the federal school lunch program (Greenman, Bodovski, & Reed, 2011;Hoffer & Shagle, 2012;Kieffer, 2008). For the details of the calculations and coding for each measure described in this report, see table B1. Age difference between fall and Calculated from student age at time of spring early learning assessment administration and spring early learning assessments student age at time of fall early learning assessment (months)"}, {"section_title": "Female", "text": "Student gender: 1 = female; 0 = male Race/ethnicity Student race/ethnicity: set of dummy variables representing Hispanic, Black, Asian, and other race/ethnicity, with White as the reference category. Hispanic includes Latino and refers to students of any race. Black includes African American, and Asian includes Native Hawaiian and Other Pacific Islander. Other race/ethnicity includes more than one race, American Indian, and Alaska Native. Family socioeconomic status Continuous measure representing student's household socioeconomic status, derived from responses to parent interviews in fall 2010 and spring 2011. Composite provided in the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, dataset, computed from parents' education levels, parents' occupational prestige scores, and household income, expressed as a z-score (deviation from the weighted mean divided by the standard deviation).  "}, {"section_title": "English learner", "text": ""}, {"section_title": "School level", "text": "Use of kindergarten entry assessments The school administrator survey presented an item asking, \"Are any children given a readiness or placement test before or shortly after entering kindergarten?\" (yes/no). Schools responding \"yes\" were then presented with a set of six yes/no items asking about five specific purposes for using kindergarten entry assessments and an \"other\" category: to determine eligibility for enrollment when a child is below the cutoff age for kindergarten, to determine children's class placements, to identify children who may need additional testing (for example, for a learning problem), to help teachers individualize instruction, and to support a recommendation that a child delay entry for an additional year. Respondents could select more than one purpose. In this study six indicator variables represented responses to each of these six purposes (1 = yes; 0 = no). If the respondent indicated that the school did not use kindergarten entry assessments, all six indicator variables were coded as \"no.\" If the respondent indicated that the school used kindergarten entry assessments and selected at least one purpose of kindergarten entry assessments but did not respond to one or more of the other specific purposes, the missing responses were coded as \"no.\" If the respondent skipped the initial question about use of kindergarten entry assessments or if the respondent indicated that the school used kindergarten entry assessments but all six indicator variables were missing, the school was excluded from the study. In total, 11 percent of schools were excluded (see appendix C). Set of dummy variables representing 150-299 students, 300-499 students, 500-749 students, and 750 students and above, with reference category less than 150 students Offers full-day kindergarten Calculated from administrator survey question detailing the number of full-day kindergarten classes offered: 1 = yes; 0 = no Cutoff age for kindergarten Calculated from cutoff date to turn five and first day of school year provided in administrator questionnaire. As noted in the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, technical manual (Tourangeau et al., 2012), some respondents appeared to answer the question as if it had asked for earliest allowed birth date; these responses were re-coded to the corresponding turning-five date. Set of dummy variables representing 56-58 months and 59 months or older, with younger than 56 months as the reference category. Some states establish a statewide cutoff age, whereas individual districts set enrollment age policies in others. Mean fall early learning scores in Calculated from the sample of students attending a given school included in this study, using reading and in math student sampling weight Percentage of students who are From administrator survey racial/ethnic minority students"}, {"section_title": "Percentage of students eligible for", "text": "Calculated by adding percentages reported in response to two separate questions on the the federal school lunch program school administrator survey listing the percentage of students eligible for either free or reduced-price lunch under the federal school lunch program. If the total percentage was greater than 100, it was coded as 100. Source: Original measures taken from Early Childhood Longitudinal Study, Kindergarten Class of 2010-11. This appendix describes the criteria used to select the analytic sample, the procedures used to address missing data, and descriptive statistics of the resulting sample."}, {"section_title": "Exclusions", "text": "Some students and schools were excluded from the analytic sample (table C1). Schools and their associated students were excluded if they were private or if they did not report information about purposes of kindergarten entry assessments in the spring 2011 admin istrator survey (see discussion of missing data in the section that follows). Students were also excluded if they changed schools between fall 2010, when a kindergarten entry assess ment could have been administered, and spring 2011, when data about use of kindergarten entry assessments were collected via the administrator survey. The sampling weight used for analyses (W4C4P_20), which adjusts for the probability of selection within the complex stratified sampling design, as well as for nonresponse and oversampling of certain pop ulations, had a zero value for some students, meaning that they were de facto excluded from analyses. Likewise, only schools with a nonzero school sampling weight (W2SCH0) were included. Table C1 refers to exclusions from the samples of students and schools with nonzero weights. Each row represents the additional cases excluded after the prior row's exclusions. Although the full Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, base-year sample of schools is representative of the population of schools nationwide that offer kindergarten, the analytic sample used in this study was limited to public schools that provided information about use of kindergarten entry assessments. Thus, results can be generalized only to schools with those characteristics. Included public schools differed from excluded schools in that they had significantly smaller enrollments (described in the next section). Attended school without data on use of kindergarten entry assessments 1,110 10.5 Changed schools in spring 2011 120 1.3 Note: All counts have been rounded to the nearest 10 to avoid disclosure of confidential information. Source: Authors' analysis based on data from the National Center for Education Statistics Early Childhood Longitudinal Study, Kindergarten Class of 2010-11."}, {"section_title": "Missing data", "text": "Data were missing at the school and student levels for some measures used in the study. School level. Eleven percent of public schools did not report on the ways they used kinder garten entry assessments (see table C1). Schools that reported on use of kindergarten entry assessments were significantly smaller on average than nonreporting schools (76 percent with enrollment of 300 or more, compared with 97 percent for nonreporting schools). Although reporting schools also had a higher percentage of racial/ethnic minority students (43 percent versus 37 percent) and a higher percentage were in a rural location (32 percent versus 28 percent), the differences were not statistically significant. Multiple imputation might be a preferable option for this level of missing data in some circumstances; however, the available school-level measures were not predictive of use of kindergarten entry assess ments overall, nor of specific purposes of kindergarten entry assessment use. Most school characteristics available in the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, are structural or organizational, not indicative of school practices and poli cies such as use of assessments. Furthermore, more than half of the schools not reporting on use of kindergarten entry assessments were also missing the entirety of the adminis trator questionnaire and the teacher questionnaires, further reducing the relevant avail able covariates. Because of the lack of viable covariates for imputation and because use of kindergarten entry assessments was the primary predictor of interest, the schools missing these data were excluded from analysis. Some public schools not excluded based on availability of kindergarten entry assessment data were missing data for one or more of three covariates: offering full-day kindergarten (8 percent of remaining schools); urban, rural, or other location (1 percent); and cutoff age for kindergarten enrollment (7 percent). To produce plausible predicted values for missing information while preserving variability, multiple imputation was used (Peugh & Enders, 2004). Five imputed datasets were generated by fully conditional specification in SPSS v. 19 (IBM Corp., 2010). The covariates for the imputation models were: \u2022 All school-level covariates used in the regression models. \u2022 School means of all student-level covariates used in the regression models. \u2022 Auxiliary variables, selected because they were significantly correlated with one or more of the three measures to be imputed: \u2022 Mean student age on first day of school. \u2022 Percentage of students with a learning disability or other type of disability. \u2022 Percentage of students who took the fall early learning assessments in English rather than in Spanish or in a shorter version for non-native English speakers of other languages. \u2022 Percentage of English learner students as reported on the administrator survey. \u2022 School district poverty level. \u2022 Whether the school offered prekindergarten. \u2022 Whether the school operated year-round. \u2022 School census region. Finally, terms representing the interactions between use of kindergarten entry assessments and each school characteristic were included. Because the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, data were collected using a stratified multistage random sampling design, descriptive statistics and associated standard errors were estimated taking this structure into account. For this purpose point estimates and standard errors were estimated using Taylor series linearization in the Complex Samples function of SPSS v.19 (IBM Corp., 2010), using the recommend ed sampling weight (W4C4P_20 for student-level variables and W2SCH0 for school-level variables) and associated indicators of strata and primary sampling unit (Tourangeau et al., 2014). Differences between schools that did and did not use kindergarten entry assess ments were tested by performing a series of logistic regressions of use of kindergarten entry assessments on each school-level variable one at a time in the Complex Samples function and evaluating the significance of the t-statistic for the resulting regression coefficient."}, {"section_title": "Hierarchical linear model estimation", "text": "The relationship between use of kindergarten entry assessments and student achievement was estimated using hierarchical linear modeling. The two-level regression models reflect ed the nested structure of students within schools and estimated standard errors that took into account the dependency among students sharing the same school context (Rauden bush & Bryk, 2002). In addition, the school-level sampling weight provided in the Early Childhood Longitudinal Study, Kindergarten Class of 2010-11, dataset was applied at the school level, as recommended in the technical manual (Tourangeau et al., 2012) for multi level modeling of base-year data, to account for the probabilities of selection of schools within the complex sampling structure, as well as for school nonresponse. The proportion of variance in the outcome measures attributable to between-school differences, measured by the intraclass correlation coefficient, was 0.17 for early reading and 0.18 for early math, indicating that multilevel modeling was justified. Each categorical variable was represented by a set of dummy variables and entered in the models uncentered, for clarity of interpretation of the regression coefficients; continuous variables were grand mean-centered. Thus, the intercept can be interpreted as the expect ed outcome when all variables have a value of zero, meaning the reference group for cate gorical variables and the grand mean for continuous variables. The model equations were as follows: Level 1: where Spring Score ij is the predicted outcome (reading or math score on the spring 2011 early learning assessment) for student i in school j, school intercept \u03b2 0j is the adjusted mean for school j assuming a value of zero for all student covariates, \u03b2 kj is a vector of regression coefficients for the set of K student characteristics, and r ij is the random component for student i in school j. Level 2: \u03b2 kj = \u03b3 k0 for k = 1\u2026K. In the level-2 equation for the school j intercept \u03b2 0j , \u03b3 00 is the predicted average spring score for a school with a value of zero for all purposes of kindergarten entry assessments and other school characteristics, \u03b3 lj is a vector of regression coefficients representing the relationships between L purposes of kindergarten entry assessments and the mean student outcome, \u03b3 mj is a vector of regression coefficients representing the relationships between M school characteristics and the outcome, and u 0j is the random component for school j. The slope for each student-level characteristic \u03b2 kj was fixed unless it met the criteria to vary randomly across schools. Four separate models were estimated. Models A and B specified early reading as the outcome, and models C and D specified early math as the outcome. In models A and C use of kindergarten entry assessments for any purpose was represented by a dummy variable. In models B and D, specific purposes of kindergarten entry assessments were represent ed by six indicator variables signifying that the school used assessments to individualize instruction, to identify additional testing needs, to determine children's class placements, to support a recommendation that a child delay entry for an additional year, to determine eligibility for enrollment when a child is below the cutoff age for kindergarten, and for \"other\" uses. These indicators were not mutually exclusive. To build the regression models the following process was followed (McCoach, 2010;Raudenbush & Bryk, 2002). Student-level covariates were entered first. For each covari ate with a statistically significant relationship to the outcome, the slope coefficient was allowed to vary randomly across schools, one at a time. If the slope's reliability was at least 0.05 and its variance was statistically significant at p = .05, indicating that a reliable estimate could be obtained and that adequate variance existed to be modeled, it remained freely estimated in the model. In both the reading and math models the slope for fall early learning assessment score in the corresponding subject area met the criteria and was allowed to vary randomly. All other slopes were fixed. The school-level covariates were then entered. To test whether use of kindergarten entry assessments predicted differences in student growth rates, a cross-level interaction between each kindergarten entry assess ment use indicator and the randomly varying fall score slope was tested in each model. However, no cross-level interaction with use of kindergarten entry assessments was statisti cally significant for either reading or math. In addition, interactions between variables on use of kindergarten entry assessments and statistically significant student-and school-level covariates were tested, but none was significant. Regression analyses were performed separately on each of the five datasets containing imputed school values, and pooled estimates of the fixed effects coefficients and their standard errors were calculated across the five sets of results (Little & Rubin, 2002). The imputed values for categorical variables were entered in the regression analyses without rounding (values other than 0 and 1 were allowed) to maximize bias reduction (Graham, 2009)."}, {"section_title": "Calculation of standardized coefficients", "text": "Standardized versions of the regression coefficients were calculated to facilitate more meaningful interpretation. For categorical predictors the standardized version was calcu lated by dividing the coefficient by the standard deviation of the outcome variable:"}, {"section_title": "Regression coefficient Standardized coefficient = Outcome variable standard deviation", "text": "For continuous predictors the coefficient was also multiplied by the standard deviation of the covariate: "}, {"section_title": "Sensitivity analyses", "text": "To assess the sensitivity of the results to the model specification, a series of alternative specifications were tested: \u2022 Natural-log transformation of the fall and spring early reading assessment scores: an examination of histograms and scatterplots of the reading score variables iden tified a slight positive skew and a curved rather than linear relationship between fall and spring scores. \u2022 Grand mean-centering all dummy variables representing categorical student and school characteristics, instead of entering them uncentered. \u2022 Retaining only the statistically significant student-and school-level covariates. None of these alternatives produced differences in the direction or statistical significance level of the regression coefficients for the overall and specific uses of kindergarten entry assessments. In addition, to examine the robustness of the relationships between use of kindergarten entry assessments and spring scores to misspecification of the school-level covariates, models with more limited sets of controls were estimated: \u2022 Student-level covariates only. \u2022 Student-level covariates, plus only two school-level covariates with well-estab lished relationships to achievement: percentage of students eligible for the federal school lunch program and aggregate fall scores. The kindergarten entry assessment regression coefficients in these alternative specifica tions exhibited the same direction and lack of statistical significance as the full covariate models. Finally, the joint significance of the six purposes of kindergarten entry assessment was tested by performing a chi-square test of the change in deviance, comparing the models with the six indicators (models B and D) against models with the six indicators removed but otherwise specified in the same way. The model fit, as indicated by the deviance sta tistic, was not significantly different with or without the six kindergarten entry assessment indicators for reading or math outcomes.      "}, {"section_title": "E-5", "text": "Effect size for use of kindergarten entry assessments An effect size expresses the magnitude of a relationship in more easily interpretable terms that can be more readily compared across studies than an unstandardized coefficient. To represent the effect size for using kindergarten entry assessments, Hedge's g was calculated from the regression coefficients for each variable on use of kindergarten entry assessments. The statistic was calculated as follows (What Works Clearinghouse, 2011): The difference between the regression-adjusted mean outcomes of group i (students at schools that use kindergarten entry assessments) and group c (students at schools that do not use kindergarten entry assessments) is expressed in units of the pooled within-group standard deviation of the student-level outcome, and multiplied by a bias correction factor related to total sample size N: \u03c9 = [1 -3/(4N -9)]. Effect sizes are summarized in table E5. For each coefficient in each model, statistical tests were conducted for violations of the assumption of equal variances in the intervention and comparison groups. In cases where unequal variances were found, the effect size was calculated using the variance of the com parison group instead of the pooled variance. a. Assumption of equal variances in the two groups was violated; effect size calculated in units of the compari son group standard deviation instead of pooled standard deviation. Source: Authors' analysis based on data from the National Center for Education Statistics Early Childhood Longitudinal Study, Kindergarten Class of 2010-11."}, {"section_title": "E-6", "text": "Variance explained The models each explained more than two-thirds of total variance in the outcomes, but school-level measures alone accounted for one-tenth or less of between-school variance (table E6). "}]