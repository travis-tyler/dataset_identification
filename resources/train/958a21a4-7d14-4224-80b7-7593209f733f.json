[{"section_title": "Abstract", "text": "Although widely used to assist in evaluating the prediction quality of linear and logistic regression models, residual diagnostic techniques are not well developed for regression analyses where the outcome is treated as ordinal. The purpose of this article is to review methods of model diagnosis that may be useful in investigating model assumptions and in identifying unusual cases for PO and PPO models, and provide a corresponding application of these diagnostic methods to the prediction of proficiency in early literacy for children drawn from the kindergarten cohort of the Early Childhood Longitudinal Study (ECLS-K; NCES, 2000).\nKey words: Model diagnostics, proportional odds models, partial proportional odds models, residual analyses.\nIntroduction Although widely used to assist in evaluating the prediction quality of linear and logistic regression models, residual diagnostic techniques are not well developed for regression analyses where the outcome is treated as ordinal. For ordinal regression models, Hosmer and Lemeshow (2000) suggested recombining outcomes according to the ordinal structure of the data and applying residual strategies developed for binary logistic models, such as outlined in Pregibon (1981). This approach is useful in the investigation of the assumption of proportionality as well as for examination of unusual or extreme values via residual diagnostics and this article presents guidelines for proportional odds (PO) and non-or partialproportional odds (PPO) models. \nanalyses provide rich opportunities for researchers to examine model fit and misfit, and require going beyond the results obtained through a direct application of a statistical model, the interpretation of parameter estimates or the summary statistics obtained from that model. Studies of residuals are becoming an important analytic process in many research situations, for example, when highperforming or low-performing students or schools are selected for intensive investigation. Despite their importance, however, results are often presented in the research literature with little emphasis on or reference to the model residuals; readers are thus not always provided with a clear understanding of study findings. In the education field, it becomes particularly important to be able to reliably identify children (or schools, or teachers, or program participants, etc.) whose response or outcome may not be adequately represented by a particular derived model, because if such unusual cases can be discerned, attention may be directed to improve desired outcomes.\nExtensive outlines of useful residual analyses and diagnostic measures have been provided for logistic (Pregibon, 1981) and linear (Fox, 1991) This study contributes to the empirical literature on detection of extreme or unusual cases, investigation of statistical assumptions and validation of ordinal regression models by: reviewing methods of model diagnosis that may be useful in investigating model assumptions, identifying unusual cases for PO and PPO models and providing a corresponding application of these diagnostic methods to the prediction of proficiency in early literacy for children drawn from the kindergarten cohort of the Early Childhood Longitudinal Study (ECLS-K; NCES, 2000). The primary focus is on how outlying or influential cases in ordinal logistic regression models can be reliably detected and on how these strategies can be applied to proportional and/or partial proportional odds models.\nOne of the most commonly used models for the analysis of ordinal data comes from the class of logistic models: the PO model. Consider a simple binary model; in a binary logistic model, the data represent two possible ordinal outcomes, success or failure, typically coded 0 for failure and 1 for success. For a K-level ordinal outcome, several different conceptualizations of success can be derived. Table 1 shows the ECLS-K ordinal outcome variable description and the data indicating the proportion of kindergarten children, drawn from a national random sample of kindergarteners followed through the third-grade, attaining mastery of five hierarchical early-literacy skills at the end of the kindergarten year. In this example, K=6, and the outcome values are scored as 0, 1, 2, 3, 4 and 5, to represent the highest level of proficiency attained on the ECLS-K literacy mastery test (0 = no mastery at any level; 5 = mastered all 5 levels). For these data, 26.9% of the children were not able to achieve beyond level 1 at the end of the kindergarten year and only 12.8% of these children mastered literacy skills beyond level 3, most students scored in levels 2 and 3 (60.3%)."}, {"section_title": "Introduction", "text": "Although widely used to assist in evaluating the prediction quality of linear and logistic regression models, residual diagnostic techniques are not well developed for regression analyses where the outcome is treated as ordinal. For ordinal regression models, Hosmer and Lemeshow (2000) suggested recombining outcomes according to the ordinal structure of the data and applying residual strategies developed for binary logistic models, such as outlined in Pregibon (1981) . This approach is useful in the investigation of the assumption of proportionality as well as for examination of unusual or extreme values via residual diagnostics and this article presents guidelines for proportional odds (PO) and non-or partialproportional odds (PPO) models. "}, {"section_title": "Residual", "text": "analyses provide rich opportunities for researchers to examine model fit and misfit, and require going beyond the results obtained through a direct application of a statistical model, the interpretation of parameter estimates or the summary statistics obtained from that model. Studies of residuals are becoming an important analytic process in many research situations, for example, when highperforming or low-performing students or schools are selected for intensive investigation. Despite their importance, however, results are often presented in the research literature with little emphasis on or reference to the model residuals; readers are thus not always provided with a clear understanding of study findings. In the education field, it becomes particularly important to be able to reliably identify children (or schools, or teachers, or program participants, etc.) whose response or outcome may not be adequately represented by a particular derived model, because if such unusual cases can be discerned, attention may be directed to improve desired outcomes.\nExtensive outlines of useful residual analyses and diagnostic measures have been provided for logistic (Pregibon, 1981) and linear (Fox, 1991) regression models. In addition, Bender and Benner (2000) suggested some graphical strategies that can be used to examine the feasibility of the proportional odds assumption. However, analysis of residuals for PO and PPO models in ordinal logistic regression is not well established; thus, this study was designed to build on the collection of strategies available through logistic and linear approaches. Specifically, these include: Pearson residuals, Deviance residuals, Pregibon leverages, DFBeta's and the use of index plots and other graphical strategies to examine and isolate unusual cases within the logistic framework. The use of Mahalanobis' distance, leverages, SDResiduals, Cook's D and other statistics from the ordinary least-squares framework, when applied to ordinal data are also investigated.\nThis study contributes to the empirical literature on detection of extreme or unusual cases, investigation of statistical assumptions and validation of ordinal regression models by: reviewing methods of model diagnosis that may be useful in investigating model assumptions, identifying unusual cases for PO and PPO models and providing a corresponding application of these diagnostic methods to the prediction of proficiency in early literacy for children drawn from the kindergarten cohort of the Early Childhood Longitudinal Study (ECLS-K; NCES, 2000) . The primary focus is on how outlying or influential cases in ordinal logistic regression models can be reliably detected and on how these strategies can be applied to proportional and/or partial proportional odds models."}, {"section_title": "Background", "text": "One of the most commonly used models for the analysis of ordinal data comes from the class of logistic models: the PO model. Consider a simple binary model; in a binary logistic model, the data represent two possible ordinal outcomes, success or failure, typically coded 0 for failure and 1 for success. For a K-level ordinal outcome, several different conceptualizations of success can be derived. Table 1 shows the ECLS-K ordinal outcome variable description and the data indicating the proportion of kindergarten children, drawn from a national random sample of kindergarteners followed through the third-grade, attaining mastery of five hierarchical early-literacy skills at the end of the kindergarten year. In this example, K=6, and the outcome values are scored as 0, 1, 2, 3, 4 and 5, to represent the highest level of proficiency attained on the ECLS-K literacy mastery test (0 = no mastery at any level; 5 = mastered all 5 levels). For these data, 26.9% of the children were not able to achieve beyond level 1 at the end of the kindergarten year and only 12.8% of these children mastered literacy skills beyond level 3, most students scored in levels 2 and 3 (60.3%). A particular series of questions are of interest when analyzing ordinal outcome data; these involve predicting the likelihood that an observation is at or beyond each specific outcome level given a collection of explanatory variables. For the ECLS-K data, this involves estimating the probability that a child with particular background characteristics or a given set of explanatory variables is at or beyond level 0 (which would always be 1.0); then estimating the probability of that same child being at or beyond level 1, at or beyond level 2, etc., until reaching the probability of the child being at or beyond the last, or K th , outcome category. This series of probabilities are referred to as cumulative probabilities.\nThe analysis that mimics this method of dichotomizing the outcome, in which the successive dichotomizations are used to form cumulative splits to the data, is referred to as the proportional or cumulative odds model (PO) (Agresti, 2000 (Agresti, , 2007 Armstrong & Sloan, 1989; Long, 1997; Long & Freese, 2006; McCullagh, 1980; McCullagh & Nelder, 1989; O'Connell, 2006; Powers & Xie, 2000) . The model is defined as: \nIn this logistic model, the prediction represents the expected logit for being in category j or above, conditional on the collection of predictors, and Y j ' represents the odds of being in higher proficiency categories. These predicted logits can be transformed to odds and then to estimated probability:\nThe intercept, \u03b1j, represents the threshold, or cutpoint, for each particular split to the data. Each person thus has K-1 predicted values, representing their estimated likelihood of scoring in category j or beyond, given their explanatory data. Note that in the PO model the effect of each predictor remains the same across each of these K-1 prediction models: This means that for each predictor, its effect on the probability of being at or beyond any category is assumed to remain constant within the model; thus, the slope estimate provides a summary of each independent variable's relationship to the outcome across all cutpoints. In this model, b 1 , for example, remains the same for all of the splits, although \u03b1 j may change. This restriction is referred to as the assumption of proportional odds.\nA model that relaxes the assumption of proportional odds is referred to as a partialproportional odds (PPO) or non-proportional odds model. This model is given by:\nIn this expression, all of the effects of the explanatory variables are allowed to vary across each of the cutpoints. If some of the effects are found to be stable, they can be held constant as in the PO model. Thus, partial-proportional odds refers to the case that at least one of the slopes for an explanatory variable varies across splits. Due to its simplicity and natural correspondence to ordinary logistic regression, the proportional odds model is the most widely used ordinal regression model. Tests for the assumption of proportional odds can be very liberal (Peterson & Harrell, 1990) , however, and are strongly affected by sample size and the number of covariate patterns -which will always be large if continuous covariates are used (Allison, 1999; Brant, 1990; Clogg & Shihadeh, 1994) . Researchers have argued that if the assumption of proportional odds is rejected, good practice would dictate that the corresponding underlying binary models be fit and compared with the PO results to check for discrepancies or deviations from the general pattern suggested by the PO model (e.g., Allison, 1999; Bender & Grouven, 1998; Brant, 1990; Clogg & Shihadeh, 1994; Long, 1997; O'Connell, 2000 O'Connell, , 2006 . This strategy of considering the PO model as a collection of underlying binary models is an approach that has been found useful not only in qualifying the nature of the proportionality assumption, but also in assessing univariate proportionality, linearity in the logit, and the distribution of residuals from the PO model (O'Connell, Liu, Zhao & Goldstein, 2004) ."}, {"section_title": "Methdology Sample", "text": "The data were drawn from the publicuse data base Early Childhood Longitudinal Study-Kindergarten Cohort (ECLS-K) (NCES, 2000) . The outcome variable of interest was proficiency in early reading, assessed at the end of the kindergarten year. Actual data were used rather than simulated data, because this could help create a realistic context for conducting residual analyses.\nThe final sample included n = 2687 public school children sampled from within 198 public schools across the U.S. The sample contained first-time kindergarten children only, who remained in the same school between kindergarten and first-grade. Analyses intentionally ignored school-level effects in order to focus on residual diagnostics for singlelevel models (only public schools were selected for this study). Analyses were conducted for the full sample as well as for 10 different randomly selected subsamples of 10% each to facilitate use of casewise statistics and plots.\nResidual analyses are often very intensive, thus, for demonstration purposes, two of the smaller subsets were selected to highlight interesting patterns and residual statistics within each data set. No attempt was made to draw inference to the overall sample or population; rather focus was placed on demonstration of diagnostic procedures and strategies for ordinal data.\nThe proficiency outcomes were obtained from the third-grade release of the ECLS-K data base (prior to that, researchers used a series of dichotomous variables to derive the ordinal proficiency scores). Proficiency is defined as mastery of a cluster of 4 items representing each of the domains outlined in Table 1 . The domains are hierarchically structured and theoretically assumed to follow the Guttman scale (NCES, 2000) . Mastery is recognized as students passing 3 out of the 4 items representing each domain.\nThe selection of explanatory variables was theoretically driven and supported through prior research on factors affecting early childhood literacy. These included: gender (male = 1), minority status (minority = 1), whether the child attended half-day kindergarten (yes = 1), number of family risks (0 to 4), frequency with which parents read books to child (0 to 3), family socio-economic status (continuous), and assessment age (continuous). The data presented were from the end of the Kindergarten year. Tables 2a, 2b and 2c present descriptive statistics for the full-sample and the two subsamples, respectively."}, {"section_title": "Data and Models", "text": "The data were used to inspect the residuals from the PO model and test the assumptions of equal slopes. Residuals from an OLS regression of the same data as well as from the five corresponding cumulative binary logistic regression models (splits) underlying the proportional odds assumption (i.e., level 0 versus beyond level 0; levels 0 and 1 combined versus beyond level 1; levels 0, 1, and 2 combined versus beyond, etc.) were examined. Logistic regression diagnostics were investigated for each cumulative split to the data; these procedures were repeated for two of the 10% subsamples (referred to as Samples I and II). The study began by investigating the plausibility of the PO assumption in the full-and sub-samples. A PPO model was then fit where the effect of minority was allowed to vary across thresholds.\nThe SAS (V. 9.1.3), SPSS (V. 15.0) and Stata (V. 9.0) software packages were used for data analyses and graphing. The options for residual diagnostics in logistic regression models were also compared among these packages. SAS PROC LOGISTIC procedure was used for binary logistic models and ordinal logistic models. SPSS was used for descriptive statistics, casewise residual diagnostics in OLS and ordinal regression, index plotting and some scatterplots. Stata was used for residual diagnostics. However, the model fit statistic \u03c7 2 7 = 633.55 (p < 0.0001), indicated that the full model provided a better fit than the null model with no independent variables in predicting cumulative probability for proficiency.\nBecause the proficiency was measured through six categories with outcomes as 0, 1, 2, 3, 4 or 5, with the descending option in SAS, \u03b1 5 corresponds to the intercept for the cumulative logit model for Y \u2265 5, \u03b1 4 corresponds to the intercept for the cumulative logit model for Y \u2265 4, and so on. The effects of the seven independent variables can be interpreted as how variables contribute to the log of the odds of being at or beyond a particular category. In terms of odds ratios, boys were less likely than girls to be at or beyond a particular category (OR=0.73). Being in a minority category (OR=0.649), the presence of any family risk factor (OR=0.649) and attending half-day kindergarten rather than full-day kindergarten (OR=0.695) all had significant negative coefficients in the model and corresponding OR's were significantly less than 1.0. These characteristics were associated with a child being in lower proficiency categories rather than in higher categories. Conversely, increasing frequency of parents reading to their children (OR=1.422) and family SES (OR=2.183) had positive effects on children being in higher proficiency categories. The slopes for both variables were positive and significantly different from zero in the model; child's assessment age was not associated with proficiency in this model because the slope was almost 0 and the OR is close to 1.0. Table 3b shows the results summary for the fitted PO model for sub-samples I (n = 244) and II (n = 278): both results were similar to that of the full-sample. An \u03b1 = 0.05 was used to assess the hypothesis of proportionality. The score test for sub-sample I, \u03c7 2 28 = 46.67 (p = 0.0148), and the score test for sub-sample II \u03c7 2 28 = 44.41 (p = 0.0253), were both statistically significant, indicating that the proportional odds assumptions for both sub-models were violated.\nThe model fit statistic for sub-sample I, \u03c7 2 7 = 38.61 (p < 0.0001), and the model fit statistic for sub-sample II, \u03c7 2 7 = 71.67 (p < 0.0001) indicated that the models with seven predictors provided a better fit than the null model with no independent variables. The Odds Ratios (OR) for the seven explanatory variables for sub-sample I and II looked similar, and were also similar to those of the proportional odds model for the full-sample. However, in the PO model for sub-sample I, it was noticeable that the effects of gender, minority and frequency of being read to by parents were not statistically significant; and the p value of the slopes of number of family risks and attendance at halfday kindergarten were slightly larger than the 0.05 level. In the CO model for sub-sample II, the effects of minority, half-day kindergarten and having parents read to their children were not significant. Table 4a shows the results of five separate binary logistic regression analyses for the full sample, where the data were dichotomized according to the cumulative probability pattern described earlier for the proportional odds model. Each logistic regression model estimates the probability of being at or beyond proficiency level j. In the data set, the grouping of categories coded 1 corresponded to children who were at or beyond each proficiency category and 0 was coded for children below each successive category. The model \u03c7 2 for each separate logistic model was statistically significant, indicating that each model fit well compared to its corresponding null model. The Hosmer-Lemeshow tests were all not statistically significant, indicating that observed and predicted probabilities were consistent."}, {"section_title": "Assumption of Proportional Odds", "text": "Examining the patterns of slopes and ORs for each explanatory variable across these five logistic regression models, it was found that the effects of gender, after adjusting for the other predictors directionally and on average, were similar across the five separate logistic regressions. This was also true for family risk, family SES, half-day kindergarten, being read to by parents and the child's assessment age. However, the effect of minority did appear to present a dissimilar pattern across the five separate logistic regressions. The direction of the effect of minority changed between the first three regressions and the last two. For the other explanatory variables, the direction and average magnitude of the slopes and the ORs from the logistic models were similar to those of the PO model.\nBecause the proportional odds assumption for the full-sample ordinal model was violated, separate score tests unadjusted for the presence of other covariates in the cumulative odds model were examined for each of the explanatory variables, in order to illuminate where non-proportionality might lie. The univariate score tests for the assumption of proportional odds were upheld for gender and child's assessment age. However, the univariate score tests were violated for minority, family risk, family SES, being read to by parents and half-day kindergarten at the 0.05 level of significance. The p-values for these unadjusted tests are presented in the final column of Table  4a ; it should be noted that these score tests are simply descriptive, given their univariate nature. Table 4b presents the results of five separate binary logistic regression analysis for sub-sample I, n = 244. The univariate score tests for the assumption of proportional odds were upheld for separate PO models for all the variables, except for the continuous variable of family SES (wksesl). The p values for these unadjusted tests are presented in the final column of Table 4b . However, minority as well as gender, half-day kindergarten attendance and frequency of being read to by parents all exhibited inconsistencies in the directional patterns across the binary splits. Table 4c shows the results of five separate binary logistic regression analysis for sub-sample II, n = 278. Based on \u03b1 =0.05, the univariate score tests for the assumption of proportional odds were upheld for separate PO models for these variables: gender, attending half-day kindergarten (halfday), having parents read to their children (readbk2) and child's assessment age (r2_kage). However, the score tests for the assumptions of proportional odds were violated for these three variables: being in a minority category (minority), number of family risks (risknum) and family SES (wksesl). The p-values for these unadjusted tests were presented in the final column of Table 4c . (Nichols, 2004) , so analysts should be aware of the possibility for discrepancies and differences in results between software packages.\nGiven the large sample size, \u03b1 = 0.01 was used to evaluate the assumption of proportionality for these univariate tests for the full-sample. Consistent results were found across the three software packages for all explanatory variables except the frequency with which parents read books to children, for which p = 0.006 (SPSS), p = 0.0426 (SAS) and p = 0.078 (Stata). However, for the two smaller subsamples, and using \u03b1 = 0.05, it was found that the results of these univariate score tests (using SAS) varied across the sub-samples and were also inconsistent with the full-sample results. For example, the p-values of the score test for the minority variable was 0.3562 in the model for sub-sample I and 0.0031 for sub-sample II; the hypothesis of proportionality was rejected for the minority variable within the full sample (p < 0.0001). In addition, the effect of attending half-day kindergarten was found to deviate from proportionality in the full sample, but this assumption was upheld in both of the smaller samples."}, {"section_title": "Results of the Partial Proportional Odds (PPO) Model", "text": "The discrepancy of results of the score tests between the full-sample and sub-sample analyses and across statistical packages presents a disheartening situation for the analyst attempting to assess the plausibility of the proportional odds model through score tests alone. These results support the view that investigation of proportional odds may be more reasonably investigated through visual examination of the variable effects and odds ratios of the binary models underlying the ordinal progression of the outcome data. Consequently, it was decided to fit a PPO model that relaxes the assumption of proportionality for the minority variable because this effect changed direction across cutpoints in all three analyses (full-sample, I and II). Results using SAS PROC GENMOD are shown in Table 4e for the fullsample data.\nThe outcome being modeled in this PPO analysis was the probability that a child was at or beyond category j, with the effect of minority being allowed to vary across the K\u22121 = 5 cutpoints while holding the other variable effects constant. Overall, only one intercept parameter was estimated (for the log-odds of a value being at or beyond proficiency level 5), but different estimates for each split were obtained which were used to modify the intercept value; and the split by minority interaction terms were used to determine how much the effect of minority changed across splits. In this analysis, the coding of categorical variables was internal to GENMOD; effects are shown in Table 4e for the lower value of the coded variables (for example, the effect for gender, I = 0.34, was the change in slope for females; this was the opposite of the slope in the PO model, where I = \u22120.31 for the change in slope for males). According to these results, the split by minority interaction terms were statistically significant for the first logit comparison (corresponding to P(Y ge 1)) and the last (corresponding to P(Y ge 5)), but not for the other splits. These results suggested that reliable differences existed in the effect of minority across the outcome levels of the ordinal model.\nOverall, when coding was taken into consideration for the effect of minority, the predicted logits were similar to those obtained from the separate binary regressions shown in Table 4a for the full-sample. Additionally, the slope effects for the remaining variables, which were held proportional in the analysis, reflected the values obtained through the PO analysis in Table 3a (after accounting for coding reversals). Thus, using the separate binary models to investigate the presence and impact of extreme or unusual scores made sense for both the PO and PPO model, as these binary models reflect what was expected in the data for each of the separate splits."}, {"section_title": "Residuals in Ordinal Logistic Regression", "text": "SAS, SPSS and Stata do not provide residual diagnostics for ordinal models. Hosmer and Lemeshow (2000) suggested considering each of the underlying models separately and applying residual methods for these binary logistic models in order to identify unusual or extreme observations. This approach mirrors the aptness of model investigations for the proportional odds assumption presented previously.\nConsider the residuals for these underlying cumulative binary models and in addition the OLS strategies that were used for preliminary analyses to examine whether that approach could assist in identifying unusual cases. Under the OLS framework, there are several commonly used measures to identify unusual cases. Mahalanobis' distance is the distance for each case to the centroid of remaining cases (multivariate outliers). Leverages are the diagonal elements of the hat matrix in OLS; they are a transformation of Mahalanobis distance. Leverages flag cases are considered extreme in the X or explanatory variable space, where two or three times the average leverage can be considered large.\nHowever, cases with large leverage values may or may not be influential; that is, an observation may be unusual in terms of being outside an acceptable range relative to the other X values, but it may not affect the shape or direction of the regression function. Cook's D assesses how influential each case is to the fit of the overall model. This measure considers what happens to the model when each case is removed, one at a time, from the overall model. A large Cook's D value is determined in relation to values obtained from all the other cases. Generally Cook's D statistics are plotted to identify any large jumps in the measures. Finally, when assessing outliers on Y, the outcome variable, a common statistic is the studentized deleted residual, or SDRESID. For SDRESID the change in residuals was examined when each case is removed, one at a time, from the model.\nAdjustments to the OLS statistics are required for logistic regression. Logistic models predict the probability that Y = 1 for a dichotomous dependent variable. The residuals obtained through a logistic regression are heteroscedastic (variance = \u03c0 i (1 \u2212 \u03c0 i )). Techniques similar to those used in OLS models have been developed for logistic regression in order to detect unusual or influential observations (Pregibon, 1981) . The Pearson residual, deviance residual and Pregibon leverages are three main types of residual statistics commonly used for logistic regression diagnostics; however, many choices are available. \nWhere y i is the observed number of success; n i is the number of observations with explanatory variable x i ; i \u03c0\u02c6 is estimated probability at x i .\nWhen the number of observations is 1, that is, n i = 1 (assuming a Bernoulli rather than binomial model), the Pearson residuals can be simplified as:\nDeviance residuals capture the difference between the maxima of the observed and fitted log likelihood functions. Dev i are components of the summary model deviance, D =\u22122LL. SAS labels this as resdev; SPSS labels it as dev; and Stata labels it as deviance. Deviance residuals are defined as:\nAlso when n i = 1, the formula can be simplified as:\n(1 ) 2 log (1 )log .\nLarge values of r i or d i suggest that the model does not fit that case well. The r i and dev i are components of alternate tests for same null hypothesis tested based on the Chi-square distribution; that is, does the model fit as well as a saturated model of the data (i.e., one that perfectly reproduces the original data). Under the null hypothesis, the individual components are approximately normally distributed and it is expected that the summary value/df will be less than 1.0. However, neither the summary Pearson residual statistic nor the summary deviance residual statistic follows a Chi-square distribution when continuous explanatory variables are included in the model. Thus, the summary statistics are not appropriately used in that situation. When the data are sparse (i.e., with continuous IVs), this Chi-square distributional assumption is not upheld.\nPregibon leverages (hat) are the diagonal elements of the hat matrix in logistic regression. They are used to measure the relative influence of an observation on the model fit. SAS labels these as h; SPSS labels them as lever; and Stata labels them as hat. Pregibon hats tend to be small when the estimated probability of observations is outside of the 0.1 to 0.9 interval, because most extreme cases may also have small leverages (Hosmer & Lemeshow, 2000) . Therefore, Pregibon hats may not provide a good assessment of influential cases when the estimated probability of an observation is too small or too large. Pregibon leverages are defined as:\nwhere W is the diagonal weight matrix; and h ii is the leverage or diagonal element of the hat matrix, H. It is also often more informative to consider how each case affects fit of the overall model. There are several approaches in logistic regression to measure the change in Chi-square fit, deviance fit, and in the estimated parameters when a single observation is removed from the model. These measures are similar to Cook's D in ordinary least-squares regression. SPSS provides a measure which is an analog of Cook's D, and labels it Cook; SPSS only provides change in estimated parameters and labels it as dfbeta. SAS and Stata provide all three options. SAS labels the standardized difference in estimated parameters dfbetas, which is different from SPSS. SAS also provides two measures of the change in the confidence interval for the regression estimates when an observation is deleted, and labels them C and CBAR. SAS labels the change in Chi-square fit as difchisq and change in deviance fit as dfdev. Stata labels the standardized change in regression coefficient as dbeta, the change in Chi-square fit as dx2, and the change in deviance fit as ddeviance. Descriptions of several of these statistics in SPSS, SAS and Stata are listed in Table 5 . "}, {"section_title": "Change in Deviance Residuals", "text": "The Hosmer-Lemeshow test does not yield a residual measure, but it does inform about the fit of a model, particularly when continuous explanatory variables are included. The H-L test attempts to compensate for the presence of continuous variables and resulting sparseness of the data by aggregating across deciles of risk, which are formed by collapsing over observations with similar covariate patterns. However, this same strategy of aggregating by covariate pattern for residual diagnostic purposes may mask influential or poorly fit cases; therefore, researchers tend to rely on visual assessment rather than specific concrete measures or approaches, for identification of unusual cases. In addition, given the lack of informative distributional theory regarding many of the residual statistics discussed above, it may be more valuable to apply graphical strategies for observing and identifying unusual or influential cases within logistic and ordinal models. Many of these graphical approaches mirror what is available through OLS. For ordinary least squares regression, a graph of the observed dependent variable, y, versus the predicted dependent variable, y-hat, can be plotted. Observed and predicted outcomes in logistic regression are dichotomous; thus modifications are required -usually the resulting graphs are done at a casewise level. For logistic regression, index plots are enormously useful. Index plots display each residual diagnostic for a case against the case number. The resulting output can be unwieldy for samples with many observations and when multiple residual statistics are investigated; but visually, extreme or unusual cases can be readily detected.\nAs a minimum, Hosmer and Lemeshow (2000) recommended plotting the change in Chisquare fit versus the predicted probability (p-hat) of the dependent variable; change in deviance fit versus p-hat; and change in regression estimates versus p-hat. They pointed out that using the summary change statistic rather than the individual component values (r i or d i , above) for each case visually emphasized the poorly fit cases. Because not all statistics are available in each statistical package, choices among possible graphs or plots have to be made depending on the options available."}, {"section_title": "Residual Diagnostics Results", "text": "With large data sets, the amount of output involved in graphical displays for diagnostic statistics can become unworkable very quickly. Thus, two smaller data sets are employed to demonstrate the use and interpretation of regression diagnostic statistics. OLS regression of the ordinal outcome was used on the collection of explanatory variables as an initial strategy to identification of unusual or poorly fit cases for both Samples I and II. A series of logistic regression models were then run for Samples I and II corresponding to the cumulative splits; residual statistics obtained from these five logistic models were used to identify unusual cases. Next, the use of index plots to visually display the residual statistics for a collection of diagnostic values derived from the logistic splits for Sample I (one sample was selected for demonstration of the index plots) was demonstrated. After reviewing the residual strategies and identifying the poorly fit cases, those cases identified as unusual by inspecting the original data were explored along with characteristics of the children in order to better understand who is potentially being poorly fit by the model. I  Table 6a presents casewise statistics based on unusual cases identified through an OLS scatterplot of observed versus predicted values, OLS casewise diagnostics, and additional cases identified through the five sequential (cumulative) logistic models and corresponding index plots for Sample I (n = 244). Figure 1 displays the OLS scatterplot of observed versus predicted values: several potentially unusual cases or outliers were observed in proficiency level 0, 3 and 5. From the scatterplot, nine cases were identified as unusual or poorly fit. The absolute values of the studentized deleted residuals (SDRESID) of these cases were mostly larger than or close to 2. For case number 1698 (ID = 0731010C) its Mahalanobis Distance was 39.23, which is very large, and the corresponding leverage value and Cook's D for this case are also the largest among those cases identified as outliers. This child was predicted to be in proficiency level 0.28 (via OLS), yet had actually scored in proficiency level 3. Visually, this case can be clearly identified as an outlier in Figure 1 for proficiency level 3. Table 6a shows statistics for two additional cases identified through the OLS residual diagnostics options as having standardized deleted residuals (ZRESID) larger than our setting of 2.5 (2.5 was used instead of the default value of 3.0 to maintain consistency with the values used in the logistic regression procedure). Both children were in proficiency level 5 but were predicted to be in levels 2.16 and 2.15 respectively. For comparison, the summary statistics of Table 6a include OLS for cases that were identified through the binary logistic models as being potential outliers: five additional cases were detected. The OLS statistics for these cases, however, do not indicate that these cases are unusual, with the exception of one large Mahalanobis' distance value of 18.84 for Case No. 1384 (ID = 0609022C). Table 6b presents casewise diagnostics for the five cumulative binary logistic regression models (splits) for Sample I. Four cases (Case No. 1059 , 1571 , 1698 and 2952 were flagged as outliers for the first cumulative split based on SRESID greater than 2.5 (set greater than the 2.0 default setting); one (Case No. 1698) was flagged as an outlier for the second cumulative split; no cases were identified in the analysis for the third cumulative split; two (Case No. 1917, and 3414) were flagged as outliers for the fourth cumulative split; and three (Case No. 2103, 3392, and 3414) were flagged as outliers for the fifth cumulative split."}, {"section_title": "Ordinal Residual Diagnostics for Sample", "text": "Ordinal Residual Diagnostics for Sample II Table 7a presents casewise statistics based on unusual cases identified through an OLS scatterplot of observed versus predicted values, OLS casewise diagnostics, and additional cases identified through the five sequential (cumulative) logistic models and corresponding index plots for Sample II (n = 278). Figure 2 displays the OLS scatterplot of observed versus predicted values; eleven potentially unusual cases or outliers can be observed in proficiency level 0, 4 and 5. Referring to Table 7a , only one of these eleven cases had a fairly large OLS Mahalanobis' distance of 11.85; this child scored in proficiency level 4 but was predicted into level 1.95. The statistics for the other 10 cases identified did not seem unusual. The absolute values of the studentized deleted residuals (SDRESID) of these cases were slightly larger than or close to 2.\nAfter running the OLS regression to request residual diagnostics, no additional unusual observations were identified. Only one case, Case 5, had already been identified through the review of the scatterplot; this case had a ZRESID value greater than 2.5. .022 a S = Selected, U = Unselected cases, ** = Misclassified cases; b Cases with studentized residuals greater than 2.500 are listed; For CUMSP3: P(Y ge 3), the casewise plot is not produced because no outliers were found Index Plots Using the separate binary logistic models to mimic the data patterns of an ordinal model yields five different regressions for a K = 6 level ordinal outcome variable. Plotting each model's residuals or diagnostic summary values against the case number can enhance the search for extreme or unusual values; however, there will necessarily be multiple plots for each binary split. Figure 3 contains a display of index plots for 8 residual measures: normalized residual, residual, deviance residual, logit residual, Cook's analog, leverages, difference in deviance statistic and difference in the Pearson Chi-square statistic. These displays contain the value of the residual statistic on the vertical axis, and the case number horizontally. Strong peaks indicate extreme value in the residual score. In the first plot, it is easy to detect unusual scores, as noted in the Figure. The three marked cases were previously identified in the residual analyses for Sample I. Figure 4 contains two of the plots recommended by Hosmer and Lemeshow (2000) , namely, the change in Chi-square and Notes: a S = Selected, U = Unselected cases, ** = Misclassified cases; b Cases with studentized residuals greater than 2.500 are listed; For CUMSP2: P(Y ge 2) and CUMSP3: P(Y ge 3) the casewise plots are not produced because no outliers were found deviance fit statistics against p-hat. These graphs are a compilation of two curves, one representing Y = 1 (the downward curve, so that outliers are in the top left corner), and one representing Y = 0 (the upward curve, so outliers are in the top right corner). As illustrated in the first graph in Figure 4 , previously identified cases are again indicated through these index plots. The plots of change in the regression coefficients versus p-hat are not shown (with seven predictors and the intercept, there are eight graphs for each of the five logistic regression splits). Figures 5 through 12 provide the same plots as above for the remaining four logistic regression splits. Reviewing plots for residual analyses can be informative, but to match extreme or unusual observations in a plot to the original data can be time-consuming. In identifying the outliers in plots, SPSS does not label the cases directly; the analyst must use a two-step procedure (isolating the extreme value and matching that back to the original case). However, Stata has an option of adding labels to the points using the mlabel command. Figure 13 displays the plots of change in Pearson Chisquare against p-hat for five cumulative splits for Sample I using Stata. This option can facilitate easy identification of unusual cases from the plots."}, {"section_title": "Characteristics of Children Misfit by the Model", "text": "Investigation of the characteristics of the children who were identified as unusual, in terms of not being well represented by the model through at least one of the strategies employed, can ultimately help with understanding who the model is not providing a good fit for and why, and thus lead to development of better models that demonstrate stronger knowledge of the outcome for all persons. Tables 8 and 9 contain the values of the explanatory variables of interest for the collection of cases identified as unusual through the diagnostics applied to Sample I and Sample II, respectively. To summarize, for both samples, most identified children were female with SES below the standardized average of 0.\nIn general, the model tended to underpredict proficiency for some children who have theoretically assumed strikes against them, such as low SES or a large number of family risk characteristics. These cases tended to perform as well as or -in many cases -better than their peers. For example, child ID 0936002C (Case No. 2103) in sub-sample I is a female minority student who does not speak English at home and who attended half-day kindergarten rather than full-day kindergarten: this child's parents read to her at least three times per week and her actual reading proficiency level is 5. The logistic models predicted her to be in a lower category, as did the OLS model (level 2). Thus, some high achieving children do not have their reading proficiency adequately captured by the current model or current set of predictors.\nConversely, some children who have perceived theoretical benefits in their favor, such as higher SES or no family risk characteristics, performed less well than the model predicts. For example, child ID 1275024C (Case No. 2952) in sub-sample I is a female non-minority student without any family risk factor, who attends fullday kindergarten, had parents read to her at least three times per week, and speaks English at home: this student's actual reading proficiency level is 0, but she is predicted to be in level 3."}, {"section_title": "Conclusion", "text": "Although poor predictions are inevitable in any modeling situation, the concern is that the typically limited range of the dependent variable for ordinal (or logistic) regression models may lead to more systematic under-or overpredictions relative to what might be expected with a continuous outcome. Identification of unusual cases or cases that are poorly fit by a particular model is only the first step in a residual analysis. After the cases are identified, the process turns towards understanding what characteristics of the collection of identified cases are associated with their corresponding under-or over-prediction from the model. This study has only examined the collection of data for the variables included in the models; it could be that a variable external to the model would better explain why some children are so strongly under-or over-predicted by the model.\nFor the proportional odds and partialproportional odds model, the analysis of residuals was split into two components, given that residual analyses for ordinal regression analyses are not directly available. These were the OLS analysis of the ordinal outcome (treated as interval/continuous) and the analysis of residuals from the separate binary regression models forming the progression of the cumulative logit model. The latter approach has been advocated by many researchers (Hosmer & Lemeshow; Harrell, 2001; Long & Freese, 2006) , but it remains unclear how well these cases may be fit by a specific ordinal model. That particular model was only approximated in the approach taken herein. Other work has investigated quality of goodness-of-fit tests for ordinal and multinomial data (Fagerland, Hosmer & Bofin, 2008; Pulkstenis & Robinson, Figure13 0037019C   0044010C   0044023C   0045019C   0053003C  0053010C   0055012C   0056014C   0056015C   0095004C 0095005C  0110005C 0110007C  0110010C  0162004C   0162017C   0164003C  0164016C   0169017C  0169023C  0180002C   0204009C   0204016C   0204019C   0204021C  0214002C   0215002C 0215009C   0215010C   0216010C  0240012C  0240014C  0245005C 0245011C   0248003C   0248024C   0258014C   0258020C  0285001C 0285015C   0303004C   0303020C   0326013C   0326018C  0330002C 0333014C  0345014C  0347004C  0348005C   0348017C   0377011C   0380011C   0380015C 0380019C   0387017C  0388016C   0401025C  0414007C   0440013C   0440018C  0440021C  0443004C   0443007C   0443015C   0473014C  0474007C 0474018C 0481021C  0483015C   0484025C   0515017C   0516004C  0516012C  0518013C 0523002C  0527020C  0532012C   0532023C   0533015C   0533016C 0534001C  0597015C   0601010C  0601014C 0601019C   0605003C   0605020C   0609003C   0609014C   0609018C   0609022C   0614003C  0614010C  0621013C  0635009C   0635017C   0635021C   0635026C   0645015C   0647002C  0647011C   0661002C   0661003C   0664002C   0664011C   0664023C   0665006C   0665014C   0665018C   0669017C  0708003C  0717008C  0717021C  0718005C   0718008C   0729009C   0729016C   0731010C   0748004C   0748019C  0754018C  0803012C  0803023C  0804001C   0804019C  0824020C  0826021C   0832011C   0832020C  0833003C  0834011C   0881016C  0881024C 0882017C   0885004C  0885019C   0886017C   0891009C  0891014C  0918004C  0918023C   0935018C   0936002C   0936018C  0949003C  0950023C   1002022C   1003015C  1003019C 1008003C  1008020C (cumsp3)   0015019C  0015026C  0022006C 0023018C  0023024C  0037008C  0037019C  0044010C 0044023C 0045019C  0053003C  0053010C  0055012C  0056014C 0056015C  0095004C 0095005C   0110005C   0110007C  0110010C   0162004C   0162017C  0164003C  0164016C 0169017C 0169023C 0180002C  0204009C  0204016C 0204019C  0204021C  0214002C  0215002C  0215009C 0215010C0216010C  0240012C  0240014C   0245005C   0245011C  0248003C  0248024C  0258014C  0258020C  0285001C 0285015C  0303004C   0303020C   0326013C  0326018C  0330002C  0333014C  0345014C  0347004C  0348005C  0348017C  0377011C   0380011C   0380015C  0380019C  0387017C 0388016C  0401025C  0414007C 0440013C  0440018C  0440021C  0443004C  0443007C  0443015C   0473014C 0474007C   0474018C  0481021C 0483015C  0484025C  0515017C  0516004C  0516012C  0518013C 0523002C  0527020C  0532012C0532023C   0533015C   0533016C 0534001C  0597015C 0601010C   0601014C   0601019C  0605003C   0605020C   0609003C  0609014C  0609018C  0609022C  0614003C 0614010C  0621013C  0635009C   0635017C   0635021C  0635026C  0645015C   0647002C   0647011C  0661002C  0661003C  0664002C  0664011C  0664023C  0665006C  0665014C  0665018C 0669017C  0708003C  0717008C  0717021C  0718005C  0718008C  0729009C  0729016C  0731010C  0748004C  0748019C  0754018C  0803012C  0803023C  0804001C   0804019C   0824020C 0826021C  0832011C  0832020C   0833003C   0834011C 0881016C0881024C 0882017C  0885004C  0885019C  0886017C  0891009C  0891014C 0918004C 0918023C  0935018C   0936002C   0936018C  0949003C  0950023C  1002022C  1003015C  1003019C   1008003C   1008020C  1010002C  1010023C  1037025C  1041022C  1044017C  1049008C  1049011C  1049022C  1052003C  1052004C 1053001C  1053021C  1071004C 1071017C  1073015C  1096003C  1096010C 1097007C 1114015C  1126020C  1126023C 1147002C  1147005C  1147011C  1147018C  1166016C  1167014C  1167020C 1174001C  1181009C  1181011C  1181012C   1181017C   1194003C   1194016C   1217020C  1222018C  1249019C  1251023C  1265009C  1265011C  1269013C  1269020C 1271005C  1271007C  1274002C  1274005C  1274012C  1274020C  1275024C  1276011C  1276013C  1277008C  2078008C   2078015C  2112007C   2112014C 2112015C  2112016C  2115003C  2116010C  3002012C 3002020C   3006003C   3006005C  3006014C  3006024C  3021020C  3023023C 3025020C 3035015C  3036001C  3036012C   3038013C   3047019C  3048009C  3068001C 3084009C  3094024C  3103023C   3105020C   3108008C  3108009C   3113018C   3113023C  3114003C 0022006C 0023018C 0023024C 0037008C 0037019C  0044010C  0044023C 0045019C  0053003C  0053010C  0055012C 0056014C 0056015C 0095004C  0095005C   0110005C   0110007C  0110010C 0162004C  0162017C  0164003C 0164016C 0169017C  0169023C  0180002C  0204009C  0204016C 0204019C  0204021C 0214002C 0215002C  0215009C 0215010C  0216010C  0240012C  0240014C   0245005C   0245011C  0248003C  0248024C  0258014C  0258020C  0285001C 0285015C 0303004C 0303020C 0326013C 0326018C  0330002C 0333014C  0345014C  0347004C  0348005C  0348017C  0377011C  0380011C  0380015C 0380019C  0387017C 0388016C  0401025C  0414007C 0440013C  0440018C 0440021C 0443004C  0443007C 0443015C 0473014C  0474007C  0474018C 0481021C 0483015C  0484025C 0515017C 0516004C  0516012C  0518013C 0523002C  0527020C  0532012C  0532023C  0533015C 0533016C 0534001C  0597015C  0601010C 0601014C  0601019C 0605003C 0605020C  0609003C  0609014C  0609018C 0609022C  0614003C 0614010C  0621013C0635009C   0635017C   0635021C  0635026C  0645015C 0647002C  0647011C  0661002C 0661003C 0664002C  0664011C 0664023C  0665006C 0665014C  0665018C  0669017C  0708003C  0717008C 0717021C 0718005C  0718008C  0729009C  0729016C  0731010C 0748004C  0748019C  0754018C  0803012C 0803023C  0804001C 0804019C  0824020C 0826021C  0832011C  0832020C  0833003C 0834011C 0881016C  0881024C 0882017C  0885004C 0885019C 0886017C  0891009C  0891014C 0918004C 0918023C 0935018C   0936002C   0936018C  0949003C  0950023C  1002022C 1003015C  1003019C  1008003C  1008020C 1010002C 1010023C  1037025C  1041022C  1044017C  1049008C  1049011C  1049022C 1052003C  1052004C 1053001C 1053021C  1071004C 1071017C  1073015C  1096003C  1096010C 1097007C 1114015C 1126020C  1126023C 1147002C 1147005C  1147011C  1147018C  1166016C 1167014C 1167020C  1174001C  1181009C 1181011C  1181012C  1181017C  1194003C   1194016C   1217020C 1222018C  1249019C 1251023C  1265009C  1265011C 1269013C  1269020C 1271005C  1271007C  1274002C  1274005C 1274012C 1274020C  1275024C  1276011C 1276013C  1277008C  2078008C  2078015C   2112007C   2112014C 2112015C  2112016C 2115003C  2116010C 3002012C 3002020C 3006003C  3006005C  3006014C  3006024C 3021020C 3023023C  3025020C 3035015C  3036001C  3036012C 3038013C 3047019C  3048009C  3068001C 3084009C  3094024C 2004). However, this study focused specifically on data diagnostics for ordinal outcomes, which constitutes a preliminary but necessary step in the determination of model fit.\nThis article reviewed proportional odds model and partial proportional odds model and the use of some valuable strategies were demonstrated for identifying influential or unusual cases after fitting ordinal regression models. In particular, OLS strategies for preliminary residual detection were applied, followed by application of logistic regression diagnostics approaches for each cumulative binary model in the cumulative odds ordinal series. Results of these methods confirm that investigation of casewise fit to the proportional odds model can be very intensive.\nOLS strategies can be a good first step in the diagnostic process, but does it not capture some extreme or influential cases. Differences across statistical packages in terms of availability of options for residual diagnostics can limit the kinds of analyses a researcher has available, thus choice of statistical package should be made with full understanding of the procedures and statistics available. Further, it was demonstrated that index and change plots can yield important information about who is not being fit well by these model and these plots can augment findings from other residual strategies.\nOverall, it may be concluded that reliance on one method or approach to understanding residuals from an ordinal regression model can be very misleading to the researcher. Results from this study clearly make a case for the need to consider multiple strategies in determining quality of model fitnot just overall, but for individuals as well. Further studies and extensions to this research should consider the residuals obtained from the PO model based on predicted category (i.e., classification accuracy). In addition, it would be worthwhile to pursue the use of Monte Carlo techniques to examine residuals and to control over the nature of departure from the assumption of proportional odds or other model characteristics; for example, one question not answered in the current study is the degree to which outliers or extreme values affects the determination of the assumption of proportional odds.\nSubstantively, it may be reasonable to consider separate models for cases that are not well-represented by a general population-type ordinal regression model. From a policy perspective, findings suggest that individual student performance or proficiency can be easily misunderstood, and in the current climate of accountability, the repercussions from such a situation can have great impact. The approaches and strategies presented here could be used to effectively argue for support for intervention programs, including gifted-education programs, or to support improved funding for special education or second-language acquisition programs. Only through residual diagnostics would the children who are left far behind, or who score far beyond their peers, be readily identified.\nProposed Diagnostic Guidelines for Ordinal Regression Models"}, {"section_title": "Residuals from both OLS and Binary", "text": "Logistic Models provide a good first look at the potential for influential or unusual cases from an ordinal model.\n2. OLS does not capture all the unique unusual values; neither do the corresponding binary logistic analyses. Thus, researchers need to be aware of the potential to miss important misfit cases and counteract this possibility by viewing/plotting as many different diagnostic statistics as possible, particularly for the binary models corresponding to a given ordinal approach (e.g., proportional odds)\n3. Graphical strategies, while extensive and often time-consuming, can tell the researcher more about their data than a single summary statistic.\n4. Researchers should make a commitment early on to include residual diagnostics in all their presented or published papers. It is easy to mislead oneself, one's audience, and various research stakeholders when residual diagnostic strategies are ignored."}]