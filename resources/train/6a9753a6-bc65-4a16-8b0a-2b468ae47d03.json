[{"section_title": "Abstract", "text": "Abstract. Traditional deformable registration techniques achieve impressive results and offer a rigorous theoretical treatment, but are computationally intensive since they solve an optimization problem for each image pair. Recently, learning-based methods have facilitated fast registration by learning spatial deformation functions. However, these approaches use restricted deformation models, require supervised labels, or do not guarantee a diffeomorphic (topology-preserving) registration. Furthermore, learning-based registration tools have not been derived from a probabilistic framework that can offer uncertainty estimates. In this paper, we present a probabilistic generative model and derive an unsupervised learning-based inference algorithm that makes use of recent developments in convolutional neural networks (CNNs). We demonstrate our method on a 3D brain registration task, and provide an empirical analysis of the algorithm. Our approach results in state of the art accuracy and very fast runtimes, while providing diffeomorphic guarantees and uncertainty estimates. Our implementation is available online at https://github.com/voxelmorph/voxelmorph."}, {"section_title": "Introduction", "text": "Deformable registration computes a dense correspondence between two images, and is fundamental to many medical image analysis tasks. Traditional methods solve an optimization over the space of deformations, such as elastic-type models [5, 29] , B splines [28] , dense vector fields [31] , or discrete methods [10, 14] . Constraining the allowable transformations to diffeomorphisms ensures certain desirable properties, such as preservation of topology. Diffeomorphic transforms have seen extensive methodological development, yielding state-of-the-art tools, such as LDDMM [7, 33] , DARTEL [3] , and SyN [4] . Unfortunately, these methods often demand substantial time and computational resources to run for a given image pair.\nRecent methods have proposed to train neural networks that map a pair of input images to an output deformation. These approaches usually require ground truth registration fields, often derived via more conventional registration tools, which can introduce a bias and necessitate significant preprocessing [26, 30, 32] . Some preliminary papers [11, 21] explore unsupervised strategies that build on the spatial transformer network [17] , but are only demonstrated with constrained deformation models such as affine or small displacement fields. Furthermore, they have only been validated on limited volumes, such as 3D patches or 2D slices. A recent paper avoids these pitfalls, but still does not provide topology-preserving guarantees or probabilistic uncertainty estimates, which yield meaningful information for downstream image analysis [6] .\nIn this paper we present a formulation for registration as conducting variational inference on a probabilistic generative model. This framework naturally results in a learning algorithm that uses a convolutional neural network with an intuitive cost function. We introduce novel diffeomorphic integration layers combined with a transform layer to enable unsupervised end-to-end learning for diffeomorphic registration. We present extensive experiments, demonstrating that our algorithm achieves state of the art registration accuracy while providing diffeomorphic deformations, fast runtime and estimates of registration uncertainty."}, {"section_title": "Diffeomorphic Registration", "text": "Although the method presented in this paper applies to a multitude of deformable representations, we choose to work with diffeomorphisms, and in particular with a stationary velocity field representation [3] . Diffeomorphic deformations are differentiable and invertible, and thus preserve topology. Let \u03c6 : R 3 \u2192 R 3 represent the deformation that maps the coordinates from one image to coordinates in another image. In our implementation, the deformation field is defined through the following ordinary differential equation (ODE):\nwhere \u03c6 (0) = Id is the identity transformation and t is time. We integrate the stationary velocity field v over t = [0, 1] to obtain the final registration field \u03c6 (1) . We compute the integration numerically using scaling and squaring [2] , which we briefly review here. The integration of a stationary ODE represents a oneparameter subgroup of diffeomorphisms. In group theory, v is a member of the Lie algebra and is exponentiated to produce \u03c6 (1) , which is a member of the Lie group: \u03c6 (1) = exp(v). From the properties of one-parameter subgroups, for any scalars t and t , exp((t + t )v) = exp(tv) \u2022 exp(t v), where \u2022 is a composition map associated with the Lie group. Starting from \u03c6\nwhere p is a map of spatial locations, we use the recurrence \u03c6"}, {"section_title": "Methods", "text": "Let x and y be 3D images, such as MRI volumes, and let z be a latent variable that parametrizes a transformation function \u03c6 z :\nWe use a generative model to describe the formation of x by warping y into y \u2022 \u03c6 z . We propose a variational inference method that uses a neural network of convolutions, diffeomorphic integration, and spatial transform layers. We learn the network parameters in an unsupervised fashion, i.e., without access to ground truth registrations. We describe how the network yields fast diffeomorphic registration of a new image pair x and y, while providing uncertainty estimates."}, {"section_title": "Generative Model", "text": "We model the prior probability of z as:\nwhere N (\u00b7; \u00b5, \u03a3) is the multivariate normal distribution with mean \u00b5 and covariance \u03a3. Our work applies to a wide range of representations z. For example, z could be a low-dimensional embedding of a dense displacement field, or even the displacement field itself. In this paper, we let z be a stationary velocity field that specifies a diffeomorphism through the ODE (1). We let L = D \u2212 A be the Laplacian of a neighborhood graph defined on a voxel grid, where D is the graph degree matrix, and A is a voxel neighbourhood adjacency matrix. We encourage spatial smoothness of z by letting \u03a3\nwhere \u039b z is a precision matrix and \u03bb denotes a parameter controlling the scale of the velocity field z.\nWe let x be a noisy observation of warped image y:\nwhere \u03c3 2 reflects the variance of additive image noise. We aim to estimate the posterior registration probability p(z|x; y). Using this, we can obtain the most likely registration field \u03c6 z for a new image pair (x, y) via MAP estimation, along with an estimate of uncertainty for this registration."}, {"section_title": "Learning", "text": "With our assumptions, computing the posterior probability p(z|x; y) is intractable. We use a variational approach, and introduce an approximate posterior probability q \u03c8 (z|x; y) parametrized by \u03c8. We minimize the KL divergence\nwhich is the negative of the variational lower bound of the model evidence [19] . We model the approximate posterior q \u03c8 (z|x; y) as a multivariate normal:\nwhere \u03a3 z|x,y is diagonal.\nseven squaring and scaling layers velocity field Fig. 1 . Overview of end-to-end unsupervised architecture. The first part of the network, def \u03c8 (x, y) takes the input images and outputs the approximate posterior probability parameters representing the velocity field mean, \u00b5 z|x;y , and variance, \u03a3 z|x;y . A velocity field z is sampled and transformed to a diffeomorphic deformation field \u03c6 z using novel differentiable squaring and scaling layers. Finally, a spatial transform warps y to obtain y \u2022 \u03c6 z .\nWe estimate \u00b5 z|x,y , and \u03a3 z|x,y using a convolutional neural network def \u03c8 (x, y) parameterized by \u03c8, as described below. We can therefore learn the parameters \u03c8 by optimizing the variational lower bound (4) using stochastic gradient methods. Specifically, for each image pair {x, y} and samples z k \u223c q \u03c8 (z|x; y), we can compute y \u2022 \u03c6 z k , with the resulting loss:\nwhere K is the number of samples used. In our experiments, we use K = 1. The first term encourages the warped image y \u2022 \u03c6 z k to be similar to x. The second term encourages the posterior to be close to the prior p(z). Although the variational covariance \u03a3 z|x,y is diagonal, the last term spatially smoothes the mean:\nwhere N (i) are the neighbors of voxel i. We treat \u03c3 2 and \u03bb as fixed hyper-parameters."}, {"section_title": "Neural Network Framework", "text": "We design the network def \u03c8 (x, y) that takes as input x and y and outputs \u00b5 z|x,y and \u03a3 z|x,y , based on a 3D UNet-style architecture [27] . The network includes a convolutional layer with 16 filters, four downsampling layers with 32 convolutional filters and a stride of two, and finally three upsampling convolutional layers with 32 filters. All convolutional layers use LeakyReLu activations and a 3x3 kernel.\nTo enable unsupervised learning of parameters \u03c8 using (6), we must form y \u2022 \u03c6 z to compute the data term. We first implement a layer that samples a new z k \u223c N (\u00b5 z|x,y , \u03a3 z|x,y ) using the \"re-parameterization trick\" [19] .\nWe propose novel scaling and squaring network layers to compute \u03c6 z k = exp(z k ). Specifically, these involve compositions within the neural network architecture using a differentiable spatial transformation operation.\nt ) recursively using these layers, leading to v (1) \u03c6 z k = exp(z k ). In our experiments, we use T = 7. Finally, we use a spatial transform layer to warp volume y according to the computed diffeomorphic field \u03c6 z k . This network results in three outputs, \u00b5 z|x,y , \u03a3 z|x,y and y \u2022 \u03c6 z k , which are used in the model loss (6) .\nIn summary, the neural network takes as input x and y, computes \u00b5 z|x,y and \u03a3 z|x,y , samples a new z k \u223c N (\u00b5 k , \u03a3 k ), computes a diffeomorphic \u03c6 z k and applies it to y. Since all the steps are designed to be differentiable, we learn the network parameters using stochastic gradient descent based methods on the loss (6). The framework is summarized in Figure 1 .\nOur implementation uses Keras [8] with a Tensorflow backend [1] and the ADAM optimizer [18] . We implement our method as part of the VoxelMorph package, with both implementations available online at https://github.com/ voxelmorph/voxelmorph."}, {"section_title": "Registration and Uncertainty", "text": "Given learned parameters, we approximate registration of a new scan pair (x, y) using \u03c6\u1e91 k . We first obtain\u1e91 k usin\u011d\nby evaluating the neural network def \u03c8 (x, y) on the two input images. We then compute \u03c6\u1e91 k using the scaling and squaring network layers. We also obtain \u03a3 z|x,y , enabling an estimation of the uncertainty of the velocity field z at each voxel j:\nWe also estimate uncertainty in the deformation field \u03c6 z empirically. We sample several representations z k \u223c q \u03c8 (z|x; y), propagate them through the diffeomorphic layers to compute \u03c6 z k , and compute the empirical diagonal covari-"}, {"section_title": "Experiments", "text": "We focus on 3D atlas-based registration, a common task in population analysis. Specifically, we register each scan to an atlas computed using external data [13] .\nData and Preprocessing. We use a large-scale, multi-site dataset of 7829 T1-weighted brain MRI scans from eight publicly available datasets: ADNI [25] , OASIS [22] , ABIDE [12] , ADHD200 [24] , MCIC [15] , PPMI [23] , HABS [9] , and Table 1 . Summary of results: mean Dice scores over all anatomical structures and subjects (higher is better), mean runtime; and mean number of locations with a non-positive Jacobian of each registration field (lower is better). All methods have comparable Dice scores, while our method and the original VoxelMorph are orders of magnitude faster than ANTs. Only our method achieves both high accuracy and fast runtime while also having nearly zero non-negative Jacobian locations and providing uncertainty prediction.\nHarvard GSP [16] . Acquisition details, subject age ranges and health conditions are different for each dataset. We performed standard pre-processing steps on all scans, including resampling to 1mm isotropic voxels, affine spatial normalization and brain extraction for each scan using FreeSurfer [13] . We crop the final images to 160 \u00d7 192 \u00d7 224. Segmentation maps including 29 anatomical structures, obtained using FreeSurfer for each scan, are used in evaluating registration results. We split the dataset into 7329, 250, and 250 volumes for train, validation, and test sets respectively, although we underscore that the training is unsupervised.\nEvaluation Metric. To evaluate a registration algorithm, we register each subject to an atlas, propagate the segmentation map using the resulting warp, and measure volume overlap using the Dice metric. We also evaluate the diffeomorphic property, a focus of our model. Specifically, the Jacobian matrix J \u03c6 (p) = \u2207\u03c6(p) \u2208 R 3\u00d73 captures the local properties of \u03c6 around voxel p. The local deformation is diffeomorphic, both invertible and orientation-preserving, only at locations for which |J \u03c6 (p)| > 0 [3] . We count all other voxels, where |J \u03c6 (p)| \u2264 0. Fig. 2 . Example MR slices of input moving image, atlas, and resulting warped image for our method and ANTs, with overlaid boundaries of ventricles, thalami and hippocampi. Our resulting registration field is shown as a warped grid and RGB image, with each channel representing dimension. Due to space constraints, we omit VoxelMorph examples, which are visually similar to our results and ANTs.\nBaseline Methods. We compare our approach with the popular ANTs software package using Symmetric Normalization (SyN) [4] , a top-performing algorithm [20] . We found that the default ANTs settings were sub-optimal for our task, so we performed a wide parameter and similarity metric search across a multitude of datasets. We identified top performing parameter values on the Dice metric and used cross-correlation as the ANTs similarity measure. We also test our recent CNN-based method, VoxelMorph, which aims to produce fast registration but does not yield diffeomorphic results or uncertainty estimates [6] . We sweep the regularization parameter using our validation set, and use the optimal parameters in our results.\nResults on Test set: Figure 2 shows representative results. Figure 3 illustrates Dice results on a range of anatomical structures, and Table 1 gives a summary of the results. Not only does our algorithm achieve state of the art Dice results and the fastest runtimes, but it also produces diffeomorphic registration fields (having nearly no non-negative Jacobian voxels per scan) and yields uncertainty estimates.\nSpecifically, all methods achieve comparable Dice results on each structure and overall. Our method and VoxelMorph require a fraction of the ANTs runtime to register two images: less than a second on a GPU, and less than a minute on a CPU (for our method). To the best of our knowledge, ANTs does not have a GPU implementation. Algorithm runtimes were computed for an NVIDIA TitanX GPU and a Intel Xeon (E5-2680) CPU, and exclude preprocessing common to all methods. Importantly, while our method achieves positive Jacobians at nearly all voxels, the flow fields resulting from the baseline methods contain a few thousand locations of non-positive Jacobians. This can be alleviated with increased spatial regularization, but this in turn leads to a drop in performance on the Dice metric.\nUncertainty. Figure 4 shows representative uncertainty maps, unique to our model. The velocity field is more certain near anatomical structure edges, and less confident in homogenous scan regions, such as the white matter or ventricle interior.\nParameter Analysis. We perform a grid search for the two fixed hyperparameters \u03bb and \u03c3 2 . We train a model for each parameter pair and evaluate Dice on the validation set. We search 30 values within two orders of magnitude around meaningful initial values for both parameters: \u03c3 2 \u223c (0.07) 2 , the variance of the intensity difference between an affinely aligned image and the atlas, and \u03bb = 10000, equivalent to a diagonal standard deviation of 1 voxel for \u03c6 z . We found \u03c3 2 \u223c (0.035) 2 and \u03bb \u2208 (20000, 100000) to perform well, and set \u03bb = 70, 000."}, {"section_title": "Conclusion", "text": "We propose a probabilistic model for diffeomorphic image registration and derive a learning algorithm that makes use of a convolutional neural network and an intuitive resulting loss function. To achieve unsupervised, end-to-end learning for diffeomorphic registrations, we introduce novel scaling and squaring differentiable layers. Our derivation is generalizable. For example, z can be a low dimensional embedding representation of a deformation field, or the displacement field itself. Our algorithm can infer the registration of new image pairs in under a second. Compared to traditional methods, our method is significantly faster, and compared to recent learning based methods, our method offers diffeomorphic guarantees, and provides natural uncertainty estimates for resulting registrations."}]