[{"section_title": "Abstract", "text": "The joint probability method (JPM) is the traditional way to determine the base flood elevation due to storm surge, and it usually requires simulation of storm surge response from tens of thousands of synthetic storms. The simulated storm surge is combined with probabilistic storm rates to create flood maps with various return periods. However, the map production requires enormous computational cost if state-of-the-art hydrodynamic models with high-resolution numerical grids are used; hence, optimal sampling (JPM-OS) with a small number of (~ 100-200) optimal (representative) storms is preferred. This paper presents a significantly improved JPM-OS, where a small number of optimal storms are objectively selected, and simulated storm surge responses of tens of thousands of storms are accurately interpolated from those for the optimal storms using a highly efficient kriging surrogate model. This study focuses on Southwest Florida and considers ~ 150 optimal storms that are selected based on simulations using either the low fidelity (with low resolution and simple physics) SLOSH model or the high fidelity (with high resolution and comprehensive physics) CH3D model. Surge responses to the optimal storms are simulated using both SLOSH and CH3D, and the flood elevations are calculated using JPM-OS with highly efficient kriging interpolations. For verification, the probabilistic inundation maps are compared to those obtained by the traditional JPM and variations of JPM-OS that employ different interpolation schemes, and computed probabilistic water levels are compared to those calculated by historical storm methods. The inundation maps obtained with the JPM-OS differ less than 10% from those obtained with JPM for 20,625 storms, with only 4% of the computational time."}, {"section_title": "Introduction", "text": "Coastal regions throughout much of the world are facing increasing flooding risk due to accelerating sea level rise (e.g., Sweet et al. 2017 ) and more intense storms with lower central pressure (e.g., Knutson et al. 2010; Emanuel 2013) . To enable coastal communities to develop adaptation, mitigation, and resilience strategies, it is essential to develop probabilistic coastal inundation vulnerability maps of coastal regions (e.g., Condon and Sheng 2012) . Probabilistic coastal inundation maps can be used to (1) determine property at risk evaluated in monetary units without mitigation alternatives; (2) identify areas of high flood vulnerability for development of mitigation alternatives; (3) determine flood vulnerability of coastal communities and infrastructures; and (4) guide the development of adaptation plan such as the use of green infrastructure to increase flood resilience. While FEMA (2014) has developed probabilistic coastal inundation maps using the traditional joint probability method (JPM, see, e.g., Myers 1970) and the joint probability method with optimal sampling (JPM-OS) (see, e.g., Toro et al. 2010a) , their maps do not include the effect of the sea level rise (SLR) and more intense storms in the twenty-first century. Condon and Sheng (2012) , on the other hand, developed an improved JPM-OS and used it to determine the coastal inundation maps due to SLR and more intense storms in the twenty-first century. This study further improves the JPM-OS and applies it to develop probabilistic coastal inundation maps in Southwest Florida, where the vulnerability to tropical cyclones and SLR and the population growth ranks among the highest in the USA (Blake et al. 2011; U.S. Census Bureau 2018) .\nThe joint probability method (JPM), developed by Myers (1970) for storm surge studies, is a traditional way to determine the base flood elevation (BFE), which is defined as the 1% annual chance (or 100-year) flood elevation (FEMA 2007) . In its contemporary version, JPM attempts to all possible combinations of storm landfall characteristics such as central pressure ( P c ), radius to maximum wind ( R m ), storm forward speed ( V f ), storm heading direction ( ), and the landfall location ( L 0 ), to define a large set of (~ 10,000-100,000 in principle, but much less in practice in order to reduce computational effort) synthetic storms. These synthetic storms are used by a numerical storm surge model to simulate the storm surge, and the annual exceedance probability is then calculated by using the probabilistic descriptions of storm characteristics and storm rate. JPM is by far the most promising method to estimate the annual exceedance probabilities of storm surge and gives more reliable estimates than other methods (distribution-fitting methods, empirical simulation techniques and Monte Carlo simulation) as shown by Agbley and Basco (2008) . It was the primary method adopted by FEMA (2007) to evaluate the storm surge return frequencies. However, the major weakness of JPM is the necessity to simulate a large number of (10,000-100,000) storms, which requires enormous computational time and cost when a high fidelity surge model is used (Toro et al. 2010a; Condon and Sheng 2012) .\nRecently the joint probability method with optimal sampling (JPM-OS) was developed using different optimization schemes (e.g., Resio 2007; Resio et al. 2008; Toro et al. 2010b; Condon and Sheng 2012; Nadal-Caraballo et al. 2015a ). Instead of simulating tens to hundreds of thousands of synthetic storms in JPM, JPM-OS applies interpolation and optimization to a small number (~ 100-200) of optimal storm simulations to retain the accuracy of the BFE. While the JPM-OS methods with various optimization and interpolation schemes all appeared to produce reasonably accurate probabilistic inundation maps with improved efficiency compared to the JPM-based maps, they all have their strengths and weaknesses, as will be shown in Sect. 2.\nSeveral fundamental scientific research questions concerning the JPM-OS remain to be answered before it can be readily applied to a variety of coastal flood studies with ease and confidence. For example: \"Is the JPM-OS process for selecting optimal storms objective and independent of the study site?\" \"Are optimal storms determined by low fidelity surge models (with simpler physics and low grid resolution) comparable to those determined by high fidelity surge models?\" \"What is the accuracy of the highresolution probabilistic coastal inundation maps produced by JPM-OS versus the JPMbased maps?\" In order to answer these questions, it is necessary to use a highly accurate and efficient JPM-OS method along with an efficient high fidelity surge model which 1 3 can be used to produce highly accurate probabilistic coastal inundation maps. To measure the accuracy of these maps, the high fidelity model must be so efficient that it can be used to produce the inundation maps using JPM with tens of thousands of storms, and to create a benchmark, against which the optimal sampling and interpolation scheme can be compared. Findings of this study should benefit the research community as well as anyone who uses JPM-OS for coastal flood mapping.\nThis paper aims to answer the above research questions by using a synthetic storm dataset (which corresponds the period of 1982-2009, see Sect. 4), rather than historical storms that are utilized and analyzed in Condon and Sheng (2012) , and two numerical hydrodynamic models to produce probabilistic coastal inundation maps in Southwest Florida (Fig. 1) . The objectives of the paper are to improve the methods for selecting optimal storms and interpolating inundation results of optimal storms, as well as to validate the JPM-OS by comparing inundation maps obtained with the JPM, using both a high fidelity model and a low fidelity model. For simplicity, this study focuses on the effects of storm surge and waves. The results should be applicable to other storm data sets (e.g., storm ensemble for 2060 or 2100), other high fidelity models (e.g., ADCIRC and FVCOM), as well as other model domains (e.g., Southeast Florida, Florida Panhandle, and New Jersey and New York coasts). Improved probabilistic coastal inundation maps should enable improved adaptation and mitigation strategies. Effects of future more intense storms, sea level rise, and precipitation will be addressed in a future paper.\nA relatively low fidelity (low resolution and simple physics) and computationally efficient numerical model SLOSH (Jelesnianski et al. 1992 ) is used to evaluate the responses of all possible synthetic storms in JPM, based on which optimal storms are determined. The optimal storms are then simulated using high fidelity CH3D-SSMS (Sheng et al. 2010a ); a state-of-the-art numerical surge model with grid size > 20 m (vs. > 1000 m for SLOSH) and probabilistic coastal inundation maps with various return periods are computed using JPM-OS interpolation process. Moreover, high-resolution probabilistic coastal inundation maps are also produced using CH3D-SSMS and JPM to provide the benchmark. One advantage of using modeled climatology is we can compare the predicted probabilistic water levels with those computed from the measured tidal gauge data (as shown in Sect. 4.8). Moreover, the JPM-OS with kriging interpolation and optimal storm selection introduced in this paper do not depend on the type of storm data used. This paper adopts a kriging surrogate model as the interpolation scheme of JPM-OS, while the optimization scheme, which uses the Gaussian quadrature to interpolate the surge response of any storm, could be regarded as a hybrid of JPM-OS-RS (Resio 2007) and JPM-OS-Q (Toro et al. 2010a, b) . Jia et al. (2016) used the kriging surrogate model with principal component analysis (PCA) to produce good (with R 2 close to 95% or better and RMSE less than 10%) peak surge response in coastal regions at 30 locations along Louisiana coast, but did not produce any probabilistic coastal inundation map. Zhang et al. (2018) used kriging surrogate model with the database from North Atlantic Comprehensive Coastal Study (NACCS) (Nadal-Caraballo et al. 2015a) to discover the annual exceedance rate with and without SLR. However, their results only focus on two representative locations (Battery, NY and Virginia Beach, VA) but not a large domain. As explained later, the kriging surrogate model does not require tuning because model coefficients are directly calculated by the kriging algorithm; hence, it is objective and allows full automation. The method is so efficient that it takes much less time to generate coastal inundation maps with much improved accuracy, compared to Condon and Sheng (2012) .\nIn the following, the JPM and JPM-OS with kriging are first briefly reviewed, although JPM-OS with variations of the interpolation scheme will also be discussed. Thereafter, the SLOSH and CH3D storm surge models are described briefly, followed by a discussion of the characteristics of the storms for Southwest Florida, which is the focus of this study. Selection process for the optimal storms is then presented. Probabilistic coastal inundation maps obtained using SLOSH and JPM and JPM-OS are then presented, followed by a presentation of probabilistic coastal inundation maps obtained using CH3D and JPM and JPM-OS. Tides in the microtidal SW Florida are relatively low compared to those in the mid-Atlantic coast. They have limited contribution to probabilistic flood elevations as tides have a similar chance to increase or decrease the inundation values. Therefore, tidal effect on probabilistic coastal inundation is less compared to the effects of storm surges and waves. This paper focuses on the processes for the selection of optimal storms and the interpolation of simulated inundation results for the optimal storms, rather than the inclusion of all physical processes for coastal inundation. Precipitation, which is becoming more important in recent hurricanes, is not included in this study for simplicity, but will be addressed in a later study.\nFor clarity, the annual exceedance probabilities of 2%, 1%, and 0.2% are referred as the 50-year, 100-year and 500-year recurrence level, respectively, which are also called 50-year, 100-year and 500-year return periods by FEMA. It is important to point out that surge level with 50-year return period does not mean that surge level will occur only once every 50 years, but the expected recurrence interval of that surge height is 50 years with an annual chance occurrence of 2%."}, {"section_title": "JPM and JPM-OS", "text": ""}, {"section_title": "JPM", "text": "The JPM uses the probabilistic descriptions of landfall parameters and storm rate to determine a set of synthetic storms, which are called test storms. A single storm with a set of the five landfall parameters is called a \"node ( x )\" in a five-dimensional parameter space:\nThe storms are simulated with a numerical model to generate the peak water level height (x) for the model domain. The annual rate of occurrence of the water level height greater than a specific value for a cell inside the model domain is calculated by the JPM integral (Niedoroda et al. 2010 ):\nThe integral depends on the mean annual rate of all storms for the domain, the joint probability density function f X (x) , and the conditional probability (Heaviside function) that a certain set of storm characteristics x i will generate a water level height greater than , is P[ (x i ) > ] . The integral is evaluated for all test storms, and the annual probability, which has the unit of storms per unit time, is calculated.\nThe joint probability density function as shown in Eq.\n(2) is difficult to calculate. Instead, the annual probability for the storms to produce water level exceeding a certain value can be approximately calculated by using the following formula as where n is the number of the test storms, and P is the probability of the storm with the landfall characteristics x i ."}, {"section_title": "JPM-OS", "text": "In JPM-OS, a small number (usually a few hundred) of storms called \"optimal\" (representative) storms are selected from the test storms in JPM. The optimal storms are then simulated by using a numerical hydrodynamic model to get the corresponding peak water levels. The peak water levels for all test storms are interpolated from the peak water levels of optimal storms, and the flood maps are calculated as discussed in Sect. 2.1.\nVariations of the JPM-OS use different optimization interpolation schemes: RS (response surface), BQ (Bayesian quadrature), SRF (surge response function), and MARS (multivariate adaptive regression splines). Detailed discussion on the development of these JPM-OS methods is given by Toro et al. (2010a, b Although the various JPM-OS methods are all robust methods, they could be further improved. For example, for determining the optimal storms for JPM-OS-BQ and JPM-OS-RS and the correlation distance for JPM-OS-BQ, sensitivity tests and expert judgement are required, which make the methods less objective and incapable of automation. The number of parameters considered by JPM-OS-SRF is limited, which does not allow the inclusion of more variables such as tide and sea level rise in the formulation. The JPM-OS-MARS requires defining spline coefficients, which are domain-specific. The optimization schemes of JPM-OS-RS, JPM-OS-BQ and JPM-OS-SRF were applied only to tens or hundreds of coastal stations, while the optimization scheme of JPM-OS-MARS was applied to hundreds of thousands of coastal and inland stations."}, {"section_title": "JPM-OS with kriging", "text": "A kriging model is a Gaussian process surrogate model that assumes the value at a point is correlated to the values at neighboring points and is weighted according to spatial covariance values. It is also known as the best linear unbiased predictor (Sacks et al. 1989) . In this study, the MATLAB toolbox \"DACE\" (Lophaven et al. 2002) is used for kriging interpolation with parallelism. The details are described below. Suppose there are m optimal storms X = x 1 \u2026 x m T with x i \u2208 \u211d p ( p = 5 in this study) and the corresponding water levels are Y = y 1 \u2026 y m T with y i \u2208 \u211d q . The water level (rather than inundation height, in order to ensure spatial smoothness) is used in the interpolation to ensure smooth interpolated results. The value of q could be selected from 1 to the number of land cells ( N c ). In practice, q is often selected as 1 or N c . If q = 1, every cell inside the domain has a set of kriging coefficients. This method produces more accurate results, but it takes more computing resources. It will be referred to as \"accurate kriging\", and the corresponding JPM-OS will be called JPM-OS-AK (JPM-OS with accurate kriging). If q = N c , then all cells inside the domain have the same set of kriging coefficients. The corresponding interpolated flood maps are less accurate, but it takes less time to finish. This method is referred to as \"quick kriging\", and the corresponding JPM-OS will be called JPM-OS-QK (JPM-OS with quick kriging). Additional details of kriging calculations are provided in \"Appendix\"."}, {"section_title": "Modeling systems and study domains", "text": "The Sea, Lake, and Overland Surges from Hurricanes (SLOSH) (Jelesnianski et al. 1992 ) is a 2-D numerical hydrodynamic model used to estimate storm surge heights and produce flood maps by considering the atmospheric pressure, size, forward speed, and track data of the hurricanes (Zachry et al. 2015) . It is an efficient numerical model usually running on a coarse grid with grid spacing greater than 1 km. Because of its efficiency (a few minutes CPU time for one forecast cycle), it is used in this study for the determination of optimal storms in JPM-OS. Although SLOSH does not consider wave effects and surge-tide interactions, the model is accurate to within \u00b1 20% of observed water level according to NOAA (2013). Curvilinear-grid hydrodynamics in 3D (CH3D) is a hydrodynamic model, originally developed by Sheng (1987 Sheng ( , 1990 which can simulate 2-D and 3-D barotropic and baroclinic circulation driven by tide, wind and density gradients. A boundary-fitted non-orthogonal curvilinear grid is used in the horizontal direction, and terrain-following sigma grid is used in the vertical direction in CH3D, to enable accurate resolution of the complex shorelines and geometries in coastal regions. The numerical model satisfies conservation for momentum, water mass, water temperature and salinity, by using finite-volume method of formulation. A Smagorinsky-type model for horizontal turbulent mixing and a turbulent-kinetic-energy (TKE) turbulence closure model for vertical turbulent mixing (Sheng and Villaret 1989) are used in CH3D. Due to the use of a semi-implicit numerical algorithm, CH3D is much more efficient than many other high fidelity hydrodynamic models [e.g., ADCIRC (Luettich et al. 1992) , POM (Peng et al. 2004 ), FVCOM (Weisberg and Zheng 2006) ] when similar high-resolution grid is used (Sheng et al. 2012a) . Therefore, in this study, CH3D is dynamically coupled to SWAN (Booij et al. 1999) to simulate surge, wave, and flooding in high-resolution coastal region, while ADCIRC and WaveWatch-III (Tolman 2009 ) are used to provide offshore open boundary conditions for CH3D and SWAN, respectively. This integrated storm surge modeling system, CH3D-SSMS (Sheng et al. 2006) , is capable of simulating flooding and drying and has been used extensively for simulating and forecasting numerous storm surges along the US Atlantic and Gulf coasts (e.g., Sheng et al. 2010a, b; Davis et al. 2010; Paramygin et al. 2016; Sheng and Zou 2017) . In a US Southeastern Regional Storm Surge Model Testbed (Sheng et al. 2012a) , it was found that CH3D-SSMS was the most efficient high fidelity surge model, following closely behind the low fidelity SLOSH model, while possessing similar accuracy as other high fidelity models. Details of CH3D and CH3D-SSMS can be found in Sheng et al. (2010a) .\nIn this study, CH3D is used as the state-of-the-art high fidelity numerical model for use with JPM and JPM-OS, driven by a synthetic parametric wind model (Holland 1980) . The wind and pressure fields are calculated based on location of the storm, pressure at the center, radius to maximum winds and translational velocity of the storm. An ensemble of storm tracks, which are straight line tracks with all parameters kept constant until landfall and then allowed to decrease, is created following Condon and Sheng (2012) . For simplicity, the storms are simulated by running CH3D model in a 2D vertically averaged mode, instead of the 3D mode. Results obtained with the 3D vegetation-resolving CH3D model will be reported in a later paper.\nSouthwest Florida is selected as the study domain ( Fig. 1) , of which the CH3D grid has 386,140 cells and a minimum resolution of 20 m in coastal areas with the average grid size of about 200 m. The bottom friction formulation in CH3D model uses a spatially varying Manning's coefficient, which is determined from the US Geological Survey (USGS Survey 2011) data with a value of 0.02 in the open water. The SLOSH domain \"efm2\" is shown in Fig. 1 , which has 11,100 cells and a minimum resolution of ~ 200 m and the average grid size of ~ 1500 m. CH3D domain has significantly higher spatial resolution, compared to SLOSH. In this study, all elevations are referred to the NAVD88 vertical datum. The inundation elevation is the difference between the water level and the local topography. The bathymetry data are based on GEOphysical DAta System (GEODAS 2009), and the topography data are based on the National Elevation Dataset (USGS NED 2009). The bathymetry and topography as shown in Fig. 1 have very gentle slopes, which make the region prone to coastal inundation by surge and wave."}, {"section_title": "Application to Southwest Florida", "text": ""}, {"section_title": "Storm data", "text": "The storm data are developed by LaRow et al. (2014) using the FSU-COAPS model (Kozar and Misra 2013) and Liu et al. (2014) using the WRF (Weather Research Forecast) model (Skamarock et al. 2008) for the current climate . A dynamical downscaling technique, the scale selective data assimilation (SSDA) approach, together with statistical downscaling methods are applied to the storm data of LaRow et al. (2014) to project the tropical cyclones (TCs) striking Southeast US coast region (Liu et al. 2014) . Storms that make landfall in Florida are plotted in Fig. 2 where CREF represents the simplified shoreline. There are 60 TCs in this region during the simulation period, of which seven TCs made landfall on Southwest Florida. These numbers compare well with the 64 historical storms with seven landfalls during the same time period for the region. The TCs with pressure deficit greater than 20mb at landfall are used in this study."}, {"section_title": "Distributions of landfall parameters", "text": "The central pressure deficit, radius to maximum wind, storm forward speed, and storm heading direction of landfalling storms in Southwest Florida are found from the storm data. Exiting storms are not considered. By following the method in Condon and Sheng (2012) , best fits of the data to known distribution functions are found using maximum likelihood estimation (Le Cam 1990) . The central pressure deficit, radius to maximum wind, and storm forward speed are found to best fit a Weibull distribution (Devroye 1986) , and the storm heading directions are found to best fit a Type-1 extreme value distribution (Kotz and Nadarajah 2000) . The probability density functions (PDFs) of the distributions are shown in Fig. 3 .\nTo calculate the flood maps based on JPM, several representative values have to be selected from the PDFs of the landfall parameters (Toro et al. 2010a) . In this study, five values are selected for each of the four parameters: P c , R m , , V f , and 33 values for L 0 (landfall location every 10 nautical miles of the coast). The central pressure deficit is discretized to evenly sized bins, with minimum of 13.5 mb and maximum of 78.5 mb, and bin size of 13 mb. The representative values are selected as median values of the bins. The same method is applied to radius to maximum wind, storm forward speed and storm heading direction. The entire parameter space of each parameter is covered and each parameter is evenly discretized to avoid any bias in storm selection (Condon and Sheng 2012) . The ensemble contains a total of 20,625 storms which cover all combinations of discretized parameters. Each combination of parameters is assigned a rate of occurrence. The representative values and corresponding probabilities for the landfall parameters other than landfall locations are shown in Table 1 . The distributions of storm parameters in this study are similar to those of historical storms (Condon and Sheng, 2012) . Although the radii of maximum wind are somewhat overestimated, it did not lead to significant difference in the resulting inundation map. Resio et al. (2017) discussed the correlation between storm heading and central pressure deficit (intensity) and showed that including the correlation would affect the return period of central pressure. However, the low correlation coefficient (0.02) between storm heading and intensity indicates that they are independent in this study. The intensity and radius to maximum wind (RMW) are usually correlated in the way that the more intense storms tend to have smaller radius (see Toro et al. 2010b; Condon and Sheng 2012) . However, Vickery and Wadhera (2008) found that for Gulf of Mexico landfalling hurricanes, the landfall values of RMW are not a function of pressure and latitude. The weak correlation coefficient (\u2212 0.15) between the two parameters shows that they could be treated as independent parameters in this study."}, {"section_title": "Storm rates", "text": "The storm rates are calculated following the method of Chouinard and Liu (1997) . The omni-directional storm rate of 3.1658E \u2212 04 storms/year/km is achieved by taking distance of a storm to the location of interest L o , and by using kernel estimator. The normal distribution function is used as a kernel function, and cross-validation is used to find the optimal degree of smoothness. The calculated omni-directional storm rate has the unit of Table 1 The representative values of the landfall parameters and corresponding probabilities (in the parenthesis) for traditional JPM The probabilities of landfall locations are shown in Fig. 4 . Positive value of L 0 indicates the location is North to CREF, and negative value of L 0 indicates the location is South to CREF storms/year/km. Figure 4 shows the storm rate, which is fitted to a seventh-order polynomial as a function of the distance from the CREF."}, {"section_title": "Selection of optimal storms", "text": "To perform kriging interpolation, a number of optimal storms (also referred to as training storms in literature) are selected from the large number of test storms. The optimal storms consist of two parts, fundamental and additional optimal storms. Every combination of parameters can be represented as a point (node) in a 5-D space. These nodes have coordinates equal to the values of discretized parameters and hence 20,625 storms form a grid in a 5-D space where nodes are intersections of planes with one of the coordinates held as constant and equal to a discretized value. The fundamental nodes are selected by Steps 1-3 in the following. While the 5-D case cannot be illustrated, examples of nodes in 2-D and 3-D spaces are shown in Fig. 5 .\nStep 1 Select the outer nodes of the grid formed by the planes, yielding 32 (2 5 ) optimal nodes. Step 2 Select the center nodes of edges of the grid, yielding 80 (5*2 4 ) optimal nodes.\nStep 3 Select the center node of the grid, yielding 1 optimal node. If the number of parameters in JPM is n, then the number of fundamental nodes selected in Steps 1-3 is\nThe red, green and yellow nodes in Fig. 5 illustrate the nodes selected in Steps 1, 2 and 3, respectively. There are 113 fundamental optimal nodes selected. Such selection ensures that the training set covers the realm of possible storms at a location, and no extrapolation is required, since kriging accuracy cannot be guaranteed in the extrapolation zone (Lophaven et al. 2002) . This is an important part of these schemes, as it is essential that the training set needs to cover the realm of possible storms at a location. The additional optimal nodes are selected by following Steps 4-5.\nStep 4 Perform simulations of 20,625 test storms from the entire ensemble using the SLOSH model and calculate the corresponding total inundation volumes (TIV) (see Sheng et al. 2012b) :\nwhere N c is the number of land cells of the domain, A i is the area of the land cell, and H i is the inundation height of the cell, which is calculated by subtracting bottom elevation of the cell from the simulated maximum envelope of water (MEOW, maximum water level over a single storm simulation) i of the cell. TIV is used as an objective index to quantify the storm surge over the entire domain caused by a single storm.\nStep 5 Calculate five-dimensional gradients of TIVs for all test nodes:\nwhere g x1 , g x2 , g x3 , g x4 , and g x5 are the gradient of TIV with respect to central pressure deficit, radius of maximum wind, storm forward speed, storm heading direction, and landfall location, respectively. The absolute value of g is\nThe values of |g| of every test storm are ranked from highest to lowest, and the nodes with largest N a values of |g| corresponding to those most influential storms are selected as the additional nodes. The number of additional nodes N a is determined by defining desired accuracy (according to Fig. 6 ) and available computing resources required to perform model simulations. For this particular study, N a is chosen to be 37. Figure 6 shows the dynamics of TIV, maximum inundation height (MIH; defined as the maximum inundation height within the model domain during the entire storm period), and the root-mean-square error (RMSE) between calculated and interpolated inundation (4) (2 n + n * 2 (n\u22121) + 1) Fig. 6 a TIV versus number of optimal storms. b MIH versus number of optimal storms. c RMSE between calculated and interpolated inundations versus number of optimal storms. The number in the parenthesis indicates the number of additional optimal storms selected in step 5. The right end of the dash lines of a and b indicates the TIV and MIH results by JPM using 20,625 test storms heights of the flood maps with 50-, 100-and 500-year return periods, with the number of optimal storms used in kriging interpolation. The number in the parenthesis indicates the number of additional storms selected in step 5, and no additional nodes are selected if the total number of optimal storms is less than or equal to 113. The number of additional nodes is determined by plotting the curves similar to those shown in Fig. 6 and selecting the desired level of accuracy. The additional nodes are needed to improve the accuracy of interpolation over the storms that have relatively large inundation volumes. These storms are the ones that matter in determining the flood maps with 50-, 100-and 500-year return periods. The workflow of JPM and JPM-OS is shown in Fig. 7 ."}, {"section_title": "Inundation maps obtained using SLOSH with JPM and JPM-OS", "text": "To ensure accurate probabilistic coastal inundation maps, it is important to analyze the differences between maps interpolated by JPM-OS and maps produced by JPM. In order to compare the accuracy of interpolation using the JPM-OS, different interpolation methods are tested. All test storms are simulated with SLOSH, and 150 optimal storms are selected as shown in Sect with JPM-OS-AK will produce similar results. Another interpolation scheme that was tested is JPM-OS-MARS by Condon and Sheng (2012) . Flood maps with 50-, 100-and 500-year return periods using the five methods above are shown in Fig. 8 . Statistics of the flood maps produced by JPM, JPM-OS-AK, JPM-OS-QK, JPM-OS-PCA and JPM-OS-MARS, and the computational time needed to calculate model coefficients and perform interpolation for all test storms by different methods (on a computer system with a 4-core Intel Core i7-6700 CPU) are listed in Table 2 . Coefficients of determination (R 2 ) and RMSE between simulated and interpolated inundation heights are shown in Fig. 9 . With 150 optimal storms, RMSE of 100-year flood map is reduced by 1 cm, and RMSE of 500-year flood map is reduced by 7 cm. The 500-year inundation heights with 150 optimal storms are improved locally though not reflected in TIV, compared to the ones obtained with 113 optimal storms.\nBoth JPM-OS-AK and JPM-OS-QK results deviate less than 10% from the JPM results, while the JPM-OS-AK results have slightly larger R 2 and smaller RMSE. The flood maps with 100-and 500-year return periods by JPM-OS-PCA are underestimated, with RMSE of 0.36 m and 0.82 m. The RMSE of the flood maps by JPM-OS-MARS is two times larger than that by JPM-OS-AK and JPM-OS-QK. Overall, the flood maps by JPM-OS-AK produce the most accurate results.\nJPM-OS-PCA is the fastest one of the four methods. The JPM-OS-AK interpolation produces the most accurate result, but it requires the longest computational time. This interpolation method is used to determine the inundation frequencies of Southwest and Southeast Florida for future climate scenarios . Interpolation time required for JPM-OS-QK is significantly smaller than that for JPM-OS-AK, but it is only slightly less accurate. Hence, JPM-OS-QK used in a Rapid Forecasting System to generate the flood map of a single storm within minutes of a storm track is available )."}, {"section_title": "Inundation maps obtained using CH3D with JPM and JPM-OS", "text": "The interpolated results by JPM-OS-AK based on SLOSH model show that it is possible to use interpolation instead of direct simulations (JPM) with little loss of accuracy. To produce detailed high-resolution flood maps, the 150 optimal storms are simulated by CH3D, which has more robust physics and higher grid resolution than SLOSH. Simulated MEOWs are then used in interpolation with JPM-OS-AK. To verify the assumption that the optimal storms selected based on SLOSH simulations are also suitable for interpolation of high-resolution maps based on CH3D simulations and JPM-OS-AK, all test storms are simulated by the high fidelity CH3D and the flood maps are calculated using JPM.\nThe flood maps with 50-, 100-and 500-year return periods based on JPM and JPM-OS-AK with CH3D simulations are shown in Fig. 10 , and the statistics of the flood maps and the total time and disk space needed are shown in Table 3 . Figure 11 shows comparisons between JPM-based and JPM-OS-AK-based inundation heights for CH3D simulations. The two sets are in good agreement with less than 10% differences. Comparisons of flood maps of JPM and JPM-OS-AK maps based on SLOSH and CH3D models (Figs. 8, 10) show that CH3D-based maps have smaller TIA and lower MIH than SLOSH-based ones. The RMSE of the water levels between JPM-OS-AK and JPM is 11-13 cm, which is smaller than the RMSE of 20-30 cm by Irish et al. (2009) , and 30-50 cm by Taylor et al. (2015) . The JPM-OS-AK with CH3D saves more than 95% of time and 99% disk space, while keeping the accuracy comparable to JPM. "}, {"section_title": "Compare the optimal storms determined by SLOSH and CH3D simulations", "text": "To answer the question \"Are optimal storms determined by low resolution surge models comparable to those determined by high-resolution surge models?\", the optimal storms are selected from the CH3D simulation of the test storms following the optimal storm selection method in Sect. 4.4. The flood maps with 50-, 100-and 500-year return periods by JPM-OS-AK using the optimal storms determined above are shown in Fig. 12 . These flood maps are compared with the flood maps that are interpolated by JPM-OS-AK using the optimal storms determined from SLOSH simulations of the test storms in Fig. 10 . The differences of the flood maps, most of which are below 1 ft, are shown in Fig. 12 . The small differences indicate that the optimal storms determined by low fidelity surge model and the high fidelity surge model and the corresponding flood maps are comparable. Thus, low fidelity surge model should be used to determine optimal storms, while high fidelity surge model should be used to simulate the surge during optimal storms, and JPM-OS-AK should be used to develop high-resolution probabilistic flood maps by interpolation."}, {"section_title": "Historical storm method using observed water level data for probabilistic storm surge", "text": "It is interesting to compare the probabilistic storm surge produced by CH3D in this study to that obtained using the historical storm method (HSM) which uses the observed water level data to estimate the return period (see, e.g., Katz et al. 2002; Tebaldi et al. 2012) . To this end, the hourly observed water level data from 1983 to 2009 (data from 1982 to 1983 are not available) at NOAA tidal station Naples Pier (shown in Fig. 1 ) are used. It should 1 3 be noted that this station is on a pier in open water, so the return period water levels are not inundations (as in all figures) but actual water levels. Two approaches are commonly used: the block maxima method (Katz et al. 2002 ) and the peak-over-threshold method (POT, Nadal-Caraballo et al. 2015b; Tebaldi et al. 2012) . The block maxima method first divides the observation period into non-overlapping periods of equal size, which is set to 1 year in this study, and finds the maximum water level within each year. The water levels are then fitted into a generalized extreme value (GEV) distribution, and the return periods are determined from the distribution. The peak-over-threshold method first detrends the hourly observed water level data, computes the daily maxima of water level and selects a threshold corresponding to the 99 th percentile (after trial and error) of observed water levels. Then the threshold exceedances are fitted to a generalized Pareto distribution (GPD), and the return periods are determined from the distribution. Nadal-Caraballo et al. (2015b) used POT with Monte Carlo life-cycle (POT-MCLC) method, which was repeated 10,000 times to compute the mean return periods and confidence limits. The probability distributions and confidence intervals of extreme water levels calculated using POT-MCLC are promising but not the focuses of this study. Thus, the method is not utilized here. Table 4 shows the comparisons of the water levels with 50-year, 100-year and 500-year return periods calculated by block maxima method, peak-over-threshold method and JPM-OS-AK method based on CH3D simulation. The differences of probabilistic water levels with 50-year and 100-year return periods are less than 9% between JPM-OS-AK and POT, and less than 13% between JPM-OS-AK and block maxima. The large differences of probabilistic water level with 500-year return period among the methods are likely due to the limited data used and parametric extrapolation by HSM, which could result in higher variability in the estimates, compared to JPM (Irish et al. 2011; Resio et al. 2017) . Additionally, the differences could be due to the fact that the simulated storms from FSU-COAPS model, rather than the historical storms, are used for JPM and JPM-OS in this study."}, {"section_title": "Conclusion and discussion", "text": "This paper presents an accurate and efficient JPM-OS that uses kriging surrogate model as interpolation scheme and an objective method for optimal storm selection to produce probabilistic coastal flood maps with two storm surge models: SLOSH and CH3D. Focusing on Southwest Florida where the threat of hurricane-induced storm surge and coastal flooding is high, the major findings of this study include:\n1. The efficient numerical storm surge model SLOSH is used to simulate an entire JPM ensemble that consists of 20,625 test storms. From the test storms, 150 optimal storms, which include 113 fundamental optimal storms and 37 additional optimal storms, are quickly and objectively selected. The selected set of optimal storms compares well to the set obtained using CH3D. 2. The probabilistic inundation maps of Southwest Florida obtained by JPM-OS with accurate kriging (JPM-OS-AK) using 150 optimal storms deviate less than 20% from the JPM-based maps using 20,625 test storms. This is true for both SLOSH-based and CH3D-based simulations. The RMSE of the water levels between JPM-OS-AK and JPM as shown in Fig. 9 is under 16 cm (0.525 ft) for both hydrodynamic models. This is the first time that the entire JPM ensemble of test storms is simulated with a state-of-the-art numerical hydrodynamic model. 3. The JPM-OS with quick kriging (JPM-OS-QK) is also employed in Southwest Florida.\nThe probabilistic flood maps by JPM-OS-QK are slightly less accurate than those by JPM-OS-AK, but require much less computation. JPM-OS-AK is recommended for producing probabilistic flood maps for current and future climate scenarios, and JPM-OS-QK is recommended for quick forecasting of an approaching storm. 4. The JPM-OS-AK can be employed to produce flood maps with little loss of accuracy, while the number of simulations is reduced by 1-2 orders of magnitude and the total computational time needed is reduced by an order of magnitude. 5. The probabilistic 50-year and 100-year water levels at Naples tidal station produced by JPM-OS-AK compare well to those by block maxima and peak-over-threshold methods using 27 years of hourly observed water level data. 6. The JPM and JPM-OS methods described in the study are independent of the storm data and can be applied to historical storms as well as modeled storm ensembles of current and future climate. The resulting probabilistic maps can be used for developing mitigation alternatives for flood damage reduction for today's storm conditions and future storm and sea level conditions. 7. Quick forecasting of an approaching storm would enhance the ability of emergency management to issue flood evacuation declarations shortly after a storm advisory is issued by the National Hurricane Center. The high-resolution coastal inundation maps could be used to supplement to NHC storm surge forecast.\nWhile tide could be included into JPM and JPM-OS, this study ignores the tide for simplicity. This simplification is justified since tidal range in the study area is approximately 1 m, hence much less than the combined effect of storm surge and wave. Tide could be included into JPM and JPM-OS in three ways. The first way is to expand the JPM parameter space to include the tidal amplitude and phase. This will further increase the number of test storms and optimal storms, which makes the number of storm simulations become costly. With JPM-OS-AK, several hundred (300-500) of optimal storms will be simulated using stateof-the-art numerical hydrodynamic model, which makes the method feasible. This method will be studied in the future work. The second way is to use Monte Carlo simulation, by adding tide as a boundary condition in optimal storm simulations by choosing a random start time of tide predictions. This is similar to the one used by Chiu and Dean (1984) to determine the Coastal Construction Control Lines. The third way is to consider the tide to be a secondary factor that contributes a small random component to the total water level (FEMA 2008) . This method could be implemented during post-processing after finishing the storm simulations and takes a small amount of computational effort. The JPM-OS with kriging interpolation schemes in this study could be applied to other coastal regions throughout the world and could be extended to include the probability of other factors such as tide, sea level rise and precipitation.\nOpen Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, "}]