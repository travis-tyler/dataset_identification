[{"section_title": "INTRODUCTION", "text": "Studies looking at the impact of information communication technology (ICT) tools, such as use of computers, on achievement have shown that not only the quantity but also the quality of such use is important (Lei & Zhao, 2007). Quantity or frequency of use is akin to more practice. The more experience one has with an ICT tool, the shorter is the time required to accomplish repeated tasks and the lower is the probability of making mistakes (Carrasco & Torrecilla, 2012;Henderson, Klemes, & Eshet, 2000;Lahtinen, 2012). The quality of technology use can be thought of as how and why that technology is used (Lie & Zhao, 2007). Although both computer use by teachers (computer assisted instruction [CAI]) and computer use by students have been shown to have a direct and generally positive effect on academic achievement, this study focuses on the latter use. For examples of research that evaluates the effect of CAI on academic achievement we refer the interested reader to applied studies such as Chandra and Lloyd (2008), Kulkarni (2013), and Park, Khan and Petrina (2009). With the widespread availability and use of personal microcomputers at homes and schools, a large body of literature has emerged during the last two decades suggesting that computer use can have a positive effect on academic achievement. In this respect academic achievement is usually understood to mean performance on both standardized and non-standardized assessments (such as grade point average [GPA]) in general areas of literacy such as reading, science, and mathematics (House, 2010;Junco, 2012;Wiebe & Martin, 1994;Wit, Heerwegh, & Verhoeven, 2012). Prior research has suggested that technology can be used in a number of ways but not all of those ways contribute to academic achievement. For instance, while using the internet as a homework support medium is expected to raise achievement, spending time playing non-educational computer games is likely to have no effect or perhaps even a negative effect on achievement as it distracts students from learning. The effect of educational games is not similar for all domains of the curriculum. For example, Kebritchi (2008) found that integration of educational games in the curriculum had a positive effect on achievement in mathematics while Wiebe and Martin (1994) found that such integration had no effect on achievement in geography. Thus, the effect of ICT tasks on achievement depends not only on the frequency with which those tasks are performed, but also on how such tasks are defined. A broad classification separates ICT use into two distinct categories: entertainment/non-educational related routine usage versus specific educational usage. Thus, the use of computer to chat with friends or family would fall under the former category while using a spreadsheet as a support tool to help with a specific homework problem would fall in the latter. Although this seems to be an intuitive classification scheme, it is not free of criticism. A recent body of literature has begun to suggest that entertainment-oriented ICT tasks, even when such tasks are not specifically designed to be educational, can have a significant impact on overall learning which then indirectly contributes to general knowledge and achievement. For example, Johnson (2006) argues that playing computer games designed purely for fun and entertainment without any consideration to educational outcomes can still significantly improve learning. In essence, the argument is that any type of learning has spillover effects and that the positive spillover effects of entertainment-based ICT use are no longer ignorable (Lei, 2010). The impact on achievement of specific computer programs directly tied to educational outcomes is relatively easier to justify. When a student uses a word processor to edit a paper or uses a paint program to modify a graphic file for a class project, the effect on achievement is more readily acknowledgeable. A logical way to assess the impact of ICT on achievement is thus to employ two distinct measures, one based on noneducational use and the other based on educational use of such technology. Compared to quantity, the quality of ICT use is difficult to assess. Should it be based on mediumspecific factors such as the actual quality of equipment used or should it be based on user experience such as the ease of understanding its mechanics? In most basic terms, quality of technology use is simply how and why that technology is used. For instance, in order to positively affect achievement, it is not only important that a technology, such as computer, be used but also the specific way that it is used (Lei & Zhao, 2007). One way to gather information about quality of use is to deploy survey questions that ask respondents directly why they use a specific technology. An indirect and arguably more reliable way to capture quality is to ask respondents how they feel about performing certain tasks using a certain ICT medium. For instance, if a respondent feels more confident in surfing the internet on a computer, it is very likely that such confidence is due to the quality of this task as perceived by that respondent. Thus, in this sense confidence in a task functions as a proxy for the quality of experience gained from that task. The main argument here is that not everyone gets the same benefit out of using the same technology with the same frequency. Individual experiences differ and such differences can be proxied by using self-perception measures, such as the level of confidence with which one uses that technology. The underlying assumption of course is that a better quality experience makes one more confident in tasks related to that technology. To summarize, by incorporating quality of computer use in our study we can specifically control for the issue where two students performing identical computer tasks and spending the same amount of time on those tasks may end up with different perceptions about their experience (Lei, 2010). Most of the earlier studies that looked at the effect of quantity and quality of computer use on academic achievement were based on small samples which made them unsuitable for making generalizations to large populations. A main reason for this trend was that large-scale data sources that included questions or measures specifically related to computer use mostly became available only during the last 15 or so years. The handful of studies that do employ nationally representative samples however suffer from another drawback in that they generally focus only on the quantity of computer use and tend to completely ignore the quality of computer use, thus presenting only a partial picture of the effect of computer use on academic achievement. For instance, using hierarchical linear modeling (HLM) with a nationally representative sample of 3,326 students nested in 157 schools in Turkey, Demir and K\u0131l\u0131\u00e7 (2010) showed that computer use positively affects achievement. However, it only looked at the frequency of computer use and ignored the quality of such use. In addition, only the effect of students' home-use (and not schooluse) of computers was examined. Another nationally representative study of computer use on achievement was conducted by House (2010) who used multiple regression analysis on a sample of 13-year olds from Trends in International Mathematics and Science Study (TIMSS) 2003 to look at the effect of computer activity on science achievement for American (n = 8,093) and Japanese (n = 4,540) students. His results suggested that not all computer activities enhance achievement. For the U.S. sample for instance, he found that using a computer to write reports for school significantly improved science achievement whereas using a computer to process and analyze data had no effect on such achievement. He also reported cross-country differences in the effect of computer use on achievement. For instance, the use of computer to look up ideas and information about science had a significant effect on the science achievement of Japanese students, but no effect on American students. This research also suffers from the limitation that only the frequency of various computer uses was studied. Furthermore, it did not control for major demographic variables such as age, gender, and race, which are known to be significant predictors of academic achievement in the U.S. Krentler and Willis-Flurry (2005) used a sample of 445 freshmen from a southwestern state university in the U.S. and used analysis of variance to show that there was a positive association between the frequency of computer use for course-related work and achievement in that course. However, this study produced limited results as it ignored the quality of ICT use, was based on a sample that came from a very specific geographical location, and failed to control for major demographic differences such as gender, race, and socioeconomic status. Lei and Zhao (2007) used a sample of 130 students from a middle school in Ohio to investigate the effect of quantity and quality of computer use on academic achievement. Their analysis of variance results showed that both quantity and quantity are significant predictors of academic achievement. For quantity of use, they found that students who used computers for more than 3 hours per day experienced a decrease in achievement while students who spent 1 to 3 hours per day with computers experienced an increase. For quality, they found that not all types of tasks enhanced achievement. For instance, for their sample, involvement in tasks such as webpage construction and programming improved achievement whereas a task such as using Word to take notes had a negative effect on achievement. Although Lei and Zhao (2007) included both quality and quantity of computer use, they did not control for demographic differences and their small sample prohibited generalization. The present study aims to address a number of deficiencies that prior studies suffer from, including small or unrepresentative samples, failure to control for demographic differences, and failure to assess the simultaneous effect of quality and quantity of computer use. To achieve that, this study investigates both quality and quantity of computer use on academic achievement in context of a large-scale probability sample which allows projection of our analytical results to the entire population of 15-year old high school students in the U.S. High school students were chosen because they form an age group that has progressed beyond the stage where students are still becoming familiar with the very basic computer mechanics, such as how to start a computer program or how to use the point and click interface, etc. We hypothesize that both quality and quantity of computer use are important predictors of academic achievement. If analytical results show that quality and quantity of computer use are both important, then specific contribution of quality of use to explain variation in achievement, over and above that of quantity of use will be investigated. Identification of this incremental effect is important because not all studies in the past incorporated quality-related measures (Lei & Zhao, 2007)."}, {"section_title": "METHOD", "text": ""}, {"section_title": "Data Source", "text": "The data used in this study came from the Program for International Student Assessment (PISA) 2003 results. This survey is conducted by Organisation for Economic Co-operation and Development (OECD, 2005) and administered every three years in the U.S. by National Center for Education Statistics (NCES, 2003). PISA is designed to assess reading literacy, mathematics literacy, science literacy, and problem-solving skills of 15-year old students without regard to their actual grade level. In addition to academic assessments, the survey also collects information about characteristics of students, their families, students' attitudes towards science and environment, career preferences, learning time, and perceptions towards teaching and learning. The target population is the entire 15-year old high school student population of the United States. The overall sample consists of 5,456 cases collected from 274 public and private schools, selected by two-stage stratified random sampling. Under this procedure, schools are randomly selected first, followed by a random selection of students within each school."}, {"section_title": "Participants", "text": "The original sample size of 5,456 was reduced to 4,356 after listwise deletion of missing values and outliers (boys, n = 2,129; girls, n = 2,227) comprising of 2,937 Caucasian, 663 African American, and 756 Hispanic students. Of these, 1,331 belonged to the ninth grade, 2,732 to tenth grade, and 293 to eleventh grade."}, {"section_title": "Measures", "text": ""}, {"section_title": "Achievement", "text": "This variable is a composite measure of academic achievement and was based on 167 items measuring a student's proficiency in four areas: math literacy, reading literacy, science literacy, and problem solving. Five plausible values reported on a continuous scale, with each plausible value being a random element from the set of scores that can be attributed to each student, were generated for each of the four domains which were then averaged and standardized in order to generate a single estimate of achievement for each student. A high score on this measure represents high achievement. The internal reliability estimate for the plausible values was .99."}, {"section_title": "Socioeconomic status", "text": "This scale includes 16 items and is constructed as a composite of parental education (measured as the highest parental education in years of schooling), parental occupation (based on openended questions with responses mapped to the international socio-economic index of occupational status), and home possessions. A home possessions sample question includes, \"In your home, do you have a dishwasher?\" Higher values on this index are representative of higher socio-economic and cultural status. The internal reliability estimate for the index of socioeconomic and cultural status is .63."}, {"section_title": "Internet/entertainment use", "text": "This scale includes 6 questions that measured the frequency of different types of information communication technology use. A sample question includes, \"How often do you use games on a computer?\" The response scale range was from 1-5, 1 (almost every day), 2 (a few times each week), 3 (between once a week and once a month), 4 (less than once a month), and 5 (never). Responses were inverted and scaled in such a way that higher scores are indicative of higher frequency of use. The internal reliability estimate of this scale was .78."}, {"section_title": "Programs/software use", "text": "This scale includes 6 questions that measured the frequency of different types of computer software programs used. A sample question includes, \"How often do you use drawing, painting or graphics programs on a computer?\" The response scale range was from 1-5, 1 (almost every day), 2 (a few times each week), 3 (between once a week and once a month), 4 (less than once a month), and 5 (never). Responses were inverted and scaled in such a way that higher scores are indicative of higher frequency of use. The internal reliability estimate of this scale was .75."}, {"section_title": "Confidence in routine tasks", "text": "This scale includes 11 questions that measured the confidence in performing routine tasks on a computer. A sample question includes, \"How well can you do the following task on a computer: Scroll a document up and down a screen?\" The response scale range was from 1-4, 1 (I can do this well by myself), 2 (I can do this with help from someone), 3 (I know what this means but I cannot do it), and 4 (I don't know what this means). Responses were inverted and scaled in such a way that higher scores are indicative of higher confidence. The internal reliability estimate of this scale was .84 for the original sample and .90 for the retained sample."}, {"section_title": "Confidence in internet tasks", "text": "This scale includes 5 questions that measured the confidence in performing internet-related tasks on a computer. A sample question includes, \"How well can you do the following task on a computer: Copy or download files from the internet?\" The response scale range was from 1-4, 1 (I can do this well by myself), 2 (I can do this with help from someone), 3 (I know what this means but I cannot do it), and 4 (I don't know what this means). Responses were inverted and scaled in such a way that higher scores are indicative of higher confidence. The internal reliability estimate of this scale was .70."}, {"section_title": "Confidence in high-level tasks", "text": "This scale includes 8 questions that measured the confidence in performing high-level tasks on a computer. A sample question includes, \"How well can you do the following task on a computer: Use a spreadsheet to plot a graph?\" The response scale range was from 1-4, 1 (I can do this well by myself), 2 (I can do this with help from someone), 3 (I know what this means but I cannot do it), and 4 (I don't know what this means). Responses were inverted and scaled in such a way that higher scores are indicative of higher confidence. The internal reliability estimate of this scale was .82."}, {"section_title": "Data collection approach", "text": "The PISA survey involves random selection of up to 35 students from each school. The selection was based on lists of all students born in 1987 provided by the schools. The administration involved an approximately half hour long student and background questionnaire which was followed by an approximately two hour long paper and pencil assessment. The assessment included multiple choice and constructed response items and assessed math literacy, reading literacy, science literacy, and problem solving skills. PISA does not report point estimates of final scores, but rather provides five plausible values for each of the four assessment areas. In order to address validity concerns regarding the academic achievement and its predictors the PISA student survey was preceded by a small scale pilot study that evaluated the appropriateness of survey items and scales. This involved getting the opinions of experts, using psychometric methods such as confirmatory factory analysis and structural equation modeling to ensure compliance with existing theory, and -after establishing unidimensional stability of constructs -confirming multidimensional relationship between constructs (OECD, 2005)."}, {"section_title": "Data analytic approach", "text": "All scales reported in the PISA dataset were constructed from individual items and standardized to have a mean of zero and standard deviation of one. The internet/entertainment and program/software use of computers are used as proxies for frequency of information communication technology use while the three confidence measures serve as proxies for quality. The construction of these indices is based on principles of item response theory (IRT). Given the high quality of these indices and the fact that this study is based on a secondary data source, they were not replaced with any scales specifically constructed for this study. All continuous variables, including average achievement, were standardized to have a mean of zero and standard deviation of one before inclusion in the analyses. Assumptions of linearity, normality, and homogeneity of variance were evaluated, diagnostic procedures for detection of outliers were performed, and residuals from each fitted model were analyzed for normality. For the primary analysis, prediction of average achievement, a weighted ordinary least squares multiple regression approach was used. This technique is similar to ordinary least squares multiple regression with the important difference that sampling weights are incorporated in estimation of regression parameters and their standard errors. In order to include gender and race in the regression model, one dummy variable for gender and two dummy variables for race were constructed. The base category for the gender dummy was female while that for race was white. Dummy variables for race were African American (1 = African American, and 0 otherwise) and Hispanic (1 = Hispanic, and 0 otherwise). Four hierarchical multiple regression models were fitted. The first model included only demographic variables, race, gender and SES. The second model added two new variables, internet/entertainment use and programs/software use, which captured the quantity of information communication technology use, to the first model. The second model therefore helped reveal the proportion of variation in achievement explained by quantity of information communication technology use, over and above that explained by demographic differences. Following the same logic the third model added three variables as a single block, which captured the quality of information communication technology use (confidence in routine tasks, confidence in internet tasks, and confidence in high-level tasks) to the second model. The order of inclusion of these variable blocks allowed comparison of results from this study with past research since many earlier studies routinely ignored variables related to quality of information communication technology use."}, {"section_title": "RESULTS", "text": "For the primary analysis, a number of predictors were used to explain variation in achievement. The zero-order correlation matrix for these variables is presented in Table 1. Achievement had a somewhat moderate and positive association with index of socio-economic and cultural status, r = .45, p < .001, and a weak but significant and positive correlation with confidence in routine tasks, r = .27, p < .001, and confidence in internet tasks, r = .18, p < .001. Achievement had a weak and negative but significant association with programs/software use, r = -.09, p < .001. Achievement was not associated with either the internet/entertainment use of computers, r = .03, p < .001, or with confidence in high-level tasks, r = .01, p < .001. Achievement was found to be not correlated with gender, r = .03, p = .174 but had significant correlations with both variables for race. Since gender and race are represented by dummy variables, the corresponding correlation coefficients should be interpreted as point biserial estimates. For instance, the negative correlation, r = -.32, p < .001, between African American and achievement suggests that there is a significant difference in mean achievement between African American and White students, with White students outperforming their African American counterparts on average. Similarly, the negative correlation, r = -.18, p < .001, between Hispanic and achievement suggests that there is a significant difference in mean achievement between Hispanic and White students, with White students outperforming their Hispanic counterparts on average. Socio-economic and cultural status had positive and significant correlations with internet/entertainment use, r = .19, p < .001, programs/software use, r = .12, p < .001, confidence in routine tasks, r = .22, p < .001, confidence in internet tasks, r = .23, p < .001, and confidence in high-level tasks, r = .19, p < .001. Internet/entertainment use had a moderate, positive, and significant relationship with programs/software use, r = .53, p < .001, which suggests that there is consider overlap between these two measures of quantity of information communication technology use. Multicollinearity diagnostics however showed that this was not a major issue for estimated regression equations. Internet/entrainment use also had weak to moderate correlations with the three confidence measures: confidence in routine tasks, r = .25, p < .001; confidence in internet tasks, r = .39, p < .001; confidence in high-level tasks, r = .37, p < .001. Programs/software use was weakly correlated with confidence in routine tasks, r = .15, p < .001, and confidence in internet tasks, r = .18, p < .001, and moderately correlated with confidence in high-level tasks, r = .40 , p < .001. This last correlation makes intuitive sense because high-level tasks, such as creating spreadsheet graphs, database construction etc., usually require specialized software programs. All three confidence variables were moderately correlated with each other suggesting that these confidence measures are inter-related and support each other: confidence in routine tasks and internet tasks, r = .59, p < .001; confidence in routine tasks and high-level tasks, r = .48, p < .001; confidence in high-level tasks and internet tasks, r = .50, p < .001. In order to predict the variation in achievement, a series of multiple regression models were fitted with achievement as the dependent variable. The results of these models are presented in Table  2. The first model predicted achievement from demographic variables including race, gender, and socioeconomic status. Cumulatively these three predictors explained approximately 28.9% of the variation in achievement, F = 442.57, p < .001. On average, the achievement of White students was significantly different from that of African American, t = -21.56, p < .001, and Hispanic students, t = -11.18, p < .001. More specifically, on average, achievement of White students was 1.06 standard deviations higher than that of African American students and .68 standard deviations higher than that of Hispanic students. The difference in achievement between males and females was found to be not significant, t = .27, p = . 785. An increase of one standard deviation in socio-economic and cultural status while controlling for race and gender was found to be associated with a .36 standard deviation increase in achievement t = 27.53, p < .001. Addition of internet/entertainment use and programs/software use, the two measures of quantity of information communication technology use, helped explain an additional 1.4% of the variation in achievement raising the proportion of explained variation to 30.3%, F = 42.58, p < .001. Except a slight change in the magnitudes of partial slope estimates, the significance pattern of demographic predictors did not change from what observed for model one. With race, gender and socioeconomic status held constant, a one standard deviation increase in programs/software use caused a .11 standard deviation decrease in achievement t = -7.52, p < .001. Internet/entertainment use was not found to be a significant predictor of achievement, t = -.66, p = .510. The third regression model added the three confidence variables, measures of quality of information communication technology use, to the predictors of model two. Although slight changes in magnitudes of partial slope coefficients were observed, the pattern of significance of the earlier predictors did not change. The change in R 2 was 4.0% raising the proportion of explained variation in achievement to 34.3%, F = 88.94, p < .001. With all other variables held constant, a one standard deviation increase in confidence in routine tasks raised achievement by .23 standard deviations, t = 14.30, p < .001, whereas a similar increase in confidence in high-level tasks, with everything else held constant, decreased achievement by -.14 standard deviations, t = -9.17, p < .001. Confidence in internet tasks was not found to be a significant predictor of achievement, t = 0.64, p = .519. In this final model, the unique contribution to the total variation in achievement was .104 for socio-economic and cultural status , .027 for programs/software use , .028 for confidence in routine tasks , and less than .001 for confidence in high-level tasks . An analysis of the standardized regression coefficients showed that the most important predictor of achievement was socio-economic status , followed by confidence in routine tasks , and confidence in high-level tasks . Residuals from the final regression model were assessed for normality. The histogram was found to have an approximately normal shape, and the expected versus observed cumulative probability plot was an almost perfect straight line suggesting that residuals were randomly distributed. The standardized residual versus standardized predicted value scatterplot showed a fairly consistent distribution of residuals suggesting that the homogeneity assumption was not seriously threatened. Multicollinearity diagnostics provided tolerance values that were much larger than zero (range: .54-1.00), VIF values that were all smaller than 10 (range: 1.00-1.85), condition index values that were all smaller than 10 (range: 1.00-3.37), and a condition number of 2.97 which is smaller than 30. Thus, there is ample evidence that our regression equation does not suffer from multicollinearity. Outlier diagnostics provided a maximum Cook's distance of .013 (cutoff: d = 1.0), maximum central leverage value of .011 (cutoff: k/n = 9/4356 = .002), and a maximum absolute residual value of 2.81 (cutoff: t = 3). These diagnostics suggest that outliers are not a source of concern. In order to see if the results were any different if achievement in specific subjects was used as the dependent variable, the multiple regression analysis was repeated four times with achievement in mathematics, reading, science, and problem solving used as dependent variables. However, the results obtained for individual subjects were not very different from those obtained for overall achievement. Hence, to save space, they were not presented here."}, {"section_title": "DISCUSSION AND CONCLUSIONS", "text": "The unique contribution of this paper is that it investigated the simultaneous effect of both quality and quantity of computer use on academic achievement in context of a large-scale probability sample which allows projection of our analytical results to the entire population of 15-year old high school students in the U.S. Results from the weighted ordinary least squares multiple regression analysis showed that quantity and quality of computer use are both significant predictors of overall achievement. However, the prediction strength of these variables is somewhat low with quantity of computer use explaining 1.4% of the variation in achievement and quality of use explaining an additional 4.0% for a total of 5.4% of the total variation in achievement. In other words, of the 34.3% of the variation in achievement that our most comprehensive multiple regression model accounted for, approximately one-sixth came from quantity and quality of computer use while the remaining came from demographic differences. One implication of these results is that when faced with a scenario where a choice needs to be made, then quality of use has a relatively larger impact on achievement relative to quantity, and should thus be awarded more attention in high school budgetary allocation and decision making. In terms of classroom practice this translates into providing students with help and support so that they know what they are doing and are more confident about their tasks. This aspect of our findings is in line with prior research that has found quality of computer use to be a relatively more important predictor of academic achievement as compared to quantity (e.g. Lei, 2010). In addition to the effect of quantity and quality of usage, multiple regression analysis also showed that socioeconomic status remains the single most important predictor of achievement. This result is in line with past research (e.g. Kitsantas, Ware, & Cheema, 2010) and justifies support for school-level decisions such as provision of free lunches or other resources to economically disenfranchised students. Another result that is in line with prior research (e.g. Kitsantas, Cheema, & Ware, 2011) is the existence of significant White-African American and White-Hispanic achievement gaps with the White-African American achievement gap being larger than the White-Hispanic achievement gap. The gender gap, the existence of which is disputed in the current literature, is absent in our results. This general agreement of our results with prior research and the observation of stable partial slope estimates that remain relatively unchanged from one multiple regression model to another provide support for robustness of our statistical results. One seemingly counter-intuitive result observed in the multiple regression analysis is that program/software use had a small but negative effect on achievement. One explanation for this negative effect is that specific computer programs affect very narrow areas of learning. Although this may improve achievement in those areas, it may have no association whatsoever with other areas of curriculum. In fact, spending too much time on these specialized programs may significantly and negatively affect other domains of learning with a small positive effect being completely overcome by a large negative effect. This explanation is also supported by the negative effect of confidence in high-level tasks on achievement. A high level of familiarity with and high confidence in high level tasks such as the ability to construct a webpage or create a multimedia presentation are likely to affect very narrow areas of learning where the achievement gets raised, perhaps to the extent of distracting a student from paying appropriate attention to other areas of the curriculum. Thus, it is not a surprise that we observe a positive, though moderate, correlation between program/software use and confidence in high-level tasks, r = 0.40. This makes intuitive sense because high-level tasks (such as creating graphs, database construction, etc.) usually require specialized software programs (such as programming tools, spreadsheets, etc.). The overall implication of our findings is that individual demographic characteristics such as race and socioeconomic status remain some of the most important predictors of academic achievement. Although ICT use (quality and quantity) was also found to have a significant effect on achievement, its relative effect was smaller than that of the demographic predictors. Thus, in cases where the overall aim is to reduce the gap in academic achievement, it is relatively more beneficial to first focus on eliminating racial and socioeconomic disparities. This paper has a number of limitations. First, only three racial groups (Caucasian, African American, and Hispanic) and three school grades (9, 10, and 11) were considered. Thus, no inferences can be drawn about students who do not belong to these groups. Second, the data used in this study came from a secondary source which means that we had little opportunity to modify and customize the scales for quality and quantity of information communication technology use. One direct effect of this limitation is that we were unable to look at types of information communication technology use other than computers. One of the primary strengths of the PISA dataset used in this study lies in the fact that it is based on a cross-country survey. A future extension of this paper could be to investigate differences in quantity and quality of technology use across different countries."}]