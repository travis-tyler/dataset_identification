[{"section_title": "Abstract", "text": "Whole brain extraction is an important pre-processing step in neuroimage analysis. Manual or semiautomated brain delineations are labour-intensive and thus not desirable in large studies, meaning that automated techniques are preferable. The accuracy and robustness of automated methods are crucial because human expertise may be required to correct any suboptimal results, which can be very time consuming. We compared the accuracy of four automated brain extraction methods: Brain Extraction Tool (BET), Brain Surface Extractor (BSE), Hybrid Watershed Algorithm (HWA) and a Multi-Atlas Propagation and Segmentation (MAPS) technique we have previously developed for hippocampal segmentation. The four methods were applied to extract whole brains from 682 1.5 T and 157 3 T T 1 -weighted MR baseline images from the Alzheimer's Disease Neuroimaging Initiative database. Semi-automated brain segmentations with manual editing and checking were used as the gold-standard to compare with the results. The median Jaccard index of MAPS was higher than HWA, BET and BSE in 1.5 T and 3 T scans (p b 0.05, all tests), and the 1st to 99th centile range of the Jaccard index of MAPS was smaller than HWA, BET and BSE in 1.5 T and 3 T scans ( p b 0.05, all tests). HWA and MAPS were found to be best at including all brain tissues (median false negative rate \u2264 0.010% for 1.5 T scans and \u2264 0.019% for 3 T scans, both methods). The median Jaccard index of MAPS were similar in both 1.5 T and 3 T scans, whereas those of BET, BSE and HWA were higher in 1.5 T scans than 3 T scans (p b 0.05, all tests). We found that the diagnostic group had a small effect on the median Jaccard index of all four methods. In conclusion, MAPS had relatively high accuracy and low variability compared to HWA, BET and BSE in MR scans with and without atrophy."}, {"section_title": "Introduction", "text": "Whole brain extraction (or skull-stripping) refers to the process of separating brain (grey matter (GM), white matter (WM)) from nonbrain (e.g., skull, scalp and dura) voxels in neuroimage data. Depending on the application, cerebrospinal fluid (CSF) spaces (ventricular and sulcal) may or may not be included in 'brain' segmentation. There is also variability in the inferior extent of the 'brain' extraction, but typically this includes brain stem and cerebellum and excludes cervical spinal cord. Accurate brain extraction is an important initial step in many image processing algorithms such as image registration, intensity normalisation, inhomogeneity correction, tissue classification, surgical planning, cortical surface reconstruction, cortical thickness estimation and brain atrophy estimation. For example, the inclusion of dura can result in an overestimation of cortical thickness (van der Kouwe et al., 2008) , or add errors to regional volumes and atrophy estimates. On the other hand, missing brain tissue following brain extraction may lead to a spurious suggestion of regional or cortical atrophy and these errors cannot easily be recovered in subsequent processing steps. It should be noted that image processing algorithms may be more or less sensitive to such errors but all are undesirable.\nFor large multi-site natural history studies such as the Alzheimer's Disease Neuroimaging Initiative (ADNI) (Mueller et al., 2005) or therapeutic trials, where thousands of MRI scans may require processing, segmentation algorithms which require large amounts of manual intervention are unfeasible. Robustness as well as accuracy of an automated brain extraction method are crucial to reduce the manual adjustment of method parameters or manual editing of unsuccessful or suboptimal automated brain segmentations, as such interventions are time consuming, and may decrease the reliability of the brain measures and potentially introduce bias to the results. Numerous automated whole brain extraction and skull-striping methods have been suggested (Smith, 2002; Lemieux et al., 1999; S\u00e9gonne et al., 2004; Hahn and Peitgen, 2000; Shattuck et al., 2001; Zhuang et al., 2006; Dale et al., 1999; Ward, 1999; Sandor and Leahy, 1997; Sadananthan et al., 2010) . Studies comparing some of the most widely used automated methods (Brain Extraction Tool (BET) (Smith, 2002) , 3dIntracranial (Ward, 1999) , Hybrid Watershed algorithm (HWA) (S\u00e9gonne et al., 2004) and Brain Surface Extractor (BSE) (Sandor and Leahy, 1997) ) with manual segmentations show that there is a range in accuracy of techniques. Similarity between the automated and manual skull-stripped brains using these methods as measured using a Jaccard index (intersection/union) ranged from 0.80 to 0.94 (Fennema-Notestine et al., 2006; Lee et al., 2003; Shattuck et al., 2009) . Common areas of missing brain tissue using automated segmentation methods were found to be in the anterior frontal cortex, anterior temporal cortex, posterior occipital cortex and cerebellar areas. In two comparison studies of HWA, BET and BSE, HWA was found to be the best at including all the brain tissues, while BSE and BET were found to be the best at removing non-brain tissues (Fennema-Notestine et al., 2006; Shattuck et al., 2009) .\nIt is important to test an image processing algorithm on as many different images as possible, e.g., images from different patient groups, scanner strengths, MR sequences and scanner manufacturers, in order to show that it can correctly segment images with different morphology, artifacts and characteristics. A key issue with brain extraction tools is their ability to perform adequately when there are varying amounts of cerebral atrophy present such as in Alzheimer's disease (AD). Table 1 gives an overview of brain extraction method comparison studies including sample sizes, diagnostic groups, scanner strengths and extraction algorithms used. The largest brain extraction method comparison study in the literature to date was carried out by Hartley et al. (2006) ) who compared BET and BSE with manual segmentations using the 1.5 T proton-density (PD) weighted images of 296 elderly subjects (22% with dementia). Other comparison studies predominantly used healthy subjects ranging from 20 1.5 T T 1 -weighted images of normal controls (Shattuck et al., 2001) to 68 1.5 T and 3 T T 1 -weighted images of normal controls (Sadananthan et al., 2010) . ADNI, which acquired MR images of hundreds of healthy subjects, AD subjects and subjects with mild cognitive impairment (MCI) using 1.5 T and 3 T scanners, therefore provides an ideal dataset to test automated brain extraction methods on images with different morphology, artifacts and characteristics, and to confirm the results of the relative few studies which have compared the performance of brain extraction methods in healthy and dementia subjects.\nSegmentation techniques based on multiple atlases have been applied to automatically and accurately segment various structures in the brain (Heckemann et al., 2006; Aljabar et al., 2009) , including the caudate (Klein et al., 2008) , hippocampus (Wolz et al., 2010; Leung et al., 2010a; Collins and Pruessner, 2010) and amygdala (Collins and Pruessner, 2010) . These techniques select multiple atlases from a library of labeled images (referred to as 'template library' in this paper), and propagate the labels from different atlases to the target image after image registration. Decision or label fusion techniques are then applied to combine the labels from different atlases to create an optimal segmentation, which has been shown to be more accurate and robust than the individual segmentations (Heckemann et al., 2006; Warfield et al., 2004; Rohlfing and Maurer, 2007) . This is analogous to the combination of the results from multiple classifiers in the pattern recognition field, which has been known to produce a more accurate and robust result than a single classifier (Kittler et al., 1998) . In this paper, we compare the accuracy and variability of three established automated brain extraction methods (BET, BSE and HWA) and a multi-atlas propagation and segmentation (MAPS) technique we have previously developed for hippocampal segmentation (Leung et al., 2010a) , using 682 1.5 T and 157 3 T MRI scans from the ADNI database. To the best of our knowledge, this is the largest comparison of automated brain extraction methods using multi-site 1.5 T and 3 T T 1 -weighted MRI scans from healthy controls, mild cognitive impairment (MCI) and AD subjects. The large number of scans from different patient groups, scanner strengths, MR sequences and scanner manufacturers provided by ADNI allows us to compare the performance of automated brain extraction methods on images with very different morphology, artifacts and characteristics."}, {"section_title": "Methods and materials", "text": ""}, {"section_title": "Method overview", "text": "In MAPS, the target image is first compared to all the atlases in a template library. Multiple best-matched atlases are then selected, and the labels in the selected atlases are propagated to the target image after image registration. Label fusion techniques are then applied to combine the labels from different atlases to create an optimal segmentation in the target image.\nIn the following methods sections, we describe the image data and the semi-automated whole brain segmentations that we used in the template library and used as the gold-standard for method comparison using cross-validation. Then, we provide details about MAPS, BET, BSE and HWA, and describe the parameter selection procedure for Table 1 A summary of automated brain extraction method comparison studies in chronological order from the literature."}, {"section_title": "Study", "text": "Sample size Diagnostic group Image acquisition Shattuck et al. (2001) 20 Healthy subjects T 1 -weighted images from 1.5 T scanner Smith (2002) 45 Healthy subjects 35 T1-, 6 T2-and 4 proton-density (PD)-weighted images from 1.5 T and 3 T scanners Lee et al. (2003) 23 Healthy subjects T 1 -weighted images from 1.5 T scanner Boesen et al. (2004) 38 Healthy subjects T 1 -weighted images from 1.5 T scanner S\u00e9gonne et al. (2004)) 43 Healthy subjects (14 young and 21 elderly) and subjects with dementia (2 AD and 6 with some form of dementia) T 1 -weighted images from 1.5 T scanner Fennema-Notestine et al. (2006) 32 Healthy subjects (8 young and 8 elderly), 8 unipolar depressed subjects and 8 AD subjects T 1 -weighted images from 1.5 T scanner Hartley et al. (2006) ) 296 Healthy subjects, 64 subjects with dementia and 59 subjects with infarcts PD-weighted images from 1.5 T scanner Park and Lee (2009) 56 Healthy subjects T 1 -weighted images from 1.5 T scanner Shattuck et al. (2009) 40 Healthy subjects T 1 -weighted images from 1.5 T scanner Sadananthan et al. (2010) 68 Healthy subjects T 1 -weighted images from 1.5 T and 3 T scanners each method. We describe the approaches used to compare the accuracy and variability of the brain extraction methods."}, {"section_title": "Image data", "text": "Our image data consisted of 682 1.5 T (200 controls, 338 MCI and 144 AD) and 157 3 T (53 controls, 74 MCI and 30 AD) MRI scans from the baseline time point of the ADNI database (http://www.loni.ucla. edu/ADNI). Table 2 shows the demographics of the subjects. Each individual was scanned with a number of sequences but for this study we only used the baseline T 1 -weighted volumetric scans. For 1.5 T scans, representative imaging parameters were TR = 2300 ms, TI = 1000 ms, TE = 3.5 ms, flip angle = 8\u00b0, field of view = 240 \u00d7 240 mm and 160 sagittal 1.2 mm-thick-slices and a 192 \u00d7 192 matrix yielding a voxel resolution of 1.25 \u00d7 1.25 \u00d7 1.2 mm, or 180 sagittal 1.2 mm-thick-slices with a 256 \u00d7 256 matrix yielding a voxel resolution of 0.94 \u00d7 0.94 \u00d7 1.2 mm. For 3 T scans, representative imaging parameters were TR = 2300 ms, TI = 900 ms, minimum full TE, flip angle = 8\u00b0, field of view = 256 \u00d7 240 mm and 160 sagittal 1.2 mm-thick-slices and a 256 \u00d7 256 matrix yielding a voxel resolution of 1 \u00d7 1 \u00d7 1.2 mm. The full details of the ADNI MR imaging protocol are described in Jack et al. (2008) , and are listed on the ADNI website (http://www.loni.ucla.edu/ADNI/Research/Cores/). Each exam underwent a quality control evaluation at the Mayo Clinic (Rochester, MN, USA). Quality control included inspection of each incoming image file for protocol compliance, clinically significant medical abnormalities, and image quality. The T 1 -weighted volumetric scans that passed the quality control were processed using the standard ADNI image processing pipeline, which included post-acquisition correction of gradient warping (Jovicich et al., 2006) , B1 non-uniformity correction (Narayana et al., 1988 ) depending on the scanner and coil type, intensity nonuniformity correction and phantombased scaling correction (Gunter et al., 2006) with the geometric phantom scan having been acquired with each patient scan."}, {"section_title": "Semi-automated whole brain extraction", "text": "In this section, we describe the semi-automated whole brain extraction method that was used to create both the gold-standard brain segmentations for method comparison and the atlases in our template library in MAPS.\nAll the semi-automated whole brain segmentations were performed by trained expert segmentors at the Dementia Research Centre using the 'Medical Image Display and Analysis Software' (MIDAS) . The brain segmentation is described in , but in summary: to separate the brain (grey and white matter) and non-brain voxels in the target image, a segmentor first selected two intensity thresholds representing the range of brain voxel intensities and the most inferior limits of the brain which excluded excess brainstem/spinal cord. Then, the segmentor used the erosion operation and manual editing to disconnect the brain from the skull. In order to recover eroded brain tissues, the segmentor applied the conditional dilation operation to dilate the voxels with intensity within 60% and 160% of the mean intensity of the eroded brain region. By dilating the voxels within an intensity window of the brain tissues, the conditional dilation prevented the inclusion of low intensity CSF and high intensity scalp. Furthermore, this helped to produce more consistent brain segmentations among different segmentors because the dilated region was restricted by the intensity window of the brain tissues. Lastly, the segmentor manually checked and edited the brain segmentation to include missing brain tissues and exclude nonbrain tissues. The whole process took about 30 min on average for each brain.\nThe intra-class correlation coefficient for inter-rater reliability (ICC) was greater than 0.99 calculated from 11 expert segmentors delineating five subjects' MR data. The ICC values for intra-rater reliability were all greater than 0.99 in all 11 expert segmentors, delineating five MR examinations twice.\nTo further estimate the intra-rater variability of the semiautomated brain extraction method, the same segmentor (S1) delineated the brains from a subset of 15 randomly chosen images (5 AD, 5 MCI and 5 controls) twice. Similarly, to assess the inter-rater variability, a different expert segmentor (S2) delineated the brains from the same subset of 15 images.\nThe mean (SD) Jaccard index between the two different semiautomated segmentations by the same segmentor S1 were 0.988 (0.005) (see Table 3 (a)), and the mean (SD) Jaccard index between the different five semi-automated segmentations delineated by the expert segmentors S1 and S2 were 0.989 (0.003) (see Table 3 (b) ). Furthermore, based on the 15 images (5 controls, 5 MCI and 5 AD), we found that the mean (SD) number of voxels modified by the expert segmentor S1 after the thresholding procedure was 6403 (3964).\nParameter selection of MAPS, BET, BSE and HWA Fig. 2 shows the accuracy of the 'undilated MAPS-brain' using different numbers of best-matched atlases and label fusion techniques. SBA performed better than voting and STAPLE, and the accuracy of SBA started to reach a plateau when combining more than 19 segmentations. As a tradeoff between accuracy and running-time, we decided to choose 19 best-matched atlases and combined them using SBA, which gave an average Jaccard index of 0.980 in the subset of 10 images. Fig. 3 demonstrates MAPS by showing the intermediate and final results using the chosen parameters. Table 3 The table shows the mean (SD) Jaccard index, false positive rate and false negative rate (5 controls, 5 MCI and 5 AD) between two different semi-automated brain segmentations by the same segmentor and by two different segmentors. Table 4 shows the accuracy of BET, BSE and HWA using different parameters. For BET, the best parameters were '-B -f 0.3,' which gave an average Jaccard index of 0.927. For BSE, the best parameters were '-n 4 -d 20 -s 0.70 -p,' which gave an average Jaccard index of 0.917. Furthermore, for HWA, the best parameters were '-less,' which gave an average Jaccard index of 0.962. Figs. 4-7) . Tables 5 and 6 show the median and CR (1st to 99th centile range) of the Jaccard index, false positive rate and false negative rate of MAPS, BET, BSE and HWA using the 1.5 T and 3 T scans, respectively. MAPS had the highest median Jaccard index, and BSE had the lowest median false positive rate. HWA, closely followed by MAPS, had the lowest median false negative rate. Furthermore, MAPS had the smallest CR in the Jaccard index, false positive rate and false negative rate. We found that while no MAPS and HWA segmentations failed, 2 BET segmentations (2 1.5 T images) and 3 BSE segmentations (2 1.5 T and 1 3 T images) failed (see Fig. S.1 (a) and S.1(b) in the supplementary material for two examples)."}, {"section_title": "Statistical analysis", "text": "To assess the intra-rater reliability, the Jaccard indices for pairs of whole brain segmentations of the 15 randomly chosen images delineated by the expert segmentor S1 were calculated. To assess the inter-rater reliability, the Jaccard indices for pairs of whole brain segmentations of the 15 randomly chosen images delineated by the expert segmentors S1 and S2 were calculated.\nAutomated whole brain extraction\nWe compared the Jaccard index, false positive rate and false negative rate between the brain extraction methods in 1.5 T and 3 T scans. Due to the highly skewed distribution of the Jaccard index, false positive rate and false negative rate, the median was used to measure the average accuracy of a method, and the 1st to 99th centile range (CR) was used to measure the variability in accuracy of a method. Confidence intervals (CI) for the differences in the median and CR were found using bias-corrected and accelerated (BCa) bootstrap CIs (Efron and Tibshirani, 1993 ) (10,000 bootstrap samples), using STATA's bootstrap command. This procedure created 10,000 samples by sampling subjects (and their data) from the original dataset (with replacement). Since the distribution of differences was non-normal, we report whether p b 0.05 on the basis of whether the BCa bootstrap CI for the differences includes the null value of 0. We also performed the same analysis to assess differences in the median and CR of the Jaccard index, false positive rate and false negative rate between subject diagnostic groups and between scanner field strength within each method, which are given in the supplementary material.\nWe refer to an automated whole brain segmentation as 'failed' when its Jaccard index was 0, meaning that there was no overlap between the automated and semi-automated whole brain segmentations.\nA pairwise t-test was used to compare the differences between semiautomated KN-BSI and MAPS KN-BSI in each diagnostic group. The agreement between the two KN-BSIs was further examined using a Bland-Altman plot (Bland and Altman, 1986) ."}, {"section_title": "MAPS", "text": "Our template library consisted of the 682 1.5 T MRI scans and the corresponding semi-automated brain segmentations obtained from the Section \"Semi-automated whole brain extraction\". To facilitate the matching of the target image to the atlases in the template library, all the atlases were put into the same reference space by affinely registering to a subject (ADNI subject ID = 021 S 0231, MCI male aged 60 with MMSE 29/30) with brain volume (1140 ml) near the mean brain volume of the whole group (1043 ml). The affine registration algorithm used in all our methods was based on maximising the normalised cross-correlation between the source and target images (Lemieux et al., 1994) using a conjugate gradient descent optimization scheme. Since the semi-automated brain segmentations in the template library were also used as the gold-standard for the method comparison, all experiments were performed in a leave-one-out fashion. We excluded the image being segmented from the template library, meaning that the template library effectively consisted of 681 scans for the leave-one-out experiments.\nTo extract the whole brain from the target image, we performed the following three steps (also see Fig. 1 ):\n1. Template selection: the target image was affinely registered to the subject to which all the template library scans were registered. Best matches from the template library were ranked as to their similarity using the cross-correlation (R 2 ) between the target image and the template library over the two-voxel dilated whole brain segmentations. Cross-correlation has been shown to provide Table 2 The demographics of the 682 subjects with 1.5T MRI scans and 157 subjects with 3T MRI scans.\nWe applied MAPS to the 10 randomly chosen 1.5 T scans in order to determine the number of best-matched atlases and the optimal label fusion technique required to produce accurate 'undilated MAPSbrains' by comparing them to the semi-automated brain segmentations. We combined segmentations from 3 to 29 best-matched atlases using either voting (Heckemann et al., 2006) , shape-based averaging (SBA) (Rohlfing and Maurer, 2007) or simultaneous truth and performance level estimation (STAPLE) (Warfield et al., 2004) . For SBA, we used the 50% trimmed mean (Rothenberg et al., 1964) instead of the simple mean when calculating the average distance of a voxel to the labels in order to increase the robustness to outliers."}, {"section_title": "1.5T scans 3T scans", "text": "Control (n = 200) MCI (n = 338) AD (n = 144) Control (n = 53) MCI (n = 74) AD (n = 30)\nMean age (SD), years 76.0 (5.1) 74.9 (7.2) 75.4 (7.4) 75.3 (5.0) 74.9 (7.6) 74.8 (9.2) Gender (male, %) 106 (53%) 214 (63%) 77 (53%) 19 (36%) 47 (64%) 11 (37%) a good criterion for template selection in multi-centre imaging data (Aljabar et al., 2009) . Once a rank of best to worst matches was established, a subset of the highest ranking matches could be used to propagate the undilated whole brain segmentation onto the target image. 2. Label propagation: the best-matched atlases were registered to the target image using affine registration and non-rigid registration based on free form deformation (Rueckert et al., 1999; Modat et al., 2010) . Multiple control point spacings (16 mm \u2192 8 mm\u2192 4 mm) were used in the non-rigid registration to model increasingly local deformations. The whole brain segmentations in the best-matched atlases were then propagated to the target image using the results of the registrations. The grey level whole brain segmentation in the target image was thresholded between 60% and 160% of the mean intensity of the segmentation, followed by a two-voxel conditional dilation within 60% and 160% of the mean intensity of the segmentation. The same intensity thresholding and two-voxel conditional dilation was previously used to recover missing brain tissues in the automated segmentation of whole brain regions in the repeat images using the propagation of the semi-automated whole brain regions in the baseline images (Evans et al., 2009; Leung et al., 2010b ). 3. Label fusion: Multiple brain segmentations in the target image were combined using label fusion. The fused segmentation was further unconditionally dilated by two voxels to recover any missing brain tissues because it was felt better to possibly include more non-brain tissues, than to exclude real brain tissues, as described in S\u00e9gonne et al. (2004) . We referred to the dilated fused segmentation as the automated whole brain segmentation from MAPS and the undilated one as 'undilated MAPS-brain.' BET in FMRIB Software Library version 4.1.4 (http://www.fmrib.ox.ac.uk/fsl/) BET estimates the minimum and maximum intensity values of the brain image, and evolves a deformable model to fit the brain surface based on smoothness criteria and a local intensity threshold (Smith, 2002) ."}, {"section_title": "BSE in BrainSuite version 09e (http://www.brainsuite.usc.edu/)", "text": "BSE uses a 2D Marr-Hildreth operator for brain edge detection after anisotropic diffusion filtering (Shattuck et al., 2001) . Mathematical morphology is then used to extract the brain from the edge map.\nHWA in FreeSurfer version 4.5 (http://www.surfer.nmr.mgh.harvard.edu/)\nHWA combines watershed algorithms and deformable surface models (S\u00e9gonne et al., 2004) . The watershed algorithm provides a robust initial estimate of the brain volume for the deformable model to fit a smooth surface around the brain. A statistical atlas is used to validate and correct the brain extraction."}, {"section_title": "Parameter selection", "text": ""}, {"section_title": "Training datasets", "text": "Our previous experiences with MAPS suggested that a relatively small number of images were sufficient to choose the reasonable parameters for the wider dataset. We randomly selected ten 1.5 T scans as the training dataset for MAPS. For BET, BSE and HWA, we randomly selected 18 scans by choosing one scan from each diagnostic group (controls, MCI and AD) in each field strength (1.5 T and 3 T) from each scanner manufacturer (GE, Philips and Siemens), in order to provide a variety of different images in the training dataset. The best parameters were determined by comparing the results with the semi-automated brain segmentations. The best parameters were then used for our whole dataset. Note that we decided to use a larger and more evenly distributed training dataset for BET, BSE and HWA than MAPS, in order to be able to get the best possible results from them."}, {"section_title": "BET", "text": "We chose to investigate the fractional intensity threshold option '-f' (default = 0.5) and the following additional mutually exclusive options: '-R' for robust brain centre estimation, '-S' for eye and optic nerve cleanup and '-B' for bias field and neck cleanup. We applied BET to the 18 randomly chosen scans using either with no option, '-R,' '-S' or '-B' to determine the best mutually exclusive option. Our previous experiences with BET showed that it had a tendency to exclude some brain voxels in the results. As the documentation of BET states that a smaller fractional intensity threshold returns a larger brain region, we varied the fractional intensity thresholds between 0.0 and 0.5 (increment of 0.1) after determining the best mutually exclusive options ('-R,' '-S' or '-B')."}, {"section_title": "BSE", "text": "We chose to examine the following parameters: '-n' for the number of diffusion iterations, '-d' for the diffusion constant and '-s' for the edge constant. We applied BSE to the same 18 randomly chosen scans (used for parameter selection in BET) using the option '-p' (for post-processing dilation of the final brain mask) and all the combinations of the following parameters: '-n' = (4, 5, 6, 7, 8, 9, 10) , '-d' = (14, 15, 16, 17, 18, 19, 20, 21, 22) , '-s' = (0.5, 0.6, 0.7, 0.8, 0.9)."}, {"section_title": "HWA", "text": "We chose to investigate the following parameters as Shattuck et al. (2009) : '-atlas': use the atlas information to correct the segmentation, 'less': shrink the surface and 'more': expand the surface. We applied HWA to the same 18 randomly chosen scans using the following options: default, '-less,' '-more,' '-less -atlas' and '-more -atlas.'"}, {"section_title": "Method comparison", "text": ""}, {"section_title": "Quantitative evaluation metrics", "text": "The automated whole brain segmentations were compared to the semi-automated whole brain segmentations obtained (described in Section \"Semi-automated whole brain extraction\") using the Jaccard index, false positive rate and false negative rate Sadananthan et al., 2010) :\n\u2022 Jaccard index was used to measure the overlap similarity of two segmentations and is defined as j A\u2229B j j A\u222aB j ; where A is the set of voxels in the automated region and B is the set of voxels in the gold-standard region;\n\u2022 False positive rate was used to measure the probability of false brain voxels in the automated segmentation, and is defined as\nwhere F P is the set of false positive voxels and T N is the set of true negative voxels. It is related to the specificity by: specificity = 1 \u2212 (false positive rate); \u2022 False negative rate was used to measure the probability of missing brain voxels in the automated segmentation, and is defined as\nwhere F N is the set of false negative voxels and T P is the set of true positive voxels. It is related to the sensitivity by: sensitivity = 1 \u2212 (false negative rate).\nDifferent automated brain extraction methods generated segmentations containing different amounts of CSF voxels. In order to avoid the influence of different amounts of CSF voxels included in the segmentations, we followed the comparison methods suggested by Boesen et al. (2004) and Sadananthan et al. (2010) when calculating the Jaccard index and false positive rate. Low intensity voxels were excluded from all the whole brain segmentations by using a consistent threshold. We chose the threshold as 60% of the mean intensity of the gold-standard semi-automated brain segmentation. The Jaccard index and false positive rate were then calculated using the thresholded whole brain segmentations. The false negative rate was calculated using the unthresholded whole brain segmentations.\nSince the 'undilated MAPS-brains' were derived from the semiautomated whole brain segmentations, we also performed a direct comparison between them using the Jaccard index, false positive rate and false negative rate without excluding low intensity voxels. This direct comparison was not performed for BET, BSE and HWA because of the different amounts of CSF included in BET, BSE, HWA, and the 'gold-standard' semi-automated segmentations, which would make the results less meaningful."}, {"section_title": "Qualitative analysis using projection maps", "text": "In order to visualise the locations of the segmentation errors in different automated whole brain extraction methods, we generated projection maps of the false positive and negative voxels ). All the images in our dataset were non-rigidly registered to the subject (ADNI subject ID = 021S 0231) to which all the template library scans were registered. Multiple control point spacings (16 mm \u2192 8 mm\u2192 4 mm) were used in the non-rigid registration to model increasingly local deformations. We then affinely registered the subjects to the MNI 305 atlas (Mazziotta et al., 1995) . Using the affine and non-rigid transformations, we mapped the false positive and negative voxels of all the segmentations into the MNI 305 atlas using nearest-neighbour interpolation. For each transformed false positive and negative map, we computed 2D sagittal, coronal and axial projections by summing the counts of voxels along the respective directions. Each pixel in these 2D projection maps denoted the number of erroneous voxels along a projected ray in the particular direction. To summarise all the false positive (or negative) projection maps of a brain extraction method, we calculated an average projection map from the projection maps of all the segmentations by taking the mean value of all the projection maps at each pixel.\nNon-brain tissue was included in all automated segmentation algorithms (see Fig. 8 ). All algorithms erroneously added dura surrounding the cerebellum (including tentorium) and cortex (including falx cerebri). Inclusion of these extra tissues appeared relatively more pronounced and extensive using HWA particularly in the tentorium and nervous tissue running medial to the temporal lobes including optic nerves. Neck and other non-brain tissues inferior to the brain area were included in some segmentations of BET. Our false negative maps (see Fig. 9 ) show more discrepancies across techniques compared with the false positive maps. It is important to note the differences in scale bar when comparing across these techniques; the scale bar for MAPS and HWA extend only to 0.6 whereas BET and BSE extend to 10. Very few areas were erroneously excluded by MAPS and these areas appear to fall largely outside of the brain (for example, tentorial tissue) and may therefore represent subtle manual missegmentations (see Fig. 10 ). BET appeared to wrongly exclude cerebellar and occipital lobe tissue as well as anterior temporal and frontal lobe areas in some cases. The fact that the whole of the brain was visible using BET was due to complete failure of the technique in a very small number of images as described above. BSE appeared to falsely exclude cerebellar and inferior temporal lobe tissue on a number of scans. HWA, much like BSE, had some problems correctly including cerebellar tissue on some images, and in a very small number of cases (see scale bar) this extended to the remainder of the brain."}, {"section_title": "Application of 'undilated MAPS-brains' in brain atrophy estimation", "text": "The boundary shift integral (BSI) provides a precise measurement of brain atrophy from two serial MR scans . The first step in BSI requires the extraction of the brain regions that includes GM and WM and excludes internal and external CSF from the two serial MR scans. KN-BSI was recently proposed to produce a more robust atrophy estimation in multi-site data by incorporating better intensity normalisation and automatic parameter selection (Leung et al., 2010b) . We therefore compared the use of semi-automated segmentations and 'undilated MAPS-brains' in brain atrophy estimation of the baseline and 12-month 1.5 T scans of our ADNI dataset using KN-BSI.\nWe applied MAPS to obtain 'undilated MAPS-brains' of the baseline and 12-month 1.5 T scans, and used them to calculate KN-BSI (referred to as MAPS KN-BSI). We also calculated a KN-BSI using the semi-automated segmentations in the baseline scans and propagated brain segmentations in the 12-month scans as Leung et al. (2010b) and Evans et al. (2009) (referred to as semi-automated KN-BSI). The propagated brain segmentations in the 12-month scans were calculated by propagating the semi-automated segmentation from the baseline scans to the 12-month scans of the same subject using affine registration and non-rigid registration based on B-splines (Rueckert et al., 1999) .\nWe found excellent agreement between semi-automated KN-BSI and MAPS KN-BSI (see Table 10 and Fig. 11) , although there were small statistically significant differences between them (with semiautomated KN-BSI N MAPS KN-BSI)."}, {"section_title": "Results", "text": ""}, {"section_title": "Jaccard index", "text": ""}, {"section_title": "Between-method comparison", "text": "Tables 7 and 8 show differences in median and CR (1st-99th centile range) of the Jaccard index, false positive rate and false negative rate between MAPS, BET, BSE and HWA.\nAccuracy. There was evidence of differences in the median Jaccard index among all the automated brain extraction methods except between HWA and BET. In both 1.5 T and 3 T segmentations, the median Jaccard index of MAPS was higher than HWA and BET, which in turn was higher than BSE.\nThere was evidence that the median false positive rates differed among all the methods. The methods in ascending order of the median false positive rate were BSE, MAPS, BET and HWA in 1.5 T segmentations and BSE, BET, MAPS and HWA in 3 T segmentations.\nThere was evidence that all false negative rates differed among the methods except in 1.5 T segmentations between HWA and MAPS. In 1.5 T segmentations, the median false negative rates of MAPS and HWA were lower than BET, which in turn was lower than BSE. In 3 T segmentations, the methods in ascending order of the median false negative rate were HWA, MAPS, BET and BSE.\nVariability in accuracy. There was evidence of differences in the CRs of the Jaccard index among all the automated brain extraction methods except in 3 T segmentations between BET, BSE and HWA. In 1.5 T segmentations, the methods in the ascending order of CR of the Jaccard index were MAPS, HWA, BSE and BET. In 3 T segmentations, the CR of the Jaccard index of MAPS was smaller than BET, BSE and HWA.\nThere was evidence of differences in the CRs of the false positive rate among all the automated brain extraction methods except in 3 T between HWA and BET. In 1.5 T segmentations, the methods in ascending order of the CR of the false positive rate were MAPS, HWA, BSE and BET. In 3 T segmentations, the CR of the false positive rate of BSE was smaller than MAPS, which in turn was smaller than HWA and BET.\nThere was evidence of differences in the CRs of the false negative rate among all the automated brain extraction methods except in 3 T between HWA, BET and BSE. In 1.5 T segmentations, the methods in ascending order of the CR of the false negative rate were MAPS, HWA, BSE and BET. In 3 T segmentations, the CR of the false negative rate of MAPS was smaller than BET, BSE and HWA."}, {"section_title": "Computation time", "text": "The computation time of BSE and HWA were about 1 minute per image running on a personal computer with a Intel(R) Xeon(R) CPU (X5472 3.00 GHz) and 4Gb of RAM, whereas the computation time of BET was about 10 min per image. The computation time of MAPS was about 19 h because of the computationally expensive nonrigid registrations. Table 9 shows the direct comparison between the 'undilated MAPS-brains' and semi-automated segmentations. The median Jaccard index (CR) was 0.980 (0.053) and 0.974 (0.106) in 1.5 T and 3 T segmentations."}, {"section_title": "Direct comparison of 'undilated MAPS-brains' with semi-automated segmentations", "text": "Note that the median Jaccard index and false positive rate of 'undilated MAPS-brains' are similar to thresholded MAPS segmentations in Table 5 . This was due to the fact that the thresholding removed most of the lower intensity voxels (e.g., CSF) after the twovoxel dilation. On the other hand, since the false negative rate was Table 4 The mean (SD) Jaccard index of BET, BSE and HWA of the 18 randomly selected scans (one scan from each diagnostic group (Controls, MCI and AD) in each field strength (1.5 T and 3 T) from each scanner manufacturer (GE, Philips and Siemens) from the parameter selection. The best parameters for each method are in bold. Note that only the top 5 BSE results are shown in the table."}, {"section_title": "Method", "text": "Parameters calculated using the unthresholded MAPS segmentation, the false negative rate of the MAPS segmentation was lower than the 'undilated MAPS-brain.'"}, {"section_title": "Post-hoc analysis", "text": "Since our results showed that the median accuracy of MAPS was higher than BET, BSE and HWA in the ADNI dataset when using our semi-automated brain segmentations as the gold-standard, we used the Segmentation Validation Engine (SVE) website (http://www.sve. loni.ucla.edu/archive/) to further test MAPS on a different dataset (40 healthy subjects; mean (SD) age = 29.2 (6.3)), and compared the results with the gold-standard brain masks delineated using a different manual segmentation protocol as described in Shattuck et al. (2009) . Since the brain masks provided by the SVE website included all the internal ventricular CSF and some external sulcal CSF, we slightly modified the MAPS algorithm to include them in the brain segmentation (see Appendix A for more details). The median (CR) Jaccard index of MAPS was 0.955 (0.019) (ID = 173, http://www.sve.loni.ucla.edu/ archive/study/?id=173), which was the highest amongst all the entries at the time of writing (other entries included BSE, BET, HWA, statistical parametric mapping (SPM) (Ashburner and Friston, 2005) and various other algorithms). The median Jaccard index of MAPS was 0.002 (95% CI (\u22120.001, 0.004), p N 0.05) higher than the second highest entry (which used the voxel-based morphometry (VBM) toolbox (version 8, http:// Fig. 4 . Examples of whole brain extraction results of MAPS, BET, BSE and HWA of a 1.5 T scan (ADNI subject ID: 126 S 0680). While all techniques had some errors in including nonbrain (e.g., dura) voxels in some areasthe amount varied between methods (arrows). www.dbm.neuro.uni-jena. de/vbm8/VBM8-Manual.pdf)), and the CR of the Jaccard index of MAPS was 0.009 (95% CI (\u22120.005, 0.013), p N 0.05) lower than VBM. The CIs suggested that both tests were close to statistical significance."}, {"section_title": "Conclusions and discussion", "text": "We wished to evaluate a template-based automated brain extraction method (MAPS) and a number of well-established automated brain extraction methods relative to a conventional semi-automated method that involves time consuming manual editing. We applied the four automated brain extraction methods (MAPS, BET, BSE and HWA) to over 800 scans from the ADNI database. This set of images included scans with a range of anatomy and atrophy: from healthy elderly subjects with little atrophy to MCI and AD subjects with very significant atrophy.\nAll four methods showed reasonable overlap (Jaccard index) with the semi-automated 'gold-standard' segmentation. Among the four methods, MAPS had higher median accuracy and smaller variability in accuracy. Both MAPS and HWA had low false negative and false positive rates, meaning that they were able to preserve nearly all the brain voxels and, at the same time, removed most of the non-brain voxels. MAPS removed more non-brain voxels than HWA and was less variable than HWA in terms of the CR of false positive rate and false negative rate. Although the median accuracy of BET was higher than BSE, the variability in accuracy of BSE was lower than BET. Of note, in the direct comparison, 'undilated MAPS-brains' were found to be very accurate, with a median Jaccard index of 0.980 in 1.5 T segmentations. This is close to the mean Jaccard index of two Fig. 5 . Examples of whole brain extraction results of MAPS, BET, BSE and HWA of a 1.5 T scan after thresholding using 60% of the mean intensity of the semi-automated whole brain segmentation (ADNI subject ID: 126S 0680). different segmentations produced by the same segmentor (0.988) and segmentations performed by different segmentors (0.989). Furthermore, MAPS KN-BSI was in excellent agreement with semiautomated KN-BSI, and the small mean (SD) difference of 0.02% (0.08%) between them was less than the mean (SD) difference of 0.05% (0.47%) in BSI between same-day scan pairs reported by Boyes et al. (2006) in a different study.\nWe compared the four automated brain extraction methods qualitatively using the false positive and false negative projection maps (see Figs. 8 and 9 ). While the false positive projection maps appear quite similar with added dura surrounding the cerebellum, the false negative projection maps show that different methods failed to include tissues in different locations as represented by different 'hot spots.' BET appeared to tend to exclude temporal and frontal lobe tissues (consistent with the findings of Shattuck et al., 2009 ) as well as cerebellar tissue. Both BSE and HWA appeared to erroneously exclude cerebellar tissue. However, Shattuck et al. (2009) did not find that HWA excluded much cerebellar tissue, which was likely due to the difference in the range of morphology and characteristics of the brain images in the datasets. The results of the quantitative comparison between BET, BSE and HWA are similar to those reported by Fennema-Notestine et al. (2006) , Shattuck et al. (2009) and Sadananthan et al. (2010) , with HWA being better at preserving brain voxels than BET and BSE, and BET and BSE being better at removing non-brain voxels than HWA.\nAlthough the effect of scanner field strength on the accuracy of MAPS and HWA was minimal, the effect on the robustness of HWA was large: the CR of the false negative rate in 3 T segmentations is 39 percentage points higher than 1.5 T segmentations. The median Jaccard index and false negative rate of BET and BSE in 1.5 T segmentations were better than 3 T segmentations. Although there was no evidence of a difference in the variability in the Jaccard index of BET and BSE between 1.5 T and 3 T segmentations, the CR of the false negative rate of BSE in 3 T segmentations was 40 percentage points higher than 1.5 T segmentations. Sadananthan et al. (2010) also found that the performance of the methods were different in their 1.5 T and 3 T datasets.\nDespite the efforts put into trying to ensure that the characteristics of MR images in the ADNI dataset were similar across different scanner manufacturers and field strengths, there are inevitably significant differences and it is interesting that field strength significantly affected the accuracy and robustness of the automated brain extraction methods. The effect of the diagnostic groups on the automated brain extraction methods was complicated; the accuracy of MAPS in all the groups was similar, however, MAPS produced slightly less robust results in controls. This is likely due to the twovoxel dilation performed at the end of the processing as the dilated brain region in controls is more likely included non-brain tissues (e.g., dura) than MCI or AD subjects. BET produced more accurate results in controls with higher median Jaccard index and lower median false negative rate. On the other hand, there was little suggestion of the robustness of BET being different across diagnostic groups except at 3 T the segmentations of AD subjects were more robust than control. Although there was no evidence of a difference in the accuracy of BSE between diagnostic groups, it was surprising that the robustness of BSE was significantly better in MCI subjects in 1.5 T segmentations. The accuracy of HWA in all the diagnostic groups was similar. Although there was no evidence of a difference in the robustness of HWA between diagnostic groups, the CR of the false positive rate of controls tended to be smaller than AD and MCI subjects.\nAlthough we did not find any significant difference in the median Jaccard index of BSE and HWA between diagnostic groups, we found that BET produced significantly more accurate results in controls than MCI and AD subjects in both 1.5 T and 3 T scans. This was similar to Fig. 7 . Examples of whole brain extraction results of MAPS, BET, BSE and HWA of a 3 T scan after thresholding using 60% of the mean intensity of the semi-automated whole brain segmentation (ADNI subject ID: 037S 1225).\nthe findings of Fennema-Notestine et al. (2006) that the average Jaccard index of BET in young normal controls was higher than AD subjects (Fig. 5 of Fennema-Notestine et al., 2006) .\nWe previously found that STAPLE was the best method to combine multiple hippocampal segmentations in terms of the Jaccard index (Leung et al., 2010a) . However, we found shape-based averaging to be better for whole brain segmentations. The best label fusion method is likely to be problem specific, consistent with the findings of Artaechevarria et al. (2009) ; in that depending on the characteristics of the images and regions, globally or locally weighted voting produced substantially better results than simple majority voting. It is interesting to note that the chosen parameters give similar results in the small subset and our whole dataset, meaning that the 10 randomly chosen 1.5 T images have provided a good sample for parameter selection in MAPS. Given the excellent results in the 3 T scans and the scans from SVE, the chosen parameters may also be suitable for scans acquired using different MR sequences and scannersthis potential generalisabilty (based on the range of anatomy included in the template library) is a possible advantage over those methods that require parameter selection based on a subset of scans. The oscillation in the accuracy of SBA in Fig. 2 may appear concerning in terms of performance; however, it is due to the discreteness in 50% trimmed mean: the 50% trimmed mean discards equal or unequal numbers of segmentations from either side depending on the number of segmentations.\nFor large studies and clinical trials, it is more important to minimise the human interaction time and expertise required to correct any suboptimal segmentation (e.g., parameter fine-tuning or manual editing) than to minimise the computation time of the algorithm. Although the computation time of MAPS is comparatively much longer than BET, BSE and HWA, the robustness of MAPS was substantially higher than the other methods. Furthermore, the processing time of MAPS can be improved by (1) running the software using a computer cluster, (2) using fewer atlases in a tradeoff between accuracy and computation time, or (3) running the non-rigid registration on a graphical processing unit (GPU) (Modat et al., 2010) .\nOne of the strengths of this study is the large number of images of AD, MCI and control subjects acquired from scanners of different field strength and manufacturers at multiple sites. To the best of our knowledge, this is the largest comparison of automated brain extraction methods in the literature. Another strength of this study is that all the data and softwares will be openly available to the public on the world wide web. All the scans can be downloaded from the ADNI website (http://www.adni-info.org). The semi-automated brain segmentations will be available on the ADNI website. BET, BSE and HWA are all available on the web (see Section \"Automated whole brain extraction\"). The registration software and label fusion softwares used in MAPS can be downloaded at http://www.sourceforge. net/projects/niftyreg/ and http://www.itk.org/. We will make all the MAPS-brain regions available online at the ADNI website (http:// www.adni.loni.ucla.edu/). 3 One of the limitations of this study is the lack of ground-truth whole brain segmentations in the method comparison. Instead, we used semi-automated segmentations which were then manually edited by trained expert segmentors. The segmentors followed a predefined segmentation protocol to ensure low intra-and inter-rater variability. Another limitation is that the amount of brain stem labelled as brain may not be consistent between the semi-automated and automated segmentations. Although the thresholding was designed to remove CSF from the automated segmentations to allow the comparison with semi-automated segmentations, it may remove some grey matter from the brains and lose some important information at the boundary of the brain. We also did not try to use other label fusion algorithms in MAPS (apart from vote, SBA and STAPLE), such as a local weighted voting method (Artaechevarria et al., 2009) or a selective and iterative method (Langerak et al., 2010) . In addition, although we examined most of the parameters in BET, BSE and HWA using a subset of scans from our dataset, an expert user may be able to fine-tune other parameters or use a different subset to produce better results.\nDespite the fact that all the MAPS experiments were carried out in a leave-one-out fashion, MAPS may have an advantage over other methods in the comparison because the definition of a brain region in the MAPS segmentations is likely to be more consistent with the semi- automated segmentations. Partly our motivation for developing and assessing MAPS was to replace the semi-automated segmentationthere is therefore some potential intrinsic advantage to MAPS (relative to BET, BSE and HWA). As such we must be cautious about the conclusions. Nonetheless the advantage is arguably minimal because of the following:\n1. The post-hoc analysis showed that MAPS performed well both in terms of accuracy and variability in accuracy on a different and independent dataset with gold-standard brain masks delineated using a different manual segmentation protocol (SVE). The comparison using SVE is not only independent but also involves a wide range of algorithms with parameters that have been fine-tuned either by the developers or Shattuck et al. (2009) . Currently, SVE contains 118 sets of results from several algorithms (e.g., VBM8, BSE and brainwash2). We found that the evaluations using our semi-automated brain segmentations and the independent gold-standard segmentations from SVE are consistent with each other; 2. The final step in MAPS involved a two-voxel unconditional dilation.\nAlthough this step was designed to recover missing brain tissues, it also substantially reduces the similarity between the MAPS segmentations and the gold-standard segmentations. For example, using a randomly chosen brain segmentation in our template library, a two-voxel dilation reduces the Jaccard index from 1 to 0.741; 3. There is a substantially amount of manual intervention in the semiautomated segmentation, which includes the selection of the initial intensity thresholds and the editing of brain/non-brain tissues during various stages of the semi-automated segmentation; 4. In order to reduce the influence of the amount of CSF included in the automated brain segmentations in the comparison, the Jaccard index and the false positive rate were calculated using thresholded brain segmentations as in Sadananthan et al. (2010) and Boesen et al. (2004) . The thresholding values were given by 60% of the mean brain intensity of the gold-standard segmentation. This thresholding step ensures consistent cut-off points between CSF and GM interface in all the automated segmentations; 5. The false positive rate and false negative rate maps of MAPS show errors near the inferior brain stem. This suggests that there is still inconsistency between the MAPS-brain segmentations and goldstandard segmentations.\nThe outputs of different brain extraction algorithms include different amount of internal ventricular and external sulcal CSF. Therefore, we chose to use a consistent threshold to exclude low intensity voxels from all the brain segmentations, as suggested by Boesen et al. (2004) and Sadananthan et al. (2010) , to try to compare different algorithms in as unbiased manner as possible. However, we acknowledge that brain extraction is rarely used in isolation and that dependent on the subsequent processing steps and ultimate outcome measure being assessed the quality of segmentation and possible errors included may or may not be important. The requirement for accuracy in brain extraction therefore varies with different uses of the Fig. 9 . Mean false negative maps of MAPS, BET, BSE and HWA from the segmentations of our whole dataset (682 1.5 T and 157 3 T scans). The colour maps show the average number of false negative counts (represented by the scales) in each projection plane. Note the differences in scale bar when comparing across these techniques; the scale bar for MAPS and HWA extend only to 0.6 whereas BET and BSE extend to 10. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) masks. We also acknowledge that each of the other methods might well be fine-tuned to particular scan types and applications. Although we showed that the semi-automated KN-BSI and MAPS KN-BSI were very similar, future work should examine the suitability of a particular brain extraction method for the specific processing pipeline or application for which it is to be used.\nIn conclusion, our results suggest that a template library approach (MAPS) is a relatively accurate and robust method of automated brain extraction. MAPS was similar to HWA in the ability to preserve brain tissues, but removed significantly more non-brain tissues than HWA. MAPS was shown to be more robust than HWA. We suggest that fully automated brain extraction methods now approach the accuracy and reliability of time consuming manual techniques and may be particularly valuable in large scale studies. Ultimately, the development and evaluation of accurate and robust brain segmentation methods that are able to equal or outperform more labour-intensive manual segmentation procedures will facilitate more efficient research. Fig. 10 . Errors in a semi-automated segmentation. Extra dura and tentorial tissues were included in the segmentation (pointed by the white arrows)."}, {"section_title": "Table 7", "text": "The comparison of the accuracy of MAPS, BET, BSE and HWA. The table shows the differences in the median (95% CI) of Jaccard index, false positive rate and false negative rate between the four automated brain extraction methods. *Statistical significance at p b 0.05."}, {"section_title": "Jaccard index (using thresholded segmentations)", "text": "False positive rate / % (using thresholded segmentations) False negative rate / % Table 10 Mean (SD) annualised brain atrophy measurement as a percentage of the baseline brain volume using KN-BSI calculated from semi-automated segmentations in baseline scans and propagated segmentations in 12-month follow-up scans (semi-automated KN-BSI), and from 'undilated MAPS-brains' in baseline and 12-month follow-up scans (MAPS KN-BSI)."}, {"section_title": "Semi-automated KN-BSI", "text": ""}, {"section_title": "MAPS KN-BSI", "text": "Difference (Semi-automated KN-BSI-MAPS KN-BSI) (95% CI), p-value Control (n=200) 0.608 (0.587) 0.596 (0.585) 0.012 (0.003, 0.021), p = 0.008 MCI (n = 338) 1.128 (0.857) 1.110 (0.850) 0.017 (0.010, 0.0251), p b 0.001 AD (n = 144) 1.566 (0.854) 1.541 (0.828) 0.025 (0.009, 0.043), p = 0.005 from the edge and taking the unflooded voxels as the brain region. The brain region was further dilated by 1-voxel to include some external CSF."}]