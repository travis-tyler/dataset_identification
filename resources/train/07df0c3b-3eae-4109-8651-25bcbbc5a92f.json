[{"section_title": "Abstract", "text": "For effective treatment of Alzheimer's disease (AD), it is important to identify subjects who are most likely to exhibit rapid cognitive decline. We aimed to develop an automatic image interpretation system based on a deep convolutional neural network (CNN) which can accurately predict future cognitive decline in mild cognitive impairment (MCI) patients using flurodeoxyglucose and florbetapir positron emission tomography (PET). PET images of 139 patients with AD, 171 patients with MCI and 182 normal subjects obtained from Alzheimer's Disease Neuroimaging Initiative database were used. Deep CNN was trained using 3-dimensional PET volumes of AD and normal controls as inputs. Manually defined image feature extraction such as quantification using predefined region-of-interests was unnecessary for our approach. Furthermore, it used minimally processed images without spatial normalization which has been commonly used in conventional quantitative analyses. Cognitive outcome of MCI subjects was predicted using this network. The prediction accuracy of the conversion of mild cognitive impairment to AD was compared with the conventional feature-based quantification approach. Accuracy of prediction (84.2%) for conversion to AD in MCI patients outperformed conventional feature-based quantification approaches. ROC analyses revealed that performance of CNN-based approach was significantly higher than that of the conventional quantification methods (p < 0.05). Output scores of the network were strongly correlated with the longitudinal change in cognitive measurements (p < 0.05). These results show the feasibility of deep learning as a practical tool for developing predictive neuroimaging biomarker."}, {"section_title": "Introduction", "text": ""}, {"section_title": "Backgrounds", "text": "Recent treatment strategies for Alzheimer's disease (AD) are aimed at slowing cognitive decline and are focused on the pre-dementia stage which includes mild cognitive impairment (MCI) [1] . However, as the etiology of MCI is heterogeneous, MCI patients show different rates of cognitive decline, and even some never convert to AD [2] . Thus, it is a matter of utmost importance to identify the patients with MCI who would benefit from treatment. So far, several studies have investigated a number of imaging biomarkers that can predict whether a patient with MCI will convert to AD. They include brain metabolism and amyloid load measured by 18 F-fluorodeoxyglucose (FDG) and 18 F-florbetapir (AV-45) positron emission tomography (PET), respectively [3] [4] [5] [6] . Previous studies have used quantitative parameters or visual assessment of the brain images for predicting MCI patients who would covert to AD. However, visual analysis cannot provide quantitative and objective data and quantitative analyses commonly require complicated processing [7] [8] [9] [10] .\nIn this study, we showed a deep convolutional neural network (CNN) based method, a type of deep learning, could accurately predict cognitive decline. Recent advances in CNN have dramatically improved image recognition field [11] . We applied CNN to FDG and AV-45 PET images to predict cognitive decline in MCI patients. Our method was designed to discriminate patients' groups classified according to the cognitive outcome with minimized image processing. In addition, it could provide a quantitative biomarker combining both the FDG and AV-45 PET information. We showed that the CNN-based biomarker strongly correlated with future cognitive decline. Our major contribution was 1) to predict future MCI patients' outcome by applying the deep CNN model trained for discriminating AD from controls, and 2) to achieve prediction with minimally processed multimodal neuroimage data due to the benefits of the deep CNN."}, {"section_title": "Related works", "text": "Recently, deep learning has been applied to brain images to classify patients' disorders. One of the initial paper that used deep learning for identifying AD using brain images employed Deep Boltzmann Machine as a feature extractor [12] . Discriminative features were extracted from 3D patches of FDG PET and MRI for the further classification task. Another study for extracting deep learning-based discriminative features from multimodal images used randomized denoising autoencoder and showed correlation between the output score of the classification model and clinical outcomes [13] . Another study used conventional image quantification and deep learning. Multimodal image features extracted by predefined region-of-interests were combined as inputs of a neural network for classifying AD [14] . These studies focused on discriminative feature extraction from multimodal image data, however, required routinely performed image processing. Furthermore, the input of the neural network was high-dimensional vector or manually extracted features instead of raw 3-dimensional voxels as CNN models. Instead of feature extracting using autoencoder or Boltzmann machine, 3D CNN models exploiting all voxels as inputs have been applied to classifying disorders. A 3D CNN model was applied to structural MRI to classify AD, MCI and controls [15] . Another 3D CNN model for structural MRI was built upon pretraining process performed by convolutional autoencoder [16] . fMRI-based classification model was reported using 2D CNN by stacking processed fMRI images across axial and time axes [17] . So far, no studies focused on exploiting multimodal 3D PET images without normalization as inputs for CNN despite ease of clinical applicability of minimally processed images. Furthermore, independent future outcome prediction of MCI patients using CNN model trained by AD and controls has not been reported."}, {"section_title": "Methods", "text": ""}, {"section_title": "Subjects", "text": "The data used in this study included subjects recruited in Alzheimer's Disease Neuroimaging Initiative-II (ADNI-2) with available baseline data on FDG and AV-45 PET (http://adni.loni.usc.edu). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD, VA Medical Center and University of California San Francisco. Subjects have been recruited from over 50 sites across the US and Canada. The primary purpose of ADNI has been to test whether serial MRI, PET, other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of MCI and early AD. For up-to-date information, see http://www.adni-info.org. Written informed consent to cognitive testing and neuroimaging prior to participation was obtained, approved by the institutional review boards of all participating institutions.\nFor diagnostic classification and learning the CNN, we firstly selected patients with AD and healthy subjects who had baseline FDG and AV-45 PET scans. We also selected MCI patients who had baseline FDG and AV-45 PET scans and 3-year follow-up clinical evaluation. This resulted in 182 normal controls (NCs), 139 AD patients and 171 MCI subjects. Based on whether the MCI patients would convert to AD within 3 years, MCI patients were grouped as MCI converters and nonconverters.\nCognitive function of the subjects was evaluated using Clinical Dementia Rating Sum of Boxes (CDR-SB), Alzheimer's Disease Assessment Scale-Cognitive Subscale 13-item (ADAS-Cog), Functional Activities Questionnaire (FAQ), and Mini-Metal Status Examination (MMSE). As we interested in whether CNN-based baseline PET biomarkers would be associated with longitudinal cognitive decline, longitudinal changes of cognitive measurements were also assessed at 1 year and 3 years after the baseline study."}, {"section_title": "FDG PET and AV-45 PET", "text": "All the PET images were downloaded from ADNI database at the most advanced preprocessing stage. FDG PET images were acquired 30 to 60 min and AV-45 PET images were acquired 50 to 70 min after the injection. The FDG and AV-45 PET images were co-registered to each other, averaged across the time frames, standardized to have same voxel size (1.5 \u00d7 1.5 \u00d7 1.5 mm). PET images were acquired in the 57 sites participating in ADNI, scanner-specific smoothing was additionally applied [18] . As the processing did not include nonlinear spatial warping, size and shape of the brains were not changed after the preprocessing. These preprocessed images could be downloaded from ADNI database and we used them for deep CNN training and testing as they are."}, {"section_title": "Study design", "text": "The main purpose of this paper was to develop a deep CNN-based method for prediction of cognitive decline and selection of subjects who would eventually convert to AD. Before the testing of MCI conversion, the deep CNN was trained using PET images of AD and NC subjects. For discrimination between MCI converter and nonconverter, the network trained by AD/NC data was directly transferred as the imaging features of MCI converter would be similar with those of AD. The nodes of the output layer were only reassigned to MCI converter and nonconverter. All the PET images of MCI subjects were tested whether they would convert to AD or not. Therefore, our deep CNN was a classifier independent from the training data to discriminate between MCI converter and nonconverter ( Fig. 1 ). In addition, we also obtained a quantitative score for MCI converter. The quantitative value of the output of the network before the final activation layer (i.e. softmax) was defined as ConvScore, a score that indicates how close inputted baseline images are to AD. The score can be expected to be utilized for a predictive biomarker.\nThe CNN was designed using MatConvNet (Version 1.0-beta 16) [19] . Additional information about the network architecture is available in the Supplementary Methods and Supplementary Table 1 .\nSensitivity, specificity and accuracy of the classification between AD and NC were calculated using cross-validation. Additional information about training and validation of the classification between AD and NC is available in the Supplementary Methods."}, {"section_title": "Prediction of cognitive decline in MCI subjects", "text": "Using the network trained by PET images of AD and NC, PET images of MCI subjects were tested whether they would convert to AD or not. The labels of the output nodes of the CNN, AD and NC, were changed to MCI converter and nonconverter, as aforementioned above. As the classification of AD/NC, we classified a patient as a predictive MCI converter if the probability of the network output layer was higher than 0.5. Sensitivity, specificity and accuracy were measured and ROC analysis was also performed using ConvScore.\nConvScore was correlated with the longitudinal changes of cognitive measurements including CDR-SB, ADAS-Cog, FAQ and MMSE. Cognitive measurements of 1-year and 3-year follow-up visits were compared with those of baseline studies to calculate longitudinal changes. Pearson correlation was used for the correlation analysis."}, {"section_title": "Feature volume of interests based analysis", "text": "To compare CNN-based biomarker with conventional quantification methods, feature volume of interests (VOIs)-based analyses for FDG and AV-45 PET were carried out. The images were processed and quantified by feature VOI as described previously [20] [21] [22] . In brief, FDG PET volumes were spatially normalized with nonlinear warping process. Average FDG uptake from the angular (right/left), temporal (right/left) and posterior cingulate cortices were calculated. The quantification data were expressed relative to the mean uptake of a reference regions, pons and cerebellar vermis [20] . For AV-45 PET, cortical uptake of AV-45 was calculated. Cortical regions were segmented with FreeSurfer, and used to extract mean AV-45 uptake in frontal, anterior and posterior cingulate, lateral parietal, and lateral temporal regions. The overall cortical mean uptake value expressed relative to uptake in the whole cerebellum was used [21, 22] ."}, {"section_title": "Voxelwise feature extraction and support vector machine", "text": "Our proposed CNN-based approach was additionally compared with a conventional machine learning approach using voxelwise feature extraction. This approach used combined information of FDG and AV-45 PET images and did not use predefined VOI. Thus, it was a datadriven method as our CNN-based approach that was independent from previous knowledge of significant VOIs relevant to the diagnosis. This approach was performed by three steps: spatial normalization of PET images, feature extraction using principal component analysis (PCA) and support vector machine (SVM) classification. SVM classifier using feature extraction from PET images has been studied several times and showed good performance for the diagnosis of AD [23] [24] [25] . We trained PCA-SVM classier using FDG and AV-45 PET data of AD/NC and tested it for MCI patients as training and testing process of the CNN-based approach. Details are described in Supplementary Methods."}, {"section_title": "Statistics", "text": "We compared the diagnostic and prediction accuracy of CNN with those of conventional feature-based approaches with McNemar's nonparametric test. ROC analysis with area under the curve (AUC) measurement was performed for ConvScore and feature VOI-based parameters. The AUCs were compared using a nonparametric test of DeLong for comparison of two correlated ROC curves [26] . The performance comparison results for predicting MCI converters were obtained by the model which showed the best accuracy for discriminating AD in the cross-validation. The performance of discriminating AD from NC was measured by the combined results of cross-validation. ConvScore was correlated with longitudinal changes of cognitive measurements using Pearson's correlation. All statistical analysis was performed by using the MATLAB software. P-value < 0.05 was considered significant."}, {"section_title": "Results", "text": ""}, {"section_title": "Results of AD classification and MCI conversion prediction", "text": "We included a total of 492 subjects in this study. Among them, 139 patients were AD, 171 patients were MCI and 182 were NC. Demographic data and cognitive measurements of each group were summarized in Table 1 .\nThe classification accuracy of the CNN-based approach was compared with feature VOI-based analysis of FDG and AV-45 PET as conventional quantitative analyses. In addition, it was compared with a SVM classifier based on PCA features of FDG and AV-45 PET images. The PCA features were shown in Supplementary Fig. 1 . Sensitivity, specificity and accuracy of CNN-based approach for classification between AD and NC were 93.5%, 97.8% and 96.0%, respectively. They were significantly higher than those of the SVM classifier as well as VOI-based analyses (p-values were summarized in Table 2 ). The performance of SVM classifiers with different kernels are summarized in Supplementary Table 2 . Sensitivity, specificity and accuracy of the CNN-based approach for the prediction of MCI conversion was 81.0%, 87.0% and 84.2%, respectively. Accuracy of the deep CNN was significantly higher than VOI-based analysis of FDG PET and the SVM classifier. Specificity of deep CNN was significantly higher than VOIbased analysis of AV-45 PET and the SVM classifier. Sensitivity was also higher compared with conventional methods, though it did not reach statistical significance (p-values were summarized in Table 2 ). In addition to the group classification, we calculated quantitative score, ConvScore, for predicting MCI converters. It was obtained from the value of the last layer of the network. Using ConvScore, ROC curves were drawn and AUC were calculated (Fig. 2 , Table 2 ). AUC of Conv-Score was significantly higher than feature-VOI based analysis for AD classification (p < 0.001 for deep CNN vs. FDG and vs. AV-45) and prediction of MCI conversion (p < 0.01 for deep CNN vs. FDG and p < 0.05 for deep CNN vs. AV-45)."}, {"section_title": "Correlation of CNN-based biomarker with cognitive outcomes", "text": "ConvScore calculated from baseline PET images of MCI patients was significantly correlated with the longitudinal change of cognitive measurements at 1 year and 3 years ( Fig. 3) . ConvScore was significantly positively correlated with longitudinal change of CDR-SB (r = 0.37, p < 0.0001 at 1 year and r = 0.63, p < 0.0001 at 3 years), ADAS-Cog (r = 0.29, p = 0.0001 at 1 year and r = 0.24, p = 0.004 at 3 year) and FAQ (r = 0.40, p < 0.0001 at 1 year and r = 0.67, p < 0.0001 at 3 year). It was significantly negatively correlated with MMSE (r = -0.30, p < 0.0001 at 1 year and r = \u22120.61, p < 0.0001 at 3 year). Note that the relatively weak correlation between ConvScore and longitudinal changes in cognitive scores at 1 year was found. The changes were steeper for the measurements at 3 years compared with 1 year. ConvScore of MCI converters was significantly higher than that of MCI nonconverters (2.40 \u00b1 1.49 and -0.13 \u00b1 1.36, respectively. p < 0.0001) ( Supplementary Fig. 2 ). ConvScore could be used as a quantitative biomarker for predicting longitudinal cognitive measurements decline in MCI patients as well as conversion to AD."}, {"section_title": "Discussion", "text": "In the present study, we developed a deep learning-based diagnostic method for predicting cognitive decline in MCI patients. According to our knowledge, we firstly applied recent deep CNN model to multimodal PET images to predict cognitive outcome. Deep CNN could accurately classify patients' diagnostic group with the minimal steps of image processing and provide a quantitative biomarker for predicting cognitive outcome. Accordingly, the prediction of cognitive decline in our method could be automatically made by simply inputting subjects' images. Output value (ConvScore) was significantly correlated with the longitudinal change of cognitive measurements. Previous PET imaging biomarkers relied on the uptake value in a set of regions of interest developed a priori or whole-cortical uptake value [6, 9, 10] . To obtain these values, several image processing steps such as spatial normalization and cortical segmentation using structural MRI were required. However, such processing was not standardized and nonlinear image transformation could introduce a potential source of errors particularly in morphological alterations [27, 28] . Our proposed method used spatially unnormalized baseline image data of AD and NC. It suggests that our approach is simply able to be utilized to redesign the voxelwise brain imaging processing pipeline which has routinely implemented normalization to template space.\nAccuracy of differentiation between MCI converter and nonconverter (84.2%) outperformed the conventional machine learning approach using SVM with voxelwise feature selection as well as conventional feature-VOI based methods. ROC comparison results also revealed that the accuracy of prediction was significantly higher than other methods. Note that the feature-VOI based methods relied on prior information about important regions and partly employs MR information for cortical parcellation [20] [21] [22] , while deep CNN-based and SVMbased approaches solely used PET information. Nonetheless, the prediction accuracy of our approach was higher than the VOI-based methods with a priori and structural information. That is because deep CNN has the benefit that could automatically discover the optimal features for image classification [11] . Furthermore, the accuracy of our approach also outperformed other state-of-the-art machine-learning algorithms based on feature selection other than deep learning for this differentiation problem [29] [30] [31] [32] , though those studies used different imaging modalities and clinical variables. For example, Cheng, et al. suggested a machine learning classifer using FDG PET, MRI and CSF biomarkers, which showed 80.1% accuracy for discriminating MCI converters [29] . Deep CNN models using MRI showed more than 95% accuracy for discriminating AD from normal which was similar with our model though they were not tested for identifying MCI converters [15, 16] . The major benefit of deep CNN compared with other conventional machine learning methods is the end-to-end training [11] . Because 3d medical images have high dimensions, previous methods have commonly required dimension reduction by feature selection. However, deep CNN model uses all voxels of image data as inputs as convolutional filters make sparse connection compared with fullyconnected neural networks [33] . It eventually reduces learning parameters of the model and enables end-to-end training.\nOur approach could provide a quantitative variable, ConvScore, to be used as a fusion biomarker for multimodal images. As an imaging biomarker, low glucose metabolism and high amyloid deposit in the cortex at baseline can predict the longitudinal decline of cognitive scores [20, 21] . However, a combined parameter considering both metabolism and amyloid deposit has been needed. ConvScore is not only a fusion biomarker directly obtained by both PET images, but correlated with longitudinal cognitive measurements. It suggests cognitive functions of patients with high ConvScore at baseline could be rapidly deteriorated. Even though relatively weak correlation between ConvScore and cognitive measurements changes at 1 year (less than r < 0.4), we could be used ConvScore as a single parameter that reflects both PET image patterns for future cognitive decline particularly for long-term outcome. This correlation is an important observation that has impact on clinical trials for early treatment intervention in prodromal AD. ConvScore could help select the subjects who would benefit from treatment in the clinical trials.\nIn the clinical setting, most imaging studies are assessed by experts' visual analysis, because it is simpler and more practical than the quantitative assessment which needs time-consuming procedures. Deep CNN is motivated by human visual perception, which hierarchically processes recognized images in the cerebral cortex [34] . As hierarchical features of images are automatically trained by data, manual feature selection or image processing steps can be minimized in deep CNN [11, 34] . Therefore, after the training, the network is automatically able to analyze patients' images by simply inputting subjects' images. Considering the ease of application, the CNN-based image interpretation system has a large potential to be used in development of biomarkers of several diseases including cancer, cardiovascular disorders as well as neurodegenerative diseases.\nRecent remedies of CNN for achieving higher accuracy are increasing the depth of the network [35] . However, to learn a deeper neural network, more image data will be essential. As the network is trained by the larger data, the higher performance it shows. In our study, to overcome the limited number of imaging data, PET images were augmented by flipping image in left-right direction (Supplementary Methods). It was based on the previous knowledge that AD and MCI converters showed symmetrically decreased FDG uptake and increased AV-45 uptake in the cerebral cortices. The network trained without this augmentation process showed 89.4% and 81.3% accuracy for the differentiation between AD and NC and predicting MCI converters, respectively. Though the augmentation process increased the performance of the network, it might cause potential error in the classification because the two brain hemispheres have partly different functions. In the future, larger image data cohort and deeper network architecture could improve the CNN-based approach. Furthermore, we used only ADNI dataset which could be insufficient for the generalized validation as well as optimal training. Therefore, as a future work, the model needs to be validated in PET images acquired from independent centers and modified by larger datasets."}, {"section_title": "Conclusions", "text": "Our deep CNN-based approach could accurately predict cognitive decline in MCI patients by combining information of FDG and AV-45 PET images. For testing whether a MCI subject would convert to AD, baseline PET images without spatial transformation were needed as a feature extraction was automatically performed. As a future work, our approach may be additionally validated in clinical trials with independent large cohorts. As an accurate biomarker, we expect our approach will help select appropriate prodromal AD patients who benefit from early intervention."}, {"section_title": "Role of the funding source", "text": "The funders of the study had no role in the study design, data collection, data analysis, data interpretation, or writing of the report."}]