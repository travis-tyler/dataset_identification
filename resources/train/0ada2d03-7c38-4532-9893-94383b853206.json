[{"section_title": "Introduction", "text": "Nonresponse in establishment surveys is an ongoing problem (Kovar & Whitridge, 1995). The problem of nonresponse affects estimates of survey statistics (Little & Rubin DB, 2002;Rubin, 1987;Kovar, et al., 1995;Ruggles & Joint Economic Committee, 2006;Groves, Dillman, Eltinge, & Little, 2002;Groves, et al., 2004). Many imputation methods used in social, demographic and health science settings have been applied within the economic survey framework and very little information is known about the effect of item nonresponse in establishment surveys (Kovar, et al., 1995;Judkins , 2000;West, Butani, & Witt, 1993). There has been a focus on procedures for reducing measurement error, improving sampling strategies (Lee & Croal, 1989) (Sirken & Shimizu, 1999), improving response rates (Chun, 1997), response selection, survey coordination, longitudinal analysis (Ruggles, et al., 2006) , (Schenker, Treiman, & Weidman, 1988;Heeringa & Lepkowski, 1986), or empirical evaluation of imputation methods (West, et al., 1993;Krenzke, Montaquila, & Mohadjer, 2000;Mueller & Butani, 1995) in establishment surveys. Many imputation methods are available in the literature. Usually, once a dataset has been imputed, analyses are performed treating the imputed values as observed data. This type of analysis could be misleading because variances and covariances may be underestimated (Kovar, et al., 1995). In this article, the effectiveness of a particular ratio imputation method when applied to an item-nonresponse from an establishment survey including a longitudinal perspective on point and variance estimates is evaluated. There are a variety of techniques for variance estimation for complex surveys (Wolter, 1985) and few of them incorporate the effect of imputation in their estimation (Shao & Sitter, 1996;Shao & Steel, 1999;Shao, 2002). Most of the time imputation methods in a survey are implemented without theoretical development of the methods (Shao, 2002). Simulation studies make it possible to evaluate and compare estimation techniques in national surveys in any country (U.S.Department of Education.National Center for Education Statistics., 2001). Pseudo-universes from survey data can be used instead of national universes (i.e., census data) which are not usually available for simulation studies. Pseudo universes permit a comparison of techniques and sample according to a plan of interest, maintaining the distributions of the variables of interest. Simulations from a pseudo universe can provide estimates of interest and give detailed insight of the estimator performance. It is the researcher's interest to study the effect on the point and variance estimates of the current imputation plan conducted in the Graduate Students and Postdoctorates in Science and Engineering (GSS) (NSF-NIH, 2005). One of the challenging aspects of any simulation is the creation of an artificial population similar to the one investigated. There are two approaches to create a finite population universe (Katzoff, Jones, & Curtin, 1988;Bernaards, Belin, & Schafer, 2006;Schafer, et al., 1996). One is to create pseudo-random values from an actual multivariate probability model, also known as a hypothetical population. The second is to use an actual large data set to reflect the target population and to define population parameters of interest, also known as a pseudo-universe. Use of a specific probability model is a limitation in the creation of a hypothetical population (Schafer, et al., 1996). Therefore, a pseudo universe was created to impose realistic missing data patterns. The following describes the generation of the pseudo universe and simulations which allow: (i) appraise the longitudinal missing data patterns in GSS between 1999GSS between -2001(ii) evaluate the effect of current imputation methods in this survey on estimates for different missing data mechanism assumptions in GSS; (iii) assess precision and accuracy measures in the total, and corresponding variance estimates in GSS. In following sections, the GSS survey will be described, the current imputation method, the methodology to evaluate the effect of the current imputation method and the results and conclusions, respectively."}, {"section_title": "The Survey of Graduate Students and Postdoctorates in Science and Engineering (GSS)", "text": "One of the current surveys conducted at the Division of Science Resources Statistics (SRS) of the National Science Foundation (NSF) is the NSF-NIH (National Institutes of Health) survey of Graduate Students and Postdoctorates in Science and Engineering (GSS) (NSF-NIH, 2005). This survey (i) measures academic department level information on all U.S. institutions offering graduate programs (masters or PhD degrees) in science, engineering, or health selected field; (ii) provides a description of graduate science and engineering (S&E) student's enrollment in US institutions; and (iii) assesses trends in financial support patterns and shifts in graduate enrollment and postdoctoral appointments. This cross-sectional establishment survey is conducted annually (NSF-NIH, 2005 Statistics, 2006). Each year, a ratio imputation technique is used to handle item nonresponse based on inflator/deflator factors (NSF-NIH, 2005). For a particular year, these inflator/deflator factors are computed from the current year observed data in combination with previous year observed and imputed data (Morgan M & ORC Macro, 2004). Replacing missing data in the current year with previous year data is an imputation method known in longitudinal human population studies as the last observation carry-forward (LOCF). This imputation method is modified in the GSS by the use of inflator/deflator factors as adjustments when replacing current cycle missing data with adjusted previous cycle data. Simulations conducted with LOCF, in longitudinal human population studies, indicates that LOCF produces biased estimates for all three types of missing data mechanisms (Missing completely at random (MCAR), Missing at random (MAR) or Missing not at random (MNAR)) and LOCF produces the smallest standard errors that are biased downward (Gadbury, Coffey, & Allison, 2005). For these reasons, evaluation of the current GSS imputation plan is needed."}, {"section_title": "Imputation at the Graduate Student Survey", "text": "The department within an academic institution is the unit of interest of this survey for imputation purposes. This imputation methodology is presented for four variables used in this research only, but can be generalizable to the rest of the variables within this survey."}, {"section_title": "Creation of inflator/deflator factors", "text": "Departments that provided full or partial information about total full-time students, total part-time students, total postdoctorates and total other non-faculty research staff are used for creation of these factors. Specifically, in this study, total full-time students and total part-time students were used. Inflator/deflator factors are computed by highest institutional degree level (doctorate and master's) and by department type (e.g. Biology, Physics, etc.). For a particular variable of interest ( k Y ), its sum is computed by institutional highest degree level and department type. Then factors are computed by dividing the sum of the variable from the current (t) year by the corresponding sum of the variable from the previous year (t-1). These inflator/deflator factors ( t k \u03c8\u02c6) in mathematical terms are calculated for the k th variable and year t. r identifies the maximum number of departments in the same institutional degree level and departmental type that provided a variable value k Y in both years t and 1 \u2212 t . Any computed factor less than 0.85 or greater than 1.15 is set to 1 for imputation purposes. In mathematical terms: Using inflator/deflator factors to impute total full-time students all sources of funding and total part-time students of all races Departments with missing information in total full-time students and/or total part-time students are imputed using equation 3. The imputation value for a particular variable in the current year is obtained by applying t k \u03c6\u02c6to previous year information for that variable. This is done at each department institutional level (i.e., MS or PhD) and department type (i.e., Biology, Physics, etc). i identifies a particular department, k identifies the variable, t identifies the year, is the imputed value of the k th variable for department i at year t . Subsequently, imputed values for total full-time students (from equation 3) are used to impute variables regarding full-time students by: source and mechanism of support. Similarly, imputed values for total part-time students (from Equation 3) are used to impute variables regarding number of part-time students by sex and their distribution by US nationals/permanent residents or foreign students. Using inflator/deflator factors to impute total part-time students The imputed value for the total of female part-time students is computed using the same percentage as reported in the previous year on the imputed value from the total part-time students in the current year. Equation 4 shows this in mathematical terms. ( ) Where i identifies a particular department, t identifies the year, j identifies women, t i Y\u02c6 represents the observed or imputed value of the total part-time students enrolled for a particular represents the observed value of the total part-time women students for year represents the observed value of the total part-time students for year 1 \u2212 t at a particular department i , and ) ( ijt I Y represents the imputed value of the total part-time women at year t at particular department i . The imputed value for the total of male part-time students is calculated as the difference between the total part-time students in the current year (observed or imputed) and the observed or imputed value for the total of female part-time students."}, {"section_title": "Methodology", "text": "The purpose is to evaluate the longitudinal effect of imputation on estimates in the GSS, data from the years 1998-2002 (the most recent data through 2005). The GSS survey in 1998 contained 639 variables and 11686 departments and in 2002 contained 639 variables and 12126 departments. Overall, 15379 departments reported any information on the GSS data from the years 1998--2002. The first four variables imputed in this survey were selected for analysis in this research: total full-time graduate students all sources of support, total part-time students of all races, total part-time male students of all races and total part-time female students of all races. To evaluate the effect of the imputation method within this survey a simulation study with a pseudo universe from this survey was conducted."}, {"section_title": "Generation of the pseudo universe 1998-2002", "text": "A dataset called \"Observed 1998-2002\" which mainly excluded departments with unit nonresponse between years 1998-2002 was created. If a department reported any missing value for any of the variables of interest in year 1998 and 2002 they were excluded. This is because stable departments were to be used, to exclude new programs (i.e., if a department created a new master or doctoral program in 2002 then previous years would not have reported any information and missing values would appear in the longitudinal structure), and to exclude non current programs. If departments provided information in years 1998 and 2002 this indicated continuity of the master's or PhD degree program at that institution. In summary, one department was excluded because it did not report the type of academic institution (neither school under which this department was associated, nor public or private nor which institutional highest degree is granted). Departments with unit nonresponse were excluded for each year as follows: 3693 within 1998, 936 within 1999, 514 within 2000, 755 within 2001 respectively and 610 within 2002. It was assumed that these departments with unit nonresponse were not stable. Furthermore, the study excluded 328 departments without students enrolled either full-time or part-time in 1998 in any of the four variables of interest, which indicated historically unstable enrollment in that program. This dataset Observed 1998-2002 contained 8542 out of 15379 departments with item nonresponse between the years 1999 and 2001. Using this dataset the researchers generated the longitudinal distributional patterns of missing data in years 1999-2001. After this, the researchers generated a pseudo universe from this survey by removing any department with missing data in our variables of interest from years 1999-2001. Researchers excluded 685 departments because they did not report full time students for at least one of these years. Forty-five departments that did not report part-time students for at least one of these years were deleted. Furthermore, 127 departments that did not report part time male students for at least one of these years were excluded. This complete dataset was called and used as Pseudo Universe 1998-2002 and contains 7685 departments with complete information on all these variables. This pseudo universe was used to develop and evaluate the imputation methods used in GSS for the variable totals and their corresponding variability measures. Total estimates coming from this pseudo-universe were treated as parameter values from this pseudo universe. This is notated t k \u03b8 as the total estimate of the k th -variable of interest for years 1999 to 2001. These parameter values were used for comparison purposes in evaluation the GSS imputation methods."}, {"section_title": "Simulation of mechanisms of missingness", "text": "Two missingness mechanisms to evaluate the imputation methods at GSS were explored. The first approach was to create an MCAR mechanism. Actual percentages of missing values were imposed within \"Pseudo Universe 1998-2002\" on within Pseudo Universe 1998-2002 on each t k Y independently of any variable in the system. Table 1 illustrates the \"Actual\" percentage of missing data observed in years 1999-2001 for the four variables of interest in this survey and these percentages were used for creating the MCAR mechanism for evaluation purposes. Our \"MCAR dataset\" contains these \"Actual\" percentages imposed randomly as missing. As you may notice these percentages are not high and it will be desired to evaluate the imputation method with this low percentages of missingness. It was assumed that the occurrence of missing values at the GSS survey is MAR. Under this assumption, the second approach was to impose the Actual percentages of missing values with the same longitudinal distributional patterns of missing data in years 1999-2001 from Observed 1998-2002 within Pseudo Universe 1998-2002. Table 2 shows the observed longitudinal patterns of missing values for these variables, where 0 represents data was missing and 1 represents data was observed. For the purposes of understanding the effect of the imputation method with increased percentages of missing values, in simulations, the researchers increased these observed longitudinal distributional patterns of missing values from the Observed 1998-2002 in 25%, 50%, 75% and 100% (data not shown) within Pseudo Universe 1998-2002."}, {"section_title": "Parameter estimation", "text": "These datasets, with imposed missing values, can be used to examine many quantities of interest. The total and its corresponding variance estimate were examined for each year. Many other parameters were included in simulations but are not reported for brevity and the research primarily presents the results under the MAR mechanism. Each one of these missingness mechanisms were replicated one thousand times."}, {"section_title": "Applying the Imputation Method", "text": "Inflator/deflator factors for year 1999 were computed using the observed data from the 1998 Pseudo Universe 1998-2002. The ratio imputation methods described in equations 3 and 4 were applied for missing values in year 1999. Then, an imputed and complete 1999 dataset was reached. Similarly, the researchers continued to generate the inflator/deflator factors and to impute missing values in years 2000 and 2001. This procedure produced an Observed and imputed longitudinal 1999-2001 dataset. Crosssectional 1999-2001 total estimates and their corresponding variances were computed. Estimates after imputation are notated as "}, {"section_title": "Evaluation criteria", "text": "The performance of the GSS imputation method by the following quantities in years 1999-2001 were evaluated. First, the bias of the total and the variance estimates after imputation of the simulations are described in Equations 5 and 6, respectively.  1  0  1  1  0  1  1  0  1  1  0  1  0.89  13  1  0  1  1  1  1  1  1  1  1  1  1  0.01  14  1  1  0  1  1  0  0  1  0  0  1  0  0.02  15  1  1  0  1  0  0  1  0  0  1  0  0  0.01  16  1  1  0  1  1  0  1  0  0  1  0  0  0.04  17  1  1  0  1  1  0  1  1  0  1  1  0  2.60  18  1  1  0  1  1  1  1  1  1  1  1  1  0.01  19  1  1  1  0  1  1  0  1  1  0  1  1  0.12  20  1  1  1  1  1  1  0  0  0  0  0  0  0.12  21  1  1  1  1  1  1  0  0  1  0  0  1  0.05  22  1  1  1  1  1  1  0  1  0  0  1  0  0.01  23  1  1  1  1  1  1  0  1  1  0  1  1  0.74  24  1  1  1  1  1  1  1  0  0  1  0  0  0.01  25  1  1  1  1  1  1  1  0  1  1  0  1  0.21  26  1  1  1  1  1  0  1  1  0  1  1  0  0.07  27  1  1  1  1  1  1  1  1  0  1  1  0  0.18  28  1  1  1  1  1  1  1  1  1  1  1  1  identifies the estimated variance after imputation. Second, given that the raw bias can be misleading the standardized bias of the total estimate using equation 7 was computed. A standardized bias of less of 50% in both directions should be considered practically insignificant. Third, the mean square error (MSE) for the total and the variance estimates are described in equations 8 and 9. ( ) Fourth, the average relative bias of the total and the variance estimates are described in equations 10 and 11. These average relative biases measure the average magnitude of over or under estimation of the imputation method compared with the true value. Finally, the average relative stability of the variance is described in equation 12.   Results Table 3 presents the results of the 1000 simulations under MCAR mechanism. The current imputation method underestimates total full-time students and total part-time female students and overestimates part-time students and part-time male students under this mechanism. The underestimation or overestimation of these variables increased yearly from 1999 to 2001. The standardized biases were larger than 50% for many of the variables of interest. Results of simulations under the MAR mechanism are presented in Tables 4-7. Table 4 shows the results from the evaluation criteria for the imputation method on full-time students all sources of funding. The relative bias of the total estimate of full-time students indicates a 10% underestimation for years 2000 and 2001 with the current amount of missing values. If the amount of missing values increases then this underestimation increased up to 20% for year 2001. It is interesting to note that this imputation method would overestimate the total estimate of full-time students by 40% if the current patterns of missing values were increased by 100% for the year 2000. Results from the relative bias of the variance of the total estimate of full-time students across the years indicates overestimation between 10% and 30% for year 1999 for increasing percentages of missing values. This overestimation is also observed for year 2001 with a range of 20% to 70%.  Results from the relative bias of the variance in year 2000 indicate that this imputation method underestimates the variance of the total estimate of full-time students from 20% to 40% depending on the amount of missingness. The MSE of the total and the variance of full-time students using the current imputation method at GSS is large. The MSE of the variance increases for each year of increase and as expected if the percentage of missing values increases then the MSE of the variance will increase. The average relative stability of the variance of the total estimate of full-time students decreases noticeably for each one year increase. This behavior is consistently observed across increasing percentages of missing values. Table 5 shows the results from the evaluation criteria for the imputation method on part-time students of all races. The relative bias of the total estimate of part-time students indicates a 20% overestimation for year 2000 and a 10% underestimation for year 2001 with the current amount of missing values. If the amount of missing values increases then this overestimation increases up to 40% for year 2000 and the underestimation will decrease by at least 20% for year 2001. Results from the relative bias of the variance of the total estimate of part-time students across years indicates increased underestimation for increased year and this behavior seems to follow a U shape for increasing percentages of missing values. Findings about the MSE for the total and variance of full-time students are similar than for part-time students as well as regarding the average relative stability of the variance. Table 6 shows the results from the evaluation criteria for the imputation method on part-time male students of all races. The relative bias of the total estimate of part-time male students with the current amount of missing values indicates 80%, 110% and 90% overestimation for years 1999, 2000 and 2001, respectively. As expected if the amount of missing values increases then this overestimation increases. Results from the relative bias of the variance of the total estimate of part-time male students across years indicates overestimation above 50% and increases for increasing percentages of missing values. Findings about the MSE for the total and variance of full-time students are equal for part-time male students and the average time male students as well as regarding the average relative stability of the variance. Table 7 shows the results from the evaluation criteria for the imputation method on part-time female students of all races. The relative bias of the total estimate of part-time female students, with the current missing values, indicates a 90%, 80% and 1813% underestimation for 199980% and 1813% underestimation for , 200080% and 1813% underestimation for , and 2001. Results from 1000 replicates under MAR for part time female students If the amount of missing values increases then this underestimation increases as well. Results from the relative bias of the variance of the total estimate of part-time female students across years indicates underestimation between 20% and 30% for year 1999 for increasing percentages of missing values. This underestimation is also observed for years 2001 and 2002 with a range from 110% to 270%. Findings about the MSE for the total and variance of full-time students are equal for parttime female students as well as regarding the average relative stability of the variance."}, {"section_title": "Conclusion", "text": "Overall, the bias and the MSE of the total and the variance estimates are not acceptable under the MCAR mechanism. Our findings under MCAR in this establishment survey are consistent with the literature in human populations where you will expect a higher underestimation or overestimation for increasing percentage of missing values in a variable including the increase as a year passes by. Overall, the bias of the total estimates for full-time students and part-time students are acceptable under the MAR mechanism. This is because although the estimates across years and for different percentages of increase of current missing values are biased, the standardized biases are less than -50% which means that this bias is practically insignificant. On the contrary, the bias of the total estimates for part-time male and female students are not acceptable under the MAR mechanism using similar criteria of the standardized bias which surpass 50% in either direction for any percentage increase of missing values. The results of overestimation for 1999 and 2001 using the relative bias of the variance of the total estimate of full-time students and its underestimation in 2000 with this imputation method are in agreement with previous descriptions of variance estimate behaviors after imputation in human population surveys, where imputation methods underestimate or overestimate depending on the variability of the variable. Most of the time it is expected to provide an underestimation of this variance estimate and this is shown in many of the variables chosen for this research. The MSE incorporates two components, one measuring the variability of the estimator (precision) and the other measuring its bias (accuracy). Overall, the estimators generated with the current imputation method in GSS do not have good MSE properties because they do not have small combined variance and bias. The findings regarding the variance estimates using the current imputation methods in this establishment survey for the variables chosen are in agreement with findings with many imputation methods for human population surveys where priority and challenges need to be overcome for improving variance estimates in surveys. The noticeable decrease in the average relative stability of the variance of the total estimates of the variables of interest warrants consideration. There were many limitations to this study. The chosen pseudo universe represents a best case scenario where departments are fully compliant and provided full information. Furthermore, sampling did not come from this finite population to test the imputation method in full when a sample is selected instead of using the entire population. The entire population was used, which is the best case scenario, being fully efficient in the scenarios regarding the imputation method. It is expected that by selecting different sample sizes will provide worst results than the ones presented here. Also, a good scenario where the current percentages of missing values do not seem very high for each cross-sectional year was used. However, the findings are overwhelming in the large effects that the current GSS imputation method affects the bias of the total estimates of part-time males and females and overall variance estimates. Another limitation is that this study only handles the issue of item-nonresponse when unit nonresponse was excluded from this research. The results limitation as a best case scenario warrants consideration because worse results would be expected under worse conditions than those presented here. Currently NSF publishes total estimates from this survey without reporting any variance estimate. Careful attention is needed for those variables where standardized biases are larger than -50% as well as how to improve the stability of the variance decreasing for increasing percentages of missingness in the cross-sectional and longitudinal setting. Minor discrepancies were observed in the bias and MSE estimates when the unit of analysis is establishments instead of individuals. Further research is needed to identify statistical methods to handle the missing data from this survey and to evaluate this method under a missing not at random mechanism."}]