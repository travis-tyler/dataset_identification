[{"section_title": "List of Tables", "text": ". Total number of public schools and students, and percentage of schools and students that participated in the Title I and federal free or reduced-price lunch programs, by selected school characteristics: 2015-16 ......................................................"}, {"section_title": "Introduction", "text": "The 2015-16 National Teacher and Principal Survey (NTPS) is a nationally representative sample survey of public 1 K-12 schools, principals, and teachers in the 50 states and the District of Columbia. This report presents selected findings from the Public School Data File of NTPS. NTPS is a redesign of the Schools and Staffing Survey (SASS). SASS was conducted on behalf of the National Center for Education Statistics (NCES) on a 4-year cycle, beginning with the 1987-88 school year and ending in the 2011-12 school year. NTPS maintains the same focus on schools, teachers, and administrators that was traditionally held by the SASS; however, it has a different structure and sample than previous administrations of SASS and operates on a 2-year survey cycle. NTPS collects data on core topics including teacher and principal preparation, classes taught, school characteristics, and demographics of the teacher and principal labor force. It is developed by the NCES of the Institute of Education Sciences within the U.S. Department of Education and conducted by the U.S. Census Bureau. This report represents the initial results of the first collection of NTPS. The purpose of NTPS is to collect information that can provide a detailed picture of U.S. elementary and secondary schools and their staff. This information is collected through school, principal, and teacher surveys, and information can be linked across all three surveys. The 2015-16 NTPS uses a school-based sample of public schools. Because of this school-based design, principals associated with public schools were included in the sample. Teachers associated with a selected school were sampled from a teacher list provided by the school, collected from school websites, or purchased from a vendor. The selected samples include about 8,300 traditional and charter public schools and public school principals, and 40,000 public school teachers. The samples were drawn to support estimates by geography, grade span, and charter school status. The reader is referred to the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming) for details about these estimation domains and their precision criteria. The data were collected via mailed questionnaires and internet instruments with telephone and in-person field follow-up. The first questionnaires were mailed in September 2015, and data collection ended in August 2016. The weighted unit response rate was 72.5 percent for public schools. For detailed information about response rates, bias analysis results, methodology, and design of the 2015-16 NTPS, please see the technical notes of this report in appendix B or the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming). The purpose of this First Look report is to introduce new data through the presentation of tables containing descriptive information. Selected findings chosen for this report demonstrate the range of information available on the 2015-16 NTPS Public School Restricted-Use Data File. The selected findings do not represent a complete review of all observed differences in the data and are not meant to emphasize any issue. This First Look report highlights findings from the NTPS public school survey. Findings from the principal and teacher surveys will be presented in two companion First Look reports: \u2022 Characteristics of Public Elementary andSecondary School Principals in the United States: Results From the 2015-16 National Teacher andPrincipal Survey First Look (NCES 2017-070); and"}, {"section_title": "\u2022 Characteristics of Public Elementary and Secondary School Teachers in the United States:", "text": "Results From the 2015-16 National Teacher andPrincipal Survey First Look (NCES 2017-072). The tables in this report contain frequencies and percentages demonstrating bivariate relationships. All results have been weighted to reflect the sample design and to account for nonresponse and other adjustments. Comparisons drawn in the selected findings have been tested for statistical significance at the .05 level using Student's t statistics to ensure that the differences are larger than those that might be expected due to sampling variation. While the selected findings include only statistically significant findings they do not include every statistically significant comparison. No adjustments were made for multiple comparisons. Many of the variables examined are related to one another, and complex interactions and relationships have not been explored. Statistical Analysis Software (SAS 9.4) and SUDAAN (11.1) were used to compute the statistics for this report. Tables of standard errors are provided in appendix A. Detailed information about the survey methodology is provided in appendix B. Appendix C contains a description of the variables used in this report. More information about NTPS can be found at https://nces.ed.gov/surveys/ntps."}, {"section_title": "Selected Findings", "text": "\u2022 During the 2015-16 school year, there were an estimated 90,400 K-12 public schools in the United States, including 83,500 traditional public and 6,900 public charter schools. These schools served nearly 49.3 million students, with about 46.2 million in traditional public schools and another 3 million in public charter schools. Between the 2011-12 SASS and the 2015-16 NTPS, the number of public charter schools increased from 4,480 to 6,900 (Bitterman, Gray, & Goldring 2013) (table 1). \u2022 About 99 percent of public schools had at least one student with an Individual Education Plan (IEP) because of special needs. Additionally, 76 percent of public schools had instruction specifically designed to address the needs of English language learners or limited English proficient students (table 2). \u2022 Nationwide, about 21 percent of public schools offered at least one course entirely online. This was more common among public charter schools (29 percent) than it was among traditional public schools (20 percent). Offering one or more classes that were entirely online was much more common among high (58 percent) or combined (64 percent) schools, and very small (45 percent) or very large (44 percent) schools than for all public schools (21 percent). Among schools offering online courses, relatively more public charter schools offered all of their classes online (14 percent) than traditional public schools (5 percent) (table 3). \u2022 Including full-time and part-time staff, public schools employed an estimated 124,420 school counselors, 66,320 psychologists, and 44,920 social workers. They also employed 96,440 speech therapists and 84,020 nurses, as well as 73,580 librarians/library media specialists and 80,920 instructional coordinators and supervisors. In addition, public schools employed a variety of full-time and part-time aides, such as 483,590 special education aides. These schools employed 400,830 food service personnel, 332,270 custodial and maintenance personnel, 66,110 technology specialists, and 260,310 secretaries and other clerical support staff (table 4). \u2022 About two-thirds (66 percent) of public schools had teachers or staff with specialist or academic coaching assignments. 2 Among public schools, 78 percent of primary schools, 60 percent of middle schools, 45 percent of high schools, and 50 percent of combined schools had teachers or staff with these assignments. Relatively fewer small schools had such staff, including only 30 percent of schools with less than 100 students and 53 percent of schools with 100 to 199 students in comparison to all public schools (66 percent) (table 5). \u2022 Overall, 59 percent of public schools had instruction beyond the normal school day for students who need academic assistance. Relatively more charter schools (65 percent) provided this instruction than traditional public schools (59 percent). This type of instruction was most frequently provided in schools with 1,000 or more students (72 percent), middle schools (68 percent), and city schools (68 percent) than for all public schools (59 percent). Additionally, 43 percent of all public schools had instruction beyond the normal school day for students who seek academic advancement or enrichment. Again, relatively more charter schools (50 percent) provided this than traditional public schools (43 percent) (table 6). \u2022 The average start time for public schools was 8:10 a.m. Nationally, only about 4 percent of schools had start times before 7:30 a.m. This early start was more common among schools with 1,000 or more students (14 percent) than all public schools (4 percent). It was also substantially more common among high schools (10 percent) than among primary (2 percent), middle (7 percent), or combined (4 percent) schools (table 7). \u2022 About 87 percent of public schools in the United States were regular schools, 6 percent were alternative or other schools, 3 4 percent were special program emphasis, 4 2 percent were special education, 5 and 2 percent were career/technical/vocational schools 6 (table 8). Alternative/other school offers a curriculum designed to provide alternative or nontraditional education; it does not specifically fall into the categories of regular, special program emphasis, special education, or vocational school. Special program emphasis school is a science or math school, performing arts school, talented or gifted school, foreign language immersion school, etc. Special education school primarily serves students with disabilities. Career/technical/vocational school primarily serves students being trained for occupations. Table 1. Total number of public schools and students, and percentage of schools and students that participated in the Title I and federal free or reduced-price lunch programs, by  selected school  or reduced-price lunch program 5,000 2,208,600 24.4 19.9 \u2020 \u2020 \u2020 Not applicable. 1 Respondents were provided the following explanation on the questionnaire for Title I of the Elementary and Secondary Education Act: \"Title I is a federally funded program that provides educational services, such as remedial reading or remedial math, to children who live in areas with high concentrations of low-income families.\" These services were received at the school or at any other location. 2 Percentages are based on all students, including those in schools that did not receive Title I services. 3 Percentages are based on all students, including those in schools that did not participate in the federal free or reduced-price lunch program. NOTE: Detail may not sum to totals because of rounding. Some of the counts for selected school characteristics may not match between school and principal data files due to independent weighting procedures, differential nonresponse, rounding, and not every school having a principal. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Data File,\" 2015-16.   (CV) for this estimate is between 30 percent and 50 percent (i.e., the standard error is at least 30 percent and less than 50 percent of the estimate). \u2021 Reporting standards not met. The coefficient of variation (CV) for this estimate is 50 percent or greater (i.e., the standard error is 50 percent or more of the estimate) or the response rate is below 50 percent. NOTE: Detail may not sum to totals because of rounding and because some data are not shown. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Data File,\" 2015-16.   1,470 4,650 ! Interpret data with caution. The coefficient of variation (CV) for this estimate is between 30 percent and 50 percent (i.e., the standard error is at least 30 percent and less than 50 percent of the estimate)."}, {"section_title": "Estimate Tables", "text": "Includes both instructional and noninstructional aides. Includes non-law enforcement security guards or security personnel. Includes career law enforcement officers with arrest authority, who have specialized training and are assigned to work in collaboration with school organizations (School Resource Officers), and sworn law enforcement officers who are not School Resource Officers. NOTE: Detail may not sum to totals because of rounding. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Data File,\" 2015-16. 14.2 45.7 ! Interpret data with caution. The coefficient of variation (CV) for this estimate is between 30 percent and 50 percent (i.e., the standard error is at least 30 percent and less than 50 percent of the estimate). NOTE: A specialist works with students and a coach works with teachers. Coaching includes observing lessons, providing feedback, and demonstrating teaching strategies. Detail may not sum to totals because of rounding. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Data File,\" 2015-16.  19.6 7.9 ! Interpret data with caution. The coefficient of variation (CV) for this estimate is between 30 percent and 50 percent (i.e., the standard error is at least 30 percent and less than 50 percent of the estimate). NOTE: Detail may not sum to totals because of rounding. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Data File,\" 2015-16. 3.0 ! 15.0 32.9 # Rounds to zero. ! Interpret data with caution. The coefficient of variation (CV) for this estimate is between 30 percent and 50 percent (i.e., the standard error is at least 30 percent and less than 50 percent of the estimate). \u2021 Reporting standards not met. The coefficient of variation (CV) for this estimate is 50 percent or greater (i.e., the standard error is 50 percent or more of the estimate). 1 Special program emphasis includes schools such as science or math schools, performing arts schools, talented or gifted schools, foreign language immersion schools, etc. 2 Special education school primarily serves students with disabilities. 3 Career/technical/vocational school primarily serves students being trained for occupations. 4 Alternative/other school offers a curriculum designed to provide alternative or nontraditional education; does not specifically fall into the categories of regular, special program emphasis, special education, or vocational school. NOTE: Detail may not sum to totals because of rounding and because some data are not shown. SOURCE: U.S. Department of Education, National Center for Education Statistics, National Teacher and Principal Survey (NTPS), \"Public School Data File,\" 2015-16.         "}, {"section_title": "A-3", "text": ""}, {"section_title": "A-4", "text": ""}, {"section_title": "A-5", "text": ""}, {"section_title": "A-7", "text": ""}, {"section_title": "A-8", "text": ""}, {"section_title": "A-9", "text": ""}, {"section_title": "A-10", "text": ""}, {"section_title": "A-11", "text": ""}, {"section_title": "Overview of the NTPS School Survey", "text": "The National Teacher and Principal Survey (NTPS) is sponsored by the National Center for Education Statistics (NCES) of the Institute of Education Sciences within the U.S. Department of Education and is conducted by the U.S. Census Bureau. NTPS is a nationally representative sample survey of public K-12 schools, principals, and teachers in the 50 states and the District of Columbia. This is the first year of NTPS. The 2015-16 NTPS consisted of questionnaires for three types of respondents: public schools, public school principals, and public school teachers. The information can be linked across teachers, principals, and schools. There is a separate data file for each type of respondent (school, principal, and teacher). For the content of the questionnaires, see https://nces.ed.gov/surveys/ntps/question1516.asp. NTPS was designed to produce national estimates for public elementary and secondary schools, principals, and teachers, including national estimates for public charter schools and the principals and teachers within them. Additionally, the teacher survey was designed to produce national estimates of teachers by subject matter taught and by full-time or part-time status. "}, {"section_title": "Sampling Frames and Sample Selection", "text": "The starting point for the 2015-16 NTPS public school sampling frame was the preliminary 2013-14 Common Core of Data (CCD) Nonfiscal School Universe data file. 1 The sampling frame was adjusted from CCD to fit the definition of a school eligible for NTPS. To be eligible for NTPS, a school was defined as an institution or part of an institution that provides classroom instruction to students, has one or more teachers to provide instruction, serves students in one or more of grades 1-12 or the ungraded equivalent, and is located in one or more buildings apart from a private home. It was possible for two or more schools to share the same building; in that case, they were treated as different schools if they had different administrators (i.e., principal or school head). This definition is unchanged from the Schools and Staffing Survey (SASS). The 2015-16 NTPS universe of schools is confined to the 50 states plus the District of Columbia and excludes the other jurisdictions, Department of Defense overseas schools, and CCD schools that do not offer teacher-provided classroom instruction in grades 1-12 or the ungraded equivalent. This last group includes schools that are essentially administrative units that may oversee entities that provide classroom instruction or may only provide funding and oversight. While Bureau of Indian Education-funded (BIE) schools are included in NTPS, these schools were not oversampled and the data do not support separate BIE estimates. The NTPS definition of a school is generally similar to the CCD definition, with some exceptions. Like SASS, NTPS allows schools to define themselves. During SASS collections, Census Bureau staff observed that in situations where two or more schools have the same administration, these schools were reported separately on CCD but generally reported as one entity for SASS. Thus, CCD schools with the B-3 same location, address, and phone number were collapsed during the frame building on the assumption that the respondent would consider them to be one school. Due to similarities with SASS, NTPS also followed the same type of collapsing procedure. A set of rules was applied to determine in which instances school records should be collapsed together. When school records were collapsed together, the student and teacher counts, grade ranges, and names as reported to CCD were all modified to reflect the change. Finally, since CCD and NTPS differ in scope and their definition of a school, some records were deleted, added, or modified to provide better coverage and a more efficient sample design for NTPS. For a detailed list of frame modifications, see the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming). After deleting, collapsing, and adding school records, the NTPS public school sampling frame consisted of about 87,600 traditional public schools and 6,500 public charter schools. NTPS uses a systematic, probability proportionate to size (PPS) sample (for an explanation of PPS sampling, see Cochran 1977). Unlike SASS, NTPS did not stratify schools prior to sampling. Rather, some types of schools were oversampled based on specific characteristics such as the following: \u2022 School grade level (primary, middle, high, combined); \u2022 Collapsed urbanicity (city, suburban, town, rural); and \u2022 Charter status. In addition to oversampling based on specific school characteristics, sample sizes were inflated for schools in the six states with the smallest number of schools: Alaska, District of Columbia, Hawaii, Rhode Island, Vermont, and Wyoming. Prior to sampling, schools were sorted by the following: \u2022 charter status; \u2022 school grade level (four categories); \u2022 urbanicity (four categories); \u2022 poverty status (four categories); \u2022 school size category (based on full-time equivalent [FTE] teachers; two categories for middle and combined charter schools, three categories for all other schools); \u2022 school type for noncharter schools (four categories); \u2022 state; and \u2022 the number of FTE teachers. These sampling procedures resulted in a total public school sample of about 7,130 traditional public schools and 1,170 public charter schools."}, {"section_title": "Data Collection Procedures", "text": "In 2015-16, NTPS employed a combined mail-based and internet survey approach, with subsequent telephone and in-person follow-up. Data collection included the Teacher Listing Form, the Principal Questionnaire, the School Questionnaire, and the Teacher Questionnaire. This report focuses on the School Questionnaire."}, {"section_title": "B-4", "text": "In preparation for school-level data collection, advance letters were mailed to the sampled schools in June 2015 to verify their addresses. Initial school packages were mailed in September 2015. 2 Next, schools were telephoned using a computer-assisted telephone-interviewing instrument to verify school information, establish a survey coordinator, and follow up on the Teacher Listing Form if the school had not already provided an electronic teacher list. The in-person follow-up period was preceded by phone calls from the telephone centers to remind the survey coordinators to have staff complete and return all forms. Data collection ended in August 2016. One of the main goals of the data collection plan for the 2015-16 NTPS was to target the schools that presented a challenge to data collection during previous administrations of SASS. These \"known difficult\" schools have resulted in poor response rates for certain school types (e.g., large schools in urban areas). Sampled schools that have a known large impact on weighting were targeted, as well. These schools were identified during sampling, and their data collection priority flag was set accordingly. Contact strategies that were more proactive during the early phases of data collection were employed during 2015-16 NTPS data collection to mitigate potential low response rates for these cases. Survey coordinators also were utilized during data collection. The role of the survey coordinator was to be the primary contact person at the school. A survey coordinator's duties included facilitating data collection by passing out questionnaires to the appropriate staff, reminding the staff to complete their questionnaires, and collecting the questionnaires to return. The data collection follow-up strategies for schools with a survey coordinator were different from schools without a survey coordinator, with the more proactive approach taken for those schools without a survey coordinator. An additional sample of schools was selected to test the impact of offering internet response at the onset of data collection on the school-level questionnaire response rates. The schools offered this option were purely experimental-that is, their data are not included in the final data files and products, and their response rates were not attributed to the 2015-16 NTPS response."}, {"section_title": "Data Processing and Imputation", "text": "The Census Bureau checked returned questionnaires, keyed the data, and implemented quality control procedures. Questionnaires that had a preliminary classification of a complete interview were submitted to a series of computer edits consisting of a range check, a consistency edit, 3 a blanking edit, 4 and a logic edit. 5 After these edits were run and reviewed by analysts, the records were put through another edit to make a final determination as to whether the case was eligible for the survey and whether sufficient data had been collected for the case to be classified as a complete interview. After the final edits were run, cases with \"not-answered\" values for items remained. Values were imputed for these cases using two main approaches. First, donor respondent methods, such as hot-deck imputation, were used. Second, if no suitable donor case could be matched, the few remaining items were imputed using mean or mode from groups of similar cases to impute a value to the item with missing data. After each stage of imputation, computer edits were run again to verify that the imputed data were consistent with the existing questionnaire data. If that was not the case, an imputed value was blanked out by one of these computer edits due to inconsistency with other data within the same questionnaire or because it was out of the range of acceptable values. In these situations, Census Bureau analysts looked at the items and Weighting adjustments were designed to reduce or eliminate nonresponse bias and to reduce the variance introduced due to sampling by adjusting the sample estimates to known totals from the frame. The finalweighted comparisons to eligible cases shown in table B-1 reflect the effect of weighting adjustment. This table shows that weighting adjustments eliminated most but not all evidence of potential bias. Evidence of potential bias remains after weighting adjustments for the following national-level items included in the analysis: \u2022 Enrollment, for schools with less than 200 students and schools with 1,000 or more students; \u2022 Number of teachers, for schools with 10 to less than 25 teachers, 75 or more teachers; and \u2022 Percent free or reduced-price lunch eligible, for schools where less than 35 percent of students were eligible for free or reduced-price lunches. For further information on unit response rates and nonresponse bias analysis, see the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming)."}, {"section_title": "B-7", "text": "Item response rates. The item response rate indicates the percentage of respondents who answered a given survey question or item. The weighted NTPS item response rate is calculated by dividing the weighted number of respondents who provided an answer to an item by the weighted number of respondents who were eligible to answer that item. 8 Table B-2 provides a summary of the weighted item response rates. For the public school data, five of the survey items included in this report have item response rates less than 85 percent. Those items were (1) the write-in portion of question 1-6, describe the school; (2) question 2-5b item 13, difficulty in filling other vacancies; (3) question 3-3, minimum number of community service hours required of 2016 high school graduates; (4) question 4-4b, number of students in K-12 schools approved for free or reduced-price lunch; and (5) question 5-2, governance structure of public charter school. For further information on item response rates and bias analysis, see the Survey Documentation for the 2015-16 National Teacher and Principal Survey (Cox et al. forthcoming). "}, {"section_title": "Weighting", "text": "The general purpose of weighting is to scale up the sample estimates to represent the target survey population. For NTPS, a base weight is used as the starting point. In most cases, this base weight is the simple reciprocal of the unit's probability of selection on the frame (the initial base weight), and in other cases, adjustments are made to this frame base weight to reflect multiple chances of selection from the frame or other situations such as subsampling. Next, a series of nonresponse adjustment factors are calculated and applied based on a weighting cell adjustment. Weighting cells are developed using tree search algorithms. These cells are selected to be homogeneous in response propensity within cells and heterogeneous in response propensity across cells (response propensity is the underlying chance that a particular sample unit will respond by completing the questionnaire: its individual response rate). The adjustment is the inverse of the weighted response rate within each cell, and each respondent in the cell receives this adjustment. Nonrespondents are given weights of zero and the respondents are reweighted to represent the nonrespondents. The variables examined for potential bias were the same as those used by the tree search algorithms. All of the subgroups that showed potential bias as given in table B-1 above were used as cell generators by the tree search algorithms, as well as other subgroups which are related, and may show differential response conditional on other subgroups (i.e., they may be chosen as cell generators by the tree search algorithm within particular branches). Finally, for the school file, a raking factor is calculated and applied to the sample to adjust the sample totals to the frame totals, so that the sum of the weights within each of the specified cells is equal to the corresponding frame total for the cell. These cells are defined based on school level, urbanicity, and percentage of students eligible for free or reduced-price lunch. The weights are then adjusted to the control totals by an iterative process, referred to as raking, until the weights simultaneously aggregate to B-8 be equal to each set of control totals. In some cases, extreme weights may be trimmed back to a cutoff value. This all improves the precision of survey estimates. The product of these factors is the final weight for each NTPS respondent, which appears as SFNLWGT on the NTPS Public School Data File. The counts in table 1 (in the Estimate Tables section) do not necessarily match the frame counts because some cases in the frame were found to be ineligible (i.e., out of scope). Some of the counts for selected school characteristics may not match between school and principal data files due to independent weighting procedures, differential nonresponse, rounding, and not every school having a principal."}, {"section_title": "Variance Estimation", "text": "In surveys with complex sample designs, such as NTPS, direct estimates of sampling errors that assume a simple random sample typically underestimate the variability in the estimates. The NTPS sample design and estimation include procedures that deviate from the assumption of simple random sampling, such as sampling with differential probabilities. One method of calculating sampling errors of complex sample designs is jackknife replication. Jackknife replication methods involve dropping a small portion of the sample from the full sample and computing the statistic of interest for the retained and reweighted sample (the jackknife replicate). The sum of squares of the replicate estimates around the full sample estimate provides an estimate of the variance of the statistic. The NTPS school data file includes a set of 200 replicate weights designed to produce variance estimates. The set of replicate weights for each file should be applied to the respondents in that file. The replicate weights for NTPS respondents are SREPWT1-SREPWT200 for schools."}, {"section_title": "Reliability of Data", "text": "NTPS estimates are based on samples. The sample estimates may differ somewhat from the values that would be obtained from the universe of respondents using the same questionnaire, instructions, and field representatives. The difference occurs because a sample survey estimate is subject to two types of errors: nonsampling and sampling. Estimates of the magnitude of sampling error for NTPS data can be derived or calculated. Nonsampling errors are attributed to many sources, including definitional difficulties, the inability or unwillingness of respondents to provide correct information, differences in the interpretation of questions, an inability to recall information, errors made in collection (e.g., in recording or coding the data), errors made in processing the data, and errors made in estimating values for missing data. Quality control and edit procedures were used to reduce errors made by respondents, coders, and interviewers."}, {"section_title": "Comparability to SASS", "text": "NTPS is a new survey that is strongly based on SASS. However, care must be taken in estimating changes over time in data elements that both surveys have in common because some of the change measured may not be attributable to a change in the education system. Some of the change may be due to changes in the sampling frame, changes in the questionnaire item wording, or other changes. Additionally, NTPS is a different survey than SASS and pulls data from a larger variety of sources and timeframes than SASS did. While SASS collected data on student race/ethnicity, special programs, and high school graduation, the 2015-16 NTPS gets this information from external sources. Data on student gender and race/ethnicity are taken from the 2014-15 CCD, while B-9 graduation rates come from the 2014-15 EDFacts data and information on special programs 9 came from the 2013-14 Civil Rights Data Collection. Additionally, the 2015-16 NTPS is not representative at the state level, and comparisons to SASS may only be made at the national level. Private sector schools are also excluded from the 2015-16 NTPS. The next round of NTPS, in 2017-18, will include private sector schools and be representative at the state level."}]