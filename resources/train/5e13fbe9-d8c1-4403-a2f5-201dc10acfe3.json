[{"section_title": "", "text": "visceral fat more than subcutaneous fat has been associated with numerous age-related problems, such as insulin resistance, chronic inflammation, and cardiac diastolic dysfunction. Computed tomography (CT) is a widely adopted technique for assessing abdominal fat. Measurements of subcutaneous and visceral fat areas are typically computed from CT images using manual or semimanual analyses operated by clinical specialists. Even though these techniques usually provide reliable results, they are time-consuming and affected by intra-and inter-operator variability. Therefore, a regional fat quantification approach is highly desirable to increase the analysis throughput and reproducibility, especially in large epidemiological studies (3)(4)(5)(6). Earlier abdomen fat quantification approaches (7,8) required user intervention to define a region of interest and detected the fat voxels using density thresholding techniques in the domain of Hounsfield units (HUs). More recent techniques make use of joint intensity and texture information in a fuzzy affinity framework to identify the fat class (9), employ shape and appearance models for quantification of regional fat and muscle compartments (10), or use radial analysis to delineate the boundary between subcutaneous and visceral fat (11). Despite the high level of sophistication and accuracy that has been achieved by the state-ofthe-art methods, the presence of food residues in the intestines that can greatly reduce precision and even introduce a bias in the measure has not been explicitly addressed in the literature. The pixels of the food particles have HUs that greatly overlap with those of the visceral fat voxels and are usually identified as fat when simple intensity criteria are used. The quantification error induced by food residues can introduce a relevant bias in studies of aging because the permanence of food residues is likely to occur in larger quantities in older than in younger individuals. Herein we present a method for automated quantification of abdominal fat in CT that concentrates on reducing false positives in the estimation of visceral fat resulting from food residues. The fat identification and separation stage uses intensity-based clustering and a gradient vector flow (GVF) active contour model. In several instances, the detected visceral fat includes regions of food residues. To exclude these areas from the quantification of visceral fat, we applied a machine learning scheme that employs texture, local shape features, and a support vector machine (SVM) classifier to identify and remove the food residues within the intestines. The food residue removal stage is applied as a final step in our methodology. In the experiment section, we report performance evaluation of our method against semimanually segmented reference masks of fat regions and draw conclusions on the applicability of this approach in a large-scale study."}, {"section_title": "MATERIALS AND METHODS", "text": "Our methodology can be divided into three main processes: identification of global fat voxels, separation of visceral from subcutaneous fat, and removal of food residues. The main steps of these processes are depicted in Figure 1 and are described in the following section."}, {"section_title": "Participants and CT Imaging", "text": "In our experiments, we used 168 CT abdomen scans of participants of the Baltimore Longitudinal Study of Aging (BLSA), an ongoing epidemiological study that focuses on aging and age-related traits. We selected participants over a wide range of body mass index and visceral and subcutaneous fat areas. We applied our scheme to single-slice CT images acquired at the umbilical level (i.e., at the L4-L5 vertebrae on the lumbar column using a Siemens Somatom Sensation 10 CT scanner [Siemens, Malvern, PA]). All scans were performed with a 500 \u00d7 500 mm field of view, 512 \u00d7 512 image matrix, and 10-mm slice thickness. The considerable slice thickness was employed to achieve a more extensive superoinferior coverage at the umbilical level and reduce the variability typical of a thin slice."}, {"section_title": "Subcutaneous and Visceral Fat Segmentation", "text": "We first removed the bed and calibration phantom from the trunk by applying foreground/ background thresholding and selecting the largest connected component as the trunk. Then, we applied Fuzzy C-Means clustering (12) to the pixel intensities of the trunk and divided the pixels into four groups corresponding to air, muscle, fat, and bone tissues. Fuzzy C-Means produces vectors of cluster membership values in the range [0,1] for all input samples. Each sample was subsequently assigned to the cluster of maximum membership. We mapped the labeled samples back to the image plane and identified the fat group based on the average cluster intensity. Our next task was to separate the subcutaneous from visceral region of fat using a GVF snakes-based approach (13). The main difficulty was that the contrast between the subcutaneous region and visceral cavity is much lower than the contrast between the subcutaneous region and air thus affecting the GVF computation. To overcome this limitation, we computed the GVF on the fat membership map produced by Fuzzy C-Means that enhances the contrast between fat and other tissues. After snake convergence, we labeled the interior fat pixels as visceral and the exterior fat pixels as subcutaneous."}, {"section_title": "Removal of Food Residues", "text": "This fat segmentation technique is expected to produce acceptable measurements of subcutaneous and visceral fat. However, a frequent source of error in the quantification of visceral fat is the presence of food residues in the intestines during the scan. Therefore, correction of this error is of critical importance. An example of manual food residue removal is displayed in Figure 2."}, {"section_title": "Feature Analysis", "text": "In our preliminary experiments, we observed that the food residues may take on variable shapes and sizes in the intestines and subsequently in the visceral cavity. Therefore we expect shape and size to be of limited separation capability. In addition, the HUs of food residues are greatly overlapping with the HUs of the visceral fat as seen in Figure 3, indicating that the use of original intensities only, would yield high classification error. Therefore we decided to use texture-based and local shape features along with intensity features for separation of food residues from visceral fat. We used Gabor filters to extract textured image features in multiple resolutions. The wavelet transform has been widely used for multiscale representation and analysis of signals in medical and biological applications. The main difference from traditional Fourier techniques is that wavelets can localize the information in the time-frequency plane (14). More specifically, the wavelet transforms provide a time-frequency decomposition of a signal over a range of characteristic frequencies that separates individual signal components more effectively than conventional Fourier analysis techniques. The Gabor filters have the advantage of optimizing the joint two-dimensional uncertainty in time and frequency and can be considered as edge and line bar detectors that can be tuned for different orientations and scales (15,16). Gabor functions form a complete but nonorthogonal basis. The twodimensional Gabor function is the product of an elliptical Gaussian and a complex sinusoid and is given by: (1) In this equation, \u03c3 x and \u03c3 y are the standard deviations of the elliptical Gaussian along x and y orientations and W is the sinusoid frequency. The filter dictionary can be produced by dilations and rotations of the mother Gabor wavelet (17). We used a filter bank of four scales and six orientations that is illustrated in Figure 4. Details on derivation of twodimensional Gabor filters are given elsewhere (18). The Laws' texture energy filters (18) were designed to measure the amount of variation within a sliding window over the image plane. The basic operators were one-dimensional arrays that can be transposed and multiplied among each other to generate two-dimensional kernels. We computed 24 features based on pair-wise combinations of the one-dimensional kernel bank of {L5,E5,S5,R5,W5} used for averaging, and edge, spot, ripple, and wave detection, respectively. We use the average L5L5 for contrast normalization and then we omit it from the texture representation producing a texture vector with 24 components for each pixel. We generated multiscale representations of the original CT images according to scale-space theory. Starting from the original formulation of scale-space theory (19), Witkin formalized the scale-space representation of a signal as its convolution with Gaussian filters of increasing widths (20). Koendering later generalized the idea and pointed out that the scalespace is produced by the solution of heat diffusion equation (21). Several applications have been proposed since then, including multiscale segmentation (22). Here we generate linear scale-space using Gaussian kernels and a nonlinear domain by anisotropic diffusion filtering. The nonlinear space smooths the interior of local pixel neighborhoods and preserves edge localization. We generate five scales in each domain resulting in 10 additional features. In our feature domain, we included the spatial coordinates of each sample on the image plane. To reduce variability resulting from the pose or size of each subject, we decided to map the spatial coordinates to a canonical space. We applied principal axes registration (23,24) to the abdominal mask-produced in the segmentation stage-to estimate a linear transformation model with 6\u00b0 of freedom corresponding to translation, rotation, and scaling. We first compute the translation using the trunk's centroid. The Principal Component Analysis (PCA) eigenvector orientations determine the rotation parameters and the eigenvalues determine the scaling factors. We then mapped the spatial coordinates of our samples to the canonical space using the computed transforms. We also added the original CT intensities, median filtered and gradient magnitude of original CT image features to our texture, scale-space and spatial coordinates features, forming a feature space of dimensionality D = 63. An example of an original CT image and the computed texture features is depicted in Figure 5."}, {"section_title": "Classification Using SVMs", "text": "Our goal was to train the classifier to distinguish the food residues from visceral fat based on the computed features and to integrate these results in the last step of our fat quantification methodology to reduce the false positives produced by the fat segmentation stage. In the classification step, we used a two-class support vector machine classifier (25) with a radial kernel function. SVM is a statistical machine learning technique that can be used for regression or classification. It can be applied to linear or nonlinear problems by means of a kernel function that maps the data samples to a high-dimensional feature space in which the problem becomes linearly separable (25). In the binary classification problem, we typically have a training data set comprising N data samples x 1 , x 2 , \u2026, x N , with targets t 1 , t 2 , \u2026, t N such that t n \u2208 {\u22121, 1}. Our objective is to define a decision function y(x), which in the linear form is y(x) = w T \u03c6(x) + b, and to be able to classify new data points x according to the sign of y(x). This is considered to be a constrained optimization problem and can be solved by use of Lagrangian multipliers a n . The function to be optimized becomes: (2) where a = {a 1 , \u2026 a N }. For nonlinear decision functions, the solution is to define a kernel function Advantages of this technique are good generalization capability, robustness in high dimensions, and convexity of the objective function. Because of these advantages, the literature of SVM theory and applications is very broad. More detailed and formal descriptions of SVMs can be found elsewhere (25)(26)(27)."}, {"section_title": "Modeling for Imbalanced Classification", "text": "As mentioned previously, because visceral fat is more prevalent than food residues at an approximate rate of 11.4:1, our dataset is imbalanced. Although SVM is known to be able to handle moderately imbalanced data, we tested two different approaches for classification. The first one was to use cost-weighting to each class and the other was based on resampling. In cost-weighing, we followed the method reported by Chang et al (28) that produced encouraging results previous work (29). We also implemented bootstrap aggregation (25) (ie, bagging) in the training stage as an alternate strategy for addressing imbalanced classes. For each subject, we randomly undersampled the majority class (ie, visceral fat) to match the sample size of the minority class (ie, food residues), and trained our classifier over the undersampled train dataset. We repeated this process n times (n = 5) thus producing n different models. At the testing stage, we predicted the class of each pixel by each model and applied classifier decision voting to produce the final classification."}, {"section_title": "RESULTS", "text": "To illustrate the significance of the food residue removal process, we computed the percentages of food residues over the visceral fat area and the visceral fat areas from reference measurements. A clinical specialist produced reference masks of subcutaneous fat, visceral fat, and food residues using a semimanual workflow. This step produced n = 516,340 pixel samples extracted from 168 CT images. We then plotted the food residue percentages versus the visceral fat areas as depicted in Figure 6. From this figure, we conclude that there is no significant correlation between food residue areas and visceral fat areas; therefore, we cannot predict the food residue areas from visceral fat measurements. We also note that although the average percentage of food residues is relatively small (ie, about 3.6%), it has a considerable variance (minimum = 0% and maximum = 81%) that may bias visceral fat quantification. As a result, this source of error needs to be addressed. In our next experiment, we trained and tested the classification scheme using different feature selection/extraction techniques. Our classification targets were the reference masks of visceral fat and food residues produced by the semimanual workflow. We compared the classification performance of the complete feature domain described in the previous section with the use of linear or nonlinear scale-space, Gabor-based, or Laws-based features only. We also tested a feature selection methodology that selects the top ranking features according to the Fisher's distance measure, the hierarchical dimensionality reduction (HDR) feature extraction method that iteratively computes the correlation matrix between features and merges the most correlated feature pair until the lower correlation threshold is reached (25), and PCA-based dimensionality reduction. To evaluate these techniques, we report the classification rates using six-fold cross-validation (Table 1). More specifically, we report values of true-positive rate (TPR), true-positive rate (TNR), classification accuracy (ACC), and area under the receiver operating characteristic (ROC) curve (AUC). The original feature space produces the most accurate classification indicating that all employed features contribute the separation between visceral fat and food residues. We then used k-fold cross-validation with k \u2208 {2, 4, 6} in the complete feature space (D = 63) and computed the classification rates. In Table 2, we observe that the classifier achieves very encouraging rates of accuracy. Although the sensitivity is very high, the lower specificity rates can be expected from the very diverse texture profiles of food residues and their considerable intensity overlapping with the visceral fat. We also note that as we use fewer samples for training-for example, 50% of the data for training and 50% for testing in twofold cross-validation-the loss in specificity (TNR) becomes more apparent. Still, the classification rates remain high, indicating solid generalizability. We make similar observations about generalization performance in Figure 7 that displays ROC curves for kfold cross-validation and Table 2 that reports AUC measurements for the ROC experiments. The AUC is slightly reduced for smaller values of k. Furthermore, we tested the two different approaches for classification of imbalanced data, namely the cost-weighting and classifier-bagging technique. The results in Table 2 were produced by cost-weighting in the training stage, whereas the results of resampling and bagging approach are displayed in Table 3. The cost-weighting approach produces a bit higher classification accuracy, whereas bagging has higher specificity. The AUC measurements are approximately equal. Another experiment was to assess the segmentation accuracy of the subcutaneous fat, the visceral cavity-that includes all tissues besides the subcutaneous region and the visceral fat after food residue removal. We compared the segmentations produced by our approach to semimanual delineations produced by a human operator over our dataset of 168 images. We first estimated the error between areas computed by the tested and reference workflows. The measures of agreement were the area error relative to the manual segmentation and the Pearson correlation coefficient between the two groups of measurements. Because the area errors do not account for the overlap between the segmented regions, we also computed the Dice similarity coefficient (30) to assess the segmentation accuracy. The results in Table 4 show that the automated segmentation algorithm achieves a high level of accuracy."}, {"section_title": "DISCUSSION", "text": "We have introduced a method for assessment of regional abdominal fat from CT images aiming for application to large scale datasets of epidemiological studies. The focal point of this article is the food residue identification and removal scheme that was developed to address the occurrence of visceral fat false positives when using conventional thresholding/ clustering methods of the literature. Having formulated this task as a pattern classification problem, we computed and extracted intensity-and texture-based features, and subsequently evaluated the classification accuracy with respect to different feature domains. Our experiments indicated that the combined use of intensity, textural, and spatial domain information produces better separation between the food residues and visceral fat. We note that the sole use of intensity-based information cannot separate the two classes efficientlyas expected by the large overlap in HU space. The introduction of spatial coordinates in canonical space produced by principal axes registration clearly improves the classification performance, but still the classification error is more than 10%.We added texture representation features produced by Gabor and Law's kernels and achieved a considerable increase in sensitivity. The Gabor features and Law's features provide equivalent separability but their joint use improves the classification performance. The inclusion of scale-space features further improves the specificity of classification. The Gabor features offer a multiscale and multiorientation texture representation, whereas the Law's features measure the local texture energy. The scale-space analysis was included to describe the morphological intensity changes in multiple scales. The morphology of food residues is expected to be dependent on the specific scale of analysis, whereas the visceral fat pixels are expected to have more uniform intensity distribution in their neighborhood on the image plane. In the HDR-based feature selection process, several Law's and some scale-space features were found more correlated and merged first. The HDR method is characterized by increased specificity and slightly decreased sensitivity. The PCA dimensionality reduction also improved specificity and decreased sensitivity relatively to the complete feature space. The Fisher-based feature selection method shows increased separation for the Law's and Gabor features and the anteroposterior spatial coordinates. The overall classification produced by Fisher-based feature selection is less accurate than the complete feature space, HDR, and PCA methods because it lacks sensitivity. Overall, these results indicate that the complete feature space is the most suitable solution because our clinically relevant variable is the visceral fat that corresponds to the majority class. In the second set of experiments, we evaluated the generalization performance of food identification and observed a limited loss of specificity because we used fewer samples for training. This indicates that the food detection generalizes in a predicted manner and can be used for the complete database of the BLSA. These results were supported by a clinical scientist who visually inspected individual segmentation and quantification results over an extensive set of 1849 BLSA CT images and observed very limited visceral fat misclassifications. Another interesting consideration is the selection of an appropriate model to handle imbalanced data. We tested cost-weighting and classifier-bagging approaches and report the results in Tables 2 and 3. In these results, we observe that the cost-weighting method performs better in terms of sensitivity and classification accuracy, whereas bagging significantly improves specificity and produces similar but more stable AUC values. The decision on which approach to use is mainly driven by the application. When we are interested in sensitivity, the cost-weighting method may be more appropriate. On the other hand, when specificity is more important, then classifier-bagging is more suitable. In addition, we conducted segmentation validation experiments to assess the separation of subcutaneous fat region from the visceral cavity. The results in Table 4 show a high level of agreement between the automated and semimanual segmentation methods. The subcutaneous fat and visceral cavity segmentations produce lower relative errors and higher Dice scores than the visceral fat segmentation. This is expected because visceral fat segmentation is susceptible to errors mainly caused by the partial volume effect and food residue false positives. Still, the segmentation accuracy is quite encouraging and applicable to clinical studies. The main advantage of our technique is that it significantly reduces a type of error that was not addressed in previous published work to the best of our knowledge. This approach also is automated and therefore time-efficient and reproducible in nature. In addition, we note that the automated separation of visceral fat from subcutaneous fat is largely insensitive to anatomical differences and that the main parameter modifications are related to the thickness of subcutaneous region. On the other hand, this method was developed using cross-sectional study frame of thinking. Therefore an extension of this technique would be to use prior segmentations of each participant as baselines for subsequent time points in longitudinal analyses. Another limitation is related to the data that are two-dimensional; therefore, the estimated regional fat may be subject to variability of anatomical site selection during acquisition. In conclusion, we presented an automated abdominal fat quantification scheme with removal of false positives that is applied to CT imaging data. The method can be divided into the stages of global fat identification, segmentation of subcutaneous fat, and removal of food residues. The key contribution of this work is the development of a statistical learning scheme aiming for detection and removal of food residues from the visceral fat region. Our method was found to meet the accuracy requirements when validated against a reference standard over a set of 168 CT images selected from the BLSA. The reduction of food residues improves the quantification accuracy of visceral fat that is expected to be critical in resolving scientific questions related to clinical outcomes. Flow diagram of our abdomen fat quantification algorithm (top). It can be divided into three main processes: identification of global fat voxels, separation of visceral from subcutaneous fat, and removal of food residues from the visceral region using a statistical learning scheme. Original computed tomography image, fat membership map produced by Fuzzy C-Means, separation of visceral cavity from subcutaneous region after snake convergence, and generation of final tissue label map (bottom). (Color version of figure is available online).  Histogram of Hounsfield units of manually labeled visceral fat and food particle pixels computed from the reference masks. The significant overlap between the two classes complicates the identification of food residues directly from pixel intensities. (Color version of figure is available online). The real components of the Gabor filter bank used for representing the texture signatures of food residues in our classification scheme. (Color version of figure is available online). Example of an original computed tomography image from our database and the computed Gabor and Laws' texture energy features. We note here that the features are computed over the visceral cavity after exclusion of the subcutaneous region. (Color version of figure is available online). Scatter plot of the food residues percentage against the visceral fat area after supervised regional fat quantification. We observe that food residues and visceral fat areas are not linearly correlated and that the estimated food residue areas are characterized by high variation. (Color version of figure is available online). Received operating characteristic of k-fold cross-validation for k \u2208 {2, 4, 6} using all computed features (D = 63). We observe only a slight decline in classification performance when we use fewer samples for training (ie, for smaller values of k). This observation is consistent with results reported in Table 2. (Color version of figure is available online).    "}]