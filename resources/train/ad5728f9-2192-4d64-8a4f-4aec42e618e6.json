[{"section_title": "Abstract", "text": "The mild cognitive impairment (MCI) stage of Alzheimer's disease (AD) may be optimal for clinical trials to test potential treatments for preventing or delaying decline to dementia. However, MCI is heterogeneous in that not all cases progress to dementia within the time frame of a trial and some may not have underlying AD pathology. Identifying those MCIs who are most likely to decline during a trial and thus most likely to benefit from treatment will improve trial efficiency and power to detect treatment effects. To this end, using multimodal, imaging-derived, inclusion criteria may be especially beneficial. Here, we present a novel multimodal imaging marker that predicts future cognitive and neural decline from [F-18]fluorodeoxyglucose positron emission tomography (PET), amyloid florbetapir PET, and structural magnetic resonance imaging, based on a new deep learning algorithm (randomized denoising autoencoder marker, rDAm). Using ADNI2 MCI data, we show that using rDAm as a trial enrichment criterion reduces the required sample estimates by at least five times compared with the no-enrichment regime and leads to smaller trials with high statistical power, compared with existing methods."}, {"section_title": "Background", "text": "Recent clinical trials designed to evaluate new treatments and interventions for Alzheimer's disease (AD) at the mild-to-moderate dementia stage have largely been unsuccessful, and there is growing consensus that trials should focus on the earlier stages of AD such as mild cognitive impairment (MCI) or even the presymptomatic stage [1, 2] , if such stages can be accurately identified in individual subjects [3] [4] [5] . However, MCI is a clinical syndrome with heterogeneous underlying etiology that may not be readily apparent from a clinical workup, posing a major challenge in reliably identifying the most probable beneficiaries of a putative effective treatment [6] . For example, MCI patients may have clinical but not biomarker evidence of incipient AD, may have biomarker evidence in some modalities but not others, or may despite biomarker presence not show symptomatic progression during the trial period. An efficient MCI trial would ideally include \"only\" those patients most likely to benefit from treatment; who possess AD pathology based on a constellation of amyloid, tau, and neural injury biomarker assessments; and who are most likely to progress clinically to symptomatic AD. The typical annual conversion rate to dementia among MCI due to AD is 3%-20% across several studies [7] , where the relatively lower rates are observed in population-based cohorts and higher rates in clinical settings. The implication is that over a 2-year trial, at best only 40% of participants would have naturally progressed and the ability to detect the true efficacy of the intervention is perhaps diminished.\nTo this end, several ongoing AD trials \"enrich\" their population by using one or more disease markers as inclusion criteria [2, 8] . The general framework here is to effectively screen out subjects who are weak decliners (i.e., MCI who may not convert to AD) [9] . Unless there is a natural phase change (i.e., an elbow) in the distribution for distinguishing the at-risk and not-at-risk subjects on this scale, a fixed fraction of the total cohort is filtered out based on the study design. Imaging-based markers (e.g., fluorodeoxyglucose [FDG] , hippocampal, and ventricular volume) and cerebrospinal fluid (CSF) profiles have been shown to be effective in screening out low-risk subjects, owing to the fact that disease manifests much earlier in imaging data compared with cognition [1, 2] . However, these markers are unimodal while several studies have shown the efficacy of multimodal data [10, 11] . Furthermore, CSF cannot be used in practice as a screening instrument because assays typically need to be performed in a single batch and are highly laboratory specific [12] . To this end, several recent studies have used support vector machines (SVMs) and other machine learning models to design such multimodal markers [8, [13] [14] [15] [16] . Although most of these approaches use longitudinal data, a practical enrichment criterion should only use baseline (trial start-point) data. We argue that existing approaches to trial enrichment, including state-of-the-art machine learning-based techniques, cannot guarantee the optimal enrichment behavior which is to optimally correlate with the spectrum of dementia with high confidence, while simultaneously ensuring small intrastage variance.\nIn this work, we report the design of a novel multimodal imaging marker that is especially tuned to yield accurate predictions of future decline to AD at the level of individual subjects with small intrastage variance. This new disease marker (which we refer to as randomized denoising autoencoder marker, rDAm) is a machine learning module based on certain extensions of recent ideas in \"deep learning\" that yield state-of-the-art results in computer vision, natural language processing, and machine learning [17, 18] . We provide extensive empirical evidence that this new marker efficiently filters out low-risk subjects from the MCI population and consequently requires much smaller sample sizes per arm (for detecting a given treatment effect at some desired power) compared with any of the existing imaging-based markers. The main contributions of the article are as follows: (1) We design a novel predictive multimodal imaging-based disease marker, based only on baseline acquisitions, that correlates very strongly with future decline (i.e., disease progression); (2) We show via extensive analyses using imaging, cognitive, and clinical data that this new marker results in efficient clinical trials when used as a trial inclusion criterion."}, {"section_title": "Methods", "text": ""}, {"section_title": "Theoretical approach", "text": ""}, {"section_title": "Randomized denoising autoencoders", "text": "Our multimodal imaging marker attempts to capture, i.e., learn from a set of training images, the pattern of differences across different dementia stages. Clearly, in the neuroimaging literature, such an objective has been tackled by numerous studies in the AD setting using well-known machine learning methods such as SVMs [10, 11, 19] . But using such SVM approaches for clinical trials has limitations (additional details provided in the following); instead, we present a method that differentiates various stages of AD (i.e., correlates with the dementia spectrum), while simultaneously obtaining a small intrastage prediction variance (the prediction variance is simply the variance of the predictions given by the trained machine learning model). Such an approach gives results which are competitive with SVM-based methods (in terms of accuracy) but aligns much better with our final goal of using these ideas for clinical trials design. The basic statistical behavior of our model is a reduction in the variance at no cost of approximation bias (or accuracy). To do this, we adapt the so-called deep learning architectures that have been shown to yield state-of-the-art performance in several computer vision and machine learning applications [17, 18, 20, 21] . The main methodological challenge we overcome is to make deep architectures \"generalize\" well (i.e., yield accurate predictions on previously unseen subjects/images) in this application, which is important due to the high dimensionality of neuroimaging data accompanied by smaller training data set sizes (at most a few hundred subjects).\nWe first provide a very brief overview of our model, which we call randomized denoising autoencoders (rDA) [22] . Please refer to the Appendix, available online, for a complete description and additional mathematical details. Our solution consists of first constructing simple deep learning architectures (referred to as weak learners). Each such weak learner is a neural network learned according to a new deep learning algorithm called stacked denoising autorncoders (SDA) [20] . Because the number of dimensions (voxels) is large, each such weak learner corresponds to inspecting only a small portion (e.g., 3D local neighborhood) of the image and/or using different model hyperparameters (the network architecture and learning parameters of SDAs [20] ; refer to Section 2 in the Appendix). Although the issue of scaling to high dimensions is handled by learning only small portions of the image, these weak learners by themselves are not useful. However, using a large number of these weak learners, each of which is learned from different portions of the image, we can generate an \"ensemble\" which is much more expressive in modeling the targets/outputs compared with the weak learners themselves [23] . The ensemble outputs can correspond to uniform or weighted combination of the outputs from this suite of weak learners and are known to be less sensitive to model hyperparameters [23] . Such an ensemble learner also comes with guarantees in terms of reducing the variance of model outputs without any loss in approximation bias (i.e., overall output is unbiased whenever the weak learners are unbiased).\nOur new model rDA is then constructed by the following procedure. First, the set of voxels are divided into B number of blocks (given a priori) by randomly assigning each voxel to one or more of the B blocks. Second, within each block, T different SDAs (again, given a priori) are constructed by randomly sampling T different hyperparameters. The BxT different SDA outputs are finally combined using ridge regression. This two-level \"randomization\" over voxels and hyperparameters motivates the name \"randomized\" denoising autoencoders. The expressive power of deep architectures ensures that rDA can successfully learn complex concepts, which provide the ability to differentiate multiple stages of AD, while forcing the output variance to be as small as possible due to the ensemble structure [23] . The framework of rDA can be extended to multiple modalities by generating weak learners specific to each imaging modality and combining them across all the modalities. The rDA outputs are guaranteed to lie between 0 and 1 [20] . Hence, by training a rDA with healthy controls labeled as 1 and AD subjects as 0, we can project the scale of dementia to 0,1. These projections then serve directly as imagingderived continuous predictors of the disease, referred to as rDA markers (rDAm), that provide the confidence of the learning model that a given subject is close to \"healthy\" or \"diseased.\" In particular, rDAm values closer to 0, on previously unseen MCI subjects, are expected to convey a stronger sign of dementia than those that are closer to 1. Please refer to the Sections 1-2 in the Appendix for additional details about the rDA model (including the required background on SDAs), its training, and the calculation of rDAm."}, {"section_title": "rDAm for sample enrichment", "text": "Sample enrichment in AD clinical trials entails filtering out those subjects who are \"not\" expected to have a higher risk of progressing to dementia. In other words, enrichment entails including only the strong decliners who are most likely to benefit from the treatment. To formalize the characteristics of a \"good\" sample enricher, consider the setting where we want to design a 2-year clinical trial on a MCI population using a certain outcome measure. Let d denote the mean longitudinal change on this outcome measure due to disease. We intend to induce the treatment and reduce this change to hd, where h is the hypothesized induced treatment effect. Within this setting, the number of subjects required per arm is computed by applying a two-sample t test, which tests for the difference of mean outcome between the treatment and placebo groups [24] , as follows,\nwhere s 2 denotes the pooled variance of the outcome i.e., average of the variances at baseline and 2-year trial end point. h is the hypothesized induced treatment effect (i.e., 12h denotes the expected percentage of reduction in the outcome measure). The null hypothesis then corresponds to no difference between the two groups. For a fixed a and b, the mentioned equation shows that the sample estimates increase with s 2 and decrease with a large d. If the trial cohort includes subjects at low risk of decline (weak decliners), then d is expected to be small. Enrichment entails removing such weak decliners, thereby increasing d. However, this might have the undesirable effect of increasing s 2 because the latter is the pooled variance of the outcome. Hence, one must ensure that the enriched cohort has smaller variance (with respect to some outcome) but also has large d i.e., we need to recognize the pool of very strong decliners whose outcomes have smaller variance.\nThe natural way of ensuring small s 2 with large d is by designing an outcome with precisely these characteristics. However, the trial outcomes are generally cognitive scores, or may be individual image or CSF measures whose statistical properties may not be altered readily. But recall that the multimodal imaging marker, rDAm, is explicitly designed to ensure smaller variance while yielding prediction scores that correlate well with existing cognitive measures, which are used as the basis for defining multiple stages of dementia: from healthy to early/late MCI to completely demented. Therefore, using rDAm at baseline (trial start-point) as an inclusion criterion to remove the probable weak decliners, we expect the enriched cohort to have large d and smaller variance s 2 with respect to any outcome measure that may be desired. This directly follows from the ability of rDAm to predict many of these scores (outcomes) with high confidence. Section 3 of the Appendix presents more details on reducing sample sizes by designing enrichers with strong correlation to dementia spectrum and small prediction variance. Note that we use the word prediction variance because rDA is trained on ADs and controls (CNs) and offers prediction scores on MCIs. Ideally, and to be practically deployable, this enrichment must be performed \"only\" at baseline or the trial start-point. Hence, our first sanity check in terms of the efficacy of rDAm and using it as enricher will focus on whether rDAm computed at baseline correlates with cognitive and other imaging-derived disease biomarkers [25, 26] . If the correlations turn out to be significant, this is evidence of convergent validity, and using baseline rDAm as an inclusion criterion for enriching a clinical trial population is, at minimum, meaningful. Observe that the scale of rDAm (closer to 0 corresponds to higher confidence that a subject will decline) implies that the trial population can be enriched by screening in subjects whose baseline rDAm is smaller than some cutoff. If the enrichment threshold is denoted by t (0 , t , 1), then the enriched cohort would include \"only\" those subjects whose baseline rDAm is smaller than t. One way to choose such a threshold t is by comparing the mean longitudinal change of some disease markers (mini mental state examination [MMSE] , CDR, and so on) for the enriched cohort as t goes from 0 to 1. An alternative is to include a fixed fraction (e.g., one-fourth or one-third) of the whole population whose baseline rDAm is closest to 0."}, {"section_title": "Experimental setup 2.2.1. Participant data and preprocessing", "text": "Imaging data including [F-18]Florbetapir amyloid PET (AV45) singular uptake value ratios (SUVR), FDG PET SUVRs, and gray matter tissue probability maps derived from T1-weighted magnetic resonance imaging (MRI) data, and several neuropsychological measures and CSF values from 516 individuals enrolled in Alzheimer's disease Neuroimaging Initiative-II (ADNI2) (The ADNI was launched in 2003 by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, the Food and Drug Administration, private pharmaceutical companies, and nonprofit organizations, as a $60 million, 5-year public-private partnership. The primary goal of ADNI has been to test whether serial MRI, positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of MCI and early AD) were used in our evaluations. Of these 516 persons, (age 72.46 6 6.8, female 38%), 101 were classified as AD (age 75.5 6 5.1), 148 as healthy controls (age 70.75 6 7), and 131 and 136 as early and late MCI (age 74.3 6 7.1 and 75.9 6 7.7), respectively, at baseline. (There was a significant age difference across the four groups with F .10 and P , .001.) Among the MCI subjects, 174 had positive FH for dementia and 141 had at least one APOE \u03b54 allele. CSF measures were only available at baseline, and three time point data (baseline, 12, and 24 months) was used for the rest.\nThe imaging protocols follow the standards put forth by ADNI. MRI images are MP-RAGE/IR-SPGR from a 3T scanner. PET images are 3D scans consisting of four 5-minute frames (http://adni.loni.usc.edu/methods/documents/ mri-protocols/; http://adni.loni.usc.edu/methods/pet-analy sis/pet-acquisition/) from 50 to 70 minutes postinjection for [F-18] Florbetapir PET, and six 5-minute frames from 30 to 60 minutes postinjection for FDG PET. Modulated gray matter tissue probability maps were segmented from the T1-weighted MRI images (other tissue maps are not used in our experiments) using the SPM8 New Segment function. The segmented map was then normalized to MNI space, smoothed using 8-mm Gaussian kernel, and the resulting map was thresholded at 0.25 to compute the final gray matter image. All PET images were first coregistered to the corresponding T1 images and then normalized to the MNI space. Manually constructed masks of pons, vermis, and cerebellum were then used to scale these PET maps by the average intensities in pons and vermis (FDG PET SUVR) and cerebellum (florbetapir PET SUVR). All preprocessing was done in SPM8."}, {"section_title": "Evaluations", "text": "We train the rDA model using only baseline imaging data (from all the three modalities, MRI, FDG PET, and florbetapir PET) for AD and CN (cognitively normal) subjects where the AD class is labeled as 0 and the CN class is labeled as 1. When tested on MCI subjects, the trained model outputs a multimodal rDAm, which is a marker representing the confidence of the learning model that a given MCI subject is (or is not) likely to decline. We only use baseline imaging data for training (hence making the model deployable in practice), whereas the predictions can be performed on MCIs at baseline or future time points. Within this setup, our evaluations are twofold. We first evaluate the premise whether rDAm is a good disease progression marker. We demonstrate this by computing the dependence of well-known outcome measures including MMSE, Alzheimer's disease assessment scale (ADAS cognition 13), Montreal cognitive assessment (MOCA), Rey auditory verbal learning test (RAVLT), neuropsychological summary score for memory (PsyMEM), summary score for executive function (PsyEF), hippocampal volume, clinical dementia rating sum of boxes (CDR-SB), conversion from MCI to AD (0 -no conversion, 1 -conversion; denoted by DxConv hereafter), CSF levels (CSF tau [t], CSF phospho-tau [pt], amyloid beta-42 [Ab42], ratio of CSF tau and amyloid beta-42 [t/Ab42], and ratio of CSF phospho-tau and amyloid beta-42 [pt/Ab42]), and APOE \u03b54 and maternal/paternal FH, on rDAm computed at baseline. We used the Spearman rank order correlation coefficient to assess these dependencies and accepted as significant those statistics where the P value was ,.05. Note that we are interested in evaluating the predictive power of baseline rDAm, i.e., we report the correlations of baseline rDAm with these markers at say, 12 and 24 months, and also the longitudinal changes providing evidence that whenever rDAm is closer to 0, the subject's longitudinal changes are in fact steeper. Once this construct is appropriately validated, it is meaningful to evaluate the use of baseline rDAm for sample enrichment. To this end, we compute the sample sizes required when using the mentioned cognitive, neuropsychological, diagnostic and other imaging-based outcome measures with (and without) rDAm-based enrichment. We also compute the performance improvement given by rDAm relative to alternative imaging-derived enrichers (including region of interest [ROI] summaries from FDG and florbetapir images; FDG ROIs include left angular lobe, right angular lobe, left temporal lobe, right temporal lobe, and cingulate. AV45 ROIs include frontal lobe, temporal lobe, parietal lobe, and cingulate gray matter. The corresponding ROI measures are summed up to obtain single global summary for each of FDG and AV45), with particular attention to the current state-of-the-art imaging-based summary measure which we refer to as MKLm [10] . MKLm is based on multi-kernel SVM (MKL) [10] , which tries to harmonize contributions from multiple imaging modalities for deriving a maximum margin classifier in the concatenated Hilbert spaces. That is, a linear combination of kernels is used unlike traditional SVMs that use one single kernel, and MKL solves for both the weights on the kernels as well as the normal to the hyper-plane concurrently. Similar to rDA, MKL is trained using AD and CN subjects, and the corresponding predictions on MCIs is referred to as the MKL measure (MKLm). Please refer to the Appendix (Section 4) for more details. For better interpretation of the estimates from the perspective of a practitioner, we estimate the effect size as a function of rDAm enrichment cutoff for a given (fixed) sample size. Note that all results (correlations and the sample size calculations) only use rDAms from MCI subjects; no AD and CN subjects are included in these calculations because they were used to train the rDA model itself. Abbreviations: NA, not applicable; MCI, mild cognitive impairment; AD, Alzheimer's disease; CSF, cerebrospinal fluid; t, CSF Tau; pt, CSF phospho-Tau; Ab, amyloid beta-42; t/Ab, ratio of CSF Tau and amyloid beta-42; pt/Ab, ratio of CSF phospho-Tau and amyloid beta-42; FH, family history; rDAm, randomized denoising autoencoder marker."}, {"section_title": "Results", "text": "NOTE. Outcomes included cognitive and neuropsychological scores (MMSE, mini mental state examination; ADAS, Alzheimer's disease assessment scale (cognition 13 scale); MOCA, Montreal cognitive assessment; RAVLT, Rey auditory verbal learning test; PsyMEM, neuropsych summary score for memory; PsyEF, neuropsych summary score for executive function), hippocampal volume, CDR-SB (clinical dementia rating sum of boxes), DxConv (conversion from MCI to AD), CSF levels (t, pt, Ab, t/Ab, and pt/Ab), and APOE and family history risk factors. Spearman correlations (coefficient and P value) and t test statistic (with its P value) are reported for continuous and categorical (DXConv, FH, and APOE) data respectively.* *Observations with P ,, .0001 are bold and P , .001 are italic. Column 2 shows correlations of baseline rDAm with markers at baseline. Columns 3 and 4 are correlations of baseline rDAm with markers themselves at 12 and 24 months, respectively. Columns 5 and 6 are correlations of baseline rDAm with \"change\" (i.e. difference) in the markers from baseline to 12 and 24 months. Note that CSF levels, FH, and APOE do not have any meaning in column 5 and 6, and hence are marker \"NA.\" Same is the case with DxConv at baseline because baseline diagnosis of all subjects considered here is MCI. some disease marker after the total MCI population is enriched by removing weak decliners (subjects with baseline rDAm above certain cutoff t, which is shown on the xaxis). The plots show that MMSE, CDR-SB, and DxConv have large changes when weak decliners are progressively removed. Specifically, the changes are much steeper for 24 months compared with baseline and 12 months (black and blue colored lines in each plot). RAVLT and PsyEF resulted in irregular changes at different time points. Supplementary Fig. 6 at the end of the Appendix presents the means of the disease markers (in contrast to the mean change as shown in Fig. 1) , and the trends support the observations in Fig. 1 . Tables 2 and 3 present samples estimated using rDAm as a sample enricher at 80% statistical power (significance level of .05) and inducing a treatment effect of 25%. Recall that higher rDAm implies closer to being healthy. Hence, enrichment entails filtering out all subjects with baseline rDAm above some cutoff. Results show that compared to the no-enrichment regime (column 2, Table 2), the sample estimates from rDAm enrichment are significantly smaller, with more than five times reduction when using bottom 20 and 25 percentiles (columns 3 and 4, Table 2 ). In particular, MMSE, CDR-SB, and DxConv give consistently smaller estimates (200-600) across all columns (the four different percentiles). ADAS and PsychEF still required very large sizes web 4C=FPO web 4C=FPO Fig. 1 . Mean longitudinal \"change\" of several disease markers as a function of baseline rDAm enrichment threshold. Each plot corresponds to one disease marker (which includes MMSE, ADAS, RAVLT, MOCA, PsychMEM, PsychEF, hippocampal volume, CDR-SB, and DxConv; refer to Section 3.1 for details about these markers). The x-axis represents the baseline rDAm enrichment cutoff (t). For each t, the subjects who have baseline rDAm .. t are filtered out, and the mean of within subject change in the disease marker is computed on the remaining unfiltered subjects. Dots represent actual values, and lines are the corresponding linear fit. Blue and black represent changes from baseline to 12 and 24 months, respectively. Abbreviations: rDAm, randomized denoising autoencoder marker; MMSE, mini mental state examination; ADAS, Alzheimer's disease assessment scale (cognition 13 scale); MOCA, Montreal cognitive assessment; RAVLT, Rey auditory verbal learning test; PsyMEM, neuropsych summary score for memory; PsyEF, neuropsych summary score for executive function; HippoVol, hippocampal volume; CDR-SB, clinical dementia rating sum of boxes; DxConv, conversion from MCI to AD.\n(774 and .2000, respectively) even at 20% enrichment. Using extra covariate information in the form of FH and APOE (we slightly abuse the term covariate here in the sense that we explicitly \"filter\" out those MCI subjects who are \"not\" FH and/or APOE-positive \"before\" performing baseline rDAm enrichment), in tandem with baseline rDAm, the sample estimates further decrease as shown in Table 3 (last three columns). APOE as a covariate resulted in smallest possible estimates (,350 per arm) across all the outcomes except PsyEF (last two columns in Table 3 ), although the last column represents using both APOE and FH as covariates. DxConv as an outcome with rDAm 1 APOE enrichment yields a sample size of 170. Fig. 2 shows the detectable effect sizes as rDAm enrichment cutoff is varied, for a fixed sample size of 500 per arm. The detectable effect size (12h) decreases as more weak decliners are filtered out. This can be seen by the \"increase\" of h (y-axis) as rDAm cutoffs (x-axis) decrease, specifically for MMSE, CDR-SB, and DxConv outcomes. Finally, Table 4 compares rDAm with other imaging-derived inclusion criteria (the cutoff for all the enrichers corresponds to including the strongest 20% decliners in their respective scales). rDAm consistently outperformed other alternatives, with up to two times smaller estimates than MKLm (multimodal generalization of SVM), and much larger reductions compared with unimodal summaries (hippocampal volume, FDG ROIs, and florbetapir ROIs)."}, {"section_title": "Discussion", "text": "The ability to design clinical trials with smaller sample sizes but sufficient statistical power will enable the implementation of affordable, tractable and, hopefully, conclusive trials. Efficiency is seriously compromised in trials where there is poor biomarker specificity of disease progression and when the outcomes contain relatively high amounts of error variance. Determining whether promising treatments are effective in the MCI phase of AD requires accurate identification and inclusion of only those MCI participants most likely to convert to AD and selection of outcomes that are both disease related and possess optimal measurement properties. We have shown that the sample size required to detect a treatment effect can be substantially reduced using the proposed inclusion strategy. The central message of our empirical evaluations is that the baseline rDAm has good Abbreviations: rDAm, randomized denoising autoencoder marker; FDG, fluorodeoxyglucose; MMSE, mini mental state examination; ADAS, Alzheimer's disease assessment scale (cognition 13 scale); MOCA, Montreal cognitive assessment; RAVLT, Rey auditory verbal learning test; PsyMEM, neuropsych summary score for memory; PsyEF, neuropsych summary score for executive function; HippoVol, hippocampal volume; CDR-SB, clinical dementia rating sum of boxes; DxConv, conversion from MCI to AD; MCI, mild cognitive impairment; AD, Alzheimer's disease.\nNOTE. All estimates at significance level of .05 and 80% statistical power with treatment effect of 0.25. The second column shows sample estimates with no enrichment (i.e. all clinically diagnosed MCI subjects included), followed by using MCI subjects from bottom 20, 25, 33, and 50 percentiles on rDAm scores, respectively. For each percentile, the cutoff on rDAm scale is shown, and sample sizes smaller than 700 are in bold. Table 3 Baseline rDAm 1 FH and/or APOE for enrichment: Using already enriched subjects from the bottom 20 percentile on rDAm scale (third column of Table 2 ) and further screening out subjects with negative FH and/or APOE. Abbreviations: rDAm, randomized denoising autoencoder marker; FH, family history; MMSE, mini mental state examination; ADAS, Alzheimer's disease assessment scale (cognition 13 scale); MOCA, Montreal cognitive assessment; RAVLT, Rey auditory verbal learning test; PsyMEM, neuropsych summary score for memory; PsyEF, neuropsych summary score for executive function; HippoVol, hippocampal volume; CDR-SB, clinical dementia rating sum of boxes; DxConv, conversion from MCI to AD.\nNOTE. Second column to last columns are results with no enrichment, FH alone, APOE alone, rDAm alone, rDAM 1 FH, rDAM 1 APOE, and rDAM 1 both, respectively. The best estimates from rDAM 1 FH and/or APOE are shown in bold.\npredictive power in identifying future disease progression as shown in Table 1 and Fig. 1 . Together with rDA's capacity to reduce prediction variance, we see smaller sample estimates compared with existing imaging-derived enrichers as shown in Table 4 . Table 1 supports the general consensus that imaging data capture disease progression [10, 26] . This can be seen from the very strong correlations of baseline rDAm with longitudinal change in several cognitive scores (last four columns in Table 1 ). It should be noted that high correlations with hippocampal volume (across all time points) are expected because T1 MRI image at baseline is used in the construction of baseline rDAm. Although hippocampus voxels are used in the rDA model, its inclusion (as an outcome) in our experiments is primarily for completeness. That is, hippocampal volume has been used extensively in previous AD imaging studies [14, 16, 25, 26] , and including it ensures continuity with this literature. Interestingly, FH had a lower dependence on rDAm which might be because its influence is superseded by actual neurodegeneration once a subject reaches MCI stage (i.e., FH may play a much stronger role in the asymptomatic phase). Note that we did not correct for age (and other covariates such as brain volume) because the markers reported in Table 1 Recall that h is the hypothesized induced treatment effect where (12h) denotes the expected percentage of reduction in the outcome measure. Each plot corresponds to using one of the nine disease markers (MMSE, ADAS, RAVLT, MOCA, PsychMEM, PsychEF, hippocampal volume, CDR-SB, and DxConv; refer to Section 3.1 for details about these markers) as an outcome measure. The xaxis represents the baseline rDAm enrichment cutoff (t). For each t, y-axis shows the effect size detectable at 80% power and significance level of 0.05 using 500 samples per arm. As with the results in Table 3 , each plot also shows improvements when using FH and/or APOE information in tandem with baseline rDAm enrichment. Blue, green, black, and red correspond to rDAm, rDAm 1 APOE, rDAm 1 FH, and rDAm 1 APOE 1 FH enrichment, respectively. Abbreviations: rDAm, randomized denoising autoencoder marker; MMSE, mini mental state examination; ADAS, Alzheimer's disease assessment scale (cognition 13 scale); MOCA, Montreal cognitive assessment; RAVLT, Rey auditory verbal learning test; PsyMEM, neuropsych summary score for memory; PsyEF, neuropsych summary score for executive function; HippoVol, hippocampal volume; CDR-SB, clinical dementia rating sum of boxes; DxConv, conversion from MCI to AD; FH, family history.\ndirectly with no covariate correction in our later evaluations on sample enrichment (Tables 2-4 ). This is based on the assumption that an actual clinical trial design with randomized treatment assignment would not need to correct for the individual's age to evaluate eligibility, and rDAm is agnostic to all such variables.\nObserve that most classification-based measures which are used as disease markers are generally unbounded [13] . These include the prediction score from a SVM-based classification model on a test subject, or summary measures such as S-score, t-score, F-score, and so forth. Unlike these measures, rDAm is bounded to 0 and 1, using which we can visualize its predictive power without any post hoc normalization (as shown in Fig. 1 ). Except for RAVLT, all other markers used as outcomes (in Tables 2 and 3) had steeper changes over time as baseline rDAm decreased, and in none of the cases was there a clear elbow separating weak and strong decliners. This shows that the disease progression is gradual from healthy to AD, and any classifications (such as early and late MCI) are mostly artificial. It is interesting to see that rDAm has high predictive power for DxConv (Table 1 and Fig. 1 ), implying that subjects with smaller baseline rDAm (closer to 0) have very high likelihood of converting from MCI to AD, providing additional evidence that baseline rDAm is a good predictive disease marker.\nAlthough there is no phase change (because rDAm is lower bounded to 0), we can always select a fixed fraction of subjects that are closest to 0 on the rDAm scale, and claim that they are the strong decliners we should include in a trial. The exact value of such fraction would depend on the logistics and size of the intended trial. This is the reason for the bottom fraction-based enrichment using baseline rDAm as shown in Tables 2-4 . Furthermore, note that the high predictive power of baseline rDAm solves an important problem with existing approaches to designing inclusion criteria which use longitudinal data (e.g., tensor-based morphometry) [8, 13] . Deploying such methods in practice implies that the trial screening time should be at least a year or longer, which is not practical. Although longitudinal signals are much stronger than cross-sectional ones, the results in Table 1 and Fig. 1 show that the rDAm marker at trial start-point can still be used with no loss of information, saving trial resources and reducing the cost of trial setup.\nThe first observation from sample estimates in Tables 2  and 3 is that MMSE, CDR-SB, and DxConv outperform all other alternate outcomes considered here, even in the no-enrichment regime. This is counter intuitive because of the simplicity of MMSE compared with other composite scores such as PsyMEM and PsyEF (neuropsych memory and executive function composites). It is possible that the composite nature of these measures increases the outcome variance, and thereby increases the sample estimates. Because our population is entirely MCIs, it is expected that the distribution of rDAms is fairly uniform from 0 to 1, which is not the case as shown from rDAm enrichment cutoffs at each percentiles (the top row of last four columns in Table 2 ). More precisely, the bottom 50% corresponds to a cutoff of 0.65 and 33% corresponds to 0.52, which indicates that more than two-thirds of MCIs in the ADNI2 cohort are healthier (i.e., weak decliners) and also that enrichment is important. This idea has also been identified by others using cognitive characteristics [27] . Ideally, we expect to observe a particular rDAm cutoff (an elbow cutoff) at which there might be the highest decrease in estimates for all outcomes in Tables 2 and 3 . The elbow cutoff should be a natural threshold point that separates strong and weak decliners on baseline rDAm scale. However, the trends in sample estimates in Table 2 do not seem to suggest such a threshold, which is not surprising from Fig. 1 and the corresponding discussion mentioned previously. Specifically, ADAS and RAVLT seem to have an elbow between 25% and 33%, whereas for MMSE, CDR-SB, and DxConv, the elbow is Table 4 Baseline rDAm versus other imaging-derived sample enrichers beyond 50%. Because we have 267 MCIs to begin with, a bottom 20% enrichment (third column, Table 2 ) corresponds to a population size of 52, implying that the estimates might be noisy.\nCovariate information (or rather, a preliminary selection based on a factor such as FH) is almost always helpful in estimating group effects, which is observed from Table 3 where using FH and/or APOE details as \"filters\" before rDAm enrichment reduced the estimates further. It has been observed that subjects with positive FH (either maternal or paternal) and/or APOE \u03b54 positive may have stronger characteristics of dementia [28] . This implies that instead of starting off with all MCIs, it is reasonable to include only those MCIs with positive FH and/or positive APOE \u03b54 and then perform the baseline rDAm enrichment on this smaller cohort. Recall that APOE had a higher dependence on baseline rDAm compared with FH (Table 1) , resulting in a higher reduction when using rDAm 1 APOE or rDAm 1 APOE 1 FH (last two columns) than using rDAm 1 FH (sixth column) for most all the cases except MMSE (row 1 in Table 3 ). Note that Table 3 corresponds to bottom 20% rDAm enrichment, of which about half were FH and/or APOE positive. The overall strong performance of DxConv resulting in small sample estimates may be because it summarizes the conversion of MCI to AD using longitudinal information, where as rDAm tries to predict this conversion using baseline information alone. Overall, Tables 2 and 3 support the efficacy of rDAm enrichment; however, an interesting way to evaluate the strength of rDAm is by fixing the number of trial-enrolled subjects and computing the detectable treatment size (h). If in fact rDAm successfully selects strong decliners, then the trial should be able to detect smaller expected decrease in disease (i.e., smaller 12h or larger h, refer to the sample size equation in Section 2.1 mentioned previously). Fig. 2 shows exactly this behavior, where h (y-axis) increases drastically as rDAm cutoffs (x-axis) are decreased (especially for MMSE, CDR-SB, and DxConv). From the practical perspective of a practitioner, this gives a tool for evaluating the minimum treatment effect that can be deemed significant, from a fixed cutoff and sample size.\nWe discussed in Section 1 that although effective imaging-derived disease markers exist (either based on machine learning models or directly computed from imaging ROIs), they may not lead to the best possible clinical trials. This is supported by the results in Table 4 , where rDAm (which is designed to explicitly reduce the prediction variance) is compared with existing markers that have been used as trial inclusion criteria [2, 14, 16] . For example, ROI summaries from multiple imaging modalities have often been used as trial enrichers [1, 2] and rDAm significantly outperforms these baselines (first four rows in Table 4 ). Furthermore [14] , we used SVM models to design effective disease marker and used it as an inclusion criterion in trials. Correspondingly, we compared rDAm to MKLm (which is based on a multi-kernel SVM), and the results in Table 4 show that baseline rDAm as an enricher outperforms MKLm, and the improvements are higher for MOCA, RAVLT, and hippocampal volume as outcomes. Note that for the present paper, we actually did not adjust any of the parameters relative to the results reports earlier [10] . These were the defaults for the MKL code-base provided on the Web page (http://pages.cs.wisc.edu/whinrichs/MKL_ ADNI/). The necessity of incorporating multimodal information in designing any disease markers has been reported earlier [10, 11] . This is further supported by the improvement of rDAm estimates over unimodal measures including hippocampal volume, FDG ROI summaries, and florbetapir ROI summaries. These results also built upon the work of [1, 2] where such unimodal imaging summaries are used for enrichment. It is possible to demonstrate that the performance gains of rDAm over [1, 2] is not merely due to using three distinct modalities but also heavily influenced by the underlying machine learning architecture that exploits this information meaningfully. To see this, compare the enricher \"FAH\" in Table 4 that corresponds to combining the three unimodal measures, FDG, florbetapir, and hippocampal volume. Its sample estimates are still larger than those obtained from rDAm, implying that the reductions are not merely due to multimodal data or small population size but due to the efficacy of deep learning methods (i.e., rDAm's capacity of picking up strong decliners with high confidence with small variance) introduced here.\nOverall, these results suggest that rDAm enrichment reduces sample sizes significantly leading to practical and cost-effective AD clinical trials. The rDA model by itself is expressive that scales to very large dimensions, uses only a small number of instances, and can be easily incorporated to design robust multimodal imaging markers. It should be noted that, the framework can be improved further, particularly in terms of using a richer pooling strategy instead of ridge regression (refer to the Appendix) and using other covariate information (such as age and CSF levels) in the rDA construction itself. These technical issues are of independent interest and will be investigated in future work. All the implementations used in the article will be made available at http://pages.cs.wisc.edu/wvamsi/rda on article acceptance."}, {"section_title": "RESEARCH IN CONTEXT", "text": "1. Systematic review: An efficient trial inclusion criterion should be able to discriminate weak decliners from the strong ones robustly. Furthermore, the screened strong decliners should have less variability if the screening criterion is to result in smaller sample estimates. These two requirements imply that the sample enricher needs to learn complex concepts while reducing the prediction variance. The statistical framework presented here offers both these features and yields substantial improvements over alternative strategies.\n2. Interpretation: First, this work provides strategies for sample enrichment in Alzheimer's disease clinical trials. Second, the results show that randomized denoising autoencoder marker (rDAm) predicts strong decliners with high confidence. Third, the findings show that baseline rDAm inclusion criterion is the best available imaging-derived enricher, which leads to smaller trials."}]