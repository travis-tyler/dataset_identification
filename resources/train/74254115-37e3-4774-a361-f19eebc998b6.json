[{"section_title": "Abstract", "text": "In this paper, we propose a landmark-based feature extraction method for AD diagnosis using longitudinal structural MR images, which requires no nonlinear registration or tissue segmentation in the application stage and is robust to the inconsistency among longitudinal scans. Specifically, (1) the discriminative landmarks are first automatically discovered from the whole brain, which can be efficiently localized using a fast landmark detection method for the testing images; (2) Highlevel statistical spatial features and contextual longitudinal features are then extracted based on those detected landmarks. Using the spatial and longitudinal features, a linear support vector machine (SVM) is adopted for distinguishing AD subjects from healthy controls (HCs) and also mild cognitive impairment (MCI) subjects from HCs, respectively. Experimental results demonstrate the competitive classification accuracies, as well as a promising computational efficiency."}, {"section_title": "Introduction", "text": "Structural MRI has been proven to be an effective tool for Alzheimer's disease (AD) diagnosis [1] . Compared with cross-sectional study at a single time point, longitudinal study is more sensitive to early pathological changes by focusing on both the spatial structural abnormalities and the longitudinal variations of tissues.\nSo far, researches that focus on cross-sectional study have obtained several achievements on AD or mild cognitive impairment (MCI) diagnosis [2, 3] . For example, Liu et al. investigated the AD diagnosis using multi-template representation [4] [5] [6] . Hinrichs et al. proposed to use spatially augmented LPboosting for AD classification [7] . Zhu et al. focused on selecting informative features from redundant region-based features [8] [9] [10] . Gerardin et al. extracted features based on hippocampal shape for the purpose of classifying AD and MCI [11] . Gao et al. proposed to use hypergraph learning for MCI classification and indexing [12, 13] . Kloppe et al. proposed to use voxel-based gray matter features for AD classification [14] .\nOn the other hand, existing longitudinal studies largely focus on the degeneration of well-known representative biomarkers including hippocampal volume, ventricular volume, whole brain volume and cortical thickness. For example, Chincarini et al. proposed four image analysis strategies based on hippocampal volume by integrating longitudinal atrophy rate as a measurement for AD diagnosis [15] . Jack et al. investigated the changing rates of four structures (i.e., hippocampus, entorhinal cortex, whole brain and ventricle), and supported the idea of using changing rates as biomarkers for AD diagnosis [16] . Aguilar et al. analyzed the longitudinal atrophy changes in cortical thickness measures and subcortical volumes, and pointed out that the use of two time points data yielded better index result compared with using the cross-sectional data only [17] . Kim et al. adopted 93 ROI features for longitudinal analysis [18] . However, there are still several challenges in existing longitudinal analysis: (1) Limited measurements may be incapable of capturing the full pattern of morphological abnormalities from the whole brain; (2) Time-consuming nonlinear registration or tissue segmentation step is required, and the longitudinal study exacerbates the computational time since more scans are involved; (3) Longitudinal scans across subjects are usually inconsistent, since some time points might be missing during the data collection.\nIn this study, a landmark-based feature extraction framework is proposed for AD diagnosis using longitudinal structural MR images. Different from traditional longitudinal studies, our method (1) does not require the time-consuming nonlinear registration or tissue segmentation, (2) can cover the representative morphological abnormalities from the whole brain, and (3) is able to handle the inconsistency among longitudinal scans. Specifically, the discriminative landmarks which have significant morphological group differences are automatically discovered from the whole brain. By using a regression forest-based landmark detection method, these landmarks can be efficiently detected in the application stage. Based on these detected landmarks, high-level spatial features and contextual longitudinal features are further extracted respectively, as below. (a) A bag-of-words strategy is used to extract high-level spatial features, by calculating the frequency of low-level landmark-based morphological features from different scanning time points. In this way, the significant spatial abnormalities from all scanning time points are aggregated together, which are also invariant to the number of longitudinal scans. (b) To extract contextual longitudinal features, an interpolation step is used to generate a Jacobian map from longitudinal landmark displacements. Then, contextual features can be extracted around the landmarks from the Jacobian map. Finally, a linear support vector machine (SVM) is adopted to perform AD/MCI classification using these spatial and longitudinal features."}, {"section_title": "Materials and Image Processing", "text": ""}, {"section_title": "Dataset", "text": "The Alzheimer's Disease Neuroimaging Initiative (ADNI) 1 is a 5-year publicprivate partnership to test whether serial MRI, positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment and early Alzheimer's disease. One goal of ADNI is to develop improved methods that will lead to uniform standards for acquiring longitudinal, multi-site MRI and PET data on subjects with AD, MCI, and elderly healthy controls (HCs). Subjects used in this study are from the ADNI-1 database. In this paper, we selected the subjects with at least three scanning time points of structural MRI, thus resulting in 207 age-matched HCs, 154 AD, and 346 MCI subjects. The demographic information (i.e., gender, age, and education) of the studied subjects used in this study are summarized in Table 1 . The statistics of scans for the studied subjects is summarized in Table 2 ."}, {"section_title": "Image Processing", "text": "The image processing includes two major steps: linear alignment and landmark discovery.\nLinear Alignment: All images are linearly aligned to a common template, namely Colin27, which was created by averaging 27 registered scans of a single subject [19] . In order to achieve high efficiency, we adopt a landmark-based affine registration method. Specifically, five pre-defined landmarks (i.e., anterior commissure (AC) and posterior commissure (PC) landmarks, and the other three representative landmarks in mid-sagittal plane) are automatically detected by a pre-trained regression forest-based landmark detection model. A global similarity transformation matrix, which encodes 7 degree of freedom (DOF), can be estimated between the landmarks from the moving image to the template. Since each landmark has 3 coordinate values, 5 landmarks are enough to estimate the transformation matrix."}, {"section_title": "Landmark Discovery:", "text": "Our target is to identify the regions with group differences in local structures between patients and HCs. To this end, we intend to perform a voxel-wise group comparison between those two groups. However, the linearly aligned images are not voxel-wisely comparable. In order to build the correspondence among voxels from different images, all images are nonlinearly aligned to the Colin27 template after linear alignment. In general, the warped images are very similar to each other so that the subject-specific structural information in different images may not be significant. Therefore, we extract patch-based morphological features (i.e., 3D histogram of orientation (HOG) features [20] ) from the linearly aligned images to describe the local structures. By using the deformation field from nonlinear registration, we can build the correspondence between voxels in the template and all linearly aligned images. Therefore, for each voxel in the template, we can extract two groups of HOG features from its corresponding voxels in all training patients and HCs, respectively. We then perform the multivariate test, namely Hotelling's T 2 statistic [21] , on the two groups, through which a p-value can be calculated for each voxel in the template. Accordingly, a p-value map can be obtained according to the template. Finally, the local minima from the p-value map are identified as locations of discriminative landmarks in the template space. More details on landmark discovery can be found in our previous work [22] .\nThen, these landmarks, which are located in the template space, can be directly projected to all training images using their deformation fields. For testing images, in order to avoid the time-consuming nonlinear registration, we train a regression forest-based landmark detector [23, 24] to detect these landmarks. In this way, both training images and testing images would have same landmarks, and particularly, the landmarks for the testing images can be obtained efficiently, thanks to the fast landmark detector."}, {"section_title": "Feature Extraction", "text": "Based on the identified landmarks, we propose a landmark-based framework for extracting features from longitudinal MR images. Specifically, two types of landmark-based features, i.e., spatial features and longitudinal features, are extracted to describe the spatial structural abnormalities and longitudinal landmark variations, respectively. In the following, we explain the details about the extraction process for each feature type."}, {"section_title": "Landmark-Based Spatial Feature Extraction", "text": "Intuitively, in cross-sectional study, the morphological features (e.g., 3D HOG) for all landmarks can be extracted and concatenated as strong features for classification. However, there are two challenges in longitudinal study: (1) The numbers of scanning time points across subjects are inconsistent due to missing time points, and thus, it is difficult to extract a unified feature representation from different number of scans. (2) It is difficult to identify the corresponding baseline images across subjects, which means a baseline scanning time point of one subject may not correspond to that of another subject. How to extract a unified spatial feature representation from those inconsistent longitudinal scans is a very challenging task.\nTo address these two problems, we propose to use a bag-of-words strategy to extract statistical high-level spatial features. The bag-of-words strategy has demonstrated impressive performance on text, language, and image classification [25] [26] [27] [28] . Specifically, Fig. 1(a) shows the procedure of our spatial feature extraction method, where each landmark is treated independently. As shown in Fig. 1(a) I, we first extract the 3D HOG feature vector for each landmark, as well as 3D HOG feature vectors for the supplementary voxels (i.e., the neighboring voxels within a small spherical patch of the landmark). After extracting features from all training images and aggregating them together, we have a set of 3D HOG feature vectors. Then, we perform K-means clustering [29] on this set of feature vectors, and build a dictionary (i.e., D) with its words (i.e., w 1 , w 2 , . . . , w M ) being the clustering centers. Then, for each individual subject, we can first extract the 3D HOG feature vectors (denoted by a feature set F) for each landmark and its supplementary voxels in all longitudinal scans. The statistical histogram representation is then calculated by counting the occurrence frequencies of the clustering centers in these HOG features (i.e., F), as shown in Fig. 1(a) II. Mathematically, the histogram representation (i.e., R) for one landmark can be defined as\nwhere \u03b4(\u00b7) is the Kronecker delta function defined as\nIn order to achieve the invariance to the number of longitudinal scans, the histogram representation is 1 normalized. Finally, we extract the statistical features for all landmarks, regardless of differences in the number of scanning time points, as shown in Fig. 1(a) III. Here, the reasons for using supplementary voxels in neighborhood of landmarks are two-fold: (1) The HOG feature set can be expanded to get statistical features by using the bag-of-word strategy; (2) It is also helpful to relieve potential errors in localizing landmark positions."}, {"section_title": "Landmark-Based Longitudinal Feature Extraction", "text": "In order to solve the problem of inconsistent longitudinal scans, we generate the normalized 3D longitudinal displacement at the beginning of feature extraction. Specifically, we first define the longitudinal displacement between two scans for one specific landmark as follows:\nwhere L ti is the landmark location of the i -th scan from all longitudinal scans and t i is the corresponding relative scanning time point with respect to the first scan. Then, the normalized 3D displacementd (mean displacement per year) is calculated from all possible combinations between two scans in different scanning time points, as shown in Fig. 1(b) I. Mathematically,d is defined as follows:\nwhere n is the number of existing scans. As shown in Fig. 1(b) II, a normalized deformation field can be built by applying thin plate splines (TPS) interpolation to the normalized 3D longitudinal displacementd of all landmarks. Based on this normalized deformation field, a Jacobian map is further calculated to describe the longitudinal volume variations. Finally, as shown in Fig. 1(b) III, we can extract morphological features (i.e., 3D HOG) for the landmarks in the Jacobian map. Therefore, longitudinal volume variations on these discriminative landmarks can be captured by these morphological features. It is worth noting that, instead of treating each landmark individually, the neighboring landmarks are jointed together with interpolation during the generation of the normalized deformation field. In this way, although the morphological features from Jacobian map are extracted for each landmark individually, the contextual information about the neighboring landmarks is automatically embedded into the calculated features."}, {"section_title": "Experiments", "text": ""}, {"section_title": "Parameter Setup", "text": "Using a 10-fold cross validation strategy, we conducted experiments for two classification tasks, i.e., AD vs. HC and MCI vs. HC. The parameters in our approach were defined as follows: For 3D HOG feature extraction, we used 9 orientations, 2 \u00d7 2 \u00d7 2 cells, and a size of 8 \u00d7 8 \u00d7 8 for each cell. Therefore, the dimensionality of 3D HOG features was 72. In the bag-of-words strategy, the number of clustering centers was set to 50, and thus, the dimensionality of spatial features for each landmark was 50. The radius of spherical patch for sampling supplementary voxels was 5. For SVM classification, we fixed the margin parameter C = 1. Due to the data-driven property of our method, the number of landmarks was determined by the training images. In our method, we searched the local minima within a 7 \u00d7 7 \u00d7 7 cubic patch, and obtained roughly 1500 identified landmarks for each fold in the cross validation."}, {"section_title": "Experimental Results", "text": "Five classification performance measures were used, namely (1) MR image (first scan). The baseline longitudinal features refer to the features obtained by directly using normalized displacements (i.e.,d) of the landmarks. Table 3 reports the classification results, and Fig. 2 shows their corresponding ROC curves. These results demonstrate that, in both classification tasks, the proposed spatial features consistently outperform the baseline spatial features, and our longitudinal features generally achieve better performance than the baseline longitudinal features. Moreover, the combination of the proposed spatial and longitudinal features can further improve the classification performance.\nIn a related work, Chincarini et al. [15] used hippocampal volume and hippocampal volume atrophy rate as measurements for longitudinal AD classification. The reported AUC for AD vs. HC on ADNI-1 is 93.00%, which is slightly lower than ours (94.01%). Moreover, they used multi-atlas based method to obtain the hippocampal segmentations which is time-consuming. As we know, it usually takes hours to get accurate hippocampal segmentation. For our landmark-based method (e.g., using four longitudinal scans), it takes less than 3 min to complete all feature extraction steps, including linear registration, landmark detection, and spatial and longitudinal feature extraction."}, {"section_title": "Discussions and Conclusions", "text": "Landmark-based Framework: The major advantages of using landmarkbased framework are two folds: (1) The identified discriminative landmarks can cover all possible abnormalities from the whole brain without using several predefined biomarkers; (2) The use of landmarks makes it possible to integrate a fast landmark detection model to the diagnosis framework such that both timeconsuming nonlinear registration and tissue segmentation are avoided. It is worth noting that, although each landmark is a weak descriptor that only covers the information from a small local patch, thousands of landmarks can well describe the brain structure and thus leading to a stable classification performance."}, {"section_title": "Spatial Features:", "text": "In the bag-of-words representation, words in the dictionary can be regarded as representative local spatial structures. Thus, the calculation of their occurrence frequency can be regarded as labeling the spatial structure of each landmark with its similarities to all words. This high-level statistic ignores both the numbers and the orders of scanning time points and only focuses on the spatial abnormalities, which is suitable for extracting unified spatial features from inconsistent longitudinal scans. As can be seen in Table 3 and Fig. 2 , the method of using bag-of-words based spatial features achieves better classification performance, compared with that using baseline spatial features."}, {"section_title": "Longitudinal Features:", "text": "Intuitively, one type of longitudinal information is the trajectory of landmarks along time. However, the coherence among neighboring landmarks is ignored if we just simply use the mean longitudinal displacements (d) as features. In our method, we generate a normalized deformation field by interpolation, through which the contextual information can be employed by jointly using the neighboring landmarks. Moreover, it is also well known that the Jacobian determinant can indicate the volume variation. Therefore, the morphological features from the Jacobian map comprehensively capture the longitudinal volume variation around landmarks. The experimental results show that using the longitudinal features from Jacobian map achieves 2% to 4% improvement in terms of accuracy as compared with the baseline longitudinal features."}, {"section_title": "Limitations and Future Work:", "text": "Since each landmark has 72 spatial features and 50 longitudinal features, the concatenation of the features from all landmarks would be high dimensional, with respect to the number of training subjects. Also, there may be some redundant or noisy features that can adversely affect the classification model learning. Therefore, selecting most discriminative landmarks and features is important and will provide a reasonable solution for further performance improvement, which is our future work."}]