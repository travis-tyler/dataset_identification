[{"section_title": "", "text": "Consortia around the world -such as the Cognition and Neocortical Volume After Stroke Consortium (CANVAS; Brodtmann et al., 2014) and the Stroke and Cognition Consortium (STROKOG; Sachdev et al., 2017) -have made significant efforts to study the role of hippocampal volumes in the context of overall stroke recovery on a large scale. The Enhancing Neuroimaging through Meta-Analysis (ENIGMA) Stroke Recovery working group (Liew et al., 2020) is also interested in studying the post-stroke hippocampus in the context of sensorimotor recovery. Currently, manual segmentations are arguably the gold standard for analyzing hippocampal volume in MRI studies (Frisoni et al., 2015) , but this approach is extremely time consuming and not feasible for large datasets such as these. Therefore, efforts to develop and test automated hippocampal segmentation methods have been undertaken to provide a more efficient way to study hippocampal volume on a large scale.\nCurrent automated brain structure segmentation algorithms predominantly rely on atlas-based approaches, involving machine learning and sophisticated image registration to a single probabilistic atlas of pre-labeled regions. FreeSurfer (Fischl et al., 2002; Fischl, 2012) , a robust method to segment both cortical and subcortical structures, is an atlasbased approach and commonly used to study hippocampal volume in cognitively healthy populations (Ritchie et al., 2018; Nobis et al., 2019) as well as in people with neurodevelopmental, psychiatric, and neurodegenerative conditions (Schmaal et al., 2016; Hibar et al., 2017; van Erp et al., 2017; M\u00fcller-Ehrenberg et al., 2018; Zhao et al., 2019) . A recent study by Khlif et al., (2019) compared automated hippocampal segmentation methods, such as the gross hippocampal segmentation available in FreeSurfer version 5.3 and taking the sum of all the hippocampal subfields segmentation available in FreeSurfer version 6.0 ('sum of subfields'), in stroke populations. Khlif et al., (2019) reported that the FreeSurfer version 6.0 'sum of subfields' segmentation was the automated method that agreed most with manual hippocampal segmentations in healthy and ischemic stroke populations with lesions outside the hippocampus.\nFreeSurfer was specifically designed to account for structural brain abnormalities common to AD and aging (Fischl, 2012) , which share some overlapping features with stroke populations (Mok et al., 2017; Yousufuddin & Young, 2019) ; perhaps as a result, FreeSurfer has performed relatively well in stroke studies. However, large brain lesions are distinct to stroke patients and can introduce large alterations to the expected spatial distribution of brain structures, presenting a significant challenge to FreeSurfer. FreeSurfer, and most other probabilistic atlas-based automated segmentation methods, were not explicitly designed to accommodate significant brain injury pathology (Irimia et al., 2012) and are more likely to fail in the presence of large lesions (Yang et al., 2016) . New methods that do not use single atlas-based automated segmentation methods may better accommodate stroke pathology and help improve segmentation accuracies in studies of the hippocampus in stroke. Related to this, recently, Hippodeep, a new convolutional neural network-based (CNN) algorithm, emerged as a fast and robust hippocampal segmentation method (Thyreau et al., 2018) . Hippodeep relies on hippocampal 'appearance' (features of the hippocampus that it has learned from the training data) instead of a single atlas-based approach. Hippodeep has better spatial agreement with manual segmentations than FreeSurfer version 6.0 'sum of subfields' segmentation in healthy aging populations but has not yet been evaluated in a stroke population (Nogovitsyn et al., 2019) .\nOur study sought to expand on previous findings (Khlif et al. 2019; Nogovitsyn et al., 2019) and evaluate how Hippodeep compares to previously tested methods for hippocampal segmentation in a stroke population. Using the Anatomical Tracings of Lesions After Stroke dataset (ATLAS; Liew et al., 2018) , we compared Hippodeep, FreeSurfer version 6.0 gross hippocampal segmentation, and FreeSurfer version 6.0 'sum of subfields' segmentation in terms of 1) output failure rates and 2) accuracy when compared to expert manual segmentations. We hypothesized that Hippodeep's CNNbased method would perform better on lesioned brain anatomy, resulting in fewer segmentation failures and more accurate hippocampal segmentations than either FreeSurfer method."}, {"section_title": "Methods", "text": ""}, {"section_title": "Data Acquisition", "text": "For our analyses, we used the ATLAS dataset (N=229), an open source dataset of anonymized T1-weighted structural brain MRI scans of stroke patients and corresponding manually traced lesion masks (Liew et al., 2018) . All 229 scans were completed on 3-Tesla MRI scanners at a 1 mm isotropic resolution, intensity normalized and registered to the MNI-152 template space. T1-weighted MRIs, lesion masks, and metadata are publicly available for download (Liew et al., 2018) . We analyzed the normalized data from these 229 participants as the input data to test the three automated segmentation methods."}, {"section_title": "Hippocampal Segmentation Methods:", "text": "FreeSurfer version 6.0\nFreeSurfer is an atlas-based software that employs a Bayesian statistical approach to segment and label brain regions (Fischl, 2012) . It involves a series of data preprocessing steps, such as intensity normalization, mapping of the input brain to a probabilistic brain atlas, estimation of statistical distributions for the intensities of different tissue classes, and labeling of cortical and subcortical structures based on known information on the locations and adjacencies of specific brain substructures (Fischl et al., 2002) .\nFreeSurfer version 6.0 can output the gross hippocampal volume as well as segmentations of 13 hippocampal subregions using a refined probabilistic atlas (Fischl, 2012) . This latter atlas was built from a combination of ultra-high resolution ex vivo and in vivo MRI scans, to identify borders between subregions of the hippocampus (Iglesias et al., 2015) . The ex vivo scans included autopsy samples of participants with AD and controls scanned with a 7T scanner at 0.13 mm isotropic resolution that were then manually segmented by expert neuroanatomists. The in vivo data consisted of manual segmentations from 1mm isometric resolution T1-weighted MRI data acquired using a 1.5 T scanner from controls and participants with mild dementia. In vivo and ex vivo segmentations were combined to create one single computational atlas of hippocampal subfields. In this study, we combined the volumes of the individually labeled hippocampal subfields output by FreeSurfer version 6.0 to create a segmentation of the entire hippocampus, which we refer to as FS-Subfields-Sum, or 'sum of subfields' throughout our study. As mentioned previously, Khlif et al. (2019) found that the 'sum of subfields' segmentation from FreeSurfer version 6.0 to be the best performing segmentation method for the stroke data they evaluated.\nFreeSurfer also outputs a separate gross hippocampal segmentation using a different atlas, the Desikan-Killiany atlas (Desikan et al., 2006) . The Desikan-Killiany atlas was built using 40 T1-weighted 1x1x1.5 mm spatial resolution MRIs acquired on a 1.5T scanner. These 40 participants were of ranging age and cognitive status with the intent to include a range of anatomical variance common to aging and dementia in the atlas. This hippocampal volume from the Desikan-Killiany atlas can be calculated using the hippocampus labels of the aseg FreeSurfer output file. Notably, the Desikan-Killiany atlas based hippocampal segmentation from FreeSurfer version 6.0 was not compared to the subfield method in the Khlif et al. (2019) study, which only examined the FreeSurfer version 5.3 Desikan-Killiany atlas.\nFreeSurfer outputs segmentations to a FreeSurfer specific image space. The FreeSurfer command, mri_label2vol, was used to transform the segmentation back to the original MNI space used in the input for both FreeSurfer versions segmentations. Segmentations from the aseg output are referred to as FS-Aseg throughout our study."}, {"section_title": "Hippodeep", "text": "Hippodeep is a recently released automated hippocampal segmentation algorithm that has not yet been tested in stroke populations. Hippodeep does not warp individual images to an atlas; instead, it relies on a hippocampal appearance model learned from existing FreeSurfer v5.3 labeled online datasets as well as synthetic data (Thyreau et al., 2018) . Two types of synthetic data are included in training the Hippodeep CNN. The first synthetic data is a manual segmentation of a synthetic high-resolution image of the hippocampus generated from an average of 35 variations of MRI scans of a single healthy participant. The purpose of segmenting the hippocampus on a high-resolution image (0.6 mm isotropic resolution) is to provide more detailed boundary information to the CNN that might not be as clear on a lower resolution image. The second type of synthetic data used to train the Hippodeep CNN is artificially geometrically distorted versions of the FreeSurfer v5.3 training data. Some of the distortion goes beyond the range of clinically plausible values but remains realistic enough to be easily delineated by a human rater. The purpose of this distorted data is to provide relevant training guidance to the CNN. By training the CNN on unconventional anatomy, Hippodeep may be more robust to severe stroke pathology. Details on the specifics of how the synthetic data were generated may be found in Thyreau et al. (2018) .\nHippodeep outputs a probabilistic segmentation map in native space, which can then be optionally thresholded. The Hippodeep outputs were binarized, in order to use the entire probabilistic segmentation and maximize coverage of the hippocampus."}, {"section_title": "Manual Segmentations", "text": "We tested the accuracy of the automated methods by randomly selecting 30 participants for whom all three automated segmentation algorithms (FS-Aseg, FS-Subfields-Sum, and Hippodeep) were able to successfully output hippocampal segmentations. Only participants with unilateral lesions were considered. The ATLAS data was organized by lesion size and divided into thirds; small (range = 0.18 -4.82 cubic centimeters (cc)), medium (range = 4.98 -22.7cc), and large (range = 23.6 -291.0cc) lesions. From each lesion size group, five participants with right hemisphere lesions and five participants with left hemisphere lesions were randomly selected. In this way, we examined the influence of lesion size across a broad range of lesion sizes, and with lesions equally distributed across hemispheres. In this data sample, all lesions occurred outside the medial temporal lobe.\nHippocampi for the subset of these 30 participants were manually traced by an expert rater (AZP), strictly adhering to the EADC-ADNI harmonized protocol for manual hippocampal segmentation (Boccardi et al., 2015; Frisoni et al., 2015) . Coronal slices were used to trace the hippocampi using ITK-Snap (Yushkevich et al., 2006) . The sagittal view was used to confirm hippocampal boundaries and edit the segmentations. Hippocampi were segmented blindly based on participant ID alone, starting with the left hippocampus, followed by the right hippocampus. Bilateral hippocampi were never overlaid on the T1-weighted image at the same time to avoid using the segmentation from one hemisphere to bias the other. The manual segmentations were checked for quality by another expert in hippocampal neuroanatomy (MAT). All manual segmentations are available for download here: https://github.com/npnl/Hippocampal_Segmentation Analyses:"}, {"section_title": "Percent of Failures", "text": "We assessed how well each automated method performed on segmenting hippocampi in the full dataset (N=229) by first quantifying the percentage of hippocampal output failures (where no segmentation was output by the method at all). This was calculated as the number of output failures divided by the total sample size (N=229)."}, {"section_title": "Segmentation Accuracy", "text": "To estimate segmentation accuracy, we measured the spatial overlap between the 30 manually traced hippocampi and each automated segmentation method (FS-Aseg, FS-Subfields-Sum, Hippodeep) using the Dice Coefficient (DC). DC is commonly used to validate segmentation algorithms in neuroimaging (Dice et al., 1945; Zou et al., 2004) and is defined as:\n!\" = 2 * |'(| |'| + |(| Here X represents the set of voxels in the manual segmentation and Y represents the set of voxels in the automated segmentation. DC can range from 0 (no spatial overlap) to 1 (complete overlap). For this study, we calculated DC using the flag DiceandMinDistSum of the ImageMath package from the Advanced Normalization Tools (ANTs) software (Avants et al., 2011) .\nA 2x3x3 Analysis of Variance (ANOVA) was performed to model dependencies of DC on the hemisphere with factors of lesion hemisphere (contralesional and ipsilesional), lesion size (small, medium, and large), and automated segmentation method (Hippodeep, FS-Subfields-Sum, FS-Aseg). A post-hoc paired t-test was used to compare DC between automated segmentation methods."}, {"section_title": "Statistical Analysis", "text": "All statistical analyses were conducted in R-Studio version 1.1.463. To promote open science and reproducibility, the code used for this study is available here: https://github.com/npnl/Hippocampal_Segmentation"}, {"section_title": "Comparison of Volumes", "text": "We evaluated the agreement in hippocampal volume across segmentation methods in the dataset of 30 participants, by calculating the Pearson's correlation coefficient (R; Pearson, 1895) and the intra-class correlation coefficient (ICC; Shrout and Fleiss, 1979) . We predetermined the number of segmentation methods and we assumed no generalization to a larger population. Therefore, we assumed fixed judges for the ICC statistical analyses."}, {"section_title": "Results", "text": ""}, {"section_title": "Percentage of Failures", "text": "First, we examined the percentage of output failures from the automated methods. This gives a sense of how robust each method was for simply completing segmentations on the stroke data. FS-Aseg failed to output a segmentation for 17.0% (N=39) of the 229 ATLAS participants. The FS-Subfields-Sum method failed on 17.5% (i.e., the same 39 whose data failed to run through FreeSurfer, plus one additional participant). Hippodeep outputted segmentations for all 229 ATLAS participants (0% failure rate). The average lesion size for participants that failed to output was 44.6 \u00b1 69.0cc for FS-Aseg and 43.6 \u00b1 69.0cc for FS-Subfields-Sum (both within the 'large' lesion size category for our lesion distribution).\nFor the 40 participants whose data failed to run through FS-Aseg and/or FS-Subfields-Sum, we examined the average hippocampal volumes from the Hippodeep outputs to determine if the segmentations were usable. A quality check of the segmentation was done by identifying statistical outliers that may have over or underestimated the hippocampus. There were three participants with average ipsilesional hippocampal volumes smaller than three times the interquartile range (hippocampal volume < 3 * 0.913 = 2.74 cc) that we considered outliers. These participants each had large lesions that impacted the temporal lobe (but not the hippocampus). Hippodeep appeared to underestimate the ipsilesional hippocampus in these participants."}, {"section_title": "Accuracy (DC Analysis)", "text": "We calculated the Dice Coefficient for each automated segmentation compared to the manual segmentation to assess the accuracy of each method in the dataset of 30 participants. This provides a quantitative assessment of the spatial overlap between the automated and manual segmentations. We performed an ANOVA to evaluate how DC differed across automated segmentation method, lesioned hemisphere, and lesion size. The ANOVA revealed that segmentation method was the only significant factor for differences in DC (F = 402.3; p-value < 2 x 10 -16 ). Hippodeep had the highest average DC (ipsilesional = 0.84 \u00b1 0.03; contralesional = 0.84 \u00b1 0.02), followed by FS-Subfields-Sum (ipsilesional = 0.73 \u00b1 0.03; contralesional = 0.72 \u00b1 0.03), followed by FS-Aseg (ipsilesional = 0.69 \u00b1 0.04; contralesional = 0.68 \u00b1 0.03). We performed a paired t-test to see if DC significantly differed between the automated segmentation methods. Results from the t-test showed that the DC for Hippodeep was significantly higher than the DC for FS-Subfields-Sum (ipsilesional p-value = 1.03 x 10 -17 , t-value= 18.7; contralesional pvalue = 4.68 x 10 -21 , t-value = 24.8) and FS-Aseg (ipsilesional p-value = 3.34 x 10 -21 , tvalue = 25.1; contralesional p-value = 1.05 x 10 -23 , t-value = 30.8) (Figure 1; Table 1 ). Figure 1. Average Dice Coefficient (DC) for Hippodeep vs. Manual segmentations was significantly higher than FS-Subfields-Sum vs. Manual (ipsilesional p-value = 1.03 x 10 -17 , t-value= 18.7; contralesional p-value = 4.68 x 10 -21 , t-value = 24.8) and FS-Aseg vs. Manual (ipsilesional p-value = 3.34 x 10 -21 , t-value = 25.1; contralesional p-value = 1.05 x 10 -23 , t-value = 30.8). DC did not differ significantly across lesion size. "}, {"section_title": "Volume Analysis", "text": "In the dataset of 30 participants with manually segmented hippocampi, we also compared hippocampal volume between automated and manual segmentations. All three segmentation methods overestimated both ipsilesional and contralesional hippocampal volume, compared to the manual gold standard (Figure 2, Figure 3) . Hippodeep and FS-Subfields-Sum segmentations were not significantly different in volume (Figure 3) . Mean hippocampal volume is plotted for manual and automated segmentation methods in the 30 participants with manually segmented hippocampi. All three automated segmentation methods on average overestimated the manually defined segmentation volume. This trend is consistently found for scans with small, medium, and large lesions.\nAs expected, volumes from all three segmentation methods were strongly correlated with volumes from the manual segmentations ( Table 2) . Volumes from FS-Subfields-Sum had the strongest correlation with manual segmentation volumes (ipsilesional ICC = 0.65; contralesional ICC = 0.83). Hippodeep measures were also strongly correlated with manual segmentation volumes (ipsilesional ICC = 0.64; contralesional ICC = 0.75). FS-Aseg was the least correlated with the manual segmentation volumes (ipsilesional ICC = 0.50; contralesional ICC = 0.71). Volumes from FS-Subfields-Sum and Hippodeep were strongly correlated with each other (ipsilesional ICC = 0.91; contralesional ICC = 0.90). "}, {"section_title": "Discussion", "text": "In this study, we compared the output failure rates and accuracy of three automated segmentation algorithms (Hippodeep, FS-Subfields-Sum, FS-Aseg) used to estimate hippocampal volume in individuals with stroke. Our study found that Hippodeep was able to output hippocampal segmentations for all of the data, while FS-Aseg and FS-Subfields-Sum failed on approximately 17% of the data. In addition, Hippodeep performed the best in terms of accuracy, as measured by the Dice Coefficient, while FS-Subfields-Sum performed slightly higher in terms of intraclass correlations (ICC). This suggests that, while both Hippodeep and FS-Subfields-Sum produce good correspondence with manual hippocampal segmentations, Hippodeep is more accurate in terms of the actual voxels identified as the hippocampus while FS-Subfields-Sum produces a closer match on the overall volume of the hippocampus.\nHippodeep successfully output segmentations for all 229 ATLAS participants in this analysis. FS-Aseg and FS-Subfields-Sum both failed to output segmentations for 17% of the data. Prior studies have reported inability to run FreeSurfer on certain participants with large lesions (Bigler et al., 2013; Khlif et al., 2019) as well as healthy participants (Nogovitsyn et al., 2019) . Hippodeep generated volume estimates for most of the participants whose data could not be run through FreeSurfer in our study. Therefore, Hippodeep can potentially help to maximize the number of participants included in analyses whose data might not run successful through FreeSurfer, potentially boosting statistical power, and reducing the bias that can come from excluding participants. Obtaining robust statistical power is of keen interest to the stroke recovery field, as a recent review by Kim & Winstein (2017) found that less than 30% of stroke recovery studies met the appropriate sample size criteria to achieve sufficient statistical power for predicting recovery. Our understanding of the role of hippocampal volume in stroke recovery will benefit from studies with larger, more representative samples.\nIn addition, hippocampal segmentation using Hippodeep resulted in the highest similarity index (DC) to manual tracing, indicating a high level of segmentation accuracy. Hippodeep performed significantly better in terms of DC than FS-Subfields-Sum and FS-Aseg. FS-Subfields-Sum also yielded a high similarity index to manual segmentations, consistent with prior results (Khlif et al. 2018) . Mean DC values for both Hippodeep and FS-Subfields-Sum were above a DC of 0.7, which is a recommended threshold for DC to indicate good segmentation overlap (Zou et al., 2004) .\nDC was influenced by segmentation method, but not by lesion size or lesion hemisphere. There was also a wide range in lesion sizes for scans that failed to output FS-Aseg and FS-Subfields-Sum segmentations. Although lesion size may not have a significant effect on DC in this sample of 30 participants, it may influence the segmentation accuracy and merits further investigation.\nFS-Subfields-Sum and Hippodeep were both very competitive in terms of their correlations with ipsilesional and contralesional volume estimates. FS-Subfields-Sum segmentations were more highly correlated with manual segmentations (ICC) than Hippodeep, although both were high and considered very reliable (Koo & Li, 2016) . Ipsilesional FS-Aseg volume estimates had the lowest ICC, but this correlation was still high enough to be considered moderately reliable (Koo & Li, 2016) . For all three automated methods, contralesional ICC was higher than ipsilesional ICC. Notably, each segmentation method has slightly different criteria for determining hippocampal boundaries (Desikan et al., 2006; Frisoni et al., 2015; Thyreau et al., 2018) . Therefore, some mild variability in correlation and accuracy versus manual segmentations is expected. Certain hippocampal boundaries (specifically along the head and the tail) are only visible in high-resolution MRIs and consensus on rules for delineating the boundaries of these regions on an MRI has not yet been reached (Olsen et al., 2019) .\nHippodeep and FS-Subfields-Sum may have performed better than FS-Aseg in terms of accuracy because information from a high-resolution hippocampus is included in both the Hippodeep and FS-Subfield-Sum algorithms. FS-Subfields-Sum is based on an atlas generated using manual segmentations on an ultra-high resolution atlas (0.13 mm isotropic resolution; Iglesias et al., 2015) . Hippodeep uses information from a manually traced hippocampus on a synthetic high-resolution image (0.6mm isotropic resolution; Thyreau et al., 2018) . In contrast, FS-Aseg uses the Desikan-Killiany atlas, which was built using only scans of 1x1x1.5mm resolution (Desikan et al., 2006) . The Desikan-Killiany atlas was designed to segment many structures across the brain, many of which are clearly delineated on low resolution scans. Including more detailed information on hippocampal boundaries that appear ambiguous on a low-resolution MRI may improve segmentation performance. Further exploration of methodological aspects of successful automated segmentation methods may be helpful to inform future development of methods in populations with irregular neuroanatomy.\nBeyond failure rates and accuracy, there are other technical aspects to consider when comparing Hippodeep, FS-Subfields-Sum, and FS-Aseg. Hippodeep requires less computational power than FreeSurfer and runs within minutes, whereas FreeSurfer can take over 24 hours on a typical CPU (Thyreau et al., 2018; Nogovitsyn et al., 2019) . However, Hippodeep only outputs estimates of the hippocampus and total intracranial volume. In addition to FS-Subfields-Sum and FS-Aseg, FreeSurfer also estimates other brain measures beyond hippocampal volume and intracranial volume, such as individual hippocampal subfield volumes (Iglesias et al., 2015) , and cortical and subcortical volumes, as well as thickness measures, and other vertex based measures and attributes that can be used for surface-based statistical analyses (Fischl, 2012) . Additionally, FreeSurfer has an extensive archive of user questions for troubleshooting, while Hippodeep is a recent method that is not as extensively documented. Therefore, selection of the appropriate hippocampal segmentation method should be evaluated within the context of the study requirements and constraints (Table 3) . "}, {"section_title": "Limitations", "text": "A key methodological limitation to consider when comparing these segmentation methods is that none of these approaches were designed specifically to accommodate severe stroke pathology. The default atlases used in FreeSurfer, including FreeSurfer subfields, were created based on data from cognitively healthy elderly adults and patients with early AD pathology (Desikan et al., 2006; Iglesias et al., 2015) . Stroke pathology, such as large lesions, hydrocephalus ex vacuo of the lateral ventricle (Nelson, 2003) , and midline shifts (Liao et al., 2018) , can alter expected spatial distribution of brain anatomy. As a result, stroke pathology can interfere with templates used by existing atlas-based approaches, resulting in inaccurate hippocampal segmentations. Although the CNN used in Hippodeep was not trained on data with stroke pathology, it is trained to anticipate extreme anatomical variability from the synthetic data. Being robust to extreme anatomical variability may explain why Hippodeep was able to perform well in stroke participants. Stroke-specific CNN hippocampal segmentation models that include stroke pathology in training data may further improve automated hippocampal segmentation in this population."}, {"section_title": "Conclusion", "text": "In this study, we demonstrated that more robust hippocampal segmentation methods (Hippodeep and FS-Subfields-Sum) are able to provide more accurate segmentations. In addition, Hippodeep was the only method able to output segmentations on our entire dataset, suggesting it may be the most robust to post-stroke anatomical distortions. The use of more accurate automated hippocampal segmentation methods may reveal clinical associations that are so far undetected. Additionally, future work should aim to extract subfields from the Hippodeep segmentation to further enhance our understanding of how the specific regions of the hippocampus are indirectly impacted by stroke lesions. Overall, our results suggest that Hippodeep may be an optimal method for accurate and robust hippocampal segmentation methods in diverse stroke populations."}]