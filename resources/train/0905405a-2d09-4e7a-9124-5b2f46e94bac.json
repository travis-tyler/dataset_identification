[{"section_title": "Abstract", "text": "Genetic discoveries underlie the majority of the current thinking in neurodegenerative disease. This work has been driven by the significant gains made in identifying causal mutations; however, the translation of genetic causes of disease into pathobiological understanding remains a challenge. The application of a second generation of genetics methods allows the dissection of moderate and mild genetic risk factors for disease. This requires new thinking in two key areas: what constitutes proof of pathogenicity, and how do we translate these findings to biological understanding. Here we describe the progress and ongoing evolution in genetics. We describe a view that rejects the tradition that genetic proof has to be absolute before functional characterization and centers on a multi-dimensional approach integrating genetics, reference data, and functional work. We also argue that these challenges cannot be efficiently met by traditional hypothesis-driven methods but that high content system-wide efforts are required."}, {"section_title": "", "text": "Genetic discoveries underlie the majority of the current thinking in neurodegenerative disease. This work has been driven by the significant gains made in identifying causal mutations; however, the translation of genetic causes of disease into pathobiological understanding remains a challenge. The application of a second generation of genetics methods allows the dissection of moderate and mild genetic risk factors for disease. This requires new thinking in two key areas: what constitutes proof of pathogenicity, and how do we translate these findings to biological understanding. Here we describe the progress and ongoing evolution in genetics. We describe a view that rejects the tradition that genetic proof has to be absolute before functional characterization and centers on a multi-dimensional approach integrating genetics, reference data, and functional work. We also argue that these challenges cannot be efficiently met by traditional hypothesis-driven methods but that high content system-wide efforts are required."}, {"section_title": "Genetics as the Basis for Therapeutic Development", "text": "A core aim of human disease genetics is to facilitate the development of etiologic-based treatments. The field's approach has centered on the notion that identifying gene mutations will ultimately allow us to understand the molecular processes that initiate and sustain the disease pathogenesis. This knowledge in turn will allow the development of mechanism-based therapies ( Figure 1 ).\nThere has been a great deal of success in the early parts of this schema. In a little over 20 years, human disease genetics has moved from a backwater of biology, to the foundation of much of our understanding of complex biological questions. While this success has been hard won, the tools and skills needed to identify disease-linked genes have improved so much that the route to disease gene identification is becoming clearer, more straightforward, and, for certain types of risk variation, routine.\nWhile our success in genetics has been both tangible and substantial, translating this understanding to the development of mechanism-based therapies has been a much more difficult, and less productive, endeavor. A common theme in the success of genetics is that the rate of progress has been dependent on the use of unbiased and system-wide assays; when we have not relied on these tools and instead used our perceived knowledge of the disease to predict genetic targets, our success has been less impressive. We argue here that until now the understanding of pathobiology has been limited by the absence of unbiased and system-wide approaches for understanding molecular processes and that the traditional approach to teasing apart pathogenic function is inefficient and often misleading. We suggest that in order to take advantage of the growing fund of genetic discovery in understanding the molecular basis of disease, we will need to develop and use high content system-wide approaches."}, {"section_title": "Monogenic Forms of Disease", "text": "The initial major successes in disease genetics were dependent on genetic linkage screens, a genome-wide and unbiased method of identifying segregating chromosomal regions. Linkage, followed by positional cloning, was the primary tool of genetic discovery from the late 1980s and is still in use today. While these efforts involved a great deal of time and resources, they were reliable and served as the mainstay of genetics for a number of years, identifying large numbers of genetic causes of monogenic disease (Bonifati et al., 2003; Goate et al., 1991; Kitada et al., 1998; Pais\u00e1 n-Ru\u00edz et al., 2004; Polymeropoulos et al., 1997; Rogaev et al., 1995; Sherrington et al., 1995; Valente et al., 2004; Zimprich et al., 2004) . The prime method in the search for causes of monogenic disease is now second-generation sequencing, usually whole-exome sequencing (WES) but also whole-genome sequencing (WGS). In the context of PD this has led to the identification of the p.D620N mutation in VPS35 as a cause of disease and the nomination of DNAJC13 and CHCHD2 mutations as disease causing (Chartier-Harlin et al., 2011, p. 1; Funayama et al., 2015, p. 2; Vilari\u00f1 o-G\u00fc ell et al., 2014 Zimprich et al., 2011) . Both WGS and WES will continue to provide insights into the causes of monogenic Parkinson's disease (PD). In each of these approaches, it was the development of methods to interrogate an entire system that was key to the success, whether the system comprised chunks of inherited DNA broken down by meiosis, as with genetic linkage studies, or the protein coding regions of the genome as with exome sequencing.\nWhile a detailed discussion of the monogenic forms of these diseases is outside the remit of this Perspective, a catalog of the dominant and recessive mutations for Alzheimer's disease (AD) and PD can be found online (http://www.molgen.ua.ac.be/ ADmutations/; http://www.molgen.vib-ua.be/PDMutDB/) (Cruts et al., 2012) ."}, {"section_title": "Common Genetic Risk Factors for Disease", "text": "While the success in genetic linkage and positional cloning is illustrative, so too are our failures during the same time. In part because of the broad availability and ease of PCR amplification, candidate gene association studies were widely applied during the mid/late 1990s and early 2000s, with the aim of identifying risk variability for complex disease. These methods were easy to apply, relatively cheap, and extensively used; yet, they were also almost universally unsuccessful. With hindsight, the likelihood of nominating the correct gene to be tested and testing the right variants within it was vanishingly small, particularly as we later appreciated that the typical risk effect sizes associated with variants were too small to be seen by the majority of studies. Candidate gene association studies were in essence the antithesis of genome-wide unbiased approaches. Our ability to guess at the molecules involved in the rather enigmatic cascade of events that constitutes disease was proven to be poor.\nThe challenge of identifying common risk variability was eventually met, again by a system-wide method: genotyping using whole-genome SNP arrays. The extremely high information content of SNP arrays, and our ability to predict the genotype of many millions of variants based on these data, provided a revolutionary tool in risk variant identification: genome-wide association (GWA). In this arena, GWA tests broadly and comprehensively, common genetic variation for association with a trait, and once again the system-wide nature of this method is a critical component of its success. GWA studies (GWAS) using these assays were initially controversial but have proven remarkably successful in identifying the genetic basis of complex disease and traits.\nIn the fields of AD and PD this work has been driven by large consortia. In Alzheimer's disease there now exist a large number of GWA efforts that have identified more than 18 loci that contain risk alleles (Harold et al., 2009; Hollingworth et al., 2011; Lambert et al., 2009 Lambert et al., , 2013 Naj et al., 2011; Seshadri et al., 2010) . Likewise there are now a large number of published GWA studies in PD, and since 2009 these have reported reliable and replicable risk loci (Do et al., 2011; Edwards et al., 2010; Elbaz et al., 2011; Hamza et al., 2010; Hernandez et al., 2012; Nalls et al., 2011; International Parkinson's Disease Genomics Consortium (IPDGC) and Wellcome Trust Case Control Consortium 2 (WTCCC2), 2011; Lill et al., 2012; Liu et al., 2011; Pankratz et al., 2009 Pankratz et al., , 2012 Pihlstr\u00f8m et al., 2013; Saad et al., 2011; Satake et al., 2009; Sharma et al., 2012; Sim\u00f3 n-S\u00e1 nchez et al., 2011) . In the latest meta-analysis of PD, GWA studies of 28 independent risk loci have been identified and confirmed (Nalls et al., 2014a) . Like most GWAS hits, individually these PD loci confer only modest risk for disease. If we examine these loci collectively, however, the 20% of individuals with the highest burden of genetic risk are about 3.5 times as likely to get disease than those 20% of individuals with the lowest burden of risk."}, {"section_title": "What Lies Beneath", "text": "Following the considerable success of GWAS, one question that remains is how much genetic influence is left to find? An analysis of the heritability of PD using genetic sharing estimates suggests 30% of the risk for PD can be attributed to genetic factors. This is likely a significant underestimate, because very rare variants are difficult to capture using this method, and this approach, which estimates narrow sense heritability (or the proportion of trait variance that is due to additive genetic factors), does not take into account other genetic factors such as those that are dominant or multiplicative in effect. Notably, however, these analyses show that to date GWAS have identified only one-tenth of this narrow sense heritable component: thus, we can be sure that there is much left to find (Keller et al., 2012) . The next question then, is where to look? Undoubtedly there are common risk loci for AD and PD that remain undiscovered, and extending the size of current GWA studies is one approach that will yield results, as will performing GWA in diverse populations and using alternate data mining methods to prioritize loci. A limiting factor in identifying additional common risk loci through GWA centers both on sample availability and cost. Most of the previous efforts have centered on marginal increases in sample sizes and metaanalysis of existing datasets; however, in large part this pool of extant data has been exhausted. The continued search for such loci will therefore likely require large increases in sample size, and it is unlikely in the current funding climate that there will be much appetite for such a substantial resource investment. Thus, gains in this area are likely to be less dramatic than in previous years. However, it is also likely that some of this missing heritability exists in risk alleles that are too rare to detect using traditional GWAS methods, and this is an area of much interest and investigation.\nSome success has already occurred in identifying rare risk alleles in AD. In 2012, Guerreiro and colleagues identified homozygous mutation of TREM2 as a cause of frontotemporal dementia (Guerreiro et al., 2012) . Mutations in TREM2 were previously shown to cause Nasu-Hakola disease, a rare disease characterized by bone cysts and early-onset progressive dementia (Paloneva et al., 2002) . We had previously predicted that variability at genes causing young-onset autosomal recessive neurological diseases would contribute to late-onset neurological diseases (Singleton and Hardy, 2011) . Because of the involvement of TREM2 in recessive diseases with a neurological component, this gene was a natural candidate for investigation in AD. Our work, and that of others, revealed that indeed rare variants at TREM2 confer moderate risk for AD (Guerreiro et al., 2013, p. 2; Jonsson et al., 2013) . In both instances, the foundation for this discovery was next-generation sequencing data (both WGS and WES), and it is likely that this method will be the primary means for discovery of additional rare risk loci. The majority of variants that confer moderate risk for disease (OR > 2) discovered thus far have altered the amino acid sequence of a protein and this, coupled with the lower price of WES compared to WGS, means that it is often argued that WES will remain the dominant methodology for some time to come. This argument is quite circular, because thus far attempts to look at non-coding sequence for rare risk variants have been quite limited, and it is difficult to interpret the consequences of such variants. Inevitably, as the true cost of whole-genome sequencing approaches that of WES, whole-genome sequencing will become the dominant approach. Interpretation of non-coding variability will remain a challenge; however, as our understanding of the functional relevance of non-coding motifs and regions increases, this will improve. We predict that WGS will become a standard and that advances in technology will center on more efficient generation of WGS, and the use of single-molecule, low-error, and long-read sequences.\nWhat is notable in the genetic architecture of PD is that the same loci show up under different risk categories, i.e., some loci contain an allelic series across a range of frequencies and functional impact. A notable example exists at the gene encoding alpha-synuclein. SNCA point mutations are a rare and highly penetrant cause of young-onset PD, SNCA dosage mutations are also rare, and penetrance is linked to copy number (Singleton and Gwinn-Hardy, 2004) , and common variability at SNCA increases risk for PD by only a modest amount (Odds Ratio 1.5) (Figure 2 ). Likewise, the p.G2019S mutation in LRRK2 occurs in about 2% of North American Caucasian PD patients and is moderately penetrant by late age. There also exist common protein coding variants in LRRK2 that increase risk for disease 2-fold, and, lastly, there are common non-coding variants at the LRRK2 locus that increase risk for disease 1.2-fold. This phenomenon of pleomorphic risk does not yet appear generalizable to every disease or locus, but it is reasonable to suggest that the known risk loci should be investigated for other types of disease risk. Again, second-generation sequencing provides an opportunity to address this question with the use of targeted Genes that contain causal mutations are shown in blue; genes that contain moderate effect protein coding risk alleles are shown in red; GWA-identified loci that contain modest effect risk alleles are represented by proximal gene symbols in black.\nresequencing. In such an approach, an entire genomic locus can be sequenced in a very large number of samples. This method has the potential to answer several questions: first, it can be used to fine map association signals identified by GWAS; second, it can be used to identify rare coding, non-coding, and copy number variants associated with disease independent from the GWA signal that nominated the locus; and third, in the identification of a coding variant associated with disease, this effort reveals the gene that is the biologic effector at a particular locus (Figure 2) .\nThus, we can see that the likely advances in PD and AD genetics will center on a combination of WGS, WES, deep resequencing of known loci, and GWA studies.\nThere are many challenges left in understanding the genetic basis of AD and PD and much work to do; however, there are other challenges that we must face in parallel. First, how can we efficiently move from a locus to a gene; second, when we have genes, how do we build an accurate picture of pathogenesis; and last, as we move toward potential therapies, how do we test these in an efficient manner? See Figure 3 .\nTranslating Gene to Pathobiology: Inefficient Success Insight into the mechanisms underlying disease has been achieved using traditional hypothesis-driven functional approaches. In the context of Alzheimer's disease, the most prominent example of this effort has come from translating amyloid precursor and presenilin mutations into an understanding of the amyloid cascade hypothesis. This represents more than two decades of hard-won functional effort (Scheuner et al., 1996) . While this progress has been absolutely critical in formulating novel therapeutic approaches for Alzheimer's disease, it has come at a substantial cost. The majority of the pathogenic hypotheses tested have either been shown to be wrong, or ultimately revealed to be true biologically but unimportant pathologically. The approaches used to test these ideas were, out of necessity, performed almost exclusively using traditional hypothesis testing reductionist experiments. In the context of these approaches, we have become used to a scientific culture of failure, punctuated by rare significant success. We argue here that much of the initial work characterizing the biology of diseaseimplicated proteins, could be more efficiently performed using the burgeoning hypothesis generating whole-genome screening methods. Such an approach does not remove the likelihood of chasing false leads, but it may minimize it, and notably it would do so at the earliest stages of investigation. Importantly, this effort does not seek to remove the need for traditional functional work, but simply to refocus it based on largely unbiased hypotheses (or more accurately those without the perception of understanding)."}, {"section_title": "Comprehensive Screening and Big Data Integration", "text": "Because the early success in human disease genetics was in the identification of gene mutations that underlie monogenic forms of disease, our approaches to understanding the pathobiologic role of disease genes and their products has centered on manipulating systems using protein coding mutations. These approaches are difficult to apply to alleles that confer only low to moderate risk. For most disease-associated loci identified by GWA the effector gene is unknown, so any attempt to understand pathobiology must initially include an assessment that will reveal the gene and protein of interest. For many loci, the underlying risk allele (which is often unknown) confers only minor risk for disease, and one might predict that the pathobiological effect is also either minor or is not evident under basal conditions. Lastly, the majority of low to moderate risk alleles are not associated with protein coding variants, and thus they must confer an effect through altering expression of a transcript. These constraints represent considerable challenges, and they certainly require a rethinking of our approach to understanding pathobiology and a retooling of functional research groups. However, we believe that the return on meeting these challenges is likely to be so meaningful that we must prepare to meet and best them.\nThere already exists a large number of datasets that can help in this regard, and these have the potential to reveal pathobiology and identify the causal gene at risk loci. A seminal example of this approach was recently published in the field of hereditary spastic paraplegia (HSP) genetics (Novarino et al., 2014) . In this work, the authors used the large number of known HSP genes and existing protein interaction databases to build an HSPome-a protein interaction network centered on HSP proteins. The construction of this network helped nominate proteins/genes for involvement in the molecular pathogenesis of HSP. Taking this information, they were then able to reexamine exome-sequencing data generated in HSP patients and were able to identify novel genetic causes of this disease. This work illustrates the power of integrating large-scale genetic and functional data and shows that the combination of these has the power to inform at both the genetic and pathobiological level. Implicitly, this work also answers a common criticism of continued genetic work: why continue to find low risk genes when we do not know how the genes we have are involved in the disease process? In short, the answer is: we believe that the larger the number of genes and loci that we have, the better chance we have of connecting their protein products in a pathologic network; in turn allowing us to build a complete picture of the pathogenic process. Work along these lines has been attempted in both AD and PD, most prominently featuring efforts to perform pathway-based analysis of GWA-implicated genes. This work centers on mining interaction or literature-based datasets in an attempt to reveal whether the GWA genes collectively highlight pathways of pathobiological relevance. Within both AD and PD, the immune system has been highlighted using this approach, although notably there does not appear to be a strong shared genetic component between these two diseases (Guerreiro et al., 2015; Holmans et al., 2013 ; International Genomics of Alzheimer's Disease Consortium (IGAP), 2015; Jones et al., 2010; Moskvina et al., 2013) . Additionally it has been argued that cholesterol metabolism may also be a pathway of significance in AD (Jones et al., 2010) .\nA more commonly used data integration method centers on using quantitative trait locus data, where the quantitative trait is a biologic measure. Most typically, this aims to provide broad maps of the genetic control of effects proximal to genetic variability such as gene expression, protein levels, and DNA methylation. These maps can then be used to map the immediate biologic effects of variants linked to disease. It is now fairly typical to combine expression quantitative trait locus (QTL) work with GWAS. There are some limitations to this work; primary of which is that association between a biologic trait and a risk variant does not necessarily imply this effect is disease related. For example, an early identified risk locus for Parkinson's disease was nominated on the short arm of chromosome 1, and denoted as PARK16 (Satake et al., 2009 ; Sim\u00f3 n-S\u00e1 nchez et al., 2009). Initial work suggested the risk alleles were also highly significant QTL's for expression of NUCKS1 and DNA methylation at PM20D1, with a less significant expression QTL for RAB7L1 (now RAB29) (International Parkinson's Disease Genomics Consortium (IPDGC), 2011); nevertheless, subsequent functional evidence strongly suggests that RAB29 is the disease related gene at this locus.\nThere are also limits that depend on the biological source used for the QTL map; for example, a typical expression QTL map would examine the relationship between genetic variability and gene expression from a tissue, such as human brain. While quite general genetic effects on constitutive expression are likely to be detectable in such a tissue, expression changes that only occur in a particular cell type, or those that are only evident after induction of expression (for example, in response to cell stress), will not be detected. It is notable that for many loci identified by GWA, no QTL effect has been identified. "}, {"section_title": ". The Application of Genetic Methods to Discovery of Novel Genetic Causes and Contributors to Disease", "text": "These methods, which center on unbiased and largely genome-wide approaches, have enabled the majority of our understanding of the etiology of disease.\nTo date much of the work in the field of expression has relied on array-based assays, which have considerable limitations, such as being relatively insensitive to splice changes, unable to detect unknown/unassayed transcripts, and having a narrow dynamic range for detection. While the resolution of this approach is likely to improve with the application of transcriptome sequencing, the problem of tissue-specific and induced expression will remain, and may need to be addressed with reference experiments aimed at recapitulating these effects, such as QTL mapping in differentiated iPSC.\nIt is notable that analysis of expression as an effector of GWAS signals is being taken a step beyond correlative studies and into mechanistic investigation; this work has shown clearly the complexity of gene regulation and serves as a warning that the most obvious association may not be disease relevant. A prime example comes from the investigation of the FTO locus, where genetic variability is strongly associated with risk for obesity and diabetes; notably, FTO expression is also linked with obesity, and it was believed that the genetic risk at this locus was mediated through FTO. Recent work has suggested however that this may not be the case (Claussnitzer et al., 2015; Smemo et al., 2014) . A critical resource in this type of mechanistic approach is data derived from the ENCODE project (encyclopedia of DNA elements), which aims to build a comprehensive list of functional elements within the human genome. The data underlying ENCODE come from a wide variety of experimental approaches and tissues, Not only did this work establish GAK and RAB7L1 as the pathologically relevant genes at these GWA-identified risk loci, but it also considerably expanded our understanding of Lrrk2 function, a critical aim in PD research.\nand provides data regarding RNA transcripts, chromatin states, and transcriptional regulation. Such data allow investigators to rapidly take the first steps toward understanding the role of genetic variability linked to disease in the context of altered gene regulation. Likewise public sources of gene expression and genetic data such as that in the GTEx, Braineac, UKBEC, and NABEC data allow the integration of genetics, transcriptomic, and regulatory data in order to better understand the genetic control of gene expression in the context of disease (GTEx Consortium, 2013; Nalls et al., 2014b ). This work is being extended in creative ways not only to understand the function of disease-linked variants, but also to identify new disease-linked genes previously undiscovered in traditional GWA studies (Gamazon et al., 2015) . Another broad-scale screening approach, in this instance combining genetic and protein interaction data, was recently performed in PD, and we believe this illustrates the power of integrating big data, and a likely path forward for complex disease research (Beilina et al., 2014) . In this work, the authors performed unbiased high content screens for interactors of the known PD protein Lrrk2. As with most high content screens, a large number of potential interactors were identified, and the prioritization of proteins for follow up would typically have been centered on factors such as putative function and cellular expression. However, the authors used a different approach: combining GWA results with the hits from the Lrrk2 interactor screen showed that two of the hits were encoded by genes under GWA peaks (Pankratz et al., 2009; Satake et al., 2009; Sim\u00f3 n-S\u00e1 nchez et al., 2009 ). These two proteins, GAK and Rab-7L1 (RAB29) were subsequently shown to form a complex with Lrrk2 that promotes clearance of Golgi-derived vesicles through the autophagy-lysosome system (Figure 4) .\nWhat we hope to have illustrated is that these high content data have the ability to be informative about the molecular etiology of disease. This is particularly relevant when integrated with a large list of genes/loci. Notably such experiments have the benefit that they both provide information regarding the molecular etiology of disease, and support the nomination of particular genes within known risk loci, creating a self-propagating knowledge generator ( Figure 5 )."}, {"section_title": "Understanding Genetic Uncertainty", "text": "As outlined above, we have rapidly moved into a space where the majority of genetic loci associated with disease are not represented by coding mutations that cause disease, but rather by common genetic risk variability with unknown consequences. As second-generation sequencing progresses, there will be an additional class of genetic variability, rare protein coding, and non-protein coding risk alleles. Notably, because these changes are rare and confer risk rather than cause disease, proving pathogenicity is a considerable challenge. In the context of dataheavy genetic approaches, the topic of proving pathogenicity is of considerable focus (MacArthur et al., 2014) . Several schema for evaluating disease association have been proposed, in general including integration of existing published data, a statistical likelihood-based assessment (association/linkage) and, notably, the generation of functional evidence (MacArthur et al., 2014) . Indeed, it is unlikely that the burden of proof for disease involvement can be fully met by genetics alone. Thus, we are rapidly finding ourselves in a situation in which alleles of uncertain pathogenic relevance will be commonplace in the literature. In order to move such alleles into an unequivocal category of risk or benign variant, it is absolutely critical that those involved in functional characterization of genetic variants understand the uncertainty surrounding these findings. Further, it is extremely important to understand the power and potential bias of the approaches they employ in order to avoid lending false support of these candidates as disease-linked genes. The literature in a field can build momentum, which is sometimes inappropriate; for example, a very large body of work has been performed on ubiquitin C-terminal hydrolase 1, despite the fact that the initial genetic evidence implicating this gene in PD was extremely weak and remains unsubstantiated (Leroy et al., 1998) . The naming of UCHL1 as a genetic locus for PD persists despite this lack of evidence, and a simple PubMed search of ''UCHL1'' and ''Parkinson's disease'' reveals 121 manuscripts on this topic.\nWe view that, largely, the testing of the involvement of genes/ variants for their involvement in pathways implicated in disease as a dangerous approach toward establishing pathogenicity.\nThe majority of such efforts use rather blunt overexpression or knockout models, and the low n associated with most functional experiments means that it is too easy to ascertain a positive effect on any pathway, regardless of whether this is a true biological effect or not. In this regard, once again the power of unbiased system-wide methods is critical. Such work has the ability to test for an effect of a variant/gene on the background of effects seen across the whole genome, and thus to understand what is noise versus what is true signal."}, {"section_title": "Next Steps for Genetics", "text": "Cataloging More Risk As discussed above, there is clearly more genetic risk to be identified for AD and PD, and there exists a compelling rationale to invest time and resources to find it. For both AD and PD, GWAS have been successful; however, also for both, tens of thousands of samples have been genotyped, and it is unclear that there will be significant support available to extend this genotyping to ever-increasing cohorts. There will likely be more that can be extracted from the extant data, through simply digging deeper into the sub-significant hits and through alternative data mining approaches, such as pathways-based analysis. Further, it is likely that as we build a greater understanding of the disease network, we will be able to specifically test genes in that network using these existing GWA data.\nSecond-generation sequencing is increasingly accessible to the research community, not only because of reducing costs per base pair, but also with the development of standardized analytical tools. WES continues to be the prime method for gene discovery, and while most of the success has been in identifying disease-causing mutations, the accumulation of WES data in large cohorts facilitates the identification of risk alleles using population based efforts. Because the majority of common variants that confer risk should have been identified by GWAS, the remaining risk variants are likely to be rare, and/or to impart very minor alterations in risk. What this means for sequence-based risk discovery approaches is that the sample size will need to be high. While GWAS started to identify loci in PD and AD when applied to 2,000 cases, it is likely that exome, genome, and targeted sequencing approaches will need to be applied to tens of thousands of samples in order to reliably find risk alleles without a priori understanding. To date, there are no studies that have reached this type of sample size for AD/PD; however, these are now underway for AD and being planned for PD.\nOne approach that has been used in several diseases, although not yet in AD/PD at a large scale, is resequencing, where candidate genes/loci are sequenced in very large numbers of cases. The genes and regions selected typically include known disease genes and GWA-linked loci. This design allows the systematic investigation of nominated genes, including non-protein coding regulatory sequence, quickly and efficiently. The advantage of this approach is not only the speed with which it can be applied but that it provides genetic information at multiple layers: it is a critical step in fine mapping of a GWA signal, and the identification of the functional risk allele(s); it allows the identification of additional risk at the same locus (for example, rare risk alleles at a GWA locus); and, because the We suggest here that this understanding can be greatly facilitated using burgeoning high-content screening technologies and large-scale data mining. Not only does this have the ability to implicate specific processes in disease, but it can also aid in further mapping of the genetic basis of disease.\nsequence is usually very deep, copy number variants are more easily detected.\nWhile WES and resequencing are available now, and offer many benefits such as speed, low costs, and standardized analysis, it is inevitable that these methods will be supplanted by WGS; it is clearly a question of when, not whether, we will perform extremely large-scale whole-genome analysis in these diseases. Notably, as sequencing reads become longer and contain less error, the alignment and analysis of sequence data will be more routine and less burdensome; such an advance will also lead to a greater resolution of the genetic basis of risk and the consequences of risk in the context of gene expression. The Role of Genetics in Overcoming Other Barriers to Therapeutic Development Both AD and PD are late onset, progressive, and genetically complex diseases, and the nature of these diseases present significant challenges to therapeutic design and testing.\nIt is clear that both AD and PD occur for a number of years before the patient presents with clinical signs and symptoms and that by the time the patient comes to clinic, the disease has progressed considerably, affecting multiple systems. It is most likely that effective therapies will focus on slowing or halting, rather than reversing, the disease process. It is also reasonable to assume that the earlier stages of disease are likely to be more responsive to etiologic-based therapeutic intervention, than later, more widespread stages. One challenge therefore lies in identifying patients that are likely to get disease well before the signs and symptoms appear, with the ultimate aim of being able to apply preclinical therapeutic intervention, but with a more immediate aim of identifying cohorts of patients for clinical trials. This is already being pursued in AD, with current clinical trials of the anti-beta-amyloid therapy crenezumab in asymptomatic subjects who carry the PSEN1 p.E280A mutation. There exist a number of causal or highly penetrant gene mutations for both AD and PD, and carriers of these mutations may likewise be recruited into preventative clinical trials. The establishment of multinational networks such as DIAN (dominantly inherited Alzheimer network; http://www.dian-info.org/) aims to study overtly asymptomatic carriers of dominant causal gene mutations in an effort to understand the disease process and identify early indicators of disease onset and progression. Such studies are ideally positioned for the execution of early clinical trials, and indeed the DIAN study has been extended to include such a component, with the testing of gantenerumab and solanezumab in this cohort (https://www.clinicaltrials.gov/ ct/show/NCT01760005).\nA greater challenge, however, lies in the identification of individuals who will go on to become affected with disease, but who do not have a simple genetic cause. It is hoped that genetic risk profiling will help in this regard by estimating risk based on an individual person's burden of known risk alleles. Progress in refining these pure genetic risk models is modest but steady. The use of genetic risk modeling alone is unlikely to identify soon-to-be-affected patients within the near future. This does promise however to improve, and it will surely be part of a battery of tests aimed at predicting disease likelihood, onset, and course. A recent example of the success of integrating diverse accessible data types to predict disease comes from our efforts in PD (Nalls et al., 2014a) . In this work, age, sex, family history of disease, anosmia status, and cumulative genetic risk score were combined to assign individuals an overall risk for PD. Using this model, we were able to show an area under the receiver operator curve of 0.92 across several studies, a remarkable predictive power. Perhaps even more interestingly, this predictive model was able to show that the PD patients who failed to show dopaminergic deficit at presentation represented two distinct risk groups and that those with the higher risk profile were more likely to progress to show dopaminergic deficit.\nLikewise, any efficient clinical trial will require quantitative markers of progression, which perform better than current clinical instruments. Markers of progression will be particularly important in preclinical trials, in which changes over a short period are likely to be very subtle; without these, trials would stretch over many years with an associated cost that would be a disincentive to risk-averse pharmaceutical companies. As with risk profiling, genetics is likely to form a part of biomarker work, not only in defining high-risk individuals for cohorts being used in the development of biomarkers, but also in subsetting of groups of patients who have different biomarker profiles over the course of disease. This latter point touches on a more general theme in disease, subtyping. Our current pathognomonic classification of disease may be too coarse, and it is plausible that there are subtypes with different, or at least not entirely overlapping, pathogeneses. This would implicitly suggest that discernable subtypes may require different therapeutic approaches, may respond differently to treatment, and need to be defined and identifiable as a part of clinical trials and biomarker studies (Figure 6) .\nA large barrier to the identification of disease subtypes, developing tools to aid in prognosis, and the discovery of biomarkers is cohort availability. Much of the genetic work to date has been appropriately carried out in cross-sectional patient collections, where numbers are very high, but clinical details are low. Detailed longitudinal clinical studies are required; these are time consuming, and extremely expensive; however, there are several attempts to collect such cohorts in PD and AD including two well-known studies, the Parkinson's Progression Markers Initiative (PPMI) and the Alzheimer's Disease Neuroimaging This includes genetic identification of at risk individuals, use in defining biomarkers, and defining sub-types of both disease and response to treatment. It can also be used as part of the process of identifying people in the prodrome of the disease before clinical symptoms become apparent, which is precisely when one would want to start mechanistic treatment.\nInitiative (ADNI) (Mueller et al., 2005; Parkinson Progression Marker Initiative, 2011 )."}, {"section_title": "Summary", "text": "The continuation of an interrogation of the genetic basis of disease is a key step toward effective therapeutic strategies. Genetics will continue to inform researchers and to drive etiologic and clinical research. Critically, we argue that in order to take full advantage of these data, a sea change is required in the way in which the field performs functional characterization of disease linked genetic variability. The generation of large unbiased functional datasets that can be integrated with the growing fund of genetic knowledge is a necessary step, and one that should occur before typical reductionist cell biology. In adopting this approach, we can more efficiently move toward true disease altering therapeutics."}]