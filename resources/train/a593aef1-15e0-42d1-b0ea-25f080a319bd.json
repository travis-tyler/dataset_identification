[{"section_title": "Introduction", "text": "In his first State of the Union Speech given in January 1964, President Lyndon Johnson declared a \"war on poverty,\" saying \"our aim is not only to relieve the symptom of poverty, but to cure it and, above all, to prevent it.\" 1 To prevent poverty, Congress and many states enacted new education programs designed to enhance the human capital of children born into poor and otherwise disadvantaged households. In this paper, for the cohorts born from 1961 to 2001 we provide consistent evidence on changes in the gap in educational achievement between children raised within families of high and low socio-economic status (SES), as measured by student performance on standardized tests. Our main finding is that, despite the policy undertakings, the SES-achievement gap remains as large today as it was when the poverty war was declared. To the extent that these tests are predictive of a child's future prosperity, our results imply that intergenerational mobility is unlikely to improve in the middle decades of the 21 st Century. In advanced industrial societies, cognitive skills are highly correlated with economic outcomes. Indeed, the U.S. labor market rewards cognitive skills more than almost all other developed countries Woessmann (2015, 2017)). It is thus for good economic reasons that President Johnson and others have long searched for tools that could break the linkage between SES and student learning (Ladd (1996); Carneiro and Heckman (2003); Krueger (2003); Magnuson and Waldfogel (2008)). Given the topic's importance, it is surprising that trends in SES-achievement gaps are so poorly documented. Popular commentary has linked widening income gaps in the United States to a perceived spread in the achievement gap between rich and poor. Richard Rothstein (2004) writes: \"Incomes have become more unequally distributed in the United States in the last generation, and this inequality contributes to the academic achievement gap.\" In Coming Apart, Charles Murray (2012) argues that \"the United States is stuck with a large and growing lower class that is able to care for itself only sporadically and inconsistently\u2026. [Meanwhile], the new upper class has continued to prosper as the dollar value of the talents they [sic] bring to the economy has continued to grow.\" Robert Putnam (2015) says in Our Kids that \"rich Americans and poor Americans are living, learning, and raising children in increasingly separate and unequal worlds.\" On the contrary, the trend tracked by PISA shows a decline over the most recent time period, while gaps observed in the other three assessments show either no change or only minor drifts upward. When data from all assessments are combined, the overall trend hardly wavers. 2 These gaps remain steady within the context of quite stagnant levels of average achievement among students nearing the end of their secondary education. While steady average gains in student performance have been registered over the past half century among middle-school students, those gains are no longer evident by age 17, the point students are expected to be ready for college and careers. In robustness analyses, we show that our results are unaffected by consideration of a range of methodological issues. The main finding of a flat SES-achievement gap is confirmed in analyses of the achievement gap by subsidized lunch eligibility and in separate estimations by ethnicity that consider changes in the ethnic composition. Further robustness analyses include a treatment of limited information on the tails in the categorical SES data, an alternative point estimation approach to our baseline group calculation approach, and an alternative analysis that considers the ordinal nature of the underlying achievement data. The next section reviews the literature on SES-achievement gaps. Section 3 describes our achievement data, and section 4 discusses our methodological approach. Section 5 reports our baseline evidence on trends in student achievement gaps and levels. Section 6 discusses various issues associated with the measurement of SES and provides supplementary analyses as robustness checks. The final section discusses and concludes."}, {"section_title": "Existing Literature on the SES-Achievement Gap", "text": "Definitions and measurement of SES differ with context and data availability, but for the most part SES is \"defined broadly as one's access to financial, social, cultural, and human capital resources\" (National Center for Education Statistics (2012a)). In this paper, we are interested in changes over time in the connection between SES and student achievement, a probable predictor of future economic opportunities. In that sense, it resembles studies of intergenerational mobility, which compare parental SES and the child's SES as an adult. After briefly summarizing research describing the relationship between indicators of family SES and student achievement, we look in more detail at research that traces temporal changes in this relationship."}, {"section_title": "The SES-Achievement Connection", "text": "The strong relationship between SES and achievement has long been known (Neff (1938)). Coleman et al. (1966), in their seminal study of Equality of Educational Opportunity, found parental education, income, and race to be strongly linked to student achievement with school factors being less significant. In a secondary analysis of these data, Smith (1972) also found family background to be the most important determinant of achievement. Subsequent research into family factors has confirmed these early findings (Burtless (1996); Mayer (1997);Jencks and Phillips (1998); Magnuson and Waldfogel (2008); Duncan and Murnane (2011); Duncan, Morris, and Rodrigues (2011); Dahl and Lochner (2012); Egalite (2016)). The literature is extensive enough that there have been a number of periodic reviews of the empirical relationship between SES and achievement (e.g., White (1982); Sirin (2005)). Many potential mechanisms may be at work in the SES-achievement connection (Cheng and Peterson (2019)). For example, college-educated mothers speak more frequently with their infants, use a larger vocabulary when communicating with their toddlers Risley (1995, 2003)), and are more likely to use parenting practices that respect the autonomy of a growing child (Hoff (2003); Guryan, Hurst, and Kearney (2008)). College-educated and higher-income families have access to more enriched schooling environments (Altonji and Mansfield (2011)) and are less likely to live in extremely impoverished communities burdened with high violent crime rates (Burdick-Will et al. (2011)). Children exposed to lower SES environments are at greater risk of traumatic stress and other medical problems that can affect brain development (Nelson and Sheridan (2011)). These and other childhood and adolescent experiences contribute to SES disparities in academic achievement (Kao and Tienda (1998); Perna (2006); Goyette (2008); Jacob and Linkow (2011)). In empirical analyses, measures of SES are ordinarily based upon data availability rather than conceptual justification. In large-scale assessments of student achievement, data collection procedures usually ignore hard-to-measure qualitative family-related factors such as parent-child interactions, child upbringing approaches, or general physical and nutritional conditions (see, for example, Gould, Simhon, and Weinberg (2019)). Rather, the general approach is to look for more readily available indicators of persistent cultural and economic differences across families as proxies for the educational input of families. The standard list includes parental education, occupation, earned income, and various items in the home (National Center for Education Statistics (2012a); Sirin (2005)). These measures tend to be highly correlated, making their separate impacts on learning and their relative importance difficult to disentangle. While family income might generally be thought of as a good summary measure of SES, its reliability for this use has not been well validated and obtaining data on this from large-scale surveys is problematic. Survey data linked to assessments often come from the students themselves, and students generally have imperfect knowledge of their parents' earned income. For that reason, large-scale assessments that gather information directly from students seek to ascertain economic well-being by asking questions about consumption items, such as the number of durable and educational items present in the home. As compared to household earned income, students are intuitively better informed about whether a durable good (e.g., a dishwasher, computer, or a separate bedroom for themselves) is available in their home (Astone and McLanahan (1991), p. 313). Investigating the reliability and validity of student reports of parental SES characteristics compared to responses provided by mothers and fathers, Kayser and Summers (1973) conclude that \"student reports were relatively stable over time and were more reliably measured for parental education than for either father's income or occupation. The validities of the reports were, for all but income reports, moderate. The validity of income reports was very low.\" An analysis by Fetters, Stowe, and Owings (1984) shows that studentreported indicators of parental education tend to be reliable but determined that \"family income \u2026 was a matter of speculation for many students and thus inaccurately reported\" (Kaufman and Rasinski (1991), p. 2). Consumption indicators may also be useful for estimating the resources of low-income families who supplement earnings with transfer payments, such as food stamps, medical services, housing assistance, and welfare benefits (Slesnick (1993)). In sum, a child's SES background has been estimated by a variety of measures. The items used depend on alternatives available in the data, but when gathering data directly from students, stable measures such as parental education and durable goods in the home are generally preferred to income."}, {"section_title": "Trends in the SES-Achievement Relationship", "text": "Somewhat surprisingly, recent analyses have used income as their SES indicator. Reardon (2011b) has pioneered characterizing the SES-achievement gaps with income, and this is widely cited in both academic literature and the general media. 3 His conclusion that incomeachievement gaps have dramatically increased over the past half century is arguably the contemporary conventional wisdom. Reardon (2011b) measures SES with data on household income obtained from students or parents. In analyses of data from twelve independent cross-sectional surveys, he estimates gaps in math and reading achievement of students at the 90 th and the 10 th percentiles of the household income distribution. He finds that the \"income achievement gaps among children born in 2001 are roughly 75 percent larger than the estimated gaps among children born in the early 1940s\" (p. 95). Interestingly, in his analysis, all of the change comes from changes in the 90-50 gap, whereas the 50-10 gap remains unchanged over the period-thus moving the discussion away from the historic concern about the troubles faced by disadvantaged students. As we show in greater detail in Appendix B, there are two strands of evidence suggesting that these estimates largely reflect measurement error in both the achievement and income data used to estimate the SES-achievement gap over time. First, six of the twelve surveys that are used in the construction of SES-achievement gap data and that receive disproportionate weight in the trend analysis do not meet current quality standards for scientific surveys. They suffer to varying degrees from relying on student reports of parental income, having very large missing data problems, lacking appropriate achievement tests, and using very selective samples. When the trend analysis is limited to the more reliable surveys with reduced measurement error, no upward trend in the income-achievement gap is observed (Appendix Figure A1)-quite consistent with our findings here. Second, the two sets of data that employ psychometrically matched tests-NLSY79 and NLSY97 and ECLS-K, ECLS-B, and ECLS-K2010-do not show any upward trend in the income-achievement gap for a time period identified in the Reardon analysis as experiencing a steep increase. These findings also imply that the apparent difference in results between his study and ours is not due to the use of different SES measures-income vs. an index based on parental education and home possessions. 4 Three other recent studies include trend data for the United States in international comparisons of SES-achievement gaps. 5 Although they differ in their data sets, methodologies, and operational definitions of SES, all three observe a diminution of the SES-achievement gap in the United States over the past two decades. The first study by the OECD (2018) estimates the change in the SES-achievement gap between 2000 and 2015, as traced through the PISA assessments, a consistent set of psychometrically linked tests in math, science, and reading that we also use. The OECD measure of SES is its index of Economic, Social and Cultural Status (ESCS), which aggregates data from students on their parents' education, their parents' occupation, and an inventory of items in their home. This index, described more thoroughly in Appendix A, resembles the SES measure used in our analysis (see section 4.2). Instead of looking at achievement gaps between the tails of the SES distribution, the study gauges changes in the SES-achievement connection by identifying changes in the socio-economic gradient. Student performance on PISA is regressed on the ESCS index, and the amount of the variance explained (R 2 ) is interpreted as an indicator of the degree to which achievement is equitably distributed across the students in the survey. The OECD (2018) reports a decline in R 2 over the fifteen-year period for the United States, which it interprets as indicating greater equity in the distribution of achievement. The second study by Chmielewski (2019) combines data from one hundred countries on international tests conducted between 1964 and 2015 in order to estimate 90-10 SESachievement gaps in all countries. She relies chiefly upon parental education as her SES indicator, although she also separately analyzes parental occupation and books in the home. She finds no significant trend in the SES-achievement gap for the United States on the eight test administrations of student performance given to cohorts born between 1950 and 2001. There are, however, concerns about her treatment of tests that are not psychometrically linked and about her reliance on compressed parental-education categories to measure SES, requiring extensive extrapolation of achievement scores far outside the range of observed categorical SES information (discussed in Appendix C). In the third analysis, Broer, Bai, and Fonseca (2019) employ psychometrically linked assessments in math and science administered by TIMSS to estimate trends in SES-achievement gaps for eleven countries including the United States between 1995 and 2015. They estimate 75-25 gaps on an SES index constructed from indicators of parent education, books in the home, and the presence of two education resources (computer and study desk). 6 They find that SESachievement gaps in the United States decline significantly for science performance but do not change significantly for math. Numerous studies look at the black-white test-score gap in the United States; see, for example, Grissmer, Kirby, Berends, and Williamson (1994), Grissmer, Flanagan, andWilliamson (1998), Jencks andPhillips (1998), Magnuson and Waldfogel (2008), and Reardon (2011b). These studies quite consistently identify a substantial closing of the black-white testscore gap for cohorts born between 1954and 1972, but, as Magnuson and Waldfogel (2008 put it, \"steady gains\" occurring among those born just after mid-century \"stalled\" among cohorts born toward the end of the century. Since the SES backgrounds of black and white students differ markedly, changes in the black-white test-score gap may provide a partial window on trends in the SES-achievement gap. But the correlation between ethnicity and SES has been declining (Wilson (1987(Wilson ( , 2011(Wilson ( , 2012) and black students constitute only around 16 percent of the school-age population (Rivkin (2016)). Thus, patterns of the black-white gap can only provide a limited picture of changes in the SES-achievement gap."}, {"section_title": "Longitudinal Achievement Data", "text": "Building on these studies, we estimate trends in SES-achievement gaps from four psychometrically linked batteries of tests that span a 47-year time period. Each of these surveys uses a consistent data collection procedure to estimate the test performances of representative samples of U.S. adolescents over multiple years. Each test is designed to have a common scale and to be comparable over time by employing psychometric linkage based on using test items that are repeated across test waves. All are low-stakes tests: No consequences to any person or entity are attached to student performances, and results are not identified by name for any school, district, teacher, or student. All four surveys contain student background questionnaires that collect information about parents' education and about a variety of durable material and educational possessions in the home that we use in constructing an SES index. In addition, parental occupation is available in one survey, and student eligibility for free and reduced-price lunch is available from administrative records in two of the surveys. Each data set provides micro data at the student level that link questionnaire responses to students' test scores for each subject."}, {"section_title": "National Assessment of Educational Progress, Long-Term Trend (LTT-NAEP)", "text": "LTT-NAEP tracks performances of a nationally representative sample of adolescent students in math and reading at ages 13 and 17 beginning with the birth cohort born in 1954 who became 17 years of age in 1971. LTT-NAEP data are available for reading in select years from 1971-2008 and for math from 1973-2008. 7 As indicated by its name, this version of the NAEP, often called the \"nation's report card,\" has been developed with the explicit intention of providing reliable measures of student performance across test waves. It is the only source of information for student cohorts born between 1954 and 1976. The U.S. Department of Education suspended administration of the LTT-NAEP in 2012. In a typical year, approximately 17,000 students participate in the administration of the LTT-NAEP. All NAEP data come from the National Center for Education Statistics (NCES) and were analyzed in a restricted-use data room."}, {"section_title": "Main National Assessment of Educational Progress (Main-NAEP)", "text": "Main-NAEP administers tests of math and reading aligned to the curriculum in grade 8. 8 Begun in 1990 with new administrations of the survey every two to four years, it is designed to provide results for representative samples of students in the United States as a whole and for 7 LTT-NAEP also tests 9-year-olds, but we do not include these data in our analyses in part because of the limited, fragile information on SES background of the students. Also, our focus is on the academic preparation of students as they approach the stage where they need to be career or college ready. For a description of NAEP, see National Center for Education Statistics (2013). In math, the first test is 1973. While we have mean math achievement in that year that can be used to analyze trends in achievement levels, we do not have access to the individual student data, making it impossible to calculate SES-achievement gaps for 1973. Thus, the achievement gap analysis that includes both math and reading is based upon two fewer observations than the level analysis. 8 We exclude Main-NAEP science because 8 th grade tests were administered in only two years, 2000 and 2005. As in prior research, we do not include results from exploratory surveys NAEP conducted prior to 1990 in part because the necessary information on SES is not publicly available. We also exclude other subject areas due to limited testing and uncertainties as to the accuracy of test measurement in these domains. each participating state. 9 Main-NAEP maintains a reputation for reliability and validity similar to LTT-NAEP, and it was thought to track trends over time accurately enough that the LTT-NAEP was no longer necessary. For each administration of the test, the Main-NAEP sample is approximately 150,000 observations, the large sample being necessary in order to have representative samples for each state. "}, {"section_title": "Trends in International", "text": ""}, {"section_title": "Programme for International Student Assessment (PISA)", "text": "PISA, administered by the Organization for Economic Co-operation and Development (OECD), began in 2000. It was originally designed to provide comparisons among OECD countries, but it has since been expanded to many other jurisdictions. PISA administers assessments in math, reading, and science to representative samples of 15-year-old students (rather than students at certain grade levels) every three years. PISA assessments are designed to measure practical applications of knowledge. The United States sample includes over 5,000 students for each administration of the test. The U.S. has participated in every wave of the test, so we use national PISA data available every three years from 2000-2015, though results are not available for reading for the 1991 birth cohort because of test administration problems."}, {"section_title": "Methodological Approach", "text": "We aggregate achievement and family background data from the four intertemporally linked surveys and construct an SES index similar to the one used by PISA in order to estimate trends in the SES-achievement gap over time."}, {"section_title": "Combining the Achievement Data Sets", "text": "We compile an aggregate distribution of achievement from student-level micro data available for each subject, testing age, and birth cohort for close to a fifty-year period. With the exception of 17-year-olds in the LTT-NAEP data, all tests were administered to students between the ages of 13 and 15. The first test was administered by LTT-NAEP in reading to a cohort of students born in 1954; the last test was administered to students born in 2001. Across this near half-century span, achievement data are available for 2,737,583 students from 46 tests in math, 40 in reading, and 12 in science. Table 1 gives for each survey the number of assessments, subject matter, age or grade level at which students are tested, birth cohorts surveyed, and number of observations. Our overall sample contains 98 separate test-subject-age/grade-year observations. 12 Appendix Table A1 indicates the specific years in which the different surveys were administered. The Main-NAEP and TIMSS tests are grade based, while the LTT-NAEP and PISA tests are administered to students at slightly different ages. For expositional simplicity, we convert grades to age groups by the modal attendance patterns and refer to all younger students as age 14, the modal age. To equate results across tests, we calculate achievement means and achievement gaps between groups in standard deviations (s.d.) for each subject, testing age, and birth-year cohort. We estimate trends in mean performance over time by calculating the distance (in s.d.) of the mean of the distribution for each test, subject, and cohort observation from the mean score in 2000 (or the closest test year), which is normalized to zero in this base year. 13"}, {"section_title": "Measuring the SES-Achievement Gap", "text": "To estimate SES-achievement disparities, we need a consistent measure of students' SES. Here, we briefly describe the construction of our SES index, relegating details of the construction to Appendix A and discussing key methodological issues in section 6. Estimating achievement differences between different parts of the SES distribution requires a measure of SES that adequately depicts the full distribution of the population, rather than dividing it into a limited number of categories such as level of degree attainment of parents. Given the inaccuracy of student reports of parental income (and the ensuing lack of such data in large-scale assessments), we construct an index of SES based on student-reported information of parental education and home possessions, which is provided in all four assessment surveys included in this analysis. We construct an SES index similar to the one used in PISA (OECD (2017a)). The index is given by the first principal component from a factor analysis of the two underlying variablesparental education and the number of home-possession items. Since the set of measured home possessions varies over time as does their individual utility for characterizing SES differences, we perform the principal component analysis separately for each test administration (for details, see Appendix A). These calculations allow us to capture the relative position of each child's family in the percentile distribution of SES in each given year. Because of data limitations, we depart from the OECD's measure of SES by excluding occupational prestige, an item that is unavailable from TIMSS or either NAEP survey. Exclusion of the occupational prestige indicator affects the SES index only slightly, because that variable, which estimates occupational prestige by the average education and income of individuals in each occupation, is largely redundant after inclusion of the education and possession variables. The SES index used here is highly correlated with the full PISA index, and the two indices reveal essentially the same trend line in the SES-achievement connection over the period tracked by PISA (Appendix Figure A2). 14 Our measure of the SES-achievement gap is the difference in achievement between students in the top and bottom quartiles of the distribution of the SES index. That is, we compare the 14 Estimating SES by a family's permanent income is conceptually an alternative, but that is not possible from data available in these assessments. Nor is it clear that this is a superior proxy for educational inputs of the family. To judge how our SES indicator correlates with permanent family income, we estimate the correlation between our SES indicator for 1988 and earnings indicators obtained from two waves of a panel survey administered as part of the 1998 Education Longitudinal Study (ELS). Using the average of the two waves as a measure of permanent income, the correlation between individual-level permanent income and our SES indicator is 0.66 (see Appendix A). average score for the group of students at or above the 75 th SES percentile to the average score for the group of students at or below the 25 th percentile. For expositional purposes, we refer to this as the 75-25 SES gap. Appendix Table A2 reports this measure of the SES-achievement gap for each of the underlying test-subject-age-year observations, together with measures of the average achievement level and the overall achievement dispersion in the population. The grouped SES-achievement comparison allows us to compare achievement across disparate broad segments of the population without imposing any functional relationship on the SES-achievement distribution. An alternative approach is to regression-estimate an empirical SES-achievement relationship and then to predict the achievement at specific SES percentiles from this estimated relationship, as done for example by Reardon (2011b), Chmielewski and Reardon (2016), and Chmielewski (2019) to estimate 90-10 gaps. As we show in section 6.4 below, we obtain similar results when using this point estimation approach to predict within the range of observed SES values. By contrast, extrapolation to extremes such as the 90 th percentile is strongly sensitive to functional form assumptions (see Appendix C). Note, however, that our approach to look at the difference in the average performance between those in the top and bottom quartiles of the SES distribution means that the median student within each of these quartiles is located at the 87.5 and 12.5 percentiles, respectively-not far from the 90-10 extrapolations attempted in the other studies. 15 In some of the underlying surveys, the available categorical information on the different SES components is somewhat limited (see section 6.3 below for details). To avoid measurement error arising from crude characterization of the SES distribution unsupported by the data, we exclude all test administrations where we cannot observe the portion of the SES group that falls in the relevant tail of the distribution corresponding to the desired SES comparisons. Specifically, if the highest SES category for a particular test administration includes more than 25 percent of the population, we exclude that test administration from our estimation of the trend in the 75-25 SES-achievement gap. 16 In practice, the concern is always about the top end of the SES distribution, because all of our observations have sufficient detail at the bottom end. This sample rule reduces our observations to 81 out of the potential 96 observations and postpones the first included birth cohort from 1954 to 1961, but it allows us to be more confident about identifying achievement patterns in the tails of the distribution. In other words, in making inferences about relative achievement in the tails of the distribution we do not want to impose fixed distributional assumptions on the achievement in the tails. In the empirical work, we investigate the sensitivity of the results to the sample reduction by also looking at the 70-30 gap that allows for 91 observations; this does not affect our overall results. 17"}, {"section_title": "Estimating Trends in Achievement Gaps and Levels", "text": "While the four separate assessment regimes-LTT-NAEP, Main-NAEP, TIMSS, and PISA-are internally consistent over time, they vary from each other in a variety of details, including relationship to the curriculum, testing philosophy, and sampling frames. We assume that each testing regime provides a valid measure of knowledge in each tested domain even though they vary in content. Differences among tests may also be a function of normal sampling error. To identify the aggregate trend in gaps and levels across birth cohorts, the estimation combines results from all assessments but includes indicators for assessment regime, subject, and age group. The fixed effects for the four testing regimes take out any impact of regime-specific characteristics on the trend-line estimation. 18 To estimate the trend in performance levels, we calculate the mean performance, t isa O , by subject s, testing age a, and birth cohort t for each survey i. We extract the performance trend with a quadratic function of birth year: where and , , i s a \u03b4 \u03b3 \u03bb are fixed effects for assessment regime, subject, and age; t is birth year; and \u03b5 is a random error. The parameters \u03b11 and \u03b12 describe the trend in achievement. 17 For the same reason, we also refrain from estimating 90-10 gaps or comparable extremes of the distribution, as 45 of the potential 96 observations provide no way of distinguishing achievement of students in the top 10 percent of the distribution from those further into the distribution. In other words, in close to half of the observations the observed top category of the SES distribution has greater than 10 percent of the students. 18 The fact that the aggregate trend line is estimated with a regression that makes use of information on trends within each separate psychometrically linked testing regime but not variations across the assessment regimes distinguishes the analysis from the Reardon (2011b) study, avoiding potential bias from scale differences. We use the same analytic approach to estimate trends in disparities in average student performance for two groups, j and k, where the gap at any time t is t jk \u2206 : In our main analysis, we focus on the SES-achievement gap as depicted by the achievement difference between those in the top and bottom quartiles of the SES index distribution, but we also report trends in other measures of disparities in our robustness analyses."}, {"section_title": "Main Results", "text": "We start by presenting results on the aggregate trend in the SES-achievement gap for all students in all subjects, followed by an exploration of heterogeneities by subject, age, and testing regime. We then report trends in the levels of achievement. As a general background on achievement disparities in the U.S. student population, we note that the overall distribution of achievement, while narrowing a little, has shown only limited change. Figure 1 plots the trend in the achievement difference between students performing at the 75 th and 25 th percentiles of the achievement distribution, as well as between those at the 90 th and 10 th percentiles, over the past half century (birth cohorts 1954-2001 "}, {"section_title": "Trends in the SES-Achievement Gap", "text": "The trend in the 75-25 SES-achievement gap, as displayed in Figure 2, presents a startling picture: The connection between SES and achievement hardly wavers over the forty-year period (birth cohorts 1961-2001) for which we have sufficiently rich SES data. 22 The trend line, which is based on the within-test data and does not use the between-test data, is essentially flat. While inference from the quadratic function necessarily becomes slightly imprecise at the endpoints of the observed time range, it is obvious that-despite the statistical uncertainty contained in the measurement of achievement on any one of the underlying assessments-we can confidently reject quantitatively noteworthy changes in the SES-achievement gap over the bulk of the observation period. Trends are quite similar for math and reading performances (Figure 3). 24 The 75-25 gap for math narrows slightly over time. In reading, the disparity increases slightly over the entire period. The overall conclusion remains: the aggregate trend shown in Figure 2 does not mask different trends across subjects. Trends in achievement gaps are also quite similar for younger and older students. Appendix  Figure A8). The finding of little change in SES-achievement gaps can be viewed from two different vantage points. On the one side, we do not perceive any trend similar to that reported in Reardon (2011b), which shows large increases in gaps between the two extremes of the distribution. On the other side, we do not find any overall narrowing in achievement gaps despite a half-century of educational programs designed to win a \"war on poverty.\""}, {"section_title": "Trends in Achievement Levels", "text": "The disappointing lack of improvement in the distributional patterns might be less of a concern if they were offset by improvements in the overall level of achievement. Using the longitudinal data on student outcomes, we can directly evaluate whether there are gains in student achievement and, if so, whether they are general or isolated gains. Figure 5 reports the nonlinear trend in achievement levels, as estimated by equation 1 There is significant heterogeneity in the trends in achievement levels by subject Importantly, the trends in SES-achievement gaps considered earlier are essentially the same for both the younger and older students. As shown in section 5.1, we detect very little temporal change in achievement gaps in both cases regardless of subject matter."}, {"section_title": "Methodological Issues and Robustness", "text": "The clear pattern of SES-achievement gaps conflicts both with past work and with common perspectives on compensatory policy actions. To show its robustness, we trace through a variety of methodological and data issues. We begin by showing that our main findings are confirmed when estimated based on student eligibility for subsidized lunch programs and when considering changes in the ethnic composition of the population. We then address several methodological issues in estimating SES-achievement gaps from categorical data, showing robustness to alternative methodological choices. We discuss limited information in some observations of the SES tails and show robustness to an expansion of test observations when considering the 70-30 rather than the 75-25 SES gap. We also show robustness in an alternative point estimation approach to estimating SES gaps. Relatedly, we discuss the measurement error from extrapolating beyond the observed SES range in Appendix C. Finally, we show that basic conclusions are unchanged when treating achievement data as ordinal, i.e., only having rankorder interpretation."}, {"section_title": "Achievement Gaps by Eligibility for Free and Reduced-price Lunch Programs", "text": "Participation in federal lunch programs provides an alternative, income-based proxy to measure students' SES. Data available in the Main-NAEP allow us to estimate gaps in performance between students who are eligible and those who are not eligible for participation in the federal free and reduced-price school lunch programs at school for cohorts born between 1982 and 2001. Students who come from households at or below 130 percent of the poverty line are eligible for free lunch (whom we refer to as extremely poor), while those from households between 130 and 185 percent of the poverty line are eligible for participation in the reducedprice lunch program (whom we refer to as poor). In Main-NAEP, the indicator of eligibility for these federal programs is obtained from administrative records. Analyzing eligibility for subsidized lunch has important limitations. First, it is dichotomous, dividing the distribution at a point near its mean, so it does not allow for estimation near the extremes of the continuum. Second, the share of the population participating in the free lunch program increases over time for a combination of reasons that include administrative changes in the programmatic rules that allowed new eligibility certification and allowed entire schools to participate in the program. For example, comparing academic years 1999 and 2015, the percentage of children below 200 percent of poverty was virtually identical (39 percent), but the percentage in the free and reduced-price lunch program increased from 37 to 52 percent (Chingos (2016); Greenberg (2018)). For these reasons, we regard this variable as only a crude SES indicator, but it does provide a direct (albeit imperfect) measure of household income over part of the time period. When measured by subsidized lunch eligibility, the gap between the extremely poor students and other students in the 1982 birth cohort is a sizeable 0.71 s.d. (Figure 6). When the extremely poor are combined with the poor eligible for reduced-price lunch, the gap for this cohort is nearly as large-still 0.64 s.d. Over the next twenty years, the gap between the extremely poor and students from families above the eligibility line narrows by 0.06 s.d. and the gap between ineligible students and all those eligible for participation in one of these federal programs narrows by 0.01 s.d. Just like the results based on the SES index, this measure of the incomeachievement gap reveals only miniscule change over the course of two decades. We do not find this binary measure of family income to be the most appropriate way to look at trends, particularly given the changing definition of eligibility discussed above. Nonetheless, these results are entirely consistent with the trends for the 75-25 SES-achievement gap."}, {"section_title": "Black-White Achievement Gaps and Consideration of Ethnic Composition", "text": "As discussed at the end of section 2.2 above, changes in the ethnic composition of the U.S. student population mean that changes in the black-white gap can provide only a limited picture of changes in the SES-achievement gap. But separate estimation of changes in the SESachievement gap for white and black students allows us to show robustness of our main finding to consideration of changes in the ethnic composition. Black-white achievement gaps. We use NAEP data to estimate trends in the black-white test-score gap. In terms of racial differences, both the LTT-NAEP and Main-NAEP use schooldistrict administrative data to classify students by their racial and ethnic background. 29 We do not track disparities for other ethnic groups. Continuous immigration has substantially altered the composition of Asian and Hispanic populations over the past 50 years, complicating comparisons of test performance for these groups over time. Our results on the black-white test-score gap in Figure 6  To see whether trends in achievement gaps are driven by shifts in ethnic composition, we estimate the SES-achievement gap for both white and black students separately (Figure 7). These calculations use the overall national SES distributions for both (i.e., the same as used in the aggregate 75-25 SES analysis above). Interestingly, the SES gaps for both whites and blacks increase modestly by about 0.1 s.d. over the past twenty years. This increment occurs at a time when the percentage of both whites and blacks in the upper ranges of the SES distribution has increased (Appendix Table A3). The percentage of blacks in the bottom 25 percent of the distribution has declined even more rapidly than the white percentage. Altogether, there is little evidence that changes in the ethnic composition of student cohorts account for the unwavering SES-achievement gap."}, {"section_title": "Limits of Categorical SES Information and Extended Observations for 70-30 Gap", "text": "When estimating gaps between groups at the tails of the SES distribution, one needs response categories to survey items that distinguish between those who are at the tail of the distribution from those who are not. Otherwise, serious potential for measurement error may be introduced by including observations that are outside the portion of the distribution under investigation. As indicated in section 4.2 above, the SES index that we use to estimate the SESachievement gaps is constructed from survey information on parental education and home possessions (see Appendix A for details). There In the data sets underlying our analysis, the potential for this type of measurement error resulting from limited categorization of the SES distribution is particularly severe for some administrations of the Main-NAEP survey, although it comes up also in the LTT-NAEP. A couple of examples chosen for illustrative purposes can document the range of available detail in SES measurement. 31 In 1990, the first year for Main-NAEP, students were asked to place their parents within one of four education categories and whether they had each of only four items in 31 Appendix A provides a fuller description of the range of parental-education and home-possession information available in the separate test administrations. In general, there is little variation in the measurement of parental education but more variation in the measurement of home possessions. However, most of the variation is between assessment regimes-with richer home-possession information in TIMSS and PISA than in LTT-NAEP and Main-NAEP-rather than within assessment regimes. These between-regime differences are taken out in our trend estimation that contains regime fixed effects. To ascertain that differences in the number of parental-education categories and home-possession items do not affect our overall results, we included both counts as control variables in our trend estimation of the SES-achievement gap. Neither the number of parental-education categories nor the number of home-possession items enters the trend estimation significantly, and the estimated birth-year trend remains statistically insignificant (not shown). their home (see left panel of Appendix Table A4 for specific survey items). As a consequence, when we construct our SES index based on these two measures, no less than 26.5 percent of the students that Main-NAEP tested in 1990 are identified as being in the top SES category, making it difficult to obtain a precise estimate of those in the top quartile of the distribution. Similar problems emerge for other surveys in early administrations of both the Main-NAEP and LTT-"}, {"section_title": "NAEP.", "text": "This limited categorical information contrasts sharply with other survey implementations. For example, the PISA survey in 2015 inquired about seven parental-education categories and the presence of twenty-two items in the home (right panel of Appendix Table A4). As a result, just one percent of the sample falls into the top SES category in the PISA 2015 survey. Figure 8 shows the frequency distribution for distinct categories identified along the continuum of our constructed SES index for the two example surveys. The tall spike at the top end of the Main-NAEP 1990 SES distribution represents the 26.5 percent of the sample falling in the top SES category that can be observed. The more granular description of the SES distribution in the PISA 2015 data derives from the greater number of parental-education and home-possession categories in that survey. These examples illustrate the reason why our main analysis excludes any test administration where more than a quarter of observations fall in the top category of our SES index, reducing the number of included SES gap observations from 96 to 81 (section 4.2). That is, the Main-NAEP 1990 observation just described is not included in our analysis above. To investigate whether the gap trend estimation is sensitive to the reduction in underlying observations, we estimate gaps for the slightly expanded tails of the 70 th and 30 th percentiles of the distribution, which are identified in several additional test administrations (including the Main-NAEP 1990 example) compared to the 75 th and 25 th percentiles. In particular, analysis of the 70-30 distribution allows us to reliably observe the relevant tails of the distribution in 91 (of the potential 96) observations. Analysis of the expanded set of observations on the 70-30 gap confirm our main results for the 75-25 gap. The markers on the trend lines in Figure 9 indicate the years for which an assessment is available, showing the increase in information from 81 to 91 observations. The 70-30 gaps are necessarily slightly smaller than for the interquartile range. More importantly, the trend line for this expanded sample remains essentially flat. Both individually and jointly, it is again not possible to reject the null that the coefficients for the linear and quadratic terms in the trend equation are zero (F(2, 82)=1.05)."}, {"section_title": "Group Calculations vs. Point Estimation of Gaps", "text": "Our main analysis provides a grouped SES-achievement comparison based on estimates of the average performance of students within a specific segment of the SES distribution. In particular, we consider the average performance of students whose families fall in the top quartile of the SES distribution compared to those in the bottom quartile (section 4.2). By focusing on this comparison, we do not have to characterize the precise pattern of achievement within the extremes of the SES distribution. An alternative approach-used, for example, in Reardon (2011b), Chmielewski and Reardon (2016), and Chmielewski (2019)-is to compare achievement at specific points in the SES distribution, such as the estimated achievement of somebody exactly at the 25 th percentile or the 75 th percentile. This approach involves two steps. The available data provide the average achievement for a given category of SES values, i.e., for a range of SES percentiles. The first step is to identify a specific SES percentile that corresponds to the average score observed in each SES category. While there is no information within the assessment data that would guide this choice, a convenient approximation used in the prior analyses is to assume that the midpoint of the SES percentile range corresponds to the average achievement of that SES group (which amounts to a linearity assumption within each SES category). For example, for the 26.5 percent in the top SES category of the 1990 Main-NAEP distribution (discussed in the previous section), the average achievement is assumed to be an accurate estimate of the performance of students at the 86.75 th percentile. The second step employs a linear or cubic regression function to estimate the SES-achievement relationship through all available SES data points observed for each testsubject-age-year observation. This approach assumes that all of the data points in the center of the SES distribution are useful in predicting achievement in the tails of the distribution. With this regression function, achievement is predicted at the respective SES percentiles of the gap under consideration. As a robustness check, we implement this alternative point estimation approach to estimate 75-25 SES-achievement gaps in our data. We use an estimated cubic function for each testsubject-age-year data to define the relevant SES-achievement gaps. We predict achievement at the 75 th and at the 25 th percentiles of the SES distribution and calculate the gap between the two. We also use this method to expand the analysis to all 96 available test-subject-age-year observations. As Figure 10 shows, the point estimation approach yields similar results to our main approach. The estimated 75-25 SES gap is essentially flat over time, with a very small downward trend that is statistically and quantitatively insignificant. As these gaps refer to the achievement difference between individuals at the 75 th and 25 th percentile of the SES distribution, rather than to the difference between the average achievement of those above the 75 th and below the 25 th percentile, their magnitude is obviously lower compared to the main analysis. 32"}, {"section_title": "Ordinal Analysis of Achievement Data", "text": "Prior research on achievement gaps most frequently treats test-score information as interval data. With that assumption, numerical differences in test scores at any point in the distribution, usually expressed in standard deviations, can be treated as equivalent to one another. However, some research has suggested that this assumption can lead to over-interpretation of achievement differences from standardized tests and has advised relying on an ordinal (rank-order) interpretation of test scales instead (e.g., Ho (2009); Bond and Lang (2013); Nielsen (2015)). To understand better the potential impact of an ordinal approach versus the cardinal approach we previously employed, we consider illustrative examples of trend analysis in SESachievement gaps over time using only ordinal, rank-preserving assumptions of test-scale information. We again distinguish two groups of students, those in the bottom and top quartiles of the SES distribution, and now create the score distributions for both groups. For each percentile of the achievement distribution of the low-SES group, we can calculate the share of students in the high-SES group whose achievement is at or below the low-SES percentile's indicated achievement. 33 We plot these two achievement distributions against each other. If there was an equal achievement distribution for the top and the bottom quartile of the SES distribution, this plot would appear as a 45-degree line-just as with a Lorenz curve. 34 The greater the divergence from this line, the greater the inequality. Performing the same analysis on tests at different points in time allows for an assessment of the change in inequality over time that does not depend on interval interpretations but uses just the rank information in the tests. As the analysis requires a clear distinction of the two SES groups at the respective SES quartiles, we perform the analysis for the PISA and TIMSS tests, but-for the reasons indicated above-refrain from analysis of the NAEP data with this approach because of the lumpiness of the SES distributions. These ordinal analyses yield conclusions very similar to our main analysis reported above. For example, using the earliest and latest installment of the PISA test, the top panel of Figure 11 shows that the 2015 distribution is considerably more equitable than the 2000 distribution, as the distance of the curved line from the 45-degree line for that year encloses much less space than the curved line for 2000. The implied reduction in inequality confirms the results of our main analysis for PISA math gaps discussed in Section 5.1 and shown in Appendix Figure A7. The bottom panel of Figure 11 shows a similar change in the inequality when comparing students in the top half to those in the bottom quarter of the SES distribution. Using the TIMSS data, Figure   12 indicates a slight increase in inequality between 1995 and 2015, just as had been implied by the interval analysis shown in Appendix Figure A6. Thus, for both PISA and TIMSS, the ordinal analysis that treats the assessment data as ordinal rankings confirms the trends in inequality estimated in our main analysis that assumes interval interpretability of the underlying scores."}, {"section_title": "Conclusions", "text": "Our analysis of long-run trends has shown that performance disparities within the United States are both large and highly persistent. The SES-achievement gap remains essentially as large as in the mid-1960s when James Coleman wrote his report on Equality of Educational Opportunity and the United States launched a national \"war on poverty\" in which compensatory education policies were the centerpiece. In terms of learning, students in the top quarter of the SES distribution continue to be around three years ahead of those in the bottom quarter by eighth grade. The constant disparity is not relieved by rising levels of achievement for all students at the end of their secondary education. Students in their early adolescent years show achievement gains over the past half century, making them better prepared for entry into high school. But at least over the past quarter century, these achievement gains disappear by the age of 17, just as students reach the point of entering college or the labor market. Our findings are consistent with a variety of combinations of demographic changes and policy shifts that have occurred over the past half century. The flat trend could be due to the absence of relative change in the family and school inputs for students in the top and bottom parts of the SES distributions, due to offsetting trends in society that counter-balance one another, due to growing inequalities in society offset by equalizing policies, or due to equalizing trends in society offset by inegalitarian policies. While the aggregate trend data currently available do not allow us to provide definitive evidence to choose among these possibilities, let alone identify the underlying causal relationships, we can summarize some of the potential mechanisms suggested in the literature. On the family side, differential trends in inputs at the top and bottom tail of the SES distribution are conceivable. On the one hand, there is a trend towards increasing disparity in household income and wealth within the United States, in particular at the very top end of the distribution (e.g., Krueger (2003); Autor (2014); Saez and Zucman (2016); Alvaredo et al. (2017)). In addition, SES differences in the incidence of single-parent households and in the age of mothers at the birth of the child may have increased over time (Duncan, Kalil, and Ziol-Guest (2017)). On the other hand, SES differences in parental education and in the number of siblings in the household-two factors consistently identified as important determinants of student achievement-have narrowed over time. Improvements in nutrition, health, and general economic well-being may also have disproportionately occurred in low SES households. Differential trends are also conceivable on the policy side. Obviously, a long list of programs has been introduced with the intention of closing SES-achievement gaps. These programs include, for example, racial school desegregation following the 1954 Supreme Court decision in Brown v. Board of Education, particularly in the South (e.g., Rivkin and Welch (2006), Rivkin (2016)); compensatory funding of schools under Title I of the Education and Secondary Education Act of 1965 (e.g., Cross (2014)); expanded special education programs starting with the 1974 Education for All Handicapped Children Act (e.g., Morgan, Farkas, Hillemeier, and Maczuga (2017)); state court decisions mandating greater fiscal equity (e.g., Peterson and West (2007), Hanushek and Lindseth (2009) We cannot resolve the relative importance of the countervailing trends in family and policy inputs here. Our goal is just to clarify the pattern of SES-achievement gaps that guides many policy discussions. On the one side, we reject the often-raised claim that the SES-achievement gap is widening in the United States. We find almost no evidence at all for this proposition. On the other side, suggestions that the SES-achievement gap is closing are premature. While PISA data, considered in isolation, may be cited to support such claims, its findings are not corroborated by results from the other three test regimes, each with high-quality psychometrically linked assessments of student performance. We also cannot explain the puzzling pattern of differing trends of achievement levels at different ages, in particular because previous research rejects a number of methodological explanations (Blagg and Chingos (2016)). The bottom line of our analysis is simply that-despite all the policy efforts-the gap in achievement between children from high-and low-SES backgrounds has not changed. If the goal is to reduce the dependence of students' achievement on the socio-economic status of their families, re-evaluating the design and focus of existing policy programs seems appropriate. As long as cognitive skills remain critical for the income and economic well-being of U.S. citizens, the unwavering achievement gaps across the SES spectrum do not bode well for future improvements in intergeneration mobility."}, {"section_title": "Appendix A: Measuring Socio-economic Status", "text": "To be able to observe percentiles of the SES distribution in each survey and year, we construct a continuous measure of SES. A single composite measure of SES allows us to identify the interquartile range of the SES distribution, which provides a clearer picture of the impact of SES on student achievement than the use of ever-changing categorical groups. None of the intertemporally linked surveys include indicators of earned income or other household receipts other than the free and reduced-price lunch indicators in NAEP surveys, and only the PISA survey contains information on parental occupation. Thus, we measure SES by use of an index that includes levels of parental educational attainment and the amount and variety of durable and educational goods available within the household. In a separate survey with parentreported income data, the index is highly correlated with an estimate of permanent income."}, {"section_title": "The PISA Index of Economic, Social, and Cultural Status (ESCS)", "text": "Across the different PISA waves, the OECD provides a measure of socio-economic status called the PISA Index of Economic, Social, and Cultural Status (ESCS). The ESCS, according to the PISA 2015 Technical Report, is \"a composite score built by the indicators parental education (pared), prestige of the occupation of the parent with the highest occupational ranking (hisei), and home possessions (homepos) including books in the home via principal component analysis (PCA)\u2026. The rationale for using these three components was that socio-economic status has usually been seen as based on education, occupational status and income. As no direct income measure has been available from the PISA data, the existence of household items has been used as a proxy for family wealth\" (OECD (2017b)). To compute the ESCS index, PISA uses a combination of highest parental education (in years), parental occupation (transformed into an International Socio-Economic Index of Occupational Status (ISEI), see Ganzeboom and Treiman (2003)), and home possessions (derived from ten to fifteen yes/no questions such as \"Do you have a desk to study at in your home?\" and three to five questions such as \"How many cars do you have at your home? (None, one, two, three or more)\", see Appendix Table A4 for further examples). PISA standardizes the three variables, performs a PCA, and defines ESCS as the component score for the first principal component. Materials in the home included in PISA 2000 included the following: dishwasher, own bedroom, educational software, a link to the Internet, a dictionary, a quiet place to study, a A2 desk, textbooks, classic literature, books of poetry, and works of art. In PISA 2015, the items included the number of personal computers and cell phones in the home. The benefit of using this method to investigate trends by socio-economic status, rather than simply using one or a combination of categorical variables like eligibility for national school lunch programs, parent education, or books in home, is that it can account for changes in the share of students within these categories over time. In any of these categorical variables, shifts in culture and technology can alter the distribution of students between categories over time, reducing the validity of their use as proxies for SES. For example, the proportion of students having no books in their home versus over 200 books in their home has changed dramatically during the past fifteen years (Appendix Figure A11, Panel A). Meanwhile, the proportion of children with internet access has increased to almost 100 percent, rendering the variable useless if used on its own (Panel B)."}, {"section_title": "Our SES Index", "text": "In the construction of our SES index, we follow closely the spirit of PISA's ESCS index, making appropriate adjustments to enable implementation in all our four surveys. Neither NAEP nor TIMSS provide a similar index, although NAEP is considering adding a similar measure to their series (see National Center for Education Statistics (2012b)). Therefore, we construct a comparable SES index for the four underlying surveys ourselves. While we make adjustments to synchronize with the other surveys in our analysis that do not include all the information available in PISA, using the PISA data we show that our SES index is highly correlated with PISA's ESCS index. Our SES index differs from the PISA ESCS index in the following ways. Parental education. Instead of using the highest parental education in years (pared), we use the categorical variable of highest parental education (hisced) to construct our index. Hisced and pared have the exact same distribution, but instead of being measured in years of education, hisced is measured categorically on the International Standard Classification of Education (ISCED). We choose to use hisced instead of pared for consistency with the other two assessments, which both measure highest parental education on the ISCED scale, so that we do not have to rely on a potentially error-prone transformation into years of education. In all LTT-NAEP and Main-NAEP waves, parental education is measured in four categories (see Appendix Table A4). PISA always uses seven categories. TIMSS mostly uses five A3 categories, with the exceptions of the first two waves, where it is three and four categories, respectively. Parental occupation. Unlike PISA, the student questionnaires in NAEP and TIMSS do not include measures of the parents' occupations that would allow for estimating occupational prestige (hisei). We therefore exclude measures of parents' occupations from our index. Though it is unfortunate to lose this element in our measure of socio-economic status, the category is largely redundant of the education and income items that remain in the index, as the prestige of an occupation is estimated from the education and income of the average member of the occupation. Estimations of the SES-achievement gap in the PISA data set closely resemble estimates obtained when PISA's ESCS index is employed (see below). Home possessions. To create ESCS, the OECD uses an index of home possessions (homepos) which is \"a summary index of all household and possessions items\" (OECD (2017b)). NAEP and TIMSS include similar questions about students' home possessions, but they do not provide a summary index. For all estimations of SES, we therefore use a simple sum of the home possessions variables as our indicator of home possessions (homepos). That is, we simply add up each of the home possessions students report owning (across both dichotomous and categorical questions) and use this number as our homepos variable in the specific survey and year. 35 There is some variation in the number of available categories of home-possession items, in particular between the two NAEP assessments and the two international assessments but also within assessment regimes over time. In LTT-NAEP, the number of home-possession items is four in the first two 1970s waves, up to eleven in the next two waves, down to four and six in the subsequent two, and steady at seven ever since 1998. In Main-NAEP, it is between four and six in the 1990s, between five and eight in the 2000s, and between six and nine in the 2010s. The available information on home-possession items is much larger in TIMSS and PISA throughout. In TIMSS, it is twenty in the two waves of the 1990s and between eleven and thirteen in the subsequent four waves. In PISA, it is 38 in 2000, 28 in 2003, and between 44 and 46 in the subsequent four waves (all reported numbers refer to the sum of possible item counts across the dichotomous and categorical questions; see Appendix Table A4 for examples). 36 Construction of the index. Using homepos and hisced, we simply follow the ESCS construction process of performing PCA and assigning each student the first principal component as a composite score. In the construction, we differ slightly from the ESCS process in the treatment of missing variables. The OECD treats missing variables in the following way: \"For students with missing data on one out of the three components, the missing variable was imputed . Regression on the other two variables was used to predict the third (missing) variable, and a random component was added to the predicted value. If there were missing data on more than one component, ESCS was not computed and a missing value was assigned for ESCS\" (OECD (2017b)). As this method requires the assumption of a positive, linear relationship among the variables and in any case only applied to 2 percent of the observations, instead of imputing missing variables we choose to discard them from the analysis. Comparing our SES index to the PISA ESCS index. The joint impact of these alterations is the construction of an index that remains highly correlated with the PISA ESCS index. When we calculate both our SES index and PISA's ESCS index within the same PISA data set, the overall correlation between the two is 0.876. It ranges from 0.87 to 0.91 when broken down by years. Because we are interested in examining trends for students at the tails of the distribution, we compare trends in the top and bottom quartiles, respectively, in PISA using both the ESCS and our SES index. No qualitatively significant differences between the trends estimated by the two indices are observed (see Appendix Figure A2)."}, {"section_title": "SES Index and Earned Income", "text": "To estimate the relationship between our index and family income, we use data from the 1988 and 2002 Education Longitudinal Study (ELS), which contain home possessions variables (quite similar to those in PISA), parent education, and income. Annual income, obtained from 36 Note that because our main analysis excludes test administrations where the top category of the constructed SES index includes more than a quarter of the population, most of the test administrations with very few homepossession items are not included in our main analysis. In particular, with the exception of only one test administration that has four home-possession items, all test administrations included in our main analysis have at least six home-possession items."}, {"section_title": "A5", "text": "parent questionnaires, is defined as \"total family income from all sources [for the previous calendar year]\", reported in thirteen categories ranging from \"None\" to \"$200,001 or more.\" In the 1988 ELS, family income is available on the base year survey (1987 income) and on the second follow-up survey (1991 income). We built the SES index in the same way as in our main analysis (using parental education and home possessions). The correlation between the SES index and reported family income is displayed in Appendix Table A6. The two variables are strongly but not perfectly correlated. Interestingly enough, at 0.66 the SES index is more highly correlated with the average of the annual earnings estimates obtained in 1987 and 1991 than with either of the annual estimates, suggesting that the average is a better measure of permanent income, a concept similar to socio-economic status. 37 gap has grown by roughly 40 to 50 percent \u2026, a very sizeable increase\" (p. 97). Elsewhere, he describes this increase as \"roughly 30 to 40 percent\" (p. 93). Unfortunately, his analysis does not reflect the overall impact of the data problems, many of which he himself identifies in an appendix (Reardon (2011a)). There are two strands of evidence indicating that the perceived trends are not real but instead are a function of measurement error. First, in a significant portion of constructed gaps household income is very poorly measured; in another portion the test instruments themselves are quite suspect; and in a final set survey sampling and missing data become serious issues. When surveys at high risk of serious measurement error are excluded, no upward trend in the incomeachievement gap is observed. Second, comparisons of gap differences among psychometrically matched observations that cover the relevant period of supposed steep gap increases reveal no upward trend."}, {"section_title": "Data Quality Issues", "text": "Survey researchers have not found it easy to collect accurate data on family income, the independent variable in the regressions that Reardon uses to create the gap estimates for each survey. As discussed in section 2.1 above, the challenge is especially large when household income is estimated from student-provided information (Kayser and Summers (1973); Fetters, Stowe, and Owings (1984); Kaufman and Rasinski (1991)). In Reardon's analysis, seven of the eight earliest estimations of the income-achievement gap are based upon \"family income \u2026 reported by students rather than by a parent\" (p. 95). Given the dependence on student reports, it is almost certain that these seven observations measure the income-achievement relationship with much greater error than the subsequent studies that collect income information directly from parents. In the construction of observations for SESachievement gaps, these errors will bias the income-achievement relationship toward zero and will yield downward-biased data points on gaps. The improvement in data collection techniques over time then contributes to the appearance of a rising income-achievement gap when none exists. Six of his twelve surveys are plagued with serious problems and clearly do not meet current scientific quality standards. Importantly, these surveys introduce systematic measurement error into the subsequent trend estimation based upon them. From the information provided in A8 Reardon (2011aReardon ( , 2011b and the online descriptions, these surveys do not provide reliable data points but nonetheless have a decided influence on the shape of the estimated trend line."}, {"section_title": "Project Talent", "text": "Talent, the earliest survey, provides estimated gaps for four cohorts born in 1942-1945. It uses student-provided estimates of family income, employing five income categories. 39 While there are questions about the sampling in the Talent survey, the largest concerns relate to nonresponse rates to the question concerning family income. No less than 54 percent of the freshmen, 50 percent of the sophomores, 45 percent of the juniors, and 39 percent of the seniors chose not to \"guess\"-the word used in the survey-the answer to the family income question. For the early Talent cohorts born in the early forties, Reardon reports income-achievement gaps in reading and math of approximately 0.75 s.d. Only Prospect, which has its own measurement problem (see below), reports gaps of a similarly low magnitude."}, {"section_title": "National Longitudinal Study of 1972 (NLS)", "text": "The National Longitudinal Study of 1972 was an early survey conducted by the National Center for Education Statistics. It was designed to follow a sample of high-school seniors of the Class of 1972 into the labor market and college. Like Talent, its parental-income measure came from sampling the students, who place estimated income into one of ten categories. 40 Twentyone percent of the respondents chose not to respond to this question."}, {"section_title": "High School and Beyond (HS&B)", "text": "The High School and Beyond study collected income data for birth cohorts in 1962 and 1964. An important element of these surveys was a 15 percent sample that collected income data from both a parent and the student. These data were particularly important in the analysis because they provided estimates of the impact of student-provided income data. Unfortunately, the parent-provided income data lacked face validity, being considerably above the comparable values from the Current Population Survey (CPS). 41 Reardon uses these parent-provided data to estimate reliabilities for the student-provided data. He concludes that the student data are more reliable than the parent data. Partly because of this and partly because of sample sizes, he uses the student-provided data from HS&B to estimate the income-achievement relationship and the subsequent SES-gap points for the trend analysis. To get some sense of the impact that measurement error can have on estimates of the income-achievement gap, one can compare HS&B estimates to those observed in NLSY79, which was administered to birth cohorts of students that overlapped with those observed in HS&B. 42 NLSY79 is much less likely than HS&B to err in its estimation of household income. The highly-regarded NLSY79 protocol, administered to parents, obtains household income as a continuous variable with just a 2 percent non-response rate. In contrast, the student-provided HS&B data are categorical and have non-response rates of 13 and 18 percent of seniors and sophomores, respectively. Because of the differential measurement error, it is not surprising that the average of the math and reading income-achievement gaps identified in the NLSY79 survey is 1.3 s.d., which is fully 0.35 s.d. higher than the gap reported in the HS&B survey."}, {"section_title": "The Congressionally Mandated Study of Educational Growth and Opportunity (Prospects)", "text": "Problems with the seldom-used Prospects survey are noted in Reardon (2011b), p. 112, note 70: \"It is difficult to find documentation on the content and psychometric properties of the Prospects tests. These tests may be much less reliable than other tests; as a result, I am inclined to discount their importance in describing the trends.\" Contrary to that statement, Reardon uses three observations from Prospects to estimate trend lines in both math and reading, while six other studies yield only one observation. 43 The estimates of the income-achievement gap from Prospects vary widely across the three cohorts surveyed at the same time-by 0.3 s.d. in math and 0.35 s.d. in reading. All three of the 41 Reardon (2011a) reports the difficulties with the complex survey: \"In HS&B, parent-reported family income is measured using a set of survey questions, rather than a single question, as in other studies. The responding parent-usually the mother-was asked 1) how much wage income s/he received; 2) how much self-employment income s/he received; 3) how much wage income his/her spouse received; 4) how much self-employment income his/her spouse received; and then 5) a set of 15 questions asking how much the respondent and spouse together received from other sources, including dividends, interest, rent, alimony, AFDC, SSI, etc.\" As a result, average income from the sum of parental responses is 33 percent above that reported in the CPS at the 90 th percentile. 42 NLSY79 surveyed cohorts born in 1961and 1963, while HS&B surveyed those born in 1962and 1964 Only one birth cohort is observed with data from NLS, NELS, ELS, SECCYD, ECLS-K, and ECLS-B. Prospects estimates are much lower than the 1.3 s.d. gap obtained from NLSY97 administered at about the same time. In other words, estimates for the income-achievement gap for cohorts born within a couple of years of 1980 vary by no less than 0.6 s.d. Measurement error is the most likely explanation for this spread in estimates made at close to the same time."}, {"section_title": "National Longitudinal Study of Adolescent to Adult Health (Add Health)", "text": "Add Health contains no math achievement data, but the study contributes over a third of the Each image plate contains 4 black-and-white drawings, one of which best represents the meaning of the corresponding stimulus word. \u2026 Starting in 1998, the administration of the PPVT-R was largely limited to 4-and 5-year-old children\". 44 Reardon makes use of the results of Add Health's PPVT scores for six of the 17 observations used to estimate the growth in the reading gap for cohorts born between 1974 and 2001. But PPVT asks respondents to point at a picture when told a word. No reading is involved. Add Health provides low estimates of the income-achievement gap in reading for students born between 1978 and 1983 when that gap is alleged to be much lower than in later years. Those lower estimations could easily be due to serious measurement error driven by a test of reading skills that does not require the student to read."}, {"section_title": "Study of Early Child Care and Youth Development (SECCYD)", "text": "Although Reardon says his surveys are nationally representative, SECCYD is not. According to U.S. Department of Health and Human Services (2018), the study recruited ten hospitals willing to participate as recruiting grounds for mothers willing and available to participate in a multi-year study. The sample description explicitly says its \"data are not representative in the statistical sense, and therefore inference to the nation as a whole is not possible. Comparisons to other databases, national or otherwise, should be made with extreme caution.\" 45 The website for SECCYD identifies use of the Woodcock-Johnson Tests, which are designed to be IQ tests. It is not clear how these might translate into the reading or math achievement tests found in the other surveys. In any event, the survey does not meet the criterion of being nationally representative."}, {"section_title": "Trends in the SES-Achievement Gap from High-quality Surveys in Reardon (2011b)", "text": "With reliance on SES-achievement gap data constructed from different birth cohorts found in large-scale surveys, it is natural to want to include as many different survey data sets as possible. As delineated above, however, six of Reardon's choices do not meet current scientific quality standards. The three early surveys rely upon student reports of household income (Talent, NLS, and HS&B); three later surveys lack reliable test information and/or pertain to non-representative samples (Prospects, Add Health, and SECCYD). These error-prone data points yield gap estimates that are biased downward. Since they tend to relate to early birth cohorts, they distort the trends that are estimated when combined with higher-quality data available later. We estimate a revised trend line using Reardon's data that restricts observations of gaps to the high-quality surveys in Reardon (2011b). These cover the birth cohorts 1961-2001 (NLSY79 [two cohorts], NELS, NLSY97 [three cohorts], ELS, ECLS-K, and ECLS-B). We supplement these limited observations with an additional observation added from Reardon and Portilla (2016) who update the SES-achievement gap analysis to include the ECLS-K2010. 46 (The 45 https://www.icpsr.umich.edu/icpsrweb/DSDR/studies/21940/versions/V6/summary [accessed 2/1/2020]. 46 While the three ECLS data sets are included among the high-quality surveys, their outcome data are tests of kindergarten readiness in math and reading. Reardon and Portilla (2016), who specifically analyze trends in these ECLS-K2010 observation became available subsequent to the publication of Reardon (2011b) and extends the birth cohorts available to 2005). Appendix Figure A1 replicates the Reardon analysis of estimated 90-10 incomeachievement gaps in math and reading for the birth cohorts 1961-2005 using only the highquality surveys. 47 All of these data come from well-regarded, nationally representative surveys that obtained income information from parents rather than students. One striking fact emerges from this figure: Simple linear regressions that estimate trends in math and reading from the ten observations taken from these surveys show perfectly flat trends with no significant change in the income-achievement gap over this time period."}, {"section_title": "Trends from Two Sets of Psychometrically Linked Surveys", "text": "One concern with the overall approach in Reardon 2011b If the income gap had truly increased, it should be evident in these two intertemporally linked surveys. But, at roughly 1.3 s.d., the average income-achievement gap in math and data, argue that these SES-achievement gaps are comparable to those for later ages in the other surveys because gaps do not change much over the school years. 47 The point estimates are estimated from observation of the points displayed in Reardon (2011b), Figures 5.1 and 5.2. Reardon and Portilla (2016) provide estimated gaps from the three ECLS surveys. 48 Household income is measured in the same way in the two surveys, and the non-response rate for NLSY97 is 3 percent, about the same as the 2 percent for NLSY79."}, {"section_title": "A13", "text": "reading estimated by NLSY97 is no different from the one observed twenty years earlier. Over the twelve years between the administration of ECLS-K and ECLS-K2010, the 90-10 math achievement gap, as reported by Reardon and Portilla (2016), declines by 0.13 s.d. and the gap for reading drops by 0.21 s.d. 49 Neither set of observations reveals any increase in the income-achievement gap. Reardon (2011b) concedes that \"the income achievement gap as measured in the NLSY97 cohort is virtually identical to the gap in the NLSY79 cohort, born twenty years earlier\" (p. 96). But, he says, \"the NLSY cohort was born in the early 1980s, just as the trend\" upward is about \"to begin\" once more. This survey was administered too soon to discern \"a rising gap among the 1980s and 1990s cohorts.\" The ECLS data, analyzed in Reardon and Portilla (2016), removes uncertainty about whether or not the NLSY comparison was simply due to observations outside the relevant range."}, {"section_title": "Conclusion", "text": "Both estimates from all high-quality surveys (Appendix Figure A1) and those from psychometrically matched surveys indicate no substantial change in the income-achievement gap in math and reading over time. The size of the gap remains constant at roughly the same level as the SES-achievement gap reported in this paper, indicating that analyses based on different surveys and different underlying SES measures actually come to the same broad conclusion. In other words, the apparently contradictory results between our analysis of SES-achievement trends and those of Reardon (2011b) are completely resolved by recognition of the systematic measurement error embedded in specific surveys used in Reardon. regression function (linear or cubic) is estimated from all of the data points, and this function is evaluated at the 90 th percentile. This step assumes that the pattern of achievement farther down the SES distribution provides a good reflection of the SES-achievement distribution in the tails of the SES distribution. Appendix Figure A10 shows the fitted linear and cubic regressions following this procedure. Even accepting the underlying distributional assumptions in the two steps, the estimated achievement of a person at the 90 th percentile would differ between the linear and the cubic extrapolation by 0.14 s.d., even though the two alternative methods are very close in the midranges of the SES distribution. 50 The extrapolation uncertainty becomes particularly severe when the range of possible categories of the SES distribution observed in the tails is limited. The limited information in the tails is generally exacerbated when the SES distribution is constructed from a single variablefor example, categorical parental income in Reardon (2011b) or parental education in Chmielewski (2019). The bottom panel of Appendix Figure A10 shows the SES-achievement distribution for PISA 2015 when just parental education is used to identify the SES distribution (instead of the combined information on parental education and home-possession items in Figure   8). Fully 46 percent of the students are found in the top parental-education category, and 89 percent are in the top three categories. This is the information based on which achievement at the 90 th percentile is extrapolated in Chmielewski (2019)'s analysis of the PISA data. The problem of choosing a functional form for extrapolation is not very important with so few categorical observations, but the problem of what SES percentile corresponds to the average achievement in the broad categories is crucial. The single SES measure cannot adequately resolve this issue, but the choice can obviously lead to enormous differences in the extrapolated achievement levels and thus in the estimated SES-achievement gaps. In fact, the top education category averages over 40 percent across our entire sample of different assessments at varying times-implying it would be necessary to extrapolate out of range all of the achievement points when looking at either 75-25 or 90-10 SES-achievement gaps based solely on surveyed parental education. 50 When estimating 90-10 gaps, Reardon (2011b) and Chmielewski (2019) use a mixture of cubic projection modified to linear projection when there are greater than 20 percent of observations in the top or bottom category. This corresponds to whether the assumed data point in the respective category from the first step falls outside the top or bottom 10 percent of the overall distribution.  Notes: LTT-NAEP math data for 1973 are available for levels but not gaps.       Notes: 75-25 (90-10): overall achievement difference between the students at the 75 th and 25 th (90 th and 10 th ) percentiles of the achievement distribution. All tests administered by LTT-NAEP, Main-NAEP, PISA, andTIMSS. 1954-2001 birth cohorts, all subjects, all students. Normalized achievement is measured in standard deviations (of the installment of the respective test series closest to 2000). Each marker indicates years where there are one or more underlying observations. Achievement difference (standard deviations)  ) 1960 1965 1970 1975 1980 1985 1990 1995 2000 2005 birth year PISA 75-25 SES Gap Main-NAEP TIMSS LTT-NAEP-17 LTT-NAEP-13   Notes: Average student achievement. Sample: 1954-2001 birth cohorts, all surveys, all subjects, all students. Younger students are those between ages 13 and 15 or in 8 th grade, depending on the test. For expositional purposes, younger students are referred to as 14-year-olds. Older students are those aged 17 or in 12 th grade, depending on the test. See Figure 1 for data and methods.  "}]