[{"section_title": "Abstract", "text": "Developments in observing system technologies and ocean data assimilation (DA) are symbiotic. New observation types lead to new DA methods and new DA methods, such as coupled DA, can change the value of existing observations or indicate where new observations can have greater utility for monitoring and prediction. Practitioners of DA are encouraged to make better use of observations that are already available, for example, taking advantage of strongly coupled DA so that ocean observations can be used to improve atmospheric analyses and vice versa. Ocean reanalyses are useful for the analysis of climate as well as the initialization of operational long-range prediction models. There are many remaining challenges for ocean reanalyses due to biases and abrupt changes in the ocean-observing system throughout its history, the presence of biases and drifts in models, and the simplifying assumptions made in DA solution methods. From a governance point of view, more support is needed to bring the ocean-observing and DA communities together. For prediction applications, there is wide agreement that protocols are needed for rapid communication of oceanobserving data on numerical weather prediction (NWP) timescales. There is potential for new observation types to enhance the observing system by supporting prediction on multiple timescales, ranging from the typical timescale of NWP, covering hours to weeks, out to multiple decades. Better communication between DA and observation communities is encouraged in order to allow operational prediction centers the ability to provide guidance for the design of a sustained and adaptive observing network."}, {"section_title": "", "text": "Developments in observing system technologies and ocean data assimilation (DA) are symbiotic. New observation types lead to new DA methods and new DA methods, such as coupled DA, can change the value of existing observations or indicate where new observations can have greater utility for monitoring and prediction. Practitioners of DA are encouraged to make better use of observations that are already available, for example, taking advantage of strongly coupled DA so that ocean observations can be used to improve atmospheric analyses and vice versa. Ocean reanalyses are useful for the analysis of climate as well as the initialization of operational long-range prediction models. There are many remaining challenges for ocean reanalyses due to biases and abrupt changes in the ocean-observing system throughout its history, the presence of biases and drifts in models, and the simplifying assumptions made in DA solution methods. From a governance point of view, more support is needed to bring the ocean-observing and DA communities together. For prediction applications, there is wide agreement that protocols are needed for rapid communication of oceanobserving data on numerical weather prediction (NWP) timescales. There is potential for new observation types to enhance the observing system by supporting prediction on multiple timescales, ranging from the typical timescale of NWP, covering hours to weeks, out to multiple decades. Better communication between DA and observation communities is encouraged in order to allow operational prediction centers the ability to provide guidance for the design of a sustained and adaptive observing network."}, {"section_title": "INTRODUCTION", "text": "Sustained high-quality observations are essential for improving our understanding of the ocean and its interactions with the atmosphere and the overall Earth system. An important tool to study the Earth system is the production of historically accurate four-dimensional reconstructions of quantities that characterize the ocean state (such as temperature, salinity, and currents). Mathematical methods from the field of Data Assimilation (DA) allow information provided from observations to be propagated in time and space to unobserved areas using the dynamical and physical constraints imposed by numerical models. When these methods are applied to form the aforementioned historical reconstructions, this procedure is called a retrospective analysis, or \"reanalysis\" (Kalnay et al., 1996; Dee et al., 2014) . In addition to aiding in the study of the ocean itself, such reanalyses can also be used to initialize the ocean component of coupled Earth system models in order to produce long-term forecasts that may provide guidance from a few weeks out to a decade or longer (Meehl et al., 2014; Balmaseda, 2017) . Here, we review the current state-ofthe-art of DA applied to the ocean and collectively look forward over the next decade to make our own predictions about what kind of complementary in situ and satellite observations will be required to advance reanalysis and prediction, address end-user engagement, identify opportunities for integration, and connect to many of the themes of OceanObs'19."}, {"section_title": "CONNECTING OCEAN DATA ASSIMILATION WITH OCEAN OBSERVING EFFORTS", "text": "Although the growing constellation of satellite observing platforms continues to provide a much more coherent view of the ocean surface, there are limitations that remain in the integrated ocean-observing system that prevent the accurate estimation of the full state of the ocean based on observations alone. In situ measurements are quite sparse, while small-scale processes important to air-sea interaction and the deep ocean remain largely unobserved. In order to acquire a complete picture of the ocean state while appropriately characterizing our uncertainty of this picture, the gaps in coverage must be bridged in space and time using rigorous mathematical methods. This is a primary activity of the DA community and requires close collaborations between theorists in academia and practitioners at operational centers.\nOcean DA has become routine practice at many operational prediction centers, both for ocean forecasting and for initializing coupled Earth system models (Edwards et al., 2015; Martin et al., 2015) . The regular application of ocean DA either through operational forecasts or using retrospective analyses (reanalyses) is valuable for assessing the completeness and accuracy of the ocean-observing system. A variety of tools are available to assess the value of specific observing platforms, some that follow the methodologies of Observing System Experiments (OSEs) and Observing System Simulation Experiments (OSSEs), or Optimal Experimental Design (OED), while others are linked to the DA cycle itself, such as Forecast Sensitivity to Observation Impacts (FSOI) and estimating the effective degrees of freedom of the observing system (e.g., Oke et al., 2015a,b) .\nAdvances in DA methods have been and will continue to be driven by new observing technologies. We mention two notable features of upcoming observing technologies that deserve attention. First, amongst recent and planned satellite missions are increasingly high-resolution datasets covering the ocean surface. The development of instrumentation such as VIIRS, SLSTR on board , and platforms such as the Surface Water and Ocean Topography (SWOT) mission indicate there will be large volumes of data available for assimilation.\nAt present, the fidelity of these data products is far higher than many operational ocean models are capable of resolving. Ocean DA faces a challenge due to computational limitations: there is a need to either increase the resolution of ocean models in order to take full advantage of new data sources using conventional DA approaches or design new methods to extract more information from these observations without resorting to highresolution modeling (e.g., by using machine learning methods applied to high-resolution observations to produce dynamic parameterizations at the subgrid-scale -see for example Bolton and Zanna, 2019) . The accurate specification of observation error correlations becomes more important as higher resolutions are used (e.g., Mazloff et al., 2018) , making it more difficult to accurately assimilate new higher resolution observations. Amongst in situ observing systems, there is a trend toward mobile and adaptive platforms and new DA methods will be needed to use the full breadth of information provided by these platforms. As technology improves, there is also an opportunity to explore potential feedback between operational ocean DA systems and observing system guidance in near real-time that redirects the observing system to increase sampling in areas where the forecasts have greatest sensitivity. Ocean-observing technologies in the form of gliders, autonomous underwater vehicles, high-frequency radars, profiling floats, drifters, tagged marine mammals (and other pelagic apex predators), and acoustic instruments continue to undergo rapid development, and data volumes from these platforms are growing rapidly, particularly in coastal regions. Quality assurance and quality control (QA/QC) protocols are necessary, especially for new types of observations. Operational centers should improve their capability to provide feedback in near real-time regarding the QC classifications of individual observations based on forecasts made using those observations. From a fundamental standpoint, most of the approaches used for characterizing uncertainty in Ocean DA methods are predicated on the principles of Bayes' theorem (Hoteit et al., 2018) . A common assumption is that errors are Gaussiandistributed and that the time evolution of the errors is linear. As such, there are common limitations to all currently used DA methods and a primary goal for improving the accuracy and applicability of DA in the coming decade will be to relax these limiting constraints (see Martin et al., 2019; Moore et al., 2019, this issue) . This has relevance to future ocean-observing system design, as it may change requirements on the observing system either to test and design new methods or to take advantage of new capabilities afforded by the methods.\nIn recent years, the Global Ocean Data Assimilation Experiment (GODAE) and its offshoot, GODAE OceanView (GOV) have been active in galvanizing ocean DA activities by providing a platform for promoting ocean DA and forging international collaborations (Bell et al., 2015) . These activities will continue under the new guise of OceanPredict. Going forward, we recommend that this activity expand to further interface with the academic and operational ocean-observing, ocean modeling, and ocean DA communities."}, {"section_title": "THE ADVENT OF COUPLED DATA ASSIMILATION", "text": "The components of the Earth system have traditionally been analyzed independently. However, modeling improvements and increases in computing power are now enabling the analysis of the Earth system as a whole (Saha et al., 2010 (Saha et al., , 2014 Lea et al., 2015) . Observation-model synthesis activities that incorporate observational data into coupled Earth system models have led to the emergence of a new research area called Coupled Data Assimilation (CDA; Penny et al., 2017) . While traditional methods have generally focused on a single scale of motion within any given DA system, an essential characteristic of CDA is the need to account for the multiple spatiotemporal scales present in the error dynamics of the coupled system. The most basic application of DA to coupled models has been the application of legacy DA systems to each component separately, which is called weakly coupled data assimilation (WCDA). In order to allow any observation to directly affect the analysis of multiple model components across their interface, the DA itself must also be coupled; this is called strongly coupled data assimilation (SCDA). For most modern DA methods, SCDA requires that the forecast error covariance matrix be produced for the coupled state. Efforts are underway to develop effective approaches for SCDA, though additional work is still needed to understand the complexities of this problem .\nBy isolating systematic errors in prediction systems, CDA may help identify new transformative directions in oceanobserving strategies targeted at eliminating these errors. Because CDA allows ocean observations to directly inform atmospheric state estimates and vice versa (Sluka et al., 2016; Sluka, 2018) , the relevance of existing observations for state estimation and prediction must be clarified as the ocean-observing network evolves. CDA developments involve a necessary reevaluation of requirements for ocean-observing capabilities, either by reducing the presence of redundant information or by using such redundant information to calibrate multiple observing platforms. CDA can effectively leverage multidisciplinary, sustained, collocated observations, and may require more information in new geographic locations, or of new previously unmeasured quantities, to better understand the structure of the cross-domain error covariance. Over the next decade, those designing components of the Earth-observing system should pay close attention to developments in CDA.\nOperational centers are now developing CDA methods for NWP and reanalysis applications that include components such as the ocean, sea ice, land, and atmosphere . One of the original motivations for improving CDA methods was to ensure consistency between the different components of the Earth system. The use of coupled Earth system models for operational prediction provides the potential to produce forecasts that target multiple prediction timescales. At NWP timescales, the diurnal cycle has a large influence on coupled processes in the boundary layers of the atmosphere and ocean. Mesoscale interactions between sea surface temperature (SST) fronts and near-surface winds (Chelton and Xie, 2010) may have significance to winds throughout the troposphere. Potential sources of predictability for Subseasonal-to-Seasonal (S2S) timescales include establishing teleconnections associated with the Madden-Julian oscillation (MJO), the evolution of the El-Ni\u00f1o Southern Oscillation (ENSO), soil moisture, snow cover and sea ice, stratosphere-troposphere interactions, upper ocean conditions, and tropical-extratropical teleconnections (Vitart et al., 2015) . At decadal prediction timescales, accounting for coupled oscillations such as the Atlantic Multidecadal Oscillation (AMO) and the Pacific Decadal Oscillation (PDO) (d'Orgeville and Peltier, 2007 ) may be of greater importance for CDA.\nBeyond coupled atmosphere-ocean interactions, the application of CDA is also important to better understand other coupled processes in more detail. For example, DA in coupled ocean-sea ice models (Fenty and Heimbach, 2013; Bertino and Holland, 2017; Kimmritz et al., 2018) and coupled physical-biogeochemical models (Brasseur et al., 2009; Song et al., 2016; Verdy and Mazloff, 2017) at both regional and global scales are currently active areas of research, driven by improvements in remote-sensing observing platforms (e.g., sea ice concentration and thickness and ocean color) or new capabilities (e.g., biogeochemical Argo floats and airborne hyperspectral imagers). There have been few studies to date exploring DA applied to coupled land-ocean processes.\nFocus on biological activity highlights the importance of physical variables often ignored in conventional ocean DA, such as upper-ocean vertical fluxes (Brasseur et al., 2009) . Largescale assimilation of marine biogeochemistry is limited by the lack of regular observations. The only routine observations with global coverage are satellite ocean color (Ford and Barciela, 2017) . Existing DA efforts typically focus on generating products based purely on biogeochemical measurements independently of physical oceanographic measurements (e.g., Ciavatta et al., 2016; Gregg et al., 2017) . As CDA begins to mature, it would be highly beneficial for the physical oceanographic reanalysis and ocean biogeochemical reanalysis efforts to start integrating with one another (Rosso et al., 2017) . Early interest in moving in this direction has been indicated, for example, by Perruche et al. (2017) as part of the ERA-CLIM2 project. Regional ocean analyses are being used to predict Harmful Algal Blooms (HABs; Anderson et al., 2016) , to understand economically important marine ecosystems (e.g., Schroeder et al., 2014 Schroeder et al., , 2017 with a view to management, and to understand the migration habits of endangered marine species (e.g., Becker et al., 2016) , and it is expected that these applications will be enhanced with CDA.\nTo date, ECMWF has one of the more mature efforts developing a CDA system. An implicit coupling approach has been implemented in their CERA system, where the atmospheric 4D-Var and oceanic 3D-Var DA systems are synchronized using multiple outer iterations in the incremental variational formulation. This outer-loop coupling system is an approximation of a fully coupled 4D-Var system that tries to find an approximation to the same optimal solution by setting the coupled adjoint model and the cross-domain error covariance at the initial time of the assimilation window to zero (Laloyaux et al., 2018b) . It takes between 6 and 12 h for the outer loop coupling to synchronize the coupled increments (Laloyaux et al., 2018a) . This finding suggests that a long assimilation window (at least 12 h) is necessary for CERA to be an effective strategy for CDA. The outer-loop coupling employed by the CERA system could in principle be augmented by both the specification of the initial time coupled covariances and coupled adjoint. Such an approach could mitigate problems in cases where the coupled model is not able to synchronize the unbalanced increments that arise because the assimilation window is too short, the observations are inconsistent due to biases present in the observing platforms, or systematic modeling errors prevent agreement across the interface."}, {"section_title": "AN EXAMPLE APPLICATION OF CDA: THE DIRECT ASSIMILATION OF SATELLITE RADIANCES FOR ESTIMATING SST", "text": "The air-sea interface is one of the prime focus areas for early explorations of CDA. In addition to requiring a rethinking of DA algorithms and solution approaches, CDA affords the opportunity to improve the methods used to map the modeled state to a simulated \"model equivalent\" for each observation that can then be compared directly with observations. One of the most obvious places to start is improving the inputs provided to radiative transfer models. CDA provides a new capability to assimilate observed brightness temperature (BT) instead of relying on retrieval products such as proxy measurements for SST.\nCurrent state-of-the-art coupled forecasting systems do not analyze interface states such as SST, sea surface salinity (SSS), or sea ice in a self-consistent manner. For example, many atmospheric and oceanic DA systems typically nudge toward SST retrieval products. However, this approach typically ignores caveats in the empirical methods used to convert satellitemeasured radiances into SST retrieval data products . Among the most serious are errors in model calibration at high latitudes as well as challenges in using skin SST estimates to constrain bulk temperature (Donlon et al., 2002) . Diurnal variations of SST and near-surface cooling in the microlayer are processes that are well observed and studied (Kawai and Wada, 2007) but not very well represented in coupled atmosphere-ocean general circulation models (Brunke et al., 2008) , in which reproducing SST variability remains a challenge (Lea et al., 2015) .\nThere are numerous definitions for SST; for example, see Figure 1 of or definitions established by the Group for High Resolution Sea Surface Temperature (GHRSST). Some of these definitions are conceptual (e.g., the interface SST) while others are derived from the method of measurement (e.g., infrared vs. microwave). Satellites have provided continuous infrared observations that sample in the upper 10-20 \u00b5m (the skin temperature) since the early 1980s and microwave observations (spatially less accurate than infrared, but insensitive to cloud cover and aerosols) that observe the upper few millimeters (the subskin temperature) since the late-1990s (Reynolds et al., 2007) . In situ measurements of SST are sparser and typically comprised of top-level (1-2 m) moored buoys, drifting buoys (about 20-30 cm), and ship intake measurements (Castro et al., 2012; Legler et al., 2015) that are known to have large errors (Folland and Parker, 1995; Kennedy, 2014) .\nSatellite-based measurements of SST are inherently coupled due to influences from not only the sea surface but also the full atmospheric column above it. The measured SST is highly influenced by both atmosphere and ocean boundary layers as well as the strength of upward longwave radiation and turbulent heat flux exchanges. To avoid dealing with the complex calibration issues associated with satellite radiances, current prototype CDA systems typically rely on SST data products produced by specialists and assimilate either along-track (L2) SST estimates or gridded (L3 or L4) SST products such as Pathfinder (Casey et al., 2010) , OSTIA (Stark et al., 2007) , or ACSPO (Ignatov et al., 2016) . See Martin et al. (2012) for a review of available L3 and L4 SST products. One of the main recommendations of a recent ECMWF workshop was to directly assimilate satellite radiances to constrain SST and sea ice, just as is done in NWP for atmospheric quantities. CDA offers an opportunity to treat the interfaces within the coupled model in a self-consistent manner, particularly when the forward model that is used to evaluate the \"model equivalent\" to the observation, H(x), depends on state information from multiple domains.\nBoth the NASA Global Modeling and Assimilation Office (GMAO) and the National Oceanographic and Atmospheric Administration (NOAA) National Centers for Environmental Prediction (NCEP) Environmental Modeling Center (EMC) (Derber and Li, 2018) have already implemented methods to directly assimilate radiances in order to compute SST analyses. The NASA GMAO procedure followed Takaya et al. (2010) allows the SST diurnal cycle to be resolved in the model, which provides a near-surface temperature profile as a function of depth. Using the forecasted SST along with the forecasted atmospheric state as inputs to the radiative transfer model, the resulting forecast BT can be compared with observed BT. The difference between observed and forecasted BT is used by the DA method to form a consistent analysis of the combined atmospheric state and SST. In order to effectively constrain SST, observations that are sensitive to SST, such as infrared satellite radiance measurements onboard operational polar orbiting satellites, were added to the observing system (see Akella et al., 2017 for details and Gentemann and Akella, 2018 for a comparison/evaluation of their results with other diurnal-SST retrievals). The capability to assimilate satellite radiances in coupled forecasting systems has improved the predictability of the GMAO system, most notably near the surface. The BTs are atmospheric column-weighted measurements. Because infrared satellite measurements are sensitive to water vapor, improved resolution and assimilation of SST-sensitive BTs translated into improved observational innovation statistics for many satellite channels that contain information about tropospheric temperature and water vapor.\nThe advantages of combining infrared and microwave radiometric measurements of SST are already well established (Chelton and Wentz, 2005) . A microwave satellite radiometer beyond the currently operational Global Precipitation Measurement -GPM Microwave Imager (Skofronick-Jackson et al., 2018) and Advanced Microwave Scanning Radiometer-2 (Kazumori et al., 2016) missions would provide the ability to maintain and further improve CDA at the air-sea interface. There is an immediate need to plan for a satellite salinity measurement mission beyond the 2020-2025 time frame (Durack et al., 2016; Vinogradova et al., 2017 this issue) . Bearing in mind the collaborative nature of satellite missions, further coordination is needed for planning the next generation of NOAA satellites that follow the GOES-R, JPSS, DSCOVR, Jason-3, and COSMIC-2 missions (Volz et al., 2016) .\nField campaigns and in situ measurements aid in the improvement of modeled near-surface temperature and salinity variations, and mixing processes. The existing network of drifting buoys [ Figure 3 of Legler et al. (2015) ] routinely reports nearsurface (about 20 cm) measurements of SST, sea level pressure (SLP). The measured SLP is routinely assimilated into the NWP forecast models, and SST are used for calibration/validation of SST retrieval products. However, one cannot measure vertical SST variability and mixing with a single sensor (e.g., at 20 cm). Dedicated cruise campaigns such as those reported by Dong et al. (2017) suggest that adding one more temperature sensor and salinity sensor to the drifting buoy network can provide valuable measurements of SST/SSS near-surface variations. Such measurements would help with calibration and evaluation of observations as well as improve the representation of the diurnal cycle, the feedbacks between SST and surface salinity variations (Bellenger et al., 2017) , and buoyancy-driven density variations in general."}, {"section_title": "OCEAN AND COUPLED EARTH SYSTEM REANALYSIS", "text": "An important application for DA is to develop historical reconstructions of the Earth system based on the observational record. Numerical models fulfill the basic large-scale equations of motion and satisfy conservation laws, but may have systematic errors. While this type of numerical modeling can provide insights into the mechanisms driving long-term variability (Haid et al., 2017) , the systematic errors that arise can cause long-term drift in the modeled climate compared to the real Earth system. In contrast, statistical observational analyses (e.g., Abraham et al., 2013) can be applied to observed data to produce a full field reconstruction that closely agrees with the observational record. However, this approach does not typically ensure conservation laws are enforced, meaning there are known errors that are unaccounted for, and is not able to recover unobserved quantities. Retrospective analyses, or reanalyses, combine the advantages of both numerical modeling and statistical observation analyses to fulfill the conservation laws over discrete periods while also incorporating observed data and subsequently estimating unobserved quantities. Reanalyses can be used to study the evolution of the Earth's climate during any time period for which we have an observational record. They are also useful for initializing \"reforecasts\" that can be used to calibrate biascorrection schemes for seasonal forecasts. Next, we document recent advances from the ocean reanalysis community and discuss unresolved challenges that require sustained activities for maximizing the utility of information content from observations, supporting data rescue, and advancing specific research and development requirements for reanalyses."}, {"section_title": "ADVANCES AND UNSOLVED CHALLENGES IN PRODUCING OCEAN REANALYSES", "text": "The original interest in developing ocean reanalyses arose largely from a desire to examine long-range climate-scale signals. Ocean reanalyses can be studied to enhance understanding of processes driving observed changes. They are also useful for studying recent changes in the climate for quantities that are difficult to observe continuously, such as transports (Mignac et al., 2018) , or those that require consistent spatial data coverage at depth, such as ocean heat content (Balmaseda et al., 2013; Wunsch and Heimbach, 2014) . To be able to draw robust conclusions, one must be confident that inhomogeneous time series or abrupt regime changes are caused by physically consistent processes -not artifacts associated with changes in the historical observing network. During much of the early history of ocean reanalysis development, there have been significant disagreements between estimates produced by different reanalysis approaches. This was due in large part to the scarcity of observational data, differences in model configurations, and discrepancies in DA methods.\nHowever, due to advances in the ocean observing system, improvements in modeling, and advances in DA methods, ocean reanalysis products have been slowly converging.\nTo date, ocean reanalyses have been produced by many operational centers and research institutes (Carton and Giese, 2008; Sugiura et al., 2008; Xue et al., 2011; Chang et al., 2013; Wunsch and Heimbach, 2013; Blockley et al., 2014; Valdivieso et al., 2014; K\u00f6hl, 2015; Forget et al., 2015; Penny et al., 2015; Toyoda et al., 2016; Storto and Masina, 2016; Palmer et al., 2017; Zuo et al., 2017b) . Balmaseda et al. (2015) provide a recent intercomparison study of about 20 reanalysis products. The extent to which reanalyses provide robust answers to questions about climate change and variability relies on many factors, including the fidelity of the numerical models, the accuracy of forcing fields, biases in observing platforms, uncertainties attributed to the observations and the background state (priors), and the sophistication of the DA schemes. Many of these considerations are highlighted in a recent study by Carton et al. (2019) comparing leading ocean reanalysis products (SODA3, ECCO4r3, and ORAS5).\nGiven the availability of ocean reanalysis products from multiple groups worldwide, we recommend that climate studies include the evaluation of as many products as possible to sample the range of uncertainty in the historical ocean state and disentangle possible inconsistencies that arise due to choices made in their construction. Uncertainties in ocean reanalysis state estimates result from accumulated errors from all system components (ocean model, boundary condition forcing, observations, and DA method). Uncertainty in ocean reanalyses as a whole can be studied using a multi-reanalysis ensemble approach Masina et al., 2017; Xue et al., 2017) , which provides a way to not only investigate the accuracy of ocean reanalyses but also disentangle sources of uncertainty. A rough estimate can be achieved by comparing the consistency of the reanalyses (ensemble spread), interpreted as noise, with the natural variability (variance in time), interpreted as the signal.\nUncertainties in an individual system can also be assessed by accounting for errors explicitly in different system components, for example by using ensemble forecasts, by introducing stochastic perturbations in the model (Brankart et al., 2015) , by estimating representativeness errors associated with observations in relation to the model resolution, and by estimating analysis/structure errors in forcing fields (Penny et al., 2015; Zuo et al., 2017a) .\nSurface forcing derived from atmospheric reanalyses induces systematic errors. Multi-forcing reanalyses may be performed to better estimate the impacts of these errors (Chaudhuri et al., 2013 (Chaudhuri et al., , 2016 Storto et al., 2016b; Carton et al., 2018; Yang et al., 2018) . Recently, Zuo et al. (2017a) introduced a stochastic perturbation for the atmospheric forcing by taking into account both uncertainty from different atmospheric analysis data sets and uncertainty from the same analysis method with multiple ensemble members. Another method for adjusting uncertain atmospheric fields is by employing control methods, where adjustments to atmospheric surface forcing data are part of a formal inversion, assuming relatively accurate oceanic observations (e.g., Stammer et al., 2004; Liang and Yu, 2016) . Uncertainty in initial conditions can also be evaluated using an ensemble approach, by performing several spin-up integrations with different DA system configurations (Zuo et al., 2018) . Chevallier et al. (2017) showed that for coupled ocean-sea ice models driven by prescribed atmospheric forcing, part of the variability across ocean reanalyses is the result of differences in the atmospheric reanalyses used to force these systems, which is large in the polar regions (Lindsay et al., 2014) . Part of the discrepancy in the atmospheric reanalyses is due to the treatment of the prescribed boundary conditions (e.g., sea ice), giving an example of a weaknesses in the \"uncoupled\" approach. Generally, both coupled climate models and ocean-ice models, driven by prescribed atmospheric forcing, cannot adequately represent the observed polar trends, whereas ocean reanalyses have proven quite adequate to capture these trends when observations are available to constrain the system Uotila et al., 2018) .\nWith the exception of smoother-based reanalyses generated by the Consortium for Estimating the Circulation and climate of the Ocean (ECCO; Wunsch and Heimbach, 2013; K\u00f6hl, 2015; Forget et al., 2015; Heimbach et al., 2019) , most of the DA systems developed under GODAE and GODAE OceanView use some form of sequential DA . Some of the systems based on simplified assumptions about the forecast error characteristics suffer from problems with initialization, where the updates applied to the model at each assimilation step are not dynamically consistent. To date, many developers have attempted to minimize the negative impacts of these dynamical imbalances by ad hoc techniques such as nudging with incremental updates (Bloom et al., 1996) . Some problems have been identified in the Equatorial region within a number of ocean reanalyses, in which the assimilation can induce spurious variability that has been damped by following several bias correction strategies (Waters et al., 2017) .\nAn application of the 4D variational method in ocean DA has been developed with an emphasis on reconstructing the ocean on climate time scales . Motivating these approaches were the goals of (i) using information contained in observations backward in time, (ii) enlarging the control space to include uncertain boundary conditions and model parameters, and (iii) deriving estimates with closed property budgets enforced by the equations of motion (e.g., Buckley et al., 2015; Piecuch et al., 2017) . However, this approach also has potential limitations. For instance, increasing the control space also increases the dimension of the problem, which in turns makes the method very expensive for high-resolution global applications. There may also be challenges with relying on the accuracy of a linearization over long time windows.\nOther difficulties are connected with the irregular observing network. This often causes spurious variability in reanalysis products, especially in multi-decadal reanalyses covering historical periods with highly varying observing systems ranging from the sparse pre-satellite era to present. This has been the subject of many investigations aiming to include bias-correction schemes within the reanalysis Lea et al., 2008; Storto et al., 2016a) . However, this creates the additional challenge of estimating these biases while having only a limited number of \"anchoring\" (i.e., unbiased) observations. Before the deployment of the Argo network, the sampling of observations used by ocean reanalyses is generally sparse, which has implications for the reliability of quantities such as global ocean heat content before the 2000s. However, several studies showed that beginning in the early 1980s, the observing system is able to reasonably constrain the global ocean heat content (Storto et al., 2016b) . There is growing interest amongst the ocean reanalysis community in the deep Argo program (Zilberman, 2017) , with the hope that this will gradually fill the gap in knowledge of the ocean state below 2000 m and allow the deep ocean warming contribution to be assessed with greater precision. Care is also being taken in ocean reanalyses to synergistically exploit a large number of data sources (altimetry, gravimetry, Argo, tide-gauges, etc.) to create a reliable representation of freshwater and mass balances. Data used for evaluation, not necessarily assimilated (e.g., buoys, drifters, tide-gauges, RAPID and OSNAP arrays, SAMOC and SOCCOM programs, ADCP data, etc.) are also crucial for assessing uncertainty in reanalyses and improving process representation in models.\nWithin historical data records, the accuracy of the observations assimilated is often unknown or underestimated due to lack of metadata. This also prevents effective biascorrection procedures from being implemented and may lead to the erroneous specification of instrumental errors. For the historical ocean subsurface temperature record, the situation is improving through an internationally coordinated community effort (Domingues and Palmer, 2015) 1 , focusing on recovery of data and metadata, development of intelligent metadata, coordinated quality control (automated and expert), and assignment of uncertainties. Their overall goal is to produce a long-term climate quality global ocean subsurface database that can be used with greater confidence by the ocean reanalysis community and other users. The first interim IQuOD database product is available from The IQuOD Team (2018).\nReanalyses will continue to extend further backward in time to cover longer historical periods, following the trend set by Compo et al. (2011) and ECMWF's ERA-20C, and later followed by comparable century-long ocean reanalyses (Giese et al., 2016; Yang et al., 2017) and the coupled reanalysis CERA-20C (Laloyaux et al., 2018a ). This will require improved methods to handle sparse observations, discontinuities in the observation network, and correction of large-scale biases, as well as continuous efforts on data rescue. With the recent emergence of coupled Earth system reanalyses, non-oceanic data will also play an important role, particularly in time periods where ocean observations are extremely sparse or non-existent. Ocean background errors are expected to evolve significantly during the reanalysis period due to the ever-changing observing 1 www.iquod.org network. The development of time dependent background error covariance estimates has proved beneficial (Penny et al., 2015; Penny, 2017; Yang et al., 2017) . The full introduction of flowdependent background errors involves estimating the ocean background error covariances from the ensemble and developing methods to deal with sampling limitations. Such ensemble-based error covariance information can account for anisotropic and inhomogeneous correlations that are difficult to estimate with traditional methods. An Ensemble of Data Assimilation systems (EDA) showed some benefits in the atmosphere by dynamically changing the weight given to the background depending on the observation density (Poli et al., 2013) and such methods may be useful for the ocean as well.\nIn addition to climate investigations, ocean reanalyses using higher resolution eddy-permitting models have a long history among the members of the Global Ocean Data Assimilation Experiment (GODAE) and the follow-on GODAE OceanView. The production of high-resolution ocean reanalyses started naturally as a historical extension of operational analysis experiments, with a series of products disseminated by Mercator Ocean (Ferry et al., 2007 (Ferry et al., , 2010 Garric et al., 2018) , by CSIRO and the Bureau of Meteorology (Bluelink) (Oke et al., 2005 (Oke et al., , 2008 , by NERSC (Sakov et al., 2012) , and by JMA and JAMSTEC (Usui et al., 2017) . These products have proved instructive for global and regional investigations of ocean variability (Schiller and Oke, 2015; Feng et al., 2016) , ocean processes (Oke and Griffin, 2011) , and for studies of the ocean-observing system (Lea et al., 2013; Fujii et al., 2015) . Going forward, it is expected that the resolution of ocean reanalyses will increase to allow representation of eddy dynamics and to fully include mesoscale and coastal ocean dynamics. This requires the improvement of small-scale ocean dynamics in models and the development of DA methods that are capable of assimilating rapidly changing, strongly non-linear, and non-Gaussian observational constraints."}, {"section_title": "ADVANCES AND UNSOLVED CHALLENGES IN PRODUCING COUPLED REANALYSES", "text": "Coupled model integrations with prescribed radiative forcing have been the backbone of the coordinated experiments for the World Climate Research Programme (WCRP) Coupled Model Intercomparison Project (CMIP) that were designed for contributing to the Intergovernmental Panel on Climate Change (IPCC). Century-long coupled reanalyses go a step further by assimilating information about the actual observed state of the Earth system, without deteriorating the model representation of low-frequency variability and change. While this is a tremendous challenge, it is essential in order to advance our understanding of climate variability and change and to identify the broader impacts on global communities.\nKey benefits expected from a coupled reanalysis are: a more consistent treatment of the interfaces between different model components, better use of observations near these interfaces, and improved representation of global budgets of conserved quantities. In principle, the use of a coupled model as the forecast component within a DA system makes it possible to fully account for ocean-atmosphere, ocean-ice-atmosphere, and landatmosphere feedbacks. This can only be achieved, however, if the assimilation of near-surface observations respects the consistency at the boundaries as imposed by the model and if the modeled dynamics at the boundary are consistent with observations.\nIn the 20th-century coupled reanalysis (CERA-20C) produced at ECMWF, the ocean and the atmosphere communicate hourly through air-sea coupling at the outer-loop level of the variational method. In this system, changes in the state of the atmosphere indirectly impact the ocean properties, and vice-versa, and both systems adjust to each other during each analysis cycle. There is a more consistent energy balance in CERA-20C, with the net heat fluxes at the air-sea interface (0.15 \u00b1 1.1 W/m 2 ) and ocean temperature increments (\u22120.11 \u00b1 1.9 W/m 2 ) averaging close to zero over the century, compared to the forced ocean reanalysis ORA-20C (\u22121.62 \u00b1 1.89 W/m 2 and 1.66 \u00b1 2.32 W/m 2 ). However, given that the SST in the ocean component of CERA-20C was nudged toward an external data product, this suggests that there is further room for improvement. While midlatitude storms, heat waves, or cold-air outbreaks are often well-represented in regions with dense observational coverage, this is not always the case for tropical cyclones, which are difficult to model and not well-constrained by observations. CERA-20C struggles to correctly represent several tropical cyclones at the beginning of the 20th century (Laloyaux et al., 2018a ). More work is needed to quality control observations from the International Best Track Archive for Climate Stewardship (IBTrACS). This is expected to improve the ability of historical reanalyses to facilitate the study of weather extremes. Based on the development of CERA at ECMWF, which implements the Copernicus Climate Change Service 2 on behalf of the European Union, there are ambitions to produce a moderate-resolution global coupled centennial reanalysis by 2022, allowing a better representation of long-term trends in the climate system.\nBeyond CERA-20C, ECMWF's reanalysis portfolio has recently been extended to include CERA-SAT (Schepers et al., 2018) , a pilot reanalysis for coupled DA using the full modern atmospheric and ocean-observing systems. CERA-SAT was produced using ECMWF's CERA coupled assimilation system and constitutes a 10-member EDA available for a 9-year period from January 1, 2008 to December 31, 2016. CERA-SAT serves as a proof-of-concept for CDA in the context of modern NWP-observing systems. Preliminary assessments have shown ocean-atmosphere coupling to be beneficial in tropical regions, while degradation is evident in the extra tropics, when comparing the coupled CERA-SAT system using SST nudged to OSTIA to an atmosphere-only reanalysis of the same setup but forced with OSTIA SST.\nCenters that routinely produce reanalyses are often also engaged in other activities (for instance, operational prediction, mission support, and ocean monitoring). In order to carry out all of these missions, and to successfully transition the currently in-production uncoupled reanalyses to future coupled reanalyses requires careful planning for appropriate 2 climate.copernicus.eu computational and storage resources. We highly recommend that funding agencies plan for such upcoming future needs in order to dedicate sufficient resources to support, within the next decade, not only coupled ocean-atmosphere reanalyses but also the inclusion of additional components, such as atmospheric constituents, chemistry, and ocean biogeochemistry. Such efforts are underway in the United States as detailed in NOAA's strategic implementation plan (SIPv4, 2017), which is a partnership among NASA, NOAA, the Department of Defense (DoD), and the Joint Center for Satellite Data Assimilation (JCSDA) and contributing external and international agencies."}, {"section_title": "USING OCEAN OBSERVATIONS TO IMPROVE PREDICTION", "text": "We next describe the existing observing system and gaps in observational coverage and recommend designs of observational and modeling experiments to evaluate the impact of ocean observations on forecast skill. The advances and enhanced spatial and temporal resolution obtained over the last 10 years in both satellite and in situ observations have enabled the use of DA to constrain coupled Earth system models for the first time to a realistic representation of the large-scale upper ocean thermal structure (upper 1000 m). However, there are still components of the coupled system that remain unconstrained. For example, the lack of air-sea flux measurements with global coverage poses a challenge to constraining the atmosphere-ocean exchanges without adequate observational sampling. This type of observing network should be enhanced in the future as they are not only crucial in the context of CDA and its applications to S2S and decadal prediction but also for the evaluation of climate simulations. In particular, we recommend the development of air-sea-flux-observing satellite missions.\nWe emphasize the need for continuous long observational records to enhance prediction capabilities. Ocean reanalysis systems naturally extend to the initialization of seasonal, interannual, and decadal prediction systems, where the role of subsurface ocean initialization has been recognized as crucial (Balmaseda et al., 2009 ). S2S and decadal forecasting typically rely on the existence of reforecasts covering several decades in order to calibrate the model output and for skill assessment. These reforecasts are initialized by ocean or coupled reanalyses (Balmaseda, 2017) . The length of the reforecast record adds value to the forecast. For this purpose, sustained data rescue activities are recommended as well as maintaining stability of the existing observing system. Recently, ocean reanalyses used to initialize seasonal prediction systems (reforecasts and near real-time reanalyses) have become publicly available via the EUfunded Copernicus Programme and are being used to evaluate subsequent forecasts (Juricke et al., 2018) .\nMeasurements from observing platforms such as satellites, moored surface and subsurface buoys, drifters, floats, dedicated manned and unmanned vehicles, research ships, and vessels of opportunity are collected and distributed with various time lags. Operational predictions rely on observational platforms equipped with the capability for distribution in real-time or near real-time. Some observation types are used primarily as independent measurements for evaluation because they cannot be assimilated due to time delays or other technical complications. These include ocean current profilers, satellitederived ocean surface currents, and a suite of biogeochemical observations such as carbon, oxygen, nutrients, ocean color, and phytoplankton.\nOverall, a lack of uniformity in data management infrastructures imposes problems for the effective and efficient use of the global observing system in prediction efforts. These issues include, but are not limited to, delayed and duplicate data receipts, versioning issues, missing data and metadata, and non-documented data processing procedures. In order to advance the deployment of effective oceanobserving systems, modern data management infrastructures are needed such that all activities along the data flow pipeline, from data collection through assembly and preservation, are more automated and fault-tolerant and progressively advance the systems toward interoperability. Building strong collaboration amongst the observing networks, data managers, and decadal forecasting centers will lead to improved access and uptake of data and to efficiencies that will eventually lead to improvements both in the observing networks and the decadal prediction system.\nThe future ocean observational requirements for the decadal prediction system include sustained and reliable data streams that have global sampling and are continuous in time, subject to regular quality control and calibration procedures, and encompass several spatial and temporal scales (e.g., National Academies of Sciences, Engineering, and Medicine [NASEM], 2017). To this end, there is great value to centralized data centers that collate observations from individual observing platforms in order to provide timely access to data and a consistent data format for ease of integration into DA systems."}, {"section_title": "PREDICTION AT SUBSEASONAL TO SEASONAL TIMESCALES", "text": "Many operational prediction centers are currently undertaking a transition from atmospheric NWP on a time range of 0-2 weeks to seamless forecasts that bridge the gap between mediumrange weather and seasonal forecasts. This transition is driven by a growing consensus that coupled Earth system modeling benefits forecasts on a wide range of timescales (Hoskins, 2013; Vitart et al., 2017) . The new focus on prediction with coupled models is highlighted in efforts such as forecasting the onset of monsoons, characterizing teleconnections of the MJO, and providing advance warning for extreme weather events (Vitart and Robertson, 2018) .\nSubseasonal prediction, focusing on the period transitioning from NWP to seasonal timescales, stands to gain considerably from combining the higher model resolutions of NWP with the coupled modeling approach of seasonal prediction. The MJO is the dominant mode of intraseasonal variability in the tropics and is considered a major source of predictability on the subseasonal time scale (Waliser, 2011) . With respect to the ocean, anomalies in SST affect air-sea heat fluxes and affect atmospheric circulation (Woolnough et al., 2007) . Vitart et al. (2014) indicated significant gains in prediction skill after a decade of producing operational forecasts at ECMWF, pointing to an average gain of about 1 day of MJO prediction skill per year and improved ability to predict the North Atlantic Oscillation (NAO) and sudden stratospheric warmings (SSW). Skill scores improve with increased horizontal resolution and the addition of new modeling components such as a dynamic sea ice model. The introduction of new modeling components also presents the opportunity to assimilate new observational data not previously utilized for sub-seasonal prediction. Zampieri et al. (2018) indicate high potential for sea ice prediction in the sub-seasonal timescales, especially for late summer forecasts, and advocate the need to reduce systematic seasonally dependent model biases and develop advanced DA capabilities to constrain sea ice extent and sea ice thickness. Zhu et al. (2018) showed that MJO forecast skill can be improved in the NCEP Global Ensemble Forecast System (GEFS) from an average of 12.5 days (control) to nearly 22 days by (1) adding stochastic physical perturbations, (2) considering ocean impacts by using a two-tiered sea surface temperature approach (combing an analysis product with a forecast of SST from a coupled model), and (3) applying a new scale-aware convection scheme to improve the model physics for tropical convection. They also showed improved ensemble mean anomaly correlation of 500-hPa geopotential height in the extratropics over weeks 3 and 4.\nEl-Ni\u00f1o Southern Oscillation is an inherently coupled phenomenon and one of the most studied sources of interannual variability in the climate system (Wu et al., 2009) . Though mostly associated with the tropical Pacific, ENSO variability impacts the global climate (Timmermann et al., 2018) . Changes in SST are an indicator of changes in ocean heat storage and transport and these oceanic processes further interact with changing atmospheric momentum and heat fluxes. Prediction skill for the SSTs associated with ENSO have improved over time. At ECMWF, for example, the skill in predicting SST anomalies in the NINO3.4 region has consistently improved as the DA system evolved starting from the S1 system in 1997. If subsurface ocean and satellite altimeter observations are withheld from the analysis, there is a severe degradation in skill comparable to 15 years of progress in seasonal forecasting (Figure 1) .\nThe original motivation for the Tropical AtmosphereOcean (TAO) array and Triangle Trans-Ocean Buoy Network (TRITON) was the 1982 -1983 ENSO event (McPhaden, 1995 Ando and Kuroda, 2002) . These moorings have provided surface meteorological observations, ocean temperatures in the upper 500 m, salinity and current measurements at selected moorings, and have played a key role in better understanding the ENSO phenomenon and advancing seasonal forecast systems in the decades since their implementation (McPhaden et al., 2010) . To support S2S prediction, new observing systems must account for processes occurring over a much broader range of timescales.\nInnovative observing technology in the sub-surface layer and at the air-sea interface can help to improve understanding of coupled interactions critical for S2S prediction. Self-sailing boats currently exist that can autonomously gather ocean and atmospheric observations over large areas of the ocean surface. Such technologies have the potential to precipitously drop costs of collecting observations of quantities such as wind, temperature, humidity, salinity, dissolved oxygen, and fluorescence near the ocean surface. These technologies are promising for constraining surface flux estimates in CDA, leading to improved modeling of air-sea interaction and improved initialization of coupled model forecasts. S2S forecasts for high latitudes and midlatitudes can be improved with more numerous and accurate ocean and sea-ice observations in datasparse regions.\nA redesign of the TAO/TRITON array is currently underway by the Tropical Pacific Observing System (TPOS-2020) working group 3 that is largely influenced by the volume of new complementary data provided by a number of new observing platforms. TPOS-2020 currently plans a \"backbone\" design that will support and supplement the broader observing network, including satellite measurements. The TPOS-2020 design is likely to include measurements of the air-sea interface with a vertical and temporal resolution not possible from remote-sensing platforms. Complementary observations include satellite measurements of quantities such as sea level, SST, SSS, wind stress, and precipitation (Mason et al., 2010 ; National Academies of Sciences, Engineering\" and Medicine [NASEM] , 2018, Chp. 2) as well as the in situ Argo profiling float program (see Legler et al., 2015 for a comprehensive review of operational observing systems).\nThe tropical Atlantic and Indian Oceans are also locations of strong air-sea interaction, exhibiting their own local dominant modes of interannual variability, such as the Indian Ocean Dipole (Saji et al., 1999; Webster et al., 1999) The requirements of an observing system change in the Arctic, where the Argo float network is limited due to seasonal ice cover and strong stratification and where satellite remote sensing is limited by heavy cloud cover. These environmental challenges, along with increasing recognition of the importance of seasonal changes in Arctic and their impact on weather systems, has led to rapid development of new instrument types. As regular data from these new instruments become available, evaluation of their impact on S2S forecasts will be needed.\nPrediction centers have been slow to incorporate SSS data in ocean DA systems (Maes et al., 2014) , though there have been some indications of potential benefits for upper ocean processes that could impact S2S and decadal prediction. Hackert et al. (2011 Hackert et al. ( , 2014 , Zhu et al. (2014) , Tranchant et al. (2018) , and Martin et al. (2019) indicated that improved salinity estimates have the potential to improve ENSO forecasts. Though, to date, the impacts shown have been somewhat minor. A number of other studies showed positive impacts due to the assimilation of SSS in controlled experiments, including improved upper ocean salinity (Vernieres et al., 2014) , improved surface currents, mixed-layer depth, and barrier layer thickness (Chakraborty et al. (2014 (Chakraborty et al. ( , 2015 , and improved temporal variability of the vertical distribution of salinity in areas with large freshwater input (Seelanki et al., 2018) . Still, the low temporal frequency of the data, large uncertainty estimates attributed to instantaneous observations, and large platform-specific biases (Bao et al., 2019) , make the assimilation of SSS a continuing challenge. A nextgeneration technology that could produce SSS observations with the frequency, accuracy, and coverage of SST observations would be a high-impact capability.\nObserving system experiments conducted with real-time forecasting systems have found utility in assimilating sea level observations from multiple altimeters Oke et al., 2015a,b) . For example, Lea et al. (2014) showed that withholding Jason-2 data resulted in a 4% increase in the global RMS SSH innovations, while withholding all altimeter data resulted in a 16% increase of the global RMS SSH innovations. Verrier et al. (2017) conducted observing system simulation experiments with an eddy-permitting model (1/4-degree horizontal resolution) and found that forecasts of sea level and ocean currents are continually improved when incrementally increasing the number of satellite altimeters from one to two (\u223c30% error reduction) and from two to three (\u223c10% additional error reduction). They also note that when assimilating several altimeters, the analysis can resolve western boundary current scales closer to 100 km, versus the native model's capability to resolve scales around 100-200 km.\nFurther evaluating observing system impacts on ocean analyses and S2S forecasts will contribute to an ongoing discussion in the design of new oceanic observing systems, such as TPOS-2020 and AtlantOS 4 . Additionally, new and upcoming satellite missions such as the Surface Water and Ocean Topography (SWOT) will provide higher-fidelity SSH observations than ever before. Coordination between international groups such as CLIVAR and GODAE OceanView is needed for significant progress to be made with international observing efforts (Fuiji, 2019) . These international efforts, together with Global Ocean Observing System (GOOS) and its expert panels focusing on physics and biogeochemistry need to work together to build an observing system that recognizes user priorities."}, {"section_title": "PREDICTION AT DECADAL CLIMATE TIMESCALES", "text": "Interest in the viability of decadal forecasts is driven by a recognition that these timescales are of increasing importance to decision makers both for governmental policy and private industry (Meehl et al., 2009; Kirtman et al., 2013) . Decadal prediction can encompass timescales between several years to a few tens of years, with relevant processes interwoven with those relevant to both S2S forecasts and long-term climate projections. In the extratropics, for example, distinct climate variability has been associated with annual changes in the storm tracks and associated meteorological conditions over the North Pacific and North Atlantic, such as the Pacific Decadal Oscillation (PDO) and the North Atlantic Oscillation (NAO) (Scaife et al., 2014) . Decadal prediction is dependent on our ability to forecast not only internal variability of the Earth's climate system, such as the large-scale climate modes (ENSO, NAO, and PDO), but also how these modes will change under the influence of changes in external forcing, such as arising from human activity. The World Climate Research Program (WCRP) has recognized near-term climate prediction as one of its grand challenges. Despite this recognition, the extent to which decadal climate predictions are able to provide reliable and useful information to users remains uncertain (Meehl et al., 2014) .\nA sufficiently well observed ocean is crucial for the development of useful decadal predictions (Smith et al., 2012) . In order to predict the evolution of natural climate variability, coupled models must be initialized with observations informing the current state of the climate system. Predictability over these timescales will rely principally on accurately forecasting the slower modes of the coupled climate system, which are highly dependent on long-timescale ocean dynamics. Thus, decadal prediction systems will rely ever more heavily on a sustained ocean-observing system to initialize and verify predictions, similarly to what happened for NWP systems. Sparseness, non-uniformity, and secular changes in the ocean observing system represent a challenge for the initialization and evaluation of a decadal prediction system. Therefore, key factors enabling improved climate prediction skill are the availability of consistent surface and subsurface ocean observations over sufficiently long time spans, improved understanding of processes involved with ocean-atmosphere coupling, and the ability to track the climate modes of variability that determine predictability on a given spatiotemporal scale.\nDuring the last decade, satellites and autonomous in situ platforms have driven a step change in our ability to observe the ocean in near real-time. The use of remotely sensed and autonomous in situ platforms has revolutionized the ocean observing system, and the fast, technological advance on platforms and sensors will continue to improve the system (Figure 2) . The next decade will expand upon these advances with new sensors and platforms, coupled with advances in telecommunications.\nDecadal prediction systems generally assimilate or relax to SST analysis products. However, an increasing number of systems are also including interior ocean observations, such as temperature and salinity profiles, and sea ice (Doblas-Reyes et al., 2011; O'Kane et al., 2018) . Decadal prediction systems, as they focus on seasonal to longer timescales, rely on both real-time data and delayed-mode quality assurance and quality control data (QA/QC) for model initialization and evaluation. Coupled decadal prediction systems often use atmospheric states sampled either from reanalyses or operational products to initialize the atmosphere. However, this practice may need to be revisited and potentially replaced with more sophisticated methods such as CDA. For example, comparison of these products with the sparsely available ocean surface meteorological flux buoys consistently show significant differences both globally and regionally, indicating imbalances in the surface energy and freshwater fluxes at the air-sea interface (Yu, 2019) . Maintaining and extending surface flux buoys is vital to understanding the source of these inconsistencies, to improving coupled models, and to evaluating decadal prediction systems.\nThe heterogeneous nature of the in situ ocean-observing system requires comprehensive metadata, sophisticated data integration, and organized interpretation activity in order to realize the maximum benefit of the observations. Effective data management requires a strong collaborative effort across activities including observation collection, metadata and data assembly using community accepted standards, QA/QC, data publication that enables local and interoperable access, and secure archiving that guarantees long-term preservation of collected data.\nStatistics of the innovations generated within the DA procedure can be evaluated to identify broad biases in the differences between model and observations. For example, one can identify regions where there are large innovations due to the assimilation of daily, satellite SSH and SST anomalies.\nSignificant impacts are often found in the dynamically active regions such as the high-latitude oceans, boundary currents, and along the Equator. Further, with appropriate DA methods, regions of large model biases can be accurately estimated and reduced via direct assimilation of observations (Evensen, 2003) . On longer timescales, the sparser in situ observing network can provide similar guidance for correcting longtimescale model biases.\nThere remain many unanswered questions on the fundamental nature and drivers of ocean variability. Decadal prediction depends on the presence of \"oscillations\" that have the potential to remain coherent on multi-year to multi-decadal time scales. To the extent that such slowly evolving dynamical regimes exist (e.g., along which climate anomalies propagate), it is important that the DA system is capable of maintaining these lower frequency signals. It is also critical to understand how these anomalous ocean signals are influenced by the ocean-atmosphere boundary. Improved dynamical understanding of the ocean, sea ice, and atmosphere, and their coupled interfaces and teleconnections, will lead to more reliable and skillful multi-year to decadal climate forecasts.\nThere is a need for full-depth observations that provide measurements able to resolve the dominant temporal and spatial scales of variability of the ocean. We encourage continuing to leverage the sustained ocean-observing infrastructure for short-term intensive process study campaigns that target key knowledge gaps such as air-sea-land and ice coupling. When such process studies are conducted, greater interaction with the DA community before, during, and after the campaigns could help to identify observations that may be good candidates for transitioning into the sustained observing system. To this end, we encourage stronger collaboration between the communities developing near-term forecasting and ocean observing platforms to aid model development and observational design."}, {"section_title": "CONCLUSION", "text": "The ocean-observing system plays an important role in developing historical reconstructions of the ocean and initializing forecasts of the coupled Earth system at all timescales. The ideal observational sampling strategy will continue to evolve as we improve our understanding of the spatial and temporal scales of ocean variability and as technological observing capabilities improve. An ongoing challenge for the reanalysis and prediction communities will be to maintain close collaboration with the ocean-observing community that is developing the nextgeneration ocean-observing systems. This collaboration should occur at all stages, including the design, implementation, and decision making that determines sustained observations. The ocean DA community should provide programmatic guidance to the ocean-observing community regarding what types of observations would be most useful when established in a sustained observing network to best support ocean monitoring and prediction at various timescales. This problem requires the solution of a complicated optimization problem that is defined by a stated goal (e.g., to maximize the skill of a forecast), while taking into account the limitations of the forecast model, of each observing platform, and of the DA method itself. So far, this is not a mainstream activity and further coordination is needed in the coming decade to make observing system design a key application of ocean DA and CDA.\nWe anticipate a continuing race between the physical scales resolved by modeling and observing systems. DA systems must be able to constrain increasingly high-resolution numerical models at physical scales supported by the observation network. This poses dual challenges to make better use of a sparse observing system that will become increasingly coarse, in a relative sense, as model resolutions increase, as well as the need to incorporate as much information as possible from highresolution satellite observing systems. With upcoming satellite missions, the satellite-based ocean-observing system may at times evolve to support much higher resolutions of observed data products than a state-of-the-art operational forecast model can support. While a precise DA strategy should be developed for such scenarios, we also encourage coordination to take place between the modeling and prediction centers and the teams developing plans for future satellite observing missions in order to ensure prioritization of those missions that have maximum impact on prediction skill.\nTo support CDA developments for operational applications, we recommend that a high priority be placed on ensuring consistency between atmosphere and ocean data governance bodies (e.g., WMO and Copernicus Climate Change Service and Copernicus Marine Environment Monitoring Service). At present, many ocean observations risk missing the cut-off times associated with the timelines of operational NWP. Improved infrastructure is needed to support research and operations, including real-time transmission of observed data and realtime feedback from users regarding the quality control of those data relative to other observing sources. For operational coupled Earth system approaches, used for reanalyses and prediction, it is crucial to enhance the consistency between the atmospheric and the ocean-observing systems, not only in terms of timeliness and infrastructure but also in terms of funding support and sustainability. The European Environment Agency State of Play Report (The European Environment Agency [EEA], 2017) pointed out that the ocean-observing system lacks prospects for long term funding. About 70% of data in the GOOS is funded by time-limited research projects (in contrast to 25% for atmospheric observations). In situ ocean observations are based on infrastructures mainly supported by national agencies, and in recent years the number of observation sites and platforms have gone through periods of decline. They also emphasized that more coordination is needed between funding agencies, operators, and users of ocean observations internationally. In addition, the EEA State of Play report emphasized the lack of biogeochemical and deep (2000 m and deeper) ocean observations. Finally, the combination of increases in computing power and availability of observations has enabled the development of ensemble coupled DA systems. Ensemble-based approaches have the ability to identify and track the largest growing disturbances within the system. These growing disturbances represent regions of high variance where potential predictability of the system resides. The identification of these growing disturbances provides information about regions of the ocean where observations are likely to have the largest impact on the evolving coupled system and likely lead to useful predictions at all scales. Emerging CDA methods, enabled by coupled Earth system modeling, provide a great opportunity for increased collaboration across communities and rapid advances in scientific understanding over the next decade."}]