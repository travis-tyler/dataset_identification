[{"section_title": "Abstract", "text": "Age Sagittal Coronal Axial X MRI (d, 75.4) 69 71 73 79 81 77 Figure 1 . Predicting accurate and realistic medical images can be revolutionary for a broad range of clinical applications. Here we propose a new framework named 3D Simulation-DANI-Net (3D.S-DANI-Net), developed to emulate the effects of ageing/neurodegeneration in high-resolution MRI. Our system can model individual spatiotemporal brain deformations using a complex adversarial network. This figure shows in a 3-plane orientation, the longitudinal MRI synthesized using our approach for a subject with Alzheimer's Disease at the age of 75.4. The blue box is the input MRI, all the other are our synthesized MRI.\nThe recent success of deep learning together with the availability of large medical imaging datasets have enabled researchers to improve our understanding of complex chronic medical conditions such as neurodegenerative diseases. The possibility of predicting realistic and accurate images would be a breakthrough for many clinical healthcare applications. However, current image simulators designed to model neurodegenerative disease progres-*Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report.\nA complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_ to_apply/ADNI_Acknowledgement_List.pdf sion present limitations that preclude their utility in clinical practice. These limitations include personalization of disease progression and the ability to synthesize spatiotemporal images in high resolution. In particular, memory limitations prohibit full 3D image models, necessitating various techniques to discard spatiotemporal information, such as patch-based approaches. In this work, we introduce a novel technique to address this challenge, called Profile Weight Functions (PWF). We demonstrate its effectiveness integrated within our new deep learning framework, showing that it enables the extension to 3D of a recent state-of-theart 2D approach. To our knowledge, we are the first to implement a personalized disease progression simulator able to predict accurate, personalised, high-resolution, 3D MRI. In particular, we trained a model of ageing and Alzheimer's disease progression using 9652 T1-weighted (longitudinal) 1 arXiv:1912.01526v1 [eess.IV] 3 Dec 2019 MRI from the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset and validated on a separate test set of 1283 MRI (also from ADNI, random partition). We validated our model by analyzing its capability to synthesize MRI that produce accurate volumes of specific brain regions associated with neurodegeneration. Our experiments demonstrate the effectiveness of our solution to provide a 3D simulation that produces accurate and convincing synthetic MRI that emulate ageing and disease progression.\nThe recent success of deep learning together with the availability of large medical imaging datasets have enabled researchers to improve our understanding of complex chronic medical conditions such as neurodegenerative diseases. The possibility of predicting realistic and accurate images would be a breakthrough for many clinical healthcare applications. However, current image simulators designed to model neurodegenerative disease progres-*Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report.\nA complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wp-content/uploads/how_ to_apply/ADNI_Acknowledgement_List.pdf sion present limitations that preclude their utility in clinical practice. These limitations include personalization of disease progression and the ability to synthesize spatiotemporal images in high resolution. In particular, memory limitations prohibit full 3D image models, necessitating various techniques to discard spatiotemporal information, such as patch-based approaches. In this work, we introduce a novel technique to address this challenge, called Profile Weight Functions (PWF). We demonstrate its effectiveness integrated within our new deep learning framework, showing that it enables the extension to 3D of a recent state-of-theart 2D approach. To our knowledge, we are the first to implement a personalized disease progression simulator able to predict accurate, personalised, high-resolution, 3D MRI. In particular, we trained a model of ageing and Alzheimer's disease progression using 9652 T1-weighted (longitudinal) MRI from the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset and validated on a separate test set of 1283 MRI (also from ADNI, random partition). We validated our model by analyzing its capability to synthesize MRI that produce accurate volumes of specific brain regions associated with neurodegeneration. Our experiments demonstrate the effectiveness of our solution to provide a 3D simulation that produces accurate and convincing synthetic MRI that emulate ageing and disease progression."}, {"section_title": "", "text": ". Predicting accurate and realistic medical images can be revolutionary for a broad range of clinical applications. Here we propose a new framework named 3D Simulation-DANI-Net (3D.S-DANI-Net), developed to emulate the effects of ageing/neurodegeneration in high-resolution MRI. Our system can model individual spatiotemporal brain deformations using a complex adversarial network. This figure shows in a 3-plane orientation, the longitudinal MRI synthesized using our approach for a subject with Alzheimer's Disease at the age of 75.4. The blue box is the input MRI, all the other are our synthesized MRI."}, {"section_title": "Introduction", "text": "Predicting and preventing neurodegenerative diseases is one of the global health challenges of the 21st century. Disease progression modelling has been used to describe the time course of neurodegeneration and track the related disease severity, enabled by the availability of large longitudinal clinical and imaging studies. Although the biomarker data contained in these studies are only available at discrete and irregular time points, and from individuals that each cover only a fraction of the entire process, data-driven approaches have shown promising results to infer a comprehensive trajectory of the disease [13] . Some of these approaches attempt to model neurodegeneration directly on full resolution MRI, opening the door for important clinical and technical applications. From the clinical point of view such systems might be useful for: i) early and differential diagnosis; ii) improved precision for clinical trials; and iii) training clinicians. From the technical point of view, such systems might be used for validating other computational models, or to generate synthetic data (data augmentation) for improving the generalizability of novel AI frameworks (avoiding the need for large numbers of expensive scans).\nInitial solutions developed for this problem were restricted to learning only one morphological deformation across all subjects or, eventually, a few morphological templates associated to specific sub-groups [3, 9, 15, 12] . More advanced approaches learn subject-specific deformations. One of the first attempts in this direction was proposed in [10] , which combined a biophysical model and a deformation field obtained by non-rigid registration of two real images to impose the desired level of atrophy and generate the simulated image. Due to its complex computational model, this approach is extremely resourcedemanding and is not scalable to high-resolution images. Exploiting the success of deep learning, Bowles et al. [2] proposed a framework based on Generative Adversarial Networks (GANs). This approach used image arithmetic to add or subtract atrophy patterns by manipulating the MRI directly but was restricted to linear disease progression and morphological changes that are the same across all subjects. To obtain subject-specific morphological changes, Dalca et al. [4] proposed a probabilistic model that can learn either a universal or a conditional template, jointly with a neural network that provides efficient alignment of the images to these templates. A more advanced deep learning approach was proposed in [19] , where adversarial training is used to learn the joint distribution of brain images and ages. Similarly, [14] proposed DANI-Net, a framework adapted initially from a face-ageing model. Rather than using a traditional conditional GAN [1, 11] , DANI-Net [14] is based on a conditional adversarial autoencoder that enables conditioning the progression not only upon age but also fixed characteristics like clinical diagnosis, while smoothing the progression to improve temporal consistency. Additionally, whilst [19] uses only cross-sectional data to train the system, [14] introduces novel biological constraints (regional and voxel-based) to exploit longitudinal data for improving the precision of neurodegeneration. Although [19, 14] both propose subject-specific progression, they are only available for 2D images.\nThe challenge of synthesizing accurate and realistic 3D medical images in high resolution is not straightforward. Memory limitations necessitate working only on a localized area of the input (patches, 2D slices, etc.) that discards spatiotemporal information. Applications that require the use of this data can decompose the problem into learning multiple models in a lower dimension of the input. However, unifying these models can be challenging, particularly if their training is hampered by instability that creates spatial/temporal discontinuity between their output. In this work, we introduce PWF developed to deal with this problem. We demonstrate its effectiveness integrated within our new deep learning framework, showing that it enables the extension to 3D of a recent state-of-the-art 2D approach called Degenerative Adversarial NeuroImage Net (DANI-Net). Our 3D simulation framework demonstrates superior accuracy and capability to model subject-specific disease progression on high-resolution 3D MRI.\nThe rest of the paper is structured as follows. In Section 2 we summarize the baseline method of [14] , which was developed to model neurodegeneration for a single 2Dslice of MRI. Then, in Section 3 we present our novel framework, \"3D.S-DANI-Net\", which extends the baseline approach to 3D via our novel PWF technique, and adds other improvements. In particular, Section 3.4 describes PWF, which is sufficiently general to be applied in many other high-dimensional computer vision applications involving deep learning. In Section 4 we describe the data set and our training protocol. Finally, the experimental results are presented in Section 5, and Section 6 concludes the paper. straints associated with neurodegenerative disease progression. DANI-Net operates on a single 2D-slice of MRI and consists of the following blocks:"}, {"section_title": "Pre-processing", "text": "The input slice x is normalized to remove irrelevant variation through three steps: i) linear co-registration to 1mm isotropic MNI template; ii) skull-stripping; iii) intensity normalisation to zero mean and unit standard deviation."}, {"section_title": "Conditional Deep Autoencoder (CDA)", "text": "This block is composed of two deep neural networks: an encoder E that embeds x in a latent space Z, and a generator G that projects back to the original manifold.\nThe latent vector Z is conditioned on two variables: d -a numerical representation [0-3] of diagnosis (i.e. cognitively normal, subjective memory concern, early/late mild cognitive impairment, Alzheimer's disease); and a \u2208 {1, ..., A} an index describing age, binned into A=10 groups. The CDA learns the morphological brain changes that occur during ageing or disease progression. This employs a deformation loss L def that minimizes the difference between the input x and a weighted average of two outputs from the nearest age bins:\nwhere \u03b1 reflects the distance between the input age a * and the output group a and a + 1 and g a = G(E(x), a, d) are the synthetic images generated by the CDA."}, {"section_title": "Adversarial Training", "text": "This block involves two discriminator networks, D z and D b , trained in an adversarial manner with the CDA. D z drives E to produce z with a uniform prior to smooth temporal progression. Training uses the following loss function: (2) where E is the expectation operator, z * is a vector sampled from U, D z estimates the probability that a vector comes from U, and E(x) is the latent vector obtained from x. D b drives G to produce realistic brain images. Training uses the following loss function:\nwhere D b estimates the probability that a slice contains realistic brain structures."}, {"section_title": "Biological Constraints", "text": "This block models neurodegeneration through a set of regional and voxelwise constraints that ensure decreasing image intensity (brain tissue density [17] ) with age. For a synthetic output g a in age group a, the first loss function L vox imposes that all g i with i < a has equal or higher intensity, and that g j with j > a has equal or lower intensity. Recall that intensity is normalized in the first block. This loss function is a good regularizer for the progression, but it introduces voxelwise rigidity caused by unmodeled intensity changes due to tissue deformation. A second loss function L reg overcomes this limitation and models regional neurodegeneration through a set of pre-trained support-vector regressors (SVRs). L vox and L reg are defined as follows:\nwhere M and N are the slice dimensions, and sgn is the sign function.\nwhere R is the number of regions, r i is the i-th regionmask, SV R i (p, a, d) is the corresponding intensity change, and = 0.1 avoids numerical errors."}, {"section_title": "DANI-Net Total Loss", "text": "The total loss used to train the CDA of DANI-Net is a weighted sum of the constituent loss functions:\nis cross entropy obtained by the discriminator D z on the generated latent vectors, and\nThe weights allow for framework customization, such as: -increasing w reg increases the contribution of disease progression (the SVRs); -increasing w vox regularizes voxel intensity changes for flat regions, but may increase rigidity of brain structures; -increasing w b increases model generalization at the cost to decrease favours qualitatively realistic brain images; -increasing w z reduces temporal smoothing to allow rapid progression, which can introduce temporal discontinuity; -increasing w def increases similarity across age, which diminishes progression learned by the SVRs. It is clear that some loss functions optimize concurrent tasks and thus finding the optimal configuration for these weights is not straightforward. Figure 2 shows 3D.S-DANI-Net, which modifies the architecture proposed in [14] in two key ways: i) increasing accuracy of the underlying model of neurodegeneration through refined loss functions L * def , L * vox , L * reg ; and ii) extending from 2D to 3D MRI using the new PWF block that unifies training of multiple 2D models (one per slice). The subsections below describe each modification."}, {"section_title": "Proposed Method (3D.S-DANI-Net)", "text": ""}, {"section_title": "Deformation Loss", "text": "Eq. 1 proposed in [14] minimizes the difference between each input x having input age a * \u2208 R, and a weighted average of the two adjacent age bins. This discretization process allows learning of morphological changes between age groups and prevents the CDA from memorizing (in the latent space) the value of a * as an individual representation for each sample and thereby overfitting the related age conditioning. The real value a * was used to compute the degree of membership \u03b1 for the two closest output bins. In 3D.S-DANI-Net, we consider not only the two closest age bins but the entire output sequence g a with a \u2208 1, ..., A. Explicitly, we impose a degree of similarity between the input and each of the generated outputs g a . The degree of similarity is determined through a fuzzy Gaussian membership function \u00b5 i [m i , \u03c3 i ] centred on the average age m i of each bin and with \u03c3 i proportional to the maximum age difference \u03b4 i (e.g. \u03c3 i = \u221a \u03b4 i \u00b7 0.2). The reason behind this is that since the generated sequence of images belongs to a single individual, the entire sequence should preserve some similarity with the input. Additionally, the similarity must be higher for output associated with age groups closer to a * and lower for the others. Consequently, we propose the following modification to L def :\n3.2. Regional Loss\nIn [14] the rates of intensities change of each brain region were imposed by a set of SVRs (Eq. 5). However, most neurodegeneration models proposed in the literature show that brain atrophy increases monotonically until a plateau is reached [8] . Accordingly, we replace the SVRs with logistic regressors (LRs). One advantage is that the regression will be less sensitive to regions having fewer training samples, e.g., age extremes. Logistic regressors are also much faster to train and to run. We also propose a second refinement to this loss that weights regressor errors by a value related to the region size s i to prioritise consistent intensity within large regions.\nAccording to these two considerations, L reg is updated as follows:\nwhere LR i is the logistic regressor for region i."}, {"section_title": "Voxel Loss", "text": "Eq. 4 proposed in [14] uses the sign function to impose monotonicity of progression in each voxel. Here we redefine L vox with min-max operators as follows:\nL2(x, min(g1, ..., ga\u22121))+ L2(x, max(ga+1, ..., gA))\nAlthough Eq. 9 and Eq. 4 optimize the same properties, the former has the advantage to be much faster during training."}, {"section_title": "3D Consistency", "text": "DANI-Net requires approximately 11GB of GPU memory to train the neurodegeneration model on a single 2Dslice. With current hardware technology we are not able to train a full spatiotemporal model for a high-resolution 3D-MRI (total memory required is 11GB \u00b7 (#slices) = 150GB). An alternative solution is to train each 2D-slice separately and unify them in a sensible manner. Here we exploit this principle imposing consistency at two different levels:\n-training consistency: we proposed PWF, a strategy for training many different networks so that they follow a similar path on the error surface, thereby ensuring a consistent optimal solution. -spatial consistency: we reinforce spatial consistency using a weighted average between models trained on consecutive slices."}, {"section_title": "Training Consistency (PWF)", "text": "Due to the high dimensionality of the problem and the use of a complex loss function (a weighted sum of multiple losses), the training of DANI-Net was often unstable [14] . This is especially problematic for extending to 3D. Convergence failures in some slices will generate spatialinconsistency in the synthetic MRI. The problems of instability of a deep neural network are often associated to the difficulty in terms of the features of the landscape or error surface that the optimization must navigate to be able to deliver a good solution that avoids local minima. The adversarial components of DANI-Net (D z and D b ) are comparable to two GANs, which makes matters worse since it is well known that they suffer from training instability [5, 7] . Consequently, traditional techniques developed to deal with this type of training issues are not adequate in DANI-Net. Fig. 3 shows an example of a hypothetical training manifold having a few local minima that some networks are not able to avoid.\nTo guarantee that multiple DANI-Net models associated with different slices converge to a stable and consistent solution, we propose PWF. The intuition behind this technique is as follows: assuming we have multiple sub-loss functions, PWF uses a set of profile functions that weight the relevance of each loss during the training and guide the network to follow a specific path towards the global minimum on the error surface. In other words, these predefined profile functions help the system to avoid exploring irrelevant areas of the manifold and prevent it from getting stuck in a w4 w5 slice n-1 slice n slice n+1\nTraining iteration (i)"}, {"section_title": "PWF", "text": ""}, {"section_title": "Loss relevance", "text": "Local minimum"}, {"section_title": "Common Initialization", "text": ""}, {"section_title": "Local minimum", "text": "Training manifold Figure 4 . Proposed PWF strategy. The relevance of each loss during training is specified by a profile function. In this case, the networks follow a specific path in the manifold and avoid local minima.\nlocal minimum. Fig.4 depicts how PWF helps to avoid the local minima and, in our case, ensure that different models reach a consistent optimal solution. The definition of these profile functions is applicationspecific and can be derived by analyzing how a human would solve that visual problem (i.e. following a multistage learning strategy where the simpler sub-tasks are optimized first and then the more complicated ones).\nIn our case, to identify the profile functions and their parameters, we perform an experimental evaluation on the validation set based on visual inspection of the results and on verifying the training convergence of different networks. For this application we found that a good strategy to train our framework is as follows: to start, high importance on the weight w * def (associated with the deformation loss) is first imposed, in this way the network learns a simple progression model based on conditional morphological deformations. Then, using an exponential decay function, the relevance of w * def is reduced whereas the contribution of w * vox and w * reg are increased allowing a further and gradual expansion of the brain regions based on the learnt LR i regressors. The relevance of w z and w b associated, respectively, with temporal smoothing and image realism, are also increased. As explained in Section 2.5, increasing w z reduces temporal smoothing so that neurodegeneration can commence without losing temporal continuity, while increasing the relevance for w b gradually relaxes the constraint on image realism. Although this last point might seem counterintuitive, it is important for generalization performance since generated images may be quite different from the training samples and, in this case, the discriminator D b would recognize them as unrealistic although they could potentially be real. This behaviour can drive the generator G to avoid creating these brain structures although they are reasonable, which amounts to overfitting of individual morphology.\nIn our experiments, we also realize that traditional ini-tialization approaches (zero initialization, random initialization, Xavier initialization, etc.) are inadequate when PWF is used in the pipeline. Instead, in this scenario, the training models have to start from a common training point (red cloud in Fig. 4 ). To do so, we build an initialization model obtained through 10 training epochs on the training-set images obtained from one of the central slices of the MRI. This pre-trained model is then used as initialization for all the models in 3D.S-DANI-Net.\nThe aforementioned training strategies are translated into the training process using the following profile functions:\nwhere e is the current epoch, l pwf = 0.99 describes how fast the profile functions inside PWF will act, b reg = 1.25, b vox = 1.25, b b = 0.002, b z = 0.05, b def = 100 are the initial weights for the different losses and finally v controls the width expansion of the profile functions."}, {"section_title": "Spatial Consistency", "text": "The last strategy used to ensure the consistency of 3D.S-DANI-Net is to impose spatial correlation between models associated with consecutive 2D slices. This process is described schematically in Fig. 5 . For each slice I i with i \u2208 {1, ..., T } the current index in the axial view of the input X M RI , we use a window of k models of 3D.S-DANI-Net named DN n with n \u2208 [i \u2212 k 2 , i + k 2 ]. A weighted sum of the outputs DN n is used to build the final synthetic slice O i . All output O i are then assembled to create the final synthetic Y M RI . In our final configuration, we use a window k=5 and a Gaussian weight function having \u03c3=1.5."}, {"section_title": "Region Extraction Based on Atlas", "text": "The brain regions in DANI-Net [14] were determined in a data-driven fashion using a hierarchical clustering approach. However, we realize that this can lead to regional inconsistency when different slices are processed separately. To avoid this problem, in 3D.S-DANI-Net the regions are pre-defined by a brain atlas and imposed on each MRI using linear registration. The extracted regions are then used to train the logistic regressors LR i , and also to embed in the system the regional ratio of intensity changes learnt by these regressors. This process not only increases the biological meaning of the disease progression model but also avoids regional inconsistencies between consecutive slices."}, {"section_title": "DNn-2(In-1)", "text": "\u2022 Figure 5 . Pipeline describing the spatial consistency strategy used in 3D.S-DANI-Net."}, {"section_title": "Training Details, Parameters and Evaluation", "text": "Data used in the preparation of this article were obtained from the ADNI database (adni.loni.usc.edu). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimer's disease (AD).\nIn our experiments, we selected 12386 pre-processed T1-weighted MRI scans from N = 1234 participants in the ADNI dataset. The scans were obtained using different preprocessing pipelines, scanners, and at multiple sites. Participants were aged between 63 and 87 years old, and 28% were cognitively normal, 4% have been diagnosed with subjective memory concern, 54% with mild cognitive impairment and 14% with Alzheimer's disease. Each participant has on average 4.7 MRI spanning 3 years. We divided our dataset in train-set (MRI: 9852; participants: 876), test-set (MRI-slices: 1283; participants: 179) and validation set (MRI-slices: 1251; participants: 179). In the test-set, we make sure that participants have at least one follow-up visit two years after baseline, to allow sufficient time for observable neurodegeneration to occur.\nThe validation set is used to tune the system through the profile functions assessed by visual inspection of the output (see Section 3.4.1).\nOnce these functions are defined, we train, using 3D.S-DANI-Net, T = 95 DN i models, each associated with one of the different slices of the X M RI . Each DN i has its own Figure 6 . Synthetic MRI obtained by different configurations of our approach against the baseline and generated starting from 2 participants in the test set. The red circle highlights an artefact created when the network does not converge to a global minimum. Green circles show aliasing artefacts due to slice misalignment, and yellow boxes show artefacts on spatial discontinuity generated again by unstable training.\nset of region masks r i and its own set of logistic regressors LR i but they are all trained using the same profile function and the same training configuration that is based on the stochastic gradient descent solver, ADAM (\u03b1 = 0.0002, \u03b21 = 0.5). We stop the training procedure after 400 epochs where each iteration uses a random mini-batch with 100 slices (2D) having the size of 128\u00d7128. In each DN i and for each test participant, we also apply a final transfer learning step where we align the test MRI-slice to the model by age and diagnosis. This step involves an additional 50 training iterations on a single input image. To note, only the MRI from each test subject's first visit is used to personalise the trained model. This transfer learning step is essential to tune the model for the specific morphology of the individual's brain. For a fair comparison, all the considered frameworks include this transfer learning step in the training pipeline. In our evaluation, X M RI is the input MRI from the baseline visits, Y * M RI is the follow-up MRI (ground truth) against which we evaluate the generated Y M RI .\nFinally, since DANI-Net was not designed to handle 3D input, for comparison purposes, we generated the corresponding full 3D MRI by stacking the 2D output obtained from the different models (one per each slice) on top of each other."}, {"section_title": "Results", "text": "Here we report the results of our experiments. We investigate each component of our framework by characterizing model performance quantitatively across multiple model configurations. We also provide a complementary qualitative analysis of image realism.\nOur quantitative experiments involve volumes of selected brain regions that are relevant to neurodegeneration in both ageing and Alzheimer's disease. In synthetic and real MRI, we calculate volumes using the FSL library [16] for the following regions: left hippocampus (lh), right hippocampus (rh), peripheral grey matter (pgm), ventricular cerebrospinal fluid (v csf ), total gray matter (gm), and total white matter (wm). We control for individual head size by dividing volumes by total brain volume. The volumetric error between synthetic MRI and real MRI is examined for multiple model configurations and benchmarked against the existing baseline method (DANI-Net [14] ).\nWe evaluate the individual contribution of each of the three components of 3D.S-DANI-Net: i) the new loss functions, denoted L * ; ii) the spatial consistency constraint SP ; and iii) the training consistency block incorporating our new profile functions, P W F . Table 1 reports absolute errors (mean and standard deviation) in volumes, expressed as a percentage of total brain volume. We also report a total error (T err ) computed as the average error across regions, each first normalized in the range [0,1] to reflect clinical applications where abnormality in regions are considered equally important [6] .\nOur results show that, with respect to the baseline approach, L * reduces error in all regions, although always within one standard deviation of the mean error. This suggests that our new loss functions are working as intended. We note that, although the errors in gm and wm appear identical, they are in fact opposite in sign, indicating that volumetric errors are concentrated around the gm/wm boundary, which could be due in part to partial volume effects [18] . Additionally, our model improves performance considerably in the pgm region, which is particularly challenging to predict due to the outer cortical brain surface being highly textured and highly variable between individuals.\nIn our experiments, we found that the proposed consistency strategies (SP and P W F ), if used separately, increased volumetric errors by up to 1% of total brain volume. This was most notable in large, flat regions (containing texture features with low-frequency) that span multiple slices. We hypothesize that this may be due to the additional complexity of enforcing constraints across models (of multiple MRI slices), relative to within a model. With reference to L * , SP increases the error negligibly for v csf (+0.09% of total brain volume), but almost doubles the error in both gm and wm (albeit only from \u223c 1.5% to \u223c 3% of total brain volume). The situation is better for P W F , where the error increases by +0.06% in v csf , and +0.35% in both gm and wm. We conclude that to generate realistic MRI with an accurate global appearance, the proposed training consistency approach (PWF) is more beneficial than the proposed spatial consistency constraints. Vice versa, if accuracy is desirable in smaller regions of interest (such as lh and rh) or in highly-textured features such as pgm, then the betweenmodel consistency (SP ) should be prioritised -as shown in Table 1 for configuration L * -SP versus L * -P W F .\nThe last row of the table shows that, although the full configuration L * -SP -P W F does not provide the best results on the individual regions in terms of absolute volumetric error, the use of the combination of SP and P W F minimizes our clinically-relevant total error metric T err . In fact, with respect to the baseline approach, our full configuration reduces T err by almost half from \u223c 0.58 to \u223c 0.33. This promotes the use of 3D.S-DANI-Net in clinical applications. We examined this further by assessing the improvements obtained by L * -T P -SC with respect to the baseline method statistically using a paired t-test. For lh, rh and pgm, all p-values were less than 0.0001 whereas for gm and wm the improvement was not statistically significant.\nFor the qualitative analysis, two randomly-selected cases are reported in Fig. 6 . As we can see here, the output generated by the L * -SP -P W F configuration produces visu-ally superior synthetic MRI having fewer artefacts than synthetic MRI generated by the baseline approach, and by the other configurations. Notable artefacts appear in sagittal and coronal axes, which are most likely due to these approaches lacking any consistency constraints. Additionally, some of the 2D models may fail to converge, thereby creating discontinuity along these axes (yellow boxes in Fig. 6 ). In the case of training instability, the artefacts may also be visible on the axial plane (red circle in Fig. 6 ).\nThe configurations L * -SP , L * -P W F and L * -SP -P W F reduce these issues. Images from L * -SP have limited discontinuity artefacts thanks to the averaging of neighbouring models, but they lose high-frequency details. Images from L * -P W F preserves high-frequency features and reduces the discontinuity thanks to PWF, but consecutive slices are not aligned since PWF does not enforce spatial consistency which creates aliasing artefacts (green circles in Fig. 6 ). Finally, L * -SP -P W F produces the fewest artefacts by trading off benefits from PWF and spatial consistency. We also report (not shown) that in age groups having fewer MRI available (i.e. age>80 and age<70), the predictions from all configurations are slightly more blurred.\nMore cases of our qualitative analysis are provided in the supplementary material where the improvements of L * -SP -P W F are tangible.\nFinally, in Fig. 1 we show an example of the entire simulation obtained using 3D.S-DANI-Net. Neurodegeneration is apparent in the progression, and the main manifestations are ventricular expansion, hippocampus contraction, and cortical thinning."}, {"section_title": "Conclusion and Future Work", "text": "We have proposed and evaluated a novel framework for simulating neurodegeneration in ageing and disease on high-resolution 3D MRI. We extended a recent 2D framework called DANI-Net [14] . Our new 3D simulation framework called 3D.S-DANI-Net encodes a spatiotemporal disease progression model in a complex deep neural network, including the use of profile weight functions (PWF) to overcome memory limitations that generally preclude full 3D spatiotemporal modelling. PWF is a deep learning training strategy that promises widespread utility in highdimensional computer vision applications where the train-ing of a complex adversarial network suffers from instability. Our approach guides model fitting convergence, especially in the case when traditional techniques developed to deal with these problems are inadequate.\nExperiments showed improved quantitative and qualitative performance of our new framework over previous work. Our framework produces realistic, high-resolution, 3D, synthetic MRI that accurately predict relevant brain volumes (in real MRI) during normal ageing and Alzheimer's disease progression. We highlighted the contributions of each component of our framework, which enable customizable modelling choices configured to specific applications.\nAlthough we specifically modelled ageing and diseaserelated neurodegeneration in MRI, we believe 3D.S-DANI-Net can be used with different medical imaging modalities (e.g. PET, CT, etc.) and to model disease progression in other organs (i.e., lung, prostate, heart, spinal cord, retina).\nIn our experiments, we limited model conditioning to only age and clinical diagnosis, but the framework can handle additional conditional features (e.g. disease phenotype, genotype, demographics, lifestyle measures, cognitive and behavioural score) to personalize the model further."}]