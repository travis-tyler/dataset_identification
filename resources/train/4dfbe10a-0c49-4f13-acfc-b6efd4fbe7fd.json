[{"section_title": "Abstract", "text": "Manifold learning theory has seen a surge of interest in the modeling of large and extensive datasets in medical imaging since they capture the essence of data in a way that fundamentally outperforms linear methodologies, the purpose of which is to essentially describe things that are flat. This problematic is particularly relevant with medical imaging data, where linear techniques are frequently unsuitable for capturing variations in anatomical structures. In many cases, there is enough structure in the data (CT, MRI, ultrasound) so a lower dimensional object can describe the degrees of freedom, such as in a manifold structure. Still, complex, multivariate distributions tend to demonstrate highly variable structural topologies that are impossible to capture with a single manifold learning algorithm. This chapter will present recent techniques developed in manifold theory for medical imaging analysis, to allow for statistical organ shape modeling, image segmentation and registration from the concept of navigation of manifolds, classification, as well as disease prediction models based on discriminant manifolds. We will present the theoretical basis of these works, with illustrative results on their applications from various organs and pathologies, including neurodegenerative diseases and spinal deformities."}, {"section_title": "Introduction", "text": "Learning on large medical imaging datasets is an emerging discipline driven from the availability of vast amounts of raw data in many of today's biomedical studies. However, challenges such as unbalanced data distributions, complex multivariate data and highly variable structural topologies demonstrated by real-world samples makes it much more difficult to efficiently learn the associated representation. An important goal of scientific data analysis in medicine, particularly in neurosciences or oncology, is to understand the behavior of biological process or physiological/morphological alterations. This introduces the need to synthesize large amounts of multivariate data in a robust manner and raises the fundamental question of data reduction: how to discover meaningful representations from unstructured high-dimensional medical images.\nSeveral approaches have attempted to understand how dimension reduction and regression establishes the relationship in subspaces and finally determine statistics on manifolds that optimally describe the relationships between the samples [1] . However, certain assumptions based on the representation of shapes and images using smooth manifolds are made in most cases, which frequently will not be adequate in the presence of medical imaging data and often perturbed by nuisance articulations, clutter or varying contrast.\nHigh-dimensional classification methods have shown promise to measure subtle and spatially complex imaging patterns that have diagnostic value [2, 3] . Defining statistics on a manifold is not a straightforward process when simple statistics cannot be directly applied to general manifolds [4] . But while Euclidean estimators have been used for vector spaces, none have been adapted for multimodal data lying in different spaces. Still, there has been interest in the characterization of data in a Riemann space [5, 6] . Unfortunately, manifold-valued metrics based on the centrality theory or the geometric median [7] often lacks robustness to outliers.\nA related topic lies in dimensionally reduced growth trajectories of various anatomical sites which have been investigated in neurodevelopment of newborns for example, based on geodesic shape regression to compute the diffeomorphisms with image time series of a population [8] . These regression models were also used to estimate spatiotemporal evolution of the cerebral cortex [9] . The concept of parallel transport curves in the tangent space from lowdimensional manifolds proposed by Schiratti et al. [10] was used to analyze shape morphology [11] and adapted for radiotherapy response [12] . Regression models were proposed for both cortical and subcortical structures, with 4D varifold-based learning framework with local topography shape morphing being proposed by Rekik et al. [13] .\nThis chapter presents several manifold learning methodologies designed to address challenges encountered in medical imaging. In Section 2, we present an articulated shape inference model from nonlinear embeddings, expressing the global and local shape variations of the spine and vertebrae composing it, introduced in [14] . We then present in Section 3 a probabilistic model from discriminant manifolds to classify the neurodegenerative stage of Alzheimer's disease. Finally, a piecewise-geodesic transport curve in the tangent space from low-dimensional manifolds designed for the prediction of correction in spinal surgeries is shown in Section 4, introducing a time-warping function controlling the rate of shape evolution. We conclude this article in Section 5."}, {"section_title": "Shape inference through navigating manifolds", "text": "Statistical models of shape variability have been successful in addressing fundamental vision tasks such as segmentation and registration in medical imaging. However, the high dimensionality and complex nonlinear underlying structure unfortunately makes the commonly used linear statistics inapplicable for anatomical structures. Manifold learning approaches map high-dimensional observation data that are presumed to lie on a nonlinear manifold, onto a single global coordinate system of lower dimensionality.\nInferring a model from the underlying manifold is not a novel concept but far from being trivial. In this section, we model both global statistics of the articulated model and local shape variations of vertebrae based on local measures in manifold space. We describe a spine inference/segmentation method from CT and MR images, where the model representation is optimized through a Markov Random Field (MRF) graph, balancing prior distribution with image data. "}, {"section_title": "Data representation", "text": "\u00bd using recursive compositions. The transformations are expressed in the local coordinate system (LCS) of the lower vertebra. Center of transformation is the intersection of all three vertebral axes, following anteroposterior, cranial-caudal and leftright directions. Rigid transformations described here are the combination of a rotation matrix R, a translation t and scaling s. We formulate the rigid transformation T \u00bc s; R; t fg of a triangular mesh model as y \u00bc sRx \u00fe t where x, y, t \u2208 \u211c 3 ."}, {"section_title": "Manifold embedding", "text": "For nonlinear embeddings, we rely on the absolute vector representation A abs as given previously. Let us now consider N articulated shape models expressed by the feature vectors A i abs ,of dimensionality D. The aim is to create a low-dimensional manifold consisting of N points Y i , [15] . In such a framework, if an adequate number of data points is available, then the underlying manifold M is considered to be \"well-sampled.\" Therefore, it can represent the underlying population structure. In the sub-cluster corresponding to a pathological population, each point of the training set and its neighbors would lie within a locally linear patch as illustrated in Figure 1 .\nThe main limitation of embedding algorithms is the assumption of Euclidean metrics in the ambient space to evaluate similarity between sample points. Thus, a metric in the space of articulated structures is defined so that it accommodates for anatomical spine variability and adopts the intrinsic nature of the Riemannian manifold geometry allowing us to discern between articulated shape deformations in a topological invariant framework. For each point, the K closest neighbors are selected using a distortion metric which is particularly suited for \nWhile for the translation, the L 2 norm is chosen, geodesical distances are used between rotation neighborhoods. This is expressed as\nwhere the log map is used to map a point in the manifold to the tangent plane.\nAfterwards, the manifold reconstruction weights are estimated by assuming the local geometry of the patches can be described by linear coefficients that permit the reconstruction of every model point from its neighbors. In order to determine the value of the weights, the reconstruction errors are measured using the following objective function:\nsubject to\nThus, \u03b5 W \u00f0\u00de sums the squared distances between all data points and their corresponding reconstructed points. The weights W ij represent the importance of the j th data point to the reconstruction of the i th element. "}, {"section_title": "Manifolds II -Theory and Applications 84", "text": "The algorithm maps each high-dimensional A i abs to a low-dimensional Y i . These internal coordinates are found with a cost function minimizing the reconstruction error:\nwith M as a sparse and symmetric N \u00c2 N matrix enclosing the reconstruction weights W ij such \n. The Gaussian regression kernels G require the neighbors A j abs of j \u2208 N i \u00f0\u00deto determine the bandwidths h, g so it includes all K data points (N i \u00f0\u00derepresenting the neighborhood of i). Plugging these estimates in Eq.(5), this gives:\nBy assuming G is symmetric about the origin, we propose to integrate in the kernel regression estimator, the manifold-based distortion metric d M which is particularly suited for geodesic metrics and articulated diffeomorphisms. This generalizes the expectation such that the observations Y are defined in manifold space M:\nwhich integrates the distance metric d M A "}, {"section_title": "Optimization on manifold", "text": "Once an appropriate modeling of spine shape variations is determined with a manifold, a successful inference between the image and manifold must be accomplished. We describe here how a new model is generated. We search the optimal embedded manifold point Y \u00bc y 1 ; \u2026; y d \u00c0\u00c1 of the global spine model. Such a strategy offers an ideal compromise between the prior constraints, as well as the individual shape variations described by the weight vector W \u00bc w 1 ; \u2026; w n \u00f0\u00de in a localized sub-patch. The energy E of inferring the model S in the image I is a function of the set of displacement vectors \u0394 in the manifold space for global shape representation. This involves: (a) a data-related term expressing the image cost and (b) a global prior term measuring deformation between low-dimensional vectors with shape models. The third term represents (c) a higher-order term which is expressed by the reconstruction weights \u03a9 for local vertebra modeling. The energy E can be expressed as the following combination of a global and local optimization:\nThe global alignment of the model with the target image primarily drives the deformation of the model. The purpose is to estimate the set of articulations describing the global spine model by determining its optimal representation Y 0 in the embedded space. This is performed by obtaining the global representation using the mapping in (7) so that:\n. This allows to optimize the model in manifold space coordinates while retrieving the articulations in I . The global cost can be expressed as:\nThe inverse transform allows to obtain A i abs \u00fe D, with D as deformations in the image space. Since the transformations T i are implicitly modeled in the absolute representation A 0 abs , we can formally consider the singleton image-related term as a summation of costs associated with each L vertebra of the model:\nwhere\nminimizes the distance between mesh vertices of the inferred shape and gradient image I by a rigid transformation. Here, n i is the normal pointing outwards and \u2207I v i \u00f0\u00de the image gradient at v i .\nThe prior constraint for the rigid alignment are pairwise potentials between neighboring models y i such that the difference in manifold coordinates is minimal with regards to a prior distribution of neighboring distances P:\nThis term represents the smoothness term of the global cost function to ensure that the deformation \u03b4 i applied to point coordinates are regular, with V ij \u00bc 0; 1 \u00f0\u00de a distance assigning function based on the distances to P.\nOne can integrate the global data and prior terms along with local shape terms parameterized as the higher-order cliques, by combining (9), (11):\nThe optimization strategy of the resulting MRF (12) in the continuous domain is not a straightforward problem. The convexity of the solution domain is not guaranteed, while gradientdescent optimization approaches are prone to nonlinearity and local minimums. We seek to assign the optimal labels L \u0394 \u00bc l 1 ; \u2026; l d fg and L \u03a9 \u00bc l 1 ; \u2026; l n fg which are associated to the quantized space \u0394 of displacements and local weight parameters \u03a9 respectively. We consider that displacing the coordinates of point y 0 i by \u03b4 l i is equivalent to assigning label l i to y 0 i .A n incremental approach is adopted where in each iteration t we look for the set of labels that improves the current solution s.t.\nwhich is a temporal minimization problem.\nThen (12) can be rewritten as:\nWe solve the minimization of the higher-order cliques in (13) by transforming them into quadratic functions [18] . We apply the FastPD method [19] which solves the problem by formulating the duality theory in linear programming."}, {"section_title": "Results", "text": "Manifold learning. The manifold was built from a database containing 711 scoliotic spines demonstrating several types of deformities. Each spine model in the database was obtained from biplanar radiographic stereo-reconstructions. It is modeled with 12 thoracic and 5 lumbar vertebrae (17 in total), represented by 6 landmarks on each vertebra (4 pedicle extremities and 2 endplate center points) which were manually identified by an expert on the radiographic images. The resulting manifold is shown in Figure 2 .\nAdaptation of the articulated model was done on two different data sets. The first consisted of volumetric CT scans (512 \u00c2 512 \u00c2 251, resolution: 0:8 \u00c2 0:8 mm, thickness: 1 \u00c0 2 mm) of the lumbar and main thoracic regions obtained from 21 different patients acquired for operative planning purposes. The MR dataset comprised multi-parametric volumetric data (256 \u00c2 256 \u00c2 160, resolution: 1:3 \u00c2 0:9 mm, thickness: 1 mm) of 8 patients acquired for diagnostic purposes. For this study, only the T1 sequence was selected for the experiments. All patients on both datasets (29 in total) had 12 thoracic and 5 lumbar vertebrae. Both CT and MR data were manually annotated with 3D landmarks by an expert in radiology, corresponding to left and right pedicle tips as well as midpoints of the vertebral body. Segmentation of the vertebrae from the CT and MR slices were also made by the same operator.\nCT imaging experiments. We first evaluated the model accuracy in CT images by computing the correspondence of the inferred vertebral mesh models to the segmented target structures. As a preprocessing step, a rough thresholding was performed on the whole volume to filter out noise artifacts. The overall surface-to-surface comparison results between the inferred 3D Figure 2 . Low-dimensional manifold embedding of the spine dataset comprising 711 models exhibiting various types of deformities. The sub-domain was used to estimate both the global shape pose costs and individual shape instances based on local neighborhoods.\nvertebral models issued from the articulated model and from known segmentations were first calculated. The mean errors are 2:2 AE 1:5 mm (range: 0:6 \u00c0 5:4 mm) for thoracic vertebra and 2:8 AE 1:9 mm (range: 0:7 \u00c0 8:1 mm) for lumbar vertebra."}, {"section_title": "MR imaging experiments.", "text": "For the experiments involving the segmentation of 3D spine models from MR images, the surface-to-surface comparison showed encouraging results (thoracic: 2:9 AE 1:8 mm, lumbar: 3:0 AE 1:9 mm) based on differences to ground-truth. As in the previous experiments with CT imaging, ground-truth data was generated by manually segmenting the structures models which were validated by an expert in radiology. As difficult as the CT inference is, the MR problem represent an even greater challenge as the image resolution is more limited and interslice spacing is increased compared to CT. Modeling of the statistical properties of the shape variations and global pose becomes even more important in this case, as it relies heavily in the nonlinear distribution of the patient morphology."}, {"section_title": "Probabilistic modeling of discriminant nonlinear manifolds in the identification of Alzheimer's", "text": "Neurodegenerative pathologies, such as Alzheimer's disease (AD), are linked with morphological and metabolic alterations which can be assessed from medical imaging and biological data. Recent advances in machine learning have helped to improve classification and prognosis rates, but lack a probabilistic framework to measure uncertainty in the data. In this section, we present a method to identify progressive mild cognitive impairment (MCI) and predict their conversion to AD from MRI and positron emitting tomography (PET) images. We show a discriminative probabilistic manifold embedding where locally linear mappings transform data points in low-dimensional space to corresponding points in high-dimensional space. A discriminant adjacency matrix is constructed to maximize the separation between different clinical groups, including MCI converters and nonconverters, while minimizing the distance in latent variables belonging to the same class."}, {"section_title": "Probabilistic model for discriminant manifolds", "text": "Manifold learning algorithms are based on the premise that data are often of artificially high dimension and can be embedded in a lower dimensional space. However the presence of outliers and multiclass information can on the other hand affect the discrimination and/or generalization ability of the manifold. We propose to learn the optimal separation between four classes (1) normal controls, (2) nonconverter MCI patients, (3) converter MCI patients and (4) AD patients, by using a discriminant graph-embedding. Here, n labeled points Y \u00bc y i ; l i \u00c0\u00c1 \u00c8\u00c9 n i\u00bc1 defined in R D are generated from the underlying manifold M, where l i denotes the label (NC, cMCI, nMCI or AD). For the labeled data, there exists a low-dimensional (latent) representation of the high-dimensional samples such that X \u00bc x i ; l i \u00f0\u00de fg n i\u00bc1 defined in R d .W e assume here that the mapping M i \u2208 R D\u00c2d between high and low-dimensional spaces is locally linear, such that tangent spaces in local neighborhoods can be estimated with y j \u00c0 y i and x j \u00c0 x i , representing the pairwise differences between connected neighbors i, j. Therefore the relationship can be established as\nIn order to effectively discover the low-dimensional embedding, it is necessary to maintain the local structure of the data in the new embedding. The graph G \u00bc V; W \u00f0\u00de is an undirected similarity graph, with a collection of nodes V connected by edges, and the symmetric matrix W with elements describing the relationships between the nodes. The diagonal matrix D and the Laplacian matrix L are defined as L \u00bc D \u00c0 W, with D i; i \u00f0\u00de \u00bc P j6 \u00bci W ij \u2200i.\nUsing the theoretical framework from [20] , we can determine a distribution of linear maps associated with the low-dimensional representation to describe the data likelihood for a specific model:\nThis joint distribution can be separated into three prior terms: the linear maps, latent variables and the likelihood of the high dimensional points Y:\nWe now define the discriminant similarity graphs establishing neighborhood relationships, as well define each of the three prior terms included in the joint distribution.\nWithin and between similarity graphs: In our work, the geometrical structure of M can be modeled by building a within-class similarity graph W w for feature vectors of same group and a between-class similarity graph W b , to separate features from all four classes. When constructing the discriminant locally linear latent variable embedding, elements are partitioned into W w and W b classes. The intrinsic graph G is first created by assigning edges only to samples of the same class (ex: nMCI). Each sample is therefore reconstructed only from feature vectors of the same clinical group. Local reconstruction coefficients are incorporated in the within-class similarity graph, such that W w is defined as:\nwith N w containing neighbors of the same class. Conversely, W b depicts the statistical properties to be avoided in the inference process. Distances between samples from different clinical groups are computed as:\nwith N b containing neighbors having different class labels from the ith sample. The objective is to transform points to a new manifold M of dimensionality d, i.e., y i ! x i , by mapping connected samples from the same group in W w as close as possible to the class cluster, while moving NC, nMCI, cMCI and AD samples of W b as far away from one another."}, {"section_title": "Model components:", "text": "The prior added on the latent variables X are located at the origin of the low-dimensional domain, while minimizing the Euclidean distance of neighboring points that are associated with the neighborhood of high-dimensional points and maximizing the distance between coordinates of different classes. In order to set the variables with an expected scale \u03b1 and H representing the probability density function, the following log prior is defined:\nThe prior added to the linear maps defines how the tangent planes described in low and high dimensional spaces are similar based on the Frobenius norm. This prior ensures smooth manifolds:\nFinally, approximation errors from the linear mapping M i between low and high-dimensional domains are penalized by including the following log likelihood:\nwith \u0394 i; j \u00f0\u00de the difference in Euclidean distance between pairs of neighbors in high and lowdimensional space and \u03b3 the update parameter for the EM inference. Samples of y are drawn from a multivariate normal distribution."}, {"section_title": "Variational inference", "text": "The objective is to infer the low-dimensional coordinates and linear mapping function for the described model, as well as the intrinsic parameters of the model \u03a6 \u00bc \u03b1; \u03b3 \u00f0\u00de . This is achieved by maximizing the marginal likelihood of:\nBy assuming the posterior r M; X \u00f0\u00de can be factored in separate terms r M \u00f0\u00de and r X \u00f0\u00de , a variational expectation maximization algorithm can be used to determine the model's parameters, which are initialized with \u03a6. The E-step updates the independent posteriors r X \u00f0\u00de and r M \u00f0\u00de , while the parameters of \u03a6 are updated in the M-step by maximizing Eq. (21).\nThe discriminant latent variable model can then be used to perform the mapping of new image feature vectors to the manifold. The variational EM algorithm described in the previous section can be used to transform a set of new input points y q without changing the overall neighborhood graph structure, by finding the distribution of the local linear map y q and it is lowdimensional coordinate using the E-step explained above. Once the manifold representation x q is obtained, a cluster analysis finds the corresponding class in the manifold, yielding a prediction of the input feature vector y q ."}, {"section_title": "Experiments", "text": "We used the Alzheimer's Disease Neuroimaging Initiative (ADNI) database with 1.5 or 3.0 T structural MR images (adni.loni.usc.edu) and FDG-PET images. For this study, 187 subjects with both MRI and PET images during a 24 month period were used to train the probabilistic manifold model, including 46 AD patients, 94 MCI patients, and 47 normal controls. During the follow-up period, 43 MCI subjects converted to AD and 56 remained stable. All groups are matched approximately by age (mean of 76:7 AE 5:4) and gender. Images were non-rigidly registered to a standard template, which was then segmented using FSL-FIRST automatic segmentation [21] .\nA 9-fold cross-validation was performed to assess the performance of the method. The optimal manifold dimensionality was set at d \u00bc 8, when the trend of the nonlinear residual reconstruction error stabilized for the entire training set. We evaluated the classification performance of the proposed method for discriminating between cMCI and nMCI patients, by training the model with MRI, PET and with MRI + PET biomarkers from the ROIs illustrated in Figure 3 . Figure 4 presents ROC curves obtained by the proposed and comparative methods such as SVM (nonlinear RBF kernel), LLE and LL-LVM [20] . The discriminative nature of the proposed framework clearly shows an improvement to standard learning approaches models which were trained using MRI only, PET only and combined multimodal features. It illustrates that increased accuracy (77.4%) can be achieved by combining MRI and PET features, showing the benefit of extracting complementary features from the dataset for prediction purposes. When comparing the performance of the proposed method to the other learning methods (SVM, LLE, \nThe discriminant manifold was trained from a database of 438 3D spine reconstructions generated from biplanar images [23] , originating from 131 patients demonstrating several types of deformities with immediate follow-up (FE), 1 and 2 year visits. Patients were recruited from a single center prospective study. Patients were divided in two groups, with the first group composed of 94 responsive patients showing a reduction in Cobb angle over or equal to 10 \u2218 between the FE and follow-up visit. The second group was composed of 37 nonresponsive (NP) patients with a reduction of less than 10 \u2218 . We evaluated the geometrical accuracy of the predictive manifold for 56 unseen surgical patients (mean age 12 AE 3, average main Cobb Predictions are evaluated at FE, 1 and 2-years. Table 1 . 3D RMS errors (mm), dice (%) and cobb angles ( o ) for the proposed method, and compared with biomechanical simulations, locally linear latent variable models (LL-LVM) and deep auto-encoders (AE).\nangle on the frontal plane at the first visit was 47 AE 10 \u2218 ), with predictions at t \u00bc 0 (FE), t \u00bc 12 and t \u00bc 24 months. For the predicted models, we evaluated the 3D root-mean-square difference of the vertebral landmarks generated, the Dice coefficients of the vertebral shapes and in the main Cobb angle. The results are shown in Table 1 . Results were confronted to other techniques such as biomechanical simulations performed on each subject using finite element modeling with ex-vivo parameters [25] , a locally linear latent variable model [20] and a deep auto-encoder network [24] . Results from the predicted geometrical models show the regressed spatiotemporal geodesic curve yields anatomically coherent structures, with accurate local vertebral morphology."}, {"section_title": "Manifolds II -Theory and Applications", "text": "LL-LVM), the probabilistic model integrating similarity graphs shows a statistically significant improvement p < 0:01 \u00f0\u00de to all three approaches based on paired t-test."}, {"section_title": "Spatiotemporal manifold prediction model for surgery prediction", "text": "In this final section, we present a statistical framework for predicting the surgical outcomes following spine surgery of adolescents with idiopathic scoliosis. A discriminant manifold is first constructed to maximize the separation between responsive and nonresponsive groups of patients. The model then uses subject-specific correction trajectories based on articulated transformations in order to map spine correction profiles to a group-average piecewise-geodesic path. Spine correction trajectories are described in a piecewise-geodesic fashion to account for varying times at follow-up exams, regressing the curve via a quadratic optimization process.\nTo predict the evolution of correction, a baseline reconstruction is projected onto the manifold, from which a spatiotemporal regression model is built from parallel transport curves inferred from neighboring exemplars ( Figure 5 ). . Proposed prediction framework for spine surgery outcomes. In the training phase, a dataset of spine models are embedded in a spatiotemporal manifold M, into responsive (R) or nonresponsive (NR) groups. During testing, an unseen baseline 3D spine reconstruction y q is projected on M using f NW based on Nadaraya-Watson kernels. The closest samples to the projected point x are selected to regress the spatiotemporal curve \u03b3 used for predicting the correction due with surgery."}, {"section_title": "Discriminant embedding of spine models", "text": "We propose to embed a collection of nonresponsive (NR) and (2) responsive (R) patients to surgery which will offer a maximal separation between the classes, by using a discriminant graph-embedding. Here, n labeled points Y \u00bc y i ; l i ; t i \u00c0\u00c1 \u00c8\u00c9 n i\u00bc1 defined in R D are embedded in the low-dimensional manifold M, where l i describes the label (NR or R) and t i defines the time of follow-up. We assume that for the sampled data, an underlying manifold of the highdimensional data exists such that X \u00bc x i ; l i ; t i \u00f0\u00de fg n i\u00bc1 defined in R d . We rely on the assumption that a locally linear mapping M i \u2208 R D\u00c2d exists, where local neighborhoods are defined as tangent planes estimated with y j \u00c0 y i and x j \u00c0 x i , describing the paired distances between linked neighbors i, j. Hence, the relationship can be established as\nBecause the discriminant manifold structure in R d requires to maintain the local structure of the underlying data, a undirected similarity graph G \u00bc V; W \u00f0\u00de is built, where each node V are connected to each other with edges that are weighted with the graph W. The overall structure of M is therefore defined with W w for feature vectors belonging to the same class and W b , which separate features from both classes. During the embedding of the discriminant locally linear latent manifold, data samples are divided between W w and W b ."}, {"section_title": "Piecewise-geodesic spatiotemporal manifold", "text": "Once sample points x i are in manifold space, the objective is to regress a regular and smooth piecewise-geodesic curve \u03b3 : t 1 ; t N \u00bd that accurately fits the embedded data describing the spatiotemporal correction following surgery within a 2 year period. For each sample data x i , the K closest individuals demonstrating similar baseline features are identified from the embedded data, creating neighborhoods N x q \u00c0\u00c1 with measurements at different time points, thus creating a low-dimensional Riemannian manifold where data points x i, j , with i denoting a particular individual, j the time-point measurement and j \u00bc 0 the preoperative model. By assuming the manifold domain is complete and piecewise-geodesic curves are defined for each time trajectories, time-labeled data can be regressed continuously in R D , thereby creating smooth curves in time intervals described by samples in R d .\nHowever, due to the fact the representation of the continuous curve is a variational problem of infinite dimensional space, the implementation follows a discretization process which is derived from the procedure in [22] , such that:\nThis minimization process simplifies the problem to a quadratic optimization, solved with LU decomposition. The piecewise nature is represented by the term K d \u2208 N x q \u00c0\u00c1 , defined as samples along \u03b3. The first component of Eq. (22) is a penalty term to minimize the geodesic distance between samples x i, j and the regressed curve, where w i are weight variables based on sample distances. This helps regress a curve that will lie close to x i, j , shifted by x q in order to have the initial reconstructions co-registered. The second term represents the velocity of the curve (defined by v i , approximating _ \u03b3 t i \u00f0\u00de ), minimizing the L 2 distance of the 1 st derivative of \u03b3. By minimizing the value of the curve's first derivatives, this prohibits any discontinuities or rapid transitions of the curve's direction, and is modulated by \u03b1 i . Finally, an acceleration penalty term (defined by a i ) focuses on the 2 nd derivative of \u03b3 with respect to t i by minimizing the L 2 norm. The acceleration is modulated by \u03b2 i . Estimates for v i and a i (weighted by \u03bb; \u03bc \u00c8\u00c9 , respectively), are generated using geometric finite differences. These estimates dictates the forward and backward step-size on the regressed curve, leading to directional vectors in M as shown in [22] . In order to minimize E \u03b3 \u00f0\u00de , a nonlinear conjugate gradient technique defined in the low-dimensional space R d is used, thus avoiding convergence and speed issues. The regressed curve \u03b3 is therefore defined for all time points, originating at t 0 . The curve creates a group average of spatiotemporal transformations based on individual correction trajectories."}, {"section_title": "Prediction of spine correction", "text": "Finally, to predict the evolution of spine correction from an unseen preoperative spine model, we use the geodesic curve \u03b3 : R D ! M modeling the spatiotemporal changes of the spine, where each point x \u2208 M is associated to a speed vector v defined with a tangent plane on the manifold such that v \u2208 T x M.\nBased on Riemannian theory, an exponential mapping function at x with velocity v can be defined from the geodesics such that e M x v \u00f0\u00de . Using this concept, parallel transport curves defined in T x can help define a series of time-index vectors along \u03b3 as proposed by [10] . The collection of parallel transport curves allows to generate an average trajectory in ambient space R D , describing the spine changes due to the corrective forces of tethering. The general goal is to begin the process at the preoperative sample, and navigate the piecewise-geodesic curve describing correction evolution in time, where one can extract the appearance at any point (time) in R D using the exponential mapping. For implementation purposes, the parallel transport curve are constrained within a smooth tubular boundary perpendicular to the curve (from an ICA) to generate the spatiotemporal evolution in the coordinate system of the preoperative model.\nHence, given the manifold at time t 0 with v defined in the tangent plane and the regressed piecewise-geodesic curve \u03b3, the parallel curve is obtained as:\nTherefore by repeating this mapping for manifold points seen as samples of individual progression trajectories along \u03b3 s \u00f0\u00de , an evolution model can be generated. Whenever a new sample is embedded, new samples points along \u03b3 s \u00f0\u00de , denoted as \u03b7 v \u03b3; \u00c1 \u00f0\u00de can be generated parallel to the regressed piecewise curve in M, capturing the spatiotemporal changes in correction.\nA time warp function allowing s to vary along the geodesic curve is described as \u03d5 i t \u00f0\u00de\u00bc \u03b8 i t \u00c0 t 0 \u00c0 \u03c4 i \u00f0\u00de \u00fe t 0 . Here, we propose to incorporate a personalized acceleration factor based on the spine maturity and flexibility derived from the spine bending radiographs and Risser grade. A coefficient \u03b8 i \u00bc C i \u00c2 R i describing the change in Cobb angle C i between poses, and modulated by the Risser grade R i . This coefficient regulates the rate of correction based on the K neighboring samples. Finally, to take under account the relative differences between the group-wise samples and the query model once mapped onto the regressed curve, a time-shift parameter \u03c4 i is incorporated in the warp function.\nFor spine correction evolution, displacement vectors v i are obtained by a PCA of the hyperplane crossing T x i M in manifold M [10] . Hence, for any query sample x q which represents the mapped preoperative 3D reconstruction (prior to surgery), the predicted model at time t k can be regressed from the piecewise-geodesic curve generated from embedded samples x in N x q \u00c0\u00c1 such that:\nwhich yields a predicted postoperative model y q, t k in high-dimensional space R D ,a n d\u03b5 q, t k a zero-mean Gaussian distribution. The generated model offers a complete constellation of interconnected vertebral models composing the spine shape S, at first-erect (FE), 1 or 2-year visits, including landmarks on vertebral endplates and pedicle extremities, which can be used to capture the local shape morphology with the correction process."}, {"section_title": "Discussion", "text": "Algorithms capable of extracting clinically relevant and meaningful descriptions from medical imaging datasets have become of widespread interest to theoreticians as well as practitioners in the medical field, accelerating the pace in recent years involving varied fields such as in machine learning, geometry, statistics and genomics to propose new insights for the analysis of imaging and biologic datasets. Towards this end, manifold learning has demonstrated a tremendous potential to learn the underlying representation of high-dimensional, complex imaging datasets.\nWe presented frameworks describing longitudinal, multimodal image features from neuroimaging data using a Bayesian model for discriminant nonlinear manifolds to predict the conversion of progressive MCI to Alzheimer's disease. This probabilistic method introduces classdependent latent variables which is based on the concept that local structure is transformed from manifold to the high-dimensional domain. This variational learning method can ultimately assess uncertainty within the manifold domain, which can lead to a better understanding of relationships between converters and nonconverters for patients with MCI.\nFinally, a prediction method for the outcomes of spine surgery using geodesic parallel transport curves generated from probabilistic manifold models was presented. The mathematical models allow to describe patterns in a nonlinear and discriminant Riemannian framework by first distinguishing nonprogressive and progressive cases, followed by a prediction of structural evolution. The proposed model provides a way to analyze longitudinal samples from a geodesic curve in manifold space, thus simplifying the mixed effects when studying groupaverage trajectories."}]