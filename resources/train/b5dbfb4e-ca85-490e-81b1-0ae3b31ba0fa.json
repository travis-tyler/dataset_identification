[{"section_title": "", "text": ""}, {"section_title": "INTRODUCTION", "text": "The emergency management profession and the meteorology profession, particularly the National Weather Service (NWS), both maintain a mission to protect life and property. This is done in many ways in each field, and there is a large overlap in the area of severe weather emergencies. Severe weather that impacts society comes in many forms -ice storms, tornadoes, floods, tropical cyclones, etc. Along the southeast and Gulf coasts of the United States, tropical cyclones are of particular concern because of the range of damage, including straight line winds, tornadic winds, rainfall related flooding, and storm-surge flooding. Emergency managers and meteorologists work together to plan for and respond to these hazards. Storm surge can be catastrophic. According to the Federal Emergency Management Agency (FEMA), of all tropical cyclone generated hazards, storm surge is the greatest threat to life and property. Statistically, 90% of all hurricane related deaths are due to storm surge (GOHSEP 2011); therefore, it is imperative that emergency managers understand the potential threat that storm surge presents and have the best tools available for planning a response to the threat (FEMA 2011). This need is graphically demonstrated in recent history, for example, by hurricanes Camille in 1969 (USDC 1969) and Katrina in 2005(Knabb et al. 2005, which produced maximum storm surges of 20+ feet and 27.8 feet, respectively. As stated in one NWS document about storm surge, \"the destruction caused by such abnormally high water is truly astounding\" (Jelesnianski et al. 1992). Storm surge is a relatively well understood phenomenon with examination and modeling of the physical process by the NWS, or its predecessor, the U. S. Weather Bureau, as the case may be, extending back to the 1960s (Jelesnianski 1965, Jelesnianski 1967. Glahn, et al. (2009) provide a current overview of SLOSH (Sea Lake and Overland Surges from Hurricanes) usage by the National Weather Service and an inclusive listing of references regarding NWS storm surge research. Several models and associated tools currently exist that are useful for storm surge estimation, both for prestorm planning and operational response. An issue with the models, though, is that they generate tremendous amounts of data that make timely operational analysis difficult. Also, they typically do not address the probability of impact. Another source of storm surge information is studies of historical occurrence, but there is a dearth of information for any given location. This research is directed at examining and analyzing data generated by the NWS SLOSH model for generating storm surge probability information that will be useful for emergency managers in developing strategies for responding to the storm surge generated by tropical cyclones."}, {"section_title": "a. Storm Surge and Other Tropical Cyclone Hazards", "text": "Storm surge is defined as \"an abnormal rise of water generated by a storm, over and above the predicted astronomical tide\" (Jelesnianski et al. 1992). While a tropical cyclone is over deep water, the frictional effect of winds on the water surface and lower central pressure cause a mounding of water that is ameliorated by vertical, subsurface circulations; however, as the tropical cyclone approaches land and the water becomes shallower, the subsurface circulations become less effective and the water is pushed onshore. As with other waves, the near-shore bathymetry affects the character of the incoming waves with a long, shallow approach to land building a higher storm surge than a short and steep approach. Storm surge does not include other physical contributions to higher/lower water levels, such as astronomical tides or waves. Besides the storm surge associated with a tropical cyclone, severe weather (thunderstorms with associated lightning, hail, and tornadoes) can also be generated by the landfalling tropical cyclone. It is possible for landfalling tropical cyclones to generate 20+ inches of rain in a 24 hour period with the heavy rains producing large amounts of riverine and flash flooding (Lutgens and Tarbuck 2010). Also, depending on storm intensity, forward motion, and location, it is possible that hurricane-force winds (in excess of 74 mph) can extend hundreds of miles inland (Kaplan and DiMaria 1995). "}, {"section_title": "b. Operational Storm Surge Estimation", "text": "The National Weather Service has been doing storm surge studies and modeling since the 1960s (Harris 1963, Jelesnianski 1967, Glahn 2009. This led to a so-called shelf model called SPLASH -the Special Program to List the Amplitudes of Surges from Hurricanes -which was presented in a 1972 National Oceanic and Atmospheric Administration (NOAA) Technical Memorandum (Jelesnianski 1972). SLOSH, the NWS successor to SPLASH, was presented in 1984 (Jelesnianski et al. 1984) and is still in use as a hurricane planning and response tool. Other models, developed by or for other agencies and locales, do exist. ADCIRC (Advanced Circulation) was developed under a United States Army Corps of Engineers (USACE) contract (Luettich, Jr. et al. 1972) and then in the early 1990s was examined for and brought into use as a storm surge model (Westerink et al. 1992). A disadvantage of ADCIRC for planning or operational use is that it requires supercomputing capabilities to run. Models have also been developed for Australia (Hubbert et al. 1990), the South China Sea (Zhang and Li 1996), and the North Sea (Verboom et al 1992 (Glahn, et al. 2009). The  results utilizing an ensemble model concept that was dubbed PSURGE, short for Probabilistic Surge (Glahn, et al. 2009 The process for developing the PSURGE product is of interest because it shows why it is not a useable product for planning, but its development process provides an example of how a planning product can be developed. Taylor and Glahn (2008) describe the creation and use of the PSURGE product. Using the forecast for a specific storm and statistical forecast errors, a set of hypothetical storms is created with each having an associated chance of occurrence. These hypothetical storms are run through the SLOSH model and the outputs are joined, with their accompanying chances, in a probabilistic manner. Since PSURGE is based on an active hurricane forecast, it is storm-specific and therefore useful for an operational response but not for long range planning purposes. However, the process of varying input parameters in a probabilistic manner to produce a family of runs can be extended to creating a family of storms across a basin. The entire hypothetical set of storms including all headings, intensities, etc. that covers the entire basin creates a set of storm surges, essentially a storm surge climatology, that can be used by an emergency planner in developing responses to various tropical cyclone-generated storm surge scenarios."}, {"section_title": "c. Overview of Risk Management", "text": "By managing risk, certain negative outcomes of a particular situation can be avoided and positive outcomes enhanced. Risk Management is a method of identifying and planning for problems that can impact a business, process, population, etc. The terms 'risk' and 'risk management' have now become central to the lexicon of just about every field (Tarrant 2006). Risk is defined as \"the potential for an unwanted outcome resulting from an incident or occurrence, as determined by its likelihood and the associated consequences\" (FEMA 2010). In the context of emergency management, risk management is defined by FEMA as \"the process of identifying, analyzing, assessing, and communicating risk and accepting, avoiding, transferring, or controlling it to an acceptable level at an acceptable cost\" (FEMA 2010). The process of planning for an emergency is generally based on defining and examining a worst-case scenario. The assumption is that if you plan for the worst that can happen, then you can deal with lesser impacts. However, it is not always practical to respond to a specific emergency based on the worst that can happen. In the context of this research, for example, it is not necessary to react to a category 2 hurricane generated storm surge in the same way as storm surge from a category 5 storm. In this example, not only is there no water to run from, it would also be a tremendous waste of money to evacuate for the real event based on the worst case. As the Emergency Management profession has matured, the way that planning is done has changed. Guidance from FEMA to emergency planners advises that: \"using a risk analysis, the planning team must compare and prioritize risks to determine which hazards or threats merit special attention in planning (and other emergency and homeland security management efforts). The team must consider the frequency of the hazard or threat and the likelihood or severity potential of its consequences in order to develop a single indicator of the risk to the jurisdiction. This effort allows for comparisons and the setting of priorities.\" (FEMA 2010) Risk management, focused on vulnerability, provides a flexible and holistic framework to advise emergency management (Salter 1997). The purpose of risk analysis and risk quantification is always to provide input to an underlying decision process that involves not just risks but also other forms of costs and benefits. Risk must thus be considered always within a decision theory context (Kaplan and Garrick 1981). The roots of Decision Theory can be traced to Blaise Pascal and his logical argument for believing or not believing in something, known as Pascal's Wager. In its most basic form, Pascal's argument for making a particular decision can be viewed in terms of an event, the probability of that event occurring, and the resulting consequence. Kaplan and Garrick (1981) state that the notion of \"probability\" is fundamentally intertwined with the definition of risk. It is commonly accepted that risk is some combination of consequence or impact and probability. So, to properly manage risk, it must be defined and therefore some way of defining probability is necessary. Probability has been used in operational weather forecasting for some time; the first routinely distributed probability based product by the NWS was precipitation forecasting in 1965 (National Research Council, Board on Atmospheric Sciences and Climate, 2006). Murphy and Winkler (1984) give a review of the early history of the use of probability in forecasting. In the early 1960s, Edward Lorenz recognized that very small changes in the initial conditions of a model could result in tremendous differences in model outputs over a period of time (Lorenz 1963). Leith (1974) proposed a collection of forecasts -with each forecast generated by slightly different initial conditions or different modeling frameworks -be used for weather forecasting. This combination of outputs would then generate probable bounds around the actual weather and the variations in the resulting forecasts could be used to estimate the uncertainty of the prediction or produce probabilistic guidance. This collection of forecasts is now known as an ensemble. Uncertainty is an overarching term that refers to the condition whereby the state of a system cannot be known unambiguously. Prediction is inherently uncertain, and only by having access to actionable uncertainty information can users consider and apply the complete information required to make the best decision for their needs and situation. given place over a given period of time. Or, simplifying somewhat, climatology is the study of weather that has already occurred. It is useful to understand historical weather and its causes because history, including weather, repeats itself. For meteorological variables such as temperature, a very extensive record of historical conditions exists and provides a very good basis for using past events to predict the future. There are some analyses and presentations of, and ongoing research into storm surge climatology (Needham 2010a, Needham 2010b). However, this history is not extensive enough to provide the needed data for producing a useful planning tool. While SLOSH can be and is used in a probabilistic manner in an operational environment, currently, there is no probabilistic tool that can be used for storm surge planning. The concept of providing data specifically regarding risk of storm surge was addressed by Zerger, et al. 2002 MOMs over the years has been very valuable because the tools provide worst-case information that provides an absolute level to plan to. However, planning for worst-case is not realistic and can result in very expensive and unnecessary actions. A tangible economic/financial benefit can be realized by using a probabilistic tool for emergency planning purposes. Zhu et al. (2002) discuss this and conclude that using ensemble-based probabilistic forecasts can considerably increase the economic benefit that weather predictions can provide to society. This benefit is recognized by local emergency managers -this tool will \"help us locals a great deal when it comes to planning for evacuation of people and in the long term can save the local governments money\" (E. Deroche, St James Parish, Louisiana Office of Emergency Preparedness, 2011, personal communication). According to Goldsmith and Ricks (2008)  require complex modeling that must be verified for each individual study and statistical processes that are complex, leading to much more work for individual results. The use of existing storm surge model data (from SLOSH) is important because the model is known to be reliable; therefore, the data being analyzed and summarized can be considered reliable. And, by using existing, accepted data generated by an existing, accepted model, the implementation of the product into the operational meteorology and emergency management communities will be relatively straightforward. CHAPTER 2"}, {"section_title": "DATA AND METHODS", "text": "While the modeling of storm surge using SLOSH is a complex and complicated task, the data generated by the model are relatively simple (although voluminous). The output is simply a set of x, y, and z values where (x, y) is the geographic coordinate of a gridcell and z is the water level above a datum for the associated location. Recently, land elevation data was also included to enable calculation/display of an inundation value. Note that by convention, the term \"surge\" is accepted as referring to the height of water above datum and the term \"inundation\" refers to the depth of water above ground surface. The generation of data by the SLOSH model has been discussed previously. It is important to note further that the combined individual model runs (defined by varied track, location, forward speed, radius of maximum wind, and minimum pressure) can be viewed as an ensemble. Also, the model output data can be treated in the same way as historical weather data, using climatological analysis concepts. The ultimate aim of this research is to develop a methodology, using data from the New Orleans SLOSH basin generated in 2007, to extract the \"raw\" storm surge data for many hypothetical hurricanes from SLOSH data files, analyze that data to determine a probability that any given location will be impacted by some amount of storm surge, and show the characteristics of the storms that generate that impact, and \"package\" that information in a GIS format to allow a forecaster or emergency manager to display the information and extract it for further display or analysis. This process will provide a prototype method that the NWS and/or emergency managers in coastal, storm-surge prone areas can utilize to generate their own probabilistic SLOSH planning products using data from any SLOSH basin. Each modeled storm generates a depth of storm surge for any given location on the grid. For each of the gridcells, the probability will be found by dividing the number of times a cell is inundated by the total number of opportunities (model runs). The probability of exceedance can be calculated in the same way -the number of occurrences divided by the total number of possibilities. The results of the calculations will be presented in a Geographic Information System (GIS) format. The advantages of using a GIS are at least threefold: 1) since the SLOSH data is geospatial, the data can be easily manipulated to develop the product, 2) there are existing GIS tools for displaying data which will provide relatively easy usability for individuals not knowledgeable in GIS use, and 3) the product dataset can be used by GIS-savvy customers in the emergency management community for advanced data manipulation and presentation. The data development process is straightforward and simple, but it consists of a number of steps. First, the grid of the entire SLOSH basin is reduced to the area of interest; that is, the cells that correspond to land areas are found. To do this, the grid is \"clipped\" to the land area, including a three mile buffer (to ensure all relevant cells are identified). The SLOSH surge data for each hypothetical storm track are then analyzed to provide the maximum surge at each gridcell for each hypothetical storm track. The list of gridcells is utilized to extract only the data of interest. The storm surge caused by each individual hypothetical storm is evaluated at each SLOSH gridcell. If, for a given storm, the gridcell receives surge it is tallied. Finally, the number of surges is divided by the total number of storms, giving the percent chance the gridcell will be impacted by storm surge. Rather than rely on the single value of percent chance of impact, a statistical confidence interval is developed using bootstrap resampling. The data to be analyzed is generated during the examination of the impact of the individual storms. At each level of intensity, the data are assessed to determine whether or not each hypothetical storm generates storm surge at each gridcell and calculations are performed at each gridcell for each category of tropical cyclone intensity, i.e. Category 1 -5 on the Saffir-Simpson scale, generating statistical confidence intervals. The results allow the statistical statement to be made as follows: \"At the given gridcell, there is a 95% confidence that the impact of storm surge will occur P percent of the time.\" In order to calculate the confidence interval using traditional statistical techniques it is necessary to know the summary statistics of a sample which describe the entire population, such as mean and standard deviation. This methodology assumes that the distribution of the population or sample is known. In the case of the data used here, neither the summary statistics nor the distribution are known. Bootstrap resampling (bootstrapping) provides a non-parametric technique for determining summary statistics. Bootstrapping is a method of building new datasets based on the original by sampling with replacement. A sufficiently large number of data sets of the same size as the source are built (in this case 3000) by sampling the original with replacement. Because the new data sets are created using the data from the original population, they become additional populations 1) that are independent of distribution and any summary sample statistics and 2) on which statistically significant calculations can be made regarding the data. Here, the mean chance of impact and the 95% confidence interval on the mean is calculated. This data is then merged into a GIS file for purposes of displaying and querying the data in a geographic, visual format. In addition to the probability of surge occurrence, two additional products are generated. For each gridcell, a listing of storm characteristics that generate the surge is recorded. This listing is a step toward the possibility that this product could be used in a more operational setting. By examining this data, the user may be able to find a pattern of what storms generate surge for the given location. For example, the data may show that only storms approaching from the southwest cause the surge. This may enable the user to make operational decisions for actual storms that are approaching from the southeast and, according to the modeling, should not generate surge at the location in question. The second output of this technique is the chance the storm surge will exceed a particular value. Conceptually, the percent chance described previously is for an exceedance of 0 feet. In the same way, defined depths can be examined and the likelihood the surge will exceed that depth generated. The prototype system includes the calculations to provide this capability, but the 2007 dataset being utilized for development purposes does not include inundation values. (Recall that the term \"inundation\" refers to the depth of water above the ground surface.) Therefore, while the process has been developed and is valid, the input and resultant data does not provide an actual value of inundation. Any SLOSH basin dataset that contains the inundation data will allow for a true exceedance calculation. CHAPTER 3"}, {"section_title": "RESULTS", "text": ""}, {"section_title": "a. Products", "text": "The primary product generated as a result of this research is the likelihood that a given location will be affected by storm surge generated by hypothetical hurricanes of a given intensity. Two other products are easily derived from the research. One shows the characteristics of the storms causing the storm surge and the other provides probability an area will be inundated over given thresholds. The probability, with statistical 95% confidence interval (CI), that any given area will be impacted by storm surge is provided graphically in Figures 2 thru 11. These probabilities were calculated using the bootstrap resampling method described in the previous section. The \"lower CI\" image shows the statistically guaranteed chance (95% confidence of this level of probability) of impact by surge generated by the given hurricane intensity. The \"upper CI\" image represents a 95% confidence that the given probability will not be exceeded. These combine to give the statistically significant range of probabilities of impact by storm surge. The maximum range of the values of the upper and lower confidence intervals is not more than about 6%. So from a practical standpoint the difference between the statistically significant impacts is not great; however, the difference is visible in the data. In each lower/upper CI pair of images there are slight differences in the percent chances. The difference is more readily noticeable in the surge generated by the lower to higher storm intensity. The category 5 storm surge has much more red and yellow (higher likelihood of surge impact) compared to the category 1 surge, which has more greens (denoting lower probability of surge impact). The second product useful to the emergency planner is a listing of the hypothetical storms that generate storm surge for a given SLOSH gridcell. This information can be used to winnow down storms that can be expected to cause impact. It is a more operational product since the information could be used for examining impact of an approaching storm and as such must be used with care and only by knowledgeable personnel. The files that contain the source data are named according to the characteristics of the tropical cyclone that generates the data which they contain. The naming follows a set code and by tracking the file that generates surge at a location then decoding the filename, a determination of what type of storms cause the surge at a given point can be made. An example filename is e305R040_R25 which can be decoded according to the information in Table 1 -it is a category 3 intensity storm traveling eastward at five mi hr -1 , on a track 40 miles to the right of the central track, and its radius of maximum winds are 25 miles. Table 1 SLOSH datafile naming "}, {"section_title": "Use of Products", "text": "GIS shapefiles containing the MOM dataset for each SLOSH basin are available online from the National Weather Service (2012). Figure 12 was generated from this data. It shows the extent of surge summarized based on the worst case of a category 3 MOM. Data for category 3 is presented here and utilized in the following discussions because it is a typical planning scenario used by emergency planners in Louisiana. This is the data that has been available and utilized for long term planning by the emergency management community in coastal areas. Further discussion of its use will be presented subsequently. Figure 12 Extent of storm surge impact for Category 3 MOM Figure 13 presents a much different picture than Figure 12. Although the worst case impact can be extreme, the probability of impact may be very low. The combination of data given in these two figures provides the necessary information, impact and likelihood, that enables a determination of risk as described in Section 1.c. Figure 13 Mean probability of impact by a category 3 storm surge A hypothetical case utilizing the combined data can be examined centered on the city of Thibodaux in southeast Louisiana (approximate location shown by the \" \u25cb \" in Figures 12 and 13) and the impact of a category 3 storm. As shown on Figure 12, Thibodaux is in the area that is covered by storm surge generated by a Category 3 hurricane. It can be seen in Figure 13, though, that Thibodaux will only be impacted by surge generated by a relatively low percentage of hurricanes. Figures 14 and 15 are provided to give a more detailed view of the Thibodaux area and a category 3 storm surge. They are zoomed segments of Figures 12 and 13, respectively. In these images, Thibodaux is shown by the black circle and Louisiana Highway 1, shown by the black line, is included for reference. In reviewing the data provided in Figure 14, an emergency planner doing long term planning for the Thibodaux area would determine, based on worst-case scenario of a surge of approximately15 feet, that this area is not suitable for any activity in response to an approaching category 3 hurricane. In fact, local and state planning call for evacuation of all but essential personnel and equipment from the Thibodaux area. This is a very costly and time consuming endeavor. When the information in Figure 15 is reviewed, however, it can be seen that there is approximately a 15% probability that the Thibodaux area will be affected by storm surge generated by a category 3 hurricane; conversely, this is an 85% chance it will not be impacted. This is a compelling piece of data for an emergency planner. This impact plus likelihood provides a risk the emergency manager can base decisions on. Plans must take into account the further issue of safety of persons in an operational setting, and it is possible that this is not an acceptable level of risk for this issue. However, regardless of the final decision, it can be made more intelligently due to the added data of probability of impact. An actual example which provides a concrete study occurred in Louisiana in 2010, the Deepwater Horizon oil spill. The responders working in deep southeast Louisiana had millions of dollars of equipment that had to be protected in the event of a hurricane. It was necessary to find a storage area outside of the near coastal zone which is known to be vulnerable to almost all storm surge. Plans called for the equipment to be moved nearly 150 miles to a location outside of the worst-case impact zone. This move actually occurred several times and was very costly and time consuming due to the amount of equipment. Moving to the Thibodaux area would have cut the distance and travel time by a third. Knowing the probability of impact by storm surge, and therefore the risk, would have allowed the responders to make a risk-based business decision, rather than spending money and time based only on information regarding a worst-case scenario. The second product is the listing of hypothetical storms and associated characteristics that cause inundation at a selected location. Table 3 shows this listing for a location in the Thibodaux area, the gridcell that is on the left side of the circle in Figure   15. A brief inspection of the filenames in Table 2 and the decoding information from   Table 1 shows that for category 3 intensity storms, only those moving to the north, the northwest, west and west northwest generate surge for that location. Therefore, based on this data, if a category 3 storm were approaching southeast Louisiana along a northeasterly track, no surge would occur at the given location in the area of Thibodaux, Louisiana. The third product is the percent chance of exceeding a user-defined depth of water. For example, if only one foot of inundation is anticipated then sandbagging may be possible as a mitigation effort, and if eight feet of inundation are likely there is not much that can be done but evacuate."}, {"section_title": "c. Process Validation and Verification", "text": "Validation that this process is correct can be seen by comparing Figures 2 and 10. Figure 2, the chance of impact by surge from a Category 1 storm shows lower probabilities than those shown in Figure 10. That the probabilities of surge impact do increase with increasing storm intensity matches with the logical expectation that higher storm intensity would give a higher chance of storm surge impact. Because this process of developing the likelihood of impact by storm surge has been performed using model results, ideally the results should be verified by comparing to actual data. A process to verify the results will be discussed below. However, due to data formats and lack of availability of parameters in the SLOSH dataset used for this study, the full verification cannot be carried out. The parameter needed, inundation, is not available in the data set used for this work; therefore, complete verification will be noted under future work. Most discussions regarding the chance of an event are phrased in terms of \"return period;\" therefore, an understanding of return periods (RP) is necessary. When RP are calculated and presented, they are commonly expressed in a temporal context, i.e. an event of this level occurs once every 100 yrs. Statistically, this phrasing is equivalent to saying that the event has a 1% chance (1/100) of occurring in any given year. In other words, the reciprocal of RP is the percent chance of occurrence. Therefore, the RP of storm surge can be compared to the percent chance of impact by calculated storm surge. Logically, for a storm surge to occur, one must experience a tropical cyclone; therefore, the percent chance that hurricane-driven storm surge occurs must include the probability of a hurricane occurrence. The likelihood of surge is then the combination of the two events occurring, or the chance of hurricane times the chance of surge (Lin 2010). Keim et.al. (2007) have calculated the return periods of hurricanes in the area of this study. To verify the probability numbers generated by this methodology, the probability of surge to the levels determined by Needham and Keim (2012) are utilized. Keim, et al. (2007) report a hurricane return period of 10 yrs for the east central coast of Louisiana and seven years for the Mississippi Delta or \"toe\" of Louisiana. Likewise, Needham and Keim (2012) report the surge levels shown in Table 1 and corresponding return periods for the same areas. feet should be on the order of 10/100, or 10%. This data value must come from a gridcell on or near the coast, because the work by Keim et al. (2007) and Needham and Keim (2012) is based on hurricane impact at the coastline. To obtain this data, a data set that includes inundation values must be utilized. When this dataset is available the percent chance of exceedance can be found for the storm surge levels shown in Table 1, then, appropriate gridcells will be chosen for comparison and calculation. While the process used to arrive at the chance of impact by surge using SLOSH data is very straightforward, there are possible errors inherent in the SLOSH model and the Needham and Keim (2012) work that translate to this product (H. Needham, LSU, 2012, personal communication) --the SLOSH model has been shown to give results valid within \u00b120% (Jelesnianski, et al. 1992) - Needham and Keim (2012) surge RP is based on a somewhat limited data set and is only based on a maximum surge at a single location. Because of the limited data, there is an inherent uncertainty in the accuracy of the data. So, when the full verification can be performed with the appropriate data, each data set will have an implied range of results. If these ranges overlap, then the test for equality in Eqn 2 will be true and will verify the process described herein."}, {"section_title": "CHAPTER CONCLUSIONS", "text": "Storm surge generated by tropical cyclones can wreak havoc on coastal areas. Surge along the Louisiana coastline is particularly severe because of the shallow slope of the bathymetric and topographic surfaces in coastal Louisiana. Emergency planning for hurricanes and the associated storm surge is typically based on worst case situations; however, emergency planning philosophy has been moving toward a risk based model. In order to calculate risk of storm surge over an area, the likelihood of an impact must be quantified. There is very little research, though, and even less actual data regarding the probability of impact by storm surge. This is in part because there are relatively few occasions of storm surge to study and the studies that have been done focus on the immediate coastline. The National Weather Service SLOSH model has been utilized for storm surge modeling for many years and is a very mature and accepted tool. The quality control processes on both the computational grid and the resulting data are extensive so the data generated by the SLOSH model is considered solid. In this research, the SLOSH data is analyzed and used to produce a map of the probabilities that given coastal and nearcoastal locations will be impacted by storm surge. This research can be verfied by comparing the chance of surge impact calculated from the SLOSH model data to climatologies generated from studies of historical hurricanes and storm surges. Two other useful byproducts are also developed: A listing of the hypothetical storms that cause the storm surge at a given location and a chance of exceeding a given level of inundation. These products are significant in their utility to the emergency management community. Past practices of planning for a worst-case scenario were safe, but could also be a wasted expense if the worst case did not occur. This is in line with the statement by the Parish Emergency Management Director presented in Section 1.c. The availability of data showing the probability of impact by surge is potentially very useful. For example, the planning done for a worst case scenario of 15' of surge in an area could be very different if it is know that the surge only occurs in ten percent of hurricanes. And knowing that the surge at a given location is only caused by storms traveling a certain direction could be useful in planning a response. Overall, emergency planning considers many different variables in determining possible courses of action. These products give the emergency management community one more piece of information to add to their planning and decision making process. Additional data is required to complete the verification of the concept on which this product was built. This data originates at the National Hurricane Center, but the data could not be obtained. Two tasks must be completed to verify fully the prototype. The first is to ensure the programming developed is applicable to a new dataset. In order for product development to be done for other basins, it is important to be able to \"plug in\" the new data and run the programs with minimal modification. Second, the current data which provides inundation values is required to properly verify the concept by comparing model data to real-world data. After the prototype is verified, future work should include developing the surge probabilities for additional SLOSH basins. The State of Louisiana is interested in obtaining this information for all three basins that cover the coast of Louisiana. Other states have also expressed interest in the product. From a research perspective, the data generated may be useful in climatological and hydrologic research into storm surge. The research being done by Needham and Keim (2012) utilized to verify the results of this work may benefit from the abundance of modeled data available from SLOSH."}]