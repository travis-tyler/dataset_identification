[{"section_title": "Abstract", "text": "In this study, Turkish fifth-grade bursary examination mathematics items, all of which are of multiple choice, from years 1999 to 2018 are analyzed based on the cognitive and content domains of TIMSS 2019 assessment framework. According to document analysis of the data collected through official website of Ministry of National Education, the distribution of the cognitive demands of all items indicates that there is an emphasis on applying or reasoning domain with about 74%. This result leads to the conclusion that Turkish fifth-grade mathematics items require upper cognitive demands comparing with TIMSS target percentages. Also, it is observed that there are dramatic changes in cognitive demands of the items from year to year which may mean that there is no framework followed for the bursary examinations. Examining the content domains of the bursary examination, findings reveal that the majority of the items are in numbers (60%), and it is followed by measurement and geometry (34%), and data (6%), which are similar with the target percentages of TIMSS 2019 that are 50, 35, and 15 respectively. Finally, suggestions are given in the light of findings and educational reforms in Turkey."}, {"section_title": "Introduction", "text": "The main high stakes exams conducted in Turkey are placement exams at eighth grade to middle schools, at twelfth grade to universities, and at the end of higher education to governmental jobs. There are also central exams from fifth to eleventh grades for boarding and scholarship, or bursary examinations in short. So, the term central exam, or sometimes called external exam, refers to regional or nationwide exam for some purposes (Woessmann, 2002, p.2) . In Turkey, these purposes can be placement for further studies, boarding and scholarship, comparison of student achievements, comparison of country achievements, or summative evaluations. As Woessmann (2003) states, central exams are like \"currencies\" that function as unit of value in the economic system, and they are a measure of value for shareholders in education systems.\nThe name for boarding and scholarship examinations in Turkey is the Elementary and Middle-school Bursary Examinations (EMBE), and starting from 1999, Turkish Ministry of National Education (MONE) has been conducting the bursary examination on fifth to eleventh grade students that have annual family income below 13480 \u20ba (Turkish Lira), which is now about 2200 \u20ac (Euro) and the amount of bursary is 260 \u20ba per month which is continuously paid until the end of the middle school (EMBE, 2019) . Thus, the earliest central examination in terms of grades conducted in Turkey is the fifth grade bursary examination, and it is the closest exam to TIMSS (The Trends in International Mathematics and Science Study) fourth grade exam in terms of its content and grade level.\nFirst conducted in 1995 only on fourth, and repeated in 1999 with fourth and eighth grade students, TIMSS reports the trend data of students' mathematics and science achievement worldwide for every four years. While there are cognitive domains classified as knowing, applying and reasoning with the target percentages 40, 40 and 20 respectively; there are content domains as number, measurement and geometry, and data with the target percentages 50, 30 and 20 respectively, and the item types are multiple-choice and constructed-response with about the same proportions in TIMSS 2019 fourth grade mathematics assessments framework. TIMSS also collects data through context questionnaire from students about their experiences, instruction, and attitudes toward learning, from teachers and school principals about school and classroom resources, and from parents about students' home contexts for learning (Mullis and Martin, 2017) .\nWhile Turkish fourth grade students participated in TIMSS in 2011 and 2015 only, eighth graders participated in 1999 , 2007 , 2011 and 2015 . The final TIMSS 2015 show that the performance of Turkish fourth graders is below the average which is similar to the previous TIMSS 2011 results. One of the consequences of the poor performances of Turkish students in past years TIMSS and the other international examinations were the reforms in primary school curricula in 2005, 2013 and 2017. After these changes in mathematics curriculum, unsatisfactory small progress in TIMSS mathematics examinations has been observed (MONE, 2015, p.21) . So, linking TIMSS assessments and national assessments it may be useful to compare the similarities and differences between them. It may also be worthwhile to examine the reflections of reforms on central exams.\nEfforts to understand the components of human learning have led to the conclusion that every learning incident is in terms of three types of domains: cognitive (knowledge based domain), affective (attitudinal based domain) and psychomotor (skills based domain) and the best known classification of cognitive domain is so called Bloom's Taxonomy which classifies cognitive domain under six categories. Bloom and his colleagues used the term cognitive \"to include activities such as remembering and recalling knowledge, thinking, problem solving, creating\" (Bloom, Engelhart, Furst, Hill and Krathwohl, 1956, p.2) . Since then many other classifications of cognitive domain have been made (e.g. Anderson and Krathwohl, 2001; Marzano and Kendal, 2008) . Nitko (2004) gives some suggestions for choosing the most suitable taxonomy: integrity, perspective, reform, simplicity and reporting. Bearing these suggestions in mind, TIMSS 2019 assessment framework is one of the most recent and simplest which classifies cognitive domain in three categories as knowing, applying and reasoning (Mullis and Martin (Eds.), 2017) . Unlike Bloom's taxonomy, TIMSS documents do not state that these domains are in a hierarchical order. However, many other frameworks including Marzano and Kendal's one are in a hierarchical structure (Marzano and Kendal, 2008, p.16) .\nGenerally, cognitive skills under knowing are assumed as in the lowest level, and cognitive skills under reasoning (Table 1) are assumed as in the highest level (Bloom et al., 1956; Anderson and Krathwohl, 2001; Marzano and Kendal, 2008) . According to Wilson (2000, p.5) , 'thinking skills' are ambiguous as there is no International Online Journal of Educational Sciences, 2019, 11 (3), 222-234. 224 consensus among the taxonomies of different researchers as to what should be included in this category. But, most taxonomies include \"collecting information, sorting information, analyzing information, drawing conclusions from the information, brainstorming new ideas, problem solving, determining cause and effect, evaluating options, planning and setting goals, monitoring progress, decision making, and reflecting on one's own progress\" and these are also mostly included in TIMSS 2019 assessment framework (Mullis and Martin (Eds.), 2017, p.22-24) . Mastery of basics in school such as reading, writing, mathematics, science etc. \"are not sufficient to meet the demands of the labor market and active citizenship\" and 'higher order' thinking skills are needed (Wilson, 2000, p.6) . Similarly, Mullis and Martin (Eds.) (2017, p.22 ) state that responding correctly to TIMSS items requires students to know the mathematics content being assessed and to make use of a range of cognitive skills.\nThere are some studies on the analysis of teacher made test items, central examination questions, curricular learning outcomes and book exercises based on item types, cognitive domains or content domains.\nFor instance, Incikabi (2012) examined the distribution of eighth graders' high stakes mathematics examination questions in terms of cognitive levels, content domains and item types based on TIMSS 2007 assessment framework. He reported that multiple choice item format is the only item type that is included in eighth grade high stakes exams contrary to TIMSS assessments which also includes constructed response items. He concluded that there is a resemblance considering content domain, but there are differences in cognitive domain distribution. Delil, \u00d6zcan and I\u015flak (2018) examined learning outcomes of 2017 Turkish primary school mathematics curriculum in terms of TIMSS 2015 assessment framework, and reported that while 50% were in number, 46% were in geometric shapes and measures, 4% in data display content domains; 58% were in knowing, 32% were in applying and the rest 10% were in reasoning cognitive domains. They concluded that for primary school students it is affirmative to have most of the learning outcomes to be at knowing cognitive domain but it is suggested to increase cognitive levels as grade level increases. Delil and Yolcu Tetik (2015) analyzed eighth grade high stakes mathematics examination items in terms of their cognitive demands, and they reported that 87% of the items are either in knowing or in applying cognitive domain. Ta\u015ftekino\u011flu and Ayd\u0131n (2014) analyzed fourth grade teacher made mathematics tests based on TIMSS 2011 framework, and they found that, concerning content domains, of all 249 questions 80% were in numbers, 16% in geometrical shapes and measures, and 4% were in data display. But concerning cognitive domains, 67% were in knowing, 18% in applying and 15% were in reasoning. They suggested that fourth grade mathematics school exam panel should cooperate in preparing questions that require upper cognitive levels.\nBeing the closest exam to TIMSS fourth grade mathematics examination in terms of its grade level and content, analyzing fifth graders bursary examination mathematics items in terms of their cognitive levels, item types and content domains may shed light on why Turkish students have difficulty in doing mathematics in comparative studies like TIMSS. So, in this study the research problem is that how are the item types, and the content and cognitive domain requirements of the Turkish fifth grade bursary examinations' mathematics items from year 1999 to year 2018 according to TIMSS 2019 assessment framework? By this effort, it is aimed to observe the similarities and differences between the bursary examination mathematics items after and before the reforms in Turkish mathematics curriculum in terms of their cognitive and content requirements. Besides, there will be opportunity to compare content and cognitive demands of bursary examination items with those of TIMSS which may shed light on reasons why Turkish students show a performance below the average. There is no study comparing bursary examinations with TIMSS assessments framework in the literature, and besides the large amount of studies on alignment between Bloom's cognitive standards and central exams, there are limited studies on alignment between TIMSS cognitive standards and central exams, and it is hoped that this study may contribute to close the gap in the literature as another significance of this study."}, {"section_title": "Method", "text": "As a qualitative research this is a descriptive study. Descriptive studies involve four consecutive steps (Y\u0131ld\u0131r\u0131m and \u015eim\u015fek, 2016, p. 240) : (1) forming a framework for the descriptive analysis, (2) processing the data in the thematic framework, (3) describing the findings, and (4) interpreting the findings. This study is defined as a descriptive one since the data were arranged and interpreted according to TIMSS 2019 assessment framework."}, {"section_title": "Selection of Items", "text": "In this study 520 Turkish fifth grade bursary examination items from 1999 to 2018 are analyzed. The "}, {"section_title": "The Coding Scheme and Classification of the Items", "text": "Since all of the item types of the bursary examination are of multiple choice, and since the content domains of the items are also unambiguous, the only problem is to work out the cognitive demands of the items reliably. According to Neuendorf (2002, p. 142) , there is an essential need for intercoder reliability, since it will be called expert analysis otherwise. So, two or more coders must be \"calibrated\" against one another.\nThe coding scheme used in this study is derived from TIMSS 2019 assessment framework. The characteristics of cognitive processes in the cognitive domains are given in Table 1 (Mullis and Martin (Eds.), 2017, p.23-24) .\nTo carry out the coding procedure, the coding panel (one the author and the other a mathematics education expert) working independently, coded the 25 mathematics items of an exam by using coding scheme of the study (see, Table 1) were coded separately by the coders. After the first coding, the intercoder reliability was found as 0.84 and this score is found large enough (Neuendorf, 2002) . Each classification for which the coders did not agree was then discussed until an agreement was reached on how the classification would be made. Then the researchers, independently, coded the rest of 520 items. For each year's exam items, some disagreements were occurred and disagreements were dissolved through a discussion based on the TIMSS 2019 assessment framework.\nFor evaluative purposes, it is assumed that cognitive skills under knowing, applying and reasoning are of lower, middle and higher-order level, respectively. In case if cognitive demands of an item belong to more than one cognitive domain, for this item, cognitive domain of the later in hierarchical order is chosen.\nExamples of classification of items are presented in Appendices. "}, {"section_title": "Findings", "text": "The bursary examination mathematics items and TIMSS assessments are compared in terms of item format and presented in Table 2 below. While all of the bursary examination questions are of multiple choice, TIMSS 2019 target percentages are both multiple choice and constructed response with about the same proportions (Mullis and Martin, 2017) . "}, {"section_title": "Draw Conclusions Make valid", "text": "inferences on the basis of information and evidence. "}, {"section_title": "Generalize", "text": ""}, {"section_title": "228", "text": "The cognitive requirements of all 520 items of fifth grade Turkish bursary examinations from 1999 to 2018 are summarized in Table 4 below. It is seen that the cognitive requirements of the mathematics items of the years 1999-2018 are in knowing, applying, and reasoning cognitive domains with percentages about 26, 38, and 36 respectively. "}, {"section_title": "(100%)", "text": "The target percentages given by TIMSS 2019 framework for knowing, applying, and reasoning domains are 40, 40 and 20, respectively (Mullis and Martin, 2017, p.14) . In the following, Figure 2 gives an overall summary of the results. By this figure, target percentages of TIMSS 2019, pre-reform, 1 st reform, 2 nd reform, 3 rd reform and all mathematics items can be compared. Also, it is seen that in terms of distribution of cognitive requirements, the most that resembles with TIMSS target percentages is the 2 nd reform period items with 39%, 34% and 27% in knowing, applying, and reasoning domains respectively.\nA Chi-square test of goodness-of-fit was performed to determine whether the cognitive requirements of all bursary examination items' percentages and TIMSS 2019 target percentages are consistent with each other or not. Evaluated value ( =2, =200) 2 = 7.592, < 0.05 suggests that there is no consistency between TIMSS target percentages and bursary examination items in terms of cognitive demands. The only period that seems to resemble with TIMSS targets is the second reform years."}, {"section_title": "Figure 2. Percentages of cognitive domains of TIMSS and bursary examination items", "text": ""}, {"section_title": "Discussion and Recommendations", "text": "This study aims to give a broad picture of the fifth grade central examinations conducted in Turkey and to make a comparison with TIMSS assessments. Concerning item formats, findings reveal that the only item type that is included in bursary examination is multiple choice in contrast to TIMSS 2019 that also includes constructed response item type. National or international central exams exclusively use multiple choice item types due to its validity and reliability advantages. Nevertheless, being familiar with different kinds of item formats such as multiple choice, constructed response, essays and performance assessment tasks may have a big effect on student performance (Ben-Simon and Cohen, 2004) . So, one reason of the low performance of Turkish students in international surveys like TIMSS may be the students' unfamiliarity with item types conducted, and such a result was also shared previously by Incikabi (2012, p.310) .\nWhen bursary examinations are compared with TIMSS in terms of content domains it is seen that of all fifth grade bursary examination mathematics items, 60% are in number, 33% are in measurement and geometry and 6% are in data content domains. Comparing with TIMSS content domain target percentages that are 50, 30\nand 20 in number, measurement and geometry, and data respectively, while there is a resemblance in number and measurement and geometry, there is a small gap in data content domain. percent in both require knowing the rest 80 percent require applying or reasoning. This result may suggest that the first reform did not bring much change considering cognitive requirements. But, while the 2 nd reform is very much similar to TIMSS targets, after the final reform the cognitive demands of items that is allocated to knowing is raised up to 72 percent, leaving only 28 percent for applying and reasoning both. Actually, Figure 2 demonstrates a decrease in reasoning cognitive domain requirements gradually, and it has not been reported by bursary examination test developers weather this is a systematical approach or not. Literature reveal that there is not a coherence between TIMSS assessments and Turkish curricular outcomes, teacher made tests or high stakes examinations cognitive domain distributions, and this could be the reason behind the low performance of Turkish students in TIMSS assessments. So, it may be suggested that more emphasis should be given to applying and reasoning cognitive domain in the next bursary examinations in order to have a balance in cognitive domains that is closer to TIMSS targets.\nA deeper analysis indicates that there are dramatic changes from year to year (see Table 4 ). For example, from 1999 to 2003 the numbers of items that require applying or reasoning are similar but from 2004 to 2006 it is seen that there is a strong emphasis on reasoning domain. Also, for years 2008, 2011, 2013 and 2014 , it is seen that the item developers focused heavily on applying domain, but in 2018 they focused on knowing domain.\nThese are all suggesting that, the test developers have not followed a cognitive framework for the central examinations that they have developed in Turkey. This result is consistent with the results of Delil and Yolcu Tetik (2015) , in which they concluded that eight grade high stakes examinations had no cognitive framework followed. Test items need to reflect cognitive domains, as well as content domains. Also, the weight of cognitive domains should not change so dramatically from year to year. In this way, the trend of student achievement can be traced reliably. In fact, Turkish central examination or high-stakes test developers have not published any framework to show content or cognitive domains of the test items, but providing such information would very much help test developers, schools and examinees to plan their work more efficiently."}, {"section_title": "Appendices", "text": "Examples for classifications of Turkish fifth grade bursary examination items (Appendix A) and the fourth grade TIMSS 2007 released items (Appendix B) are given below. While the classifications of the bursary examination items were done by the coding panel of this research, the classifications of the TIMSS 2007 released items were done by TIMSS experts."}, {"section_title": "Appendix A", "text": ""}, {"section_title": "Example 1", "text": "Problem #10 in Bursary Examination 1999:\nWhat is the result of the operations ( "}, {"section_title": "Coding: applying", "text": "Example 3:"}, {"section_title": "Problem #3 in Bursary Examination 1999:", "text": "A load is planned to be carried equally by 6 people. However, since 2 persons do not attend, each of the rest has to carry 15 kilograms more. How many kilograms is the load? Coding: reasoning"}]