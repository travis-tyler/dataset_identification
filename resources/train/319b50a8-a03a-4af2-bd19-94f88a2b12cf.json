[{"section_title": "Introduction", "text": "Large-scale assessment surveys in the educational research and policy landscape have played a growing role over the last two decades (Gustafsson, 2008;Kamens, 2009). Broadly defined, large-scale assessments are surveys of knowledge, skills, or behaviors in a given domain that provide comparable data about many different educational systems around the world. Researchers can use this information to analyze differences in achievement between and within countries and to investigate the effects of various educational and societal factors on educational achievement, as well as the impact of skills on economic and social outcomes (Creemers and Kyriakides, 2008;Hanushek and Woessman, 2011). Likewise, such international comparisons are particularly useful for evaluating the impact of educational reforms, especially with respect to some specific institutional features for which the variation can only be observed across countries (Strietholt et al., 2014). Historically, most empirical analyses using these comparative data have been based on regressions in the form of educational production functions that link resource inputs with educational outcomes after controlling for various background features (Hanushek, 1979;Todd and Wolpin, 2003). However, this approach may fail to produce convincing estimates when the treatment, an explanatory variable in the model, is not exogenous due to the well-known endogeneity problem. In education, the main source of endogeneity is self-selection. For example, schools with better academic outcomes tend to attract relatively more motivated parents seeking the best education for their children. When this unobserved heterogeneity is correlated with receiving the treatment, the econometric estimation of the causal effect of this treatment is likely to be biased. Reverse causality is a second major source of endogeneity that arises, for example, when poor test scores for some students or schools lead to the implementation of a reform (treatment) to boost the results. In this case, the direct comparison between treated and untreated schools will be biased because the treatment is correlated with the unobserved reason behind the poor performance of these schools. Therefore, the estimation of causal effects in the presence of endogeneity often biases results (Webbink, 2005). This limitation has led to the development of more sophisticated techniques that allow valid causal inference based on defining the counterfactual group through a quasi-experiment on observational data (Morgan andWinship, 2007, Gertler et al., 2016). Such econometric techniques in education economics are mainly represented by instrumental variables, regression discontinuity designs, difference in differences and propensity score matching. The aim of this paper is to review empirical studies applying such methods to observational data from three well-known large-scale assessments and explain the specific estimation strategies employed by educational researchers with these databases in order to identify the causal impact of different educational policies on outcomes. tested 15-year-old students in math, science, and reading performance every three years since 2000. TIMSS has assessed the mathematics and science achievements of fourthand eighth-grade students every four years since 1995, whereas PIRLS focuses on the reading literacy achievement of fourth-grade students, who have been surveyed every five years since 2001. This survey describes the estimation strategies used by educational researchers and highlights the potential of these databases for analyzing the causal effects of multiple key issues in education policy (class size, instructional time, maturity and so on) on students' results. The aim is to inspire new empirical applications using these databases with insight from the research developed to date. Additionally, we summarize the trends for this line of research regarding different issues and also provide a snapshot of the scientific journals in which the papers were published. The remainder of the paper is organized as follows. Section 2 discusses the literature review strategy followed to retrieve the analyzed papers. Section 3 briefly explains methodological aspects related to the econometric approaches applied in empirical studies in order to facilitate their interpretation. Section 4 presents the results of the literature review conducted considering four different categories corresponding to the employed econometric approaches and distinguishing several research topics. Section 5 summarizes the contents of the empirical studies surveyed in the previous section, including an overview of the journals in which they were published. Finally, Section 6 concludes."}, {"section_title": "Literature review and search strategy", "text": "The literature addressing the econometric techniques available for developing causal inference on impact evaluation problems in depth is vast Pischke, 2008, 2014;Gertler et al., 2016). Likewise, there are also some papers providing helpful guidelines for practitioners interested in implementing causal inference econometric approaches in education economics problems (Webbink, 2005;Schlotter et al., 2011). In addition, Hanushek and Woessman (2014) provide an extensive review of studies using international survey data to analyze different institutional features as part of a crosscountry approach. However, they address several papers using traditional econometric methods, such as least squares, whose estimated effects are very unlikely to reveal causal implications. Taking this literature as a reference, our target here is to review empirical applications for four causal inference techniques: instrumental variables, regression discontinuity designs, difference in differences and propensity score matching on the three bestknown international databases: PISA, TIMSS and PIRLS. In order to conduct our search for empirical studies, we used three main search engines: ERIC (Educational Resources Information Center), Scopus and ISI Web of Science (WoS). ERIC is an online digital library of educational research and information and is sponsored by the Institute of Education Sciences of the United States Department of Education. It is the largest educational database worldwide, providing access to about 1,000 scientific journals. It provides a comprehensive, searchable, Internet-based bibliographic and fulltext database of education research and information for educators, researchers, and the general public. Scopus is a bibliographic database maintained by Elsevier, which contains abstracts and citations for academic journal articles, books and conference proceedings in many different fields of research. Finally, ISI WoS is the world's leading academic citation indexing database and search service, which is provided by Thomson Reuters. It covers the sciences, social sciences, arts and humanities. Likewise, it provides bibliographic content and tools to access, analyze and manage research information. Finally, we rounded out our search by consulting other well-known databases like Econlit (American Economic Association), ABI/Inform Global and Google Scholar to add any articles that we possibly missed to our results. Our literature search was performed from June to October 2016 and was restricted to studies written in English language. We included empirical papers starting from 2004 up to the year 2016. We performed a computerized systematic search using a wide range of search terms or keywords merged into two groups. The first one included terms related to the methodological approach applied (causal inference, identification strategy, exogenous variation, instrumental variables, regression discontinuity, propensity score matching, difference in differences, fixed effects), and the second one was referred to the database employed (PISA, TIMSS, PIRLS, large-scale assessment, cross-country, comparative study, student performance and achievement). Our initial search identified more than 180 papers. After a careful review of their content, however, this number was reduced significantly because some of the studies were not in fact using causal inference methods or employed national databases instead of the three international large-scale assessments considered. The final selection included 66 studies. The studies can be classified according to different criteria (e.g. chronological order, topic studied or database employed). However, we decided to organize them according to the identification strategy applied to deal with the common problem of endogeneity bias in data since this is the main focus of this paper. Section 3 roughly explains each approach pointing out their main advantages and drawbacks with respect to international databases. Section 4 describes the empirical studies applying each causal inference approach on international databases to evaluate the effects of different educational programs or interventions. The discussion or comparison of the results is beyond the scope of this survey. In order to facilitate the identification of the main characteristics of each empirical study, similarly to Hanushek and Woessman (2014), we built a table listing their main details (see Table A1 in the Annex). Each record includes the year of publication, the dataset/s employed, type of data (cross-sectional or pooled data), the country/countries studied, the estimation method and an overview of the analyzed research question. From this information, we found that the authors of almost half of the studies adopt a cross-country approach in order to leverage the often much larger variation existing across countries (Woessman, 2007). Nevertheless, we also came across multiple studies analyzing data about a single nation, especially among European countries."}, {"section_title": "Methods", "text": "The estimation of causal effects is now the top priority of current educational research. Both researchers and policy makers are interested in having empirical evidence suitable for guiding decision-making on effective educational policies and practices. The foundations of causal inference derive from the work of Rubin (1974;. Rubin developed the fundamental pillars of the counterfactual theory of causation with respect to the estimation of treatment effects. The basic idea is that, ideally, researchers would like to know what would have happened if an individual exposed to a treatment condition (T) had instead been in the control group (C). With this definition of the potential outcomes, the causal effect (\u03b4) of treatment for individual i is defined as the difference in the outcome (Y) for individual i when he or she receives T versus C, all else being equal: In practice, we cannot estimate the causal effect because each individual is in either the treatment group or the control group. Thus, we can observe only one of these potential outcomes. This is often referred to as the fundamental problem of causal inference (Holland, 1986). Therefore, causal inference is basically a missing data problem, where at least half of the values of interest (the potential outcomes) are missing (Stuart, 2007). In this context, researchers need to make assumptions in order to approximate what they would have observed if individuals were in the alternative condition (counterfactuals). The gold standard approach for dealing with this problem and estimating the effects of treatments or interventions on outcomes is the randomized control trial (RCT). Randomization guarantees that individuals belonging to the treated and counterfactual groups are equal with respect to all observed and unobserved characteristics except for treatment reception. In RCT designs participants are randomly assigned to treatment and control groups, ensuring that treatment status will not be confounded with either measured or unmeasured baseline characteristics. Therefore, the effect of treatment on outcomes can be estimated over time by comparing average outcomes directly between the two groups. Nevertheless, RCTs are often difficult conduct in the education sector because of high implementation costs, ethics or political differences. In such circumstances, researchers are forced to rely on secondary observational data sourced from large-scale assessments (Schneider et al., 2007). Over the past four decades, different statistical procedures have been designed to deal with potential endogeneity when making comparisons between treatment and control groups (e.g., Heckman, 1976Heckman, , 1979Rosenbaum, 1986). Note, at this point, that we do not intend to provide a detailed explanation of the research methods applied in such empirical studies. As mentioned above, descriptions are available in several manuals and handbooks specifically designed for this purpose 1 . However, we do provide a brief non-technical description of the basic ideas underlying each method in order to give interested readers a feeling for each approach. The four quasi-experimental approaches included in this survey are instrumental variables, regression discontinuity designs, difference in differences and propensity score matching."}, {"section_title": "Instrumental variables (IV)", "text": "The so-called IV method is a standard econometric approach applied to overcome omitted variable problems in estimating causal relationships. Only that part of the variation in the predictor that is not related to unobservable factors affecting both predictor and outcome can be used in this technique. It relies on finding an additional variable that is related to the decision rule but not correlated with the outcome. This variable, known as the 'instrument', introduces some randomness into the assignment. This reproduces the effect of an experiment. Such a procedure allows researchers to isolate the exogenous variation in the treatment to get unbiased estimates of the causal relationship between the outcome and the predictor (Schlotter et al., 2011;Pokropek, 2016). The key issue in the implementation of the IV approach is, therefore, the choice of a valid instrument. In this respect, the researcher has to attempt to find a variable that is correlated with the treatment determining the probability of treatment, but causally uncorrelated with the dependent variable. This means that it should not be correlated with the error term (Wooldridge, 2010). When a convincing instrument is found, causal effects can be identified with cross-sectional observations. Thus the implementation of this econometric approach is becoming increasingly frequent in empirical studies using data from large-scale international assessments. In practice, this effect is usually estimated by implementing the two-stage least squares (2SLS) approach proposed by Heckman (1979) "}, {"section_title": "Regression Discontinuity Design (RDD)", "text": "This approach can be applied in specific settings when the participation in an intervention or treatment changes discontinuously with some continuous or running variable. Thus, the key point of this method is that the probability of participating is determined by a certain cut-off value of a running variable . The basic idea of the method is that the comparison of students or schools within a fairly small range above and below this cut-off point guarantees that the characteristics of both groups are statistically similar, but only some of them receive the treatment. This scenario is very close to an experimental design with random assignment, since we have a control group (below the cut-off) and a treatment group (above the cut-off) that can be compared. In this framework, the jump or discontinuity in outcomes that can be observed at the threshold can then be interpreted as the causal effect of the program. In most cases, however, the cut-off threshold does not always divide the sample into two groups, since it is sometimes possible to find control and treatment observations below and above the cut-off. In this framework, the usual estimation strategy is a fuzzy regression discontinuity design. This exploits discontinuities in the probability of treatment using the legal cut-off point as the instrumental variable 4 . The most common problem for implementing the RDD approach using data from international comparative studies is to find enough observations around the cut-off point 5 ."}, {"section_title": "Difference in differences (DiD)", "text": "The idea behind this approach is simple. We need two groups of individuals or schools observed in two different periods. If one group is exogenously exposed to a treatment or policy shift and the other is not, then the effect of the treatment can be easily measured taking the differences between the average results for the two groups before and after the educational policy is implemented. Subsequently, the impact or causal effect of the treatment is calculated as the difference between those two differences. The main benefit of this approach is that it accounts for changes within units of interest only. This limits the bias caused by unobserved or uncontrolled differences between these units. The key assumption required to identify the effect of the treatment is that the trends in the outcome of interest would be identical in both groups in the absence of treatment. For this reason, this approach is normally performed with a panel or pseudo-panel database that can be used to test the equal trends hypothesis assuming that any existing heterogeneity is constant over time (McCaffrey et al., 2003). In a panel data framework, we can control for fixed effects. In this manner, we can account for an indicator variable that takes out mean differences between units so that the effect of the evaluated program or policy can be identified by the changes experienced by the other variables over time. Note also that such fixed effects can be introduced in the model at different levels (students, teachers or schools) or even combining some of them in more complex settings (e.g. Rivkin et al., 2005;Clotfelter et al., 2007). In principle, this approach cannot be implemented when data are retrieved from largescale international assessments since they do not provide longitudinal information at individual or school level. However, this methodology can be adapted to a single dimension of time when there are at least two observations for the same evaluated unit (e.g. test scores for different subjects or students enrolled in different grades) or, alternatively, when the units have very similar characteristics (e.g. evaluating the impact on twins). Another possibility would be to use several international waves as a pseudopanel database to account for differences at regional or country level."}, {"section_title": "Propensity Score Matching (PSM)", "text": "Rosenbaum and Rubin (1983) proposed propensity score analysis as a practical tool for reducing selection bias by balancing treatment and control groups with respect to observed covariates. This method is an extension of the non-parametric matching approach. This approach aims to reproduce the treatment group among the non-treated to emulate the experimental conditions in a non-experimental setting with observational data. In order to implement this method, the unobserved variables have to be assumed to be equally distributed in treated and control groups. In other words, the underlying assumption is that the set of observables contains all the information that determined the probability to be treated. Heckman and Navarro (2004)  As a result, the implementation of the propensity score matching approach in empirical papers using data from international comparative studies has increased notably in recent years. PSM is implemented in two stages. In the first stage, the researcher calculates the probability, known as the \"propensity score\", of each individual receiving the treatment. This reduces the matching problem to a single dimension, thus significantly simplifying the matching procedure (Wilde and Hollister, 2007). The idea behind this estimator is that if two students or schools have the same propensity score but are in different treatment groups, the assignment can be assumed to be random. When using propensity score matching, the comparison group for each treated individual is chosen using a predefined matching criterion of proximity between the propensity scores for treated and controls. Likewise, after defining a neighborhood for each treated observation, it is necessary to select the appropriate weights to associate observations in the treatment and control group and drop treatment and control observations whose propensity score is greater than the maximum or less than the minimum of the controls. This ensures a common support for all matched observations. PSM is a non-experimental technique. Thus, although this method can mitigate the problem of self-selection, the assumption of no unobserved differences between the treated and empirically derived control group, essential for the propensity score strategy, is unlikely to hold. For this reason, PSM is probably the worst choice for improving estimations with respect to the use of all untreated individuals as controls as long as unobservable variables correlate with observables, leading to a reduction in the endogeneity bias. To conclude this section, Table 1 summarizes the main characteristics of these four econometric techniques, as well as their main strengths and weaknesses for their use with international databases. Sometimes nature or the legal framework leads to exogenous sources of variation correlated with the treatment but uncorrelated with the dependent variable. The method exploits a partial random assignment that reproduces a natural experiment. It provides even more robust results than other methodological approaches. It is mostly quite difficult to find a good, endogeneityfree instrument for international databases.\nBeneficiaries are matched with control individuals using priorto-treatment observed covariates. This requires an estimation of the probability of belonging to the treated group for all individuals. Then, the estimated probabilities are used to match pairs of treated PSM improves causal estimations with respect to using all untreated individuals as a control as long as unobservable variables correlate with observables. Whenever this assumption holds and treated and control individuals have PSM is a non-experimental approach because there is no randomization in the treatment assignment. It is mostly unreliable to assume that the unobservable variables of students or parents affecting both the treatment and the results individuals and control individuals that have a similar probability of being treated but are in the control group. the same distribution on unobservable variables, PSM mitigates the endogeneity problem. will be equally distributed in the treated and untreated groups."}, {"section_title": "Regression Discontinuity Designs (RDD)", "text": "Participation is decided by an exogenous cut-off point, normally defined by an education law requirement. The cut-off point reproduces a random experiment. It is easy to apply and provides robust results. It works well with educational policies based on rules, such as grants, entry criteria, etc. Results are average local treatment effects in the sense that they could not be generalized for individuals that are far from the cut-off point."}, {"section_title": "Differences in Differences (DiD)", "text": "\"Before\" and \"after\" information is required for the treated and the counterfactual groups. The treatment should be exogenous for the treated group. Once the information is available and the equal trends assumption is verified before applying the treatment, the method is easy to apply and provides robust results. Data demanding in terms of 'pre' and 'post' periods. It is crucial to demonstrate the equal trends assumption. For international databases, this probably requires the linkage of different waves."}, {"section_title": "Empirical studies review", "text": "In this section, our goal is to review the empirical studies in which the above methods have been applied to estimate the causal effect of different educational practices or treatments using observational data from PISA, TIMSS or PIRLS or a combination of databases. To organize the results, we classify the surveyed studies according to the estimation strategy applied and the issue covered."}, {"section_title": "Instrumental Variables", "text": "Exogenous sources of variation are difficult to find. Therefore, this approach requires researcher creativity, the availability of a valid instrument and a profound knowledge of the intervention and the circumstances under which it was developed. The most frequent topics analyzed using this approach are the private-public school debate or the effects of class size, school entry age and immigrant concentration in schools. Nevertheless, there are some studies using this strategy covering other issues. Public vs. private schools Vandenberghe and Robin (2004) pioneered the application of the IV approach (compared with other alternative methodologies like PSM) to deal with selection bias in their analysis of the effect of private school attendance on educational achievement using data about different countries participating in PISA 2000. The instrument that they used in their attempt to control for the potential endogeneity of the treatment was the location of the school defined by a dummy whose value is one if the school is located in a big city (more than 100,000 inhabitants) and 0 otherwise. The same instrument was also selected by Pfeffermann and Landsman (2011) "}, {"section_title": "Class size", "text": "Another topic of research studied by applying this method is the effect of class size and class composition on student performance using the rule indicating the maximum number of students per classroom established by states or countries. With the aim of identifying size effects (controlling for within school sorting), J\u00fcrges and Schneider (2004), Woessmann and West (2006) \nWoessmann 2005 "}, {"section_title": "Age at school entry", "text": "The IV approach has also been applied by Bedard and Dhuey (2006) to examine the impact of maturity differences on student performance. Since the relative age evaluated at any point in the educational process is endogenous, they base their estimation strategy on birth date, which is arguably exogenous. To do this, they pool data from different datasets (mainly TIMSS 1995 andTIMSS 1999)   Moreover, Isphording et al. (2016) analyze the causal effect of immigrant students\u00b4 reading performance on their math performance using an IV approach in an attempt to overcome endogeneity issues related to the unobserved ability of students. To do this, they pool data from four different PISA waves (2003,2006,2009,2012) and exploit variation in different ages at arrival and linguistic distance between origin and destination country languages. Such variables cannot be used as instruments because both have a direct effect on migrants\u00b4 math performance, but the interaction between such variables can be considered as a good identifying variable in order to isolate variation that only affects language performance."}, {"section_title": "Other topics", "text": "Lee Edwards and Garcia-Marin (2015) examine whether the inclusion of educational rights in political constitutions has an influence on student performance using data from 61 countries participating in PISA 2012. In their empirical analysis, Edwards and Garcia-Marin selected two different instruments: the historical origins of legislation protecting minority investors in a score of countries and the year of independence of each country.\nAmmermuller (2012) merges micro data from two different datasets  to investigate whether cross-country differences in educational opportunities are related to the institutional features of schooling systems using a DiD estimation approach. The schooling systems are analyzed at grade four and grade nine/ten, and the features studied are as follows: the use of streaming in school systems, annual instruction time, proportion of students in private schools and school autonomy. The identification strategy uses the difference in the dependence between social status and educational outcomes across grades between countries whose institutions have changed between grades and countries with no institutional changes across grades. Therefore, this by and large controls for country-specific factors, aside from the schooling system, assuming they are identical for students of different ages. Therefore, the DiD approach consists of eliminating the country-specific factors in order to estimate the changes in educational opportunities between grades for each country. Kiss (2013) examines grade discrimination using data about German primary and secondary schools from PIRLS 2001 and PISA 2003, respectively. Specifically, Kiss studies whether second-generation immigrants and girls are graded worse in math than comparable natives or boys by applying class fixed effects regressions to control for the average teacher effect. Additionally, he applies a matching approach that accounts for nonlinear relationships between grades and teacher characteristics. Hanushek et al. (2013) study the effect of school autonomy on student achievement or, more specifically, whether altering the degree of local school decision-making autonomy might have an impact on performance. For this purpose, they propose using a cross-country panel analysis covering the 42 countries that participated in at least three of the four waves of . Being a panel analysis at country level, their model can include country fixed effects to exploit international variation in policy initiatives focused on autonomy, while accounting for cross-country divergences in institutional features. Hanushek et al. (2014) combine the use of student fixed effects and an IV approach to investigate the role of teacher cognitive skills in explaining student outcomes. The data used for estimating teacher numeracy and literacy skills was the Programme for the International Assessment of Adult Competencies (PIAAC). Subsequently, this dataset was merged with PISA micro data for 23 countries to estimate international education production functions. Their identification strategy exploits information about the performance of students and teachers in two different subjects, thus they can control for unobserved student-specific characteristics that similarly affect math and reading performance, as well as for all differences across countries that are not subject specific. Subsequently, they also exploit exogenous variation in teacher cognitive skills using international differences in relative wages of non-teacher public sector employees as an instrument. Green and Pensiero 2016 \nAgasisti and Murtinu (2012) employ propensity score matching to investigate the effects of perceived competition among Italian secondary schools on their performance in mathematics using data from PISA 2006. Specifically, the authors exploit the information provided by school principals regarding whether or not the school is operating in an area where there is competition for students to split the available sample into two groups. Consequently, the presence of competition is considered as a potential endogenous treatment. In another study referred to the case of Italy, Ponzo (2013) examines whether being a victim of school bullying affects educational achievement. Specifically, using data from PIRLS 2006 and TIMSS 2007, Ponzo analyzes the impact on performance in two different subjects (math and science) for students enrolled in the fourth and eighth grade levels, applying PSM to control for a wide number of individual characteristics. Jiang and McComas (2015) apply the PSM approach to examine the effects of the level of openness of inquiry teaching on student science achievement and attitudes using PISA data from 2006. In the context of their study, the term inquiry teaching includes very different teaching practices, all of which somehow involve student decisionmaking. In order to evaluate such practices, the authors define five different levels of inquiry teaching considered as five categories of treatments in their causal analysis. Since the treatment is a five-level categorical variable, the generalized propensity scores were estimated using multinomial logistic regression. This generates one set of propensity scores for each treatment level (Imbens, 2000). The empirical analyses were conducted separately for each country participating in PISA. Thus it is possible to examine whether the impact of inquiry teaching is consistent across different countries. Finally, Hogrebe and Strietholt (2016) use data from PIRLS 2011 to estimate the effect of not attending preschool on grade-four students' reading achievement by implementing propensity score matching. The empirical analysis is performed for nine different countries with well-established early childhood education systems with high enrollment rates. Thus they are well suited for identifying both control and treatment groups. It is noteworthy that their binary treatment variable is defined in such a way that non-attendance is the treatment condition 9 , since they consider this effect to be more relevant for policy makers who are considering extending preschool attendance."}, {"section_title": "Regression discontinuity designs", "text": "There are very few empirical studies using this estimation strategy on international databases, although we can find several studies covering topics such as the effects of class size, schooling or tracking."}, {"section_title": "Effect of schooling", "text": "Luyten (2006) studies the absolute effect of schooling based on empirical data using the regression discontinuity approach. The estimation strategy exploits the availability of data about two adjacent grades in TIMSS 1995 combined with students\u00b4 date of birth. In this framework, the effect of age on achievement is estimated for each grade, where there is expected to be a discontinuity between the oldest students in the lower grade and the youngest students in the higher grade. This discontinuity reflects the effect of having received an extra year of schooling (i.e. being in the higher grade), assuming the average level of achievement is similar across cohorts. In order to obtain the cut-off points, the original variable representing the date of birth is transformed into a continuous variable with 12 potential values (one for each month) 7 . Luyten et al. (2008) also adopt a RD approach to assess the effect of one year\u00b4s schooling on student performance in reading, engagement in reading, and reading activities outside school. They use data from UK students participating in PISA 2000, because there are very low retention rates in this country. Therefore, the criterion for assigning students to the lower or upper grade according to their age can be assumed to be strictly adhered to. In this context, the effect of schooling is estimated as the difference between both grades minus the effect of age. Tiumeneva and Kuzmina (2015) also estimate the effectiveness of one year of schooling in seven countries using PISA 2009 data. Their approach is based on the determination of a particular threshold date and takes into account the distribution of students around this threshold point. Moreover, the empirical analysis was performed for both regular and vocational training programs."}, {"section_title": "Tracking", "text": "Kuzmina and Carnoy 2016rely on a fuzzy regression discontinuity design based on school system age of entrance rules to examine the relative labor market value of vocational and academic education. In particular, they exploit the variation in a student's age relative to age cut-offs for entering primary school in each country to compare the gain for students in vocational and academic tracks using data from three European countries (Austria, Croatia and Hungary) with early tracking systems.\nThis approach has been applied by several authors to evaluate the effect of early tracking on performance by comparing differences in achievement between students attending primary school (when there is no tracking in any country) and secondary school (when some countries use tracking and others do not) across countries with and without tracked school systems. This idea was first explored by Hanushek and Woessman (2006)  Nicaise (2015) also adopted a similar approach. However, they attempted to account for the fact that part of the social origin effect already exists before tracking. Thus they apply the DiD analysis to social origin and reading achievement data from PIRLS 2006 (primary education) and PISA 2012 (secondary education). Ruhose and Schwerdt (2015) also analyzed the effect of tracking using DiD in a cross-country framework (45 countries), but they control for unobserved differences in relevant characteristics of the migrant and native student populations that remain constant across educational stages. They also exploit variation in migrant-native test score gaps between primary and secondary schools after pooling data from all cycles of TIMSS, PIRLS and PISA conducted between 1995 and 2012. Finally, Lavrijsen and Nicaise (2016) also adopted a DiD approach to examine the effects of the age at which tracking occurred on student achievement in a comparative perspective using data from PIRLS (2001, 2006 and 2011),  and . In addition, they distinguish the effects on different groups in the achievement distribution. We can also find empirical studies in the literature that focus on a single country and evaluate some specific educational policies. For instance, Piopiunik (2014) studied the effects of early tracking exploiting a school reform implemented in the German region of Bavaria. He estimates a triple-differences model in which students in elementary and middle schools in Bavaria are compared with the respective changes of students in the non-gymnasium tracks in the control states using data from PISA 2003 and 2006. Then, the performance of gymnasium students is added to the double-differences model as an additional control group to compute the triple differences estimator.\nIn a comparative study, Lee (2014) applies the propensity score matching technique to PISA 2009 data to compare the effect of academic and vocational tracks on students' educational expectations and whether the effect varies across different socio-economic statuses in Austria and Italy. Austria and Italy were selected for comparison because they apply tracking at different stages of the educational system (early stages in Austria and later in Italy). Similarly, Arikan et al. (2016) also use PSM to predict the mathematics achievement of Turkish students compared to Australian students. In particular, they match the Australian and Turkish samples from TIMSS 2007 and 2011 based on relevant background variables (educational resources at home and selfconfidence). Jakubowski 2015evaluates differences in the magnitude of student progress across two types (vocational and general vocational) of upper secondary education in Poland using data from the PISA 2006 national study that extended the sample to cover 16-and 17-year-olds (enrolled in tenth and eleventh grade in the Polish school system). This dataset provides supplementary information on students\u00b4 previous scores in national exams. This makes it possible to control for students' innate abilities using a PSM approach. More specifically, the main contribution of this study is that the proposed model adds a latent variable to propensity score matching. This latent variable should make the treatment estimates more precise than a standard approach, where matching is conducted considering only the set of observable variables."}, {"section_title": "Difference in differences", "text": "The implementation of this method requires longitudinal data, where the same individuals are followed over time, or repeated cross-sectional data 8 , where samples are drawn from the same population before and after the intervention. Unfortunately, this type of information is not available in comparative international datasets at individual or school level, since they only provide cross-sectional data referred to different population (fourth-or eighth-grade students in TIMSS and PIRLS or 15-year-old pupils in PISA). However, it is possible to take advantage of the strength of longitudinal designs in international studies when data are aggregated at country level, as Gustafsson (2007) claims. Thus we can find a large number of empirical studies adopting a DiD approach pooling data from different databases to assess the effects of multiple aspects, such as tracking, peers, instructional time, preschool attendance, central examinations or different questions related to teaching."}, {"section_title": "Peer group", "text": "Another interesting topic that can be studied using this approach is the impact of schoolmates on students' academic outcomes, i.e. the so-called peer effect. Schneeweis and Winter-Ebmer (2008) study this issue using PISA 2000 and 2003 data from Austria, where lower and upper secondary education is highly segregated. In order to address the potential self-selection of students into schools and peer-groups, they use two specifications: school type fixed effects and school fixed effects. Vardardottir (2015) also used PISA data about a highly segregated schooling system (Switzerland), although he controls for student heterogeneity by using track-by-school fixed effects to mitigate problems of self-selection in the type of students across schools. Ammermuller and Pischke 2009 Schiman (2015) also control for variations in the quality of instruction and classroom environment across schools for specific subjects. This is possible thanks to the existence of data for multiple grades in many schools (mainly ninth and tenth grade), thus they can include school-by-subject fixed effects in the model (panel data structure). Therefore, they estimate a model that accounts for both school-by-grade and school-byyear fixed effects. This can be viewed as a difference in difference in differences model, where the difference between mathematics and reading scores for tenth grade minus the difference in ninth grade is related to the difference between mathematics and reading instruction time for tenth grade minus the difference in ninth grade. Finally, they also propose a model including a country-by-subject-by-grade term to account for national differences in the curriculum and other institutional features that might affect student performance. Cattaneo et al. (2016) also use the variance of subject-specific instruction time to determine the causal impact of instruction time on student test scores in Switzerland using data from PISA 2009. However, they refined the empirical analyses performed in the previous papers by controlling for extra time spent on specific subjects either during school or after school (enrichment, remedial courses or paid private tutoring). Likewise, they performed separate empirical analyzes for different school tracks, since tracking starts in primary school in Switzerland."}, {"section_title": "Preschool participation", "text": "Schultz (2009) uses data from a single database  to analyze the impact of pre-primary institution attendance on student performance at age 15. Her estimation strategy relies on the assumption that pre-elementary enrollment follows the same rules in all countries, thus the interaction of pre-primary attendance with structural quality measures resembles an international difference in differences approach. In particular, Schultz exploits within-country variation in pre-primary attendance and achievement, controlling for differences in various student, family, and school characteristics. This model yields reliable results when country fixed effects are included in the model. This implies that the remaining cross-country heterogeneity is unrelated to the effect of preprimary attendance. Felfe et al. (2015) evaluate whether the introduction of high-quality public childcare for three-year-olds has an influence on their cognitive performance by the end of compulsory schooling. In particular, they compare the educational outcomes of children (at age 15) who were three years old before and after the reform in states where public childcare expanded substantially and states with a less pronounced increase in public childcare in the years immediately after the reform. Using this estimation strategy, they can control for all average time-constant differences between children living in different locations (by including a dummy for the treatment areas) and in different years (by including a dummy for the different cohorts)."}, {"section_title": "Central examinations", "text": "Some researchers have also applied DiD using data from a single period. The application of this strategy is, however, subject to the adaptation of the method to other dimensions, such as the consideration of different subjects or grade levels. Jurges et al. mathematics test) and after the treatment (students who took the 2009 PISA reading exam or the 2012 mathematics test), where the control group is composed of students from other Spanish regions where there was no primary school exam before  and after the treatment ."}, {"section_title": "Pupil-teacher gender interaction", "text": "Several different researchers have used this approach to examine a number of aspects related to teaching activities. For instance, Ammermuller and Dolton (2006) investigated the potential existence of pupil-teacher gender interaction effects on performance, i.e. whether boys perform better when they are taught by male teachers and girls perform better when taught by female teachers. They use data from different waves of TIMSS (1995, 1999 and 2003) and  for only two countries (England and United States). Their strategy consists of considering two performance measures for the same student in different subjects and including student fixed effects in their econometric model to avoid potential bias in the estimation of the treatment effects because the assignment of class teacher gender may not be random. Subsequently, Cho (2012) extended this empirical analysis to a sample of students from 15 OECD countries using a similar approach."}, {"section_title": "Teaching practices", "text": "Schwerdt and Wuppermann (2011) use information provided by teachers and students about US eighth-grade students participating in TIMSS 2003 to study the effect of different teaching strategies on student achievement. In particular, they compare two teaching practices (lecture style presentations vs. in-class problem solving) exploiting between-subject variation to control for unobserved student traits. Focusing on a variable representing the teaching time spent on lecture style presentation relative to problem solving, they also apply school fixed effects to eliminate the effects of between-school sorting and exclude any systematic between-school variation in performance or teaching practice. Similarly, Bietenbeck (2014)  to analyze the effects of traditional and modern teaching practices on students\u00b4 cognitive skills. He also exploits the existence of two different observations for each student from two different subjects and includes student fixed effects in the empirical model to account for the sorting to teaching practices across schools and classrooms. Moreover, he also controls for a rich set of teacher and class characteristics in order to account for potential bias derived from unobserved teachers\u00b4 characteristics."}, {"section_title": "Propensity Score Matching", "text": "Although weaker than other methods, PSM has been widely applied with international data in order to obtain more accurate estimates when performing comparisons between public and private schools or students in different tracks, for example."}, {"section_title": "Public vs. private schools", "text": "The first authors to use the PSM approach were Vandenberghe and Robin (2004). They analyzed the effect of attending a private school on students\u00b4 achievement in different countries using alternative approaches. Specifically, propensity score matching is implemented by matching pupils attending private schools (treated) and students attending public schools (control). Similarly, Dronkers and Avram (2010) also use this method to estimate the effectiveness of private schools on reading achievement in 26 countries using a pooled sample of data from three waves of ). In addition to such cross-country studies, we can also find empirical studies dealing with this issue in a national context for countries with a high proportion of students enrolled in private schools. For example, Cornelisz (2013) uses data from two different waves of  to analyze the case of the Netherlands, where this proportion is nearly two-thirds of all students. Crespo-Cebada et al. (2014) also apply this technique to analyze the case of Spanish schools, using PISA 2006 data about different regions. The main novelty of their approach is that they implement this estimation strategy within the framework of stochastic parametric frontier analysis. Finally, Gee and Cho (2014) analyze the problem of aggressive behaviors in South Korea comparing single-sex versus coeducational schools. In their empirical study, they use data from TIMSS 2011 and the 2005 Korea Education Longitudinal Study (KELS) and also rely on the PSM approach to reduce the threat of selection bias between the two groups of schools."}, {"section_title": "Summary of empirical studies", "text": "After reviewing the four approaches and the contents of all the applications, we now synthesize the main aspects of these papers and provide an overview of the journals in which they were published. From our viewpoint, this should provide sound guidance for researchers interested in combining the use of causal inference techniques with educational data from large-scale assessments. In this manner, they would be able to identify the best outlets for their empirical studies. First of all, we find that the number of studies has increased substantially over the analyzed period, as shown in Figure 1. Thus it is clear that the use of causal inference methods with educational data from large-scale international assessments is gradually becoming a more common practice in the field of education economics, and this trend is very likely to continue to grow in the near future.  [2004][2005][2006][2007][2008][2009][2010][2011][2012][2013][2014][2015][2016] Regarding the data sources, PISA is clearly the most common option used by researchers given that this dataset provides the world's most extensive and rigorous information about the knowledge and skills of secondary school students. As a result, it is employed in two out of every three studies (Figure 2), although it is sometimes combined with other datasets. Then, of the two surveys conducted by the IEA, TIMSS seems to be more popular among researchers, especially in older articles, since it started PIRLS (1995PIRLS ( vs. 2001. Moreover, TIMSS is repeated every four years. This means that there are more available waves of data. It also provides information about student outcomes in two different subjects (mathematics and sciences) or at two different stages of the educational system (fourth and eighth grades). Thanks to this, the difference in differences approach can be implemented. In contrast, PIRLS only assesses one subject (reading) for fourth graders, and there are only three different waves available. In addition, Figure 3 highlights that the most common strategy employed in the cited studies is DiD closely followed by IV. Although the work with different cross-sectional waves complicates the use of DiD (Rutkowski and Delandshere, 2016), the assumptions required for adopting this strategy are less demanding than for other methods. As a result, we find that a considerable number of papers use this approach. However, DiD requires researchers to be creative, since they have to emulate an ideal situation in which students or schools can be evaluated at two different times (before and after implementing the evaluated intervention) without actually having longitudinal data. In the case of IV, all that is required for implementation is to find an instrument that suits a particular problem and meets some basic assumptions. Although this also requires some creativity on the part of the researcher, the wide range of variables provided by largescale assessments makes this search more feasible 10 . Other methods such as PSM or RDD require a huge number of observations with similar characteristics. This condition might be difficult to satisfy in many cases, and therefore they are used less frequently.  The first conclusion of this analysis is that the huge majority of the surveyed empirical papers (55 out of 66) were published in journals ranked in the above classifications (55 in SCImago and 46 in JCR). The exceptions are two chapters in books, six working papers and three journals not included in either the SCImago or JCR classifications. Another interesting conclusion derived from this exercise is that significantly more papers are published in economics journals than in education journals ( Figure 5). Nevertheless, we consider that the quality of the journals should also be taken into consideration. To do this, we explore the quartile rankings of the journals using the impact factor data estimated in each classification 12 . In this respect, the information reported in Figure 6 indicates that most papers using these estimation strategies were published in the two highest quartiles for both categories. Therefore, we take the view that adopting a causal inference approach to deal with large-scale data facilitates access to publication in top-ranking journals, irrespective of the subject category in which those journals are included. research is potentially of use for policy makers, professionals, researchers and practitioners interested in implementing rigorous evaluations of the available databases based on quasi-experimental designs. Thus we focus essentially on the methodological issues related to the econometric approach employed and not on the significance of the investigated effects. Our literature review reveals a wide range of alternative estimation strategies that can be adopted to avoid the recurrent problem of endogeneity. Endogeneity frequently biases the results of traditional econometric methods based on associations between variables, especially when only cross-sectional data are available. Actually, the shortage of reliable data and/or the low quality of the available information are the main problems that researchers wishing to conduct causal inference analysis in the field of education economics have to face in most countries. Thus, their only option for performing an empirical analysis in many cases is to fall back on data provided by international comparative surveys. The main weaknesses of such datasets are that they do not provide information about a previous measure of achievement and their cross-sectional and pseudo-panel structure. Nevertheless, many authors have demonstrated that it is possible to draw causal inference from these datasets, even if there is no clear exogenous variation in the observed data. In particular, some authors exploit existing information about different classes within the same school (this is only possible with TIMSS), having students enrolled in different courses and being evaluated in different subjects (this applies for PISA and also for TIMSS 1995) or, alternatively, the use of institutional rules as an instrumental variable or cut-off point to apply a regression discontinuity approach. On the other hand, others make a greater effort to emulate the existence of longitudinal data by matching data retrieved from different datasets implemented at different times of the educational track (e.g. TIMSS for fourth or eight graders and PISA for 15-year-old pupils) or build pseudo-panels using data from different waves of the same dataset. According to our systematic review, the most common strategy employed in empirical studies is to use difference in differences and instrumental variables. The difference in differences method has weaker assumptions, and the only requirement for the instrumental variables technique is to find an instrument suitable for a particular problem. Both methods require some level of creativity on the part of the researcher, but the wide range of variables provided by large-scale assessments makes this search easier. Likewise, researchers might also gather information from other external sources of data. Other methods such as propensity score matching or regression discontinuity design require a lot of observations with similar characteristics. This condition might be difficult to satisfy in many cases. Thus they are less often used in empirical studies. Even though educational researchers have demonstrated that it is possible to evaluate interventions based on the data available in the analyzed international datasets, we would like to alert policy makers about the need to improve the volume and quality of data in national and international datasets. This would help researchers to apply an appropriate evaluation procedure for the process of evaluating interventions or practices. For example, several such enhancements have already been implemented as national options for the PISA studies in Germany or Poland (Klieme, 2013;Jakubowski, 2015). In view of the importance of assessing the impacts of educational policies in particular, we would like to draw attention to the need to build longitudinal datasets at student or school level. In this manner, it would be possible to follow up the assessed units of analysis over a long period. This is the type of data that is required to evaluate the effectiveness of particular interventions in the long run. 8 In repeated cross-sectional surveys, the composition of the groups with respect to the fixed effects term must be unchanged to ensure before-after comparability (Blundell and Dias, 2009). 9 Another possible alternative would be to model different preschool doses (See Imai and van Dyck, 2004 for details)."}, {"section_title": "Notes", "text": "10 Researchers might also gather information from other external data sources. 11 In some cases, the journal can be classified in more than one category (e.g. Economics of Education Review is included in both categories -Economics and Education-). "}, {"section_title": "Year", "text": ""}, {"section_title": "Authors", "text": ""}]