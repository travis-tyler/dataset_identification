[{"section_title": "Introduction", "text": "The National Survey of College Graduates (NSCG) has been conducted by the Census Bureau for the National Science Foundation (NSF) since the 1960s. It is the nation's only source of detailed statistics on the science and engineering (S&E) labor force. The NSCG uses a rotating panel design and selects its sample on a biennial basis from the American Community Survey to allow both cross-sectional and longitudinal analysis of education, employment, and demographic characteristics of the S&E labor force. Under this design, the NSCG data is collected and released on a biennial or triennial schedule. Data are gathered in the survey on the number and characteristics of individuals with education and employment in S&E fields. Together the NSCG, the National Survey of Recent College Graduates (NSRCG), and the Survey of Doctorate Recipients (SDR) comprise the Scientists and Engineers Statistical Data System (SESTAT). The Demographic Statistics Methods Division (DSMD) of the U.S. Census Bureau provides statistical support on the NSCG to the National Science Foundation (NSF)."}, {"section_title": "NSCG Design Changes", "text": "The NSCG is undergoing design/frame changes. Prior to recent years, the frame for the NSCG was the Decennial Census. As illustrated in Table 1, the NSCG was selected from the Decennial Census. It is a longitudinal survey in the sense that subjects selected for one NSCG survey are again eligible for future NSCG surveys.  2001NSCG 2000Decennial 2003NSCG 2001NSCG 2000Decennial 2005NSCG 2003NSCG 2001NSCG 2000Decennial 2007NSCG 2005NSCG 2003NSCG 2001NSCG 2000 In the near future, the frame for the NSCG will be the American Community Survey (ACS; see NRC 2008). Table 2 illustrates the future design. Each NSCG survey takes respondents from four years of the ACS. Once a ACS respondent is a respondent to the NSCG the respondent stays in the NSCG for four rounds. Several years of ACS data are not used in estimation, weighting, or design of the NSCG.  3 rd  2 nd  1 st  ACS year used by round  NSCG 2017  2009  2011  2013  2015  ' 16, '14, '12, '10, etc. NSCG 2019201120152017'18, '16, '14, '12, etc. NSCG 2021201520172019 The design for NSCG 2010 is a hybrid that bridges the two designs. In 2010, there is a sample from the 2000 decennial census plus a supplement from the 2009 ACS. The 2000 decennial census was sub-sampled for the 2001, 2006, and 2008. A selection of individuals surveyed in those years is contacted again in 2010. Those individuals are referred to as the Old Cohort. The 2009 ACS was sub-sampled to add individuals to the 2010 NSCG. Those individuals are called the New Cohort. The new cohort has n=65,195 members. They are non-institutionalized, less than 76 years of age, and report having at least a bachelor's degree in ACS. The new cohort subsample from the 2009 ACS will be used in these analyses, because it has both ACS and NSG variables and will be similar to future scenario."}, {"section_title": "Project Overview", "text": "A project was funded by the U.S. Census Bureau (contract number YA-1323-SE-0066) to examine statistical issues in the NSCG. The four steps in the project are as follows. 1. Gather documentation on NSCG and ACS design and estimation; 2. Learn about the formation/use of survey weights, estimation, and variance estimation in NSCG (and ACS); 3. Investigate models for data in and between the NSCG and ACS; and 4. Conduct analysis on focal questions. The first two steps have been accomplished and steps 3 and 4 are underway."}, {"section_title": "Gather documentation", "text": "Efforts to gather documentation yielded a variety and number of documents. Many documents were provided by staff at the U.S. Census Bureau. For NSCG and ACS, the documentation included the following classes of information. Some citations are listed by category in the References section. \uf097 Survey questionnaires; \uf097 Survey variable code books/dictionaries; \uf097 Technical reports on sample selection and weighting (oversampling, non response adjustment, raking, post stratification) and other topics; \uf097 Research reports and memos on survey design evaluation and study; \uf097 Conference proceedings, such as those of the Joint Statistical Meetings (JSM) ; and \uf097 Reports from the NSF to Congress and the public, including the NSF S&E Indicators (NSB 2012) and the NSF report on Women, Minorities, People with Disabilities (NSF 2013). Generally not in existence are refereed journal articles on the survey design and estimation. Also generally not available are research articles based on data from the surveys. It appears that the primary use of the data is in reports from the NSF to Congress and the public."}, {"section_title": "Survey weighting", "text": "Survey weighting for the NSCG 2010 New Cohort involves several steps as described in several documents by Michael White (see references). The process of weighting the NSCG begins with the base weight, which comes from the ACS and sampling for the NSCG. After several steps, a final NSCG weight is produced. An outline of the steps based on the reports by Michael White is given below. 1. Base weight: sampling probability (ACS, NSCG) 2. Adjust weights of the sampling frame cases for duplication (8 pairs) 3. Development of the population controls -Female/Male; black/non black; young/old. 4. Weighting adjustment to account for the 2010 NSCG sample selection (adjust for non location of cases). 5. Identification of and adjustment for within-sample duplication (not needed for new cohort). 6. Weighting adjustment for unit nonresponse (propensity modeling). 7. Implementation of an iterative raking procedure: sex, race/ethnicity, S&E degree. Eight 8iterations of raking were implemented to stabilize the weights 8. Identification of and adjustment for extreme weight values. This step was processed in the sampling cells and in three (3) primary analysis domains (PADs). Weights within cells were judged to be extreme if they were greater than the mean within the cell plus five (5) standard deviations within the cell: extreme > mean + 5 SD. Extreme weights are trimmed; 9. Reallocation of weights to address trimmed-weight bias: rake to sampling cell and secondary analysis domain SAD23 (ACS sex by broad occupation); 10. Construction of the 2010 NSCG final weights through an additional implementation of an iterative raking procedure. Estimation in the 2010 NSCG uses the final weights for estimation and replicate variance estimation to estimate uncertainty associated with the estimates. Variance estimation was based on eighty (80) replicates with successive difference replication variance estimation (U.S. Census Bureau 2009; Fay and Train 1995). Issues concerning variance estimation were studied Opsomer (2011, 2012)."}, {"section_title": "Modeling Overview", "text": "The modeling task of this project involves defining and estimating statistical models relating variables to one another within and across surveys. There are discrete and continuous variables in the ACS and NSCG. Table 3 illustrates the structure of the surveys over time. The ACS is a cross sectional survey, whereas the NSCG is a rotating panel (longitudinal) survey. One can model aggregates across time for cross sectional surveys. One can model aggregates across time for longitudinal surveys, but one also can model the longitudinal nature of the data; i.e., the same people are respondents in multiple survey years. The NSCG is a subsample from a previous year ACS. Therefore one can model aggregates or micro data across time between the two surveys. In summary, one can consider models relating \uf097 ACS in year t, ACS in year t+1, ACS in year t+2, \u2026 (aggregates, not longitudinal); \uf097 NSCG in year t+1 and NSCG in year t+3 (aggregate and longitudinal); and \uf097 ACS in year t and NSCG in year t+1 (aggregate, subsample). "}, {"section_title": "Topics for Analysis", "text": "Initial discussions with staff at the NSF and at Census identified four (4) possible topics for study. The discussion produced a rank ordering of the importance and hence timing of the planned studies. It is not anticipated that all four studies will be completed fully during the contract period. The four topics in rank order of importance are listed below. The rest of this paper concerns the first topic estimation for small domains. "}, {"section_title": "Small Area Estimation: Estimation for Small Domains", "text": "The NSCG is designed to give sufficient accuracy at the national level and at the level of large regions of the country. There is an interest in estimation in small areas (e.g., states) and small domains (e.g., subgroups by demographics, including female/male, race/ethnicity, age, and other factors). Estimation methods that \"borrow strength\" across areas/domains can produce reductions in mean square error (MSE), especially for small areas and domains. Estimation methods that utilize information from multiple surveys (NSCG, ACS) could also produce gains in MSE. Small \"areas\" of interest to NSF, as suggested in conversations with the NSF staff, include Hispanics with U.S. bachelor's degrees by broad occupation group and American Indians Alaskan Natives (AIAN) and Native Hawaiians and Pacific Islanders (NHPI) by broad occupation group. In the 2010 NSCG, based on publicly available data, there were 7,533 respondents of Hispanic origin, representing 9.8% of the sample. In 2010, there are 317 AIAN respondents and 307 NHPI respondents, each representing 0.4% of the sample. A variable USCAB is a variable that indicates whether the bachelor's degree is predicted to be a U.S. bachelor's degree. More generally, there are several race/ethnicity categories with low counts by broad occupation code. Table 4 reports counts of respondents with U.S. bachelor's degrees (USCAB) by broad occupation and race/ethnicity for a selection of race/ethnicity groups. Whites and Asians are not included, because they are larger in number. These data come from the public use web site for the NSCG. Beyond the cross of race/ethnicity with broad occupation, there are many other variables that, if used in tabulating sample numbers, would produce small counts in many cells. Considering additional variables creates many more small areas of potential concern. In the 2010 NSCG, ACS_RACETH has 6 levels, ACS_SEX has 2 levels, ACS_DEMGROUP includes two age groups, ACS_SE has two levels (S&E versus not), and ACS_HIDEG has 3 levels (BA/BS; MA/MS; PhD). Fully crossed, there are 12*6*2*2*2*3 = 1,728 cells. Of course, other variables might also be considered. "}, {"section_title": "Small area models", "text": "The models that are being considered for these data are small area models for cross classified nominal variables. Area level models and unit level models can be considered. Area level models specify relationships of expected counts to characteristics describing areas. Respondents have variation within their respective areas. Unit level models specify relationships of probabilities of cell membership based on individual respondents. The former (area level models) in this application might use age group (2 levels) as a covariate. The latter (unit level models) might use age as a covariate for membership in other (non-age) categories. In the case of area level models, \u2022 Data have a multinomial distribution with proportion parameters \uf097 The Prior distribution on the proportions is a Dirichlet distribution \uf097 The Posterior distribution for proportions is a Dirichlet. In this case, means, variances, and simulated values of proportions are simple to produce \uf097 The Predictive distribution for unknown data is a multinomial distribution with sample size 1: simulated cell entries are possible based on observed cell information and draws of proportions from the posterior distribution. The number of variables involved in defining the contingency table and how variables are used in the model define a series of models. A Large model could involve a full cross classification of variables and produce a saturated log linear model. Reduced models are log linear model with some higher order interactions set to zero. Unit level modeling ideas will be discussed below as potential model extensions."}, {"section_title": "Small area modeling issues", "text": "A number of modeling issues arise with small area estimation in general and in this application in particular. \uf097 How should one select models? The set of available models include fully saturated or reduced area level models and unit level models with various uses of covariates. AIC or BIC criteria can be used to select models. One also can examine residuals: differences between model estimates and empirical (direct survey) estimates. One expects some shrinkage under the small area estimates, especially in cells with small sample sizes, but one probably does not want all the estimates to be nearly equal to the mean given the size of the data set. \uf097 Use of design and other variables: Additional variables (e.g., detailed occupations crossed with demographics) were used for sampling cells. Should models be made bigger to account for the levels of these variables? \uf097 Use of survey weights: A population size by cell is implied by the sum of survey weights. Posterior mean value for proportions for unobserved cases could be used in estimation. Then the weighted posterior means could be used to produce a population-based estimate of small area size. Methods of incorporating survey weights into the analysis need to be considered. \uf097 Replicate survey weights: Replicate weights could be used in place of final survey weights in the weighting procedure described in the previous bullet; this would enable use of successive difference replication variance estimation on the modeled data. The question arises, however, whether one should do this. Instead, in the Bayesian context, one can simulate the posterior variance or posterior interval about an estimate. \uf097 Evaluation of models and their impact on MSE: In the context of the example, how does one judge whether the modeling effort has produced improved estimates. Simulation studies can suggest the quality of performance that should be anticipated. Other anecdotal evidence, such assessments of patterns and reasonableness within the data itself, also can be considered."}, {"section_title": "Extensions to small area models", "text": "A number of extensions to the small area models can be considered. One idea is described briefly as follows. \uf097 For each category (small area domain or cell), one could model the propensity of being in that category -this is multinomial (polytomous) logistic regression. \uf097 Some variables (e.g., Highest degree, Sex, Age group) would then be used as predictors of cell membership in the logistic regression models. Models could have main effects and some interactions. \uf097 A unit level model could use additional variables (such as design variables) for each person in the sample. If the ACS frame includes all the unit level variables, then predictions can be formed for all ACS sample members. \uf097 Prior distributions would be placed on model regression parameters. This produces a hierarchical polytomous logistic regression model. References on small area estimation are numerous. A selection of references that could be useful in the current investigations include Berg and Fuller (2012), Chattopadhyay et al. (1999), Ghosh and Maiti (2004), Jiang and Lahiri (2006), Larsen (2003), Pfefferman (2013), Rao (2003), and Xie, Raghunathan, and Lepkowski (2007)."}, {"section_title": "Conclusions and Future Work", "text": "Conditions in the National Survey of College Graduates (NSCG) seem right for trying small area estimation (SAE). There are many domains and it is a large data set but with small sample counts in some places and subgroups. Bayesian log linear models can be one approach to try. Other approaches can be compared. The plan for the near future is to continue research on SAE for NSCG 2010 using the new cohort of NSCG 2010 drawn from the 2009 ACS. The long term goal for this project is to address four research topics of interest to the NSF and Census for the National Survey of College Graduates (NSCG). \uf097 Estimation for small domains/areas \uf097 Update weighting for NSCG using new ACS \uf097 Intermediate year estimation for the NSCG \uf097 Design and evaluation for rotation of question blocks"}]