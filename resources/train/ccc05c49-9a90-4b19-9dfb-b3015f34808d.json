[{"section_title": "Abstract", "text": "Abstract. We investigated the performance of four popular supervised learning algorithms in medical image analysis for white matter hyperintensities segmentation in brain MRI with mild or no vascular pathology. The algorithms evaluated in this study are support vector machine (SVM), random forest (RF), deep Boltzmann machine (DBM) and convolution encoder network (CEN). We compared these algorithms with two methods in the Lesion Segmentation Tool (LST) public toolbox which are lesion growth algorithm (LGA) and lesion prediction algorithm (LPA). We used a dataset comprised of 60 MRI data from 20 subjects from the ADNI database, each scanned once in three consecutive years. In this study, CEN produced the best Dice similarity coefficient (DSC): mean value 0.44. All algorithms struggled to produce good DSC due to the very small WMH burden (i.e., smaller than 1,500 mm 3 ). LST-LGA, LST-LPA, SVM, RF and DBM produced mean DSC scores ranging from 0.17 to 0.34."}, {"section_title": "Introduction", "text": "White hyperintensities (WMH) segmentation is an important problem in medical image analysis because it is believed that WMH are associated with the 3 Data used in preparation of this article were obtained from the Alzheimers Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc. edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf progression of dementia [21, 1] . WMH are brain regions that have higher grayscale intensities than normal tissues in T2-Fluid Attenuation Inversion Recovery (FLAIR) magnetic resonance images (MRI).\nThere have been many attempts to automatically segment WMH in the past few years. Most of the works used support vector machine (SVM) and random forest (RF) for which some image features need to be extracted first. Some notable works were done in [10, 11] where several feature extraction methods and learning algorithms were evaluated to find the best possible combination for this purpose. Both studies concluded that SVM was the best performer in the experiments. In another study, RF was compared with SVM and the former performed better [8] . However, these studies cannot be compared to each other directly because they use different feature extraction methods. Feature extraction and selection are as important as the learning algorithm itself for WMH segmentation. Fortunately, machine learning algorithms have developed into more sophisticated approaches of deep learning, which are now commonly used in image analysis. In these approaches, the algorithm extracts the features automatically from the data to get the best results possible. Some algorithms of this type like deep Boltzmann machine (DBM) [12] and convolutional encoder network (CEN) [2, 3] have been successfully tested to work well with medical image data, including brain MRI.\nIn this study, we investigate performances of supervised learning algorithms of SVM, RF, DBM and CEN for WMH segmentation in brain MRI with mild or no vascular pathology. We choose brain MRI with mild or no vascular pathology because it is important to detect the presence of WMH as early as possible. It is also notably more challenging to do WMH segmentation in this type of data because the WMH burden for each patient is smaller. We also compare the results of these algorithms with those from with a publicly available toolbox for WMH segmentation named Lesion Segmentation Tool (LST) [19] ."}, {"section_title": "Data, Processing Flow and Experiment Setup", "text": "Data used in this study are obtained from the Alzheimers Disease Neuroimaging Initiative (ADNI) public database [14, 22] . Our dataset contains MRI data from 20 ADNI participants, randomly selected and blind from any clinical, imaging or demographic information at the time of selection. MRI data were acquired on three consecutive years, resulting in data from a total of 60 MRI scans. Three of them were cognitively normal (CN), 12 had early mild cognitive impairment (EMCI) and 5 had late mild cognitive impairment (LMCI). Ground truth segmentation of the respective MRI data is produced by an experienced image analyst, semi-automatically by thresholding the T2-FLAIR images using the region-growing algorithm in the Object Extractor tool of Analyze T M software, simultaneously guided by the co-registered T1-and T2-weighted sequences. A subset of manually delineated WMH masks from another observer is also used for validation purposes. Each brain scan was processed independently, blind to any clinical, cognitive or demographic information and to the results of the WMH segmentations from the same individual at different time points. For more details and to access these segmentations, please refer to http: //hdl.handle.net/10283/2186.\nThe preprocessing steps of the data comprise of co-registration of the MRI sequences on each scanning session, skull stripping and intracranial volume mask generation, cortical grey matter, cerebrospinal fluid and brain ventricle extraction and intensity value normalisation. FSL-FLIRT [9] is used for rigid-body linear registration of the T1-W to the T2-FLAIR. Whereas, optiBET [13] and morphological fill holes operation are used for skull stripping and generation of the intracranial volume mask. On the other hand, two steps intensity value normalisation, which are adjustment of maximum grey scale value of the brain without skull to 10 percent of the maximum T2-FLAIR intensity value and histogram matching algorithm for MR images [16] , are done. Furthermore, zeromean and unit-variance grey scale value normalisation is also used for CEN to ensure a smooth gradient in the back propagation. In addition, scaling the features to [0...1] is used for DBM and SVM training processes as it is needed for the binary type of DBM and for easing the SVM training process. After the normalisation is finished, patch-wise data of WMH and non-WMH from MRI with ratio of 1:1 (i.e., the same number of patches from WMH and non-WMH regions) are extracted for SVM and RF training processes while ratio of 1:4 is used for DBM training process (i.e., there are four times more patches from non-WMH regions than patches extracted from WMH regions in the data used for training the DBM). On the other hand, in CEN, one slice of MRI is treated as one training data.\nTwo different tests are done, which are 5-fold cross validation test and longitudinal test. Cross validation is done with 16 individuals for training and 4 individuals for testing in each fold. Whereas, longitudinal test is done using MRI data from the first year of acquisition for training and the second and the third years of acquisition for testing. Dice similarity coefficient (DSC) [6] , sensitivity (TPR), specificity (TNR), precision (PPV) and volume difference (VD) and its ratio (VDR) are used as performance metrics. VDR is computed using Equation 1 where V olume(Seg.) is the WMH volume resulting from segmentation and Volume(GT) is the WMH volume from ground truth. VD is computed using the same Equation 1 without normalisation of the ground truth volume. All evaluation metrics are computed after probability map values of WMH, resulting from automatic segmentation method, are cut-off using threshold value t \u2265 0.7. This value was chosen after the results were reviewed by a neuro-radiologist."}, {"section_title": "Methods", "text": "In this section, all methods used in this study for WMH segmentation are discussed. The methods are Lesion Segmentation Tool (LST) toolbox, support vec-tor machine (SVM), random forest (RF), deep Boltzmann machine (DBM) and convolutional encoder network (CEN)."}, {"section_title": "Lesion Segmentation Tool, Support Vector Machine and Random Forest", "text": "Lesion Segmentation Tool (LST) is a public toolbox developed for segmenting multiple sclerosis (MS) lesions in MRI [19] . It also claims to be useful in other brain diseases including WMH in normal aging. In this study, we use both algorithms available on LST version 2.0.15 3 toolbox, which are lesion growth algorithm (LGA), an unsupervised algorithm, and lesion prediction algorithm (LPA), a supervised algorithm pre-trained with data from 53 MS patients.\nSupport vector machine (SVM) is a supervised machine learning algorithm that separates data points by a hyperplane [5] . Whereas, random forest (RF) is a collection of decision trees trained individually to produce outputs that are collected and combined together [17] . These two algorithms are commonly used in segmentation and classification tasks. For reproducibility and repeatability reasons, and also to make comparison easier, we modified a public toolbox: W2MHS 4 [8] , which uses RF for WMH segmentation. We retrained the RF model using the following parameters: 300 trees, 2 minimum samples in a leaf and 4 minimum samples before splitting. The feature extraction of the toolbox is used without any change. The features extracted and used in the training process comprise of 125 MR image grey scale values and 1875 response values from a filter bank of low pass filter, high pass filter, band pass filter and edge filter (see [8] for full explanation), all of them extracted from 3D ROIs with the size of 5 \u00d7 5 \u00d7 5. In total, for training the SVM and RF classifiers we used 200,000 samples: 100,000 patches from WMH regions and 100,000 from non-WMH regions. We also modified the toolbox so that we can now choose from which MRI modality, T2-FLAIR or both T2-FLAIR and T1W, these features are extracted from. These extracted features are also used to train the SVM classifier after the feature's dimensionality is reduced to 10 using PCA and then whitened before training. In this study, radial basis (RBF) kernel is used for SVM classifier."}, {"section_title": "Deep Boltzmann Machine", "text": "Deep Boltzmann Machine (DBM) is a variant of restricted Boltzmann machine (RBM), a generative neural network that works by minimizing its energy function, where multiple layers of RBM are used instead of only one layer. Each hidden layer captures more complex high-order correlations between activities of hidden units than the layer below [18] . Each layer can be independently trained first (pre-trained) to get better better initialization of the weight matrix. A DBM with two hidden layers is used in this study (depicted by Figure 1a) \n. Given a restricted structure where each layer units are conditionally independent of each other, the conditional distribution of the probability for a unit in a layer given other layers can be computed as in Equations 4, 5 and 6 where \u03c3 is a sigmoid function. Full mathematical derivation of RBM and its learning algorithm can be read in [7] . Whereas, derivation of DBM and its learning algorithm can be read in [18] .\nWe use 5 \u00d7 5 \u00d7 5 3D ROIs to get grayscale intensity values from the MRI's T2-FLAIR modality for the DBM's training process. The intensity values are feed-forwarded into a 2-layer DBM with 125-50-50 structure where 125 is the number of units of the input layer and 50 is the number of units of both hidden layers. Each RBM layer is pre-trained for 200 epochs, and the whole DBM is trained for 500 epochs. After the DBM training process is finished, a label layer is added on top of the DBM's structure and fine-tuning is done using gradient descent for supervised learning of WMH segmentation. We modified and used Salakhutdinov's public code for DBM implementation 5 ."}, {"section_title": "Convolutional Encoder Network", "text": "Convolutional encoder network (CEN) is one of deep learning models which is usually used to generate a negative data (i.e., synthesised data) learned from a dataset. In this study, CEN is used to generate a WMH segmentation of an MRI data learned from the dataset. CEN is trained using a whole image of MRI, just like in natural images where a whole image is feed-forwarded into the network, to form a DBM (right). In (b), input image is encoded by using two convolutional layers and an average pooling layer and decoded to WMH segmentation using two de-convolutional layers and an un-pooling layer. This architecture is inspired from [2, 3] .\nrather than using a patch-wise approach (i.e., uses image segments) of MRI like in other medical image analysis studies that use deep learning algorithms. This approach has been applied before in [2, 3] for MS lesions segmentation and the results were reported as promising. However, we used a 2D CEN instead of a 3D CEN like in the previous studies due to the anisotropy of the MR images used in this study (i.e., the T2-FLAIR MRI from ADNI database have dimensions of 256 \u00d7 256 \u00d7 35 and voxel size of 0.86 \u00d7 0.86 \u00d7 5 mm 3 ). In this study, we use a simple CEN composed of 1 input layer, 5 hidden layers (i.e., feature maps or FM in deep learning study) and 1 output layer. The input layer is made of the MRI slices with size 256 \u00d7 256 and 2 channels (i.e., T2-FLAIR MRI and brain mask). Whereas, the output layer is a simple binary mask of WMH labels for the corresponding T2-FLAIR MRI. The first feature map (FM) is produced by convolving a 9\u00d79 kernel to the input layer. The second FM is produced by doing average pooling operation to the first FM. The third FM is produced by convolving a 5 \u00d7 5 kernel to the second FM. All together, they are called an encoding path. All convolution operations in the encoder path use the following Equation 7 where x is input/output vector, l is index layer, W l\u22121,l is weight matrix from layer l \u2212 1 to layer l, * is convolution operation, b is bias vector and \u03c3 is non-linear ReLU activation function [15] .\nOn the other hand, the fourth and the fifth FMs are produced by using deconvolution (with 5 \u00d7 5 kernel) and un-pooling operations respectively to the previous FMs. Output layer is produced by a deconvolution operation (with 9\u00d79 kernel) to a merged FM composed by the fifth and the first FMs. This merger is called a skip connection which provides richer information before pooling and un-pooling operations. All together, these operations formed a decoding path. Also, please note that the same size of kernel is used at the same level of encodingdecoding. Deconvolution at the fourth layer follows the same Equation 7 except that * is now a deconvolution operation. On the other hand, the output layer follows Equation 8 where y is output vector of output layer, W 1 and W 5 are weight matrices connecting FM #1 and FM #5 to output layer respectively, x 1 and x 5 are FM #1 and FM #5, b y is bias vector of output layer and \u03c3 is non-linear sigmoid activation function.\nFor optimising the CEN, we use Dice similarity coefficient (DSC) [6] as objective function of CEN as we want to get the best DSC metric as possible in the evaluation. This is different from [2] where they use a combination of specificity and sensitivity as objective function. CEN is implemented by using Keras [4] , with its default values of layer's hyper-parameter are used. The CEN itself is trained for 2500 epochs without early stopping (i.e., the same epoch and approach suggested in a previous study [3] for limited number of training dataset), learning rate of 1e-5 and batch size of 5 in each epoch. The number of FM in all layers is 32 feature maps. Table 1 shows the overall results for all methods tested in this study. This table is interesting because the highest overall DSC score is produced by CEN whereas the highest scores of sensitivity, specificity and precision are all produced by different methods which are LST-LPA and RF-FLAIR respectively. If we look closely, all methods have high scores of sensitivity and precision, but all of them have different scores of specificity. The highest specificity score, 0.8133, is produced by RF-FLAIR which also has a high sensitivity score of 0.9705. However, RF-FLAIR produce a low DSC score, 0.2215. If we compare to CEN, which has the highest DSC score of 0.4400, it has 0.9985 and 0.4287 for sensitivity and specificity scores respectively. From this observation, we can conclude that DSC score is highly related to sensitivity. The relationship between DSC and sensitivity is stronger than between DSC and specificity. A small drop in the sensitivity score (e.g., 2.85% drop from CEN to RF-FLAIR) changes the DSC score considerably (i.e., 22.15% lower) independently from the specificity score (i.e., RF-FLAIR is 38.46% higher than CEN). This means that there should be a balance between the DSC, sensitivity and specificity, to get the best result possible."}, {"section_title": "Results and Discussion", "text": "To see the distribution of segmentation performance based on WMH burden for each subject, we grouped our data into 5 groups based on WMH volume of each patient. volume is bigger than 24000 mm 3 . We then plotted and listed DSC scores based on the group in Figure 2 and Table 2 . From both the figure and the table, we can see that all methods do not have any problems in segmenting very large WMH burden from a subject, but their performances are decreasing greatly in smaller WMH burdens, except for DBM and CEN where the decrease in performance with WMH load is not much. Some visual examples of WMH segmentation can be seen in Figure 3 where visualisations from ground truth, LST-LGA, SVM-FLAIR, RF-FLAIR-T1W, Table 2 : Average values of dice similarity coefficient (DSC) and volume difference ratio (VDR) for grouped MRI data based on its WMH burden. VS, S, M, L and VL stand for 'Very Small', 'Small', 'Medium', 'Large' and 'Very Large' which are names of the groups. DBM and CEN in a subject with small WMH burden are shown. We can see that CEN produced much better results than the other methods. In addition to the evaluations that have been mentioned in all figures, tables and previous paragraphs, we also keep records on the time training and testing processes take in the experiments. SVM, RF and DBM took roughly 26, 37 and 1341 minutes respectively for the training process. Whereas, it took 83, 41 and 17 seconds for SVM, RF and DBM to complete one MRI data in the testing process from a workstation in a Linux server with 32 Intel(R) Xeon(R) CPU E5-2665 @ 2.40GHz processors. On the other hand, Linux Ubuntu desktop with Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz and EVGA NVIDIA GeForce GTX 1080 8GB GAMING ACX 3.0 was used to train and test the CEN; and the training and testing processes took 152 minutes and 5 seconds respectively. An image analyst can take from 15 to 60 minutes to segment WMH on a single dataset depending on the level of experience [20] ."}, {"section_title": "Conclusion and Future Work", "text": "In this study, we have seen performances from different supervised learning methods for WMH segmentation in brain MRI with mild or no vascular pathology. We tested SVM, RF, DBM and CEN and compared them with a public toolbox LST which provides two different algorithms, LGA and LPA. From the experiments, we can see that WMH volume is the most challenging problem in this study because WMH segmentation results using all methods on subjects with low and very low WMH produce low DSC scores. Furthermore, we also find that there are strong dependencies between DSC, sensitivity and specificity, especially between DSC and sensitivity. To produce a high score of DSC, we need to find a good balance between these three metrics. In this study, we use DSC as objective function on CEN. If DSC, sensitivity and specificity are used all together on CEN on objective function, better results of WMH segmentation may be obtained. Furthermore, the MRI could be re-sampled to isotropic images so that a 3D CEN can be tested and compared with the 2D CEN evaluated in this study."}, {"section_title": "Acknowledgement", "text": "The first author wants to thank Indonesia Endowment Fund for Education (LPDP) "}]