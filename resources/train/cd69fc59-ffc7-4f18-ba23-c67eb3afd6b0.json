[{"section_title": "Abstract", "text": "Characterization of long-term disease dynamics, from disease-free to end-stage, is integral to understanding the course of neurodegenerative diseases such as Parkinson's and Alzheimer's; and ultimately, how best to intervene. Natural history studies typically recruit multiple cohorts at different stages of disease and follow them longitudinally for a relatively short period of time. We propose a latent time joint mixed effects model to characterize longterm disease dynamics using this short-term data. Markov chain Monte Carlo methods are proposed for estimation, model selection, and inference. We apply the model to detailed simulation studies and data from the Alzheimer's Disease Neuroimaging Initiative."}, {"section_title": "Introduction", "text": "Disentangling the effects of normal aging from the effects of pathophysiology on neurobiological trajectories is crucial for predicting who will develop Alzheimer's or other neurodegenerative diseases. To make matters more difficult, the determination of neurobiological trajectories is typically based on data obtained over a relatively short time frame relative to the time span of normal aging and neurodegeneration [1] . There are four key barriers to the accurate characterization of longitudinal trajectories of neurodegeneration and pathology in older adults: 1) late-life trajectories can span 40 or more years; 2) there is substantial variation in the timing and temporal dynamics of late-life trajectories; 3) study selection criteria and sampling have a substantially different impact across age groups; and 4) there are potentially significant levels of censoring due to death and disability in late-life that cannot be treated as independent of pathology trajectories in most cases. Accounting for these issues Email address: mdonohue@usc.edu (Michael C. Donohue) 1 Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/ wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf is crucial to studying the onset, course and fluctuations of neurodegenerative diseases [2, 3] , and for guiding when and how to target interventions and preventative approaches [4] . A better understanding of how and when to intervene necessitates the determination of dynamic networks of trajectories of markers of cognition, function, and pathology. Long-term disease dynamics are of great interest and importance, and have been hypothesized without rigorous methods.\nWe propose a latent time joint mixed effects model (LTJMM) for characterizing biomarker trajectories in aging. The model extends joint mixed effects models [5] to include an individual-specific latent time shift. Each individual's latent time shift is shared across all of their outcomes and represents the extent of their long-term disease progression. The model is similar to others proposed for this application (e.g. Jedynak et al. [6] and Donohue et al. [7] ). However, the proposed model can also accommodate covariates for fixed-effects and the Bayesian implementation allows flexible but rigorous interrogation of the posterior distribution to make inferences about long-term disease dynamics and the potential propagation of treatment effects from early biomarkers to downstream cognitive and functional measures. Estimation and inference are accomplished using Hamiltonian Markov Chain Monte Carlo as implemented in Stan [8] and the R package rstan (Stan Development Team [9] , version 2.10.1). The Stan code model specifications and related tools for estimation and prediction are available as an additional R package from https://bitbucket.org/mdonohue/ltjmm."}, {"section_title": "Methods", "text": ""}, {"section_title": "Latent time mixed-effects models for joint longitudinal responses", "text": "Suppose that p response variables are measured for n individuals at q follow-up times. Follow-up may be differ from subject to subject and outcome to outcome, but we fix q to simplify notation. The measured outcomes for individual i at time j are denoted as y ij = (y ij1 , \u00b7 \u00b7 \u00b7 , y ijp ) , which could be mixtures of binary, count, ordinal, and continuous outcomes. Assuming y ijk has a distribution in the exponential family with canonical parameter \u03b8 ijk , the latent time joint mixed effects model (LTJMM) is given by\nwhere h k (\u00b7) is a monotonic differentiable link function specific to the k-th outcome, \u03b7 ijk is the linear predictor for the k-th outcome from individual i at time j. The vector x ijk represents possibly time-varying covariates, and the vector \u03b2 k is their corresponding regression coefficients. The \u03b5 ijk \u223c N (0, \u03c3 2 k ) is a measurement error term, which accounts for outcome-specific variance.\nThe parameters \u03b1 0ik and \u03b1 1ik are the subject and outcome specific random intercept and slope, and \u03b4 i is the subject-specific time shift shared among outcomes. The parameter \u03b3 k corresponds to the outcome-specific slope with respect to \"shifted\" or \"long-term\" time. The time shift \u03b4 i quantifies the progression of the i-th individual relative to the population, and \u03b1 1ik provides the information on whether individual i is evolving faster or slower than the average individual for outcome k.\nIn application of the model, we typically include a fixed effect for age, as a time-varying covariate, for each outcome. This admits two relevant rate-of-change parameters: one for biological age and one for \"disease time.\" This reflects the fact that individuals can reach the same stage of disease at different ages, and allows independent effects of healthy aging and disease progression. The random effects accomodate additional subject to subject variation in the level and rate of change of disease markers. The link function, h k , can be used to accomodate any distribution from the exponential family.\nSome constraints must be placed on (1) to ensure model identifiability based on the observed data without relying on informative prior distributions. In particular, to ensure identifiability of \u03b4, the following two constraints are sufficient:\nfor all individuals i = 1, . . . , n; and Constraint 2 \u03b3 k > 0 for all outcomes k = 1, . . . , p.\nA proof of identifiability is available in the appendix. In practice, we find that it was sufficient to merely constrain p k=1 \u03b1 0ik = 0, however the proof of identifiability requires that \u03b1 1ik terms are also constrained. Identifiability also requires there are more subjects than outcomes (n > p). Shape invariant models and self modeling regression (e.g. Kneip and Gasser [10] ) similarly require positive first derivatives (Constraint 2). Model (1) can be modified to address more flexible nonlinear relationships over time by incorporating higherorder terms or splines [11] , provided these extensions maintain monotonicity (Constraint 2).\nFinally, we explore two different distribution assumptions for random effects, namely:\nwhere \u03a3 is a covariance matrix of dimension 2p. The latter assumption allows more direct exploration and inference regarding the correlation of response variables."}, {"section_title": "Prior specification", "text": "Since an improper prior may result in an improper posterior, we will use proper but weakly informative priors on all the model parameters [12] . The regression parameters \u03b2 and \u03b3 are assigned independent weakly informative normal N (0, 100) priors (truncated below by 0 for \u03b3). Without specific information, the half-Cauchy prior is a good default choice for scale parameters [12] . The standard deviations, i.e., \u03c3 \u03b4 , \u03c3 01 , \u00b7 \u00b7 \u00b7 , \u03c3 0p , \u03c3 11 , \u00b7 \u00b7 \u00b7 , \u03c3 1p and \u03c3, are given weakly informative half-Cauchy priors with a small scale, i.e., half-Cauchy (0, 2.5). The prior variance 100 for the regression parameters is chosen to be sufficiently high to be vague enough, but sufficiently low to avoid slow mixing due to near impropriety of the posterior [13] .\nTo ensure efficiency and arithmetic stability, we applied the Cholesky decomposition to the covariance matrix for the random effects, \u03a3, allowing us to model the standard deviations and correlations independently. We first decomposed the covariance matrix as \u03a3 = \u039b\u2126\u039b, where \u039b is a diagonal matrix with diagonal elements \u03c3 01 , \u00b7 \u00b7 \u00b7 , \u03c3 0p , \u03c3 11 , \u00b7 \u00b7 \u00b7 , \u03c3 1p , and \u2126 is the correlation matrix with 1's on the diagonal and off-diagonal elements \u03c1. A Choleksy decomposition gives \u2126 = LL , where L is a lower triangular matrix. Furthermore, \u03a3 = \u039bLL \u039b. During sampling, a draw is obtained from a multivariate Gaussian z \u223c N (0, I), and then the random effects are calculated as \u039bLz. Here, z is regarded as a random reparameterization and independent of \u03c1. As suggested in Stan [14] manual, we imposed an LKJ prior on the correlation matrix [15] ."}, {"section_title": "Model comparison criteria", "text": "We use two model comparison criteria, namely, the widely applicable information criterion (WAIC) [16] and the leave-one-out cross-validation information criterion (LOOIC) [17, 18] . WAIC and LOOIC can be computed using the log-likelihood evaluated at the posterior simulations of the parameter values. Both have various advantages over the deviance information criterion (DIC). WAIC can be viewed as an improvement on DIC for Bayesian methods [19] . We refer to Gelman et al. [20] for the detailed reasons we prefer WAIC to DIC.\nApproximate LOO can be computed using raw importance sampling (IS, Gelfand et al. [17] ). Vehtari et al. [19] improved the LOO estimate using Pareto smoothed importance sampling (PSIS) method which provides a more accurate and reliable estimate than IS. The R package loo [21] provides tools for efficient computation of WAIC and LOOIC. The minimum WAIC and LOOIC indicate the best fit."}, {"section_title": "Results", "text": ""}, {"section_title": "Simulation study", "text": "We conducted a simulation study to assess the model performance and assess small sample bias. Data were generated from two candidate LTJMMs with identity link: (M1) Univariate Gaussian random effects; (M2) Multivariate Gaussian random effects. We simulated n = 400 individuals with p = 4 outcomes and q = 4 time points each. The observation times for each individual were sampled from a Uniform distribution t ij \u223c Uniform (0, 10). Additional simulation parameters were set to \u03b2 = (1, 0.5, 2, 0. \u03b8 m \u2212 \u03b8 m 2 /M , and (iii) coverage rate of the 95% credible intervals, C 95 . Results are reported and discussed in Section 3.2. Each model was simulated M = 100 times and both models were fit to each simulated data set.\nFor each model fit, two parallel Markov chains were run with dispersed initial values to diagnosis convergence. For each single chain, we ran 2 000 iterations and discarded the first 1 000 iterations as a warm-up phase, yielding a total of 2 000 samples for posterior analysis. The remaining samples were used to calculate posterior summaries of the parameters of interest and model comparison measurements. The potential scale reduction statisticR [22] , calculated by Stan was used to verify posterior convergence."}, {"section_title": "Simulation study results", "text": "The estimated potential scale reduction factors were below 1.1 for all parameters, indicating successful convergence. Table 1 summarizes the measures of total bias, MSPE, C 95 , and the percentage of best performance in terms of WAIC and LOOIC for each scenario. In Table 1 , we can see the advantage of M2 under two different scenarios with better coverage rates of the 95% credible intervals for most parameters and larger percentage of best performance. It may not be surprising that M2 is preferred even when M1 is the true model, since M2 accommodates the association between outcomes and includes M1 as a special case. For both scenarios, the regression parameters were estimated with low bias and MSPE, indicating good performance in terms of prediction error. Figure 1 plots the true versus estimated individual intercepts and slopes for the first outcome, and the true versus estimated time shifts of one simulated data set. Both plots demonstrate agreement between the true and estimated values."}, {"section_title": "Application to Alzheimer's Disease Neuroimaging Initiative", "text": "The LTJMM was fit to data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), which has followed volunteers diagnosed as cognitively healthy or with varying degrees of cognitive impairment since 2005 [23] . The ADNI battery includes serial neuroimaging, cerebrospinal fluid (CSF), and other biomarkers; and clinical and neuropsychological assessments. Participants returned for repeated assessments at six months, one year, and every year thereafter. Seven outcome measures were included in the model: CSF tau and amyloid beta (A\u03b2) 1-42; PET imaging of amyloid deposition and glucose metabolism in the brain; volumetric magnetic resonance imaging (vMRI) of the hippocampus; the 13 item Alzheimer's Disease Assessment Scale (ADAS13); and the Functional Activities Questionnaire (FAQ). Fixed effect covariates for each outcome included age, carriage of the APOE\u03b54 allele, sex, and education. The model was fit with and without assuming a multivariate Gaussian distribution for the random effects. Three parallel Markov chains were run for 8 000 iterations and the first 4 000 warm-up iterations were discarded. Every fourth value of the remaining part of each chain were stored to reduce level of correlation, yielding a total of 3 000 samples for posterior analysis. The posterior mean and the 95% credible intervals were calculated using the obtained samples for each parameter.\nOne goal of the analysis is to compare the long-term trends of the outcomes on a comparable scale, and make conclusions about the temporal ordering of their emergence. With this goal in mind, the outcome measures were transformed first to quantiles, and the quantiles were then transformed by the inverse Gaussian quantile function. All the transformed outcomes were then modeled as Gaussian with identity link. ADNI subjects were diagnosed at their first visit with normal cognition (24%), subjective memory concern (6%), early Figure 2 : Subject-level observed and predicted severity. The top panel shows spaghetti plots of the observed quantiles of each outcome from all subjects in the Alzheimer's Disease Neuroimaging Initiative with respect to their age over time. The bottom panels shows modeled trajectories for these same subjects from the fitted LTJMM with respect to the sum of age and estimated latent time, \u03b4. The colors indicate diagnostic severity at first observation, from cognitively normal (blue) through dementia (red). Abbreviations: ADAS13, Alzheimer's Disease Assessment Scale (13 Item version); FDG, fluorodeoxyglucose; PET, positron emission tomography; CSF, cerebrospinal fluid; FAQ, Functional Activities Questionnaire; CN, cognitively normal; SMC, subjective memory concern; EMCI, early mild cognitive impairment; LMCI, late mild cognitive impairment; AD, probable Alzheimer's Disease with mild to moderate dementia. mild cognitive impairment (17%), late mild cognitive impairment (32%), and mild to moderate dementia (19%). A weighted quantile transformation [24] was used so that quantiles approximate the quantiles from a sample with equal numbers of each diagnosis. We fit both models described in Section 2.1 to examine gains by incorporating correlated random effects. Table 2 presents model comparison results, and posterior estimates of the key model parameters for the best model. As shown in Table 2 (b), the model assuming multivariate Gaussian random effects was preferred, with lower DIC, WAIC and LOOIC. Figure 2 shows the subject-level observations (top) and predictions (bottom) according to age. It is clear from the the observations, that age explains only a small proportion of the variance in these outcomes. The bottom panel shows that the predictions provide a reasonable smooth of the observations, and that latent time provides a reasonable ordering of individuals according to disease severity. The posterior mean (95% credible interval) for the latent time parameter was 14.2 (12.7 to 16.1) years (Table 2 ). Figure 3 shows a density plot for the posterior mean of the subject-specific latent time by diagnosis at first ADNI visit. Diagnosis, which is a somewhat subjective interpretation of the clinical presentation (excluding CSF and imaging data) of the individuals by their physician, was not included as a covariate in the model. Figure 3 shows that the latent time estimates are temporally sorting individuals in a manner that is consistent with physician diagnosis. Latent time estimates provide a continuous alternative to diagnosis which is objectively derived from a comprehensive model of longitudinal measures of disease. Figure 4 shows the posterior mean of correlation parameters for random intercepts and slopes. Not surprisingly, we see strong correlations between change in cognitive tests Figure 3 : Distribution of the subject-specific latent time shifts. The estimated latent time shifts are colored by baseline diagnostic group, a variable not included in the model. This plot suggests that the time shifts are well aligned and consistent with diagnostic criteria. The density plot also demonstrates that there is much overlap of the diagnostic criteria with respect latent time. Abbreviations: CN, cognitively normal; SMC, subjective memory concern; EMCI, early mild cognitive impairment; LMCI, late mild cognitive impairment; AD, probable Alzheimer's Disease with mild to moderate dementia. (ADAS13) and the function (FAQ). However we also, see strong correlation between measures of symptomatic change (cognition and function) and biomarkers (hippocampal atrophy and glucose metabolism [FDG PET]). The two amyloid measures, CSF A\u03b2 and amyloid PET, show a moderate positive correlation for random intercepts and weakly negative correlation of change. Figure 5 displays the population-level predicted trajectories. The depicted curve are for female APOEe4 carriers with the ADNI mean education. Recall that age and latent time contribute to the model independently. For the sake of these predictions, age is calibrated so that the ADAS13 trajectory attains the ADNI mean ADAS13 at the ADNI mean age at the first visit. The bottom panel shows the same trajectories for progressive Alzheimer's (red triangles) with contrasting trajectories for healthy aging (blue dots). To obtain estimates for healthy aging, the effect of latent time is forced to be zero to isolate the effect of age."}, {"section_title": "Discussion", "text": "We explored sampling the random effects from both univariate and multivariate Gaussian distributions, and found the multivariate to always be preferred by model selection criteria. The model with multivariate random effects has the advantage of providing additional parameters for the correlation among outcomes (random intercepts) and among change in outcomes (random slopes). However, fitting the model with univariate random effects was often computationally faster, so it may have advantages in practice. We plan to explore extension of the model which include monotone smooth functions of latent time, and other random effects options.\nThe LTJMM provides a parsimonious extension of the existing family of joint generalized linear mixed effects models with a subject-specific latent time parameter that accommodates the temporal heterogeneity common to multicohort longitudinal data in late-life neurodegenerative diseases. The model provides key insights and inference regarding the evolution of disease markers over a period of time that is longer than the period of observation. The framework allows consideration of the independent effects of healthy aging and disease progression.\nThese novel features can be leveraged to improve subject-level prediction and better understand long-term disease dynamics. In particular we plan to leverage the model to help improve clinical trial design. For example, given an estimate of the short-term effect of a treatment on a biomarker, the model can be interrogated to estimate the downstream effects on cognition and function. The model can also be used to help identify populations expected to experience the maximum benefit from a given intervention. The LTJMM provides a flexible framework to begin to explore these and many other applications."}, {"section_title": "Supplementary material", "text": "The Stan code model specifications and related code and functions for simulation, estimation and prediction are available as an R package from https://bitbucket.com/mdonohue/ ltjmm. Interactive convergence plots of the model fit to Alzheimer's data is available from https://shiny.atrihub.org/public/adni_ltjmm/. "}]