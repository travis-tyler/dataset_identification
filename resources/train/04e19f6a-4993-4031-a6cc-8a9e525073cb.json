[{"section_title": "Abstract", "text": "Abstract. Most natural images can be approximated using their low-rank components. This fact has been successfully exploited in recent advancements of matrix completion algorithms for image recovery. However, a major limitation of low-rank matrix completion algorithms is that they cannot recover the case where a whole row or column is missing. The missing row or column will be simply filled as an arbitrary combination of other rows or columns with known values. This precludes the application of matrix completion to problems such as super-resolution (SR) where missing values in many rows and columns need to be recovered in the process of up-sampling a low-resolution image. Moreover, low-rank regularization considers information globally from the whole image and does not take proper consideration of local spatial consistency. Accordingly, we propose in this paper a solution to the SR problem via simultaneous (global) low-rank and (local) total variation (TV) regularization. We solve the respective cost function using the alternating direction method of multipliers (ADMM). Experiments on MR images of adults and pediatric subjects demonstrate that the proposed method enhances the details of the recovered highresolution images, and outperforms the nearest-neighbor interpolation, cubic interpolation, non-local means, and TV-based up-sampling."}, {"section_title": "Introduction", "text": "Matrix completion algorithms have been shown recently to be effective in estimating missing values in a matrix from a small sample of known entries [1] . For instance, it has been applied to the famous Netflix problem where one needs to infer user's preference for unrated movies based on only a small number of rated movies [2] . To address this ill-conditioned problem, matrix completion methods often assume that the recovered matrix is low-rank and then uses this as a constraint to minimize the difference between the given incomplete matrix and the estimated matrix. Candes et al. proved that, most low-rank matrices can be perfectly recovered from a small number of given entries [3] . Matrix completion is widely applied to image/video in-painting and decoding problems. However, matrix completion is limited when applied to matrices with a whole missing row or column (see white horizontal and vertical lines in Fig. 1 ). In this case, the missing row or column will be simply filled as an arbitrary combination of other known rows or columns to keep the total rank small. This precludes the application of matrix completion to problems such as super-resolution (SR) where missing values for many rows and columns need to be recovered in the process of up-sampling a lowresolution image by a factor of 2 times or larger [4] . Note that the goal of SR is to recover the fine anatomical details from one or more low-resolution images to construct a high-resolution image. In MR applications, single-image based SR is widely used since it requires only a single input image. For example, non-local means (NLM) is broadly employed [5] , sometimes with the help from other modalities [6] . In this work, we focus on recovering a high-resolution image from a single MR image."}, {"section_title": "Fig. 1.", "text": "Recovering missing values in a 2D image by using low-rank matrix completion [1] . The red arrows mark the horizontal and vertical lines that the algorithm fails to recover.\nAnother limitation of matrix completion algorithms is that they consider information globally from the whole image and does not exploit the local spatial consistency. Although local information may not be useful in applications such as the Netflix problem, where different rows (e.g., users) can be considered independently, it is valuable in image recovery. A solution to this problem is to integrate low-rank regularization with local regularization such as total variation [7] . By doing so, we can take advantage of both forms of regularization to harness remote information for effective image recovery and the local information to handle missing rows and columns.\nSpecifically, in this paper, we propose a novel low-rank total variation (LRTV) method for recovering a high-resolution image from a low-resolution image. Our method 1) explicitly models the effects of down-sampling and blurring on the lowresolution images, and 2) uses both low-rank and total variation regularizations to help solve the ill-conditioned inverse problem. Experiments on MR images of both adults and pediatric subjects demonstrate superior results of our method, compared to interpolation methods as well as NLM and TV-based up-sampling methods."}, {"section_title": "Method", "text": "For recovering the high-resolution image, our method 1) uses low-rank regularization to help retrieve useful information from remote regions; and 2) uses total variation regularization for keeping better local consistency."}, {"section_title": "Super-Resolution Problem", "text": "The physical model for the degradation effects involved in reducing a high-resolution (HR) image to a low-resolution (LR) image can be mathematically formulated as:\n( 1) where T denotes the observed LR image, D is a down-sampling operator, S is a blurring operator, X is the HR image that we want to recover, and n represents the observation noise. The HR image can be estimated using this physical model by minimizing the below least-square cost function:\nwhere the first term is a data fidelity term used for penalizing the difference between the degraded HR image X and the observed LR image T. The second term is a regularization term often defined based on prior knowledge. Weight \u03bb is introduced to balance the contributions of the fidelity term and regularization term."}, {"section_title": "Formulation of Low-Rank Total-Variation (LRTV) Method", "text": "The proposed LRTV method is formulated as follow:\nwhere the second term is for low-rank regularization, and the third term is for total variation regularization. and are the respective weights."}, {"section_title": "Low-Rank Regularization.", "text": "A N-dimensional image can be seen as a high order tensor, and its rank can be defined as the combination of trace norms of all matrices unfolded along each dimension [1] : \u2211 , where is the number of image dimensionality such as 3 for the 3D images. \u03b1 are parameters satisfying 0 and \u2211 1 . is the unfolded along the i-th dimension: . For example, a 3D image with size of can be unfolded into three 2D matrices, with size of , , and , respectively. is the trace norm, which can be computed by summing the singular values of . We employ the alternating direction method of multipliers (ADMM) [8] to solve this problem.\nTotal-Variation Regularization. The TV regularization term is defined as the integral of the absolute gradient of the image [9] : | | . TVregularization is formulated based on the observation that unreliable image signals usually have excessive and possibly spurious details, which lead to a high total variation. Thus, by minimizing the TV to remove such details, the estimated image will more likely match the original image. It has been proved quite effective in preserving edges. The TV-regularization problem can be solved by split Bregman method [10] ."}, {"section_title": "LRTV Optimization", "text": "We follow the alternating direction method of multipliers (ADMM) algorithm to solve the cost function in Eq. (3). ADMM is proven to be efficient for solving optimization problems with multiple non-smooth terms in the cost function [8] . We introduce redundant variables to obtain the following new cost function:\nHere, for each dimension i, we use to simulate by requiring that the unfolded along the i-th dimension should be equal to the unfolded along this dimension . The cost function in Eq. (4) can be further rewritten as an unconstrained optimization problem by replacing the constraints between and using a new term based on Augmented Lagrangian method of multiplier with multiplies [8] :\nAccording to ADMM [8] , we break Eq. (5) into three sub-problems below that need to be solved for iteratively updating the variables."}, {"section_title": "Subproblem 1: Update by minimizing:", "text": "arg min 2\nThis subproblem can be solved by gradient descent with step size ."}, {"section_title": "Subproblem 2:", "text": "Update by minimizing:\nwhich can be solved using a close-form solution according to [11] :\nwhere \u00b7 is the inverse operator of \u00b7 , i.e., . \u00b7 is the Singular Value Thresholding operator [11] using \u2044 as the shrinkage parameter."}, {"section_title": "Subproblem 3:", "text": "Update by:\nParameters are optimized based on a small set of datasets. In this work, we set 1/3, 0.01, 0.01, 0.1, and the maximum iteration as "}, {"section_title": "Experiments", "text": ""}, {"section_title": "Low-Rank Representation", "text": "We first evaluated whether brain images can be sufficiently characterized using lowrank representations. We selected a representative 2D slice from an adult T1 MR image in Brainweb (http://www.bic.mni.mcgill.ca/brainweb/), which has a size of 181\u00d7181 and in-plane resolution of 1 mm (Fig. 2) . We then performed singular value decomposition (SVD) on this image to obtain its 181 eigenvalues. As shown in Fig. 2 , the eigenvalues decrease dramatically, with most values being close to zero. We reconstructed the image after removing the small eigenvalues, and compared it with the original image. Peak signal-to-noise ratio (PSNR) is used to evaluate the quality of reconstruction: 20 10 \u2044 . The result shows that, by using the top 80 eigenvalues, the reconstructed image has high PSNR (39.5db), although some edge information in the brain boundary is lost. However, when using the top 120 eigenvalues (out of 181), the resulting image does not show visual differences with respect to the original image. For the 3D Brainweb image with size of 181\u00d7217\u00d7181, its rank can actually be computed by the average rank of its 3 unfolded 2D images, which is thus less than its longest image size 217. This rank is very low, compared to its voxel number of 7.1\u00d710 6 . Our analysis suggests that brain images can be represented using the low-rank approximations."}, {"section_title": "Experimental Setting", "text": "We applied our method to a set of down-sampled and blurred 3D brain images and evaluated whether our method can successfully recover the original high-resolution images (Fig. 3) . Blurring was implemented using a Gaussian kernel with a standard deviation of 1 voxel. The blurred image was then down-sampled by averaging every 8 voxels (to simulate the partial volume effect), resulting in half of the original resolution. The quality of reconstruction of all methods was evaluated by comparing with the ground-truth images using PSNR."}, {"section_title": "Fig. 3. Simulation of low-resolution image from high-resolution image", "text": "Our method was evaluated on two publicly available datasets. First, we randomly select 30 adult subjects from ADNI (http://www.loni.ucla.edu/ADNI), with 10 from Alzheimer's disease (AD), 10 from mild cognitive impairment (MCI), and 10 from normal controls. Their ages were 75\u00b18 years at MRI scan. T1 MR images were acquired with 166 sagittal slices at the resolution of 0.95\u00d70.95\u00d71.2 mm 3 . Second, we randomly select 20 pediatric subjects from NDAR (http://ndar.nih.gov/), with age of 11\u00b13 years at MRI scan. T1 MR images were also acquired with 124 sagittal slices at the resolution of 0.94\u00d70.94\u00d71.3 mm 3 ."}, {"section_title": "Results", "text": "Fig . 4 shows the representative image SR results of an adult scan (upper panel) and a pediatric scan (lower panel). For the first row of each panel, from left to right show the input image, the results of nearest-neighbor interpolation, cubic interpolation, NLM based up-sampling [5] , TV based up-sampling [10] , proposed LRTV method, and ground truth. Of note, here we used the implementation of NLM released by authors (https://sites.google.com/site/pierrickcoupe/). We implemented TV through the proposed method by setting 0, 0, and solving only the subproblem 1. he images of 30 adults and 20 pediatric subjects are sho method significantly outperforms all other comparison m adult subjects demonstrate less variance and higher ac subjects, which may be because the image quality is hig anel, obhods TV and osed own meccugher in the matured brain and clearer gyri/sulci patterns appear in the adult images. No significant difference was found between the adult subjects of AD, MCI, and controls."}, {"section_title": "Conclusion and Future Work", "text": "We have presented a novel super-resolution method for recovering a high-resolution image from a single low-resolution image. For the first time, we show that estimation with a combined low-rank and total-variation regularization is a viable solution to the SR problem. This combination brings together global and local information for effective recovery of the high-dimensional image. Experimental results indicate that our method outperforms the nearest interpolation, cubic interpolation, NLM-and TVbased up-sampling. It is worth noting that the interpolation methods (nearest, cubic) do not estimate the image generation process, which is the intrinsic limitation of that kind of methods. While for TV and NLM, they used the same model as the proposed method, so the comparisons are fair. Meanwhile, although our method is developed for single-image SR, it can be easily generalized to multiple-image SR. Our future work will be dedicated to extend the proposed method to longitudinal scans, i.e., images acquired from the same subject at different time points."}]