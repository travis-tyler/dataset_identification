[{"section_title": "Abstract", "text": "In the study of Alzheimer's disease, researchers often collect repeated measurements of clinical variables, event history, and functional data. If the health measurements deteriorate rapidly, patients may reach a level of cognitive impairment and are diagnosed as having dementia. An accurate prediction of the time to dementia based on the information collected is helpful for physicians to monitor patients' disease progression and to make early informed medical decisions. In this article, we first propose a functional joint model to account for functional predictors in both longitudinal and survival submodels in the joint modeling framework. We then develop a Bayesian approach for parameter estimation and a dynamic prediction framework for predicting the subjects' future outcome trajectories and risk of dementia, based on their scalar and functional measurements. The proposed Bayesian functional joint model provides a flexible framework to incorporate many features both in joint modeling of longitudinal and survival data and in functional data analysis. Our proposed model is evaluated by a simulation study and is applied to the motivating Alzheimer's Disease Neuroimaging Initiative study."}, {"section_title": "", "text": "Functional data consist of a sample of functions that provide information about curves, surfaces, or anything else varying over a continuum. These functions are usually defined on a one-dimensional time domain, such as growth curve data, heart rate monitor data, and electroencephalogram (EEG) data. A growing volume of functional data is also collected on higher dimensional domains such as magnetic resonance imaging (MRI), positron emission tomography (PET), and functional magnetic resonance imaging (fMRI). Functional data are closely related to multivariate data because functions are highly multivariate objects. 5 The main distinction between functional data and multivariate data are the natural ordering (in time or space) within a function. The high dimensionality and the complex structure in functional data pose challenges in both statistical theory and computation. 6, 7 Functional regression, especially functional predictor regression, is an active area of functional data analysis in the past decade. Although there is a rich literature in functional predictor regression to model the relationship between a scalar outcome and functional predictors, [8] [9] [10] [11] [12] [13] most of the work focuses on cross-sectional data. Goldsmith et al. 14 proposed a penalized functional regression model to handle longitudinal measurements in both the response variable and functional predictors by incorporating scalar random effects. Gertheiss et al. 15 improved the longitudinal model to allow for different effects of subject-specific curves. More recently, Gellar et al. 16 extended the Cox proportional hazards model to incorporate functional predictors and estimated the parameters via penalized partial likelihood approach. Lee et al. 17 developed a Bayesian functional Cox regression model with both functional and scalar covariates, but used different regularization approaches. However, these works focus on the statistical inference instead of prediction. To the best of our knowledge, there are no studies of dynamic prediction based on functional regression modeling that simultaneously analyze the longitudinal measurements and time-to-event data. By using functional data as predictors in the dynamic prediction framework using a joint model, the rich information in functional data may increase the model's power of predicting disease progression in clinical practice.\nIn this article, we propose a novel joint model that incorporates the growing volume of functional data in the longitudinal-survival setting. Specifically, we develop a functional joint model (FJM), where outcomes consist of a longitudinal measure and a time-to-event variable, and the exposure variables include both scalar predictors and functional predictors. The key idea of characterizing FJM is to treat each functional predictor as a single structured object rather than a collection of data points, 7 in contrast to the scalar predictor. Thus, the FJM needs to handle the complex structure within each function and the association between different data types. In addition, the coefficient for a functional predictor in the FJM is also a function, which increases the difficulty for estimation and inference. We estimate the coefficient functions for the functional predictors using penalized spline approach. We develop a Bayesian approach for statistical inference of our FJM and a dynamic prediction framework for the predictions of target patients' future outcome trajectories and risks of event. These important predictive measures can provide valuable information to discover and validate prognostic biomarkers, which may advance the design of future clinical trials.\nThe rest of the article is organized as follows. In Section 2, we describe the motivating Alzheimer's Disease Neuroimaging Initiative (ADNI) study and the data structure. In Section 3, we discuss the joint longitudinalsurvival model with functional predictors, Bayesian inference procedure, and dynamic prediction framework. In Section 4, we apply the proposed method to the ADNI study. In Section 5, we conduct a simulation study to examine the performance of the proposed Bayesian FJM. Concluding remarks and discussion are presented in Section 6."}, {"section_title": "A motivating clinical study", "text": "The methodology development is motivated by the ADNI study. The primary goal of the study is to test whether serial MRI, positron emission tomography (PET), cerebrospinal fluid (CSF) markers, and neuropsychological assessments can be combined to measure the progression of Alzheimer's disease (AD). The phase 1 of the ADNI study (ADNI-1) recruited more than 800 adults, of which about 200 cognitively normal individuals, 400 mild cognitive impairment (MCI) patients, and 200 early AD patients. Participants were reassessed at 6, 12, 18, 24, and 36 months, and additional follow-ups were conducted annually as part of ADNI-2. At each visit, various neuropsychological assessments, brain image, and clinical measures were collected. Detailed information about the ADNI study procedures, including participant inclusion and exclusion criteria and complete study protocol can be found at http://www.adni-info.org.\nBecause MCI is commonly considered as a transitional stage between normal cognition and Alzheimer's disease, numerous recent studies assess various clinical markers and neuroimaging techniques to predict AD diagnosis among MCI patients. 18 To this end, our analysis focuses on 355 MCI patients in the ADNI-1 study without missing data in covariates of interests, and we consider AD diagnosis among MCI patients to be the survival event of interest. In the ADNI-1 study, the 355 MCI patients were followed up for a mean of 3.2 years (SD 2.6; range 0.4-9.3) before AD diagnosis or censoring. Among them, 180 patients were diagnosed with AD (survival event) and 175 had stable MCI over a mean follow-up period of 2.3 years and 4.2 years, respectively.\nMoreover, the longitudinal Alzheimer Disease Assessment Scale-Cognitive (ADAS-Cog) score was reported to be the strongest predictor of time from MCI-to-AD. 19 It is an important clinical measure for cognitive functions and it manifests disease status. It is usually reported as a composite score of the 11 items (ADAS-Cog 11), with a total score of 70 and higher score indicating poor cognitive function. Figure 1 displays the lowess smoothing curve 20 of ADAS-Cog 11 scores over time for the MCI patients, with follow-up time less than 3 years (203 patients), 3-6 years (82 patients), and more than 3 years (70 patients), in addition to 95% pointwise confidence intervals. Figure 1 suggests that the ADAS-Cog 11 scores of patients in all three groups increase with time, which indicates the deteriorating of cognitive functions. The patients with shorter follow-up time tend to have higher ADAS-Cog 11 scores, indicating that patients with more severe cognitive impairment were more likely to progress to AD or censoring. This phenomenon manifests strong correlation between the longitudinal ADAS-Cog 11 values and the time to AD diagnosis, and is often referred to as ''dependent censoring'' or ''informative censoring'' in the literature of joint modeling. 21 However, many studies 22, 23 designed to explore the association between longitudinal measures and disease progression of MCI patients analyzed the two processes separately. Their approaches failed to account for such informative censoring and resulted into biased inference.\nFurthermore, the degree of atrophy within the medial temporal lobe structures, especially within the hippocampus, was reported to be associated with the AD progression. 24 Most of the current analysis was based on volumes of brain regions. [24] [25] [26] For example, AD patients and MCI patients have been shown to have 27% and 11% smaller hippocampal volumes, respectively, as compared with normal age-matched elderly. 24 However, some research 27, 28 demonstrated that the surface-based morphology analysis offers more advantages because this method studies patterns of subregion atrophy and produce detailed pointwise correlation between atrophy and cognitive functions. In these surface-based analyses, the hippocampus is modeled as a surface model which is a mesh of triangles. Each triangle is known as a face and the place where the corners of the triangles meet is called a vertex. The coordinate of each vertex is determined during image processing and allows one to compute many morphometric measures based on it. In this article, we propose a Bayesian personalized prediction model based on the FJM of longitudinal ADAS-Cog 11 score and the time to AD diagnosis, accounting for the clinical covariates and MRI measures. We include as a functional predictor the hippocampal radial distance (HRD) of vertices on bilateral hippocampal surfaces. The HRD measures the distance from the medial core to each surface vertex and represents the hippocampal thickness. The HRD is calculated based on the surface model and the image processing procedure is detailed in the Web Supplement."}, {"section_title": "Methods", "text": ""}, {"section_title": "FJM framework", "text": "For each subject i \u00f0i \u00bc 1, . . . , I \u00de at visit j \u00f0 j \u00bc 1, . . . , J i \u00de, we observe data f y ij , x ij , g \u00f0x\u00de i \u00f0s\u00deg, where y ij \u00bc y i \u00f0t ij \u00de is a scalar outcome recorded at time t ij from the study onset. Vector x ij is a p-dimensional covariate vector. Function g \u00f0x\u00de i \u00f0s\u00de is a time-invariant functional predictor defined over a 1D domain s 2 \u00bd0, S max \u00bc S. The domain of the functional predictor S is not the same as the time domain t over which the survival event is followed. For the ease of illustration, we only incorporate a single time-invariant functional predictor, such as the baseline MRI measure, in both the longitudinal and survival submodels, while the FJM can readily accommodate multiple functional predictors. We use superscript (x) and (w) to denote the functional predictors in the longitudinal and survival submodels, respectively. The longitudinal submodel is\nwhere m i \u00f0t ij \u00de is the unobserved true value of the longitudinal outcome at time t ij , 0 is the intercept, and b is the regression coefficient vector. Coefficient function B \u00f0x\u00de \u00f0s\u00de (defined on the same domain as g \u00f0x\u00de i \u00f0s\u00de) determines a pointwise association between g \u00f0x\u00de i \u00f0s\u00de and y i \u00f0t ij \u00de. Vector z ij is a q-dimensional covariates corresponding to random effects u i , which is assumed to have u i $ N\u00f00, AE u \u00de to account for the within-subject correlation. The measurement error \" ij $ N\u00f00, 2 \" \u00de is independent from u i . To allow flexibility and smoothness in modeling the effects of some covariates, smooth functions using splines can also be included in model (1) .\nThe event history is recorded for each subject i with observed event time T i \u00bc min\u00f0T To build the functional regression model, we adopt a penalized approach to incorporate functional components into functional predictor regression model. 14, 16 We first express the time-invariant functional predictor g , is a fixed term in the model. The number of components K x can be determined using the proportion of explained variance (PEV). Specifically, K x may be chosen as the minimum number of FPCs such that\nwhere L is a pre-specified PEV, e.g. L \u00bc 80%, 90%, or 95%. However, the selected number K x can explain the majority of the variability in the functional predictor, but it may not adequately represent the coefficient function. Thus, in this article, we refer to Ruppert 29 and choose K x and K B sufficient large (e.g. 20) to capture the complexity in both functional predictors and coefficient functions, with the identifiability constrain\nSimilarly, the functional predictor g \u00f0w\u00de \u00f0s\u00de in model (2) \nand h i \u00f0t\u00de \u00bc h can be treated as scalar covariates. Similar to mixed models, our FJM can readily handle unbalanced data in the longitudinal measurement of y i \u00f0t\u00de. \nand the density function of the random effects u i is p\u00f0u i jh\u00de \u00bc \u00f02\u00de\nwhere q is the dimension of the covariance matrix AE u . The conditional likelihood from the survival data are Under the local independence assumption (i.e. conditional on the random effect vector u i , all components in y i and T i are independent), the joint likelihood function is\nTo prevent overfitting, we adopt penalization technique to estimate spline coefficients B \u00f0x\u00de and B \u00f0w\u00de and to introduce smoothness in the resulting coefficient function. The penalized log-likelihood is formed by subtracting the penalty terms from the log-likelihood, can be defined. For model fitting, we propose a Bayesian approach based on Markov Chain Monte Carlo (MCMC) posterior simulations, which provides a flexible way for statistical inference. In Bayesian framework, unknown parameters are considered as random variables with appropriate prior distributions. We use vague prior distributions on all elements in parameter vector h. Specifically, the prior distributions of parameters b, c, a are N(0, 100), and InverseGamma (0.01, 0.01) for all variance parameters. We impose smoothness on coefficient function estimates through the prior specification on B \u00f0x\u00de and B \u00f0w\u00de . We replace the penalty terms in the penalized likelihood (6) by their stochastic analogues, and assume a random walk prior distribution on the B The model fitting is performed in Stan by specifying the full likelihood function and the prior distributions of all unknown parameters. Stan adopts a No-U-Turn sampler, 33 which offers faster convergence and parameter space exploration compared with other MCMC algorithms such as Gibbs sampler. We use the history plots and view the absence of apparent trend in the plot as evidence of convergence. In addition, we use the Gelman-Rubin diagnostic to ensure the scale reductionR of all parameters are smaller than 1.1. "}, {"section_title": "Dynamic prediction framework", "text": "We next illustrate the dynamic prediction framework based on the proposed Bayesian FJM. Given a new subject N's outcome histories y \nwhere p\u00f0y Similarly, based on model (4), the conditional probability of event-free at time t 0 is\nSuppose that subject N has not experienced the event of interest by time t 0 , then the outcome histories are updated to y It is essential to assess the performance of the proposed predictive measures. Information criteria, such as deviance information criterion (DIC), can be useful to assess the overall predictive ability of the model. Here we mainly focus on the survival outcome, probability of event-free N \u00f0t 0 jt\u00de, and on how well the model discriminates between patients who had the event from patients who did not. Such discrimination performance is measured by the time-dependent receiver operating characteristic (ROC) curve and the area under the ROC curve (AUC; higher value indicates better discrimination performance). Specifically, for any given cut point c 2 \u00f00, 1\u00de, the timedependent sensitivity and specificity are defined as sensitivity: In the absence of censoring, sensitivity and specificity can be simply estimated from the empirical distribution of the predicted risk. To accommodate censoring time, Li et al. 36 proposed a kernel weighting method to estimate the time-dependent ROC curve nonparametrically and a closed-form formula to calculate ROC. Consistent estimation of the time-dependent sensitivity and specificity can be achieved by weighting the patients by their conditional probabilities of disease onset prior to the time horizon, given the data. This method produces unbiased and efficient estimators and is less sensitive to the selection of kernel bandwidth as compared with Heagerty et al. 37 Moreover, we also assess our model's performance in calibration, i.e. the agreement between the predicted and true risks. We use the dynamic expected Brier score (BS) for joint models, which is an extension from the BS developed in the survival model. 38 is to account for censoring with\u015c 0 denoting the Kaplan-Meier estimate. 39 In general, BS \u00bc 0 indicates perfect prediction and BS \u00bc 0:25 means no better than a random guess."}, {"section_title": "Implementation using software", "text": "An advantage of the proposed Bayesian FJM is that its implementation and extension can be done via available softwares and the sample Stan code. The first step is to conduct functional principal component analysis (FPCA) for functional predictors and estimate the FPC eigenfunctions and scores, by using either fpca.sc function in the refund packages 40 in R or fpca.mle and fpca.score functions in the FPCA package 41 in R. In the second step, the cubic B-spline basis functions can be evaluated over the discretized domain S using the bs function in the package spline in R. In the third step, the FPC scores obtained from FPCA are used as scalar covariates in the joint model and the parameters can be estimated using the sample Stan code. For prediction, the samples of the random effect vector u N can be drawn from its posterior distribution using the arms function in the HI package in R. The future survival probability can then be calculated based on the samples. Finally, assessment of the predictive performance based on time-dependent ROC can be achieved using the tdROC package in R."}, {"section_title": "Application to the ADNI study", "text": "We apply the proposed Bayesian FJM to the motivating ADNI-1 study. We include the following variables as scalar covariates: baseline age (bAge, mean: 74.4, SD: 7.3, range 55.1-89.3), gender (gender, 36.1% female), years of education (Edu, mean: 15.6, SD: 3.0, range [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] , and presence of at least one apolipoprotein E allele (APOE \u00c0 \"4, 56%), given their potential effects on AD progression. 25, 26, 42 To utilize the brain imaging information, we include baseline hippocampal volume (bHV) as a scalar covariate and the baseline hippocampal surface based on HRD as a functional predictor. We follow the procedure in Section 2 to convert the 3D HRD to a 1D domain denoted by S. In an exploratory analysis of the ADNI data, we plot the lowess curve of the longitudinal outcome ADAS-Cog 11 against each scalar covariate and there is no strong nonlinearity in these curves. Hence, we include linear terms of these covariates, and avoid using splines to have easy interpretation and less computational burden.\nThe first model we consider is the regular joint model (refer to as model JM), which incorporates variable bHV in both longitudinal and survival submodels. Additionally, we consider three FJMs, i.e. model FJM1 that includes HRD only in the longitudinal submodel, model FJM2 that includes HRD only in the survival submodel, and model FJM3 that includes HRD in both submodels as We compare the four candidate models by assessing their predictive performance, manifested by the timedependent AUCs, at different time points over the follow-up period. To avoid overestimation of the prediction, we conduct a 10-fold cross validation. Specifically, the total sample of patients is randomly splitted into 10 subgroups of about equal size. The analysis is repeated 10 times with one subset being set aside as the validation dataset and the remaining nine subsets being used as the training dataset. Parameters of the joint model are estimated from the training dataset and applied to the validation dataset. The conditional event-free probability corresponding to the time frame \u00f0t, t \u00fe \u00c1t is predicted for each patient in the validation datasets as described in Section 3.3. Because the ADNI patients were reassessed approximately every half year, we select t at 1, 1.5, and 2 years, and \u00c1t as 0.5 and 1 years for analysis. Then the time-dependent AUCs and BSs are calculated based on the predicted probabilities of all patients. Table 1 displays the time-dependent AUCs and dynamic expected BSs from the four candidate models. Model FJM2 and FJM3 have notably larger AUCs and smaller BSs than models JM and FJM1 for most of combinations of t and \u00c1t. This suggests that including functional predictor HRD in the survival submodel, in addition to scalar predictor hippocampal volume, improves the capability of the joint model in predicting risk of AD diagnosis. We also notice that FJM3 has a smaller DIC than FJM2 (12063 compares to 12097), which indicates that HRD is an important functional predictor for the cognitive functions manifested by variable ADAS-Cog 11 among the MIC patients. These results suggest that including HRD in the longitudinal submodel may further improve the overall predictive ability of the FJM model. Hence, we select FJM3 as the final model because it has a competitive good discrimination capability and a smaller DIC value.\nParameter estimates from model FJM3 using whole dataset are presented in Table 2 as in models (3) and (4)) are presented in Web  Tables 1 and 2 . In the longitudinal submodel, the ADAS-Cog 11 score increases (deteriorates) as time progresses, i.e. an average increase of 0.428 unit (95% CI: [0.338-0.521]) per year for MCI patients. Larger hippocampal volume at baseline (bHV) is associated with lower (better) ADAS-Cog 11 scores. In the survival submodel, the presence of APOE-\"4 allele(s) increases the hazard of AD diagnosis by 70% (exp\u00f00:533\u00de \u00c0 1, 95% CI: [26%-107%]), which is consistent with the literature. 43 Older age at baseline is associated with lower risk of AD diagnosis. The hippocampal volume (bHV) is no longer significant after including the functional predictor HRD in the survival submodel. Furthermore, larger ADAS-Cog 11 score increases the risk of AD diagnosis, i.e. one unit increase in ADAS-Cog 11 score increases the hazard of AD diagnosis by 14. that the thinner of the area, the higher of the risk of progressing from MCI to AD. Most blue regions in Panels (b) and (c) are located in the CA1 subfield and subiculum (Sub) subfield displayed in Panel (a), suggesting that regional radial atrophy in these subfields may be a good predictor of AD progression among MCI patients.\nTo illustrate the personalized dynamic predictions, we select two target patients as validation data, and predict their future health outcome and event-free probability based on FJM3 estimates using the remaining data as training set. Patient A has a baseline age of 73, no APOE-\", as compared with a more severe Patient B, 69 years old at baseline, and with APOE-\". Figure 3 demonstrates how the predicted ADAS-Cog 11 scores are updated over time for the two patients. From left to right on Figure 3 , by using more follow-up data, predictions are closer to the true observed values and the 95% uncertainty band is narrower. It also suggests that Patient A (upper panels) has lower and more stable predicted ADAS-Cog 11 scores (better cognitive function) than patient B (lower panels). Figure 4 displays the predicted probability of being free of AD diagnosis. For Patient A, the event-free probability curve does not show large change because Patient A's predicted ADAS-Cog 11 scores are relatively low. In comparison, Patient B has higher predicted ADAS-Cog 11 scores and worse cognitive function, and thus has considerably drop in the event-free probability. This suggests that Patient B has a higher risk of AD diagnosis and should be monitored frequently."}, {"section_title": "Simulation study", "text": "In this section, we conduct a simulation study to evaluate the proposed Bayesian FJM models, and investigate the predictive and calibration performance of the survival probability using the FJM models. We generate 200 datasets with sample size I \u00bc 700 subjects and each subject has J i \u00bc 5 measurements at time 0, 3, 6, 9, and 12. The simulated data structure is similar to the motivating ADNI study, and we include one functional predictor in both longitudinal and survival submodels. The longitudinal submodel is Table 3 presents the AMSE, in addition to bias (the average of the posterior means minus the true values), standard error (SE, the square root of the average of the variance), standard deviation (SD, the standard deviation of the posterior mean), and coverage probabilities (CP) of 95% credible intervals. Table 3 suggests that the proposed Bayesian FJM performs reasonable well with relatively small AMSE values for both coefficient functions and other parameters, SE being close to SD, and the credible interval coverage probabilities being reasonably close to 95%. Figure 5 displays the true coefficient functions B \u00f0x\u00de \u00f0s\u00de and B \u00f0w\u00de \u00f0s\u00de (red solid lines) and their estimated curves (black solid lines), along with the 95% pointwise credible interval (dashed lines). Both panels suggest that the estimated coefficient functions are reasonably close to the true coefficient functions, with 95% pointwise credible interval always covering the true functions.\nFor each testing dataset, we predict subject-specific conditional survival probability k \u00f0t 0 jt\u00de for each subject at different time points t and t 0 \u00bc t \u00fe \u00c1t using the MCMC samples from the fitted model and available measurements up to time t. The predicted time-dependent AUCs are calculated based on the predicted probabilities of all subjects. The true conditional survival probability N \u00f0t 0 jt\u00de and AUCs are computed using the prespecified parameter values and the generated random effects. We use the dynamic expected BS c BS\u00f0t 0 jt\u00de to assess the bias between the predicted and true risks. "}, {"section_title": "Discussion", "text": "The methodology introduced in this article is motivated by many current studies where functional data are collected. The ADNI is just one example of such studies. However, both theoretical and computational complexity in modeling functional data restrict researchers to focused on scalar measures, e.g. volumes of a few brain regions. Without careful analysis of the functional data, pace to understand diseases and population's health condition can be dramatically slowed down. Moreover, some high dimensional data, such as genetic variant profiles defined along chromosomes or genomic regions, are commonly treated as functional data. To this end, functional data analysis methods are becoming increasingly important.\nIn this article, we first propose a Bayesian FJM to account for functional predictors in both longitudinal and survival submodels within the framework of joint modeling. We use the FPCA to approximate the functional predictor, and expand its corresponding coefficient function using penalized B-spline approach. We then develop the process of making personalized dynamic prediction of future outcome trajectories and risks of event using both scalar and functional predictors. Simulation indicates that the proposed Bayesian FJM yields accurate inference and prediction. Being applied to the motivating ADNI study, the FJM can efficiently estimate the association between the trajectory of cognitive functions measured by the ADAS-Cog 11 score and time to AD diagnosis, while accounting for the functional predictor (HRD) and other scalar covariates. We have identified the regional radial atrophy in the CA1 subfield and the subiculum subfield as a good predictor of AD progression among patients with MCI. More importantly, the proposed Bayesian FJM can utilize the functional predictors to make correct predictions for new subjects. The inclusion of functional predictor HRD into both the longitudinal and survival submodels improves overall model fitting and predictive performance. When new measurements are available, the predictions can be updated with improved accuracy and efficiency. Thus, earlier diagnosis can be made to subjects with high predicted risk of deterioration, and intervention can be planned in a timely manner to delaying the manifestation of AD in prodromal AD patients. In addition, although we only use HRD in ADNI data analysis, the proposed Bayesian FJM can readily include multiple brain regions, and even genotype profiles, as functional predictors to provide even precise prediction of Alzheimer's disease progression.\nThere are some limitations we will address in the future. First, we exclude from analysis the subjects (45 out of 400) with missing data in baseline covariates of interest. Most of these subjects either do not have baseline image data measured or do not have image data in the archive due to the technical difficulty in image data collection and storage. Although the well-established imputation methods, e.g. multiple imputation, can be used for missing data in scalar predictors, it is challenging in both statistical theory and computation to handle missing functional data. We will extend our Bayesian FJM to account for missing data in both scalar and functional covariates in the future. Second, we use time-invariant functional data as predictor in this article. It would be of scientific interest to extend the proposed Bayesian FJM to accommodate longitudinal functional data. We can decompose the longitudinal functional predictor using longitudinal functional principal component analysis (LFPCA) 45 to account for its longitudinal data structure. Alternatively, we can treat the longitudinal functional data as a functional response variable in the longitudinal submodel (function-on-scalar regression problem) and it can be incorporated in the survival submodel as a time-dependent functional predictor. This model can investigate how the longitudinal functional variable directly impacts the risk for an event.\nMoreover, in model (2), we implicitly assume that the risk for an event at time t depends on the unobserved true value of the longitudinal outcome at the same time point. We can investigate different functional forms for the association structure between the longitudinal outcome and the risk for an event. 46, 47 For example, both the unobserved true value of m i \u00f0t ij \u00de in model (1) and its time-dependent slope m 0 i \u00f0t ij \u00de or even its cumulative effect R t 0 m i \u00f0s\u00deds can be included in model (2) . The proposed Bayesian FJM can readily accommodate various functional forms with minor modification to the sample codes. Furthermore, the Bayesian procedure we develop is shown to have good inferential properties in simulation studies. As sample size and the number of parameters associated with B-spline grow, computation time may increase dramatically. To this end, paralleling MCMC 48 and variational approximations 49 may address the computational concerns and result in good estimations of model components. We would like to investigate these issues in our future research. "}]