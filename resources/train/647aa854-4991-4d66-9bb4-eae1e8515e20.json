[{"section_title": "Abstract", "text": "Many disease processes can be divided into three stages: i.e. the non-diseased stage, the early diseased stage and the fully diseased stage. To assess the accuracy of diagnostic tests for such diseases, various summary indexes have been proposed, such as volume under the surface (VUS), partial volume under the surface (PVUS), and the sensitivity to the early diseased stage given specificity and the sensitivity to the fully diseased stage (P 2 ). This paper focuses on confidence interval estimation for P 2 based on empirical likelihood. Simulation studies are carried out to assess the performance of the new methods compared to the existing parametric and nonparametric ones. A real data set from Alzheimer's Disease Neuroimaging Initiative (ANDI) 2 is analyzed. Key Words: Empirical Likelihood; Diagnostic tests; The sensitivity to the early diseased stage.\nEmpirical Likelihood; Diagnostic tests; The sensitivity to the early diseased stage"}, {"section_title": "INTRODUCTION", "text": "Disease process is usually divided into two stages: the non-diseased and the diseased, and diagnostic tests are utilized to classify the subjects into different stages. The probability that a non-diseased subject is correctly classified is defined as the specificity, and the probability that a diseased subject is correctly identified is called sensitivity. When the outcome of diagnostic test is continuous, both sensitivity and specificity are functions of the cut-off value. As the cut-off value changes, sensitivity and specificity vary inversely to each other. The Receiver Operating Characteristic (ROC) curve, a plot of sensitivity versus (1-specificity) as the cut-off value runs through the whole range of all possible outcome values, is a popular graphical assessment of the diagnostic accuracy for a diagnostic test. For detailed review of statistical methods in ROC analysis, please see Shapiro (1999) , Zhou et al. (2002) , Pepe (2003) and Zou et al. (2010) .\n2 Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.ucla.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.ucla.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf To assess the diagnostic accuracy of a binary-scale test, there exist many diagnostic accuracy measures such as the area under the curve (AUC). The AUC indicates the overall performance of a diagnostic test for all the cut-off values. However, in medical practice, a cut-off value is often chosen by medical practitioners so that a fixed value of specificity is achieved (typically 80, 90, or 95 per cent) . Hence, the sensitivity given the specificity serves as a meaningful diagnostic measure. Towards this end, several papers discussed the issues of estimation of sensitivity given specificity. For example, Greenhouse and Mantel (1950) presented the inference procedures for a diagnostic test with continuous range, either with or without normal distribution assumptions; McNeil and Hanley (1984) estimated the pointwise confidence interval for sensitivity at a fixed specificity in the bi-normal model; Linnet (1987) took into account the sampling variation of the discrimination limits and proposed both parametric and non-parametric methods to construct the confidence interval; Platt et al. (2000) recommended a confidence interval by using Efron's bias-corrected acceleration (BCa) bootstrap; and Zhou and Qin (2005) introduced two non-parametric confidence intervals. Most recently, Qin et al. (2011) presented empirical likelihood-based confidence intervals for the sensitivity at a fixed level of specificity.\nIn practice, a disease process might involve three ordinal diagnostic stages: the normal healthy stage without even the earliest subtle disease symptoms, the early stage of the disease, and the stage of full-blown development of the disease. For example, mild cognitive impairment (MCI) and/or early stage Alzheimer's disease (AD) is a transitional stage between the cognitive changes of normal aging and the more serious AD. Recently, the traditional ROC analysis has already been extended to three-stage cases, see e.g., Mossman (1999) , Dreiseitl et al. (2000) , Heckerling (2001) , Nakas and Yiannoutsos (2004) , Xiong et al. (2006) , He and Frey (2008) , Zhou (2009), Nakas et al. (2010) , Tian et al. (2010) , He et al. (2010) , Dong et al. (2011) and Li et al. (2012) . For diseases such as AD, early detection is critical since it often means optimal time window for therapeutic treatment due to the fact that no pharmaceutical treatments to-date are effective for the late stage AD. However, it is far more challenging to diagnose subjects at the earliest disease stage for clinicians because of the subtle clinical symptoms in the early stage of many complex disease processes. Hence, the probability associated with the detection of early diseased stage is critical in medical science and serves as a very important diagnostic accuracy measure for diseases with three ordinal stages.\n(1)\nGiven P 1 and P 3 , c 1 and c 2 can be determined. Consequently, P 2 , the sensitivity to the early diseased stage given the specificity P 1 and the sensitivity to the fully diseased stage P 3 , can be formulated as a function of P 1 and P 3 , i.e. P 2 = P 2 (P 1 , P 3 ) which also defines a surface in the three-dimensional space (P 1 , P 3 , P 2 ), namely, the ROC surface. The point (P 1 , P 3 , P 2 ) = (1, 1, 1) indicates the perfect discrimination ability.\nTo evaluate the diagnostic accuracy of the biomarkers for three-class diseases, various summary measures of the ROC surface have been proposed. Among them, the volume under the ROC surface (VUS), considered as the extension of AUC in the three-class disease paradigm, is a very popular one. The VUS denotes the probability that a randomly chosen subject from the non-diseased group, that from early diseased group and that from fully diseased group follow simple order, i.e., VUS = P(Y 1 < Y 2 < Y 3 ). More details about VUS can be found in Nakas and Yiannoutsos (2004) , Xiong et al. (2006) , He and Frey (2008) , Wan (2012) and Kang and Tian (2013) .\nIn addition to the overall performance of a biomarker measured by VUS, an accurate estimate of P 2 helps clinicians to identify the best disease markers for early diagnosis and therefore the inference procedures for P 2 are very useful. Dong et al. (2011) first attempted to provide parametric and non-parametric confidence interval estimation methods for P 2 .\nHowever, the most recommended methods depend on either normality assumption or BoxCox transformation to normality. It is well known that not all of the non-normal distributions can be transformed to normal via Box-Cox transformation. Therefore, some alternative approaches for estimating the confidence interval of P 2 which do not depend on distributional assumption and also provide good coverage probabilities are worth exploring.\nThe goal of this paper is to present empirical likelihood-based confidence intervals for P 2 , i.e. the sensitivity to the early diseased stage given specificity and the sensitivity to the fully diseased stage. Empirical likelihood is introduced by Owen (1990 Owen ( , 2001 ) and has many advantages over normal approximation-based methods. For instance, empirical likelihoodbased confidence regions are range preserving and transformation respecting, the regularity conditions for empirical likelihood-based methods are weak and natural, and it utilizes the power of likelihood-based approaches to solve complex statistical problems. The empirical likelihood has been used widely in many applied areas including diagnostic tests with binary outcomes, e.g., Claeskens et al. (2003) suggested a smoothed empirical likelihood-based method (SEL) to estimate the sensitivity, and Qin et al. (2011) proposed two empirical likelihood-based confidence intervals for the sensitivity at a fixed level of specificity. The rest of this paper is organized as follows. Section 2 presents a review of existing methods. In Section 3, the large sample properties of P 2 and the empirical likelihood approaches are proposed. In Section 4, simulation studies are conducted to evaluate the proposed methods. In Section 5, a real data set from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database is analyzed. Section 6 is the discussion. The proofs for the formula of the variance for an estimator of P 2 and the empirical likelihood theorem are given in the Appendix."}, {"section_title": "EXISTING METHODS", "text": "This section presents a brief review of the existing methods including the generalized inference method and bootstrap approaches for confidence interval estimation of sensitivity to the early diseased stage by Dong et al. (2011) ."}, {"section_title": "Generalized Inference Method", "text": "Assume Y i follows normal distributions with mean \u03bc i and variance for i = 1, 2, 3, the generalized pivotal quantity for P 2 as given in (1) can be written as where , Z i ~ N(0, 1) and where for i = 1, 2, 3. By generating V i and Z i repeatedly, an array of R P 2 's can be obtained. A two-sided 100(1 \u2212 \u03b1)% generalized inference confidence interval for P 2 , GI, is (R P 2 (\u03b1/2), R P 2 (1 \u2212 \u03b1/2)) where R P 2 (\u03b1) denotes the 100\u03b1th percentile of R P 2 .\nWhen the normality assumptions are violated, the Box-Cox transformation is utilized as P 2 is invariant under monotonic transformations. Assume the data after transformation does follow the normality assumptions, then the GI method can be applied. Such confidence interval is noted as BCGI hereafter."}, {"section_title": "Non-parametric Approaches", "text": "The P 2 as given in (1) can be non-parametrically estimated as (2) With a bootstrap sample (b = 1 to 500), the 100(1 \u2212 \u03b1)% bootstrap percentile confidence interval (BTP) can be obtained as where is the 100\u03b1% percentile. An adjusted estimator of P 2 proposed by Agresti and Coull (1998) is Dong and Tian Page 4 ( 3) where z 1\u2212\u03b1/2 stands for 100(1 \u2212 \u03b1/2)% percentile for standard normal distribution. The 100(1 \u2212 \u03b1)% BTI confidence interval is where is the bootstrap estimate for the variance of (more details can be found in Dong et al. (2011) ). Replacing with the mean obtained from the bootstrap sample, the 100(1 \u2212 \u03b1)% BTII confidence interval is given as\nIn Dong et al. (2011) , through a simulation study, GI and BCGI were shown to provide accurate confidence intervals, given the corresponding normality assumptions were satisfied. Otherwise, BTII was recommended except in the scenarios with large P 2 and small sample sizes where BTP was preferred."}, {"section_title": "TWO NEW APPROACHES", "text": "In this section, two new methods for confidence interval estimation of P 2 are presented. Section 3.1 presents a method based on asymptotic normality and Section 3.2 presents two confidence intervals based on empirical likelihood.\nwhere f 1 , f 2 and f 3 are the probability density functions for Y 1 , Y 2 and Y 3 respectively. It can be shown that when n 1 , n 2 and n 3 are large,\nhas an approximately normal distribution with mean P 2 and variance . The can be estimated as (5) where (P 1 ) is the P 1 th sample quantile of Y 1 s, (1 \u2212 P 3 ) is the (1 \u2212 P 3 )th sample quantile of Y 3 s, and f\u00ee is the kernel density estimate of f i , i = 1, 2, 3. We use the \"oversmoothed bandwidth selector\" by Wand and Jones (1995) to select the bandwidth for the Gaussian kernel function. The (1 \u2212 \u03b1)100% normal approximation-based confidence interval is referred as asymptotic parametric variance confidence interval (APV) hereafter."}, {"section_title": "Empirical Likelihood Confidence Interval", "text": "Define an indicator function \u03d5 as Given P 1 and P 3 , for a test result Y of a subject from the early diseased group, define a random variable It is evident that Based on this relationship between P 2 and U, we can develop an empirical likelihood procedure for making inference about P 2 . Let p = (p 1 ,\u2026,p n 2 ) be a probability vector for the early diseased group, and and p i \u2265 0 for all i. The empirical likelihood for P 2 can be defined as Dong and Tian Page 6 where , i = 1,2,\u2026,n 2 . Since U i 's depend on the unknown distribution functions F 1 and F 3 , we replace them by their empirical distributions F1 and F3, and obtain a profile empirical likelihood for P 2 where , i = 1, 2,\u2026, n 2 . By the Lagrange multiplier method, we can easily obtain the following expression for p i where \u03bb\u0303 is the solution of (6) Note that , subject to , attains its maximum at . The profile empirical likelihood ratio for P 2 is defined as Hence the corresponding profile empirical log-likelihood ratio is (7) where \u03bb\u0303 is the solution of (6).\nSince the profile empirical log-likelihood ratio l(P 2 ) is a sum of dependent variables, its asymptotic distribution is no longer a standard chi-square distribution. In the Appendix 2, it is proven that l(P 2 ) follows a scaled \u03c7 2 distribution. The asymptotic distribution of l(P 2 ) is summarized in the following theorem. Theorem-Assume that F 1 , F 2 and F 3 are continuous distribution functions, and the density functions f 1 , f 2 and f 3 are positive and continuous at c 1 and c 2 . If 0 < \u03c1 1 = lim n 1 ,n 2 \u2192\u221e n 1 /n 2 < \u221e, 0 < \u03c1 2 = lim n 2 ,n 3 \u2192\u221e n 3 /n 2 < \u221e, and P 2 is the true value of the sensitivity to the early diseased stage given specificity and the sensitivity to the fully diseased stage, the limiting distribution of l(P 2 ), defined by (7), is a scaled chi-square distribution with one degree of freedom. That is, where the scale constant r P 1 ,P 2 ,P 3 is with and as given in (4).\nIn order to construct confidence interval for P 2 based on the above Theorem, we need to estimate and . The can be estimated as and a Gaussian kernel was used to obtain a parametric estimation of , as shown in (5). The 100(1 \u2212 \u03b1)% ELP confidence interval for P 2 is where and is the (1 \u2212 \u03b1)th quantile of . The performance of this ELP method highly depends on the density estimates from the Gaussian kernel, whose bandwidth is chosen without a well recognized standard. Therefore, the following bootstrap approach is proposed to estimate instead:\nFor b = 1 to B = 500 bootstrap iterations,\nStep 1: Draw re-samples of sizes n 1 , n 2 , and n 3 with replacement from the non-diseased sample Y 1j 's, the early diseased sample Y 2j 's, and the fully diseased sample Y 3j 's respectively. Denote the bootstrap samples as , i = 1, 2, 3, j = 1, 2,\u2026,n i .\nStep 2: Calculate the bootstrap version of according to (2).\nwhere is defined in (2). This leads to the second 100(1 \u2212 \u03b1)% empirical likelihood confidence interval (ELB) for P 2 where and is the (1 \u2212 \u03b1)th quantile of ."}, {"section_title": "SIMULATION STUDIES", "text": "Simulation studies are carried out to compare the performance of the proposed empirical likelihood confidence intervals ELP and ELB, as well as the asymptotic confidence interval APV, with the existing ones, i.e. GI, BCGI, BTP, BTII proposed in Dong et al. (2011) . As BTI is always inferior than BTII, it is not included in the tables.\nWe evaluate these approaches under the normal and beta distribution scenarios proposed in Dong et al. (2011) , to check whether the new approaches can give comparable performance as the recommended GI/BCGI parametric approach where the normality assupmtions are satisfied with or without Box-Cox transformation. In addition, we also investigated the combined scenario where the normality assumptions cannot be met; that is, gamma for the non-diseased, log-normal for the early diseased and Weibull for the fully diseased group. The density functions for the combined distribution scenario are plotted in Figure 1 . Sample sizes (n 1 , n 2 , n 3 ) are set as (10, 10, 10), (30, 30, 30), (50, 30, 30), (50, 50, 50) , (100, 100, 100), (100, 50, 50) and (100, 100, 50). With a fixed 80% specificity and a fixed 80% sensitivity to the fully diseased stage, the parameters for the distributions are chosen correspondingly so that P 2 equals to 50% or 90%. Under each setting, 5,000 random samples are generated. The simulation results are presented in Tables 1-3 . Table 1 presents simulation results under the normal distributions. The performance of the newly proposed empirical likelihood confidence interval ELB is satisfactory in terms of coverage probability although the ELB tends to be slightly conservative for the small sample sizes. ELP performs well for P 2 = 0.5 except at the sample size (10, 10, 10), but becomes conservative when P 2 = 0.9. BTII gives good estimates at P 2 = 0.5, but when P 2 increases to 0.9, BTII obtains a 0.8956 coverage probability at the sample size 11 (10, 10, 10), which is much lower than the 95% nominal level. In addition, as the sample size increases, BTII grows conservative. The BTP interval is generally conservative. The normal approximationbased confidence interval APV is slightly conservative at small sample sizes. The generalized inference method GI performs the best in the closeness of coverage probability to the nominal level and the length of the confidence interval. Table 2 presents simulation results for the beta distribution. The coverage probability of ELB remains conservative for the small sample sizes at P 2 = 0.5, however, when P 2 = 0.9, for the small sample size (10, 10, 10), ELB attains coverage probability which is very close to the nominal level, and is even better than the BCGI approach. The other empirical likelihood method ELP, yields satisfactory coverage probabilities when P 2 = 0.5 except at the sample size (10, 10, 10), while it is conservative for medium sample sizes when P 2 = 0.9. The non-parametric method BTII is satisfactory at P 2 = 0.5; while at P 2 = 0.9, it changes from being liberal to being conservative as sample sizes increase. The large sample method APV is generally liberal when sample sizes are small. The generalized inference approach with Box-Cox transformation is usually satisfactory, but it can be worse than ELB for a few scenarios, such as (100, 100, 50) at P 2 = 0.5 or (10, 10, 10) at P 2 = 0.9.\nIn Table 3 , the simulation results for the combined distribution are presented. For such cases, the Box-Cox transformation fails to transform the data to the normal distributions. Therefore, as expected, the performance of BCGI is unsatisfactory. Generally speaking, the ELB method is close to the 95% nominal level except being slightly conservative at the sample size (10, 10, 10). The ELP method provide reasonable coverage at P 2 = 0.5 except for the sample size (10, 10, 10). however, it becomes conservative for P 2 = 0.9. BTII maintains the nominal level for most cases except for the sample size (10, 10, 10), where the coverage probability can be as low as 0.7848. In addition, for scenarios such as (100, 50, 50) and (100, 100, 50), BTII becomes more conservative than ELB. The BTP method is generally conservative except at the sample size (10, 10, 10) when P 2 = 0.9. The asymptotic approach APV remains liberal for most of the cases; 12 however, as the sample size increases to (100, 100, 100), the coverage probability is very close to the 95% nominal level.\nIn summary, the GI method or the BCGI method work well for normal and beta distributions, but becomes unusable for the combined distributions case, where the Box-Cox transformation fails to work. The performance of APV is very unstable as it is slightly conservative for the normal case and is generally liberal for the non-normal ones. The BTII, for large P 2 's, is conservative under large unbalanced sample sizes and gives very liberal estimates under small sample sizes. The BTP produces conservative confidence intervals for most of the cases. The ELP performs well for scenarios with smaller P 2 , but it turns out to be conservative for the cases with higher P 2 . Finally, the proposed ELB method gives stable confidence interval estimation with coverage probability close to the nominal level for almost all cases, except that it can be slightly conservative under small sample sizes. Therefore, overall speaking, the ELB method is highly recommended, especially for the cases when normality assumptions are violated and Box-Cox transformation fails to work."}, {"section_title": "EXAMPLE", "text": "Alzheimer's disease (AD) is the most common form of dementia, and it is one of the most costly diseases for society in Europe and the United States. According to Wimo et al. (2013) , the total estimated worldwide costs of dementia were US$604 billion in 2010. About 70% of the costs occurred in western Europe and North America. The Alzheimer's Disease Neuroimaging Initiative (ADNI) is a research project that is designed to validate the use of biomarkers including blood tests, tests of cerebrospinal fluid, and MRI/PET imaging for Alzheimer's disease clinical trials and diagnosis. It aims to define the rate of progress of mild cognitive impairment (MCI) and AD, to develop improved methods for clinical trials, and to provide a large database which will improve design of clinical treatment trials.\nIn the ADNI database, there are many biomarkers to measure the disease progress of AD.\nHere we use a small subset which includes ratio of levels of protein Tau and protein A\u03b2 42\n(TAU/ABETA), Fluoro Deoxy Glucose (FDG) and Alzheimer's Disease Assessment Scale (ADAS11) at the 24th month visit. The clinical dementia rating (CDR) denotes the severity of dementia and a global CDR is derived from individual ratings in multiple domains by an experienced clinician. CDR 0 indicates no dementia and CDR 0.5, 1, 2 and 3 represent very mild, mild, moderate, and severe dementia, respectively. Since patients with large CDR such as 2 or 3 are rarely available, patients with CDR greater than or equal to 1 are referred as the fully diseased group. CDR 0 and 0.5 refer to the non-diseased group and the early diseased group respectively. This subset contains 194, 290 and 183 subjects for the non-diseased, the early diseased, and the fully diseased group respectively. Due to missing values, the actual sample sizes for each variable may vary, as reported in Table 4 . Figures 2 presents the estimated kernel densities of the three disease groups for TAU/ABETA, FDG and ADAS11 respectively. By utilizing the Shapiro-Wilk's normality test, TAU/ABETA is found to satisfy the normality assumptions after the Box-Cox transformation; for FDG, the original data meets the normality assumptions; and for ADAS11, the data either with or without the BoxCox transformation cannot achieve the normality assumptions for all three groups simultaneously. Since the parametric assumptions are not met, GI/BCGI cannot be rationally applied. Therefore, only the other methods are used to analyze this variable. Table  5 presents the estimated confidence intervals of P 2 for each variable. Under the recommended ELB approach, ADAS11 achieves (0.4660, 0.6657) as its 95% confidence interval for P 2 , suggesting it gives a mediocre performance to diagnose the early stage AD patients."}, {"section_title": "SUMMARY AND DISCUSSION", "text": "For disease processes with three ordinal stages, the sensitivity to the early diseased stage given specificity and sensitivity to the fully diseased stage, P 2 , is considered as an important diagnostic accuracy index, especially for early disease detection. The higher P 2 , the better the diagnostic ability of the diagnostic test or biomarker for identifying the early diseased stage. Therefore, an accurate estimation of the confidence interval for P 2 will facilitate investigators to identify the good biomarkers. This article proposes the ELB approach and compares it with the existing confidence intervals. Simulation studies show that ELB not only is more robust than parametric methods which heavily rely on the normality assumptions, but also generally gives more accurate confidence intervals than nonparametric methods, especially for unbalanced data sets. Therefore, the ELB method is highly recommended in practice. For future work, following the same vein of Dong et al. (2014) , we would like to develop the semi-parametric inference procedure for the difference of two correlated P 2 's, based on the empirical likelihood technique."}, {"section_title": "APPENDIX 2: PROOF OF THEOREM IN SECTION 3", "text": "Proof:\nBy similar arguments used in Owen (1990) , we can easily show that and max 1\u2264j\u2264n 2 |\u00db \u2212 P 2 | = O(1) a.s.. Then we have where .\nFrom (6), Therefore, where \u03d5 is defined in (6) and P2 is a three-sample statistic and\nFrom the previous proof and the central limit theorem, we know that is asymptotically normal with the variance . From the law of large numbers, we have\nIt is easy to check Therefore, by the Slutsky Theorem, where the scale constant r P 1 ,P 2 ,P 3 is Density functions for the non-diseased, early diseased and fully diseased group for the two simulation scenarios in Table 3 . Estimated kernel densities for TAU/ABETA, FDG and ADAS11 in the ADNI data. Table 1 Summary of approximate 95% two-sided confidence bounds of BTII, BTP, ELB, ELP, GI and APV for Table 2 Summary of approximate 95% two-sided confidence bounds of BTII, BTP, ELB, ELP, BCGI and APV for Table 3 Summary of approximate 95% two-sided confidence bounds of BTII, BTP, ELB, ELP, BCGI and APV for Table 4 Summary Statistcs for ADNI data. Table 5 Estimated confidence intervals for the probability of detecting early diseased individuals using TAU/ABETA, FDG and ADAS11 of the ADNI data (sensitivity to fully diseased stage and specificity are assumed to equal to 0.8). "}]