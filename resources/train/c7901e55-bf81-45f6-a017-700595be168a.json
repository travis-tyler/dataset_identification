[{"section_title": "Abstract", "text": "Abstract. It is well known that sampling variability, if not properly taken into account, affects various ecologically important analyses. Statistical inference for stochastic population dynamics models is difficult when, in addition to the process error, there is also sampling error. The standard maximum-likelihood approach suffers from large computational burden. In this paper, I discuss an application of the composite-likelihood method for estimation of the parameters of the Gompertz model in the presence of sampling variability. The main advantage of the method of composite likelihood is that it reduces the computational burden substantially with little loss of statistical efficiency. Missing observations are a common problem with many ecological time series. The method of composite likelihood can accommodate missing observations in a straightforward fashion. Environmental conditions also affect the parameters of stochastic population dynamics models. This method is shown to handle such nonstationary population dynamics processes as well. Many ecological time series are short, and statistical inferences based on such short time series tend to be less precise. However, spatial replications of short time series provide an opportunity to increase the effective sample size. Application of likelihood-based methods for spatial time-series data for population dynamics models is computationally prohibitive. The method of composite likelihood is shown to have significantly less computational burden, making it possible to analyze large spatial time-series data. After discussing the methodology in general terms, I illustrate its use by analyzing a time series of counts of American Redstart (Setophaga ruticilla) from the Breeding Bird Survey data, San Joaquin kit fox (Vulpes macrotis mutica) population abundance data, and spatial time series of Bull trout (Salvelinus confluentus) redds count data."}, {"section_title": "INTRODUCTION", "text": "Stochastic population dynamics models constitute an important component of applied and theoretical ecology. When analyzing population time-series data, DeValpine (2002) makes a strong case for using such mechanism-oriented models as compared to simple statistical regression models. These models are also used extensively in population viability analysis (Morris et al. 1999 ) with important implications in public-policy decision making. Statistical inference for population dynamics models has had a long history. Dennis et al. (1991) provide a review of this literature and an introduction to the method of maximum likelihood for estimation of parameters of population dynamics models. However, the approach used in Dennis et al. (1991) does not explicitly consider sampling variability. As argued by various researchers, not taking into account sampling variability can have significant impact on the statistical and scientific inferences (Shenk et al. 1998 reviewing the literature I only discuss, in brief, the salient and distinguishing features of the problem and the approaches proposed in the literature so far. There are two components to this problem: Component 1.-This consists of the stochastic population dynamics model that describes the relationship between population sizes from one time point to the next. Such models typically provide the one-step transition distributions. Given these transition distributions and the equilibrium distribution f (N 1 ; ), one can write down the likelihood function, assuming we have T time points, in a straightforward fashion as\nwhere indicates the parameters in the model. Component 2.-In reality, one does not have the exact knowledge of N t , the true population size. One may only have an estimate of the population size, denoted by N t . These estimates may be obtained through various sampling procedures such as capture-recapture methods or counts from pheromone traps (Seber 2002) . Different sampling procedures lead to different samplingerror distributions. In general, these distributions might contain parameters of their own for taking into account observer effects and other covariates such as weather conditions that might affect the accuracy of the estimator. Let us assume that the form of the sampling distribution is known, based on the sampling procedure used. It is also reasonable to assume that conditionally on the true states, sampling errors from one time point to the other are independent of each other. Now consider the likelihood function based on these available data, namely, the estimated population sizes N t . One cannot simply substitute N t in place of N t in the likelihood function in Eq. 1 because one has to explicitly account for the sampling error. The likelihood function that incorporates sampling error, however, can be written in a general form a\u015d\nHere P(N t \u0366 N t , ) indicates the probability mass function or probability density function of the samplingerror distribution. Further, f (N 1 , N 2 , . . . , N T ; ) indicates the joint distribution of the original but unobserved time series of population sizes. This joint distribution is the same in form as the likelihood function given in Eq. 1.\nNotice that the likelihood function that takes into account the sampling error involves T-dimensional integration. This is far more complicated than the likelihood function without sampling error that was presented in Eq. 1. This likelihood function becomes further complicated if each N t is a vector-valued observation. Such is the case when one considers spatial time series models where an observation at a given time point consists of population estimates at S spatial locations or the community-structure models considered in Ives et al. (2003) where the observation consists of population estimates of S species in the community. In such cases, the likelihood function involves S \u03eb T dimensional integration where S corresponds to the number of spatial locations or number of species. Potentially this can be an extremely high-dimensional integral. Likelihood functions for the models that involve age or stagestructured populations (DeValpine 2004) or models that involve dispersal ) are far too complicated to describe here.\nAs shown by Dennis et al. (1991) , if the actual population sizes N t are available and one can write down the likelihood function in Eq. 1, then it is relatively easy to obtain parameter estimates using the maximum-likelihood method of estimation. However, writing down the likelihood function and hence estimation by maximizing it is substantially difficult if only estimates of the population sizes are available. In some well-structured problems, the likelihood function in the presence of sampling error can be written down explicitly. B. Dennis, J. M. Ponciano, S. R. Lele, M. L. Taper, and D. F. Staples (unpublished manuscript) , Holmes (2000) , and Staples et al. (2004) exploit the structure of the Gompertz and exponentialgrowth models and the lognormal sampling-error distribution to explicitly write down the likelihood in the presence of sampling error. Even when such a likelihood function can be written down explicitly, as reported by B. Dennis, J. M. Ponciano, S. R. Lele, M. L. Taper, and D. F. Staples (unpublished manuscript) , maximizing such a function can be a tricky task involving multiple modes and such.\nWhen computing the likelihood function for less structured problems, one is confronted with the task of high-dimensional integration. Because of the high dimensionality, standard numerical-integration techniques are not practical. One way out of this difficulty is found in the form of Monte Carlo integration. But if the dimension of the integral is high, Monte Carlo integration is computer intensive due to the ''curse of dimensionality'' (Robert and Casella 1999:18) . Thus brute-force integration, numerical or Monte Carlo, does not seem to be an effective answer to the problem. Kitagawa's algorithm (Kitagawa 1987) for nonlinear non-Gaussian time series, adapted by DeValpine and Hastings (2002) for ecological models, uses an ingenious combination of the structure of the problem, namely the first-order Markov property, and repeated use of one-dimensional numerical integration to reduce the computational burden. However, these structural advantages quickly disappear for vector time-series data such as those occurring in spatial-time series. For example, for spatial time-series data with S spatial locations and T time points, the application of Kitagawa's algorithm involves repeated evaluations of several 2S-dimensional integrals and S-dimensional integrals. This is practically impossible if we have more than two spatial locations. In essence, one cannot use Kitagawa's algorithm for spatial time-series analyses. Simple introduction of covariates in the population dynamics models (Lele et al. 1998, Dennis and Otten 2000) makes the underlying population dynamics model nonstationary. These models are also computationally difficult to handle using the existing methods. Thus, there is still a need for a computationally simple statisticalinference method for stochastic population dynamics models in the presence of sampling error.\nWhen the likelihood function is difficult to write or involves computationally difficult problems, the method of composite likelihood has been effectively used in the past (Besag 1975 , Lindsay 1988 , Lele 1997 , Heagerty and Lele 1998 , Lele and Taper 2002 . The main attraction of the composite-likelihood method is its computational and pedagogical simplicity. Previous studies (Lele and Taper 2002 , Henderson and Shimakura 2003 , Zhao and Joe 2005 suggest that relative loss of efficiency as compared to full-fledged likelihood analysis is likely to be small. When the sample sizes are large or the model is complex, the statistically fully efficient, but computationally difficult, method of maximum-likelihood estimation may have to be abandoned in favor of a somewhat statistically less efficient but computationally feasible method of estimation such as the method of composite likelihood. This paper presents an application of the method of composite likelihood in the context of population dynamics models with sampling error.\nThe outline of the paper is as follows. I introduce the concept of composite likelihood; next I consider the stationary Gompertz model with Poisson errors in detail, and then I apply the methodology to reanalyze the American Redstart counts data reported in B. Dennis, J. M. Ponciano, S. R. Lele, M. L. Taper, and D. F. Staples (unpublished manuscript) . The next section discusses application of the method to an important case of the nonstationary Gompertz model where the intrinsic growth rate is affected by environmental conditions. Currently available methods either are not applicable in this situation or have not been studied in this context. To illustrate the method, I reanalyze the San Joaquin kit fox population time-series data with amount of rainfall as an environmental factor affecting population growth. The next section addresses spatial time-series data. This extension allows analysis of a commonly occurring situation in ecology: availability of spatial replications of short time series . I illustrate the method using the bull trout data reported in Dennis et al. (1998) . Finally, I summarize the results and discuss further extensions."}, {"section_title": "A BRIEF INTRODUCTION TO COMPOSITE-LIKELIHOOD METHODS", "text": "A fairly elementary introduction to composite likelihood is available in Curriero and Lele (1999) and Lele and Taper (2002) . Here I provide a brief description that will be sufficient for the application discussed in this paper. Let the joint distribution of the observations be given by f ( y 1 , y 2 , . . . , y n ; ) where denotes the parameters. Then the full likelihood function for can be written as L( \u0366 y) \u03ed f ( y 1 , y 2 , . . . , y n ; ). However, suppose writing down the joint distribution of all the observations is difficult but one can write down the joint distribution of pairs of observations as f ( y i , y j ; ) comparatively easily. Then, under regularity conditions it can be shown, using the theory of estimating functions (Godambe 1991) , that the estimators obtained by maximizing\nconsistent and asymptotically normal (Heagerty and Lele 1998) . Thus, when computation of the joint distribution of all observations is difficult, but computation of the distributions of pairs of observations is relatively easy, then this provides a feasible method of estimation. This particular idea of considering pairs of observations has been used in various situations (Heagerty and , Lele and Taper 2002 , Zhao and Joe 2005 . In fact, one does not have to use only pairs of observations. If one-dimensional marginal distributions are easy to obtain, then one can consider the product of one-dimensional marginal distributions to construct a composite likelihood CL 1 ( \u0366 y) \u03ed f ( y i ; ).\nn \u2338 i\u03ed1 In Markov random-field models, Besag (1975) notes that the joint distribution is difficult to write but that it is easier to specify the conditional distributions of the form f ( y i \u0366 y j , j \u2208 N(i); ) where N(i) denotes the neighborhood of the ith location. Using this fact, he\nNotice the commonality in all of the above methods. Each one considers an objective function that is a product of functions such that each component function in the product is itself a proper likelihood (based only on the joint distribution of two observations or one observation or conditional distribution, etc.). Thus, Lindsay (1988) calls such an objective function ''composite likelihood.'' The method of composite likelihood is useful when writing the full likelihood is difficult but lower-dimensional distributions can be written somewhat easily. Simply taking the product of these lowerdimensional distributions provides an objective function that, when maximized, leads to reasonable estimators of the parameters.\nThe justification for the composite-likelihood method is not based on the quality of its approximation to the likelihood but through the estimating functions that it generates. The resultant estimating functions are zero unbiased and form a mixing sequence. Such estimating functions yield consistent and asymptotically normal estimators. Thus, the main justification of the method of composite likelihood is that it is a computationally simple method that yields consistent, asymptotically normal estimators of the parameters. For this method, no general results about the loss of efficiency are available. However, past experience Taper 2002, Henderson and Shimakura 2003) suggests that the loss of efficiency could be minimal. I suggest that this method be used only when the standard method of maximum likelihood is computationally or otherwise difficult to implement. This method is not a panacea. One has to be careful to first prove that the parameters are estimable using the marginal or conditional distributions. For example, consider the case of simple Gaussian auto-regressive time series of order 1. In this case, it is known that the one-dimensional marginal distribution is given by the following (Chatfield 1989) :\nSuppose we consider the composite likelihood CL 1 ( \u0366 y) \u03ed f ( y i ; ). It can be shown that in this n \u2338 i\u03ed1 case the only estimable parameters are /(1 \u03ea ) and 2 /(1 \u03ea 2 ). Essentially, we can estimate the marginal mean and variance. However, that is not enough to tease out the autocorrelation or the three parameters (, 2 , ) separately. Unfortunately such analysis of identifiability has to be conducted on a case-by-case basis and general results are difficult to specify. In the following section I consider the particular case of the Gompertz model and show that two-dimensional marginal distributions are sufficient to conduct the statistical analysis.\nSTATIONARY GOMPERTZ MODEL, SAMPLING VARIABILITY, AND COMPOSITE LIKELIHOOD Let us now look at the stationary stochastic Gompertz model (Reddingius 1971 , Dennis and Taper 1994 , Dennis et al. 2004 ) in detail. As before, let N t denote the population size and N t denote the estimated population sizes at time t where t \u03ed 1, 2, . . . , T. Basic structure of this model is as follows:\nActual population sizes are related to each other according to the relationship N t\u03e91 \u03ed N t exp(a \u03e9 b log N t \u03e9 t\u03e91 ) where the parameter a may be considered per individual intrinsic growth rate and the parameter b indicates how the growth is affected by the density dependence. Logarithmic transformation of both sides linearizes the model, yielding the Eq. log N t\u03e91 \u03ed a \u03e9 (1 \u03e9 b)log N t \u03e9 t\u03e91 . We assume that t \u03f3 (0, 2 ) are N independent random variables. Note that after logtransformation the Gompertz model corresponds to an autoregressive process of order 1 (Chatfield 1989) . Hence, provided that \u0366(1 \u03e9 b)\u0366 \u03fd 1 and that the process has reached equilibrium, we can write down the joint distribution of the log-transformed population sizes log N t as multivariate normal with mean vector and the covariance matrix, respectively:\n. Given this result, one can write down the two-dimensional marginal distribution of a pair of observations (log N i , log N j ) as a bivariate normal distribution with parameters\nNote that given the parameters of the bivariate distribution, namely ( 1 , 2 , b), we can uniquely determine the values of the parameters (a, b, 2 ) by using the transformations a \u03ed \u03ea 1 b and 2 \u03ed \u03ea 2 b(2 \u03e9 b). Hence, composite likelihood based on two-dimensional marginal distributions will be sufficient for estimation (at least when there is no sampling error). Now let us introduce sampling error into this model.\nIn biological field studies, several different methods are used to estimate population sizes (Seber 2002) . Most of these sampling procedures provide not just estimated population sizes but also the standard errors or complete distributions associated with such estimated values. The procedure outlined below is applicable to any of these sampling procedures where the sampling-error distribution is completely known. If the sampling error is log-normal, then the model reduces to the standard linear Kalman-filter approach (Kalman 1960 ; B. Dennis, J. M. Ponciano, S. R. Lele, M. L. Taper, and D. F. Staples, unpublished manuscript). Statistical methods for the linear Kalman-filter situation are widely available. In this paper the goal is to deal with the case where the sampling distribution is not lognormal and hence is a particular case of a nonlinear Kalman filter. Kitagawa's solution (Kitagawa 1987), used by De Valpine and Hastings (2002) , is a frequentist approach to the problem of nonlinear Kalman-filter models. In this paper, I apply the method of composite likelihood to alleviate the computational burden of Kitagawa's algorithm. For the sake of concreteness, let us assume that N t \u0366 N t \u03f3 Poisson(N t ). In this model there are no additional parameters that may, for example, account for observer effects or other environmental conditions that may affect sampling error. I discuss these general models later in the paper (see Nonstationary Gompertz model with sampling variability: Negative binomial sampling error, below).\nLet us now proceed with the Poisson sampling distribution. We can write down the bivariate marginal distribution of (N i \nIn the above formula, g(log N i , log N j ) denotes the bivariate normal density with parameters given earlier.\nConducting a two-dimensional numerical integration is computationally simple and hence it is feasible to obtain the bivariate marginal distributions of the pairs (N i , N j ). Now we apply the concept of composite likelihood to define an objective function\ntation of this composite likelihood involves T(T \u03ea 1)/ 2 two-dimensional integrals. Recall that as the temporal distance between two observations increases, these observations become almost independent. Thus little information is lost and computational effort can be greatly reduced by considering only those pairs that are within a certain finite neighborhood. For example, Heagerty and Lele (1998) , when using composite likelihood for spatial binary data, only consider pairs that are in the immediate neighborhood. The properties of consistency and asymptotic normality are not affected by this reduction. A straightforward, na\u00efve maximization of the objec-\nOne can use any of the standard maximization routines such as the Newton-Raphson or Nelder-Mead simplex algorithm (Press et al. 1992 ). However, maximization of a function over several variables, three parameters in the above case, requires a significant number of function evaluations. One can reduce the complexity of the maximization problems further.\nConsider one-dimensional marginal distributions of N i . This is given byN\nAs before g(log N i ) denotes the probability density function of a normal variable with mean 1 and variance 2 . Notice that this involves only one-dimensional numerical integration. This is substantially simpler than two-dimensional integration. One can write down the composite likelihood based on these one-dimensional marginal distributions:\n. This composite likelihood is a function of ( 1 , 2 ) and using this we can estimate ( 1 , 2 ). We still need to estimate the density-dependence parameter b. I suggest the following procedure to estimate ( 1 , 2 , b):\nStep 1.-Maximize the composite likelihood CL 1 ( 1 , 2 \u0366 N ) \u03ed f (N i ; 1 , 2 ) with respect to ( 1 , 2 ).\nStep 2.-Fix the value of ( 1 , 2 ) at the estimates obtained in Step 1 and then maximize the composite likelihood\n2 , b) with respect to the parameter b."}, {"section_title": "Confidence intervals, missing data, and non-Poisson sampling errors", "text": "Once the initial estimates are obtained, one can use a parametric bootstrap to obtain confidence intervals. The general procedure is explained elsewhere in detail (Dennis and Taper 1994 ; B. Dennis, J. M. Ponciano, S. R. Lele, M. L. Taper, and D. F. Staples, unpublished manuscript) . Since the basic logic is identical for composite-likelihood-based estimators, I do not replicate the description here.\nMissing data is another common problem in ecological data sets. If the data are missing completely at random, the bivariate marginal distribution of the pairs (that are formed only with the observed time points) is unaffected. Hence computation of the CL is unaffected by the presence of missing observations. On the other hand, to compute the likelihood, e.g., using Kitagawa's algorithm, requires integrating over the missing values. Thus the complexity of Kitagawa's algorithm increases in the presence of missing observations. It is the sequential nature of the computation of the likelihood function that makes handling missing data difficult using the maximum-likelihood estimators. On the other hand, the method of composite likelihood does not use the sequential nature and hence missing observations do not pose a problem for this method. So far I have described the method of maximumcomposite-likelihood (MCL) estimators for the Gompertz model with Poisson sampling errors. However, notice that none of the formulas depend on the Poisson error distribution. If one has different sampling error, one can simply replace the Poisson probability mass function in Eqs. 2 and 3 by the probability mass function for the appropriate sampling distribution. Later in the paper, we will consider sampling error induced by the capture-recapture method of sampling (see Nonstationary Gompertz model with sampling error: Negative binomial sampling error, below)."}, {"section_title": "ILLUSTRATIVE DATA ANALYSIS AND STUDY OF STATISTICAL PROPERTIES OF MAXIMUM COMPOSITE-LIKELIHOOD (MCL) ESTIMATORS:", "text": "STATIONARY CASE\nIn the following, I present a reanalysis of the American Redstart counts data set reported and analyzed in B. Dennis, J. M. Ponciano, S. R. Lele, M. L. Taper, and D. F. Staples (unpublished manuscript) . This is strictly an illustrative analysis. I do not claim that all model assumptions are fully satisfied. For example, the , 1966-1005) to conduct the Monte Carlo study; these estimates are shown in the first column. For all sample sizes, the estimator of the log (carrying capacity), 1 , behaves quite well. The estimators of the variance, 2 , and density-dependence parameter, b, are biased downward. This problem goes away as the sample size increases. Also notice that bias is very small compared to the mean absolute deviation (MAD).\nassumption of Poisson sampling error may not be strictly correct. There are observer biases, environmental conditions affect the sampling error, and the parameters in the underlying Gompertz model might also vary with the environment. For these data, information about these complications is unavailable and hence, while acknowledging their existence, I am unable to consider them explicitly here. Some of these complications are addressed in other analyses presented in the paper."}, {"section_title": "Description of the American Redstart counts data set", "text": "The North American Breeding Bird Survey (BBS; Robbins et al. 1986 , Peterjohn 1994 ) poses both challenges to and opportunities for ecological and statistical analyses. While the BBS data are problematic for various reasons, investigators remain optimistic that meaningful ''signals'' might be extracted Sauer 1997, 1998) . The major advantages of the BBS data sets are their extensive spatial coverage and reasonable time-series lengths. The hope is that the extensiveness of the data might trump the imprecision. We consider the counts of American Redstart (Setophaga ruticilla) from the BBS record number 0214332808636 observed during 1966-1995. These data were reported and analyzed in B. Dennis, J. M. Ponciano, S. R. Lele, M. L. Taper, and D. F. Staples, unpublished manuscript) using the maximum-likelihood (ML) and restricted maximum-likelihood methods (REML) under lognormal sampling-error distribution.\nHere we consider the Gompertz model, and a simple, yet reasonable, Poisson distribution as the model for sampling error. I use the algorithm described above to obtain maximum-composite-likelihood estimates. Following Heagerty and Lele (1998) I use only the nearest neighbors to form pairs. This decreases the computational burden substantially by reducing the number of pairs at the same time allowing for the estimation of all the parameters. Table 1 provides the estimated values of the parameters obtained under the Poisson assumption. I further present a simulation study that studies various properties of the estimation procedure described above. First, we study the effect of not taking into account the sampling variability. These are the estimators (ML-NA\u00cfVE) obtained by using the method described in Dennis et al. (1991) ignoring the fact the observations are not true population sizes but only estimated population sizes. Then we study the maximumcomposite-likelihood estimators that take into account the fact that we have estimated population sizes (MCL-GP [Gompertz Poisson]). I provide evidence for reduced bias, consistency, and asymptotic normality of the maximum-composite-likelihood (MCL-GP) estimators as compared to the ML-NA\u00cfVE estimators. Furthermore, I wish to provide some assurance that the loss in efficiency for MCL estimators is probably small. As discussed earlier, the computation of the maximumlikelihood estimators for the full model that takes into account sampling error is difficult. Hence we cannot do a direct comparison of the variance of the MCL estimator with the ML estimator based on the estimated population sizes. However, when there is no sampling error, it is possible to compute both the ML (ML-ORIG [original data]) and the MCL (MCL-ORIG) estimator. Hence we compare the efficiency of the MCL-ORIG estimator with that of the ML-ORIG estimator in the situation where there is no sampling error. The implicit argument is that if the loss of efficiency for MCL estimators is small in the no-sampling-error situation, then it is likely to be small in the case when there is sampling error. Table 1 summarizes the distributional properties of the MCL-GP estimator for time series of lengths 30, 50, and 100. These simulations were conducted under the parameter values obtained from fitting the model to the American Redstart data. In Fig. 1 we provide MEASUREMENT ERROR AND DENSITY DEPENDENCE FIG. 1. Comparison of the performance of four estimators (ML-NA\u00cfVE, ML-ORIG, MCL-ORIG, and MCL-GP) of (a) 1 , the log(carrying capacity), and (b-d) the square root of 2 , the variance. The horizontal line corresponds to the true value. All estimators behave quite well for estimating log(carrying capacity). The ML-NA\u00cfVE estimator of the variance is biased, and this bias does not go away, even with larger sample sizes. The bias characteristics of the ML-ORIG, MCL-ORIG, and MCL-GP estimators of variance are quite comparable. Their bias goes to zero as sample size increases. Variability in MCL-GP is higher than in ML-ORIG and MCL-ORIG. This is to be expected, given the presence of sampling variability. However, notice that the variability of MCL-ORIG is very slightly larger than ML-ORIG, indicating very little loss of efficiency with the use of the maximum-composite-likelihood (MCL) over the maximum-likelihood (ML) method.\ncomparison of ML-ORIG, MCL-ORIG, MCL-GP and ML-NA\u00cfVE estimators for the parameters 1 and 2 . The exact algorithm for this simulation study is described in Appendix A. The results of this simulation study are summarized below. a) Fig. 1a indicates that estimation of the log(carrying capacity) 1 works quite well using any of the estimators. Since this parameter is estimated well by all methods, its behavior is not presented for varying sample sizes. b) ML-NA\u00cfVE estimator of 2 has large positive bias for all sample sizes. Moreover, this bias is not reduced with increased sample size. Thus, ML-NA\u00cfVE provides an inconsistent estimator of process variability. This estimator consolidates sampling variability with the process variability.\nc) It appears that the MCL-GP estimator of 2 is also biased; however the bias is smaller than that for the ML-NA\u00cfVE. Thus, by taking into account sampling variability, we have improved the analysis. Moreover, the variance, as indicated by the spread of the box plots for MCL-GP, also decreases as the sample size increases (Fig. 1b, c, and d) . These observations together lend support to the claim of consistency of the MCL-GP estimators. Also notice that the distributions are symmetric around the median supporting asymptotic normality of the MCL-GP estimators.\nd) The ML-ORIG and MCL-ORIG estimators of 2 are also biased. Thus, even if there is no sampling error, estimation of 2 is difficult. However, as the sample size increases from 30 to 50 to 100 (Fig. 1b, c, and d) , this bias decreases. Also note that this suggests that the problem of bias in MCL-GP is probably not a fault of the composite-likelihood method but rather a problem intrinsic to the model itself.\ne) The distributions of ML-ORIG and MCL-ORIG are quite similar to each other. This indicates a minor loss of efficiency by using the composite-likelihood estimator as compared to the maximum-likelihood estimator when there is no sampling error. This result provides indirect evidence for possibly only a small loss of efficiency using MCL in the presence of sampling error. Fig. 2 shows the comparison of the estimators of the density-dependence parameter, b, for time series of lengths 30, 50, and 100. The first striking thing to notice is the negative bias in the ML-NA\u00cfVE estimator. If sampling variability is not taken into account, we underestimate the density dependence substantially. The MCL-GP estimator of b is also biased but less so than ML-NA\u00cfVE. The MCL-GP improves the analysis by accounting for sampling error. Moreover, as the sample size increases the distribution of the MCL-GP esti-Ecology, Vol. 87, No. 1"}, {"section_title": "FIG. 2.", "text": "Comparison of the distribution of the ML-NA\u00cfVE, ML-ORIG, MCL-ORIG, and MCL-GP estimators of the density-dependence parameter, b. The horizontal line indicates the true value. It appears that even the ML-ORIG and MCL-ORIG estimators are biased downward and that MCL-GP estimators are quite comparable with them in terms of bias. MCL-GP estimators are, as expected, more variable than ML-ORIG estimators. This is mostly due to the presence of sampling error. From comparing the distribution of ML-ORIG and MCL-ORIG, it appears that the loss of efficiency by using the MCL instead of ML method is quite small when the original data are available. One can implicitly conclude that the loss of efficiency in using MCL-GP estimators in place of ML-GP estimators must also be small. mators becomes more concentrated around the true value. This result lends support to the claim that MCL-GP is a consistent estimator. Symmetry of the distribution also supports the claim of asymptotic normality. Furthermore, the ML-ORIG and MCL-ORIG estimators of b are also biased for small sample sizes. Thus, the bias in the MCL-GP is not aberrant. Moreover, also note that the distributions of ML-ORIG and MCL-ORIG estimators are quite similar. This indicates the loss in efficiency for MCL-ORIG is small, indirectly suggesting that loss in efficiency for MCL-GP probably is also small."}, {"section_title": "NONSTATIONARY GOMPERTZ MODEL", "text": "WITH SAMPLING VARIABILITY To illustrate the power and versatility of the method of composite likelihood, we now consider a case that has not been dealt with in previous papers. This case is extremely important for various applications of stochastic population dynamics models. In the stationary model considered above, it is assumed that the intrinsic growth parameter, a, and the density-dependence parameter, b, do not vary from time to time. Ecologically it is more sensible to model these parameters as dependent on the environmental conditions. For example, higher availability of food should lead to higher growth rate and vice versa. Environmental conditions vary from year to year; so should the parameters in the stochastic growth model.\nSuppose there are p covariates summarizing environmental conditions that may affect the intrinsic growth rate. Let Z t \u03ed (1, Z t1 , Z t2 , . . . , Z tp ) denote the covariate vector corresponding to time point t. I have included ''1'' to account for the intercept. Let the regression parameters be denoted by \u2424 T \u03ed (\u2424 0 , \u2424 1 , . . . , \u2424 p ). The nonstationary Gompertz model is specified by log N t \u03ed \u2423 t \u03e9 (1 \u03e9 b)log N t\u03ea1 \u03e9 t where \u2423 t \u03ed Z t \u2424. Thus the intrinsic growth parameter is time varying and depends on the environmental conditions at that time. For this model, it can be shown that the joint distribution is multivariate normal with means, variances, and covariance given by\n(see Appendix B for mathematical derivations). Notice that the mean is a function of the initial population size and environmental conditions at all the intermediate time points. The variances and covariances, although independent of the covariates, are time dependent. Since marginal distributions are easy to compute, we can apply the method of composite likelihood to estimate the parameters. Somewhat counterintuitively, the nonstationary case is simpler than the stationary case. This is because in the nonstationary case, the one-dimensional distributions are sufficient to identify the parameters of interest, namely, (log N 1 , \u2424, b, 2 ). We can use one-dimensional integrals instead of two-dimensional integrals. This makes the computational problem easier to deal with. Thus, to obtain the MCL (maximum composite-likelihood) estimators we maximize the following objective function: "}, {"section_title": "Notes:", "text": "The estimated values and 90% confidence limits (CL) for the parameters of the nonstationary Gompertz model fit to the San Joaquin kit fox data. The environmental factor of rainfall is significant in determining the population dynamics. Also notice the reduction in the environmental variation in the stationary fit to the model that accounts for rainfall, indicating the importance of the covariate in the model. Estimated carrying capacity under the stationary model is 141.5773; under the nonstationary model at the average rainfall value it is 164.2728, and the mean of the observed population size is 156.2308."}, {"section_title": "\u0375 t t t 1 2 t", "text": "As before, g(\u00b7) indicates the probability density function of the normal random variable. We want to emphasize again that we have to estimate the regression parameters as well as the initial population size. We consider Poisson sampling error in the following."}, {"section_title": "Algorithm for nonstationary Gompertz model with Poisson sampling error", "text": "Step 1.-Estimate the initial log-population size by log \u00d1 1 \u03ed log(N 1 \u03e9 0.5).\nStep 2.-Fix N 1 \u03ed \u00d1 1 and maximize the objective function CL 1 (\nNotice that this objective function only involves onedimensional marginal densities and hence requires only one-dimensional numerical integration, reducing the computational burden substantially.\nTo illustrate this method and to study the statistical properties of these estimators under realistic parameter values, I reanalyze the population time series of San Joaquin kit fox (Vulpes macrotis mutica) from 1985 through 1994 reported in Dennis and Otten (2000) . This population time series is accompanied by the environmental covariate of amount rainfall. As noted by Dennis and Otten (2000) , the population sizes are estimated values using the mark-recapture method. They also provide standard errors associated with the estimated population size. I refer the reader to the original paper for more details on the data collection. To check the reasonableness of the Poisson sampling error, I plotted the estimated population sizes vs. the reported squared standard errors associated with these estimates. I observed that the plot (not presented here) was linear with slope close to 1. There was some indication that variance might be slightly larger than the mean, but given the small sample size (12 years) and the illustrative nature of our analysis, initially I chose to ignore this minor deviation from the Poisson model. Table 2 presents the estimated parameters along with the parametric bootstrap-based 90% confidence intervals. Given the small sample size, these confidence intervals are expectedly wide. However it is remarkable that even for such a small sample size, there is a clear indication that rainfall has a significant effect on the population growth (confidence interval excludes zero). The strength of the density-dependence parameter is also (although marginally) significant at the 10% level of significance. In any case, for such a small sample size, one cannot expect to obtain strong inferences. It is also worth noting that these scientific inferences are similar to the ones obtained by Dennis and Otten (2000) . For comparison, in Table 2 the estimated parameter values under the stationary Gompertz model are presented. It is clear that the estimate of environmental variance is substantially higher in the stationary case. Much of the variation is explained by the rainfall effect on the population growth. Thus, in the nonstationary case, the estimate of the environmental variance is substantially smaller and is another indication that the covariates might a play significant role in modeling population dynamics.\nThe sample size for the original data is quite small. To study the behavior of these estimators for larger sample sizes, I conducted a Monte-Carlo study. I considered time-series lengths of 30, 50, and 100. The covariate values for longer time series were generated from a normal distribution with mean and variance equal to mean and variance of rainfall in the original time series. The results are shown in Fig. 3 and are summarized below. 1) Regression coefficients indicating how environmental variables affect the intrinsic growth rate are estimated quite well for all sample sizes.\n2) The density dependence parameter, b, is also estimated quite well for all sample sizes.\n3) The environmental variance parameter is estimated with a negative bias for smaller samples. How- Ecology, Vol. 87, No. 1 FIG. 3 . Monte Carlo study of the behavior of MCL estimators for a nonstationary Gompertz model for sample sizes 30, 50, and 100, based on 500 simulations. The horizontal line corresponds to the true parameter value. (In this figure we have used CL, MO, and MN in place of MCL-GP, ML-ORIG, and ML-NA\u00cfVE, respectively, to conserve space. In each panel, the group of three box plots at the left has sample size n \u03ed 30; for the middle three, n \u03ed 50; and for the right-hand three, n \u03ed 100. Except for the variance parameter ( 2 ), the environmental (\u2424 0 , \u2424 1 ) and density-dependence (b) parameters are estimated quite effectively for all sample sizes. As the sample size increases, the variance parameter is well estimated also. The performance of MCL is comparable to that of ML-ORIG estimators, whereas the ML-NA\u00cfVE estimator of variance is biased upward for all sample sizes. ever this bias is reduced as the sample size increases indicating consistency of the estimator. Notice that the ML-NA\u00cfVE estimator of variance has positive bias even for large sample sizes. As in the stationary case, the ML-NA\u00cfVE estimator consolidates the sampling variability with the process error. Further the ML estimator of the environmental variance, even in the absence of sampling variability, is biased. This again shows that the behavior of the MCL estimator is not aberrant.\n4) The distribution of the MCL estimator is symmetric, indicating reasonableness of the asymptotic normality of these estimators.\nThe above simulations are based on the composite likelihood that is based on only one-dimensional marginal distributions. To see if consideration of two-dimensional distributions reduces the bias in the estimator of environmental variance, I fixed the parameters (\u2424 0 , \u2424 1 , c) at the estimates obtained from one-dimensional composite likelihood and used the two-dimensional distributions, with nearest neighbors forming the pairs, to obtain the estimate of the environmental variance 2 . The new estimated value was 0.0914, clearly larger than the estimated value obtained using the onedimensional composite likelihood. The estimator based on one-dimensional distribution is negatively biased and hence it is reassuring that consideration of bivariate distributions improves the performance of the MCL. I conducted a simulation study (500 replications) to study the behavior of the estimator of 2 based on twodimensional distributions. The median of the bootstrap distribution of the MCL estimator with the one-dimensional distribution was 0.034, while with the twodimensional distribution it was 0.056. Although it is not surprising, it is reassuring that consideration of two-dimensional distributions reduces bias in the MCL estimators substantially. However, this improvement in the performance is obtained at an increased computational cost of using two-dimensional integrals in place of one-dimensional integrals."}, {"section_title": "Negative binomial sampling error", "text": "As mentioned earlier, the plot of estimated values versus their variances (square of the standard errors) indicated that the relationship was not quite linear with slope equal to 1. Variance appeared larger than the mean, which indicates overdispersion. To account for overdispersion, I fitted the variance function corresponding to the negative binomial distribution, namely, var \u03ed mean \u03e9(mean) 2 /size. This achieved a better fit than the variance function corresponding to the Poisson distribution, var \u03ed mean. The estimated value of the parameter ''size'' was 625. The value of the size parameter is fairly large indicating the difference between Poisson and negative binomial sampling model might be negligible. However, to illustrate the fact that the method of composite likelihood is not limited to using only the Poisson sampling error, I considered the negative binomial distribution as the sampling-error model. Based on the one-dimensional composite likelihood, the estimated values of the Gompertz parameters are reported in Table 2 . Notice that these estimates are similar to the ones obtained under the Poisson distribution except that the estimated environmental variance is marginally smaller. The estimates do not change substantially because the size parameter is large enough that the difference between the Poisson and the negative binomial distribution is fairly small.\nOne can potentially consider a nonstationary Gompertz model where the density-dependence parameter b is also a function of the covariates. However, it seems more natural that the environmental conditions would affect the intrinsic growth rate rather than the density dependence parameter, which is an innate characteristic of the organism. Nonetheless, it will be an interesting study to analyze several data sets using the general model where both a and b depend on the environmental conditions and to check how often the submodel with only a depending on the environmental conditions provides an adequate fit."}, {"section_title": "SPATIAL TIME SERIES AND SAMPLING VARIABILITY", "text": "It should be quite apparent from the simulation results presented thus far that estimation of the parameters of a stochastic population dynamics model is a difficult task, with or without sampling variability. If the length of the time series is small, even with no sampling error, maximum-likelihood estimators are biased and highly variable. However, it is the ecological reality that many ecological time series are short. One reasonable way to boost the sample size is by using spatial replications . Likelihood-based statistical inference for spatial time series in the presence of sampling error is substantially more computer intensive and complicated than for a single time series. For example, to evaluate the likelihood function at a single parameter value using Kitagawa's (1987) sequential-integration method involves numerical evaluation of T, 2S-dimensional integrals and T, S-dimensional integrals where S corresponds to the number of spatial locations. Further, to obtain the maximum-likelihood estimator, numerical maximization requires repeated evaluations of the likelihood function. This is prohibitive and practically impossible even for a small number of spatial locations.\nHowever, one can use the composite likelihood for the analysis of spatial time-series data very easily. This extension to the spatial time-series data entails minimal increase in the computational complexity. The composite-likelihood method requires only two-dimensional integrals and not S-dimensional integrals as are required by Kitagawa's algorithm (DeValpine and Hastings 2002) . This reduction in the dimension provides substantial computational advantage because the computational burden for numerical integration increases exponentially with the dimension of the integral. What is practically an impossible analysis for the maximumlikelihood method is a feasible analysis for the composite-likelihood approach.\nLet us start with a description of a spatial Gompertz model. Let S denote the number of spatial locations. Then at each time point, an observation is an S \u03eb 1 vector consisting of log(population sizes) at each of the locations. Let us denote this vector by log N t . The spatial Gompertz model is given by log N t \u03ed a \u03e9 (I \u03e9 B)log N t\u03ea1 \u03e9 t . The vector a \u03ed (a 1 , a 2 , . . . , a s ) corresponds to the intrinsic growth-rate parameters at the S spatial locations. The matrix B \u03ed diag(b 1 , b 2 , . . . , b s ) is a diagonal matrix of dimension S \u03eb S and I is an S \u03eb S identity matrix. The process error is given by t \u03f3 multivariate (0, \u233a). In this general model, N the spatial aspect comes from the fact that process errors are spatially correlated. This completely general model has S \u03e9 S \u03e9 S(S \u03e9 1)/2 number of parameters. To reduce the number of parameters, one generally needs to assume a structure on the spatial correlations such as an exponential covariogram (Cressie 1993) . One can model the spatial heterogeneity of the intrinsic growth-rate parameters as well as that of density-dependence parameters by considering location-specific environmental covariates. One can also consider spatial version of the random coefficient models such as those considered in Zeng et al. (1998) . The kind of model chosen will depend on the availability of relevant information.\nLet us consider the bull trout (Salvelinus confluentus) data representing counts of redds (breeding sites) recorded during 1980-1993 on four tributaries of the Middle Fork of the Flathead River, Montana, USA . This data set provides no information on the environmental covariates, has only four spatial locations and 14 time points. Also, the spatial coordinates of the locations were not available to the author. Given this fairly limited information, we consider a model with spatially homogeneous intrinsic growth and density dependence parameters. We also assume spatially homogeneous process-error variance and equi-correlation between the locations. In summary, our model is based on a \u03ed (a, a, a, a) , B \u03ed diag (b, b, b, b) and\nTo apply the method of composite likelihood, we need to compute one-dimensional and two-dimensional distributions. Using the theory of multivariate autoregressive processes (Chatfield 1989) , these can be written as follows. Then parameters for our spatial Gompertz model are ( 1 , 2 , b, ). In terms of these parameters, the onedimensional marginal distributions of observations log N t,s are normal with mean 1 and variance 2 for t \u03ed 1, 2, . . . , T and s \u03ed 1, 2, . . . , S. Furthermore, the pairs that are between time points (i, j) but within the same spatial location s, namely, (log N i,s , log N j,s ) are distributed as bivariate normal random variable with mean vector 1 1 and covariance matrix\nThe pairs that are formed within the same time point but between spatial locations, namely, (log N t,l , log N t,m ) are distributed as bivariate normal random variables with mean vector Using these results, we can write down the algorithm for computing composite-likelihood estimators for spatial Gompertz model with sampling error as follows.\nStep 1.-Use the one-dimensional marginal distributions to construct CL 1 ( 1 , 2 ; N 1 , N 2 , . . . , N S ) \u03ed f (N i,s ; 1 , 2 ). Maximize this function with\nrespect to the parameters ( 1 , 2 ).\nStep 2.-Use the two-dimensional marginal distributions of the pairs formed within a spatial location but between time points to construct the objective func-\n1 , 2 , b). Fix the ( 1 , 2 ) parameters at the estimates obtained in Step 1 and maximize with respect to b.\nStep 3.-Use the pairs formed between spatial locations but within a time point to construct the objective function CL 2 ( 1 , 2 ,\nfunction with respect to the parameter with ( 1 , 2 ) fixed at the estimated values from step 1.\nIn Fig. 4 , we study the performance of MCL-GP estimators. Clearly pooling information across space has improved the performance of these estimators; they are more stable and less variable as compared to what was observed in the kit fox data where there were only 12 observations. The ML-NA\u00cfVE estimator of the variance is larger than the MCL-GP estimators because it does not separate out the sampling variability. It also has negative bias in both density-dependence parameter and spatial correlation. These conclusions are similar to the ones that were noted for single time-series analysis. As before, MCL-GP estimators are somewhat biased but this behavior is not aberrant; the ML-ORIG estimators for data without sampling variability are bi-ased as well. The most important thing to note here is that the method of composite likelihood facilitated the analysis of the spatial time-series data without much computational difficulty. This would have been a nearly impossible task for the method of maximum likelihood."}, {"section_title": "SUMMARY AND CONCLUSIONS", "text": "The problem of estimation of parameters of stochastic population dynamics models in the presence of sampling variability is a computationally difficult problem. The standard frequentist approach to statistical estimation is based on the likelihood function. The application of likelihood to statistical analysis has been generalized through the use of estimating functions (Godambe 1991) . For the problem of inference for stochastic population dynamics models with sampling variability I noted that writing down the likelihood function is difficult. To overcome this problem, I proposed the method of composite likelihood. The main benefit of the MCL (maximum composite likelihood) is the reduction in the dimensionality of the integration to two, no matter what the time-series length or the number of spatial locations is. This method thus provided a practical, feasible approach to the problem of estimation in the presence of sampling variability. Although composite likelihood can be looked upon as an approximation to the full likelihood, the main justification of the method of composite likelihood is via the theory of estimating functions. It generates estimating functions that, under fairly general conditions, lead to consistent and asymptotically normal estimators. These estimators have somewhat larger asymptotic variance as compared to the maximum-likelihood estimators. But in the cases we study, maximum-likelihood estimators are computationally difficult. Hence, in using the method of composite likelihood we paid a price in statistical efficiency but gained in computational feasibility. However, previous studies Taper 2002, Henderson and Shimakura 2003) as well as the simulation studies presented in this paper indicate that the loss in statistical efficiency is likely to be small. Although I did not explicitly illustrate it, the method of composite likelihood is also applicable in the presence of missing observations. Computing the likelihood using Kitagawa's algorithm, which is sequential in nature, requires integration over the missing observations. This increases the computational complexity. On other hand, the definition of the composite likelihood is based on the marginal distributions. These are unaffected by the presence of missing data. One forms the composite likelihood based on the single or pairs of observations that are actually present in the data set. I also showed that the method of composite likelihood can entertain any sampling-error model. We started with an analysis of a single time-series data using the Gompertz growth model with Poisson sampling error. It was shown that the method of composite likelihood is easy to apply and that the estimators have reasonable statistical properties. Then we studied the rarely considered nonstationary Gompertz model where the intrinsic growth parameter varies with time. The sampling-error model used was based on the mark-capture method of estimation of population sizes. The method of composite likelihood was easy to apply even in this nonstandard situation and the estimators had reasonable statistical properties. From the simulation studies, we learned that to obtain reliable estimates and short confidence intervals one needs large sample sizes. Most ecological time series tend to be short, but spatial replications are usually available. In such situations, the method of composite likelihood was shown to have even bigger computational advantage over the existing methods. Computational simplicity of the method of composite likelihood also facilitates computation of parametric bootstrap confidence intervals. One need not depend on asymptotic methods to obtain standard errors or confidence intervals. The method of composite likelihood involves computation of at most twodimensional numerical integrals. These routines are readily available in many standard computer packages such as R, MATLAB, GAUSS, or MATHEMATICA. Programming the method of composite likelihood is straightforward and easier than the existing methods for the computation of the maximum-likelihood estimators.\nAs is true of any method of estimation, there are limitations to the application of the method of composite likelihood. In this paper, I used only one-or twodimensional marginal distributions to construct the composite likelihood. This particular construction is applicable when such marginal distributions are easy to compute. Furthermore, to be successful, these marginal distributions should be informative about the parameters of interest. This may not hold true for all models of ecological interest. No general recipe can be provided for the construction of suitable estimating functions for models where small dimensional marginal distributions are not informative. On the other hand, I have shown that when such marginal distributions are easy to obtain, the method of composite likelihood is a reasonable alternative to more complicated methods for analyzing stochastic population dynamics models in the presence of sampling variability. Although the discussion in this paper was based on the Gompertz growth model, the method is equally applicable to other stochastic population dynamics models such as the logistic growth model or the delayed density-dependence models. However, some of the technical details are more involved than for the Gompertz model and, hence, these extensions will be discussed elsewhere."}]