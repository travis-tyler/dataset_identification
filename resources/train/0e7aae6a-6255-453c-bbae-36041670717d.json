[{"section_title": "Foreword", "text": "This report provides a brief description of the degree attainment and persistence of a nationally representative sample of students who began postsecondary education for the first time in the 2003-04 academic year. The report provides a first look at the experience of these students over three academic years, from July 2003 to June 2006, and provides information about rates of program completion, transfer, and attrition for students who first enrolled at various types of postsecondary institutions using data from the 2004/06 Beginning Postsecondary Students Longitudinal Study (BPS:04/06). The BPS survey is the longitudinal component of the 2003-04 National Postsecondary Student Aid Study (NPSAS:04), a nationally representative sample that includes students enrolled in all types of postsecondary institutions. The BPS:04/06 cohort consists of students in the NPSAS:04 sample that were identified as having enrolled in postsecondary education for the first time during the 2003-04 academic year. These beginning students were initially interviewed in 2004, at the end of their first year in postsecondary education, and then interviewed again in 2006, three years after they had started. The information in this report may be compared to a previous NCES report that examined the degree attainment and persistence after three years of students who began postsecondary education for the first time in 1995-96 (Berkner, Horn, and Clune 2000). The estimates presented in the report were produced using the NCES Data Analysis System (DAS), a web-based software application that enables users to specify and generate tables for most of the postsecondary surveys conducted by NCES. The DAS produces the design-adjusted standard errors necessary for testing the statistical significance of differences in the estimates. The DAS for BPS:04/06 is available on the NCES website (http://nces.ed.gov/das). For more information on the DAS, see appendix B of this report."}, {"section_title": "Introduction", "text": "Approximately 4 million undergraduates started postsecondary education for the first time during the 2003-04 academic year, enrolling in a wide variety of institutions, including 4-year colleges and universities, public 2-year community colleges, and private for-profit institutions offering career-oriented and vocational programs. A sample of these first-time beginning students was surveyed in 2004, at the end of their first year in postsecondary education, and then surveyed again in 2006, three years after they had started. This report provides a first look at the results of the 2006 survey data to describe the patterns of enrollment and program completion of the 2003-04 beginning students during that three-year period. The data in this report are from the 2004-06 Beginning Postsecondary Students Longitudinal Study (BPS:04/06), the latest in a series of BPS studies covering the years 1990-94 (BPS: 90/94), 1996-2001 (BPS: 96/01), and now 2004-06 (BPS:04/06). The students in the BPS:04/06 study will be contacted again and interviewed in 2009. The descriptive reports and public access datasets for all of these studies are available on the NCES website (http://nces.ed.gov/das). The BPS:04/06 study includes the results of the 2004 survey, administered during the students' first year of enrollment, as well as the results of the First Follow-up of 2006. The 2004 survey was administered as part of the 2003-04 National Postsecondary Student Aid Study (NPSAS:04). NPSAS:04 is a nationally representative sample of about 90,000 undergraduate, graduate, and first-professional students in about 1,600 postsecondary institutions in the 50 states, the District of Columbia, and Puerto Rico 1 that are eligible to participate in the federal Title IV student aid programs. Approximately 19,000 respondents were identified as first-time beginners in the NPSAS:04 survey and became the sample for the BPS:04/06 longitudinal study. The NPSAS:04 study sample represents the approximately 19 million undergraduates enrolled in 2003-04, while the BPS:04/06 study sample represents about 4 million of these undergraduates who were first-time beginners that academic year. Introduction 2 interview. The information about the beginning postsecondary students in 2006 is primarily based on the follow-up student interview, supplemented with data from the same federal databases, college admissions test agencies, and the National Student Clearinghouse enrollment records. The student interviews in both years used a web-based questionnaire that was either self-administered or conducted via telephone with a trained interviewer. In 2006, about 15,000 students completed the interview, resulting in a weighted response rate of 77 percent. The technical notes in appendix B supply additional information about response rates, the methodology of the data collection, file preparation, and analysis. The tables in this report present information about beginning student enrollment and program completion from two different perspectives. The first is from the perspective of the students. It looks at the beginning students' enrollment history and degree attainment at any postsecondary institution over the three-year period under consideration. This will be referred to as student attainment and persistence anywhere (tables 1-3). The second is from the perspective of the first institution attended. The first institution attended designates students as first-time beginners (or freshmen) and reports whether those students continue to be enrolled or complete a program at that institution. This perspective will be referred to as attainment and retention at the first institution attended (tables 4-6). The difference between these two perspectives reflects the fact that many students transfer out of the first institution attended. When beginning students leave the institution where they first enrolled and then enroll at a different institution, they continue to persist in postsecondary education, but from the perspective of the institution where they started, they have no longer been retained. Figure 1 illustrates the relationship of these two perspectives for first-time beginners who were recent (2003) high school graduates with bachelor's degree plans and were enrolled full time in the fall of 2003. The normal length of time it takes for a full-time student to complete a program and attain a certificate or degree depends on the type of program. Vocational certificate programs normally take less than two years to complete, associate's degree programs can be completed in two or three years, and bachelor's degree programs can be completed in four or five years. The threeyear period covered in this report (from July 2003 to June 2006) is long enough for students beginning in 2003-04 to complete certificates and associate's degrees, but too short for most students to complete bachelor's degrees at 4-year colleges and universities. A glossary describing the variables used in the tables is provided in appendix A. All comparisons made in the Selected Findings were tested using Student's t statistic, and all differences cited were statistically significant at the .05 level. Standard errors for estimates in this report are available at http://nces.ed.gov/das/library/reports.asp."}, {"section_title": "Selected Results", "text": ""}, {"section_title": "Attainment and persistence anywhere through 2006", "text": "\u2022 Among the beginning students who were recent (2003) high school graduates, enrolled full time in the fall of 2003, and had bachelor's degree plans, 83 percent had not attained a degree and were still enrolled at some postsecondary institution three years later; 5 percent had attained a degree or certificate; and 12 percent had not attained any degree and were no longer enrolled in June 2006 (figure 1 and table 1). \u2022 Among the 2003-04 beginning students who first enrolled at a public 2-year institution and then transferred to another institution, 18 percent had attained a certificate or associate's degree and were still enrolled at some postsecondary institution in June 2006; 62 percent had not yet attained any degree and were still enrolled at some postsecondary institution (table 2). \u2022 Fifty percent of the beginning independent students who first enrolled at 4-year institutions in 2003-04 had not attained any degree and were no longer enrolled; 41 percent had not attained any degree, but were still enrolled; 5 percent had attained a degree or certificate and were still enrolled; and 5 percent had attained a degree or certificate and were no longer enrolled (table 3)."}, {"section_title": "Attainment and retention at the first institution attended", "text": "\u2022 Among the beginning students who were recent (2003) high school graduates, enrolled full time in the fall of 2003, and had bachelor's degree plans, 70 percent were still enrolled at their first institution without a degree, 4 percent had attained a degree or certificate at their first institution, and 20 percent had transferred elsewhere without a degree by June 2006. Seven percent had left the first institution attended without a degree or certificate and did not enroll anywhere else within three years (figure 1 and table 4). \u2022 Among the students who were recent (2003) high school graduates, first enrolled at a public 2-year institution full time in the fall of 2003, and had associate's degree plans, 23 percent attained an associate's degree at that institution, 31 percent were still enrolled there without a degree, 24 percent had transferred elsewhere without a degree by June 2006, and 21 percent had not attained any degree at the first institution and did not enroll anywhere else (table 5). \u2022 Five percent of the beginning students who first enrolled at a doctorate-granting 4-year institution in 2003-04 had attained some degree at that institution within three years, 71 percent were still enrolled there without a degree, and 17 percent had transferred elsewhere without a degree by June 2006. Eight percent had left the institution and did not enroll anywhere else within three years (table 6).  Table 1.-Degree attainment and persistence anywhere of 2003-04 beginning postsecondary students as of  Table 1.-June 2006, by first type of institution attended, degree plans first year, enrollment patterns, and  Table 1 Tables  Table 2.-Degree attainment and persistence anywhere of 2003-04 beginning postsecondary students as of  Table 2.-June 2006, by degree plans first year, transfer and degree plans, enrollment patterns, and student  Table 2 Tables  Table 2.-Degree attainment and persistence anywhere of 2003-04 beginning postsecondary students as of  Table 2.-June 2006, by degree plans first year, transfer and degree plans, enrollment patterns, and student  Table 2 Tables  Table 3.-Degree attainment and persistence anywhere of 2003-04 beginning postsecondary students as of Table 4.-June 2006, by type of first institution attended, degree plans first year, enrollment patterns, and  Tables  Table 3.-Degree attainment and persistence anywhere of 2003-04 beginning postsecondary students as of Table 4.-June 2006, by type of first institution attended, degree plans first year, enrollment patterns, and  Tables  Table 4. 10.4 \u2020 Not applicable. # Rounds to zero. NOTE: \"Degree\" includes certificates in vocational programs. Students who attained a degree and continued to be enrolled at the first institution are only included in the degree columns. Full-time enrollment is enrollment in 12 or more credits per term or 24 credits per year. Black includes African American, Hispanic includes Latino, American Indian includes Alaska Native, Pacific Islander includes Native Hawaiian, and Other includes respondents having origins in a race not listed. Pacific Islanders have been combined with Asians because of small sample sizes. Race categories exclude Hispanic origin unless specified. Dependent students were under age 24, unmarried, and had no dependents of their own in 2003. Family income of dependent students is the annual income of the parents in 2002. Categories represent the income quartile ranges of all dependent student families. Totals include students in private not-forprofit less-than-2-year institutions; sample size was too small to show as a separate category. This "}, {"section_title": "THIS PAGE INTENTIONALLY LEFT BLANK", "text": ""}, {"section_title": "Figures and Tables", "text": ""}, {"section_title": "Highest degree", "text": "Attained degree at the first institution Retention at the first institution through 2006 through 2006 Table 5.-Degree attainment and retention at the first institution attended of 2003-04 beginning Table 5.-postsecondary students as of June 2006, by degree plans first year, transfer and degree plans, Table 5.-enrollment patterns, and student characteristics: Students beginning at public 2-year institutions Indicates whether the student was financially dependent or independent for federal financial aid purposes in 2003-04, and subcategories of independent students based on marital status and whether they had legal dependents. Students were considered to be financially independent for federal financial aid purposes in 2003-04 if they met any of the following criteria: The student was 24 years old or older as of 12/31/2003. The student had legal dependents other than spouse. The student was married. The student was an orphan or ward of the court. The student was a veteran of the U.S. Armed Forces. The student was enrolled in a graduate or professional program (beyond a bachelor's degree). All other students under 24 were considered to be financially dependent on their parents unless they could demonstrate that they were receiving no parental support and were classified as independent by a financial aid officer using professional judgment. For the independent student subcategories, \"unmarried\" and \"single\" include students who were separated, divorced, or widowed. \"Married\" students include those with or without dependents."}, {"section_title": "Dependent student family income DEPINC", "text": "Indicates dependent student parents' total income for 2002. Based on amounts reported in the financial aid application, estimates by students in the student interview, and stochastic imputation. Federal financial aid need analysis uses the family income in the calendar year prior to the academic year of enrollment. The low and high categories used in this report are approximately the lowest and highest 25 percent of the income range for all dependent student families. Less than $32,000 $32,000-59,999 $60,000-91,999 $92,000 or more"}, {"section_title": "Degree plans first year DGPLNY1", "text": "Student's degree plans during the 2003-04 academic year. Based first on the 2004 interview question \"What degree were you working on at [the NPSAS sample school]?\" If this was not available, the program reported by the NPSAS institution was used. If neither was available, the program reported by the student in the financial aid application was used."}, {"section_title": "None", "text": "The student was not working on any degree."}, {"section_title": "Certificate", "text": "The student was working on a vocational certificate or diploma below an associate's degree. Associate's degree The student was working on an associate's degree. Bachelor's degree The student was working on a bachelor's degree, including those enrolled at less-than-4-year institutions who planned to transfer to a 4-year institution to complete a bachelor's degree."}, {"section_title": "Transfer and degree plans DGTRNY1", "text": "Indicates whether students at less-than-4-year institutions in 2003-04 planned to transfer to a 4-year institution and whether they had plans to complete a certificate or associate's degree. Based on the 2004 interview questions about reasons for enrolling at the NPSAS sample school and plans to transfer in order to pursue a bachelor's degree. Degree, no transfer The student's reason for enrolling was to complete a certificate or associate's degree, but not to transfer to a 4-year institution."}, {"section_title": "Degree and transfer", "text": "The student's reasons for enrolling were to complete a certificate or associate's degree, and to transfer to a 4-year institution. No degree, transfer The student's reason for enrolling was to transfer to a 4-year institution, but not to complete a certificate or associate's degree. No degree, no transfer The student's reasons for enrolling did not include completing a certificate or associate's degree or transfer to a 4-year institution."}, {"section_title": "Attendance intensity through June 2006 ENINPT3Y", "text": "Indicates the pattern of full time, part time, or mixed full time and part time attendance intensity in the months enrolled at any postsecondary institution between July 2003 and June 2006. Full-time generally means enrollment in 12 or more credit hours per term or 24 credit hours per academic year. Students enrolled full time in an academic year except for summer months (which may have been part time) were considered to be always full time. Always full time The student attended full time in all months while enrolled."}, {"section_title": "Always part time", "text": "The student attended part time in all months while enrolled."}, {"section_title": "Mixed", "text": "The student attended full time in some months and part time in some months while enrolled."}, {"section_title": "Recent (2003) high school graduates enrolled full time fall 2003 FALLHSFT", "text": "Indicates categories of beginning students who graduated from high school with a regular diploma in 2003, were enrolled full time in the fall of 2003, and were working on a degree in the first year (DGPLNY1). "}, {"section_title": "Certificate plans", "text": ""}, {"section_title": "Level of first institution FLEVEL", "text": "The highest degree or award offered in any program by the first institution attended."}, {"section_title": "4-year", "text": "Institutions that can award bachelor's degrees or higher degrees. Some of these institutions may also offer associate's degrees or certificates."}, {"section_title": "2-year", "text": "Institutions offering certificate or associate's degree programs, or 2-year programs that fulfill part of the requirements for a bachelor's degree or higher at 4-year institutions. These institutions do not award bachelor's degrees. Less-than-2-year At least one of the programs offered at these institutions is 3 months or longer, and produces a terminal award or certificate. No program at these institutions lasts longer than 2 years."}, {"section_title": "Doctorate granting status of first institution FSECDOC", "text": "Indicates whether the first 4-year institution attended did or did not grant doctorates. Less-than-4-year institutions are not included in this variable."}, {"section_title": "Doctorate-granting", "text": "Non-doctorate-granting 4-year"}, {"section_title": "Type of first institution FSECTOR", "text": "The level and control of the first institution attended by the student in 2003-04, based on the classification in the 2003 IPEDS Institutional Characteristics file. Control concerns the source of revenue and control of operations (public, private not-for-profit, private for-profit) and level concerns the highest degree or award offered by the institution in any program. 4-year institutions award at least a bachelor's degree; 2-year institutions award at least an associate's degree; less-than-2-year institutions award certificates or other credentials in vocational programs lasting less than 2 years. In most cases, the first institution attended in 2003-04 is also the institution at which the student was sampled for NPSAS:04. However, if the student was enrolled at another institution for more than 3 months in 2003-04 prior to enrolling at the NPSAS sample institution, the prior institution was classified as the first institution attended. Private not-for-profit less-than-2-year institutions are included in the overall totals and totals for less-than-2-year institutions, but the sample size was too small to show as a separate category. "}, {"section_title": "Highest education of parents PAREDUC", "text": "Indicates the highest level of education completed by the student's mother or father, whoever had the highest level. The variable was aggregated to the following categories in this report: High school or less Neither parent earned more than a high school diploma or equivalent or they did not complete high school. Some postsecondary At least one parent received some postsecondary education, but did not earn a bachelor's degree. Bachelor's degree or higher At least one parent attained a bachelor's or advanced degree."}, {"section_title": "Persistence anywhere through June 2006 PRAT3Y", "text": "Indicates whether the student had attained any degree and/or was still enrolled at any postsecondary institution as of American Indian/Alaska Native A person having origins in any of the original peoples of North America and who maintains cultural identification through tribal affiliation or community recognition. More than one race/Other A person having origins in more than one race or in a race not listed above."}, {"section_title": "Transfer status through June 2006 TFNUM3Y", "text": "Indicates whether the student left one postsecondary institution and then enrolled in another postsecondary institution at any time before June 2006. The student may or may not have transferred any credits between the institutions. Some students transferred more than once. Students who enrolled in more than one institution at the same time are not considered to be transfers."}, {"section_title": "Never transferred", "text": "The student never left one institution and enrolled in another before June 2006."}, {"section_title": "Transferred", "text": "The student left one or more institutions and enrolled in another before June 2006."}, {"section_title": "Type of associate's degree UGDEGAA", "text": "Student's associate's degree type during 2003-04 academic year. Based on the 2004 student interview or the type of program reported by the institution attended."}, {"section_title": "Applied fields", "text": "The student was working on an applied associate's degree in occupational or technical programs that are generally terminal degrees. General education/transfer The student was working on an academic associate's degree in general education or in preparation for transfer to a 4-year institution. Unlike the typical retention and attainment studies that follow entering freshmen at a single institution, BPS:04/06 allows researchers and others to study the persistence and attainment of students who enroll in multiple institutions. BPS:04/06 also represents a departure from previous longitudinal studies of high school age cohorts: it starts with a cohort of individuals beginning their postsecondary studies, regardless of when they completed high school. Consequently, BPS:04/06 data include information about nontraditional postsecondary students who have delayed continuing their education after high school due to military service, family responsibilities, or other reasons. BPS:04/06 is a follow-up to the 2003-04 National Postsecondary Student Aid Study (NPSAS:04), a recurring survey of a nationally representative, cross-sectional sample of postsecondary students. The NPSAS surveys have been implemented every 3 or 4 years since 1986-87, and the data for the most recent survey (for the 2003-04 school year) were released in early 2005. BPS:04/06 represents the first follow-up of the NPSAS:04 FTB students. An additional follow-up interview will occur in 2009. The BPS:04/06 data collection effort involved interviews of both respondents and nonrespondents to the NPSAS:04 study. The interview took place in one of three ways: selfadministered through a web-based instrument, interviewer-administered via computer-assisted telephone interviewing (CATI), or interviewer-administered in person via computer-assisted personal interviewing (CAPI)."}, {"section_title": "Data Sources for BPS:04/06", "text": "Because BPS:04/06 is based on NPSAS:04, the sources for NPSAS:04 are relevant to BPS:04/06. Information for NPSAS:04 was obtained from several sources, including the following: \u2022 Student Records: Data from institutional financial aid and registrar records at the institutions currently attended. These data were entered at the institution by institution personnel or field data collectors in 2003-04 using a computer-assisted data entry (web-CADE) program or directly downloaded to a data file. \u2022 NPSAS Student Interview: Data collected directly from sampled students via webbased self-administered or interviewer-administered questionnaires. Additional data sources for BPS:04/06 include the following: \u2022 BPS Student Interview: Data collected directly from sampled students via web-based self-administered or interviewer-administered questionnaires. \u2022 SAT File: Student SAT data from the College Board. \u2022 ACT File: Student ACT data from ACT. \u2022 National Student Clearinghouse (NSC): A central repository and single point of contact for the collection of postsecondary enrollment, degree, and certificate records on behalf of participating postsecondary institutions."}, {"section_title": "Sample Design", "text": "This section provides an overview of the sample design, including the respondent universe and the statistical methodology."}, {"section_title": "Respondent Universe", "text": "The respondent universe for the BPS:04/06 full-scale study consisted of all students who began their postsecondary education for the first time during the 2003-04 academic year at any postsecondary institution in the United States or Puerto Rico that was eligible for NPSAS:04. The BPS:04/06 sample students included potential FTBs from NPSAS:04, which included confirmed FTBs from the NPSAS:04 student interview, respondents to NPSAS:04 who were initially determined to be non-FTBs but were potentially FTBs based on data from other sources, and NPSAS:04 nonrespondents. The institution and student universes are defined in greater detail in the subsections that follow."}, {"section_title": "Institution Universe for NPSAS:04", "text": "The institutions eligible for NPSAS:04 were required during the 2003-04 academic year to meet all the requirements for distributing federal Title IV aid, including \u2022 offering an educational program designed for persons who have completed a high school education; \u2022 offering at least one academic, occupational, or vocational program of study lasting at least 3 months or 300 clock hours; \u2022 offering courses that are open to more than the employees or members of the company or group (e.g., union) that administers the institution; and \u2022 being located in the 50 states, the District of Columbia, or Puerto Rico. Institutions providing only vocational, recreational, or remedial courses or only in-house courses for their own employees were excluded. U.S. service academies were excluded because of their unique funding/tuition base. The institutional sampling frame for NPSAS:04 was constructed from the 2000-01 Integrated Postsecondary Education Data System (IPEDS) Institutional Characteristics (IC) file and header files, and the 2000 Fall Enrollment file. The sample of institutions was freshened using the 2002-03 IPEDS, to include a sample of newly formed institutions. Records on the IPEDS files that did not represent NPSAS-eligible institutions were deleted. Hence, records that represented central offices, U.S. service academies, or institutions located outside the U.S. were deleted. The above institutional eligibility conditions are consistent with previous NPSAS studies with two exceptions. First, the requirement of being eligible to distribute Title IV aid was implemented beginning with NPSAS:2000. 1 Second, the previous NPSAS studies excluded institutions that only offered correspondence courses. NPSAS:04 included such institutions if they were eligible to distribute Title IV student aid."}, {"section_title": "Student Universe for NPSAS:04 and BPS:04/06", "text": "Students eligible for the BPS:04/06 full-scale study were eligible both to participate in NPSAS:04 and identified as FTB students at NPSAS sample institutions in the 2003-04 academic year. Consistent with previous NPSAS studies, the students eligible for the NPSAS:04 full-scale study were those enrolled in eligible institutions and who satisfied all the following eligibility requirements: \u2022 were enrolled in either (1) an academic program; (2) at least one course for credit that could be applied toward fulfilling the requirements for an academic degree; or (3) an occupational or vocational program that required at least 3 months or 300 clock hours of instruction to receive a degree, certificate, or other formal award; and \u2022 were not concurrently or solely enrolled in high school, a General Educational Development (GED), or other high school completion program. NPSAS-eligible students who enrolled in a postsecondary institution for the first time during the NPSAS year (July 1, 2003-June 30, 2004) after completing high school were considered pure FTBs and were eligible for BPS:04/06. Those NPSAS-eligible students who had enrolled for at least one course after completing high school but had never completed a postsecondary course before the 2003-04 academic year were considered effective FTBs and were also eligible for the BPS:04/06 full-scale study. In the BPS:04/06 full-scale data collection, we sampled from both (a) NPSAS:04 respondents who were identified as (pure or effective) FTBs and (b) NPSAS:04 nonrespondents who were potential (pure or effective) FTBs. 2"}, {"section_title": "Statistical Methodology", "text": ""}, {"section_title": "Institution Sample for NPSAS:04", "text": "The institutional sampling frame for NPSAS:04 was constructed from the 2000-01 and 2001-02 IPEDS IC file and header files, and the 2000 and 2001 Fall Enrollment files. Records on the IPEDS files for NPSAS-ineligible institutions were deleted. NPSAS-ineligible institutions included U.S. service academies, institutions located outside the U.S. and Puerto Rico, and institutions offering no programs of study lasting at least 3 months or 300 clock hours. The IPEDS files were then cleaned to resolve the following types of problems: \u2022 missing enrollment data, because these data are needed to compute measures of size for sample selection; and \u2022 unusually large or small enrollment, especially if imputed, because if incorrect, these data would result in inappropriate probabilities of selection and sample allocation. Table B-1 presents the allocation of the NPSAS:04 institutional sample to the nine institutional sampling strata. The number of sample institutions was 1,670, accounting for historical rates of participation in Computer Assisted Data Entry (CADE), institution eligibility rates, and rates with which sample institutions provide student lists for sample selection. Table  B-1 also shows the resulting institutional sample sizes, which included 1,360 institutions providing student enrollment lists. A direct, unclustered sample of institutions was selected for NPSAS:04, like the sample selected for NPSAS:2000 and NPSAS:96, rather than a clustered sample used for earlier NPSAS studies. In addition, to allow analysis of the effects of state tuition and student aid policies in individual states, representative samples of institutions were selected from three strata-public 2year institutions; public 4-year institutions; and private not-for-profit 4-year institutions-in each of the following 12 states: California, Connecticut, Delaware, Georgia, Illinois, Indiana, Minnesota, Nebraska, New York, Oregon, Tennessee, and Texas. "}, {"section_title": "Student Sample for NPSAS:04", "text": "The NPSAS:04 student sampling design was based on fixed stratum sampling rates, not fixed stratum sample sizes. The design used two student sampling strata for undergraduates (FTB and other undergraduates), three student sampling strata for graduate students (master's, doctoral, and other graduate students), and one stratum for first-professional students. Differential sampling rates were used for the three types of graduate students to get adequate representation of students pursuing doctoral degrees and to limit the sample size for \"other\" graduate students, who are of limited inferential interest. The NPSAS:04 student interview data collection procedures were expected to produce about a 70 percent student response rate based on historical experience. The sample sizes were determined using prior NPSAS experience regarding institutional CADE response rates and sample student eligibility rates. A total of 109,210 sample students were selected for NPSAS:04, including 49,410 potential FTBs; 47,680 other undergraduate students; and 12,120 graduate and first-professional students (see table B-2). Postsecondary institutions are sometimes unable to accurately identify their FTB students. Therefore, students classified as potential FTBs for sampling for NPSAS:04 included both pure FTBs who began their postsecondary education for the first time during the NPSAS year and effective FTBs who had enrolled in but not completed a postsecondary class prior to the NPSAS year. The NPSAS sampling rates for students identified as FTBs and other undergraduate students by the sample institutions were adjusted to yield the desired sample sizes after accounting for expected false positive and false negative FTB rates. The false positive and false negative FTB rates experienced in NPSAS:96 were used to set appropriate sampling rates for NPSAS:04. 3"}, {"section_title": "Table B-2. Numbers of NPSAS:04 sampled and eligible students and response rates, by type of institution and student type: 2004", "text": "Responding students 1,2 Type of institution and student type 3 Sampled students "}, {"section_title": "BPS:04/06 Full-Scale Sample", "text": "The BPS:04/06 student sample consisted of four groups according to their base-year response status: 1. students who responded to the NPSAS:04 student interview who were determined to be FTBs; 2. students who responded to the NPSAS:04 student interview who were initially determined to be non-FTB other undergraduates, but who were potentially FTBs based on data from other sources; 3. a subsample of potential FTBs who were NPSAS:04 study respondents and student interview nonrespondents; and 4. a subsample of potential FTBs who were NPSAS:04 study nonrespondents. Multiple data sources were used to provide information regarding a student's FTB status during the NPSAS year, including the NPSAS:04 student interview, records from the student's base-year institution via CADE, and federal financial aid sources. The data elements that were examined to estimate a student's likelihood of being an FTB and to construct the frame for the BPS:04/06 sample included the following: \u2022 FTB status from the institution enrollment lists used for NPSAS:04 student sampling; \u2022 FTB status from the CPS; 4 \u2022 FTB status from student-level data obtained from institutional records via CADE; \u2022 student reports (obtained during the NPSAS:04 interview) indicating that they were FTBs during the 2003-04 academic year; \u2022 year of high school graduation; \u2022 receipt of Stafford loan (date loan was first received and number of years loan was received); \u2022 receipt of Pell grant (date grant was first received and number of years grant was received); and \u2022 undergraduate class level. Using the above indicators, an index was created to estimate the likelihood of being an FTB. A positive index value was assigned to cases with more positive indicators than negative indicators. For example, a student for whom all of the indicators listed above suggested that the student was an FTB were assigned an index value of 8. This index was then used to create a set of decision rules to identify which cases would be included or excluded from the follow-up sample, and which among those included would require additional eligibility screening. The determination of \"low,\" \"medium,\" and \"high\" likelihood of being an FTB differed for base-year study respondents and base-year study nonrespondents because more data elements were available for the base-year study respondents. Base-year study respondents were considered to have a \"low\" likelihood of being an FTB if (1) they were not identified as a potential FTB based on CADE or CPS data, (2) they had a negative index value, or (3) they had any Stafford loans or Pell grants that began prior to 2003 (indicating enrollment prior to the NPSAS year). Students with a \"low\" likelihood of being an FTB were excluded from the BPS sample. If the index was between 0 and 2, the student was classified as having a \"medium\" likelihood of being an FTB. If the index was 2 or more, then the student was classified as having a \"high\" likelihood of being an FTB. Base-year study nonrespondents had very little extant data. Students were considered to have a \"low\" likelihood of being an FTB if they were not identified as a potential FTB by either CADE or CPS. These students were excluded from the BPS sample. Students who were identified as a potential FTB from CADE (but not CPS) were classified as having a \"medium\" likelihood of being an FTB. Students who had an indicator from CPS that they were an FTB were classified as having a \"high\" likelihood of being an FTB. The NPSAS:04 sample yielded the numbers of students below who either indicated that they were FTBs during the interview and had other institutional records or federal financial aid sources that supported this, or were identified as potential FTBs based on institutional records or federal financial aid sources. 1. Approximately 24,990 students responding to the student interview indicated that they were FTBs during the 2003-04 academic year. Based on a review of the FTB status indicators above, approximately 21,170 of these were identified for inclusion in the follow-up sample. Of the approximately 21,170 included in the follow-up sample, approximately 19,800 had other data that strongly supported their FTB status, and approximately 1,370 of these students had some indications that they were not FTBs; these potential false positives were rescreened during the BPS:04/06 interview to confirm their status. The remaining approximately 3,820 of the original 24,990 were identified for exclusion from the follow-up when multiple data sources confirmed that they could not have been FTBs during the NPSAS year. 2. Approximately 1,420 students were not originally classified as FTBs, but were potential FTBs based on CPS data or because they had a high school graduation date in 2003 or 2004. These potential false negatives were also expected to be screened during the BPS:04/06 interview to verify their status. 3. Approximately 8,860 students did not respond to the student interview but were classified as NPSAS:04 study respondents and were potential FTBs based on CADE or CPS data, more positive than negative indicators among the other variables, and any Stafford loans or Pell grants that began after 2003. 4. Approximately 720 NPSAS:04 sample members were potential FTBs based on information from CADE or CPS, but did not respond to the student interview and did not have sufficient data to be classified as study respondents. The sample distribution for BPS:04/06 is summarized in table B-3. As noted earlier, approximately 9,580 NPSAS:04 student interview nonrespondents were classified as potential FTBs. Of these, approximately 8,860 were NPSAS:04 study respondents who did not respond to the student interview and approximately 720 were NPSAS:04 study nonrespondents. NPSAS:04 student interview nonrespondents who were potential FTBs were subsampled for follow-up to improve upon the nonresponse bias reduction achieved through the nonresponse adjustments incorporated into the NPSAS:04 statistical analysis weights. For these students, sampling strata were developed from the following characteristics: \u2022 likelihood of being an FTB (medium, high); and \u2022 tracing outcome (located, not located). 5 Stratification by tracing outcome and the likelihood of being an FTB was used to oversample the students most likely to be located and eligible for the study. The frame was also sorted by institutional sector to ensure representativeness of the sample. A stratified sample of 500 NPSAS:04 student interview nonrespondents was selected with probabilities proportional to their NPSAS:04 sampling weights. Table B-4 summarizes the BPS:04/06 counts of students eligible for the sample and the sample sizes, including the allocation of the subsample of 500 cases to the two groups of NPSAS:04 student interview nonrespondents. Given that the NPSAS:04 sampling weights were available for all student interview nonrespondents, they served as the basis for computing the BPS:04/06 analysis weights. Therefore, selection of the NPSAS:04 student interview nonrespondents with probabilities proportional to these weights was used to reduce the overall unequal weighting effects for the sample. NOTE: Detail may not sum to totals because of rounding. The likelihood of being a first-time beginner (FTB) was determined from student financial aid data and institutional record (computer-assisted data entry) data and based on the number and type of indicators suggesting a student was an FTB. The location information was based on whether the advance tracing information from BPS:04/06 either confirmed the existing telephone number or yielded a new telephone number. Eligibility rates were assumed to be lower for NPSAS:04 study nonrespondents because less information was available for these students. SOURCE: U.S. Department of Education, National Center for Education Statistics, 2004 National Postsecondary Student Aid Study (NPSAS:04) and 2004/06 Beginning Postsecondary Students Longitudinal Study (BPS:04/06). As listed above, several data sources were used to estimate a student's likelihood of being an FTB prior to the start of first follow-up data collection. After data collection ended, logistic regression models for predicting eligibility among BPS nonrespondents were developed using data from BPS:04/06 respondents and the variables available for the BPS frame construction (date of birth, dates the student began receiving Stafford loans or Pell grants, FTB status according to the institution, CPS, or CADE, and institutional sector). All BPS:04/06 nonrespondents who had responded to the NPSAS:04 interview and were classified as FTB were initially classified as eligible for BPS. Separate logistic regression models were fitted for each of the remaining sampling groups (NPSAS:04 respondents who were not initially classified as FTB and NPSAS:04 nonrespondents). At the conclusion of the modeling, 99 percent (4,480) of the nonrespondents were predicted to have a high probability of being eligible for BPS. Added together with the eligible respondents to the BPS interview, a total of 22,180 sample members were initially classified as eligible for BPS. One additional source of data on the BPS:04/06 sample, the NSC Tracker (www.studentclearinghouse.org), was obtained following completion of full-scale data collection and the modeling described above to facilitate imputation of key variables. However, as an additional check on the eligibility of the BPS:04 sample, the Tracker data were also used in combination with interview and other extant data to verify the eligibility status of all sample members retained for inclusion in the cohort. An analysis of enrollment and financial aid data within and across data sources identified a subset of the sample who, based on the results, were determined to be ineligible for membership in the BPS:04 cohort. Table B-5 presents the distribution of these cases by type of student and BPS:04/06 interview response status. The large majority of cases come from the group of NPSAS:04 respondents determined during that base-year interview to be FTBs based on a series of questions in the eligibility section. The distribution of final eligible FTBs is shown in the top half of table B-5. "}, {"section_title": "Perturbation", "text": "To protect the confidentiality of NCES data that contain information about specific individuals, BPS:04/06 data were subject to perturbation procedures to minimize disclosure risk. Perturbation procedures, which have been approved by the NCES Disclosure Review Board, preserve the central tendency estimates, but may result in slight increases in nonsampling errors."}, {"section_title": "Imputation", "text": "All variables with missing data used in this report as well as those included in the related Data Analysis System (DAS) have been imputed. Item response rates were high for most of the items in the BPS:04/06 interview. However, BPS:04/06 nonrespondents who were determined to be eligible for BPS:04/06 required imputation of their BPS:04/06 data. BPS:04/06 sample members who were NPSAS:04 study nonrespondents also required imputation for NPSAS data. The following groups of students and types of items were imputed: \u2022 NPSAS:04 derived variables were imputed for the NPSAS:04 nonrespondents who were in the BPS:04/06 sample. \u2022 Students who were not FTBs based on NPSAS:04 interview data but were determined to be FTBs in BPS:04/06 received imputed data for NPSAS:04 interview items that were only administered to FTBs (e.g., attitudes, experiences, plans, etc.). \u2022 Scholastic Assessment Test (SAT)/ACT test scores, high school math courses, and other high school courses and grades were obtained from a merge with the ACT and SAT files. Information on math courses was also obtained in the BPS interview. Values were imputed for any without this information. \u2022 BPS:04/06 first follow-up interview data were imputed for cases with completed interviews with some missing items, abbreviated interviews with some missing sections, and cases who did not have a BPS interview. The imputation procedures employed a two-step process. First, the matching criteria and imputation classes that were used to stratify the dataset were identified such that all imputation was processed independently within each class. Second, the weighted sequential hot-deck process was implemented, 6 whereby missing data were replaced with valid data from donor records that match the recipients with respect to the matching criteria. Variables requiring imputation were not imputed simultaneously. Basic demographic variables with full information were imputed first. Then, variables with increasing levels of missing data were imputed using previously imputed variables in the determination of optimal matching criteria. The order in which variables were imputed was also determined to some extent by the substantive nature of the variables. For example, basic demographics (such as age) were imputed first, and these were used to process education variables (such as student level and enrollment intensity) that, in turn, were used to impute the financial aid variables (such as aid receipt and loan amounts). For variables with less than 5 percent missing data, the variables used for matching criteria were selected based on prior knowledge about the dataset and the known relationships between variables. For example, in almost all cases, the student's age and enrollment intensity (fulltime/part-time status) were used as matching variables in the imputation process. For variables with more than 5 percent missing data, a statistical process called Classification and Regression Tree (CART) was used to identify the matching criteria that were most closely related to the variable being imputed. CART (Breiman et al. 1984) is similar to Chi-Square Automatic Interaction Detection (CHAID) (Kass 1980) that was used for the imputation procedures in NPSAS:04. CART, however, is a nonparametric approach to forming imputation classes. This step produced a number of imputation classes that contain sets of donors used to impute recipients belonging to that class. Next, the imputation classes were used as input to a SAS macro that implemented the weighted sequential hot-deck procedure. Additionally, data were sorted within each imputation class to increase the chance of obtaining a close match between donor and recipient. The hotdeck process was sequential in that the search for donors occurred sequentially, starting with the recipient and progressing up and down the sorted file to find the set of eligible donors from which a random selection of one was made. The process was weighted because it incorporated the sample weight of each record in the search and selection routine. 7 In some cases, further intervention was needed to ensure accuracy and consistency of imputation, as determined by preexisting edit rules. For example, to impute the level of parents' education when it was known that the parents had some college but the specific education level was unknown, the potential pool of donors was limited to those with at least some college education to prevent imputing parents' education level as less-than-college. Account for the institution's probability of selection."}, {"section_title": "Institution multiplicity adjustment", "text": "Adjust the weights for institutions that had multiple chances of selection. Institution poststratification adjustment Adjust the institution weights to match population enrollment totals to ensure population coverage."}, {"section_title": "Institution nonresponse adjustment", "text": "Adjust the weights to compensate for nonresponding institutions."}, {"section_title": "Student sampling weight", "text": "Account for the student's probability of selection."}, {"section_title": "Student subsampling weight", "text": "Account for the subsampling of students on paper lists."}, {"section_title": "Student multiplicity adjustment", "text": "Adjust the weights for students who attended more than one institution. Student unknown eligibility adjustment Adjust the weights of nonresponding NPSAS students with unknown eligibility."}, {"section_title": "Student subsampling adjustment", "text": "Adjust the weights of the subset of NPSAS CATI nonrespondents who were included in the BPS:04/06 sample Student trimming and smoothing adjustment Adjust the weights for outliers, to reduce the design effect due to unequal weighting Student poststratification adjustment Adjust the student weights to match known population enrollment and aid totals to ensure population coverage. "}, {"section_title": "Quality of Estimates", "text": ""}, {"section_title": "Unit Response Rates and Bias Analysis", "text": "The bias in an estimated mean based on respondents, R y , is the difference between this mean and the target parameter, \u03c0, i.e., the mean that would be estimated if a complete census of the target population was conducted and everyone responded. This bias can be expressed as follows: The estimated mean based on nonrespondents, NR y , can be computed if data for the particular variable are available for most of the nonrespondents. The true target parameter, \u03c0, can be estimated for these variables as follows: where \u03b7 is the weighted unit (or item) nonresponse rate. For the variables that are from the frame, rather than from the sample, \u03c0 can be estimated without sampling error. The bias can then be estimated as follows: or equivalently: This formula shows that the estimate of the nonresponse bias is the difference between the mean for respondents and nonrespondents multiplied by the weighted nonresponse rate. Nonresponse bias could come from a variety of sources, including failure of the institution to provide lists for NPSAS:04, student nonresponse to BPS:04/06, and item nonresponse to the BPS:04/06 interview."}, {"section_title": "Institution-Level Bias Analysis", "text": "An institution respondent is defined as any sample institution for which \u2022 a student list was received that was sufficient for selecting a sample; or \u2022 a sample of students was selected from an NSLDS file of Stafford loan and Pell grant recipients in cases where such a student file was believed to include at least 85 percent of the student population. Of the 1,630 eligible NPSAS:04 sample institutions, 1,360 were respondents (84 unweighted percent and 80 weighted percent). The institution weighted response rate is also below 85 percent for six of the nine types of institutions. The weighted response rates by type of institution range from 70 percent for public 4-year non-doctorate-granting institutions to 93 percent for private not-for-profit less-than-4-year institutions. A nonresponse bias analysis was conducted for all institutions and for the six types of institutions with a weighted response rate below 85 percent. The nonresponse bias was estimated for variables known (i.e., non-missing) for most respondents and nonrespondents. Extensive data from IPEDS are available for all institutions . The following variables were used: 9 \u2022 type of institution; 10 \u2022 Carnegie classification; \u2022 degree of urbanization; \u2022 Bureau of Economic Analysis Code OBE region; \u2022 historically Black college or university indicator; \u2022 percentage of students receiving federal grant aid; \u2022 percentage of students receiving state/local grant aid; \u2022 percentage of students receiving institutional grant aid; \u2022 percentage of students receiving student loan aid; \u2022 percentage of students enrolled: Hispanic; \u2022 percentage of students enrolled: Asian or Pacific Islander; \u2022 percentage of students enrolled: Black, non-Hispanic; \u2022 total undergraduate enrollment; \u2022 male undergraduate enrollment; \u2022 female undergraduate enrollment; \u2022 total graduate/first-professional enrollment; \u2022 male graduate/first-professional enrollment; and \u2022 female graduate/first-professional enrollment. First, for the institution-level variables listed above, the nonresponse bias was estimated and tested to determine if the bias was significant at the 5 percent level. Second, nonresponse adjustments were computed, and the variables listed above were included in the nonresponse models. The nonresponse adjustments (see the weighting section of this appendix) were designed to significantly reduce or eliminate nonresponse bias for variables included in the models. Third, after the weights were computed, any remaining bias was estimated for the variables listed above, and statistical tests were performed to check the remaining significant nonresponse bias. As shown in table B-7, the institution weighting adjustments eliminated some, but not all, bias. For all types of institutions combined, about 6 percent of the variables showed statistically significant bias due to institution nonresponse prior to the nonresponse adjustment; the variables with significant bias were type of institution, degree of urbanization, OBE region, and graduate/first-professional enrollment. After the nonresponse weight adjustment, none of these variables had statistically significant bias. The results varied by type of institution. Before weighting for public less-than-2-year institutions, and public 2-year institutions, 6 percent and 7 percent, respectively, of the variable categories were significantly biased. Variables 11 with statistically significant bias before weight adjustment for these types of institutions were percentage of students enrolled who are Black non-Hispanic, OBE region, and percentage receiving institutional grant aid. After the weighting adjustment, no significant bias remained for the variables analyzed for these types of institutions. None of the variables showed statistically significant bias either before or after the nonresponse adjustment for the private not-for-profit 4-year non-doctorate granting institutions. For the other types of institutions, the percentage of variable categories with significant bias decreased after weight adjustments, but was not completely eliminated. For public 4-year non-doctorate-granting institutions, variables with statistically significant bias prior to the nonresponse adjustment were whether the institution is a historically Black college or institution, total undergraduate enrollment, total graduate/first-professional enrollment, male graduate/firstprofessional enrollment, and female graduate/first-professional enrollment; after the nonresponse adjustment, the bias was reduced for all of the variables but was still statistically significant for total graduate/first-professional enrollment and female graduate/first-professional enrollment. For private not-for-profit 4-year non-doctorate-granting institutions, OBE region had statistically significant bias prior to nonresponse adjustment, but this bias was reduced and was no longer statistically significant after nonresponse adjustment; one level of variable for this type of institution, the percentage receiving student loan aid, had statistically significant bias after the nonresponse adjustment, but was not statistically significant before the adjustment. For private for-profit less-than-2-year institutions, the percentage receiving student loan and total undergraduate enrollment showed statistically significant biases prior to the nonresponse weight adjustment; after the adjustment, bias for the total undergraduate enrollment was reduced and no longer significant, but the bias for the percentage receiving student loans was still statistically significant. In summary, significant bias was reduced for the variables known for most respondents and nonrespondents, which are considered to be some of the more analytically important variables and are correlated with many of the other variables. Further details of the institution-level bias analysis can be found in the 2004 National Postsecondary Student Aid Study (NPSAS:04) Full-Scale Methodology Report (Cominole et al. 2006)."}, {"section_title": "Student-Level Bias Analysis", "text": "As mentioned in the sample design section above, a student respondent was defined as any sample member who was determined to be eligible for the study and had valid data for a selected set of key analytical variables. The BPS:04/06 analysis file contains all eligible sample members. Nonrespondents to the BPS:04/06 interview appear on the analysis file with imputed data. Of the 18,640 eligible sample students, 14,900 responded, resulting in an unweighted response rate of 80 percent and a weighted response rate of 77 percent. Since these rates are less than 85 percent, a nonresponse bias analysis was conducted. The nonresponse bias was estimated for variables known for most respondents and nonrespondents. Some of these variables were known for all sample members, and the remaining were only known for federally aided students. These variables are included on the DAS and are listed below. For all sample members: \u2022 type of institution; \u2022 region; \u2022 institution total enrollment; \u2022 CPS match (yes/no); \u2022 Pell grant recipient (yes/no); and \u2022 Stafford loan recipient (yes/no). For federally aided students: \u2022 Pell grant amount; and \u2022 Stafford loan amount. The nonresponse bias was estimated for the above variables, and tested (adjusting for multiple comparisons) to determine if the bias was significant at the 5 percent level. This bias analysis was conducted for the entire sample and for each of the institutional strata. As shown in table B-8 for the entire sample, the bias was significant for many of these variables; almost half of the categories had significant bias. However, the relative bias was generally very small; for 7 of the 18 significant variables the relative bias was less than 5 percent, and for another 5 the relative bias was less than 10 percent. This analysis looks at the difference between respondents and nonrespondents. However, a separate weight adjustment for unit nonresponse was not made because the data file contains both respondents and nonrespondents (with imputed data). As a result, the bias after nonresponse adjustment was not compared or evaluated. Because all of the nonrespondents were included in the data file, there was no nonresponse bias for the variables listed in table B-8. As noted earlier, the variables used in this analysis were known for almost all of the sample members (nonrespondents as well as nonrespondents). Only the Pell amount and Stafford amount variables had any missing values. Of the 18,640 eligible students in BPS:04/06, the Pell amount variable was missing for 27 students and was imputed during NPSAS:04 for 40 students. The Stafford amount variable was missing for 27 students and was imputed during NPSAS:04 for 87 students. Table B-9 summarizes the bias analysis for each institution type. For the total BPS:04 cohort, approximately 45 percent of the variables examined in table B-8 had statistically significant bias, but the mean and median relative bias was low: less than 3 percent. The percentage of variables with statistically significant bias varied from 0 to 22 percent, by type of institution. The public, less-than-2-year institutions and public, 4-year, doctorate-granting institutions had the largest percentage of variables with significant bias due to student nonresponse; however, the mean relative bias was less than 5 percent for these categories. As noted earlier, all respondents and nonrespondents are included on the BPS:04/06 data file, which eliminates bias due to student nonresponse."}, {"section_title": "Item-Level Bias Analysis", "text": "Another analysis examined the items with response rates less than 85 percent. Item response rates (RRI) are calculated as the ratio of the number of respondents for whom an inscope response was obtained (I x for item x) to the number of respondents who are asked to answer that item. The number asked to answer an item is the number of unit-level respondents (I) minus the number of respondents with a valid skip item for item x (V x ). When an abbreviated questionnaire is used to convert refusals, the eliminated questions are treated as item nonresponse (U.S. Department of Education 2003). A student is defined to be an item respondent for an analytic variable if that student has data for that variable from any source, including logical edits. Item-level bias analysis was conducted, and none of the items used in the First Look were found to have weighted item response rates less than 85 percent. A more detailed bias analysis of items in the BPS:04/06 interview will be conducted for the 2004/06 Beginning Postsecondary Students Longitudinal Study (BPS:04/06) Methodology Report (Cominole et al. 2007) (hereinafter referred to as BPS:04/06 Methodology Report). For additional information on item nonresponse and bias analysis refer to the BPS:04/06 Methodology Report. A byproduct of the imputation (described in the imputation section of this appendix) is the reduction or elimination of item-level nonresponse bias. Imputation reduces or eliminates nonresponse bias by replacing missing data with statistically reasonable values. Missing data and the associated nonresponse bias for variables such as other grants, dependent student income, and independent student income are usually non-ignorable (i.e., the respondents' distribution patterns differ from those in the full population). Therefore, replacing missing data with reasonable values produces imputed sample distributions that resemble full population distributions, thus reducing, if not eliminating, nonresponse bias. The use of carefully constructed imputation classes, donor-imputee matching criteria, and random hot-deck searches within imputation cells are all designed to ensure that imputed data are reasonable and that the nonresponse bias is ignorable within the imputation classes. The effectiveness of imputation implemented to reduce item nonresponse bias will be presented in the forthcoming BPS:04/06 Methodology Report. at two stages of sampling. The NPSAS and BPS:04/06 application of the method incorporated the finite population correction factor at the first stage only where sampling fractions were generally high. At the second stage, where the sampling fraction was generally low, the finite population correction factor was set to 1.00."}, {"section_title": "Cautions for Analysts", "text": ""}, {"section_title": "Sources of Error", "text": "The estimates in this report are subject to sampling and nonsampling errors. Nonsampling errors are due to a number of sources, including but not limited to nonresponse, coding and data entry errors, misspecification of composite variables, and inaccurate imputations. In a study like BPS:04/06, there are multiple sources of data for some variables (CPS, CADE, Student Interview, etc.) and reporting differences can occur in each. Data swapping and other forms of perturbation, implemented to protect respondent confidentiality, can also lead to inconsistencies. Sampling errors exist in all sample-based datasets, including BPS:04/06. Estimates calculated from a sample will differ from estimates calculated from other samples even if all the samples used the same sample design and methods. The standard error is a measure of the precision of the estimate. In this tabulation, each estimate's standard error was calculated using bootstrap replication procedures and can be produced using the BPS DAS software."}, {"section_title": "Comparing BPS:04/06 Estimates to Prior BPS Estimates", "text": "Comparison of results with prior rounds of BPS requires compensation for three changes in the design of the base-year NPSAS survey over time and also for a change in how nonrespondents are handled in the BPS:04/06 data file. First, prior to NPSAS:04, institutions that only offered correspondence courses were not eligible for the NPSAS. NPSAS:04 included such institutions if they were eligible to distribute Title IV student aid. Second, for NPSAS:2000, the survey was restricted for the first time to institutions participating in Title IV student aid programs. According to the DAS for NPSAS:96, only about 1 percent of the sampled undergraduates were attending an institution not eligible to participate in Title IV aid programs. When students attending non-Title IV-eligible institutions were excluded from the NPSAS:96 sample, the percentage of undergraduates who received financial aid increased by less than 1 percent. This small change primarily affects comparisons of students enrolled in less-than-2-year and private for-profit institutions. When using the DAS from prior BPS studies for comparison to the BPS:04 cohort, analysts may want to filter cases in the prior studies (BPS:90 cohort, BPS:96 cohort) based on the variable that identifies whether the student was sampled from an institution that was eligible to participate in Title IV aid programs (T4ELIG). Finally, a design change in the NPSAS was made, beginning with NPSAS:90, to improve full-year estimates. NPSAS:90 sampled students who were enrolled at four discrete points in time: summer (August), fall (October), winter (February), and spring (June). Since implementation of NPSAS in 1993, institutions have been asked to provide one list that represented students enrolled at any time during the respective financial aid award year. In NPSAS:90, those students who were initially sampled in the fall could have been enrolled for the full academic year. The BPS:04/06 also differs from prior rounds of BPS in that the BPS:04/06 dataset contains data items and a positive analysis weight for all sample members who were determined to be eligible; this includes nonrespondents as well as respondents to the BPS:04/06 data collection. Nonrespondents to the interview appear on the data file with imputed data for all variables. In previous rounds of BPS, the nonrespondents appeared on the file but did not have data items and had a value of zero for the analysis weight."}, {"section_title": "Additional Notes on the Accuracy of Estimates", "text": "RTI conducted a bias analysis to determine if any variables were significantly biased due to institutional and student-level nonresponse. Several variables were found to have significant bias before weighting. The weighting procedures appear to have reduced the amount of significant bias for these variables. Additional information on the nonresponse bias analysis and weighting procedures can be found in the quality of estimates and weighting sections of this appendix."}, {"section_title": "Data Analysis System", "text": "The estimates presented in the report were produced using the BPS:04/06 Data Analysis System (DAS), a web-based software application that enables users to generate tables for most of the postsecondary surveys conducted by NCES. The DAS produces the design-adjusted standard errors necessary for testing the statistical significance of differences in the estimates. The DAS also contains a detailed description of how each variable was created, and includes question wording for items coming directly from an interview. With the DAS, users can replicate or expand upon the tables presented in this report. The output from the DAS includes the table estimates (e.g., percentages or means) the proper standard errors 12 and weighted sample sizes for the estimates. If the number of valid cases is too small to produce a reliable estimate (fewer than 30 cases), the DAS prints the message \"low-N\" instead of the estimate. In addition to tables, DAS users may conduct covariance analyses, either with Weighted Least Squares or Logistic regressions. Many options are available for output with the regression results. For example, a Winsor filter can be used to eliminate cases with extreme values by deleting a certain percentage of cases from the top and bottom of the range. For a description of all the options available, users should access the DAS website http://nces.ed.gov/dasolv2. If users are new to the DAS, the DAS Help Center provides on-line tutorials offering step-by-step instructions in how to use all the functions of the DAS: http://nces.ed.gov/dasol/help. "}, {"section_title": "Statistical Procedures", "text": ""}, {"section_title": "Differences Between Means", "text": "The descriptive comparisons were tested in this First Look using Student's t statistic. Differences between estimates are tested against the probability of a Type I error, 13 or significance level. The significance levels were determined by calculating the Student's t values for the differences between each pair of means or proportions and comparing these with published tables of significance levels for two-tailed hypothesis testing (p < .05). se E E t + + \u2212 = . (3) The estimates and standard errors are obtained from the DAS. If the comparison is between the mean of a subgroup and the mean of the total group, the following formula is used: where p is the proportion of the total group contained in the subgroup. 15 The estimates, standard errors, and correlations can all be obtained from the DAS. There are hazards in reporting statistical tests for each comparison. First, comparisons based on large t statistics may appear to merit special attention. This can be misleading since the magnitude of the t statistic is related not only to the observed differences in means or percentages but also to the number of respondents in the specific categories used for comparison. Hence, a small difference compared across a large number of respondents would produce a large t statistic."}]