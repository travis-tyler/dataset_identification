[{"section_title": "Abstract", "text": "Content-based medical image retrieval (CBMIR) is an active research area for disease diagnosis and treatment but it can be problematic given the small visual variations between anatomical structures. We propose a retrieval method based on a bag-ofvisual-words (BoVW) to identify discriminative characteristics between di\u21b5erent medical images with Pruned Dictionary based on Latent Semantic Topic description. We refer to this as the PD-LST retrieval. Our method has two main components. First, we calculate a topic-word significance value for each visual word given a certain latent topic to evaluate how the word is connected to this latent topic. The latent topics are learnt, based on the relationship between the images and words, and are employed to bridge the gap between low-level visual features and high-level semantics. These latent topics describe the images and words semantically and can thus facilitate more meaningful comparisons between the words. Second, we compute an overall-word significance value to evaluate the significance of a visual word within the entire dictionary. We designed an iterative ranking method to measure overall-word significance by considering the relationship between all latent topics and words. The words with higher values are considered meaningful with more significant discriminative power in di\u21b5erentiating medical images. We evaluated our method on two public medical imaging datasets and it showed improved retrieval accuracy and e ciency."}, {"section_title": "Introduction", "text": "Content-based medical image retrieval (CBMIR), which retrieves a subset of images that are visually similar to the query from a large image database, is the focus of intensive research (M\u00fcller et al., 2004; Cai et al., 2008; Akg\u00fcl et al., 2011; Kumar et al., 2013) . CBMIR provides the potential of having an e cient tool for disease diagnosis, by finding related prediagnosed cases and it can be used for disease treatment planning and management. In the past three decades, but in particular in the last decade, medical image data have expanded rapidly due to the pivotal role of imaging in patient management and the growing range of image modalities (Duncan and Ayache, 2000; Menze et al., 2014; Liu et al., 2015a,b) . Traditional text-based retrieval, which manually indexes the images with alphanumerical keywords , is unable to su ciently meet the increased demand from this growth. At the same time, advances in computer-aided content-based medical image analysis systems mean that there are methods that can automatically extract the rich visual properties/features to characterize the images e ciently (El-Naqa et al., 2004; Lehmann et al., 2004; Napel et al., 2010; Avni et al., 2011; Andr\u00e9 et al., 2012a; Xu et al., 2012; Jiang et al., 2014; Zhang et al., 2014b Zhang et al., , 2015d Liu et al., 2015c; Song et al., 2015a,b) .\nIn CBMIR research, the main challenge is to design an effective image representation so that images with visually similar anatomical structures are closely correlated. A number of research groups are working in this area (M\u00fcller et al., 2004; Zhang et al., 2010; Akg\u00fcl et al., 2011; Cai et al., 2012; Hanbury et al., 2012; Kumar et al., 2013; Jiang et al., 2015a) , and there is a trend to use a bag-of-visual-words (BoVW) for medical image representation (Castellani et al., 2010; Song et al., 2011c; CruzRoa et al., 2012; Kwitt et al., 2012; Foncubierta-Rodr\u00edguez et al., 2013; Liu et al., 2013a; Depeursinge et al., 2014; Zhang et al., 2015b ). The BoVW model represents an image with a visual word frequency histogram that is obtained by assigning the local visual features to the closest visual words in the dictionary. Rather than matching the visual feature descriptors directly, BoVW retrieval approaches compare the images according to the visual words that are assumed to have higher discriminative power (Foncubierta-Rodr\u00edguez et al., 2012; Tamaki et al., 2013 ). The BoVW model was proposed by Sivic and Zisserman (Sivic and Zisserman, 2003) and has been adopted by many researchers in non-medical domains such as computer vision (Li and Pietro, 2005; Yang et al., 2007; Bosch et al., 2008) , showing the advantages of describing local patterns over using global features only. This model has recently been applied to tackle the large-scale medical image retrieval problem (Jiang et al., 2015b; Zhang et al., 2015e) . In this study, we focus on a new BoVW-based retrieval for better retrieval accuracy and e ciency."}, {"section_title": "Related work", "text": "The aim of CBMIR is to extract visual characteristics of images to identify the level of similarity between two images. Feature extraction can be categorized into global-(GFM) and local-feature (LFM) models based on the scope of descriptors (Bannour et al., 2009) . The GFM extracts a single feature vector from the whole image and the LFM partitions the image into a collection of smaller regions, namely patches, and considers that each patch has its own importance in describing the whole image (Avni et al., 2011) . This patch-based model is particularly useful in medical image analysis since di\u21b5erent image regions can represent the anatomical structures that play di\u21b5erent and essential roles in medical imaging diagnosis (Tong et al., 2014; Zhang et al., 2013 Zhang et al., , 2014a .\nThe BoVW representation builds upon the LFM. Visually similar patches from di\u21b5erent images are assigned to the same code in a codebook. Then, the patch-code co-occurrence assignment can be used to describe the image features and to compute the similarity between images. The workflow of BoVW-based image retrieval can be generalized into three steps (Caicedo et al., 2009 ): feature extraction, BoVW construction and similarity calculation. Specifically, the LFM is used to extract a collection of local patch features from each image. The entire patch feature set computed from all images in the database is then grouped into clusters, with each cluster regarded as a visual word and the whole cluster collection considered as the visual dictionary. Then, all patch features in one image are assigned to visual words, generating a visual word frequency histogram to represent this image. Finally, the similarity between images is computed based on these frequency histograms for retrieval.\nIn this workflow, an important issue is the dictionary construction. The visual word in the dictionary corresponds to a group of visually similar patches. Normally, these words are obtained within the local patch feature space using unsupervised clustering methods, e.g., k-means (Andr\u00e9 et al., 2011; Yang et al., 2012) . These approaches often generate a redundant and noisy dictionary since they tend to accommodate all local patch feature patterns (Foncubierta-Rodr\u00edguez et al., 2013) , thus reducing the e\u21b5ects of the most crucial words and increasing the computational cost. Hence, it is preferable to remove the visual words that are less essential for the BoVW representation.\nTo ensure that only the meaningful feature patterns are included, the supervised clustering method of Bilenko et al (Bilenko et al., 2004) can be used to regulate the construction of dictionary, but the method adaptability is limited because prior knowledge is required for the learning process. Another approach is to analyze the discriminative power of visual words (Caicedo et al., 2009 ), but the weighting scheme also requires supervised classifiers. Some researchers have suggested that the most frequent visual words in images are 'stop words', which occur widely but have little influence on di\u21b5erentiating images, and need to be removed from the dictionary (Sivic and Zisserman, 2003) . Yang et al., however, showed that ranking the visual words based on their occurrences in the di\u21b5erent images only was not su cient to evaluate the importance of visual words (Yang et al., 2007) . Term frequency-inverse document frequency (TF-IDF) (Jones, 1972) relies on the inverse frequency weighting and has demonstrated its benefits on visual word evaluation. Nevertheless, it merely utilizes the direct cooccurrence relationship between the images and visual words. Jiang et al. (Jiang et al., 2015b) proposed an unsupervised approach to refine the weights of visual words within the vocabulary tree and showed the advantages of using the correlations among the visual words. We suggest that this relationship can be further used to infer the semantic information and can provide a better description of the discriminative power of visual words.\nThe ultimate goal of CBMIR is to identify cases with similar clinical properties (M\u00fcller et al., 2004) . Such similarity may not be accurately captured in the low-level visual features (Depeursinge et al., 2014) . The BoVW model is also mostly restricted within the visual appearance scope since the images are represented by a collection of visual words (Yang et al., 2012) . One approach to handle this limitation is to perform semantic feature extraction by inferring the high-level semantic information based on the low-level visual data. A number of researchers have shown the e\u21b5ectiveness of high-level feature description (Quellec et al., 2010; Song et al., 2011a,b; Batet et al., 2011; Andr\u00e9 et al., 2012b; Quddus and Basir, 2012; Kurtz et al., 2014a,b) . It is important to emphasize that most of these approaches require additional information including manual annotation (Andr\u00e9 et al., 2012b) , supervised learning (Andr\u00e9 et al., 2012b; Quddus and Basir, 2012) and biomedical ontological knowledge (Batet et al., 2011; Kurtz et al., 2014a,b) .\nThe latent semantic topic model (LSTM) (Li and Pietro, 2005; Bosch et al., 2008) can be used to automatically extract semantic information and it has been recently introduced into medical image analysis (Castellani et al., 2010; Cruz-Roa et al., 2012; Kwitt et al., 2012; Foncubierta-Rodr\u00edguez et al., 2013) . Probabilistic Latent Semantic Analysis (pLSA) (Hofmann, 2001 ) is one of the more popular latent topic techniques. pLSA is a language modeling technique and it is widely used in document analysis. The underlying idea is that each document can be considered as a mixture of latent topics. The latent topic is a probability distribution of words, and can be inferred from the co-occurrence relationship between documents and words, i.e., the latent topics. It has been used to extract the semantic relationship of morphological abnormalities on the brain surface (Castellani et al., 2010) and model histological slides to construct similarities between images (Cruz-Roa et al., 2012) . pLSA is also employed to identify the meaningful visual words for BoVW based on the latent topics (Foncubierta-Rodr\u00edguez et al., 2013) . The words with conditional probabilities below a significance threshold are regarded meaningless and removed from the visual dictionary. Since the conditional probabilities only describe the individual words, this method does not consider the relationship among the words. It also assumes that all latent topics can be treated equally in the evaluation of significant words but this is controversial, and so, this work reported by Foncubierta-Rodr\u00edguez et al (Foncubierta-Rodr\u00edguez et al., 2013) has not resulted in clear improvements in retrieval accuracy."}, {"section_title": "Contributions", "text": "We propose a BoVW-based medical image retrieval method with a Pruned Dictionary based on the Latent Semantic Topic description, which we refer to as PD-LST retrieval. Our goal is to measure the discriminative power of a visual word in the dictionary so that less meaningful words are removed to enable better similarity computation between images. This discriminative power is quantitatively measured by a ranking metric, which we define as the significance value. Our method has two main contributions: a topic-word significance computing with pLSA topic extraction and an overall-word significance computing with a ranking approach. For the topic-word significance, we compute a significance value for a word relative to a certain latent topic. A pLSA method is applied to extract the latent topics between images and words, and the learnt conditional probability of a word given a latent topic is then adopted to quantitatively measure the topic-word significance. For the overall-word significance, we calculate a final significance value for each word. We designed a ranking method to incorporate the overall relationship between all latent topics and words. While the topic-word significance is used to describe a word's individual significance, the overall-word significance is used to evaluate the word's discriminative power in the entire dictionary.\nThe benefits of this pruning are: a) The updated BoVW representation can better capture the similarity level between images so that it can obtain higher retrieval accuracy. b) Our PD-LST method can largely reduce the amount of required words, leading to higher retrieval e ciency. We evaluated our method on two publicly available datasets -the Early Lung Cancer Action Program (ELCAP) (ELCAP and VIA, 2003 ) and Alzheimer's Disease Neuroimaging Initiative (ADNI) (Jack et al., 2008) . Our prior work showed the e\u21b5ectiveness of the dictionary pruning-based analysis and reported some preliminary results. In this work, we elaborate the topic-word and overall-word significance computation process with further details. The ranking method is justified by a mathematical explanation. We extend the evaluation to the ADNI dataset for brain image retrieval task, in addition to the originally used ELCAP dataset, to demonstrate the general applicability of our method. More comprehensive performance comparison with various approaches are performed on the two datasets. We also compared the execution time for e ciency analysis.\nThe structure of this paper is as follows: in Section 2 we describe the two stages of the proposed PD-LST method; in Section 3 we introduce the experimental datasets and experimental design; in Section 4 we present the experimental results and discussion, and we provide a conclusion and an outline of future work in Section 5."}, {"section_title": "Methods", "text": ""}, {"section_title": "Overview of the PD-LST retrieval", "text": "The outline of our PD-LST method is shown in Fig.1(a) . The left part shows the standard BoVW workflow (Section 1.1). A dictionary of size M is generated from the extracted low-level features using k-means. The word frequency histograms of images are then calculated and used to compare the image similarity with Euclidean distance for retrieval. In addition to the standard BoVW model, PD-LST incorporates a dictionary pruning stage to remove the less meaningful words, i.e., the ones with limited discriminative power, as illustrated in the right part of Fig.1(a) . A pLSA method is employed to extract the latent semantic topics based on the image-word co-occurrence relationship, and the learnt conditional probability of a word given the latent topics is adopted to measure its individual significance (Section 2.2). A ranking algorithm is designed to update the significance value of the words by incorporating the overall relationship among all latent topics and words, and calculate the final significance of each word (Section 2.3). The words with lower overall-word significance are removed to prune the dictionary. The similarity between images is then calculated based on the new frequency histograms using the pruned dictionary, followed by a k-NN for retrieval (Section 2.4). Fig. 1(b) gives the visual illustration of our PD-LST method. The underlying idea of our method is that the visual dictionary used for constructing the BoVW model can be very noisy and redundant, reducing the representative and discriminative power of the visual words in identifying similar images. For example, the patches from the pleural surface of lung nodule image in Fig. 1 (b) (left sample) are visually di\u21b5erent, making the local features of these regions assigned to di\u21b5erent visual words, i.e., w 2 , w 3 and w 4 , and causing confusions in finding similar images based on the visual word distributions. Building upon the aforementioned work of Foncubierta-Rodr\u00edguez et al (Foncubierta-Rodr\u00edguez et al., 2013) , we propose a new way to prune the dictionary considering the overall relationship between latent topics and visual words. We hypothesize that such a design would perform well because with the help of latent topics, the relationship between images is captured in terms of semantic descriptions, instead of the visual appearance. In this example, w 2 , w 3 and w 4 are connected to the first latent topic representing the pleural surface. Then w 2 and w 3 would be removed since they don't present the co-occurrence information between the two images, and the corresponding patches would be assigned to w 4 . In this way, the Euclidean distance between the two images from the same category is smaller after the dictionary pruning process."}, {"section_title": "Topic-word significance", "text": "The topic-word significance describes the significance of a word based on the latent semantic topics inferred from the relationship between the images and words. These latent topics provide the semantic description to bridge the gap between lowlevel visual features and high-level semantics. While the words are considered as the visual content pattern obtained from the visually similar patches, the latent topics are regarded as the pattern categories (Bosch et al., 2008) . For example, in images to evaluate lung nodules, the latent topics can be used to describe the pulmonary structure that the patches belong to. An image that contains multiple instances of these patterns is modeled as a mixture of latent topics. A latent topic that describes the common characteristic of the content patterns is modeled as a mixture of words. The words are thus linked to the latent topics rather than directly to the images.\nFor this study, we used pLSA to extract the latent topics. In pLSA, the similar words tend to have high conditional probabilities given the same latent topic. The anatomical structures represented by the visual words are thus correlated indirectly with the latent topics. In an unsupevised manner, we do not need to explicitly specify these correlations, making our method more adaptive to di\u21b5erent imaging problems, e.g., lung nodule and brain images. Fig.2 shows the flow of topic-word significance measurement using pLSA. A visual word is connected to a latent topic with a conditional probability that can quantitatively evaluate the significance of the word regarding this certain latent topic, i.e., the topic-word significance.\nFormally, an image-word co-occurrence matrix OCC M\u21e5N is computed by assigning all local patch features in an image to the visual words, where the element occ(w i , I j ) refers to the number of occurrences of word w i with i 2 [1, M] in image I j with j 2 [1, N], in which N is the number of images and M is the size of the dictionary. pLSA considers that the observed probability of a word w i occurring in a given image I j can be expressed with a latent or unobserved set of latent topics Z = {z h : h 2 [1, H]} where H is a constant parameter as the Figure 2 : Outline of topic-word significance measurement with pLSA. The occurrence relationship (green lines) between the images (large blue rectangles) and visual words (small orange rectangles) is computed. pLSA is then used to extract the latent topics (purple ellipses). The conditional probability P(w i |z h ) (black line) of word w i given the latent topic z h is learnt and used to measure the significance of the word.The word with the higher probability (yellow) has the higher topic-word significance regarding this latent topic (shadowed).\nnumber of latent topics, as:\nThe probability P(w i |z h ) describes how word w i is linked to latent topic z h , with higher value of P(w i |z h ) indicating it is more connected. The latent topics Z can be learnt by fitting the model with Expectation-Maximization (EM) (Hofmann, 2001 ) algorithm that maximizes the likelihood function L:\nA total of H latent topics and the conditional probabilities of all words given these latent topics are learnt using pLSA. We consider that a visual word is more meaningful / discriminative if it is connected to the important latent topics (Section 2.3). The conditional probability is thus adopted as the topic-word significance to measure the closeness of a word relative to a certain latent topic for the overall-word significance computation."}, {"section_title": "Overall-word significance", "text": "With the obtained topic-word significance, the simplest dictionary pruning approach would be to keep the words with high conditional probabilities for all latent topics. Such an approach is based on the assumption that all latent topics can be treated equally, which is not appropriate for practical application. Taking lung nodule images as an example (Section 3.1), the latent topics are regarded as the local content pattern categories, which represent di\u21b5erent types of anatomical structures such as the nodule, vessel, pleural surface or background. However, these structures do not have the same importance in determining the pathological categories of lung nodule images. A word might have high topic-word significance for certain latent topics, but it would be less significant compared to the other words if the connected latent topics are unimportant. For example, some stop-words that describe the background regions in lung nodule images tend to have high conditional probabilities with the unimportant latent topics that imply the 'background'. Thus, we wanted to compute the contribution of the latent topics for measuring the overall significance of words, i.e., the overall-word significance.\nWe designed a ranking-based method, based on the relationship between the latent topics and words, to derive their contributions and significances. Suppose we have some latent topics that make high contributions, then the word that is strongly connected with these latent topics will have a higher significance value. Similarly, if many high-significance words are strongly connected to a certain latent topic, it reflects that this latent topic will make a high contribution. The proposed ranking metric is based on this relationship to compute the significance of words and contribution of latent topics conditioned on each other. Fig.3 shows the flow of the overall-word significance measurement.\nFirstly, a higher topic-word significance means the word is more closely linked to this latent topic, and thus is used to describe the 'strongly connected' relationship between the latent topic and word. Specifically, a topic-word threshold twth is used so that only the words with higher topic-word significance are regarded as strongly connected with the latent topic. Thus, the relationship between the latent topics and words is represented with a bipartite graph B, as:\nwhere twth is a percentage such that the top twth, e.g., 10%, words with higher P(w i |z h ) are kept for the latent topic z h . In this way, we can have the same number of words connected to each latent topic (we will discuss this after introducing the ranking method). With the connections defined in the bipartite graph B, the relationship between the latent topics and words for significance and contribution computation can be explained as follows: the significance value s(w i ) of a word w i is approximated from the contributions of the connected latent topics, and the contribution value c(z h ) of a latent topic z h is approximated based on the significance of the connected words. We define the values as:\nEqs.(4) and (5) can be alternatively solved iteratively to calculate the final overall-word significance, as shown in Algorithm 1. Supposing the significance value of all words is denoted with a vector S 2 R M\u21e51 and the contribution value of all latent topics is represented with a vector C 2 R H\u21e51 , both the significance value vector S = {s(w i ) : i 2 [1, M]} and contribution value vector C = {c(z h ) : h 2 [1, H]} are initialized with 1, i.e., s 0 (w i ) = c 0 (z h ) = 1. At each iteration t 2 [1, T ], the significance value s t (w i ) is updated with Eq.(4) and then the contribution value c t (z h ) is updated with Eq.(5). The two vectors are then L2 normalized so their squares sum to 1 at the end of each iteration, as:\nThe significance value of a word w i at the final iteration T is thus the desired overall-word significance.\nThe ranking algorithm updates the significance and contribution values iteratively. At the beginning, we have the same number of words connected to each latent topic (same twth for all latent topics) and initialize the same contribution and significance values (s 0 = 1 and c 0 = 1) for all latent topics and words. normalize s t (w i ) and c t (z h ) with Eqs. (6) and (7); 10: end for; 11: return S T .\nIn this way, without the prior knowledge on the contribution of latent topics and discriminative power of words, we can treat all latent topics and words without any bias at the beginning of the ranking method. Then, within each iteration, the significance of a word is computed according to the most related latent topics and the shared knowledge between the latent topics and words is incorporated. Across the iterations, the significance of a certain word is di\u21b5used to the latent topics at the current iteration and gathered at the next iteration for updating the other words so that the relationship between the words is also used. Thus, the overall-word significance is derived based on the words and latent topics collectively.\nThe algorithm can be formulated alternatively as follows. With the bipartite graph B 2 R M\u21e5H that indicates the adjacent matrix between all latent topics and words, Eq.(4) for word significance updating and Eq.(5) for latent topic contribution updating can be expressed as:\nGiven the iteration t 2 [1, T ], the sequence of the significance vectors {S t } can be expressed as:\nWith the normalization in Eq.(6), S t is the unit L2-norm vector in the direction of (BB > ) t S 0 (similarly to C t ). As reported by Golub, Van Loan and Wilkinson, the unit L2-norm vector sequence of {S 1 ...S t } converges to a limit S \u21e4 as t increases arbitrarily, and so does the sequence of {C 1 ...C t } (Wilkinson, 1965; Golub and Van Loan, 2012) .\nThe above explanation illustrates that our ranking method generates a convergent ranking result and the significance and contribution values can be estimated approximately with the principal eigenvectors of BB > and B > B. This provides an alternative to compute the significance values. However, through the experiments, we observed that the retrieval performance tends to be stable with a relatively small number of iterations (Section 4.1). We can thus obtain the final ranking order for the retrieval without achieving the converged ranking values. This can also be helpful to improve the e ciency if there are a large amount of image data. In addition, the proposed iterative method represents that the significance of words and contribution of latent topics are computed based on each other and the final ranking is obtained from the overall perspective 2.4. PD-LST retrieval using the pruned dictionary\nThe dictionary is pruned according to the overall-word significance in the final step. All words within the dictionary are ranked, and the ones below a percentage point, namely the pruning percentage p, are considered meaningless and are removed, leading to a pruned dictionary with the size of p \u21e5 M. Then, the standard BoVW retrieval is conducted on the pruned dictionary. The co-occurrence matrix of the images is reconstructed by computing the new visual word frequency histograms on the pruned visual dictionary. Euclidean distance similarity is employed to calculate the similarity between images and k-NN method is used for retrieval."}, {"section_title": "Dataset and experimental design", "text": "We employed two publicly available medical imaging datasets, i.e., the ELCAP (ELCAP and VIA, 2003) and ADNI databases (Jack et al., 2008) , for experimental evaluations."}, {"section_title": "Datasets", "text": "The ELCAP database contains 50 sets of low-dose computed tomography (LDCT) human lung scans, with the lung nodules annotated at the centroid. In our study, a set of 379 lung nodule images were used for evaluation. Lung nodules are small masses in the lung and can be divided into four di\u21b5erent categories based on their location and connection with the surrounding structures such as vessels and the pleural surface (Diciotti et al., 2008) , as follows: well-circumscribed (W), vascularized (V), juxta-pleural (J) and pleural-tail (P), as shown in Fig.4 . The numbers of nodules for the four types are 57 (W), 60 (V), 114 (J), and 148 (P) respectively. The ADNI database comprises 331 subjects with magnetic resonance (MR) and positron emission tomography (PET) scans with a diagnosis of cognitively normal, mild cognitive impairment (MCI) and Alzheimer's Disease (AD). Examples are shown in Fig.5 . We segmented each brain scan into 83 functional regions. The risk of progression to dementia is higher if more regions display glucose hypometabolism (Liu et al., 2013c) . The numbers of subjects for the three stages are 77 (normal), 169 (MCI) and 85 (AD) respectively.\nThe literatures suggest that identifying the location information of lung nodules is essential for the early detection of lung cancer and determining the neurodegenerative progression stages is helpful for finding the patients at a high risk of dementia (Liu et al., , 2013b . Finding a list of related cases is of high clinical interest for the disease diagnosis and treatment. Therefore, in this study for the ELCAP dataset, we tried to retrieve the lung nodules at similar locations relative to the surrounding pulmonary structures as W, V, J and P, and for the ADNI dataset, we aimed to retrieve images with similar neurodegenerative progression patterns as AD, MCI and the cognitive normal."}, {"section_title": "Feature extraction and dictionary construction", "text": "In the ELCAP database the lung nodules are small and have an average size of 4\u21e54 pixels (approximately from 3\u21e53 to 7\u21e57 pixels) across the centroid in the axial direction. Therefore, to restrict the problem scope to lung nodule analysis, an ROI of 33 \u21e5 33 pixels was cropped from each image slice with the annotated nodule centroid appearing in the center, similar to the processing in some related works for lung nodule analysis (Wu et al., 2010; Farag et al., 2010; Farag, 2013) . We conducted a pixel-by-pixel patch feature extraction process to build the LF representation for the nodule and surrounding pulmonary structures. For each pixel around the annotated centroid (including the centroid pixel) as a keypoint, we computed a scale invariant feature transform (SIFT) (Lowe, 1999) descriptor using the VLfeat library 1 , with the parameter f rames = [x, y, s = 4, o = 0], where x and y indicate the pixel position, s is the scale and o is the orientation. A 128-dimension vector was obtained for each frame and used as a local patch feature. Based on our previous work (Zhang et al., 2014a,b) , incorporating too many surrounding pulmonary structures, e.g., including extra pleural surface, or too few, e.g., excluding the essential vessels, reduces the performance of recognizing the nodule type. Therefore, a total of 100 patch features were used by selecting the SIFT descriptors from the nearest 100 pixels around the nodule centroid.\nFor the ADNI dataset, the MR and PET data were preprocessed following the ADNI image correction protocols and 1 From VLfeat project, downloaded at: http://www.vlfeat.org/ index.html nonlinearly registered to the ICBM 152 template to segment the entire brain into 83 functional regions (Liu et al., 2013c) . Then, for each subject, we extracted 8 features. Each feature was an 83-dimension vector where each element described one of the 83 functional regions. The mean (Cai et al., 2010) and Fisher (Liu et al., 2011) indices, and di\u21b5erence-of-Gaussianbased (DoG area, DoG contrast, DoG mean) features (Toews et al., 2010; Cai et al., 2014a) were extracted from the PET data, and solidity, convexity (Batchelor et al., 2002; Liu et al., 2014b) and volume (Heckemann et al., 2011) were extracted from the MR data. Thus, we obtained an 8-dimension vector for each functional region as one local patch feature, and 83 feature vectors for each subject to construct the LFM. The overall statistics of the two datasets are shown in Table 1 . "}, {"section_title": "Experimental design", "text": "In our study, leave-one-case-out cross-validation was conducted by using each case as query and the remaining cases in the dataset as the retrieval candidates. In this way, we can provide a comprehensive comparison by enabling the similarity computation between every two cases in the dataset. During the experiments, we had the same parameter setting for all testing queries. Therefore, the optimal values of the parameters did not result in biases with the leave-one-case-out cross-validation. All images in the dataset were included for, e.g., dictionary construction, latent topic extraction, word significance computing and dictionary pruning, due to the unsupervised nature of all comparison methods involved. With such experimental design, we could better utilize the image information including the testing images. It is worth noting that the class label information was not involved in these steps but only for the accuracy computation.\nThe most related items were retrieved for a given query as the retrieval results with an output number K. The performance was measured using the average retrieval accuracy (i.e., retrieval precision) of N queries, as,\nwhere T P is the number of true positive items within the K retrieved results for the query image Q l with l indicating the index of the query Q. The retrieved item is true positive if it is within the same class with the query image."}, {"section_title": "Experimental results and discussion", "text": ""}, {"section_title": "Parameter analysis", "text": "Our method has four major parameters: the number of latent topics H, topic-word threshold twth, number of iterations T , and the pruning percentage p. We have conducted the experiments given various dictionaries (M was from 100 to 2000) and outputs (K was from 1 to 10). In the following paragraphs, we provide the retrieval results from the 1-output for the 500-dictionary to show the e\u21b5ects of the four parameters. Figure 6 : The retrieval accuracy curve given the number of latent topics. Fig. 6 displays the accuracy curves given di\u21b5erent numbers of latent topics on the two datasets. For each H (50 to 600), the maximum, minimum and average accuracies across di\u21b5erent twths (0.05 to 1) and ps (10 to 90) with T fixed at 20 are reported. While the curves on the ADNI dataset fluctuated more than with the ELCAP dataset, the accuracies of these two datasets were stable, in particular, for the average accuracy curves. This suggested that the number of latent topic had a limited impact on retrieval accuracy, due to the fact that only the latent topics making greater contributions a\u21b5ected the dictionary pruning. Given di\u21b5erent topic-word threshold twths, Fig. 7 shows that if too few or too many words were kept to construct the bipartite graph between the latent topics and words there was lower performance. This finding was because too few words led to the loss of important knowledge and too many produced noise. In general, keeping relatively few words for each topic (10% and 30% for the ELCAP; 20% to 40% for the ADNI) generated better performance.\nAs shown in Fig. 8 , the retrieval accuracy gradually increased with larger T values and then stayed constant after T reached a certain value. Less iterations were needed for stable retrieval results with a smaller dictionary and a larger number of outputs. The smaller dictionary led to a fewer connections between the latent topics and words and the larger number of outputs made it easier to include the most related items into the results. Overall, fixing T at 20 was su cient to obtain stable accuracies given di\u21b5erent numbers of iterations. Fig. 9 shows the e\u21b5ects of di\u21b5erent pruning percentages on the two datasets. For each p (10 to 90), the maximum, minimum and average accuracies given di\u21b5erent Hs (50 to 600) and twths (0.05 to 1) with T fixed at 20 are reported. In general, the best accuracy results were obtained when p was between 20% and 40%. The similarity between images was better represented on the pruned dictionary, since the similar local patch features were more likely to be assigned to the same word. Based on our observations, incorporating more words for the dictionary construction helped on computing the similarities between the less related items, e.g., a pruning percentage of 40% normally performed better when K = 9 but 20% generate higher accuracy when K = 1. Hence, we suggested that a larger number of outputs needs more words kept and vice versa."}, {"section_title": "Retrieval performance evaluation 4.2.1. Visual retrieval results", "text": "Figs. 10 and 11 give the visual examples of the retrieval results from the standard BoVW method and our PD-LST method. The results were obtained on the original dictionary with M = 100. Our method conducted the dictionary pruning with H = 50, twth = 0.2, T = 20 and p = 20. It can be seen that our method can retrieve the cases with the same diagnosis, which are visually similar or di\u21b5erent. For example of the lung nodule images, we retrieved #16(W) and #1(W) as the most desired cases. While the first result is visually similar to the query, the second one is with a larger lung nodule than that in the query image and has more noise in the background regions. In addition, the proposed method can find the di\u21b5erences between the visually similar images that present different diseases. For instance, given the query case #298(AD), our method retrieved #286(AD) as the first result and the standard BoVW found #163(MCI). While the two retrieved cases are very similar to the query case regarding the visual appearance, our method obtained the case with the same stage to the query. These observations can be explained by the fact that our method conducted the similarity computation between images through the latent topics, which provide high-level semantic descriptions, instead of merely using the visual content information. Given the pruned dictionary, our method generated a more compacted word frequency histogram that can better di\u21b5eren-tiate the images with the most discriminative words. We can observe that the frequency distributions between the query and retrieved results were more consistent with the pruned dictionary than the original one."}, {"section_title": "Accuracy analysis", "text": "We then quantitatively analysed the performance of the proposed method compared to related retrieval approaches regrading the retrieval accuracy. The experiments were conducted as follows: a) the comparison among the approaches that are based on the subsections of our method's pipeline (Table 2) , b) the evaluation regarding the di\u21b5erent dictionary pruning approaches in the literature (Fig. 12) , and c) the investigation of performance improvement by integrating other retrieval methodologies (Fig. 13) . a) Table 2 shows the retrieval accuracy comparisons of the approaches that are based on parts of our PD-LST method on the ELCAP and ADNI datasets for the 1-NN retrieval. 1) For the GFM, we calculated a global feature vector 2 to represent an individual image and performed the k-NN retrieval with the Euclidean distance. 2) For the BoVW, it followed the standard BoVW model as introduced in Section 2.1. This method was adopted as baseline. 3) For the pLSA-F, we calculated the similarities between images based on the latent topic distribution P(z h |I j ) obtained during the pLSA parameter estimation (Bosch et al., 2008) . 4) For the pLSA-P, we pruned the dictionary based on the conditional probability of a word given a certain latent topic (Foncubierta-Rodr\u00edguez et al., 2013), i.e., the topic-word significance. 5) For the VWW, we utilized the overall-word significance to perform visual word weighting, instead of pruning the visual dictionary. The images were represented as vectors with the element of a visual work's significance value other than its frequency. (6) For the TD, we truncated the word frequency histogram of the image based on the pruned dictionary instead of recomputing the histogram.\nThe GFM retrieval obtained the lower accuracies when compared to BoVW method that was based on the LFM feature extraction. By making use of more local content information, e.g., the surrounding pulmonary structures of a nodule and the spatial structure of di\u21b5erent regions of the brain, the LFM is more e\u21b5ective in capturing the similarity between images. The pLSA-F retrieval had the lowest accuracies among all approaches over the two datasets. As we explained previously, latent topics can be used to categorize di\u21b5erent anatomical structures. The pLSA-F method represents the images as the latent topic distributions, which can describe what structures are contained in the images but cannot di\u21b5erentiate the role of these structures for the diagnosis. The pLSA-P retrieval obtained higher accuracies regarding the pLSA-F method. This suggests that although the latent topics were not e\u21b5ective in measuring image similarity directly, they can be employed to evaluate the words' significance for the improved similarity computation. On the other hand, the pLSA-P method achieved the similar accuracies with the BoVW approach, indicating that measuring the significance of the word individually would restrict the ability to identify the most meaningful words. The VWW method showed retrieval improvement over the aforementioned methods. This was attributed to the overallword significance that can emphasize the e\u21b5ects of the words with the most discriminative ability, considering the overall relationship between all latent topics and words. The TD method had an approximate 6% accuracy improvement on the ADNI dataset compared to the BoVW. However, TD did not perform well on the ELCAP dataset. This was due to the reason that some lung nodule images only contain a few anatomical structures, e.g., some type W nodule images only have nodules except for the background regions. The word frequency histograms can be very concentrated on a few words. Truncating the frequency histogram may remove these words resulting in an empty histogram. For the PD-LST method, recomputing the frequency histogram based on the pruned dictionary can relocate the local features to other words and thus can reserve the original feature information in the images.\nb) In Fig. 12 , we compared the following state-of-the-art dictionary pruning approaches on the ELCAP and ADNI datasets. 1) For the OCC, it ranks the words according to their occurrences on all images and prunes the ones with higher frequencies (Yang et al., 2007) . 2) For the IDF, the method weights the visual words according to the inverse image frequency and keeps the ones with higher IDF values (Yang et al., 2007) . 3) For the pLSA-P, it evaluates the words according to the conditional probabilities for each latent topic and prunes the ones with lower probabilities (Foncubierta-Rodr\u00edguez et al., 2013) . 4) For the Fisher 3 , the method aggregates local image descrip- tors in terms of the Fisher kernel representation and conducts the dimensionality reduction by principal component analysis (PCA) (J\u00e9gou et al., 2012) . 5) For the VLAD 4 , considered as a simplification of the Fisher kernel, it works on the visual dictionary obtained with k-means rather than with Gaussian mixture model (GMM) in the Fisher method, with the PCA employed for the dimensionality reduction (J\u00e9gou et al., 2012) . 6) For our PD-LST, the method measures the words according to the overall-word significance and prunes the ones with lower values. During the experiments, we observed that the methods can obtain di\u21b5erent retrieval accuracies given di\u21b5erent parameter settings and datasets. Therefore, we reported the mean, maximum and minimum of the highest retrieval accuracies across the di\u21b5erent dictionaries to compare the overall performances.\nThe OCC method generated the worst results and so had an unfavorable performance. These findings were in accordance with the work of Yang et al. who showed that the most frequent words are unlikely to be the stop words (Yang et al., 2007) . Such comparison suggested that it was not su cient to evaluate the significance of the words merely based on occurrence. The IDF method obtained retrieval improvement when compared to the OCC method, indicating that the inverse frequency weighting can assist on identifying discriminative power of the words. The IDF however utilized the direct image-word co-occurrence information to wight the words without further analysing the relationship among the words, which can lead to performance enhancement as used in our method. The pLSA-P method was also more accurate than the OCC approach but were similar to the baseline of BoVW as discussed above. Hence, the pLSA conditional probabilities can describe the significance of a word to a certain extent but it can be further improved upon. Although pLSA pruning did not achieve an observable improvement in retrieval accuracy, it did reduce the number of words required for feature representation and so would improve the e ciency of retrieval.\nThe Fisher and VLAD methods obtained better retrieval performance by incorporating the local feature encoding process. One reason for the improvements is the feature dimensionality reduction with PCA as reported in the work by J\u00e9gou et al.\nIn general, for the datasets under study, the highest accuracies were obtained given the reduction according to the first half components with PCA. These improvements showed the benefits of evaluating the discriminative ability of the visual words, though the two methods obtained the visual dictionaries in different ways (with GMM and k-means). Our method achieved the higher retrieval accuracies across all the approaches. The improvements were because that our method not only utilizes the semantic descriptions of the latent topics learnt from the word-image co-occurrence relationship but also measures the contributions of the topics based on the overall relationship between the words and latent topics. In addition, the di\u21b5erences between the maximum and minimum highest accuracies given di\u21b5erent dictionary sizes of the proposed method were relatively smaller. These observations indicated the stability of our method with di\u21b5erent dictionaries. c) Fig.13 shows the retrieval performance of the approaches that utilize our PD-LST method. The large margin nearest neighbor (LMNN) retrieval 5 is a supervised method using distance metric learning to identify the most related neighbors (Weinberger and Saul, 2009 ). This method usually shows performance improvement over k-NN, therefore we employed it to exploit the accuracy enhancement with the pruned dictionary. During the experiments, half of the dataset was randomly selected for training the LMNN model. A leave-one-case-out cross-validation was then used to perform the retrieval given the trained model. The iterative ranking (ITRA) retrieval conducts the retrieval result refinement by calculating the ranking scores of the retrieved items and remaining candidates, which are the similarity measurement to depict their distances with the query, corresponding to the overall-word significance and contribution values of the words and latent topics . The ranking score is computed based on the bipartite similarity relationship between the retrieved items and remaining candidates, in a way similar to the ranking method that works between the latent topics and words in this study. Therefore, we employed this method to investigate the performance of ranking method. The retrieval accuracies of the two approaches and k-NN method based on the original and pruned dictionaries are displayed.\nApplying the LMNN method on the pruned dictionary gave retrieval accuracy improvement when compared to the original dictionary on the two datasets by incorporating the distance learning metric. The higher accuracies suggested our method's potential on retrieval improvement by using the prior knowledge, e.g., the labeling information. Although employing the ITRA method on the two dictionaries for the ELCAP dataset achieved similar accuracy, applying it on the pruned dictionary for the ADNI dataset gave the highest retrieval accuracy. The improvement showed the benefit of the combination of the retrieval result refinement and the pruned dictionary. 5 The LMNN package was downloaded from http://www.cse.wustl. edu/~kiliancode/lmnn/lmnn.html Figure 13 : Retrieval accuracy comparisons among the k-NN, LMNN and ITRA approaches. For the LMNN method, the default parameter settings of the LMNN package were used with maximum number of iterations as 1000, suppress output as 0, output dimensionality as 3, tradeo\u21b5 between loss and regularizer as 0.5. For the ITRA method, we fixed the numbers of initial retrieval results and neighbours for bipartite graph construction at 10 and the iteration number at 20. The parameter settings for obtaining the original and pruned dictionaries were the same as used for the BoVW and PD-LST in Table 2 . ODC = original dictionary construction, DP = dictionary pruning, R = retrieval, s = second."}, {"section_title": "E ciency analysis", "text": "The process of PD-LST retrieval has two components: an offline dictionary construction stage and an online image retrieval stage. The first component contains the original dictionary construction and dictionary pruning and the second consists of the word frequency histogram calculation and similarity computation for the query image. Table 3 shows the comparisons of execution time between the two stages (with same parameter settings for the two datasets as M = 1000, H = 300, twth = 0.3, T = 20, p = 0.2). It can be observed the o\u270fine stage required more processing time (about 25 times for the ELCAP dataset and 15 times for the ADNI dataset) than online retrieval. In addition, the dictionary pruning only occupied a small portion of the whole o\u270fine processing.\nOur method prunes the dictionary by keeping the most meaningful words and thus obtains a low-dimensional word frequency histogram vector for each image. Such dimensionality reduction can increase the speed of the retrieval process. Table  4 shows the total retrieval time of all query images (for leaveone-case-out validation) from the two datasets based on the original dictionary and the pruned dictionary. Our method had the shortest processing time with the pruned dictionary, suggesting an e ciency improvement."}, {"section_title": "Conclusions and future work", "text": "We have presented a PD-LST retrieval method for medical image analysis. Our method focused on dictionary pruning so that only the words with high discriminative power are kept. The method has two main components: topic-word significance and overall-word significance computing. By pruning the trivial words, the updated BoVW representation better captures the similarity relationships between images and largely reduces the amount of required words.\nIn the study, we aimed at investigating the performance of dictionary pruning, hence we did not overemphasize on the analysis of the image data themselves. One aspect of the future work will be conducted by further exploring the image data. For example, we will use 3D raw data of the ELCAP dataset, which would provide a more comprehensive description of the lung nodule structures than the 2D images. For tackling a certain task in which more domain-specific knowledge can be incorporated, the analysis about the latent topic categories will be conducted to explore the correlations among di\u21b5erent anatomical structures. In addition, the e\u21b5ectiveness of di\u21b5erent low-level features, such as histogram of oriented gradients (HOG) (Dalal and Triggs, 2005) , GIST (Oliva and Torralba, 2001 ) and Hashing features (Zhang et al., 2015d) , for constructing the BoVW model will be further investigated. More experimental comparisons will be conducted to furhter validate the e\u21b5ectiveness of our methond. For instance, Zhang et al. proposed an interesting re-ranking approach based on graph analysis, which is highly related to the currently used compared method of ITRA. We will also test our method on other medical or general imaging domains such as the lung tissue classification in high-resolution computed tomography (HRCT) images ) and the thoracic tumor retrieval in positron emission tomography-computed tomography (PET-CT) images (Song et al., 2013b) . As the scalability of image data has become an important issue in medical image retrieval, it would be also interesting to test if PD-LST can be integrated in a scalable CBIR approach, e.g., building on vocabulary tree (Jiang et al., 2015b) or hashing methods (Zhang et al., 2015e) ."}, {"section_title": "Acknowledgments", "text": "This work was supported in part by ARC, AADRF, NIH NA-MIC (U54 EB005149) and NAC (P41 EB015902)."}]