[{"section_title": "", "text": "ha \u22121 ) compared to nonadopters, leading to fertilizer input cost savings of $30.27 ha \u22121 for nitrogen, $5.93 ha \u22121 for phosphorous, and $7.39 ha \u22121 for potash (U.S. Department of Agriculture, 2009). Aside from the financial benefits of soil testing (Griffin et al., 2004;Lambert and Lowenberg-DeBoer, 2000), lower fertilizer use may generate observable environmental benefits (Larkin et al., 2005). These benefits are important because commercial fertilizer use and nutrient runoff from agriculture remain significant causes of nonpoint source pollution, groundwater degradation, and waterway eutrophication (U.S. Environmental Protection Agency, 2002). Thus, best nutrient management practices supplemented by soil testing have the potential to improve the environmental performance of farms by modifying the application intensity of fertilizers, reducing the loss of inputs to the environment and potentially reducing nutrient runoff (Bongiovanni and Lowenberg-Deboer, 2004;Griffin et al., 2004). Agricultural producers use information technologies such as precision soil testing to acquire a comprehensive understanding of soil variability and crop nutrient requirements. Soil testing is a gateway technology to the adoption of other precision-agriculture technologies (Schimmelpfennig and Ebel, 2011), which is why disseminating information about advances in soil-testing strategies and how they are used is important. Empirical evidence suggests that georeferenced soil testing (also known as precision soil testing, or PST) is superior with respect to the information it provides compared to other soil-testing strategies (Mallarino and Wittry, 2004). Instead of a simple average of randomly selected points in a field, PST provides more accurate information about the spatial variability of soil fertility. For comparison, grid soil-testing strategies systematically divide fields into equal-sized areas ranging from 0.4 to 1.6 ha (Schepers, Schlemmer, and Ferguson, 2000), and about one sample of five to ten cores is taken per hectare (Ferguson and Hergert, 2009). Although the time between testing varies by nutrient, estimates have ranged from four years (Peters, Laboski, and Bundy, 2007) to ten years (Ferguson and Hergert, 2009). Cost components for grid soil sampling include identifying test locations, sampling, sample analysis, and labor, but costs vary by location. 1 These costs represent a potentially substantial cash outflow in testing years. Given the cost and uncertainty of optimal testing intervals, understanding the factors contributing to producer perceptions about how frequently soils should be tested may be useful for increasing participation in nutrient best management practices with benefits to both the environment and the profitability of cotton farming. This research identifies the farm characteristics, information sources, and technologies associated with PST adoption and the period of time in which cotton producers perceive soil-test information to be useful. From an operator's perspective, if soil fertility is expected to change under a nutrient management plan, precision soil-test information would be important for understanding where and when those on-site changes occur and when amendments are needed. From an agency perspective, documenting the adoption of nutrient management plans through PST use is important for determining program eligibility and quantifying environmental benefits. Information about the factors associated with PST adoption and the period between information updates may also be useful for managers charged with designing, monitoring, or evaluating program effectiveness. Understanding the factors contributing to the perceived usefulness of GPS-referenced soil-test information as measured by the time producers wait before retesting may also provide guidance to extension and agricultural service providers with respect to product marketing, advertising, and information dissemination."}, {"section_title": "Conceptual Model", "text": "Farmers are hypothesized to maximize expected discounted profits over a planning horizon subject to input prices, commodity prices, and technology constraints. Producers compare the benefits and costs of incorporating precision-agriculture technologies into current operating plans. Additional variable and fixed costs incurred in the initial period of adoption include the development and implementation of input-management plans based on soil-test information and data collection and storage. The decision to retest after some period is examined using a hurdle count regression (Cameron and Trivedi, 1998). These models are typically used to analyze two-stage decision-making processes. In the first stage, an individual chooses an action (for example, to adopt PST). The expected utility from adopting (not adopting) PST technology in the first stage is U 1 (U 0 ). The latent utility that producer i receives from adoption (AD) of PST technology is U AD * i = U 1 \u2212 U 0 . Producers are expected to adopt PST when U AD * i > 0. The unobservable latent variable, U AD * i , is hypothesized to be a function of observable covariates, x i (including farm household and business attributes, operator characteristics, and possibly off-farm factors), and unknown parameters, \u03b2 \u03b2 \u03b2 AD . The PST adoption decision is modeled as a linear random utility function (McFadden, 1974), is a random disturbance with an expected mean of 0 and constant variance. Given that utility is unobservable, the decision to adopt PST can be modeled as a dichotomous variable, such that The first stage of the model explains the decision to adopt PST (1 = yes, 0 = no) using a logistic regression, where F 1 is the cumulative logistic function. The last expression in equation ( 1) follows, given the symmetry of the logistic distribution. In the second stage, individuals who adopted PST determine the length of time until retesting (i.e., how long the soil-test information is perceived to be useful before it needs to be updated). In this stage, the producer is assumed to maximize profit given adoption of precision soil sampling. Given the decision to use PST, the producer waits k years until retesting. The producer decides when to retest based on expectations about profits, experience with other precision-agriculture technologies, and knowledge about yield variability. Producers will therefore select the optimal number of years to wait until retesting (k * ) to maximize expected profits. A producer must have adopted PST to answer how long soil-test information was perceived to be useful before retesting. Because the choice set is observed as years between tests (a discrete, countable decision) and management decisions such as soil testing and retesting are made annually, the retesting decision is appropriately modeled using a count regression such as the Poisson (Cameron and Trivedi, 1998). Given the adoption of PST, the number of years between tests (a strictly positive, discrete variable; k = 1, 2, . . . , K) is modeled using a zero-truncated Poisson regression. The log link function is used to model expected counts, which implies that , 1983). The conditional probability of waiting k years before retesting after adopting PST is where f 2 is the Poisson probability mass function (Cameron and Trivedi, 1998). Shonkwiler and Shaw (1996) explain that the log-likelihood of the hurdle count model is additively separable, implying that the system can be estimated separately as logistic (the \"hurdle\") and zero-truncated Poisson regressions. The composite log likelihood function is with the terms L 1 and L 2 corresponding to the logistic and zero-truncated Poisson log likelihood functions, respectively. The parameters are typically estimated by maximizing this additive function."}, {"section_title": "Data", "text": "The 2009 Cotton Incorporated Precision Agriculture Survey was mailed to 13,783 cotton producers in Alabama, Arkansas, Georgia, Florida, Louisiana, Mississippi, Missouri, North Carolina, South Carolina, Tennessee, Texas, and Virginia (Mooney et al., 2010). The list of cotton producers was provided by the Cotton Board in November 2008 and constitutes the population of active cotton producers in these states as of 2007, such that a probability sampling approach was not necessary. The survey included questions about precision-agriculture adoption, farm and operator characteristics, and the number of seasons producers waited between soil tests. Following Dillman's 1978 general mail survey procedures, the questionnaires were mailed February 20, 2009, with a reminder post card sent two weeks later and a follow-up mailing (two weeks later) to producers who had not responded. The overall response rate was 12.5% (1,723). The survey prompted producers with the following question: \"If you have ever used grid or zone soil sampling to collect information for cotton production, continue with the questions below, otherwise skip [to another section].\" Producers were then asked, \"Have you ever, or do you currently use Global Positioning technology (GPS) to collect grid/zone soil sampling information for cotton production?\" Responses to this question were used to indicate whether the producer had adopted GPS-referenced grid or zone soil testing. Producers were then asked, \"How long is GPS-referenced grid/zone soil-test information useful until you need to collect new information again?\" A comparison of the distribution of respondents with the USDA's 2007 Agricultural Census (U.S. Department of Agriculture, 2007) reveals that the distribution of respondents was skewed toward larger cotton farms (figure 1). To account for this discrepancy, post-stratification survey weights were estimated and used to calibrate the survey data such that the central tendency measures of survey respondents closely approximated the distribution of the population of cotton producers enumerated by the USDA in 2007 (Lohr, 2010). The post-stratification weights were estimated using a nonlinear optimization procedure suggested by Ireland and Kullback (1968). The algorithm uses the number of survey respondents that produced cotton in 2007 or 2008 in a surveyed state by farm-size class (n = 1, 523 farms that reported cotton hectares for these years) and the number of cotton farms in each state and farmsize class enumerated by the 2007 U.S. Agricultural Census (n = 16, 724) as shown in figure 1. The weights are arranged in a matrix along two dimensions: the number of cotton farms belonging to one of six size classes (h = 0.40-40. 06, 40.47-100.77, 101.17-201.94, 202.34-404.28, 404.68-808.97, 809.37+ cotton ha) and the number of cotton farms in each state surveyed (g =Alabama, Arkansas, Missouri, Georgia, Virginia, South Carolina, North Carolina, Louisiana, Tennessee, Texas, Florida, and Mississippi), yielding seventy-two strata. The objective function for determining the post-stratification weights is (3) min  where n gh is the number of survey respondents that produced cotton in the gth state and farm-size class h and m gh is the number of cotton farms in each state and farm-size class enumerated by the 2007 Census of Agriculture. The arguments minimizing the objective are the post-stratification weights for the lth stratum, w l = a g b h (see Golan, Judge, and Miller, 1996, p. 61, for additional details about this optimization routine). The procedure yields weights identical to those estimated using Sinkhorn's 1964 RAS method. The sum of the post-stratification weights across the sample is therefore approximately equal to the number of cotton farms enumerated by the 2007 Census of Agriculture (figure 1). Each respondent belonging to a farm-size class/state category receives the same weight. By incorporating ex post information about the cotton farm population into the survey design, the leverage attributable to different size classes and states is moderated or increased, depending on the cotton producer population characteristics and the survey response pattern. Because fewer small operations responded to the survey than were proportional to the number of smaller cotton farms in the population, the estimated post-stratification weights are relatively larger at the low end of farm-size classes than the weights corresponding to larger operations (figure 2). After eliminating observations with missing records, the final sample size used in this analysis was 1,010 responses, which expanded to 9,961 cotton producers according to the sample with poststratification weights. On average, producers who adopted precision soil sampling retested about every 2.5 years (weighted, 2.68 years) (figure 3). The average time between testing only corresponds to GPS-referenced soil-testing adopters. There is no information regarding the frequency of soil testing for producers not using PST. About 16.5% of the sample (n = 187) and 18.5% of the weighted sample (n = 1, 653) adopted PST. For most of the covariates, the weighted and unweighted means were similar in magnitude (table 1)."}, {"section_title": "Estimation and Inference", "text": "Adoption of GPS-referenced soil testing was estimated using a logistic regression. The period between testing was estimated using a zero-truncated Poisson regression. A zero-truncated negative binomial regression was also estimated to test for overdispersion of the zero-truncated Poisson model. A key assumption of the Poisson model is that the conditional mean and variance are equal (Greene, 2000). Overdispersion occurs when this assumption is violated, suggesting that the mean function is misspecified. A common solution to overdispersion of the Poisson model is to estimate the counts using a negative binomial regression. When the overdispersion coefficient of the negative binomial regression is not different from 0, the negative binomial model reduces to the Poisson model (Freese and Long, 2006). The zero-truncated version of the negative binomial regression is estimated to test the null hypothesis that the zero-truncated Poisson model is not overdispersed. A likelihood ratio (LR) statistic was calculated to test this hypothesis: LR = -2(log likelihood zerotruncated negative binomial -log likelihood zero-truncated Poisson). All regressions were estimated using STATA 12. The unweighted and post-stratification weighted estimates are reported to examine the effect of using the weights in this application. Regardless of the sample, heteroskedastic robust covariance estimates (Wooldridge, 2004) were used to make inferences about the covariates explaining soilsampling adoption and the period between testings. Variance inflation factors were used to detect multicollinearity (Chatterjee and Price, 1991). Marginal effects are reported for the logistic and count models, with the conditional marginal effects reported for the zero-truncated count regressions (Grogger and Carson, 1991). Negative signs of coefficients suggest that a variable is associated with a decrease in the period between retesting while the converse is true for coefficients with positive signs. The marginal effects reported for the The survey response pattern suggests that smaller farms may be under-represented (figure 1). Post-stratification weights improve the representativeness of the survey respondents in terms of the population of cotton producers in the region, but whether the central tendencies of the weighted and unweighted variables are statistically different is unknown. As Lohr (2010) notes, it is extremely difficult to adjust for survey nonresponse bias, which requires information about respondents who did not respond to the survey. To address this issue, we developed a bootstrap procedure to formalize the comparison of weighted and unweighted estimates. The null hypothesis is that the conditional means of the unweighted sample statistics are not different from those obtained from the data calibrated to the 2007 Census of Agriculture distribution of cotton producers. The proposed method assumes that the weighted estimates reflect the \"true\" population parameters. We use the percentile-t method (Cameron and Trivedi, 2009, p. 432), which is an asymptotically pivotal statistic, to test the null hypothesis that the bootstrap estimate from the survey sample is equal to the post-stratification weighted estimate. The procedure indicates how statistically \"close\" the sample estimates are to those calibrated to the population of cotton producers; however, rejection of the null hypotheses does not conclusively indicate the presence of nonresponse bias."}, {"section_title": "Variable Descriptions and Hypothesized Effects", "text": "Expectations about the profitability and usefulness of information-gathering technologies may encourage producers to adopt PST, but there is little empirical evidence explaining how long producers perceive soil information to be useful before they decide to retest. Soil-testing frequency depends on the nutrients managed, soil-nutrient carryover capacity, crop rotations, and the producer's planning horizon (Kennedy, 1986;Lambert, Lowenberg-DeBoer, and Malzer, 2007;Harper et al., 2012). Peters, Laboski, and Bundy (2007) recommended that soils should be tested every four years, and Mylavarapu (1997) recommended soil testing before changing fertilizer rates. Ferguson and Hergert (2009) suggested that grid-based soil-test information is useful for eight to ten years, but the duration depends on the nutrient analyzed. The length of time producers wait until testing soils may also be determined by a number of producer-specific factors, including familiarity with other precision-agriculture technologies, field conditions and history, the public or private information sources accessed to gather information about precision-agriculture technologies, planning horizon of the farmer, and the inherent soil variability of fields (Walton et al., 2008;Schimmelpfennig and Ebel, 2011).  Variables hypothesized to be associated with the PST adoption decision and the length of time between retesting are grouped by: 1) farm and operator characteristics, 2) information sources, 3) information gathering/processing technologies, and 4) off-farm and regional attributes. Definitions of the covariates, their corresponding weighted and unweighted means, and the hypothesized signs for each decision model are summarized in table 1. The natural logarithm of the total hectares farmed in 2008 (area) was hypothesized to be positively associated with the decision to adopt grid or zone soil testing but negatively related to the years between testing. For the logit and count regressions, the coefficient of this variable is interpreted as elasticity (Wooldridge, 2004). The unweighted (weighted) area farmed in 2008 was 320 (219) ha, with a median of 202 ha. The larger the area managed, the more likely that soil fertility may vary, increasing the difficulty of managing inputs (Walton et al., 2008). Producers may therefore be more likely to invest in precision soil-sampling technologies to determine soil variability, but information about soils may also need to be updated more frequently because, on average, more fields are managed. Land tenure is measured as the proportion of owned land to total farmland operated (landten). The variable landten would be positively correlated with the decision to adopt precision soil sampling, but negatively associated with years between testing if operators who owned relatively more land are concerned about decisions affecting the future soil fertility and quality of their cropland (Roberts et al., 2004). However, operators who own more of the land they operate may be easing out of farming and near retirement, while operators reporting relatively lower ratios of area owned to area operated may rent more land than they own . If so, the expectation is that landten would be positively correlated with the adoption decision, but the sign associated with the period until retesting is uncertain. A positive association suggests proclivity towards waiting longer between tests, which suggests familiarity with fields, a shorter planning horizon, or the use of other technologies to collect and process soil fertility data. Operators reporting higher shares of income from farming (inc f arm) are expected to be more likely to adopt precision soil-sampling technologies and test more frequently. Farmers earning relatively higher profits from agriculture may have the ability and long-term incentive to reinvest capital into maintenance, new equipment purchases, or information. Experienced farmers content with current management plans may perceive changing production practices to be too costly and may resist adoption of new technologies (Batte, Jones, and Schnitkey, 1990). Previous studies analyzing the adoption of precision-agriculture technologies have included both age and years of farming experience in the same model (Daberkow and McBride, 2003;Sevier and Lee, 2004;Paxton et al., 2011). However, because the two variables are likely correlated, including them in the same regression may introduce multicollinearity. The ratio of self-reported farming experience (number of years making managerial decisions) to operator age was used as a relative measure of accumulated knowledge-capital gained from longer commitments to farming ( f armcommit). Producers with higher experience-to-age ratios are hypothesized to be less likely to adopt precision soil-sampling technologies and more likely to wait longer between soil tests. Operators with a bachelor's degree (bs) are expected to be more likely to use PST technologies. Higher levels of education may be associated with an individual's appreciation for problem definition, data acquisition and synthesis, and applied problem solving. But the expected sign of this variable with respect to years between testing is ambiguous. While more educated producers may be able to synthesize and use precision soil-sampling information to make managerial decisions, their actions will depend on the information generated by soil-test results and their ability to interpret results correctly. The percentage of noncotton crop area to total cropland farmed (ocrops) and soil fertility yield variability (yvar) are included in the adoption and period between testing models. The yvar variable is the difference between the farmer's best estimates of lint yields (kg ha \u22121 ) observed on 33% of the most productive area and 33% of the least productive area of their typical field. Ocrops and yvar are hypothesized to be positively related with adoption of soil testing but negatively correlated with the time period between tests. Greater yield variability may encourage the adoption of informationgathering technologies like precision soil sampling but also encourage more frequent testing. Information plays a critical role in the adoption and continued use of precision-agriculture technologies (Jenkins et al., 2011). Lack of information about or technical support for a technology could hasten its abandonment. Conversely, access to and use of precision-agriculture information sources may influence the likelihood of adopting PST and the period between retesting. Information from crop consultants (in f ocons), trade shows (in f oshows), and the use of consultants or input providers to apply inputs (appcons) are hypothesized to be positively correlated with the adoption of PST but negatively associated with the time period between soil tests. These hypotheses relate to field operation consultants and private service providers who may have financial reasons for promoting or marketing soil tests and encouraging producers to test soils more frequently. Information about precision-agriculture technologies also circulates through farmer-to-farmer networks and personal interaction. Information about precision-agriculture technologies obtained from other farmers (in f ooth) could reflect technology abandonment by early adopters dissuading others from adoption or an increase in adoption rates from a critical mass of early adopters triggering adoption of a technology by latecomers. Similarly, we hold no prior on the role of extension (in f oexten) and the intensity of precision soil-sampling adoption or the frequency of soil testing once precision soil sampling is adopted. Nonetheless, information networks are expected to influence managerial decisions. On the other hand, producers relying on media outlets such as the Internet or other news sources to gather information about precision agriculture (in f omedia) are hypothesized to be more likely to adopt soil testing and wait longer before retesting. The Internet has become a popular resource for communicating and acquiring learning materials (Dimmick, Chen, and Li, 2004). Operators who use the Internet more frequently may already be familiar with computer technologies that supplement soil-test interpretation and fertilizer management. Farm-input suppliers locate where market potential is highest, and the geographic locations of dealerships and their availability to customers provides some individuals with greater access to new technologies, services, and experts than those located elsewhere (Pierce and Nowak, 1999). About 59% of agricultural service providers offer precision soil-sampling services (Whipker and Akridge, 2009). The number of farm suppliers located in a county ( f armsupply) is expected to have the same effect as the number of consultants, discussed previously. The use of aerial imagery (image), cotton yield monitors to generate yield maps (ymmap), computers for farm management decisions (com), person digital assistants (PDAs) (handheld), and soil electrical conductivity technologies (electric) were hypothesized to be positively associated with the likelihood of adopting PST. Precision-agriculture technology may be adopted in bundles or sets of technologies (Paxton et al., 2011). Experience with other precision-agriculture technologies may offset unfamiliarity with processing and applying soil-test information, which may increase the probability of adoption and prolong the time between tests. Alternatively, the use of some of these information-gathering technologies may provide complementary information about soil quality, which could increase the time between soil testing. Farmers who tested soils might believe that information generated by soil electrical-conductivity data supplements or duplicates soil-test results. If true, producers using these devices might extend the period between soil tests, putting more weight on (for example) the information obtained from soil electrical-conductivity readings in making site-specific fertilization plans. Similar conclusions could be drawn with respect to the use of other information-gathering technologies such as aerial imagery or remote sensing. The use of precision soil sampling and variable-rate input management is another example of technology stacking in the sense that one information-gathering strategy leads to another action, which may mean adopting additional technologies, reformulating nutrient-management plans, or contracting custom application services. For producers using the information obtained from PST, the next step could entail making a variable-rate fertilizer management plan. To address this question, the survey asked, \"Have you ever made a Variable Rate Fertilizer Management Plan using the GPSreferenced soil sample information?\" The use of a variable-rate technology plan (vrt plan) based on GPS-referenced soil-test information is excluded from the adoption equation but included in the time-between-testing equation. In the survey, cotton producers could only respond to the question concerning the formulation of a GPS-referenced variable rate fertilizer management plan if they had conducted precision grid or zone soil sampling. Producers who made a variable-rate fertilizer management plan may be more attentive to soil-nutrient carryover and soil-amendment timing and generally be able to determine how their fertility management practices impact soil quality. Therefore, farmers who reported making a variable-rate fertilizer plan based on the georeferenced soil-test data are hypothesized to test soils more frequently. Six regional dummy variables from the USDA's Economic Research Service were included in the adoption and frequency of retesting models (Heimlich, 2000). The Southern Seaboard region is the reference category. The Heartland (heartland), Prairie Gateway (prairie), Eastern Uplands (eastup), Fruitful Rim ( f ruit f ul), and Mississippi Portal (missport) regions are included to control for geographic differences in growing seasons, weather conditions, and input costs (Khanna, 2001)."}, {"section_title": "Results", "text": "Measures of fit for the logistic, truncated count (Poisson and negative binomial) and hurdleregression specifications based on the post-stratification weighted and unweighted data are reported table 2. The null hypothesis that the dispersion parameter of the truncated negative binomial was 0 could not be rejected at any conventional level (LR = 0.002, with P = 0.99, df = 1, table 2). Therefore, only the zero-truncated Poisson estimates are reported. The sum of the logistic log likelihood with the log likelihoods of the zero-truncated Poisson model or the negative binomial model were equal to the log likelihoods of the Poisson hurdle and negative binomial hurdle models, respectively, as expected (table 2). The Akaike's Information Criteria (AIC) corroborated these results, with post-stratification weighted and unweighted Poisson hurdle models exhibiting the lowest AIC values. The percentile-t test comparisons of the logistic (table 3) and zero-truncated Poisson models (table 4) suggest some differences in the post-stratification weighted and unweighted estimators, but in general the sample and population-adjusted estimates are similar. The logistic regression coefficients are different for the information source variable appcons, the information technologies ymmap and handheld, as well as the regional variables prairie, f ruit f ul, and missport. The differences in the marginal effects of these variables were not remarkable except for handheld. Turning to the zero-truncated Poisson model (table 4), the only statistically significant differences between the weighted and unweighted estimators were those associated with farm size (area), cropland ownership (landten), and the regional variable missport. The marginal effects of these variables on the period between testing do not appear to be remarkably different, suggesting that the central tendency measures of survey respondents closely approximate those of the population of cotton producers. The variance inflation factors suggested collinearity was not serious for the logistic model (average 2.2; maximum 8.2) or the zero-truncated Poisson model (average 1.9; maximum 7.1). The adoption model performed well, with 91% of the respondents correctly classified as adopters in both the weighted and unweighted models. The null hypothesis that the covariates were jointly uncorrelated with the decision to adopt precision grid or zone soil testing was rejected at the 1% level (Wald test = 261, df = 25). The statistically significant regression results in tables 3 and 4 are summarized below as approximate averages or the range of weighted and unweighted estimates, highlighting only where substantial differences in inference occur."}, {"section_title": "Precision Soil-Sampling Adoption", "text": "Logistic regression estimates based on the survey sample suggest that the likelihood of adopting precision soil sampling increased with the farmer's assessment of within-field cotton yield variability (yvar) (table 3). The marginal effect was significant, suggesting that a one-unit increase in the yield variability index was associated with a 0.6% increase in the likelihood of adoption. The magnitude of the weighted marginal effect of yvar on the probability of precision soil sampling adoption was similar to the unweighted estimate, although the weighted coefficient was statistically insignificant. The association between yvar and adoption was moderated in terms of precision by placing more emphasis on operators responding to the survey managing relatively smaller farms. Cotton farmers obtaining information about precision agriculture from trade shows or other public demonstrations (in f oshows) were, on average, 3% to 4.3% more likely to have used precision soil sampling (table 3). Producers who hired consultants to make fertilizer-management recommendations or to apply fertilizer (appcons) were, all else equal, 40% to 42% more likely to report using precision soil sampling. Private consultants and companies attending trade shows anticipating financial benefits from producers adopting precision soil sampling technologies, with promotion of GPS-referenced soil testing as a component of their marketing strategies, could explain these results. Cotton growers producing maps with yield monitors (ymmap) were, on average, about 20% more likely to have used PST. Mapping yield data over time could be correlated with field sections that need to be amended with lime, potassium, or other nutrients. Producers could test such hypotheses by sampling potential problem areas identified by yield monitor data. Producers who used handheld devices to manage inputs (handheld) were about 28.1% to 40.5% more likely to have used precision soil sampling, which supports previous suggestions of complementarities between these technologies (Walton et al., 2010). Finally, cotton farmers located in the prairie (prairie) and coastal ( f ruit f ul) regions of the survey area were approximately 10% and 5% less likely to have used precision soil sampling compared to farmers located in the Southern Seaboard region. In the Mississippi Portal region (missport), farmers were, on average, 5% to 7% more likely to have used precision soil sampling compared to farmers in the Southern Seaboard region. Soil-type variability and fertility potential may be relatively higher in the Mississippi Valley due to the alluvial flood plains. Regional concentration of cotton production was also relatively higher in the Southern Seaboard and Mississippi Portal regions compared to the prairie regions represented in the survey."}, {"section_title": "Years between Soil Testing", "text": "The zero-truncated Poisson regression for years between soil testing is less precise; fewer covariates were correlated with the outcome variable (table 4). The association between the frequency of GPS- referenced soil-testing strategies and farm size (area) is negative and significant in both the weighted and unweighted models. A 1% increase in the area operated is associated with a 0.37-to 0.58-year decrease in the interval between soil tests. The number of years between soil testing increased with land tenure (landten) and accumulatedknowledge capital gained from longer commitments to farming ( f armcommit) (table 4). A onepercentage-point change in the experience-to-age ratio was associated with a positive change in the years between tests (0.03 years). Cotton growers in the Mississippi delta region waited longer than producers in the Southern Seaboard region to retest soils. The use of a variable-rate fertilizer plan based on GPS-referenced soil-sample information (vrt plan) was associated with a decrease of 1.4 years in the interval between soil tests. From the profit maximizing perspective of producers, more frequent testing could provide information about the effectiveness of fertility amendment plans over the medium term. Information pertaining to the distribution of soil-nutrient needs may not always lead to overall reductions in input use, but in some cases it could decrease the likelihood of unneeded applications and would be expected to increase input efficiency. These findings may also be encouraging for conservation program managers to the extent that payment eligibility for some best fertilizer management practices was tied to soil fertility and input monitoring. The coefficient associated with the use of electrical conductivity devices (electric) was positive and significant. Respondents using electrical conductivity devices to monitor soil fertility waited to conduct GPS-referenced soil tests, on average, 1.18 years longer. However, an association between soil-testing frequency and electrical-conductivity devices was not evident when the zero-truncated Poisson model was estimated using the post-stratification weights (i.e., reducing the influence of relatively large farms). Thus, without extrapolating beyond the sample of respondents, there appears to be evidence suggesting that some field information-gathering technologies may be perceived by producers as substituting for soil-test information collected on GPS-referenced sampling areas."}, {"section_title": "Conclusions", "text": "This research builds on previous precision-agriculture technology-adoption studies by providing information about how long cotton producers wait before retesting soils, given the adoption of GPSreferenced soil testing, or PST. The adoption of PST by cotton farmers in the U.S. cotton belt and the perceived usefulness of soil-test information over time were analyzed using a Poisson-hurdle regression model. Findings suggest that operators who gathered information from trade shows, hired consultants to apply inputs, generated yield maps with yield monitors, or used handheld devices to manage information were more likely to adopt PST. Subsequent to PST adoption, more experienced farmers, farmers with larger farms, farmers owning more of the land they operated, and farmers using sensor-based technologies waited longer before updating soil-test information. Cotton farmers who developed variable-rate fertilizer plans based on precision soil tests retested soils earlier. With respect to the post-stratification weighting procedure, use of the percentile-t bootstrap method revealed significant differences in some instances between the weighted and unweighted data, suggesting that attempts to increase the representativeness of the sample (such as through the proposed post-stratification protocol developed in this study) should be pursued. Understanding the factors contributing to the perceived usefulness of PST information provides guidance to agribusinesses. Dissemination of precision-agriculture technologies continues to be driven by farm-input suppliers and machinery dealerships. User information gaps reflect differences between individual producers' ability to process and apply information generated by precisionagriculture technologies. These gaps are influenced by a variety of factors related to social and economic characteristics of producers as well as individual ability. To bridge these gaps, agribusinesses and trade-show sponsors may be inclined to target farmers already using precision technologies that complement information from GPS-referenced grid or zone soil sampling. Findings also provide insight into the design and monitoring of conservation programs targeting the adoption of nutrient-management plans and producer willingness to continue best management practices after contracts expire. Clearly, one-size-fits-all programmatic expectations about soiltesting frequency may not coincide with farmers' willingness to participate and continue a best management practice in the absence of program support. How frequently producers should conduct soil tests and revise nutrient management plans likely varies on a case-by-case basis, depending on the experience, life-planning stage, site-specific factors, and the importance of farming as perceived by producers. Current federal conservation programs focusing on nutrient management suggest updating soil-test information every four years. Yet in-sample and population-weighted results suggest that producers may indeed test soils more frequently. Producers with operations in watersheds that are near or surpass total maximum daily loads for nitrates or phosphorous and who test soils more frequently could be acknowledged for their current management practices through various cost-share arrangements supported by programs like the Conservation Stewardship Program or EQIP. Cotton producers also appear to maintain perceptions about the substitution between information obtained from PST and information generated from newer sensor-based technologies (e.g., electroconductivity maps, yield monitor maps, or other maps generated from sensor-based technologies). Operators of larger farms more frequently adopt advanced sensor-based information gathering devices, and evidence suggests that these devices are considered proxies for information obtained from GPS-referenced grid or zone soil testing. This complementary use of precision soiltest information and other technologies generating multivariate data about soil nutrients is presently anecdotal in terms of producer perceptions and agronomic realities. With the recent interest in nutrient-management plans and producer eligibility to receive cost-share payments for adopting nutrient-management plans, the role of other precision-agriculture technologies in the development and implementation of these plans should be investigated. Numerous methods are available whereby soil-test data can be collected and applied to make management plans, in addition to georeferenced soil-test data. For example, producers might develop yield maps to delineate zones across a field and then test soil in each zone without affixing GPS positions to test locations. Although this study deals specifically with the effects on soil-test frequency of creating fertility management plans from georeferenced soil-test data, future studies could explore the complementarities between soil testing and other sensor-based technologies and how they could inform best fertilizer-management practices. Findings from these research activities could help define or revise state and federal program parameters, potentially increasing the flexibility of programs recognizing that sensor-based technologies may be useful for supplementing soil nutrient information and managing fertilizer inputs. [Received June 2013; final revision received February 2014.] "}]