[{"section_title": "", "text": ". A-3  Table 3."}, {"section_title": "1990-91 SASS Teacher Transcript Study", "text": "The Family Educational Rights and Privacy Act (FERPA) A-4 Table 4a. B&B:93/94 Longitudinal Study A-5 Table 4b. B&B:93/94 Transcript Collection Procedures A-5 Table 5."}, {"section_title": "Introduction", "text": "Since the 1980s, policymakers, educators, and analysts have discussed the relationship between the quality of teachers in the nation's classrooms and the condition of education. With the right data, policymakers and others interested in education reform would be better equipped to address such issues as: the quality of prospective and current teachers; differences, if any, between college graduates who become teachers and those who choose other professions; and changes in teacher quality over time. Analysis of such data might also provide insight into the relationship between teacher quality and student achievement and the differential characteristics of various measures of teacher qualifications, such as ability, content knowledge, pedagogic knowledge, and teaching credentials. For this paper, we distinguish among the terms teaching quality, teacher quality, and teaching qualifications, and address only the last of these. Conceptually, measuring teaching quality ought to be a high priority of any examination of teaching and learning, since, literally defined, it represents the direct effect on students by teachers as they create their classroom magic. Teacher quality, representing some measure of the dynamic characteristics, abilities, and decisions of teachers is, like teaching quality, a complex and subjectively defined concept. Teaching qualifications, static measures grounded on relatively objective assessments of the skills, abilities, and knowledge that others have determined to be important, may also be subject to much debate, but at least have been administratively defined and addressed at the state level. This paper focuses exclusively on teacher qualifications. Measuring teacher qualifications is conceptually and practically more approachable than defining and measuring teacher quality or teaching quality, despite the measurement limitations and data challenges identified in this paper. Measuring teacher quality and teaching quality would each likely require substantially more research, review, thought, and discussions with national experts as preliminary steps toward developing a consensus definition, measurement objective, and data collection program. Of the three objectives, better national measurement of teacher qualifications may be the most reachable. In this review, we identify existing and potential measures of teacher qualifications as a single aspect of teacher quality. We categorize the types of teacher qualification measures, discuss the sources of data, and the availability and quality of data collected from these sources. Teacher qualification measures, data collection surveys, and sources discussed in this paper are shown in Table 1 of the Appendix. This focus on teacher qualifications does not at all imply that qualifications are better indicators of quality than, for example, knowing the level of cognitive demand associated with a teacher's emphasis on selected curriculum topics, or understanding the unique mix of instructional practices a teacher orchestrates as she or he moves through the curriculum. Those are indeed important topics and deserve concerted effort to define, measure, and track, but would require substantially more attention than can be provided by this brief review of existing and potential measures."}, {"section_title": "Teacher Qualification Measures", "text": "For this paper, we have grouped measures of teacher qualifications into four categories: (1) ability or aptitude, (2) content knowledge, (3) pedagogic knowledge, and (4) teaching credentials. For each category, we discuss the underlying rationale and current and potential measures."}, {"section_title": "Ability or Aptitude", "text": "The strength of one's verbal, mathematical and analytic skills is considered to be a strong sign of an individual's ability or aptitude. Scores on national assessments of these areas are part of the information used by many institutions of higher education to determine a candidate's suitability for admission. Consequently, regardless of their academic plans or intended occupations, the majority of college-bound students across the country take the SAT and/or ACT when applying for undergraduate study and the GRE when applying for graduate study. Scores from the National Teacher Exam (NTE) and Praxis I of the Praxis Series: Professional Assessments for Beginning Teachers are other measures of the ability and reading, math, and writing skills of prospective and beginning teachers. Students seeking entry into certain teaching programs and those applying for teacher licensure in some states are required to take the NTE or Praxis I. The NTE is used for entry into some teacher preparation programs and for state licensing. Praxis I is the first component of ETS's new series of program and licensing exams intended to ultimately replace the NTE. With data from these large-scale, nationally-taken, standardized tests, analysts can gauge the caliber of prospective and current teachers. Since these tests have been given for a number of 2 it years (more than 50 years in the case of the SAT), analysts can identify national trends or significant shifts in the ability of cohorts of test takers over time, develop an informal measure of the selectivity of colleges and universities using average SAT scores of admitted students, and assess the quality and analyze changes over time of the teacher supply pool and current teaching force using the NTE and Praxis I scores. In an essay on the undergraduate experiences of teachers, analysts compared the college entrance exam score data of 1992-93 Baccalaureate and Beyond (B&B:92-93) sample members and found that teachers tended to perform below non-teachers on these achievement tests (Henke, Geis, and Giambattista, 1996). As noted in the essay, \"At several points along the teacher pipeline, those more inclined toward teaching tended to have lower college entrance examination scores ... than those less inclined toward teaching\" (p.15). While national exams do permit national cross-sectional and longitudinal comparisons, there are potential limitations to relying solely on these tests as measures of teacher qualifications. As Berliner and Biddle (1995) note, for example, the SAT is a \"one shot, multiple-choice test that is taken by high school seniors (and) assesses only students' knowledge of a fixed set of topics in mathematics and English...\" (p. 22). Ingersoll (1996) recognizes the near-universal availability and face validity of SAT scores, but strongly questions their use to measure ability. Recent changes in the format of the SAT may also be problematic for analysts interested in mapping trends in teacher qualifications over time. Since ACT content topics are revised each year to reflect changes in the curricula at colleges and universities, making longitudinal comparisons based on ACT scores may also be problematic (Berliner and Biddle, 1995). Analysis of NTE or Praxis data is also limited since analysts do not have access to individual-level information on NTE or Praxis scores."}, {"section_title": "Content Knowledge", "text": "While standardized measures of ability may be a basic starting point for assessing teacher qualifications, they provide little information about teacher knowledge of particular content areas. Teachers with academic backgrounds in the subject of their main teaching assignments are presumed to be better prepared than those teaching outside their field of academic study. Analysts can assess the level of teachers' content knowledge using data on the type and number of courses taken, majors and minors, credits earned in specific subject areas, and achievement in specific subject areas. Current measures of subject knowledge include: Praxis II: Subject 3 ii Assessments test scores; GPA in major; area of certification; GRE subject test score; number and type of courses taken; credits earned; and undergraduate/graduate major and/or minor. Content knowledge and measures of it are time-sensitive in that some content knowledge has a limited lifespan. This suggests that measuring content knowledge may be more relevant for beginning teachers than for experienced teachers. Data on these measures help estimate the effect on student achievement resulting from assigning teachers to subjects outside of their certification or major field of study. While Praxis II and GRE subject scores are standardized and therefore easily compared, GPA and course information are limited in that both are relative to the granting institution's policies and procedures, as well as variations in the academic rigor or level of difficulty of the courses taken by students."}, {"section_title": "Pedagogic Knowledge", "text": "Ability, content knowledge, and certification communicate little about teachers' understanding of content-specific pedagogy or their ability to successfully share their content knowledge with students. SAT scores and the number of courses taken are not clear indicators of how well teachers communicate with, motivate, challenge, or engage studentsall traits one might consider when measuring teacher qualifications. While it is clearly desirable to collect data on pedagogic knowledge and ability, this measure is more difficult to quantify and may be more subjective than ability or content knowledge. Some tests and standards for quantifying pedagogic knowledge have been developed; more are in the process. They include National Board for Professional Teaching Standards (NBPTS) certification; Praxis III: Classroom Performance Assessments, which is being pilot tested in Ohio (ETS, 1998); and the Interstate New Teacher Assessment and Support Consortium (INTASC) Test for Teaching Knowledge, which is being developed. Praxis III: Classroom Performance Assessments are performed by trained assessors using a combination of in-class observations of teaching performance, written documentation, and preand post-observation interviews. Using a common evaluation framework, ETS expects Praxis Ill results to contribute to state licensing decisions (ETS, 1998). The National Board for Professional Teaching Standards is currently setting advanced standards in more than 30 certificate fields and developing multi-part assessments that will be used to measure the professional skills, knowledge, and accomplishments of teachers applying for National Board certification. To date, standards have been developed in 21 fields (NBPTS Web Site, 8/4/98). INTASC is currently developing the INTASC Test for Teaching Knowledge. With this test, they intend to measure beginning teachers' understanding of foundational knowledge and the skills essential to the teaching profession, such as child development, theories of teaching and learning, diagnostic skills, and the role of student background in the learning process (Council of Chief State School Officers Web Site, 8/4/98)."}, {"section_title": "Teaching Credentials", "text": "Data on teaching credentials include: degree(s) earned, name of the degree-granting institution, overall GPA, state teacher certification, and years of teaching experience. NCATE accreditation of the degree-granting institution is another potential measure of teacher quality. Such data may enable analysts to test the hypothesis that higher quality teachers have certification, high overall GPAs, advanced degrees from accredited teacher-training programs, and more teaching experience. Variations in standards and procedures used by universities in the grading process and by states in the teacher certification process (National Research Council, 1992), however, may limit analysts' ability to generalize and compare teacher quality using state certification or GPA. ETS notes that state \"qualifying scores [on Praxis] vary considerably across [the different subject] tests, depending on each test's level of difficulty, and across states\" (ETS, 1998, p.4). Furthermore, only 31 states plus the District of Columbia and the Virgin Islands use one or more Praxis exams for state teacher licensure (ETS, 1998). Comparisons based on GPAs must also be viewed with caution. While data from B&B:92-93 illustrate that teachers tend to have higher GPAs than non-teachers, Henke et al. (1996) suggest that this discrepancy is partly explained by differences in course-taking between these two groups, noting that: ...those who taught, only prepared to teach, or were only considering teaching were more likely than other graduates to have taken education courses, less likely to have taken advanced mathematics and calculus, and tended to take fewer courses in science or engineering. Because grades in education course tend to be higher than those in advanced mathematics, calculus, science, and engineering courses, the mix of courses taken by those inclined to teach tended to result in higher GPAs than the mix taken by those who were not so inclined. (Henke et al., 1996, p. 15) 5"}, {"section_title": "13", "text": "Data Sources: Availability and Quality The two principal sources for teacher qualification data are: (1) self-reports on questionnaires like the Schools and Staffing Survey (SASS) and (2) teachers' academic and testscore records maintained by colleges/universities, the Education Testing Service (ETS), and the American College Testing (ACT) Company. In this section, we assess the availability and quality of data collected from these sources."}, {"section_title": "Self-report Questionnaires", "text": "Survey questionnaires provide the most common and cost-effective way of collecting nationally representative data on teachers and their qualifications. The following NCES data collections have gathered teacher qualification data from the self-reports of individuals who are considering teaching, studying to be teachers, currently teaching,  Table 1 of the Appendix, we present the topics covered by each survey. Availability. Response patterns from the Chaney (1994) sub-sample of the 1990-91 SASS indicate, not surprisingly, that very specific and/or sensitive items generate fewer responses than non-sensitive questions. For example, the response rates ranged between 97 and 100 percent for general questions on degrees earned, while response rates for more specific questions on courses taken in teachers' second teaching assignment were between 38 and 59 percent. Response rates also tended to be lower for questions concerning the number of courses or credits taken than for items on whether or not courses had ever been taken. For example, 88 percent of teachers responded to a general question on whether they had taken courses in computer science, but only 73 percent responded to a more specific question of the number of undergraduate computer science courses taken. Similarly, the percentage of responses on courses in teaching methods or education (98 percent) was higher than the percentage of responses on the specific number of teaching methods or education graduate courses (78 percent) (Chaney, 1994). 14 Similarly, B&B:93/94 respondents were less likely to respond to questions about their individual academic achievement. Nearly 30 percent of respondents reported that they did not know their SAT score and 0.4 percent refused to answer; more than 25 percent said they did not know their ACT scores and 0.3 percent refused to answer; and 58 percent said they did not know their advanced GRE score (Green, Meyers, Giese, Law, Speizer, Tardino, & Knepper, 1996). \"Don't know\" responses were also high for questions on state teaching exam scores (33 percent) and undergraduate GPA (14 percent). Considering such low response rates, Henke et al. (1996) suggest using college transcripts as an alternative data collection method. Quality. The level of detail, sensitivity of an issue, and the respondent's ability to accurately recall affect the quality of data gathered from teacher self-reports. Chaney (1994) examined the accuracy of teacher self-reports of college attendance on a small sample of SASS teacher questionnaires by comparing self reports to school transcripts. He discovered errors in both directions: some teachers reported school attendance not verified by the school and others failed to note attendance that was later indicated by the school. That study requested 1,835 transcripts for 592 teachers and received 1,356 transcripts (74 percent). For 134 (9.9 percent) of all the transcripts requested, schools were unable to locate the transcript or said that the individual had never attended that school. (Of those 134 requests, Chaney's team determined that 121 were teacher misreports and 13 were college errors.) Additionally, the team received 168 transcripts 0 ...reflecting an undergraduate or graduate enrollment that had not been indicated on the SASS questionnaires. 0 This represented 9 percent of all known transcripts for that sample (Chaney, 1994). "}, {"section_title": "Student Records", "text": "Past NCES-sponsored data collections have obtained transcripts, other student record data, and standardized test scores of individuals who are considering teaching, studying to be teachers, currently teaching, or who have previously taught. The following NCES surveys include student record data: SASS:90/91 Teacher Transcript Study, B&B, HS&B, RCG, NLS:72, BPS, and NPSAS. These data collection efforts obtained student record information from colleges/universities, and in some cases, ETS, and ACT, Inc. Availability. Legal issues involving individual privacy, financial costs, and time constraints each affect NCES' access to data on teacher qualification measures. The Family Educational Rights and Privacy Act is the legal statute that protects the privacy of student education records. There are some cases in which signed consent is waived, but this is not the norm. The sections of the law that directly relate to NCES' (or its authorized representative) authority to collect these data are included in Table 3 of the Appendix. In addition to FERPA, data collectors must consider the policies and longevity of data maintained by ETS and ACT. ETS maintains records of SAT scores dating back to 1941, but expunges GRE records five years after the exam is taken. ACT records are available from 1968 forward. To access SAT, ACT, or GRE data requires the test taker's permission, date of birth, and Social Security Number. Knowing the approximate time frame in which a student took the test also facilitates the collection of these records. Collecting student record abstracts or matches has additional costs. The price of college/university transcripts ranges from $5 to $12 (Dennis Carroll, NCES, personal communication, 9/15/98). Additional expenses to collect transcript data include technical assistance to schools and computer software to facilitate uniform record abstraction. ETS and ACT also charge for the release of student test data. Drew Malizio, NPSAS Project Officer, estimates that record matches done with ETS and ACT for NPSAS:95/96 and B&B:92-93 cost $25,000 to $35,000 (personal communication, September 17, 1998). Following are three examples of recent NCES data collection efforts that included student record abstracts br ETS and ACT matches: B&B:93/94 requested transcripts for all respondents who received bachelor's degrees from schools that had participated in the National Postsecondary Student Aid Study (NPSAS) (Green et al., 1996). In six months, transcripts were collected for 98 percent of the eligible sample (Green et al., 1996). NPSAS data collectors performed post-interview matches with ETS and ACT of SAT and ACT scores for the NPSAS:95/96 sample of beginning students enrolled in four-year institutions. The record match took four to six weeks to complete (Drew Malizio, personal communication, September 18, 1998). As a result of the NPSAS:95/96 student record abstract and the ETS and ACT matches, NPSAS:95/96 obtained either an SAT or ACT score 16 8 for 85 percent of the students in the sub-sample (Paula Knepper (NCES) and Dan Kasprzyk (NCES), e-mail communication, July 7, 1998). In the 1990-91 SASS Teacher Transcript Study, 592 eligible teachers (71 percent) agreed to participate. Three hundred and forty-nine teachers (59 percent of teachers who agreed to participate; 42 percent of the eligible sample) provided signed consent. The other 143 teachers gave verbal consent during their telephone interview or supplied sufficient information for the release of their student record data. Tables 2, 4a, 4b, and 5 of the Appendix provide more detailed information on the collection procedures and success of these student record abstracts. Quality. While student records are likely to be the most reliable source for data on teacher qualification data, analysts must not assume that these data are error-free. For example, transcripts may not provide a complete picture of teachers' course-taking histories. Transcripts from the degree-granting institution may exclude courses teachers completed at other universities during their undergraduate studies. Data taken from student records are not easily standardized or representative either. Schools may vary in the way failures, withdrawals, remedial/not-forcredit courses, and incompletes are treated (Chaney, 1994). Relying on transcripts to obtain data on GPAs also has certain drawbacks. GPAs are relative to courses taken and schools attended and make it difficult to compare individuals with different academic backgrounds (Henke et al., 1996). Course-catalogs and descriptions of the school's grading systems are needed in concert with transcripts for analysts to even begin to interpret GPA."}, {"section_title": "Summary", "text": "This review examined existing and potential measures of teacher qualifications, focusing on their underlying rationale, the ways such data may be used, and the availability and quality of data collected from various data sources. Ability or aptitude is often measured by SAT, ACT, GRE, NTE, and Praxis I scores; the tests are standardized and widely taken across the country; and their results can be easily generalized and compared. Data on all of the measures except for NTE and Praxis I scores can be collected from self-reports, transcripts, and national test records. Low response rates and false reporting on self-reports reduce the availability and reliability of self-reported data on ability measures; accessing such data from national testing organizations can be complex or impossible. Transcripts may be the best source for collecting these data. Analysts question the relationship between scores on these national tests and ability."}, {"section_title": "9' 1 7", "text": "Content knowledge has been measured by Praxis 11 scores, GPA in major, area of teaching certification, GRE subject test scores, number and type of courses taken, credits earned, and undergraduate/graduate majors and/or minors. Transcripts are a direct and reliable method of collecting information on GPA in major and the exact number of courses taken in a field. Transcripts and/or ETS records provide the most reliable information on GRE subject test scores. Because of variations in grading systems and course content among postsecondary institutions, however, GPA and course-taking data are not easily generalized or comparable across individuals from different academic backgrounds. Self-reports are the most efficient and costeffective way to collect complete and reliable data on the remaining content knowledge measures, especially Praxis II scores. Content knowledge may be most relevant for beginning or new teachers. NBPTS certification, Praxis III scores, and INTASC scores provide a measure of pedagogic knowledge and/or teaching ability. These measures have yet to be used widely and have not been collected on a national level. Teaching credential measures include overall GPA, highest degree earned, name of degree-granting institution, NCATE accreditation of that institution, and teaching experience. With the exception of GPAs, which are more accurately provided by transcripts, self-reports may be a complete and reliable source for data on this type of basic background information."}, {"section_title": "This review suggests that:", "text": "Most data collected on teacher qualifications have been general information (i.e., degrees earned or major) with response rates similar to other non-sensitive items. Collecting information that is highly specific, sensitive, or difficult to recall (i.e., GPA or SAT/ACT score) has been done less often and with response rates substantially lower than average. The Schools and Staffing Survey and the Baccalaureate and Beyond study currently collect the most information on the broadest range of teacher qualification measures. The Baccalaureate and Beyond study and the survey of Recent College Graduates are the only NCES data collections that collect information on teachers' tested ability or academic achievement. Teachers' academic records provide a detailed and complete picture of teacher qualifications, but access to these records has legal and financial considerations."}, {"section_title": "Future Directions", "text": "Building on the information and understanding developed from the previous efforts reported above, and in concert with the SASS staff, we make the following recommendations. Each relies on a different data source that could lead to improved national measures of teacher qualifications. Investigate the feasibility of a transcript study as part of the Teacher Followup Survey, given that the SASS timetable is too advanced to add non-fieldtested items. Determine the cost of college transcript studies and whether the FERPA requirement for signed consent could be waived. Will the added value of transcript datai.e., the completeness of information, level of detail, and the accuracy of data on measures like coursetaking and GPAoutweigh the legal and financial burdens to collect it? Transcript studies would provide information on teacher aptitude and knowledge of content areas and pedagogic techniques; repeated data collections could address change over time in the qualifications of the teaching force. Examine teacher response to providing signed consent, Social Security numbers, and other personal identifying information required by ETS and ACT for the release of SAT, ACT, GRE, and Praxis scores. SAT, ACT, GRE, and Praxis I scores could provide information on teacher ability and aptitude; Praxis II and some GRE scores would provide a measure of content knowledge. This could be done by using a sub-sample of the SASS teacher sample. Determine the type and availability of data collected by states for teacher certification. What data do states routinely collect, how long do they mainatin these data, and what is the quality? What are the idiosyncrasies of state record collection practices that may facilitate or impede cross-state comparisons? Then explore the possibility of obtaining qualification data on teachers from state records. Will states and/or teachers consent to the release of this information? State records could be expected to include data that measure aptitude, pedagogic knowledge, content knowledge, and teaching credentials. Each exploration should consider: (1) the recency of information and its effect on quality, (2) the degree to which measurements might be expected to change over time and so influence data collection frequency, (3) the level at which the data are best collected, (4) the method by which data are best collected, and (5) whether and how such information on teacher qualifications would inform our understanding of the quality of college graduates choosing to be teachers (relative to others) and the changes in teacher quality over time."}, {"section_title": "11'", "text": "Teachers are the primary deliverers of K-12 education. Having commonly accepted national measures of teacher qualifications will help policymakers and the public determine and appreciate the quality of the teacher force and, if necessary, identify steps to maintain that quality."}, {"section_title": "0", "text": "Pratt, D.J., Whitmore, R.W., Wine, J.S., Blackwell, K.M., Forsyth, B.H., Smith, T.K., Becker, E.A., Veith, K.J., Mitchell, M., & Borman, G.D. (1996)    The B&B:93-94 study is the first in a series of five-follow up interviews of persons who received a bachelor's degree in the 1992-1993 academic year. Baseline data for the B&B:93 cohort were collected as part of the National Postsecondary Student Aid Study (NPSAS:93). The first follow-up interview (B&B:93-94) collected information from respondents one year after they received their bachelor's degree. Subsequent interviews will take place at three year intervals. By the end of the 12-year period, most students who attend graduate or professional schools should have completed, or nearly completed, their education and be established in their careers."}, {"section_title": "Sample Size and Response Rates", "text": "12,478 students were initially identified as potential B&B sample members during the NPSAS:93 data collection. As part of the B&B:93-94 first follow-up, a transcript was requested for all of the 12,478 students initially identified as eligible for the B&B:93 sample. In all, 626 of the 635 (99 percent) of the eligible schools complied with the request for student transcripts, and another 80 schools (1,258 students) were considered out-of-scope, resulting in a transcript collection rate of 98 percent at the student level (10,970/11,220). Of the initially identified 12,478 cases, 1520 were found to be ineligible or out of scope (primarily because their graduation date fell outside the July 1 June 30 window), leaving a total of 10,958 eligible-cases for the B&B:93-94 interview. Interviews were completed with 10,080 (92%) of these students. Of the 8% of students that did not participate, 6% refused to take part, and another 1 percent did not participate for other reasons. Just under 1% of potential respondents could not be located. Source: The B&B 93-94 First Follow-up Methodology Report a student checklist with the names and other relevant information for each student for whom a transcript was requested; a request for reimbursement form and postage paid return envelope in which to send student transcripts. Schools were also asked to provide a course catalog and information on their grading and credit-granting systems and school term. Source: The B&B 93-94 First Follow-up Methodology Report A-5 30 . Table 5: Accessing ETS and ACT Record Data Overview NPSAS data collectors performed post-interview matches with ETS and ACT of SAT and ACT scores for NPSAS:95/96 sample beginning students enrolled in four-year institutions. They also performed a match with ETS for the GRE scores of the B&B:92-93 cohort. Below we describe the legal issues, financial costs, and timeframe of this collection, as well as the results of the match.'"}, {"section_title": "Legal Issues", "text": "Since data were requested for NPSAS sample members, neither ETS nor ACT required the permission of the test takers before releasing test score data. NCES did, however, assure ETS and ACT that student data would be handled confidentially and that individual scores would not be released. Analysts with access to these data were required to sign affidavits stating that they would protect the confidentiality of each student."}, {"section_title": "Financial Issues", "text": "While he did not have exact figures, Drew Malizio, the NCES staff person on this project, estimates that the combined cost of attaining the data from ETS and ACT for the NPSAS:95/96 and B&B:92-93 samples, was between $25,000 and $30,000."}, {"section_title": "Timeframe", "text": "Drew Malizio estimates that it took between four and six weeks to attain these data from ETS and ACT."}, {"section_title": "Results", "text": "As a result of the match and the student record abstract done in NPSAS:95/96, NPSAS now has either SAT or ACT scores for approximately 85 percent of the approximately 12,000 beginning students in 4-year institutions included in the NPSAS:95196 sample. The results of the GRE match are not yet available."}]