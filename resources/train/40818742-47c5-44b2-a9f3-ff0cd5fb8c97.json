[{"section_title": "Introduction", "text": "Structural equation models (SEMs) constitute a popular framework for formulating, fitting, and testing an abundant variety of models for continuous interval-level data in a wide range of fields. Special cases of structural equation modeling include factor analysis, (multivariate) linear regression, path analysis, random growth curve and other longitudinal models, errors-invariables models, and mediation analysis (Bollen 1989; Kline 2011) . The main development of structural equation modeling has been in social science fields such as psychology (Ullman and Bentler 2003) , education (Kaplan 2008) , and sociology (Duncan 1975; Saris and Stronkhorst 1984) , while more recently structural equation modeling is finding applications in other fields such as ecology and biology (Grace 2006) and neuroscience (Mclntosh and Gonzalez-Lima 1994; Roelstraete and Rosseel 2011) .\nWhile classical SEM theory assumes independently and identically distributed (iid) observations (Bollen 1989) , applications often require the analysis of data from complex surveys that may involve stratification, clustering, and unequal selection probabilities, violating this assumption (Skinner, Holt, and Smith 1989; Muth\u00e9n and Satorra 1995, p. 281) . For example, Marsh and Hau (2004) explained the relations between academic self-concepts and achievements in a 26-country complex multistage survey. Outside of the realm of complex surveys clustering may also occur, for instance in Byrnes et al. (2011) 's analysis of the effect of storms on kelp forest food webs, where variables such as kelp density and species richness are likely correlated across sites that are geographically close to each other. It is well-known that under complex sampling, both point and variance estimators derived under iid assumptions may produce biased and inconsistent estimates (Cochran 1977; Skinner et al. 1989 ). This finding was reproduced for SEM parameter estimates by Kaplan and Ferguson (1999) and Asparouhov and Muth\u00e9n (2005) . Hahs-Vaughn and Lomax (2006) analyzed student data from the Beginning Postsecondary Students Longitudinal study to explain college experiences and learning outcomes with pre-college traits, showing that SEM parameter estimates, standard errors, and fit measures can change dramatically when complex sampling is taken into account.\nAdjustments to point and variance estimators for SEMs under complex sampling were discussed by Muth\u00e9n and Satorra (1995) and Stapleton (2006) , and estimation using pseudomaximum likelihood procedures by Asparouhov (2005 Asparouhov ( , 2006 and Asparouhov and Muth\u00e9n (2005) . For an overview of literature related to complex sampling in structural equation modeling, see Bollen, Tueller, and Oberski (2013) . These procedures have since been implemented in standard closed-source commercial software for SEMs: LISREL (J\u00f6reskog and S\u00f6rbom 2006) , Mplus (Muth\u00e9n and Muth\u00e9n 2012) , EQS (Bentler 2008) , and Stata (Stata- Corp. 2011a,b) . Another popular commercial program, AMOS (Arbuckle 2011), does not implement complex sampling estimation at the date of writing.\nNone of the open-source SEM packages, sem (Fox 2006; Fox, Nie, and Byrnes 2012) , OpenMx (Boker et al. 2011) , and lavaan (Rosseel 2012) , directly implement complex survey adjustments. These packages do provide enough flexibility to allow for such adjustments through resampling methods if the user is willing to program these (the sem manual provides some guidance to this effect). More user-friendly interfaces are currently not available. Furthermore, with the exception of Stata and Mplus, the commercial packages that do implement estimation procedures for complex sampling still omit features dealing with several complications that may arise in the analysis of complex surveys:\nSome secondary data sources such as the OECD's Programme for International Student Assessment (PISA) do not provide the sampling design variables directly, but instead provide a set of so-called \"replicate weights\" (OECD 2009 ). In principle this represents a considerable simplification of highly complex survey analysis (Brick, Morganstein, and Valliant 2000) . Currently, however, not all SEM software allows for adjustments of SEM estimators using replicate weights;\nMore generally, variance estimation of SEM parameters with complex sampling using resampling methods such as the jackknife and bootstrap are not implemented directly but require additional programming on the part of the user (see Stapleton 2008 , for a discussion of these methods in the context of SEMs); Structural equation modeling is primarily an analytic method, so that finite population corrections may not usually be relevant (e.g., Fuller 2009, p. 342) . However, structural equation modeling is also a flexible method of reformulating several descriptive methods for which the finite population may be of interest, such as domain mean and modelbased small area estimation. Currently finite population corrections, which may be relevant for these purposes, are not available in all SEM programs.\nThe purpose of this article is to introduce the lavaan.survey package (Oberski 2013a) for the R environment (R Core Team 2013), which serves to bring user-friendly complex survey SEM analysis to the open source SEM implementation lavaan. In addition, by leveraging the many features of the survey package (Lumley 2004 (Lumley , 2010 (Lumley , 2012b ) it provides users with the above features currently omitted from some commercially available SEM software packages. Thanks to code reuse and the flexibility of the survey and lavaan packages, the lavaan.survey package is able to provide an extremely flexible, user-friendly, and open source framework for design-based analysis of complex survey data using SEM. It also allows for the analysis of multiply imputed complex survey data (Little and Rubin 1987; Graham and Hofer 2000) . At the time of writing, a limitation of the package is that it deals with the continuous case only. The package is available from the Comprehensive R Archive Network at http://CRAN. R-project.org/package=lavaan.survey. Section 2 discusses the theory of structural equation modeling in general and SEM under complex sampling in particular. After a brief overview of the package in Section 3, Sections 4.1, 4.2, 4.3, and 4.4 demonstrate the usage of the package by applying it to SEM analyses arising from the literature."}, {"section_title": "Technical explanation", "text": "Different methods have been suggested to deal with complex sampling in SEMs. In this article we will only deal with \"aggregate\" design-based methods (see Skinner et al. 1989, p. 8; Muth\u00e9n and Satorra 1995) . \"Design-based\" refers to the fact that inferences are based on the theoretical distribution of all possible samples under a particular survey design. Such a basis for inference stands in contrast to the \"model-based\" approach, which derives point and variance estimators from the assumed model. In practice, the two may sometimes coincide (see Sterba 2009 , for an overview). Three aggregate design-based point estimators have been suggested in the literature: adjustment of the weights or sample size to an effective sample size (Stapleton 2002) , pseudo-maximum likelihood (Muth\u00e9n and Satorra 1995; Asparouhov 2005 Asparouhov , 2006 , and weighted least squares estimation (Skinner et al. 1989, p. 86; Vieira and Skinner 2008) ; see Stapleton (2006) for an overview of these approaches. For these point estimators, different variance estimation methods are possible, including linearization (Skinner et al. 1989, p. 83; Muth\u00e9n and Satorra 1995, p. 279 ) and a range of resampling methods (Stapleton 2008) . This article and the lavaan.survey package adopt a framework due to Muth\u00e9n and Satorra (1995) that encompasses pseudo-maximum likelihood (PML) or weighted (\"generalized\") least squares (WLS) point estimation, and variance estimation by linearization or resampling. The option of which combination of methods to employ is left to the user, the default being PML, the de facto standard for SEMs at the time of writing (Asparouhov 2005) .\nThe framework adopted here starts from the observation (Skinner et al. 1989, p. 78 ) that the problem of the estimation of SEM parameters under complex sampling can be simplified to the usual problem of estimation of means under complex sampling through a classical three-step device (e.g., Fuller 1987, Appendix 4.B) . The current discussion of this remarkable observation is necessarily more condensed than that found in the comprehensive discussion by Muth\u00e9n and Satorra (1995) , but, following the design principle of lavaan.survey, also slightly more general in that it allows one to take into account all complex survey design aspects allowed for in the survey package. I focus on explaining the three steps which comprise the basic logic behind complex survey analysis of SEMs followed by lavaan.survey:\n1. All SEM parameter estimates are implicit nonlinear functions of the vector of variances and covariances or, more generally, moments of the observed variables;\n2. The moments themselves are linear estimators of the mean vector of a redefined vector of variables d;\n3. Therefore, after fitting a SEM using the estimation method of choice, the usual theory for variance estimation of means under complex sampling can be applied to the (co)variances and projected back into the parameter space.\nThis simple logic produces an incredibly flexible framework for SEM estimation incorporating sampling weights, stratification, and clustering, but also resampling methods and multiple imputation."}, {"section_title": "Structural equation models", "text": "Given a p-vector of observed variables y, let \u03a3 denote its population covariance matrix, and S n a sample estimator such that E \u03c0 (S n ) = \u03a3, where E \u03c0 denotes expectation under the sampling design. A SEM is a covariance structure model \u03a3 = \u03a3(\u03b8) expressing the population covariances \u03a3 as a function of a parameter vector \u03b8, an often used parameterization of SEM being the \"LISREL all-y\" model also used by lavaan,\nwhere \u03b7 is a vector of latent variables, or, equivalently, random effects, and \u03b6 and are vectors of (latent) residuals. This model implies the covariance structure\nwhere \u03a6 := VAR(\u03b6) and \u03a8 := VAR( ) 1 . The model encompasses well-known methods such as factor analysis (B = I), random effects modeling (B = I, \u039b = 1 p , \u03a8 is diagonal and dg(\u03a8) = \u03c8), and path analysis (\u039b = I, \u03a8 = 0), as well as any combinations that might be identified. Typically the model parameters are not identifiable without further restrictions; indeed it is customary to impose more restrictions than necessary for identification, allowing for a test of these restrictions. In that case the model degrees of freedom are usually taken to equal df = p * \u2212 q, where q is the number of free parameters and p * = p(p + 1)/2, the number of unique (co)variances. For clarity the mean structure is ignored, though the present treatment is easily extended to means and other moments (Satorra 1992) .\nSEM parameter estimates\u03b8 n are obtained by minimizing a discrepancy function F (s n , \u03c3(\u03b8)), where s n := vech(S n ), \u03c3 := vech(\u03a3), and the vech operator denotes columnwise stacking of the non-redundant moments (Magnus and Neudecker 2007) . The most common choice for F is the maximum likelihood (ML) discrepancy function,\nIt is straightforward to show (e.g., Bollen 1989, Chap. 4 Appendix) that minimizing F ML maximizes the likelihood of the data under multivariate normality. Under the model (see Fuller 1987, pp. 334-5) and as the sample size increases, the F ML becomes asymptotically equal to the weighted (\"generalized\") least squares (WLS) fitting function (Browne 1984) ,\nwhere V n consistently estimates a symmetric estimation weight matrix V . For the asymptotic equality to normal-theory ML to hold, the estimation weights V n are chosen as the inverse of the normal-theory sampling variance of s n , denoted \u0393 NT (Fuller 1987 , Appendix 4.B):\nwhere D is the duplication matrix (Magnus and Neudecker 2007) . When the data do not follow a multivariate normal distribution, both F ML and F WLS still provide consistent estimates. The asymptotically optimal estimator is obtained by replacing V with a consistent estimate of VAR(s n ) \u22121 , a method sometimes called \"asymptotic distribution free\" (ADF) estimation (Browne 1984; Satorra 1989) . In spite of its asymptotic optimality, the ADF estimator has performed very badly in simulation studies of its finite sampling behavior (Hu, Bentler, and Kano 1992; Bentler and Yuan 1999; Chou, Bentler, and Satorra 2011) .\nThe choice of discrepancy function and estimation weight matrix V n thus determines the precise form of the estimator. Regardless of this choice, unless the model is just-identified, \u03b8 n (s n ) is neither a linear estimator nor an explicit function of s n . However,\u03b8 n (s n ) is the solution to the equation \u2202F [s n , \u03c3(\u03b8)]/\u2202\u03b8 = 0, so that under mild regularity conditions (Satorra 1989) ,\u03b8 n (s n ) can be viewed an implicit function of s n ."}, {"section_title": "Estimation of (co)variances under complex sampling", "text": "Since the\u03b8 n are determined entirely by the s n , it follows that the complex sampling properties of SEM parameter estimates depend on those of the variances and covariances. These can be easily studied by redefining them as a linear estimator. Suppose a complex sample is obtained by sampling, not necessarily with equal probability, primary sampling units (PSU's) within strata, after which second and third stages are sampled. For instance, in the British sample of the European social survey (ESS) round four, 232 postcode sectors (PSU's) were sampled within strata, 20 delivery points (2SU's) sampled within postcode sectors, and for each delivery point, one person aged 15 or over was sampled (3SU's).\nLetx denote a design-consistent estimator of E \u03c0 (x). The estimatorx possibly but not necessarily involves weighting. Define\nwhere y hict is the vector associated with the tth third-stage unit of the cth second-stage unit of the ith PSU of stratum h, with the summation going over all the units within the ith PSU (Satorra 1992, p. 260) . This device essentially redefines the observed data matrix to d, simplifying the estimation of the (co)variances s to that of estimating the mean vector\nThis simplification of the problem to that of estimating a mean implies that the usual theory of estimators for means may be applied. Assuming that \u0393 := VAR \u03c0 (s n ) is finite, the variance estimator\u0393 can be obtained by \"nonparametric\" Taylor linearization (Skinner et al. 1989, p. 48; Muth\u00e9n and Satorra 1995, p. 279) , or by resampling methods including jackknife, balanced repeated replicates, bootstrap, and half-sample methods (Wolter 2007) . The R implementation of these methods is described by Lumley (2004 Lumley ( , 2010 . These variance estimators\u0393 are also consistent under nonnormality, so that all complex sampling analyses also take into account any effects of nonnormality of the observed variables. In smaller samples, non-parametric estimators of \u0393 may become unstable; since, under the model,\u0393 also estimates Yuan and Bentler (1998, p. 293) suggested using residuals in a model-based adjustment to\u0393 that was found to stabilize the estimator in small samples; lavaan.survey allows this optionally.\nA common problem in surveys is that of missing data, either through item or unit nonresponse. A common solution under the assumption of missingness at random given covariates is to multiply impute the missing values (Little and Rubin 1987; Rubin 2004) . For M imputations this yields M estimates s mn for m = 1, . . . , M . The point estimate is then simply the average over imputations,s .n . The variance \u0393 of these estimates can be estimated by (Schafer 1997) \nIn lavaan.survey, this procedure is applied while also taking into account the complex sampling design within imputations whenever multiply imputed data sets are given as data. This is the approach taken for other analysis types in many software packages including, for instance, the survey package. It should be noted, however, that any survey weights should be included in the imputation models, and Equation 5 may not consistently estimate the variance if the response mechanism is not at random with respect to the weights (Kott 1995; Kim, Brick, Fuller, and Kalton 2006) . Some care should therefore be taken with this approach when weights are involved."}, {"section_title": "SEM under complex sampling", "text": "Complex sampling impacts a SEM analysis in two ways:\n1. The conventional estimator of the covariance matrix may be biased and inconsistent. This, in turn, causes bias in the SEM parameter estimates;\n2. The sampling variance \u0393 of consistent estimates of the (co)variances may be affected by the design. This will affect standard errors and test(s) of model fit.\nThe first point suggests simply that the design-consistent estimator of the (co)variancesd should be used for s n in the fitting function. This will then guarantee consistency of the estimator\u03b8(s n ), at least for the population value\u03b8(\u03c3), when the model is misspecified. It can be shown that minimizing F ML withd as an estimate of s n is equivalent to the PML estimator introduced by Skinner et al. (1989, pp. 80-3) .\nThe second point means that a design-consistent estimate\u0393 of the sampling variance of the (co)variances under the complex sampling scheme needs to be taken into account. Wolter (2007, Eq. 6.2.2) notes that\nwhere r n is a term that converges to zero as the sample size increases (see also Lumley 2004, p. 3-4) . When the model is identified, \u2202\u03b8 n /\u2202s n can be obtained by invoking the implicit function theorem: since\u03b8 n is the solution to \u2202F [s, \u03c3(\u03b8)]/\u2202\u03b8 = 0,\nwhere \u2206 := \u2202F/\u2202\u03c3(\u03b8), and o \u03b8 (n 1/2 ) is a term that, under the model, converges to zero as the sample size increases (see Neudecker and Satorra 1991 , for the precise form of both quantities).\nThus, when the model is correct, the asymptotic variance of the parameter estimates is\nwhere E \u03b8 denotes expectation under the model. Equation 8 can be recognized as the \"sandwich\" estimator of variance, which is well-known in econometrics. When F ML is used and the data truly have an iid multivariate normal distribution, but also when F WLS is used and V n is chosen such that V \u0393V = V , the asymptotically optimal estimator (AO) is obtained. Its asymptotic variance can then be seen from Equation 8 to reduce to\nFor F ML this corresponds to the inverse of the Fisher information.\nTwo strategies can now be followed for estimation of SEM parameters under complex sampling:\nWLS: Fit the model using WLS with data s n =d, and the (Moore-Penrose) inverse\u0393 + as the estimation weight matrix V n in Equation 4. In this case, after fitting the model, the simple form of Equation 9 can be used as a variance estimator;\nRobust ML (PML): Fit the model using ML with data s n =d, and estimate the variance with Equation 8, setting\nNT and plugging in the design-consistent\u0393 matrix.\nWLS estimation is asymptotically optimal and similar to the commonly employed complex sampling estimator for multiple regression (Skinner et al. 1989; Skinner and de Toledo Vieira 2007; Fuller 2009, Section 6.3) . However, it can lead to unstable estimates and has been found in simulation studies to have larger mean square error than the robust ML method, as well as producing test statistics that do not approach their nominal distribution (Hu et al. 1992; Bentler and Yuan 1999; Vieira and Skinner 2008; Chou et al. 2011) . For this reason the robust ML method is the default in lavaan.survey, though both methods are implemented."}, {"section_title": "Goodness-of-fit testing of the restrictions", "text": "Under the null hypothesis of model correctness, the residual covariances should approach zero as the sample size increases. A chi-square statistic for a test of this hypothesis when the estimation procedure is AO is \u03c7 2 AO (df ) = nF . A large number of other fit indices exist, all of which are derived either from this model chi-square statistic or from the residuals directly (Kline 2011) . When the robust ML procedure is used, nF no longer follows a chi-square distribution and an adjustment to the test statistic is necessary. The most commonly used adjustment matches the first moment of the test statistic to that of the true distribution:\nwhere\u03b4 is the average generalized design effect (Rao and Scott 1984, p. 53; Skinner et al. 1989, pp. 43-4) . This adjustment is known in the SEM literature as the \"Satorra-Bentler\" (SB) chi-square (Satorra and Bentler 1994) . In lavaan, robust ML estimation using the mean generalized design effect adjustment is called \"MLM\" estimation, and this is the default used in lavaan.survey. Equivalently, the options se = \"robust\" and test = \"Satorra.Bentler\" may be passed to lavaan. The mean generalized design effect is given in the output as the \"scaling correction factor for the Satorra-Bentler correction\". If one defines n eff := n/\u03b4, Equation 10 provides a rationale for the effective sample size method discussed by Stapleton (2002) , although the method of obtaining n eff is different, and there is no guarantee that standard errors will be adequately corrected just by replacing n by n eff in variance estimators.\nOther adjustments include the \"mean-and-variance\" (T 3 ) adjustment of Asparouhov and Muth\u00e9n (2010, p. 4 ) and the Satterthwaite (1941) adjustment, which adjusts the degrees of freedom in addition to the value of the test statistic itself. These options are available in lavaan.survey by making use of their implementations in lavaan. For contingency table tests, Thomas and Rao (1987) found that the Satterthwaite adjustment had a good overall performance, whereas the mean-adjusted test statistic required the coefficient of variation of the generalized design effects to be small. Although the SEM literature on complex sampling (see Bollen et al. 2013) has mostly focused on the Satorra-Bentler adjustment, it is therefore possible that the Satterthwaite adjustment may actually be preferable. Currently, I am not aware of any simulation studies investigating this issue explicitly in SEM; therefore lavaan.survey follows the SEM literature in choosing the Satorra-Bentler adjustment by default but allows the Satterthwaite adjustment optionally.\nInstead of a chi-square fit statistic, one may also consider an F reference distribution, where the denominator degrees of freedom are chosen as the survey design degrees of freedom. This adjustment was found by Thomas and Rao (1987) to perform well when the number of PSU's was small (thanks are due to an anonymous reviewer for this suggestion). The function pval.pFsum allows the user to obtain p values for the global test statistic from the F reference distribution with df and survey design degrees of freedom.\nIn small samples or with few clusters relative to the number of observed covariances to be estimated, it may happen that\u0393 is singular. This is not a problem in itself, as the model is typically restricted so that the parameters may still be identified from the observed moments even when some of these moments are collinear. However, for robust ML there may also be cases where the effective degrees of freedom for the goodness-of-fit test are smaller than df = p * \u2212 q, which is the default. After using robust ML with a singular\u0393, lavaan.survey therefore checks whether the degrees of freedom for the goodness-of-fit test are still valid.\nOutput from a conventional SEM analysis using lavaan.\nsurvey.design Either a 'svydesign' or svrepdesign' object produced by a function from package survey.\nestimator Point and variance estimator to be used. Robust ML (PML). estimator.gamma Any adjustments/smoothing of\u0393.\nNo adjustments. "}, {"section_title": "About the package", "text": "lavaan.survey is a concise package written entirely in interpreted R code and published under the GPL 2. It links the survey and lavaan packages, thus providing an interface to a great variety of structural equation model analyses under complex sampling. Its aim is to provide sensible defaults while allowing for flexibility and to check for any estimator-specific problems where possible. In addition, it pools the mean and covariance estimates from data sets obtained by multiple imputation to allow for complex sampling analyses with missing data. The general workflow of a lavaan.survey analysis is:\nCreate lavaan fit object to specify the model;\nCreate survey 'svydesign' object to specify the sampling design;\nCall the lavaan.survey function with the fit and design objects as arguments.\nThe order of the first two items does not matter. Table 1 gives an overview of the arguments taken by the function lavaan.survey."}, {"section_title": "Applications", "text": "This section demonstrates the use and features of lavaan.survey by discussing four example applications. Code and data for the examples are available as supplementary material from the journal web page.\n4.1. Replicate weights analysis of math ability in PISA large multinational survey that employs multistage stratified sampling (OECD 2009). Due to the high complexity of PISA's sampling design as well as for purposes of nondisclosure, the OECD does not provide the original design variables, but rather a set of 80 replicate weights generated by the closed-source program WesVar (?). To take the sampling design into account in SEM analyses of PISA data, these replicate weights need to be included in the analysis, a feature not available in any standard SEM software. This section shows how such an analysis may be performed using lavaan.survey. The 2003 PISA data are freely available from the OECD website (http://www.oecd.org/pisa/); here I follow the original authors in analyzing a subset of these data containing the Belgian sample and variables measuring students' math ability in four domains, self-concept of their math ability, self-efficacy, and school level. For the precise definitions of these variables and the indicators used please see the appendix to Ferla et al. (2009) . In addition, gender and socio-economic status of the parents will be used as fixed covariates. The subset analyzed is included in the online supplement and can be loaded onto the R workspace with the command R> data(\"pisa.be."}, {"section_title": "2003\")", "text": "In addition to the observed variables, the raw data also contain 80 replicate weights generated by balanced-repeated replication using Fay (1989) 's method with \u03c1 = 0.5 (OECD 2009). Using the svrepdesign function from the survey package, a survey design object is defined taking this into account:\nR> des.rep <-svrepdesign(ids =~1, weights =~W_FSTUWT, data = pisa.be.2003, + repweights = \"W_FSTR[0-9]+\", type = \"Fay\", rho = 0.5)\nIt may be of interest to educational researchers that the options used here, weights = W_FSTUWT, repweights = \"W_FSTR[0-9]+\", type = \"Fay\", and rho = 0.5, are applicable to any analysis of the 2003 PISA data, not just the one at hand.\nHaving defined the sampling design, the next step is to perform a conventional SEM analysis without taking this design into account. Figure 1 shows a simplified version of the model analyzed by Ferla et al. (2009) as a path diagram. The figure shows that a reciprocal effect between self-concept and self-efficacy is specified, which is identifiable due to the absence of a direct effect of school level on self-concept. Self-concept and efficacy affect math ability and are also partially mediating variables for the effect of school level on math ability. All structural relationships are controlled for gender and socio-economic status of the parents. For clarity, Figure 1 omits the indicators of the three latent variables self-concept, self-efficacy, and ability; these are assumed to be measured by five, eight, and four indicators respectively in a simple factor structure. This model can be specified in lavaan syntax as: In this syntax, =~indicates \"measured by\" and~\"regressed on\". Means and variances are freed in the lavaan function call. For more information on the precise working and syntax of lavaan, please see Rosseel (2012) . A conventional SEM analysis on the raw data is then performed:\nR> fit <-lavaan(model, data = pisa.be.2003, auto.var = TRUE, std.lv = TRUE, + meanstructure = TRUE, int.ov.free = TRUE, estimator = \"MLM\") R> fit lavaan (0.5-10) converged normally after 161 iterations By specifying estimator = \"MLM\", this conventional analysis uses the option of calculating nonnormality-robust standard errors and chi-square, yielding a \"scaling correction\" (average generalized \"design\" effect of nonnormality) of 1.1. This serves to make the conventional analysis more comparable to the complex sampling analysis, which can be expected to increase the scaling correction relative to the value after taking nonnormality into account. Now that a survey design object and a lavaan fit object have been obtained, the complex sampling analysis can be performed using lavaan.survey: This example call uses all the defaults, i.e., robust ML estimation without model-based smoothing; this is equivalent to pseudo-maximum likelihood (PML) estimation. The average generalized design effect taking into account both nonnormality and the sampling design is 1.45, which is 31% higher than that for the conventional analysis only taking nonnormality into account. Table 2 gives the point and standard error estimates for the parameters of primary interest, corresponding to the black arrows in Figure 1 . For comparison, both the results from the \"naive\" conventional SEM analysis and from the lavaan.survey analysis employing the replicate weights are given. Table 2 shows that the differences in point estimates are relatively small. The differences in standard error estimates, however, are considerable. The average ratio between the standard errors from the complex sampling and the conventional analysis, termed \"conditional relative efficiency\" (creff) in the table (Oberski 2011 , Chap. 3, Oberski 2013b , is 1.38.\nThe model fits very badly, even after taking the scaling due to complex sampling into account. One method of investigating which restrictions are especially offensive is to examine the \"modification indices\" (also known as \"score\" or \"Lagrange multiplier\" tests) for restricted parameters. Under the null hypothesis of a correct restriction, these will follow a chi-square distribution with one degree of freedom. lavaan allows the user to obtain modification indices with the command modificationIndices, which are adjusted to the complex sampling design after the call to lavaan.survey.\nR> head(arrange(modificationIndices(fit.surv) [, -c(7, 9) The plyr (Wickham 2011) function arrange was used to give a concise syntax. The modification indices adjusted for complex sampling are shown as mi.scaled. The most problematic restrictions appear to be zero error correlations among items in the self-efficacy construct. This may indicate common method variance or multidimensionality of the latent self-efficacy variable."}, {"section_title": "Confirmatory factor analysis (CFA) of welfare state attitudes", "text": "Roosma, Gelissen, and van Oorschot (2013) discuss an analysis of citizens' attitudes toward the welfare state. They used data from the 2008 (fourth) round of the ESS to compare factor means that represented whether respondents thought the welfare state was legitimate and achieved its stated goals across countries. An additional goal of the study was the investigation of the relationship between the factors. The ESS is a multinational survey in which each country has its own sampling design -a design that can vary in complexity from simple random sampling from a population register (e.g., Denmark) to four-stage stratified cluster sampling (e.g., Turkey). This section analyzes the United Kingdom (UK) sample, focusing on two of the factors investigated by Roosma et al. (2013) .\nThe ESS data for round four are publicly downloadable online (http://www.europeansocialsurvey. org/data/). The UK subset analyzed here additionally includes information on strata and primary sampling units that is absent from the public database. The subset is included in the online appendix."}, {"section_title": "R> data(\"ess4.gb\")", "text": "Focusing on two factors representing \"range\" and \"outcomes goals\" (Roosma et al. 2013 , Table 1), a two-factor model is formulated using lavaan syntax as:\nR> model.cfa <-+ \"range =~gvjbevn + gvhlthc + gvslvol + gvslvue + gvcldcr + gvpdlwk + goals =~sbprvpv + sbeqsoc + sbcwkfm\"\nThe \"range\" factor represents the opinion that government should be responsible for various outcomes associated with the welfare state and has six observed indicators. The \"outcome goals\" factor represents the respondent's opinion of whether these goals are actually reached, and is measured by three observed variables. Of particular interest here are the covariance between the two factors as well as the factor variances. For the precise question formulations and rationale behind these definitions of the factors, please see the ESS website and the original article respectively. The factor model can be estimated with lavaan using R> fit.cfa.ml <-lavaan(model.cfa, data = ess4.gb, estimator = \"MLM\", + meanstructure = TRUE, int.ov.free = TRUE, auto.var = TRUE, + auto.fix.first = TRUE, auto.cov.lv.x = TRUE) R> fit.cfa.ml lavaan (0.5-10) converged normally after 51 iterations This shows again that the nonnormality of the data have a considerable effect on the standard errors and chi-square test of model fit. Since the original authors were satisfied with the attained model fit and the focus is here on the estimation of the relationship between the factors, we shall ignore the issue of model fit in this application.\nThe UK sample was stratified based on 37 regions (stratval). Within each region, postcode sectors (psu) were listed in increasing order of population density and tenure; sectors with fewer than 500 delivery points were combined. In the first stage a systematic sample of 232 sectors (225 in Great Britain and 7 in Northern Ireland) was then drawn with probability proportional to postal delivery point count. The second and third stages were simple random sampling of 20 postal delivery points within the sector, and selection by Kish grid of one person aged 15 or over at the selected address. In some cases there was an intermediate stage in which a dwelling required selection from an address before a person could be selected within the dwelling. The final sampling weights (dweight) were constructed by the ESS sampling team by multiplying all selection probabilities together, normalizing to the nominal sample size, and finally trimming the weights at 4. This rather complicated design can be neatly summarized in a survey design object:\nR> des.gb <-svydesign(ids =~psu, strata =~stratval, weights =~dweight, + data = ess4.gb)\nAfter the definition of the sampling design, the confirmatory factor analysis taking it into account using robust ML is again performed using lavaan.survey:\nR> fit.cfa.surv <-lavaan.survey(fit.cfa.ml, survey.design = des.gb) R> fit.cfa.surv lavaan (0.5-10) converged normally after 50 iterations The mean generalized design effect taking both nonnormality and the sampling design into account is 21% higher than that taking only nonnormality into account.\nAn alternative to the default robust ML estimator is WLS using the (generalized) inverse of \u0393 as a weight matrix. This can be accomplished in lavaan.survey by changing the estimator to \"WLS\".\nR> fit.cfa.surv.wls <-lavaan.survey(fit.cfa.ml, survey.design = des.gb, + estimator = \"WLS\")\nSince, as remarked above, this method was found unstable in a range of simulation studies and applications, a possible adjustment is to smooth the estimation weights for WLS using the model-based smoothing method suggested by Yuan and Bentler. This can be done by changing the setting for estimator.gamma to \"Yuan-Bentler\".\nR> fit.cfa.surv.wls.yb <-lavaan.survey(fit.cfa.ml, survey.design = des.gb, + estimator = \"WLS\", estimator.gamma = \"Yuan-Bentler\")\nTo estimate the covariances used as input for the SEM analysis and their\u0393 matrix, it is also possible to use the various resampling methods available in the survey package:\nR> des.gb.rep <-as.svrepdesign(des.gb, type = \"JKn\")\nIn this call to the survey function as.svrepdesign, the jackknife for stratified designs (\"JKn\") is specified, which is the default. The confirmatory factor analysis can then be performed on the jackknifed covariances using lavaan.survey:\nR> fit.cfa.surv.rep <-lavaan.survey(fit.cfa.ml, survey.design = des.gb.rep) R> fit.cfa.surv.rep lavaan (0.5-10) converged normally after 50 iterations In this case, the results of complex sampling CFA using the jackknife gives results very similar to the default method using Taylor linearization. Table 3 presents point and standard error estimates, as well as a relative efficiency compared with the naive method for three parameters of interest, namely the factor variances and the covariance. Table 3 gives results using the five different methods discussed above: ML not taking the sampling design into account (\"Naive\"), the default robust ML method using linearization to estimate\u0393 (\"Taylor\"), the robust ML method using the stratified jackknife to estimate\u0393, WLS using the linearized\u0393 \u22121 matrix as weights (\"WLS\") and the same method using the model-based smoothing estimate of\u0393 suggested by Yuan & Bentler (\"WLS, Y-B\") . Table 3 again shows that the point estimates for different versions of ML are very similar. As the conditional relative efficiencies indicate, the standard error estimates using both Taylor linearization and the jackknife are substantially larger than those obtained under the naive method; these two methods give very similar results in all respects. Unadjusted WLS estimation gives point estimates that are wildly different from those obtained by all of the other methods: most strikingly, the relationship between the factors is estimated to be positive rather than negative using this method, with z-values larger than 2 for both WLS and the other methods. However, when the Yuan-Bentler smoother is applied to the\u0393 matrix, point estimates are obtained that are much more similar to those obtained with ML.\nAlthough it is possible that WLS is the only method indicating the correct direction of the relationship, cautions in the literature on this estimator would suggest that the ML or YuanBentler smoothed WLS estimators are likely to be preferable. A caveat on this last estimator is that it relies on the correctness of a model for which the fit statistic indicates significant misspecification, so that the stability it introduces relative to the WLS estimator may be paid for with some amount of bias. This trade-off may work out well in some applications, however."}, {"section_title": "Multiple imputation of dropouts in the LISS panel", "text": "The longitudinal internet studies for the social sciences (LISS) panel is a web survey panel recruited by probability sampling. A random sample of households from the Dutch population register was asked to participate in the panel, and all household members were then asked to participate. To prevent undercoverage problems, the panel organizers provided internet connections and computers to those who did not have them. For more details on the design of the LISS panel and recruitment efforts, see Scherpenzeel (2011) . The LISS panel measures a wide range of variables and allows external researchers to submit proposals as well.\nOne question of interest is whether these questions have sufficient reliability to be of use for substantive research. Thanks to the longitudinal design, this can be investigated by the so-called \"quasi-simplex\" model (Alwin 2011) , which Figure 2 represents as a SEM for the variable \"internet use\". The model in Figure 2 is only identified by the additional restriction VAR(e t ) = \u03d1, i.e., equality of measurement error variances (J\u00f6reskog 1970 ). Parameters of interest could then be the error variance \u03d1 itself, but also the reliability ratio at a time point, for example \u03c1 1 := \u03d1/VAR(cs08a247).\nThe data for estimating the model in Figure 2 can be loaded by:"}, {"section_title": "R> data(\"liss\")", "text": "This data set contains the answers 7369 respondents gave to the question \"How many hours per week, on average, do you use the internet at home?\" when asked in 2008, 2009, 2010, and 2011 , as well as the household identifier. The model in Figure 2 can be written in lavaan syntax as:\nR> model.liss <-\" + cs08 =~1 * cs08a247 + cs09 =~1 * cs09b247 + cs10 =~1 * cs10c247 + cs11 =~1 * cs11d247 + + cs09~cs08 + cs10~cs09 + cs11~cs10 + + cs08a247~~vare * cs08a247 + cs09b247~~vare * cs09b247 + cs10c247~~vare * cs10c247 + cs11d247~~vare * cs11d247 + + cs08~~vart08 * cs08 + + reliab.ratio : = vart08 / (vart08 + vare) + \"\nThe last line defines the reliability ratio as reliab.ratio. lavaan will automatically output the point estimate for reliab.ratio as well as its standard error (using the delta method). As before, the model accounting for household clustering (nohouse_encr) can be estimated with lavaan.survey: As shown in the lavaan output, although there are 7369 respondents in the data set, after listwise deletion only 3374 complete observations are left to estimate the reliability. Figure 3 shows that this large amount of missing data is mostly due to panel attrition (dropouts) over time. The attrition is considerable, reaching 46% in the 2011 wave.\nOne method of dealing with this large amount of missing data is multiple imputation. As with many missing data methods, the core assumption is that the data are missing at random, given the covariates used for imputation. In this application the covariates for a missing answer by a respondent are that respondent's answers at previous time points, so that this assumption is not entirely implausible. To create multiply imputed data sets, the R packages mice (Buuren and Groothuis-Oudshoorn 2011) , mi (Su, Gelman, Hill, and Yajima 2011) , and Amelia (Honaker, King, and Blackwell 2011) can be used, but the user can also create multiply imputed data sets with an external program such as WinBUGS (Spiegelhalter, Thomas, Best, and Lunn 2003; Lunn, Thomas, Best, and Spiegelhalter 2000) . This example uses the mice package to impute the dropouts 100 times (not run):\nR> library(\"mice\") R> liss.imp <-mice(liss, m = 100, method = \"norm\", maxit = 100)\nThe lavaan.survey package follows the survey package's design in employing the mitools (Lumley 2012a) package to analyze multiply imputed data sets. This provides full flexibility by allowing the multiply imputed data sets to come from any source. After imputation using mice, an 'imputationList' object can be created by:\nR> library(\"mitools\") R> liss.implist <-lapply(seq(liss.imp$m), + function(im) complete(liss.imp, im)) R> liss.implist <-imputationList(liss.implist)\nThe analysis can then proceed as before, using liss.implist as data; lavaan.survey will detect that multiply imputed data sets have been given as input and pool these in the estimation of the covariance and\u0393 matrices. Using the multiply imputed data set, the reliability estimate for the first time point is slightly lower than that when using the default listwise deletion. The confidence interval, in spite of the added uncertainty due to the multiple imputations, is narrower, indicating an overall increase in information used relative to listwise deletion."}, {"section_title": "Species diversity and O 2 productivity of algae in streams", "text": "The features of lavaan.survey can not only be applied to surveys, but more generally to any situation in which the observations are not iid. To demonstrate a non-survey analysis with dependent observations, we reproduce an analysis of an experiment on patches of algae in Californian streams. Cardinale, Bennett, Nelson, and Gross (2009) chose 20 streams in the Sierra Nevada. In each stream, they placed 5 or 10 PVC elbows containing different levels of nutrients and a small patch of agar on which algae could grow. They then returned to the streams about 42 days later and measured 1) species diversity in the stream, 2) species diversity in each patch, 3) biomass of the algae, and 4) rate of oxygen production on each patch. Their SEM explicates the indirect relationship between patch diversity and oxygen production and the role played by the experimentally manipulated nutrient supply. Data on 127 patches in 20 streams are available from:\nR> data(\"cardinale\") This model can be fitted to the patches of algae using R> fit.card <-sem(model.card, data = cardinale, fixed.x = FALSE, + estimator = \"MLM\")\nThe Satorra-Bentler chi-square is 6.18 on 7 degrees of freedom with scaling factor 0.95 and thus appears to be in line with the observed covariances (p = 0.519).\nThe 127 patches were considered independent observations. In practice, however, patches are nested within streams. A way of taking this into account while still estimating the same target parameters is to use lavaan.survey, viewing the streams as clusters.\nR> des.card <-svydesign(ids =~Stream, probs =~1, data = cardinale) R> fit.card.survey <-lavaan.survey(fit.card, des.card, estimator = \"MLM\")\nThe corrected model yields a Satorra-Bentler chi-square of 3.88 on 7 degrees of freedom with scaling factor 1.52. The conclusion on model fit does not change (p = 0.793). The only qualitative difference between the non-iid analysis and the robust iid analysis is that the nonlinear effect of log(Nutrient) 2 on patch species diversity does not differ significantly from zero (p = 0.051) in the robust iid analysis, while it does (p = 0.005) in the non-iid analysis.\nThe Satorra-Bentler chi-square p value for the overall model fit statistic is derived from large-sample theory applied not only to the number of observations, but also to the number of clusters. Since there are only 20 clusters, a better finite-sample performance might be expected from a p value obtained from an F reference distribution with 19 denominator degrees of freedom. It can be obtained using R> pval.pFsum(fit.card.survey, survey.design = des.card)\nThe p value from the F reference distribution (0.610) differs considerably from that obtained using the chi-square reference distribution (0.793), although neither leads to a rejection of the null hypothesis."}, {"section_title": "Summary", "text": "Structural equation modeling is frequently applied to samples that are not iid: lavaan.survey is designed to deal with this case. This article introduced the lavaan.survey package and demonstrated its usage and some of its features by application to four examples motivated by the literature. Because the package joins together the lavaan and survey packages, both very flexible implementations of respectively structural equation modeling and complex survey analysis, the number of combinations of SEM analyses and sampling designs is countless, and not all of these possibilities could be demonstrated. Instead the goal has been to demonstrate, on the one hand, the manner in which SEM analyses using lavaan might be adapted to incorporate the issue of non-iid samples, and, on the other, the application of the SEM analysis framework to common problems in complex survey analysis. By joining these two worlds in the open-source R environment, lavaan.survey hopes to stimulate progress in the various application areas of SEM, as well as provide a flexible framework for the analysis of methodological issues in survey methodology. An important limitation of lavaan.survey at the time of writing is that categorical data cannot be incorporated, a feature that is planned for future releases of the package."}]