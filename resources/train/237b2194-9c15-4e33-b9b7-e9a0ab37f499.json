[{"section_title": "Abstract", "text": "The Modifiable Areal Unit Problem (MAUP) is the classic term for describing different totals observed from spatially different aggregation units. In a typical analytical problem (e.g. estimating total population within a watershed from census unit totals) the spatial distribution of populations within the census units are modeled. To minimize MAUP errors, areal interpolation techniques are used to model such sub-unit population distributions. Areal interpolation techniques are highly dependent on ancillary data (e.g. land use/cover data) and typically do not include \"intelligent\" relations about where people choose to live, other than a weighted association between nominal land cover/use and population density. The purpose of this research was to design and implement an \"intelligent\" areal interpolation method for housing data in coastal environments, validate the accuracy, and compare to other techniques. This study was conducted for Miami-Dade County in Florida at census scales from county to block. Parcel boundary data was used as a reference layer to validate each technique. Not surprisingly, all techniques perform best at finer spatial resolutions (e.g. block level) with error increasing at coarser resolutions. The accuracy of the dasymetric technique is directly related to the accuracy of ancillary data. The new intelligent technique, (referred to as the process-oriented technique from here onwards) models the relationship between housing unit density distribution and proximity to the coast. This process-oriented technique performed better than the areal weighting and the dasymetric mapping technique. Combining the 'process-oriented' technique with a dasymetric technique provided the least amount of error."}, {"section_title": "", "text": "other familiar problem is the Modifiable Areal Unit Problem (MAUP), which results from the use of geographic data obtained at varying spatial scales of analysis and also from the use of source zones and target zones that are completely different and not hierarchical (Openshaw 1983) .\nThe MAUP is a very common problem in hazard studies, where the physical risk is modeled at an observational scale (e.g. flood zone) different from the scale at which population data are obtained. Another example is the use of loss estimation techniques to model storm surgeinduced dollar loss in risk assessment. These techniques rely on accurate loss data to model potential loss, such as the number of storm surgeaffected housing units, their exact location, and cost of housing units. These data sets are difficult to obtain due to confidentiality issues (Changnon 2003 ). An approximate and alternate solution is to use socioeconomic and demographic data collected at aggregate scales of analysis (e.g. census units). Because the MAUP typically results in error associated with the use of aggregate data, the results of such models relying on spatial data gathered at different spatial scales of analysis, would be less confident (either underestimated or overestimated).\nOne of the solutions to minimizing the MAUP impact is areal interpolation, which is a spatial interpolation technique used to disaggregate spatial data available at a coarser scale of analysis to a finer scale of analysis (e.g. counties to blocks). An areal interpolation technique enables aggregation/disaggregation of spatial data acquired at one areal unit (i.e. source zones) to another areal unit (i.e. target zones) for efficient comparison of data sets and analysis (Eicher and Brewer 2001; Fisher and Langford 1996; Holt, Lo and Hodler 2004) . These techniques often rely on ancillary data (e.g. land use/cover data) to distribute spatial data (e.g. housing units within residential zones), and typically do not include \"intelligent\" relations, for example, where people choose to live in coastal areas. Rather, the common areal interpolation assumes either a constant population density within a census unit or discrete population density classes associated with nominal land use/cover categories.\nThe purpose of this research was to design, implement and evaluate an intelligent interpolation method, referred to as \"process-oriented technique\" that models people's relationship with a physical process (i.e. the desire to live near a coastal environment). The study was conducted for Miami-Dade County, which is one of the most heavily populated coastal counties in Florida. The process-oriented technique was compared to two commonly used interpolation techniques (i.e. areal weighting and dasymetric mapping) to disaggregate housing units in the study site at four census scales (i.e. block, block group, census tract and county). Housing unit information available at the parcel scale was used as \"ground truth or reference data\" to validate each technique and for error estimation. The major research questions explored in the study were 1) Does the proposed intelligent areal interpolation technique perform better than the conventional techniques? and 2) Which areal interpolation technique performs better at all census scales of analysis? The housing unit disaggregation was performed at each census scale of analysis.\nThe paper is organized into five sections. The second section reviews the primary interpolation techniques used to disaggregate socioeconomic variables. An introduction to the study site, description of data sets and data processing, and an illustration of the methodology implemented are provided in section three. The results of the study are presented in section four. Finally, a discussion and summary of the outcome is presented."}, {"section_title": "Areal Interpolation", "text": "To reduce data volume and preserve confidentiality, socioeconomic data are typically reported at aggregate spatial scales of analysis. For instance, in the United States, the finest scale at which U.S. Census population data (e.g. population counts, race, gender) are available is the census block, which are then aggregated to coarser scale units (e.g. block groups, tracts, etc) for reporting more sensitive data (e.g. income). The end result is the MAUP problem. To minimize the MAUP problem, numerous areal interpolation techniques have been developed, which may be classified into non-volume and volume preserving categories (Lam 1983) ."}, {"section_title": "Non-Volume Preserving Approaches", "text": "In a non-volume preserving approach, each source zone is typically represented by a control point (usually the centroid of the source zone). A grid is superimposed on source zone(s), and a value at each grid node is determined by using a point interpolation technique. The values of all grid nodes located within a target zone are totaled (or averaged) to yield the target zone estimate. Because a point interpolation approach is used to aggregate data/compute statistics for target zones, this method is also known as a \"point-based areal interpolation approach\" (Lam 1983) .\nThough the method is simple to implement and understand, it has some inherent limitations.\nThe centroid is rarely a good representation of populated and unpopulated areas. The centroid also does not account for other factors (e.g. land use/cover) that may be a proxy for underlying population distribution. Determining the density of grid nodes (i.e. size of each grid cell) and their spatial arrangement is also subjective. Because an a priori assumption about the use of census unit centroids to depict populations is made, this method fails to incorporate anthropogenic activities. To obviate these problems, volumepreserving approaches are used for distribution of socio-economic data within a target zone."}, {"section_title": "Volume Preserving Approaches", "text": "A volume-preserving approach, also known as area-based areal interpolation, ensures that total population count in each source zone is maintained (Lam 1983) . A number of volume-preserving approaches have been developed, which can be categorized into three classes -cartographic, regression and surface methods (Fisher and Langford 1995) ."}, {"section_title": "Cartographic Method", "text": "A cartographic method (or overlay approach) is the most common volume-preserving technique. The two most widely used cartographic approaches are areal weighting and dasymetric mapping. Areal weighting is a ratio-based approach, in which target zones are superimposed on source zones, and a value for each target zone is estimated as proportional to the ratio of target zone area to source zone area (Fisher and Langford 1995; Fisher and Langford 1996; Lam 1983 A ts is the intersection area of source zone s with target zone t; and P s and A s are the population and area of source zone s respectively. The method could be implemented with either a raster or vector data model. This method implicitly assumes an even distribution of data (e.g. population) in both source and target zones. To obviate the even distribution assumption, Wright (1936) used topographic maps in conjunction with township boundaries to determine populated and unpopulated areas in a township in Cape Cod. Using an average population density of a township and the area ratio of populated locations to unpopulated locations in the township, the author was able to compute population density in different sections within the township. The algorithm Wright developed to estimate population density is represented by equation (2) This approach by Wright (1936) , well known as dasymetric mapping (i.e. density measuring) and filtered areal weighting, was first conceptualized in 1911 by the Russian cartographer, Benjamin Semenov-Tian-Shansky (Petrov 2008) , but became popular for J. K. Wright's (1936) work in the U.S. In this method, data in a source zone is redistributed within homogenous subzones in a target zone based on ancillary information (Eicher and Brewer 2001; Langford and Higgs 2006) . The accuracy of the method, however, depends on the accuracy and appropriateness of ancillary data. The stronger the correlation between the ancillary variable (e.g. residential/ non-residential zones) and interpolated variable (e.g. housing units) is, the more accurate the interpolated estimates by dasymetric method will be. Over the years, variations of the conventional dasymetric approach by using different ancillary layers have been conducted to increase accuracy of interpolated estimates. Holt et al. (2004) used a binary dasymetric approach to estimate rates of population change in 13 counties located in Atlanta, Georgia, during 1980 Georgia, during -90 and 1990 Georgia, during -2000 . The authors estimated population density in residential areas for 1980 and 2000 at the tract level (i.e. source zones) by using 1980 and 2000 county population data, tract boundaries and satellite imagery. The computed population density for 1980 and 2000 was then redistributed within 1990 tract boundaries (i.e. target zones) to determine population change. Eicher and Brewer (2001) employed a three-class dasymetric approach for 159 counties in parts of four states (i.e. Pennsylvania, West Virginia, Maryland and Virginia). The authors allocated a percent weight representing relative population density to each land use class (i.e. urban, agricultural/woodland and forestland), such that the total weight was 100%. The weight was then used to distribute six socioeconomic variables within a county among the three land-use classes.\nTo avoid subjectivity of selecting weights, Mennis (2003) used land cover data along with road network and road density information to extract occupied and unoccupied areas in a study site. Each occupied area was further categorized into three classes: high-density and low-density urban areas, and non-urban areas. The author computed a density fraction (population density of a class divided by sum of population density in all three classes) and an area ratio for each class in an occupied area in a block group. The density fraction and area class were then combined with total population to estimate population for each class in the block group.\nInstead of land-use/cover data, Xie (1995) used transportation layers to develop a street-weighting technique. The author used street-length, street-hierarchy-weighting and street-housebearing to determine weights corresponding to residential density, which was then used to distribute population gathered at tract level to block group level in Erie County, New York. Following this approach, Reibel and Bufalino (2005) determined residential density zones and corresponding weights using street and road networks in Los Angeles County. The weight was then used in distributing total population and total housing unit count collected at the census tract level in 1990 to 2000 census tracts. Moon and Farmer (2001) used Arkansas State Highway Transportation Department data to identify housing areas at the block level in eight counties of Arkansas. Population data were linked to block centroids to generate a relative population distribution surface. The surface was overlain on block groups to determine population distribution within block groups. Maantay et al. (2007) used cadastral data representing property boundaries as an ancillary layer to disaggregate total population reported at the block group level to the tax lot level in New York City. The authors reported that using cadastral data provided higher accuracy than other ancillary layers."}, {"section_title": "Regression Method", "text": "In this method, a statistical relationship between the area of land cover classes (independent variable(s)) and the attribute to be interpolated (dependent variable) is established (Fisher and Langford 1995) . Although numerous regression approaches have been developed, the following are the widely used regression based interpolation methods.\nIn the Ordinary Least Square (OLS) method, a linear relationship is established between variables. The coefficients enable reassigning data to various land cover classes in an areal unit. The conventional model for this approach is Langford 2006):\nwhere:\nP s is the population of zone s; \u03b1 is the intercept; \u03b2 c is the regression coefficient for land cover c; C is the total number of populated land cover classes in the study region;\nA sc is the area of land cover c in zone s; and \u03b5 s is the error term.\nThe method is simple to implement, but its accuracy relies on the accuracy and appropriateness of ancillary data. Negative coefficients sometime result in negative population, which theoretically is impossible. Fisher and Langford (1995) described three OLS methods specific to the number of land cover classes and density of a corresponding land cover class. In the \"Simple Model\" all residential areas were considered as one class. The \"Focus Model,\" advancement over the Simple Model accounted for variable residential density. The \"Shotgun Model,\" accounted for both residential density and landuse classes (e.g. agricultural area, forest, etc.) and, therefore, was reported to be the most accurate of the three models.\nIn a similar study, Langford (2006) used two variations of OLS. In the regional regression method, a unique regression model for a subset of source zones from the entire study area was developed. The coefficients of each model were then used to distribute population within corresponding target zones and specific landuse classes. The uniqueness of each regression model was reported to produce a better goodness of fit. Identifying source zones to be included in the regression model, however, is subjective and depends on an individual application. In a global regression approach, the coefficients of one equation representing the relationship between land use classes in the entire study site were used for disaggregation. The author also combined dasymetric mapping with a regression technique to determine a coefficient for each land-use/cover class within a district. Each regression coefficient represented the number of people per pixel or population density in a land-use/cover class in each source zone. The population and area of each land cover class in an Enumeration District (ED) were substituted in the regression model developed with district data to compute unique population density in each land cover class in the ED.\nTo overcome the problems of the OLS approach, Goodchild et al. (1993) implemented a \"log-normal\" distribution to interpolate socioeconomic data in hydrologic basins of California. The general form of the method can be expressed as follows:\nwhere:\ny is a socioeconomic variable in a source zone; X is the area of the source zone; \u03b2 is the coefficient; and \u03b5 is the error term. Both the error term \u03b5 and y are log-normally distributed.\nIn this method, the variance of the distribution is proportional to the mean, which imposes a maximum likelihood approach to estimate population in target zones more precisely. Including additional knowledge, such as density distribution in target zones or control zones usually tends to increase its accuracy. The method, however, does not account for land-cover classes while distributing the variables.\nThe \"Bayesian\" interpolation approach overcomes the negativity constraint of the OLS and accounts for location of land-cover classes. The general form of the interpolation equation can be represented by (Mugglin et al. 1999 ):\nwhere:\nk denotes the covariates used in the model and associated with sub region i within j (target zones); and \u03a6 ij is the error term specific to the sub region and accounts for the random effects. Mugglin et al. (1999) employed a Bayesian interpolation technique to disaggregate leukemia data available at census tract level for Tompkin County, New York, to block groups. Based on distance from a Trichloroethylene (TCE) waste site, urban-rural areas and exposed-unexposed block groups were identified. Finally, the covariates u and w for urban/rural areas and exposed-unexposed areas were used in equation 5 to generate equation 6, which resulted in a smoother map of leukemia distribution in the study site.\nSurface Method A surface method assumes that volumetric data (e.g. population density) can be characterized by a spatially continuous probability distribution function (Fisher and Langford 1995) . Though a number of mathematical functions have been developed to create surfaces, a discussion of widely used surface methods is presented in the following section. The pycnophylactic method is used to create a smooth density map using discrete population data at different enumeration units (Tobler 1979) . The method supposes that population density is a non-negative function and influenced by surrounding source zones. The density is computed as a finite value at any location (x,y \nEq. (10) \u03b4x \u03b4y\nIf the Pycnophylactic and non-negativity assumptions are not taken into account, the minimum is given by Laplace's equation (equation 11), which requires the value of a grid point to be close to the average of four of its neighbors:\nTo achieve a Pycnophylactic condition, the initial value of each lattice point within a zone is incremented or decremented after each computation so that the population density of each point is closer to the smoothness criterion (partial derivative of smoothing function). To smooth density along edges, Tobler (1979) suggested two major boundary conditions. The first condition is Dirichlet's condition in which a numerical value is given to each cell present in the boundary of a zone. The other condition is Neumann's condition in which a rate of density change is specified for each cell located at the boundary.\nThe radially symmetric kernel function is another surface method used to create a density surface using centroids of areal units (Goodchild et al. 1993) . The function (equation 12) is used to assess population distribution in different parts of an areal unit with regard to radial distance of the region from centroid of the areal unit:\nEq. (12) where: p 0 is the population at the centroid; B is a constant; r is the radial distance from the centroid; p(r) is the population at distance r.\nThe radially symmetric kernel function approach is monocentric in nature (single population centroid within a zone), and does not compensate for the variation in population density in different parts of the areal units.\nThe source zone centroid interpolation suggested by Martin (1989) , is a surface method that is an advancement over density distribution method. Each populated area identified using ancillary data and with an above-average density is assigned a centroid such that a source zone could have more than one centroid. A window establishing the maximum extent of a centroid's influence is placed on each centroid. Each window is then subdivided into a number of cells. Each cell is allocated a weight signifying the proportion of the centroid's population within that cell. Usually, a distance-decay function based on distance of each cell from the centroid within a window is employed to compute a weight for each cell. After eliminating unpopulated cells from a window, equation 13 is used to compute the total population in a cell:\nEq (13) j=i where; \u02c6 P i is the estimated population to fall within a cell i; P j is the population associated with centroid j; C is the number of centroids within the study area; and W ij is the weight assigned based on distance between i and j.\nAlthough numerous areal interpolation techniques are available, some techniques are reported to be more accurate than others. Langford (2006) compared areal interpolation, binary and three-class dasymetric mapping and regression based interpolation techniques. He reported that a simple areal weighting method (i.e. an assumption of even population distribution) performed worst and the result from the three-class dasymetric approach was no different than the binary method. The author found that the regional regression approach performed much better than other approaches. Eicher and Brewer (2001) reported that the binary dasymetric technique produced less error than the threeclass areal interpolation technique. The authors also found that using vector data as ancillary layer produced a more accurate outcome than raster data. Langford and Higgs (2006) found that dasymetric mapping produced better results both in urban and rural areas. On the other hand, the authors found that both areal weighting and a non-volume preserving approach performed equally while distributing population in urban areas. Godchild et al. (1993) reported that the Ordinary Least Square regression under-predicted population and a Bayesian approach over predicted population for some areas. However, by imposing a positivity constraint, the log-normal distribution produced the lowest error, and was reported to be more accurate than the other two techniques. Moxey and Allanson (1994) found that by imposing positive and zero constraint for some land-use classes, the Inequality Restricted Least Square (IRLS) interpolation technique produced very accurate results. The Bayesian approach, on the other hand, always resulted in a positive coefficient, and was more accurate than the OLS and IRLS techniques.\nIdentifying the best possible interpolation technique for minimizing MAUP related problems is still dependent upon (1) the individual application, (2) the quality and type of ancillary data and (3) the expected outcome of the study. Moreover, none of the techniques studied account for human behavior and the relationship between human and physical processes. In most coastal counties, people tend to live close to the coastline, originally for transportation-related reasons but more prevalently, for aesthetic reasons. In this study, a new \"process-oriented\" technique accounting for the relationship between housing unit density and proximity to the coast was developed."}, {"section_title": "Methodology", "text": "This study was conducted for Miami-Dade County, located along the southeastern part of Florida and one of the most populous counties in the state (Figure 1a) . The residential building stock in Miami-Dade County is also highly susceptible to future hurricanes. Total area of the county is 6,297km2 (2,431 m2). In 2000, the total population of the county was 2,253,362. By 2005 the county had experienced a 6.6% increase in population (2, 402, 208) . As of April 2005, according to the Florida Department of Revenue, the total number of land parcels in the county was 534,312 of which about 58% (308,836) were zoned as single-family residential parcels. The total number of housing units in these parcels was 312,967."}, {"section_title": "Data and Variables", "text": "The majority of residential parcels of the county are located within about 17.5 kilometers (10.8 miles) inland of the Atlantic coastline ( Figure 1b) . As was evident during Hurricane Andrew, some of these housing units may get damaged from a future storm surge, thereby causing severe prop-erty damage. To estimate economic risk, unless individual structure information is available, aggregate housing unit data collected at census scales is usually used. Thus, the MAUP is a common problem in hazard related studies such as this. To determine an interpolation technique that would provide the most accurate outcome across census scales, this study was conducted at block, block group, tract and county level.\nParcel boundaries and tax assessor's data describing housing units present in a building were obtained from the Florida's Department of Revenue for the year 2005. Population data was not used because 1) no reliable population count at fine scales (e.g. parcel scale) exists, and 2) residential buildings are at serious financial risk to future hurricane related losses. All singlefamily residential parcels were extracted using the zoning code provided in the tax-roll data. Small polygonal areas (< 20-m2) that were likely 'orphaned' parcels or spurious polygons were eliminated as they would not contain structures. Duplicate parcels were also removed. To obtain a consistent set of housing units at each census scale, the county assessor's data was used rather than the U.S. Census Bureau's data. The total single-family residential housing units at each census unit scale (e.g. block, block-group, census tract, county) were summarized from the parcel level housing units. This approach obviated the definition of single-family structures from the U.S. Census versus county assessor's office and assured the total number of housing units was consistent. The tax assessor's parcel data, therefore, was used as the reference data for validation and error estimation.\nThree different land use/ cover data sets obtained from (1) the United States Geological Survey's (USGS) National Land Cover Database (NLCD), (2) the GAP National Land Cover Data, and (3) the National Ocean and Atmospheric Administration's (NOAA) Coastal Change Analysis Program (C-CAP) were used as ancillary layer. All three land use/cover data sets represented land use/cover distribution in MiamiDade County in 2005. The NOAA identified Mean High Water Boundary was used as the coastline boundary, which was used to determine housing unit density distribution with respect to proximity from the coastline. The U.S. Census -2000 boundaries for block, block group, census tract and county were obtained from ESRI.\nA raster data model at 10m x 10m spatial resolution was used for all interpolation techniques. Land use/cover data layers obtained at 30m x 30m resolution (i.e. the only reliable and commonly available observational scale) were re-sampled using nearest neighbor sampling technique to 10m x10m resolution to increase precision of land use/cover distribution. All data layers were converted to North American Datum 1983, Universal Transverse Mercator Projection (Zone 17N)."}, {"section_title": "Techniques", "text": "Four interpolation techniques: areal weighting, dasymetric mapping, process-oriented, and process-oriented with dasymetric mapping, were implemented to distribute housing units at each scale of analysis within the county. In the areal weighting approach, all the housing units present within a census unit (e.g. county) were evenly distributed within the unit (Figure 2) .\nTo minimize the problem of under-and/or over-predicting total number of housing units due to their even distribution within a census unit using the areal weighting approach, a twoclass binary dasymetric mapping technique using land use/cover data was implemented. To illustrate the sensitivity of the interpolation method to different land use/cover data, three different land cover data sets were examined in this study.\nUsing the classification schemes available for each land use/cover data set, residential and non-residential zones were identified a priori. The residential zones were then used to distrib- ute housing units within a census unit (Figure 3) . Based on the Anderson land use/cover classification describing residential land use, developed low intensity (22), developed medium intensity (23) and developed high intensity (24), were used to represent residential zones in NLCD data. Developed low intensity (1202), developed medium intensity (1203) and developed high intensity (1204), were used to represent residential zones in GAP data. Developed low intensity (4), developed medium intensity (3) and developed high intensity (2), were used to represent residential zones in C-CAP data. The dasymetric mapping (1) eliminates the issue of ascribing housing units to non-residential zones as is the case with the areal weighting, and (2) accounts for variable housing unit density distributions rather than a subjective density distribution identified by the classification scheme.\nHowever, it does not reflect the variability in housing unit density with regard to the geographic location of each census unit, which is evident in the case of coastal counties, where people tend to live close to the coastline. Obtaining high-precision ancillary data to conduct dasymetric mapping is also not always feasible. In this study, three different land use/cover data sets were obtained just to determine the ancillary layer providing highest accuracy. Though obtaining these data sets was relatively easy for the U.S., it is not always the case with other countries.\nThe \"process-oriented\" technique was implemented to model the variable relationship between housing unit density and proximity to coastline. In Miami-Dade County, as is the case with most coastal counties, the total number of housing units decreases with increasing inland distance (Figure 4 ). Unlike the total number of housing units, the housing unit density does not decrease immediately with increasing inland distance. Rather the housing unit density increases with increasing distance from the coast up until 5 kilometers ( Figure 5 ). Except for a few small \"bumps\" in the housing unit density pattern representing inland urban areas, beyond 5 kilometers, the housing unit density decreases monotonically with increasing distance from the coastline. The housing unit density to coastline proximity was used to spatially disaggregate housing units within a census unit.\nA housing unit density surface (d) representing total housing units within 100 m 2 or 0.01 hectares (a cell of 10m x 10m size) was created. A surface (p) representing proximity to the coastline was also created. This surface was classified into different zones at 250meters interval from the coast. Using both the surfaces (d and p), a new surface depicting housing unit density distribution with regard to proximity to the coast was created (cd). Using the surface (d), a surface (h) was created. This surface represented the total number of housing units present in a census unit at a census scale. Using the surface (cd), total number of housing units present within a census unit at a census scale was computed, which was then used to create a new surface (zs). The new surface (zs) represented total housing units within a census unit based on density variation with respect to proximity to coastline. Finally, the surface representing housing unit density distribution with respect to proximity to the coastline within each census unit at each census scale (I t : interpolation value within a target zone) was generated by using the following expression:\nI t = h/zs * cd Eq. (14) The process-oriented technique was also combined with the dasymetric mapping technique. To accomplish this task, the binary residential/ non-residential layer (b) generated from the NOAA C-CAP land use/cover data was used. First, the housing unit density surface (d) was multiplied with the binary layer to determine housing unit density distribution in residential zones (d b ). Using the new housing unit density surface (d b ) and proximity to coastline surface (p), a new surface (cd b ) was created. This surface depicted housing unit density distribution within residential/non-residential zones with regard to inland distance from the coastline. Using (d b ), total housing units within each census unit was also computed, which was then distributed within residential zones in each census unit to generate the new housing unit surface (h b ). Using (cd b ), total number of housing units within a census unit was also determined, which was then used to create a new surface (zs b ). This surface represented total number of housing units located in a census unit based on housing unit density distribution within residential zones and with regard to proximity to coastline. The following expression was implemented to create the interpolated housing unit density surface (I tb ) within residential zones with regard to distance from the coastline:\nError Estimation Housing unit data obtained at the parcel level was used as reference data for validation and error estimation, which obviated the problem of uncertainty in the quality of reference data. To assess overall accuracy and performance of all Vol. 39, No. 1 13 three techniques, a range of measures were used: mean absolute error (as used by Goodchild et al. 1993; Langford 2006) , root mean square error (as used by Eicher and Brewer 2001; , and percent error (loss of housing units in comparison to total number of housing units present in the study site)."}, {"section_title": "results", "text": "In the simple one-class areal weighted interpolation technique, the housing units are homogenously distributed within a census unit (Figure 6 ).\nThe dasymetric mapping technique using land use/cover data, on the other hand, accounts for the location of water bodies, forest and unoccupied areas, and distributes housing units within populated areas only (Figure 7) . The \"processoriented\" technique though did not account for residential/non-residential zones; it accounted for the location of water bodies. Though homogenously distributed within a census unit, the housing unit disaggregation in the simple \"process-oriented\" technique followed housing unit density variation with regard to proximity to coastline (Figure 8 ). To be clear, the \"process-oriented\" technique does not allocate housing units from one census unit to another -it modifies the spatial distribution of housing units within the census unit. To ensure for housing unit distribution within residential/non-residential zones and account for the density variation with regard to proximity to coastline, the process-oriented technique was implemented in conjunction with the dasymetric technique ( Figure 9 ). Because NOAA-C-CAP data provided the least amount of mean absolute error when used in dasymetric mapping, C-CAP data was used with the process-oriented technique.\nThe mean absolute error and root mean square error (RMSE) resulting from each interpolation techniques is presented in Table 1 . Based on the mean absolute error, it is evident that higher accuracy resulted when housing unit disaggregation is conducted at the block level regardless of the interpolation technique used. Although the dasymetric technique was expected to produce good results, the outcome accuracy varies with the ancillary land use/cover data. In this study, NOAA-C-CAP data resulted in the least error at all scales of analysis.\nThe new process-oriented technique produced less error than both the fundamental areal interpolation technique and the dasymetric mapping at all scales of analysis. When combined with dasymetric mapping, however, the new processoriented technique produces the least amount of error at all scales of analysis. This variation of RMSE also increases at coarser scale of analysis. Among all interpolation techniques, the higher variation in error resulted with the areal weighting technique and least variation resulted from the process-oriented technique combined with the dasymetric technique."}, {"section_title": "conclusion", "text": "Not surprisingly, all areal interpolation techniques perform best at the finest scale of analysis (i.e. block level). Thus, error increases at coarser spatial scales for all techniques. The study also revealed that using different land use/cover data resulted in different accuracy levels for the dasymetric approach, which agrees with the findings made by others (discussed earlier). Among GAP, NLCD and NOAA-C-CAP data, the use of NOAA-C-CAP data resulted in least error at all scales of analysis. Among all techniques, the new process-oriented technique combined with the dasymetric technique consistently resulted in more accurate population distribution than the other techniques. The new process-oriented technique performs better than areal weighting and also dasymetric mapping. As the new technique does not require ancillary data, which is very often difficult and/or expensive to gather, this technique could easily be implemented in a GIS environment. "}]