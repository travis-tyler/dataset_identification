[{"section_title": "", "text": "to support effective data-driven planning not only in the showcased area but in other coastal regions as well. Based on local data available for analysis, the application framework could be expanded as needed and include other topics (e.g. measure the effect of SLR for specific types of businesses) or utilize alternative inundation models (e.g. include hydrologic runoff analysis)."}, {"section_title": "INTRODUCTION", "text": "The ocean economy consists of six economic sectors: living resources, marine construction, marine transportation, offshore mineral extraction, ship and boat building, and tourism and recreation. It contributed 1.6% ($304 billion) to the United States gross domestic product and accounted for 3.3 million employees, 154,000 business establishments and $129 billion in wages (NOAA, 2019). However, different forms of coastal inundation, such as sea level rise (SLR), storm surges and high tide flooding (often called \"king tide\", see Figure 1) interrupt this economy and result in economic losses. A recent study estimated that the loss in real estate market value between 2005 and 2016, in areas that are projected to be inundated with tidal flooding in 2032, has already reached $465 million in Miami-Dade County alone (McAlpine and Porter, 2018). Climate Central's Program on Sea Level Rise estimates that 422 km of roads and 53,000 homes are less than 3 feet from the tidal surface in the county (Climate Central, 2020), and could be inundated as soon as 2050 under an extreme SLR scenario (NOAA, 2017). South Florida, due its low elevation and lack of topography, is especially exposed to coastal inundation. For example, in the Upper Florida Keys about 41 km 2 of land with $350 million in real estate property and 1,200 people is already below the NAVD 88 vertical datum line, and is therefore influenced by salt water at least twice a day on average during semidiurnal high tides (Zhang et al., 2011). For an SLR scenario of 0.3 m, an additional $430 million in property values are projected to be lost. The rate of SLR varies significantly by location, therefore any adaptation techniques and resilience action plans must consider local characteristics. The average SLR rate in the Miami area (9 \u00b1 4 mm/year) is significantly more accelerated than the global average (3.2 \u00b1 0.4 mm /year) (Wdowinski et al., 2016), which will likely show increased impacts of coastal flooding on South Florida. Multiple local, regional, and federal agencies publish data related to SLR and storm surges which can support local policy making. Unfortunately, this information is scattered among data portals and not easily accessible to the public and governmental decision makers. However, using innovative solutions to improve data accessibility and visualization, to increase their relevance for local decisionmaking, has become a trend in recent years on all levels of planning (Hall et al., 2019). Coral Gables is a community of about 50,000, located southwest of Downtown Miami (Figure 2a). The city has direct access to Biscayne Bay, which makes it particularly vulnerable to tidal flooding and SLR. The web-based SLR Impact Assesment Tool introduced in this paper was developed for the city, to be used in its planner's decision making processes. The tool allows the user to select from different SLR and storm surge scenarios. In response, inundated areas are mapped, based on these scenarios. The tool also assesses the impact of these hazards on various socio-demographic factors and infrastructure variables for user-selected census blocks. This functionality is achieved by dynamically generating visualization and quantitative reports for the user-selected area within the city (Figure 2b). This work presents the implementation of this application and describes its functionality. Free and open source geospatial (FOSS4G) components have already been used to develop interactive web GIS applications before , however, our approach to development of this tool favors the latest technology in web development over traditional GIS solutions. The remainder of the paper is structured as follows. Section 2 provides a review of data products and resources used for inundation mapping in the United States. Section 3 details data sources and data preparation methodology of the SLR Impact Assessment Tool (available at https://slr.fiu.edu/CoralGables). The technical development process is described in Section 4, which is followed by the presentation of the application functionality in Section 5. Section 6 critically reflects on the application development process and provides recommendations for the development of similar applications. Section 7 summarizes and concludes the work. "}, {"section_title": "DATA ECOSYSTEMS AND TOOLS FOR COASTAL INUNDATION MAPPING AND IMPACT ASSESSMENT", "text": "In its simplest form, passive coastal inundation mapping is the process of comparing a digital elevation model (DEM) with a digital water surface, to identify areas where the water surface is above the ground elevation surface. This comparison shows the extent of inundated areas and water depth. This approach is often called the \"bathtub\" approach. The bathtub can be filled in two ways, namely with or without hydrological connectivity. In the first case, in addition to being below the flood level, an area must be hydrologically connected to the source of the flooding, such as the ocean or a previously flooded area, to be inundated (Yunus et al., 2016). As opposed to this, in the second case, the inundation is solely determined by the flood level and the DEM. Coastal planners and the public are concerned about the physical, ecological and socio-economic impacts of coastal inundation (Merwade et al., 2008). Therefore, assessing this potential impact can be considered as an associated step of inundation mapping. Various data are needed throughout all phases of the coastal mapping process. However, potentially useful datasets are generated, maintained and published by multiple federal, state and local agencies, which makes discovering and utilizing the most suitable datasets a challenge. The main federal actors involved in costal inundation mapping and risk assessment in the United States are summarized in Table 1. This scattered picture is even further complicated by interagency and interdepartmental collaborations (e.g., National Climate Assessment (NCA)), and the fact that multiple subsidiary agencies within an umbrella organization can be involved in coastal mapping. For example, the National Oceanic and Atmospheric Administration (NOAA) houses the National Weather Service (NWS), the National Hurricane Center (NHC), the Office for Coastal Management (COAST) and the Center for Operational Oceanographic Products and Services (CO-OPS). All these subsidiary agencies and offices are responsible for maintaining different resources related to coastal infrastructure, hydrology, oceanography, weather, and inundation models. The following subsections provide an overview of (some) resources that are made available for coastal inundation mapping through different levels of government agencies. High resolution elevation data is crucial for accurate coastal inundation mapping (Titus et al., 2009). One problem that coastal scientists and planners face is that the National Elevation Dataset (NED), maintained by the USGS and available nationwide, has at most 1 arc-second spatial resolution (~30 m), which is not adequate for coastal inundation mapping. However, for certain areas 1/9 arcsecond (~3 m) NED datasets are available, and the newly established 3D Elevation Program (3DEP) also includes a non-seamless LiDAR (Light Detection and Ranging) based 1 m elevation layer (Arundel et al., 2018) . Another service, the Data Access Viewer (https://www.coast.noaa.gov/dataviewer), allows the user not only to search and discover, but to directly download nationwide elevation data."}, {"section_title": "Coastal Inundation Mapping Resources", "text": "The presented application focuses on two types of coastal inundation, namely SLR and storm surge. However, coastal areas also suffer from high tide and inland flooding. Data and resources related to these types of inundation can be tied to specific events. An example of event-based data is the collected real-time advisories, warnings and hazard alerts issued by the NWS in response to a specific event, such as high tide flooding which, however, come in coarse spatial resolution (e.g., a city or county). Similar alerts are issued by state emergency and transportation departments, which are often available in a machine readable format (e.g., https://alerts.weather.gov/). The Coastal Inundation Dashboard (https://tidesandcurrents.noaa.gov/inundationdb/) developed by NOAA CO-OPS provides both real-time and historical coastal flooding data for water level stations across the U.S. A widely used resource is FEMA's Coastal Flood Insurance Rate Maps (FIRMs), which is a probability-based product. It is used to create insurance zones, to identify flood risk and hazards (Brown, 2016), and to delineate floodplains, showing the boundaries of floods with a certain probability. For example, the 100-year floodplain is the area of the flood that has a 1% probability of happening in any given year. FIRMs are created after detailed flood insurance studies that determine the effects of storm surges and other coastal flooding. FIRMs are often used by local communities for planning. Another widely used resource for storm surge inundations is the SLOSH (Sea, Lake and Overland Surge from Hurricanes) model developed by the NWS. In SLOSH, the Maximum Envelope of High Water (MEOW) shows the maximum likely extent of flooding in a basin for a hypothetical storm category with a certain trajectory and forward speed. It is calculated for various scenarios. Our tool uses the MOM (Maximum of MEOWs) output of SLOSH, which considers multiple combinations of forward speed and trajectory for a basin to create a worst-case snapshot for a particular storm category (Jelesnianski et al., 1992). SLOSH outputs are freely available through the SLOSH Display Program. P-Surge (Probabilistic Hurricane Storm Surge) is a related model that uses the NHC's official hurricane advisories to create storm inputs for SLOSH. Using historical errors in the official NHC hurricane forecast, it derives the probability of storm surge from an active hurricane (Taylor and Glahn, 2008). A summary and short description of other storm surge, coastal flood risk, wave and damage assessment models is given by Goodison and Thomas (2015) (Mitsova et al., 2016). These stabilization options are based on an exposure index which considers wind/wave exposure, boat wake, nearshore slope, storm surge, water depth, nearshore habitat, and distance to inlet. SLR on the national scale is mapped by NOAA COAST, which also operates the Sea Level Rise viewer (https://coast.noaa.gov/slr). The viewer can be used for planning, education and awareness purposes only, and not for site-specific analysis. The methodology (NOAA, 2017) and data (https://coast.noaa.gov/slrdata) are publicly available for download. To define local adaptation strategies, mapping SLR is usually undertaken on a localized scale, which can yield better results than a global model (e.g., by using refined elevation models). Many jurisdictions follow passive mapping techniques such as the bathtub approach, which are computationally less intensive and not as sophisticated as hydrodynamic models (Hinkel et al., 2014). The Sea Level Change Curve Calculator (http://corpsmapu.usace.army.mil/rccinfo/slc/slcc_calc.html) is maintained by USACE and visualizes different sea level scenarios for any NOAA tide gauge (Huber and White, 2017). It can be used by local authorities to develop their adaptation plans, as it calculates projected sea levels for a specific area."}, {"section_title": "Supplementary Data for Impact Assessment", "text": "Assessing vulnerability to coastal inundation comprises an estimation of social and economic impacts and the utilization of this information for the development of adaptation strategies. In the United States, such assessments can be based on official data due to copyright laws, which place all works created by the federal government in the public domain. The U.S. Government's open data website (https://data.gov) is designated to be the federal government's open data site, which contains data from multiple agencies. However, simply liberating and consolidating data from multiple sources does not spur innovation by itself (Krishnamurthy and Awazu, 2016), and access to data is still cumbersome. In addition, copyright laws are different among individual states. Even though many states, counties, and cities operate their own open data sites, their agencies may also operate their own repositories. As a result, in-depth knowledge of agency and government structures is necessary to gather a wide array of datasets."}, {"section_title": "METHODOLOGY AND DATA SOURCES", "text": ""}, {"section_title": "Inundation Modeling", "text": "The SLR Impact Assessment Tool relies on modeling inundation caused by SLR and storm surges. SLR was measured relative to the mean higher high water (MHHW) surface. A series of SLR inundation scenarios between one foot and eight feet, with one-foot increments, was created using a bathtub model with hydrological connectivity, based on a DEM which considers heights of levees and weirs in canals. The DEM used in the computations was derived from a 2015 LiDAR dataset of Miami-Dade County given in the NAVD 88 vertical datum. This surface is 0.1 m below the MHHW in South Florida (Zhang et al., 2011), which was taken into account in the calculations. Inundations from storm surges caused by hurricanes of category one through five at high tides in the Miami basin are sourced from SLOSH. As a last step, all possible combinations of SLR and storm surge inundations which define inundation scenarios were created by adding inundation values of the different layers. Although it was found that the interaction between SLR and storm surge is almost linear at the open Atlantic Ocean outside Biscayne Bay (Zhang et al., 2013), adding inundation from both sources is only an approximation in coastal areas and likely underestimates the combined effect of SLR and storm surge. However, since the complex interaction between the two effects is still an open research question (Hall et al., 2019), which would require extensive modeling and simulation efforts, inundation in our application was approximated through simple addition of inundations generated by SLR and storm surge."}, {"section_title": "Estimating the Social and Economic Impact of Coastal Inundation", "text": "The potential impact for all SLR/storm surge scenarios on various social and economic variables was estimated at the U.S. Census block level. Table 2 shows the attributes of interest incorporated in the tool, which were grouped into five categories. Estimating these impact statistics involves multi-step pre-processing. First, the inundation extent corresponding to a certain SLR/storm surge scenario in the user-selected area is converted to an inundation vector layer. This layer is then used to clip the GIS layer of the variable of interest (see Table 2) to the inundation extent. Finally, the affected supply per block (e.g., affected population) is estimated in blocks overlapping the inundation extent. An example of the workflow that computes the area affected for each land use type is visualized in Figure 3. Similar procedures were executed for other variables of interest and repeated for each scenario combining SLR and storm surge, using Python scripts. At the end of this step, the total count and the affected count for an attribute (e.g., total area of residential land use along with the area of flooded residential land use) were available for each block within the city, for each combined SLR/storm surge scenario.  "}, {"section_title": "APPLICATION DEVELOPMENT", "text": "A lightweight and flexible application was designed and implemented with FOSS4G (Free and Open Source Software for Geospatial) components. This section explains the architecture design (Figure 4). Data layers are shown in green, and server components in orange. Subsequent sections provide more details about each component."}, {"section_title": "Data Processing Framework", "text": "The data processing framework is a custom-built Python tool that serves two purposes. First, it normalizes the input dataset. The input data contains statistics about the total and affected areas for each scenario combining SLR and storm surge, as described in Section 3.2. Initially, this data was generated as an ESRI Geodatabase feature class which, for each U.S. census block geometry stored, estimated values for each SLR/storm surge scenario as a flat database. There is a total of 27 measured variables for five storm and 9 SLR scenarios (between 0 and 8 feet SLR), which results in more than 1,200 attributes. The tool normalizes this flat database into the structure outlined in Table 3. In addition, the data processing framework converts inundation layers to vector tiles for seamless display in the user interface. Vector tiles are described in Section 4.3. The framework was designed such that it can easily be extended with new variables and scenarios in the future. "}, {"section_title": "API and Database", "text": "The data is exposed to the web through a RESTful Application Programming Interface (API) which is connected to a MySQL database. The database stores statistics at the block level (Table 3). In this database, multi-column indexes were created specifically to optimize the performance of predefined queries performed by the API. The API accepts HTTP GET requests through five endpoints corresponding to categories in Table 2. An example request is given in Figure 4b, which illustrates the procedure of data retrieval. In this query, demography statistics for two census blocks (IDs 123 and 124), corresponding to an SLR of three feet and a category two hurricane are returned, which include both the total and affected population. By design, the structure of API calls and responses are analogous for all categories, with only the properties differing from each other. Similarly to the data processing framework, this design choice improves flexibility as it allows the quick and seamless integration of new variables if needed. "}, {"section_title": "Vector Tiles", "text": "Geospatial data is served as vector tiles through a tile server. Tiled web maps are often used in web mapping applications, as this approach is effective in transferring and visualizing geographic data. In the tile system, the world is divided into different sets of tiles corresponding to zoom levels. At zoom level 0, one tile covers the whole world. The geographic area representing a tile is divided into 4 smaller tiles in subsequent zoom levels, hence, as the zoom level increases, tiles gradually contain more detail. In each zoom level (Z), tiles are indexed by X (column) and Y (row) to provide a common reference system. Hence, this schema is also referred to as the XYZ tile schema, since an X and a Y along with a zoom level (Z) specify a distinct area on Earth's surface (Juh\u00e1sz and Hochmair, 2016). The system is illustrated in Figure 5. It is possible to transfer both raster and vector data using this schema. In our application, vector tiles were chosen as the data format for their versatility and capabilities for in-browser visualization and user friendliness. In most cases vector tiles load faster, reducing server load and the amount of data transferred when compared to other mapping approaches, such as using raster tiles (Netek et al., 2020). Two types of tiles are utilized in the application, namely inundation tiles generated from binary inundation layers, and background map tiles based on OpenStreetMap (OSM) data. Inundation tiles are built with polygon geometries through the processing framework. Each polygon contains two values, which are the minimum SLR and the storm scenario in which they become inundated. The visual appearance of features stored as vector styles can be modified on the fly in a web map. As a result, inundation scenarios can be quickly changed by filtering these attributes. The same flexibility applies for the background map. In addition, using OSM as the background map data provider and hosting background tiles as part of the infrastructure eliminates dependence on commercial map providers that may charge licensing and subscription fees. Both types of tiles are processed and stored as mbtiles and served through tileserver-gl-js. "}, {"section_title": "User Interface", "text": "Users interact with the tool through the front-end component, which was written in JavaScript and is running in a Node.js container. The design of the user interface was guided by the principle of providing instant feedback to the user (Shneiderman et al., 2016), in this case through visualization of the modelled social and economic impact of SLR and storm surge inundation based on user-chosen parameter settings. As seen in Figure 6, the interface is divided into a map viewer (left) and a statistics report area (right). The map interface was built with Mapbox GL JS, which renders vector tiles using WebGL technology. An advantage of this technology is that rendering takes place in the web browser. As opposed to loading pregenerated raster tiles, all map features, including the background map, can be easily manipulated in the browser. Furthermore, the ability to access vector geometries in the browser allows performance of geospatial operations. For example, the Turf.js library is used to calculate the combined area of the user selection in real time, and to calculate centroids and spatial extents for dynamic zooming. The statistics report area conveys the potential impact of chosen inundation scenarios, which is achieved by dynamically created and updated charts. "}, {"section_title": "APPLICATION FUNCTIONALITY", "text": "Storm categories and different levels of sea rise can be adjusted by changing the slider positions above the map interface ( Figure 6). A change in these settings will highlight inundated areas on the map instantaneously. In order to assess the potential impact of these inundated areas, the user needs to select census blocks within the city limits of Coral Gables (highlighted area in Figure 6), upon which charts and numbers will be displayed in the statistics pane. Users also have the option to select the entire city at once. In line with Table 2, the statistics pane is organized into five topic categories, which are demography, property, facility, land use and roads. For each of these categories, multiple charts are presented. Numbers that appear here reflect the current settings (SLR and storm surge) inside the selected area and all statistics groups present information for both total and affected counts or values (i.e., population, property value). Changes in inundation level settings and area selection are instantly reflected in both the map and statistics panes. This dynamic relationship empowers users to interactively explore and study the potential impact of different SLR and storm surge scenarios in any area of interest. The application displays information on a localized scale which facilitates adaptive planning, as decision makers can tailor strategies to their city or even their neighborhood. On the application level, each change triggers five API calls to load statistics for each topic category. To improve performance, data caching is also implemented so that previously loaded scenarios can be displayed without loading data through the API again. Figure 7 shows the same interface displaying different data categories for a different SLR and storm surge scenario. Several other features have also been implemented to aid the interpretation of results. For example, the size of the selected area is dynamically calculated and reported in the interface (top right panel). Additional GIS layers, such as land use, can also be turned on to be rendered on the map (Figure 8). Furthermore, these polygons are dynamically linked with the corresponding statistics. Upon highlighting a land use category on the right side, the corresponding category will also be emphasized on the map, such as recreational areas rendered with dark brown color both on the map and charts (Figure 8). The WebGL technology utilized in this application also supports 3D rendering and the view can be tilted and rotated freely. Currently, buildings are rendered with their correct heights. Lastly, we expect that the tool will be used by city officials. Therefore, an export functionality was also implemented, which dynamically generates and downloads a PDF document for the current settings. This report also features additional data tables and further explanations that help with the interpretation of results, in addition to the map and charts shown in the application. "}, {"section_title": "LESSONS LEARNED AND BEST PRACTICES", "text": "There are several findings that emerged throughout the project. This section summarizes the lessons learned and provides recommendations for the planning and development of similar applications. Lessons learned are not specific to applications dealing with coastal inundation but may be relevant for a wider group of data-driven applications. One of the most important aspects in developing web-based, data intensive mapping applications is to identify the target audience, which can, for example, entail professionals, researchers, planners, public administration, or the general population. A too broadly defined audience can lead to an ineffective application that does not resonate well with its users. As opposed to this, developing for a more specific group of intended users dictates design decisions as the group, their level of training and planned use cases are known (Muehlenhaus, 2013). The SLR Impact Assessment Tool is aimed at assisting decision-making, and intended for use by local government agencies, planners, and other professionals. It is likely that due to their training, this group of users is more familiar with different data visualization techniques than a general audience, so that maps, data and charts are useful decision-making aids. Although a target audience of a narrow group of professionals allows to portray more data and use more advanced visualization techniques, applications should avoid the 'data rich but information poor syndrome' that limits the efficacy of portraying a message (Mooney and Juh\u00e1sz, 2020). Recent examples are data maps and portals developed for the  (coronavirus disease 2019) pandemic in early 2020 that often fail to convey the intended message due to containing more data and visuals than one can understand (Mooney and Juh\u00e1sz, 2020). Uncertainty is inherently present in inundation modeling due to presenting a probabilistic outcome (will this area be inundated?) on a deterministic map. Furthermore, this uncertainty also affects the estimation of socio-economic variables as described in Section 3. Even though communicating uncertainty is important, Beven et al. (2015) conclude that the effort of conducting a full uncertainty analysis may not be proportionate for all applications. In this work, due to the limited budget and resources, we assume that professional users have some understanding of the sources of uncertainty. The SLR Impact Assessment Tool contains a disclaimer section that points out methodological weaknesses important to the end user. Finally, we emphasize the importance of limiting the liability of the developers in case the application is misused. In our case, this required to involve legal counsel to review and finalize the disclaimer. Using open source software (OSS) can effectively reduce development costs (Perens, 2005). While OSS can exist in isolation, developing a geospatial web application requires the integration of multiple software components and data, therefore interoperability of these different components is important. There is a noticeable shift towards interoperability through APIs and standards in the geospatial domain, which makes the development of such applications easier. Similarly, feeding open data into open geospatial software is also a noticeable trend (Minghini et al., 2020). As described in Section 4, the SLR Impact Assessment tool uses several OSS components, open data sources and standards. Several advantage of this approach can be mentioned. For example, OSS does not require license fees, which is an important cost consideration. Furthermore, similar projects are usually funded for a limited amount of time, therefore, not relying on annual license fees allows to keep the project alive for a longer time period with minimal investments. Using OSM data to generate background map tiles eliminates data subscription fees that otherwise would have to be paid to commercial providers like Google, Bing or Mapbox. Furthermore, the technology field is changing rapidly. The short development cycle of OSS can adapt new technologies quicker than traditional software developed by large firms. However, ensuring the continuity of the development is another important consideration that might be problematic. Traditional software corporations like ESRI in the geospatial world have a mature ecosystem of software and data. In addition, the large market share makes recruiting and hiring qualified professionals that are familiar with these components relatively easily compared to some specialized open source software companies. Furthermore, training people to use specialized tools can be time consuming, and so does finding suitable replacement of developers that are familiar with OSS components."}, {"section_title": "SUMMARY AND CONCLUSIONS", "text": "This paper introduced the Sea Level Rise Impact Planning Tool that was developed for the City of Coral Gables. As South Florida faces challenges posed by coastal inundation, such a tool can be an asset to both policy makers and the general public for their decisions when facing coastal inundations. Our application can display inundation levels for SLR between one and eight feet and for storm surges caused by hurricanes category one through five. The potential impacts of these inundations are estimated at the U.S. Census block level and are also reported in the application in the form of interactive charts organized into five topics of social and economic categories. We conclude that high quality applications to support planning related to SLR and storm surges can be built with open source components. The use of WebGL technology and vector tiles provides a high level of interactivity in terms of geospatial applications. The paper also provided an overview of the data ecosystem around coastal inundation mapping in the United States. While mapping inundation and assessing its impact can be achieved by using data created by government entities, access to these datasets is still cumbersome and complicated, due to the scattered locations of data, requiring detailed knowledge of where to access the available resources. For future work, we plan to extend our collaboration to other coastal municipalities in Florida that can adapt our solution. In addition, future work will explore other possibilities for displaying inundation in web maps, such as exploiting 3D rendering of flood depth. We expect that this feature will increase people's understanding of different inundation levels. Collection of crowd-generated flood data to validate inundation models is also planned."}]