[{"section_title": "Abstract", "text": "Longitudinal analysis of anatomical changes is a vital component in many personalized-medicine applications for predicting disease onset, determining growth/atrophy patterns, evaluating disease progression, and monitoring recovery. Estimating anatomical changes in longitudinal studies, especially through magnetic resonance (MR) images, is challenging because of temporal variability in shape (e.g. from growth/atrophy) and appearance (e.g. due to imaging parameters and tissue properties affecting intensity contrast, or from scanner calibration). This paper proposes a novel mathematical framework for constructing subject-specific longitudinal anatomical models. The proposed method solves a generalized problem of joint segmentation, registration, and subjectspecific atlas building, which involves not just two images, but an entire longitudinal image sequence. The proposed framework describes a novel approach that integrates fundamental principles that underpin methods for image segmentation, image registration, and atlas construction. This paper presents evaluation on simulated longitudinal data and on clinical longitudinal brain MRI data. The results demonstrate that the proposed framework effectively integrates information from 4-D spatiotemporal data to generate spatiotemporal models that allow analysis of anatomical changes over time."}, {"section_title": "Introduction", "text": "Analyzing longitudinal anatomical changes, via medical imaging, is a crucial component in many clinical scenarios. Subject-specific models of longitudinal changes of anatomy and tissue properties are essential in personalized-medicine applications for predicting disease onset, determining growth/atrophy patterns during neurodevelopment/aging, evaluating disease progression, and quantitating recovery and treatment efficacy. Estimating anatomical changes from longitudinal data, especially magnetic resonance (MR) images, is challenging because of temporal variability in shape (e.g. from growth/atrophy) and appearance (e.g. due to imaging parameters and tissue changes affecting intensity contrast, or scanner calibration).\nClinically relevant anatomical changes are characterized not only by the deformation of anatomical structures but also by changes in spatial distributions and volumes of tissues and structures. Recent literature [6, 8] has started addressing this problem, but it presents methods for estimating deformations, underlying longitudinal changes, separately from the problem of estimating spatial tissue distributions. On the other hand, this paper solves the problem of joint estimation of the deformations and tissue distributions underlying longitudinal changes. This paper presents a novel formulation for constructing spatiotemporal subject-specific models from longitudinal image data based on a generative model for changes in image appearance and anatomy. To perform this task, the proposed method defines, and solves, an optimization problem. The proposed method captures the deformation of anatomical shape by estimating a chain of diffeomorphisms that is constrained to be temporally smooth. The method achieves this by implicitly defining an optimal spatiotemporal tissue \"atlas\" (a time sequence of tissue probability maps for a single subject) and optimal segmentations at each time point. Thus, the proposed method solves a generalized problem of joint segmentation, registration, and atlas building, which involves not just two images [1, 13] , but an entire longitudinal image sequence. The proposed framework describes a novel approach that integrates fundamental concepts that underpin segmentation, registration, and atlas construc-tion. This paper presents evaluation on simulated longitudinal data and results on clinical longitudinal brain MR images."}, {"section_title": "Related Work", "text": "The study of subject-specific longitudinal changes often relies on 4-D segmentation methods that extract anatomical objects consistently in the presence of temporal variations, as described before. Thus, 4-D segmentation methods need to exploit spatiotemporal relationships to ensure smooth and realistic changes in anatomy and to robustly handle varying noise in the temporal image sequence. The quantification of spatiotemporal smoothness is essential for this problem and, to our knowledge, this has not been adequately defined. A pioneering approach by Xue et al . [16] proposed an algorithm for temporally-consistent segmentation for longitudinal images through iterated registration and segmentation. However, it remains unclear what the convergence properties of such an algorithm are, what objective function it optimizes, how free parameters (such as number of iterations) are chosen, etc. Furthermore, this method does not provide a formulation for interpolating anatomical structures at specific time points.\nRegistration of 4-D images is fundamental for analyzing sequences of cardiac images. Peyrat et al . [12] and Shen et al . [15] proposed methods for registering spatiotemporal cardiac images by registering images sequentially. In their methods, registration is performed based on images without segmentation of the underlying anatomies. These methods do not incorporate a spatiotemporal anatomical atlas and an explicit longitudinal growth model. In addition to cardiac imaging, 4-D registration is also critical for respiratory motion correction. Bai and Brady [3] proposed a method for registering sequence of Positron Emission Tomography (PET) images of the lung using a periodic temporal weighting. This method registers all images to a reference time point, and thus does not contain a model for longitudinal changes.\nThe literature on atlas construction from population data includes the population-regression framework proposed by Davis et al . [5] , which uses kernel regression and diffeomorphic mappings for cross-sectional longitudinal MR images. However, their method performs age regression of single time point MRI data and does not model correlations introduced by repeated MRI acquisitions per subject. Recent approaches were also proposed for constructing spatiotemporal population atlases for neonatal brains [11] and fetal brains [7] , with the assumption that anatomical structures are known beforehand. In contrast, our proposed model estimates tissue probability maps from MR images and incorporates a specific sequence of diffeomorphic mappings resulting in a true longitudinal anatomical model. Atlas construction for an ensemble of images is an integral part of the proposed framework, similar to the latentatlas-based segmentation approach of Raviv et al . [14] . Unlike the latent-atlas model for a population, the proposed atlas construction scheme is subject-specific with longitudinal constraints."}, {"section_title": "Building Spatiotemporal Anatomical Models", "text": "Let us consider multimodal MR images {I t }, of a single subject, acquired at multiple time points t = 1, \u00b7 \u00b7 \u00b7 , T . Each image I t = {I t (x) : x \u2208 3 } has an anatomical structure, characterized by C tissue types (c = 1, \u00b7 \u00b7 \u00b7 , C), changing smoothly over time. This section describes a mathematical model for spatiotemporal anatomical changes and the method for estimating these model parameters from longitudinal image data. Figure 1 illustrates the key ideas."}, {"section_title": "Mathematical Model", "text": "We rely on a generative model for changes in image appearance and anatomy incorporating the following components:\n(1) We model image appearance by assuming that the multimodal image data I t is obtained from a Gaussian mixture model (one Gaussian N (\u00b5 sue type c). The likelihood probability of observing intensity I t (x) given tissue class c is P \nThus, diffeomorphic maps for a subject over time are constrained to preserve the temporal ordering of the sequence. The atlases are constrained to be a set of probability mass functions\nThe parameters underlying our model are \u0398 = (A, h, \u00b5, \u0393). We estimate an optimal \u0398 by solving the following constrained minimization problem:\nsubject to the atlas probability constraints describe before, where\nwhere Q denotes the spatiotemporal distance between the model and the data and R denotes the regularity term for the deformations h t,t+1 that enforces smooth changes between consecutive time points. \u03c3 Q is a scalar weight that balances the distance term and the regularity term. Given the model parameters \u0398 = (A, h, \u00b5, \u0393), we define Q to be the spatiotemporal \"distance\" between data I and atlas A, weighted by temporal kernel function K:\nThe temporal kernel K defines the range of influence of each time point to the other time points. The distance Figure 2 . Conceptual view of the distance between image data at time ti and the atlas at time tj. We measure the distance through the image-appearance likelihood probabilities P t i that are warped (using ht j ,t i ) to time tj. The atlas A t j is A warped to time tj (using h t j ,ref ) and \"distance\" d is measured as the negative log likelihood weighted by the temporal kernel K(ti, tj), where closer time points have higher influence.\nbetween image data at time t i and atlas at time t j is the negative log likelihood of the atlases and imageappearances that have been mapped to the same time point, yielding\n(6) Thus, at a time point t j , we want the atlas A tj to be similar to the warped (using h tj ,ti ) image-appearance likelihoods P ti at time points t i , weighted by the kernel K(t i , t j ).\nAn important effect of the kernel is that of enforcing smooth transitions, at time points t, between the diffeomorphisms h t\u22121,t and h t,t+1 (note that R doesn't enforce this; clarified further in the Appendix). Lorenzi et al. [10] achieve this effect via a prior for regularizing the global temporal evolution in the diffeomorphic demons framework. A conceptual view of the distance between the data and atlas, taking account of temporal distance, is shown in Figure 2 .\nWe construct each of the diffeomorphic mappings h following the framework of large deformation diffeomorphic metric mapping [4] , where the regularization Figure 3 . Overview of the construction scheme for diffeomorphic maps by shooting a trajectory from an initial momentum. The discrete maps are computed from the initial momenta and then composed to form the mappings. Interpolation of the diffeomorphic maps is done by flowing at an intermediate step between t and t + 1.\nterm R(h) is defined as: (7) where w denotes the discretization of the transform between t i and t i+1 , u denotes the momenta defining the construction of the diffeomorphic mappings, and G is the spatial kernel that defines the smoothness of the mappings. Following the geodesic shooting formulation of Ashburner and Friston [2] , each mapping h ti,ti+1 is parametrized only by its initial momenta u ti,ti+1 (0). Figure 3 shows an overview of the diffeomorphic construction scheme."}, {"section_title": "Model Estimation", "text": "We estimate the parameters \u0398 for the spatiotemporal model using alternating step-adaptive (projected) gradient descent over the parameters. The projection step is required for atlases due to the constraints on A and A t . The atlas constraint/feasible sets correspond to convex regions on the hyperplanes where all coordinates are non-negative and sum to unity. The projection operation maps the gradient-descent update to the nearest point in the feasible region. The projected gradient descent is guaranteed to converge, given sufficiently small step sizes. Thus, the model estimation is an iterative optimization procedure, where at each iteration we compute the gradient directions and determine the step in each direction that reduces the criterion \u03a8. We enforce the probability constraint only on A because this automatically enforces the constraints on the diffeomorphically warped A "}, {"section_title": "Validation", "text": "This section presents validation results using simulated and real longitudinal brain MR images with \u03c3 Q = 0.5 and Gaussian kernel K. We validate our model estimation method (similar to a cross-validation strategy) by leaving out data at a specific time point, building a model from the remaining data, and then comparing the ground truth segmentation of the left out data against the interpolated result from the model. Figure 4 shows an overview of our validation approach.\nThe anatomy at an arbitrary time point s is obtained by interpolating the deformations h ti,s , and then interpolating the atlas and image-appearance likelihood probabilities that have been deformed to time point s. The atlas probabilities A for class c at time s is chosen to be the one that is matches best to the likelihoods from other time points warped to s, or arg min Figure 4 . Overview of the validation scheme (similar to a cross-validation strategy) by leaving out data from one time point. We interpolate the anatomy (the tissue probabilities Z) at the left-out time point via interpolation, and then compare the interpolated anatomy against the ground truth.\nwhich yields the following kernel regression equation for interpolating the image likelihood:\nThe classifications for each time point and each class is obtained from the normalized tissue probabilities\nValidation measures are obtained by comparing the maximum-probability segmentation labels (discrete label map) against the ground truth (discrete label map) for the left-out time point using the Jaccard overlap measure [9] ."}, {"section_title": "Simulated Longitudinal Data", "text": "We generate synthetic longitudinal data with known ground truth by specifying a combination of basic shapes that may change over time. These shapes include two circles and a clover-like structure (sinusoidal change in the radial component in polar coordinates). The top-circle radius increases over time, the bottom-circle radius decreases over time, and the size of the clover decreases over time. We simulate different image-appearance models (representing MR modalities) and different noise levels over time. Figure 5 shows the synthetic images. The results of our model construction scheme, compared to independent segmentations at each time point, are shown in Figure 6 . We measure the performance of our model by comparing the synthetic ground truth against the interpolated segmentations at the third time point, where we obtain Jaccard overlap measures of 0.9326, 0.9036, "}, {"section_title": "Clinical Longitudinal Data", "text": "We analyze the performance of our method using the longitudinal clinical data provided by the Alzheimer's Disease Neuroimaging Initiative (ADNI). These subjects were scanned at 4 time points including a baseline age that varies per subject, and subsequently at 6 months, 1 year, and 2 years after the baseline scan. We apply our method on a subject with Alzheimer's disease (subject 1055) that has a baseline age of 84.75 years, and a subject with normal aging (subject 0303) that has a baseline age of 84.42 years. For validating our model and the estimation algorithm, we leave out the scans taken one year after baseline and compare the white-matter segmentation obtained by interpolating the anatomy against ground truth. The groundtruth data is composed of manual segmentations of white matter in a single slice in the 3D image data. We obtain a Jaccard overlap measure of 0.778 for subject 1055, and 0.785 for subject 0303. Figure 7 shows the image data for subject 1055 and the white-matter segmentations. Figure 8 shows the image data for subject 0303 and the white-matter segmentations."}, {"section_title": "Comparing Spatiotemporal Anatomical Changes", "text": "The models generated using our method can be used to compare 4-D anatomies, that may not be sampled at the same time points, through interpolation. squares and triangles) . Interpolation of these models at regularly sampled time points allow us to characterize differences in the two anatomies. At each time point s we interpolate the tissue probabilities and measure shape difference by computing the diffeomorphic mapping g(s) between the two tissue probability distributions.\nThis approach compares the trajectory of anatomical changes, which is more comprehensive than binning the data at specific time points and performing individual comparisons at each time point, similar to the shape regression approach developed by Durrleman et al. [6] . Figure 9 shows a conceptual view of how the models can be used to compare the trajectory of two anatomies. We show an example of comparing the 4-D anatomy of a subject with Alzheimer's disease (subject 1055) against a normal control subject (subject 0303) from ADNI in Figure 10 . The figure shows the log-determinant of the Jacobian mapping between the white matter probabilities of the two subjects at time points t = 85, 85.25, 85.5, 85.75, 86, 86.25 years. The mapping g between the anatomies from two different subjects (a subject diagnosed with Alzheimer's disease and a normal subject) is defined as the one minimizing:\nwhere Z(t) denotes the probabilities interpolated at time t, and \u03c3 g balances the distance term with the regularity term R. Overall, the discrepancy between the chosen subject with Alzheimer's disease and the chosen subject with normal aging increases over time. The integral of the absolute values of the log determinant of the Jacobian increases over time (Figure 10 top row "}, {"section_title": "Conclusions", "text": "This paper presents a novel mathematical formulation for estimating spatiotemporal anatomical changes that describes a data-driven method solving a joint 4-D segmentation, registration, and atlas construction. We Figure 10 . Comparison of the trajectories of Alzheimer's disease and normal aging, showing larger anatomical shape discrepancy at later stages. Top row: log determinant of the Jacobian of the mapping between interpolated anatomies of subjects with Alzheimer's disease and normal aging. Bottom row: same as top row, where we subtract the log determinant of the Jacobian at the first time point to highlight the temporal differences.\nintroduce an optimization scheme with guaranteed convergence, involving (projected) gradient descent. To the best of our knowledge, this is the first formulation for joint 4-D anatomical modeling and segmentation in a unified manner with a definition of optimality. Experimental results demonstrate that the proposed framework effectively integrates information in 4-D spatiotemporal data to generate spatiotemporal models that allow interpolation of anatomical structures over time. In addition to being unsupervised, and thereby fully reproducible, the approach combines information from all temporal sequences making it more robust to varying noise and corruption in data in individual time points. Anatomical mappings are defined on tissue probabilities instead of MR images, thereby enabling the framework to naturally deal with changes in imaging modalities over time and allowing it to handle different sets of modalities at different time points. Furthermore, the acquired image data do not undergo complex nonlinear deformations.\nOur current methodology is limited to single subject longitudinal analysis. Moreover, the clinical data used in our experiments capture only a limited time range of the entire disease progression. Hence, the exhibited temporal changes for one subject are subtle. As a result of these two limitations, the longitudinal models estimated by our method do not show drastic temporal variations. Nevertheless, for the chosen pair of Alzheimer's-disease and normal subjects we are able to quantify the divergence in their longitudinal shape changes. In the future, we will extend our methodology to population analysis which will allow us to reliably capture subtle longitudinal changes (intra-and interpopulation), and to do so over a larger time range.\nContemporary practices for longitudinal analysis often rely on independent segmentations at each time point, but with our approach we obtain a complete spatiotemporal model via joint segmentation, registration, and atlas estimation. In this way, the proposed model enables future research in longitudinal studies using trajectories of anatomical shape changes. These trajectories can be obtained using serial image data acquired within different time periods at different sampling rates (number of temporal scans). \nwhere |Dh| denotes the determinant of the Jacobian of the mapping h. This yields the following gradient equation for A: . (15) The gradient-descent update for A changes the atlas probability so that the class with the maximum class likelihood will be assigned more mass.\nFor the gradient of the criterion \u03a8 with respect to one of the diffeomorphic maps h tm,tm+1 in the temporal chain, we first gather the terms in Q related to h tm,tm+1 and rewrite the criterion as follows: \nThus, gradient descent optimization using the gradient of Q results in the update of the diffeomorphic warps in the directions \u2207P and \u2207A weighted by the temporal kernel K. This update results in diffeomorphic maps that are smooth over the entire temporal sequence rather than being smooth only between sequential time points t m and t m+1 (i.e. temporally global rather than local). Finally, by following [2] , we have the following gradient-descent direction for \u03a8 with respect to the initial momenta u tm,tm+1 (0) that constructs h tm,tm+1 : "}]