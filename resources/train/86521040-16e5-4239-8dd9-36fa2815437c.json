[{"section_title": "Abstract", "text": "Abstract The importance of medical imaging for clinical decision making has been steadily increasing over the last four decades. Recently, there has also been an emphasis on medical imaging for preclinical decision making, i.e., for use in pharamaceutical and medical device development. There is also a drive towards quantification of imaging findings by using quantitative imaging biomarkers, which can improve sensitivity, specificity, accuracy and reproducibility of imaged characteristics used for diagnostic and therapeutic decisions. An important component of the discovery, characterization, validation and application of quantitative imaging biomarkers is the extraction of information and meaning from images through image processing and subsequent analysis. However, many advanced image processing and analysis methods are not applied directly to questions of clinical interest, i.e., for diagnostic and therapeutic decision making, which is a consideration that should be closely linked to the development of such algorithms. This article is meant to address these concerns. First, quantitative imaging biomarkers are introduced by providing definitions and concepts. Then, potential applications of advanced image processing and analysis to areas of quantitative imaging biomarker research are described; specifically, research into osteoarthritis (OA), Alzheimer's disease (AD) and cancer is presented. Then, challenges in quantitative imaging biomarker research are discussed. Finally, a conceptual framework for integrating clinical and preclinical considerations into the development of quantitative imaging biomarkers and their computer-assisted methods of extraction is presented."}, {"section_title": "Introduction", "text": "The overwhelming success of medical science and industry in the 20th century in delivering innovative discoveries to patients has recently given way to a relative stagnation of advancement in the 21st century. This has occurred mainly as a result of challenges in the translation of benchside basic science discoveries to bedside diagnostics and therapeutics. In fact, since 1995, the US Food and Drug Administration (FDA) has observed a decrease in drug and biologic product submissions for regulatory approval [1] . For example, the number of new molecular entities that have been submitted to the FDA for approval has declined from 45 in 1996 to just 23 in 2010 [2] . This unexpected decrease in the number of innovative medical diagnostics and therapeutics reaching patients has been termed the pipeline problem. This problem is a result of the increasingly challenging, inefficient and costly path of medical product development. For example, the time required to bring a new drug to market can be up to 12 years at a cost of hundreds of millions of dollars. The FDA has identified the main cause of the difficulties in the path to medical device marketing approval to be the failure of the applied sciences which are necessary for medical product development in keeping pace with the advances in the basic sciences. In response, multiple government agencies including the FDA, the National Institutes of Health (NIH) and the National Cancer Institute (NCI), along with other public and private partners, have developed an array of initiatives and consortiums with the ostensible goal of tackling this pipeline problem (Table 1) [1, [3] [4] [5] [6] [7] [8] .\nA common theme among all these efforts is the importance of imaging for the future advancement of medicine.\nMedical imaging provides the ability to detect and localize many changes that are important to determine whether a disease is present or a therapy is effective, by depicting alterations in anatomic, physiologic, biochemical or molecular processes [9] . Quantitative imaging biomarkers are sensitive, specific, accurate and reproducible imaging measures of these changes which can be used in disease diagnosis, treatment planning and medical product development. The use of computerassisted image processing and analysis is extremely important for the discovery, characterization, validation and application of these quantitative imaging biomarkers. In particular, the application of advanced image processing and analysis procedures (e.g., semi-automated or automated segmentation and registration) provide for more robust and efficient incorporation of quantitative imaging biomarkers into clinical and preclinical decision making.\nThe objectives of this article are to: (1) introduce concepts of quantitative imaging biomarkers; (2) discuss important considerations in the validation of quantitative imaging biomarkers; (3) describe the use of advanced image processing and analysis for quantitative imaging biomarker discovery and characterization, with an emphasis on opportunities for their utilization in osteoarthritis (OA), Alzheimer's disease (AD) and cancer; (4) discuss current challenges in quantitative imaging biomarker research and (5) present a conceptual framework to use when utilizing image processing and analysis in the development of quantitative imaging biomarkers, which can help to meet some of the research challenges. Overall, this article is meant to promote a common understanding of quantitative imaging biomarkers between image processing and analysis researchers and clinicians or basic scientists and provide suggestions to help advance research in quantitative imaging biomarkers and address the challenges of medicine in the new century."}, {"section_title": "Review", "text": "Quantitative Imaging Biomarkers A biological marker, or biomarker, is a characteristic that is objectively measured and evaluated as an indicator of normal biological processes, pathogenic processes or a response to a therapeutic intervention [10] . Biomarkers can be used for diagnosis, prognosis, staging or prediction and monitoring of the clinical response of a disease to a therapeutic intervention. For the case of predicting or monitoring the clinical response to therapy, a biomarker must be associated with a clinical endpoint. A clinical endpoint is \"a characteristic or variable that reflects how a patient feels, functions, or survives\" [10] . Clinical endpoints generally fall under the clinical terms morbidity (an incidence of ill health such as stroke or recurrence of cancer) and mortality (death). Three difficulties with using a traditional clinical endpoint in clinical studies are that: (1) it may be difficult to standardize or quantify, (2) it may take a long time to manifest and (3) it may be very costly, particularly when a long-term endpoint, such as mortality, is used. In order to expedite the process of clinical analysis, the identification and application of socalled surrogate endpoints is highly desired. A surrogate endpoint is \"a biomarker that is intended to substitute for a clinical endpoint. A surrogate endpoint is expected to predict clinical benefit (or harm or lack of benefit or harm) based on epidemiologic, therapeutic, pathophysiologic, or other scientific evidence\" [10] . The utility of surrogate endpoints is a result of their ability to be measured earlier, more conveniently or more frequently than traditional clinical endpoints [11] . Although a surrogate endpoint is one type of biomarker, not all biomarkers are surrogate endpoints; in fact, the large majority of biomarkers are not surrogate endpoints. For example, the World Health Organization (WHO) and Response Evaluation Criteria in Solid Tumors (RECIST) criteria are the only quantitative imaging [12] . Extending the definition of a biomarker from above, a quantitative imaging biomarker can be defined as an imaged characteristic that is objectively measured and evaluated as an indicator of normal biological processes, pathogenic processes or a response to a therapeutic intervention. Therefore, modalities such as magnetic resonance imaging (MRI), computed tomography (CT), Xray, ultrasound, positron emission tomography (PET), single photon emission computed tomography (SPECT), optical imaging and light microscopy, among others, can be employed for identification of quantitative imaging biomarkers. Imaging biomarkers can also be semiquantitative, e.g., using a scoring scale based on expert-selected atlases representative of disease severity such as the use of Kellgren-Lawrence (KL) grade for OA [13] .\nThe push towards analysis of medical images for identifying quantitative imaging biomarkers of disease has led to the formation of several projects which mean to develop and disseminate image collections for use in research towards the discovery of quantitative imaging biomarkers. Descriptions of some of these projects are presented in Table 2 ."}, {"section_title": "Validation of Quantitative Imaging Biomarkers", "text": "Quantitative imaging biomarkers are validated by demonstrating an association between the measured biomarker value and a physiologic, pathophysiologic or therapeutic response. These responses can be manifested by anatomic, physiologic, biochemical or molecular changes. Associations between these changes and disease state can be analyzed using statistical models or classifiers.\nThere are two criteria that need to be met in order to validate a quantitative imaging biomarker [9] :\n1) The presence of the quantitative imaging biomarker is closely coupled or linked to the presence of the target disease or condition.\n2) The detection and quantitative measurement of the quantitative imaging biomarker are accurate, reproducible and feasible over time.\nThe most stringent validation is required when a quantitative imaging biomarker is being assessed for use as a surrogate endpoint. Weir and Walley have stated the challenge in validating a biomarker as a surrogate endpoint in the following way: \"It is insufficient in the validation of a biomarker as a surrogate endpoint to show that it correlates well with the clinical endpoint \u2026 What is required is that effect of treatment on the biomarker correlates well with treatment effect on the final endpoint, so that a valid surrogate endpoint allows correct inference to be drawn regarding the effect of an intervention on the true clinical endpoint of interest\" [14] . This is effectively an additional criterion for the validation of a quantitative imaging biomarker for use as a surrogate endpoint.\nA well-known example of the peril of adoption of an insufficiently validated biomarker for use as a surrogate endpoint occurred in the Cardiac Arrhythmia Suppression Trial [15] . The hypothesis of the trial was that the sup< \"\u2026To define the rate of progress of mild cognitive impairment and Alzheimer's disease, to develop improved methods for clinical trials in this area, and to provide a large database which will improve design of treatment trials\"\nhttp://www.adni-info.org/ Osteoarthritis Initiative (OAI) \"\u2026 To develop a public domain research resource to facilitate the scientific evaluation of biomarkers for osteoarthritis as potential surrogate endpoints for disease onset and progression\" http://oai.epi-ucsf.org/datarelease/ pression of ventricular arrhythmia after myocardial infarction (MI) would reduce the incidence of sudden death. Participating patients were randomly assigned into two groups-those who received an antiarrhythmia drug and those who received a placebo. The suppression of cardiac arrhythmias on an electrocardiogram (ECG) was taken to be a surrogate for the clinical endpoint of reduced mortality after MI. However, it was found that patients who took antiarrhythmia drugs had an increased risk of mortality compared to patients who received placebo. Therefore, the belief that arrhythmias on ECG could serve as a surrogate endpoint for post-MI mortality proved to be false."}, {"section_title": "Improving Quantitative Imaging Biomarkers through the Application of Advanced Image Processing and Analysis", "text": "The National Institutes of Standards and Technology (NIST) has identified three primary sources of uncertainty in the use of quantitative imaging biomarkers: (1) the biological variability, (2) the variability associated with clinicians interpreting the images and (3) the physical measurement variability associated with image data collection and analysis across the same or different imaging platforms [16] . Work towards a solution to the biological variability requires the identification of confounding variables within the patient population which may be accounted for before, during or after acquisition and is not particularly amenable to solutions through the application of advanced image processing and analysis. The variability due to clinicians interpreting the images and those associated with image data collection and analysis across the same or different imaging platforms, however, may be decreased by the application of advanced image processing and analysis. In many cases, image processing and analysis is used to increase accuracy, reproducibility or efficiency of manual analysis. In these cases, an automated processing method may be used to, say, segment a structure of interest. The result of automated segmentation must be compared to those of manual readers as one step in the validation of the process to the application of quantitative imaging biomarker calculation. There are many methods of comparing segmentations, for example, the Dice similarity coefficient (DSC), relative overlap or mean distance [17] . The choice of similarity measure has important implications for the evaluation of calculations derived from a segmentation or analysis as potential quantitative imaging biomarkers. For example, DSC may be used to validate an automated or semiautomated method of segmentation with respect to a manual reader, but if the quantitative imaging biomarker values which are to be calculated from the segmentation are dependent on the surface area of the volume or contour, the use of an overlap-dependent similarity metric such as DSC may not give an accurate measurement and the resultant quantitative imaging biomarker calculations will be inappropriate."}, {"section_title": "Applications of Advanced Image Processing and Analysis Towards Quantitative Imaging Biomarker Research", "text": "Image processing is fundamentally concerned with the extraction of information from an image. The resultant information is then used to derive meaning from the image, a task known as image analysis. The image processing and analysis tasks of enhancement, registration, segmentation and classification play important roles in the consistent and accurate evaluation of quantitative imaging biomarkers.\nThe possible applications of quantitative imaging biomarkers are broad, but the FDA has defined several diseases in which research into quantitative imaging biomarkers may offer the most benefit in the near future [4, 18, 19] . Three of those diseases are presented in this section: OA, AD and cancer.\nIn the following subsections, overviews of the use of advanced image processing and analysis for the discovery and characterization of quantitative imaging biomarkers for particular diseases are discussed. Though not intended to be comprehensive, in each subsection, a brief description of the disease, the use of imaging and the anatomical focus of most analyses are provided. In OA, the focus is cartilage morphology; in AD, the focus is hippocampus/medial temporal lobe morphology; and in cancer, the focus is solid tumor morphology and vascularity. Due to the breadth of image processing and analysis methods, in these examples, the methods discussed are focused on the task of segmentation. In addition, due to the substantial amount of different imaging modalities, the modality focused on in the following subsections is MRI. Table 3 provides an analysis of advanced image processing and analysis methods which incorporated quantitative imaging biomarkers for OA and AD.\nThe literature search for the review of each topic was undertaken through a PubMed search using the keywords \"quantitative imaging biomarkers,\" \"imaging biomarkers\" and \"computer-assisted diagnosis.\" Articles that were included in the review were in two major categories: (1) reviews of imaging biomarkers, especially in the areas of AD, OA and cancer and (2) use of advanced image processing and analysis techniques (e.g., automated segmentation) for the discovery, characterization, validation and application of quantitative imaging biomarkers."}, {"section_title": "Osteoarthritis (OA)", "text": "OA is a disease that causes degeneration of the cartilage in the joints [20] . It is the most common form of arthritis, affecting approximately 21 million American adults [21] . Clinical onset and progression is generally specified using semiquantitative grading schemes of OA severity based on radiographs; these grading schemes are also accepted for regulatory approval of drugs meant to treat OA [13, 22, 23] . The challenge with using radiographs for assessing the entire joint is the poor soft-tissue contrast. Radiographic measurements used for OA grading, such as joint space width, do not provide adequate information about the state of all joint components (e.g., cartilage, bone, muscle, meniscus, etc.). Therefore, newer imaging modalities, such as MRI, are being used more frequently for research into OA. The improvement in MRI technology, including the increased clinical use of high strength magnets, has allowed for the development of image acquisition protocols which can highlight particular joint components [22, 24] . Other factors that have moved research forward in arthritis have been the development of a standard nomenclature for defining joint compartments in the knee, in order to promote consistent research into morphological measurements of cartilage [25] , and methods of improving the reproducibility of cartilage thickness measurements [26] . In the case of cartilage, these developments have led to several validated morphological measures-such as volume and thicknesswhich can be used to assess OA onset and progression ( Fig. 1 ) [27] . In addition, research initiatives, such as the Osteoarthritis Initiative (OAI), have developed a set of standardized protocols which have been used on a large patient population, which allows for the consistent postacquisition analysis of images of patients with OA [28] . Currently, the majority of imaging research into OA is focused on the cartilage, but increasingly, there is more interest in a whole-joint approach to the understanding of OA.\nThere have been several attempts at the automated segmentation of the articular cartilage. Many of these techniques had limitations that prevented analysis of underlying pathology and, therefore, did not extend to an analysis of potential quantitative imaging biomarkers of OA [29] [30] [31] . In contrast, some studies have incorporated an assessment of differences between normal and pathologic (i.e., OA) knees, and these studies can be taken as working towards developing quantitative imaging biomarkers for OA onset and progression [32, 33] . Table 3 presents descriptions of these methods."}, {"section_title": "Alzheimer's Disease (AD)", "text": "AD is a type of cortical, neurodegenerative dementia [34] . It accounts for approximately 70% of all cases of dementia in the elderly, is estimated to occur in up to 30% of adults older than 85 years of age and currently affects nearly 5 million people in the US [34] . Established primary clinical trial endpoints used for AD research are based on symptoms such as functional or cognitive impairment. However, there have been some imaging measures based on structural MRI which have been used as secondary clinical trial endpoints, but none of these imaging biomarkers has been sufficiently validated for use as a surrogate endpoint. Currently, it is thought that the use of neuroimaging in screening at-risk populations (e.g., those over 60 years old) for risk of Fig. 1 Validated methods for quantifying cartilage volume, joint morphology and cartilage thickness from threedimensional datasets have been reported [27] cognitive decline may be feasible over a time frame of 3-4 years [35] . One goal of the Alzheimer's Disease Neuroimaging Initiative (ADNI) is to characterize morphological changes in the brain of patients with AD [36] . The protocol developed by the ADNI for MR imaging was specifically developed to work with major image analysis methods used in neuroimaging [37] .\nMR-based morphological measures have been shown to be sensitive in the detection of AD early in the disease course and for the tracking of disease progression. In fact, structural MRI has been shown to be accurate for the detection of disease prior to the onset of symptoms [37] . The medial temporal lobe, specifically the hippocampus, is an area of the brain responsible for episodic memory function in which early AD neurofibrillary pathology is manifested through atrophy (i.e., neuron and tissue lost) [38] . The most common MRI-derived morphological measure in the analysis of AD is hippocampus volume [36] . Recently, however, calculations based on the morphological and intensity characteristics of brain regions in patients with AD have received an increased amount of attention (Fig. 2) [39] [40] [41] [42] [43] [44] [45] . Table 3 describes these methods in detail."}, {"section_title": "Cancer", "text": "The types of cancer amenable to structural or functional image processing and analysis are generally solid tumors; however, there are many different types of solid malignant neoplasms. Although beyond the scope of this article, there are some general similarities in the processing and analysis of images of different types of solid tumors. The FDA has stated that the most valuable role for quantitative imaging biomarkers in cancers is in the use as a clinical diagnostic, rather than as a surrogate endpoint [36] . O'Connor et al. provide a thorough review of the state of biomarkers in the development of cancer therapeutics [12] .\nIn general, morphological measurements, such as length, area and volume, are the most recognized and accepted quantitative imaging biomarkers used in cancer studies. For instance, uni-or bidimensional linear measurements, such as RECIST or WHO criteria, are the standard for assessing tumor burden and response to therapeutic intervention in certain studies [46, 47] . However, there have been attempts to employ advanced morphometry, such as contour analysis, in the detection of malignant lung nodules [47, 48] . In fact, the use of computer-assisted diagnosis/detection (CAD) for lung nodules has been one of the most active areas of quantitative imaging biomarker research; however, in the case of CAD, the older term \"image feature,\" in many cases, may be used as a synonym for quantitative imaging biomarker (although not necessarily always synonymous) [49] . Currently, however, RECIST measurements are the only validated surrogate endpoint in lung cancer [47] .\nThere are a significant number of structural imaging studies analyzing the use of advanced image analysis measurements for the classification of tumors as benign or malignant, for example, the detection of microcalcifications in breast mammograms [50] [51] [52] or the quantification of tumor vascularity in a physiologically meaningful way using DCE-MRI through the use of kinetic modeling [53] [54] [55] [56] and multiscale modeling [57] . However, there are new quantitative imaging biomarkers such as the disappearance of intratumoral arterial enhancement, which are being assessed for tracking treatment response [58, 59] . In the future, molecular imaging methods also promise to be an important tool in the analysis of cancer [48] ."}, {"section_title": "Discussion", "text": "The path of quantitative imaging biomarker discovery, characterization, validation and, ultimately, application is challenging. However, whereas the criteria required for the validation of a quantitative imaging biomarker (\"Validation of Quantitative Imaging Biomarkers\") are stringent, they are not intractable. An important component in the development of any method for extracting and measuring a quantitative imaging biomarker is the early and consistent incorporation of preclinical or clinical information. The developed methods are then required to be consistent and accurate in the calculation Fig. 2 Two templates and their difference image from analysis of a 30-patient subset of the OASIS dementia dataset demonstrating differences between patients with dementia and healthy controls [43] of the quantitative imaging biomarkers that are employed for subsequent preclinical or clinical decision making. The fulfilment of these requirements can be greatly assisted through the use of advanced image processing and analysis techniques, which can reduce the variability associated with different researchers or clinicians interpreting the images and the physical measurement variability associated with image data collection and analysis across the same or different imaging platforms. In this way, advanced image processing and analysis techniques can be leveraged to assist in the resolution of the pipeline problem described by the FDA.\nThere are several challenges in the incorporation of advanced image processing and analysis into quantitative imaging biomarker research. In Table 3 , examples of quantitative imaging biomarkers are presented. The final column of the table lists weaknesses with the validation of the methods in the extraction and calculation of the quantitative imaging biomarkers. In addition to the weaknesses presented, there are general weaknesses within advanced image processing and analysis research when applied to medical images. Following is a list of weaknesses and considerations which can help to address them. However, it is often known which sequence can best delineate (visually, at least) the boundary between a region of interest and \"everything else.\" By incorporating segmentation and registration together, the performance of both the algorithm for extraction of a structure and the calculation of a quantitative imaging biomarker can be improved. For example, incorporation of \"segmentation\" imaging protocols (e.g., anatomical sequences) which are quick but accurate with structural delineation may be necessary for consistent and robust application of advanced image processing and analysis techniques. Then, registration of a different set of images which were acquired using a more appropriate protocol for the structure being analyzed can be performed, with the segmentations from the anatomical protocol registered using the calculated transformation. This is, of course, the thought behind the development of registration algorithms, such as maximization of mutual information, and acquisition methods, such as PET/CT. However, there is still room for advancement in the application of these methods to quantitative imaging biomarker research.\nWith these challenges in mind, it is important to consider a general structure for the incorporation of advanced image processing and analysis methods into the development of quantitative imaging biomarkers for use in clinical and preclinical decision making. The stages of development for quantitative imaging biomarkers are well represented by the five-phase model for cancer screening biomarkers presented in Ref. [60] . In Table 4 , the application of that model to quantitative imaging biomarker development is presented. An important thought from this conceptual model is that when considering the application of quantitative imaging biomarkers to questions of preclinical or clinical interest, it may be useful to think of the development of a quantitative imaging assay using advanced image processing and analysis."}, {"section_title": "Summary", "text": "The advancement of medical imaging technology, including an increase in the use of functional and molecular imaging, provides a wealth of new information to be used in preclinical and clinical decision making. Quantitative imaging biomarkers extracted from the available imaging modalities have become increasingly important in medical product development, disease diagnosis and treatment planning. The forecast is that the role of quantitative imaging biomarkers will only continue to increase. Methods of advanced image processing and analysis can provide powerful tools for the discovery and characterization of quantitative imaging biomarkers. Future advancements in medical science and industry are likely to benefit significantly from the increased availability of quantitative imaging biomarkers as well as theoretical and software tools for the processing and analysis of the images from which the biomarkers are being extracted."}]