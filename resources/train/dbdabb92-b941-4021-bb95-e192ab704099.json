[{"section_title": "Abstract", "text": "Machine learning\nWe propose a new method to maximize biomarker efficiency for detecting anatomical change over time in serial 33 MRI. Drug trials using neuroimaging become prohibitively costly if vast numbers of subjects must be assessed, so 34 it is vital to develop efficient measures of brain change. A popular measure of efficiency is the minimal sample 35 size (n80) needed to detect 25% change in a biomarker, with 95% confidence and 80% power. For multivariate 36 measures of brain change, we can directly optimize n80 based on a Linear Discriminant Analysis (LDA). Here 37 we use a supervised learning framework to optimize n80, offering two alternative solutions. With a new medial 38 surface modeling method, we track 3D dynamic changes in the lateral ventricles in 2065 ADNI scans. We apply 39 our LDA-based weighting to the results. Our best average n80-in two-fold nested cross-validation-is 104 MCI 40 subjects (95% CI: [94,139]) for a 1-year drug trial, and 75 AD subjects [64,102]. This compares favorably with 41 other MRI analysis methods. The standard \"statistical ROI\" approach applied to the same ventricular surfaces 42 requires165 MCI or 94 AD subjects. At 2 years, the best LDA measure needs only 67 MCI and 52 AD subjects, 43 versus 119 MCI and 80 AD subjects for the stat-ROI method. Our surface-based measures are unbiased: they 44 give no artifactual additive atrophy over three time points. Neuroimaging Initiative (ADNI) database (adni.loni.ucla.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at:"}, {"section_title": "", "text": "U N C O R R E C T E D P R O O F"}, {"section_title": "31", "text": "Machine learning 32 We propose a new method to maximize biomarker efficiency for detecting anatomical change over time in serial 33 MRI. Drug trials using neuroimaging become prohibitively costly if vast numbers of subjects must be assessed, so 34 it is vital to develop efficient measures of brain change. A popular measure of efficiency is the minimal sample 35 size (n80) needed to detect 25% change in a biomarker, with 95% confidence and 80% power. For multivariate 36 measures of brain change, we can directly optimize n80 based on a Linear Discriminant Analysis (LDA). Here 37 we use a supervised learning framework to optimize n80, offering two alternative solutions. With a new medial 38 surface modeling method, we track 3D dynamic changes in the lateral ventricles in 2065 ADNI scans. We apply 39 our LDA-based weighting to the results. Our best average n80-in two-fold nested cross-validation-is 104 MCI 40 subjects (95% CI: [94, 139] ) for a 1-year drug trial, and 75 AD subjects [64, 102] . This compares favorably with 41 other MRI analysis methods. The standard \"statistical ROI\" approach applied to the same ventricular surfaces"}, {"section_title": "Introduction", "text": ""}, {"section_title": "52", "text": "Biomarkers of Alzheimer's disease based on brain imaging must 53 offer relatively high power to detect longitudinal changes in subjects 54 scanned repeatedly over time (Cummings, 2010; Ross et al., 2012 (Fox et al., 2011; 78 Holland et al., 2011; Hua et al., 2011) , and while avoiding removing"}, {"section_title": "79", "text": "scans from the analysis that may lead to unfairly optimistic sample 80 size estimates (Hua et al., 2012 ; Wyman et al., accepted for publication)."}, {"section_title": "81", "text": "Promising MRI-based measures include the brain boundary shift integral 82 (Leung et al., 2012; Schott et al., 2010) (Fischl and Dale, 2000; Reuter et al., 2012;  87 Smith et al., 2002) ."}, {"section_title": "88", "text": "Although several approaches are possible, one type of power analysis,"}, {"section_title": "89", "text": "advocated by the ADNI Biostatistics Core (Beckett, 2000) , is to estimate 90 the minimal sample size required to detect, with 80% power, a 25% reduc- "}, {"section_title": "97 98", "text": "Here z \u03b1 is the value of the standard normal distribution for which P"}, {"section_title": "99", "text": "[Z b z \u03b1 ]=\u03b1. The sample size required to achieve 80% power is common- weights (Duda et al., 2001) . While many studies have used machine 132 learning to predict the progression of neurodegenerative diseases and 133 differentiate diagnostic groups such as AD, MCI, and controls (Kloppel 134 et al., 2012; Kohannim et al., 2010; Vemuri et al., 2008) , we found no 135 attempts in the literature that used learning to directly optimize power"}, {"section_title": "136", "text": "to detect brain change. The closest work is perhaps that of Hobbs et al. 137 (2010) . In this paper, SVM was used to separate subjects with"}, {"section_title": "138", "text": "Huntington's disease from controls, and the resulting score used to calcu- analysis (PCA)."}, {"section_title": "149", "text": "A common criticism of the power analysis provided by Eq. (1) is 150 that it does not take into consideration normal ageing in non-high 151 risk healthy subjects \nThe All subjects were scanned with a standardized MRI protocol devel-232 oped for ADNI due to gradient non-linearity (Jovicich et al., 2006) , i.e. \"gradwarp\""}, {"section_title": "254", "text": "(2) \"B1-correction\" for adjustment of image intensity inhomogeneity 255 due to B1 non-uniformity , (3) \"N3\" bias field correc-256 tion for reducing residual intensity inhomogeneity (Sled et al., 1998), 257 and (4) phantom-based geometrical scaling to remove scanner and 258 session specific calibration errors (Gunter et al., 2006) ."}, {"section_title": "259", "text": "The ADNI-1 dataset"}, {"section_title": "260", "text": "For our experiments, we analyzed data from 683 ADNI subjects 261 with baseline and 1 year scans, and 542 subjects with baseline, "}, {"section_title": "279", "text": "Surface extraction"}, {"section_title": "280", "text": "Our surfaces were extracted from 9-parameter affine-registered, fully 281 processed T1-weighted anatomical scans. We used a modified version of"}, {"section_title": "282", "text": "Chou's registration-based segmentation (Chou et al., 2008) , using 283 inverse-consistent fluid registration with a mutual information fidelity 284 term (Leow et al., 2007) . To avoid issues of bias and non-transitivity,"}, {"section_title": "285", "text": "we segmented each of our subjects' two or three scans separately. "}, {"section_title": "293", "text": "Medial curve-based surface registration"}, {"section_title": "294", "text": "In this study, we focus on mapping changes in the lateral ventricles, a 295 fluid-filled space that expands as brain atrophy progresses (Fig. 1) "}, {"section_title": "Mathematical preliminaries", "text": ""}, {"section_title": "313", "text": "Anatomical surfaces in the brain, such as the ventricles, hippocam-314 pus, or caudate, have often been analyzed using surface meshes and 315 features derived from them, such as a medial curve, or \"skeleton\", 316 that threads down the center of a 3D structure (Thompson et al., 317 2004). These reference curves are often used to compute the \"thick-318 ness\" of the structure, by assessing the distance from each boundary 319 point to a central line or curve that runs through a structure."}, {"section_title": "320", "text": "The problem of finding the \"medial curve\" or \"skeleton\" of an 321 orientable surface is not well-defined, but a few properties are gener-322 ally accepted as desirable (Cornea et al., 2005) . Here we focus on 323 those properties that are particularly pertinent for registering and 324 comparing surfaces across multiple subjects:"}, {"section_title": "325", "text": "(1) Centered: we would like our curve to be \"locally\" in the middle 326 of the shape. This is important for accurately estimating local 327 thickness on boundaries of shapes."}, {"section_title": "328", "text": "(2) Onto, smooth mapping: There must exist a subjective, smooth 329 mapping from the surface to the curve. This is essential in 330 order to use the medial curve for registration. is smooth and every point on it is \"locally in the middle\" of the shape. \n344 345 where c 0 \u00f0 \u00de; c 1 \u00f0 \u00de\u2208M: Here, w c; c 0 ; p; M \u00c0 \u00c1 is the weight defining the 346 \"localness\" of point p relative to c. Our weight function is defined as in 347 Gutman et al. (2012) . Adding a smoothness term penalizing curvature 348 \u03ba c , we have our final cost function: (GOF) G and medial thickness D:"}, {"section_title": "359 360", "text": "An example of a medial curve and the corresponding GOF is shown 361 in Fig. 2 (A) and the weighting function is illustrated in Fig. 2 "}, {"section_title": "368 369", "text": "We first perform longitudinal registration following (Gutman et 370 al., 2012) \n380 381 where * can correspond to D or \u015a\u25b5D. The 1D registration minimizes 382 C(r, r') ="}, {"section_title": "384 385", "text": "Here the functions f * are the feature functions of each subject's 386 surface, and g * are the corresponding features of the target shape. The "}, {"section_title": "413 414", "text": "Here C \u00bc 32 z 1\u2212 \u03b1 = 2 \u00fe z power \u00c0 \u00c1 2 , x i is the thickness change for the i th 415 subject, m is the mean vector, the covariance matrix\nMinimizing Eq. (9) is equivalent to 417 maximizing\n418 419 which is a special case of the LDA cost function, with a maximum given by"}, {"section_title": "421 422", "text": "For our purposes, m represents the mean of the diseased group."}, {"section_title": "423", "text": "We denote this by m = to a direct computation: "}, {"section_title": "454 455", "text": "Here a is the smoothing weight, and L is the Tikhonov matrix. We use \nwhere m NC is the mean expansion among controls."}, {"section_title": "466", "text": "The order of subjects in each diagnostic group is randomly changed to these folds is then used to optimize the relevant parameter, i.e., the num-"}, {"section_title": "476", "text": "ber of principal components k, the smoothing weight a, or the parametric fold, and the model is tested on the other fold. We note that for the PCA gle parameter already embedded in the model, we also need to find an 502 optimal threshold. For computational speed, we choose to threshold the Fig. 3 . P-maps show the group differences in annual atrophy rates between healthy controls and (left) AD, and (right) MCI subjects. The progressive expansion from normal aging to MCI/AD is in line with prior reports. Loss of significance near the ends of the medial curve are likely due to the nature of the measurement rather than true anatomical change. shows a more disease-specific atrophy pattern. Significantly more weight is given to the inferior horns bordering the hippocampus, and more weighting is also given to the middle of the occipital horns, characteristic of white matter degeneration. Unlike (A)-(C), this map is directly comparable with Fig. 3 . The pattern is again different compared to a mass-univariate weighting. the first three methods are summarized in Table 3a ."}, {"section_title": "583", "text": "The sample sizes based on t-statistic weighting were very similar 584 to stat-ROI results, with no significant difference, though stat-ROI 585 n80s were generally slightly lower. These weights are visualized 586 in Fig. 4C . The LDA-ROI sample sizes were greater than the Table 3b ."}, {"section_title": "597", "text": "Finally, the control-augmented sample sizes resulting from the "}, {"section_title": "608", "text": "All methods had good agreement between the two folds' models."}, {"section_title": "609", "text": "The sample sizes in each fold were similar, and the weight patterns with previous studies. Sample size estimates for clinical trials, using ventricular change over 12 months as an outcome measure. Depending on how we weight the features on the ventricular surfaces, the t2:3 sample size estimates can be reduced, and the power of the study increased. The two LDA-based methods (top two rows) show lower sample size estimates (i.e., greater effect sizes) t2:4 than the standard \"statistical ROI\" approach, which uses a binary mask to select a region of interest. The \"t-stat\" row shows results when weighting the vertex expansion rates with t2:5 the t-statistic. \"PCA sign.\" and \"PCA uns.\" show results when thresholding PCA-LDA based weight maps, with \"sign.\" meaning that negatively weighted areas were considered and t2:6 assigned a weight of \u22121 when below the threshold. \"Uns.\" means \"unsigned,\" i.e. only positively weighed vertices were considered, and weighed with 1 if exceeding the threshold. t2:7"}, {"section_title": "Q4", "text": "All surface-based approaches (top six rows) outperform measures of change based on ventricular volume. The \"mean\" columns display n80s and CIs of the two folds' estimates t2:8 averaged. Sample size estimates for clinical trials, using ventricular change over 24 months as an outcome measure. Depending on how the features on the ventricular surfaces are weighted, t5:3 the sample size estimates can be reduced, and the power of the study increased. The two LDA-based methods (top two rows) show lower sample size estimates than the stat-ROI t5:4 approach. Control subjects' average atrophy now approaches that of MCI subjects in magnitude. Sample size estimates for clinical trials, using ventricular change over 24 months as an outcome measure, modified by change in controls. The NC-modified analogues to Table 4a  t6:3 show a marked increase in required sample size. The 2-class model greatly outperforms all other ventricular measures, with ventricular volume performing on par with the best t6:4 1-class surface measures: unsigned LDA-ROI and Stat-ROI. classifier to further improve diagnostic AD and MCI classification."}, {"section_title": "788", "text": "It is important to stress that while many studies have used machine 789 learning to derive a single measure of \"AD-like\" morphometry for 790 discriminating AD and MCI subjects from the healthy group, no study 791 we are aware of has used machine learning to maximize the power of 792 absolute atrophy rates in AD. We have attempted this by using a straight-"}, {"section_title": "793", "text": "forward application of LDA, using either PCA or Tikhonov regularization."}, {"section_title": "794", "text": "The Tikhonov approach was intended to improve generalization relative 795 to PCA, but surprisingly, there were essentially no major differences in and non-negativity constraints are perhaps not appropriate for Fig. 8 . Regression plots for surface-based ventricular expansion measures in controls. 95% confidence belts for the regression models are shown with dotted green lines. All surface models are longitudinally unbiased, since the zero intercept is contained in the 95% confidence interval on the intercept, for each of the methods. The 2-class model is trending on additive bias; however, in this model the mean of controls is subtracted for power estimates. P-values estimating the chance that the true 24 month n80 of the first method is equal t7:3 to or greater than that of the second method. Null distributions were created by t7:4 bootstrapping 100,000 samples with replacement. Note that depending on how rigort7:5 ous one is about hypothesis testing, the true p-values may need a Bonferroni correction t7:6 by a factor of 3, if one accepts a separate correction for each subset of the data, or 9. The t7:7 improvement of the Tikhonov-LDA method over the stat-ROI approach reaches signift7:8 icance, when uncorrected, for AD subjects. At 24 months, the improvement in power t7:9 when using Tikhonov-regularized LDA model over the PCA model approaches trend t7:10 levels for MCI subjects. focused only on the ventricles, non-negativity would probably be 826 appropriate here, though it would lead to slower convergence."}, {"section_title": "Q9", "text": "P U N C O R R E C T E D P R O O"}, {"section_title": "827", "text": "The second paper (Hobbs et al., 2010) , which we mention in the in- Brun et al., 2009 ). This may partially explain the slight additive"}, {"section_title": "925", "text": "\"bias\" that is detectable in AD and MCI subjects (though not in controls)."}, {"section_title": "926", "text": "In disease, the power law describing changes as a function of time may"}, {"section_title": "927", "text": "be different compared to controls due to disease effects. As a result, only 928 control subjects should be used when using the linear fit CI test, but Table 7a t9:1 t9:2 Ventricular surface summary atrophy measures for continuous weightings. Averages and standard deviations for atrophy rates are in millimeters of radial expansion. The vertex weights are normalized by their 1-norm, which corresponds to t9:3 averaging over the ROI for the stat-ROI method, assuming equal area elements for all vertices. "}, {"section_title": "996", "text": "the control subjects, alleviates the latter issue."}, {"section_title": "997", "text": "We deliberately chose to use only 12-month data in training our 998 optimized atrophy models. This choice was motivated by practical"}, {"section_title": "999", "text": "It is also important to validate the LDA-weighted measures as well as Table 7a , because negative weights are allowed in signed LDA-ROI, the nort10:3 malized average expansion is closer to the 2-class LDA result, while the unsigned version is closer to stat-ROI and t-statistic weighting. "}, {"section_title": "Q2", "text": ""}]