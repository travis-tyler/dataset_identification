[{"section_title": "Abstract", "text": "ABSTRACT-Secondary data analysis of large longitudinal and national data sets is a standard method used in many social sciences to answer complex questions regarding behavior. In this article, we detail the advantages of using these data sets to study developmental questions across the life span. First, we provide an overview of how using secondary data can increase studies' scientific integrity. Then, we detail where and how data sets can be obtained that answer specific questions. Finally, we discuss methodological issues related to using longitudinal, population data sets. These data sets can enhance science and test theories by increasing the rigor and generalizability of research to the general population, making secondary data analysis an important method to consider."}, {"section_title": "University of Texas at Austin", "text": "ABSTRACT-Secondary data analysis of large longitudinal and national data sets is a standard method used in many social sciences to answer complex questions regarding behavior. In this article, we detail the advantages of using these data sets to study developmental questions across the life span. First, we provide an overview of how using secondary data can increase studies' scientific integrity. Then, we detail where and how data sets can be obtained that answer specific questions. Finally, we discuss methodological issues related to using longitudinal, population data sets. These data sets can enhance science and test theories by increasing the rigor and generalizability of research to the general population, making secondary data analysis an important method to consider."}, {"section_title": "KEYWORDS-secondary data; quantitative methods; population studies", "text": "In social science disciplines such as sociology and economics, secondary data analysis is often used to answer complex questions of human behavior. Within developmental psychology, this method is used less often because researchers prefer primary data sets. Primary data are collected by an individual or a team of researchers and are often based on the theory or models of the researcher or research team (1) . These data are also generally proprietary and not shared with the larger research community. In contrast, secondary data analysis uses data collected by other researchers or organizations, and the users are generally not part of the design of the study. These data sets (e.g., most national studies) have been collected for the use of the research community or have been made available for other researchers to use (e.g., in data archives). Secondary sources of data are uniquely equipped to test some of the key theories and models in our science, and expanding their use within developmental science will augment the rigor of our field. In this article, we detail the advantages of secondary data analysis for developmental science, discuss how to obtain and use secondary data, and suggest analytical steps and potential hurdles in using secondary data to answer developmental questions."}, {"section_title": "WHAT ARE THE ADVANTAGES OF USING SECONDARY DATA?", "text": "Developmental scientists now have some good longitudinal studies that examine children's and adolescents' development across time. These data sets were collected based on the research theories and models of the primary researchers and include extensive measurements on the areas of interest to the research team (e.g., IQ, achievement, problem behavior, motivation, aggression, mental health). These studies are rich sources of developmental data; even though they may focus on a topic of interest to the primary researcher (e.g., problem behavior, achievement), they often feature complementary measures of other topics that covary with these outcomes. For example, studies that feature data sets designed to answer questions about problem behavior also collected data on achievement and IQ as potential predictors of these behaviors. Thus, within developmental science, a rich and diverse set of large longitudinal data sets is available to the broader community of scientists to test questions that differ from those tested by the original researcher (see Davis-Kean et al. (2) , for an example of using many secondary data sets to answer questions). As we will discuss, many of these data sets are available in data repositories and available for analysis by other researchers. Although some data sets remain proprietary to the original researcher or research team, new regulations on data sharing from the National Institutes of Health and the National Science Foundation are increasing the amount of data available for secondary data analysis. Developmental scientists will find that many secondary data sets contain measures (sometimes the exact measures) used in primary data collection by developmental psychologists to study outcomes such as achievement (e.g., Woodcock Johnson Achievement Test) and behavior problems (e.g., Child Behavior Checklist, Social Skills Rating System) as well as other outcomes. This similarity in measurement allows many data sets to be combined using techniques such as integrative data analysis (IDA; 3, 4, 5), a technique that is especially useful for data sets that represent highly selective groups (e.g., children of alcoholics) that would be difficult to find in a general population sample. Combining the data sets increases the sample size and thus the power to examine these groups (3) . IDA has a range of potential applications, including comparing similar processes across different study samples or age groups (6), or testing whether findings in a smaller, primary data set can be replicated in a larger, secondary data set.\nUsing secondary data sets, especially those collected at the population level, increases statistical power and external validity as a result of a larger sample size and greater diversity of respondents (with regard to race, ethnicity, and socioeconomic status). This advantage, combined with reducing the time and money it takes to collect one's own longitudinal data, makes secondary data analysis a good option for developmental scientists. Furthermore, these data resources are easy to obtain."}, {"section_title": "HOW CAN SCIENTISTS FIND AND USE SECONDARY DATA SETS?", "text": "In this section, we explain where to access secondary data sets and how to navigate data archives, and we describe some first steps for working with secondary data.\nWhere to Access Secondary Data Several major archives contain available data; see Table 1 for a list of major archives, data sets contained in each archive that are relevant to developmental psychology, and the web link for that archive. In the United States, the two largest social science data archives are the Interuniversity Consortium for Political and Social Research (ICPSR) and the Murray Research Archive. Also relevant to developmental psychologists is the educational data archived by the U.S. Department of Education, which includes the Early Childhood Longitudinal Study (birth and kindergarten cohorts) and many other educational data sets collected across the United States. Additional population data sets study children (e.g., the Panel Study of Income Dynamics-Child To access data, researchers usually have to create an account with the data archive. ICPSR requires affiliation with a member institution. Some data sets are available for immediate download while others require an application explaining the scientific purpose for data use. Data are generally free, though fees may apply for digitization of not-yet digital materials or other labor-intensive data-preparation tasks."}, {"section_title": "Navigating Data Archives", "text": "The organization of each data archive varies slightly, but most share several major features. First, archives are easily searchable, including the ability to search by study topic or variable name. Searching by study topic is helpful when the researcher is looking for studies focused on a specific subject. Searching by variable name is helpful when the researcher is interested in a particular variable, such as rates of endorsement or forms of measurement of a variable across studies (e.g., ICPSR's Search and Compare Variables function). Often, studies are organized into thematic or keyword-based collections in each archive so a researcher can quickly identify groups of studies focused on a particular subarea (e.g., education, crime, racial and ethnic minorities).\nMost archives allow researchers to perform basic descriptive analyses online before downloading a data set, including frequency counts for each variable and tabular analysis. In this way, scientists can determine whether a variable of interest has a large enough sample size, enough variance in responses, or not too much missing data for the new study. Such online analyses are also useful for testing a new hypothesis before collecting new data on the topic or performing preliminary analyses for grant applications. Finally, most archives offer support in the form of Frequently Asked Questions, tips for effective searching within the archive, and access to staff members via e-mail or phone."}, {"section_title": "Getting Started With Secondary Data Sets", "text": "Before beginning a secondary data analysis, researchers need to ensure that they analyze the data correctly and do not redo work that has already been done with a given data set. The most important step is to read all the data documentation-text documents posted in the data archive alongside the data. These include such vital information as the study's description and scope, a summary of the data collection procedures, sampling frame, weight variables, data management considerations, and known errors or irregularities in the data set and what has been done to correct them. Understanding and properly accounting for the sampling frame and necessary weights are crucial in producing accurate results, and the study documentation contains the necessary information.\nSecondary data rarely have all the measures to answer investigators' questions. Using data that have been collected by others typically means that measures for some of the constructs germane to the research question will be missing. In these instances, compromises have to be made regarding how to answer and test questions. Additionally, because population data sets typically measure a broad set of constructs with limited measurement on any given construct, they often are not ideal for answering nuanced questions that require in-depth measurement. Once a researcher has addressed the issue of obtaining the data set or sets to address his or her research questions and whether they adequately answer the relevant research questions, additional statistical issues must be considered in analyzing this data."}, {"section_title": "WHAT ARE THE ANALYTICAL HURDLES WHEN USING SECONDARY DATA?", "text": "In this section, we describe three analytical hurdles typically associated with using large-scale, secondary data and suggest ways to meet these challenges. Although the first two hurdles deal with incorporating sample weights into analyses, the third hurdle entails adjusting for the effects of a complex sampling design."}, {"section_title": "Hurdle 1: Apply Sample Weights to Avoid Estimate Bias", "text": "Because oversampling of one or more subpopulations is common in population-based studies, researchers often must apply a sample weight if they want their findings to generalize to the target population. For illustration, consider the panel data from the Monitoring the Future Study (MTF; 7), an ongoing national study of the epidemiology and etiology of drug use among adolescents and adults. As part of the MTF, nationally representative samples of approximately 16,000 12th-grade students have been sampled annually since 1975. Each year, approximately 2,400 students from each cohort are selected randomly for follow-up. Because respondents who reported illicit drug use in 12th grade are purposely oversampled for follow-up, within the MTF, the Wave 1 percentage of illicit drug users is inflated relative to the target population (see Figure 1 and Table 2 ). Specifically, although the percentage of those who used illicit drugs in 12th grade among the target population is around 12.5% (i.e., this percentage is based on the fact that among the MTF's nationally representative sample of 12th graders, about 12.5% of respondents reported illicit drug use), the percentage of those who used illicit drugs in 12th grade at Wave 1 of the MTF is 30%. However, because a disproportionate amount of students who used illicit drugs in 12th grade were lost to attrition at Wave 2 (see Figure 1 and Table 2 ), the overrepresentation of those who used illicit drugs in that grade was slightly less pronounced at Wave 2 (Wave 2 = 28%). Although the oversampling of illicit drug users solves one potential problem (i.e., it helps ensure that the sample size of illicit drug users remains sufficiently large even with attrition), it creates another problem-estimates of substance use and other risk behaviors are inflated and biased relative to the target population. Sample weights correct for the estimate bias introduced by purposeful nonrandom sampling (in the case of the MTF, oversampling of 12th-grade illicit drug users at Wave 1). Mathematically, sample weights are the inverse of the likelihood of being sampled, that is, P (target population)/P (Wave 1). Therefore, for 12th-grade illicit drug users and nonusers, the sample weights, respectively, are 0.416 and 1.25 (see Table 3 ). When these sample weights are applied (see Table 2 ), the Wave 1 percentages of 12th-grade illicit drug users (12.5%; i.e., 0.300 9 0.416 = 0.125) and nonusers (87.5%; i.e., 0.700 9 1.25 = 0.875) match the target population percentages of 12th-grade illicit drug users (12.5%) and nonusers (87.5%). More conceptually, subpopulations that are underrepresented in the sample relative to the target population have sample weights larger than 1.0, while the opposite holds for subpopulations overrepresented in the sample relative to the target population. When no sample weights are applied, it is as if a sample weight of 1.0 is uniformly applied to all subpopulations. In effect, this assumes all subpopulations are represented accurately within the sample, leading to biased estimates when this assumption Note. Calculations for sample, attrition, and combo weight are presented in Table 3 .\ndoes not hold. Typically, the appropriate set of sample weights and its corresponding variable name are identified clearly within a data set's documentation files."}, {"section_title": "Hurdle 2: Harmonize Weights and Missing Data Strategy to Maximize Power and Minimize Bias", "text": "In contrast to sample weights, which adjust for sampling bias, attrition weights correct for bias introduced by attrition. The objective of attrition weights is to render the Wave 2 sample (see Figure 1 and Table 2 ) comparable to the full Wave 1 sample. Mathematically, attrition weights are the inverse of the likelihood of being lost to attrition or dropping out: P (Wave 1)/P (Wave 2). As such, because those who used illicit drugs during 12th grade are underrepresented at Wave 2 relative to Wave 1, the 12th-grade illicit drug users' attrition weight is larger than 1.0, while the reverse holds for the 12th-grade nonusers' Wave 2 attrition weight (see Table 3 ). After applying the Wave 2 attrition weight (see Table 2 ), the Wave 2 percentage of 12th-grade illicit drug users (30%) matches the Wave 1 percentage (30%). Combination weights (also called longitudinal weights) adjust for both sampling bias and attrition bias. Mathematically, combination weights are the inverse of the likelihood of being sampled (i.e., the sample weight) multiplied by the inverse of the likelihood of being lost to attrition (i.e., the attrition weight): [P (target population)/P (sample)] 9 [P (Wave 1)/P (Wave 2)]. After applying the Wave 2 combination weight (see Table 2 ), the Wave 2 percentage of 12th-grade illicit drug users (12.5%) matches the Target Population percentage (12.5%).\nTypically, data administrators instruct users of their data to use combination weights when carrying out longitudinal analyses because they assume that these users will not adjust for attrition on their own. However, counter to this recommendation, we suggest avoiding the use of attrition weights (either alone or as a part of combination weights) and instead using full information maximum likelihood (FIML) or multiple imputation (MI; see Enders (8) or Graham (9) , for a primer on FIML and MI) to adjust for attrition bias and then use the appropriate sample weight to adjust for sampling bias. We make this recommendation because relative to FIML and MI, attrition weights (including combination weights) have two disadvantages: First, unlike FIML and MI, attrition weights often sharply reduce the analytical sample size and, thereby, statistical power. Typically, only those participants with data at every wave are assigned an attrition weight and used in subsequent analyses. Within the MTF example, where the Wave 1 N = 64,839 and the Wave 2 N = 45,194, one's analytical N would be 45,194 with attrition weights, but 64,839 with FIML or MI. Of course, this problem is compounded as a study's number of waves (and therefore attrition) increases. Second, if many auxiliary variables (i.e., nonmodel variables related to missing data) are incorporated, FIML and MI may adjust for attrition bias more effectively than attrition weights. Most statistical packages can use FIML , including STATA (10), SAS (11), Mplus (12), R (13), SPSS (14) , and AMOS (15) , and many can use MI (e.g., STATA, SAS, Mplus, R, SPSS)."}, {"section_title": "Hurdle 3: Adjust for Complex Sampling Design to Avoid Type I Errors", "text": "Most large-scale data sets were collected using complex sample designs that entail a clustered sampling design (e.g., schools are randomly sampled and then all students within the selected schools are sampled). Because a clustered sampling design reduces variance (e.g., 100 students from the same school are likely more similar to one another demographically than are 100 students from 100 different schools), it also reduces standard errors and thereby inflates the chance for Type I errors (16; for more information on complex sample designs, see Bornstein et al. (1) or Levy & Lemeshow (17] )). To adjust for these design effects, a primary sampling unit variable (e.g., schools) and potentially a stratification variable are incorporated into analyses. Most statistical packages (e.g., STATA, SAS, Mplus, R, SPSS) can adjust for a complex sampling design and typically the appropriate primary sampling unit and, if necessary, stratifi- cation variables are clearly identified within a data set's documentation files."}, {"section_title": "SUMMARY", "text": "Secondary data analysis is used in other social sciences as the primary method for studying behavior. It can be used easily by developmental scientists to answer questions of how individuals develop across time and in different contexts (18) . Researchers who use these data sets need to have some additional statistical knowledge, but it is minimal given the advantages. Moreover, given the time and effort to collect primary data and the difficulty of obtaining participants, using secondary data sets allows researchers to test longitudinal questions that would take years if the researcher were collecting primary data. Thus, this method allows for more rigorous, diverse, and longitudinal analyses of the topics that are most important to developmental scientists (19) ."}]