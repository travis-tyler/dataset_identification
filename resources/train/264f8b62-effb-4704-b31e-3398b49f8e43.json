[{"section_title": "Introduction and Background 3", "text": "The National Survey of College Graduates (NSCG) is a longitudinal survey conducted every two to three years by the U.S. Census Bureau on behalf of the survey sponsor, the National Science Foundation (NSF). The NSCG is the largest of three surveys that combine to form the Scientists and Engineers Statistical Data System (SESTAT). The other two surveys are the National Survey of Recent College Graduates (NSRCG) and the Survey of Doctorate Recipients (SDR). SESTAT is a comprehensive and integrated system of information about the employment, educational, and demographic characteristics of the science and engineering population in the United States. The integrated data from these three surveys serve as the basis for the development of national estimates on the science and engineering (S&E) workforce. Traditionally, the NSCG has selected its sample from the decennial census long form respondents. The long form was a large frame from which to select a sample (approximately 1 in 6 households in the United States, including Puerto Rico and the outlying areas 4 ) and provided a wealth of information for sampling purposes. The SESTAT target population is defined to be people with a bachelor's degree or higher, educated or working in an S&E or S&E-related field or occupation, who are aged 75 or younger, noninstitutionalized 5 , and living in the United States as of the survey reference date. The long form asked for the highest level of education a person completed, so we could identify the college graduates in the population. However, we could not distinguish those with an S&E or S&E-related degree that we were targeting. We could only identify people working in an S&E or S&E-related occupation. Thus, we needed to field a large screener survey in order to capture those with an S&E or S&E-related degree who were working in a non-S&E occupation or not working at all. In addition, the decennial census long form was only available once per decade, so later rounds of the NSCG during the decade were supplemented with respondents from the NSRCG. This method captured new graduates in the population, but did not catch new immigrants coming into the country who earned their degree before entering the U.S or people who entered an S&E occupation. Previously, the 2003 NSCG initially selected a sample of 177,320 persons from the 2000 decennial census long form frame, of which approximately 100,000 responded. And of these respondents, only 66,247 had either an S&E or S&E-related degree or occupation. The remaining 111,073 cases were either nonrespondents or otherwise ineligible for the SESTAT target population and were not followed-up with in the 2006 NSCG. Thus, most of this initial sample was screened out of future rounds of the survey. In 2010, the Census Bureau discontinued the use of the long form. Everybody received what had been known as the short form as part of the 2010 Census. Unfortunately for the NSCG, the short form does not collect information on educational attainment, occupation, or some other variables we need to identify persons who are eligible for the NSCG sample. Continuing to supplement the existing NSCG sample with new NSRCG respondents only is not desirable due to the immigrant coverage issue mentioned above. In addition, sample attrition over time can introduce bias to the estimates. The only practical alternative frame identified from which to select a new 2010 NSCG sample is the 2009 American Community Survey (ACS). This paper discusses some of the opportunities and challenges the NSCG faced in switching from the decennial census long form to the ACS as a sampling frame. Section II discusses the question of how many cases to select for the sample, section III addresses the question of how to select the sample, and section IV describes who should be selected for the NSCG sample. Most of this research was done concurrently using 2005-2008 ACS data with a person's field of degree predicted by a statistical model."}, {"section_title": "The ACS as a Sampling Frame -How Many to Sample?", "text": "The ACS is an ongoing survey conducted monthly by the U.S. Census Bureau. Similar to the decennial census long form, the ACS collects demographic, social, economic, and housing data from across the fifty states, the District of Columbia, and Puerto Rico 6 . It samples approximately three million households per year, which results in approximately 850,000 persons eligible for selection into the NSCG. At first glance, this seems like it would be of sufficient size to select a sample for the NSCG. However, upon further review, we found about 17% of our sampling strata (as defined in the 2003 NSCG) could not be fully fielded with one year's worth of ACS. In fact, we estimated it would take up to 28 months of ACS in order to fully sample the NSCG at 2003 levels, especially for relatively rare populations (e.g., disabled female engineers with at most a bachelor's degree). In order to resolve the insufficient sample size problem in the ACS frame, changes were instituted in both the ACS and the NSCG. Beginning in 2009, a question was added to the ACS questionnaire asking for a respondent's field of degree for any bachelor's degree they may have earned (for those that reported having earned at least a bachelor's degree). The field of degree question allowed for more efficient sampling from the ACS frame, as less screening was necessary to identify the S&E population. Instead of needing to sample 177,000 people for the NSCG, we anticipate needing to sample only 130,000 cases to get similar results (with most of this reduction coming from non-S&E cases that we should not need to screen as much). The field of degree question also provided improved stratification options for NSCG sampling in that we could sample persons in non-S&E occupations with S&E degrees at different rates than those without S&E degrees. Eventually we may even sample different degree fields at varying rates, although for 2010 we only considered the S&E status of a degree in our stratification. The field of degree question as currently used on the ACS questionnaire only relates to a person's bachelor's degree(s). Thus we are unable to identify someone with a non-S&E bachelor's degree but with an advanced degree in an S&E or S&E-related field. However, in previous NSCG surveys, we found this situation to be relatively uncommon (we estimated this to be around 5% of people with an S&E advanced degree in the 2003 NSCG). The second major change made to address the insufficient sample size problem in the ACS frame was to the NSCG sample design itself. After reviewing proposals provided by the NSF, the Committee on National Statistics (CNSTAT) recommended the introduction of a rotating panel design beginning in 2010. The full NSCG sample will be split up into four panels. At each survey cycle, a new panel (quarter sample) will be selected from the previous year's ACS, and the oldest panel will drop out of the survey. With this approach, we will only need to select a sample of approximately 32,500 from the ACS (1/4 of the 130,000 targeted sample size) instead of 177,000 like we did for the 2003 NSCG from the 2000 decennial census long form frame. Not only can we select fewer cases under a rotating panel design, but it also leaves more ACS sample cases available for other surveys from which to select a sample should the need arise. Additional advantages of a rotating panel design are the continuing renewal of the sample to combat sample attrition and the inclusion of recent immigrants and recent college graduates to the population. The rotating panel design will be phased in over two survey cycles. The 2010 NSCG sampled two panels -approximately 65,000 people -from the 2009 ACS, and retained some cases from the previous 2008 NSCG and NSRCG surveys for a total sample of approximately 100,000 cases. The next NSCG survey cycle (in either 2012 or 2013) will select another two panels from the 2011 ACS and drop the 2008 NSCG and NSRCG cases completely. From that point on, future NSCG surveys will add one panel and drop one panel with each cycle. The transition to the rotating panel design is discussed in more detail in Finamore, et al (2011). Once we determined that we needed a sample size of 65,000 people from the 2009 ACS for the 2010 NSCG, we needed to decide how to allocate those cases to our sampling strata. Traditionally, the sample was allocated to key characteristics (race/Hispanic origin, sex, occupation, and highest degree level) to provide \"adequate\" sample for key estimation groups while maintaining a \"reasonable\" weight range. The allocation process was not directly tied to estimation and was very subjective. For 2010, the NSF decided they would like to develop a sample allocation process that was more repeatable and allowed us to use the ACS-based sample more efficiently to meet the NSCG estimation needs. The NSF is congressionally mandated to produce two biennial reports: Science and Engineering Indicators and Women, Minorities, and Persons with Disabilities (WMPD). The Indicators mandate is broad, requiring NSF to report on the U.S. status of science and engineering. The WMPD mandate is more specific in that it requires NSF to ensure that obtaining information on women, minorities, and persons with disabilities in the S&E workforce is an important consideration in data collection and analysis. While SESTAT data is used in numerous ways beyond fulfilling the legislative mandates, NSF believed it is the Indicators and WMPD reports that best reflect the key analytical domains for the SESTAT surveys, including the NSCG. NSF evaluated these two reports and identified several key analytical domains, along with their reliability requirements and priorities. Domain reliability requirements in the form of coefficients of variation (CVs) were based on reliability information from the 2000-decade design with modifications to reflect current interests. The domains were prioritized to indicate the importance of maintaining the preferred reliability. The final product was a set of three primary analytical domains (PADs) and twenty secondary analytical domains (SADs). The PADs were a cross between demographic group, highest degree level, and occupation group, while the SADs included such characteristics as sex, age, citizenship, disability status, and employment status. The Census Bureau used the PADs developed by NSF in a systematic process for sample allocation, modeled after the approach used by Mathematica Policy Research, Inc. (MPR) for the 2008 NSRCG. This new method used the priority and reliability requirements for each analytical domain to determine sample allocation. The sample allocation for each PAD was determined sequentially based on priority level. It included an iterative feature that allowed reconsideration of CVs for higher priority domains if sufficient sample was not available to meet the CV requirements for lower priority domains. The SADs were then used to evaluate the impact that the allocation had on other estimates of interest. This new approach is repeatable once CV levels and priorities are finalized, and it incorporates the impact of ACS weight variation in determining the sample allocation. The ACS frame of NSCG-eligible persons was categorized into the same analytical domains, and frame sizes and CVs were calculated for each domain. Then, the sample allocation for a given primary analytical domain was calculated using the following formula: where: n NSCG = the desired domain-level sample size for the 2010 NSCG n ACS = the domain-level frame size from the 2009 ACS CV ACS = the calculated domain-level CV from the 2009 ACS CV NSCG = the required domain-level CV for the 2010 NSCG This calculated sample size was adjusted for expected nonresponse and used as a constraint for the next priority domain in an iterative fashion. This process resulted in a sample allocation for our sampling strata, defined as the cross between all primary analytical domains, that met the desired reliability requirements for each primary analytical domain (or as close as possible given the ACS frame size)."}, {"section_title": "The ACS as a Sampling Frame -How to Sample?", "text": "The ACS annual sample is split into twelve monthly sample panels. The survey data for each sample panel is collected over a three-month time period using three sequential modes of data collection. 7 In the first month, a self-administered questionnaire is mailed to each household. 8 If that household does not respond by the end of the first month, they are followed-up by telephone (if a telephone number is known) using computer assisted telephone interviewing (CATI). If they have still not responded by the end of the second month, a subsample of nonrespondents is followed-up with a personal visit in the third month using computer assisted personal interviewing (CAPI). An illustration of this mixed mode of data collection is provided in the following For example, a household selected for the January 2009 ACS sample panel would receive a questionnaire by mail in January, be followed-up by telephone in February if they had not responded by the end of January, and followed-up by personal visit in March if they 7 Group quarters are handled differently, but they constitute such a small portion of the NSCG sample that we will not discuss them here. 8 A second questionnaire is mailed in the first month to nonrespondents, and a third questionnaire is mailed in month 2 for those nonresponding households for which a telephone number is unknown. had not responded by the end of February and were selected into the CAPI subsample. All three modes are in process during any particular calendar month, but on different sample panels. The CAPI subsample of nonrespondents after the mail and CATI stages introduces increased weight variation in the ACS, which reduces the effective sample size. Furthermore, it is not uniform across domains (e.g., blacks and Hispanics seem to be less likely to respond by mail or telephone, so have higher CAPI rates than do whites). This caused great concern for the NSCG. Traditionally, the NSCG has selected its sample from the decennial census long form frame using probability proportional to size (PPS). The long form was a much larger sample with no personal visit subsampling, so the weight variation was not nearly as large as found in the ACS. The CAPI subsampling in the ACS creates large weights, and those cases would be more likely to be selected using a PPS sample selection mechanism. Unfortunately, we would expect these cases to be less likely to respond to the NSCG. The ACS is a mandatory survey, required by law, with a personal visit stage of data collection. What are the odds that a person who refused to answer a mandatory survey, given the opportunity to respond by mail and telephone, will cooperate with a voluntary survey with no personal visit stage of data collection only a few months later? Research from the 2003 NSCG supports this conjecture. The NSCG response rate for people in households that returned their 2000 Census long form by mail was 67%, while the NSCG response rate for people in households that were visited by a Census enumerator in 2000 was only 45%. This twenty percentage point difference held true for S&E cases as well as non-S&E cases. 9 How then should we select a sample for the NSCG from the ACS? We researched eight different sample selection techniques, using a combination of PPS and simple random sampling (SRS). We considered SRS because that should reduce the number of ACS CAPI cases selected for sample when compared to PPS. Unfortunately, that resulted in some very large NSCG base weights after sampling, especially for non-S&E cases (due to their already low sampling rates). For PPS samples, we considered various ACS weights as the measure of size -the final person weight, the household base weight (before the CAPI subsampling adjustment), and the noninterview adjusted weight (before the person-level raking adjustment, which introduced additional extreme weights -see Finamore, et al (2011) for more details). We used two main evaluation criteria to compare the eight sample selection techniques under consideration. We wanted to (1) minimize the percentage of cases selected into the NSCG sample that responded to the ACS by personal visit, and (2) minimize the extreme NSCG base weights after sampling. 10 best across all evaluation criteria, but the approach we chose did fairly well under both. The combined approach we chose used SRS to select S&E cases (to reduce the number of CAPI cases among the majority of our sample in order to maximize the expected NSCG response rate) and PPS with ACS final weights as the measure of size to select non-S&E cases (to reduce the extreme weights). 11 To summarize the comparisons, a graph of maximum weight by the proportion of cases selected into the sample that were interviewed in ACS via personal visit is shown below. The corresponding value for the overall ACS frame of NSCG-eligible cases is also plotted as a green diamond on the graph. Since we would like to minimize these values, points to the lower left on the graph are more desirable. A couple of the points on the graph are labelled to highlight some of the observations discussed earlier. The sample selected using PPS contained a large proportion of cases that were interviewed in the ACS during the personal visit stage. We believe this would hinder NSCG response rates. The sample selected using SRS resulted in some cases with very large weights. This would reduce our effective sample size and could be detrimental to NSCG estimates and variance. The chosen sample selection technique is highlighted by the light-colored circle in the graph and performed relatively well under both criteria."}, {"section_title": "The ACS as a Sampling Frame -Whom to Sample?", "text": "Once we decided how to select a sample for the NSCG and how many cases to sample from the ACS, we still encountered a number of NSCG sample selection issues. Several of these issues involved determining a person's eligibility for inclusion into the ACS sampling frame. As described earlier, a person is eligible to be selected into the NSCG sample if they have at least a bachelor's degree and are aged 75 or younger, nonistitutionalized, and residing in the United States. Previous experience has shown that a large percentage of cases with an allocated 12 degree reported in the Census did not actually have a college degree. NSF decided to exclude all cases with an allocated degree due to concerns about coverage bias related to allocated degree cases identified as ineligible (i.e., no bachelor's degree). These allocated degree cases were excluded from selection into the frame, and their weights were redistributed to the other ACS cases within the same sampling stratum. 13 Due to the rolling nature of its sample design, the 2009 ACS does not have complete coverage of people who earned their first degree in 2009. Depending upon when the degree was earned and when the household was interviewed in the ACS, it may or may not be reported. For example, if a person earned their first bachelor's degree in May 2009, it would be reported if their household was interviewed by ACS in September, but not if their household was interviewed by ACS in February. Thus, NSF defined the NSCG education eligibility requirement as having earned at least a bachelor's degree as of January 1, 2009. Since the ACS does not identify when a degree was earned (only the highest level of education completed and whether or not a person is currently attending school or college), we cannot exclude these cases that first earned a degree in 2009 from selection into the frame. Instead, if we find a case that first earned a degree in 2009 during the NSCG interview, they will be deemed out-of-scope for the 2010 estimates (but may be retained for interview in the 2012 NSCG). Likewise, the ACS has only partial coverage of the immigrants who first came to the U.S. in 2009. Unlike degree status, though, immigration is not an eligibility criterion, so NSF decided to include these cases in the frame. NSF believed that some coverage of this population of interest was better than no coverage. Another concern for NSCG sampling was name quality in the ACS. The ACS is a onetime household survey and individual names are not necessarily a priority (especially if pressing for them in a telephone or personal interview might increase the risk of a nonresponse). We found about 2.5% of ACS frame cases did not have a valid name (this was about twice the bad name rate as for the 2000 decennial census long form). Examples of bad names include blanks, initials, generic names (e.g., John Doe), descriptive names (e.g., Lady of the House, Son #2), and age-based names (e.g., 36-year old). Since we cannot mail a questionnaire to \"29-year old Jones,\" we were forced to exclude these cases from the frame as well. Likewise, cases with incomplete addresses were also excluded. The weights for these cases with bad names and incomplete addresses were redistributed to the other eligible ACS cases within the same sampling stratum like we did for the 12 In this context, \"allocation\" is a term used by the Census Bureau to identify a specific way in which an item imputation process is accomplished. Under the ACS edit process, an allocation occurs when an answer from a response record (a donor) is duplicated for a missing or inconsistent item on another response record (the donee). Allocation usually involves the use of hot deck matrices. 13 In addition to ineligible cases being imputed to having a college degree, there is also concern that eligible cases could be imputed to not have a college degree and thus have no chance for selection into the NSCG. It is hoped that the weight redistribution will balance out these two errors. allocated degree cases. There is some concern about potential bias, as the bad name rate is not uniform across all domains (e.g., minorities have a higher bad name rate than do whites) or data collection modes (bad name rates are much higher for telephone, personal visit, and group quarters cases). After the 2010 NSCG was fielded, additional examples of bad names were identified (e.g., \"Pseudonym Pseudonym\"). These examples will be incorporated into the future frame creation processes as bad names to exclude from sample selection and will be handled in the 2010 NSCG through a weight adjustment. Additional issues were uncovered once the sample was out in the field. For example, the ACS CATI/CAPI instrument autofills the last name of each person in the household using the last name of previous person on the household roster. The interviewer can change that, but it doesn't always happen as it should. As a result, especially in households consisting of unrelated roommates and unmarried partners, this caused some difficulty in locating the correct sample person. Another source of locating difficulty was person order misalignment. The ACS questionnaire collects basic demographic information for the household members up front (e.g., sex, age, race, and Hispanic origin) followed by housing data. Detailed demographic information is then collected at the end of the ACS questionnaire for each household member listed at the beginning of the form (e.g., educational attainment, citizenship, disability, employment status, occupation, etc.). If the person numbers did not match up between the basic and detailed demographic sections, we could select the wrong sample person (or there could be nobody in that particular household with those desired characteristics -for example, there is a female in the household, and there is an astronomer in the household, but there is no female astronomer). During the creation of the sampling frame, we found a similar issue in the ACS files with record linkage and person renumbering. For example, a questionnaire returned by mail may list information for person numbers 1, 3, and 4 (perhaps they started to fill out the information for person number 2, but crossed it out). At some point during the editing process, they were renumbered as 1, 2, and 3. This renumbering is an entirely reasonable thing to do, but it can cause trouble when merging data files together. In this scenario, person number 3 on file A is not the same person as person number 3 on file B. Again, this method can lead to selecting the wrong sample person if not caught and corrected. Finally, published ACS data is subject to disclosure avoidance by the Census Bureau. Disclosure avoidance (DA) techniques are statistical methods used in the tabulation of data prior to releasing data products to ensure the confidentiality of responses. This confidentiality is guaranteed by law (Title 13 of the U.S. Code) to ensure that individually identifiable data will not be released. Several disclosure avoidance methods are utilized, including swapping pairs of households in different geographic regions, topcoding, and age perturbations. Since eligibility for the NSCG is determined by a person's individual characteristics, it was imperative that we used data prior to disclosure avoidance to create the sampling frame. Unfortunately, disclosure avoidance activities were performed prior to weighting of the data, so no weighted pre-DA data existed, and we needed weights to select the sample of non-S&E cases using PPS. So we performed our own simplified weighting procedure on the pre-DA edited data (based on the weighting procedure used by the ACS) to create our own person-level weights. See Finamore, et al (2011) for more information on this process."}, {"section_title": "Summary and Future Research", "text": "The 2010 NSCG experience has demonstrated that sampling directly from the ACS is not straightforward. The 2010 NSCG sample was selected in July 2010 and fielded in October 2010. Data collection continued until July 2011 and post-data collection processing is ongoing. Results from the 2010 NSCG will be analyzed to evaluate the sample selection and allocation methods used in preparation for the 2012 NSCG. Further research into the quality and possibility of using finer levels of the field of degree as reported in the ACS in the sample stratification will also be conducted, time permitting. In addition, research will also be conducted on weight trimming options to lessen the impact of extreme weights due to the CAPI subsampling in the ACS."}]