[{"section_title": "Introduction", "text": "Numerous policy issues arise at the institutional, state, and national level which may be addressed with data about faculty. While in the past, it has been difficult if not impossible to gather data to support this research, the advent of the World Wide Web has transformed the dissemination and diffusion of the national datasets. In particular, the National Center for Education Statistics (NCES) and the National Science Foundation (NSF) have taken significant steps to make the data they collect available on the Web in a readily-accessible format for analysis. The purpose of this AIR Professional File article is to document the national datasets which may be used for policy studies and research about faculty. These include 11 datasets which include faculty information (the IPEDS S, IPEDS SA, CUPA, Oklahoma State, AAUP, NSOPF, HERI, SDR, NRC, NSCG, and the NSRCG); two datasets about student enrollment (the IPEDS EF and the GSS); two datasets about degrees awarded (the IPEDS C and the SED); and two datasets about institutional activity (the IPEDS F and IPEDS IC). An extensive review of each dataset is provided. This includes a discussion of the nature of each survey and examples of how the data may be used for faculty studies. The review also describes whether each dataset is based on a population or sample survey, key variables, the administering agency, response rates, where the data Number 70 Winter, 1999 Using the National Datasets for Faculty Studies may be obtained, what historical data are available, and the most current data available. Most of the discussion focuses on the datasets with information about faculty or potential faculty. The six non-faculty datasets are analyzed in terms of how they may be used in conjunction with the other 11 for purposes such as calculating performance measures. When examining the data, it is helpful to think of using different lenses for different kinds of analysis. Most of the datasets may be used for peer comparison of specific institutions and these serve as important resources for institutional research. It is also important to think about ways to aggregate the data by Carnegie classification and/or control. Regional issues such as the impact of cost of living on faculty salaries may be addressed with location, state, and zip code fields. At the national level, patterns of faculty workload, salary compression, and access may be discerned."}, {"section_title": "Caveats", "text": "It is important to understand certain caveats about how the data were collected and how the data should be used. For example, the IPEDS datasets on full-time instructional faculty salaries (SA) do not include data for survey cells or items for which there are three or fewer faculty. NCES does this to safeguard privacy by preventing the possible identification of individuals. The results of average salary calculations will be different for records in which this is the case. In the data administration and dissemination of each dataset, many such decisions are made and it is critical that users carefully read the field definitions and instrument collection instructions. Another element to consider with each file is the census date, especially when merging files that are presumed to be of the same year or semester. All of the datasets are based on headcount. Nowhere is the variable of full-time equivalent (FTE) faculty collected. Faculty FTE are often assumed, using the fulltime headcount of the IPEDS SA or Fall Staff Survey (S). However, definitions of full-time faculty vary between institutions and between individuals. Some surveys include faculty on leave, while others do not. How did institutions determine whether faculty are teaching, research, or service? This requires examination of multiple funding records in which faculty are paid from different accounts for different purposes. Some survey data are weighted back to the universe of institutions as documented by NCES, some are weighted to population estimates from the Decennial U.S. Census, and others are weighted to surveys of the entire population (for example research doctorates from the Survey of Earned Doctorates). It is important to examine sample sizes, response rates, and stratification procedures. Much has been written about peer comparisons and the reader is referred to this literature for better discussion of caveats in using data for this purpose (Brinkman and Teeter, 1987). One word of caution is that users of these data need to look for anomalies and outliers. Does a suggested pattern such as low expenditures for instruction per faculty FTE show up in other variables, such as expenditures for libraries? Does the same pattern show up in previous years? When working with data dictionaries to understand the structure of each survey, it is helpful to have a copy of the actual questionnaire in hand. It is even better to have a copy of an individual institution's survey submission, in order to correctly match up field names with data cells on the survey form. While great time is saved with electronic access to the data, sometimes it is more efficient, timely, and cheaper to obtain print copies of surveys, such as institutional submissions to the CUPA or IPEDS IC surveys. These may then be collated within a spreadsheet for comparisons of peers and competitors on chosen variables. This is especially necessary when the data are not available with institutional identifiers. The interpretation of the survey instructions may be different depending on who completed it. For example, in completing the NSF-NIH Science and Engineering Graduate Student Survey (GSS), some schools gather the data centrally while others send it to departments to complete. Discussions held by the author with the vendor, Quantum Research Corporation, NSF staff, and institutional researchers suggest that very different results are obtained with each method of collection. Departments will count postdoctoral fellows that do not appear in the human resource payroll files that institutional research offices would use to complete the survey centrally. Departments may count students who are not actually enrolled in the semester of the census date or for whom they have only an advising load. Many of the surveys have undergone extensive changes over time, making historical comparisons at times impossible. Yet the field names may remain similar, leading the casual user to think that the data may be used in this way. Copies of some early survey instruments are available on the Internet, though others are not available. Users must read carefully about changes in the instrument and in the collection effort. The NCES is working to provide better data for decisionmaking. In 1994, Congress authorized the creation of the National Postsecondary Education Cooperative (NPEC). NPEC's mission is \"to identify and communicate on-going and emerging issues germane to postsecondary education, and to promote the quality, comparability and utility of postsecondary data and information that support policy development, implementation, and evaluation\" (NPEC, http://nces.ed.gov/npec/). All levels of postsecondary education are included in NPEC activities, along with statewide governing and coordinating agencies, federal agencies, and national higher education associations. In the aftermath of the National Commission on the Cost of Higher Education report to Congress, \"Straight Talk About College Costs and Prices,\" and the Higher Education Reauthorization Act of 1998, NCES is working to redesign the IPEDS surveys. NCES has an internal task force and is building a national dialogue about ways in which the data are used and collected. NCES is also working with four IPEDS redesign subcommittees of the NPEC to focus on finance, faculty/staff, student, and survey population/sample issues. It is clear that many of the IPEDS forms will change dramatically in the next several years and users of the national data are urged to follow and participate in this dialogue. The reports of the task force and working groups are available on the Web at http://nces.ed.gov/Ipeds/whatsnew.html. When working with these datasets, it is necessary to recognize the difference between the kind of descriptive statistics used for most institutional research and more sophisticated methods of quantitative analysis. Though software programs such as SAS, SPSS, or Access are used for reading, merging, and re-coding the data, many of the policy analyses described in this paper require only simple cross-tabs or pivot table calculations. While the National Study of Postsecondary Faculty (NSOPF) and other surveys may be used for complex studies, such as faculty life and research productivity by discipline, the focus of this paper is on more pragmatic, policy analysis. With this approach to descriptive statistics, the results may be used only to suggest the presence of a possible pattern in the data, not for any kind of generalization."}, {"section_title": "Review of Datasets", "text": "The following table (also Appendix A) lists the data sets and their availability in various formats. In addition to the primary Websites (WebCASPAR, SESTAT, and IPEDS), the table documents whether files are available by FTP download; if there is any cost associated with obtaining the This survey documents graduate enrollment and financial support for graduate students. The GSS is the \"only nationally representative data bank on sources of support of graduate science and engineering (S&E) students and their enrollment characteristics, and on S&E postdoctoral appointments\" (Guide, 1998). Institutional aggregate totals of discipline-specific data are collected for full-and part-time students by gender within ethnicity and by funding source, and for post-docs and other nonfaculty, doctoral, research staff.  Some critical variables have changed over the years, but the survey offers consistent data about enrollment at the program and/or departmental level. The entire universe of graduate programs in S&E has been surveyed since 1988. In 1997  item non-response rates range from 0.4% for gender to 4.6% for race. Aggregated to the institution level, these data compare well to the IPEDS Degrees Completions survey collected by NCES, which will be discussed later. Where the Completions survey documents all doctoral awards and is reported by institutions, the SED surveys all research doctorates and is completed by individuals. The key variables in the SED include: academic institution, citizenship, country of birth, country of citizenship, birth date, disability status, educational attainment of parents, educational history, enrollment status (full-/part-time), field of degree, field of employment, field of science and engineering, field of study, level of degree, marital status, number of dependents, birth place (within U.S.), postgraduate plans, primary source of financial support (e.g., NSF, NIH, etc.), race and ethnicity, gender, type of academic institution (historically black/ others), type of employer planned, type of financial support (e.g., fellowship, research assistantship, etc.), type of institutional control (public versus private), and work activity planned. The three-digit taxonomy of disciplines used for the SED continues to evolve and is the most exhaustive of any of the surveys reviewed, with more than 300 specialties, albeit not without debate about the most current and appropriate taxonomy. Specialty data are collected for each degree earned, the dissertation topic, the field of intended postdoctoral study, and the expected field of work. In addition to complete demographic data, the SED collects data on educational history, time to degree, financial support, and post-graduation plans. Numerous tables from the data are available on the Web and in the annual publication Science and Engineering Doctorate Awards. These degree data are also used by NSF for publications such as Science and Engineering Degrees, Researchers use the SED for studies about doctoral graduate characteristics and about the impact of various variables, such as funding, on time to degree. The SED also affords the institutional researcher critical data about peer comparisons. For example, it is possible to compare doctoral degree data in a much more complex manner than is possible with the IPEDS completions survey. (3) Survey of Doctorate Recipients (SDR) The SDR is a longitudinal survey that was initiated in 1973. A biennial survey of the science and engineering doctorates in the U.S., new doctoral recipients are added each cycle and individuals older than 75 are dropped. The sample is drawn from the Doctorate Records File of the SED, with a sampling rate of approximately 1 to 12, with fifty thousand individuals surveyed in 1995. From 1977 to 1995, the SDR included humanities doctorates. It is hoped that, with additional funding, these data will once again be collected. Information about the SDR is available on the Web at http://www.nsf.gov/sbe/srs/ssdr/. Initial data collection is done by mail, with follow-up by computer-assisted telephone interviewing (CATI). The sample is stratified by field of degree, gender, race and ethnicity, disability, and U.S. versus foreign birth place. Data from the survey are weighted to the total S&E doctorate population in the U.S., using the Doctorate Researchers may access public SESTAT files either on the Web or by obtaining a microdata license for the complete file. Web access is offered with a simple registration form at http://sestat.nsf.gov/. Selected SESTAT tables and a data element dictionary are available online. These include extensive technical notes and frequencies of responses to each variable in the 1993 and 1995 files. The SESTAT variables are also organized by topic, keyword, and crosswalks between survey, question number, and SAS field name. A problem of the SDR for faculty studies is that data about current faculty employment is collected only by major postsecondary occupation codes. These occupational data lose the fine level of detail available in the coding for field of degree from the SED. Field of degree is sometimes used as if it were comparable to field of employment in the SDR. However, some Ph.D.s work outside of their field of doctoral degree (Burton and Parker, 1998). Any crosswalk between the SDR and WebCASPAR or other disciplinary taxonomies must be very simplistic, given the broad nature of the postsecondary occupation codes. Another problem is that, because it is based on the SED for its sample, the SDR excludes persons with professional degrees in the medical sciences, yet it The SDR may be used to document the faculty population by gender, race, rank, and tenure for a sample of S&E higher education faculty, but only for the 29 postsecondary occupation codes. An example of the limitations of this taxonomy may be seen in the grouping for \"Life and Related Sciences,\" which has only four The SDR does allow for estimates of postdoctoral data, in and out of academe, that are not included in the GSS (Regets, 1998). It is possible to estimate the percentage of Ph.D. recipients entering post-docs by occupation and field of degree. These data are sometimes used for doctoral unemployment studies by discipline and industry. However, the SDR is inadequate for documenting the faculty population by detailed discipline, even for S&E faculty. Since the SDR is only a sample, it is not appropriate to estimate data at the institutional level. If SDR data are to be used for peer comparisons, it is necessary to aggregate the data up to a combination of educational institution type and control. Not all institutional variables such as Carnegie classification are readily available in the file. SDR microdata must remapped by institutional codes to a lookup table of Carnegie classification data. NSF staff are working to include more institutional identifiers for further analysis. The longitudinal component of the SDR collects agerelated data useful for modeling faculty retirement and longitudinal data useful for modeling rank transitions. However, due to major survey design and instrument changes, users should consult with NSF staff before using SDR data longitudinally. Study.\" The B&B was designed to \"determine how many graduates become eligible or qualified to teach for the first time and how many were employed as teachers in the year following graduation, by teaching.\" The B&B is also designed to evaluate \"the relationship between courses taken, student achievement, and occupational outcomes\" (NCES, 1998, http:llnces.ed.gov/surveys/b&b.html). Like the other SESTAT databases, the occupation field for faculty in the NSRCG is reported for 29 postsecondary occupations, and then only for persons with S&E degrees. The technical notes about the survey explain that \"individuals do not always know the precise definitions of occupations that are used by experts in the field and may thus select occupational fields that are technically incorrect\" (NSF, 1997, http://wmcnsf.gov/sbe/srs/nsf97333/secta.htm). The use of occupation codes was simplified between the 1993 and 1995 surveys. Occupation codes were recognized as a problematic variable and best coding practices were used, resulting in two occupation codes for each respondent in the three surveys reported and best code. The NSRCG survey provides a portrait of the faculty population by gender within race for the 29 possible postsecondary occupations, but only for each general type of academic institution. Since the survey is designed to reach new graduates, the results allow researchers to study the new faculty population in institutions which do not require a doctorate, such as community colleges. It is necessary to aggregate to the general type of educational institution where faculty are employed. No weighting techniques are used, since the entire population is surveyed at the school level. Response rates range from 85% to 96%. Data on non-responding institutions are imputed from the previous year's data in order to complete national estimates. Out of the universe of 6,698 institutions included in the third release of 1996-97 data, a total of 6,304 completed the survey for a response rate of 94.2%. The IPEDS completions data are available from a number of sources: (1) data from 1987 through 1995 are available on WebCASPAR at the institution level; (2) the raw data for 1989-90 to 1996-97 are also Using the completions survey data, it is possible to document the number of doctoral graduates by gender within race by CIP code at each institution. The data on master's degrees may be useful for some models of doctoral enrollment demand and for predicting faculty supply for community and two-year colleges. The IPEDS SA collects aggregate salary and fringe benefits data by institution on full-time, instructional faculty, with breakouts by gender, rank, tenure, and contract length. Information about the SA is available on the Web at http:/ /nces.ed.gov/Ipeds/facultysalaries.html. SA data are available from numerous sources, among them: (1) salary data from 1971 to 1995 and fringe benefit data from 1977 to 1995 are available on WebCASPAR; (2) 1989-90 to 1997-98 files are available for download from the NCES Website; the IPEDS CD-Rom (five years of historical data); (3) (4) the NCES Interactive IPEDS Database search site (1996-97 most current); 1 0 (5) Users must be careful in the calculation of salary averages using the SA. These may result in differences with those collected by the AAUP. In calculating average salaries from sources such as WebCASPAR and the raw data files, users must equate 11/12 month salaries to 9/ 10 month contract length (multiply by .81818) to have results comparable to AAUP. Also, NCES suppresses cells in the data which contain three or fewer individuals. For submissions that include these cells, the AAUP and NCES calculations of average salaries will always differ. For documenting the faculty population, the SA provides aggregate data on gender within rank within tenure at the institutional level. Along with the IPEDS Fall Staff Survey (S), the SA may be used as a population estimate of faculty totals by Carnegie classification and control. These data may also be used as validity checks for other estimates of the total, full-time, instructional faculty population, such as sampled by the National Study of Postsecondary Faculty (NSOPF)."}, {"section_title": "(8) NCES IPEDS Fall Staff Survey (S)", "text": "In 1993, the IPEDS Fall Staff survey (S) replaced the EE0-6 survey administered by the Equal Employment Opportunity Commission. Prior to this, both surveys collected data on higher education full-and part-time faculty and staff biennially in odd-numbered years. The S documents every other year the number of full-and part-time staff by EEO category (occupational activity), gender within race/ethnicity, and salary range. It also includes a version of the SA form, broken out by gender within race/ethnicity for all full-time instructional, research, and public service faculty. Information about the S is available on the Web at http://nces.ed.gov/ Ipeds/fallstaff.html. The 1997 IPEDS S survey includes 6,777 postsecondary schools, with 6,194 respondents for a response rate of 91.4%. Data are imputed for missing schools, based on previous years' submissions. Staffing data are available from several sources: biennial files from 1991 to 1997 are available for download at the NCES Website; (2) the IPEDS CD-Rom, with historical data; (3) the NCES National Data Resource Center; and commercially available from John Minter Associates \"Staff 98 CD\" with 1997-98 data. See http://www.edstats.net/staff98cd/ for more information. The \"Higher Education Data CD 99\" provides five biennial surveys worth of S data. The bulk of the IPEDS S is devoted to collecting data on the broad occupational categories developed by the EEOC for affirmative action reporting. These include: executive/administrative/managerial, other professionals (support/service), technical and paraprofessionals, clerical and secretarial, skilled craft, and maintenance. Data are collected on part-time employees, including part-time faculty (with teaching, research, and service combined). Another table of information about new hires is collected, broken out for total, full-time, instructional, research, and service faculty by gender and ethnicity. Unfortunately, these are not further broken out by tenure status or rank. These data on hiring reflect the only national population source on the number of part-time employees and the number of new faculty hired by the universe of institutions. In documenting the faculty population, the IPEDS S provides aggregate, institutional data by gender within ethnicity by rank within tenure. The data on new hires is useful in predicting an annual growth rate by institution. It is also possible to take data by institution from the S, subtract data from the SA, and estimate the number of full-time research and public service faculty, something not collected directly by either survey. Tenure and rank issues for research and service faculty may also be analyzed using this comparison between S and SA data. While the SA report is often completed by institutional research staff, and like the AAUP survey is central to national analyses of faculty compensation, the S is sometimes not given as much analytical scrutiny in its preparation. The survey may be compiled by human resources 11 office staff, with different dates and selection criteria than those used for the SA. Therefore, any analysis of the relationship between S and SA data must be done cautiously. The survey has historically collected data by gender and rank within discipline, with minimum, maximum, and average salaries for full-time, instructional faculty. Recently with the 1998-99 survey, CUPA started to collect data on three levels of non-ranked researchers. Research These may be comparable to non-faculty research staff listed on the GSS. Senior level Research III positions such as senior research scientist or senior research engineer are responsible for research projects, usually hold an advanced degree, and have four or more years of \"high-level research experience.\" Only data that fit into the survey's unique combinations of CIP code taxonomy are collected, so the results may not be used as an estimate of the total faculty population at participating institutions. Data are also collected for new assistant professors as a subset of the assistant professor data. These are very useful for estimating the number of new assistant professor hires by discipline to document benchmarks of the salary marketplace. For example, the data may be used to verify issues of salary compression, illustrating disparities between the salaries of new and existing faculty in a given discipline. The sample size does not permit extensive extrapolation. The CUPA publication arrays salary averages by Carnegie classification, control, and region. Participating schools also receive benchmark analyses of their data versus national averages by CIP code. The data on new assistant professors is useful in making assumptions about the number of new hires by discipline. These data are often used to document equity issues in faculty salaries by discipline for men and women. Annual data are collected electronically for full-time instructional faculty by gender and rank, with a breakout for new assistant professors. Every other year, ethnicity data are also collected, with approximately 65 institutions participating. In order to be listed in the analytical reports which aggregate data by discipline, a CIP code must be used by more than a few institutions. If there is no match, the data are rolled into the other (99) version of the four digit CIP code and then, if necessary, aggregated to the (01) version of the CIP code. Data reports are provided to participating institutions, but without institutional identifiers. Institutional research offices may request special studies of their peers at a cost of $120. This allows them to weight the data to match their own profile of disciplines. Reports on faculty salaries by CIP code are published at a cost of $60, though participants receive a free copy. The \"Distribution Study\" is published every two years with the ethnicity data, with the 1997-98 data published in Summer, 1998. Some institutions exchange data files with their peers. A subset of institutions is routinely analyzed by the University of Alabama for the Southern University Group (SUG). For documenting the faculty population, the Oklahoma State survey provides data on gender within ethnicity by rank at the CIP code discipline level, but only for a relatively small, somewhat homogeneous sample of land grant institutions. This is still a critical source for setting faculty availability statistics by discipline, gender, and ethnicity for the eight factor analyses for affirmative action reporting. (11) National Study of Postsecondary Faculty (NSOPF) The NSOPF survey was conducted in 1988 and in 1993 by NCES, with support from NSF and the National Endowment for the Humanities, and will be administered again in 1999. In 1993, institutional and faculty versions of the survey were collected. A department chair survey was administered in 1988. The 1993 NSOPF was administered by the National Opinion Research Center (NORC) at the University of Chicago. Information about the NSOPF is available on the Web at http://nces.ed.gov/surveys/nsopf.html. The NSOPF is the primary national survey of faculty activities, demographics, and attitudes. A two stage sampling procedure was used for the faculty questionnaire. First, 974 institutions were contacted, of which 817 agreed to participate. These institutions provided lists of faculty by discipline. Limited disciplinary data were keyed in order to over-sample four NEH disciplines. The sampling rate was also increased for full-time women and minorities. From the lists, samples with a measure of size of 41.5 faculty (41 or 42) per institution were developed, stratified by Carnegie classification and control. Most public and private research universities and most public doctoral universities were included (with certainty) in the sample. A total of 25,780 surveys were completed for a response rate of 86.6%. In analyzing the NSOPF data for 1988 and 1993, anomalies were detected in the number of part-time and health science faculty. The initial Data Analysis System (DAS) and analyses were revised and re-released after it was determined that the survey was not adequately administered to medical school faculty and that the weights of part-time faculty were incorrect due to problems in the institutional lists. The part-time issue has been corrected, but NSOPF still under-reports health science faculty. While data on discipline were collected with 149 possible fields, the sample was not stratified by discipline. For this reason and because of the problems with health sciences, the data should not be interpreted for population estimates by discipline, except by the broadest clusters of disciplines. For all other uses, such as comparisons of faculty workload, the discipline-specific data are sufficient. The NSOPF data are available from these sources: (1) in a data analysis system (DAS) on CD-Rom from NCES. The CD also includes data on most other non-IPEDS surveys administered through NCES, each with its own DAS. The Windowbased software allows filtered, two dimensional cross-tabs. Two versions of the software are provided, one for regular tables and one that 1 3 produces correlation matrices for further analysis in SAS or SPSS. The software produces a tab delimited text file with information on weights, cell counts, and standard errors; (2) DAS on the Web, an Internet-based version of the DAS. Users download and install the software, then upload/submit a table parameter file (TPF) to run queries. The DAS Website processes the TPF, generates a table, and the user picks up a PRN file with the results from an FTP directory. The Web DAS is kept current with recodes and new data administration, while the CD only documents the file at a point in time; microdata are available for controlled use under licensing agreements with NCES; (4) the National Data Resource Center is able to produce data tables from the NSOPF if the required analysis cannot be easily obtained with the DAS. ( 3)Numerous reports and studies of the NSOPF data are now available, including Faculty and Instructional Staff: Who Are They and What Do They Do? and Institutional Policies and Practices Regarding Faculty in Higher Education. A list of publications, most available online in PDF format, is provided at httpi/nces.ed.gov/pubsearch/getpubcats.idc?sid=011. It is important to note that the definition of faculty used for the NSOPF differs from that of the IPEDS S and SA. In order to gather data on all types of teachers, the institutional lists included full-time, part-time, permanent, and temporary instructional faculty and staff, along with non-instructional faculty. This is an important source of information on part-time and temporary staff. However, the reader must be careful in interpreting tables of NSOPF data to ensure that the correct faculty definition is used. In weighting the sample to the population, NORC first weighted the respondents by institutional type to the lists from institutions (approximately 500,000 faculty names). These data were then weighted again by institution to the 17 possible strata of Carnegie classification and control and the total faculty population as documented in the IPEDS S. The number of strata is uneven because there are no public, religious institutions. The institutional survey gathers information about instructional and non-instructional faculty hires, retirements, tenure policies, benefits, evaluation procedures, and downsizing for all types of faculty. Totals of instructional and non-instructional tenured and tenure track faculty were collected for Fall 1991 and Fall 1992 by institution. Faculty eligible for and granted tenure are documented. These types of data are extremely valuable in making assumptions about faculty mobility and the impact of certain policies such as early retirement programs. Final technical reviews have been completed for the 1999 NSOPF survey. According to NCES staff, the institutional lists will be sorted by discipline and each institutional sample size will vary in order to better estimate the population by discipline."}, {"section_title": "(12) HERl Faculty Survey", "text": "The Faculty Survey administered by the Higher Education Research Institute (HERI) of the University of California -Los Angeles is very similar to the NSOPF in its focus on faculty demographics, activities, and attitudes. Information about the HERI survey is available on the Web at http:// www.gseis.ucla.edu/herVfacultysurvey98.html. The survey administered in 1995 included 384 institutions and 33,986 respondents, for an overall response rate of 42%. Over the course of six surveys conducted since 1969, HERI has gathered data on 500,000 faculty at 1,000 institutions. The survey was administered again in 1998-99. This survey is an invitational sample and HERI charges institutions a fee, similar to the administration of the UCLA CIRP Freshmen survey. For 1998-99, the institutional cost was $325 plus $3.25 per returned survey. For the purpose of the survey, faculty are defined broadly. Depending upon whom institutions chose to sample, the survey includes employees who teach undergraduates, full-time administrators, full-time researchers, and faculty who teach only at the graduate level. The publication The American College Teacher: National Norms for the 1995-96 HERI Faculty Survey reports the results of this survey and is sent to participating institutions. The book is also available for purchase from HERI. The HERI sends a standard set of cross-tabs of the data to institutions and will prepare additional analysis of the data for a fee. \"National Norms\" were developed based on the portion of respondents who code themselves as undergraduate teaching faculty. The norms include all institutions which surveyed a minimum percentage of their faculty population, as determined from analysis of IPEDS reports. The list of participating institutions was examined \"using a 23 cell stratification based on institutional type, selectivity, and control\" (Sax et al, 1996, p. 1). The sample was supplemented with 21 randomly selected institutions for the cells with low counts. The participation of 22 additional institutions was supplemented with funding from the Corporation for National Service. For documenting the faculty population, the HERI faculty questionnaire provides data on gender within ethnicity by rank within tenure status by Carnegie classification and control. The instrument does not permit coding as non-tenure track, only if and when tenure was awarded. Many types of faculty policy questions may be addressed. It is particularly interesting to example changes in the data over time. (13) Doctoral Program Rankings -1995 The National Research Council (NRC) collected data on faculty as part of its doctoral program rankings project in 1982 and 1995. Information about the NRC Doctoral Rankings project is available on the Web at http://www.nap.edu/readingroom/books/researchdoch For the 1995 study, the NRC gathered data on 41 fields selected because of three factors: the number of Ph.D.s produced nationally, the number of programs training Ph.D.s within a particular field, and the average number of Ph.D.s produced per program. Based on reports from Institutional Coordinators (lCs) who provided information about their programs, 3,634 research-doctorate programs at 274 U.S. universities were targeted in the 1995 project. Of these, 105 were private and 169 were public institutions. Data on specific faculty were taken from \"various sources of information,\" including the Doctorate Records File of SED data. Using the combination of IC reports and faculty survey instruments, data were gathered about program ratings, Ph.D. recipients, women and minority enrollment and degree patterns, and the number of faculty. Sources for data on the NRC Doctoral Program rankings include: (1) the book Research-Doctorate Programs in the United States: Continuity and Change (NRC, 1995). (2) an executive summary of the book, along with HTML versions and Excel spreadsheets of key tables which are available online; a CD-Rom which is available for purchase and includes all data, including faculty names, used in the study; and 4WebCASPAR includes the 1982 NRC data, which were actually collected in 1980, with publication data from even earlier. Hopefully, NSF will add the 1995 data soon. It is possible to document the faculty population by discipline for research programs, using the NRC data. Massy and Goldman (1995) did this using the 1980 NRC data for their classic study The Production and Utilization of Science and Engineering Doctorates in the United States. Data about gender, ethnicity, and tenure status of faculty are not collected. The NRC data allow users to get a portrait of research programs by discipline by institution. It is an excellent source for many kinds of benchmarks of research productivity by discipline."}, {"section_title": "(14) AAUP Faculty Compensation Survey", "text": "The American Association of University Professors (AAUP) collects data similar in many ways to those collected with the IPEDS SA. These include aggregate, institutional data on salaries, fringe benefits, and the headcount number of full-time instructional faculty by gender, rank, and contract length. In addition, the AAUP survey gathers data on salaries and percentage increases for continuing instructional faculty, allowing it to calculate yearly trends in faculty salaries. The AAUP also collects benefits data by rank and contract length. Information about the AAUP survey is available on the Web at http://www.igc.apc.org/aaup/indexfcs.htm. Data from the survey are published in the March/April issue of the magazine Academe as the \"AAUP Annual Report on the Economic Status of the Profession.\" The report details salary increases against inflation, analyzes geographic differences, compares salaries by Carnegie classification, and focuses on gender-based salary Custom faculty data may be ordered from AAUP for peer comparisons. Seven different items of data are offered, at a cost of between two and six dollars per school per item. Institutional identifiers are provided. Since the bulk of the survey data are identical to the SA, the AAUP would normally offer little of new interest for researchers except the salary increase comparison. However, the AAUP data are released in March/April, months before the first release of SA data. Due to this timing, the AAUP is the primary source for the national dialogue about faculty salaries and compensation and the data are widely cited in the media. The regional and Carnegie breakouts allow for various levels of peer comparisons. The AAUP data may be used for many classic studies of faculty, such as the demise of tenure, reliance on nontenure track faculty, gender equity, and salary compression."}, {"section_title": "(15) NCES IPEDS Fall Enrollment Survey (EF)", "text": "This survey collects enrollment data for every postsecondary institution eligible to participate in Title IV financial aid programs. Institution-specific data are collected by race and ethnicity, gender, degree level, full-/part-time status, and year of study. Enrollment data by age and residency status are also collected as biennial components of the survey. Information about the EF is available on the Web at http://nces.ed.gov/Ipeds/fallenrollment.html. The Fall 1997 IPEDS EF survey included 6,645 postsecondary schools, with 6,278 respondents for a response rate of 94.5%. Data were imputed for missing schools, based on previous years' submissions, in order to make national enrollment estimates and projections. EF data are available from these sources: (1) files from Fall 1988 to Fall 1997 are available for download at the NCES Website with extensive documentation; (2) the IPEDS CD-Rom, with five years historical data; (3) For faculty studies, the most common use of the EF is to calculate faculty workload ratios. For this purpose, headcount is inadequate and full-time equivalent (FTE) student is appropriate. The NCES has shared its method for calculating FTE from headcount using the EF and this is widely adopted among institutional researchers. The number of full-time students is equated to FTE without any calculation. The part-time student headcount is divided by three. Full-and part-time FTE are added together to estimate the total student FTE and it is this student FTE figure which is used for many ratios of funding and faculty workload. This method is particularly problematic for community colleges and urban institutions which enroll a large number of part-time students. For faculty studies, the most common use of the IC is to calculate student FTE data for faculty workload ratios. If the NCES calculation from the EF is inadequate, another method is to use the student credit hour (SCH) data collected on the IC. For internal purposes, many institutions calculate FTE based upon credit hour activity, using agreed upon conventions such as 15 undergraduate credit hours equals one FTE or 12 graduate credit hours equals one FTE. There are different opinions on calculating FTE from SCH for graduate and professional activity, such as whether to divide by 12 or 15 SCH. It is important to be consistent in this application. However, NCES staff report that the SCH data reported on the IC are inconsistent and not clean enough for national use. One topic for discussion in the redesign of the IPEDS forms is the possibility of collecting student FTE directly on the IC survey, along with SCH. There are other problems in comparing the IC data, such as different extract dates. (3) (17) NCES IPEDS Finance Survey (F) This survey collects data on revenues, expenditures, scholarships, plant debt, plant assets, endowment, fund balances, and hospitals by institution. The finance survey is, in many ways, the most complex, misunderstood, and potentially fruitful survey in the IPEDS system for peer comparison purposes. Information about the F is available on the Web at http://nces.ed.gov/Ipeds/finance.html. Traditionally, the dissemination of IPEDS files does not differentiate between public and private control. With the establishment of new accounting standards from Financial Accounting Standards Board (FASB) and Governmental Accounting Standards Board (GASB), different editing and data administration procedures are necessary for public and private institutions. As of February 1999, only the public version of the 1996-97 IPEDS F has been released. From a universe of 1,802 public postsecondary schools, there were 1,714 respondents for a response rate of 95.1%. For the 1995-96 data, the total number of private and public schools in the universe was 3,965, with 3,520 respondents for a response rate of 88.8% Finance data are available from several sources: (1) files from 1988-89 to 1996-97 are available for download at the NCES Website; (2) the IPEDS CD-Rom, with five years of historical data; the NCES National Data Resource Center; (3) For faculty studies, there are several critical ratios using the IPEDS finance data. These usually involve combinations of instructional expenditures, research expenditures, and library expenditures per type of fulltime faculty (using the S and/or SA). (5)"}, {"section_title": "Conclusion", "text": "Clearly, the national datasets have much to offer policy analysis, institutional research, peer comparisons, and other types of research about faculty. The 11 datasets about faculty, two datasets about student enrollment, two datasets about degrees, and two datasets about institutional activity represent a wealth of information, rich for mining on a myriad of questions. Potential users should not be daunted by the complexity of these surveys. While there is a natural learning curve with understanding the data elements, value labels, instrumentation, and report structures of each survey, this is really an issue of learning to use any dataset well. What are the meaningful ways to group, sort, aggregate, merge, recode, and query data? Once users begin to think this way about data, it is much easier to approach a new dataset and explore ways in which is could be used. As documented in the reviews, all of the datasets are available for free in some census date and format except for the CUPA, AAUP, HERI, and Oklahoma State surveys."}, {"section_title": "With the NCES Interactive IPEDS Database and", "text": "WebCASPAR, analysts have user-friendly and relatively quick methods to conduct institutional or other types of comparisons. The DAS on the Web for NSOPF and the online version of SESTAT are more complicated to use, but represent a significant improvement over requirements for license agreements and SAS/SPSS programming. For those who prefer the SAS environment or Microsoft Access, there is extensive documentation from NCES for its data files. In reviewing the datasets, some brief examples were described about ways in which they might be used for policy analysis. Virtually any area of faculty research may be examined with these data. For studies of faculty retirement, the NSOPF and SDR are valuable resources. Basic ratios of faculty workload may be calculated using the IPEDS S, SA, and EF survey data. More complex analysis of workload may be conducted with the NSOPF and HERI. Campus surveys of faculty may be benchmarked against questions in the national datasets. Table 2 outlines typical research topics and potential data sources (Appendix B). This listing is not exhaustive and users may find many new ways to use the datasets for their purposes. The table is prepared as a guide to where to begin looking for data to respond to broad policy questions. This evolution in the dissemination and diffusion of the national datasets is possible because of significant efforts by NCES and NSF to improve access to the data. The National Postsecondary Education Cooperative with its goal of \"Better Decisions Through Better Data\" is also critical to this effort. Another important effort is the program of research grants and institutes titled \"Improving Institutional Research in Postsecondary Educational Institutions.\" Managed by the Association for Institutional Research, with financial support from NCES and NSF, one of the goals of this project is to \"foster the use of the federal data bases to inform researchers on institutional research in postsecondary education\" (AIR, 1998, http:llairweb.org/ GDRES99.html).  "}, {"section_title": "APPENDIX A", "text": ""}]