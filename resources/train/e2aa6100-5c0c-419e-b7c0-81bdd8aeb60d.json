[{"section_title": "Abstract", "text": "In this work, we selected predictive variables in a classification framework, using the collected measurements X = {x n } N n=1 of the aMCI subjects as input variables. A group label t = {t n } N n=1 , t = \u00b11 was used to indicate whether a subject converted to AD within the 2 years follow-up period. At last, we employed the predicative automated relevance determination (pred-ARD) method to conduct variable selection and classification on the training data to obtain a classifier w.\n1 Data used in the preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (http://www.loni.ucla.edu/ADNI). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete list of ADNI investigators is available at http://adni.loni.ucla.edu/research/active-investigators/. Pred-ARD is a hierarchical Bayesian approach that determines the relevance of input variables based on their prediction performance. It extends the classical Bayesian variable selection method, automatic relevance determination (ARD). Both ARD and pred-ARD model the prior distribution of the parameters in the classifier to explicitly represent the relevance of different input variables. It is usually accomplished by assigning hyperparameters to determine the range of variation for the parameters relating to a particular input variable. In particular, the ARD method models the width of a zero-mean Gaussian prior on those parameters:\nwhere i = 1, . . . p, and p is the number of variables. In ARD, the hyperparameters are estimated to maximize the model evidence (marginal likelihood): p(t|X, \u03b1) = p(t|X, w)p(w|\u03b1)dw\nwhere\ndenote data, and t = {t n } N n=1 , t = \u00b11 denoted group labels, As described before."}, {"section_title": "CLASSIFICATION BASED ON PREDICTIVE AUTOMATED RELEVANCE DETERMINATION", "text": "In this work, we selected predictive variables in a classification framework, using the collected measurements X = {x n } N n=1 of the aMCI subjects as input variables. A group label t = {t n } N n=1 , t = \u00b11 was used to indicate whether a subject converted to AD within the 2 years follow-up period. At last, we employed the predicative automated relevance determination (pred-ARD) method to conduct variable selection and classification on the training data to obtain a classifier w. 1 Data used in the preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (http://www.loni.ucla.edu/ADNI). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete list of ADNI investigators is available at http://adni.loni.ucla.edu/research/active-investigators/. Pred-ARD is a hierarchical Bayesian approach that determines the relevance of input variables based on their prediction performance. It extends the classical Bayesian variable selection method, automatic relevance determination (ARD). Both ARD and pred-ARD model the prior distribution of the parameters in the classifier to explicitly represent the relevance of different input variables. It is usually accomplished by assigning hyperparameters to determine the range of variation for the parameters relating to a particular input variable. In particular, the ARD method models the width of a zero-mean Gaussian prior on those parameters:\nwhere i = 1, . . . p, and p is the number of variables. In ARD, the hyperparameters are estimated to maximize the model evidence (marginal likelihood):\nwhere\ndenote data, and t = {t n } N n=1 , t = \u00b11 denoted group labels, As described before.\nThe Pred-ARD method, proposed by Qi et al. [1] , assigns hyperparameters \u03b1 in the same fashion, but estimates them to optimize the predictive performance\nAs a result, many elements of \u2423 go to infinity, which naturally prunes irrelevant variables in the data. Furthermore, this method uses Expectation Propagation (EP), a more accurate approximation method, for pred-ARD model estimation, and uses the LOO generalization error obtained directly from EP as estimates of predictive performance.\nUsing pred-ARD, we can not only select relevant variables, but also learn the posterior distribution of classifier p(w|D, \u03b1) from the training set D = (\nThe posterior distribution can then be used to estimate the posterior predictive distribution for a new data point using Equation (3). In this two-class classification problem, we adopt the simple decision rule:\nUsing this method, we can estimate the posterior distribution p(w|D, \u03b1) of the classifier, where only variables relevant to separating converters from nonconverters have nonzero weights. Moreover, we can rank the importance of these variables to the classification by using their corresponding weights. The larger the magnitude of the weight, the more significant the variable is for distinguishing the two groups. Finally, we can use p(w|D, \u03b1) to calculate the prediction probability on testing subject."}, {"section_title": "DISCUSSION ON CLASSIFICATION METHODS", "text": "The classification method we employed in this paper is a wrapper method that jointly select features while building the classification model. This kind of wrapper method can help to more accurately find only relevant biomarkers for predicting MCI to AD conversion, compared with a filtering approach. Secondly, the Bayesian Supplementary method we used is designed to build models that can be generalized well to other datasets, especially when the available training set is relatively small (63 subjects), and has been shown to provide better prediction performance compared with benchmark methods such as support vector machines [1] . This Bayesian method is also computationally efficient with the advanced approximation method for inference; in the present study, it took about 16 seconds to build the model with 63 subjects and 22 variables on a standard PC. Furthermore, as a Bayesian method, it estimates the probability distribution of the classifier, instead of making a point estimation. Using these classifiers built with this Bayesian method, we can readily estimate the probability of conversion (0-100%) for any MCI subject using their corresponding biomarker measurements. Prediction accuracies shown in this paper were calculated with a probability threshold of 50%. Using this threshold, test patients with predicted conversion probability >50% were diagnosed as MCI to AD converters and patients with predicted conversion probability \u226450% were diagnosed as nonconverters. When applying these classification models, we can change the probability threshold to increase either sensitivity or specificity. The change of classification threshold will subsequently affect the cost saving and patient-screening time when using this method for patient enrollment. For example, if we change the classification threshold to 85% (probability >85% are converters and probability \u226485% are non-converters), we would potentially further enrich our population with patients more likely to convert to AD. Accordingly, we would need to recruit fewer patients and reduce the cost associated with the clinical trial. However, since we are using more rigorous inclusion criteria (higher threshold), we would need to screen more patients and increase the cost and time associated with screening. These scenarios can be quantitatively simulated with these classification models to assess the logistical benefit and select the best threshold to use for patient selection in MCI clinical trials. As demonstrated in the results, the use of biomarkers (including CSF and imaging modalities) can generate strong predictions with >80% of subjects assigned to the first and fourth quartiles of prediction probability p (i.e., p < 25% or p > 75%). In contrast, screening based on genotype and cognitive tests alone generates less informative predictions with borderline conversion probabilities, with 75% of subjects assigned a prediction probability between 25 and 75%.\nIn theory, for prospective application of our model in a clinical trial, it may not be necessary to use the same data acquisition or analysis methods as long as equivalent measurements, expressed in the same physical units, as those used to build the classification model are used. In practice, however, care must be taken for vMRI measures in particular; at the present time different structural MRI segmentation software packages and methods are likely to generate slightly different values for nominally the same brain structures. This is exemplified by the current ongoing effort to harmonize the manual delineation of the hippocampus [2] . Similarly, for FDG-PET, a composite SUVR measure should use consistent mask and reference regions. Thus, a classifier of the type presented here should be trained using summary measures generated using the same analysis method that will be applied in its prospective application to clinical trial data."}]