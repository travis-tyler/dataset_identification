[{"section_title": "CHAPTER 1: INTRODUCTION", "text": "Disasters are not just one-off phenomena and represent the results of continuous social, economic, and environmental processes over time (Lavell 2008, p. 82). Vulnerability provides a conceptual link between disasters, built environment, and people. This research applies exploratory regression methods and spatial econometric models to examine the relationships between hazard vulnerability science, disaster impact modeling, and disaster management practice in the context of Atlantic Hurricanes in the United States from 1999-2004. It considers an operational framework that fuses those disciplines into an all-hazards, all-threats regime to provide a more practical mechanism for informing disaster management policy. Figure 1 shows a map of the storm tracks for the nine (9) hurricanes and Table 1 lists the disaster declaration numbers. These observations represent the hurricanes that made landfall and received presidential disaster declarations during the study period that data was made available for this research. FEMA registers presidential disaster declarations with a unique identification number in the National Emergency Management Information System (NEMIS), more commonly referred to as a DR#, to track and monitor activities relating to these events.  Gall 2007). While the occurrence of natural disasters cannot be prevented, losses from their impacts can be minimized through better understanding of natural disaster losses and informed policies that are risk-based, linking disaster operations, preparedness, and mitigation. The United States government responds to more than 50 declared disasters or emergencies per year totaling more than $3 billion annually in relief and recovery expenditures (Garrett and Sobel 2003). These facts are attributed in part to political motivations, as the Robert T. Stafford Disaster Relief and Emergency Assistance Act (Public Law 93-288) was amended in 1988 to provide the US president more discretion in declaring natural disasters Sobel 2002, Sobel et al. 2007). A more holistic interpretation is that a variety of factors from settlement patterns, land-use practices, and global climate change have placed society increasingly in harm's way. This perspective is underscored by the Gulf Coast hurricanes of Katrina and Wilma making landfall in 2005; in which, more than 1,500 people perished and initial direct losses covered by federal disaster assistance programs exceeded 25 billion dollars as these storms became the deadliest and costly hurricanes in United States history (FEMA 2013). One way to counter the upward trend in disaster losses is through mitigation and preparedness strategies to reduce risk as people continue to settle in more hazard prone areas. The United Nations identified comprehensive mitigation and preparedness planning as critical opportunities to reduce future losses and costs associated with disasters at the World Summit for Sustainable Development in 1992 (UN/ISDR 2004). The causes of risk must be identified in order to assess the effectiveness of both corrective and prospective mitigation measures to properly inform response and recovery plans and appropriately 5 influence disaster management policy . Neal (1997) indicated that the disaster management lifecycle has been traditionally viewed as an over-simplified heuristic device due to the lack of holistic understanding of the four phases of mitigation, preparedness, response, and recovery. Geis (2000) reiterates this view noting that \"everything is interconnected in [disasters and emergency management] and a holistic, integrated approach is required\" (p. 152). The complexity of emergency management, as realized through the disaster management lifecycle, depicted in Figure 2, below is often misinterpreted as a sequential process of cascading activities where preparedness precedes response, followed by recovery, ending with mitigation. should inform policy and preparedness activities rather than a finite activity necessitated by disaster. This intellectual shift in the disaster management community, while significant, belies linkages between pre-event mitigation planning envisioned through hazard vulnerability indices and the conduct of disaster operations supported through event-specific impact modeling. Those same indicators used to quantify community vulnerability as part of on-going mitigation planning activities are seldom validated against ground-truth data from real-world events nor aligned to impact modeling efforts used by disaster response teams to support critical life-saving, damage assessment and recovery missions. The difficulty in achieving effective disaster risk management has been partly the result of a lack of a comprehensive framework of disaster risk that facilitates multidisciplinary impact modeling and subsequent mitigation strategies . McEntire (2004) suggests that the concepts of hazard vulnerability \"may help us to better describe and comprehend the true nature of disasters, since they deal with the goals of liability reduction and capability enhancement (i.e.: reducing risk and susceptibility and raising resistance and resilience)\" (p.11). Alexander (2006) argues that \"the key problem of vulnerability\" serves \"as a far greater determinant of disaster risk than hazards themselves\" (p.2). Gall contends that hazard vulnerability, risk, and capacity assessments form the basis for effective mitigation and preparedness strategies (Gall 2007). According to Cardona, these assessments are an unavoidable and necessary step in evaluating the performance of disaster management policy and risk reduction strategies (Cardona 2005b). ). To avoid skewed vulnerability assessments and decision-making, hazard researchers need to take stock of existing indices (Gall 2007). Without calibrated measures of vulnerability and risk, applied to impact models utilized across the disaster management lifecycle, mitigation cannot be effective and losses will be difficult to reduce over time (Cutter 2003 andGall 2007, p. 4) as evidenced by the magnitude of federal disaster losses in the United States over the preceding decade. To date, substantial research has been conducted by social and physical scientists on disaster management with an emphasis toward hazard vulnerability and risk assessments to help focus efforts to strengthen communities and enhance their local resiliency. A multitude of hazard vulnerability and risk indices have been realized through this applied research. While this research has contributed to our understanding of vulnerability; it has done little to improve our ability to identify, measure, and reduce disaster risk (Birkmann 2007). These hazard indices often do not represent the true nature of a hazard or vulnerability as they are quantitative, subjective measures that act as proxies for natural hazard susceptibility (Cobb 2001, Cobb andRixford 1998). Cardona states that \"most existing indices and evaluation techniques do not adequately express risk and are not based on a holistic approach that invites intervention\" (2005a p. i). In many cases, indices were defined based on the availability of data rather than the information that truly represents the hazard (King 2001). Additionally, there is little research validating these indicators and no framework that integrates hazard 8 vulnerability assessments with disaster operations and associated impact modeling activities. In other words, research needs to establish linkages between the factors of vulnerability and the elements of disaster impact using empirical data from federal disaster assistance programs. Federal Operating procedures for Emergency Support Function #5 of the National Response Framework (NRF) compiles situational reports based on essential elements of information (EEIs) that cover population, infrastructure, and economic conditions. These EEIs are intended to serve as indicators for mobilizing federal assistance programs required to facilitate community recovery and rebuild. This dissertation attempts to address Cardona's concerns by examining hazard vulnerability based on disaster management policy and practice. It compares the social vulnerability index, a proxy measure of vulnerability, with ground-truth data that represents actual impacts from Atlantic hurricane disasters. Schmidtlein et al. (2008) suggests that the inability to assess the validity of vulnerability indices is due to \"the complexity of factors contributing to vulnerability, no variable has yet been identified against which to validate such indices\" (p 3-4). Cutter et al. (2003) attempted to test the reliability and usefulness of the social vulnerability index (SoVI) to predict disaster impacts using the number of presidentially declared disasters at the county level. This examination yielded no statistically significant results. This lack of statistical correlation may be a reaffirmation of the theory about the political nature of disaster declarations. Downton and Pielke (2001) argue that disaster declarations are often treated as political rewards rather than as a result of disaster impacts. An alternate interpretation of the finding from Cutter et al. (2003) may suggest a dissonance between the concepts of vulnerability and the impacts of a disaster. Or the lack of correlation may indicate that there is no single variable that can be used to authenticate vulnerability indices, but validation must come from a multivariate approach. Questions like these indicate a need for further research in this area and the validation of hazard vulnerability indexes as useful instruments for formulating effective disaster management policies. Without applied research that demonstrates a direct link between vulnerability science and disaster impact, vulnerability indexing will continue to be considered an academic exercise (theoretical endeavor) rather than a practical tool for mitigating disaster risk. Empirical based research on vulnerability indicators and indices will provide much needed insight into the validity of hazard vulnerability indicators to accurately assess the level of community susceptibility from Atlantic Hurricanes. It also helps bridge the research policy nexus described by Cutter et al 2008 (p. 598) and improve our understanding of the components of vulnerability in the context of actual disasters based on empirical data. This will help progress vulnerability science past the \"leap of faith\" conundrum expressed by Adger (2006, p. 275) into a reliable metric based on proven indicators. Reliable hazard vulnerability indicators will go a long way toward understanding the predictors of hurricane disaster losses, thereby determining the factors most important in explaining the behavior of such losses. This knowledge will also help better enlighten decision-makers on the dimensions of hazard vulnerability to hurricanes and inform subsequent policies and mitigation strategies. Additionally, an operational framework for impact modeling that applies validated hazard vulnerability indicators and incorporates the geographic characteristics of hurricanes would be a crucial tool toward ensuring public safety and economic stability, given the heightened risk of future catastrophic hurricane disasters along the Atlantic-Gulf coast of the United States. Aligning indicators used by mitigation planners to determine hazard vulnerability, to those indicators used by disaster operators to derive impact models should result in better community preparedness and resiliency, improve disaster response and recovery efforts, and produce more informed policies. Such a model would help to expedite disaster recovery efforts, by ensuring appropriate resources are available to aid individuals and families and enable community rebuild. Theoretical contributions would likely serve as a grounding agent for many of the scholarly premises influencing disaster management research. McEntire (2004) suggests that disaster management theory grounded in reality is more likely to generate theories with practical implication; while theories based on faulty assumptions will produce conclusions that will inevitably be problematic. To put it more bluntly, \"what gets measured, gets managed\" and what the hazard research community attempts to measure and understand needs to be validated (Drucker 1954, Gall 2007."}, {"section_title": "RESEARCH OBJECTIVES", "text": "The purpose of this dissertation is to examine the relationships between hazard vulnerability indicators, disaster impacts, and the essential elements of information (EEIs) that drive disaster operations with the objective of establishing an operational framework that integrates social vulnerability indicators with the modeling of community impacts to 11 serve as a proxy for estimating the likelihood of and magnitude of direct federal assistance (i.e., quantified losses from a declared disaster) expected for Atlantic hurricane disaster declarations. It uses the following definitions of hazard and social vulnerability as a conceptual anchor. These definitions are both widely recognized by the hazard science community and consistent with U.S. disaster preparedness policy. Hazard vulnerability or \"vulnerability to environmental hazards means the potential for loss. Since losses vary geographically, over time, and among different social groups, vulnerability also varies over time and space.\" (Cutter and Emrich 2006). \"Social vulnerability to natural hazards is the potential for loss and the complex interaction among risk, mitigation, and the social fabric of a place\" (Schmidlin et al. 2009) and \"is defined as the susceptibility of social groups to the impacts of hazards, as well as their resiliency, or ability to adequately recover from them.\" (Cutter and Emrich, 2006;Sapam Ranabir Singh, Mohammad Reza Eghdami and Sarbjeet Singh, 2014). Demonstrating linkages between disaster impacts and vulnerability indices provides a validation point for the use of risk-based vulnerability assessments as a practical tool for creating local strategies and prioritizing the efforts necessary for building more resilient communities. It also provides a starting point for considering a vulnerability indexing method comprised of impact model simulations calibrated by empirical data from historical events rather than general socio-economic indicators or national estimates of loss. This approach is very similar to that employed by the National Hurricane Center (NHC), and validated by the meteorological community, to produce the Sea, Lake, and Overland Surges from Hurricanes (SLOSH) model. The SLOSH model is a numerical model that uses a proven set of characteristics (indicators) run through a set of statistical equations several thousand times to produce a composite measure of risk for an area based on estimated storm surge heights from historical, hypothetical, and predicted hurricanes (NHC website 2016)."}, {"section_title": "DISSERTATION STRUCTURE", "text": "The remaining content of this dissertation is organized as follows. Chapter two provides a synthesis of hazard vulnerability science complemented by a review of disaster management policy and practice. It includes a discussion of existing weaknesses and gaps in the development, application, and validation of sound measures to support place vulnerability, hazard assessment, and impact modeling activities. Chapter two also outlines current challenges moving beyond hazard vulnerability and impact modeling theory into applied research and toward operationalizing it to support the various facets of the disaster management lifecycle. Chapter three assesses the linkages between hazard vulnerability theory and disaster management policy and the selection of SoVI as the most applicable vulnerability index for evaluating whether hazard vulnerability indices can accurately predict exposure of a community to a hurricane disaster. It includes a comparative analysis of three hazard vulnerability indices (social vulnerability index, disaster risk index, and disaster preparedness index) and their underlying indicators to determine which variables are considered the most common elements of vulnerability. These vulnerability indices were chosen as representative of the three dimensions of hazard vulnerability: economic, social, and physical (UNDP / BCPR 2004). The social vulnerability index focuses on the social dimensions of vulnerability. The disaster risk index is more exposure based with an emphasis on ecological conditions. The disaster preparedness index emphasizes economic dimensions with additional elements for measuring emergency management factors to account for policy shifts toward prevention and mitigation strategies. Many of the preparedness factors in the disaster preparedness index are expressed as fiduciary terms such as funding for emergency operations, local funding for mitigation/planning, funding per capita, and public debt (Simpson 2006). Each index has its own merits and subsequent shortcomings. These characteristics will be fully discussed in this dissertation. Chapter four discusses the statistical analysis approach for analyzing the predictive power of SoVI with the Federal disaster assistance data and the FEMA Disaster Operations Impact Models for the selected hurricanes. The chapter includes a discussion of the data sources and processing routines used to prepare the data for statistical analysis. Data used in this study differs from previous research such as Cutter et al. (2003) in that they include both frequency counts and financial totals for federal mitigation and disaster loan assistance programs for individuals and public, at the county unit for each presidentially declared hurricane disaster included in the research sample. Cutter (2003) only evaluated SoVI for correlation with the single variable of frequency of presidentially declared disasters at the county level. Chapter 4 also introduces the regression scenarios used for analyzing the relationships between hazard vulnerability science, disaster management policy, and disaster operations practice and for validating the accuracy of SoVI to serve as a good predictor of community vulnerability for disaster management purposes. Chapter 5 attempts to quantify the findings from the comparative analysis completed in chapter 3 using a correlation analysis. It includes an exploratory regression to assist with variable selection for the OLS regression. Chapter 6 presents findings from the regression analysis based on the OLS models constructed to analyze the relationships between hazard vulnerability science and disaster management, using SoVI, and the FEMA disaster impact models. Chapter 7 addresses model bias in the OLS regression that includes skewness of data and missing variables. Chapter 8 seeks to resolve issues with spatial autocorrelation in the OLS regression by applying spatial econometrics and geographically weighted regression (GWR) to the same regression scenarios."}, {"section_title": "15", "text": "Chapter 9 provides a summary of findings and implications for future research, reasoning for a conceptual framework for operationalizing hazard vulnerability into disaster management practice by fusing impact modeling and vulnerability indexing, that integrates deterministic and probabilistic methods to incorporate results from historical, hypothetical, and predicted events to produce a more dependable, composite index for hazard vulnerability."}, {"section_title": "CHAPTER 2: LITERATURE REVIEW", "text": ""}, {"section_title": "DISASTER MANAGEMENT POLICY AND PRACTICE IN THE UNITED STATES: A BRIEF HISTORY", "text": "From a historical perspective, an increasing federalization of disaster policy and emergency management in the United States has been happening during the past sixty years. During this same period of federalization, disaster management practice has refocused from a reactive profession emphasizing preparedness (education and training) and response to a proactive emergency management approach emphasizing mitigation and protection measures (McEntire 2004, Sylves 2008. Disaster policy has shifted from its roots in civil defense where disasters are viewed as one-off local events best managed by local resources toward an all-hazards emergency management perspective that involves all levels of government with exceedingly more federal bearing (Sylves 2008). This one-off attitude means events are not assessed in context to other similar events to identify weaknesses or lessons learned that could affect operations for future like events or other events that may have similar characteristics because there was no effort to connect the dots or draw commonalities stressed in an all-hazards emergency management approach. Figure 3 illustrates these trends in disaster management and provides a timeline of key policy and legislation."}, {"section_title": "Figure 3: Timeline of Key Federal Disaster Policy and Legislation", "text": "The Federal Disaster Relief Act of 1950 (DRA) set forth a framework and process that underscores most of the major federal disaster legislation to this day (Sylves 2008). The 1950 DRA introduced the notion that state governors could request federal disaster assistance from the president. It also recognized the \"dual use\" philosophy of civil defense, where federal support to civil defense units provided overlapping benefits to emergency management. The 1950 DRA served as a companion measure for the Federal Civil Defense Administration (Sylves 2008). The Disaster Relief Act of 1966 furthered the \"dual use\" policy linking civil defense warning systems with natural disaster alerts; and that same year, Congress amended the 1950 Civil Defense Act to authorize funding on a \"dual use basis to prepare for the threat of enemy attack and for natural disasters\" (Sylves 2008, p. 50). These congressional attempts to unify disaster policy on the \"dual use\" premise did nothing to address the disjointed nature of federal disaster authorities 2010 1980 1985 1990 1995 2000 2005 1950 1955 1960 1965 1970 1975 Federal that were spread across several agencies, antecedents of the organic and reactionary developments of the preceding acts. Congress passed the Disaster Relief Act of 1974 to help remedy a series of presidential reorganizations of federal disaster functions across multiple agencies. This same law introduced three key concepts to federal disaster policy: 1) direct federal assistance to individuals and families affected by a disaster, 2) hazard mitigation as a precondition for federal disaster assistance, and 3) a multi-hazard approach to disasters (Sylves 2008). In many ways, the 1974 DRA signaled the start of a new trend in disaster management toward mitigation and the transition away from civil defense toward allhazard emergency management. introduce the notion of emergency support functions, and establish a single agency within the federal government dedicated to emergency management (Sylves 2008). Whitehouse policy memorandum 2011, \"the national preparedness goal shall be informed by the risk of specific threats and vulnerabilitiestaking into account regional variations -and include concrete, measurable, and prioritized objectives to mitigate that risk. The national preparedness goal shall define the core capabilities necessary to prepare for the specific types of incidents that pose the greatest risk to the security of the Nation, and shall emphasize actions aimed at achieving an integrated, layered, and all-of-Nation preparedness approach that optimizes the use of available resources.\" The national preparedness system is intended to \"allow the Nation to track the progress of our ability to build and improve the capabilities necessary to prevent, protect against, mitigate the effects of, respond to, and recover from those threats that pose the greatest risk to the security of the Nation\" and capacity \"for building and sustaining a cycle of preparedness activities over time\" (Obama 2011). PPD-8 signifies a further transition in disaster management policy from one of response and recovery to one of disaster risk management and vulnerability assessment."}, {"section_title": "22", "text": "\"The national preparedness goal shall be informed by the risk of specific threats and vulnerabilitiestaking into account regional variations -and include concrete, measurable, and prioritized objectives to mitigate that risk. The national preparedness goal shall define the core capabilities necessary to prepare for the specific types of incidents that pose the greatest risk to the security of the Nation, and shall emphasize actions aimed at achieving an integrated, layered, and all-of-Nation preparedness approach that optimizes the use of available resources. The national preparedness goal shall reflect the policy direction outlined in the National Security Strategy (May 2010), applicable Presidential Policy Directives, Homeland Security Presidential Directives, National Security Presidential Directives, and national strategies, as well as guidance from the Interagency Policy Committee process. The goal shall be reviewed regularly to evaluate consistency with these policies, evolving conditions, and the National Incident Management System (Obama 2011).\""}, {"section_title": "DISASTER MANAGEMENT THEORY, PRINCIPLES, AND CONCEPTS", "text": "During the period of federalization of disaster policy and practice, disaster management began to emerge as a field of study, coalescing around a handful of core principles and holistic theory. Since 1950, the concept of CEM has become the traditional theory of disaster management (McEntire et al. 2001, McEntire 2004. CEM organizes disaster management into disaster phases: preparedness, response, recovery, and mitigation that represent the full lifecycle of disaster (Sylves 2008, McEntire et al. 2001, McEntire and Marshall 2003, McEntire 2004 as depicted in figure 2. While CEM may represent the bedrock of federal emergency management theory, the concept has underlying weaknesses (McEntire and Marshall 2003). Neal (1997) determined that the four phases recognized by CEM are useful, but CEM in general is an over-simplified heuristic device that does not recognize the complexity of disasters (McEntire 2004). According to Britton, CEM fails to capture the wider political, economic, and cultural explanations of disaster (Britton 1999, McEntire and Marshall 2003, McEntire 2004. To address the weaknesses in CEM, several paradigms have emerged in the academic literature. Some scholars have suggested a move toward the concepts of disaster resistant community (Geis 2000, Armstrong 2000. Others have emphasized a need to focus on resiliency (Britton and Clarke 2000, Burby et al. 2000, and Buckle et al. 2000. Boulle et al. (1992), Berk et al. (1993) and Mileti (1999) championed the concept of sustainability or sustainable hazards mitigation. Cutter (1996Cutter ( , 2001, Cutter et al. (2003), Blaikie et al. (1994), and Anderson (2000) recommended a focus on hazard vulnerability as a means to tie in all phases of disaster management. Regardless of its weaknesses, CEM attempts to provide a holistic view of the disaster lifecycle and its concomitant functions. Geis (2001) notes that \"everything is interconnected and a holistic, integrated approach [to disaster management] is required\u2026 (p. 152).\" Mileti (1999) observes that \"researchers have called for a broad view of the disaster problem\u2026 (p. 35).\" McEntire (2004) furthered this notion stating that \"comprehensive perspectives should become more valued in future disaster scholarship and that maintaining a reliance on the phases of disasters should be a priority in emergency management theory\" (p. 35). While it is clear more research on the complexities of disaster is required to better understand the disaster problem as described by Mileti (1999), scholars need to direct more research toward understanding and measuring the relationship between mitigation, recovery, preparedness and response (McEntire et al 2001, McEntire and Marshall 2003, McEntire 2004. The disaster management community historically has placed more emphasis on emergency response rather than disaster mitigation and recovery. This preference for response over preparedness has done little to address rising disaster losses (McEntire 2004). This is understandable given the limelight endeared by live video feeds of disaster victims, flooded homes, or streets filled with debris. Mitigation is not the sexiest of endeavors and more often than not goes unnoticed by the public until local protective measures fail during times of need. Although disaster policy and operations remain largely event driven, a paradigm shift in emergency response practice has taken place over the past fifty years from simply responding to disasters and providing relief to victims toward emergency management as a discipline to better prepare for, respond to, mitigate for, and recover from disasters (McEntire et al 2001, McEntire and Marshall 2003, McEntire 2004, Sylves 2008). This philosophical shift has been strengthened by enabling legislation passed by Congress incorporating mitigation into routine federal disaster operations and as a requirement for federal assistance for local preparedness activities and post-disaster relief. This paradigm shift has also been reinforced by acknowledgement of several core principles that have invariably guided federal disaster policy and local emergency management practice during this period. These fundamental tenets of disaster management are: \uf0b7 emergency management is a shared responsibility across all levels of government \uf0b7 emergency response is primarily a local responsibility \uf0b7 policy and practice should represent the full life cycle of disaster 25 \uf0b7 all-hazards approach to disaster management instead of maintaining unique and separate capacities PPD-8 characterizes an evolution in national emergency management policy and application of CEM theory. By joining the traditional pillars of the disaster lifecycle with the law enforcement and interdiction elements of Homeland Security through prevention and protection, PPD-8 represents a logical progression toward all hazards, all threats emergency management. Encapsulated by five mission frameworks: Prevention, Protection, Response, Recovery, and Mitigation and their supporting initial operating plans; PPD-8 engenders a culture of preparedness, bridging comprehensive emergency management with disaster risk management, recognizing that\" risk unmanaged leads to the occurrence of disaster\" (Yodmani 2001). With its notions of risk, vulnerability, and regional variation, it is reasonable to assert that PPD-8 is largely based on a Hazards-of-Place construct of vulnerability assessment. Other disaster management concepts also operate within the framework of CEM."}, {"section_title": "Many of these concepts and operating models are encapsulated by the National Incident", "text": "Management System (NIMS) that was established as federal emergency management doctrine under HSPD-5. NIMS covers the emergency management concepts of incident command system, unified command, multiagency coordination and addresses common terminology, training and qualifications, and information and technology to name a few. The NIMS is linked to PPD-8 and the coordinating structures of the underlying national preparedness system."}, {"section_title": "26", "text": ""}, {"section_title": "DISASTER OPERATIONS, IMPACT MODELING, AND ESSENTIAL", "text": ""}, {"section_title": "ELEMENTS OF INFORMATION", "text": "The National Incident Management Systems (NIMS) serves as the foundation for disaster operations across all levels of government and community involved in emergency management. The NIMS unites the practice of emergency management and incident response throughout the country by focusing on five key areas or components (preparedness, communications and information management, resource management, command and management, and ongoing management and maintenance) and leveraging existing structures such as the incident command system to create a comprehensive and proactive system for those responding to incidents or planned events (FEMA NIMS Fact Sheet 2012). Disaster operational units apply the principles of NIMS, Incident Command System (ICS), and the various frameworks under PPD-8 to manage the conduct and maneuvers necessary to assist in the response, recovery, mitigation, and future planning and preparedness activities related to an incident. Many of the functions necessary to support disaster operations are executed by emergency support functions (ESFs) per the National Response Framework that aligns to NIMS (NRF Fact Sheet 2012). FEMA serves as the federal lead for ESF #5: Emergency Management. ESF#5 operates at all levels of disaster operations, serving as the emergency support team for DHS and the information and planning section for the disaster field office. ESF#5 facilitates the overall activities of the Federal Government in providing assistance to one or more affected States, coordinating with the local incident commander, as well as mission and decision support elements through collection, analysis, processing, and dissemination of information about a potential or actual disaster or emergency to all parties involved (ESF 5 -Information and Planning Annex 2003). Standard operating procedures require that ESF#5 provide the initial assessment of the incident, work across the emergency support functions and mission support partners to compile timely and appropriate information on the incident, and disseminate necessary information to emergency managers and first responders. To achieve situational awareness, ESF#5 compiles situational reports based on essential elements of information (EEIs) from a variety of sources. These EEIs serve as the basis for understanding disaster conditions, forecasting potential impacts and consequences, provisioning key resources, tracking progress and ground crews, conducting current and future planning, and maintaining overall situational awareness of the incident. According to the ESF#5 -Information and Planning Annex, EEIs provide emergency managers early intelligence on the effect of a disaster on the population and infrastructure of an area and gage the resourcing requirements that might be required to support the incident response and recovery. For hurricane events, ESF#5 and disaster field units leverage hurricane storm track information supplied through the NOAA subtropical weather advisories published from the National Weather Service, storm surge information derived from the sea, lake, and overland surge (SLOSH) model outputs generated by the NOAA Coastal Services Center, and damage and impact assessments produced using the FEMA HAZUS-MH program (HLS GeoCONOPS v5.0 2013; FEMA Geospatial Standard Operating Procedures 2012). \"This information [from the EEIs] facilitates accurate assessment of what response activities and materiel are required to save lives, relieve human suffering, and expedite response and recovery operations. During the early hours of a disaster and in the absence of \"ground truth\" information such as actual on-site surveys or imagery, GIS, computerized predictive modeling, and damage estimation software may be used to develop initial estimates of damage. As soon as possible, actual onsite ground surveys will be performed. Sources may include a Federal-State Preliminary Damage Assessment (PDA) and information from Federal, State, and local government agencies, among others, to establish \"ground truth\"\u2026 (ESF#5 -Information and Planning Annex 2003). See appendix A. During the recovery and mitigation phases of disaster operations, public and individual assistance grant programs are initiated to support community rebuild and restoration and to provide citizens with housing and other needs. This direct federal assistance also includes grants issued through the hazard mitigation grants program to assist state and local governments with the development of hazard mitigation risk plans and with the implementation of long term mitigation measures to promote community resilience. The status of these projects and activities become EEIs within the situational reports produced by ESF#5. In many ways, EEIs act as indicators for assessing the scope and severity of a disaster and the ensuing actions required to support disaster operations and serve as outcomes measures for assessing the impact of the disaster and tracking progress toward recovery. Since EEIs are intended to reflect ground-truth and the effects of a disaster on population and infrastructure, it begs a comparison with the indicators used to conduct hazard vulnerability assessments and derive the associated hazard vulnerability / risk indexes. This comparative analysis may reveal any potential relationships between the practice of disaster operations and disaster risk management and help to validate if vulnerability indicators are true surrogates of exposure, susceptibility, and risk."}, {"section_title": "HAZARD VULNERABILITY AND COMPREHENSIVE EMERGENCY MANAGEMENT", "text": "Hazard assessment and vulnerability research offers one of the more promising approaches to CEM within disaster management research, fusing the science of mitigation with the practice of emergency response. McEntire (2004) suggests that \"vulnerability may [in fact] help us to understand the purpose of emergency management since it deals with the goals of liability reduction and capability enhancement (i.e., reducing risk and susceptibility and raising resistance and resilience (p. 11).\" As Cuny postulated in his work titled, \"Disaster and Development\", the rise in disasters is related to a rise in the vulnerability of people induced by the development of the built environment and that the increase in vulnerability is not uniform and varies across regions (Cuny 1983). From this perspective, vulnerability is the only aspect emergency managers have control over in the disaster equation and may provide the best venue for accurately describing and understanding the true nature of disasters. Yodmani notes that within emergency management the \"emphasis has shifted to using vulnerability analysis as a tool in disaster management\" as part of a more comprehensive approach to disaster risk management that encompasses \"three distinct but interrelated components: hazard assessment, vulnerability analysis, and enhancement of management capacity\" and the ongoing development of disaster operations (Yodmani 2001, p. 2). Taking this one step further, hazard assessment and vulnerability thereby extends the practice of mitigation performed through risk indices into the realm of response operations often accomplished through the application of impact models. The fusion of impact modeling with vulnerability indexing may offer the best opportunity for studying the complexity of disasters and their associated response and recovery operations, and gaining a better understanding of disaster phenomena and how impact models relate to vulnerability assessments to complete the CEM feedback loop of the disaster lifecycle. This is especially true when considering the large number of variables involved in the two processes."}, {"section_title": "HAZARD VULNERABILITY RESEARCH TRENDS AND CONCEPTS", "text": "Hazard assessment and vulnerability research is a relatively new paradigm in the social sciences only materializing as an important theoretical topic in the 1980s (Bohle et al. 1994, Rygel et al. 2005. Alwang et al. conducted a multi-disciplinary review of vulnerability research and concluded that \"practitioners from different disciplines use different meanings and concepts of vulnerability, which, in turn, have led to diverse methods of measuring vulnerability\" (2001, p. 2). Cutter et al (2003, p.1) also concluded that \"vulnerability has many different connotations depending on the research orientation and perspective\" (Dow 1992, Cutter 1996, 2003. According to Cutter, vulnerability is broadly defined as the \"potential for loss \" (1996, p.529). Balikie et al. define vulnerability as \"the characteristics of a person or group in terms of their capacity to anticipate, cope with, resist, and recover from the impact of a natural hazard\" (Kumpulainen 2006, p. 67). Other researchers define vulnerability as the capacity to be wounded (Kates 1985, Dow 1992. The United Nations Development Project Bureau for Crisis Prevention and Recovery defines vulnerability as \"a condition or process resulting from physical, social, economic, and environmental factors, which determines the likelihood and scale of damage from the impact of a given hazard\" (UNDP 2004, p. 11)."}, {"section_title": "The European Union Spatial Program Observation Network (ESPON) Hazards Project", "text": "defines \"vulnerability as a set of conditions and processes resulting from physical, social, economic, and environmental factors that increase susceptibility of a community to the impact of hazards\" (EPSON 2003, p. 12). Vulnerability encompasses the idea of response and coping, since it is determined by the potential for a community to react and withstand a disaster. Rygel et al. (2005) have determined that two main perspectives or camps on vulnerability have formed within the academic literature based on the difference conceptualizations of vulnerability (Dow 1992, Cutter 1996, Wu et al. 2002, Adger et al. 2004. Cutter asserts that a third perspective exists based on \"hazard of place\" (Cutter 1996, 2003, Rygel 2005. The first perspective treats vulnerability as a preexisting condition with an emphasis on potential exposure to hazards (Cutter 1996, Rygel et al. 2005). Cutter brands this perspective as an exposure-based model (Burton et al. 1993;Cutter 1996Cutter , 2001Cutter , 2003. Research from this perspective tends to assess the distribution of some hazardous conditions, the human occupancy of the hazard zone, and the degree of loss of life and property resulting from a particular event (Rygel et al. 2005). The second perspective on vulnerability advocates that not all individuals and groups exposed to a hazard are equally vulnerable and affected people display patterns of differential loss (Wu et al. 2002). This differential loss depends in part on the coping ability of those affected as well as exposure to the hazard (Anderson and Woodrow 1991, Dow 1992, Watts and Bohle 1993, Cutter 1996, Clark et al. 1998, Wu et al. 2002, Rygel et al. 2005. Coping ability in this context has been defined as a combination of resistance and resilience (Dow 1992, Cutter 1996, Clark et al. 1998, Wu et al. 2002. Resistance is expressed as the ability to absorb the damaging impacts of a hazard and continue functioning and resilience as the ability to recover from losses quickly (Rygel et al. 2005). Cutter refers to this perspective as vulnerability as a social condition, a measure of societal resistance or resilience to hazards (Blaikie et al, 1994, Hewitt 1997, Cutter 2001, 2003. The third perspective on vulnerability combines the elements of the first two perspectives and is referred to by Wu et al as the vulnerability of places framework (Wu et al. 2002, Rygel 2005. This perspective treats vulnerability as a biophysical risk and a social response within a specific geographic domain (Rygel 2005). Cutter expresses this perspective as the integration of potential exposures and societal resilience with a specific focus on particular places or regions (Kasperson et al. 1995;Cutter, Mitchell, and Scott 2000, Cutter 1996, 2003. This perspective attempts to address the \"vulnerability paradox\" described by Cutter to examine social and place inequalitiescharacteristics of community and the built environment. In this conceptualization, risk interacts with mitigation to produce hazard potential (Cutter 2003, p. 243). This construct is realized through the Hazards-of-Place model of vulnerability ( Figure 4) as a means to understand the components of vulnerability (Cutter 1996, Cutter et al. 2000Heinz Center 2002). "}, {"section_title": "MEASURING VULNERABILITY IN HAZARDS RESEARCH", "text": "Vulnerability science is not nearly as advanced as risk estimation science (Hill and Cutter 2002, p. 25). Measuring vulnerability is usually achieved by constructing a vulnerability index based on several indicators that are reflective of a phenomenon (Pine 2009). Gall (2007) characterizes a vulnerability index as \"an abstract theoretical construct in which two or more indicators of the construct are combined to form a single summary score\" (p. 13). This construct requires a careful balance between simplifying the phenomenon and providing sufficient detail to detect characteristic differences (Deiner and Suh 1997). The complexity of the quantitative analysis used to derive the vulnerability index increases as the number of indicators selected increases in order to represent the phenomena. This yields a \"complex measure [of vulnerability] that is almost impossible to verify, especially when the phenomena cannot be measured directly\" (Gall 2007, p. 18). The selection of vulnerability indicators is often subjective and descriptive having been chosen based on a particular theoretical framework or functional relationship (Deiner and Suh 1997). These indicators can be either direct variables of interest or proxy variables that serve as substitutes for the variables of interest (Gall 2007). Hill and Cutter (2002) find that current indices of vulnerability differ in indicator selection, statistical downscaling and incorporation of scale. Gall (2007) contends \"there is no generally accepted set of indicators to assess social vulnerability nor is there empirical evidence for the connectivity or relative importance of those indicators\" (p. 15-16). For example, indicators for the disaster risk index (DRI) are based on best-fit linear regressions or statistical relationships; while, indicators for the social vulnerability index (SoVI) are based on a combination of theoretical framework and functional relationships (Gall 2007, p. 17). The disaster preparedness index (DPI) also employs a combination approach to choosing its indicators. Additionally, \"vulnerability indices at all scales possess questionable reliability and explanatory power not only because of conceptual challenges but also because of the lack of empirical evidence, standards, and quality assessments in constructing these indices\" (Gall 2007, p. 19). Deiner and Suh (1997) find that vulnerability science is plagued by significant amounts of subjective judgment in the research process. Andrews et al. (1994) argue that many indices rarely have adequate scientific foundations to support precise rankings. Cash and Moser (2000) infer that vulnerability assessments are often conducted at geographic scales that differ from the scale at which management occurs. Clark et al. (2000) propose choosing a vulnerability assessment scale that is congruent with the level at which social-environmental interactions are particularly intense or problematic for that hazard and at which management occurs. Eakin and Luers (2006, p. 381) suggests that \"scale is not only a concern of the unit of analysis in research but also an issue of compatibility with decision making\". According to Gall (2007), \"implementation of theoretical knowledge in the form of vulnerability indices is currently subject to arbitrary choices by researchers\" (p. 28). This lack of transparency, empirical basis, and uncertainty poses a challenge to the reliability, voracity, and utility of vulnerability indices to deliver robust vulnerability metrics (Gall 2007). 2). It is relevant to note that increased land-use and economic development are considered contributing factors to the increased susceptibility and vulnerability of the coastal United States to hurricane damage. According to Gall (2007), \"the selection of the DRI indicators was guided by correlations with proxy measures and not by theoretical framework or expert opinion\" (p. 54). DRI is based on the methodology: Risk = Hazard * Population * Vulnerability. The DRI is a backwards looking vulnerability index as it considers vulnerability from the context of past events rather than attempting to predict vulnerability through statistical modeling (Gall 2007). \"All indicators are aggregated averages over a 21-year period from 1980-2000 (Gall 2007, p. 55) Tapsell et al. (2003), Cardona (2005a), and Davidson and Lambert (2001). According to Simpson (2006), the disaster preparedness index (DPI) is a composite result of the presumed relationship between community preparedness measures and the derivation of the vulnerability score as depicted in Appendix D. It is based on the equation: Vulnerability = hazard * probability * frequency * Vulnerability measures (VM). Unlike the DRI, the selection of indicators for the disaster preparedness index was driven by expert opinion among identified experts in vulnerability science (Simpson 2006) The social vulnerability index (SoVI) is based on the Hazards-of-place model posited by Cutter (1996a). However, it does not utilize expert opinion to determine the vulnerability indicators. It defines vulnerability through the interaction of biophysical and social conditions with the integrating mechanism as place. From the perspective of Hill and Cutter (2002, p. 15), \"understanding the social vulnerability of places is just as essential as knowing about the biophysical exposure.\" This approach allows for more direct insertion of location as a factor of exposure and better understanding of the role of geography as a determinant of vulnerability. It allows us a means to discern between disaster-prone and disaster-resilient communities and what factors influence both outcomes (Hill and Cutter 2002). In simple terms, \"SoVI quantifies the social vulnerability of U.S. counties to environmental hazards and results in a comparative metric that facilitates the examination of the differences in social vulnerability among them\u2026\" (HVRI SoVI\u00ae webpage 2013) 1 . SoVI is constructed based on an initial analysis of 250 variables of social vulnerability identified through a broader review of vulnerability research. Cutter et al. (2003) tested these 250 variables for multicollinearity producing a subset of 42 normalized variables. Using principal component analysis, Cutter et al. (2003) reduced the 42 independent variables to 11 factors that represented 76.4% of the variance. The 11 factors, depicted in Table 2 below, consist of personal wealth, age, density of the built environment, singlesector economic dependence, housing stock and tenancy, race, ethnicity, occupation, and infrastructure dependence. Schmidtlein et al. (2008Schmidtlein et al. ( , p. 1110 suggests that the \"SoVI algorithm does not appear to be substantially influenced by scalar changes, [and] it is sensitive to variations in construction.\" This highlights the need to validate SoVI using disaster outcome data to provide an empirical analysis of its ability to characterize community vulnerability.  occur. First, the study performs a qualitative analysis of hazard vulnerability indices using a pedigree matrix based on a qualitative taxonomy adopted from Gall (2007, p.33-34). This approach is widely used for critical analysis of indices and indicators (Gall 2007, Booysen 2002Eyles andFurgal 2002, von Schirnding 2002) and allows for an \"apples to oranges\" comparison of the scale and the composition of the social vulnerability, disaster risk, and disaster preparedness indices. These vulnerability indices were chosen as representative of the leading concepts in hazard vulnerability science considering the three dimensions of hazard vulnerability: economic, social, and physical (UNDP / BCPR 2004). The social vulnerability index focuses on the social dimensions of vulnerability. The disaster risk index is more exposure based with an emphasis on ecological conditions. The disaster preparedness index emphasizes economic dimensions with additional elements for measuring emergency management factors to account for policy shifts toward prevention and mitigation strategies. Many of the preparedness factors in the disaster preparedness index are expressed as fiduciary terms such as funding for emergency operations, local funding for mitigation/planning, funding per capita, and public debt (Simpson 2006). Hazard vulnerability indicators and disaster data are not free from bias regardless of the data source. Each hazard vulnerability index examined is based on certain theoretical aspects that emphasize different elements or components of vulnerability just as disaster management policy is influenced by currents of ideology. Cobb and Rixford (1998) contend that all indicator work has some political aspects that are value oriented and subjective in nature. Carly (1981) argues that all social indicators can and will be used to advocate particular political stances, and Cobb (2000, p. 20) claims that government data are subtly motivated by ideology. King (2001) suggests bias arises more from the misapplication of data based on availability rather than the applicability of the data to vulnerability. The goal is to compare and contrast the indices to understand the theoretical frameworks, structures, merits, and shortcomings of the vulnerability indices. The findings from this analysis answer the question regarding the most suitable vulnerability index for testing the hypothesis that hazard vulnerability indices can be used to accurately predict the exposure of a community to a hurricane hazard or the level of damages in the community if a hurricane disaster of similar size and magnitude did occur. The first step in the qualitative assessment is to input the characteristics for each vulnerability index into a pedigree matrix using the scoring criteria and ratings listed in Table 3. Based on the pedigree matrix scoring system, an index is ranked from poor to excellent by averaging the results for each characteristic. Table 3 shows that SoVI received the highest qualitative score amongst the three indices. SoVI received an average score of good (3.1) on the pedigree matrix. It received a score of good or excellent on 7 of 9 dimensions. SoVI is based on well-established theory in hazard vulnerability science and uses a composite approach to selecting indicators that relies on expert opinion and statistical relationships. The data used to produce SoVI is public domain and regularly maintained. However, SoVI uses proxy indicators to determine vulnerability rather than direct measurements. This resulted in a medium score for technique. There has also been limited empirical validation of SoVI with independent measurements warranting a score of 2 for validity. Overall, SoVI scored 27 out of a possible 36 points or 75% on the pedigree matrix. This is 36 percentage points higher than the next closest candidate index. The other 2 indices each scored below 50% with average scores of 1.6 and 1.1. The DRI scored 14 points out of a possible 36 or 39%. It achieved low scores for conceptual framework, representativeness, reliability, and validity. Previous research suggests the DRI has issues with documentation, repeatability of results, very weak and low validation of results, and methodological limitations (Gall 2007, Openshaw andAlvanides 2005;Wrigley et al. 1997). Gall (2007) found that \"bias related to hazard mortality ultimately diminishes the explanatory power of the DRI\" (p. 107), and that the DRI is \"contestable due to its implicit acceptance of ecological fallacy and/or modifiable areal unit problem since it neglects the socio-economic characteristics of its population at risk in demarcated zones\" (p. 110). The DPI received the lowest score of the indices included in the pedigree matrix receiving 10 points out of a possible 36 or 28%. This is partly due to limited application of the DPI. Research was scarce on the actual implementation of the DPI based on the conceptual 44 framework developed by Simpson 2006. It was also not clear if the data required to support the DPI were publicly available and maintained. The DPI received a score of 0 for sensitivity and reliability due to those factors. The theory behind the DPI was considered preliminary due to the limited availability of supporting research and many of the indicators used to comprise the DPI are based on survey or imputed data. These qualitative analysis findings indicate that SoVI is the most viable candidate index for testing the hypothesis. and disaster operations impact model variables (representing the disaster operations practice). FEMA produces the impact model variables using HAZUS-MH software and spatial algorithms that are consistent with ESF#5 operating procedures and the best practices described in the Homeland Security Geospatial Concept of Operations. The findings from this analysis answer the question whether hazard vulnerability theory and disaster management policy and practice share common foundations.    share common foundations. As SoVI is based on the hazards-of-place model posited by Cutter et al. (1996a), it defines vulnerability through the interaction of biophysical and social conditions using place as the integrating mechanism. SoVI was initially comprised of 11 factors, depicted previously in Table 2, personal wealth, age, density of the built environment, single-sector economic dependence, housing stock and tenancy, race, ethnicity, occupation, and infrastructure dependence. SoVI was updated by the authors following the 2010 Decennial census and release of the American Community Survey to one based on 29-variables representing 7 factors that account for 72.5% of the variance as compared to earlier versions that utilized 11 factors that made up 74.6% of the variance. The 7 factors included in the current version of SoVI are: personal wealth, race and class, age, Hispanic ethnicity, nursing home residents, gender, and Native American ethnicity. These factors are essentially a more calibrated subset of the previous 11 factors. This dissertation uses the more current 7 factors versions of SoVI as those were the data provided by the HVRI for this dissertation. 'During the early hours of a disaster and in the absence of \"ground truth\" information such as actual on-site surveys or imagery, GIS, computerized predictive modeling, and damage estimation software may be used to develop initial estimates of damage.' (ESF #5 -Information and Planning Annex 2003, p. 11) The comparative analysis conducted for this dissertation utilized a two-tiered approach using a pedigree matrix and variable crosswalk matrix. The pedigree matrix was used to compare the various dimensions of vulnerability indices to determine that This was accomplished using a comparative analysis based on a pedigree assessment of hazard vulnerability indices and a crosswalk mapping of variables across these disciplines. The pedigree matrix results argue that SoVI has the best pedigree compared with two other leading composite vulnerability indices. It also argues that SoVI was constructed to serve as a reliable metric for disaster preparedness and mitigation planning. According to Cutter et al (2003), SoVI provides the emergency management community and policy makers a useful tool to illustrate the geographic variation in social vulnerability, to identify areas where there is uneven capacities for preparedness and response, to target areas where resources might be used more effectively to reduce preexisting vulnerability and promote risk mitigation measures, and as an indicator in determining the differential recovery from disasters (Cutter et al 2003, HVRI SoVI webpage 2013. Today, SoVI is actively being used in hazard mitigation planning and disaster response and recovery by states and federal agencies (Emrich and Cutter 2016). SoVI was used in support of Hurricane Sandy along the Mississippi coast and New Jersey Shore and for the 2015 floods in South Carolina. Emrich and Cutter (2016) "}, {"section_title": "claim that", "text": "SoVI \"has high utility as a decision-support tool for emergency management\" turning \"historical disaster impact measures into actionable information for emergency managers, recovery planners, and decision makers because it empirically measures and visually depicts a population's (in)ability to adequately prepare for, respond to, and rebound from disaster events\" (Emrich and Cutter 2016). This chapter expands upon the findings from the comparative analysis conducted in chapter 3 and the work from Cutter et al. (2003) and Gall (2007) to quantify the theoretical foundations and to test the reliability and usefulness of SoVI to predict disaster impacts and form the basis for effective mitigation and preparedness strategies. It applies exploratory regression using ordinary least squares combined with spatial econometrics and geographically weighted regression to examine the relationship between the SoVI scores, federal disaster assistance outcome data, and impact model runs for nine (9) Atlantic hurricanes that occurred between the years 1999-2004. The hurricane disasters were selected based on the following criteria: a) geographic position along the Atlantic coastline, b) storm intensity between categories 1-5 on the Saffir-Simpson scale, and c) access to the micro-level disaster outcome data. The statistical approach proposed in this research provides a means to determine: a) if SoVI is a reliable metric for disaster management based on empirical data, b) quantify the relationship between the determinants of vulnerability and disaster policy and c) improve our understanding of the spatial dimensions of vulnerability."}, {"section_title": "52", "text": ""}, {"section_title": "DATA SOURCES AND PROCESSING ROUTINES", "text": "Statistical analysis was conducted at the county levelunit of geography -using three types of data: social vulnerability index, disaster outcome, and FEMA impact model data. A complete list of data sources incorporated into this research is listed in table 4 below including those that served as inputs for the FEMA impact models."}, {"section_title": "Table 4: Data Sources", "text": "The disaster outcome data are based on a sample of disaster declarations for nine hurricanes spread along the Atlantic seaboard representing 1037 county level observations. An observation is a county that received a disaster declaration (604) or was captured in the impact model (1037 unique). Each observation includes a SoVI score that was computed using the complete SoVI dataset of counties and county equivalents. Table   5 below lists the total number of observations for each hurricane. The frequency counts for those counties declared that were included in the analysis are depicted in Figure 6 below. There were 214 counties declared under multiple hurricane events included in the analysis. The breakdown is as follows: 8 counties were declared under 5 hurricanes, 9 counties were declared under 4 hurricanes, 20 counties were declared under 3 hurricanes,   "}, {"section_title": "Hurricanes", "text": "The social vulnerability index data was supplied by the Hazard Vulnerability Research Institute at the University of South Carolina (HVRI). The HVRI also provides a complete county-level dataset of the social vulnerability index (SoVI) developed by Cutter et al. (2003). The version of the SoVI dataset represented in this analysis is based on a more current iteration of SoVI that relies on statistical analysis from 29 of the original 42 variables of economic, demographic, and housing characteristics that hazard vulnerability research suggests influence a county's ability to prepare for, respond to, and recover from a natural hazard (Cutter et al. 2003). This updated version of SoVI is based on 7 factors that account for 72.5% of the variance. Table 6 below provides the complete list of SoVI variables with component loadings for each of the 7 factors used to generate the county level SoVI index.   ). The data also contains the mailing address of the borrower and not the location of the damaged property. This may skew financial calculations based on locations depending on the level of data aggregation. Regardless of these reporting issues, the SBA disaster loan dataset provides a useful tool for examining the effects of a particular disaster on small businesses and various sectors of the economy using the NAICS codes. The disaster assistance data was aggregated to the county level using the 5-digit county FIPS code. To remove the duplicate records for hurricane events that encompassed multiple disaster declarations, the county records were unduplicated using a composite key based on event name and 5-digit county FIPS code. The amounts of federal assistance were then standardized per capita using Census 2000 population to control for county size and population variance. The SoVI scores were appended to the composite dataset for each county. The disaster outcome data was down selected to the 18 most meaningful variables. Data elements with little or no applicability to a statistical regression analysis were disregarded.  and demographic data enumerated during the 2000 Census. This data was also used by Cutter et al. (2003) in the construction of the social vulnerability index (SoVI). These two factors will allow for more consistency in the analysis based on common data sources. Community Survey data. FEMA will also need to update their operating procedures to include a replacement dataset for Census SF3 variables. Figure 10 below provides a visual representation of the data schema for the impact model data. The data elements that were duplicates or had little or no applicability to a statistical regression analysis were removed from the dataset. SoVI scores and total assistance per capita variables (TA_pcap) were appended to the composite dataset for each county. In total, there are nine federal impact model datasets; one for each hurricane event included in the analysis. A complete list of variables for the impact model data is enumerated in Appendix E.           Statistical regression analysis has been used effectively to evaluate the relationship between human and environmental factors in climate vulnerability studies (Samson et al. 2011, p.2), forest management studies on modeling of forest growth factors (Shi et al. 2006, p. 996), and hazard vulnerability studies related to the spatial distribution of consent forms for individual requiring assistance during disaster in Japan (Arima et al. 2014, p.2), the analysis of vulnerability assessments (Emrich 2005, p.53), and in quantifying urban vulnerability to terrorist incidents (Piegorsch et al 2007(Piegorsch et al , p.1417. Schmidtlein et al. 2008 infers that \"there is no obvious avenue through which indices of social vulnerability may be validated\" and hazard researchers \"must strive at least to understand the limitations of [sic] their methodologies\" (p. 1111). While statistical regression analysis is often used to understand and explain complex phenomena like hazard vulnerability; it is not always easy to find a set of independent variables to explain or predict the phenomenon in question. Exploratory spatial regression is an iterative approach that applies ordinary least squares (OLS) Ordinary least squares (OLS) regression was used to determine the relationship between the variables, assess the goodness of fit, and derive the beta estimates to test for spatial dependence. The adjusted R-squared values were used to evaluate the performance of a modelhow well it was able to explain the dependent variable. The Pvalues were used to identify the independent variables that are significant predictors. The variance inflation factors (VIF) were used to identify variable redundancy or multicollinearity. If there is a presence of multicollinearity, which is highly likely given that mulitcollinearity was discovered in the construction of SoVI, then exploratory regression analysis was used as a way to identify and eliminate variables causing Additionally, geographically weighted regression (GWR), a local regression model that allows for the depiction of spatial heterogeneity in a regression context and the description of spatial non-stationarity through a spatial weighting function using the local estimate of model coefficients (Shi et al. 2006, p. 997), was also employed. Spatial nonstationarity refers to variations in relationships over space between some sets of variables because the \"rates of change are not universal but determined by local culture or local knowledge, rather than a global utility assumed for each commodity\" (Brunsdon 1996, p. 283). The spatial weights matrix serves as an expression of spatial dependence between observations (Fotheringham et al. 2002, p. 44). Model results from OLS, spatial regression, and GWR were compared using goodness of fit measures: Akaike Information criterion (AIC), Schwarz criteria (SC), "}, {"section_title": "SPATIAL REGRESSION SCENARIOS", "text": "Using the exploratory regression and spatial econometrics approach described in the preceding section, this research sought to evaluate if the theoretical relationships between SoVI and disaster management policy and practice are supported by the empirical evidence, using the selected 9 hurricanes. It also investigates the ability of To determine if spatial econometrics is able to produce a better fit model, the results of OLS, spatial regression, and GWR are compared using the AIC, Schwarz criterion, R-squared values, and model coefficients.  Figure 5. Based on these conclusions and hazard vulnerability theory, one expects to find strong statistical correlations between SoVI scores and key disaster impact variables. This chapter attempts to quantify these conceptual linkages using a combination of correlation analysis and exploratory OLS regression with SoVI as the dependent variable and disaster impact model data elements as the independent (explanatory) variables. These are the same variable sets used in the crosswalk matrix depicted in Chapter 3, Figure 5. Correlation analysis provides a means for determining the degree of linear association between the variables. Exploratory regression analysis provides a means to assess the statistical relationships between the variables, to eliminate redundant variables, and find a potential set of variables able to explain the dependent variable. Statistically significant results would substantiate the conclusions from chapter 3."}, {"section_title": "CORRELATION ANALYSIS", "text": "By To examine the utility of SoVI in disaster operations as claimed by Cutter and Emrich 2016, Pearson correlation coefficients were generated for each set of variables for the 9 hurricanes. The complete correlation matrixes are provided in the appendix.  "}, {"section_title": "Figure 21: Exploratory Regression -Model Variables", "text": "The parameter settings for the exploratory OLS regression are depicted in Figure   22, and these settings were consistent for all 9 hurricanes. The objective was to identify a consistent set of variables that would be effective for all 9 hurricanes. The output reports, produced    2) Jarque-Bera is not statistically significant and residuals are normally distributed. 3) Spatial autocorrelation p-value is not statistically significant and residuals are randomly distributed, or exhibit no systematic patterns in the attribute space and geographical space. The next step of the exploratory OLS regression analysis was to examine the summaries of multicollinearity to eliminate redundant variables based on the VIF score, number of violations, and covariates for each hurricane run. The results of this examination were that six variables were selected for inclusion in the OLS regression model to eliminate issues of multicollinearity. Population density (POPDen00) was chosen as an indicator of individual assistance; even though, it had mixed significance across the 9 hurricanes. Percent poverty (PctPOV) was highly significant for all the hurricanes and was selected as an indicator of disadvantaged at risk population. Average distance to coast (AVEDISTC) and maximum sustained wind speed (MAXSUSWIN) were chosen to represent the geophysical properties of hurricanes. The variables for probability of damage for the different facility types (police, fire, medical, etc.) had collinearity with total building loss (BldLoss1k) for all facilities, so that variable was chosen to represent those elements of public assistance from the impact model data. The facility probabilities and facility counts were also highly collinear amongst one another, so it made sense to remove these variables from the final selection. "}, {"section_title": "93", "text": "(NUMBRIDGE) was collinear with road mileage affected and was chosen to represent public infrastructure damaged. HUNITS and POP2000 were routinely correlated with each other as well as with the variables for facility probabilities and facilities counts, so they were also eliminated from the selection. 5 of these 6 selected variables had significant correlations with SOVI based on the correlation analysis depicted in Table 8."}, {"section_title": "REGRESSION SCENARIO 1 -ANALYSIS OF VARIABLE SELECTION USING OLS REGRESSION", "text": "The final step is to run classic OLS regression for each of the 9 hurricanes to demonstrate the effectiveness of those six variables and if this model will produce more consistent results. This will help quantify the conceptual relationships from chapter 3 and provide the benchmark variables for regression scenario 4. Model diagnostics for the OLS model are shown in table 10 below. The adjusted R-squared values indicate the model was able to explain 57% or above of the variance in SoVI for 6 of 9 hurricanes and approximately 40% for 2 of the remaining 3 hurricanes. Adjusted R-squared values were lowest for hurricane Jeanne at 28.9%. The other model diagnostics and results were examined to determine the reliability of the adjusted R-squared values. The probabilities for the Koenker (BP) statistics were insignificant for all the hurricanes, suggesting the data is generally stationary with little regional variation. Since the Koenker (BP) statistics were insignificant, we consult the probabilities from table 11 to determine if the model coefficients were statistically significant. Results varied across hurricane run."}, {"section_title": "94", "text": "Model coefficients for PCTPOV were significant for 7 of 9 hurricanes, while the model coefficients for the remaining variables were significant in 2 or less hurricanes. The Jarque-Bera probabilities were also insignificant indicating the residuals are normally  Table 11 suggests that the OLS models may be suffering from skewness in the data. This skewness issue will be examined further in the remaining regression analysis. The results from the chapter 5 analysis identified 6 variables for inclusion in an OLS regression model. These 6 variables addressed the following issues critical to performing a meaningful OLS regression: a) eliminate multicollinerity, b) significant correlation with SoVI, c) theoretical basis in disaster management and hazard vulnerability, and d) best able to explain the most variance across the 9 hurricanes.  The OLS models are constructed using the six independent variables identified in chapter 5, to accurately predict the level of damages in the community --expressed as total cost of federal assistance. It involved running 3 scenarios using OLS regression where total amount of federal assistance per capita (TA_pcap) serves as the dependent variable. "}, {"section_title": "REGRESSION SCENARIO 2 -OLS REGRESSION USING SOVI AS THE INDEPENDENT VARIABLE", "text": "This model was run using the SoVI score as the independent (explanatory) variable. OLS models were run for all 9 hurricanes included in the research sample. Based on this scenario, one expects to find a positive relationship between the dependent and independent variables, where a county with a larger amount of federal assistance would have a high SoVI score compared to a county with a lower SoVI score for each hurricane event. Table 13 shows the diagnostics for the OLS regression model runs for each hurricane. Table 14 shows the results for those same OLS model runs. Model diagnostics for the OLS regression model runs indicates poor model performance for 8 of 9 hurricanes. The AIC scores varied widely across hurricanes from 142.386169 to 4582.9921 suggesting the model is miss-specified or not a good match. The adjusted R-squared values show the model was able to explain less than 5% of the variance for 8 of 9 hurricanes. The only model run to demonstrate significant explanatory power was hurricane Bret, where SoVI was able to explain 38% of the variance. To determine the reliability of the adjusted R-squared values, the other model diagnostics and results were examined.  Floyd are non-stationary, and the robust probabilities were consulted to determine coefficient significance. The coefficients for hurricanes Bret and Floyd were significant based on the robust probabilities. For the remaining 6 hurricanes, the probabilities were consulted. The coefficients were insignificant based on the probabilities. The scatterplots from figure 27 show linear relationships for 6 hurricanes and narrowly linear relationships for the remaining 3 hurricanes (Irene, Ivan, and Lili). The relationship between dependent and independent variable was positive as expected for 6 of 9 hurricanes. The relationship was negative for hurricanes Claudette, Irene, and Lili. This is anomalous as one expects when damages are high that vulnerability is high. Moran's statistics were run to determine if spatial autocorrelation issues were influencing model performance. These statistics are listed in Table 15 below. The Moran's I results indicate the presence of spatial autocorrelation in the OLS model runs for 7 of the 9 hurricanes. This map shows residual clustering that is closely associated with the hurricane storm tracks and points of landfall as depicted in figure 40 below. While the histograms from figure 37 also showed significant outliers and removing these outliers might boost model performance; it might introduce new bias by eliminating significant geographic components from the analysis. By their nature, hurricane events are spatially biased by their storm tracks and geophysical properties. Collectively, the results from OLS regression for scenario 3 suggest model bias is a result of model mismatch or model mis-specification rather than data outliers. The results also suggest there is a problem with skewness in the data based on the scatterplots and spatial autocorrelation from the Moran's I statistics."}, {"section_title": "REGRESSION SCENARIO 3 -OLS REGRESSION USING SOVI FACTORS AS INDEPENDENT VARIABLES", "text": "Since the results from regression scenario 2, that tested the explanatory power of the SoVI composite index, were dubious, it begs the question whether particular subfactors of SoVI are statistically more significant than others? If certain SoVI sub-factors are significant, how does their significance in explaining disaster impacts compare to their significance in explaining social vulnerability? For example, wealth (factor 2) is able to explain 15.9% of the variance in SoVI and has a negative relationship. Employment in services industries (factor 7) has a variance of 4.8% and has a positive relationship with SoVI. Do these same relationships hold true in explaining disaster impacts using total federal assistance per capita? This model was run using the individual SoVI factors as the independent (explanatory) variables as depicted in figure 31 and total federal assistance per capita as the dependent variable. Table 16 shows the diagnostics for the OLS regression model runs for each hurricane. Table 17 shows the results for those same OLS model runs.  relationships for the remaining 3 hurricanes (Irene, Ivan, and Lili). The relationship between dependent and independent variable was positive as expected for 6 of 9 hurricanes. The relationship was negative for hurricanes Claudette, Irene, and Lili. This is anomalous as one expects when damages are high that vulnerability is high."}, {"section_title": "Figure 31: Regression Scenario 3 -Model Variables", "text": "The relationships for the model coefficients also varied across hurricanes and factors. In many cases, the type of relationship (positive or negative) contradicts the cardinality of that factor to SoVI. For example, factor 2 (wealth) has a negative cardinality to SoVI but has a positive relationship to the dependent variable for 4 hurricanes and a negative relationship for the other 5 hurricanes. The scatterplots in figure 32 illustrate the varying type of relationship between the factors across the 9 hurricanes.   Moran's I statistics were run to examine the effects of spatial autocorrelation. Table 18 shows that 6 of 9 hurricanes had spatial autocorrelation. These results are contrary to the Koenker statistic that was insignificant for 7 of 9 hurricanes. A composite map of the OLS residuals displayed in figure 46 shows clustering is associated with the hurricane storm tracks and points of landfall. These findings are consistent with findings for regression scenarios 2-3. The results from OLS regression for scenario 3 also suggest model bias is a result of model mismatch or model mis-specification rather than data outliers. These results also suggest there is a problem with skewness in the data based on the scatterplots and spatial autocorrelation from the Global Moran's I statistics."}, {"section_title": "REGRESSION SCENARIO 4 -OLS REGRESSION USING THE SIX INDEPDENDENT VARIABLES", "text": "This model was run using the 6 independent (explanatory) variables from the FEMA impact models as depicted in figure 36. OLS models were run for all 9 hurricanes included in the research sample. This scenario examines the relationship between actual damages and impact model data to determine, if there is a statistical basis for indexing hazard vulnerability using a combination of these data rather than proxy measures of susceptibility used to compile SoVI. To validate the efficacy of this approach, it attempts to quantify the relationships between disaster operations practice and disaster management policy using disaster costs and disaster impact model data. A key question considered by regression scenario 4 is: if impact model variables have significant explanatory power for total amount of federal assistance per capita as an expression of actual damages, then could SoVI be refactored from these same variables to be a more effective measure of vulnerability? This approach would directly link hazard vulnerability across disaster operations policy and practice and provide a basis for establishing common variables across disaster management that could be used to improve the reliability of hazard vulnerability indexes. This OLS model was able to explain over 57% of the variance in SoVI for 6 of 9 hurricanes when applied in regression scenario 1. The question is will these 6 variables be able to produce similar results using the total amount of federal assistance per capita as the dependent variable? hurricane Charley. It was able to explain less than 10% of the variance for 3 of 9 hurricanes. These results are much lower than those from regression scenario 1, suggesting there are weak linkages between these variables and disaster management policy. The other model diagnostics were examined to determine the reliability of the adjusted R-squared values. The probabilities for the Koenker (BP) statistics were insignificant for 7 of 9 hurricanes indicating the data are stationary. For these 7 hurricanes, the probabilities were consulted from table 20 to determine if the model coefficients were statistically significant. For the other 2 hurricanes, the robust probabilities were consulted to determine if the model coefficients were significant. Results varied across hurricane run. Model coefficients for POPDEN00 and AVEDISTC were significant for only 1 hurricane. PCTPOV and NUMBRIDGE had significant model coefficients for 2 hurricanes. BLDGLOSS1K had significant model coefficients for 3 hurricanes; while MAXSUSWIN had significant model coefficients for 4 hurricanes. The variables representing hurricane intensity and damage to critical facilities were significant in the most hurricanes. The Jarque-Bera probabilities were significant for 6 of 9 hurricanes. This indicates there are problems with model bias, as the residuals are not normally distributed. This is confirmed by the histograms depicted in figure 38. Scatterplots from figure 37 shows that the relationships between the dependent and independent variables are linear. The types of relationships were mixed for some of the variables and contradict current hazard vulnerability science. For example, figure 37 shows that POPDEN00 has a negative linear relationship; when the dependent variable is high, POPDEN00 is low. PCTPOV, AVEDISTC, and MAXSUSWIN also exhibited negative linear relationships for several of the hurricanes. BLDGLOSS1K had a positive linear relationship for 8 of 9 hurricanes, and NUMBRIDGE had a negative linear relationship for 8 of 9 hurricanes. The type of relationship for BLDGLOSS1K is expected but not for NUMBRIDGE. These results suggest the model is mis-specified.   shows clustering is associated with the hurricane storm tracks and points of landfall, findings consistent with regression scenarios 2-3. between the variables. To determine the effectiveness of the log transformations, the descriptive statistics were consulted including the mean, median, skewness, and kurtosis parameters. The Skewness measure indicates the level of non-symmetry; if the distribution of the data is symmetric then skewness will be close to 0. Kurtosis is a measure of the peakedness of the data; for normally distributed data the kurtosis is 0. The Jarque-Bera statistics were used as the goodness-of-fit test to determine whether the transformed data have skewness and kurtosis matching a normal distribution. The Akaike's Information Criteria (AICc) was used to assess the quality of the OLS model. AICc is a measure of the relative quality of the statistical models for a given set of data and provides a relative estimate of the information lost when a given model is used to represent the dependent variable. Low AICc scores indicate little data is lost. Log transformations were performed on the following 6 variables: TA_PCAP (total federal assistance per capita), POPDENN00 (population density 2000), AVEDISTC (average distance to coast), MAXSUSWIN (maximum sustained wind speeds), BLDGLOSS1K (building loss in thousands of dollars), and NUMBRIDGE (number of bridges). Histograms of these log transformations as well as the descriptive statistics are provided in the appendix. The OLS models for regression scenarios 2-4 were re-run using the log variables.  Table 22, 8 of 9 hurricanes had issues with skewness in the data based on the Jarque-Bera test of normality prior to the log transformation. After the log transformations, 8 of 9 hurricanes had insignificant Jarque-Bera statistics indicating the data was normally distributed for all but hurricane Jeanne. The AICc scores also showed significant improvement indicating the OLS models using the log transformations are better specified. For regression scenario 3, depicted in Table 23, 7 of 9 hurricanes had issues with skewness in the data based on the Jarque-Bera test of normality prior to the log transformation. After the log transformations, all 9 hurricanes had insignificant Jarque-Bera statistics after the log transformations, indicating the data was normally distributed. The AICc scores also showed significant improvement indicating the OLS models using the log transformations are better specified.  For regression scenario 4, depicted in Table 24, 6 of 9 hurricanes had issues with skewness in the data based on the Jarque-Bera test of normality prior to the log transformation. After the log transformations, 6 of 9 hurricanes had insignificant Jarque-Bera statistics after the log transformations, indicating the data was normally distributed. The AICc scores also showed significant improvement indicating the OLS models using the log transformations are better specified. Even the 3 hurricanes with significant Jarque-Bera statistics (Ivan, Jeanne, and Lili) showed significant improvement in their AICc scores after the log transformation also indicating improvement in the model fit.  "}, {"section_title": "ADDING MISSING INDEPENDENT VARIABLES", "text": "The OLS regressions for scenarios 2-3 indicated model-misspecification due to key explanatory variables missing. The results from the comparative analysis in chapter 3 also indicated SoVI was missing variables for the geophysical properties of the hazard. To address this issue, variables for AVEDISTC and MAXSUSTWIN were combined with SoVI for regression scenario 5. Figure 41 provides an illustration of the regression model."}, {"section_title": "Figure 41: Regression Scenario 5 -Model Variables", "text": "OLS models were run for all 9 hurricanes included in the research sample. Table   25 shows the diagnostics for the OLS regression model runs for each hurricane. Table 26 shows the results for those same OLS model runs. The model diagnostics for the OLS regression model runs indicate some measure of improvement with the additional geophysical variables; however, the model still performed poorly for 5 of 9 hurricanes. variance for 5 of 9 hurricanes. Four model runs were able to demonstrate significant explanatory power (hurricanes Bret, Charley, Irene, and Isabel), SoVI was able to explain more than 39.8% of the variance. To determine the reliability of the adjusted R-squared values, the other model diagnostics and results were examined. Scatterplots of the variables relationships in figure 42 suggest that while the log transformations improved the models, these transformations had limited effect in linearizing the variables. The Jarque-Bera statistic was significant for only hurricane    Moran's statistics were run to determine if spatial autocorrelation issues were influencing model performance for regression scenario 5. These statistics are listed in Table 27 below. The Moran's I results indicate the presence of spatial autocorrelation in the OLS model runs for 6 of the 9 hurricanes."}, {"section_title": "CHAPTER 8: RESOLVING SPATIAL AUTOCORRELATION", "text": "Model bias from data skewness and missing variables were resolved using regression scenarios 4 and 5. Regression scenario 5 produced the best results in the OLS regression analysis. It used 6 independent variables from the FEMA impact models of which 5 variables had log transformations performed. Regression scenario 6 produced the best results using SoVI as the independent variable plus log transformations for 2 geophysical variables. This chapter seeks to resolve the third issue encountered in the OLS regression that of spatial autocorrelation by applying spatial econometrics and geographically weighted regression (GWR) to these same regression scenarios. This approach is supported by the global Moran's I statistics that indicate significant clustering in a majority of the 9 hurricanes models examined. This allows for an \"apples to apples\" comparison to determine if a modified SoVI model can produce better results or a model based on FEMA impact model data can produce the best results. For regression scenarios 4-5, spatial regression was run using queens-contiguity spatial weights for each of the 9 hurricanes to determine the significance of the spatial dependency identify in the global Moran's I results. The Lagrange Multiplier (LM) diagnostics were interpreted to decide if spatial regression is necessary and whether to use spatial lag or error terms to account for the spatial effects. The LM diagnostics for each regression scenario are presented in tables 53-54 below. For regression scenario 4, the LM diagnostics indicated that spatial dependency was significant for hurricanes Floyd, Isabel, Ivan, and Jeanne. Spatial regression should be run using both spatial lag for hurricanes Isabel and Ivan. Spatial error should be used for hurricanes Floyd and Jeanne."}, {"section_title": "Table 28: Regression Scenarios 4 -Lagrange Multiplier Diagnostics", "text": "For regression scenario 5, the LM diagnostics indicated that spatial dependency was significant for hurricanes Charley, Floyd, and Isabel. Spatial regression should be run using spatial lag.  Tables 55-56 compare the results from the OLS and spatial regression diagnostics for regression scenario 4 and 5, respectively. The model results were interpreted by 1) comparing the AIC and Schwarz criterion to determine if the spatial regression is a better fit versus the OLS and 2) using the order of precedence per Anselin (2005, p. 209) to determine if the model is properly specified which is W > LR > LM. For regression scenario 4, the AIC and Schwarz criterion (SC) were lower in the regression models versus the OLS models. For the order of precedence test, the results were mixed. Hurricanes Ivan and Jeanne satisfied this test indicating the spatial regression is an improvement and the model is properly specified. Hurricanes Floyd and Isabel failed this test. LR diagnostics were less than the LM diagnostics for these two hurricanes. This suggests the models are missing a key explanatory variable or external influence. For regression scenario 5, the AIC and Schwarz criterion (SC) were lower in the regression models versus the OLS models for hurricanes Floyd and Isabel but not the case for hurricane Charley. For the order of precedence test, the results were also mixed. Hurricanes Charley and Isabel satisfied this test indicating the spatial regression is an improvement and the model is properly specified. Hurricanes Floyd failed this test; the LR diagnostic was less than the LM diagnostic. This suggests the model is missing a key explanatory variables or external influence."}, {"section_title": "Table 31: Regression Scenarios 5 -Spatial Regression Diagnostics", "text": "Given that the spatial regression results were inconclusive, the GWR models were used to explore the spatial dependency and assess model fitness for the regression scenarios. For regression scenario 4, GWR executed for 4 of 9 hurricanes; the remaining hurricane models failed to execute due to a severe model design error in ArcGIS. This type of error is usually due to global or local multicollinearity or non-linear relationships.    Hur. Lili"}, {"section_title": "Figure 45: Regression Scenario 4 -GWR Residual Maps", "text": "For regression scenario 5, GWR executed for 7 of 9 hurricanes; the remaining hurricane models failed to execute due to a severe model design error in ArcGIS. This type of error is usually due to global or local multicollinearity or non-linear relationships. collinearity. This conclusion was confirmed by the coefficient standard error values for each model which were also very low. Table 35 below  This clustering also appears to be closely associated with the hurricane storm tracks and points of landfall. Overall analysis of the GWR results indicates that using a GWR approach yields a modest improvement over the OLS global model for regression scenario 5.  This chapter summarizes this research and discusses key findings. The contribution and implications of this research, a critique of it, and opportunities for future research are presented."}, {"section_title": "SUMMARY OF RESEARCH FINDINGS", "text": "This dissertation was concerned with establishing the conceptual linkages between hazard vulnerability science and disaster management policy and practice. This research was able to establish common conceptual foundations and theoretical underpinnings across these three disciplines, using a pedigree matrix and variable cross walk (Chapter 3). The pedigree matrix was used to compare and contrast three hazard vulnerability indices (social vulnerability index, disaster risk index, and disaster preparedness index) and to select the best one suited to test -if a hazard vulnerability index can accurately predict the exposure of a community to a natural hazard and therefore its level of vulnerability or the level of damages and serve as a good predictor for disaster management purposes. The comparative analysis was based on a qualitative taxonomy adopted from Gall (2007, p.33-34) that allowed for an \"apples to oranges\" comparison of the scale and the composition of the indices. Results from the pedigree analysis determined that SoVI was the best suited index for testing the predictive power of hazard vulnerability indices. The results from the comparative analysis also showed that there is general alignment between the indicators used by hazard vulnerability science (SoVI), the essential elements of information (EEIs) used by disaster management policy, and the disaster impact model variables used by disaster response. EEIs were grouped into four main categories: disaster area, geophysical information, socio-economic information, and critical infrastructure information. EEIs for geophysical information were not aligned with any hazard vulnerability indicators, but hazard vulnerability indicators were aligned to the EEI groupings for disaster area, socio-economic, and critical infrastructure. A correlation analysis of SoVI with the FEMA impact model variables that are linked to disaster management policy substantiated the findings from the comparative analysis. SoVI had strong statistical correlations with the socio-economic grouping of EEIs and weak correlations with the critical infrastructure grouping. Additionally, the correlation analysis showed that SoVI had few statistically significant correlations with the geophysical information. There was conflicting information for several variables across different storms, so the utility of the correlation matrices was limited. Exploratory regression was used as a more manageable method to quantify the statistical relationships between hazard vulnerability science and disaster management policy and practice. It also provided a means to eliminate redundant variables and choose a good set of independent variables. From the exploratory regression, six variables were chosen and analyzed for effectiveness using OLS regression. The six variables were SoVI: POPDEN, PCTPOV, AVEDISTC, MAXSUSTWIN, BLDGLOSS1K, and NUMBRIDGES. These variables map to the four EEI groupings and allowed for an apple to apples comparison in the subsequent OLS regressions. Findings from the comparative and correlation analyses were consistent. Since This research found that there were stronger statistical relationships between SoVI and the disaster operations impact model based on results from the exploratory regression, but weaker relationships between SoVI and disaster outcomes using the federal disaster assistance data. SoVI had little ability to explain disaster impact expressed as total federal assistance per capita. These findings indicate disconnectedness between hazard vulnerability science and disaster management policy. It appears that how we link vulnerability to disaster response and recovery operations is not the same as how we link those two domains to disaster policy. These findings in part substantiate the hazards-of-place theory that vulnerability is a function of the interactions between hazard, place, and society, but refute the claim by Emrich and Cutter (2016) that SoVI \"has high utility as a decision-support tool for emergency management\" turning \"historical disaster impact measures into actionable information for emergency managers, recovery planners, and decision makers because it empirically measures and visually depicts a population's (in)ability to adequately prepare for, respond to, and rebound from disaster events\" (Emrich and Cutter 2016, p.???). This research also question the claim by Cutter et al. (2003) that SoVI provides the emergency management community and policy makers a useful tool to illustrate the geographic variation in social vulnerability, to identify areas where there is uneven capacity for preparedness and response, to target areas where resources might be used more effectively to reduce pre-existing vulnerability and promote risk mitigation measures, and as an indicator in determining the differential recovery from disasters (Cutter et al 2003, HVRI SoVI webpage 2013. This research was unable to demonstrate the effectiveness of SoVI in explaining disaster impacts expressed as total federal cost per capita. Furthermore, SoVI is constructed from proxy measures for social vulnerability. While SoVI was initially developed to include indicators for the built environment, it does not adequately account for critical infrastructure and other key characteristics of the built environment. More significantly, SoVI does not account for any of the geophysical properties of the various natural hazards (i.e.; wind speed, rainfall amounts, etc.). Developing a composite measure of vulnerability must factor in the diversity of place, variation of the hazard, and complexity of the built environment or become too homogenized. These results show that SoVI is an inconsistent measure of vulnerability and that it is not able to reliably capture the complexity of regional and event specific variation necessary to accurately predict the level of damages or costs for a hurricane disaster."}, {"section_title": "CONTRIBUTIONS AND IMPLICATIONS", "text": "This dissertation examined the relationship between hazard vulnerability science, disaster management policy, and disaster operations practice. It provided a quantitative analysis of the reliability and utility of SoVI to accurately predict exposure of a community to a disaster, therefore its level of vulnerability or the level of damages, and serve as a good predictor for disaster management purposes using empirical data for 9 Atlantic hurricanes. It also provided the first cross mapping between the indicators used by hazard vulnerability science (SoVI), the essential elements of information (EEIs) used by disaster management policy, and the disaster impact model variables used by disaster response. One of the main contributions of this research is that it improves our understanding of the research policy nexus described by Cutter et al 2008 (p. 598). Since 1964, the US has continuously pursued a research policy nexus to better understand hazards, community vulnerability, and societal tolerance of risk and broad dissemination of this knowledge to inform policy and improve decision making (Cutter et al. 2008, p. 598). We have yet to design \"robust and credible measures of vulnerability\" that are accepted by the research and practitioner communities (Adger 2006, p. 268, Gall 2007. We have yet to develop a proven vulnerability index that incorporates the components of disaster response and recovery with mitigation and resiliency and that is more directly integrated with disaster management policy. This research demonstrated that developing a composite measure of vulnerability must include diversity of place, variation of the hazard, and complexity of the built environment. These contributions have implications for national disaster management policy by increasing our understanding of how vulnerability indices correlate with actual exposure and level of damage, and for developing a measure of community resiliency that is based on a set of proven indicators that takes into account 1) potential exposure, 2) likely impact to people, infrastructure, and environment, 3) capacity to cope, and 4) ability to recover. This enhanced understanding may lead to more sustainable practices, more effective policies, and actionable guidance and provide a means for comparing our disaster preparedness, practice, and resiliency across space and over time. It may also help pivot the nation away from a disaster response focus toward one of preparedness, with an emphasis on building resiliency."}, {"section_title": "FUTURE RESEARCH", "text": "\"Measuring vulnerabilityi.e. selecting vulnerability indicators and determining their interactionsis [still] less empirical and more a leap of faith\" (Adger 2006, p. 275). This dissertation has created many avenues for future research. First, hazard vulnerability science should seek an alternative approach to the equation; Disaster = Hazard * Vulnerability, by examining the \"risk that people and communities are exposed to with their social, economic, and cultural abilities to cope with the damages that occurred\" (Hilborst and Bankoff 2008, p. 2). Vulnerability should not be considered a property of disaster or hazard, but an outcome. Hazards are natural, disasters are not. Disasters are not just one-off phenomena; they represent the results of continuous social, economic, and environmental processes over time. According to Lavell (2008, p.82), \"as long as disaster is seen as externally imposed, little advance will be achieved in\" building resiliency and reducing vulnerability. Subsequently, vulnerability provides a conceptual link toward improving the understanding between disasters, built environment, and people. According to Hilhorst and Bankoff, \"vulnerability is the key to understanding risk\" (2008, p. 1) and \"the ways in which human systems place people at risk in relation to each other and their environment\" (Cannon 1994, p. 14). Petak and Atkisson (1982) maintains that much of the scientific work on modeling, estimating, and forecasting disaster impacts are examples of risk assessments applied to natural hazards. Hill and Cutter (2002) contend that vulnerability assessments should include risk and exposure and are more difficult to undertake than simple risk analyses because they require more data, have more complex interactions, and involve more advanced and composite techniques of statistical analysis. Cutter (2002) argues that vulnerability science has not adequately developed an approach to the \"integration of natural sciences, engineering sciences, and social sciences to produce credible vulnerability assessments at the local level\" (p. 159). This suggests more investigation in necessary toward understanding what characteristics or decisions are occurring or present that could be modified or changed to reduce long term risk and how these potential indicators relate to the actual costs/damages. Another consideration for future work would be to develop a hazard vulnerability index that integrates deterministic and probabilistic methods to incorporate results from historical, hypothetical, and predicted events to produce a more dependable, composite index for hazard vulnerability. This hazard vulnerability index would be based on impact model simulations, calibrated by empirical data from historical events, rather than general socio-economic indicators or national estimates of loss. This approach is very similar to the one employed by the National Hurricane Center (NHC), and validated by the meteorological community, to produce the Sea, Lake, and Overland Surges from Hurricanes (SLOSH) model. The SLOSH model is a numerical model that uses a proven set of characteristics (indicators) run through a set of statistical equations several thousand times to produce a composite measure of risk for an area based on estimated storm surge heights from historical, hypothetical, and predicted hurricanes (NWS website 2016). This type of approach would provide a more useful, understood, and acceptable metric of risk. Future research should also consider experimenting with integrating hazard vulnerability into an operational framework constructed from the premise that vulnerability assessments will be assembled in part with the inputs from pre-impact models and forecasts and these same models and forecasts would be used in near realtime as part of the response and recovery. The fusion of vulnerability assessments and impact model/forecasting would incorporate the likelihood of the hazard occurring, the potential level of impact to the population and the potential damage to the infrastructure, environment, and economy. A conceptual diagram of this framework is depicted in Figure 47. The framework envisions that both sets of results would be continuously calibrated with actual outcome data creating a regime similar to other first responder approaches that encompasses training, exercising, executing, evaluating and correcting. This would provide a basis for improving and refining the accuracy and performance of all components of the framework (vulnerability assessment, mitigation planning, preevent forecast modeling for resource management, post disaster impact and recovery) with the potential result of producing more common disaster operations practice. These common practices could serve as the bases for determining capability maturity and assessing community readiness and resiliency.  "}]