[{"section_title": "Abstract", "text": "Differences-in-Differences Evidence across Countries * Even though some countries track students into differing-ability schools by age 10, others keep their entire secondary-school system comprehensive. To estimate the effects of such institutional differences in the face of country heterogeneity, we employ an international differences-in-differences approach. We identify tracking effects by comparing differences in outcome between primary and secondary school across tracked and non-tracked systems. Six international student assessments provide eight pairs of achievement contrasts for between 18 and 26 cross-country comparisons. The results suggest that early tracking increases educational inequality. While less clear, there is also a tendency for early tracking to reduce mean performance. Therefore, there does not appear to be any equity-efficiency trade-off.\nJEL Classification: I2"}, {"section_title": "Introduction", "text": "Many countries worry about the relative merits of a selective versus comprehensive school system, and the resulting system choices are surprisingly different. Some countries track students into differing-ability schools as early as at age 10 (e.g., Austria, Germany, Hungary, and the Slovak Republic). By contrast, others including Canada, Japan, Norway, Sweden, the United Kingdom, and the United States essentially keep their entire lower secondary school system comprehensive. Parents and politicians alike would like to know whether it has consequences for the equity and efficiency of educational outcomes if a country tracks its students into different school types, hierarchically structured by performance. Such macro issues of institutional structure are extraordinarily difficult to evaluate within individual countries, largely because the variations in structure that exist there are almost certainly related to the characteristics of the families and schools choosing to follow an anomalous pattern. To deal with these analytical complexities, we provide evidence from international experiences across countries.\nThe arguments about school placement policies -variously called tracking, streaming, or ability grouping -often rest on a perceived trade-off between equity and efficiency. 1 Some discussions of tracking are mainly concerned with placements between different types of schools and others with placements into different tracks within schools, but the arguments for and against tracking are basically the same. 2 The central argument behind tracking is that homogeneous classrooms permit a focused curriculum and appropriately paced instruction that leads to the maximum learning by all students. In such a situation, the teacher does not have to worry about boring the fastest learners or losing the slowest learners. The arguments for ungrouped classrooms largely revolve around concerns that the lower groups will be systematically disadvantaged by slower learning environments that leave them far behind the skills of those in the upper groups. The argument frequently goes further to relate preparation on entry into school to socio-economic background of the students, implying that grouping will also lead to continuing bias against more disadvantaged students. 1 It appears that the costs of tracked and untracked systems are roughly comparable. Therefore, although we do not perform any direct efficiency calculations, we often refer to variations in outcomes in the loose manner of efficiency differences. 2 See the papers on \"comprehensive and selective schooling\" collected in Heath (1984) for examples of the UK-based discussion of streaming between schools and Slavin (1990) for an example of the US-based discussion of ability grouping within schools.\nThe argument in favor of or against tracking gets even more complicated once possible peer effects are taken into account, because the precise nature of any interactions then becomes a key element in considering tracking. Proponents of ungrouped classrooms often suggest that heterogeneous classrooms might give rise to efficiency gains through nonlinear peer effects: the higher ability students lose nothing, but the lower ability students gain through the interaction (from motivation, better classroom discussion, and the like). By contrast, if the impact of peer achievement is linear, tracking would tend to increase the variance in outcomes without having any clear impact on the level of achievement (e.g., Argys et al. 1996) . And if individuals are better off with peers of their own ability level, tracking could even improve the level of performance while possibly also reducing inequality (e.g., Dobbelsteen et al. 2002) . 3 Thus, theory suggests considerable uncertainty about the impact of tracking on both the level and distribution of schooling outcomes. 4 So far, the empirical literature attempting to sort out the effects of tracking on both the level and distribution of outcomes has followed two general strategies. The difficulty for any empirical research is that the major elements of the institutional structure of schools are choices whose impact is difficult to separate from other influences on achievement. When some schools or local education authorities introduce alternative structures, these choices are likely to be linked to other features of the students and schools if for no other reason than parental choices of residence and schools. Thus, the first empirical approach, which focuses on tracking within schools, attempts to standardize for heterogeneity across institutional structures through statistical analyses of measured factors (see Argys et al. 1996; Betts and Skolnick 2000; Betts et al. 2003; Figlio and Page 2002). 5 Alternatively, if operating at the level of nations or states, the lack of within-state variation eliminates any control group unless there is variation over time. Thus, the second empirical approach, which focuses on tracking between different types of schools, looks within countries for situations where the institutional structure is altered and with some 3 Lazear (2001) provides an alternative model of possible externalities within classrooms that lead to nonlinear effects of peer composition on student outcomes, which also generally implies efficiency improvements through grouping. 4 For recent advanced theoretical treatments of the effects of tracking, see Brunello and Giannini (2004) ; Epple et al. (2002); and Meier (2004) . 5 The direct analyses of tracking are also supplemented by investigations of peer achievement effects. Early peer investigations were not very concerned about problems of omitted variables and simultaneity (i.e., the \"reflection problem\"). More recent peer studies have concentrated on those issues Hoxby 2000) . Nonetheless, the importance of peer ability remains disputed. embellishments compares outcomes before and after. 6 The results of the different empirical analyses, while far from uniform, tend to suggest that tracking leads to more inequality in outcomes, particularly from the perspective of family backgrounds (but see Figlio and Page 2002 for an opposite finding).\nThe concern with both empirical approaches is that other unmeasured factors bias the estimated impacts of tracking. For example, with the trend analyses, the change in tracking structure is frequently just one of a series of changes to the schools. While these studies also include a variety of controls for other observable factors, it is hard to assess whether they sufficiently capture the concomitant factors that might affect student outcomes over time. The statistical analyses of tracking that employ both national and local samples for U.S. schools face complications of family residential choice plus generally sparse controls for family, teacher, and school differences -elements that are likely both to affect achievement and to be related to the institutional structure of classrooms.\nTo address these empirical problems, we use the macro variation in both the institutional structure of between-school tracking and student performance that exists across countries to sort out the impacts of tracking. Of course many other things also differ by country, leading us to adopt a differences-in-differences strategy to parse the effects of tracking. In this, we compare the level and distribution of performance of younger students (before tracking is introduced in any country) with those of older students (after some countries have started tracking) across countries with and without tracking, effectively using early outcomes in each country as the control. The existence of several large international assessment programs permits a consistent evaluation of student performance across a wide range of countries.\nOur analysis provides reasonably strong support for the disequalizing effects of early tracking. Variation in performance, measured in a variety of ways, tends to increase across levels of schooling when a country employs early tracking. On the other hand, the evidence about possible efficiency gains from tracking is more mixed.\nThe remainder of the paper is structured as follows. Section 2 discusses the empirical identification strategy in detail. Section 3 describes the data. Section 4 presents the results on the impact of tracking on educational inequality, mean performance, and gainers and losers in the performance distribution. Section 5 concludes."}, {"section_title": "Cross-Country Identification", "text": "Understanding the impacts of macro institutional factors requires observing instances both of use of the structure and nonuse. In the case of between-school tracking, with the rare exception of when a country changes policies, the institution is common to all of the schools, implying that variation within countries is not useful. 7 ) is determined by a country specific intercept (\u03b1), varying attributes of families and schools (X), the existence of tracking (T), and an error (\u03b5). In principle, if we could measure the various inputs to achievement, we could directly estimate equation (1). Two problems exist, however. First, we do not have sufficient knowledge or data to be confident of any estimates of the \u03b2 (see Hanushek 2003) . Second, with respect to the influences of tracking, if every student in the country is subject to tracking, T will be a constant, and we cannot estimate its influence on achievement.\nIn reality, no country tracks students between differing-ability schools in the early primary grades. Thus, we can consider looking at the changes that occur between primary school (grade g) and later schooling (grade g * ). A simple estimate of the impact of tracking could be found by looking at the average difference in achievement between g and g * for a country that introduced tracking during that period: The estimation still depends upon the expected composite errors (\u03bd) being uncorrelated with the existence of tracking. This would be violated if, for example, the observed tests came from widely different cohorts of students such that the X's were to change (and to be correlated across countries with the existence of tracking), or if tracked nations tended to introduce more changes in their schools between the testing of students in different grades. We return to this below.\nIn reality, we estimate equation (3) in a regression framework where mean performance in grade g * is regressed on mean performance in grade g along with an indicator for the existence of tracking. Thus, our approach applies a differences-in-differences methodology to the cross-country comparisons, combining tests in primary school with tests in secondary school. The effect of tracking is identified by comparing performance differences between primary and secondary school across tracked and non-tracked systems, where each country's own primary-school outcome is used as a control for its secondaryschool outcome.\nWe also estimate a similar equation for inequality in performance. The simplest model is one where the variation in outcomes within countries are magnified (or shrunk) by the use of tracking. Again, the most basic model is a regression of late variance on early variance plus an indicator for tracking."}, {"section_title": "School Performance Data", "text": "International testing of students began in the early 1960s when the International Association for the Evaluation of Educational Achievement (IEA) developed a mathematics test that could be used to compare student performance across countries. Although the earliest testing was plagued by uncertainties about the within-country sampling, the selectivity of students who were not in school, and a variety of other factors, more recent testing has followed strict protocols with elaborate efforts to ensure both high quality test designs and representative sampling of students.\nTo implement the differences-in-differences estimation, we concentrate on the series of international assessments conducted since 1995. We match international student achievement tests in secondary school with tests late in primary school. Because the methodology requires a stable educational system, we concentrate on roughly contemporaneous measures of performance at the two different grade levels. 8 We supplement the six different test observations that meet this requirement, however, by following the 1995 cohort of 4 th grade students that subsequently was assessed in the 8 th grade in 1999 (on the TIMSS math and science tests). Table 1 summarizes the comparisons that are used, and the data and sources are described in detail in the Appendix.\nTests are found in reading, mathematics, and science. Each assessment produces 18 to 26 country level observations. For analytical purposes, the differences in the tests and subjects lead us to treat each of the eight assessment pairs as a separate test of the impacts of early tracking, although the common grouping of countries implies that these are not truly independent tests.\nIn our analyses, we use the data on age of first tracking as a dummy representing whether an education systems tracks its students before the age at which the specific secondary-school test is performed or not. For the PISA secondary-school tests, we consider tracking by age 15 (the average student age on the two PISA tests is 15 years and 9 months);\nfor the TIMSS secondary-school tests, we consider tracking by age 14 at the latest (corresponding to an average testing age of 14 years and 5 months). Half the countries in our samples based on the PISA tests had a tracked system by the age of 15. The share of countries that tracked by the age of 14 in the TIMSS tests is roughly one third (see Appendix Table   A2 ), reflecting both the earlier testing age and the different country compositions of the samples."}, {"section_title": "Impacts of Early Tracking", "text": "Because of the importance attached to inequality in the existing literature, we begin with an analysis of distributional aspects of tracking. This is followed by implications for mean performance."}, {"section_title": "Tracking and Inequality", "text": "The The regression analysis expands this to consider different measures of inequality: the standard deviation of test scores within each country; the test-score difference between the student performing at the 75 th percentile and the student performing at the 25 th percentile in each country; and the performance difference between the 95 th and the 5 th percentile. We also provide a comparison with estimation of a simple model of average achievement that, along the lines of equation (1), compares mean performance of the 15 year olds just to tracking.\nAs the results reported in columns (1), (3), and (5) of Table 2 show, none of the three inequality measures is statistically significantly related to tracking in a simple bivariate analysis. However, as argued in Section 2, these bivariate estimates may be biased by general heterogeneity in inequality of the participating countries. Thus, columns (2), (4), and (6) report differences-in-differences estimates of the effect of early tracking on the three 9 Standard deviations are expressed relative to the average national standard deviation on each test.\ninequality measures which condition on the extent of educational inequality already present in late primary school, before tracking in any country. With all three measures of inequality, it is obvious that countries that exert high inequality already in primary school also tend to have high inequality in secondary school. The point estimates of roughly 0.6 indicate that schools everywhere tend to reduce the inequality which was present in primary grades -and which presumably represents the proportionately greater influence of families.\nMore importantly, on all three measures of inequality, countries that track their students before age 15 show a statistically significantly larger inequality on the PISA 2003 secondary-school test, once the difference in inequality that existed already in primary school is accounted for. Specifically, early trackers show a national standard deviation of test scores in secondary school that is one quarter of a cross-country standard deviation larger than nontrackers. Consider for example the observed country differences in outcome variation. The The estimates across the other seven pairs of international achievement tests are generally consistent with the results in Table 2 but are not as strong or statistically significant. Table 3 reports the differences-in-differences results using the standard deviation as the inequality measure. 10 With the exception of the PISA 2000/02-PIRLS pair, all estimates of the coefficient on early tracking are positive, and four are statistically significant at the 10 percent level or better. For the insignificant results of columns (11)- (13), inequality in secondary school is not even statistically significantly related to inequality in primary school, raising some concerns about the specific tests.\nThe limited samples of countries preclude very elaborate specification checks, but some extensions are interesting. First, rather than entering the tracking variable as a dummy, we can also enter tracking as a linear variable depicting the age at which a country first tracks its students. Unfortunately, the continuous variation in when the tracking occurs is limited, with no country starting to track at the age of 13, for example. Results using the linear tracking variable (available from the authors) are broadly consistent with results using the simple existence of tracking, and the main impact comes from the mere existence of early tracking with no consistent linear pattern detectable for the age at which tracking occurred.\nAdditionally, experimentation with adding further control variables to the estimation did not change the basic results. In terms of the estimates of "}, {"section_title": "Tracking and Mean Performance", "text": "Given that comprehensive schooling systems seem to reduce inequality, the question arises whether this effect is achieved by improving the lowest performers or by holding back the best performers. That is, does performance converge at a lower or higher level? We first estimate the effect of tracking on a country's mean performance level using the same differences-in-differences identification strategy as before; following that, we estimate the effects at different percentiles of student performance in the next section. Table 4 reports the results on the effect of early tracking on mean performance for all 8 pairs of international student achievement tests. In all pairs, we see a clear tendency for countries which performed better on average in primary school to also perform better in secondary school.\nThe impact of early tracking is, however, inconsistent across subjects and tests. The two reading comparisons indicate a statistically significant lower achievement associated with early tracking. Similarly, the mathematics results are always lower with early tracking, although the result is statistically significant at the 10 percent level or better in only one of the three comparisons. For science, however, two of the three estimates indicate positive achievement effects from early tracking (and one is statistically significant at the 5 percent level).\n11 OECD (2004) reports GDP per capita (in purchasing power parities) for 15 of the 18 countries. When included, it enters statistically significantly positive, while the tracking dummy also remains statistically significantly positive. The expenditure measure (again in purchasing power parities) is available for 13 countries but does not enter significantly, although the significance level of the tracking dummy falls to 15 percent.\nAs an alternative approach, we allow for the possible correlation of the residuals of the inequality and the mean-performance equations. In order to improve the estimation efficiency, we estimate the two equations by seemingly unrelated regressions (SUR). The results in Appendix "}, {"section_title": "Who Gains, Who Loses?", "text": "One final issue is where any losses (or gains) from early tracking are found in the distribution. To address this, we estimate the effect of early tracking on the performance of students at different percentiles of the performance distribution, again in differences-indifferences models. Specifically, we estimate whether a student at the 5 th percentile (or 25 th , 75 th , and 95 th percentiles) of the national distribution is affected by tracking. Although effects cannot be statistically significantly estimated in most pairs of international achievement tests, where they can, they reinforce the results in Tables 2-4. For example, the increased inequality and decreased mean performance in tracked systems detected in the PISA 2003-PIRLS pair come from the lower percentiles losing more than the upper ones, even though each of the four percentiles loses a statistically significant amount. The coefficient estimates on the early-tracking dummy for the different achievement levels are depicted in Figure 2 , which shows that lower performers suffer more from early tracking than higher ones.\nAcross the estimates from the remaining samples (available from the authors), the most striking finding is that in no case do some students gain at the expense of others; both high and low achievers lose (or, in the one case of a positive effect on mean performance, gain) from tracking. The net impact comes from the differential impacts on different parts of the distribution."}, {"section_title": "Conclusion", "text": "This analysis provides preliminary results about the impact of early tracking on the level and distribution student performance. The results consistently indicate that early tracking increases inequality in achievement. Although the evidence on the level of performance is less certain, there is very little evidence that there are efficiency gains associated with this increased inequality.\nOn the research side, these preliminary results also suggest the value of further study of tracking. Some of the literature has suggested that one channel for increasing inequality is reinforcing the effects of family background. Specifically, if much of the early inequality in achievement is associated with differences in family background, many of the track placements will be associated directly with family background. Indeed, some have suggested that family background is a driving force in setting track placements even beyond its impact on early achievement levels (e.g., Schnepf 2003). The implications for family background inequality can potentially be investigated through use of the micro data generated by the international assessments. Beyond that, with the micro data it would be possible to consider more fully the underlying structural model of achievement that would generate these patterns of aggregate outcomes. Also, extending the dichotomous analysis between tracked and nontracked systems pursued in this paper, there may be heterogeneity in the rigidity of tracked systems. Future research may explore the extent to which allowing mobility across tracks might reduce the negative effects of tracking.\nFrom a policy perspective, it seems incumbent on those advocating early tracking in schools to identify the potential gains from this. These preliminary results suggest that countries lose in terms of the distribution of outcomes, and possibly also in levels of outcomes, by pursuing such policies."}, {"section_title": "Appendix: Data Sources and Description", "text": "The most recent international test employed is the 2003 edition (data release: December 2004) of the Programme for International Student Assessment (PISA), conducted by the Organisation for Economic Cooperation and Development (OECD). 12 PISA tested representative samples of 15-year-old students in reading, math, and science, with a focus of test items on real-life applications. A recent primary-school test to which the PISA test can be matched is the Progress in International Reading Literacy Study (PIRLS). In 2001, the International Association for the Evaluation of Educational Achievement (IEA) conducted the PIRLS reading test to 4 th -grade students, 13 which is the grade just before the first countries start tracking their schools. There are 18 countries that participated both in PISA 2003 and in PIRLS. Appendix Table A1 provides a list of countries participating in each pair of tests.\nSince the mid-1990s, there are seven further international student achievement tests at the end of lower secondary education to which we can match specific primary-school tests, all of which tested representative samples of students in each participating countries (see Table 1 ). The first PISA study, also testing 15-year-olds in reading, math, and science, was conducted in 2000 for most participating countries and in 2002 for several additional countries. We match the PISA 2000/02 test again with the 2001 PIRLS primary-school test, which gives a sample of 20 countries participating in both tests. Next, the IEA performed the Third International Mathematics and Science Study (TIMSS, later re-named to Trends in International Mathematics and Science Study) in 1995, which tested both 4 th -grade and 8 th -grade students in math and science. 14 Matching the TIMSS 1995 tests in primary and secondary school, there are 26 countries participating both in the two math tests and in the two science tests. The next primary-school TIMSS tests were conducted in 2003, which we can match to the TIMSS 2003 secondary-school tests, yielding a sample of 25 countries participating in primary and secondary school both in math and in science.\nAll these matches test primary-and secondary-school students at exactly or roughly the same point in time. We can also follow specific cohorts of students over time. This is possible by relating the 8 th -grade performance on the TIMSS tests in 1999 to the 4 th -grade performance on the TIMSS tests in 1995. That is, the very same cohort which was tested in math and science in 4 th grade in 1995 was again tested in 8 th grade in 1999. 18 countries participated both in the 1995 4 th -grade and in the 1999 8 th -grade math and science tests, allowing for matching of representative samples from the same cohort followed over time.\nWe take the data on means, standard deviations, and percentiles of the test-score performance on the different international tests from the following sources: OECD (2003; 2004) for reading performance in PISA 2000 and PISA 2003 Mullis et al. (2003) for reading performance in PIRLS; Beaton et al. (1996a; 1996b) for secondary-school math and science performance in TIMSS 1995; Mullis et al. (1997; 2000; 2004) for math performance in TIMSS 1995 primary school, TIMSS 1999 and TIMSS 2003 2000; 2004) for science performance in TIMSS 1995 primary school, TIMSS 1999 and TIMSS 2003 For the purposes of this paper, we re-scale the test scores of each primary-secondary pair of tests so that they are normalized to have a mean of zero and a cross-country standard deviation of one between the countries jointly participating at both test levels. Note that this normalization refers to the cross-country variation of test scores among the sample of participating countries only, without considering possible differences in the withincountry variation of test scores between the primary-and secondary-school tests. Thus, for example, the mean of the standard deviation of test scores within each country is considerably larger in the PISA 2003 test than in the PIRLS test, at 4.0 versus 2.9 cross-country standard variations on each of the tests, respectively. That is, in PISA 2003, the standard deviation of test scores within a country was, on average, four times as large as the standard deviation of test scores across the 18 countries.\nWe collected data on the age at which students are tracked into different schools for the first time in each country from different sources, including the data collections of the European Commission (2000; , the Encyclopedia of national education systems of Postlethwaite (1996) , a table in OECD (2003), and detailed 12 TIMSS assessments for 2003 were also released in December 2004, but we start with the PISA 2003 test because it tests students who are older and thus longer exposed to tracking than the students tested in the TIMSS tests and because it has a broader coverage of developed countries. 13 Specifically, PIRLS tested the upper of the two adjacent grades with the largest share of nine-year-olds in each country, which is usually fourth grade. 14 Specifically, the different TIMSS tests tested the upper of the two adjacent grades with the largest share of 9-year-olds (4 th grade) and 13-year-olds (8 th grade), respectively, in each country. Note: Coefficient estimate on the early-tracking dummy in separate differences-indifferences estimations of the performance of the X th percentile in PISA 2003 on the performance of the X th percentile in PIRLS and the early-tracking dummy. "}]