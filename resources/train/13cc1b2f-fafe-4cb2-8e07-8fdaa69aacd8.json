[{"section_title": "Abstract", "text": "Die Dokumente auf EconStor d\u00fcrfen zu eigenen wissenschaftlichen Zwecken und zum Privatgebrauch gespeichert und kopiert werden.\nSie d\u00fcrfen die Dokumente nicht f\u00fcr \u00f6ffentliche oder kommerzielle Zwecke vervielf\u00e4ltigen, \u00f6ffentlich ausstellen, \u00f6ffentlich zug\u00e4nglich machen, vertreiben oder anderweitig nutzen.\nSofern die Verfasser die Dokumente unter Open-Content-Lizenzen (insbesondere CC-Lizenzen) zur Verf\u00fcgung gestellt haben sollten, gelten abweichend von diesen Nutzungsbedingungen die in der dort genannten Lizenz gew\u00e4hrten Nutzungsrechte. \nTerms of use:\nDocuments in\nDaniel L. Millimet Rusty Tchernis The Institute for the Study of Labor (IZA) in Bonn is a local and virtual international research center and a place of communication between science, politics and business. IZA is an independent nonprofit organization supported by Deutsche Post World Net. The center is associated with the University of Bonn and offers a stimulating research environment through its international network, workshops and conferences, data service, project support, research visits and doctoral program. IZA engages in (i) original and internationally competitive research in all fields of labor economics, (ii) development of policy concepts, and (iii) dissemination of research results and concepts to the interested public.\nIZA Discussion Papers often represent preliminary work and are circulated to encourage discussion. Citation of such a paper should account for its provisional character. A revised version may be available directly from the author. \nABSTRACT\nWe characterize the bias of propensity score based estimators of common average treatment effect parameters in the case of selection on unobservables. We then propose a new minimum biased estimator of the average treatment effect. We assess the finite sample performance of our estimator using simulated data, as well as a timely application examining the causal effect of the School Breakfast Program on childhood obesity. We find our new estimator to be quite advantageous in many situations, even when selection is only on observables.\nJEL Classification: C21, C52"}, {"section_title": "Introduction", "text": "Program evaluation methods in econometrics have become increasingly sophisticated. In this study, we assess and compare the bias of estimators of three common parameters -the average treatment effect (ATE), the average treatment effect on the treated (ATT), and the average treated on the untreated (ATU) -that require the unconfoundedness assumption when, in fact, unconfoundedness fails. Thus, our study represents an extension to the analysis first put forth in Black and Smith (2004) for the ATT.\nIn that paper, the authors show that under certain conditions, estimators of the ATT that require the unconfoundedness assumption to be unbiased, but are biased when this assumption fails to hold, obtain a minimum bias when the sample is restricted to observations with a probability of treatment, conditional on covariates, close to one-half.\nIn this paper, we have four specific objectives. First, we assess the bias of so-called selection on observables estimators of the ATE and ATU under the same assumptions as in Black and Smith (2004) .\nSecond, we provide a set of assumptions -frequently invoked in applied settings -that enable us to rank the magnitude of the bias of estimators across the three parameters. Third, we propose a new estimation technique for researchers seeking to minimize the bias of selection on observables estimators of the ATE when unconfoundedness fails to hold. We then compare the finite sample performance of our proposed method by Monte Carlo methods. Finally, we compare the performance of our estimator to those currently utilized in the literature to assess the effects of participation in the national School Breakfast Program (SBP) on childhood obesity.\nOur results should be of interest to the growing number of applied researchers relying on estimators from the program evaluation literature, especially when the researcher is concerned that the unconfoundedness assumption is problematic but a valid exclusion restriction is unavailable. Specifically, we offer two recommendations to applied researchers. First and foremost, researchers ought to be skeptical of estimates obtained using parametric methods unless the correct functional form is known. Second, our new estimation technique represents an improvement over the performance of the semiparametric estimator of the ATE proposed in Hirano and Imbens (2001) . In fact, our bias minimizing approach yields a finite sample improvement over Hirano and Imbens (2001) even when the underlying assumptions of their estimator are valid in the population. However, our estimation technique is particularly useful when there is selection on unobservables. While the fact that our estimator is preferable even when unconfoundedness holds may appear striking at first glance, it is consistent with other results in the literature. In particular, Hirano et al. (2003) find that using an estimated propensity score is preferable even when the true propensity score is known, and Millimet and Tchernis (2007) find that over-fitting the propensity score equation is preferable to using the true functional form.\nThe remainder of the paper is organized as follow. Section 2 begins by providing a quick overview of the potential outcomes and corresponding treatment effects framework. Next, it contains our analysis of the bias of each of the three parameters considered herein under certain assumptions. Finally, we propose a new estimation method in Section 2. Our estimator attempts to minimize the bias of estimators of the ATE that rely on unconfoundedness when, in fact, this assumption is false. Section 3 presents a Monte\nCarlo study comparing the performance of our proposed estimator to other estimators commonplace in the literature. Section 4 contains the application to school nutrition programs. Section 5 concludes. is defined as the difference between the corresponding potential outcomes. Formally,\nIn the evaluation literature, several population parameters are of potential interest. The most commonly used include the ATE, the ATT, and the ATU. These are defined as\nIn general, the parameters in (2) -(4) may vary with a vector covariates, X. As a result, each of the parameters may be defined conditional on a particular value of X as follows: \nThe parameters in (2) -(4) are obtained by taking the expectation of the corresponding parameter in (5) - (7) over the distribution of X in the relevant population (the unconditional distribution of X for the ATE, and distribution of X condition on T = 1 and T = 0 for the ATT and ATU, respectively).\nFor each individual, we observe the triple {Y i , T i , X i }, where Y i is the observed outcome, T i is a binary indicator of the treatment received, and X i is a vector of covariates. The only requirement of the covariates included in X i is that they are pre-determined (that is, they are unaffected by T i ) and do not perfectly predict treatment assignment. The relationship between the potential and observed outcomes is given by\nwhich makes clear that only one potential outcome is observed for any individual. As such, estimating \u03c4 is not trivial as there is an inherent missing data problem; some assumptions are required to proceed.\nOne such assumption is unconfoundedness or selection on observables (Rubin 1974; Heckman and Robb 1985) . Under this assumption, treatment assignment is said to be independent of potential outcomes conditional on the set of covariates, X. As a result, selection into treatment is random conditional on X and the average effect of the treatment can be obtained by comparing outcomes of individuals in different treatment states with identical values of the covariates. To solve the dimensionality problem that is likely to arise if X is a lengthy vector, Rosenbaum and Rubin (1983) propose using the propensity score,\n, instead of X as the conditioning variable."}, {"section_title": "Bias When Unconfoundedness Fails", "text": "Given knowledge of the propensity score, or an estimate thereof, and sufficient overlap between the distributions of the propensity score across the T = 1 and T = 0 groups (typically referred to as the common support condition; see Dehejia and Wahba (1999) or Smith and Todd (2005) ), the parameters discussed above can be estimated in a number of ways under the unconfoundedness assumption (D'Agostino (1998) and Imbens (2004) offer summaries). Regardless of which such technique is employed, each will be biased if the unconfoundedness assumption fails to hold. Black and Smith (2004) consider the bias when estimating the ATT under unconfoundedness and the assumption is incorrect. The bias of the ATT at some value of the propensity score, P (X), is given by\nwhere b \u03c4 AT T refers some propensity score based estimator of the ATT (e.g., propensity score matching or inverse propensity score weighting).\nTo better understand the behavior of the bias, Black and Smith (2004) make the following two assumptions:\n(A1) Potential outcomes and latent treatment assignment are additively separable in observables and unobservables\nGiven A1 and A2, (9) simplifies to\nwhere \u03c6(\u2022) and \u03a6(\u2022) are the standard normal density and cumulative density function, respectively. As noted in Black and Smith (2004) , B AT T [P (X)] is minimized when h(X) = 0, which implies that P (X) = 0.5. Thus, the authors recommend that researchers estimate \u03c4 AT T using the 'thick support' region of the propensity score (e.g., P (X) \u2208 (0.33, 0.67)).\nPrior to continuing, it is important to note that if the ATT varies with X (and, hence, P (X)), then using only observations on the thick support estimates a different parameter than the population ATT given in (3). Indeed, the procedure suggested in Black and Smith (2004) accomplishes the following. It searches over the parameters defined in (6) to find the value of P (X) for which the \u03c4 AT T [P (X)] can be estimated with the least bias. This subtle, or perhaps not so subtle, point is very intriguing. Stated differently, when unconfoundedness fails, \u03c4 AT T , the population ATT, cannot be estimated in an unbiased manner using estimators that rely on this assumption. Rather than invoking different assumptions to identify the population ATT (e.g., those utilized by selection on unobservables estimators), the Black and Smith (2004) approach identifies the parameter that can be estimated with the smallest bias under unconfoundedness.\nWhether or not the parameter being estimated with the least bias,\n, where the outer expectation is over X|0.33 < P (X) < 0.67 and T = 1, is an interesting economic parameter is a different question. The key point, however, is that when restricting the estimation sample to observations with propensity scores contained in a subset of the unit interval, the parameter being estimated will differ from the population ATT unless the treatment effect does not vary with\nWith this point in mind, we now consider the bias for the ATE and the ATU since the ATT is not the only parameter of interest in applied settings. For the ATU, it is trivial to show that\nwhich is also minimized when h(X) = 0, or P (X) = 0.5. However, it is useful to note that\nwhere \u03b4 = \u03b5 1 \u2212 \u03b5 0 is the unobserved, individual-specific gain from treatment. Thus, the magnitude of the bias of the ATU may either be larger or smaller than the corresponding bias of the ATT. If we add the following assumption:\n(A3) Non-negative selection into the treatment on individual-specific, unobserved gains\nNow consider the ATE. Utilizing the fact that\nand rewriting Y (1) = g 1 (X) + (\u03b4 + \u03b5 0 ), the bias for the ATE is given by\nEquation (12) leads to three salient points. First, the bias of the ATE is minimized when h(X) = 0 only in the case where \u03c1 \u03b4u = 0 (i.e., no selection on unobserved, individual-specific gains to treatment).\nThird, the value of P (X) that minimizes the bias of the ATE is not fixed; rather, it depends on the signs and magnitudes of \u03c1 0u \u03c3 0 and \u03c1 \u03b4u \u03c3 \u03b4 . Simulations (see Figures 1 and 2 ) reveal that B AT E [P (X)] displays the following properties:\n(a) above or below 0.5, but monotonically increasing, for \u03c1 0u \u03c3 0 \u2208 (\u2212\u03c1 \u03b4u \u03c3 \u03b4 , 0) (b) strictly less than 0.5, but decreasing in \u03c1 0u \u03c3 0 (holding \u03c1 \u03b4u \u03c3 \u03b4 fixed) for \u03c1 0u \u03c3 0 < \u2212\u03c1 \u03b4u \u03c3 \u03b4 (c) decreasing in \u03c1 \u03b4u \u03c3 \u03b4 (holding \u03c1 0u \u03c3 0 fixed) for \u03c1 0u \u03c3 0 < \u2212\u03c1 \u03b4u \u03c3 \u03b4 .\nwhere P * is the value of the propensity score that minimizes the bias in (12) . We refer to P * as the bias minimizing propensity score (BMPS). See Figure 3 for a complete characterization of P * ."}, {"section_title": "Estimation", "text": "To assess the bias of selection on observables estimators of the ATE when unconfoundedness fails, we utilize the normalized inverse probability weighted estimator of Hirano and Imbens (2001) . Horvitz and Thompson (1952) show that the ATE may be expressed as\nwith the sample analogue given b\u0177\nThe estimator in (14) is the unnormalized estimator as the weights do not necessarily sum to unity. To circumvent this issue, Hirano and Imbens (2001) propose an alternative estimator, referred to as the normalized estimator, which is given b\u0177\nMillimet and Tchernis (2007) provide evidence of the superiority of the normalized estimator in practical settings.\nUnder unconfoundedness, the normalized estimator in (15) provides an unbiased estimate of \u03c4 AT E .\nWhen this assumption fails, the bias is given (12) . To minimize the bias, we propose to estimate (15) using only observations with a propensity score in a neighborhood around the BMPS, P * . Formally, we propose the following minimum biased estimator of the ATE:\nwhere\nand C(P ) denotes a neighborhood around P . In the estimation below, we define C(P * ) as\nwhere P = max{0.02, P * \u2212 \u03b1 \u03b8 }, P = min{0.98, P * + \u03b1 \u03b8 }, and \u03b1 \u03b8 > 0 is the smallest value such that at least \u03b8 percent of both the treatment and control groups are contained in \u2126. In the exercises below, we set \u03b8 = 0.05, 0.10, and 0.25. For example, if \u03b8 = 0.05, we find the smallest value, \u03b1 0.05 , such that 5% of the treatment group and 5% of the control group have a propensity score in the interval (P , P ). Thus, smaller values of \u03b8 should reduce the bias at the expense of higher variance. Note, we trim observations with propensity scores above (below) 0.98 (0.02), regardless of the value of \u03b8, to prevent any single observations from receiving too large of a weight.\nAs defined above, the set \u2126 is unknown since, in general, P * is unknown. To estimate the set \u2126, we propose to estimate P * assuming A1, A2, and functional forms for g 0 (X), g 1 (X), and h(X) using the Heckman bivariate normal (BVN) selection model. Specifically, assuming\nwhere \u03c6(\u00b7)/\u03a6(\u00b7) is the inverse Mills' ratio, \u03b7 is a well-behaved error term, and\nThus, OLS estimation of (17) \nHowever, if these assumptions fail, then perhaps the estimator in (15) or (16) will perform better in practice. 2 To estimate P * , we conduct a grid search over 1,000 equally-spaced values of h(\u00b7) from -5 to 5. If P * is above 0.98, we truncate it to 0.98; if P * is below 0.02, we truncate it to 0.02.\nTo better understand the finite sample performance of these estimators, we now turn to our Monte Carlo study.\n3 Monte Carlo Study"}, {"section_title": "Setup", "text": "To assess the performance of the various estimators, we use five experimental designs. However, for each experimental design, we use two data-generating processes (DGPs): (i) a constant treatment effect setup (i.e., \u03c4 i = \u03c4 for all i), and (ii) a heterogeneous treatment effect setup, where the heterogeneity is due to unobserved, individual-specific gains to treatment (i.e., \u03c4 i varies across i, but this variation is unrelated to variation in observables, X). Thus, we are focusing on cases where all of the estimators being compared are estimating the same underlying parameter,\nEach experiment entails simulating 500 data sets containing\n0 otherwise for 1000 observations. Furthermore, in the constant treatment effect setup:\nwhich implies that \u03c4 i = 1 for all i and \u03c4 AT E = E [\u03c4 i ] = 1. In the heterogeneous treatment effect setup:\nOur five experimental designs are:\n1. All assumptions of the BVN selection model are correct. In particular, in the constant treatment effect setup,\nwhere\nIn the heterogeneous treatment effect setup,\nwhere\nIn addition, in both cases, the correct functional forms of the first-stage propensity score equation and the second-stage outcome equation in (17) are assumed to be known.\n2. All assumptions of the BVN selection model are correct except the second-stage outcome equation in (17) is mis-specified. Specifically, the error distributions are identical to experiment #1, and the first-stage propensity score equation is assumed to be known, but x 2 1 , x 2 2 , and x 1 x 2 are omitted from the set of covariates included in (17).\n3. All assumptions of the BVN selection model are correct except the first-stage propensity score equation and the second-stage outcome equation in (17) are mis-specified. Specifically, the error distributions are identical to experiment #1, but x 2 1 , x 2 2 , and x 1 x 2 are omitted from the set of covariates included in both the first-stage propensity score equation and (17).\n4. All assumptions of the BVN selection model are correct except the errors are uniformly distributed.\nIn particular, in the constant treatment effect setup,\nIn the heterogeneous treatment effect setup,\nwhere\nIn both cases, the correct functional forms of the first-stage propensity score equation and the second- (17) is mis-specified. Specifically, the error distributions are identical to experiment #4, and the first-stage propensity score equation is assumed to be known, but x 2 1 , x 2 2 , and x 1 x 2 are omitted from the set of covariates included in (17) .\nEach experiment is conducted for several combinations of true values for \u03c1 0u \u03c3 0 and \u03c1 \u03b4u \u03c3 \u03b4 , including the case where unconfoundedness holds. To assess the performance of the estimators, we report the mean estimates of \u03c1 0u \u03c3 0 and \u03c1 \u03b4u \u03c3 \u03b4 , and the mean values of \u03b1 \u03b8 , \u03b8 = 0.05, 0.10, and 0.25. In addition, we report the mean bias, the mean absolute error (MAE), and the mean squared error (MSE) for each estimator.\nNote, for the constant treatment effect setup, we estimate \u03c1 0u and (19) using\nwhere \u03b2 \u03bb = \u03c1 0u \u03c3 0 ."}, {"section_title": "Results", "text": "The results for the five experimental designs are presented in Tables 1-5 . Table 1 is the benchmark case;\nthe DGPs satisfy the assumptions of the BVN model, and the correct functional forms are utilized in the first-stage probit model for the propensity score and second-stage equation for the outcome. As mentioned above, even absent an exclusion restriction in the first-stage, we expect the BVN estimator to outperform the other estimators given the efficiency gain from imposing restrictions that hold in the DGP.\nThe results in Table 1 Prior to continuing, it is worth emphasizing the point that the 'optimal' \u03b8 does not go to unity when unconfoundedness holds. Thus, even when selection on observables holds in the population, finite sample performance can be improved by removing any within sample correlation among the errors. This finding is consistent with the results in Hirano et al. (2003) , who find that using an estimated propensity score is preferable even when the true propensity score is known, and Millimet and Tchernis (2007), who show that over-fitting the propensity score equation is preferable to using the true functional form. Table 2 provides the results from our second experimental design. Recall, the only deviation from the design employed in Table 1 is that now the second-stage outcome equation in (17) and (20) is mis-specified;\nwe omit x 2 1 , x 2 2 , and x 1 x 2 from the estimation. Thus, this corresponds to a situation where a researcher incorrectly assumes a linear functional form in the second-stage.\nNote two important details before turning to the results. First, the first-stage probit model for the propensity score is specified correctly. As a result, the model now contains three exclusion restrictions in the probit equation, although they are not 'valid' exclusion restrictions since x 2 1 , x 2 2 , and x 1 x 2 also have a direct effect on y. Second, because the propensity score equation is correctly specified, the performance of b \u03c4 HI will be identical to that in Table 1 ; the difference in the experimental designs does not impact this estimator. However, our estimator, b \u03c4 MB , is affected because the estimate of the BMPS, P * , depends on the estimates from the second-stage equation in (17) and (20). Thus, whether our estimator continues to outperform b \u03c4 HI is not clear a priori.\nIn terms of the results, three findings stand out. First, b \u03c4 BV N does significantly worse than any of the other estimators in terms of bias, MAE, and MSE. Specifically, the MAE ranges from roughly ten to 100 times as large; the MSE is 100 to 1000 times as large. Second, our estimator, b \u03c4 MB , continues to outperform b \u03c4 HI in all cases. Thus, our estimator continuous to constitute an improvement upon b \u03c4 HI even when unconfoundedness holds (for at least some value(s) of \u03b8).\nFinally, while not universal, a smaller value \u03b8 is generally preferable in terms of bias, MAE, and MSE as the degree of selection of unobservables increases; b \u03c4 MB,0.25 yields the smallest MAE only when unconfoundedness holds or when \u03c1 0u \u03c3 0 = 0 and \u03c1 \u03b4u \u03c3 \u03b4 = 0.15 and the smallest MSE only in two other cases where the extent of selection of unobservables is not 'sufficiently' large (the constant treatment effect setup with \u03c1 0u \u03c3 0 = 0.25 and the heterogeneous treatment effect setup with \u03c1 0u \u03c3 0 = 0.15 and \u03c1 \u03b4u \u03c3 \u03b4 = 0).\nThus, as the extent of selection on unobservables gets stronger, one wants to restrict the estimation sample to observations closer to the estimated BMPS, P * . Table 3 presents the results for the same DGPs as in the two preceding tables except now both the first-stage probit model and the second-stage outcome equation are mis-specified. Specifically, both are estimated incorrectly assuming a linear functional form; x 2 1 , x 2 2 , and x 1 x 2 are omitted. Unfortunately, this might be the most relevant case for applied researchers. The results are easily summarizable. First, none of the estimators perform well, but b \u03c4 BV N does significantly worse than the other estimators. Second, b \u03c4 MB,0.05 yields the lowest bias, MAE, and MSE in all cases. Relative to b \u03c4 MB,0.05 , the MAE (MSE) of b \u03c4 HI is roughly two to three (four to ten) times larger.\nThe results in Table 3 should have been expected given the prior results in Table 2 . The common omitted covariates from both the first-and second-stage equations generate a strong correlation between the error terms in the potential outcome equation in the untreated state and treatment assignment equation even if \u03c1 0u \u03c3 0 = 0 in the population. Thus, given the mis-specification, all cases in experimental design correspond to the case of 'sufficiently' strong selection on unobservables. In this case, as we saw in Table   2 , \u03b8 = 0.05 is preferable. Table 4 displays the results from the next experimental design. Here, we revert back to the benchmark case in that we assume the correct functional form for both the first-stage propensity score model and second-stage outcome equation are known. However, the error terms are no longer normally distributed; rather, they are drawn from a correlated multivariate uniform distribution. The results are interesting. The results are provided in Table 5 . Again, several interesting findings emerge. First, as in Table 2 , b \u03c4 BV N performs significantly worse than the other estimators. Thus, while error mis-specification (of the type analyzed here) is not particularly problematic for the BVN estimator, mis-specification of the outcome equation is very troublesome. Second, our estimator continues to outperform b \u03c4 HI when unconfoundedness holds (for \u03b8 = 0.10 and 0.25), and when it does not (for all values of \u03b8). In the heterogeneous treatment effect setup under unconfoundedness, the MAE and MSE of b \u03c4 HI is 1.3 and 1.5 times higher, respectively, than of b \u03c4 MB,0.25 . Finally, there continues to exist a negative, monotonic relationship between the 'optimal' \u03b8 and the extent of selection on unobservables as in Table 4 .\nThe results are presented in Table 12 . We report OLS estimates of the ATE in addition to the estimators considered in the Monte Carlo study. Given the increase in sample size relative to the Monte Carlo study, 5 Percentiles are obtained using the -zanthro-command in Stata. 6 Except for maternal employment, all controls come from either the fall or spring kindergarten survey.\nwe also set \u03b8 = 0.01 and 0.03. In addition, we report the coefficient estimates on the selection terms included in the BVN model, as well as the corresponding BMPS, P * , and bias obtained from (12) . Finally, all standard errors and 90% confidence intervals are obtained using 500 bootstrap repetitions. 7 Turning to Table 12 , three findings stand out. First, consonant with MTH, there is evidence of selection on unobservables. Specifically, \\ \u03c1 0u \u03c3 0 is positive and statistically significant in five of the seven models.\nWhile \\ \u03c1 \u03b4u \u03c3 \u03b4 is negative in six of the seven models, the estimates are never statistically significant. Thus, the evidence suggest that unobservables associated with higher weight in the untreated state are positively correlated with treatment participation. However, there is no statistically meaningful evidence that children select into the treatment on the basis of unobserved, individual-specific effects of treatment.\nSecond, the estimated ATE is positive and statistically significant across all outcomes when using b \u03c4 HI or b \u03c4 OLS . However, in light of the BVN estimates discussed above, as well as the evidence provided in MTH, it is unlikely that these estimators are unbiased. The BVN estimates of the ATEs, on the other hand, are negative in five of seven models, although the estimates are very imprecise; the standard errors are between 13 and 17 times larger than those for b \u03c4 HI .\nFinally, our minimum biased estimators yield estimates that are always statistically insignificant. This arises for two reasons. First, given the evidence provided here and in MTH concerning selection on unobservables, the point estimates when \u03b8 = 0.05, for example, are smaller than the corresponding Hirano and Imbens (2001) estimator in five of seven cases. Moving to \u03b8 = 0.01, the point estimates become even smaller, and are negative, in four of seven cases. Second, the standard errors when \u03b8 = 0.05 are roughly two to three times larger than for b \u03c4 HI ; the standard errors are roughly twice as large when \u03b8 = 0.01 than when \u03b8 = 0.05. Nonetheless, the fact that the point estimates diminish in the majority of cases as \u03b8 gets smaller, and four are negative for the smallest value of \u03b8, is consistent with our expectations and illustrates the usefulness of our approach.\n5 Conclusion Black and Smith (2004) propose restricting the estimation sample to observations with propensity scores around one-half when estimating the ATT under unconfoundedness, but the researcher is worried that this assumption may not hold. In this study, we extend this argument to the case where the researcher may be interested in other average treatment effect parameters such as the ATU or ATE. This extension reveals two interesting findings. First, under non-negative selection on individual-specific, unobserved gains to treatment, the bias that results when unconfoundedness fails to hold is smallest when estimating the ATT.\nSecond, the value of the propensity score that minimizes the bias of estimators of the ATE is not fixed, but rather depends on the correlation structure of the unobservables in the underlying data-generating process.\nTo operationalize this knowledge, we have proposed a new, two-stage estimation technique of the ATE. In the first-stage, one estimates the usual Heckman bivariate normal selection model in order to recover estimates of the error correlation structure. These estimates are then used to obtain the value of the propensity score that minimizes the bias of selection on observables estimators of the ATE when unconfoundedness fails. In the second-stage, one estimates the ATE using only observations within a neighborhood around this bias-minimizing value of the propensity score.\nSimulated data reveals that our approach is extremely useful in certain situations, and thus provides a nice addition to existing methods. Importantly, we show that our approach improves upon traditional selection on observables estimators not only when unconfoundedness does not hold and the usual Heckman bivariate normal selection model is mis-specified, but also when unconfoundedness holds. Future work should consider how \u03b8 may be chosen optimally in some sense, how observations may be differentially weighted depending on their proximity to the bias-minimizing propensity score, and how our method performs when the effect of treatment varies with observables. Note: P * denotes the bias-minimizing value of the propensity score. Notes: Results using estimated correlation structure are replicated from Table 1 . Results using true P* utilize the P* corresponding to the true values of \u03c1 0 \u03c3 0 and \u03c1 \u03b4 \u03c3 \u03b4 . Shaded area indicates best overall performance. True P* results are omitted under unconfoundedness since there is no unique value of P*. For further details, see Table 1 ."}, {"section_title": "Discussion", "text": "The simulation results presented, while clearly not exhausting all situations applied researchers confront, suggest a number of guidelines that researchers ought to find useful. First and foremost, researchers ought to be very wary when using the BVN estimator. Aside from the reliance on distributional assumptions, our study indicates that utilizing the proper functional form in the outcome equation is crucial. It is so crucial that we obtain drastically better estimates utilizing semiparametric estimators that require unconfoundedness even when unconfoundedness does not hold.\nSecond, regardless of whether the outcome equation used in the BVN model is correctly specified, restricting the sample to only those observations whose propensity score lies in a certain region of the unit interval, where the restricted region is determined utilizing estimates obtained from the estimation of the BVN model, improves the performance of the semiparametric estimator proposed in Hirano and Imbens (2001) . Thus, our bias minimizing approach yields a finite sample improvement over Hirano and Imbens (2001) even when the underlying assumptions of that estimator are valid in the population.\nFinally, how 'tight' to restrict the sample used in the estimation depends on the underlying correlation structure of the unobservables in the model. Among the cases considered here, the 'optimal' restriction becomes tighter as the degree of selection on unobservables increases. When unconfoundedness holds, utilizing \u03b8 = 0.25 achieves the best performance of the values considered here. However, when selection on unobservables is present, but is 'modest' in some sense, utilizing \u03b8 = 0.10 tends to do best, while \u03b8 = 0.05 is preferable under relatively 'strong' selection on unobservables.\nIn light of these recommendations, one might wonder why restricting the sample to an interval deter- Tables 1-5 with those obtained fixing the BMPS, P * , at its true value (i.e., the optimal value using the values of \u03c1 0u \u03c3 0 and \u03c1 \u03b4u \u03c3 \u03b4 from the DGP). 4 The results indicate three findings.\nFirst, when the parametric assumptions are all valid (Table 6 ) or only the error distribution is mis-specified (Table 9) , there is little substantive difference in performance between using our estimated P * and the true P * . This is not surprising given our previous finding that b \u03c4 BV N performs well in this two experiments.\nSecond, when both the outcome equation is mis-specified with or without the error distribution also being mis-specified (Tables 7 and 10 ), the is a definite gain to knowing the true P * . Note, this is a not an indictment of our estimation procedure, but it does show that the performance of our estimator, albeit better than the Hirano and Imbens (2001) estimator, can do even better with an improved estimate of P * . Finally, when both the propensity score equation and the outcome equation are mis-specified (Table   7) , using the true P * does significantly worse relative to using our estimated P * . As a result, when we 4 Note, when unconfoundness holds, P * does not take on a unique value, but all values of P * minimize the bias (and the bias is zero). Thus, we focus only on the cases where unconfoundedness does not hold.\nare using poor estimates of the propensity score -because the equation is mis-specified -we are better off choosing the estimation sample using the estimated P * based on the same mis-specified model, rather than choosing the estimation sample using the true P * combined with the poorly estimated propensity scores.\nIn sum, then, our minimum biased estimator proves to be beneficial when unconfoundedness holds, but especially when it does not. Moreover, practitioners would be wise to assess the sensitivity of the estimators to various values of \u03b8. We now illustrate this approach with an application."}, {"section_title": "Application", "text": ""}, {"section_title": "Background", "text": "To illustrate the estimation approach advocated herein using actual data, we revisit the analysis of school nutrition programs and childhood obesity in Millimet et al. (2008; hereafter MTH) . As is quite evident from recent media reports, childhood obesity is deemed to have reached epidemic status (see Rosin (2008) for a review). In light of this, school nutrition programs, particularly the School Breakfast Program (SBP), have garnered much interest. We are interested in the role of this program in the obesity crisis.\nSince extensive institutional details are provided in MTH, we simply provide a brief sketch of the SBP here. The SBP is federally funded, overseen by the US Department of Agriculture, administered by state education agencies, and been in existence for several decades. Participation by schools -both public and private -is voluntary (unless mandated by the state). If schools do participate, they are reimbursed a fixed amount per breakfast served. However, to qualify for reimbursement, the meals must meet federal nutrition guidelines. Finally, students residing in households with family incomes at or below 130% of the federal poverty line are eligible for free meals, while those in households with family incomes between 130% and 185% of the federal poverty line are entitled to reduced price meals. Schools are reimbursed at a higher rate per free or reduced price meals served. Currently, about 10 million students eat breakfast at school on any given day (covering about 80% of all schools).\nResearchers interested in analyzing the causal effect of participation in either program have been concerned with the possible non-random selection of students into the program. MTH find evidence of positive selection on weight (in levels and growth rates) into the SBP (see also Bhattacharya et al. (2006) ). In light of the Monte Carlo results above, this suggests a lower value of \u03b8 is more appropriate when analyzing the impact of participation in the SBP."}, {"section_title": "Data", "text": "The data are obtained from Early Childhood Longitudinal Study-Kindergarten Class of 1998-99 (ECLS-K) and are identical to MTH; thus, we only provide limited details. We measure of participation in the SBP at the earliest possible date, which is in spring kindergarten. Our outcomes of interest are measures of child health in spring third grade or the change from fall kindergarten to spring third grade. As such, we are analyzing more of the long-run relationship between child health and participation in these two programs.\nSpecifically, we utilize seven measures of child health: where we define overweight (obesity) as having a BMI above the (85 th ) 95 th percentile. 5 To control for student, parental, and environmental factors, the following covariates are included in X:\nchild's race (white, black, Hispanic, Asian, and other) and gender, child's birthweight, household income, mother's employment status, mother's education, number of children's books at home, mother's age at first birth, an indicator if the child's mother received WIC benefits during pregnancy, region, city type (urban, suburban, or rural), and the amount of food in the household. 6 Given the nature of our data, children with missing data for gender and race are dropped from our sample. Missing values for the remaining control variables are imputed and imputation dummies are added to the control set. The final sample contains 13,534 students, of which 3,161 participate in the SBP. Table   11 provides summary statistics."}, {"section_title": "Constant Treatment Effect", "text": "Heterogeneous Treatment Effect 0.15 0.30 0 Notes: Results using estimated correlation structure are replicated from Table 2 . For further details, see Table 6 . Notes: Results using estimated correlation structure are replicated from Table 3 . For further details, see Table 6 . Notes: Results using estimated correlation structure are replicated from Table 4 . For further details, see Table 6 . Notes: Results using estimated correlation structure are replicated from Table 5 . For further details, see Table 6 . Notes: N = 13,534 (full sample); 3,161 (SBP participants); 10,373 (SBP non-participants). Data are from spring third grade wave of ECLS-K. Change in BMI percentile and BMI growth rate calculated using baseline data from fall kindergarten. Omitted category for race is 'other', city type is 'small town & rural', mother's age at first birth is greater than 29 years old, mother's employment is 'missing', mother's education is 'less than high school', and sufficient food is 'sometimes or often there is not enough to eat'. "}, {"section_title": "Constant Treatment Heterogeneous Treatment Effect", "text": "\n\n\n"}]