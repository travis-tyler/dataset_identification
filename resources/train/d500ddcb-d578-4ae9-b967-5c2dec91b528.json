[{"section_title": "Abstract", "text": "other forms of related neurodegenerative diseases. Source code for DKT is available online: https://github.com/mrazvan22/dkt."}, {"section_title": "", "text": "Abstract. We introduce Disease Knowledge Transfer (DKT), a novel technique for transferring biomarker information between related neurodegenerative diseases. DKT infers robust multimodal biomarker trajectories in rare neurodegenerative diseases even when only limited, unimodal data is available, by transferring information from larger multimodal datasets from common neurodegenerative diseases. DKT is a joint-disease generative model of biomarker progressions, which exploits biomarker relationships that are shared across diseases. As opposed to current deep learning approaches, DKT is interpretable, which allows us to understand underlying disease mechanisms, and can also predict the future evolution of subjects instead of solving simpler control vs diseased classification tasks. Here we demonstrate DKT on Alzheimer's disease (AD) variants and its ability to predict trajectories for multimodal biomarkers in Posterior Cortical Atrophy (PCA), in lack of such data from PCA subjects. For this we train DKT on a combined dataset containing subjects with two distinct diseases and sizes of data available: 1) a larger, multimodal typical AD (tAD) dataset from the TADPOLE Challenge, and 2) a smaller unimodal Posterior Cortical Atrophy (PCA) dataset from the Dementia Research Centre (DRC) UK, for which only a limited number of Magnetic Resonance Imaging (MRI) scans are available. We first show that the estimated multimodal trajectories in PCA are plausible as they agree with previous literature. We further validate DKT in two situations: (1) on synthetic data, showing that it can accurately estimate the ground truth parameters and (2) on 20 DTI scans from controls and PCA patients, showing that it has favourable predictive performance compared to standard approaches. While we demonstrated DKT on Alzheimer's variants, we note DKT is generalisable to Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wpcontent/uploads/how to apply/ADNI Acknowledgement List.pdf"}, {"section_title": "Introduction", "text": "The estimation of accurate biomarker signatures in Alzheimer's disease (AD) and related neurodegenerative diseases is crucial for understanding underlying disease mechanisms, predicting subjects' progressions, and enrichment in clinical trials. Recently, data-driven disease progression models were proposed to reconstruct long term biomarker signatures from collections of short term individual measurements [1, 2, 3] . When applied to large datasets of typical AD, disease progression models have shown important benefits in understanding the earliest events in the AD cascade [2] , quantifying biomarkers' heterogeneity [4] and they showed improved predictions over standard approaches [2] . However, by necessity these models require large datasets -in addition they should be both multimodal and longitudinal. Such data is not always available in rare neurodegenerative diseases. In particular, most datasets for rare neurodegenerative diseases come from local clinical centres, are unimodal (e.g. MRI only) and limited both cross-sectionally and longitudinally -this makes the application of disease progression models extremely difficult. Moreover, such a model estimated from common diseases such as typical AD may not generalise to specific variants. For example, in Posterior Cortical Atrophy (PCA) -a neurodegenerative syndrome causing visual disruption -posterior regions such as the occipital lobe are affected early, instead of the hippocampus and temporal regions in typical AD.\nThe problem of limited data in medical imaging has so far been addressed through transfer learning methods. These were successfully used to improve the accuracy of AD diagnosis [5] or prediction of MCI conversion [6] , but have two key limitations. First, they use deep learning or other machine learning methods, which are not interpretable and don't allow us to understand underlying disease mechanisms that are either specific to rare diseases, or shared across related diseases. Secondly, these models cannot be used to forecast the future evolution of subjects at risk of disease, which is important for selecting the right subjects in clinical trials.\nWe propose Disease Knowledge Transfer (DKT), a generative joint model that estimates continuous multimodal biomarker progressions for multiple diseases simultaneously -including rare neurodegenerative diseases -and which inherently performs transfer learning between the modelled phenotypes. This is achieved by exploiting biomarker relationships that are shared across diseases, whilst accounting for differences in the spatial distribution of brain pathology. DKT is interpretable, which allows us to understand underlying disease mechanisms, and can also predict the future evolution of subjects at risk of diseases.\nWe apply DKT on Alzheimer's variants and demonstrate its ability to predict non-MRI trajectories for patients with Posterior Cortical Atrophy, in lack of such data. This is done by fitting DKT to two datasets simultaneously: (1) the TADPOLE Challenge [7] dataset containing subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) with MRI, FDG-PET, DTI, AV45 and AV1451 scans and (2) MRI scans from patients with Posterior Cortical Atrophy from the Dementia Research Centre (DRC), UK. We first show that the estimated trajectories for PCA and tAD subjects are plausible as they agree with previous literature findings. We further validate DKT on simulated data from two synthetic diseases with known ground truth, and a set of 20 DTI scans from controls and PCA patients, showing it yields favourable performance compared to standard approaches. Code for DKT is available online: https://github.com/mrazvan22/dkt. Fig. 1 shows the overall diagram of the DKT framework. We assume that the progression of each disease (X-axis, top row) can be modelled as a unique evolution of dysfunction trajectories (top row) representing multimodal pathology within a specific brain region. Each dysfunction trajectory is modelled as the progression of several biomarkers within that same region, but acquired using different types of modalities (e.g. MRI, PET or DTI, see Fig. 1 bottom row). Each group of biomarkers in the bottom row will be called a disease-agnostic unit or simply agnostic unit, because the biomarker dynamics are assumed to be shared across all diseases modelled."}, {"section_title": "Method", "text": ""}, {"section_title": "Method Overview", "text": "The assumption that the dynamics of some biomarkers are disease-agnostic (i.e. shared across diseases), is key to DKT. There are several reasons why we can make this assumption. First of all, pathology in many related neurodegenerative diseases ( e.g. Alzheimer's variants) are hypothesised to share the same underlying mechanisms (e.g. amyloid and tau accumulation), and within one region, such accumulation leads to the same pathology dynamics across all the related disease variants: hypometabolism (FDG PET), neuronal damage (T1/DTI MRI) and region-specific cognitive decline [8] -the difference between these variants is that distinct brain regions are affected at different times and with different pathology rates and extent, likely caused by selective vulnerability of networks within these regions [9] . Secondly, even if the diseases share different upstream mechanisms (e.g. amyloid vs tau accumulation), downstream biomarkers measuring hypometabolism, white matter degradation and structural markers follow the same pathological cascade and will have similar dynamics across diseases. We choose to model the correlations within each agnostic unit using the disease progression model (DPM) by [3] , but any other DPM can also be used. The DPM allows us to reconstruct unit-specific dysfunction progression manifolds (bottom row, X axis), which can be used for staging subjects. Finally, we use the same model to express the progression within each disease (Figure 1 Fig. 1 : Diagram of the proposed DKT framework. We assume that each disease can be modelled as the evolution of abstract dysfunction scores (Y-axis, top row), each one related to different brain regions. Each region-specific dysfunction score then further models (X-axis, bottom row) the progression of several modality-specific biomarkers within that same region. For instance, the temporal dysfunction, modelled as a biomarker in the disease specific model (top row), is the X-axis in the disease agnostic model (temporal unit, bottom row), which aggregates together abnormality from amyloid, tau and MR imaging within the temporal lobe. The biomarker relationships within the bottom units are assumed to be disease agnostic and shared across all diseases modelled. Disease knowledge transfer can then be achieved via the disease-agnostic units. Mathematical notation from section 2 is shown in red to ease understanding.\nin terms of the dysfunction scores estimated within each agnostic unit. More precisely, the X-axis dysfunction scores from the agnostic units become Y-axis measurements in the disease specific models."}, {"section_title": "Disease-Specific Model", "text": "In this section we model the biomarker dynamics that are specific to each disease, by mapping the subjects' disease stages to dysfunction scores. We model the progression of related diseases as the unique dynamics of abstract dysfunction scores, which aggregate together data from multiple biomarkers. We assume that each subject i at each visit j has an underlying disease stage s ij = \u03b2 i + m ij , where m ij represents the months since baseline visit for subject i at visit j and \u03b2 i represents the time shift of subject i. We then assume that each subject i has a dysfunction score \u03b3 l i corresponding to multimodal pathology in brain region l, which is a function of its disease stage:\nwhere f is a smooth monotonic function mapping each disease stage to a dysfunction score, having parameters \u03bb l di corresponding to agnostic unit l \u2208 \u039b, where \u039b is the set of all agnostic units. Moreover, d i \u2208 D represents the index of the disease corresponding to subject i, where D is the set of all diseases modelled. For example, MCI and tAD subjects from ADNI as well as tAD subjects from the DRC cohort can all be assigned d i = 1, while PCA subjects can be assigned d i = 2. We implement f as a parametric sigmoidal curve similar to [3] , to enable a robust optimisation and because this accounts for floor and ceiling effects present in AD biomarkers. Variable k denotes the variance of measurements for biomarker k."}, {"section_title": "Disease-Agnostic Model", "text": "We model the biomarker dynamics that are disease-agnostic, by constructing the mapping from the dysfunction scores \u03b3 l i to the biomarker measurements. We assume a set of given biomarker measurements Y = [y ijk |(i, j, k) \u2208 \u2126] for subject i at visit j in biomarker k, where \u2126 is defined as the set of available biomarker measurements, since subjects can have missing biomarkers at various visits. We further denote by \u03b8 k the trajectory parameters for biomarker k \u2208 K within its agnostic unit \u03c8(k), where \u03c8: {1, ..., K} \u2192 \u039b maps each biomarker k to a unique agnostic unit l \u2208 \u039b. These definitions allow us to formulate the likelihood for a single measurement y ijk as follows:\nwhere g( . ; \u03b8 k ) represents the trajectory of biomarker k within agnostic unit \u03c8(k). Parameters \u03bb \u03c8(k) di are used to define \u03b3 \u03c8(k) i based on Eq. 1, where agnostic unit l is now referred to as \u03c8(k), to clarify that this is the unit where biomarker k has been allocated."}, {"section_title": "Extending to Multiple Subjects and Biomarkers", "text": "We extend the above model to multiple subjects, visits and biomarkers to get the full model likelihood:\nwhere y = [y ijk |\u2200(i, j, k) \u2208 \u2126] is the vector of all biomarker measurements, while \u03b8 = [\u03b8 1 , ..., \u03b8 K ] represents the stacked parameters for the trajectories of biomarkers in agnostic units, \u03bb = [\u03bb l d |l \u2208 \u039b, d \u2208 D] are the parameters of the dysfunction trajectories within the disease models, \u03b2 = [\u03b2 1 , ..., \u03b2 N ] are the subject-specific time shifts and = [ k |k \u2208 K] estimates biomarker measurement noise. Here we assumed independence across different subjects, but the biomarker measurements and visits are linked through the latent time-shift \u03b2 i for each subject. The parameters of the model that need to be estimated are [\u03b8, \u03bb, \u03b2, ]."}, {"section_title": "Parameter Estimation", "text": "We estimate the model parameters using a two-stage approach. In the first stage, we perform belief propagation within each agnostic unit and then within each disease model. In the second stage we jointly optimise across all agnostic units and disease models using loopy belief propagation. An overview of the algorithm is given in Figure 2 . Given the initial parameters estimated from the first stage (line 1), the algorithm continuously updates the biomarker trajectories within the agnostic units (lines 4-5), dysfunction trajectories (line 8) and subject-specific time shifts (line 10) until convergence. The cost function for all parameters is nearly identical, the main difference being the measurements (i, j, k) over subjects i, visits j and biomarkers k that are selected for computing the measurement error.\nFor estimating the trajectory of biomarker k within agnostic unit \u03c8(k), measurements are taken from \u2126 k representing all measurements of biomarker k from all subjects and visits. For estimating the dysfunction trajectories, \u2126 d,l represents the measurement indices from all subjects with disease d (i.e. d i = d) and all biomarkers k that belong to agnostic unit l (i.e. \u03c8(k) = l). Finally, \u2126 i (line 10) represents all measurements from subject i, for all biomarkers and visits.\n1 Initialise \u03b8 (0) , \u03bb (0) , \u03b2 (0) 2 while \u03b8, \u03bb, \u03b2 not converged do ; // Estimate biomarker trajectories (disease agnostic)\n; // Estimate dysfunction trajectories (disease specific)\n; // Estimate subject-specific time shifts "}, {"section_title": "Generating Synthetic Data", "text": "We first test DKT on synthetic data, to assess its performance when ground truth is known. More precisely, we generate data that follows the DKT model exactly, and test DKT's ability to recover biomarker trajectories and subject time-shifts. We generate synthetic data from two diseases (i.e. synthetic PCA and synthetic AD) using parameters from Table 1 , emulating the TADPOLE and DRC cohorts. The six biomarkers (k 1 -k 6 ) have been a-priori allocated to two agnostic units l 0 and l 1 . To simulate the lack of multimodal data in the synthetic PCA subjects, we discarded the data from biomarkers k 0 , k 1 , k 4 and k 5 for all these subjects. Remaining biomarkers k 2 and k 3 , for which data was still available in the synthetic PCA cohort, are assumed to be of the same modality (e.g. MRI volume) but to represent measurements from different brain regions (e.g. temporal and occipital). "}, {"section_title": "Data Acquisition and Preprocessing", "text": "We trained DKT on ADNI data from the TADPOLE challenge [7] , since it contained a large number of multimodal biomarkers already pre-processed and aggregated into one table. From the TADPOLE dataset we selected a subset of 230 subjects which had at least one FDG PET, AV45, AV1451 or DTI scan. Most subjects also had MRI scans and cognitive tests. In order to model another disease, we further included 76 PCA subjects from the DRC centre in the training set, along with 67 tAD and 87 age-matched controls, all of which only had MRI scans.\nFor both datasets, we computed multimodal biomarker measurements corresponding to each brain lobe: MRI volumes using the Freesurfer software, FDG-, AV45-and AV1451-PET standardised uptake value ratios (SUVR) extracted with the standard ADNI pipeline, and DTI fractional anisotropy (FA) measures from white-matter regions adjacent to each lobe. For every lobe, we regressed out the following covariates: age, gender, total intracranial volume (TIV) and dataset (ADNI vs DRC). Finally, we normalised the biomarker values to lie within the [0,1] range. For each lobe, we allocated all multimodal biomarkers corresponding to that lobe to its own agnostic unit.\nFor demonstrating DKT's performance at predicting missing biomarkers in PCA, we used a separate test set of 20 DTI scans from controls and PCA subjects from the DRC dataset. As this test set was acquired at a centre different from ADNI and on different scanners, we matched the FA mean and standard deviation of the DRC controls to be equal to the FA mean and standard deviation of the ADNI controls. No DTI data from PCA subjects was exposed to the algorithm at training time."}, {"section_title": "Results on Synthetic and Patient Datasets", "text": "Results on synthetic data are presented in Fig. 3 , showing the true and estimated subject shifts and trajectories for each agnostic unit l and biomarker k (see figure caption for detailed description). Results suggest that the DKT-estimated trajectories match closely (MAE < 0.058) with the true trajectories, for both the unit-trajectories within the disease-specific models and the biomarker trajectories within the disease-agnostic models. Moreover, the subject time-shifts are very close (R 2 > 0.98) to the true time-shifts.\nResults on TADPOLE and DRC datasets are presented in Fig. 4 , showing the estimated biomarker trajectories within the occipital unit plotted over the dysfunction scores, along with aligned subject data. The model shows an unbiased data fit (Fig. 4A) , and we can observe most PCA subjects having abnormal occipital volumes, thus leading to high occipital dysfunction scores, in line with the current understanding of PCA as affecting posterior regions [10] . We also show the progression of dysfunction scores over the disease stage for typical AD ( Fig 4B) and PCA ( Fig 4C) . While both typical AD and PCA show early hippocampal dysfunction, PCA shows higher dysfunction in the occipital, temporal and parietal regions in late stages, while tAD shows widespread dysfunction, in line with previous literature findings [10] .\nIn Fig. 5 , we plot the inferred trajectories for PCA directly across the disease progression, for all five modalities analysed. The results again recapitulate known patterns in PCA, where posterior regions are predominantly affected in all modalities. However, for MRI volumes and AV45, we also see early abnormalities, which we attribute to the models underestimating the biomarker measurement noise."}, {"section_title": "Validation on DTI Data in PCA", "text": "We validated our model using a separate test set of 20 DTI scans from controls and PCA patients from the DRC. We used DKT to predict the DTI biomarker values for the subjects within the unseen test set, using only their MRI biomarkers. Table 2 shows the prediction mean squared error (MSE) and rank correlation between the DKT-predicted biomarker values and the measured values. We computed the rank correlation in order to remove the effect of any systemic biases due to the completely different progressive disease and dataset that we are predicting on. We also show the same performance metrics for two simpler models:\n(1) a latent stage model, as described in [3] , which assumes all tAD and PCA subjects follow the same progression and (2) a linear univariate model that predicts the DTI biomarker based on the corresponding MRI biomarker, independently for each region.\nThe results from Table 2 indicate that the DKT prediction errors are relatively small for the frontal, occipital, temporal and parietal areas. Moreover, the rank correlations of the DKT predicted values are also high for the cingulate lobe and the hippocampus. In terms of model comparison, DKT has better performance than the linear model (all results significant with p < 0.002, Bonferroni corrected), since it uses information across all brain regions instead of assuming independence across regions. While DKT has similar performance to the latent stage model, it does not assume that the diseases have the same progression and it allows us to understand mechanisms that are shared between related diseases. "}, {"section_title": "Discussion", "text": "We presented DKT, a framework that enables, for the first time, joint modelling of biomarker progressions in multiple neurodegenerative diseases simultaneously. The framework allows the inference of biomarker trajectories in rare diseases, for which there is not enough data to allow estimation of such trajectories, and accounts for a different spatial distribution of pathology between distinct phenotypes. Our approach is also interpretable, enabling us to understand complex mechanisms underpinning these diseases. While we provided an example implementation of DKT using specific models of the biomarker trajectories, measurement noise and link function (the disease progression score), DKT should be considered as a general framework for joint modelling of biomarker trajectories within different diseases simultaneously. The actual implementation of DKT can thus be extended to use non-parametric Fig. 5 : Estimated trajectories for the PCA cohort. The only data that were available were the MRI volumetric data. The dynamics of the other biomarkers has been inferred by the model using data from typical AD, and taking into account the different spatial distribution of pathology in PCA vs tAD. trajectories, or more complex link functions that estimate not only subject timeshifts but also progression speed or higher order terms. While here we have focused on Alzheimer's variants such as tAD and PCA, DKT can also be applied to other progressive neurodegenerative diseases of non-Alzheimer's type and even the normal ageing process. While we only used imaging data, cognitive tests can also be included in the disease-specific submodels of DKT, or even allocated in the agnostic units of the regions that are responsible for those tasks.\nOur work has several limitations: 1) DKT assumes all subjects within a disease follow the same trajectory, without considering heterogeneity within the disease population, 2) the allocation of biomarkers into agnostic units has to be done using a-priori human knowledge, 3) DKT currently works only on extracted brain features, discarding important information present in the brain morphometry, 4) for validation, the synthetic experiment we ran was limited to only one setting of parameters mimicking the datasets from TADPOLE and the DRC centre and 5) the validation on patient data was also done only on a small set of 20 DTI scans, due to lack of multimodal data in PCA.\nThere are several potential avenues for further research: 1) to account for heterogeneity, DKT can be easily extended to include subject-specific effects; 2) improved schemes for biomarker allocation to agnostic units can take connectivity into account, or derive it from the data automatically; 3) to account for brain morphometry and connectivity, DKT can be extended into a fully spatiotemporal model, by estimating continuous changes in volumetric brain imagesin this case, each voxel can have an associated dysfunction score that is derived from measurements of various modalities from that voxel; 4-5) DKT can be further validated on more complex synthetic experiments with a range of parameter settings, as well as on patient data from ADNI, where the population could be a-priori split into sub-groups with different progressions.\nAs a key direction of further research, DKT can be used to understand novel mechanisms within a disease (e.g. AD variants), as well as across diseases (e.g. AD vs FTD). For AD variants in particular, one can study whether early biomarkers such as amyloid and tau have different dynamics compared to typical AD, and what these differences are. This can be done by choosing different a-priori allocations of biomarkers to agnostic units -e.g. allocating amyloid and tau into one a shared agnostic unit, or otherwise directly to the disease specific models, thus making them dependent on the disease. The model with the best data fit or predictive power will indicate the most likely mechanism."}]