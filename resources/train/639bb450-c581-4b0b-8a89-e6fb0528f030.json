[{"section_title": "", "text": "Introduction 1.2 A measurement framework for drivers of student outcomes and school quality 1.3 The structure of this report 2 The drivers of school quality -establishing a measurement framework Implications for government and future research directions 5.1 An evidence base on schooling systems, practice and performance in Australia 5.1.1 Results of empirical analysis of drivers of school quality 5.1.1 A framework for understanding the role of government in the school system 5.1.2 The current state of schooling policy in Australia However, there remains a gap in the evidence base to support findings on the drivers of school quality in Australia. This arises from the fact that: \uf0b7 While this existing evidence base has helped us understand the factors that drive educational outcomes in schools, the link between this evidence base and the role of government is often less clear and few researchers seek to provide a summative structure which relates their findings to implications for government."}, {"section_title": "\uf0b7", "text": "Further, this evidence typically relies on a range of studies conducted on students in different educational contexts and systems which make meaningful comparisons of their relative effects on a consistent measure of student outcomes hard to establish. Few studies have sought to conduct empirical analysis of the drivers of student outcomes, and school quality, using a comprehensive dataset of Australian students and schools. Similarly, few studies seek to use such an evidence base to link the drivers of school quality to the role of government. This research study is differentiated from previous research as it seeks to use a consistent set of Australia-specific evidence on student outcomes and school practice to provide insights on the drivers of school quality within a single consistent framework. This makes it possible to identify the relative effect sizes of different drivers of school quality, information that is not presented by the existing literature. Any analysis of this nature is limited by the quality of the data available. This study utilises indicators of practice contained in the PISA and TIMSS datasets to match particular aspects of practice to observed student outcomes. The accuracy of the results is therefore limited in part by the quality of the matching exercise facilitated by these datasets and the quality and appropriateness of the questions that comprise these datasets. Hence, this report provides evidence on the most important drivers of school quality, while noting that the approach may be further refined over time as better evidence becomes available.\nThe attributes of practice that define school quality, and how these attributes may be measured; and \uf0b7 The role that governments can play in influencing school practice and driving improvements in school quality. It is possible to organise the contributing factors to student learning outcomes into three broad categories: 1. Student factors-including factors that relate to a student's background, and context, as well as measures of prior achievement and self-efficacy in learning. 2. School level factors-including aspects of teaching efficacy, school practice and management, and other aspects of school practice. 3. System level factors-including characteristics of schooling systems, such as autonomy, accountability and resourcing. Within each of these categories is a range of factors that are known to influence student outcomes. Some of these (such as socio-economic status) are identified and measured in international datasets such as PISA and TIMSS. 1 Others may be identified through external evidence sources, such as system level attributes relating to policy and regulatory settings.\nThe questions contained in the PISA and TIMSS datasets are then mapped to these themes, effectively creating proxy variables in these datasets for each of the themes. iii \uf0b7 Student outcomes are then regressed against these drivers to empirically determine which elements of practice have the greatest impact on student outcomes. These identified aspects of practice are defined as the drivers of school quality. Figure i below provides a high-level overview of this measurement framework, which relates system, school, and student level factors to a set of nine anchor themes. These themes represent the key drivers of student outcomes that have been identified through a targeted review of the leading literature on what matters in school education internationally. \nFollowing from the static nature of the PISA and TIMSS tests, it is not generally possible to account for students' prior achievement when measuring the effect of practice on outcomes. This may overstate the effects of aspects of school quality on student outcomes relative to their actual effect, particularly in the presence of ability-based school selection policies. Using the TIMSS data, the analysis can focus on variation between individual classrooms (including their teachers), rather than variation between schools. As outlined in Chart i below, the contribution made by classroom quality to student outcomes is typically higher than the contribution made by school quality. This finding is consistent with evidence from similar studies which emphasise the significance of individual teaching practice in driving student outcomes, irrespective of the specific school environment. It should also be noted that PISA and TIMSS are different assessments in terms of the skills examined. In particular, noting that TIMSS is a curriculum based test (while PISA measures student skills in reading, maths and science) and that the age and grade of students is higher in PISA than TIMSS it may be expected that classroom related factors (such as teaching practice) would be more important in TIMSS than PISA. viii Estimates of the contribution of school quality, classroom quality and other factors to student outcomes\nIn this context, government can play a central role in curating and evaluating the evidence base which schools draw upon when making decisions about their practice and management. -Schools do not make decisions about professional learning and pedagogy in isolation. Indeed, they are influenced by a wide range of sources, such as professional bodies, private educational businesses, academics and government. -Current examples of best practice in collating such an evidence base include the NSW Centre for Education Statistics and Evaluation and the Education Endowment Foundation's Teaching and Learning Toolkits. -These enabling initiatives can influence the consistency of practice and management interventions which schools utilise to improve their performance. A strong evidence base serves as a useful guide for policymakers and school decision-makers about interventions that improve student outcomes. A high quality and transparent evidence base, when combined with effective accountability processes, may provide the necessary assurance that the schooling system is investing in higher quality education practice. One of the most important levers available to the Australian Government to change school practice is that of funding. One of the aims of the government's Quality Schools, Quality Reforms initiative is to ensure \"public accountability for the way in which funding is distributed, how that funding is used behind the school gate and achievement of outcomes\". This transparency -around the funding given to schools, the interventions being tried in schools, and the outcomes for students subject to these interventions -helps to continue the development of the education evidence base described above. This study has identified a significant and diverse range of schooling policy interventions which have occurred in Australian schools over the past 10-15 years. While diversity and complexity in policy design and application need not necessarily be a shortcoming, the lack of a consistent and universal basis for evaluating the impact of policy on student-level outcomes means there exists little capacity to ensure Australia is on a path towards overall school improvement. It may be that Australia can make material progress in improving school quality not by making new or different interventions, but instead by more consistently adopting and applying proven best practice (and distributing resources accordingly). This can only be achieved through better data and evidence, and better sharing of and access to that data, across Australia's schooling system. Through greater transparency of student outcomes, school practice and system settings, government-in particular, the Australian Government-will be in a better position to evaluate current initiatives and practice across Australia. More specifically, governments can play a key role in the improvement of school quality through ensuring that policy makers consistently: \uf0b7 Demonstrate the link to improvements in teaching practice before investing in initiatives intended to drive improvements in outcomes. \uf0b7 Set a strategic and long-term focus on the outcomes impact of sustained changes to practice at the classroom level. xi \uf0b7 Rely on, and encourage the use of, evidence-based interventions across Australian classrooms.\nCollect and share data and evidence on how interventions result in improved practice. Figure vii below presents a framework for understanding the factors that influence school practice, and the role of government in determining system settings and enabling initiatives which provide the necessary conditions for schools to identify and invest in high quality practice. This framework emphasises the role of government in monitoring and evaluating the effectiveness of school practice to inform the system settings and enabling initiatives which guide decision-making, while simultaneously holding the system accountable for driving improvements in student outcomes. \nAdding further causal structure to the empirical analysis to understand how different drivers of quality affect each other, and then subsequently drive student outcomes (for example, by estimating the link between school leadership and teaching practice).\nThe indicators in the PISA and TIMSS datasets are then matched to these themes based on which theme each indicator is most likely to represent. A representative indicator (or set of indicators) is then selected in order to proxy and measure the extent of each quality driver (theme) faced by a student. This selection of representative indicators is based on a statistical selection process.\nRegression analysis is then undertaken to analyse the relative effects of the identified drivers on student outcomes, and to compare the relative sizes of these effects in order to determine what drivers of quality have the greatest effect on outcomes. These observable characteristics at the classroom, school, system, and jurisdiction level are central to this study's enquiry into what drives student outcomes, from the perspective of government. In thematically constructing and identifying these drivers of student outcomes, the aim of this study is to-to the greatest extent possible-link these back to tangible levers for government, and to identify where governments should broadly direct their attention to have the greatest impact on student outcomes (and in what contexts and circumstances). This work does not go so far as to consider the impact of particular initiatives, but rather provides a broad strategic framework in which governments and schools have areas of focus in improving school outcomes. The findings of this study are only accurate to the extent that the PISA and TIMSS questions are good proxies for the themes they are intended to represent. In many cases, judgement has been applied when interpreting and categorising these questions for the purposes of analysis and alternative approaches to categorisation may result in different empirical findings. This study looks to examine the effects of education practice on outcomes using proxy measures of outcomes available in these datasets. This is in contrast to an approach built on actual field analysis of practice in classrooms, which may provide more nuanced and robust findings on the drivers of school quality in schools (albeit, for a smaller subset of observed schools and teachers). In this regard, this study has sought to develop a robust and replicable methodology which may be used by the Department to explore the relative effects of different drivers of school quality using the PISA and TIMSS datasets. This would naturally be achieved by building on and refining this initial approach over time.\nChapter 3 summarises the approach taken to matching the findings from the literature review to the PISA and TIMSS datasets, and how this is then used to test empirically for the core drivers of students' outcomes. \uf0b7 Chapter 4 presents the findings from the empirical analysis.\nChapter 5 summarises the analysis and provides the key implications for government by the findings and identifies future research that could build on the results of this analysis.\nTeacher attributes -Static and indirect in the way it influences teaching efficacy, these drivers are present with teachers before they enter the classroom setting.\nTeaching practice -Dynamic in the context of the classroom environment, these drivers are direct in that they are transmitted immediately from the teacher to the student. This study uses the term 'teaching efficacy', broadly synonymous with teaching quality, to characterise these attributes and practices which influence student outcomes.\nMultilevel models -the multi-level modelling approach has strong advantages as it does account for the nested nature of educational data (Lu and Rickard, 2014). The degree of levels that can be simultaneously modelled are: -Intra-student level: performance across tests in current and previous years; -Student level; -Teacher level; and -School level. Previous multilevel models have attempted to approach measuring school effectiveness by omitting non educational factors, with the assumption being that prior achievement has accounted for this as proposed by Sanders (2000). Other studies have found insufficient evidence supporting this claim (Griffin, Woods & Nguyen, 20005;OECD, 2008), leading to the inclusion of noneducational factors. The resultant model has been labelled as multilevel contextual value added models. Multilevel contextual value added models have also utilised PISA data when investigating international differences in student performance. Most notably Fuchs and Woessmann (2004) use this approach to yield significant findings with the model accounting 85% of the between country variation, with roughly 25% of variation accruing to institutional variation.\nThe IEA Trends in International Mathematics and Science Study (TIMSS), which tests students' curriculum knowledge and learning progress in maths and science in year 4 and year 8. 10 Both datasets provide measures of student cognitive outcomes, from 2000 to 2015 in the case of PISA, and from 2003 to 2015 in the case of TIMSS. They also include details about: \uf0b7 A range of student and school attributes (such as student socio-economic background, highest parental education, indigenous status and school location); \uf0b7 Questions that measure students' engagement, wellbeing, and learning self-efficacy; \uf0b7 Questions of school principals, teachers and students which capture a range of measures of approaches to school practice and management and the climate of the school (these were mapped to the themes within the measurement framework, identified through the literature review). PISA and TIMSS take stratified random samples of students and schools in Australia, to ensure adequate representation among key characteristics at both the student and school level such as indigenous status and school sector. The approach to sampling in PISA changed between 2009 and 2012: the number of schools sampled more than doubled, with a commensurate reduction in the average number of students in each school. A summary of the number of students, schools and the average number of students in each school is provided in Table 3.1 below. As outlined in the table above, the PISA dataset captures a sample of students within a school, where these students may come from a range of different classrooms with different teachers. In contrast, the TIMSS dataset samples students from specific classes in a school (although in some schools, some students from outside the core class also sit the assessment). This means that it is possible to link teachers directly with students in the TIMSS dataset, but not for the PISA dataset. The PISA and TIMSS datasets measure student outcomes through standardised tests, where estimates of achievement are based on statistical measures of the underlying academic ability of the student (that is, the tests of ability are measured with error, and the test results are interpreted as predictions of a student's academic ability). Scores are general presented in numerical terms and generally range from 360 to 630 for PISA and 390 to 610 for TIMSS. 11\nThe question with the greatest significance is selected as the first representative question. Other questions within the sub-theme that are highly correlated with this question are 'represented' by this question, and are not included in the full analysis. The correlation threshold is set at 0.3, however this may be varied to provide a more or less strict threshold for inclusion, and varying the threshold can support robustness checks. The threshold was set at a relatively low level to reduce the full set of questions down to a tractable number. However, it is possible that questions that are weakly linked together have been included together. This parameter may be altered in future applications of the methodology \uf0b7 If there are un-discarded questions after the first round of clustering, the question with the lowest correlation to the first representative question is chosen as the second representative question.\nThe process is repeated until there are no more questions left (either unchosen as a representative question or un-discarded) in the sub-theme.\nThe final list of representative questions are then included in the full model as drivers of student outcomes, representing the drivers of school quality. It should be noted that this process is in part subjective. Due to the specific availability of information contained within PISA and TIMSS questionnaires, and further with the subjective mapping of questions, the results that arise from the proceeding analysis are predicated on the process outlined above and may be altered under alternative assumptions and qualitative heuristics. This is an inherent constraint to the analysis, however the analytical process utilised in this study is intuitive and aims to make best use with the data available.\nThe number of government initiatives in the schooling sector across Australia is practically innumerable. DET, for this project, has provided a preliminary list of 329 schooling reforms. Building on the evidence from the literature review with respect to the system level factors that drive educational outcomes, a set of themes was developed that can be used to tractability categorise and prioritise the nature of differences and reforms across Australian jurisdictions. Using the framework from the literature review on drivers of school quality, hypotheses can be formed about the pathways through which system changes ultimately affect student outcomes. Some initiatives may have an indirect impact on outcomes because they involve changing high-level system settings. Others which aim to more directly shape school practice may have a more direct impact on outcomes.\nAcross each of the themes, the next steps of the approach were to identify evidence of permanent and timing differences in the approaches of government, across Australian schooling jurisdictions and over time. This is required to properly parametrise the empirical analysis, and form effective hypotheses on how certain changes may influence student outcomes. -Permanent differences are identifiable differences between schooling systems that are fixed (at least for some period of time) between jurisdictions, such that observable differences in system performance may be associated with these observed differences in the approaches of government. -Timing differences are where a comparable initiative is implemented at different times across different jurisdictions, so that changes in outcomes over time can be associated with the implementation of certain initiatives. In practice, some aspects of schooling systems across jurisdictions may have both permanent and timing differences.\nBased on the quality of available evidence, and the level at which initiatives are implemented, hypotheses were drawn about the expected impact of future changes. -Where possible, system-level settings will be mapped against their expected effectiveness based on factors in the literature review. -Those initiatives which rely on school level implementation are harder to assess the impact of from PISA results, as PISA itself relies on an unidentified sample of schools. Accordingly, it is hard to determine which school-level interventions have been implemented in the PISA dataset. For these, case studies will be used to examine initiatives, to illustrate the ways in which government can change school practice.\nThe strength of the conclusions made in this report rely on the quality of the evidence available in the PISA and TIMSS datasets, and the way in which the data is used to represent the measurement framework developed through this study. While these datasets are extensive, they are by no means comprehensive. In some cases, where the evidence shows that a given theme is more or less important in explaining student outcomes, this may result from the fact that no effective instrument was available to demonstrate its impact.\nWhile the PISA and TIMSS tests and surveys are conducted every 3-4 years, they are not longitudinal in nature. That is, the students and schools sampled for the test are not common across years. This means that it is not possible to capture dynamic effects of practice on student outcomes over time and that the analysis can only be conducted with contemporaneous observations of school practice and student performance. -In this sense, it is difficult to determine whether the effects of certain factors on students' outcomes are causal in nature. Unlike a random controlled trial (RCT) this study uses naturally occurring variations in the data to estimate the effects of different factors.\nFollowing from the static nature of the PISA and TIMSS tests, it is not generally possible to account for the prior achievement of students when measuring the effect of practice on their outcomes. Because this is a 'point-in-time' association of school and teacher quality with outcomes, the effects of aspects of school quality on student outcomes may be over-stated relative to their actual effect (for example, in the presence of ability based school selection policies, which may attribute more of a student's outcomes to a school's practices and less to a student's prior ability) or under-stated relative to their actual effects (as prior achievement also contains information about the accumulated effects of school quality on the student). \uf0b7 While this study briefly considers aspects of student outcomes beyond academic achievement on tests (for example, student engagement and wellbeing) they do not form a significant component of the analysis. This is not to downplay the importance of these other measures of outcomes in understanding the drivers of student outcomes and school quality in Australia. \uf0b7 Similarly, the regression models which this utilises focus on mean student outcomes, and do not consider the effects on the distribution of outcomes (or the typical outcomes for student with certain characteristics). Further extensions to this research may look to explore these other effects in more detail, due to their implications for understanding how drivers of school quality can influence different aspects of student performance in varying contexts.\nThe effect of teaching practice is estimated to be twice as significant as the next most significant driver of school quality.\nWithin teaching practice, the most significant drivers of student outcomes include instructional approaches, targeted teaching strategies, professional approaches to teaching and learning, and strategies for student engagement and wellbeing. These drivers emphasise the importance of teachers adapting their approaches to meet the needs of individual students in classrooms of varying levels of interest and ability.\nThe second largest contribution to student outcomes is the classroom environment, which explains up to 7.5% of the variation in student outcomes.\nIn relative terms, teaching practice and the classroom environment (including the engagement and wellbeing of students) account for more than half of the variation in student outcomes attributed to the identified 'drivers of school quality'.  The contributions of other factors are generally smaller. For example: -Measures of school autonomy at the school level identified through PISA contribute very little to the variation in student outcomes after controlling for other factors; and -Differences in teacher attributes (including qualifications) are also found to be less important in explaining variations in student outcomes, relative to teaching practice. Chart 5.1: Illustration of the overall relative importance of quality drivers (TIMSS Year 8 maths scores) Source: Deloitte Access Economics analysis of TIMSS data 5.1.1 A framework for understanding the role of government in the school system For policy purposes, knowing relative importance/relative contributions is a significant improvement from just knowing rankings of different practice-based drivers from the literature. In particular, it is more instructive when it comes to decisions about where to invest additional resources in schools. This study demonstrates that the key drivers of outcomes improvementteaching practice, classroom environment and school leadership -are held at a school level. What, then, leads to practical changes in teaching practice and in classrooms that results in improved student outcomes? The link between these drivers and the role of government is not always clear, as school practice and management can be influenced and guided by a range of sources, across different systems, jurisdictions, regions and local communities. However, schools do not determine and implement changes to these drivers in isolation. Schools develop an understanding of the appropriate choices to make in response to identified challenges from a number of sources. Teachers are influenced by the practices that they have been taught in their initial training, and that they have developed over the course of their career. They may be influenced by their own research into academic evidence. Schools also have the option of procuring professional learning from private and public providers, and participating in system-led initiatives. Figure 5.1 below presents an emerging framework for understanding the factors which influence school practice, and the role of government in setting system settings and enabling initiatives which provide the necessary conditions for schools to identify and invest in high quality practice. \uf0b7 Governments establish the broad architecture of the schooling system, determining: -The resourcing provided to schools; -The content taught in schools (curriculum); -The parameters through which schools make decisions (autonomy) and report on practice and outcomes (accountability); and -The requirements individuals need to meet to become, and continue to work as, teachers.\nGovernments also directly offer options to schools for improving teacher practice, such as changes to pedagogical approach for particular subject areas. \uf0b7 Schools, operating within these parameters, make decisions about where they should focus their attention in a process of continual improvement. They do this by selecting interventions from government as well as from private providers (companies offering curriculum and practice material for purchase by schools), and from the practices of other teachers and other schools.\nTargeted implementation of these interventions leads to improvements on the key drivers of school quality, which in turn leads to outcomes improvement.\nAt all levels (from the system to the school), evidence underlies the selection of appropriate interventions, and those interventions are evaluated for their effectiveness, helping to build the evidence base into the future. Most importantly, in this framework, governments will often not seek to prescribe changes to school practice directly. The system instead has an important role to play in holding schools accountable for pursuing and achieving improvements in outcomes and other goals. In this context, system settings are a necessary pre-condition for establishing an environment where schools identify areas for change, and invest in initiatives that meets the needs of students in their local context. Importantly, policymakers should seek to demonstrate a link between any proposed initiative, and drivers that are shown to most significantly contribute to variation in outcomes. For many initiatives, this link is intuitive: for instance, teacher standards and initial teacher education accreditation helps to set a standard of professionalism and practice, and provide incentives for continual development across the teaching profession. A more indirect link can be drawn between the key drivers and the curriculum which educators use to guide their teaching practice. System-wide focuses on accountability and decentralisation of schooling policy helps to create a schooling system where teachers can pursue effective practices, though they do not direct those practices themselves. Governments also play a key role in the improvement of school quality through: \uf0b7 Using funding and grants to provide particular programs and incentivise certain practices in schools; \uf0b7 Demonstrating the link to improvements in teaching practice before investing in initiatives intended to drive improvements in outcomes; \uf0b7 Setting a strategic and long-term focus on the outcomes impact of sustained changes to practice at the classroom level; \uf0b7 Relying on, and encouraging the use of, evidence-based interventions across Australian classrooms; and \uf0b7 Collecting and sharing data and evidence on how interventions result in improved practice.\nThey may be targeted at individuals, or particular groups of students. Scholarship programs, for instance, undoubtedly have a personal impact on recipients, but their effects are unlikely to be represented in system-wide results. Rather, their aim is to enable individual students' achievements or particular equity related goals.\nMost programs are not implemented across all schools at once. Indeed, very few initiatives are likely to lead to across-the-board improvement in every school the same way. Government-led initiatives, sensibly, are piloted with small groups of schools, and used in schools with recognised areas of local need.\nInitiatives may also have considerable impact lags. In particular, those relating to changing the process of initial entry into the teacher profession -be it changes to initial teacher education, or incentives in industrial arrangements -rely on a long-term change to the teaching workforce, meaning their effect will not be clear from a system-level analysis.\nThe exercise of selecting policies that may, or may not, have had an impact on PISA or TIMSS results requires subjective decisions about the priority of particular settings within schooling systems, and a level of knowledge about the implementation of initiatives and student outcomes that is not presently available at a school level.\nThe drivers of student outcomes and school quality that are understood to matter most;\nThe levers which policy-makers can use to influence these aspects of schooling; and \uf0b7 The overall performance of education systems, in terms of student outcomes. Australian states and territories have been collecting broad-based outcomes data on numeracy and literacy for many years now. This is now done in a standardised manner nationally, through the NAPLAN process. This is intended to provide an incentive to monitor individual students' progress, benchmark school performance and create competition between schools. However, as the Productivity Commission (2016) noted, this type of 'top-down' evidence alone does not ensure that Australian schools can realise gains in outcomes. The evidence base in the Australian education community, according to the Commission, lacks a 'bottom-up' assessment of policies, programs and teaching practices. Detailed individual evaluations of particular policies exist and can demonstrate whether particular 'levers' have worked in improving student outcomes in particular contexts. However, these provide limited strategic insight into how improvements may be made within the context of a consistent, strategic, overarching policy framework, which is oriented towards the drivers of school quality. At the centre of such strategic policy direction is a connection between the aspects of school practice that are known to matter and the role of government in determining system level policy. While more research and analysis will be required to better understand this link, which falls outside of the scope of this study, the measurement framework and initial analysis developed here provides a foundation for further research to be completed.\nCareful and detailed attention to implementation, along with opportunities for teachers to practice new ideas and learn from their colleagues. \uf0b7 A single integrated strategy and one set of expectations for both teachers and students. \uf0b7 Support from teachers for the reforms. \uf0b7 A framework and methodological approach which provides greater clarity in understanding the drivers of student outcomes and school quality in Australia; \uf0b7 A robust, detailed and Australian specific evidence-base which builds confidence for policymakers in understanding the key factors which contribute to student outcomes in Australia \uf0b7 An emerging framework to support the strategic focus and direction for policymakers when considering the role of government in driving improvement in Australia's school education system. Future research may build on and refine this methodology towards providing further evidence and insight. This future research may expand on this study by, among other things: \uf0b7 Expanding the scope of the empirical analysis to examine the effects of different drivers of school quality over time (for example, by mapping key PISA and TIMSS questions across years). This will be an important test of the external validity of the findings provided in this initial application of the established methodology. \uf0b7 Incorporating (more fully) additional student outcome dependent variables, incorporating aspects of student engagement and wellbeing. \uf0b7 Adding further causal structure to the empirical analysis to understand how different drivers of quality affect each other, and then subsequently drive student outcomes (for example, by estimating the link between school leadership and teaching practice). -A possible causal structure may incorporate the following nested components (which affect each other in turn, with the final component driving student outcomes): 1. System policy settings (to the extent they can be identified in PISA and TIMSS) 2. School leadership and management 3. Teacher attributes 4. Classroom organisation 5. Classroom environment 6. Teaching practice 7. Student engagement and wellbeing 8. Student academic achievement -This more complex structural analysis may provide further insights into how different drivers of school quality influence each other, and provide a more complete link between the role of system level policies, school practice, teacher effectiveness, and student outcomes.\nFurther exploration of the impact of prior performance on outcomes. The use of other data sources such as NAPLAN, or more detailed analysis of measures of student self-efficacy, may be incorporated into the modelling to examine how significant the omission of prior performance is on the findings of this study.\nThe TIMSS dataset may be used to explore the importance of variation within schools (and across classrooms) as well as across schools, to better understand the relative effects of teaching practice and school quality, and how teaching practice contributes to overall measures of school quality.\nMore detailed comparisons can be made across different learning domains (such as reading, maths and science) to understand how different aspects of school practice and management can affect influence performance in different areas. (For example, do teachers 'matter' more for maths than science?)\nConsidering the heterogeneity of estimated effects across the distribution of student outcomes, and for students with different characteristics. For example further analysis may explore whether the effects of aspects of teaching practice matter more or less for low and/or high socio-economic status schools, or in different schooling systems/jurisdictions. From a practical standpoint, this may involve enhancements to the regression models that include interaction terms, random forests, generalised additive models, etc.\nInternational data may be incorporated into the methodology to expand the analysis of Australia's performance relative to other countries, and provide insights into how the identified drivers of school quality vary across countries, in their nature and relative effects.   Key observations that can be made from this evidence include: \uf0b7 While controlling for contextual factors, the differences in performance between jurisdictions are smaller than they appear otherwise (that is, as outlined in Chart 3.3 Chart 3.4 earlier in this report, where student and school context is not accounted for). This suggests that the difference in the performance between jurisdictions is not as material as un-adjusted average student test scores would suggest \uf0b7 Victoria has had the smallest decline across the time period across subject areas. \uf0b7 Tasmania has performed at or above the level of other jurisdictions over the time period. It has also tended to have the greatest improvement, or smallest decline, in valueadd among the states. \uf0b7 The Northern Territory improved dramatically between 2012 and 2015, while Western Australia also recorded a significant improvement in that time frame (noting that the small sample size in the Northern Territory limits the precision of this analysis). \uf0b7 Over the entire time period, other states and territories declined by roughly the same amount relative to their original position.\nGovernments also establish enabling initiatives that provide guidance to schools in pursuing system-level goals effectively. \uf0b7 Schools undertake school interventions to change their school practice to pursue systemwide goals. These include measures like teacher professional learning and pedagogy. However, they do not undertake these activities in isolation. They select interventions from those available from government authorities and those available on the market. Importantly, these interventions generally happen at a school level, rather than at a system-wide level. Schools are most aware of the particular needs of their cohort and few interventions are appropriate for implementation across the entire schooling system.\nOn a day-to-day basis, schools are responsible for pursuing these goals. How effectively they achieve these goals is determined through their overall school practice: their classroom practice, school culture and teaching efficacy. In this framework, governments have two tools to manipulate in achieving school outcomes: (1) system settings; and (2) enabling initiatives. This section examines each of these in turn.\nThe implementation of the Curriculum was targeted as much, if not more, at making Australian school curriculums uniform as it was at deploying a high-quality curriculum. To expect a clear impact from its implementation presupposes that each Australian jurisdiction's existing curriculum was not already teaching the PISA domains at international standards.\nApart from the ACT, all Australian jurisdictions made modifications to the Australian Curriculum to suit local needs. These jurisdiction-level changes cannot be separated from the benefit of the national push for a uniform curriculum. \uf0b7 Implementation of the Curriculum may have occurred significantly later than published implementation dates. \uf0b7 Further, primary responsibility for the implementation of the Curriculum fell to the hands of schools, which may vary significantly in their practices.\nWestern Australia, in 2010, Queensland, in 2013, and the Northern Territory, in 2015, implemented a system of Independent Public Schools. Under this system certain schools with demonstrated capacity to make the most of autonomy are granted control over their staffing profile and selection processes. Other schools are generally centrally staffed-in part because of the difficulty of attracting staff to regional and rural schools in these jurisdictions. In Western Australia, by 2015, around 70 per cent of public school students and teachers were in Independent Public Schools   Victoria has consistently been among the top performers in PISA, and has had a long-term focus on autonomy as a jurisdiction. Western Australia also had a notable improvement between 2012 and 2015, as the proportion of that state's Independent Public Schools increased. However, the ACT performs poorly in terms of value-add, despite also having an earlier focus on autonomy as Victoria did; similarly, even though the Northern Territory had not made substantial autonomyfocused changes until 2015, it had an even more dramatic improvement than Western Australia. This aligns with earlier findings from PISA and TIMSS (see section 4.2.1) suggesting that autonomy in management and teacher selection has a small correlation with outcomes. In any case, autonomy enables schools to meet local needs more effectively-improving teaching practice by allowing schools to make decisions appropriate for their context. In this way, the impact of autonomy may not appear as a direct result of autonomy, but rather through the indirect avenue of improved teaching practice.\nOther students have a total of six opportunities opportunity to sit an Online Literacy and Numeracy Assessment (OLNA): two times per year from Year 10 until Year 12. They need only reach the standard once in each component. Students must reach this minimum standard by the end of Year 12 to be eligible to receive a high school certificate. Students who do not pass the OLNA instead do receive an official statement of their secondary school achievements to provide to employers or training providers. The Department of Education offers assistance and adjustments to the OLNA for students with a disability. The OLNA drives improvements in literacy and numeracy in two key ways: \uf0b7 Most directly, it creates a form of external accountability to ensure that schools are providing support to assist students in reaching the minimum standard by the time they complete Year 12. \uf0b7 More indirectly, it provides an important incentive for students and schools to improve performance on Year 9 NAPLAN tests, and to use those tests to diagnose any existing literacy and numeracy issues to provide appropriate support to students to assist them in meeting the standard before they complete high school. 28.1% of 2016's Year 12 graduates had achieved the minimum standard in their Year 9 NAPLAN test; more than 90 per cent of those students achieved the minimum standard by Year 12 (Western Australian . The OLNA has been credited with raising NAPLAN performance, with Western Australia recording results above the mean of other states in reading, writing and numeracy (AAP, 2016). The New South Wales Government intends to introduce a similar requirement from 2020 onwards (NSW Education Standards Authority, 2017). This apparent impact is also evident in the 2016 PISA results in reading and numeracy, where Western Australia appears to have had significant recent improvements (see above). With respect to accountability, there does not appear to be any level of consistency among other jurisdictions, which have on the whole performed or declined at similar levels since 2003. Further, the introduction of NAPLAN testing in 2008 does not seem to have produced a consistent lift in student outcomes. It should be noted that NAPLAN testing cannot be isolated from the number of other changes happening at a jurisdictional level at that time. Nonetheless, accountability serves more as a structure in which schools seek system level gains in outcomes, rather than as a panacea for school improvement.\nTeacher professional standards set a benchmark for the common capabilities that all teachers must possess across general teaching practice and articulate the range of skills all teachers should have to be effective in the classroom. Beyond training teachers in evidence-based practices to improve student outcomes, there is increasing pressure on universities to focus on developing teachers' capacity to deal with behavioural issues, interacting with parents, and other skills necessary to render them \"classroom ready\" (Teacher Education Ministerial Advisory Group, 2014). The importance of this focus is emphasised by the relative importance of the classroom environment in influencing student outcomes, as outlined in section 4.2.1 above. Much like industrial arrangements, these two forms of accreditation work across domains of school quality but ultimately provide an indirect lever to government to facilitate improving teacher attributes and practice (see Figure D.9). Prior to 2011, each state and territory regulatory authority set its own requirements for the accreditation of initial teacher education courses. In 2011, all states and territories agreed to national accreditation standards. The agreed transition arrangements meant that courses were assessed for accreditation under the new national standards when their existing accreditation expired. By 2015, while many programs were accredited under the national accreditation standards, there were still a large number of programs accredited under the previous state and territory standards. In December 2015, all states and territories endorsed the revised Accreditation of initial teacher education programs in Australia: Standards and Procedures. The development of the revised standards was led by the Australian Institute for Teaching and School Leadership (AITSL) as part of the Australian Government response to the Teacher Education Ministerial Advisory Group. State and territory regulatory authorities remain responsible for accrediting initial teacher education programs using these standards. It is expected that most initial teacher education programs will be accredited under the revised standards by the end of 2017. In 2010 the Australian Government established the Australian Institute for Teaching and School Leadership (AITSL). In 2011 all Education Ministers endorsed the Australian Professional Standards for Teachers (Teacher Standards). The Teacher Standards provide a nationally agreed quality assurance mechanism that ensures Australian teachers have the required competencies to be effective educators. They reflect the common capabilities that all teachers must possess and are designed to reflect quality across general teaching practice and to articulate the range of skills all teachers should have to be effective in the classroom. Although, ultimately, the responsibility of evaluating teachers falls to schools in line with the relevant industrial agreements, the In practice, each state and territory's enterprise bargaining agreements vary in their approach to enforcing this evaluation framework. The University of Melbourne Graduate School of Education (2015) evaluated the Teacher Standards through a series of case studies. It noted that although the Standards provided important strategic and practical direction to systems, schools and teachers for ongoing development, they were used for different purposes at different schools. This would suggest that the change to a uniform standard of evaluation will require further time, and ongoing strategic direction, to result in improved outcomes at a student level."}, {"section_title": "Providing a link between practice and performance", "text": "The goal of this study is to develop a framework that links elements of practice and student outcomes, and which is capable of utilising existing data sources to empirically estimate this link, in order to provide evidence of: \uf0b7 The factors that drive student outcomes in Australia, and in particular the role that school quality plays in driving student outcomes;"}, {"section_title": "A simple overview of the approach", "text": "The most robust way to determine the relative effectiveness of different drivers of school quality is to regress a measure of student outcomes (such as test scores) on these drivers, while controlling for other contextual factors. Unfortunately it is difficult to observe each driver for an individual student, meaning that this simple regression analysis cannot be undertaken. However, the PISA and TIMSS datasets do contain other indicators that are observed for each student. By mapping these indicators to the (unobserved) drivers of quality, it is possible to use them in the regression analysis in place of those drivers. The core contribution of this work is to undertake this mapping in a way which allows the derivation of empirical estimates of the relative importance of the different drivers using a robust and consistent framework. The methodology for this study involves providing a link between practice and student outcomes by bringing together evidence from literature and previous research, and original empirical analysis of the PISA and TIMSS datasets. This is made possible through the inclusion of questions in each of these datasets that provide indications of certain aspects of practice, thereby providing a measurable link between practice and student outcomes. More specifically, the approach involves the following steps: \uf0b7 A literature review is undertaken to identify the key drivers of student outcomes in existing research. These drivers are then categorised into themes and sub-themes."}, {"section_title": "Key literature review findings", "text": "Evidence from the literature clearly shows that teaching efficacy is among the most influential factors driving educational outcomes, while school leadership, governance and culture at a school level generally influence student outcomes through their impact on the classroom learning environment and the quality of teaching. The factors that influence teaching efficacy are complex and multi-faceted. Broadly, the literature indicates that teaching efficacy can be conceptualised broadly by two themes-teacher attributes and teaching practice. For the purposes of categorising questions and measures within the PISA and TIMSS datasets, this framework is subsequently explored in greater levels of granularity. For example, the theme of teaching efficacy (which is broadly synonymous with the notion of 'teaching quality') is separated into teacher attributes and teaching practice. These separate themes distinguish between the skills and qualifications of teachers which inform the effectiveness of their teaching practice; and their teaching practice itself, which includes factors such as ongoing professional development and approaches to teaching and learning in the classroom-as outlined in Figure ii below. In broad terms, these different factors or themes can be classified as being: contextual, in the sense that they relate to the attributes that students bring with them to the classroom or other contextual circumstances relating to the school environment; or factors which relate more to the quality of schools and the performance of systems, which capture elements of educational practice that can be influenced by government and can be connected to the quality of teaching and learning in the classroom. By separating the drivers in this way it is possible to isolate the variation in outcomes explained by individual school practice, separate from their contextual environment (for example, the socioeconomic status of their local community), the system (for example, government or nongovernment) or jurisdiction (that is, state or territory) in which they operate and seek to identify the observable characteristics that explain these variations. A conceptual illustration of this empirical approach is provided in Figure iii below. As with any original empirical study, the approach used in this report has its limitations. In particular: \uf0b7 While the PISA and TIMSS tests and surveys are conducted every 3-4 years, they are not longitudinal in nature. That is, the students and schools sampled for the test are not common across years. This means that it is not possible to capture dynamic effects of practice on student outcomes over time and that the analysis can only be conducted with contemporaneous observations of school practice and student performance."}, {"section_title": "PISA (national) TIMSS (year 8)", "text": "Source: Deloitte Access Economics analysis of PISA and TIMSS data Table i below lists the relative importance of nine high level themes across the PISA and TIMSS datasets. The results in this table and can be interpreted as the proportion of variation in outcomes explained by each of the themes. For instance, variation in teaching practice explains the greatest variation in student scores, at 6.1% for PISA maths scores, and up to 13.1% for TIMSS math scores. This result is not unexpected, based on findings from the literature about what matters in schooling education. However, the magnitude of the importance of teaching practice relative to other factors, such as school leadership, governance and autonomy, is notable. Indeed, the most important drivers of student outcomes and school quality, ranked in order, are: An illustration of the relative importance of these drivers is provided in Figure vi below. This piechart shows the share that the school quality 'themes' contribute to the overall contribution made by school quality drivers (that is, the relative proportion of the variation in outcomes explained by each driver), averaged across the PISA and TIMSS datasets. ix The relative importance of the sub-themes within teaching practice is presented in Table ii below. Instructional approaches describe the pedagogical approaches utilised by teachers which relates to the degree of students' ability to express opinions, teacher and student engagement in idea discussion, and explanation of content and ideas. This sub-theme is found to have the largest explanatory power for high school students in PISA and TIMSS. For primary schools, variations in instructional approaches are less important drivers of outcomes than teaching practice relating to curriculum and aspects of teacher engagement and wellbeing. "}, {"section_title": "TIMSS (maths, year 4)", "text": "Approach to teaching and learning -Assessment 0.09% 1.94% 0.02% Approach to teaching and learning -Instructional approaches 2.85% 4.28% 0.92% Approach to teaching and learning -Curriculum n/a 2.83% 1.18% Approach to teaching and learning -Lesson planning and collaboration n/a 1.03% 0.25% Approach to teaching and learning -Targeted teaching strategies 2.00% n/a n/a Wellbeing and development -Professionalism 3.06% 0.20% 0.46% Wellbeing and development -Engagement and wellbeing n/a 4.02% 1.18% Wellbeing and development -Support and development 0.08% 0.16% 0.07% Total teaching efficacy -practice 6.07% 13.11%"}, {"section_title": "3.88%", "text": "Source: Deloitte Access Economics analysis of PISA and TIMSS data Overall, these results emphasise the importance of key aspects of teaching practice, such as targeted teaching and effective instructional approaches. Notably, these pedagogically focused themes are more important than those themes which relate to curriculum and assessment, and the process of lesson planning and collaboration."}, {"section_title": "Implications for the role of government in Australia", "text": "This work illustrates the potential gains to be made from Australian schooling policies that focus on improving the most important drivers of school quality-teaching practice, classroom organisation & environment, and school leadership. x These gains will only be achieved by focusing the policy levers of government on the factors which matter most-those which influence practice in the classroom. However, these critical drivers are often the most removed from system level policy settings and levers. This means better evidence is needed-evidence which links practice at the school and classroom level to policy and performance. Against this backdrop, the role of government can be viewed in the following ways: \uf0b7 Effective system settings are seen as a pre-condition to provide the environment for schools to identify and invest in effective practice in their own unique context. -These system settings, among other things, set standards and performance expectations for the teaching profession, establish the curriculum that educators use to guide their teaching practice, and guide the strategic focus of schools through processes of accountability for student outcomes. -At the educational front-line, quality improvements result from individual schools undertaking interventions to change their school practice and teaching practice to pursue school-level goals best suited to the unique characteristics of their student intake. These include measures like teacher professional learning and improvements in pedagogy, which are known to be the most important drivers of student outcomes."}, {"section_title": "Conclusions and future research directions", "text": "This study has demonstrated how the Department can use available evidence from PISA and TIMSS to identify the key drivers of student outcomes and school quality in Australia, and measure their relative importance. This empirical methodology, and the underpinning measurement framework, provides the Department with a detailed and impactful evidence base to inform future directions for government. In particular, it has answered the key research questions established for this study by providing: \uf0b7 A framework and methodological approach which provides greater clarity in understanding the drivers of student outcomes and school quality in Australia; \uf0b7 A robust, detailed and Australian specific evidence-base which builds confidence for policymakers in understanding the key factors that contribute to student outcomes in Australia; and \uf0b7 An emerging framework to support the strategic focus and direction for policy-makers when considering the role of government in driving improvement in Australia's school education system. The framework and evidence developed through this study may be used to inform frameworks for improving student performance to be used by Australian jurisdictions to demonstrate a link between new policies and the drivers of school quality. That is, the measurement framework and xii evidence base developed here may assist policy-makers in providing evidence of a link between policies-including those relating to resourcing-and effective school and classroom practice, measured at the level of the classroom. Future research may build on and refine this methodology towards providing further evidence and insight. This future research may expand on this study by, among other things: \uf0b7 Expanding the scope of the empirical analysis to examine the effects of different drivers of school quality over time (for example, by mapping key PISA and TIMSS questions across years)."}, {"section_title": "Introduction", "text": "Deloitte Access Economics conducted a research study in 2016 for the Department of Education and Training that filled a gap in the existing Australian literature regarding the quantitative impact of an increase in school quality (as opposed to school attainment) on the economy. That previous study estimated the impact that an increase in school quality (associated with a sustained increase in PISA scores) had on total economic output. It demonstrated the mechanisms through which improved cognitive ability translates to higher educational attainment and accumulation of human capital, which in turn grows the economy through both higher investment and labour productivity. This project builds on that research and seeks to complete the 'chain' which links the role of government, school leaders and teachers to economic outcomes, as illustrated in Figure 1.1 below. Studies such as Hattie's Visible Learning (2009) have sought to provide a comprehensive overview of each of the key factors that influence student outcomes in school education. However, a lack of evidence from Australia, and the piecemeal nature of research on particular aspects of schooling, conducted at different times and in different countries and schooling systems, make it difficult to gain a complete picture in an Australian context."}, {"section_title": "What is school quality?", "text": "In the context of this report, school quality is defined as the contribution that a school makes to the outcomes of its students, after controlling for contextual characteristics. The quality of a school is therefore a driver of student outcomes, as are other factors relating to the individual characteristics of students, or the context of the school and/or education system. Drivers of school quality are defined as the attributes of a school's practice and management that drive student outcomes, and therefore determine a school's 'quality'. These attributes of practice and management are defined as factors over which a school has some degree of control-in contrast to a school's contextual characteristics. Drivers of school quality are-by definition-also drivers of student outcomes. Indeed, the empirical models used in this study use student outcomes as a 'dependent variable' in each aspect of the analysis. Throughout this study, all empirical findings should be interpreted as drivers of student outcomes (that is, the effect of a given factor on students learning achievement, engagement or wellbeing). Findings which refer to the 'drivers of school quality' relate to those attributes of school practice and management which are found to drive student outcomes. It can be separated from other broad sets of factors that drive student outcomes: \uf0b7 Contextual factors-including factors at both the student and school level (such as students' socio-economic status, school location, etc. \uf0b7 System level factors-including characteristics of schooling systems, such as autonomy, accountability and resourcing, noting that these factors influence can influence school quality indirectly. The PISA and TIMSS datasets provide an opportunity to bridge this gap by exploring the impact of multiple drivers of student outcomes within the same study. In addition to student assessment, PISA and TIMSS collect detailed information about the students and their school environment. Together these two datasets provide a rich source of information about school quality and differences between schools and between classrooms. Importantly, because these drivers can be tested within the same dataset (that is, with the same students and schools) they allow fully consistent and comparable effect sizes to be obtained. The core contribution of this current work is through the way in which it matches the indicators contained in these datasets, to a measurement framework of the different drivers of school quality, which allows this empirical exercise to be undertaken in a systematic fashion. The overarching research questions that this project seeks to address are: \uf0b7 What evidence is available from the PISA and TIMSS datasets on the drivers of school and classroom quality and student outcomes in Australia? \uf0b7 How might the content of these datasets be evaluated now and in the future? \uf0b7 Using this data, how much do different aspects of practice in the school and classroom matter in determining both school quality and student outcomes? \uf0b7 Based on this evidence, to what extent can the system improve student outcomes and school quality, using the levers of government policy? More details on the high level approach are contained below, and set out in full in subsequent sections of the report."}, {"section_title": "1.2", "text": "A measurement framework for drivers of student outcomes and school quality Both the classroom drivers of outcomes, and the broader contextual drivers, have been extensively studied in the literature. This literature allows an identification of the key themes that drive outcomes at the different levels within the schooling system: namely, contextual factors beyond a school's control, school quality factors within a school's control, and system level factors amenable to policy at the jurisdictional, sector or national levels. Each student's outcome can be taken as a combination of these drivers specific to that student. That is, a student's outcome depends on characteristics unique to them (such as their socioeconomic status), the school they attend (such as characteristics of the student cohort), the quality of the school (such as characteristics of the teachers), and overall system factors, as illustrated in the stylised equation presented in Figure 1 PISA is an assessment of 15 year old students from different class years, classes and teachers. The school environment questionnaires have a greater focus on the principals' view of the school, including their view of school management, school level practices and their staff overall. This means that PISA is an ideal source of information on differences in school quality between schools, different student experiences across different years, and in different classrooms. TIMSS is an assessment of selected year 4 and year 8 classes. The school environment questionnaires have a focus on what happens in a particular classroom from the perspective of students and their teacher. This means that TIMSS is an ideal source of information on differences in school quality from a classroom perspective. Measuring the drivers of outcomes at each of these levels is therefore important in fully understanding student outcomes. This lends itself to a regression based on a 'multi-level' model that explicitly accounts for the nested nature of different students within a school, and different schools within a schooling system. Such models are used to estimate the 'value-added' of schools, by identifying how much variation in students outcomes can be explained by the school a student attends, relative to the specific contextual factors that drives a student's outcomes."}, {"section_title": "A methodology for measuring the drivers of student outcomes, and school quality", "text": "To empirically estimate the relative importance of the different drivers of student outcomes it would be necessary to identify the extent of each driver faced by each student and compare that to the student's outcome (as measured, for example, by test scores). Naturally, it is not simple to identify and quantify the quality of the educational environment a particular student faces and this makes testing the size of the effects of these drivers on student outcomes difficult. However, the PISA and TIMSS databases do contain questions that provide indications of these quality drivers. By carefully matching these indicators to identified drivers of school quality it is possible to undertake empirical analysis that identifies the different drivers of quality that have the greatest impact on student outcomes. The key approach of this work therefore contains three research streams: \uf0b7 A review of the literature is undertaken to identify the established drivers of school quality. This review leads to key themes that are known to drive quality, such as those that relate to teaching practice, school leadership, or school autonomy, for example."}, {"section_title": "1.3", "text": "The structure of this report The report is structured as follows: \uf0b7 Chapter 2 provides a summary of the relevant literature, to identify the established drivers of student outcomes at the student, school, and system levels. Based on this summary, a measurement framework to underpin the empirical analysis is established."}, {"section_title": "2", "text": "The drivers of school quality -establishing a measurement framework A plethora of literature highlights how different aspects of school quality influence student outcomes. Visible Learning, John Hattie's synthesis of over 800 meta-analyses relating to student achievement, is perhaps the most notable collation of such literature. 2 From a targeted review of this literature, a measurement framework was developed to identify, describe and evaluate key drivers of student outcomes, at the student, school and system level. Frameworks are a useful way of organising the literature into a logical, coherent and consistent basis for empirical measurement, 3 where the different factors that drive student outcomes can be separately identified and measured. The framework is used to inform and guide the empirical analysis outlined in chapters 3 and 4 by providing: \uf0b7 A common understanding of the terminology used in the study \uf0b7 Identifying the relationship of each factor with student outcomes, including: -How each factor drives student outcomes; -Which drivers are contextual in nature and which are amenable to change by schools and by government; and -The links between different drivers of student outcomes. The themes identified in the literature are organised below as system-level, school-level and student-level drivers of student outcomes. Within each level, the drivers of student outcomes are classified into nine anchor themes. A high level view of the measurement framework is introduced in Figure 2.1 below. Each anchor theme has a number of sub-themes which were identified in the literature review as the most important areas to be considered when thinking about each theme. For example, within the school-level theme 'classroom organisation and environment', there are several sub-themes (as illustrated in Figure 2.2). It is important from a system and school perspective to understand how each of these themes and sub-themes influence student outcomes both directly and indirectly. As outlined in chapter 1, many determinants of student outcomes are contextual drivers -that is, outside of the control of the school. Some drivers directly determine student outcomes (practice based drivers) while other drivers are intermediate outcomes in and of themselves, that then contribute to students' academic achievement. Figure 2.3 below illustrates the conceptual link between these types of driver. Ultimately, this report identifies the school-and classroom-level drivers of most importance and explore the role that government may ensure that ongoing system reforms are directed to the areas which make the most significant differences to outcomes."}, {"section_title": "Different domains of student outcomes", "text": "The notion of educational outcomes for students is varied. Broadly however, they can be considered to be captured by two domains, captured in the figure below."}, {"section_title": "Student achievement", "text": "The idea of student achievement as an outcome domain broadly captures the different skills associated with educational experiences of the students. A distinction is often made between cognitive skills, as outlined above, and non-cognitive skills, which can also be referred to as soft skills or socioemotional skills. These non-cognitive abilities relate to important personal attributes such as perseverance, motivation, self-control, conscientiousness, perseverance, sociability, and curiosity (Heckman, 2004;Heckman and Kautz, 2012). These are also considered elements of self-efficacy (considered further in section 2.1.1). Non-cognitive skills are therefore significant and important educational outcomes that relate strongly to human capital. Indeed, Conti and Heckman (2014) conclude that conscientiousness is strongly correlated with attainment and labour market outcomes. These researchers argue that such traits are generally stable, but do evolve slowly over time and are malleable. As such, it has been found that formal education and other interventions can shape non-cognitive skills in such a way as to improve individuals' human capital over time. This does not necessarily suggest that tests of student achievement are perfect measures of the elements of the cognitive and non-cognitive abilities that contribute to human capital, but they are nonetheless strong indicators, particularly in contrast to indicators of educational attainment. That is to say, attainment in and of itself does not capture all of the aspects of an individual's value to future employers, particularly relative to more nuanced measures of student achievement. While intuitive, this observation can have profound implications for public education policy centred on improving attainment in order to raise earnings (Burgess, 2016)."}, {"section_title": "Student engagement and wellbeing", "text": "Beyond the measures of student achievement, the quality of a school can also be considered in terms of other forms of student outcomes, which include student engagement and wellbeing (Lamb et al., 2015). Student engagement and wellbeing are important not only because of their relationship with student learning, but also because they represent a disposition towards schooling and life-long learning (Willms, 2003). Engagement and wellbeing therefore have more ontological implications for students beyond their schooling life. In practice, the relationships between student engagement, wellbeing, and cognitive and non-cognitive achievement are highly complex and in many cases occur in a largely contemporaneous fashion, which limits the extent to which researchers can understand their causal inter-dependencies."}, {"section_title": "2.1", "text": "The factors which contribute to student outcomes -a brief literature review To motivate the development of the measurement framework, this section presents a brief review of the international and Australian literature on the drivers of student outcomes and school quality."}, {"section_title": "2.1.1", "text": "Contributions from the student and home Student level characteristics, including the student's home environment, are primary factors known to determine educational outcomes. These factors are generally not influenced directly by school practice-they are contextual factors which affect a student's learning, in the sense that a student brings them with them into the classroom. The literature relating to contributions from the student and home identifies three core themes that influence student outcomes: self-efficacy; socio-economic status; and ethnicity and cultural background."}, {"section_title": "Student prior achievement and self-efficacy", "text": "When considering the drivers of educational outcomes, prior achievement and self-efficacy play an important role in influencing student learning achievement. Student prior achievement and selfefficacy are also intrinsic measures of student engagement and wellbeing, which may be considered outcomes in and of themselves (Almlund et al 2011, andCunha et al 2006). Prior achievement, in part, reflects the existing abilities of students, A range of studies have demonstrated that prior school achievement (as a measure of a student's existing ability in a subject area) is a significant predictor of current achievement (see, for example, Hemmings, Grootenboer and Kay, 2010). However, this is inextricably tied to the overall attitude that students bring to learning in the subject area. Self-efficacy is a type of personal cognition defined as people's judgements of their capabilities to organise and execute courses of action required to attain designated types of performance (Bandura, 1997). Using the mathematics classroom as an example, Warwick (2008) establishes four main sources that influence students' judgements of capabilities and execution: 1. Performance experience (prior achievement): high performance in math assessments generally strengthens students' beliefs about their abilities in students whilst repeated low performance will weaken them; 2. Vicarious experience: the process by which a student compares oneself with peers; 3. Verbal persuasion: comments made by teachers (or parents) regarding the ability of a student to complete mathematical tasks; 4. Psychological and affective states: inner-feelings (anxiety, worry, tension, confidence, happiness etc.) that might be provoked by the student having to undertake mathematical tasks. Self-efficacy is related to engagement in learning activities and subsequently is manifested through learning outcomes. Therefore, positive self-efficacy feeds into stronger levels of engagement and results in positive learning outcomes which feed back into engagement in learning activities both directly and indirectly (through improved self-efficacy). The feedback loop is presented below: Source: Deloitte Access Economics, adapted from literature discussed in this section. Some researchers have suggested that teachers should pay attention to the development of students' perception of competence in addition to the level of actual competence itself, as Pajares (2003) notes: \"\u2026there are situations in which inaccurate self-beliefs, rather than a weak knowledge base or inadequate skills, are responsible for students short-changing themselves academically.\" At a foundational level, different aspects of self-efficacy are perceived as inputs which drive engagement and wellbeing and ultimately influence academic performance. For example, a student displaying a strong degree of confidence in learning is more likely to achieve better outcomes at school (Multon, Brown, & Lent, 1991). Motivation is an important related concept; a motivated student, with sufficient classroom autonomy, worthwhile goals and a supportive feedback system is more likely to achieve better educational outcomes (Dornyei, 2001). The influence of prior achievement and self-efficacy implies that, all else being equal, investments in early education can be effective, through their effect on self-efficacy and by supporting student engagement and promoting wellbeing, and subsequently performance. In this sense, other intermediate outcomes, such as engagement and wellbeing, 4 have risen to the attention of researchers, as they are considered objectives for schools in and of themselves. When considering measures of school quality and performance, one must account for prior achievement as an explanatory factor when seeking to understand the value added to students' learning by teachers or schools (Lu and Rickard, 2014). 5 In this regard, many measures of teacher and school performance focus on learning gain, not just absolute performance. 6"}, {"section_title": "Socio-economic status", "text": "From an empirical perspective, there is a strong link between student outcomes, and socioeconomic status at a school and community level (Betts, Zau and Rice 2003). The impact of a student's socio-economic status on educational outcomes is significant and robust to jurisdictional contexts and across time. At an aggregate level, Heyneman and Loxley (1983) find that socio-economic status is a more powerful determinant of achievement in higher-income countries, explaining 35% of the variance in student test scores. In an Australian context, the use of the family occupation and education indices in Australian jurisdictions like NSW and Victoria, or similar measures of parental education and/or occupational background, are positively associated with educational outcomes (Lu and Rickard, 2014). Organisations like the OECD (through PISA) and ACARA develop composite index measures which capture a diverse range of aspects of a students' background and home environment. These measures are typically calibrated to predict variations in student outcomes as accurately as possible, for the purposes of identifying relative educational need. 7 In this regard, measures of socio-economic status in schools are practically developed as proxies for learning outcomes, based on observed contextual factors. This suggests a high level of endogeneity between measures of current achievement, prior achievement, and socio-economic background, which has important implications for measuring and understanding school performance and school quality in different contexts. When comparing student outcomes on an international level, the reading outcomes of students from high socio-economic backgrounds do not substantially differ, as seen in the case of Canada and the US through PISA data (Willms, 2004). Students from low socio-economic backgrounds however, fare markedly better in Canada than the US, suggesting that system level policies may influence the level of equity in educational performance. Interestingly, the difference in the extent of socio-economic inequalities between Canada and the US stems mainly from differences between schools, indicating that school level interventions, especially at the low socio-economic end of the spectrum can be implemented to correct the inequity in schooling."}, {"section_title": "Ethnicity and cultural background", "text": "Contemporary schooling in Australia is generally of high quality. The dominant cultural expectations of the schooling systems, however, can negatively impact students from other ethnic and cultural backgrounds. Indigenous students in Australia often experience poor student outcomes even after controlling for remoteness and socio-economic status (Biddle and Cameron, 2010). This discrepancy in student performance can potentially be attributed to the differences in learning approaches at a cultural level. As Nakata (2007) notes, knowledge transfer is deeply entwined in Indigenous cultural and social practice: 7 See the PISA index of economic, social and cultural status (ESCS). https://stats.oecd.org/glossary/detail.asp?ID=5401"}, {"section_title": "Socio-economic levels and mechanisms affecting student outcomes", "text": "Socio-economic status may be more important at the school than at the individual levelparticularly after accounting for the effects of prior academic achievement (which is strongly linked to socio-economic status). This suggests that the environment of the local community and the involvement of parents in education (particularly at home), while highly correlated with a student's socio-economic status, may be more causally significant than socioeconomic status in and of itself (Hattie, 2013). In this sense it is not only the student's measure of socio-economic status that influences student performance, but the intermediate mechanisms (parental involvement, home learning environment, etc.) that also drive student outcomes. The mechanics by which socio-economic status affects student outcomes is diverse and complex. For example, there is evidence to suggest that unobserved family practices may differ significantly by socio-economic status, including the nature of the home learning environment (including access to learning resources at home), the use of out-of-school time and parental involvement in learning (Belfield and Levin 2002). Differences at the home level is emblematic that it is the process by which socio-economic status affects student outcomes rather than the nominal socio-economic status of the student. \"the Indigenous epistemological bases of knowledge construction ... are embedded ... in ways of story-telling, of memory-making, in narrative, art and performance; in cultural and social practices, of relating to kin, of socialising children; in ways of thinking, of transmitting knowledge\" By not utilising these bases of knowledge construction in mainstream education systems, educational outcomes of students are impacted. In Australia, Indigenous disadvantage begins early in their schooling life and continues throughout childhood (Biddle and Cameron, 2010). There is a strong imperative to address the disparity in educational outcomes which arises from differences in culture or ethnicity. The interactions between teachers and students of different ethnicities can result in differing educational outcomes, potentially as a result of bias in assessing student performance (Entwisle and Alexander, 1988). Student outcomes are therefore driven by not only their cultural and ethnic background directly, but also through the interactions with the school and teachers. Students who have migrated to Australia may have little to no prior schooling experience, which may have been in a different cultural setting to the Western classroom context. Students from culturally and linguistically diverse backgrounds may also need additional support to develop English language and learning skills (Australian Institute of Family Studies, 2015). Governments, through their role in developing the education evidence base and setting standards for the schooling system, can therefore guide teachers and schools to establish approaches in accommodating students from different cultural and ethnic backgrounds. Resources such as ACARA's English as an Additional Language or Dialect Teacher Resource support teachers as they develop teaching and learning programs in the Australian Curriculum. One aspect of its development is to help teachers understand students' cultural and linguistic diversity and how this understanding can be used in the classroom."}, {"section_title": "2.1.2", "text": "Contributions from the classroom and the teacher At the school level, several factors influence student outcomes. First is school leadership, governance, and culture, which can be considered a more indirect driver of student outcomes that effectively determines the conditions in which teacher and student interact. Second, classroom organisation and environmental factors are those that drive student outcomes directly through their influence on the classroom learning environment. Third, teaching efficacy, including pedagogy and curricula, encompasses the most direct and significant drivers of student outcomes."}, {"section_title": "School leadership, governance, and culture", "text": "School leadership is defined as the process of guiding and leading the talents and energies of teachers, students and parents toward achieving the educational aims set by the school. While there is no single model of the best practice of effective leadership, it is possible to identify a common set of broad educational values, competencies and strategic actions which result in improved leadership qualities in teachers and principals which lead to improved educational outcomes. In particular, school leaders can improve teaching and learning through setting a 'mission' for the school: by focusing on a small set of goals, directing staff attention to initiatives relevant to those goals, and taking a transformational approach to staff motivation, commitment and working conditions (Day et al., 2009). School leaders can improve outcomes not just by these influences, but by setting directions for a school's pedagogy, and classroom learning environment which can be enacted by teachers themselves (Marks and Printy, 2003). In other words, school leaders play a role in developing models of distributed leadership within schools, where teachers have flexibility adapt to the needs of the students in their classrooms. Beyond school leadership developing the autonomy and capacity of teachers within the classroom, administrative support and guidance to principals and school leadership teams can be important in the short run. Evidence exists that in Australia, the ongoing work of administrating a school can inhibit school principals from focusing on the school's strategic direction (Watson, 2009). However long term leadership capacity building, to focus on a school's particular goals, is necessary to sustain improvement in educational outcomes. School leadership, governance and culture, however, also covers the engagement of parents in the culture of the school. Significant evidence exists in the literature that \"parents' attitudes, behaviours, and actions in relation to their children's education have a substantial impact on student learning and educational attainment\" (ARACY, 2012). Engaging in their child's school community permits parents to socialise their children for academic achievement, and to facilitate effective communication between schools and homes. Ultimately, school leadership and governance exists to establish a positive school-wide culture that seeks to promote effective schools and improve student outcomes (Grant, 1988;Lightfoot, 1983). However, links between attributes of the school of this kind and student outcomes are generally uncommon in literature. Rowe (2003) cites substantive and methodological difficulties in connecting organisational factors with student outcomes. The substantive issue arises from determining the explicit link between school organisational factors and student outcomes. In light of this, other levers held by government such as school autonomy can play a part in enabling school leadership and governance to drive the initiatives required to improve student performance, as seen in case studies from Caldwell (2015). School leadership therefore broadly functions as an effective pre-condition that implicitly enables improved student outcomes to be achieved via the conditions in which teachers work and deliver classes."}, {"section_title": "Classroom organisation and environment", "text": "At the classroom level, drivers of student outcomes can broadly be grouped into three sub-themes. Classroom context involves the structural or foundational elements of the classroom which are not determined by teachers, such as class sizes. There is little evidence in the literature to support the notion that reducing class sizes is an effective method in increasing student achievement. Ehrenberg and Brewer (2001), Hanushek (1999) and Mishel & Rothstein (2002) all find that although hundreds of studies have looked at the impact of reducing class sizes, the vast majority have found small or inconclusive benefits, despite the significant costs associated with increasing the ratio of teachers to students in education systems. Remoteness of a school has also been observed to have a negative impact on outcomes in both Australian and international contexts (see, for example, Gonski, 2011). Beyond the increased cost pressures associated with regionality, the literature has suggested that the \"\u2026homogeneous character of \u2026 neighbourhoods creates enclaves denying young people social and cognitive challenges\" (Sellstr\u00f6m, 2006). Aspects of classroom organisation -namely, strategies pursued by the school to shape the way students and teachers interact in the classroom -can have beneficial effects on student outcomes. Effective teachers use rules, procedures and routines to direct students' attention towards their learning, and to avoid distractions (Stronge, Tucker and Hindman, 2004). Classroom environment refers to the resultant climate of the classroom as a function of the previous two sub-themes. Peer culture, or how students interact with each other, influences the development of the classroom environment while also being a product of the context of the classroom and how it is organised by the school. The effect of peer culture is difficult to credibly estimate, given the possibility that individuals are likely to self-select into peer groups based on unobservable characteristics. Despite this, Hoxby (2000) finds that when there is a change of 1 percentage point in the reading scores of an individual's peers, that individual's reading scores improve by between 0.15 and 0.4 percentage points, suggesting there are some peer 'spillovers' toward improved educational performance. Evidence also suggests that these impacts are stronger within ethnic groups, and that these effects are likely to diminish as peer groups become more similar. In this sense, the interaction between ethnicity and peer effects influences educational performance depending on the ethnic composition and degree of ethnic diversity within peer groups. Ability grouping provides another example of a common technique by teachers that ultimately affects the classroom environment in which they teach. Burke and Sass (2013), with controls for differences in student ability and teacher effectiveness, find evidence for peer effects at the classroom level, but not at the grade level-suggesting that the organisations of students within classes can help to redress the negative effects of inequitable peer groupings. Importantly, grouping students into different classes based on ability has minimal effects on student outcomes and profound negative equity effects for students in 'low track' classes, though it may have positive outcomes for gifted students (Hattie, 2013). In contrast, the literature is inclined to support approaches that balance ability grouping within classes, as opposed to across classes, as it creates positive spill over effects, especially for low ability students.\nClassroom environment, as a sub-theme, covers the learning climate of a classroom that students participate in, separate from the explicit efforts of the teacher. Class order and cohesion (which describes the level of discipline and student behaviour in class) is represented by key questions such as how often students do not listen to what the teacher says (PISA), the degree to which teaching is hindered by uninterested students (TIMSS year 8), and whether the students behave in an orderly manner (year 4). Peer culture (which describes the manner that students interact with each other) is represented in PISA by whether students enjoy working in teams, and whether students enjoy considering different perspectives. The proportion of variation explained by the sub-themes within teaching practice is given in Table 4.4. Overall, classroom environment is found to be important for explaining variation in student scores, particularly at the high school level. Classroom organisation, on the other hand, describes the approach used by a school in determining the number of students in each class (compositional strategies), the support offered to teachers (in the form of teaching aides) (teacher working conditions), and the method used by schools in grouping students into subject classes (practice driven organisation). Each of these were found to be of relatively little importance in explaining variation in student outcomes, with the exception of compositional strategies in TIMSS (year 8). In this case, a greater number of students in a class was associated with stronger student outcomes. This result should be interpreted with caution: with the significant number of contextual controls in the model, class size may contain other information about the school that are positively associated with student outcomes. Student gender mix and grade mix are also aspects of composition strategy but were not measured in the datasets. Based on the TIMSS year 8 analysis, moving a student from a class with an average level of uninterested students to one that is a standard deviation more interested would raise the student's score in maths by 6.28 points. This suggests that increased classroom segregation, such as removing disinterested students to separate education environments, is likely to have a disproportionately negative impact the outcomes of residualised students and classrooms. This is because there will be fewer students in the class to prevent teaching being hindered by uninterested students/encourage different perspectives, and promote overall order and cohesion in the classroom. Notwithstanding the observations made above regarding teaching strategies that encourage within class ability groupings of students, this analysis suggests that grouping students based on ability to different classes could have a positive effect after controlling for other factors (such as classroom order and cohesion, like student interest levels). It should be noted that this finding is significant at the 10 percent level, where the other key findings in this sub-theme are significant at the 1 percent level. This suggests that this is an area where further exploration and research may be required. This is particularly true because of the complex impact that ability streaming may have on particular types of students. For example, the results presented here represent an average impact of the effects of ability-based 'streaming' on student outcomes, and do not consider the separate impacts of students with low or high levels of current achievement. As has been noted previously, ability-based streaming can have disproportionally negative effects on those students who are streamed into lower achievement levels classes. "}, {"section_title": "Teaching efficacy", "text": "Hanushek, (2011), in a study on the impact of teaching quality on student outcomes, concludes that: \"No other attribute of schools comes close to having as much influence on student achievement\" The nature by which teaching quality influences student outcomes is complex in that there is no one-to-one causal relationship; rather, there is a complex interplay between different conditions and methods that produce varying student outcomes. When considering the effect on student outcomes, there is a large disparity between the most talented teachers and the teachers at the bottom end of the distribution. Due to this, and the large costs associated with other approaches (such as reducing class sizes), teaching quality has become the focus for much of the research in primary and secondary school education around the world (Hanushek, 2011). Teaching quality can be conceptualised in several ways. Measures of teaching quality can include attributes that are both observed and unobserved within the classroom. That is, while it is clear that different teachers can lead to different educational outcomes, it is not always clear what the exact attributes of teachers are that lead to this. Indicators observable to administrators may include the teacher's level of academic proficiency (measured using observations of professional qualifications). Indicators that may be more difficult to directly observe may include teaching styles and other personal attributes that may be confounded with pedagogical practices that are not necessarily unique to the individual teacher. In practice, both observed and unobserved attributes of the teacher matter, but when considering the implications of increased teaching quality it is important to understand the distinction between inherent attributes of the teacher (like latent ability and cultural orientation) and practice based attributes (like teacher development and instructional approaches) (Deloitte Access Economics, 2014)."}, {"section_title": "Teacher attributes", "text": "Teacher qualifications can influence the quality of teaching practice through the skills and knowledge that teachers bring into the classroom. Betts et al (2003) find that teacher qualifications matter more in upper grades than in lower grades. In particular, teachers with a Masters qualification are estimated to increase the rate of learning among high school students by 20% and teachers with a Ph.D. are estimated to increase the rate of learning by 80%, suggesting that the level of qualification (as a proxy for teaching efficacy) matters for the rate of learning for the student. This suggests that having higher qualifications allows teachers to bring either domain specific knowledge or pedagogical expertise from their own learning experiences to influence educational outcomes. Beyond degree qualification, strong attributes associated with content knowledge and subject matter expertise are indicative of positive teaching efficacy. The most effective teachers have a deep understanding of the subjects they teach, and if this deep knowledge falls below a threshold level, it can have detrimental effects to students' learning (Coe, Aloisi, Higgins, and Elliot Major, 2014)."}, {"section_title": "Teaching practice", "text": "Teacher wellbeing and engagement is an essential pre-condition that provides strong self-efficacy for teachers to execute their classes effectively and sustainably. 8 For example, teacher beliefs can include the teacher's reason behind adopting particular practices, the purpose they aim to achieve, the teacher's idea about what learning is and how it happens, and their conceptual model of the nature of teaching in the learning process (Coe, Aloisi, Higgins, and Elliot Major, 2014). Other forms of wellbeing such as teacher professionalism builds positive teaching efficacy in the classroom, this includes participation in professional development, supporting colleagues, punctuality, preparation, and liaising and communicating with parents. Underpinning the other core element of teaching efficacy is the practice that goes on in the classroom. Through their practice, teachers have the ability to create a conducive learning environment to improve student outcomes by focusing on the following elements: These are broadly the 'levers' teachers control during the teaching process that drive student outcomes. These approaches to teaching and learning are however, predicated on the notion that teachers possess good classroom management skills, which includes efficient use of lesson time, coordinating classroom space and resources, and managing behaviour with clear rules that are consistently enforced. These are the environmental components necessary for good learning rather than the components that students experience directly during the class (Coe, Aloisi, Higgins, and Elliot Major, 2014). For example, Curriculum programs vary in effect and nature. At a high level, there are curriculum programs aimed at catering for gifted and disadvantaged students. In this regard, Hattie (2009) analyses three different curriculum effects: The most effective method is to accelerate students through the curriculum, with enrichment and ability grouping being secondly effective and least effective respectively. It is important to note that the practice of curriculum programs by teachers in the instances above are often coupled with classroom organisation strategies (such as individually accelerating students and ability grouping). With regard to disadvantaged students, developmental curriculum programs like 'repeated reading', 'vocabulary programs', 'creativity programs' and 'phonics instruction' are found to have the greatest impact on student outcomes, with improvements being manifested through effect sizes of around 0.65 standard deviations of improvement, which ranks among the most significant in terms of student outcome effects (Hattie, 2013). From a school perspective, allowing teachers to tailor the curriculum for students of different backgrounds allows students to develop based on their educational needs (Goss et al., 2015). Large gains in educational outcomes can be made via direct pedagogical teaching strategies (Coe, Aloisi, Higgins, and Elliot Major, 2014). The quality of instructional approaches of a teacher which includes techniques such as effective questioning, reviewing previous learning, providing model responses for students, giving adequate time for practice to embed skills securely, progressively introducing new learning material (known as scaffolding), reciprocal teaching, and direct instruction are shown to be the more effective methods in improving student outcomes (Hattie, 2013). Professional development of this type have been highlighted as a major imperative for the Australian educational system (Jensen, 2010). Lesson planning and collaboration strategies such as sharing by teachers of their conceptions about what constitutes progress through the curricula is essential to achieving improved student outcomes (Hattie, 2013;Gonski et al., 2011). These tools and methods can then be taken into the classroom to provide teachers with effective classroom practice on an individual level. Overall, this evidence suggests that variations in teacher quality outweigh the impact of other education initiatives aimed at improving student outcomes (Jensen 2014;Burgess, 2016). Studies by Jensen (2010) have demonstrated that as much as a 10% increase in overall teacher effectiveness can be associated with a 19 point increase in PISA scores. In driving improvements to student outcomes across Australian schools, classroom quality is important not only on its own, but also to the extent that it interacts with a suite of other factors influencing educational outcomes (Jensen, 2010)."}, {"section_title": "Teacher development", "text": "Learning and development and maintaining professional standards are flagged as essential elements in improving teaching quality (CESE, 2017). Teaching efficacy can be improved through approaches focussing on the wide range of in-class approaches. Generally however, initiatives geared toward improving teaching efficacy are cumulative in nature, in that students who have consistently effective teachers are more likely to get ahead (Sanders and Rivers, 1996). Strategically focusing on early intervention, and focusing on practices backed by a strong evidence base is paramount in effectively driving student outcomes."}, {"section_title": "The Sutton Trust Educational Endowment Fund", "text": "In the UK, The Sutton Trust Education Endowment Fund (EEF) Teaching and Learning Toolkit (TLT) provides a summary of educational research provided for guidance for teachers and schools on how to improve the attainment of disadvantaged pupils. Programs focused on adjusting curricula to be better suited to the learning style of students were found to improve student educational outcomes by around 2 months at very low cost. The EEF has undertaken a number of studies of particular curricula programs, evaluating their effectiveness as drivers of educational outcomes and the relative cost of their implementation. One example is the Catch Up\u00ae Numeracy program, a one to one intervention for learners who are struggling with numeracy. The approach is based on research indicating that numeracy is not a single skill, but a composite of several relatively discrete component skills. The program was found to have a strong and significant effect size on numeracy outcomes, equivalent to around 3-4 months progress in student achievement. This was achieved at an estimated cost of \u00a3130 per pupil."}, {"section_title": "2.1.3", "text": "System level factors Although not at the forefront of the classroom experience, system level factors drive student outcomes by creating favourable conditions for schools to develop improved educational outcomes. Improvements in student outcomes given current resource levels, requires a mix of system and school level changes which are predicated on some degree of autonomy and accountability. A broad set of performance improving interventions that views education as a system, not as disconnected schools and sectors, is a critical component of this (Bracks, 2015). The major components that can be considered as important system level factors are: resourcing, accountability, and autonomy."}, {"section_title": "Resourcing", "text": "Literature and evidence on the relationship between school resources and educational outcomes consistently concludes that, resourcing (and implicitly, 'funding') can be necessary but is not sufficient in its own right to improve educational outcomes -that is, how resources are used is the critical issue, provided that, as a threshold requirement, the level of resources are adequate. To elaborate, Odden et al. (2007) argue that schools require both adequate resources combined with an effective use of funding in order to improve performance. Darling-Hammond (2010) explores this theme, suggesting that how resources are used is critical to their impact on outcomes, as not all investments of resources have equivalent results: \"An effective system should create both a means for determining and funding adequacy and incentives to increase the likelihood of funds being wisely spent. At a minimum, states should not force schools to waste scarce resources through ill-conceived requirements.\" (Darling-Hammond 2010) Indeed, Hanushek, who has consistently argued that there is no systematic relationship between funding and outcomes, has acknowledged that: \"\u2026there clearly are situations where small classes or added resources have an impact\" (Hanushek 2003) As a result, when considering the nature and form of methodologies or models that allocate resources to schools within a system, the manner in which this methodology requires or enables resources to be deployed towards 'effective investments' is critical to the overall efficacy of the resourcing arrangements, and education system more broadly. Indeed, the findings from recent reviews of school funding arrangements in Australia, including Gonski (2011) and Bracks (2015), suggest that the level of funding and effective use of additional funding is critical to improving both the overall level and equity in students' educational outcomes."}, {"section_title": "Summary of the school level themes", "text": "The literature indicates that school leadership, governance and culture at a school level influences student outcomes insofar as they effect the classroom learning environment and the quality of teaching. While teaching efficacy is understood to be the most important (noncontextual) driver of student outcomes, the factors which influence teaching efficacy are complex and multi-faceted. Broadly, the literature indicates that teaching efficacy can be conceptualised broadly by two themes-teacher attributes and teaching practice. Within the notion of teacher attributes, are characteristics of the teacher that are not directly associated with the classroom, including teaching specialisation and experience levels. Conversely, teaching practice concerns itself with the professional attributes relating to (i) teacher wellbeing and development and (ii) approaches to teaching and learning-these help to characterise what high quality teachers should be focussed on attaining. The component factors of school quality indicate the themes which this study will consider in identifying the key drivers of school quality within PISA and TIMSS. Evidence on how resourcing drives educational outcomes can be broadly decomposed into two themes -Material based resources (the physical resources available to the school, such as books) and curriculum and practice based resources (the overall capacity of the school and toolkit of techniques available to be used in teaching particular students)."}, {"section_title": "Material based resources", "text": "Analysis of Programme for International Student Assessment (PISA) data has shown that there is a correlation between the level of material resources (defined as the average adequacy of a school's educational resources) and mathematics performance, however the inequity in the allocation of material resources (defined as the difference in the quality of schools' educational resources between socio-economically advantaged and disadvantaged schools) is negatively correlated with mathematics performance-that is, both the adequacy of funding and the way in which it is allocated is important in driving student outcomes (OECD, 2013). Generally, literature has indicated that funding has the highest impact when it is directed towards changes to teacher practice, but these effects vary on the basis of individual school and student context. System level contextual factors such as autonomy and accountability also contribute to the efficacy of funding and resourcing. However, resourcing is not as simple as 'more funding means improved student outcomes'. Rather, it is more important to consider the manner in which funding is used."}, {"section_title": "Curriculum and practice based resources", "text": "There are a vast number of different programs available to schools and teachers to support the transfer of particular skills to students. An extensive amount of literature exists on the effectiveness of these different programs. As one example, there has been considerable debate around the use of phonics programs versus whole language courses of instruction for basic literacy skills (see, for example, Rowe, 2005). In some cases, these programs might be directed at particular groups of students: for instance, literacy programs may be tailored for students learning English as an additional language or dialect. However, these varied school level programs can have very different impacts on student outcomes, and can have significantly variable levels of associated cost. An effective schooling system should aim to develop the institutional knowledge of schools such that they have access to evidence-based curriculum and practice based resources, and that they can select resources that help them to target their teaching approaches towards particular students. Recognising the importance of understanding the efficacy of different programmatic investments in school quality, Evidence for Learning's Teaching and Learning Toolkit 9 presents a summary of educational research to guide teachers and schools on how to improve the attainment of disadvantaged students."}, {"section_title": "Accountability", "text": "Accountability is the broad notion that schools, districts, educators, and students are held responsible for their educational outcomes. Generally, students in countries with externally administered exit exams consistently and substantially achieved higher scores as measured by internationally standardised exams (Hanushek and Woessmann, 2014). Externally administered exams can have strong impacts on the level of achievement, with the impact on average being more than a year of schooling. These results are robust to within country studies (where some regions have external exams while others do not, or some subjects are tested externally while others are not), suggesting that this is not driven by cultural differences. This reinforces the role of government in influencing student outcomes by administering external examinations for students.\nAutonomy appears to be an important driver of school quality from the literature. However, if not paired with effective accountability measures, school leaders may not face clear incentives to guide their decision-making. School leaders have the opportunity to develop a culture of accountability within their school by focusing on student improvement at a school level. There are several mechanisms through which schooling systems can render schools accountable for outcomes improvement:  In these ways, accountability indirectly drives student outcomes by setting the agenda against which schools direct their resources and classroom practice. Although governments have a role to play in each of these forms of accountability, their goal is most clear in outcomes, strategic and practice accountability. Below, the analysis focus on standardised testing initiatives, the well-embedded form of outcomes accountability in the Australian schooling system. Standardised testing, as a form of outcomes accountability, drives a school-level focus on student outcomes in several ways: \uf0b7 It allows for longitudinal comparisons at an individual level. Improvements, or declines, in student outcomes between years can be recognised, aiding targeted teaching practices. \uf0b7 It allows for comparison between subgroups, particularly those identified as being in need of additional support -for instance, low socio-economic status students. \uf0b7 Consistent standardised testing throughout primary and high school encourages early diagnosis of literacy and numeracy issues. In Australia, standardised testing rose to prominence upon the implementation of the National Assessment Plan for Literacy and Numeracy (NAPLAN) in 2008. The aim was to place all students on a single national scale for literacy and numeracy achievement (Fachinetti, 2015). Prior to NAPLAN, each jurisdiction, to varying degrees, had standardised testing initiatives to compare student performance consistently between schools. These initiatives are outlined in Figure D.7 below. In relation to PISA results over time, it is worth noting that Tasmania, the state with the longeststanding standardised testing initiative, has consistently performed at or above the average level of other jurisdictions. This may not be surprising, given that PISA itself is a standardised test. Nonetheless, it suggests that the system, and its schools and teachers, have had a focus on student outcomes and improvement over a longer time frame than other Australian jurisdictions. Separate from the historical introduction of standardised testing, it is also worth noting the recent introduction of the Online Literacy and Numeracy Assessment (OLNA) in Western Australia, which has been credited with driving outcome improvement in that state."}, {"section_title": "Examples from Evidence for Learning's Teaching and Learning Toolkit", "text": "The research in the Teaching and Learning Toolkit is intended to be used to ensure maximum return is achieved for government spending on education resources. In particular, it focuses on how schools can make informed decisions with regards to spending on individual students, especially in attempts to raise achievement among disadvantaged students 1 . Importantly this research considers both the relative impact and cost of different spending initiatives, indicating areas where increased funding can be linked with improved outcomes via particular drivers. The results from the research presented in the tool kit show that, while interventions like reducing class sizes and improving parental involvement have similar impacts on student outcomes (increasing student attainment by around 3 months), they do so at very different costs, with class size reduction having a very high cost compared to a moderate cost for parental involvement. Programs focused on pedagogical practices and curricula programs, like metacognition and self-regulation, and feedback mechanisms, have the highest impact on educational outcomes, for relatively low cost. This demonstrates the importance of programs like the Smarter Schools National Partnerships (SSNP) in providing funding for classroom drivers that have a demonstrable impact on educational outcomes and that can be implemented in a cost effective way (Parkville Advisory Group, 2014)."}, {"section_title": "Selected Approaches", "text": "Average cost"}, {"section_title": "Evidence security", "text": ""}, {"section_title": "Months impact Summary", "text": "Feedback Even when drivers are demonstrated to have a significant positive effect on student outcomes, as found in the literature, the individual context of the school and classroom will still have a significant impact (EEF, 2014). This may mean that inferences drawn from meta-analyses and other syntheses of the literature are not applicable in certain contexts, highlighting that these results are to be reflected on in general contexts. Therefore, contextual factors like autonomy, accountability and school leadership can be important in ensuring that funding is tailored to meet the needs of students in different classroom contexts, by supporting and enabling the drivers of student outcomes that have been evaluated as being most effective at a classroom level. At a school level, student achievement can increase as principals and teachers are held accountable because they are continuously subject to monitoring and review processes. Appropriate accountability, both at a system and school level can play a pivotal role in directly improving student outcomes, and also indirectly providing a conducive environment for schools, educators, and students to drive improvements in student, engagement and wellbeing."}, {"section_title": "Autonomy", "text": "Autonomy in the schooling system is when schools have been devolved discretion towards the practice and management of schools. In Australia, schools across states and territories have been moving towards more independent and autonomous educational models that seek to improve student results through a more flexible and needs-based system. Through analysis of PISA scores both internationally and in an Australian context, higher levels of autonomy are associated with higher levels of student achievement, provided there is a healthy balance of accountability (Hanushek and Woessmann, 2014;Caldwell, 2015). Higher levels of autonomy should align with strategies that are linked (via research and evidence) with professional practice and subsequently to gains in student achievement directly and not on structural changes for their own sake. Much of the evidence in aligning autonomy and professional practice strategies shows that school leadership and management can improve student outcomes: through building professional capacity (staff selection, professional development and appraisal); through the communication of purpose, process and performance at a school level, and setting priorities about performance based on data and evidence. Professional standards at a school management level and coherence and understanding between school management and educational practices compound the positive effects of autonomy. Indeed, the different educational settings that exist within and across jurisdictions have influenced the degree of autonomy provided to schools over time. Over the past four decades, Australia has experienced a higher degree of autonomy within schools across all jurisdictions, further Accountability -school and system performance Schools within Australian educational jurisdictions on average are afforded a relatively high level of autonomy, however this occurs within a robust framework of accountability. In Victoria for example, at least once every four years schools are subjected to a review within a system framework (DEECD 2013:10). At a school level, review processes include (Caldwell, 2015): \uf0b7 Peer Review -school management and externally accredited reviewers assess school performance leading to develop new four-year school plans \uf0b7 Exemplary Practice Review -identification of exemplary practice in specific fields of practice are documented so they may be shared with the broader learning community \uf0b7 Priority Review -an accredited review team undertake in-depth diagnosis of the causes underlying the school's low performance, with feedback being provided back to the community \uf0b7 Support and intervention Review -Given the findings and feedback from the Priority Review, a design team will support to develop an intervention program which is then monitored by external bodies (e.g. Regional Services Group in Victoria) Peer and Exemplary Practice reviews generally occur in high performing schools, whilst Priority and Support and Intervention reviews occur in low performing schools. In this sense, accountability frameworks not only hold schools responsible for their decisions in practice, but also serve as a means by which new and effective practices can be derived in light of performances of exemplary schools. Mechanisms for accountability can therefore promote varying conditions and structures by which schools can align and develop positive educational outcomes. highlighting the attention policymakers have put on differences in school environments, and not necessarily on the jurisdictional differences themselves (Caldwell, 2015). This robust body of evidence provides an example of how affording schools greater autonomy channelled through school leadership and professional practice can positively influence student outcomes provided there is sufficient accountability within the system. Governments can therefore set positive foundations for schools to lead and navigate their own professional practice needs to achieve better educational outcomes.\nSchool autonomy-that is, greater local decision-making at the level of the school and school community-has been identified in the literature as a crucial factor to good student outcomes (Gonski, 2011). Autonomy over process and personnel decisions has been found to encourage higher performance at a school level. However, effective accountability mechanisms at a systemlevel are necessary to realise the potential of school autonomy, to ensure that schools are making decisions that make progress towards system goals (Hanushek and Woessmann, 2014;Hanushek, Link and Woessmann, 2013). While the empirical analysis outlined in section 4.3 above considered measures of system autonomy identified by schools in PISA and TIMSS, here consider measures of autonomy across Australian jurisdictions are considered through a consideration of the differing nature of system settings drawn from desktop research and evidence compiled from sources outside of PISA and TIMSS. Autonomy is not a one-size-fits-all reform. Many complex decisions are made on a day-to-day basis throughout schooling systems, and accordingly, there are different types of autonomy that may be provided to schools (illustrated in Figure D.4 below). It is also important to distinguish between structural and professional autonomy in schools. Schools may be given structural authority to make particular decisions about their operations and their classroom practice. However, in order to see improvements in results, they need the professional capacity to exercise that authority in pursuit of key system goals. Australian school systems have had varying degrees of autonomy for some time. There has been no attempt to comprehensively catalogue the relative autonomy of government or nongovernment schools, though there have been a number of separate studies which make some effort to consider the relative autonomy of each state's government schooling systems. Although devolution of decision-making power to government schools was first seriously floated in 1973 in the Karmel Report, limited progress was made until the 1990s. 40 Each Australian jurisdiction can be grouped into one of three categories as to their relative focus on school autonomy: 121 \uf0b7 Victoria has offered a unique environment for schools in terms of autonomy since the early 1990s. More than 90 per cent of the state's recurring annual budget is decentralised for schools to determine their own approach to staffing and administration. South Australia and the ACT also devolved powers to a greater extent than other jurisdictions in the early 2000s, though central authorities still have a greater say over school staffing decisions and management than in Victoria."}, {"section_title": "2.1.4", "text": "Implications for this study's methodological approach This literature review has provided a thematic summary of the range of factors known to influence student outcomes, and a measurement framework underpinned by literature which serves as a basis to extract meaningful information from the PISA and TIMSS data sets. The overarching theme that this literature review has highlighted is the importance of teaching efficacy, and, by association, school quality. Interconnected with this notion are more indirect drivers such as autonomy and strong school leadership and governance, which serve as preconditions that have lead-on effects for overall teaching efficacy. The purpose of this study is to further uncover the specificities of school quality present in the Australian education system using"}, {"section_title": "Case study: Broadmeadows Primary School", "text": "Broadmeadows Primary School, in the northern suburbs of Melbourne, has had a long standing interest in higher levels of school autonomy. With the introduction of the Schools of the Future program in the mid-1990s, the school was one of the first to be selected providing a higher level of school autonomy. Strategies such as internationalising professional development, training staff to mentor younger teachers, and allocating $300,000 to employ a full-time curriculum coach are some of the autonomous strategies being implemented to improve teaching practice. Autonomy in building staff capacity has enabled positive school outcomes: in the 2014 NAPLAN tests, Broadmeadows scored higher on average in Year 3 and 5 literacy and numeracy compared to similar schools. Autonomy has also enabled the involvement in other initiatives, such as the Powerhouse Schools project (Social Ventures Australia). This included initiatives such as: teachers being trained in the use of research-based learning behaviours toolkit, 30 percent of students being interviewed, with individualised programs being subsequently implemented, and parents attending forums to build awareness and capacity to improve their children's learning behaviour (Caldwell, 2015)."}, {"section_title": "Summary", "text": "While system level factors can play a key role in driving student outcomes and school performance, the literature indicates that this is achieved through indirect transmission mechanisms, which support the pre-conditions and incentives for schools to invest in good practice and management, which drives high quality teaching and improved school performance. Overall, the literature indicates that how resources are used is much more important in determining student outcomes than how much funding is provided to schools. In this context, school autonomy, when supported by effective school accountability, is a powerful enabling force for effective practice and improved performance. Critically, autonomous schools must have access to robust and transparent evidence on effective practice, and the capacity to be able to use data and evidence to target teaching strategies towards the needs of students in their individual context. These themes have strong parallels with aspects of reform which Australian schools have experienced over recent years, which are further uncovered and analysed as part of this study. the PISA and TIMSS datasets, and measure the extent to which variation in practice influence student outcomes. The ability to see which elements of school and classroom quality influence student outcomes can guide a more robust discussion in government about its role in the schooling system. In parallel, it is also important to understand how other factors also interact with each other and how they contribute to student outcomes. The reviewed as part of this study highlights different scenarios to which certain factors influence student outcomes, which emphasises the importance of classification and measurement further outlined in Chapter 3. The empirical analysis will therefore include a wide range of factors outside of the teacher's control to (i) isolate the notion of school quality; and (ii) provide potential insights into factors that are out of the direct control of government."}, {"section_title": "2.2", "text": "How school performance and school quality is measured As background and to inform the model developed for this study, outlined in Chapter 3 of this report, this section briefly discusses different approaches to measuring school performance and school quality in the literature. Early studies in measuring school quality and educational outcomes (Coleman, et al., 1966;Jencks et al., 1972) suggest that school effects have little impact on students' learning outcomes, rather ethnic and SES background factors constituted the predominant effects of students' educational outcomes. The consensus around these findings at the time were consistent with social and political opinion (Rowe, 2003). Rowe (2003) further highlights that the earlier findings have undergone much scrutiny on the primary basis of not accounting for the inherent nested nature of the educational system. This criticism spurred a range of studies into school effectiveness. Studies by Brookover, Edmonds, and Rutter began to analyse the contextual features of schools where students were performing better than their counterparts in comparable schools, after adjusting for the effects of intake characteristics. These early works found effective schools are characterised by a 'culture' oriented towards learning (e.g. professionalism amongst teachers, high expectations), and educational leadership (e.g. principal establishing agreed goals, increasing staff competence and involvement). A commonality of these early studies is that they also lacked methodological sophistication required to model and analyse the complex interrelationships between inputs, processes and outcomes, including indirect effects and reciprocal effects (Rowe, 2003). Absent also, was the ability to take into account the inherent nested nature of the schooling system -that is schools organised students into classes taught by teachers (Rowe, 2003). Raudenbush and Wilms (1991) note: \"An irony in the history of quantitative studies of schooling has been the failure of researchers' analytic models to reflect adequately the social organization of life in the classrooms and schools. The experiences that children share within school settings and the effects of these experiences on their development might be seen as the basic material of educational research; yet until recently, few studies have explicitly taken account of the effects of particular classrooms and schools in which students and teachers share membership.\" Rowe (2003) outlines two methodological advances worth noting. The first of which is the development of structural equation modelling techniques that enable the simultaneous estimation of interdependent effects among variables within a framework that takes into account measurement error, and the structural prediction residual. The second of the developments is the multilevel analysis methods that control for the inherent nested structure of the data, which enables the measurement of variables' effects at different levels of analysis (student, school, etc.). These statistical developments have been implemented in value added models, both in Australia and internationally. The term 'value added' does not have a uniform definition, however, it is most commonly used to describe the additional value schools bring to the learning outcomes of students, after controlling for students' characteristics and attributes (such as prior educational achievement) (DEECD, 2007). Hill (1995) distils the notion of value added as an attempt to \"indicate the educational value that the school adds over and above that which could be predicted given the backgrounds and prior attainments of the students within the schools\". The term 'school effects' or 'school performance' within the literature is equally interchangeable with the term 'value added' (Lu and Rickard, 2014). Internationally and within Australia, value-added models vary in the technical approach to measurement as well as in the compositions of the model. The range of approaches reflect the different times and purpose when they were developed. Lu and Rickard 2014 There are three predominant statistical approaches for value added modelling: \uf0b7 Gain core model -relatively simplistic in nature, this approach uses the average of the gain scores (the difference in pre-test scores to post-test scores) across all students in a school. Other variations include comparing the growth percentile for each students by taking the difference of the growth of a student and average growth of all students in the district/system with similar scores in previous tests. The growth measure is then aggregated across all the students in the school as indicator of the value a school adds to students' learning. A key assumption is that the effect of external and contextual factors (e.g. student SES) on students' achievement has been accounted for in their prior achievement. This assumption is not always met indicating limitations in the simplicity of the approach. \uf0b7 Covariate adjustment model -a single level regression model, either at the student or school level. Using the current test score as the outcome variable, the covariate adjustment approach attempts to explain the variation in this variable by using a simple statistical regression method to account for prior achievement of students attending a school and other student and/or school level contextual factors. When controlling for such factors, the difference between actual school mean performance and predicted mean performance is then associated as an indicator of school effectiveness. One of the main drawbacks of this model is that it does not take into account the nested nature of educational data."}, {"section_title": "2.3", "text": "A structural equation to isolate the drivers of school quality The approach of this report builds on early work by Fuchs and Woessman (2004) to isolate measures of school quality and the factors which underpin it, with a specific focus on the Australian context. This is achieved through the development of a structural equation of the drivers of student outcomes, and school quality, illustrated by Figure 2.4. This stylised equation builds on the measurement framework developed by this literature review. In this equation, contextual factors (the characteristics of students and schools that schools and government cannot change) combine with school quality and system performance (that is, the attributes of schools and school systems within the control of government) to determine outcomes. Chapter 3 of this report outlines how the PISA and TIMSS datasets may be used to develop detailed measures under each of these themes, and subsequently estimate effects of different drivers of student outcomes, and school quality. This chapter explains the approach taken to matching the findings from the literature review to the PISA and TIMSS datasets, and how this is then used to test empirically for the core drivers of students' outcomes. \uf0b7 Section 3.1 outlines the relevance of the PISA and TIMSS datasets from a statistical perspective. \uf0b7 Section 3.2 details the 'value-add' econometric approach to analysing the relationship between student outcomes and the drivers of school quality. \uf0b7 Section 3.3 considers the method used to aggregate individual question responses within the PISA and TIMSS databases into the themes of the measurement framework. \uf0b7 Section 3.4 discusses PISA scores over time between Australian jurisdictions, and considers the feasibility of drawing a connection between system settings and outcomes. \uf0b7 Section 3.5 outlines some of the limitations of the empirical analysis."}, {"section_title": "3.1", "text": "The PISA and TIMSS datasets The primary datasets used in this empirical analysis are: \uf0b7 The OECD Programme for International Student Assessment (PISA), which tests students' skills and learning progress in reading, mathematical and scientific literacy at age 15 (including students from years 9, 10 and 11)."}, {"section_title": "Accounting for variations in age and year level", "text": "The PISA and TIMSS datasets include different measures of students learning achievement and measure students at different points in their schooling life. PISA measures students' skills in understanding and applying key concepts in the domains of Reading, Maths and Science; whereas TIMSS focuses on students' knowledge and learning progress of the Maths and Science curriculum. The timing of the PISA test also means that 15 year old students across multiple school year levels sit the test at the same time, whereas TIMSS captures students of different ages in years 4 and 8. The implications of this for this analysis include: \uf0b7 Observations for Primary schools are only available through the TIMSS dataset; and 26 \uf0b7 Controls for school year level (and potentially age) are required when analysing the PISA data, whereas controls for student age are required when analysing the TIMSS data. Because of the variation in schooling grades (years 9, 10 and 11) sampled in the PISA dataset, it is possible to derive a concordance between PISA scores and 'equivalent years of schooling'. For Australia, a difference in scores of around 30 points is estimated to be equivalent to one year of additional schooling. An equivalent measurement cannot be directly estimated for TIMSS, as all students who sit the two TIMSS tests (for year 4 and year 8 students) are in the same year level."}, {"section_title": "3.2", "text": "Understanding and measuring school quality Following practice established in the literature, the contribution of school quality to student outcomes can be measured as the variation in student outcomes that remains after controlling for the observable characteristics of students and the school (Fuchs and Woessmann, 2004). In order to estimate school quality, so called 'value-added' models of student outcomes are used. In the context of PISA and TIMSS data, the value-added model of student outcomes is defined as: Here, the score of student i in school k in setting 12 j at time t is modelled as a function of student characteristics , observable school characteristics \u0393, and indicators for specific policy settings (such as differences across schooling systems) . After controlling for these observable characteristics, what remains are idiosyncratic student level variations (driven by omitted variables that systematically influence student outcomes, such as innate ability or attitude; as well as randomness-such as falling sick on the test day) and school quality or value-added . In plain language terms, value-added models (also known as multi-level models) are used to isolate the effects of differences in school practice on student performance, while controlling for observable student and school characteristics. Comparisons of performance between schools (in PISA) and across classrooms in schools (in TIMSS) can then be made on a 'like-for-like' basis to provide an estimate of the effect of school quality. Chart 3.1 below provides a simple illustration of how school level value-added is estimated. In these charts, a variety of students with a variety of outcomes attend each school. After controlling for the starting ability of students, and assuming that each school has a similar profile of students, the vertical difference between the red and green lines can be considered as the additional value added by School A to the outcomes of its students, relative to School B. It is a measure of the additional score an average student receives simply by attending School A (due to its higher quality) instead of School B. This approach measures the variation in outcomes resulting from the different practices and management of schools (in PISA) and across classrooms (in TIMSS)."}, {"section_title": "Identifying and measuring the drivers of school and classroom quality", "text": "The second part of the analysis unpacks the relative importance of the various factors that make up school quality ( ) in the proposed model, to identify which ones are most strongly associated with student performance in Australia. Findings from this study can then be used to inform where governments might look to identify proven practices that will provide the strongest improvement to Australian schools in order to lift student outcomes. Questions of school principals, teachers and students from PISA and TIMSS 2015 datasets were mapped to various aspects of school quality outlined in the measurement framework. These were included in the empirical model along with the student and school contextual factors to estimate student performance. This is achieved by replacing the indirect value-added measure of school quality with direct observations of school management and teaching practices. The mapping process of representative questions for the themes and sub-themes in the measurement framework from 418 data items in PISA and 255 data items in TIMSS is explained in section 3.3.1 below. After incorporating direct observations of school quality using representative questions, the full student level model then becomes: Here, the score of student i in school k in setting (all of Australia, metro, provincial or remote) j at time t is modelled explicitly as a function of the representative questions , along with student ( ) and school ( \u0393) characteristics, as well as differences across schooling systems . Including the drivers of school quality together (as opposed to the partial analysis undertaken in the previous section) allows us to isolate the effect of each sub-theme in driving student outcomes while controlling for both the contextual factors: in effect, controlling for the impact of the other themes. The standardised effect size of each representative question and theme can be calculated using the method described in Section 3.3.2 below. Findings from the PISA dataset show the extent to which variation in student performance is driven by differences in the various aspects of school quality within the school and across schools. Findings from the TIMSS dataset, on the other hand, show the variation in aspects of school quality across classrooms of different schools. PISA captures information about teaching practice indirectly from the principal and through student perceptions of their teachers. PISA also provides more insight into the school climate while TIMSS has detailed information about the classroom and resourcing at the school. The TIMSS dataset offers direct insight into teaching practice and curriculum in the classroom from the teacher of students in the same class. Representative questions from PISA and TIMSS datasets would complement each other as each individual dataset has limitations in particular areas of the measurement framework. Themes and sub-themes can then be ranked in order of relative importance, based on the extent to which their representative questions can explain variations in student performance. Themes that are considered more important aspects of school quality could identify substantial differences in school management and teaching practices across schools and classrooms that affect student outcomes in Australia. The relative importance of a theme is most commonly measured by two methods (Liu et al., 2014). A 'bottom-up' approach measures the difference in the coefficient of determination 2 from adding all representative questions in a sub-theme, compared to just using the observed controls of student and school characteristics. Alternatively, the 'top-down' approach measures the difference in the 2 measure that results from removing questions in a theme, compared to the full model (which includes the controls and all of the themes). This analysis takes the average of the two approaches to calculate the relative importance."}, {"section_title": "Robustness testing", "text": "To test whether the identified set of representative questions capture the differences in school quality between schools, it is possible to rerun the multilevel regression with the representative questions and examine the residual school level value added that is yet to be accounted for. It is also possible to undertake testing for different sub-samples, such as for different student and school characteristics, as well as across different time periods and jurisdictions. This allows for the identification of whether drivers of school quality differ between cohorts, and across time."}, {"section_title": "3.3.1", "text": "Mapping questions to themes and clustering From a conceptual standpoint, the literature review outlined in Chapter 2 establishes a framework of the themes that drive student outcomes. Nine broad anchor themes capturing system, school and student level drivers of student outcomes guide the development of the measurement framework. The process of mapping PISA and TIMSS questions to these conceptual themes is achieved by decomposing these themes into a series of nested sub-themes, which capture more nuanced aspects of the drivers of student outcomes, broadly illustrated by Figure 3.1 below. In approaching the mapping process, PISA and TIMSS questions are used to create instruments (that is, variables) that represent the themes identified in the literature, and which form the basis of the empirical modelling. That is, they comprise the independent variables which are modelled against student outcomes-the dependent variable. Given that the PISA and TIMSS questions generally relate to specific aspects of school practice and management within a given theme, a more precise definition of what each question is intending to capture is developed within the context of the overarching analytical framework. The process of mapping survey questions to themes is summarised as follows (further illustrated in in Figure 3.2): 1. Each question is analysed and allocated to its 'anchor theme'; 2. Questions that are unrelated or tenuously linked to the framework are discarded; 3. Repeat step 1 for questions in the anchor themes: analyse the question in each anchor theme and allocate it to the appropriate sub-theme; and 4. Continue until the survey question is allocated to the final level sub-theme. It should be noted that this process generates a measurement framework that is more detailed than the broad outline motivated by the literature canvassed in Chapter 2. In particular, the detailed themes captured in the expanded measurement framework make use of the detail of the PISA and TIMSS datasets by establishing a set of detailed sub-themes within the broad categories previously established in Chapter 2. Through this process, questions can be interpreted differently (as a result of containing different aspects of educational quality within the question itself) which makes the allocation of questions to sub-themes within the framework partly subjective. For example, the TIMSS question on how often the \"teacher asks students to complete challenging exercises that require them to go beyond the instruction\" (BTBG14C) can be interpreted in several ways, as seen in Figure 3.3. Within each of these sub-themes however, the wide array of survey questions invites the notion of further clustering questions together for the purpose of analysis. 13 This is done to ascertain a representative question that is used in the estimation model, which is described in section 3.3.2. 13 Partial correlation analysis clusters variables together to derive a representative question (not all sub-themes will necessarily contain multiple representative questions)"}, {"section_title": "Identifying system level factors in the PISA and TIMSS datasets", "text": "The PISA and TIMSS datasets include a broad range of questions and instruments which capture aspects of students' educational experience and school practice. These questions are necessarily answered at the level of the school, including teachers and students within the school. There are questions in these datasets that capture aspects of the system context in which the school operates. In this regard, they are not measures of school practice, but rather aspects of the system context over which educational authorities would generally be expected to exercise control. These questions broadly relate to the themes of autonomy, accountability and resourcing as established by the system, but from the perspective of the school. These system focused questions are relatively few in number (particularly for TIMSS), and are not direct observations of specific system policies across Australia's schooling jurisdictions, and therefore do not lend themselves to direct assessments of the impact of any given policy. Rather instruments should be interpreted as instruments which capture aspects of system level attributes which may have implications for policy. An alternative approach to considering the effects of system level attributes on student outcomes is to directly compare the performance of Australian schooling jurisdictions to differences in system levels policies, which relate directly to these themes. This more 'top-down' analysis of the impacts of system level drivers of student outcomes and school quality is considered in section 3.4 below. An example of a complete mapping based on literature and survey questions can be seen through the anchor theme of Teaching Efficacy. In this framework, evidence from the literature has guided the structure to the 'level 3' sub-strata. Beyond this, the PISA and TIMSS survey questions were used to develop further decompositions of the drivers. This is presented in Figure 3.4 below. Detailed mappings for all nine anchor themes are included in Appendix A."}, {"section_title": "Example of mapping a question to a sub-theme", "text": "The below provides an example process of mapping a question to a sub-theme. This process accounts for the subjective nature of questions. Question: BTBG14C: How often the teacher asks students to complete challenging exercises that require them to go beyond the instruction? Source: TIMSS 2015 question 1. This question describes the notion of autonomous learning within the classroom environment, which is administered by the teacher. Applying the process of allocating the question to a sub-theme (whilst accounting for the element of subjectivity), the question strongly relates with the anchor theme of Teaching Efficacy. 2. Within Teaching Efficacy, the question is determined to be most related to Teaching practice (as it is also not an attribute of the Teacher). 3. Requiring students to complete challenging exercises beyond the instruction is an approach the educator takes to teaching and learning, in this sense, the questions is most suited to be allocated into the Approach to teaching and learning sub-theme 4. This question further pertains to a specific instructional approach, therefore it is further allocated to the Instructional Approaches sub-theme. 5. Finally, requiring the student to go beyond the instruction is strongly associated with autonomous learning techniques and results in the final location of the survey questionnaire. "}, {"section_title": "Identifying key questions for modelling and analysis", "text": "The top down approach of sorting survey questions into their appropriate themes can generate multiple questions that are associated with a final sub-theme, creating 'clusters' of questions for each sub-theme. From a statistical standpoint, having multiple questions being modelled as individual independent variables increases the dimensionality of the model. Where these questions represent the same fundamental driver of student outcomes, estimation becomes less accurate, particularly where these variables are collinear in their effect. In light of this, the methodology aims to reduce the number of questions, and the dimensionality issue, while capturing the underlying interpretation of the theme the questions are intended to represent. This is done through identifying one (or more) representative question(s) within each sub-theme, that are highly significant in explaining student outcomes, and that are correlated with the other questions in the sub-theme (that the chosen question effectively 'represents')-as illustrated in Figure 3.5 below. This procedure produces a set of final questions that are all significant predictors of student outcomes, while being largely uncorrelated with each other. Partial correlation analysis is used to determine the association between each relevant question and student outcome measures while controlling for student and school level contextual factors. To account for the degree of variability in responses to each question and allow for comparisons across questions, the standardised absolute effect and p-value is calculated using the partial correlation results. For categorical responses, this is given by the following equation: The standardised effect of question i ( ) is given as the weighted average of the absolute standard effect of each response j relative to the omitted response (given as the standard deviation multiplied by the absolute value coefficient | |). The weights are given by the likelihood of each response j being given relative to the omitted response ( ). A similar standardisation process is undertaken for the p-value. For each sub-theme, the standardised p-values and the correlation between questions is used to cluster the full set of questions around a representative questions. The clustering process for each sub-theme is given as follows: \uf0b7 Rank the questions in terms of their significance using the standardised p-value. Questions that do not meet a given significance threshold are discarded as not having a strong link to student performance."}, {"section_title": "Providing a link between system settings and jurisdictional performance", "text": "As outlined above, the PISA and TIMSS datasets do not generally include measures or instruments which directly capture the difference between system settings and policies in Australian jurisdictions, for the purposes of analysing how these aspects of policy may influence student outcomes in Australia. Separate to the analysis outlined above, this analytical stream examines the longer term trends in student performance across different school systems in Australian jurisdictions, seeking to relate movements in these trends to differences in system settings at a thematic level. This is achieved by broadly mapping the system specific trends in performance estimated through the model outlined in section 3.3 above, against major historical system initiatives across Australian school jurisdictions and systems over the past 20 years. The following sections outline the approach to developing this evidence base and identifying the impact of these initiatives on student outcomes. The results of this analysis are presented in Appendix D of this report."}, {"section_title": "3.4.1", "text": "Revealing systemic changes in performance Chart 3.2 and Chart 3.3 below show a summary of the recent trends in PISA scores for Australian jurisdictions, from 2000-2015. While there is a clear downward trend in system level performance (measured in terms of average student outcomes) over this period, there is also an observable difference in the permanent levels of performance across jurisdictions, and the level of change that has occurred over time. The ACT and Western Australia, in absolute terms, have been the highest performers on PISA, while Tasmania and the Northern Territory's scores have been consistently lower than those of the other states. Although all states have declined over the period, the Northern Territory has significantly improved between 2012 and 2015 (noting the limitations of the small sample sizes in that jurisdiction); Victoria has had the smallest decline among jurisdictions while Tasmania has had the largest decline. The results above do not account for the fact that each jurisdiction has a different-and changingcohort of students across each test year. As identified in the literature review, both school and student contextual factors, such as socio-economic status, can have a significant impact on student results. When measuring the performance of a jurisdiction in contributing to student outcomes, it is necessary to control for these contextual factors to isolate the impact of each jurisdiction's schooling system at a high level. Following the method of controlling for observable contextual factors, estimated system level effects-all else being equal-represent differences in the system settings of jurisdictions within Australia. In practice, it is possible that these estimated system level effects will be relatively small, given much of the variation in student outcomes can be explained by student and school level factors. Where significant variations in system level effects are identified, both across jurisdictions and over time, these may be linked to observed changes in governments' approach to schooling that has occurred in these jurisdictions."}, {"section_title": "3.4.2", "text": "Desktop review of schooling system settings and initiatives To unpack what system-level differences are contributing to variation between jurisdictions, a desktop review of 'grey literature' has identified the most significant schooling system changes in Australia over the past 15-20 years. 14"}, {"section_title": "3.5", "text": "Limitations to the analysis As with any original empirical study, the approach used in this study is not without its limitations. In particular: \uf0b7 One of the central contributions of this research involves the mapping of PISA and TIMSS questions to conceptual themes and drivers of student outcomes, to identify and estimate the relative importance of these different factors. A key limitation of this work lies in the quality of the instruments available for this study (that is, the usefulness of the variables in the PISA and TIMSS datasets), as well as the accuracy and appropriateness of the mapping exercise. -Ultimately, the mapping process identified above is subjective, and there will exist limitations in the appropriateness of the interpretation of different questions when representing different conceptual themes. -The results of this analysis should be interpreted in the context of the particular PISA and TIMSS questions which are used in the modelling, which may have vague or inconclusive links to aspects of practice. -The approach to this study has been to develop a methodology which will extract the most meaningful insights available from this dataset, and future research which builds on this methodology would be expected to refine and enhance the mapping process and interpretation of the results accordingly."}, {"section_title": "Findings from the analysis", "text": "This Chapter outlines the findings from the empirical analysis, in line with the methodology set out in Chapter 3. \uf0b7 Section 4.1 presents results from the first stage of the analysis-a 'value-added' modelling approach to estimating school and classroom quality; \uf0b7 Sections 4.2-4.5 outline the findings from the analysis of the different drivers of school quality, based on the variables identified through the mapping process set out in section 3.3. The results from the analysis set out in section 3.4 are provided in Appendix D of this report."}, {"section_title": "4.1", "text": "Measuring school quality and value-added Multi-level modelling utilises the nested nature of students within schools to isolate the effects of differences in school practice on student performance from the attributes of individual students, such as their socio-economic status, age and other contextual factors. As the isolated effect can be considered the 'value-added' by the school (over and above the other contextual drivers of outcomes), they are also often referred to as value-added models (see Section 2.2 of this report). Multi-level models are important in education research as just looking at the absolute performance of schools does not give an accurate reflection of the school's quality. This is because students are not randomly placed within schools, but instead students tend to congregate, based on factors such as socio-economic status and prior academic achievement, which themselves have an effect on school performance outside the actions of the school. By controlling for observed student and school characteristics, comparisons of performance between schools are made on a 'like-for-like' basis. The results can be interpreted as the effect of moving the same student from one school to another. Note that this is a relative measure that compares against the value added by the average school. Consequently, the results are meaningful in understanding the variation between schools rather than the absolute value added by schools. Table 4.1 outlines the contextual factors that have been controlled for in the multi-level modelling for PISA. They cover both contextual factors at the student level and at the school and jurisdictional level. A similar set of controls have been used for the TIMSS dataset, however it is smaller due to limitations in the questionnaire. This can be found in Appendix C: Table C.1. It is notable that prior academic achievement is not observable through the PISA and TIMSS datasets, which is a limitation of the analysis, to the extent that non-random assignment of students to classes (based on ability) is not properly controlled for in the modelling. It should be noted though that the analysis does explicitly control for whether the school is academically selective or not. However, the difference between the top and bottom 10% of schools in terms of value added still represents significant differences for individual students, at a difference of 44 points, which is equivalent to approximately 1.5 schooling years. 24 This suggests that if Australia were able to lift the performance of a school from the bottom 10% to the top 10%, it would equivalent to 1.5 years of schooling for those students. Indeed, the estimated value-added of schools to student outcomes is jointly significant in predicting student outcomes across the Australian schooling system. These results should not be interpreted as school quality having only a small impact on student outcomes, but rather as an indication of the variation in quality that exists across schools. Under this methodology, a high performing system could be one where all schools contribute equally to the outcomes of students and hence where there is no measurable variation in value-added made by schools. Indeed, this form of value-added analysis says nothing about the overall level of quality of Australian schools, only variation in quality. The results above isolate the school level value added while controlling for differences in jurisdictions (that is, Australian states and territories). However, the results can be disaggregated to both show the average jurisdiction's value added compared to the national average, as well as differences in the distribution of value added estimates across jurisdictions. This jurisdictional analysis is further explored in Appendix D of this report, when considering the link between performance and policy at a jurisdictional level in Australia. Similar results can be produced for the TIMSS datasets. Recognising that the TIMSS dataset nests students within classes with a single teacher, it is possible to estimate the 'value-added' provided by classrooms to student outcomes, which can be interpreted as a measure of classroom quality. The contribution of classroom quality to student maths scores in TIMSS for year 4 and year 8 are given in Chart 4.2. Comparing the TIMSS results to the PISA results, the contribution made by classroom quality to student outcomes is typically higher than the contribution made by school quality alone. This is particularly the case for year 8, where 37% of classrooms have a value added estimate statistically different from zero. The equivalent figure is 20% for year 4 classrooms. This finding is consistent with evidence from similar studies which emphasise the significance of individual teaching practice and the classroom environment in driving student outcomes, irrespective of the specific school environment. The difference in value added between the top and bottom 10% of classrooms is 106 points for year 8 and 65 points for year 4. While it is not possible to convert this score into equivalent years of schooling, this contribution is highly significant, particularly when compared to the relatively modest contribution made by value-added measures of school quality. Chart 4.2: Distribution in classroom value added to student TIMSS maths scores Source: Deloitte Access Economics analysis of PISA and TIMSS data 24 Deloitte Access Economics makes the simplifying assumption that 30 points in PISA scores is approximately equivalent to one schooling year (ACER, 2016)."}, {"section_title": "Year 4 Year 8", "text": "The results of the multi-level modelling can be disaggregated to show the proportion of the variation in student outcomes that is explained by different contextual factors at the student and school level, relative to the value-add contribution of schools and teachers. The results from the analysis show that approximately 30% of the variation in PISA scores is accounted for by observable student and school contextual characteristics, including student and school level Economic Social and Cultural Status (ESCS), the location of school, the system (that is, government or non-government) and the jurisdiction. Then, variations in `school quality' explain between 2% and 7% of the total variation in student outcomes observed across the country (Chart 4.3). This represents approximately an additional 0.3 to 1.2 years of schooling. The share of value added explained by schools have broadly remained constant over time. It increased from 2% in 2000 to 7% in 2012 before decreasing to 5% in 2015. These results are lower than those presented in the 2016 report by Deloitte Access Economics, which found that schools accounted for 6% of variation in maths scores in 2003 and 14% of maths scores in 2012. 25 The difference is due to the inclusion of additional controls for state, age and grade in the current modelling. This is because these factors are not random at the school level. For instance, the grade of students will cluster due to differences in starting school ages between states. With the addition of these controls, the variation explained by them are now attributed to the observed controls. Nonetheless, a significant proportion of variation remains unobserved and therefore cannot be attributed to particular causes. This includes, but is not limited to students' ability, prior achievement, self-efficacy and motivation, and their home learning environment. The TIMSS data shows that between 11%-13% of the variation in year 4 maths scores is due to differences at the classroom level. This increases to 28% to 30% for year 8 students. This is higher than the school level results from PISA, and suggests that differences in classroom quality is a more significant factor in driving student outcomes, as discussed above. Compared to the PISA results, there has been less variation in the contribution of classroom quality over time. In very broad terms, these results demonstrate that a modest increase in the variation of school quality (but not classroom quality) in Australia has coincided with an overall decline in performance. This indicates that variation in school quality may be associated with more unequal distributions of quality teachers (and effective teaching) across the schooling system, disproportionally affecting certain students and schools who are potentially falling behind as others succeed in improving their performance and outcomes. In addition to the role of schools in explaining variation in student academic performance (as proxied by their scores in the TIMSS and PISA test), it is also possible to isolate the school (and classroom) effects on non-academic outcome measures, including student sense of belonging, and engagement. The results for TIMSS for 2015 are presented in Table 4.2 below. To place the contribution of teacher and school quality to student outcomes in context, it is possible to compare the effect of school quality against the standardised (that is, the typical) effects of different contextual characteristics at both the student and school level. The results for PISA are presented in Chart 4.5, while the results for TIMSS are presented in Chart 4.6. These results emphasise the importance of socio-economic status (measured using the ESCS index) and Indigenous status in predicting student learning outcomes. This typical effect of school quality is estimated to be lower than the typical effect of school level socio-economic status on student outcomes, which indicates that typical variations in school quality do not offset the typical impact of factors of educational disadvantage. The typical effects of other contextual characteristics are generally modest-for example, the effect of being in a government school (relative to a non-government school)-while positive-is very small. 26 Measured based on student reports of bullying"}, {"section_title": "(Year 4) (Year 8)", "text": "Source: Deloitte Access Economics analysis of PISA data The TIMSS data suggests that while school quality alone is unable to overcome contextual disadvantage, it can when combined with classroom quality. Variations in classroom quality typically contributes 50 points to student outcomes, compared to -20 to 10 points for contextual factors. While the effects at the student and school levels are likely to be underestimated in the TIMSS data due to their correlated nature-for instance parental education and home possessions, and the proportion of economic advantage and disadvantage within a school-classroom quality is still likely able to offset their typical impact on student outcomes. "}, {"section_title": "Identifying and measuring the drivers of school quality", "text": "As a part of the PISA and TIMSS tests, questionnaires for students, school principals and teachers (TIMSS only) are administered to gain insights into the aspects of school practice and management that are associated with student achievement (among other objectives). In PISA, there are over 400 individual questions related to teaching practice and school conditions. For TIMSS, there are over 250 questions. Given the large number of questions, it is neither tractable nor desirable to work with the full set of questions. Sections 3.3.1 and 3.3.2 outline the methodology used to categorise, cluster and prioritise these questions for inclusion in the modelling of student outcomes, and school quality. This is achieved by selecting a set of representative questions for analysis, which are statistically significant predictors of student outcomes, and which are correlated with a range of other (ontologically similar) questions (which the questions subsequently 'represent'). For the questions identified under the most granular strata of the measurement framework set out in section 3.3.1, a p-value significance threshold of 0.15 is used to reduce the set of questions to relevant and significant predictors of student outcomes. This excludes questions that are not significant in explaining variation in student outcomes after controlling for contextual factors. Then, the questions are ranked in terms of their p-value significance, and a correlation threshold of 0.3 is used to reduce the set further. This removes questions that move in line with one another and are consequently 'represented' by the most significant identified question in a given theme. An illustrative example of the process is seen for the theme 'instructional approaches'. Of the 14 PISA questions considered under this theme, four are excluded for not having a strong relationship with student PISA scores. The remaining eight questions (which include how often the teacher demonstrates an idea, how often the teacher discusses students' questions etc.), are all highly correlated with each other. Consequently, the set is reduced to one key question, how often students are allowed to design their own experiments (in science class), which had the lowest pvalue among the correlated set of questions. This question, while specific in nature, is used to represent the general theme of 'instructional approaches' and-by virtue of the established methodology-will approximately provide a measure of the effects of the other, omitted, questions under the 'instructional approaches' theme. A similar process is repeated across each of the sub-themes constructed in the measurement framework. Overall, the 418 questions of the PISA dataset are reduced to 63 representative questions that represent 22 sub-themes relating to quality at the school and system level. A similar process is undertaken for TIMSS, reducing the set of 255 questions to 76 questions representing 24 sub-themes. The set of representative questions is then added to model with the student and contextual controls to understand the relative importance of each driver of school quality, as outlined in"}, {"section_title": "School quality and economic outcomes", "text": "Based on previous research by Deloitte Access Economics on the Economic contribution of improving school quality, it is possible to consider the economic effects of increases in school quality, estimated through the above modelling and analysis. Assuming an initiative was able to lift the performance of the bottom 10% of schools to the 10% of schools. This would add 1.5 years of schooling to those students, and is equivalent to 44 points. Given an average of 494 points in PISA 2015 maths scores, this would raise the average PISA score by 4.4 points, or 0.9% overall. Given a 0.9% increase to average PISA scores, GDP will increase by 0.14% once the effect is fully realised in the labour force. This is equivalent to a gain of $2.0 billion (if the effects were fully realised in 2017). As classroom quality is a larger contributor to student outcomes compared to school equality (see TIMSS results), it is likely that improving classroom quality will have a larger positive impact on the economy. The factors that contribute to school and teaching efficacy are further explored and estimated in the following sections, providing insights into how government may change their approach to achieve such improvements in quality. section 3.3.3 above. A full list of the representative questions mapped under each theme has been provided as an accompanying addendum to this report. "}, {"section_title": "4.3", "text": "Drivers of school quality and their relative importance This section tests the relative importance of each school quality 'driver' in explaining variation in student PISA or TIMSS scores, following the method set out in section 3.3.3. In simple terms, a driver that explains more variation in student outcomes, and has a greater standardised effect on student outcomes, is considered more important. The results from this analysis at the sub-theme level (level 2 in the overarching measurement framework) are presented below in Table 4.3. These results provide an estimate of how much each theme contributes to differences, or variation, in student outcomes. This is presented as a percentage of the total variation in student outcomes. For instance, variation in teaching practice explains the largest variation in student scores, at 6.1% for PISA maths scores, and 13.1% for TIMSS year 8 (and 3.9% of TIMSS year 4) math scores. When all the drivers of school quality are added, 13.8% of variation in PISA maths scores can be explained. Similarly, 27.5% and 8.4% of the variation in TIMSS math scores can be explained respectively at the year 8 and year 4 levels. The variation in outcomes explained by school quality drivers in the PISA dataset is higher than the variation explained by the value-added measures outlined in section 4.1. This is likely the case as the PISA questions capture aspects of practice at the student level, which may vary within schools, and therefore capture unobserved effects of varying classroom quality. The variation in"}, {"section_title": "Representative questions for 'system level factors' in the PISA and TIMSS datasets", "text": "The process of identifying only significant representative questions based on an analysis of the relationship between questions and student outcomes eliminates a range of questions from the full model. In particular, this process eliminates all questions considered to be related to the system level theme of accountability. Further, the model includes relatively few questions that relate to aspects of autonomy in PISA, and no such questions in TIMSS. In this regard, this 'bottom-up' approach to analysing the drivers of student outcomes and school quality is limited in its ability to highlight the contribution of these more enabling system factors like accountability and autonomy. Further, these questions are not instruments for specific policies that may relate to these aspects of Australian education systems. The relationship between more direct observations of system settings and system level performance is explored further outside of this core model, in section 4.3 of this report. outcomes explained by school quality drivers in the TIMSS dataset is broadly in line with the valueadded measures set out in section 4.1. The effects of observed aspects of school and teaching practice in TIMSS explain slightly less variation in student outcomes than the value-added measure of classroom quality, which suggests that some important aspects of teaching practice (which influence student outcomes) remain unobserved in this analysis. Across the data sets, teaching practice is consistently found as the most important theme driving student outcomes. Classroom environment; school leadership, governance and culture; and material based resourcing are also ranked among the most important drivers in all three of the test data sets. Factors relating to system autonomy-as identified by schools-are found to be less important in predicting student outcomes than other, more direct, aspects of teaching practice. This is to be expected, as factors relating to autonomy vary at a system level, and would be expected to influence student outcomes and school quality through their impact on aspects of school practice. Given this analysis considers the contribution of different factors of student outcomes at a school level in a 'bottom-up' fashion, it does not provide a direct link to aspects of policy which relate to factors such as autonomy, and the link between these policies and initiatives on system level performance. Section 4.3 of this report considers the performance of Australia's schooling jurisdictions in the context of these more direct differences in policy initiatives, while Chapter 5 of this report makes some observations regarding the implications of these findings for policy-makers in Australia. 0.4% n/a n/a Classroom organisation and environment -Organisation 0.2% 3.6% 1.1% Teaching efficacy -Attributes 0.1% 1.4% 0.3% Accountability 0.0% n/a n/a Resourcing -Curriculum and staff based n/a 0.3% 0.2% The relative importance of each driver in the analysis of each data set is indicated by the colour of the cell: a darker blue indicates that a driver was of greater relative importance, while lighter blue shading indicates that a driver was of lower relative importance. * School leadership, governance and culture is an anchor theme."}, {"section_title": "Source: Deloitte Access Economics analysis of PISA and TIMSS data", "text": "The following sections disaggregate results for the most significant identified themes into further detail. It should be noted that the methodology developed for this study generates an extremely detailed set of results and findings, of which the below is only a subset. The questions which comprise this analysis are often complex and nuanced in nature, and this report does not seek to examine and evaluate the implications which arise from all of the findings which have been generated. Rather, it intends to consider the implications at a more strategic and summative level. While some specific and detailed commentary is provided in the following sections, a more comprehensive analysis and discussion of implications for policy which arise from all of this study's empirical findings remains an area for further work."}, {"section_title": "Teaching efficacy -teaching practice", "text": "'Teaching practice' pertains to the professional attributes and attitudes of teachers, as well as their approaches to delivering teaching and learning in the classroom. This covers many elements of practice, including what the educator delivers to the class (curriculum), how the educator delivers to the class (instructional approaches), how the educator tracks learning outcomes (student assessment) and whether the educator provides one on one assistance as required (targeted teaching strategies). Teacher wellbeing and development factors (engagement and wellbeing, professionalism) are more indirect components of teaching practice that influence the effectiveness of teaching. The relative importance of the sub-themes within teaching practice are presented below. 'Instructional approaches' covers variations in the methods used by teachers to run their classes: the pedagogical approaches that teacher employ, the extent to which students may express opinions, teacher and student engagement in idea generation and discussion, and explanation of content and ideas. This sub-theme has the largest explanatory power for high school students, explaining 2.9% of the variation in student PISA maths scores, 4.3% of year 8 TIMSS maths scores. By way of comparison, the relative contribution made by school level 'value-add' in explaining student outcomes is around 5%. This suggests that differences in teaching practice between schools are the most significant driver of the variation of outcomes explained by schools. In contrast, instructional approaches are relatively less important in explaining variation in TIMSS year 4 maths scores after controlling for contextual factors, accounting for 0.9% of the variation in scores. 'Instructional approaches' as a driver of quality is represented by 9 key questions at the year 8 level representing variations in approaches to teaching, including how often the teacher asks students to work on challenging problems or problems for which there is no immediately obvious method of solution. At the year 4 level, it is represented by 4 questions, including whether the teacher asks students to work on problems while the teacher is occupied by other tasks, and how often students are allowed to design or plan experiments or investigations. Two questionshow often students are permitted to use calculators in class, and how often students work in mixed abilities groups -are common to both grades. In the PISA dataset, professionalism (exhibiting the conduct and behaviours expected of a teacher) is also a relatively important sub-theme, explaining 3.1% of the variation in student maths scores. In contrast, it is relatively less important for TIMSS, explaining just 0.20% of the variation in maths scores for year 8 students. This, in part, may be the result of the questions available for mapping in each test. 28 For the PISA questionnaires, the theme is represented by two key questions: (1) whether teachers disciplined the student more harshly compared to other students, and (2) whether the teacher called on the student less often than other students. In contrast, professionalism in the TIMSS dataset does not directly focus on their behaviour towards students, and is represented by the question whether teacher arriving late is a problem for the school. The PISA dataset also suggests that the employment of targeted teaching strategies contribute to significant variation, and that in particular, student achievement is greater where teachers who are more likely to provide individual help when an individual student has difficulties. In TIMSS, the most important sub-theme for explaining variation in year 8 maths results is 'instructional approaches'. This is followed by teacher engagement and wellbeing (the extent to which teachers are motivated and prepared to teach). This is represented by questions relating to whether they feel prepared to teacher certain topics in mathematics. This explains 4.0% of the variation in maths scores for year 8 students, and 1.2% of the variation in maths scores for year 4 students. Engagement and wellbeing is relatively more important for explaining variation on year 4 student outcomes (compared to teaching practice overall). For year 4 students, curriculum (that is, the type of content covered by the teacher) is also more important in explaining variation relative to year 8 students. This could be because at the lower grades, there are fundamental numeracy topics that should be covered. Consequently, ensuring what students learn (whether through the curriculum or through teacher confidence in particular topics) is more important than variation in instructional approaches themselves. The proportion of variation explained by the sub-themes within teaching practice is given in Table 4.4. It is also possible to directly interpret how the representative questions affect student PISA scores both directionally and in terms of the effect size. The partial effects in Table 4.5 show the relationship when only controlling for student and context, and the full effects show the relationship when controlling for student and context, as well as other teaching practice and school quality drivers. The theme 'instructional approaches' is represented by the question how often students are allowed to design their own experiments in PISA 2015 (Table 4.5). For instance, the table shows that holding contextual factors and the effects of other drivers of school quality fixed, moving a student to a class that is a standard deviation more likely to allow students to design their own experiments compared to the average class will lower their PISA maths scores by 2.45 points. Note that, because PISA 2015 had a science focus, it did not directly survey some aspects of maths teaching. Accordingly, there is no direct link between the sciencebased instructional approach question and student maths outcomes. In TIMSS, more frequent use of instructional approaches that focus on certain tasks compared to the average teacher has a positive effect on student TIMSS results in maths. This includes assigning specific tasks such as working on problems as a whole class with guidance from the teacher, and allowing students to use calculators. Furthermore, encouraging students to work in mixed abilities groups more often than average has a positive relationship with student PISA scores. This emphasises the value of collaboration, as also seen through the positive effect when students are also encouraged to work on problems in class. This finding supports previous research around the use of ability-based groupings, and raises the importance of understanding the difference between within-class targeted teaching and betweenclass ability grouping. Targeted teaching strategies-where teachers of one class use different approaches to educating students with different levels of prior ability in a topic area-play a significant role in determining outcomes. However, grouping students into entirely separate classes based on their ability has been found to have particularly negative equity impacts on 'lowtrack' groups (as discussed in section 2.1.2 above). It should be noted that some of the results presented here are not intuitive in terms of their effect size. In some cases, controlling for other factors can make interpreting results difficult. For example, the question: \"Teacher work together with other teachers to try out new ideas more often than average\" is found to have a negative effect on student outcomes. Controlling for other measures of practice though, this question may be identifying those less experienced teachers, who seek support to develop lesson plans and improve their practice. In general, it should also be noted that these questions are intended to be representative of a broader range of correlated questions which sit within each practice theme, and any direct interpretation of the focus of a particular question should be made with caution. Overall, these results emphasise the importance of key aspects of teaching practice, such as targeted teaching and effective instructional approaches. Notably, these pedagogically focused themes are more important than those themes which relate to curriculum and assessment, and the process of lesson planning and collaboration. It is not within the scope of this study to examine the findings for each question and identify implications for practice and policy. Such analysis and evaluation of implications may be conducted by building on the methodology and evidence base established through this study."}, {"section_title": "School leadership, governance and culture", "text": "School leadership, governance and culture covers a number of sub-themes on the overall school mission and specific policies, as well as the degree of parental and staff involvement with the governance of the school. It functions as an effective pre-condition that implicitly enables improved student outcomes to be achieved via the conditions in which teachers work and deliver classes. This includes the following: \uf0b7 School policy, mission and goals informs the high level strategic direction and objectives set out by the school. It is represented by key questions including whether the school uses data to plan specific action for school development, whether improvement exists at the school, and whether the school offers assistance with schoolwork. \uf0b7 Principal attributes, culture and integration describes the degree to which principals are involved with the governance and culture of the school. It is represented by key questions including the highest level of education obtained by the principal, whether the school implemented any measures in teacher development, and whether the principal promotes teaching practices based on recent educational research. \uf0b7 Parental culture and involvement describes the degree to which parents are involved with the governance and culture of the school. It is represented by questions including whether the school provides a welcoming and accepting atmosphere for parents to get involved, and the degree of parental commitment to ensure that students are ready to learn. \uf0b7 Staff culture and involvement describes the degree to which teaching staff are involved with the governance and culture of the school. It is represented by questions including the principal's opinion on teacher's ability to inspire students, and the frequency that principals engage teachers to help build a school culture of continuous improvement. The relative importance of the sub-themes in explaining variation in student maths scores is summarised in Table 4.9. Using the PISA dataset, principal attributes, culture and integration is the most important sub-theme, but is relatively less important for TIMSS. This is due in part to the different ways in which the questions are framed. Whereas the PISA questionnaire focuses on the role of principals, in encouraging teacher professional development, and driving school improvements, the TIMSS questionnaire focuses on the attribute of principals, such as their years of experience. In contrast, the TIMSS dataset finds that policy, mission and goals is the most important sub-theme within school leadership. It is difficult to compare the findings of this report with those of Deloitte Access Economics' 2016 report, which similarly tried to show how different aspects of schooling explained variation in PISA maths scores (in 2003 and 2013). This is due to differences in the measurement framework used for identifying and measuring the drivers of school quality. For instance, the 2016 analysis found that the amount of homework received by students, the disciplinary climate in class, and classroom management were the aspects of schooling that drove the greatest variation in PISA test scores. In contrast, teacher morale, teacher behaviour and the quality of material resources were not found to be significant across either the 2003 or 2012 cohorts. The disciplinary climate in class maps directly to classroom environment (class order and cohesion), while questions on the amount of homework received by students is mapped to teaching practice (assessment). These are both found to be relatively important as drivers of school quality. Given the different approach and focus of the previous report, the impact of instructional approaches was not explicitly examined. Further analysis of previous years of data from PISA and TIMSS may provide further insights on the relative importance of these different factors."}, {"section_title": "Relative importance of school quality drivers across outcome measures", "text": "Student academic achievement is not the only measure of student outcomes. It is also possible to disaggregate the relative importance of different school quality drivers on a range of other measures of student outcomes. These outcomes can be both important in and of themselves (such as outcomes for student safety and wellbeing), and also be indirectly linked to student academic achievement. Within the TIMSS dataset, aggregate student outcome variables have been created based on student responses to individual questions. Chart 4.7 below highlights the top four most important themes in explaining variation in each of the student outcomes. Teaching practice is consistently the most important theme across all outcome measures. More than student maths scores, it explains a larger share of variation in student safety and wellbeing, and student sense of school belonging. Teacher attributes are generally not found to be important in determining student outcomes, with the exception of their estimated contribution to student engagement with teaching. Material based resourcing is also found to be important for student engagement with teaching. It is possible that attributes such as experience with teaching allow teachers to explain concepts more clearly, while better resources help to add variety to teaching methods, which would encourage student engagement. Classroom environment is found to be relatively unimportant in explaining student safety and wellbeing, with classroom organisation the more relevant theme. Chart 4.7: Relative importance of quality drivers by student outcome measure (TIMSS, year 8, 2015)"}, {"section_title": "Student maths scores Student engagement with teaching (maths)", "text": ""}, {"section_title": "Student sense of school belonging Student safety and wellbeing", "text": "Source: Deloitte Access Economics analysis of PISA and TIMSS data"}, {"section_title": "Relative importance of school quality drivers across geographies", "text": "The relative importance of the themes in explaining variation in student outcomes also differs between geographies, that is, whether a school is located within a metropolitan area, a provincial area, or remote area. Chart 4.8 shows the relative importance of school quality drivers averaged for PISA and TIMSS (maths, year 8). Teaching practice is the most important driver for all geographies. School leadership and classroom organisation are relatively more important for schools located within metropolitan and provincial areas. In contrast, classroom environment and material based resourcing is relatively more important for schools located in remote areas. School leadership and classroom organisation are potentially more important for metropolitan and regional schools given the student population is more diverse. Consequently, these schools may require a more targeted approach to school leadership and classroom organisation to meet to the needs of the students. In contrast, these factors are relatively less important for non-metropolitan schools as the student population is likely to be more homogenous. Detailed findings for the geographic analysis is given in Appendix C. In summary, across these data sets, teaching practice and the classroom environment are consistently found to be the most important theme driving student outcomes. This result aligns with the literature; however, the magnitude of the importance of teaching practice relative to other factors, such as school leadership and autonomy, is notable. These results demonstrate that, as a driver of student outcomes, teaching practice (such as approaches to teaching and learning) is significantly more important than teacher attributes (such as teacher qualifications). These findings have implications for this report's understanding of the role that the strategic direction of schooling systems play in driving improvements in student outcomes across Australia's education system. This is discussed in the concluding Chapter 5 of this report, and further evidenced with respect to variations in historical system level policies and practices in Appendix D."}, {"section_title": "Metro Regional", "text": "Remote 56 5 Implications for government and future research directions The empirical analysis above builds upon the existing literature to demonstrate where the most significant gains can be made in improving students' outcomes in Australian schools. The analysis-in part-confirms what is already known, that differences in teaching practice, and classroom organisation and environment, explain the most significant amounts of variation between schools and classrooms. This provides confidence and assurance for policymakers in targeting policies towards the most important drivers of school quality, based on a comprehensive, and perhaps most significantly, Australia-specific evidence base. This section draws out the results of the empirical analysis of most importance to policy makers, examines the current policy landscape, and considers how the empirical results of this work can be implemented in policy, before concluding with a summary of the directions for future research building on this work."}, {"section_title": "5.1", "text": "An evidence base on schooling systems, practice and performance in Australia 5.1.1 Results of empirical analysis of drivers of school quality Variations in average 'school quality'-the differences in the practice and management of schools that affect student outcomes-explain around 5% of the total variation in student outcomes in Australia. The contribution made by variations in classroom quality is typically much higher than the contribution made by school quality: as much as 28% of the variation on student outcomes is explained by variations in what happens in the classroom. Digging deeper into the drivers of this variation in school and classroom factors, this analysis finds that variations in teaching practice have the most significant effect on student outcomes (Chart 5.1): \uf0b7 Variations in teaching practice explain 6.1% of the variation in PISA maths scores, and 13.1% of the variation in TIMSS math scores (for year 8 students)."}, {"section_title": "Funding and incentives", "text": "Although state and territory governments ultimately have responsibility for government schools in Australia's federal system, the Australian Government provides a substantial part of funding for schools: on average, close to a fifth of all public funding for schools. The Australian Government has also announced its intention to fund 20% of the Schooling Resource Standard for all government schools by 2027. The Australian Government also offers funding incentives to state and territory governments implementing particular evidence-based reforms, through its Quality Schools, Quality Reforms initiative and through National Partnership Agreements (such as those supporting the implementation of autonomy measures through the Commonwealth Independent Public Schools initiative). These levers allow the Australian Government to encourage evidence-based reforms by state governments and at a school level."}, {"section_title": "Demonstrating a link between initiatives and improvements in practice", "text": "The framework and evidence developed through this study may be used to inform evaluation frameworks to be used by Australian jurisdictions to demonstrate a link between new policies and the drivers of school quality. This may include a framework which requires policy-makers to provide evidence of a link between policies-including those relating to resourcing-and effective school and classroom practice, measured at the level of the classroom."}, {"section_title": "Strategic and long-term focus", "text": "Alongside evaluations of individual programs, governments must make improvements in school quality a strategic priority. In many cases, initiatives are not evaluated against the existing data sets that these tests provide. Some initiatives will take more than a semester to evaluate-indeed, some may take many years to register a measurable impact (for instance, changes to initial teacher education). As a result, any implementation of initiatives-and evaluation of those initiatives-must be sustained to permit a true picture of effectiveness for school quality measures to emerge."}, {"section_title": "Evidence-based interventions", "text": "Government can also play a central role in curating and evaluating the evidence base which schools draw upon when making decisions about their practice and management. This framework emphasises the role of government in monitoring and evaluating the effectiveness of schooling systems, enabling initiatives and practice to inform the system settings and enabling initiatives which guide school practice, while simultaneously holding the system accountable for driving improvements in student outcomes. An emphasis on evidence-based practice underpins all aspects of decision making within the system. Current examples of best practice in collating such an evidence base include the Education Endowment Foundation's Teaching and Learning Toolkits (see Appendix B). Governments may then offer implementations of these initiatives to the schools that need them, or offer incentives which encourage teachers to acquire knowledge in line with the current state of thinking (by enabling teacher professional learning)."}, {"section_title": "Collecting and sharing data evidence", "text": "The Productivity Commission (2016) observed that measuring outcomes in the education system can be done well with large scale datasets and simple data analysis. NAPLAN, PISA and TIMSS are already providing useful data to schools and policy makers on student outcomes. The most significant gap in Australia's education evidence base, according to the Commission, is on the impact or effect of particular initiatives. These questions require \"a bottom-up approach, using small scale research projects and datasets that are often question-specific and apply sophisticated quantitative research methods.\" (Productivity Commission, 2016). Governments have a key role to play in developing this evidence base of practice to supplement the existing datasets relating to outcomes. Notably, while datasets like TIMSS and PISA provide critical evidence on the contribution of teacher and school practice and management to student outcomes, they do not identify student or schools and so cannot be used to monitor the outcomes of particular schools or students-and therefore cannot be linked to specific policies for the purpose of evaluation and monitoring. The development of a similar dataset, that captures a level of detail in practice and performance, but may also be used for the purposes of monitoring and evaluation, would go some way in filling this gap. Indeed, this study has demonstrated the analytical value of such a dataset in terms of the ability for policy makers to examine and measure the key drivers of student outcomes and school quality across the Australian schooling system."}, {"section_title": "5.1.2", "text": "The current state of schooling policy in Australia Commonwealth, state and territory governments establish the broad architecture for the operation of a largely decentralised schooling system. In Australia, the largest part of responsibility for schools is held by state and territory governments. In theory, differences between the policies in each jurisdiction could be linked to differences in outcomes. This could provide an indication that particular system-wide approaches to schooling are contributing to student achievement. To unpack the relationship between system-level differences and variation between jurisdictions, a desktop review of 'grey literature' has identified the most significant schooling system changes in Australia over the past 15-20 years. 29 The detail of this review is contained in Appendix D. The key areas of focus identified by this review were: The results from the research in Appendix D do not reveal any consistent relationships between particular aspects of system policy and overall performance, when analysed at a jurisdictional level. In some respects, this is not surprising, as it reaffirms the observation that it is practice at the school level, rather than distinct system level policies, which have the most direct relationship with student outcomes. It also demonstrates that there is no apparent 'silver-bullet' policy prescription -at the system level-which can be associated with higher (or lower) levels of performance. Rather, it is a range of enabling policies and initiatives which combine to provide the right environment to allow for effective classroom environment and teaching practice to eventuate. This is not to suggest that governments-as makers of system level policy-cannot materially influence school quality and student outcomes in Australia. Indeed, many of these enabling policies and initiatives have clear conceptual links to the drivers of school quality which have been found to be most significant in driving student outcomes. Commonwealth, state and territory governments are highly active in the schooling space. A preliminary review by the Department of Education for this project found more than 300 discrete policy initiatives, across a number of areas, over the past 10-15 years or more. It is difficult to examine the impact of these varied initiatives at a system-wide level. This does not mean that they are not worthwhile investments for Australia's complex and diverse schooling system to be making. From a measurement perspective, there are a number of reasons why this analysis cannot observe the impact of such initiatives on student outcomes: \uf0b7 They may be aimed at intermediate outcomes such as student access, participation and engagement. Although these are necessary preconditions to student success, it would not be expected that such interventions to have an immediate system-wide impact. \uf0b7 They may be aimed at broader school system goals than literacy, numeracy and science. Civics, languages other than English, information technology and arts education all form part of a school-level education in developed nations; however, initiatives in these categories are unlikely to have a direct effect on literacy and numeracy performance."}, {"section_title": "The importance of evaluation", "text": "Ultimately, the sheer number of initiatives being taken by state and territory governments limits the ability of empirical analysis to isolate their impact without direct observations of school and classroom level data. Evaluating the effectiveness of particular school-level interventions, from a system perspective, requires at a minimum an understanding of: The outcomes of students before and after the intervention. This is particularly relevant knowing that teaching practice is the most significant driver of school quality. Although government policy may steer schools in a particular direction, the evidence from this study's analysis of PISA and TIMSS suggests that through the practice of individual teachers that particular policy initiatives lead to changes in outcomes. Governments play an important role in setting a strategic direction for schools and creating the culture in which teachers operate, but ultimately the methods used by teachers in classrooms are determined by those teachers. Nonetheless, the limitations preventing this type of evaluation demonstrate that further evidence and analysis is required to understand the link between:"}, {"section_title": "Possible implications for policy-makers", "text": "The research outlined in Appendix D has identified a significant and diverse range of schooling interventions which have occurred in Australian schools over the past 10-15 years. The findings from this study may be used to support Australian jurisdictions in demonstrating a link between Case study -Framework for Improving Student Outcomes (FISO) In Victoria, the Framework for Improving Student Outcomes (FISO) provides information, resources and support for schools to identify and implement strategies that enable school improvement. In line with the indications of our empirical analysis, it recognises that schools are best placed to understand what works for their school, and aims to balance school-level decision making with a need for evidence, research and best practice backing to any initiatives. The FISO is comprised of four headline priorities: excellence in teaching and learning, professional leadership, a positive climate for learning and community engagement in learning which are based on robust evidence of the drivers of student outcome, in proportion to their relative importance. Among these headline priorities, there are 16 initiatives, most of which focus on the excellence in teaching and learning priority. This case study provides an example of how evidence of the drivers of student outcomes in Australia, within a consistent measurement framework, can be used to guide school's strategic decision making towards the improvement of student outcomes."}, {"section_title": "The FISO Framework", "text": "Source: Victorian  new policies and known drivers of school quality. These findings may also provide the basis for developing a new evidence accountability framework which requires policy-makers to provide evidence of a link between policies-including those relating to resourcing-and effective school and classroom practice, measured at the level of the classroom. This study demonstrates how a system-wide evidence base of practice, policy and performance in Australia may be used to provide a robust evidence base to inform policy. Building on this work, next steps for government may include: Developing a consistent and system-wide evidence base While diversity and complexity in policy design and application need not be a shortcoming, the lack of a consistent and universal basis for evaluating the impact of government policies and programs on student-level outcomes means there exists little capacity to assure Australia is on a path towards overall school improvement. For this task, there are abundant evidence bases about both outcomes and practice from professional bodies, private educational businesses, academics and government. However, it is apparent that a given intervention that has been demonstrated to improve student outcomes in one context will not necessarily produce the same result in other contexts. As a result, all parts of the schooling system (from the National and State governments to schools themselves) must play a role in continual evaluation of school practice and building the broader evidence base. This is in line with the recommendations of the Productivity Commission (2016) in its recent Inquiry Report into the National Education Evidence Base. The suggested approach of the Commission combines 'top-down' transparent assessment and collection of outcomes data with 'bottom-up' evaluation of programs. Combined, the availability of data on both student outcomes and practice will help to facilitate conversations between levels of government and schools on how to drive student outcomes."}, {"section_title": "Maintaining long-term strategic goals", "text": "In particular, the maintenance of a clear strategic policy direction is critical in ensuring that the development of new policies and initiatives are consistently and clearly oriented towards the drivers of practice which matter for schools. This report reinforces the most crucial areas of school practice that have the most potential to influence student outcomes. A strategic policy direction built on this evidence would be expected to direct the focus of all areas of policy to both proven effective initiatives, and to continual evaluation of policies, that relate to these drivers."}, {"section_title": "Establishing accountable and transparent schooling systems", "text": "In order to evaluate the impact of initiatives and policies enacted across Australia's schools, governments must take responsibility for establishing accountable and transparent schooling systems. Collecting outcomes data in a granular but broad manner, and sharing it nationally, will help to facilitate analysis and discussion about the impact of initiatives."}, {"section_title": "Continuous evaluation and refinement", "text": "Beyond just collecting data on outcomes, it is crucial for data to be used at all levels of the schooling system to critically reflect on, and refine, the practices used in schools. The OECD, in its Review on Evaluation and Assessment Frameworks for Improving School Outcomes, observed that evaluation is needed at student, teacher, school and system levels, but noted universal challenges to the implementation of effective evaluation systems in schools. In particular, the goals of each form of evaluation need to be aligned, to ensure teachers and schools are pursuing system-level goals in a strategic and focused manner. In this area, Australian schools still have some progress to be made -for example, a review of teacher effectiveness evaluation frameworks found that there was still room to develop a nationally consistent approach (University of Melbourne Graduate School of Education, 2017). Below, a case study of schooling system reform in Ontario, Canada, which implemented a systemwide approach to improving student outcomes is detailed. The continued use of this new methodology, coupled with expanded evidence of practice and policy across Australian schools, enhances the depth and scope of evidence and insights available to the Department, and provide the basis for developing a framework for developing consistent national evidence that links policy, practice and performance-allowing for greater transparency and accountability in the policy interventions that are taking place across schools and jurisdictions. The findings from this study may be used to support Australian jurisdictions in demonstrating a link between new policies and known drivers of school quality. These findings also provide the basis for developing a new evidence accountability framework which requires policy-makers to provide evidence of a link between policies-including those relating to resourcing-and effective school and classroom practice, measured at the level of the classroom."}, {"section_title": "5.3", "text": "Conclusions and future research directions The empirical methodology developed through this study, and the underpinning measurement framework, is intended to provide the Department with a detailed and impactful evidence base to inform future directions for government. In particular, it has answered the key research questions established for this study by providing: Case study of system reform -Canada, Ontario In the early 2000s the school education system in Ontario, Canada was shown to perform poorly on a range of national indicators. A new provincial government elected in 2003 prioritised education transformation and change. The reform framework was characterised by a deliberately contained and limited suite of key objectives and a coherent structure of concerted support-focus, build relationships, persist, develop capacity, and spread quality implementation. The system explicitly committed to raising performance outcomes for all students and closing achievement gaps between all groups. Two major initiatives were accordingly pursued by the Ontario Ministry of Education over the reform time period: 1. The Literacy and Numeracy initiative aimed to increase reading and mathematics outcomes in elementary schools. Described as a capacity-building strategy, the initiative succeeded in raising the average pass rate in provincial exams from approximately 55% 2003to approximately 70% (2010) in reading, mathematics and writing in grade 3. Similar gains of about 10-12 percentage points were apparent in the same subjects in grade six. 2. The Student Success initiative aimed to increase the high school graduation rate to 85%. By identifying students at risk early, funding a \"student success officer\" in each school, and creating programmes of \"credit recovery\" through which students could make up the parts of courses that they failed, the graduation rate increased from 68% to 79% over several years. Key success factors identified for enabling the Ontario system to achieve progress on key indicators included the consistent application of centrally-driven pressure for higher results, combined with extensive capacity building and a climate of relative trust and mutual respect."}, {"section_title": "Strategic measures associated with the success of this initiative included:", "text": "\uf0b7 Strategies directly focused on improving teaching practice."}, {"section_title": "Limitations of value-add as a longitudinal performance measure", "text": "Value-add is only one way of thinking about school outcomes and performance. This measure has the benefit of controlling for various school-and student-level contextual factors (namely, those outlined in section 4.1 above). However, it also has limitations as a measure of performance over time. In particular, neither TIMSS nor PISA use the same sample of students in each test -they test a different cohort of students in the same year levels (for TIMSS) or age (in PISA) from different schools. Accordingly, results are highly sensitive to the approach taken to sampling. As a result, value-add provides no more than an indication of the average levels and trends in performance between jurisdictions. It should be examined in the context of outcome measures from other sources. In the following section, significant differences between these jurisdictions' schooling systems and over time are outlined, which may contribute to these trends. The aspects of difference are included in this analysis are selected based on a process of identification and prioritisation, as set out in section 3.4.2 of the methodology chapter of this report."}, {"section_title": "D.2. Identification of key system settings", "text": "Deloitte Access Economics has identified several historical differences between schooling systems, supported by preliminary research from the Department in line with the methodology set out in section 3.4.2 of this report. Permanent and timing differences have been prioritised by the: To aid in the understanding of the different forms which government initiatives may take, Figure  D.1 below provides a framework through which governments affect school practice and, ultimately, student outcomes. In this framework: \uf0b7 Governments have direct power over system settings -the framework in which schools operate, the goals which they pursue, and the processes for demonstrating that schools are achieving those goals."}, {"section_title": "Historical analysis of system settings", "text": "The following section is primarily an exploratory exercise. Having identified an evidence base for particular practices in the earlier literature review, the section maps the historical differences between jurisdictions. This is done with the aim of providing some understanding of why variation exists in outcomes across jurisdictions. It does not aim to provide conclusive evidence that certain practices are or are not effective in the Australian context -such conclusions could only be drawn from controlled trials or other evaluations. The policies and initiatives discussed are not necessarily current or best practice. Rather, they serve as illustrations of historic practice. Changes at a system level may take several years to have an impact on student outcomes. Accordingly, this research has been driven by past reforms. In some cases where this historical mapping exercise does not reflect current practice, recent reforms are noted. "}, {"section_title": "117", "text": ""}, {"section_title": "D.3. System settings", "text": ""}, {"section_title": "Curriculum", "text": "Curriculum-the content of the education which teachers deliver in schools-forms a fundamental part of the schooling system. Accordingly, it can have an impact on student outcomes across a number of domains (see Figure D.2). In particular, of the domains identified in this study's framework of themes of school quality outlined in section 2.2 above, curriculum can influence aspects of:  In 2008, the Australian Government established the Australian Curriculum, Assessment and Reporting Authority (ACARA) which began the task of creating a national curriculum for Australian schools in English, mathematics, science and history for students between Foundation and Year 10. The Review of the Australian Curriculum (Australian Government, 2014) noted that this push in Australia came alongside a trend of curriculum review in many parts of the world. The Review noted observations of the OECD that the highest-performing curricula: These are all objects of the Australian Curriculum to varying degrees-in particular, the curriculum has a focus on the development of general skills and abilities, rather than focusing only on discipline-based skills. The first four learning areas of the Australian Curriculum-English, Mathematics, Science and History-were endorsed in December 2011 for students between Foundation and Year 10. However, the Curriculum was not implemented at once, but rather at different points in time between: \uf0b7 Learning areas; \uf0b7 States and Territories; \uf0b7 School year levels; and \uf0b7 School sectors. Because of implementation across all Australian schools, and the ability to track the sequence of implementation over time, it is possible to concord the implementation of the Australian curriculum against performance on PISA and TIMSS. If the Australian Curriculum has had a positive effect in developing the capacity of students to tackle the types of problems in the two tests, it would be expected that this difference only appear in states which had implemented the Australian Curriculum before the test dates observed in the PISA and TIMSS datasets. Using published implementation dates from ACARA and state and territory education departments, it is possible to identify the point in time at which the Australian Curriculum had been implemented in each of its core learning areas. Evidence from the literature review also suggests that the effect of improved curriculum is cumulative-that is, that the gain from improved curriculums increases through several years of schoolings. If the Australian Curriculum has had an impact on student outcomes, a more significant improvement-or smaller decline-would be expected in states where it was implemented than those where it was not. Noting the trends in PISA results discussed in Section 4.3.1 above, there is no clear sign that jurisdictions that implemented the Curriculum earlier performed better in PISA. The ACT, Tasmania, and Queensland were among the earliest jurisdictions to implement the curriculum across a number of domains, yet all declined in the value-added measure (by varying degrees) between 2012 and 2015 after controlling for contextual factors. This is not to say that implementing the Australian Curriculum has not had a beneficial effect on student outcomes in Australia. There are a number of caveats that prevent drawing strong conclusions from any comparisons of states based on implementation dates:"}, {"section_title": "Western Australia -Online Literacy and Numeracy Assessment", "text": "From 2014, the Western Australian government introduced a minimum literacy and numeracy standard. Students must demonstrate a level of reading, writing and numeracy needed to \"meet the demands of everyday life\" (Western Australian Government, 2013). Students may demonstrate this standard in one of two ways: \uf0b7 Students who achieve Band 8 or higher in the reading, writing or numeracy component of their Year 9 NAPLAN test do not need to complete the corresponding section of the OLNA."}, {"section_title": "Industrial arrangements", "text": "Industrial arrangements for teachers -their pay and conditions -comprise one of the most significant parts of resourcing provided by schooling systems to schools (in dollar terms). Teachers-as a human resource-can be distinguished from material and curriculum resources in the measurement framework developed in this study. The direct impact of industrial arrangements is on teacher attributes, rather than teaching practice. The pay, conditions and status of teachers relative to other professions have potential to \"crowd out\" good graduates from the teaching profession (Ingvarson and Rowe, 2007); more competitive salaries help to attract higher-performing high school graduates to the teaching profession. Indeed, for teachers, while their salary on graduation might be competitive with their peers in other professions, salaries in other industries often grow more rapidly with experience (Chevalier and McIntosh, 2001). However, this view also presupposes that teachers' capacity is, to some degree, fixed by their performance in high school, and that salaries dominate among the many and varied incentives for individuals to pursue teaching careers. It is difficult to draw firm conclusions from the literature relating to the impact of teacher industrial arrangements on classroom quality. Nonetheless, industrial arrangements have potential to shape a number of incentives for potential and serving teachers (see Figure D.8 below). 125 Australia has an older teaching service: the typical Australian teacher has taught for 17 years (OECD, 2013). Changing the incentives for individuals to start a career in teaching will not change the inherent attributes nor the practices of the majority of teachers. Accordingly, opportunities for professional development throughout teachers' careers offer a greater potential reach to improve teacher and school quality. Australia, in general, has limited differences between graduate teachers' salaries and experienced teachers' salaries. The OECD (2016) reported that the top salary for lower secondary teachers was 44% percent higher than their starting salary, while across the OECD on average, the difference was 70%. Australian teachers also reach the top of their career progression more quickly relative to teachers in other countries -in just 8 years, compared to an OECD average of 25. This, arguably, discourages teachers from staying in the profession once they have reached their salary peak. As Ingvarson, Kleinhenz and Wilkinson (2007) put it: \"\u2026the implicit message in the salary scale is that teachers are not expected to improve their performance after nine years.\" This also gives high-quality teachers a financial incentive to pursue management or principal positions within schools, taking them out of classrooms. In general, Australian teachers' salaries grow incrementally with each year of service. Each jurisdiction uses a different progression scale with its own salaries and steps. In addition, several jurisdictions offer an additional pay grade for teachers who have demonstrated higher levels of competency. This has historically been assessed against state based criteria. More recently, the Highly Accomplished and Lead Teacher (HALT) levels of the Australian Professional Standards for Teachers (Teacher Standards) have aimed to provide a uniform standard for this assessment. HALT certification is a national initiative, implemented from 2013, which recognises skilled teachers and promotes the development of collaborative professionals who continually reflect upon and improve their practice in the classroom. There are currently 353 teachers (at December 2016) certified teachers across Australia in participating jurisdictions, from the government, independent and Catholic sectors in ACT, NT, SA, NSW and the independent sector in WA. Queensland is currently conducting a certification pilot project in 2017, with full implementation expected by 2019. Tasmania, Victoria and the government sector of WA do not currently participate in certification. As noted above, Australia has a well-established workforce of teachers with an average of 16 years' experience. The impact of recent changes, like the HALT certification initiative, will take some time to appear; it may be many years before changes lead to changes at a classroom level. Salaries and industrial arrangements more broadly for teachers have varied very little between jurisdictions historically. In any case, a top-down analysis of the entire school systems of states may not recognise the benefits of rewarding high-quality teachers. As Ingvarson, Kleinhenz and Wilkinson (2007) note: While the impact that these teachers have on their students is likely to be significant, the impact that these schemes have in a wider sense across schools and school systems is probably small as the numbers of teachers in these positions is quite small. There is insufficient evidence to draw a clear link from PISA and TIMSS performance of each jurisdiction's cohort to the incentives in industrial arrangements. As noted by Ingvarson, Kleinhenz and Wilkinson (2007), there has historically been relatively little variation between jurisdictions. Some recent changes to industrial agreements for teachers may change this: NSW is to have just 6 steps in its newest teacher agreement, with the earliest steps taking 2 years to complete (NSW Government, 2017); Victoria's pay scale has grown to 15 steps (Australian Education Union, 2017). It is also noteworthy that there is little difference in outcomes between government and nongovernment schools once contextual factors have been controlled for (see section 4.1 above). Independent and Catholic schools have their own industrial arrangements with teachers outside of the enterprise bargaining agreements established by state and territory education departments. Taken together, this policy analysis suggests that differences in industrial arrangements do not significantly drive school quality. Nonetheless, it is important to ensure that teachers are given incentives to continually develop throughout their careers. Effective incentives can drive improvements in school quality through levers that PISA and TIMSS indicate are more important but are harder to assess at a system level, such as teaching practice."}, {"section_title": "Teacher education course accreditation and teachers standards", "text": "Another important role that government plays in determining the efficacy of the teaching workforce is in setting standards for teachers. There are two key standards of interest in the Australian context: \uf0b7 Pre-service teacher course accreditation ensures that teachers enter the workforce with the necessary skills and attributes. The process aims to make universities accountable for the courses that they provide, recognising the important social role played by teachers."}, {"section_title": "Enabling initiatives", "text": "Governments only directly determine the framework in which schools operate -the \"system settings\" described above. Ultimately, the practices of schools in classrooms are determined by teachers and leaders in those schools. Governments, however, have several tools which can be used to change that classroom practice: \uf0b7 They can offer professional learning to schools; \uf0b7 They can seek schools to participate in system-administered subject-specific initiatives; \uf0b7 They can offer incentives for particular changes in practice at a school level. These initiatives must necessarily be implemented by schools, rather than a system level-they rely on schools determining their relative areas of need and seeking interventions to implement. Teacher professional learning Professional development-that is, \"deliberate processes designed for the purposes of teacher post-initial professionally related education and training\" (McRae et al., 2001)-provides a crucial link between the ever-expanding evidence base for effective interventions, and teacher implementation of those interventions. Recognising its overall importance, each state and territory government offers professional learning on an ongoing basis. Schools, in general, have capacity to select from a variety of professional learning opportunities from both public and private providers (McRae et al., 2001). Teacher professional learning is deemed to be high quality when it includes opportunities for active learning and interaction with colleagues, is for an extended time period and comprises collective learning activities (e.g. communities of practice) or research with other teachers (OECD, 2017; B. Jensen, 2014 and F. Barrera-Pedemonte, 2016). Professional learning is most effective when it is relevant, collaborative and future focused, and when it supports teachers to reflect on, question and consciously improve their practice (AITSL, 2012). Attendance at short-term conferences and seminars, workshops, discussions, lectures and field trips to other schools, are reported to have less impact on professional learning (AITSL, 2012). Jurisdictions vary in their professional development programs in: The degree of autonomy in program selection at school level (McRae et al., 2001). However, the literature notes that \"evidence of the links between teacher professional development and student learning outcomes is hard to pin down\" (Meiers and Ingvarson, 2005). The content of professional development programs significantly vary. Many may focus on areas outside of those measured by the outcomes recorded in PISA and TIMSS. Accordingly, its benefits may not be readily apparent in system-level data like that used in this analysis. Further detail on the role of government and schools in evaluating teacher professional learning is elaborated in Section 5."}, {"section_title": "Pedagogy initiatives", "text": "Each jurisdiction, at different times, has implemented initiatives aiming to develop teachers' approaches to particular areas of curriculum. In some cases, these initiatives are part of broader strategies which cut across several domains of school improvement: for instance, they may combine pedagogical changes with new accountability measures or increased resourcing. Background research conducted by the Department and Deloitte Access Economics has identified a number of such initiatives. Some case studies are included below. They are not intended to reflect current or best practice, but rather, to demonstrate the role governments and schools have historically played in such initiatives."}, {"section_title": "Western Australia -Getting it Right -Literacy and Numeracy Strategy", "text": "The Getting it Right -Literacy and Numeracy Strategy began in 2002 in Western Australia. It aimed to develop the expertise of teachers in order to improve outcomes and opportunities for children with literacy and numeracy difficulties. The Western Australian Department of Education placed Specialist Teachers in schools to focus on either literacy or numeracy. These teachers mentored and supported their colleagues and modelled effective teaching strategies. Principals of participating schools also set targets for measurable improvements in literacy and numeracy outcomes. Meiers et al (2008) evaluated the impact of the program, using a combination of survey results and observations of classrooms and teachers. Teachers incorporated strategies from Specialist Teachers, and as a result, reported better belief in their self-efficacy and improved processes for identifying and teaching students at risk. Importantly, many teachers reported that they more explicitly identified goals and considered whether they had achieved them."}, {"section_title": "Tasmania -Raising the Bar", "text": "Raising the Bar, Closing the Gap, as it was originally known, began in 2008. Its aim is to increase the number of students completing primary school with functional literacy skills. It began in 36 regional primary schools, involving approximately 150 teachers and 2000 students from years 1 to 6 identified as being at or below the national minimum standard for literacy. The program provided participating schools with an additional assistant principal, releasing the principal to lead literacy and numeracy improvements within their schools. Participating schools also worked with a full-time literacy leader to facilitate discussions about improving literacy levels. Hay et al (2011) evaluated the performance of the program using a combination of principal surveys and performance data from schools. They observed improvements in average scores across a number of standardised literacy tests. Principals also reported greater reliance on evidence for literacy planning. Noting the positive results from evaluations of these programs, it is still difficult to identify their impacts at a system-wide level using PISA or TIMSS results: \uf0b7 Participating schools run these programs in tandem with other State and Commonwealth programs. \uf0b7 The programs are often run at select schools, particularly those below minimum literacy and numeracy standards. For instance, 365 schools, or around 50% of Western Australian government schools, participated in the Getting it Right program in the years studied by Meiers et al (2008). \uf0b7 The programs often focus on a cohort of students within schools. For instance, although it aimed to improve literacy and numeracy achievement across all groups of students, Getting it Right focused on \"Aboriginal students, students with a language background other than English (LBOTE), boys and students in rural and remote locations\" -students who were more likely to face lower literacy and numeracy scores. Each participating school had one Specialist Teacher, who could be placed at the principal's discretion. Accordingly, a program may only have a real impact on student outcomes for a select group of students who were not participating in PISA or TIMSS. Nonetheless, these types of targeted initiatives serve as a useful tool for improving student outcomes: \uf0b7 They bring together a number of drivers of school quality -like improved accountability and teacher professional learning as a uniform intervention. \uf0b7 They help to develop an improvement-focused culture at a school level. In particular, as part of a school-wide intervention, teachers are keen to demonstrate positive outcomes."}, {"section_title": "School leadership and management", "text": "School leaders can improve teaching and learning indirectly, through their influence on staff motivation, commitment and working conditions. Although many forms of school leadership are important in improving educational outcomes, those intended to influence pedagogy and which can be enacted by teacher leaders rather than principals are evidenced to be the most effective (Marks and Printy, 2003). By cultivating a results-focused culture, and seeking evidence-based strategies to pursue systemwide goals, principals and senior teachers can provide school-level incentives to change classroom practice. Below, two case studies of leadership development initiatives in Western Australia and Victoria are outlined. Western Australia -principal preparation programs Anderson et al (2007) note that the career path of an Australian school principal follows an 'apprenticeship' model. All principals begin as teachers, gradually gain experience in leadership roles, and become principals over time. Although many aspiring principals pursue higher qualifications, they are not a requirement in Australian government school systems. In Western Australia, a need was identified for further support for incoming principals. As a result, the Western Australian Department of Education's Leadership Centre established a number of training programs for aspiring principals. For teachers and classroom leaders aspiring to principal roles, an online program Explore: A Career in School Leadership is available online. It is structured around the Australian Professional Standard for Principals, evaluating participants on their ability to incorporate those standards into their practice and develop a strong leadership vision and school culture. In order to become formally eligible to apply for principal roles, candidates must complete a series of Principal Eligibility Modules. Taught by a school leader, the course helps participants to develop the necessary knowledge and skills in: "}, {"section_title": "Bastow Institute", "text": "The Bastow Institute of Educational Leadership, established in 2009, aims to \"build the capacity of educational leaders and to identify and develop high quality leaders for the future.\" Unlike professional learning institutes in other jurisdictions, it is specifically aimed at leadership training."}, {"section_title": "Its offerings include:", "text": "\uf0b7 A series of career stage programs for emerging leaders, middle leaders, aspiring and new principals, which provide structured professional learning that complement school practice; \uf0b7 Courses on extending the capability of all education and early childhood education; \uf0b7 Professional practice workshops of one to three days in length; and \uf0b7 A number of thought leadership initiatives which focus in more depth on issues and trends in current learning theories. These all provide school leaders with the opportunity to see exemplary practice modelled in action, and apply high-quality evidence-based practice in their own context. Thee professional learning programs at Bastow emphasise the role of school leaders in creating a school-wide focus on high performance, which acts at all levels to change classroom practice."}, {"section_title": "132", "text": "Limitation of our work"}, {"section_title": "General use restriction", "text": "This report is prepared solely for the use of the Department of Education and Training. This report is not intended to and should not be used or relied upon by anyone else and we accept no duty of care to any other person or entity. The report has been prepared for the purpose of undertaking original empirical analysis and qualitative research into the drivers of school quality in Australia. You should not refer to or use our name or the advice for any other purpose."}]