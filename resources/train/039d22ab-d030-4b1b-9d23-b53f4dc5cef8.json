[{"section_title": "", "text": "The neuroimaging community is at a crossroads. Long characterized by individualism, the data and computational and analytic needs of the connectome-wide association era necessitate cultural reform. Emerging initiatives have demonstrated the feasibility and utility of adopting an open neuroscience model to accelerate the pace and success of scientific discovery.\nHuman neuroimaging has entered the connectome-wide association (CWA) era. As with genome-wide association studies (GWAS), the objective is clear: to attribute phenotypic variation among individuals to differences in the macro-and microarchitecture of the human connectome (Bilder et al., 2009; Cichon et al., 2009; Van Dijk et al., 2010) . Similar to the genome, the complexities of the connectome have compelled the community to expand its analytic repertoire beyond hypothesis-driven approaches and to embrace discovery science (e.g., exploratory data analysis). The discovery paradigm provides a vehicle for generating novel and unexpected hypotheses that can then be rigorously tested. The acquisition and aggregation of large-scale, uniformly phenotyped data sets are essential to provide the necessary statistical power for effective discovery. In addition to the challenges of amassing such data sets, the neuroscience community must develop the necessary computational infrastructure and inference techniques (Akil et al., 2011) .\nIt is my tenet that adoption of an open neuroscience model can overcome many barriers to success. This NeuroView will look at the neuroimaging community through the lens of discovery science, identifying practices that currently hinder progress, as well as open neuroscience initiatives that are rapidly advancing the field. I will focus on functional neuroimaging, because resting-state functional MRI (R-fMRI) approaches have proven to be highly amenable to discovery science. However, the majority of issues raised will apply to all scales (macro to micro) and modalities (e.g., diffusion imaging) used to characterize the human connectome.\nThe Data-Sharing Dilemma Van Horn and Gazzaniga first called for unrestricted public sharing of functional imaging data in 2002 (Van Horn and Gazzaniga, 2002) . They created the fMRI Data Center (fMRIDC) and asserted that data sharing would lead to the generation of new hypotheses and testing of novel methods. However, the dominant approach at the time was task-based imaging (T-fMRI), which has struggled with marked variability in approaches and findings across laboratories, even when studying the same cognitive construct. Such variability is problematic for data aggregation. The community failed to embrace their enthusiasm, limiting the practical success of the visionary fMRIDC effort.\nThe 1000 Functional Connectomes Project (FCP) reinvigorated the ethos of data sharing and discovery science among imagers (Biswal et al., 2010) . In large part, the success of the FCP can be attributed to its focus on R-fMRI. Despite initial concerns, R-fMRI has emerged as a powerful imaging modality due to high reproducibility of findings across laboratories and impressive testretest reliability. In December 2009, the FCP (http://fcon_1000.projects.nitrc.org) publicly released over 1,300 data sets independently collected at 33 imaging sites worldwide-a sample size several orders of magnitude greater than nearly any laboratory could hope to obtain alone. Investigators from over 2,000 sites in 86 countries have downloaded FCP data sets (per Google Analytics). The initial FCP publication demonstrated the feasibility of data pooling and discovery science for R-fMRI. However, barriers to open sharing remain. Here, I enumerate existing obstacles and then review the progress of data-sharing efforts that aim to overcome them.\nCountless data sets comprising both phenotypic and neuroimaging data remain stored in laboratory archives long after publication and are often lost to the scientific community forever. Such a loss commonly reflects a lack of appreciation of the potential value of one's data to others beyond the primary study focus. Additionally, such a loss can arise from concerns about losing a competitive advantage. Regardless of motive, the end result is a missed opportunity to advance our understanding of brainbehavior relationships and the methodologies required to successfully characterize them.\nWhen data sharing does occur, it is commonly after a cycle of data collection, data analysis, and subsequent publication. This cycle can last 3-6 years, resulting in substantial opportunity costs relative to promptly shared data, as well as unnecessary duplication of effort among groups with similar interests. Understandably, researchers are reluctant to release data that they themselves have had insufficient time to analyze or explore, let alone publish-again primarily a reflection of fears about loss of competitive advantages. Yet, as the molecular genetics community has demonstrated, open, prospective data sharing is a powerful means to advance a field rapidly. This is especially true when the broader scientific community can be brought into the process through the provision of free and unrestricted access to full data sets.\nImportantly, the potential to create large-scale aggregate data sets across independent imaging sites will not be realized by the adoption of an open-sharing philosophy alone. The success of such aggregate data sets is dependent on the collection of common phenotypic information across imaging sites. Unfortunately, no commonly accepted standards for collecting phenotypic information exist (Bilder et al., 2009) . A wide variety of instruments exists, often with numerous versions and revisions, to measure seemingly simple traits (e.g., handedness) or complex phenomena (e.g., psychiatric symptomatology). Further, few instruments are designed for crosscultural use, limiting the feasibility of global aggregation.\nAnother challenge is that researchers pay limited attention to variations in R-fMRI data acquisition, and the specifics of the scan sessions are rarely documented. Systematic variation can be introduced by acquiring R-fMRI data after an effortful task (Barnes et al., 2009 ). Similarly, fatigue related to duration of time in the scanner can also impact R-fMRI measures (i.e., if a scan is collected early versus late in a session) (Yan et al., 2009) . Additional sources of variation that are inconsistently taken into account include the specific instructions provided to subjects (e.g., ''relax'' versus ''try not to think'' versus ''keep your head still'') and eyes open/closed status (Yan et al., 2009) . FCP feasibility analyses suggested that these sources of variation do not preclude the possibility of successful data aggregation. However, greater attention to these details will minimize the unexplained noise that degrades the statistical power inherent in large-scale data aggregation.\nFinally, beyond the coordination of data acquisition and distribution approaches, a key question that remains is whether to share only data that pass certain quality criteria or to share all data, thereby placing responsibility for quality control in the hands of users. A complicating reality is the lack of consensus regarding data quality standards to guide the detection of outliers. Even if standards for data quality were established (Friedman and Glover, 2006) , data rejected based on current standards may become useful in the future as correction algorithms emerge that are capable of ''rescuing'' some of the previously rejected data. , the NIH recently charged the Human Connectome Project (HCP) with the generation and open sharing of a large-scale coordinated data set with state-of-theart multimodal imaging and genetics using a twin design (n = 1,200; 300 families) (Marcus et al., 2011) . The effort promises to deliver carefully collected, high-quality data sets, which will fuel years of analytic efforts. Additionally, the HCP is working to innovate data acquisition procedures (e.g., fast repetition time acquisitions) and to address the limitations of current data formats. Although this effort will be transformative, advances in imaging cannot depend solely on the acquisition and release of a single sample."}, {"section_title": "Open", "text": "Extensively coordinated efforts, such as ADNI, BIRN, and HCP, are designed to maximally reduce noise arising from between-site differences in imaging protocols or sampling strategies. However, the costs of such efforts (e.g., $69 million for ADNI or $40 million for the HCP) limit how many extensively coordinated efforts can be conducted. As an alternative, investigator-initiated sharing efforts provide an economical option for accelerating discovery science. In that regard, the International Neuroimaging Datasharing Initiative (INDI), a next-generation FCP endeavor, was founded in an attempt to (1) expand the scope of open data sharing in the functional neuroimaging community to include phenotypic data beyond age and sex (a limitation of the FCP data set) and (2) provide a model for prospective, prepublication data sharing. INDI has already demonstrated the feasibility of achieving these goals. In particular, the Nathan Kline InstituteRockland Sample (NKI-RS) successfully and prospectively distributed over 200 deeply phenotyped R-fMRI and diffusion tensor imaging data sets sampling the life span via weekly uploads. With recently granted National Institute of Mental Health funding, the NKI-RS effort will phenotype and image 1,000 individuals over the next 4 years-once again with weekly prepublication sharing, including R-fMRI and diffusion imaging data acquired via novel sequences (Feinberg et al., 2010) provided by the HCP. Numerous other prospective data sets have been pledged or provided, with varying distribution schedules (e.g., quarterly). INDI also actively gathers and shares retrospective data sets. The Brain Genomics Superstruct Project, launched in 2008 at Harvard University and Massachusetts General Hospital, will share 1,500 data sets in 2012 (Yeo et al., 2011) . The ADHD-200 was launched in March 2011, sharing data sets from 485 typically developing children and 291 children with Attention Deficit Hyperactivity Disorder aggregated from eight independent imaging sites. This was a landmark event for child psychiatry, for which data collection can be exceedingly costly and technically challenging. INDI offers a drastically less expensive means of accelerating science by providing large boluses of data upon which future efforts can be based.\nThe FCP and INDI efforts are not unique in embracing open data sharing. The first, fMRIDC, successfully accumulated thousands of images and inspired researchers worldwide. Similarly, Brainscape, OASIS (http://www.oasis-brains. org) and XNAT Central (http://central.xnat. org) were established to encourage investigators to deposit data sets for open sharing. Additionally, the XNAT-based efforts aim to enable easy data accessioning and databasing: highly desirable goals that are increasingly being realized (Marcus et al., 2007) . The mantle of T-fMRI data sharing is now being taken up again by Open fMRI (http://www.openfmri.org), which also provides analytic tools (Poldrack, 2011) . Additionally, http:// openconnectome.org has launched a data-sharing initiative for electron microscopy data that provides information about microlevel connectome properties. Finally, the NIH recently demonstrated its commitment to open neuroscience by mandating that certain NIH-funded autism research be entered into the National Database for Autism Research for eventual sharing.\nBeyond unlocking data archives, numerous initiatives are attempting to advance phenotypic harmonization. The NIH Toolbox, a suite of assessment tools, will be the phenotyping engine for largescale data-collection efforts such as the HCP. The National Institute of Neurological Disorders and Stroke has developed the Common Data Elements (http://www. commondataelements.ninds.nih.gov), consisting of a streamlined set of phenotypic acquisition tools for characterizing clinical populations in neurology. PhenX (http:// www.phenxtoolkit.org) has emerged as a comprehensive acquisition package for phenotypic and exposure information. Finally, INDI plans to promote the global usage of the Achenbach System of Empirically Based Assessments (ASEBA; http:// www.aseba.org), which provides standardized dimensional measures of psychiatric symptomatology. The ASEBA consists of easily administered self-report and informant questionnaires, normed between ages 1.5 and 90+ years and available in more than 85 languages. Potential Barriers to Progress beyond Data Sharing As discussed, the establishment of an open-access, data-sharing community would represent an important step forward for the CWA era. However, it is not the only cultural change required. Below I discuss neuroimaging community practices that can continue to retard progress.\n1 2. In-House Software. Although numerous fMRI analysis packages are available, their interfaces and workflows tend to be geared toward regional analysis rather than connectivity. In response, R-fMRI researchers frequently rely on inhouse software that either specifically conducts connectivity analyses or interfaces with common analytic packages to accomplish the goal. Rarely is this software available to others, often due to concerns about insufficient documentation or the challenges of supporting it. The resulting unnecessary duplication of efforts hampers the development of common, user-friendly software. Moreover, the lack of open access to in-house software and typically sparse descriptions of implementation details limits fair evaluations for accuracy. The open sharing and/or publication of code and scripts supporting data analysis can rapidly alleviate these challenges.\n3. Big Data, Small Databases. As thoroughly outlined by Akil et al. (2011) , the creation of large-scale data sets will challenge the vast majority of in-house databasing infrastructures, as well as current implementations of freeware databases (e.g., XNAT, Human Imaging Database). Greater investment in the development and/or maturation of userfriendly, high-capacity databases is required for the CWA era.\n4. The Jack-of-All-Trades Phenomenon. The modern-day neuroscientist feels increasingly pressured to be proficient in a growing array of scientific domains (e.g., cognitive neuroscience, clinical neuroscience, computer science, statistics, and biophysics). Unfortunately, existing centralized educational resources cannot cover the broad gamut of interdisciplinary domains with which a researcher must be familiar. Although interdisciplinary training and fluency in multiple domains is essential, mastery of all is unlikely. Success in the CWA era will require the involvement of the broader scientific community and greater focus on active interdisciplinary collaboration. Open science initiatives serve to both inspire and facilitate collaborative research efforts within and across scientific disciplines.\n5. Analytic Inertia. To date, imaging analysis has predominantly relied upon univariate statistical approaches. Unfortunately, such analytic frameworks fail to consider the complexities of the connectome. Similarly, conventional statistical models are poorly equipped for high-dimensional data sets. Novel analytic approaches to characterizing and exploring the connectome, as well as linking its properties to phenotypic variation, are needed. Recent applications of multivariate pattern analytic techniques based in graph theory and statistical or machine learning have highlighted the potential value of more complex analytic approaches (Bullmore and Bassett, 2011; Craddock et al., 2009; Dosenbach et al., 2010; Poldrack, 2011) . Once again, the expertise and input of the broader scientific community will be needed to ensure appropriate implementation.\nOpen Neuroscience Computational and Analytic Resource-Sharing Initiatives Every significant innovation entails a new set of challenges and opens new avenues of research-often larger in scale. Although neuroimaging researchers could once work in silos, with only a limited set of developers supporting the community (e.g. pipeline development using nonproprietary platforms (e.g., NiPype, Niak), or (4) provide novel analytic platforms for the connectome (e.g., The Brain Connectivity Toolbox, Connectome Toolkit, Connectir). These efforts represent the building blocks of a new culture of competitive collaboration.\nAn example of this developing culture comes from the recent Global ADHD-200 Competition. The path of the data from origin to the winning entry was as follows: data were (1) contributed to INDI by the ADHD-200 Consortium (eight independent imaging sites spanning three continents), (2) organized by the INDI team, (3) distributed via the INDI website based on NITRC-an open community resource, (4) downloaded from INDI and preprocessed by the Neuro Bureau, (5) distributed via NITRC in preprocessed form by the NB, and (6) downloaded in processed and unprocessed form by competitors around the world. The winning team (specializing in biostatistics) elected to use NB processed data, as did many others. This is an excellent model of open neuroscience: the community worked collaboratively, building off of each other's accomplishments, whether in a coordinated fashion or not."}, {"section_title": "Conclusion", "text": "The promise of the CWA era is as great as the infrastructural and analytic challenges posed. Ongoing initiatives demonstrate the feasibility and desire for the community to adopt an open neuroscience model to meet this challenge. The support of scientific leaders and funding institutions has and will continue to be paramount in this transformation. Neuroimaging in Python (NIPYPE; http://nipy.sourceforge.net/nipype) is an open-source, community-developed software initiative dedicated to analytic workflow development in Python. Provides a uniform interface to existing imaging analysis software, allowing distinct packages to interact within a single workflow.\nThe Neuroimaging Tools and Resources Clearinghouse (NITRC; http://www.nitrc.org) is a web-based clearinghouse for openly shared analytical tools and resources-both popular and in-house software. Provides support forums, workflow, and traffic monitoring free of charge. Also provides support for data repositories such as the 1000 Functional Connectomes Project and the International Neuroimaging Data-sharing Initiative.\nNeuroscience Information Framework (NIF; http://www.neuinfo.org) is a data-sharing initiative that allows researchers to discover and share data, materials, and tools through an open-source, networked environment. NIF provides access to over 3,800 resources through their registry and more than 70 independent databases in the data federation. "}]