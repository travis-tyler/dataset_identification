[{"section_title": "Abstract", "text": "Prediction of Alzheimers disease (AD) progression based on baseline measures allows us to understand disease progression and has implications in decisions concerning treatment strategy. To this end we combine a predictive multi-task machine learning method 1 with novel MR-based multivariate morphometric surface map of the hippocampus 2 to predict future cognitive scores of patients. Previous work by Zhou et al.\n1 has shown that a multi-task learning framework that performs prediction of all future time points (or tasks) simultaneously can be used to encode both sparsity as well as temporal smoothness. They showed that this can be used in predicting cognitive outcomes of Alzheimers Disease Neuroimaging Initiative (ADNI) subjects based on FreeSurfer-based baseline MRI features, MMSE score demographic information and ApoE status. Whilst volumetric information may hold generalized information on brain status, we hypothesized that hippocampus specific information may be more useful in predictive modeling of AD. To this end, we applied Shi et al.\n2 s recently developed multivariate tensor-based (mTBM) parametric surface analysis method to extract features from the hippocampal surface. We show that by combining the power of the multi-task framework with the sensitivity of mTBM features of the hippocampus surface, we are able to improve significantly improve predictive performance of ADAS cognitive scores 6, 12, 24, 36 and 48 months from baseline."}, {"section_title": "INTRODUCTION", "text": "Recent work in psychological testing, 3 genetic studies, 4 magnetic resonance (MR) imaging, 5 positron emission tomography (PET) imaging, 6 cerebral spinal fluid (CSF) measurements, 7 cardiovascular status 8 and others have yielded tremendous amounts of diagnostic data for diagnosing and staging dementias, especially Alzheimers disease (AD). Moreover, many of these studies now also include longitudinal information. 3, 9 This has lead to a problem often referred to as the curse of dimensionality, where the size (number of dimensions) of the dataset makes it difficult to do various numerical analysis on the data. This in turn makes it increasingly difficult to draw consistent conclusions from the dataset. Statistical analysis together with clinical disease models have helped with determine how the different sets of diagnostic information interacts with one another but they require a large number of ad hoc assumptions and therefore does not lend itself well to large scale Medical Imaging-based features. These problems become even more important when trying to use machine learning techniques because at some point the predictive power of the model ceases to increase even though we're adding more information or dimensions. The question is then about how to select the \"correct\" features to maximize predictive power. This paper leverages existing sparsifying machine learning techniques with temporal priors, 1 built specifically for progressive disease models, such as AD, together with multivariate tensor-based morphometric (mTBM) "}, {"section_title": "METHODS", "text": ""}, {"section_title": "ADNI Data", "text": "Data used in the preparation of this article were obtained from the Alzheimers Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). The ADNI was launched in 2003 by the National Institute on Aging (NIA), the National Institute of Biomedical Imaging and Bioengineering (NIBIB), the Food and Drug Administration (FDA), private pharmaceutical companies and non-profit organizations, as a $60 million, 5-year public-private partnership. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimers disease (AD). Determination of sensitive and specific markers of very early AD progression is intended to aid researchers and clinicians to develop new treatments and monitor their effectiveness, as well as lessen the time and cost of clinical trials.\nThe Principal Investigator of this initiative is Michael W. Weiner, MD, VA Medical Center and University of California San Francisco. ADNI is the result of efforts of many co-investigators from a broad range of academic institutions and private corporations, and subjects have been recruited from over 50 sites across the U.S. and Canada. The initial goal of ADNI was to recruit 800 subjects but ADNI has been followed by ADNI-GO and ADNI-2. To date these three protocols have recruited over 1500 adults, ages 55 to 90, to participate in the research, consisting of cognitively normal older individuals, people with early or late MCI, and people with early AD. The follow up duration of each group is specified in the protocols for ADNI-1, ADNI-2 and ADNI-GO. Subjects originally recruited for ADNI-1 and ADNI-GO had the option to be followed in ADNI-2. For up-to-date information, see www.adni-info.org.\nFor our experiment we used 616 subjects for M06, 606 for M12, 533 for M24, 364 for M36 and 97 for M48. 90% of the data was used for training and 10% used for testing. The reported results are for 20 different selection splits of training and testing. More information about the demographics and patient selection is available in Zhou et al 2013. "}, {"section_title": "convex Fused Sparse Group Lasso (cFSGL)", "text": "Zhou et al 2013 1 has proposed a powerful multi-tasked learning technique that incorporates sparsity as well as temporal smoothing for modeling a progressive disease model. In their formulation, each tasked can be though of a single forward predictor from baseline measurement to a measurement at a certain future time point. In their case, they used the ADNI dataset and predicted ADAS cognitive scores 6 months after baseline (M06), 12 months after baseline (M12), 24 months after baseline (M24), 36 months after baseline (M36) and 48 months after baseline (M48). In our study we aim to use the same ADNI dataset but also incorporate mTBM hippocampus features and compare it to features used in their study. We also attempt to combine the different feature sets to try to evaluate the predictive power of each set of features.\nThe proposed cFSGL can be considered a multi-task regression problem with t time points and from n subjects each with d features, where {x 1 , x 2 , . . . , x n } represents each of the d input features for each subject at baseline (i.e. x i \u2208 IR d ). Similarly, {y 1 , y 2 , . . . , y N } represents the target cognitive scores for each subject at N time points (i.e. y i \u2208 IR N ). For a single subject (n) each task can be seen as a projection of MR / demographic / genetic baseline measurements at t = 0 represented at x n to a future cognitive score measurement at time t = t 1 (e.g. at 48 months) given by y n (t 1 ). We can extend this formulation to a multi-task one by performing"}, {"section_title": "Figure 3 Average Weights for mTBM Feature 1 used for Prediction of Disease Progression", "text": "projections of all time points simultaneously. In other words, each set of baseline measurements at t = 0 given by x n is projected to a vector (IR N with N time points) given by y 1 . The entire mapping can be summarized as a linear operation using matrices X and Y . X and Y is formed by arranging the patient feature space row-wise, each row being x n or y N , and yields a IR n\u00d7d X matrix and a IR n\u00d7N Y matrix. Since this is a linear model, a set of weights W (IR d\u00d7N ) is trained to map x n to y n or X to Y . To achieve a set of weights that encodes both sparsity and temporal smoothness. The following cost function is minimized during training.\nwhere W 1 is the L1-norm or lasso penalty that encodes for sparsity,\nij is the group Lasso penalty that encodes for temporal grouping of features, RW "}, {"section_title": "Multivariate Tensor-based Morphometry (mTBM) features", "text": "After automatically segmenting hippocampus with FSL 11 from brain MR images, we build parametric meshes to model hippocampal shapes. High-order correspondences between hippocampal surfaces were enforced across subjects with a novel inverse consistent surface fluid registration method. Multivariate statistics consisting of multivariate tensor-based morphometry (mTBM) and radial distance were computed for surface deformation analysis. "}, {"section_title": "RESULTS", "text": "Predictions using mTBM significantly outperform prediction without using mTBM as shown in Figures 1 and  2 . Quantitative measures such as nMSE, wR and rMSE show across the board improvements as shown in Table  1 and Figure 4 . Average weights for one of the mTBM features across the 20 trials is shown in Figure 3 ."}, {"section_title": "DISCUSSION AND CONCLUSIONS", "text": "By merging fused multi-task learning that encodes temporal smoothing 1 together with AD sensitive mTBM maps of the parametric hippocampus surface 2 , we were able to get significant gains in future ADAS cognitive score prediction. We believe that these results are some of the highest performing predictions based on baseline data only and is consistent with our survey of other comparable studies.\n1 Other factors not addressed in this work is the effect of percentage of data used for training and testing. Previous work 1 has shown that although there would be a decrease in performance measured with a smaller training set, the trends and relative performance remains comparable. We have also treated the parametric surface data, patient demographics and MRI volumetric information as one continuous information vector. It would be interesting to see if adding neighborhood information based on the location on the parametric surface would give us smoother and more realistic weights on the parametric surface and perhaps even better or more consistent results.\nThe current study also serves as a illustration of how machine learning methods can be used with whole parametric surfaces or even volumetric volumes such as in fMRI studies. However, as the number of voxels and vertex points increase, we again run into problems with the curse of dimensionality. To counter such problems, sparsifying penalties such as in cFSGL can be employed. However, without a reasonable starting weight, finding a reasonable solution that has the required sparsity can get computational intensive. One solution that we intend to explore is the use of stability selection in seeding the initial weights for the algorithm in a hierarchical approach to learning. We believe that this a reasonable way of leveraging prior information whilst allowing the algorithm to impose explore ensure temporal smoothness and sparsity.\nAs this is a model of a epidemiological system, we cannot ignore the investigator's selection of reasonable features. Moreover, the performance of the system is as interesting as the weights that yield the predictions. Our future work includes work in understanding the behavior of the weights across the parametric surface space as well as in time. Previous work has shown that stability selection may be a good fit for analyzing the feature weights on the model."}, {"section_title": "FUTURE WORK", "text": "Future work including stability analysis of the weights may yield more information about the relationship between the deformation of hippocampal subfields and other clinical indicators during AD progression. "}, {"section_title": "ACKNOWLEDGEMENTS", "text": ""}]