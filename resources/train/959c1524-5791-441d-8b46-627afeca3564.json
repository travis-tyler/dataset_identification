[{"section_title": "Abstract", "text": "In many applications it is important to estimate a fluid flow field from limited and possibly corrupt measurements. Current methods in flow estimation often use least squares regression to reconstruct the flow field, finding the minimum-energy solution that is consistent with the measured data. However, this approach may be prone to overfitting and sensitive to noise. To address these challenges we instead seek a sparse representation of the data in a library of examples. Sparse representation has been widely used for image recognition and reconstruction, and it is well-suited to structured data with limited, corrupt measurements. We explore sparse representation for flow reconstruction on a variety of fluid data sets with a wide range of complexity, including vortex shedding past a cylinder at low Reynolds number, a mixing layer, and two geophysical flows. In addition, we compare several measurement strategies and consider various types of noise and corruption over a range of intensities. We find that sparse representation has considerably improved estimation accuracy and robustness to noise and corruption compared with least squares methods. We also introduce a sparse estimation procedure on local spatial patches for complex multiscale flows that preclude a global sparse representation. Based on these results, sparse representation is a promising framework for extracting useful information from complex flow fields with realistic measurements."}, {"section_title": "Introduction", "text": "Estimating the structure of a flow field from limited and noisy measurements is an important challenge in many engineering applications. For example, accurate estimation is central to active flow control (Noack et al., 2011; King, 2014; Brunton & Noack, 2015; Sipp & Schmid, 2016) , which has the potential to revolutionize next-generation technology, ranging from fuel-efficient, low-drag automobiles (Pfeiffer, 2016) to high-efficiency turbines (Strom et al., 2017) and internal combustion engines (Maurya, 2017) . The ability to reconstruct important flow features from restricted observations is also critical in applications as diverse as cardiac bloodflow modeling (Yakhot et al., 2008; Sankaran et al., 2012) , ship wake identification (Graziano et al., 2016) , and climate science (Kalnay, 2003) . All of these applications rely on estimating the structure of complex fluid flows based on limited measurements. This work focuses on addressing this challenge using modern techniques from machine learning and sparse representation (Wright et al., 2009) , which have recently been applied to flow field classification (Bright et al., 2013; Brunton et al., 2014; Bright et al., 2016; Kramer et al., 2017) .\nModern experimental methods and the increasing scale and resolution of numerical simulations have led to an abundance of fluid flow data. Although we are able to achieve unprecedented fidelity in measurement and simulation in lab settings, in applications we are typically limited to a few noisy sensors. The challenge in flow field estimation is thus synthesizing the profusion of offline data and limited, unreliable online information. This synthesis relies on learning and representing the essential structure of the flow field based on past data. Fluid mechanics is not unique in having a wealth of data, however, and recent years have seen the rapid development of revolutionary machine learning techniques to leverage big data, particularly in image processing (Krizhevsky et al., 2012; LeCun et al., 2015) . Since flow field data is often discretized on a grid, many of these techniques can be applied to fluid mechanics with only minor modifications, for example for flow field classification (Bright et al., 2013) and estimation (Yu & Hesthaven, 2018) .\nA common model-free approach to flow field reconstruction is to represent the field as a linear combination of modes in a library, such as empirical eigenfunctions from proper orthogonal decomposition (POD) (Sirovich, 1987; Berkooz et al., 1993) or dynamic mode decomposition (DMD) (Schmid, 2010; Rowley et al., 2009; Tu et al., 2014b; Kutz et al., 2016) . Gappy POD was introduced by Everson & Sirovich (1995) to repair corrupted or missing data, and was adapted to flow field reconstruction by Bui-Thanh et al. (2004) . This method has been used to reconstruct unsteady flow fields around a cylinder (Venturi & Karniadakis, 2004) and an airfoil (Willcox, 2006) , arterial blood flow data (Yakhot et al., 2008) , and low-dimensional ocean velocity and temperature fields (Yildrim et al., 2009) . Podvin et al. (2005) used a similar method to estimate POD coefficients for 3D cavity flow from 2D particle image velocimetry (PIV) data. Other leading methods for flow field estimation include stochastic estimation and model-based observers, which are discussed in more detail in section 2. However, these majority of these approaches are based on least-squares regression, which may be prone to overfitting and sensitive to noise.\nInspired by the work of Wright et al. (2009) on sparse representation for image recognition, we propose searching for a sparse representation in a library of example flow fields rather than a minimum-energy solution in the modal library, as shown schematically in figure 1. If the flow is statistically stationary and the library is sufficiently extensive, it may be possible to identify a sparse combination of the few most similar fields in the library that are consistent with the measurements. Sparsity-promoting techniques are known to prevent overfitting and provide robustness to noisy and corrupt measurements, which are essential for flow field estimation. Sparse representation has been previously applied to classify flow regimes in a library of POD modes based on limited sensors in the seminal work of Bright, Lin & Kutz (2013) , and sparse flow classification has been extended in related work (Brunton et al., 2014; Bright et al., 2016; Kramer et al., 2017) . Our work builds on this framework, extending regime classification to full flow field reconstruction and demonstrating sparse representation in a library of training examples instead of a modal basis. We show that when the flows are more complex than previously studied, or the measurements are corrupted, this method significantly outperforms reconstruction with a POD library. Since highly complex flows may not have a sparse representation in terms of POD modes, this result reinforces the importance of sparsity for robustness to noise and accuracy of reconstruction. We extensively explore this method on several example systems of increasing complexity with various levels of measurement noise, including numerical and geophysical data sets, and find that it produces more accurate and robust reconstructions than standard least-squares methods. Flow field estimation continues to be an important and difficult challenge, but improvements in robustness and accuracy are consistent with previous work in sparse regression and highlight the value of sparsity in reconstruction methods.\nThe remainder of this work is organized as follows. Section 2 provides an overview of related work on flow field estimation. In section 3, we describe the proposed method for flow field reconstruction based on sparse representation. The four flow configurations used to test this method are described in detail in section 4. Section 5 explores sparse reconstruction for flow field re- Figure 1: Flow field reconstruction process using sparse representation. In offline library building (a) the measurement operator C is applied to the training set \u03a8. The sparse representation step (b) solves the relaxed convex optimization problem (7) to estimate sparse coefficients\u015d which are consistent with the noisy measurements y. Finally the full flow field is reconstructed with as a linear combination of the training examples (c). The reconstructed field shown in (c) is the actual output of the sparse representation algorithm with the noisy test data and measurements shown in (b). Flow past a cylinder is discussed further in section 5.1.\nconstruction on these examples with various sampling strategies from corrupted measurements, demonstrating that sparse representation exhibits improved robustness and accuracy compared to least-squares estimation. These results include careful benchmark comparisons on four fluid flows, including two canonical flows and two geophysical flows: periodic vortex shedding past a cylinder at Re = 100 (section 5.1), a mixing layer at Re = 720 (section 5.2), global sea surface temperature fields (section 5.3), and data from a Gulf of Mexico ocean model (section 5.4). On the mixing layer and Gulf of Mexico ocean data, we demonstrate that when a globally sparse representation is not available, the flow field can be more accurately estimated with a superposition of local reconstructions and show that this improvement is facilitated by enhanced sparsity of the local representations. In section 6 we summarize the main results and discuss limitations of the method, and we conclude with section 7. To promote reproducible research, all code is available online 1 ."}, {"section_title": "Prior work in flow field reconstruction", "text": "Because of its far-reaching applications, flow field estimation is a rich field with seminal works spanning the past half century. Here, we provide a brief overview of some of the most relevant related works, which are organized into three broad groups: stochastic estimation, model-based observers, and library-based reconstruction. Each of these methodologies approaches the problem with a slightly different motivation, but many modern studies are driven by the overarching goals of estimation and control. Stochastic estimation (SE) was introduced by Adrian (1975) to study coherent structures in turbulence. SE is a statistical technique that estimates a quantity of interest in the flow as a conditional average given the measurements. Expanding the conditional average in a Taylor series and minimizing the mean-square estimation error yields a functional dependence between the observation and flow field variables determined by unconditional statistics, such as the two-point correlation tensor. SE has been extended to the estimation of POD coefficients (Bonnet et al., 1994) , spectral coefficients (Ewing & Citriniti, 1999; Tinney et al., 2006) , and inclusion of time-delayed measurements (Durgesh & Naughton, 2010; Ukeiley et al., 2008) . The stochastic estimation method has been used to study isotropic turbulence (Adrian, 1975 (Adrian, , 1979 Tung & Adrian, 1980) , turbulent boundary layers (Guezennec, 1989; Naguib et al., 2001) , axisymmetric jets (Bonnet et al., 1994; Tinney et al., 2006) , the backwards-facing step (Cole & Glauser, 1998; Taylor & Glauser, 2004; Hudy & Naguib, 2007) , open cavities (Murray & Ukeiley, 2003 , 2007 , and for feedback in closed-loop control of flow separation over an airfoil (Pinier et al., 2007) .\nIn another approach to flow field estimation, an observer ?ynamical system is used to evolve the estimate of the system state according to a reduced-order model while measurements provide feedback used to improve the estimate. The model may be linear, for example, based on dynamic mode decomposition (DMD) (Schmid, 2010; Rowley et al., 2009; Tu et al., 2014b; Kutz et al., 2016) , with an estimate maintained by Kalman filtering (Tu et al., 2013; Surana & Banaszuk, 2016; Kramer et al., 2017) . The model could also be nonlinear, based on a Galerkin projection of the Navier-Stokes equations onto a set of POD modes (Holmes et al., 1996; Noack et al., 2003; Buffoni et al., 2008) , or the result of model identification . Recent work has investigated the use of data assimilation techniques (e.g. particle filters or ensemble Kalman filters) to estimate the mean flow (Suzuki, 2012; Foures et al., 2014; Symon et al., 2017) or the full flow field (Comb\u00e9s et al., 2015; Kikuchi et al., 2015; Mons et al., 2016; da Silva & Colonius, 2018; da Silva, 2019) . In any case, the accuracy of observer-based methods depends on the quality of the reduced-order model, so there is inevitably a tradeoff between low-latency and high-accuracy models. See ; Taira et al. (2017) for reviews of modal decomposition and model reduction in fluids.\nA third category of model-free flow field estimation takes advantage of large offline data sets via library-based reconstruction. Often the flow field will be discretized and reshaped into a high-dimensional vector, which is then approximated by a linear combination of modes in a library (Taira et al., 2017) . The modes may be generic (e.g. a Fourier or wavelet basis) or tailored to the particular flow (such as POD or DMD modes), which each have advantages for sensorbased flow reconstruction (Manohar et al., 2018) . Advanced data-driven algorithms such as K-SVD and GOBAL (Mathelin et al., 2018) may also be used. Gappy POD (Everson & Sirovich, 1995 ) is a popular library-based method, where the library consists of POD modes and coefficients are estimated by least-squares regression based on limited or masked data (Bui-Thanh et al., 2004; Willcox, 2006; Murray & Ukeiley, 2007) . Podvin et al. (2005) used gappy POD to estimate POD coefficients for a 3D flow past a cavity from 2D PIV data, choosing the number of measurements to equal the number of modes, resulting in the inversion of a square matrix. In a related approach, Yu & Hesthaven (2018) use deep learning to estimate POD coefficients. More generally, deep learning is a powerful emerging technique to represent multi-scale flow structure and model turbulence closure (Zhang & Duraisamy, 2015; Ling et al., 2016; Kutz, 2017; Duraisamy et al., 2018) , although it generally requires tremendous amounts of training data and may be prone to overfitting unless care is taken to constrain the models with known physics. In a sense, deep learning may be considered a sophisticated nonlinear interpolation scheme that leverages a large library of historical examples (Mallat, 2016) . With different choices of library and optimization problem, the library-based reconstruction framework also encompasses compressed sensing and the sparse representation approach outlined here, although typically a library of POD modes is used with least-squares regression.\nThe estimation and reconstruction algorithms described above are generally based on 2 -optimization, which suffers from the same limitations as standard least-squares parameter estimation; sparsity-promoting methods have emerged as a principled way to address these shortcomings by regularizing the regression (Xu et al., 2010; Kutz, 2013; Zheng et al., 2018) . Sparse representation in a library takes advantage of known structure in the data and is robust to measurement corruption (Wright et al., 2009) . If the coefficient vector of the modal representation is sparse in the sense that it has relatively few nonzero entries, the coefficients can be recovered from surprisingly few measurements with efficient tools, such as matching pursuit (Mallat & Zhang, 1993; Pati et al., 1993; Tropp & Gilbert, 2007; Needell & Tropp, 2009) or by 1 -minimization of the coefficient vector (Donoho, 2006b; Cand\u00e8s & Tao, 2006) , under certain assumptions. If the library consists of generic modes, such as a discrete cosine transform (DCT) basis, then recovery based on 1 -minimization is known as compressed sensing (CS) (Donoho, 2006a; Cand\u00e8s, 2006; Baraniuk, 2007) . Compressed sensing has been used in fluid mechanics to reconstruct a signal in a linear-duct acoustic problem (Huang, 2013) , identify dominant frequencies in low-dimensional projections of sub-Nyquist rate PIV data (Tu et al., 2014a) , and to find a compact representation for wall-bounded turbulence (Bourgiuignon et al., 2014) . Although these results are promising, general flows are often not sparse enough to take advantage of compressed sensing, requiring prohibitively many measurements and expensive computations that do not scale well.\nThe sparsifying library does not need to be universal, however. Bright et al. (2013 Bright et al. ( , 2016 use sparse representation in a data-driven POD basis to classify the Reynolds number for flow past a cylinder. Bai et al. (2015) similarly demonstrated CS in a POD library to reconstruct PIV data. Wright et al. (2009) proposed a straightforward alternative to modal libraries, such as DCT and POD, in the sparse representation for classification (SRC) algorithm for facial recognition. In SRC, an image of an individual is downsampled and approximated with a sparse representation in terms of a library consisting of the training data itself, which contains some example images of the same person. The coefficients corresponding to the test individual will naturally be of greater magnitude, indicating the identity of the subject. SRC is robust to noise, corruption, or occlusion of the image, and has been applied for early diagnosis of Alzheimer's disease (Liu et al., 2012) , segmentation of MRI images (Tong et al., 2013) , automatic detection and classification of brain tumors (Nabizadeh & Kubat, 2015) , music genre categorization (Panagakis et al., 2009) , and dolphin whistle classification (Esfahanian et al., 2014) . Although SRC was introduced for classification, the success of sparse representation in a library of the training data has far reaching applications, including for flow field reconstruction, as will be explored here."}, {"section_title": "Sparse representation of a flow field in a library", "text": "In this work, we will investigate the utility of sparse representation for flow field reconstruction in a library of historical flow field data, exploring robustness and scaling with flow complexity. This section provides the methodological foundations for the results that follow. We describe the general library-based signal recovery framework in section 3.1, including reconstruction from sparse representation. In section 3.2 we introduce our method for sparse representation-based flow field reconstruction."}, {"section_title": "Library-based signal recovery", "text": "Here we provide the general problem statement and notation for sensor-based reconstruction of a high-dimensional state in a library. Given a discretized state vector x \u2208 IR n , for example representing the fluid velocity or vorticity field at a set of grid points, and linear measurements y = Cx, with y \u2208 IR p and p n, we seek an estimatex of the full signal. We assume that the state x can be accurately expressed as a linear combination of library elements \u03c8 j , j = 1, 2, . . . , r with \u03c8 j \u2208 IR n , so that\nfor some coefficient vector s \u2208 IR r , where columns in the library \u03a8 \u2208 IR n\u00d7r are the vectors \u03c8 j . The reconstruction problem reduces to estimating the coefficients\u015d that satisfy\nIn other words, we seek an estimate that produces measurements\u0177 = C\u03a8\u015d consistent with actual observations y. As described earlier, the library \u03a8 may comprise a modal basis, such as Fourier, wavelets, POD, or DMD modes, or it may be chosen to contain examples of flow fields from training data. We will also explore reconstruction for different classes of measurement matrix C, although it is also possible to tailor this matrix for a given library \u03a8 for improved reconstruction (Manohar et al., 2018) . In practice, solving for\u015d in Eq. (2) must be formulated as an optimization problem, since C\u03a8 is not typically a square matrix. For instance, in the overdetermined case where p > r and there are more measurements than library elements, we may choose to solve for the least-squares solution\nIt is generally useful to modify the least-squares regression by adding a regularization term to prevent overfitting and promote robustness to noise and outliers in the data:\nA choice of q = 2, corresponding to Tikhonov or ridge regression, penalizes high-variance solutions. For instance, Buffoni et al. (2008) employed this regularization to estimate POD coefficients in a nonlinear observer. A choice of q = 1 (LASSO regression) promotes a sparse representation (Tibshirani, 1996) . The regularization parameter \u03bb can be tuned to adjust the strength of this term. Other choices of q are possible, but q = 1 and q = 2 are the most common since they can be solved with convex optimization (Boyd & Vandenberghe, 2009) , which scales well to large problems. For high-dimensional and multiscale data, it is often the case that there are fewer available measurements than modes in the library, leading to an underdetermined problem with p < r. In this case the appropriate optimization problem i\u015d\nAgain, q = 2 leads to the minimum-energy solution consistent with measured data, while q = 1 leads to a sparse representation in the library \u03a8.\nIf the coefficient vector s is known to be sparse, and it is assumed to have exactly K nonzero elements (i.e., the vector s is K-sparse), this problem can be formulated a\u015d\nwhere s 0 is the number of nonzero entries of s. Although an estimate of the sparsity K may not generally be available, there are many efficient algorithms such as OMP (Mallat & Zhang, 1993; Pati et al., 1993; Tropp & Gilbert, 2007) or CoSaMP (Needell & Tropp, 2009 ) that can solve this problem more efficiently than Eq. (5). The representation problem in Eq. (5) can be applied to noisy sensor measurements y. In this case, the measurements are y = Cx + \u03b7, where \u03b7 is a noise vector. The optimization problem then relaxes the equality constraint:\nwhere is an error tolerance. If the measurements have independent and identically distributed Gaussian noise (i.e., \u03b7 \u2208 IR p with \u03b7 i \u223c N (0, \u03c3)), may be chosen as a multiple of the total noise \u03c3 \u221a p. When noise is introduced artificially, we nondimensionalize the noise level \u03c3 by the RMS fluctuations of the field variable in the training set. The relaxation in Eq. (7) assumes that \u03c3 is relatively small compared to typical fluctuations in the measurement vector y. Wright et al. (2009) describe a method for sparse representation, with q = 1, to handle sparse corruption with large amplitude, where some unknown fraction \u03c1 of random entries in y suffer from uniformly distributed corruption over the full range of observed values. That is, the measurement y is now y = Cx + e, where e has \u03c1p nonzero entries. The optimization problem is extended to also identify e by direct minimization of its 1 norm. If the signal is additionally corrupted by dense low amplitude noise as in (7), the problem become\u015d\nWe find, consistent with their results, that although the corruption e must be sparse in the sense that it has enough zero entries to enable identification via minimization of its 1 norm, it can actually consist of a substantial fraction of total measurements (see e.g. figure 5 ). We demonstrate reconstruction from noisy measurements in sections 5.1 and 5.2, but we relax the optimization problem even when noise is not explicitly added. Since Eq.\n(1) will generally not be exact, the relaxation plays a similar role to the regularization parameter \u03bb in Eq. (4); larger relaxations allow sparser estimates\u015d which still satisfy the constraint in Eq. (7). As mentioned earlier, there are many choices for the library of modes, and some may be more natural depending on the application. Fourier modes or wavelets may be useful in audio or image compression, and empirical POD modes are often used in fluids. In order to construct \"tailored\" libraries, such as POD modes, it is necessary to have a training set X \u2208 IR n\u00d7m of flow fields that contains representative examples. Such a training set can be obtained from simulations or experiments. Other libraries may be designed to be optimal in another sense. For instance, the K-SVD algorithm ) iteratively constructs a library in which data should have a representation with some prescribed sparsity. GOBAL (Mathelin et al., 2018 ) is a similar method that enforces observability of the library modes. Wright et al. (2009) simply use the training set as the library, so that the columns of \u03a8 are the prior observations.\nFigure 2: Schematic of the sparse representation method shown graphically in figure 1. After constructing the library C\u03a8 in an offline step, the sparse coefficients\u015d consistent with measurements y are estimated. The full flow field can be reconstructed as a linear combination of the training examples in \u03a8.\nThis reconstruction framework enables many choices for the library and the optimization formulation. For example, gappy POD (Everson & Sirovich, 1995) solves the least-squares problem (3) with a library of POD modes.To identify the high-energy structures in the flow field and ensure that the problem remains underdetermined, the library of POD modes can be truncated. This may be done automatically, for instance with the hard threshold of Gavish & Donoho (2014) , although it is not clear in general what level of truncation is optimal for flow reconstruction."}, {"section_title": "Flow field reconstruction from sparse representation", "text": "We now adapt the library-based reconstruction framework for fluid flow field reconstruction. The procedure is shown schematically in figures 1 and 2. The signal x \u2208 IR n is the full discretized flow field and the measurement operator C still relates measurements y to the full field by y = Cx. Following the work of Wright et al. (2009) in image analysis, we assume that the flow field has a sparse representation in a library of training examples \u03a8, as opposed to POD modes. That is, x = \u03a8s for some s with s 0 = K n. The coefficient vector s can be estimated using one of the optimizations in Eqs. (5)-(8).\nIn order to improve the performance of this method for systems in fluid mechanics, we make several modifications. First, the empirical mean of the training set may be subtracted from all data. This is effective in cases where the mean represents a significant fraction of the energy in the data, for instance in sea surface temperature fields (section 5.3). Second, the amplitudes of the reconstructed flow fields can be rescaled so that the total energy of the flow is equal to that computed from the training data. This rescaling is useful for reconstruction from noisy measurements; flow fields reconstructed with (7) tend to have lower amplitudes than the true field, since high levels of noise can be consistent with qualitatively accurate fields of reduced amplitude. In this work we only use this modification in section 5.1.\nThird, we develop a method of localized reconstruction for complex fluid flows. In the reconstruction process above, it is assumed that the test field is a simple linear combination of global fields in the library. However, for flows with coherent structures at multiple spatial scales, it may be prohibitively expensive to collect enough data to have representative examples of all likely global flow fields. Said another way, for multi-scale flows, it is difficult to collect enough data for the library to converge to a statistical stationary distribution. Fortunately, if we decompose the global domain into local patches, each patch may be much lower rank, enabling a local sparse representation. To facilitate localized reconstruction, we introduce local kernels \u03a6 j , j = 1, 2, . . . , k that restrict the measurement y j = C\u03a6 j x and reconstruction to the j\u2212th local region:\nThese decoupled optimization problems lead to compact local estimatesx j = \u03a6 j \u03a8\u015d j , with a full state estimate,x = jx j , that is globally valid. Finally, we define a metric to compare the quality of various reconstructions.The normalized root-mean-square residual of the difference of the reconstructionx and the test field x is:\nIf the empirical meanx is subtracted from both x andx, then the appropriate metric is\nAt this point, it is important to summarize some of the main assumptions that sparse representation relies on. First, as with all reconstruction methods based on a tailored library, we assume that the flow is statistically stationary, so that a sufficiently large library based on training data can generalize to future states. We then assume that the training set is comprehensive enough that the observed states are well-approximated by a linear combination of library elements. This is a related requirement, but while the former is a property of the flow, the latter is a property of the training data itself. All reconstruction methods further rely on the measurements containing sufficient information to accurately identify the coefficients\u015d. Just as reconstruction is impossible, even with relatively dense sampling, for a flow state that is essentially orthogonal to the library, we cannot realistically expect to accurately reconstruct a turbulent channel flow from one point measurement, no matter how extensive the library. Finally, sparse representation assumes that a flow field of interest may be expressed as a linear combination of a small number of other flow fields in the training library. This assumption holds for simple flows, such as periodic vortex shedding at low Reynolds number, but may be unjustified for complex, multiscale flows unless a staggering amount of data is available. We examine the implications of these assumptions in the following sections."}, {"section_title": "Algorithm", "text": "The complete flow field reconstruction based on sparse representation is as follows:\n1. Compute the library \u03a8 \u2208 IR n\u00d7r . The library may be given by the unmodified training data X \u2208 IR n\u00d7m , although we also investigate reconstruction using POD modes and a K-SVD library. Optionally, the empirical mean flow fieldx \u2208 IR n may be subtracted from X.\n2. Take measurements y = Cx + \u03b7 of the flow field x using the measurement operator C \u2208 IR p\u00d7n with noise \u03b7. For the examples below, the measurement matrix C consists of rows of the identity matrix corresponding to measured locations in the discretized field.\n3. Solve the appropriate optimization problem in Eqs. (5)- (8) for the coefficient vector\u015d. If the coefficients are found by minimizing the 1 \u2212norm, we refer to this as sparse representation.\n4. Reconstruct the estimated flow field withx = \u03a8\u015d. Optionally, rescale the estimated field to have the same variance as the training fields; this is helpful for very noisy measurements.\nFor dictionary learning with K-SVD, we use KSVD-Box v13. We solve the pursuit problem in Eq. (6) with OMP-Box v10 (Rubenstein et al., 2008) . To solve the convex optimization problems (7), (8), and (9), we use the CVX Matlab package (Grant & Boyd, 2008 . The complexity of sparse approximation grows with the number of measurements and the number of modes in the dictionary, but does not directly depend on the number of points in the original discretized field. \u00a75.1: Re = 100 vortex shedding \u00a75.2: Re = 720 mixing layer \u00a75.3: Sea surface temperature \u00a75.4: Gulf of Mexico vorticity Figure 3 : Example flow fields from the data sets which we investigate with the sparse representation-based reconstruction method. We study two canonical flows (periodic vortex shedding past a cylinder at Re = 100 and a mixing layer at Re = 720) and two geophysical data sets (sea surface temperature and Gulf of Mexico vorticity fields)."}, {"section_title": "Flow configurations", "text": "Here we describe the fluid flows explored in this work and the methods used to obtain the data. We apply flow field reconstruction to four data sets of increasing complexity, shown in figure 3: vortex shedding past a cylinder at Re = 100, a mixing layer at Re = 720, observations of sea surface temperature, and sea surface vorticity in the Gulf of Mexico."}, {"section_title": "Periodic vortex shedding", "text": "The first test case is given by the two-dimensional fluid flow past a circular cylinder at Reynolds number 100, which is characterized by periodic, laminar vortex shedding. This flow is a canonical benchmark system, although it is considerably simpler than most flows of practical interest. Our data was generated from direct numerical simulation of the incompressible Navier-Stokes equations using the immersed boundary projection method of Taira & Colonius (2007) ; Colonius & Taira (2008) 2 . The computational domain consists of four nested grids with the smallest grid covering a domain of 9 \u00d7 4 cylinder diameters and the largest grid covering a domain of 72 \u00d7 32 diameters. The resolution for each grid is 450 \u00d7 200 (50 points per cylinder diameter) and the simulation uses a time step of \u2206t = 0.02 time units that are non-dimensionalized by the freestream velocity and the cylinder diameter. We collect 151 post-transient snapshots, corresponding to five periods of vortex shedding, with each snapshot separated by 10\u2206t. The Reynolds number for this flow, based on the cylinder diameter and free-stream velocity, is Re = DU \u221e /\u03bd = 100, where D is the diameter, U \u221e is the free-stream velocity, and \u03bd is the kinematic viscosity. The training set consists of the first 32 snapshots, which spans one full period. We analyze the vorticity field, although the method could be applied to velocity, pressure, scalar concentrations, or any other field variables of interest. The mean vorticity field is included in visualizations, although analyses and error calculations are performed after subtracting the empirical mean of the training data.\nWith the wealth of potential reconstruction techniques within the library-based optimization framework, it is interesting to explore the relative resilience to noise of different choices of the library and regularizing norm. Figure 6 shows a comparison of reconstruction accuracy with increasing noise level for several of these combinations. We find that over a wide range of Gaussian noise levels, the sparse reconstruction ( 1 norm) with either the training library or a K-SVD library outperforms POD-based methods. The slope of the 2 -based methods are smaller than those of the 1 -based methods, so they will eventually achieve lower relative error, although at such large levels of noise it is unlikely that any method will result in a useful reconstruction. The poor performance of 1 optimization with a POD library indicates that the POD basis does not admit a sparse representation; empirical POD modes are eigenfunctions of a time-averaged correlation matrix, so that the energy in any particular flow field is distributed across modes. Thus, although the POD basis is optimal in the sense that it offers the best global reconstruction for a given number, this does not translate into optimality for the problem of reconstruction from limited measurements. In contrast, the K-SVD library is designed to admit a sparse representation of the data, and it is not surprising that this library results in the best performance 5 . However, sparse representation in a library of the training data exhibits similar performance and benefits from simple implementation and interpretable results. These results reinforce the importance of sparse representation with respect to robustness to noise, a quality which has made 1 \u2212regularization a popular tool to 5 K-SVD allows for tuning several parameters; although our chosen values work well, these are not necessarily optimal. prevent overfitting in parameter estimation (Xu et al., 2010) . It is not surprising that sparse representation is so effective on this example, since the flow is low-rank, periodic, and does not exhibit multiscale phenomena. For a periodic flow, sparse representation reduces to choosing the single example with the correct phase from the library. In contract, each flow field is a dense linear combination of POD modes, so that this library does not admit a sparse representation. In this sense, a highly sparse representation can be expected to reproduce realistic flow physics. Reconstruction from limited, noisy measurements via sparse representation in a training library can therefore provide a robust alternative to 2 \u2212based methods. "}, {"section_title": "Mixing layer", "text": "As a more complex example, we consider a two-dimensional, compressible mixing layer at Reynolds number Re = \u2206U \u03b4 \u03bd = 720, where \u03b4 is the initial vorticity thickness, \u2206U is the velocity difference across the layer, and \u03bd is the kinematic viscosity. Stanley & Sarkar (1997) showed that two-dimensional numerical simulations in this regime reproduce the flow structures observed in three-dimensional experiments. We generated this data set by direct numerical simulation of the compressible Navier-Stokes equations using a finite volume, 5th-order WENO scheme (Coralic & Colonius, 2014) . The spatial coordinates are normalized by the vorticity thickness at the inlet. The velocities are normalized by the speed of sound of the fluid far from the mixing region. The Mach numbers of the high-and low-stream velocity are 0.5 and 0.25, respectively. The computational domain is x \u2208 [0, 800] and y \u2208 [\u2212200, 200] . The flow is forced at the inflow boundary at its most unstable fundamental frequency, and its sub-harmonic. Non-reflective boundary conditions are implemented on the other boundaries. The grid is smoothly stretched away from the mixing region to the non-reflective boundaries to prevent contamination by reflections. The grid in the mixing region is uniform with \u2206x = 0.08 and \u2206y = 0.02, respectively. After removing the transient portion of the simulation, we collect 2400 snapshots of the vorticity field in a window of (x, y) \u2208 (0, 128) \u00d7 (\u221212, 12), separated by non-dimensional time steps of \u2206t = 0.5827. We compute the normal vorticity from these velocity fields both for ease of visualization and for the importance of vorticity in identifying dynamically significant coherent structures (Hussain, 1981) .\nForcing at the inlet excites instability waves, which roll up into vortices and convect downstream. These vortices pair and eventually merge into successively larger vortices. This process contributes to the linear growth of the mixing layer (Winant & Browand, 1974) , and at higher Reynolds number, the turbulent mixing layer is dominated by the linear growth of the coherent structures (Brown & Roshko, 1974) . These structures play a significant role in mixing, transport, and entrainment in turbulent shear flows (Hussain, 1981) . Therefore, we study this laminar mixing layer as a representative case to assess the ability of sparse representation to generalize to other shear flow configurations.\nThe downstream evolution of the mixing layer leads to globally aperiodic dynamics, so we cannot expect to exactly reproduce an arbitrary flow field with a single example from in the training library, as was the case for the periodic vortex shedding behind a cylinder. However, we find that highly sparse representations still lead to accurate flow field estimates. This suggest that, as with the cylinder, the library of mixing flow fields generalize to new flows that are not in the training set, allowing a sparse representation. Figure 7 demonstrates reconstruction of the normal vorticity of the mixing layer from spatially downsampled measurements, given by 10:1 downsampling of the original data in the middle region containing the mixing layer. This may be thought of as a super-resolution problem (Yang et al., 2010; Freeman et al., 2002) , where low-resolution measurement data is synthesized into a higher-resolution field based on a high-resolution library. We compare reconstruction via sparse representation to 2 minimization in a truncated library of POD modes (r = 50). Both suffer from some degree of overfitting, since the specific global arrangement of vortices in the test data is likely not observed in the training data. Still, sparse representation builds a reasonable picture of the early perturbations and later large-scale vortical structure, whereas both are barely identifiable in the POD reconstruction.\nThe Separating the domain into windows that grow linearly in the streamwise direction, consistent with the flow dynamics, leads to a more realistic reconstruction from sparse representation (e), although gappy POD does not improve with this approach. The relative sparsity, given by the fraction of nonzero coefficients, of the global and windowed sparse representations (g) shows that windowing enables improved sparsity.\nshedding past a cylinder, this flow exhibits more complex, multiscale dynamics that are driven by the successive vortex pairing process. The local measurements may not be informative or correlated with the global structure of the flow field, which is an implicit assumption of the global library-based estimation. In such cases, where the global domain is larger than the de-correlation length, it may be helpful to assume that measurements inform only the local spatial region of the flow. Thus, we apply the localized reconstruction process introduced in section 3.2. We divide the full flow field into ten windows that grow linearly in the streamwise direction, consistent with the streamwise dynamical scaling, and solve the local sparse representation problems independently. Reconstructions are then formed from sparse combinations of the windowed training fields. This localized method (figure 7e) outperforms the global reconstruction from sparse representation (figure 7c), and both significantly improve upon POD-based reconstructions ( figure 7d, f) . Figure 7g compares the relative sparsity of the global and windowed sparse representations, given by the fraction of total nonzero coefficients across all independent windowed optimization problems. The local representations are more sparse and have higher fidelity than the global re- figure 7 , we construct windows that grow linearly in the spanwise direction and collect ten point measurements at noise level \u03c3 = 0.3 (white and black dots) from the mixing layer centerline in each window (separated by dashed lines). Local reconstructions are computed based on a windowed library of training examples (e, f). The normalized residual errors for these examples are 0.50 for the global sparse reconstruction (c), 0.40 for the windowed sparse reconstruction (e), 1.29 for global gappy POD reconstruction (d), and 0.98 for the local POD estimate (f). Although the windowed sparse representation has larger global errors than the global estimation, the local reconstruction is more accurate in the windows closer to the inlet, since the time scales of the flow are shorter there and the training set is more likely to contain examples of similar fields (see also figure 12b ). The relative sparsity of the global and windowed sparse representations in (g) shows improved sparsity with windowing.\nconstruction. This suggests a connection between multiscale features of the flow and the sparsity of representation. By restricting the scope of the reconstruction problem, we simplify the effective dynamics, and this is reflected in the order of magnitude difference in the sparsity of representation. These results suggest that the proposed flow field reconstruction method may generalize well to spatially complex flow fields. Note that on average, the various reconstruction results are comparable in an 2 error metric, even though the fields obtained via sparse representations exhibit more visually accurate flow structures. However, the 2 metric is likely not ideal for measuring differences in convecting flow structures, as shifting the exact test field by a couple of pixels will result in an error that is comparable to the gappy POD field. Figure 8 demonstrates reconstruction from ten noisy point measurements evenly spaced along the centerline of each window. In this case, sparse representation significantly outperforms gappy POD, although when averaged across the test data, the global sparse reconstruction is more accu-"}, {"section_title": "Sea surface temperature field", "text": "Real-world data is rarely as well-behaved as the numerical solutions of canonical flows. However, it is these flows, with limited training data, multiscale dynamics, and unmodeled coupling to external systems, where the ability to infer the structure of the field would be most useful. To this end we explore reconstruction methods with the NOAA Optimum Interpolation Sea Surface Temperature (SST) V2 data set 3 . Due to seasonal fluctuations, the SST field exhibits strongly periodic structure, although complex ocean dynamics still lead to rich flow phenomena. Flow data is available on a weekly basis on a one degree grid, and it is produced by combining local and satellite temperature observations. We use all available data at the time of analysis (1914 weeks, spanning October 1981-June 2018). Our training set consists of the first 20 years of data (1040 weeks, spanning 1981-2001) . We calculate a long-term annual mean field and subtract the mean for all analyses, since the mean accounts for the majority of the spatial structure of the field and is therefore uninformative with respect to the performance of reconstruction methods. \nThe global sea surface temperature (SST) data set represents a flow field that is strongly driven by periodic seasonal forcing but also deviates from oscillatory behavior under the influence of complex oceanographic and environmental processes. For this reason, the SST data may be viewed as a problem of intermediate difficulty for the algorithm, with complexity somewhere between the Re = 100 flow past a cylinder from section 5.1 and the strongly aperiodic Gulf of Mexico data in section 5.4. Figure 9 shows a comparison of mean-subtracted temperature field reconstructions from randomly located point measurements restricted to the mid-latitude region from 50 \u2022 S to 50 \u2022 N. We reconstruct the field with sparse representation in a training library and compare the result to gappy POD with the same measurements in a heavily truncated library (r = 2) and with many more measurements in a library of r = 50 POD modes. Both methods perform similarly in the error metric given by Eq. (10); average reconstruction errors across the test data are within standard error of one another. Fluctuations in the sea surface temperature field are dominated by seasonal oscillations, so that two POD modes capture a surprising amount of structure. In the absence of measurement noise, gappy POD has proven effective in estimating flow fields that can be represented accurately in terms only a few modes (Willcox, 2006) . The fact that a flow as apparently complex as in figure 9a can be accurately reconstructed with either method from as few as 10 random point measurements is a reflection of the underlying low-dimensional structure of this data set. The global sparse reconstruction (c) suffers from overfitting, since there is not a highly sparse global representation of this flow field in the training set. Gappy POD on the global field (d) is comparable to global sparse representation; residual errors in both cases are \u223c 0.60. Sparse reconstruction from the same measurements, but using the local kernel method described in section 3.2 with k = 96 equally spaced kernels, enables locally sparse representations that combine to form a significantly more accurate global estimate (e), with a reconstruction error of 0.37. The local least-squares POD still suffers from high-frequency overfitting (f)."}, {"section_title": "Mode number Cumulative energy Normalized singular value", "text": ""}, {"section_title": "Gulf of Mexico surface vorticity", "text": "Finally, we consider the Gulf of Mexico surface velocity estimates from the HYbrid Coordinate Ocean Model (HYCOM) group. This data-assimilative model synthesizes remotely sensed and in situ measurements on a hybrid coordinate system 4 . We use daily 1/12.5 \u2022 -resolution data from 1992-2018 (9268 snapshots, combined from HYCOM experiment numbers 19.0, 19.1, 90.9, 91.1, and 91.2). The training set consists of 8341 snapshots, or approximately 90% of the total data. As with the mixing layer and cylinder, we compute vorticity from 2D velocity measurements, although the methods are readily applied to any quantity of interest. We analyze the fluctuating vorticity fields relative to the empirical mean of the training set, but include the mean flow in visualizations. Figure 4 shows the singular value spectra, equivalent to the POD eigenspectra, of the four data sets. This offers a rough comparison of the complexity of the flows. The low-dimensional dynamics of the flow behind a cylinder is clear from the sharp decay of singular values; most of the energy is contained within the first twenty POD modes. On the other hand, the spectrum for the Gulf of Mexico data converges slowly, indicating complex multiscale dynamics. The difficulties with this data set are intuitive: by restricting our view to the Gulf of Mexico we study a flow with an unmodeled coupling to a much larger chaotic system. The mixing layer and sea surface temperature data exhibit intermediate complexity. For the mixing layer, the flow near the inlet is approximately periodic, and the behavior becomes more complex as the flow evolves downstream. Similarly, the SST fields show strong seasonal fluctuations with perturbations.\nThe final test flow is the HYCOM Gulf of Mexico ocean velocity data, which poses the greatest challenge for reconstruction. On the time scale of the available data, the flow is not statistically stationary, and given the spatial complexity of the flow, accurate reconstruction requires significantly more measurements than the other fields considered in this work. Figure 10 shows a typical example of field reconstruction from p = 4000 random point measurements, which account for about 8.5% of all grid locations. Global reconstructions from both sparse representation in the Local sparse representation (c) with k = 96 equally spaced kernels yields a 26% improvement in reconstruction error over gappy POD in a library truncated to r = 500 modes (d). Global sparse representation and local gappy POD both perform worse than these methods.\ntraining set and gappy POD with a truncated library of r = 500 modes successfully reconstruct much of the large-scale structure in the field and have comparable reconstruction errors, although the sparse representation estimate is contaminated by non-physical high-frequency fluctuations.\nAs with the mixing layer, the test field cannot be accurately represented as a sparse combination of training examples, because of the complexity of the flow and the fact that the training data does not fully generalize to the test set. The sparsest representation identified by equation (7) contains K = 3995 (around 48%) nonzero coefficients (figure 10c), around 400 times as many as the sea surface temperature field in figure 9b. However, we achieve a more accurate reconstruction through the local kernel approach outlined in section 3.2 and the appendix. By separating the reconstruction problem into localized kernels, we can stitch these local reconstructions together to obtain a global field that more accurately captures the large-scale vortical structures in the test field. This is intuitive from a measurement perspective, since the localization essentially relaxes the optimization constraints so that the sparse representation need only be consistent with local measurements. Seeking a global reconstruction that matches all measurements simultaneously is overly restrictive for a flow in which spatial correlations decay rapidly. As with the mixing layer, sparsity appears to be a hallmark of complexity; on average, each kernel representation contains only K \u2248 106 (\u223c 1%) nonzero coefficients. This suggests that features in local patches of the flow may closely resemble those present in the training data, even if the global flow field does not. Figure 11 demonstrates reconstruction from uniformly downsampled measurements. The test field is sampled at a 5:1 ratio in the ocean region (p = 1261 points) and reconstructed with gappy POD and local sparse representation, using the same parameters as in figure 10 . Again, reconstruction from a local sparse representation is more accurate than gappy POD, suggesting that the method may be useful for interpolating low-resolution sensor data."}, {"section_title": "Results", "text": "We now investigate flow field reconstruction from limited measurements using the four data sets described in section 4, which span a range of physical scales and complexity. For the two numerically generated flows, we study the impact of measurement noise on reconstruction accuracy and find improved robustness with sparse representation. In the mixing layer, we demonstrate the advantages of sparse representation by analyzing the flow in windows to enable higher levels of sparsity. Finally, we demonstrate the proposed method on two geophysical data sets: global sea surface temperature and Gulf of Mexico surface vorticity. In all cases, we compare the performance of sparse representation to other library-based methods, including gappy POD. Figure 5 demonstrates reconstruction of the flow past a cylinder from various measurements with increasing levels of noise and corruption. In particular, we consider sparse representation in a library of the training data and find that this flow can be accurately reconstructed, even in the presence of significant noise. We also investigate various measurement strategies, including random point measurements, a \"window\" inspired by PIV-type measurement, and continuous \"slices\" in both vertical and horizontal orientations. For example, figure 5 demonstrates recovery of the entire field from a cross-stream slice measurement where 70% of the measured points are corrupted by replacing the observed value with a uniform random value on the range of observed vorticity. In all cases, the measurement strategies with larger numbers of observations (e.g., the red window) exhibit more robust reconstruction performance. In addition, for corrupt measurements, there is a phase change observed at a critical corruption density, consistent with the wider sparse representation literature. It is not surprising that sparse representation is effective for this simple example, since the flow is periodic and patterns observed in the training data generalize to the test fields. However, these results are encouraging, as sparse representation exhibits accurate and robust reconstruction across a variety of physical measurement configurations and noise intensity."}, {"section_title": "Test field", "text": "Sparse representation (p = 10) Gappy POD (p = 10, r = 2)\nGappy POD (p = 500, r = 50)\nFigure 9: Example reconstruction of a sea surface temperature field (a) using sparse representation (b) and gappy POD with p = 10 and p = 500 measurements (resp. c and d). The POD libraries were truncated r = 2 and r = 50 modes respectively, which were the empirically determined optimal values. Errors in all three estimates are around 0.30. The long term annual mean temperature field has been subtracted to highlight variations in the data.\nrate, in an 2 sense, than the windowed estimate. As discussed further in section 6 and shown in figure 12 , the dynamics have longer time scales in the downstream windows. Thus, the training data may not include enough representative examples of downstream behavior to admit a sparse representation. Indeed, the local reconstructions in the first seven windows are highly accurate and the errors in the total flow field estimate are largely due to the final three windows."}, {"section_title": "Discussion", "text": "This work demonstrates the enhanced robustness and accuracy of flow field reconstruction by sparse representation in a library of training data, and we have explored this approach on a range of example flow fields of increasing complexity. We also discuss potential limitations of sparse representation, along with proposed methodological extensions and improvements. The success of sparse representation depends on the availability of both an extensive library that contains representative examples of relevant flow structures and sufficiently rich sensor information to infer which of these structures are active. Both of these requirements are related to the flow physics and spatiotemporal scales of the particular system under consideration.\nFirst, the library must contain a sufficiently extensive collection of example flow fields, so that a new flow field may be approximated by a sparse combination of these examples. Even for aperiodic flows, this may be satisfied if the training set contains a long enough flow history. To quantify if the training library is sufficiently complete to generalize to a new test field, we compute the residual error obtained by approximating a test field by orthogonal projection onto the training library. If the test field is well approximated in the training library, the residual is small, and if the test field has new structures that are not observed in the training data, there will be a large residual. Figure 12 shows the residual error for each of the four flow examples from section 5 as a function of the length of the training data; the orthogonal projection is obtained by computing the POD subspace for the given library with m training examples. Even with very few examples in the library, the flow past a cylinder generalizes to the test data, since the flow is periodic. However, the mixing layer and Gulf of Mexico vorticity data have relatively large generalization error, even for large training libraries, indicating that there are new structures that haven't been observed in the training data. With enough training data, it is conceivable that the generalization error can be controlled for these flows, although this may be prohibitively expensive in terms of data collection and processing. Instead, decomposing the flow domain into local patches results in considerably improved library generalization (see figure 12b) , meaning that less training data is required for an accurate representation of a new flow field in the library. As shown in figures 7, 8 and 10, the local patches also admit a sparser representation in the library, resulting in more accurate and robust flow reconstructions. The improved performance of a local sparse representation is intuitive, as decomposing the spatial domain makes it more likely to find similar local flow structures in the training data. Thus, the generalization error of the training library provides a useful diagnostic to quantify the expected performance of sparse representation.\nThroughout these examples, we find that least-squares solutions generally overfit to noisy sensor measurements, resulting in non-physical high-frequency fluctuations, as in figures 7 and 10. In contrast, sparse representation in a library of training examples results in robust and accurate flow reconstruction, preventing overfitting and ensuring that that the unmeasured regions of the field are consistent with prior knowledge. If a sufficiently sparse approximation is not possible, however, the method will not reliably produce a field that is qualitatively similar to actual observations. However, even if a sparse representation of the entire flow field does not exist, figures 8b-c and 10d demonstrate that locally sparse representations can be used for globally accurate reconstruction.\nA second condition for successful sparse flow reconstruction, even with a rich enough library, is for the measurements to provide sufficient information to correctly identify the sparse library coefficients. For example, it is unrealistic to hope that a single point measurement can be used to reconstruct a highly turbulent flow field, no matter how comprehensive the training library. In the Bayesian perspective, even perfect knowledge of the prior distribution is not enough for an accurate estimation, unless it is sufficiently conditioned on measurement information. # random measurements n s Reconstruction error Figure 13 : Normalized residual error of sparse representation-based reconstructions with increasing number of random point measurements. We use the global reconstruction method for the periodic vortex shedding past a cylinder (blue), mixing layer (red), sea surface temperature fields (yellow), and Gulf of Mexico (purple) flow fields. For computational efficiency we estimate coefficient vectors\u015d using Orthogonal Matching Pursuit (OMP) with empirical estimates of the sparsity K. Accurate reconstruction requires both rich training data and sufficient measurement information; the latter condition can vary widely depending on the flow.\n13 shows the accuracy of the sparse representation method versus the number of random point measurements for each example. In each case, there is a rough number of sensors where the error sharply decreases: p = 10 for the flow past a cylinder and sea surface temperature fields, p = 100 for the mixing layer, and p = 4000 for the Gulf of Mexico data, which roughly correspond to the number of measurements used in section 5. Further increasing the number of sensors results in a minimum error plateau, which is defined by the generalization error of the library, as described above. It is important to note that it may be possible to reconstruct the flow field with less error from fewer measurements by leveraging additional knowledge about the flow, for example from a reduced-order model or via time-delay embedding ."}, {"section_title": "Conclusion", "text": "In this study, we develop a method for flow field reconstruction based on sparse representation in a library of examples. This method builds on prior work in library-based reconstruction and sparse representation, in particular the sparse representation for classification algorithm (Wright et al., 2009; Bright et al., 2013) . We apply this method to several example flows, ranging from simple canonical flows to challenging geophysical data sets, and demonstrate improved accuracy and robustness to noise and corruption compared to typical least-squares flow reconstruction, provided that the library is sufficiently rich and the measurements are sufficiently informative.\nThis work suggests several directions of ongoing research to refine the method for practical applications. Although figures 12 and 13 give rough metrics for sufficiency of the training data and measurement information, more quantitative and principled criteria for both requirements would be useful to determine a priori which flows are good candidates for this method, how much training data is required, and which sensor configurations will sufficiently inform the structure of the flow field. The performance of this method may also be improved with more sophisticated library learning methods Mathelin et al., 2018) or optimal sensor placement strategies (Willcox, 2006; Yildrim et al., 2009; Manohar et al., 2018; Mons et al., 2017) , both of which are active areas of research. Further, there are many ways to formulate and solve the sparse optimization problem (7), and alternative approaches, such as sequentially thresholded least-squares (Zheng et al., 2018) or pursuit algorithms, may outperform 1 regression. In addition, the sparse optimization procedure may be too computationally expensive for some real-time control applications, motivating ongoing work to improve algorithmic efficiency; fortunately, the timescales of the geophysical flows investigated in this work are slow compared with the sparse optimization. Finally, most flows of interest are three-dimensional, and it will be important to demonstrate this method on three-dimensional flows. While it is straightforward to generalize this method to three-dimensional fields, e.g., by the same vectorization approach used for two-dimensional flows, the matrices representing discretized 3D flows can become very large. The main computational cost is due to the optimization problem, which scales with the number of measurements and not the dimensionality of the discretized flow field; however, the number of measurements necessary to sufficiently inform the structure of a complex three-dimensional flow field may lead to prohibitively expensive computations.\nIn the examples considered here, we have shown several advantages which make sparse representation an attractive candidate for flow field reconstruction. In particular we find that reconstruction from sparse representation in a library of training examples is robust to noise and leads to physical flow field estimates. We have shown that this framework can be modified to handle dense sensor noisae and gross measurement corruption. The method can also be extended to turbulent flows by decomposing the spatial domain and seeking localized sparse representations. With this flexibility, sparse representation may provide a powerful tool for estimating complex flow fields in a range of applications.\nSince the kernels are normalized, the local flow field estimatesx j = \u03a6 j \u03a8\u015d j can be combined to form a global estimatex = jx j . The simplest such kernels are the windows used for the mixing layer reconstructions in figure 8c-d, where each kernel has the value 1 within its window and 0 outside.\nFor the Gulf of Mexico data we define 96 points r 1 , r 2 , . . . , r j , r 96 as the kernel centers on a uniform 12 \u00d7 8 grid covering the spatial domain, as in figure 14. Each kernel \u03a6 j is constructed with a radial Gaussian function of the distance from each grid location to the kernel center:\nwhere the width \u03c3 is half the longitudinal distance between successive kernel centers. Values below 10 \u22122 are set to zero, and the normalization factors N (r) are then calculated as the sum of the unweighted values of all kernels\nso that the resulting estimates may be combined in a weighted average. Computationally, each location r is a point on the grid, and so just as the flow field snapshots are arranged into column vectors, the corresponding values of \u03a6 j are the entries in a sparse diagonal matrix. The product \u03a6 j x of a kernel with a discretized flow field is then nonzero only in the region surrounding the kernel center r j . "}]