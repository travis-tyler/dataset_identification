[{"section_title": "", "text": "This technical report documents the methodology of the National Education Longitudinal Study of 1988 (NELS:88) base year survey of eighth graders through the 1992 second followup survey of high school students and dropouts. Chapter 1 begins with an overview and history of the NELS:88 and its database, Chapter 2 contains a description of the data collection instruments. Base year through second followup sample design and weighting procedures are discussed in chapter 3, and chapter 4 describes data collection procedures, schedules, and results. Chapter 5 describes data control and preparation activities, and chapter 6 contains recommendations for future studies. The 18 appendixes contain supplemental information, including Spanish versions of the student and parent questionnaires, completion and nonresponse tables, forms used in conducting the survey, and discussions of the data files. (Contains 10 figures and 22 tables.) (SLD) ******************************************************************************** * Reproductions supplied by EDRS are the best that can be made * * from the original document. Final Methodology Report Tables   Page   Table 2             The first of the NELS projects, the National Longitudinal Study of the High School Class of 1972 (NLS-72), began in the spring of 1972 with a survey of a national probability sample of 19,001 seniors from 1,061 public, secular private, and church-affiliated high schools. The sample was designed to be representative of the approximately three million high school seniors enrolled in more than 17,000 schools in the spring of 1972. Each sample member was asked to complete a student questionnaire and a sixty-nine minute test battery. School administrators were also asked to supply survey data on each student, as well as information about the schools' programs, resources, and grading systems. Five follow-ups, conducted in 1973Five follow-ups, conducted in , 1974Five follow-ups, conducted in , 1976Five follow-ups, conducted in , 1979Five follow-ups, conducted in , and 1986, have been completed."}, {"section_title": "List of", "text": "In addition to background information, the NLS-72 base year and follow-up surveys collected data on respondents' educational activities, such as schools attended, grades received, and degree of satisfaction with their educational institutions. Participants were also asked about work experiences, periods of unemployment, job satisfaction, military service, marital status, and children. Attitudinal information on self-concept, goals, participation in political activities, and ratings of their high schools are other topics for which respondents have supplied information."}, {"section_title": "High School and Beyond of the 1980s: HS&B", "text": "The next major longitudinal study sponsored by NCES was High School and Beyond. HS&B was initiated in order to capture changes that had occurred in education-related and more general social conditions, in federal and state programs, and in the needs and characteristics of students since the time of the earlier survey. Thus, HS&B was designed to maintain the flow of education data to policymakers at all levels who need to base their decisions on data that are reliable, relevant, and current. Base year data collection was conducted in the spring of 1980. Students were selected using a twostage probability sample with schools as the first-stage units and students within schools as the second-stage units. Unlike NLS-72, HS&B included cohorts of both tenth and twelfth graders. Since the base year data collection in 1980, four follow-ups of the HS&B cohorts have been completed: one in the spring of 1982; one in the spring of 1984; one in the spring of 1986, and (for the sophomore cohort only) one in the spring of 1992. The four NELS program cohorts (NLS-72 seniors, the HS&B sophomores and seniors, and NELS:88 eighth graders) are displayed in figure 1-2 according to their initial and subsequent survey years and their modal age at the time of each survey. As illustrated, NLS-72 seniors were first surveyed in 1972 at age eighteen and have been resurveyed five times since, with the last survey occurring in 1986, when these respondents were about thirty-two years of age. The HS&B cohorts have been surveyed at points in time that would permit as much comparison as possible with the time points selected for NLS-72. NELS:88 is also designed to fit into this larger analytical scheme. The NELS:88 first follow-up sophomore class of 1990 parallels the HS&B sophomore class of 1980; similarly, the second follow-up senior class of 1992 will parallel the 1980and 1982HS&B, and 1972 Note, however, that the HS&B 1980 sophomore cohort in 1982 does not strictly constitute a representative sample of the nation's 1982 seniors, but rather a representative sample of 1980 sophomores two years later. Because of the sample freshening that took place in NELS:88 (but not in HS&B), the subset of NELS:88 sample members who were high school seniors in the spring of 1992 are nationally representative of seniors and are wholly comparable to the NLS-72 and HS&B 1980 probability samples of twelfth graders. 1--29 28   NELS:88 Second Follow-Up Final Methodology Report 1.3 The National Education Longitudinal Study of 1988: Overview"}, {"section_title": "20", "text": "The base year of the National Education Longitudinal Study of 1988 (NELS:88) represented the first stage of a major longitudinal effort designed to provide trend data about critical transitions experienced by students as they leave elementary school and progress through high school and into postsecondary institutions or the work force. This study of the 1988 eighth-grade cohort collects data about educational processes and outcomes pertaining to student learning, predictors of dropping out, and school effects on students' access to programs and equal opportunity to learn. The first follow-up in 1990 provided the first opportunity for longitudinal measurement of the 1988 baseline sample. It also provided a comparison point to high school sophomores ten years before, as studied in HS&B. The study captured the population of early dropouts (those who leave school between the end of eighth grade and the end of tenth grade), while monitoring the transition of the student population into secondary schooling. Freshening the NELS:88 sample to represent the tenth-grade class of 1990 makes trend comparisons with the HS&B sophomore cohort possible.' The second follow-up took place in 1992, when most sample members entered the second term of their senior year. The second follow-up provides a culminating measurement of learning in the course of secondary school, and also includes information that facilitates investigation of the transition into the labor force and postsecondary education after high school. The NELS:88 second follow-up resurveyed all students from the eighth-grade cohort including students who were identified as dropouts in 1990, and identified and surveyed those students who left school after the first follow-up. In addition, the freshening process was also implemented in the second follow-up, creating a representative sample of the twelfthgrade class of 1992 and making trend comparisons with the senior cohorts of both NLS-72 and HS&B possible. The third follow-up occurred in 1994, with most sample members in postsecondary education or in the labor market. The goals of the 1994 round were to provide data for trend comparisons with NLS-72 and HS&B, and to continue cross-wave comparisons with previous NELS:88 rounds. The third follow-up permits researchers to assess the effect of eighth-grade and high school curricular experiences on postsecondary education choice. The third follow-up also provides the means by which access of individuals with different backgrounds to quality educational institutions can be examined. The third follow-up facilitates study of the influences of high school education experiences on postsecondary education and employment opportunities and choices. Labor force participation, postsecondary persistence, curricular progress, and family formation are further research topics which are explored by the third follow-up. Additionally, the third follow-up provides a basis for assessing how many dropouts have returned to school and by what route, and measures the access of dropouts to vocational training programs and to other postsecondary institutions. A fourth follow-up is tentatively scheduled to take place in 2000. 2 The process referred to here as \"freshening\" added students who were not in the base year sampling frame, either because they were not in the country or because they were not in eighth grade in the spring term of 1988. The 1990 freshening process provided a representative sample of students enrolled in tenth grade in the spring of 1990. The 1992 freshening process provided a representative sample of students enrolled in twelfth grade in the spring of 1992."}, {"section_title": "5", "text": "NELS:88 Second Follow-Up Final Methodology Report 1.3.1 NELS:88 Study Objectives NELS:88's major features include the planned integration of student, school dropout, school administrator, teacher, and parent studies; the initial concentration on an eighth-grade student cohort with follow-up at two year intervals; the inclusion of supplementary components to support analyses of geographically or demographically distinct subgroups; and the design linkages to previous longitudinal studies and other current studies. Multiple research and policy objectives are addressed through the NELS:88 design. The study is intended to produce a general purpose data set for the development and examination of federal educational policy. Part of its aim is to inform decision makers, education practitioners, and parents about the changes in the operation of the educational system over time, and the effects of various elements of the system on the lives of the individuals who pass through it. Specifically, NELS:88 focuses on a number of interrelated policy issues including: identification of school attributes associated with achievement; the transition of different types of students from eighth grade to secondary school; the transition of secondary students to postsecondary education or the work force; the influence of ability grouping and program type on future educational experiences and achievements; determinants of dropping out of the educational system; and changes in educational practices over time. One of the defining features of NELS:88 is the extensive attention it gives to the role of parents. The second follow-up parent survey gathered data on the effect of parents' attitudes and behaviors on educational or career choices, financial preparation for postsecondary education, the correlates of active parental involvement in the school, and the parent's role in the educational success of their children. Appendix R of this report provides a matrix of key policy issues of education research in relation to the content of the second follow-up student, dropout, school, parent, and teacher instruments. The NELS:88 design enables researchers to conduct analyses on three principal levels: crosswave, cross-sectional at a single time point, and cross-cohort by comparing NELS:88 findings to those of HS&B and NLS-72. The first of these levels provides NELS:88 with its primary objective: to serve the purposes of longitudinal measurement. The sampling and data collection designs give priority to maintaining and surveying a substantial number of base year sample members, as well as to sustaining overlapping but analytically distinct cohorts of sophomores and seniors.3 Users of NELS:88 data can study the effect of a wide variety of factors on students' educational and professional attainment. The longitudinal data gathered from students, and augmented through school administrator, teacher, parent, and academic transcripts, accounts of students' progression and development, facilitate scrutiny of various facets of students' livestheir problems and concerns, their relationships with parents, peers, and teachers, and the characteristics of their schoolsand permit examination of the impact of these factors on social, behavioral, and educational development. The second analytic level within NELS:88 is cross-sectional. By beginning with a cross-section of 1988 eighth graders, following a substantial subsample of these students at two-year intervals, and freshening the 1990 and 1992 samples to obtain representative national cross-sections of tenth and twelfth graders, the study also provides a statistical profile of America's eighth graders, high school sophomores, and high school seniors. Figure 1-3 depicts the components in each wave of NELS:88, while figure 1-4 illustrates the sample design for the base year through the third follow-up.  Finally, NELS:88 has been designed to provide researchers with data for drawing comparisons with previous NCES longitudinal studies. After the release of NELS:88 first follow-up data, researchers were able to conduct trend analyses with the 1980 sophomore cohort of HS&B. With completion of the NELS:88 second follow-up, comparisons may be made among NELS:88, HS&B, and NLS-72 senior cohorts, as well as, through comparison of data from the NELS:88 transcript component with transcript data from HS&B and NAEP, the senior classes of 1982, 1987, 1990, and 1994. To facilitate cross-cohort comparisons, many of the content areas contained in the HS&B base year survey were repeated in each wave of NELS:88, and data processing and file conventions have been kept consistent, to the maximum extent feasible, with HS&B and NLS-72. For users specifically interested in conducting trend analyses of NLS-72, HS&B and NELS:88 data, further information on content and design similarities and differences between these three studies is presented in appendix D of the NELS:88 Second Follow-Up Student User's Manual, and appendix E of the same manual provides information on the specific items which were used across these studies. Appendices M and N of NELS:88 Second Follow-Up Student User's Manual the provide an overview of the content areas of the second follow-up student, dropout, school, parent, and teacher components."}, {"section_title": "Base Year Study and Sample Design", "text": "The base year study design comprised four components: surveys and tests of students, and surveys of school administrators, teachers, and parents. A student questionnaire gathered information about basic background variables and a range of other topics including school work, educational and occupational aspirations, and social relationships. Students also completed a series of curriculum-sensitive cognitive tests to measure educational achievement and cognitive growth between eighth and twelfth grades in four subject areas--reading, mathematics, science, and social studies (history/geography/civics). One parent of each student was asked to respond to a parent survey intended to measure parental aspirations for children, family willingness to commit resources to children's education, the home educational support system, and other family characteristics relevant to achievement. Selected teachers in two of the four subject areas completed a teacher questionnaire designed to collect data about school and teacher characteristics, evaluations of the selected students, course content, and classroom teaching practices. Finally, a school administrator questionnaire was completed by school principals. It gathered descriptive information about the school's teaching staff, the school climate, characteristics of the student body, and school policies and offerings. In the NELS:88 base year, a two-stage stratified probability design was used to select a nationally representative sample of eighth-grade schools and students. Schools constituted the primary sampling unit; the target sample size for schools was 1,032. A pool of 1,032 schools was selected through stratified sampling with probability of selection proportional to eighth-grade size and with oversampling of private schools. A pool of 1,032 replacement schools was selected by the same method. Of the 1,032 initial selections, 30 proved to be ineligible. Of the 1,002 eligible selections, 698 participated. An additional 359 schools (supplied by alternative selections available from the replacement pool) also participated, for a total school sample of 1,057 cooperating schools, of which 1,052 schools (815 public schools and 237 private schools) contributed usable student data. For 1,035 of these 1,052 schools, both student and school administrator data were received. In the NELS:88 base year design, students were the secondary sampling unit. The second stage, student sampling, produced a random selection of 26,432 students among participating sampled schools, resulting in participation by 24,599 spring term 1988 eighth graders. On average, each of the participating schools was represented by twenty-three student participants. Additional 29   9NELS:88 Second Follow-Up Final Methodology Report information about the base year sample design is provided in the NELS:88 Base Year Sample Design Report.'  The first follow-up of NELS:88 comprised the same components as the base year study, with the exception of the parent survey, which was not repeated in the 1990 round. In addition, three new componentsthe dropout study, base year ineligible study, and High School Effectiveness Studywere initiated in the first follow-up, and a freshened sample was added to the student component. As in the base year, students were asked to complete a questionnaire and cognitive test. The cognitive test was designed to measure tenth-grade achievement and cognitive growth between 1988 and 1990 in the subject areas of mathematics, science, reading, and social studies (history/geography/civics). The student questionnaire collected basic background information, and asked students about such topics as their school and home environments, participation in classes and extra-curricular activities, current jobs, their goals and aspirations, and opinions about themselves. Following the base year design, two teachers of each student were asked to complete a teacher questionnaire, and a school administrator questionnaire was completed by school principals. First-time participants in NELS:88including students just added to the cohort through the sample freshening process, base year ineligibles who became eligible in the first follow-up, and base year nonrespondents who did participate in the first follow-upcompleted a new student supplement, containing basic demographic items which were asked in the base year but not repeated in the first follow-up. The first follow-up also surveyed and, when possible, tested youths who had dropped out of school at some point between the spring term of the 1987-88 school year and that of the 1989-90 school year. The dropout questionnaire collected information on a wide range of subjects, including reasons for leaving school, school experiences, absenteeism, family formation, plans for the future, employment, attitudes and self-concept, and home environment. The selection of students was implemented in three steps. The first step of sampling involved the selection of 21,474 students who were in the eighth-grade NELS:88 sample in 1988.5 Because some sophomores in 1990 were not in the country or were not in the eighth grade in the spring term of 1988, the representative subsample of the eighth-grade cohort was augmented through a second step of sampling called freshening. The goal was to provide a representative sample of students enrolled in the tenth grade in the 1989-90 school year. Freshening added 1,229 tenth graders (of whom 1,043 were found to be eligible and retained after final subsampling) who were not contained in the base year sampling frame. A third step stemmed from the base year ineligible (BYD study, which was added to the first follow-up in order to ascertain the 1990 school enrollment status and the 1990 NELS:88 eligibility status of students who were excluded from the base year survey due to a language barrier or physical or mental disability which precluded them from completing a questionnaire and cognitive test. Any eligible students were included in both the first and second follow-up studies. Thus, the 1990 sophomore cohort consists of 1990 sophomores, first follow-up freshened students, and ineligible base year students who were deemed eligible in the first follow-up. Because multilevel microdata carries with it some risk of statistical disclosure of institutional or individual identities, the NELS:88 data have been extensively analyzed to determine which data elements, when used alone, in conjunction with other key variables, or in conjunction with public external sources such as school universe files, have significant disclosure potential. Variables that were found to pose significant disclosure risks were suppressed or altered to remove or substantially reduce such risks. For example, in some cases, continuous variables have been recast as categorical variables, or fine-grained categorical variables have been more grossly recategorized. In a few instances, data elements have been suppressed or changed. Because of this, a particular school or individual student might be characterized in terms of a certain variable on the privileged use version of the NELS:88 data, but be coded to missing on the public files, coded to an adjacent response category, or included in a code which collapsed two or more response categories. These suppressions and recodes have been clearly labeled in the codebooks included in each second follow-up data file user's manual. Refer to chapter V of this report for a complete discussion of the steps implemented to ensure the confidentiality of both schools and students in NELS:88. While confidentiality considerations justify these alterations of the data, some of these protections against disclosure may reduce the analysis potential of certain variables in the data set. For example, when only ranges of percentages are given for a variable, threshold points that may be important for some analyses may be obscured, or nonlinearities in relationships hidden. No matter how thoughtfully continuous variables are transformed into categorical form, different cut points for the categories may be desirable, depending on one's particular analytic purposes. While most suppressed data will have only a negligible effect on most analyses, there are times when the suppressed information is critical. For this reason, NCES also makes privileged use data files available to qualified researchers with a proven need for the data in its privileged use form. To obtain the privileged use data, it is necessary for an organization to obtain a licensure agreement from NCES. The agreement must be signed by the principal investigator and by someone authorized to commit the organization to the legal requirements. In addition, each NELS:88 Second Follow-Up Final Methodology Report of teachers, transitions and articulation practices, involvement of parents, and other practices recommended for middle grades reform. The enhancement questionnaire is reproduced in appendix F of the NELS:88 Second Follow-Up: School Component Data File User's Manual. The enhancement questionnaire was sent to all 1,057 participating base year schools (including five schools later removed from the sample because of loss of usable data in transit). Mail questionnaires were completed by 826 principals and an abbreviated telephone interview by 182 principals. Because of the high response rate, a separate weight was not created for enhancement survey schools. While a very close approximation of weighted school values can be computed by applying BYQWT, weights are missing for 21 schools for which there is an enhancement questionnaire but no spring 1988 school questionnaire. The data file includes the principal's responses, a variable (SOURCEDA) indicating whether the principal completed the mail questionnaire or the abbreviated telephone follow-up, the base year ID (SCH_ID) so that the data can be linked to the other NELS:88 data files; and the base year school weight (BYQWT). 1.6.2 Christian Schools Supplement (CSS) In 1988, a sample of Reformed Christian schools that were members of the Christian Schools International (CSI) Organization was drawn to supplement the NELS:88 base year school sample. The sample was selected from CSI schools with probability proportional to eighth-grade size. Two disproportionately large school units were double-sampled. Of the initially contacted 58 schools, 41 schools agreed to participate. (Due to the double-sampling of the two schools, the number of sampling units was 43.) The student sample drawn from the selected CSI schools constitutes a nationally representative sample of eighth graders attending CSI schools in 1988 and supports both cross-sectional and longitudinal analyses. Sampled students and their parents, teachers, and school administrators were surveyed in the spring of 1988, during the NELS:88 base year. Students completed both the cognitive test battery and the student questionnaire during the in-school survey sessions held in their schools. Base year CSS sample members still enrolled in school, their school administrators, and their parents were surveyed again in the spring of 1992, during the NELS:88 second follow-up. Instruments used in the 1988 and 1992 CSS surveys were identical to those completed in the core NELS:88 base year and second follow-up surveys. (CSI schools also constitute a separately analyzable sampling stratum within the NCES Schools and Staffing Survey.) 1.6.3 Early Graduate Supplement The early graduate supplement to the second follow-up student questionnaire was included for persons who had already completed high school at the time of the second follow-up data collection during the spring of 1992. Specifically, early graduate supplement data are provided for respondents who: completed the main portion of the second follow-up student questionnaire; answered \"Already graduated\" to Q. 6A in the main portion of the questionnaire (\"What grade are you in?\"); and answered at least one item in the early graduate supplement (Q. 114 -Q. 127B of the second follow-up student questionnaire). The NELS:88 supplement paralleled the High School and Beyond (HS&B) early graduate supplement and collected information about when the student graduated, why he or she chose to graduate early and who helped in making the decision and the student's activities since early graduation (continuing his/her education, working, participating in a training program, actively serving in the military, etc.) If  Final Methodology Report the student attended a two-or four-year college or vocational school, additional information was sought about when, where and how often the student attended the school. If the student worked, information about the type and length of employment was requested. The NELS:88 early graduate supplement differs from the HS&B supplement in one respect: NELS:88 included in the early graduate sample sample members who had graduated by alternative means, such as the GED, whereas HS&B did not. Early graduates who earned a GED can be separated from those who earned a high school diploma to compare NELS:88 and HS&B early graduates, using responses to NELS:88 second follow-up student questionnaire item F2S6B. 1.6.4 Cognitive Test Item Data The three cognitive test item files contain raw (unscored) choices selected by test takers in the NELS:88 base year, first follow-up, and second follow-up.' In each of the three waves, subsets of test items were selected from an overall pool for each of the four subject areas (reading, mathematics, science, and history/citizenship/geography) to make up the test forms administered to survey participants in that year. The overlap among the test forms allowed the development of a common score scale that could measure change over time even though participants answered different assortments of test questions at each administration. In the base year, all participants received the same test form. On the basis of their performance in the base year, students were assigned reading and math tests of different average difficulty in the first follow-up in order to increase accuracy of measurement. Similarly, second follow-up reading and math tests were assigned on the basis of performance in the first follow-up. There were two levels of the reading test and three levels of the math test in each of the latter two years. (In the first and second follow-up surveys, freshened students and prior-round nonrespondents were assigned the low-difficulty reading test and the middle-difficulty math test.) Users who have access to the original test booklets may wish to identify the actual test questions that correspond to the positions in the item pool. (Test booklets are available from NCES on written request for approved research; interested users should contact Ralph Lee, 202/219-1732.) Other analyses may simply require knowing the order in which the test items were administered in each form. Documentation accompanying the file, and included in appendix A of this report, shows the actual location in the original booklets of each of the re-ordered items in the file.  The second follow-up universe file includes records for all cases that have been delivered on the NELS:88 base year through second follow-up student-level data files. The universe file includes cases from the base year, first follow-up redelivery, and second follow-up restricted-use student files, the second follow-up restricted-use transcript file, and the second follow-up expanded sample file. (The universe file does not include cases that were in the original first follow-up delivery file that were not included in the first follow-up redelivery file, nor does it include base year or second follow-up Christian School Supplement cases.) Variables on the universe file indicate how students entered the NELS:88 sample and also indicate sample member enrollment and eligibility status in each of the three waves, base year, first follow-up, and second follow-up . 1.6.6 NELS:88 1990/HS&B 1980 HS&B and NELS:88 Mathematics Tests. The HS&B sophomore cohort mathematics test administered in 1980 (and repeated in 1982) comprised thirty-eight items, with twenty-one minutes allowed for completion. The items consisted of quantitative comparisons in which the student indicated which of two quantities is greater, or asserted their equality or the lack of sufficient data to determine which quantity is greater."}, {"section_title": "NELS:88 Second Follow-Up Final Methodology Report", "text": "The NELS:88 first follow-up mathematics test contained forty items, to be completed in 30 minutes. This battery assessed both simple mathematical application skills and more advanced skills of comprehension and problem solving. As in HS&B, only multiple choice tests were administered. However, test items included word problems, graphs, quantitative comparisons (as in NLS-72 and HS&B), and geometric figures. Three versions of the mathematics test were developed for the first follow-up, varying in the level of difficulty. Assignment to a first follow-up mathematics test form was based on the respondent's base year math test results. HS&B-NELS:88 Test Equating. In order to compare the mathematics performance of the 1980 HS&B sophomore cohort with that of the 1990 NELS:88 sophomores, it was necessary to put the 1980 mathematics test scores on the same scale as the 1990 scores. The NELS:88 mathematics test was originally designed to be linked to the HS&B mathematics test scores. This was accomplished by including 16 quantitative comparison items from the HS&B test in the NELS:88 test. The mathematics test was the only cognitive test in the NELS:88 battery that shared sufficient items with its counterpart measure in HS&B to enable a reliable cross-walk between the two scales. The linking was carried out by estimating the item response theory (IRT) parameters for the common items using the NELS:88 sophomore sample and then putting the remaining non-overlapping HS&B items on that scale. Before the fmal linking was carried out, the item traces for the common items were estimated separately for the two populations and compared to insure that they were \"behaving\" similarly in the two populations. A final check on the validity of the equating was carried out by inspecting subpopulation differences among the HS&B students after they were put on the same scale as the NELS:88 cohort. If the linking worked as desired, then the relative differences that were found among the HS&B subpopulations on their original scales should not change when they were put on the new scaling. All subpopulation differences remained relatively invariant, indicating that the linking was successful. In 1994, the IRT scales for all three waves of the survey were recalculated using different procedures. However, the NELS:88-HS&B mathematics test equating scales were nz recalculated. Thus, the NELS:88-HS&B equated math scores are on the same scale as the original NELS:88 scores that were released with the first follow-up data tapes. While they are not comparable to the rescaled scores calculated in 1994, the Pearson correlation coefficients for the original versus the rescaled math test scores are greater than 0.99. The NELS:88-HS&B equated math test scores for the 1980 HS&B sophomore cohort are available as a separate file. 1.6.7 Expanded Sample File The NELS:88 second follow-up expanded sample file was constructed to allow licensed researchers to generate more accurate national dropout rate estimates for the eighth grade cohort as well as more accurate and HS&B-comparable sophomore cohort dropout statistics. In addition, the file can be used to more fully characterize students who were excluded from the NELS:88 base year samplecategories of students who typically have been excluded from national and state assessmentsand to explore the biasing impact on estimates for the ideal target population that stem from ineligibility and exclusion rules. The NCES publication Dropout Rates in the United States: 1992 (NCES 93-464) illustrates one use of the expanded sample file. The methodological report Sample Exclusion in NELS:88: Characteristics of Base Year Ineligible Students; Changes in Eligibility Status After Four Years (NCES 95-724) also illustrates the uses of expanded sample data. Cases on the expanded sample file include the grade 8 and grade 10 cohort members who appear on the NELS:88 core restricted-use files, plus ineligible grade 8 or grade 10 cohort members who have never before appeared on a NELS:88 core restricted-use file, except for the transcript component files. Included in the group of ineligible students appearing on the expanded sample file are base year ineligible (BYI) students who remained ineligible in the first and second follow-ups of NELS:88 and students who were freshened in the first follow-up but were found to be ineligible and remained ineligible in the second follow-up. A number of variables have been specifically constructed for use with the expanded sample and are included on the file, including student and school background variables, enrollment and out-of-sequence indicators, a variable indicating reason for ineligibility for the student survey (if applicable), cohort flags and a statistical weight, F2EXPWT, which is the only weight that can be used with the expanded sample. The enrollment status indicators for the expanded sample, FlENREXP and F2ENREXP, include imputed values for cases with missing enrollment data. Only the variables created specifically for the expanded sample should be used with the sample. See appendix B for a detailed description of the expanded sample and expanded sample composites. 1.6.8 NELS:88 1990 Census Data The school-level NELS:88 1990 Census data files contain selected 1990 zipcode-level Census characteristics for the schools participating in the NELS:88 base year, first follow-up and second follow-up school surveys. Census data aggregated at the zipcode level (from the STF3B zipcode-level Census files) were linked to NELS:88 schools by school zipcode, which does no/ appear on any NELS:88 files. The NELS:88 Census variables are structural characteristics that are intended to approximate the local community surrounding the school. (No empirical mapping of school community boundaries compared to zipcodes was undertaken for NELS:88). In the interest of standardization across zipcodes, the raw counts provided in Census tables have, for many variables, been used to calculate the proportion of zipcode residents displaying a given attribute (for example, the proportion of zipcode residents who are black). Researchers who wish to recalculate raw counts can easily do so using the data provided on the file. four separate variables providing the percentage of zipcode residents living in areas classified as: 1) rural farm; 2) rural not farm; 3) urbanin an urbanized area; or 4) urbannot in an urbanized area; it is not unusual for a single zipcode to include residents with different urbanicity classifications; several ethnicity variables indicating the percentage of zipcode residents who are white, black, American Indian/Eskimo/Aleut, Asian or Pacific Islander, Hispanic (broken down into Mexican, Puerto Rican, Cuban and other Hispanic) or other ethnicity; variables indicating the proportion of zipcode residents above and below the poverty level, by 12 age categories, as well as variables indicating the proportion of zipcode residents with income-to-poverty ratios within defined ranges; median income for the zipcode.\nResearchers should note that, instead of attempting to characterize each school's zipcode as urban or suburban or rural, as do the NELS:88 urbanicity variables, the Census scheme recognizes that diversity occurs even within small areas. It is not unusual to find that a single zipcode encompasses residents with different urbanicity classifications; for example, one zipcode may include some residents classified as ruralnot farm and others classified as urban-not in an urbanized area. See appendix C for additional information on the NELS:88 variables derived from 1990 Census data. Three special student-level residential zipcode Census variable files have been created (1988, 1990, and 1992), and are available to licensed users on approval of special application. The data files contain 715 variables from 1990 Census Summary Tape File 3B (STF3B) linked to home zipcodes for members of the eighth grade cohort in 1988, 1990, and 1992. There are a variety of computed measures on population characteristics, labor force participation, education, fertility and marriage, and income/poverty. A few examples of some of the specific variables taken from the 1990 Census at the residence zip code level include: percent of families in poverty, median family income, percent of 25 + year olds graduated from college, percent of males unemployed (overall and by sex and race), percent of mothers with children in the labor force, ratio of single males to single females, percent of births to women under age 20, and so on. Primarily because zip code boundaries may change over time, there are a few schools (55 out of 2,487) and students (1,619 out of 64,000 records) that could not be matched to the Census variables. In addition to the three files containing Census variables for the 1988-92 samples, there is a separate privileged use file that links student ID to residential zipcode. This file can be used by researchers to make their own selection of Census measures."}, {"section_title": "NELS:88 QED-CCD-SDDB School Link Files", "text": "The NELS:88 QED-CCD-SDDB school link files contain link variables that permit licensed researchers to merge the three waves of NELS:88 core school data with additional contextual variables on the school and district frames available from Quality Education Data (QED), Inc., and NCES (the Common Core of Data [CCD] and the School District Data Book [SDDB]). The QED frames include records for public and private schools and public districts and Catholic dioceses. The CCD frame includes records for public schools and districts, while the SDDB files are at the public district (agency) level. A wide range of information is available on the QED and CCD files. The QED files include information on grade span and enrollment size, the number of schools in a public district, instructional dollars per pupil, ethnic composition, urbanicity, and Orshansky percentile. FIPS county and metropolitan statistical area (MSA) codes are also provided. Variables that appear on CCD school and district files include: number of teachers per school, school enrollment, school racial/ethnic distribution, diplomas awarded, selected 1990 Census variables from the SDDB (available at the district level only) and financial information for districts extracted from the Survey of School District Finances data files. The School District Data Book (SDDB), a CD-ROM product, is an unprecedented NCES resource for education research that provides thousands of 1990 Census variables and other data for all 15,274 public school districts in the United States. In collaboration with the Council of Chief State School Officers and the States, NCES contracted with the Census Bureau to map the geography of public school districts to the Census TIGER files. The 1990 Census variables were then retabulated within those geographic boundaries. Results are available at school district, county (FIPS state and county codes are provided), state and national levels. The SDDB also includes CCD data for the academic year 1989-1990 and data from the 1989-1990 Survey of School District Finances. The SDDB CD-ROM includes software for manipulating the data. See appendix D for detailed information on the NELS:88 QED-CCD-SDDB link variables."}, {"section_title": "NELS:88 Second Follow-Up", "text": "Final Methodology Report 1.6.10 NELS:88 QED District and School Files A total of six district and school filesone school and one district file per wavederived from files purchased from Quality Education Data (QED) of Denver, Colorado are available on the 1996 NELS:88 CD-ROM or on magnetic media. These files contain variables describing the characteristics of the public districts, Catholic dioceses and schools of all types that participated in the NELS:88 base year, first follow-up and second follow-up surveys. The QED files include information on grade span and enrollment size, the number of schools in a public district and instructional dollars per pupil. (QED collects and sells a broad range of information on all schools in the United States, including private schools. In addition to the research community, the QED client base includes purveyors of educational goods such as textbook publishers and hardware/software vendors.) The QED data may be merged with the 1996 NELS:88 BY-F2 restricted-use school file, and subsequently the student-level file, for further investigation of contextual effects in the NELS:88 sample. The QED files may be merged with previously-released NELS:88 files using the NELS:88 QED-CCD-SDDB link file as a crosswalk. The QED files have played an important role in NELS:88. The NELS:88 base year district/diocesan and school sampling frames for institutions with eighth grades were compiled by QED. The files used in the NELS:88 base year were leased from QED in 1987. In 1989, QED files were leased for the first follow-up, and in 1991 for the second follow-up. In the first and second follow-ups, the QED files were used not for sampling but were used as sources of contacting and locating information for districts and schools to which sampled NELS:88 students had dispersed by 1990 and 1992. QED itself maintains only files with current information; the files used in NELS:88 are no longer available from QED. QED has generously given NCES and NORC permission to release the QED data for NELS:88 schools and their districts/dioceses to researchers. Detailed documentation on the NELS:88 QED district and school files is included as appendix E. 1.6.11 Files Not Included as Part of the NELS:88 Extended Database. Supplemental data (additional cases and sometimes additional questionnaire items) collected as part of state augmentations of the NELS:88 sample are not included on any NCES release. As indicated in 1. 6.9 above, special files linking student 1988-92 residential zipcodes to 1990 census data on population characteristics, labor force participation, education, fertility and marriage, and income and poverty, have not been included on the CD-ROM privileged use release. Nor are the NELS:88 raw weights, or base year teacher transcript files included on the NELS:88 extended data base CD-ROM. The raw weights for NELS:88 (design weights prior to nonresponse adjustment) are of potential interest for methodological analyses, while the college transcripts of base year science and math teachers have considerable analytic value. Both are described below. NELS:88 Raw Weights. The data file raw wts.dat (September 1995) provides a single source for all of the raw weights (design weights prior to nonresponse adjustment) that were used in the creation of NELS:88 final weightsthe nonresponse-adjusted student cross-sectional and panel weights for the base year through third follow-up rounds of NELS:88. In addition, the set of status variables known as the \"universe variables\" is included, along with IDs for all sample members who were included in the 1996 base year through second follow-up privileged use delivery. There are ten raw weights created for NELS:88. STRAVVWT is the base year raw weight and is non-zero for students who were in the base year sample; this weight was used in the creation of the student final weight, BYQWT. F1RAWWT is the first follow-up basic raw weight. Freshened students received NELS:88 Second Follow-Up Final Methodology Report the F1RAWWT value of the student they were linked to in the freshening process. This weight was used in the creation of the first follow-up student final weights, F1QWT and F1PNLWT. F2RAWWT was the basic second follow-up raw student weight. This weight was used in the creation of F2QWT, F2PNLWT, and F2F1PNWT. Additional raw weights were created in the second follow-up to accommodate the contextual sample, the parent survey, and the transcript component. These weights are (respectively) F2RAWWTC, F2RAWWTP, and F2RAWWTT. In the third follow-up, the basic student raw weight was F3RAVVWT, used to create the final (nonresponse-adjusted) weights F3QWT, F3PNLWT, F3F1PNWT, and F3F2PNWT. To accommodate the contextual (student linked to teacher-principal data), parent, and transcript sample, three further raw weights were created: F3RAWWTC, F3RAWWTP, and F3RAWWTT. Base Year Math-Science Teacher Postsecondary Education Transcripts. The purpose of the teacher transcript component of the NELS:88 base year teacher survey was to significantly extend the available measures on eighth grade science and mathematics teachers' academic background and performance and pedagogical preparation. This component of NELS:88 was funded by the National Science Foundation and data collection was carried out by NORC's base year subcontractor, Westat, Inc. Information was abstracted from postsecondary transcripts about degrees (degree earned, cumulative grade point average, receipt of honors at graduation, month and year in which degree was earned), majors and minors, terms (including semester vs. quarter, start/end dates, grading system, and so on), and courses (department, course title, credits earned, type of grade, grade received). Majors, departments and courses were coded (normally to two digits only though to four digits for math or science courses) based on the Classification of Instructional Programs (CIP). Eight separate files are provided within the databasefour files for the 737 science teachers and four files for the 1,066 mathematics teachers. The four files comprise degree files (containing general information about the teacher), major files (describing each major and minor), term files (providing information on each term), and course files (containing information on each course taken. The database is organized by teacher ID. A complete set of linking IDs was developed to allow for merges with the NELS:88 student and teacher data files. The teacher transcript files are not included in the NELS:88 extended database available in electronic codebook on CD-ROM. The National Science Foundation also sponsored, in the NELS:88 Second Follow-Up, a validity study of NELS:88 teacher reports on instructional content, strategy and goals. While no analysis files are available from this study, results are summarized in Validating National Curriculum Indicators (L. Burstein et al., RAND, 1995 \nFinal Methodology Report corrected t-value of 2.475. However, applying this method using SUDAAN-calculated design effects will not yield the same corrected t-value for all subgroups because the two design effects treat oversampling differently. Thus, both for this reason and in order to allow analysts to compare design effects across all rounds of NELS:88, design effects calculated using both the conditional and unconditional methods are included in tables in the second follow-up tables in appendix F.\nFinal Methodology Report For public schools the next step involved contacting the Chief State School Officer (usually the state Superintendent of Schools) of each state to explain the objectives of the study and the data collection procedures, especially those for protecting individual and institutional confidentiality. Once approval was obtained at the state level, contact was made with district superintendents and, upon receipt of district approval, contact was made with the school principals. Wherever selected private schools were organized into an administrative hierarchy, for example, Catholic school dioceses, a \"courtesy\" call to request permission to contact the principal of the school was placed at the higher level before the school principal or other chief administrator was actually approached. Within each cooperating school, principals were asked to designate a school coordinator who would serve as a liaison between NORC staff and selected respondentsthe school administrator, students, teachers, and parents. The school coordinator, who was often a guidance counselor or senior teacher, but sometimes the principal or assistant principal, handled all requests for data and materials, as well as all logistical arrangements for data collection on the school premises. Included among these responsibilities was annotating the list of eligible students to identify students whose physical or learning handicaps or linguistic disabilities would preclude participation in the survey. Coordinators were also asked to classify all eligible students as Hispanic, Asian-Pacific Islander, or \"other\" (neither Hispanic nor Asian-Pacific Islander), and to distribute parental permission forms to sampled students. Parents who initially refused to grant permission for their child to participate in the study, but who later consented when contacted by an NORC representative, usually allowed their child to complete a questionnaire by telephone. Given the mode of administration, test data were not collected for these students. NORC organized an Orientation Day for 158 schools that requested it or for schools that were deemed likely to particularly benefit from it.' The Orientation Day was usually scheduled for a day one or two weeks prior to the administration of the student questionnaire and tests. During the orientation, sampled students were informed about the objectives of NELS:88, its voluntary nature, and the measures to be used to ensure respondent confidentiality. Students were also briefed about the tasks and procedures that would be followed in administering the questionnaire and tests. Base year student data were collected from students\" in the core and state augmentation sample schools between February 1 and June 30, 1988. Selected eighth graders within each school were gathered in a group session on the scheduled Survey Day. Two NORC field staff members, a \"team leader\" and a clerical assistant, were responsible for overseeing the administration of the questionnaires and tests during the planned session.\nFinal Methodology Report Following telephone prompting of nonresponding parents, interviewers attempted to administer the parent questionnaire over the telephone. If an interviewer was unable to complete the interview over the telephone, the he or she made a personal visit to the respondent to conduct a face-to-face interview.\nFinal Methodology Report 4.3.2 Second Follow-Up Dropout Survey The NELS:88 second follow-up dropout survey sought to interview all sample members who had left school prior to graduation, including both first follow-up dropouts who had not returned to school and sample members who dropped out after the first follow-up. All sample members appear on the second follow-up student data file regardless of their spring 1992 enrollment status. Basic classification variables and test data appear for both students and dropouts, though dropout questionnaire data appear separately on the dropout component data file. School Enrollment Classification and Data Collection. In order to determine which sample members were eligible to complete a dropout questionnaire, school enrollment status was determined for all sample members during the spring of 1992. Four enrollment categories were identified. The first category included high school students who were enrolled in a school culminating in a high school diploma. These students were administered the student questionnaire and, when possible, the cognitive test battery. Early graduates were included in this category, and were asked to report retrospectively on the school from which they graduated and to complete supplemental questions about their reasons for graduating early. The second category encompassed sample members who dropped out of high school but later reenrolled in a high school program to obtain a high school diploma. These sample members were administered the student questionnaire and, when possible, the cognitive test battery. The third category contained sample members who dropped out of high school but subsequently pursued an equivalent to a high school diploma, usually the General Educational Development test (GED). If an alternative completer had finished the requirements of his or her equivalency program (e.g. passed the GED test), the individual was classified as a \"completer\" (in effect, an early graduate by alternative means) and the student questionnaire (including the early graduate supplement) was administered. If the alternative completer had not yet fulfilled the requirements for certification, the sample member was administered a dropout questionnaire. In both cases, the cognitive test battery was also administered when possible. Dropouts constituted the fourth enrollment category. These sample members had left their high school by the spring of 1992 and were not working toward an alternative certification. Dropouts were administered a dropout questionnaire and, when possible, the cognitive test battery. Regardless of whether a dropout completed a student or dropout questionnaire, data collection efforts for the dropout component of the second follow-up were similar to those in the first follow-up survey. Interviewers attempted to survey most dropouts in off-campus survey sessions with testing conditions similar to in-school sessions. For analytical purposes, sample members classified as alternative completers can be included or compared with either high school completers or dropouts. Additionally, alternative completers can be examined separately, depending on the needs of the analyst.'\" For a complete description of the dropout component, see the NELS:88 Second Follow-Up: Dropout Component Data File User's Manual. 45 Longitudinal data from the Department of Labor's NLSY79 surveys suggest that GED-holders do not fare as well in the labor market as high school diploma-holders (Cameron & Heckman, Journal of Labor Economics, 11 [11,1993) though they do fare modestly better than dropouts (Murnane, Willett & Boudett, Educational Evaluation and Policy Analysis, 17 [21,1995 The Followback Study of Excluded Students of the NELS:88 second follow-up attempted to reassess the eligibility status and ascertain the enrollment status of students who: 1) had been excluded because of linguistic, mental, or physical obstacles to participation when the baseline sample of eighth graders was drawn in the 1987-88 school year, were subsampled into the Base Year Ineligibles Study in the first followup, and were ineligible for the first follow-up survey; 2) were eligible in the base year but became ineligible in the first follow-up; or, 3) were identified as ineligible when selected through the freshening process in the first follow-up. Eligibility information was gathered for 94.7 percent of the excluded sample members. For excluded students who were identified as eligible, second follow-up student or dropout questionnaires were administered either in-person or over the telephone. Cognitive tests were administered to a small percentage of these students. For students who remained ineligible, school enrollment status and other key characteristics were obtained. For eligibility and completion rate data, see  (Ingels, 1996; NCES 96-723)."}, {"section_title": "II. Data Collection Instruments", "text": "This chapter provides a brief description of the form and content of the student, new student supplement, dropout, school administrator, teacher, and parent survey instruments and cognitive tests used in the base year and first and second follow-ups. The academic transcript component of the second followup is also described. Copies of the NELS:88 questionnaires and crosswalks of items repeated across survey rounds, can be found in the appendices to the NELS:88 data file user's manuals. Appendices K through N of this report contain copies of the Spanish-language versions of the second follow-up student, dropout, and parent questionnaires and new student supplement, which were not included in the second follow-up data file user's manuals. A content by process matrix of the base year through second follow-up cognitive tests is provided later in this chapter. A summary of second follow-up research constructs and corresponding questionnaire content appears as appendix R. (For base year and first follow-up research constructs and questionnaire content, see the respective user's manuals.) 2.1"}, {"section_title": "Instrument Development", "text": "The NELS:88 data collection instruments were similar in content and form across all three survey waves. The base year instruments consisted of a student questionnaire and cognitive tests and parent, teacher, and school administrator questionnaires. All of these instruments, with the exception of the parent questionnaire, were enhanced and administered in the first and second follow-ups; two new instruments, the dropout questionnaire and the new student supplement (designed to elicit demographic information from newly freshened students or base year nonrespondents) were developed for the first follow-up and enhanced for the second follow-up. A parent questionnaire was created for the second follow-up, but not for the first follow-up. The second follow-up also included a transcript component. The figure below summarizes the instrumentation for each survey wave.  Questionnaires were designed to meet the longitudinal goals of the study; items were chosen based on their utility in predicting or explaining future outcomes as measured in later survey waves. All of the questionnaires employed in the base year, first follow-up, and second follow-up surveys were framed to provide continuity and consistency with earlier NCES education longitudinal studies, as well as to address new areas of policy concern and to reflect recent directions in theory. Where appropriate, NELS:88 drew test and questionnaire content from NLS-72, HS&B, and other NCES studies, such as the National Assessment of Educational Progress (NAEP), the Second International Math Study (SIMS), and the Schools and Staffing Study (SASS), to ensure a common standard of measurement that would permit comparisons with other important data sources, and maximize the utility of NELS:88 data. For example, NELS:88 mathematics tests were designed so that NELS:88 and NAEP test scores can be equated, and so that HS&B and NELS:88 mathematics test results can be equated as well. Crosswalks illustrating the item overlap between the NELS:88 questionnaires and the HS&B and NLS-72 instruments can be found in the NELS:88 data file user's manuals for the rounds and components of interest. In each round of NELS:88, a field test of data collection procedures and instruments was conducted one year prior to the main study. The field test played a key role in the development of survey instruments and procedures for the main study. Data from the field test were used to inform planning for the main study, and the analysis of field test data was also used to improve the measurement properties of test and questionnaire items and to identify instrument items which needed to be modified or deleted for reasons of instrument length or item format. Detailed descriptions of the base year and first follow-up field tests can be found in the Field In the base year, all sample members completed a student questionnaire. In the first and second follow-ups, sample members who were enrolled in school during the spring term of the survey year (first follow-up: 1989-90 school year; second follow-up: [1991][1992] were administered a student questionnaire, either at an in-school or off-campus survey session. In the second follow-up, sample members who had left school but had already passed the General Educational Development test (GED) or had obtained some other equivalency certification were also eligible to complete the student questionnaire. In the first followup, these sample members completed the dropout questionnaire. The first and second follow-up student questionnaires were available in both English and Spanish, while only an English language version of the base year questionnaire was available.2 2 Dowd, K. et al.;v. 1;1991;Chicago: NORC. ERIC ED 335-418. Excluding the base year ineligible students who were reclassified as eligible in the first follow-up, nineteen students completed the Spanish-language questionnaire in the NELS:88 first follow-up. Eight dropouts and 41 students completed the Spanish-language questionnaire in the second follow-up. Because of the small numbers of questionnaires completed in Spanish, flags were not created to identify these cases. The percentage of questionnaires completed in Spanish in 1990 and 1992 is similar to the percentage of HS&B respondents who opted to complete Spanish-language questionnaires in 1980 and 1982."}, {"section_title": "26", "text": ""}, {"section_title": "4C", "text": "NELS:88 Second Follow-Up Final Methodology Report The sixty-minute, self-administered student questionnaire used in each wave collected information on a wide range of topics, including: Information collected in the base year and in the second follow-up provide baselines for the study of two important transitions experienced by the NELS:88 cohort: the transition from elementary or middle school to high school (baseline = base year), and the transition to postsecondary education or entry into the labor market (baseline = second follow-up). In the second follow-up, the student questionnaire was adapted for telephone administration. The adaptation of the questionnaire was guided by the need to preserve each question's original meaning while wording each question so that it made sense when read aloud. Two abbreviated versions of the questionnaire were created. One version excluded a small number of questions which did not lend themselves to telephone administration. A second version consisted mainly of locator items and key questions and was administered to sample members who explicitly refused to complete the full-length instrument. A small percentage of abbreviated questionnaires were completed by personal interview."}, {"section_title": "Base Year through Second Follow-Up Cognitive Test Batteries", "text": "In addition to the student questionnaire, students completed a series of cognitive tests in each wave at their in-school or off -campus survey sessions. The combined tests covered four subject areas and included 116 items to be completed in 85 minutes. The cognitive tests are briefly described below: Reading Comprehension (21 questions, 21 minutes) This subtest contained five short reading passages or pairs of passages, with three to five questions about the content of each. Questions encompassed understanding the meaning of words in context, identifying figures of speech, interpreting the author's perspective, and evaluating the passage as a whole. One version of the reading test was developed in the base year, and two versions were administered in the first and second follow-up."}, {"section_title": "Mathematics (40 questions, 30 minutes)", "text": "Test items included word problems, graphs, equations, quantitative comparisons, and geometric figures. Some questions could be answered by simple application of skills or knowledge, others required the student to demonstrate a more advanced level of comprehension and/or problem solving. One version of the mathematics test was developed in the base year, and three versions were administered in the first and second follow-up. p1   27NELS:88 Second Follow-Up Final Methodology Report Science (25 questions, 20 minutes) The science test contained questions drawn from the fields of life science, earth science, and physical science /chemistry. Emphasis was placed on understanding of underlying concepts rather than retention of isolated facts. History/Citizenship/Geography (30 questions, 14 minutes) American history questions addressed important issues and events in political and economic history from colonial times through the recent past. Citizenship items included questions on the workings of the federal government and the rights and obligations of citizens. The geography questions touched on patterns of settlement and food production shared by various societies. NORC's subcontractor, the Educational Testing Service (ETS), developed the cognitive test batteries for all three waves. One cognitive test battery form was used in the base year, while six forms were produced for both the first and second follow-ups, each comprising a different combination of mathematics and reading difficulty levels. Each sample member's test form was determined by his or her scores on the base year and/or first follow-up mathematics and reading tests; freshened students and priorround nonrespondents received the intermediate version of the cognitive test battery. The purpose of the multilevel design of the first and second follow-up cognitive test batteries was to guard against ceiling and floor effects which may occur when testing must span four years of schooling. This adaptive approach tailors the difficulty of the reading and mathematics tests to the ability of the respondent, thereby leading, given limitations in testing time, to a more accurate measurement than a single level design. Psychometric properties of the cognitive tests are discussed in the Psychometric Report for the NELS:88 Base Year Test Battery, the NELS:88 First Follow-Up Final Technical Report and the NELS:88 Base Year Through Second Follow-Up Psychometric Report, all of which can be obtained from NCES. The diagram below (table 2.2.2) presents the content by process specifications for the NELS:88 achievement battery comprising cognitive tests in reading, mathematics, science, and social studies."}, {"section_title": "First and Second Follow-Up Dropout Questionnaires", "text": "In the first follow-up survey, the dropout questionnaire was administered to sample members who, according to data gathered through administration of a status screener, were not in an academic program leading to a high school diploma; this group included sample members who had received a GED or other alternative certification. In the second follow-up, the dropout questionnaire was completed by sample members who were not enrolled in a diploma-granting program and who furthermore had not obtained a GED or other alternative certification. Sample members with a GED or other certification completed the second follow-up student questionnaire and early graduate supplement. The hour-long, self-administered dropout questionnaire was normally completed with an interviewer present, at either a group or single survey session. The second follow-up instrument was available in both English and Spanish; the first follow-up questionnaire was available only in English.   The first and second follow-up dropout questionnaires collected data about the following areas: the last school attended by the sample member and the school's climate reasons for leaving school, and actions school personnel, parents, and friends took when the respondent stopped going to school the sample member's likelihood of returning to and graduating from high school the sample member's current activities, employment history, and future plans The dropout questionnaire was designed to facilitate comparisons with the NELS:88 first and second follow-up student questionnaires and the HS&B 1982 dropout questionnaire. Item overlap between the NELS:88 dropout and student questionnaires permits users to contrast for dropouts and students factors such as school environment, family life, aspirations, and self-perceptions. The overlap of 1982 and 1992 dropout items facilitates comparison of contemporary dropouts with those of a decade before (see Ingels and Dowd: Conducting Trend Analyses of HS&B and NELS:88 Sophomore Cohort Dropouts, NCES, 1995). In both survey waves, the dropout questionnaire was adapted for telephone administration. The adaptation of the questionnaire was guided by the need to preserve each question's original meaning while wording each question so that it made sense when read aloud. In the second follow-up, two abbreviated versions of the questionnaire were created. One version excluded a small number of questions which did not lend themselves to telephone administration. A second version consisted mainly of locator items and key questions and was administered to sample members who explicitly refused to complete the full-length instrument. A small percentage of abbreviated questionnaires were completed by personal interview in the second follow-up. In the first follow-up, only one abbreviated version of the questionnaire was developed and administered. In both rounds dropouts also completed when possible the 85-minute cognitive test battery described in section 2.2.2. Because of the difficulty in collecting test data from dropouts, and because data from many dropouts were collected in telephone interviews which precluded testing, the NELS:88 second follow-up achieved a comparatively low 41.7 percent weighted cognitive test completion rate for dropouts."}, {"section_title": "First and Second Follow-Up New Student Supplements", "text": "In the first and second follow-up surveys, first-time NELS:88 participantsdue to freshening or previous ineligibility or nonparticipationcompleted the new student supplement questionnaire, which was available in English and Spanish. In the second follow-up, new student supplement data were also obtained for a number of first follow-up freshened students who had completed a first follow-up student questionnaire but had not completed a new student supplement in 1990. The self-administered supplement took approximately fifteen minutes to complete, and contained questions that gathered basic demographic information (such as birthdate, sex, family socioeconomic status, and race /ethnicity) about students and their families which was gathered by the base year questionnaire, but not repeated in the student questionnaires for later rounds. The new student supplement was available in English and Spanish. such as the GED prior to data collection in the spring term of 1992 completed the early graduate supplement to the second follow-up student questionnaire. The intent of this supplement was to document the reasons for and the circumstances of early graduation, the adjustments required to finish early, and respondents' activities compared with those of other school survey members. The items for the NELS:88 early graduate supplement were modeled on those used in the HS&B sophomore cohort early graduate supplement administered in the HS&B first follow-up in 1982."}, {"section_title": "Base Year through Second Follow-Up School Administrator Questionnaires", "text": "The primary purpose of the school administrator questionnaire was to gather general descriptive information about the educational setting and environment associated with the individual students who were selected for participation in NELS:88. This school information describes the overall academic climate in terms of specific school practices and policies as well as enrollments and educational offerings. The information obtained through the school administrator questionnaire provides supplemental data to that provided by the student questionnaire so that student outcomes can be considered in terms of school measures. The NELS:88 base year school survey provided a national probability sample of 1988 eighthgrade schools and a stand-alone school data set. Because the first and second follow-up school samples do not constitute a national probability sample of schools, the first follow-up and second follow-up school administrator data should be used only to supplement student-level analyses. In each survey wave, the self-administered school administrator questionnaire (forty minutes in length in the base year, sixty minutes in the first follow-up, and forty-five minutes in the second follow-up) was completed by the school principal, headmaster, or other knowledgeable school official designated by the school administrator of NELS:88 schools. (In the first follow-up, an abbreviated version of the questionnaire was also designed for telephone administration to nonresponding principals.) The content areas in the base year through second follow-up questionnaires were similar. Topics covered by the questionnaires include: General school characteristics, such as grade span, school and twelfth-grade enrollment sizes, and school control and demographic characteristics. General student characteristics for the modal grade of the survey cohort, including average daily attendance rates, ethnic and racial composition, percentage of students with limited English proficiency, and numbers of students receiving special school services. Teaching staff characteristics encompassing such areas as the number of full-time and part-time faculty, departmentalization of faculty, salary levels, and evaluation of teachers. School policies and programs including requirements for minimum competency and proficiency tests, and programs for language minority students. School governance and climate such as administration practices, school reforms, types of parental involvement, student behavioral problems within school, and areas of principal's control. The school administrator questionnaire was designed so that the first several sections could be answered either by the school principal or by a designee who was able to provide the requested information. Only the principal could answer the last section, which asked for his or her subjective opinions regarding the school environment."}, {"section_title": "Base Year through Second Follow-up Teacher Questionnaires", "text": "The NELS:88 teacher component was designed to provide teacher information that can be used to analyze the behaviors and outcomes of the student sample, including the effects of teaching on longitudinal student outcomes. The design of this component does not provide stand-alone analysis samples of teachers, but instead permits specific teacher characteristics and practices to be directly related to the learning context and educational outcomes of sampled students. The teacher questionnaire is the critical instrument for investigating the student's specific learning environment. In both the base year and first follow-up, a forty-five minute self-administered questionnaire was completed by selected teachers responsible for instructing sampled students in two of the four cognitive test subjects: mathematics, science, English, and history. In the first follow-up, the teachers of each sample member were chosen when possible from the same two cognitive test areas that were chosen for that student in the base year. In some cases, however, students who were not enrolled in classes in the same subject areas as the base year were evaluated by teachers in another one of the four subjects. In the second follow-up teacher component, a thirty-minute questionnaire was collected for only one of two cognitive test subjects, mathematics or science, if the student was enrolled in a class in one of the subjects. In all three survey waves, teachers were asked to respond to the questionnaire items in relation to a specific list of sampled students enrolled in their classes. The teacher questionnaire was designed to illuminate questions of the quality, equality, and diversity of educational opportunity by obtaining information in the following four content areas: Teacher's assessment of the student's school-related behavior and academic performance, educational and career plans and goals. Respondents completed this section with respect to the sample members they instructed in a particular subject. Information about the class the teacher taught to the sample member (e.g., track assignments, instructional methods, homework assignments, and curricular contents). This section of the instrument included classroom topic coverage items (\"opportunity to learn\" items) that articulate with the cognitive tests. Information about the school social climate and organizational culture (e.g., teacher autonomy, participation in determining school policy, and relationships with the principal). Information about the teacher's background and activities (e.g., academic training, subject areas of instruction, years of teaching experience, and participation in professional growth activities). A validation study was conducted of NELS:88 second follow-up teacher reports on instructional content, instructional strategy and goals (Burstein et al., 1995). Teachers completed daily logs over a five week period, describing their instructional practices; copies of their textbooks were obtained; and artifacts such as homework, quizzes, classroom exercises, projects, and exams were collected and coded. This information was compared to survey responses. The authors found that curricular topics are reported more  Final Methodology Report accurately for upper-level than for lower-level courses; that survey data \"reveal reasonably accurately whether a topic has been taught not at all, for only a few periods, for a week or two, or for several weeks.\" They found that survey data \"present an accurate picture of the instructional strategies used most often by teachers, and they provide some indication of how teachers combine strategies during instruction.\" The authors' analysis suggested that instructional goals, however, \"cannot be validly measured through national surveys of teachers.\""}, {"section_title": "Base Year and Second Follow-up Parent Questionnaires", "text": "The self-administered parent questionnaire was designed to collect information from parents about factors that influence educational attainment and participation. The objective of the parent questionnaire was to provide data that could be used primarily in the analysis of student behaviors and outcomes, and only secondarily as a data set by itself. The questions focused on family background and socioeconomic characteristics, and on the character of the home educational support system. In addition, the parent instrument collected data related to parental behaviors and circumstances with which the student may not be familiar, such as parental education and occupation, and contained more sensitive questions about income, postsecondary educational costs and financial aid decisions, and religious affiliation. In both the base year and the second follow-up, the parent questionnaire instructed the parent or guardian who was most knowledgeable about the sample member's educational activities and related behaviors to complete the questionnaire. Accordingly, the parent respondent was self-selected. The parent questionnaire is divided into the following thematic areas: Information about the family's background. Base year and second follow-up. In this section of the questionnaire respondents identified their relationship with the student or dropout sample member, provided data on the family size and composition, and answered questions about their employment situation and occupation, race, and language background and skills. Information about the teenager's school life. Base year and second follow-up. This section elicited parental knowledge of key characteristics of the teenager's educational situation and collected data on the forms of interaction between the school and parent. The teenager's family life. Base year and second follow-up. This section of the questionnaire asked parents about the decision making process within the household and the kinds of interaction between the respondent and teenager. Included wee sensitive questions about community life and drug and alcohol use by the teenager. Opinions about the teenager's school. Base year only. The teenager's postsecondary plans. Second follow-up only. Parental aspirations for the teenager, preparations for postsecondary education, and plans for the teenager's transition to the workforce were covered in this section. The teenagers plans for the future. Second follow-up only. Parental educational aspirations for the teenager were covered in this section. Financial information and educational costs. Items about family income and fmancial preparations for the teenager's postsecondary education were asked in this section. NELS:88 Second Follow-Up Final Methodology Report Supplemental questions for parents new to NELS:88 in the second follow-up. Second follow-up only. The final section of the second follow-up parent questionnaire was administered only to parents who had not participated in the base year parent survey either because the parent or guardian was a base year nonrespondent or because the student was added to the sample in the first or second follow-up. This section included a number of questions asked in the base year parent survey for which new data were not required from base year respondents. These items covered family characteristics, size, and composition in 1988, parent education, and parent age. In the base year, a small number of parents were interviewed by telephone. In the second followup, a greater proportion of parents completed telephone interviews. In both surveys, a number of steps were taken to minimize mode effects. Interviewers were trained to adapt questionnaire items so that they were intelligible when read over the telephone, and parents were asked to read along in the questionnaire during the interview if they had a copy of the self-administered questionnaire."}, {"section_title": "Second Follow-up Transcript Component", "text": "In the second follow-up, high school transcripts were collected for members of the contextual sample (students for whom contextual school and teacher data were collected), all eligible sample members who were dropouts (including GED recipients) or early graduates, and sample members who were in the twelfth grade in 1992 and ineligible for all three waves of NELS:88. The collection of high school transcripts facilitates two important research efforts: the validation of certain dataincluding high school coursetaking, course grades, and attendance dataprovided by sample members in their responses to first follow-up and second follow-up questionnaires; and, the investigation of coursetaking patterns by sample member characteristics, and the relationship of such patterns to sample members' postsecondary activities and achievement. The NELS:88 high school transcript study was conducted so that comparability would be maintained with the HS&B andNAEP 1987, 1990, and 1994 transcript studies; on using the various transcript data sets for trend analysis, see Ingels and Taylor, Conducting Cross-Cohort Comparisons Using HS&B, NAEP, and NELS:88 Academic Transcript Data, NCES 1995. The following data elements were abstracted from transcripts: Course-level items (for courses taken in grades 9 through 12) course title, department, and number; year, grade level, and term course taken; number of credits earned; and grade awarded. In the processing of transcripts, CSSC (Classification of Secondary School Courses) codes were assigned to the high school courses taken by sample members, and a number of derived variables were constructed from transcript data. A matrix of NELS:88 second follow-up policy research areas, measurement constructs, and questionnaire variables appears as appendix R of this report. NELS:88 questionnaires are reproduced in the various user's manuals, and are available from NCES."}, {"section_title": "NELS:88 Second Follow -Up", "text": "Final Methodology Report III. Sample Design, Weighting, and Estimation This chapter provides an overview of the design and procedures used for selecting schools and students into the NELS:88 base year and first and second follow-up samples. It also briefly discusses the calculation of sample weights and the relative efficiency of the sample design. Finally, this chapter provides information about procedures used to adjust sample weights for nonresponse and about the effect of unit nonresponse and other potential sources of bias on estimates. The NELS:88 Base Year Through Second Follow-Up Sampling Design, Weighting and Estimation Report presents a detailed discussion of NELS:88 base year through second follow-up sample design, weighting, and computation of design effects. More limited discussions of sampling and weighting can be found in the data file user's manuals."}, {"section_title": "NELS:88 Sample Design", "text": "This section describes the sample design of NELS:88, from its base year inception through the first and second follow-ups. Beginning from a straightforward two-stage stratified sample, the complexities of the NELS:88 sample design have grown exponentially with each subsequent wave. Base Year Sample Design. The NELS:88 base year survey employed a two-stage, stratified sample design, with schools as the first-stage unit and students within schools as the second-stage unit. Within each stratum, schools were selected with probabilities proportional to their estimated eighth grade enrollment to achieve virtual self-weighting. In addition, schools were oversampled in certain special strata so that policy-relevant subgroups would be adequately represented in the sample. NORC's sampling frame was the school database compiled by Quality Education Data, Inc. (QED) of Denver, Colorado. The QED list contained information about whether a school was urban, suburban, or rural. NORC used this information for stratification purposes. Readers who desire more detail on the base year sample design should consult the NELS:88 Base Year Sample Design Report. First Follow-Up Sample Design. There were three basic objectives for the NELS:88 first followup sample design. First, the sample was to include approximately 21,500 students who were in the eighthgrade sample in 1988 (including base year nonrespondents). This longitudinal cohort was to be distributed across 1,500 schools. The general sample design strategy for this component of the sample involved subsampling students selected for the base year with non-zero probabilities related to characteristics of their 1990 schools. Base year students who had dropped out of school between 1988 and 1990 or who werereported to be attending a school with at least ten other base year students were subsampled with certainty (that is, their probabilities of selection were set equal to one). Base year students attending school in 1990 were subsampled with probabilities related to the number of other base year students attending the same school. All other students were sampled with probabilities greater than zero, but less than one. Second, the sample was to constitute a valid probability sample of all students currently enrolled in the tenth grade in the spring term of the 1989-1990 school year. This entailed freshening the sample with students who were tenth graders in 1990 but not in the eighth grade during the spring term of the 1987-1988 school year. The freshening process could yield zero, one, or more than one new sample member in a given school. Altogether, 1,229 new students were added to the tenth-grade sampleon average, just less than one student per school. Next, two categories of sample members were subsampled: 1) students who had transferred out of the school from which they had initially been selected for the first follow-up sample; and 2) first follow-up nonrespondents who were classified as potential dropouts. As a result of this subsampling, the longitudinal cohort and the tenth-grade freshened student samples were reduced by 1,990 cases. Third, the first follow-up was to include a sample of students who had been deemed ineligible for base year data collection (because physical, mental, or linguistic barriers prevented them from participating) so that those able to participate could be added to the first follow-up student sample, and demographic and school enrollment information could be obtained for them. Data were obtained on the numbers of such ineligibles to facilitate inferences to the larger population that includes such persons. About 5.3 percent of the students at base year sample schools were excluded from participation. Of these, 57 percent were excluded because of mental disability, another 35 percent because of language barriers, and 8 percent because of physical disability. Further detail on sample eligibility in the base year is provided in the NELS:88 Base Year Sample Design Report. Specific reasons for adding a sample of ineligibles to the first follow-up design, details of the sampling methodology and composition of the base year ineligibles sample, and information on the analytic implications of undercoverage of the limited English language proficient population can be found in Sample Exclusion in NELS:88: Characteristics of Base Year Ineligible Students; Changes in Eligibility Status after Four Years. Second Follow-Up Sample Design. There were five basic objectives for the NELS:88 second follow-up sample design. First, the sample was to constitute a valid probability sample of all students enrolled in the twelfth grade in the 1991-1992 school year. This entailed freshening the sample with students who were twelfth graders in 1992 but were not in the eighth grade in the U.S. in the 1987-88 school year, just as the first follow-up sample had been freshened in 1989 to achieve a 1990-91 representative sample of sophomores. Additionally, it was necessary to reassess the eligibility status of selected students found in previous waves to be ineligible, and to include them in the cohort if they were determined to be eligible for the second follow-up. This was accomplished through the second follow-up followback study of excluded students. Second, to continue the examination of the dropping out phenomenon, dropouts were to be retained with certainty.. Third, it was highly desirable for policy analysis purposes to retain the maximum number of Hispanics, Asians, and American Indians from the first follow-up sample. Fourth, to minimize nonresponse bias first follow-up nonrespondents were to be retained with certainty. Fifth, the sample was to be clustered in 1,500 schools from which contextual dataincluding school administrator, teacher, and transcript datawould be collected. It was hoped that these goals could be achieved with minimal loss to both sample efficiency and effective sample size. Details about the second follow-up sample design are provided in the NELS:88 Second Follow-Up: Student Component Data File User's Manual."}, {"section_title": "Calculation of Weights", "text": "The general purpose of weighting survey data is to compensate for unequal probabilities of selection and to adjust for the effects of nonresponse. Weights are often calculated in two main steps. In the first step, unadjusted weights are calculated as the inverse of the probabilities of selection, taking into account all stages of the sample selection process. In the second step, these initial weights are adjusted to compensate for nonresponse; such nonresponse adjustments are typically carried out separately within multiple weighting cells. This is the process that was applied to weighting NELS:88 data in all rounds."}, {"section_title": "Calculation of Base Year Sample Weights", "text": "The base year weights were based on the inverse of the probabilities of selection into the sample and on nonresponse adjustment factors computed within weighting cells. Two different weights were calculated to adjust for the fact that not all sample members have data for all instruments. The weight BYQWT applies to 24,599 student questionnaires (and is also used in conjunction with parent data), while BYADMWT applies to the 1,035 school administrator questionnaires (seventeen base year school principals 53 39 NELS:88 Second Follow-Up Final Methodology Report failed to complete a school questionnaire). These weights project to the population of approximately 3,008,080 eligible eighth graders in public, Catholic, and other private schools in 1988. Base Year School Weights. The final school weight, BYADMWT, was derived using a multistage process. First, an initial weightwhich represented the inverse of the school's selection probabilitywas attached to each school record in a file containing records for all eligible schools in the NELS:88 sample. A logistic regression procedure was used to estimate (in terms of a probability of nonresponding) the degree to which each of the responding schools resembled a nonresponding school. This estimated probability of nonresponse was the first adjustment factor applied to a school's weight. Next, a polishing proceduremulti-dimensional rakingfurther adjusted the weights to sum to known population totals within strata. Estimating the nonresponse probability for each of the responding schools was possible because key background information on almost all of the nonresponding schools was available. The final result of these procedures was a weight for each of the responding schools adjusted to compensate for nonresponse. For the purpose of adjusting the school weight, a nonresponding school was defined as a school for which both school administrator questionnaire data and student questionnaire data were unavailable. Base Year Student Weights. The final student weight, BYQWT, was also derived using a multistage process. A design weight for each eligible student on a participating school's sample roster represented the student's probability of selection within the school. A student-level nonresponse adjustment factor was calculated by forming weighting cells based upon the combination of certain levels of variables representing school type, region, ethnicity, and gender. For each student, the product of a preliminary school weight and the student's design weight was formed. (The preliminary school weight was slightly different from BYADMWT. BYADMWT was adjusted to accommodate the seventeen schools for which school administrator questionnaire data were unavailable though student questionnaire data had been obtained. The preliminary school weight eliminated this step in the adjustment process. Thus, it is appropriate for application to the 1,052 schools with student questionnaire data available.) This product was summed for all students and all participating students within weighting cells. The ratio of the sums for all sampled students to participating students was used as the nonresponse adjustment factor for each student's design weight."}, {"section_title": "Calculation of First Follow-Up Sample Weights", "text": "Two weights were developed for the overall NELS:88 first follow-up sample. The first, or basic, weight applies to all members of the first follow-up sample who completed a first follow-up questionnaire, regardless of their participation status in the base year. The basic weight (F 1QWT) allows projections to the population consisting of all persons who were either in the eighth grade during the 1987-88 school year or in the tenth grade during the 1989-90 school year. Thus, this population encompasses both populations of prime analytic interestthe population of 1990 tenth graders (including those who were not eighth graders in 1988) and the 1988 eighth-grade population (excluding any additional 1990 tenth graders). By selecting the appropriate sample members, analysts can use this basic weight to make unbiased projections to the first of these populations (i.e., 1990 tenth graders). The second, or panel, weight applies to all members of the first follow-up sample with complete data from both rounds of the study. The panel weight (F1PNLWT) can be used to make projections to the other key analytic population-1988 eighth graders (excluding those ineligible for base year data collection). Basic First Follow-Up Weight (F1QWT). Calculation of the basic weight required somewhat different procedures for the three groups of the full first follow-up sample-1988 eighth graders deemed eligible for the base year survey, 1990 tenth graders who were not in the eighth grade in 1988, and 1988 eighth graders who were deemed ineligible for participation in the base year but were considered eligible to participate in the first follow-up. For details concerning the weighting for each specific group, see the second follow-up student data file user's manual. First Follow-Up Panel Weight (F1PNLWT). The panel weight was developed only for those cases who were selected for both the base year and first follow-up samples and who provided complete data in both rounds. The same procedures used in developing the basic first follow-up weight for 1988 eighth graders selected for the base year sample were applied to the subset of them for whom complete data were obtained in both rounds. As with the basic first follow-up weight, the target sum of weights for the panel weight was the sum of the final base year weights for all base year sample cases who remained eligible for the first follow-up sample. The same nonresponse adjustment groups and multidimensional raking procedures used in calculating the basic first follow-up weight were also used in calculating the panel weight. Users should note that compared to the base year questionnaire weight (BYQWT), the first followup questionnaire (F1QWT) and panel (F1PNLWT) weights are larger, on average, and more variable. This reflects the effect of subsampling students at different rates depending upon the number of other NELS:88 students with whom they were clustered in their first follow-up schools."}, {"section_title": "Calculation of Second Follow-Up Weights include:", "text": "Explanation of Weights. Eight weights were developed for inclusion on the data files. They"}, {"section_title": "F2QWT", "text": "This cross-sectional weight applies to all members of the second follow-up sample who completed a second follow-up questionnaire, regardless of their participation status in previous rounds. It allows projections to the population consisting of all persons who were either in the eighth grade during the 1987-88 school year or in the tenth grade during the 1989-90 school year, or in the twelfth grade in the 1991-92 school year. By selecting the appropriate sample members with the flag G 12COHRT, analysts can use F2QWT to make unbiased projections to suck populations as 1992 twelfth graders. F2PNLWT This panel weight applies to sample members who completed a questionnaire in 1988, 1990, and 1992 (all three rounds of NELS:88). This can be used to make projections to the population of 1988 eighth graders. F2F1PNWT This panel weight applies to all sample members who completed both a first followup and a second follow-up questionnaire, regardless of base year status. This allows projections to the population consisting of persons who were in the eighth grade in 1988 or in the tenth grade in 1990. By selecting appropriate sample members with the flag F2F1PNFL, analysts can use F2F1PNWT to make projections to such populations as 1990 tenth graders. F2CXTWT This cross-sectional weight applies to students who attended the schools selected for inclusion in the teacher and school administrator components and who completed NELS:88 Second Follow -Up Final Methodology Report a second follow-up questionnaire. The population was restricted to early graduates and students who were in the schools during spring data collection. This weight allows analysts to generate national statistics using the teacher and school administrator data despite the bias against small cluster sizes in sample selection. F2PAQWT This cross-sectional weight applies to all students for whom we collected a parent questionnaire during the second follow-up. F2TRSCWT This cross-sectional weight applies to all early graduates, dropouts, students in sampled schools during spring data collection, and all sample members who were both ineligible for all three rounds of NELS:88 and were in the twelfth grade during the 1991-92 school year for whom we received a transcript. F2TRP1WT This panel weight applies to sample members who were participants in 1988, 1990. and 1992 (all three rounds of NELS:88) and for whom transcript data are available. F2TRP1WT allows analysts to perform panel analyses using transcript data in conjunction with 1988, 1990, and 1992 test and questionnaire data. F2TRP2WT This panel weight applies to sample members who were participants in 1990 and 1992 (the first and second follow-up) and for whom transcript data are available. F2TRP2WT allows analysts to perform panel analyses using transcript data in conjunction with 1990-1992 test and questionnaire data. Process for Calculation of Second Follow-Up Weights. A basic four-step process was defined for the calculation of all eight weights. The first step, developing a classification scheme, was done at the beginning of the weighting process for all students in the sample. All sample members were divided into basic sample groups depending upon their status during data collection for each of the three rounds of NELS:88. Freshened students were assigned the status of their linked student for those rounds where they had not been in the sample. Students for whom status was unknown had their status imputed based upon the distribution of status across others in their base year, first follow-up or second follow-up categories and, where group size permitted, race and gender were also considered. The values remained static and were used throughout the process for all weights. Steps 2 through 4 were followed for all weights, but the results of each were tailored according to the characteristics of each weight's specific population. Step 2 entails establishing a second follow-up design weight. The design weight reflects the selection probabilities for each case for a given population. Sample members may have multiple design weights that vary depending upon the weight that is being calculated. For the weights unaffected by school sampling (F2QWT, F2PNLWT, F2F1PNWT) and for the dropouts, early graduates, and ineligible twelfth graders in F2TRSCWT, the design weight used is equal to the first follow-up design weight.' Second follow-up freshened students take on the first follow-up design weight of the student they were linked to in the freshening process. When sample members are included due to their association with a sampled school in F2TRSCWT and for all members in the F2CXTWT population, it is equal to the first follow-up design weight divided by their school's second follow-up selection probability. For students represented in the parent sample, the calculation of F2PAQWT uses the first follow-up design weight divided by the parent's second follow-up selection probability. In Step 3, an adjustment is made for second follow-up nonresponse. Nonresponse adjustment cells were based upon combinations of the classification values from step 1 as well as race (Hispanic, API, other, unknown), and gender for the members of that weight's population. The second follow-up design weight for each responding sample member was inflated by a factor equal to the inverse of the weighted response rate for their cell. This yielded their nonresponse adjusted weight. This step was performed independently for each weight calculated. For second follow-up freshened students the nonresponse adjusted weight serves as their final weight. Finally, Step 4 provides a multidimensional raking process by which sample members who were not freshened in the second follow-up had their second follow-up nonresponse adjusted weight further adjusted. The total sum of the weights and percentage distributions that were used in raking were developed by creating targets which used the expanded sample weight and first follow-up weights. Weighted frequency distributions using the expanded weights associated with a questionnaire weight's inference population were calculated for dropout rates between base year and first follow-up, dropout rates between first follow-up and second follow-up, first follow-up status (from step 1) and second follow-up status (from step 1). Weighted frequencies calculated using the first follow-up weights were used as target distributions. These target categories included race (white, black, Hispanic, API, American Indian, unknown), gender, base year school region, base year school type, and base year school urbanicity. For a more detailed description of the calculation of second follow-up weights, see chapter III of the NELS:88 Second Follow-Up Student Component Data File User's Manual."}, {"section_title": "Estimation: Standard Errors and Design Effects", "text": "In this section we discuss the calculation of standard errors as a measure of sampling variability in survey results; the standard error is an estimate of the expected difference between a statistic from a particular sample and the corresponding population value."}, {"section_title": "Survey Standard", "text": "Errors. Because the NELS:88 sample design involved stratification, dispropor-. tionate sampling of certain strata, and clustered (i.e. multi-stage) probability sampling, the resulting statistics are more variable than they would have been had they been based on data from a simple random sample of the same size. The calculation of exact standard errors for survey estimates can be difficult and expensive. Popular statistical analysis packages such as SPSS (Statistical Program for the Social Sciences) or SAS (Statistical Analysis System) do not calculate standard errors by taking into account complex sample designs. Several procedures are available for calculating precise estimates of sampling errors for complex samples. Procedures such as Taylor Series approximations, Balanced Repeated Replication (BRR), and Jackknife Repeated Replication (JRR) produce similar results.' Consequently, it is largely a matter of convenience which approach is taken. For NELS:88, NORC used the Taylor Series procedure to calculate the standard errors. Design Effects. The impact of departures from simple random sampling on the precision of sample estimates is often measured by the design effect (designated as DEFF). For any statistical estimator (for example, a mean or a proportion), the design effect is the ratio of the estimate of the variance of a statistic derived from consideration of the sample design to that obtained from the formula for simple random samples. The square root of the design effect (also called the root design effect, and designated as DEFT) is also useful. The following formulas define the design effect and root design effect for this section: where DESIGN-SE designates the standard error of an estimate calculated by taking into account the complex nature of the survey design, and SRS-SE designates the standard error of the same estimate calculated as if the survey design were a simple random sample. Documentation of the calculation of design effects for the NELS:88 Second Follow-Up Survey. The SUDAAN program was used to calculate design effects for the NELS:88 second follow-up analysis.' In the base year and first follow-up, the design effects were calculated by taking the ratio of a design adjusted standard error, obtained from CTAB, and dividing it by the weighted simple random sample standard error obtained from SAS. SUDAAN's calculation of the design effect differs both quantitatively and qualitatively from methods used in past rounds, and in certain circumstances large discrepancies between SUDAAN-calculated design effects and those calculated with methods used in previous rounds can occur. These differences involve the SUDAAN program's estimation of the simple random sample standard error used in the denominator of the design effect. In its design effect calculation, SUDAAN uses an unconditional estimate of the simple random sample standard error based on the estimated proportion of subgroup respondents in the population. Design effects calculated for previous rounds of NELS:88, however, used a simple random sample standard error based on the proportion of the subgroup respondents in the sample (conditional estimate). The two standard error estimates are different because of oversampling and nonresponse. For example, if there were 3,000 Hispanics in a sample and Hispanics were oversampled at twice the rate of their proportion in the population, the conditional simple random sample standard error estimate for Hispanics would be based on an n of 3,000. For its unconditional estimate, however, SUDAAN would base the design effect on half of that sample size, an n of 1,500. Basing the denominator standard error on an n of 3,000, which is comparable to the way design effects were calculated in previous rounds of NELS:88, would give a larger design effect (i.e., a smaller simple random sample standard error) than basing it on the n of 1,500. The conditional estimate is likely to overstate the design effects for oversampled groups in NELS:88. While the difference between the conditional and unconditional (SUDAAN) design effect estimates will be relatively small for such oversampled groups as Hispanics and even for Asians, it will tend to be larger for non-Catholic private school students. SUDAAN design effects are improved measures of the effect of sample design on sample efficiency. However, they do not function as statistical correction factors. Sometimes design effects are used by analysts who do not have access to software, such as SUDAAN, which takes into account sample design. For these analysts, the conditional design effect acts as a correction factor to statistics such as tvalues. For example, with a conditional design effect of 2, a t-value of 3.5 that is calculated assuming simple random sampling would be divided by the square root of the design effect to obtain a design-3 For convenience, the SUDAAN option WR (with replacement) was used, which provides a more conservative result (slightly larger standard errors) than the technically more correct but cumbersome option WOR (without replacement)."}, {"section_title": "44", "text": "\nWhile a questionnaire was sought from one parent of each dropout and student, approximately 1,500 parents of second follow-up respondents were subsampled out late in the parent component data collection effort. Parents of dropouts were retained with certainty. Further information can be obtained in the NELS:88 Second Follow-Up: Parent Component Data File User's Manual."}, {"section_title": "Base Year and First Follow-Up Standard Errors and Design Effects", "text": "Selection of Base Year Items. Standard errors and design effects were selected for thirty means and proportions based on the NELS:88 base year student, parent, and school data.4 The thirty variables from the student questionnaire were selected to overlap as much as possible with those variables examined in High School and Beyond. The remaining variables from the student questionnaire and from the parent and school questionnaires were selected randomly from each topical section of the questionnaire. Standard errors and design effects were calculated for each statistic both for the sample as a whole and for selected subgroups. For both the student and parent analyses, the subgroups were based on the student's sex, race and ethnicity, school type (public, Catholic, and other private), and socioeconomic status (lowest quartile, middle two quartiles, and highest quartile). For the school analysis, the subgroups were based on two levels of school type (public and combined private) and eighth-grade enrollment (at or below the median and above the median). Results. Design effects for questions selected from the student questionnaire, and means and proportions based on student questionnaire data for all students are presented in table F-1. Table F-2 gives the mean design effects (DEFFs) and mean root design effects (DEFTs) for each subgroup. On the whole, the design effects indicate that the NELS:88 sample was slightly more efficient than the High School and Beyond sample (see figure 3.3.2-1). The smaller design effects in the NELS:88 base year may reflect the somewhat smaller cluster size used in the later survey. The High School and Beyond base year sample design called for thirty-six sophomore and thirty-six senior selections from each school; the NELS:88 sample called for the selection of only twenty-four students (plus, on average, two oversampled Hispanics and Asians) from each school. Clustering tends to increase the variability of survey estimates, because the observations within a cluster are similar and therefore add less information than independently selected observations. 4 For a more detailed presentation of de4siiii 'effects' fotindividual items fiat the total sample and for various subsamples, see the NELS:88 Base Year Sample Design Report. For tables of base year parent and school administrator questionnaire data standard errors and design effects, see the respective base year data file user's manuals, or the sample design report.  Selection of First Follow-Up Items. Standard errors and design effects were also calculated for thirty means and proportions based on the NELS:88 first follow-up student and dropout data. The goal was to estimate standard errors/design effects for all respondents including dropouts and separately for dropouts. Because of the lack of perfect overlap between questions on the student and dropout questionnaires, and because 25 percent of the dropout sample was administered an abbreviated questionnaire, it was necessary to select two sets of thirty items, one to represent questions asked of all respondents and one to represent questions asked of all dropouts. To select questions for the standard errors/design effects analysis of all respondents a number of criteria were used. The first criterion was whether a question appeared in the NELS:88 base year or High School and Beyond analyses of standard errors/design effects. Policy relevance was the second criterion used for selecting questions. This criterion was used in order to ensure that variables that were important to analysts, thus likely to receive considerable use, were represented. The remaining variables were selected randomly from the pool of remaining critical items. The selection process occurred using the following procedure. First, all critical items not selected by the first two criteria formed a pool of eligible items. This involved three types of itemsbinary items, multiple category items, and continuous or quasi-continuous items. Each category of a multiple-category item was treated as a separate binary item. Second, all of the items (binary and continuous) were rescaled such that the lowest possible value was zero and the highest possible value was 100. Finally, the rescaled items were sorted from by the size of their means and a systematic sample of sixteen items was selected from the sorted list of items. For dropouts, the starting point for selecting the variables for standard error/design effect calculations was to use items that overlapped the student and dropout questionnaires and that were already selected for the analysis of all respondents. The remaining items were selected randomly from the pool of critical items not already selected that were in both the full and abbreviated versions of the dropout questionnaire, using the same transformation, ordering, and systematic sampling procedure used to select items for all students. Results. As expected, the design effects in the first follow-up are somewhat higher than those of the base year. This is a result of the subsampling procedures used for the first follow-up; students who were found to be attending schools with a small number of base year sample students were undersampled in the first follow-up. Tables F-5 and F-6 show that subgroups also have larger design effects compared to those in the base year. Table F-2 presents base year design effects for twelve subgroups defined similarly to those in tables F-5 and F-6. For eleven of the twelve subgroups, the first follow-up survey average design effects are larger than those for the base year survey, regardless of whether the full or panel samples are considered. The one exception is students from private schools. While having the highest average design effect (as they did in the base year analysis), these students show a lower average design effect in the first follow-up survey (full sample, 6.65; panel sample, 6.53) than in the base year survey (8.80). Both average design effects for the first follow-up survey were larger than the average design effect of 2.88 obtained for the base year HS&B Sophomore Cohort. The direction of this difference held for ten of the eleven subgroups comparable across the first follow-up and HS&B. Catholic school students are the exception. The average first follow-up design effect for Catholic school students is lower than the average HS&B Catholic school student design effect (first follow-up: full sample, 2.67, panel sample, 2.62; HS&B, 3.60). In HS&B, black and Hispanic Catholic schools were oversampled; however, the sample of Catholic schools in NELS:88 is more diverse. This diversity resulted in less clustering and, in effect, lower design 47 BEST COPY AVAILABLE NELS:88 Second Follow-Up Final Methodology Report effects. Further, while the first follow-up design effect for private school students was higher than in HS&B, the difference is small (first follow-up: full sample, 6.65,panel sample,6.53;HS&B,6.22); in fact it is the smallest of the differences in average design effects between the two surveys. The general tendency in longitudinal studies is for design effects to lessen over time, as dispersion reduces the original clustering. However, subsampling has the opposite effect, that is, it increases design effects. This is so because subsampling introduces additional variability into the weights with an attendant loss in sample efficiency, as may be illustrated by the case of the sophomore cohort of HS&B. For example, considerable subsampling of nonrespondents was done in the HS&B first follow-up, which had a rather higher design effect, 3.59, than HS&B base year. Comparatively more subsampling was done in the NELS:88 first follow-up, which has an overall design effect similar to, though somewhat higher than, the HS&B first follow-up (3.8 or 3.9 for NELS:88, 3.6 for HS&B). The larger design effects (compared to NELS:88 and HS&B base years) in the NELS:88 first follow-up survey are probably due to disproportionality in strata representation introduced by subsampling. This is illustrated in the higher design effects for dropouts than for students (full sample: students, 3.86, dropouts, 4.71; panel sample: students, 4.71, dropouts, 4.70); dropouts were retained at a much higher rate (i.e., certainty) than students, who were subsampled at rates corresponding to their clustering in first follow-up schools. To make a more exact assessment of the expected increase in design effects for the first follow-up sample an additional analysis of the student data was conducted using NELS:88 base year data. Standard errors and design effects were calculated on the base year student respondents, using the same variables that were used in the base year analysis, but using the first follow-up panel weight. Any magnitude of the increase in design effects in the first follow-up can be assessed by comparing the average design effect obtained from this analysis with the design effect obtained using the entire base year sample and the base year questionnaire weight, BYQWT. This analysis yielded a design effect of 3.90 (root design effect =1.96), and supports the contention that the increase in first follow-up design effects is due to weighting necessary to accommodate the subsampling."}, {"section_title": "Second Follow-Up Standard Errors and Design Effects", "text": "Selection of Second Follow-Up Items. Standard errors and design effects were also calculated for thirty means and proportions based on the NELS:88 second follow-up student and dropout data. As in the first follow-up analysis, the goal was to estimate standard errors/design effects for all respondents including dropouts, and separately for dropouts. Criteria similar to those used in the first follow-up were used to select questions for the second follow-up standard error/design effects analysis. The first criterion was whether a question had been used in the NELS:88 base year and first follow-up or High School and Beyond analyses of standard errors/design effects. This overlap resulted in the inclusion of sixteen items. Additionally, it was important to maximize the overlap between questions that appeared in both the second follow-up student and dropout questionnaires. Nine of the remaining items selected appear in both second follow-up instruments. A total of five non-overlap items were selected from the student questionnaire to supplement those in common with the dropout questionnaire. Policy relevance was the second criterion for selecting items. This criterion was applied in order to ensure that variables that are important to analysts, thus likely to have a higher frequency of use, were represented. Using this criterion, four cognitive test scores were selected: the IRT-estimated number right scores for mathematics, English, science, and social studies. Although several test score composites were available, the IRT-estimated number right scores were used because they compensate for guessing and omitted items. The IRT scores have also been equated across the multi-level math and reading test forms. Results. The conditional design effects in the second follow-up are lower than those in the first follow-up (for both the full sample and the panel) but higher than those in the base year. Tables F-12, F -13, and F-14 show that, for the most part, the second follow-up design effects for subgroups are also larger than those obtained for similar subgroups in the base year (see table F-2 for comparison). For eleven of the twelve subgroups in the full sample, and for ten of the twelve subgroups in the panel samples, the second follow-up survey average design effects are larger than those for the base year survey. The exceptions are students from Catholic and other private schools, although the design effect for other private schools remains the highest of all the second follow-up subgroups for the full and panel samples. As mentioned earlier, the tendency in longitudinal studies is for design effects to lessen over time because of dispersion of the sample members from the original clusters. However, subsampling introduces additional variability into the weights with an attendant loss in sample efficiency. The second follow-up design effects are probably larger than the base year design effects because of the subsampling in the first follow-up. They are most likely smaller than the design effects of the first follow-up because of sample dispersion between the first and second follow-ups. When the NELS:88 second follow-up design effects are compared to those from the HS&B first follow-up of the sophomore cohort a remarkable similarity is found (see figure 3.3.2-2). DEFF is 3.709 for the full sample NELS:88 second follow-up data, and 3.589 for the equivalent HS&B first follow-up data. DEFT is 1.890 for NELS:88 and 1.837 for HS&B. Figure  3.3.2-2 below illustrates the design effects for NELS:88 follow-ups in contrast to the first follow-up of the HS&B sophomore cohort."}, {"section_title": "Design Effects and Approximate Standard Errors", "text": "Researchers who do not have access to software for computing accurate estimates of standard errors can use the mean design effects presented in tables F-2 (for base year data), F-5 and F-6 (for first follow-up data), and F-12, F-13 and F-14 (for second follow-up data) to approximate the standard errors of statistics based on the NELS:88 data. Similarly, the standard error of a mean can be estimated from the weighted variance of the individual scores and the appropriate mean DEFT. Section 3."}, {"section_title": "of the NELS:88", "text": "Second Follow-Up Student Data File User's Manual contains specific information concerning the calculation of such estimates for researchers conducting additional analyses."}, {"section_title": "Additional Sources of Nonobservational Error", "text": "Analysis of survey error is important for understanding the potential bias in making inferences from an obtained sample to a population. Sampling errors occur because the data are collected from a sample rather than a census of the population. Sampling error analyses for NELS:88 (documenting standard errors of measurement for key variables) were presented earlier in this chapter (see section 3.3). In this section, other sources of nonobservational error are discussed. 6  Nonobservational error results from measurements not being taken from a portion of the population and comprises several factors, including undercoverage and nonresponse biases caused by unit and item nonresponse.5 For an extended discussion of student sample exclusion and undercoverage issues, see Ingels, Sample Exclusion in NELS:88, NCES, 1996. Base year data quality was examined by Kaufman and Rasinski (Quality of the Responses of Eighth-Grade Students in NELS:88, 1991, NCES 91-487). The authors compared student and parent reports to similar items, examined the consistency of student responses to similar items, and assessed the reliability of several of the scales that have been constructed from parent, school administrator or student data. Kaufman and Rasinski concluded that \"the NELS:88 data displayed a high degree of accuracy and consistency\". McLaughlin and Cohen (NELS:88 Survey Item Evaluation Report, forthcoming 1997, NCES 97-052), have examined base year through second follow-up data. Their approach is less to assess reliability and validity of responses than to assess which items are most sensitive to changes in the source of the information, within a study that provides data at multiple time points from multiple respondent populations. Their report examines 64 pairs of measures from parents and students (or dropouts), 12 from teachers and students, and 112 from students across waves in order to determine: (1) degree of similarity of response distributions for items from different sources; (2) nonresponse bias; (3) subgroup differences in pair convergence and item omission; and (4) the impact on conclusions about student outcomes of the investigator's choice of source of information. For documentation of item nonresponse in NELS:88 see the NELS:88 Base Year Sample Design Report (Spencer, Frankel, Ingels, Rasinski & Tourangeau, 1990;NCES 90-463, Section 4.3); the NELS:88 First Follow-Up Student Component Data File User's Manual (Ingels, Scott, Lindmark, Frankel & Myers, 1992, NCES 92-030, section 3.7.2); the NELS:88 Second Follow-Up Student Component Data File User's Manual (Ingels, Dowd, Baldridge, Stipe, Bartot & Frankel;NCES 94-374, Section 3.4.2 ); and the NELS:88 Third Follow-Up Methodology Report (Haggerty, Dugoni, Reed, Cederlund, & Taylor, 1996, NCES 96-174, Section sections 5.5-5.6). Item nonresponse does not have the same meaning for the cognitive battery because a test item may be omitted because the student does not know the answer and indeed cannot even make an educated guess. Because the NELS:88 tests have time constraints, and because there is no reward or penalty for completing the test hence questions of motivation become especially important, a critical question becomes whether test-takers completed each of the four achievement assessments in the NELS:88 battery. Table 3.4-1 presents speededness indices for the gender, racial/ethnicity groups and totals. The speededness index presented here is the percentage of students in each group who attempt the last item. If over 80 percent attempt the last item the test is assumed to be not speeded, that is, differences in test performance are judged not to be due to time constraints. To a certain extent the proportion attempting the last item is at best an approximate estimate of speededness and likely to be biased in the direction of showing speededness when it is not present. One reason for this is that the items at the end of the test form tend to be the most difficult. As items near the end increase in difficulty, they may not be attempted by the less advanced students, and the speededness index would infer that the test is speeded rather than just having items towards the end that are too difficult for some test takers. Another reason for not answering one or more items at the end of the test might be lack of motivation to complete a test for which the student will be neither rewarded nor punished. Inspection of table 3.4-1 suggests that there is little problem with speededness. Not unexpectedly, speededness indices for the twelfth grade high math form fell below 80 "}, {"section_title": "51", "text": "NELS:88 Second Follow-Up Final Methodology Report percent for some subgroups. This form had five very difficult items at the very end. Another speededness index defines a test as not being speeded if \"almost all\" test takers complete 80 percent of the test. This definition is not affected by clusters of hard items at the end of the test. When this criterion was applied, the percentages completing at least 80 percent of the test exceeded 95 percent for virtually all subgroups and this finding was consistent for all grade levels. The vast majority of students who took the NELS:88 tests answered all of the questions. There is little indication that time constraints differentially affected scores for any gender or racial/ethnic subgroup. The analysis above suggests that for those students who attempted the cognitive battery, motivation is not a problem. There is still a concern that those students who did not take the cognitive battery for whatever reason may not be missing at random, particularly in the twelfth grade. This is a central question for the unit nonresponse analysis that follows. Unit Nonresponse. Unit nonresponse occurs when an individual respondent (such as a student, school administrator, or teacher) declines to participate, or when the cooperation of a school cannot be secured. In examining the impact of nonresponse, it is useful to think of the survey population as two independent strataa respondent stratum that consists of all units that would have provided data had they been selected for the survey, and a nonrespondent stratum that consists of all units that would have been survey nonrespondents. The actual sample of respondents necessarily consists entirely of units from the respondent stratum. Sample statistics can serve as unbiased estimates only for this stratum; as estimates for the entire population, the sample statistics will be biased to the extent that the characteristics of the respondents differ from the entire population. The bias may be expressed as: Bias = YR -Y, (1) in which: YR =a parameter (e.g., a mean) characterizing the population of respondents, and Y =the corresponding parameter characterizing the entire population. For many simple parameters such as means and proportions, the population parameter (Y) is a weighted average of the stratum parameters (YR and YNR): where: P =the proportion of the population in the nonrespondent stratum. Equations (1) and (2) together are mathematically equivalent to the expression: In other words, the nonresponse bias for an estimated mean or proportion depends on P and on the magnitude of the difference between respondents and nonrespondents. This bias will be small if the nonrespondent stratum constitutes only a small portion of the survey population or if the differences between respondents and nonrespondents are small. P can generally be estimated from survey data using an appropriately weighted nonresponse rate. In the base year of NELS:88, an analysis of school-level nonresponse suggested that, to the extent that schools can be characterized by size, control, organizational structure, student composition, and other characteristics, the impact of nonresponding schools on the quality of the student sample is small (for details, see the Base Year Sample Design Report). School nonresponse has not been assessed in the first and second follow-ups for two reasons. First, there was practically no school-level nonresponse; institutional cooperation levels approached 99 percent in both rounds. School nonresponse consequently had little impact on the collection of student or school contextual data in either the first or second followup. Second, the first and second follow-up samples were student-driven, unlike the two-stage initial sample design in the base year. Hence, even if a school refused in either the first or second follow-up, the individual student was pursued outside of school, though school contextual data were not collected for the student. Analysis of NELS:88 Student Nonresponse. This section examines nonresponse in the first three waves of NELS:88. Analyses were conducted for both the eighth-grade and sophomore cohorts; any member of the eighth-grade cohort who did not complete a survey in all three rounds of NELS:88 (base year, first follow-up, and second follow-up) and any member of the sophomore cohort who did not complete a survey in the second and third rounds (first follow-up and second follow-up) was considered a survey panel nonrespondent for that cohort. Panel nonresponse, under the stringent conditions described above, was the main focus in this analysis because the first priority of NELS:88 is to provide a basis for longitudinal analysis rather than for within-round estimates. Even when within-round response rates are quite high, panel response rates may be much lower. Moreover, in NELS:88, the requirement for eligibility for a panel weight was participation in all relevant rounds (1988, 1990 and 1992 for members of the eighth grade cohort; 1990 and 1992 for members of the sophomore cohort). There were several causes of student nonparticipation in the base year and follow-up surveys. Some students refused to cooperate; others could not be located or were unavailable at the time of the survey, and a few had died. An additional nonresponse variable was created to indicate cognitive test participation. Not all questionnaire completers also completed the NELS:88 test battery. Moreover, no special nonresponseadjusted weight has been created to compensate for test noncompletion. It is therefore important to determine the degree of bias attendant upon test nonresponse of questionnaire completers. A member of the eighth-grade cohort who did not complete a cognitive test in all three rounds, or a member of the sophomore cohort who did not complete a cognitive test in the first and second follow-ups, was considered a cognitive test panel nonrespondent. (The definitions for each type of panel respondent are displayed in figure 3.4-1.) Some cognitive test nonresponse was due to the mode of survey administration. All dropouts and some students were surveyed outside of school in the first and second follow-ups, by telephone or in person at a group or individual survey session. When possible, sample members were surveyed in person. However, for cost or cooperation reasons, a significant percentage of questionnaires completed outside school were completed by telephone; for obvious reasons, the cognitive tests could not be administered during a telephone interview. The rate of cognitive test refusal was also higher among sample members surveyed in group or individual survey sessions than among students surveyed in school.   1990 + 1992 Panel Respondent N=16,749 (Cohort Nonrespondent N=1,427) Cognitive Test 1988 1990 + 1992 Panel Respondent N=12,574 (Cohort Nonrespondent N=5,602) Nonresponse rates were calculated on the basis of full participation in the panel; the nonresponse rate is the proportion of the selected students (excluding deceased students) who were nonrespondents in any round in which data were expected: in which: P = NR / (R + NR) P = the nonresponse rate, R = the number of responding students, and NR = the number of nonresponding students. Nonresponse rates for the eighth-grade and sophomore cohorts were calculated by school-level and student-level variables using both weighted and unweighted data. The weight used was the second followup raw panel weight.' Participation patterns across rounds of NELS:88 are depicted in figure 3.4-2 in unweighted percents. Patterns are given for both questionnaire and cognitive test participation. The last row for each cohort represents the panel respondents, and the remaining rows together define the panel nonrespondents. The overall unit response rates for participants and nonparticipants (i.e., the percentage of certain subgroups who responded in at least one round of NELS:88 or for whom some basic information was recorded) were compared using several items that were selected from the base year, first follow-up, and second follow-up questionnaires, including attitude items and participation in extracurricular activities as well as basic demographic and school variables. These items were used to give some indication of the characteristics of unit nonrespondents in the two cohorts. The questionnaire variables chosen represent characteristics which remain relatively stable across all three rounds and which are repeated across questionnaires. Thus, for panel nonrespondents who completed a questionnaire in at least one round, the response for these items were assumed to be consistent across rounds, had they participated in all three. In other words, the response given by a panel nonrespondent in one of the rounds is considered to be the 6 The raw (or \"design\") weight does not appear on the NELS:88 public release file. The public release files contain only the final (that is, nonresponse-adjusted) weight. true response had the individual responded in all of the rounds. For all members of the cohort, both respondents and nonrespondents, these questionnaire responses were collected from survey data from the first round of that member's participation. For example, if the student participated in the base year survey, information was collected from 1988 survey data. If the member did not participate in the base year but did participate in the first follow-up, first follow-up survey data were used. Finally, second follow-up data were used only if the member did not participate in either the base year or first follow-up but did participate in the second follow-up. Only minimal demographic information is available for members who did not respond in any of the three rounds. Responses for questions regarding attitudes and extracurricular participation, conversely, were only available for panel members who participated in at least one round of data collection. School variables are taken from the base year survey for the eighth-grade cohort and from the first follow-up survey for the sophomore cohort. Demographic information, however, is taken according to that which is most recent. In other words, second follow-up data are taken first, and data from previous rounds are used if student data are missing. Across the three rounds of NELS:88, about eighteen percent of the eighth-grade cohort and ten percent of the sophomore cohort were survey nonrespondents at one or more time points. Cognitive test nonresponse was much higher. Approximately forty-three percent of the eighth-grade cohort did not complete a cognitive test in all three rounds, and thirty-five percent of the sophomore cohort did not complete a cognitive test in the second two rounds. Weighted frequencies for participants and nonparticipants of the NELS:88 surveys and cognitive tests are presented in tables 3.4-1 through 3.4-4. Comparisons are shown for sex, race, and educational aspirations. Results for an additional eighteen variables are included in appendix G. Equation (1) shows that bias due to nonresponse depends on the difference between the respondents and all selected students: a parameter, such as a mean or proportion, characterizing respondents, and the corresponding parameter characterizing all selected students. The percentages in tables 3.4-1 through 3.4-4 for all students are estimates of Y, and the percentages for participants in all three rounds of NELS:88 are estimates of YR. The differences between the two are estimates of bias. The final weights used in NELS:88, in contrast to the raw weight used in this analysis, do adjust for nonresponse (i.e., adjust to correct population totals) in estimates for sex and race categories. However, these weights do not necessarily correct for bias in these categories. On the whole, tables 3.4-1 and 3.4-2 reveal only small discrepancies between estimates based only on data from participants and estimates based on data from both participants and nonparticipants. In terms of survey nonresponse bias, the tables indicate that the student-level bias components for the sophomore cohort are small. However, because of the more stringent requirements for being an eighth-grade cohort respondent than a sophomore cohort respondent, bias estimates are higher for the eighth-grade cohort.      Tables 3.4-3 and 3.4-4 indicate larger discrepancies between estimates based on data from cognitive test completers and estimates based on data from both completers and noncompleters. Cognitive test nonresponse bias is notably higher than survey nonresponse bias for both cohorts. Tables 3.4-1 through 3.4-4 include estimates of survey nonresponse bias for thirteen estimates for each cohort; the frequency distributions of these bias estimates are given in tables 3.4-5 and 3.4-6. For the eighth-grade cohort, the mean of the unsigned bias estimates for survey nonresponse is 0.98 percentage points and the median is 0.8; for the sophomore cohort, the mean and median for survey nonresponse are 0.48 and 0.4 percentage points, respectively. The results for sex, race, and educational aspirations for both cohorts are representative of the larger set of variables examined in appendix G."}, {"section_title": "7.", "text": "The results for survey nonresponse bias show that the magnitude of the bias is generally smallfew percentage estimates will be off by as much as two percent in the eighth-grade cohort and one percent in the sophomore cohortand the direction predictable. The direction of the bias is partly a function of the different rates of nonresponse for different subgroups. For example, blacks had a higher nonresponse rate than whites. As a result, when estimates of racial composition are based only on participants' data, the estimate for blacks appears to be too low and the estimate for whites too high. However, this bias reflects the raw weight; the nonresponse-adjusted weight corrects for differences by race and sex to produce correct population estimates for each subgroup. It cannot correct for bias attendant upon characteristics of interest if they are differentially distributed between nonresponding and responding members of a weighting subgroup. Further, whenever a factor related to nonresponse is also related to a variable of substantive interest, estimates concerning the substantive variable will be somewhat biased. However, because few variables are strongly related to student nonresponse and because the overall rates of student survey nonresponse are low, bias estimates are relatively small.  NELS:88 Student Nonresponse Rates: Student-Level School Variables. This section examines survey and cognitive test nonresponse for each cohort by school variables at the student-level. Again, panel nonresponse is investigated, with a nonrespondent defined as (a) any member of the eighth-grade cohort who failed to complete a questionnaire in any one (or more) of the three rounds of NELS:88 (1988NELS:88 ( , 1990NELS:88 ( , 1992; or (b) any member of the 1990 sophomore cohort who failed to complete a questionnaire at either or both time points (1990,1992). Six variables are shown in tables 3.4-7 and 3.4-8: school type, census region, level of urbanization, percent minority in the eighth-grade school, percent students receiving free or reduced-price lunch in eighth grade (a measure of school socioeconomic status), and school enrollment. Base year data were used to classify the schools for the eighth-grade cohort, and first follow -up data were used to classify the schools for the sophomore cohort. The response rates given in the tables are weighted using the raw weight. Table 3.4-7 indicates that eighth-grade cohort students attending schools with a high percentage of minority students and those attending schools with a high percentage of students receiving reducedpriced lunches are significantly more likely than their counterparts to be questionnaire nonrespondents (minority >20 vs < =20 t =8.05; lunch >20 vs < =20 t= 5.17). Conversely, students in the eighthgrade cohort who attend schools in rural areas are much less likely to be nonrespondents (rural vs. urban t=5.32, rural vs. sub t=4.17). For the sophomore cohort, students attending schools in urban areas are more likely to be nonrespondents (urban vs. sub t=2.54, urb vs. rural t=3.4). In both cohorts, students attending schools in the West have higher nonresponse rates than those in other areas of the country (g8 cohort: West vs.   Overall, nonresponse rates are lower in the sophomore cohort than in the eighth-grade cohort. This is undoubtedly due to the more stringent requirements for respondent status among eighth-grade cohort members (completion of a questionnaire or cognitive test in all three rounds of NELS:88) than among sophomore cohort members (completion of first and second follow-up questionnaires or cognitive tests). Indeed, when nonresponse is evaluated based on only one round of participation (for example, nonresponse in the NELS:88 second follow-up), nonresponse rates are even lower. Survey Nonresponse. In both cohorts, males and females are approximately equally likely to be questionnaire nonrespondents. The difference between male and female nonresponse rates is 2.6 percent in the eighth-grade cohort and 1.0 percent in the sophomore cohort. Racial differences are more pronounced and show Hispanics and blacks with higher rates of nonresponse. In the eighth-grade cohort, Asian students also exhibit relatively high levels of nonresponse -(22.5 percent) (Asian v White t=4.17, A v Black t=n.s., A v Hispanic t=n.s.), while Hispanic and black nonresponse rates are 24.7 percent and 23.6 percent, respectively, compared to 14.4 percent for whites (H v W=6.31, B v W=4.91). In the sophomore cohort, nonresponse rates are significantly higher for blacks and Hispanics (14.9 percent and 14.5 percent, respectively) than for whites (8.0 percent) (B v W=3.71, H v W=4.26). The sample size for American Indians is too small to make comparisons with other racial subgroups. High school program is also related to nonresponse. Students in an academic program exhibit the lowest rates of nonresponse (10.6 percent in the eighth-grade cohort and 5.0 percent in the sophomore cohort), while the highest nonresponse rate for both cohorts is among students in an unspecified (other) program (21.6    Finally, members of the cohorts who dropped out at least once between 1989 and 1992 show much higher rates of survey nonresponse. For the eighth-grade cohort, the dropout nonresponse rate is 32.3 percent compared to 15.4 percent for students who never dropped out. For the sophomore cohort, dropouts have a nonresponse rate of 23.6 percent, compared to a student rate of 8.7 percent (g8: do v stud =10.66, g10: do v stud=7.70). Cognitive Test Nonresponse. Although cognitive test nonresponse is larger in magnitude, the differences among the subgroups are no more marked. Male and female nonresponse rates are virtually identical in both cohorts, with differences of 1.0 percent in the eighth-grade cohort 0.2 percent in the sophomore cohort. Racial differences are also similar to those among survey nonrespondents: blacks and Hispanics have higher rates of nonresponse in both cohorts. The eighth-grade cohort shows black and Hispanic nonresponse rates of 53.9 percent and 51.6 percent, respectively, compared to 38.0 percent for whites and 43.8 percent for Asians (H v A=2.55, H v W=8.20, B v A=3.31, B v W=8.25). In the sophomore cohort, the nonresponse rate is 44.0 percent for Hispanics and 42.8 percent for blacks, while white and Asian rates are substantially lower (31.9 percent and 35.4 percent, respectively) (H v A=3. 12, H v W=6.73, B v A=2.44, B v W=4.96). Results for high school program show students enrolled in an academic program with the lowest rates of nonresponse, and students enrolled in another (unspecified)  Students who dropped out sometime between 1989 and 1992 also have higher rates of cognitive test nonresponse than those who never dropped out. Dropout nonresponse rates are 76.8 percent in the eighth-grade cohort and 71.6 percent in the sophomore cohort, compared to student nonresponse rates of 36.0 percent and 30.8 percent, respectively (g8: do v stud=25.66; g10: do v stud =22.54) Summary of NELS:88 Panel Nonresponse Analysis. The nonresponse analysis suggests that groups with lower levels of engagement in their schooling were less likely to participate in the survey: 89 69 NELS:88 Second Follow-Up Final Methodology Report students who had dropped out of school at least once had higher nonresponse rates than non-dropouts, students in the lowest test quartile had higher nonresponse than students in the highest quartile, and students who had low educational aspirations had higher levels of nonresponse than those with high educational goals. Also, students whose parents had a lower level of education responded less than those whose parents had a higher level of educational background, and students enrolled in a vocational or technical program responded less than students enrolled in an academic program. Because the analyses of student nonresponse are based on survey data, they are themselves subject to nonresponse bias. Despite this limitation, however, the results consistently indicate that survey nonresponse had a small impact on NELS:88 base year through second follow-up and (for the sophomore cohort) first follow-up through second follow-up panel estimates. There is, however, some concern that those students who did not complete a cognitive test in every round may not be missing at random, particularly in the second follow-up. Tables 3.4-11 and 3.4-12 present both unweighted and weighted proportions of panel questionnaire respondents in each cohort, shown by subgroup within each timepoint, who completed the test battery.' These tables indicate that there is a decline in participation at the second follow-up. Furthermore, this does not appear to be completely at random. There is some indication that certain groups decline in participation more drastically than others. For example, blacks and Hispanics in the eighth-grade cohort responded at approximately the same rate in the base year (within three percent) as whites and Asians did. However, by the second follow-up response rates for students in these racial groups had declined to as much as seven percent below those of whites and Asians. Public school students in the eighth-grade cohort also declined in response more than private school students did. In the base year, response rates for public school students were only two percent lower than for private school students, but at the second follow-up that difference increased to about six percent. Even larger differences can be found among socioeconomic status. Differences in response rates between the lowest and highest SES quartile students in the eighthgrade cohort increased from less than two percent in the base year to more than eight percent in the second follow-up.' Finally, dropouts in the eighth-grade cohort showed the largest decline in response. In the first follow-up, students who had dropped out at least once showed response rates nearly twenty percent lower than those for students who had never dropped out. However, by the second follow-up the difference was almost forty percent. This large decline points out some of the difficulties encountered in obtaining inperson interviews and participation in cognitive testing for dropouts. The same overall patterns are evident for the sophomore cohort; there is a sharp decline in participation in the second follow-up. However, some of the individual patterns are not consistent with those for the eighth-grade cohort. For example, the racial differences found for the eighth-grade cohort are not apparent for the sophomore cohort. In fact, although the response rates for Hispanics and blacks are indeed lower in the first follow-up by up to eight percent than those for whites and Asians, these differences actually narrow in the second follow-up to only four percent. And while Asians in the first follow-up respond at a rate four percent lower than whites, by the second follow-up their response rate is    two percent higher than whites. The same anomaly occurred for school type. In the first follow-up, public school response rates were more than ten percent higher than other private response rates, but by the second follow-up other private school students were responding at a rate five percent higher than public school students. The sharper decline in response for some subgroups than others supports the larger bias components for cognitive test nonresponse than for survey nonresponse. However, given the large number of cognitive test nonrespondents, bias estimates are not as large as would be expected. In fact, these rates point out the worst case scenario because both contextual and noncontextual students and in-school students and dropouts are analyzed together. When analyzing these groups separately, however, the patterns are noticeably different. Comparison of NELS:88 to HS&B Student Nonresponse. A comparison of the effect of nonresponse on the NELS:88 study to its effect on the HS&B study provides an additional measure by which the impact of bias and the nonresponse patterns among subgroups may be evaluated. HS&B conducted an analysis of bias in the base year (1980), which was paralleled using NELS:88 sophomore cohort data in the first follow-up (1990). Results for both analyses are presented in tables 3.4-13 and 3.4-\nKaufman, P., and Bradby, D. Characteristics of At-Risk Students in NELS:88, 1992; NCES 92-042. The study described in this report examined the characteristics of eighth-grade students who were at risk of school failure. The study used data from the National Education Longitudinal Study of 1988, which is a large-scale, national longitudinal study begun in the spring of 1988 when 25,000 eighth graders attending public and private schools across the nation were surveyed along with the students' parents, teachers, and school principals. The students were re-surveyed in 1990, and the base year and follow-up data of NELS:88 taken together provide a wealth of information about eighth graders' as they move in and out of the U.S. school system and into the varied activities of early adolescence. This study, focused on at-risk students within the eighth-grade cohort, examined the following sets of variables: (1) basic demographic characteristics; (2) family and personal background characteristics; (3) the amount of parental involvement in the student's education; (4) the students' academic history; (5) student behavioral factors; (6) teacher perceptions of the students; and (7) characteristics of the students' schools. Black, Hispanic American, and Native American students and students from low-socioeconomic backgrounds were more likely to be at-risk. Male eighth graders were more likely to have low basic skills, but were no more likely to drop out. After controlling for sex and socioeconomic status, Black and Hispanic American dropout rates were found to be the same as that for Whites. However, even when controlling for sex and economic status, Black and Hispanic American students were more likely than White students to perform below basic proficiency levels. (Included are 15 tables in the text and 31 tables in 2 appendixes; 107 p.). Bradby, D. Language Characteristics and Academic Achievement: A Look at Asian and Hispanic Eighth Graders in NELS:88, 1992;NCES 92-479. This report examines the demographic and language characteristics and educational aspirations of Asian American and Hispanic American eighth graders and relates that information to their mathematical ability and reading comprehension as measured by an achievement test. Special attention is paid to students who come from homes in which a non-English language is spoken. Of the 1,505 Asian American students evaluated, 73 percent were reported as language minorities (LMs), while 77 percent of the 3,129 Hispanic American students evaluated were LMs. Of the LM students, 66 percent of the Asian Americans had high English proficiency as compared to 64 percent of the LM Hispanic Americans. Both Asian American and Hispanic American groups had 4 percent of LM students showing low English proficiency. Overall, the study found many similarities between the two groups. However, differences are apparent when data are divided along language proficiency, mathematics achievement, aspiration, and other measures. Statistical data are provided in 33 tables and 44 graphs. Appendices present selected survey questions, technical notes and methodology, and 109 standard error tables. (197 p.)."}, {"section_title": "14.", "text": "The bias was calculated according to the difference between the estimates based on data from participants and the estimates based on data from all selected members of the sophomore cohort. In comparing tables 3.4-13 and 3.4-14, it can be seen that bias estimates for NELS:88 are consistently lower than those for HS&B. The only exception to this is for the Hispanic category of the racial subgroup; in this case, the HS&B bias estimate is smaller by two percentage points. It also appears that the NELS:88 and HS&B samples may be intrinsically different. For example, the educational aspirations for the two groups seem to differ quite dramatically. While nearly half of all NELS:88 1990 sophomores expect to graduate from college, only 17 percent of HS&B 1980 sophomores expect to earn a college degree. Further, 35 percent of HS&B 1980 sophomores plan to go no further than high school, while only 10 percent of NELS:88 1990 sophomores intend to end their education at high school. Thus, while these differences may be accounted for at least partially by the time periods they span, the direction of the bias estimates may not be entirely comparable for these two groups. In addition, nonresponse rates for the NELS:88 sophomore cohort in the second follow-up (1992) can be compared to rates for HUB sophomores in the first follow-up (1982), when the majority of each group of students was in the twelfth grade. Estimates for NELS:88 second follow-up and HS&B first follow-up nonresponse broken down by student-level school characteristics are found in table 3.4-15. The sophomore cohort of NELS:88 shows an overall survey nonresponse rate of 6.3 percent in the second follow-up, compared to a rate of 6.4 percent for the sophomore cohort of HS&B in the first followup.    "}, {"section_title": "96", "text": "Students attending public schools are among those with the highest second follow-up nonresponse rates for the NELS:88 sophomore cohort (pub v Cath=6.71,pub v NAIS=5.18,public v other=9.65). Conversely, students attending schools in rural areas have some of the lowest nonresponse rates among the NELS:88 sophomore cohort (rural v urban=2.41, rural v suburban=2.10). Table 3.4-15 indicates that for the HS&B sophomore cohort, the highest rate of nonresponse is among students attending schools with more than 550 students, and the lowest is for Catholic school students. Table 3.4-16 displays the weighted rate of nonresponse for the NELS:88 1990 sophomore cohort in the second follow-up and the HS&B 1980 sophomore cohort in the first follow-up by individual-level variables including sex, race, high school academic program, cognitive test quartile, and dropout status. In both NELS:88 and HS&B, males and females exhibit essentially equal nonresponse rates. The difference between male and female nonresponse is 0.9 percent for the sophomore cohort of NELS:88 and 2.1 percent for the sophomore cohort of HS&B. Racial differences for NELS:88 and HS&B show blacks with the highest rate of nonresponse. For NELS:88, nonresponse rates are highest for blacks and Hispanics (9.1 percent and 8.7 percent, respectively), and lowest for whites (5.0 percent) (B v W=2.73, H v W=2.73). Rates for HS&B differ quite notably. Although the highest nonresponse rate among racial subgroups is for blacks (5.0 percent), the lowest rate is for Hispanics (3.0 percent), and the nonresponse rate for whites falls between them (4.0 percent). High school academic program also shows some differences in nonresponse rates. For both NELS:88 and HS&B, students in an academic program exhibit the lowest rates of nonresponse (2.3 percent for NELS:88 and 3.6 percent for HS&B), while students in a vocational or technical program have the highest rates of nonresponse (8.8 percent for NELS:88 and 5.5 percent for HS&B) (NELS: acad v gen=5.03, acad v voc =5. 28, acad v other=3.28). Because estimates in the \"other/unknown\" category for HS&B are inflated due to missing data,' they are not evaluated with the other categories in this analysis. In each cohort, nonresponse rates are highest for individuals in the lowest test quartile (9.4 percent for NELS:88 and 6.1 percent for HS&B), and lowest for individuals in the highest quartile (2.5 percent for NELS:88 and 3.2 percent for HS&B) (NELS: low v midlow=3.42, low v midhi=3.84, low v high=8.44, midlow v midhi=1.13, midlow v high=5.94, midhi v high=2.99). These differences indicate that nonresponse is inversely related to tested achievement."}, {"section_title": "10", "text": "The category \"other/unknown\" is a general classification that includes both missing data and data for respondents who did not fall into any of the other specifically defined categories. Nonresponse generally is substantially higher for the \"othenunknown\" categories. This is an artifact attributable to the substantial number of HS&B first follow-up nonrespondents who were also base year nonrespondents. These double non-participants could only be classified in the unknown category, elevating the nonresponse rate for that group. 87 77 NELS:88 Second Follow-Up Final Methodology Report Finally, dropouts show much higher rates of survey nonresponse than do students. For NELS:88, the dropout nonresponse rate is 13.1 percent compared to 5.5 percent for students, while the HS&B dropout rate is 14.7 percent compared to a student rate of 4.2 percent (NELS: do v stud=5.94). Summary of NELS:88 and HS&B Nonresponse Comparison. The comparative analysis above shows that the same general patterns hold for both the NELS:88 and the HS&B studies. The analysis of school characteristics shows both studies with comparatively higher nonresponse rates for students enrolled in schools in the West. Individual characteristics are also consistent among the two groups. For both NELS:88 and HS&B, high nonresponse rates occur among blacks, students in a vocational or technical program, individuals in the lowest test quartile, and dropouts. The overall rate of nonresponse for NELS:88 is nearly identical to the rate for HS&B. Furthermore, the analysis of bias suggests that the bias for NELS:88 in 1990 is smaller than the bias for HS&B in 1980. Thus, as the HS&B analysis concluded with confidence in the minimal impact of bias on its sample estimates, NELS:88 can be assured similar confidence."}, {"section_title": "IV. Data Collection", "text": "This chapter provides an overview of the data collection procedures and results for the student, dropout and contextual (e.g., parent, teacher, and school administrator) surveys conducted in the NELS:88 base year, first follow-up, and second follow-up. Detailed completion rates for each survey wave are provided in appendix H. Detailed descriptions of procedures can be found in the data file user's manuals for the base year, first follow-up and second follow-up student components and in the manuals for the individual component surveys."}, {"section_title": "4.1", "text": ""}, {"section_title": "Base Year Data Collection", "text": "The base year survey collected data from students, parents, teachers, and school administrators. Self-administered questionnaires and tests were the principal mode of data collection. Completion rates based on sample eligibility for each instrument are listed in table 4.1-1. Additional completion rates for the base year, including completion rates by sampling strata, are presented in appendix H. Before the data collection effort could begin, it was first necessary to secure from the administrator of each sampled school a commitment to participate in the study. Several levels of cooperation were sought before school administrators were approached. The first level involved contacting key educational organizations. The Education Information Advisory Council (EIAC) of the Council for Chief State School Officers was asked to give its approval for the project. Contact was also made with the National Catholic Education Association (NCEA) and the National Association of Independent Schools (NAIS) in order to inform them of the study and to solicit their endorsements."}, {"section_title": "80", "text": ".100"}, {"section_title": "38", "text": "Orientation days were originally planned for all schools. However, the NELS:88 base year field test indicated that orientation days for eighth grade students would not significantly affect participation rates in most schools. (See Ingels, S. J., et al., National Education Longitudinal Study of 1988: Field Test Report, NORC, 1987ERIC ED 289-897.) 39 Student sample selection procedures are discussed in the NELS:88 Base Year Sample Design Report. NELS:88 Second Follow-Up Final Methodology Report Survey administration, normally conducted in a school classroom or library, consisted of several steps. Students first completed the student questionnaire. A ten-minute break followed, during which time NORC field staff began their review of the questionnaires for completeness (i.e., checked for missing or multiple-response critical items).4\u00b0F ollowing the break, an 85 minute battery of cognitive tests was administered. The tests consisted of four timed sections devoted to mathematics, reading, science, and social studies (history /government). Once the test battery was completed, an attempt was made to retrieve missing (or inappropriately marked) questionnaire items before the student left the classroom. At the end of the session, arrangements were made to conduct make-up sessions for students who were scheduled, but unable to attend Survey Day. If fewer than five students were scheduled for a Make-Up Day, the school coordinator was asked to handle the arrangements and oversee its administration.'\" When five or more students were scheduled, or in instances where the school coordinator was unavailable to conduct a Make-Up Day, NORC representatives arranged a return visit to the school. 4.1.3 Base Year School Administrator Survey For the school survey, the school principal or headmaster was asked to complete a self-administered questionnaire. Questionnaires for school administrators who did not initially return their completed questionnaire were collected through telephone follow-up."}, {"section_title": "Base Year Teacher Survey", "text": "A self-administered teacher questionnaire was distributed to selected eighth-grade teachers of the sampled students. After the initial return of self-administered teacher questionnaires, questionnaires for nonresponding teachers were collected through telephone follow-up. Each school was randomly assigned to one of the following combinations of curriculum areas: mathematics and English; mathematics and history; science and English; and science and history. In each NELS:88 school, data were collected from each sampled student's current teacher(s) in the two designated subject areas. This selection procedure was designed to ensure representation of mathematics or science curriculum and English or history in all schools. Combinations of English and history as well as science and mathematics were excluded by the design. The design also achieved balanced representation of the four curriculum area combinations across the school variables of control (public, Catholic, and other private); level (elementary, middle, junior-senior high school); geographical stratum; and school size."}, {"section_title": "Base Year Parent Survey", "text": "A self-administered questionnaire was hand-delivered by each sampled student to his or her parent or guardian. The questionnaire included a written request that it be completed by the parent or guardian most familiar with the student's current school situation and educational plans. An NORC field staff member was instructed to review the questionnaires to ensure that all critical items were completed. A specially designated oval indicating \"no retrieval\" was marked whenever the missing data could not be retrieved due to respondent refusal or inability to clarify an inappropriate response. To ensure respondent confidentiality, school coordinators were prohibited from reviewing the student questionnaire for completeness. Instead, the review was conducted by NORC staff in Chicago, and missing data were retrieved by telephone."}, {"section_title": "First Follow-Up Data Collection", "text": "The first follow-up survey collected a second wave of questionnaire and cognitive test data from the eighth-grade cohort of 1988, the majority of whom were enrolled in the tenth grade at the time of data collection. In addition, a first wave of data was collected from freshened students, and a first wave of dropout information was collected from those students who dropped out of school between the base year and the first follow-up. Contextual data were also collected for sample members. A questionnaire was administered to two teachers for each sampled student, as well as a separate questionnaire to the school administrator of each sampled school. Self-administered questionnaires remained the principal mode of data collection for all respondent populations. Although the data collection procedures employed in the first follow-up were modeled after those of the base year, the design of the study necessitated four activities that had not been performed previously. First, in order to select the first follow-up sample, an extensive effort was undertaken to locate the nowdispersed base year sample. Second, the base year sample was freshened to generate a representative sample of the tenth-grade class of 1990. Third, off -campus survey sessions, similar to those employed in High School and Beyond, were scheduled for the administration of the student or dropout questionnaire to sample members who were not enrolled in a first follow-up school at the time of data collection. And fourth, to obtain a more precise estimate of the rate of dropping out for the eighth-grade cohort of 1988, a subsample of first follow-up nonrespondents and base year ineligible students was further pursued. The first follow-up survey was executed in four phases which spanned two years. Pre-data collection took place during phases 1 and 2, while data collection took place during phases 3 and 4 as follows: Phase 1. Conducted from January to June of 1989, Phase 1 of the first follow-up survey encompassed the pre-data collection activities of tracing sample members to their 1990 school of attendance and securing state, district, and school permission to conduct the study. Phase 2. From September to December 1989, all first follow-up schools were contacted again in the fall of 1989, primarily to re-verify student enrollment, freshen the core and state augmentation student samples, and schedule in-school data collection sessions. Phase 3. Phase 3 comprised the main data collection period, from January through July 1990. Sample members completed either a student or dropout questionnaire, as well as a cognitive test battery. Data collection took place at either an in-school or off -campus group survey session. Phase 4. After the main data collection period in phase 3, a second data collection effort was undertaken from January through June 1991. An attempt was made to survey certain nonresponding sample members. The number of completed instruments and completion rates based on sample eligibility for the sample members are summarized in Off-campus survey sessions were initially planned as a method for surveying students who were enrolled in schools that had refused to participate in the study or who had transferred to a school outside the original set of first follow-up schools. However, if a student who had missed both the initial in-school session and the make-up session resided close to the site of an off-campus session, he or she was also invited to attend. Off -campus sessions, which typically involved only one to three participants, were conducted using procedures as similar as possible to those of on-campus sessions and were typically held in a public library or community association meeting room. Off-campus survey sessions were held from April to July 1990. If a sample member was unable to attend an off-campus group survey session, he or she was surveyed either in person or over the telephone."}, {"section_title": "First Follow-Up Dropout Survey", "text": "During all four phases of the first follow-up, the enrollment status of sample members was carefully monitored. If a sample member was found to have dropped out of school before data collection, he or she was administered a dropout questionnaire rather than a student questionnaire. Definition of a Dropout. For the purposes of the first follow-up data collection, the following definitions were used to identify sample members who dropped out of school: an individual who, during the spring of 1990, according to the school (if the sample member could not be located), or according to the school and home, was not attending school or, more precisely, had not been in school for four consecutive weeks or more and was not absent due to accident or illness, or 2. a student who, during the spring of 1990, had been in school less than two weeks after a period in which he or she had missed school for four or more consecutive weeks not due to accident or illness. Because contact was made with the schools during each of the four phases during the first follow-up, the enrollment status of each sample member was collected at four separate time periods. If at any point in phases 1 -4 a sample member met the above criteria, he or she was considered a dropout. Some sample members who were initially identified as dropouts later re-enrolled in their school before data collection took place in phase 3. A student in this situation was no longer considered a dropout, but instead was classified as a stopout. Stopouts are defined as a student who had a dropout episode between spring term 1988 and spring term 1990, but who were back in school in the spring term of 1990. At the data collection level, stopouts who were identified in phase 1 or phase 2 as a dropout, but who; in phase 3, had been attending school for two weeks or more were administered the first follow-up student questionnaire and cognitive test battery. Stopouts who had been attending school for less than 2 weeks were administered the dropout questionnaire. When a school official identified a sample member as a dropout, interviewers were instructed to contact the household to confirm the status of the sample member. If either the sample member or an adult household member indicated that the dropout definition above was applicable, the sample member was classified as a dropout. This policy of confirming status through the household was applied during all four points of enrollment status verification.' Furthermore, whenever a sample member was identified as a dropout, the sample member was flagged as such, and the date he or she dropped out of school was recorded. If subsequent enrollment 42 For those cases where the school identified a sample member as a dropout but the sample member or a household member identified the sample member as a student, information about the student's new school of enrollment was collected. The new school was then contacted to verify that the student was in fact enrolled at that school. X05 85 NELS:88 Second Follow-Up Final Methodology Report verification contacts revealed that the sample member had returned to school, the date he or she returned was recorded. Once a sample member was flagged as a dropout, regardless of whether or not he or she returned to school, the flag was maintained. Data Collection. Data collection for the dropout survey was executed during phase 3 from January to July 1990, and phase 4 from January to June 1991. Under the initial data collection period in phase 3, interviewers administered the dropout questionnaire and cognitive tests to cohort dropouts during off-campus group administration sessions, described in section 4.2.1. During phase 4, a second data collection effort took place. In an attempt to obtain a more precise estimate of the cohort dropout rate for the eighth-grade class of 1988, enrollment status information was gathered for nonrespondents, previously identified dropouts (sample members who were identified as dropouts by school officials but not home-confirmed), and base year ineligible students."}, {"section_title": "First Follow-Up Survey of Base Year Ineligible Students", "text": "The Base Year Ineligibles (BYI) Study of the NELS:88 first follow-up was a followback of students who had been excluded because of linguistic, mental, or physical obstacles to participation when the baseline sample of eighth graders was drawn in the 1987-88 school year. The BYI study had several purposes, the primary foci of which were to correct for potential sample undercoverage; to accommodate the group of 1988-ineligible sample members who were 1990-eligible sophomores, and hence must be added to the 1990 survey to ensure its cross-sectional representativeness; and to provide a basis for a corrected cohort dropout estimate taking account of both 1988-eligible and 1988-ineligible eighth graders two years later. Eligibility information was gathered for 93.9 percent of the excluded sample members. For excluded students who were identified as eligible, student or dropout questionnaires were administered either inperson or over the telephone. Cognitive tests were administered to a small percentage of these students. For students who remained ineligible, school enrollment status and other key characteristics were obtained. For eligibility and completion rate data, see "}, {"section_title": "First Follow-Up School Administrator Survey", "text": "In the spring of 1990, the chief administrators of all schools with first follow-up sample members still in attendance were asked to complete a self-administered school administrator questionnaire. Like the base year school administrator survey, first follow-up school principals could designate another knowledgeable school official to complete the first six of seven sections of the questionnaire. The seventh section of the questionnaire, which contained items on school climate, was completed only by the school's principal. The purpose of this option was to lower response burden and increase participation; the first follow-up school questionnaire was more than double the length of the base year instrument. School administrator data were collected in two data collection periods. At the close of the initial data collection period, 77 percent of eligible school administrators had completed a self-administered questionnaire. In the second data collection period, interviewers administered an abbreviated version of the school administrator questionnaire over the telephone. Abbreviated versions of the questionnaire were completed for 21 percent of the respondents, and at the end of the second phase of data collection the school response rate was 97 percent. To ensure comparability of data across the two data collection periods, principals were instructed, during the follow-up period, to reference the 1989-1990 academic school year in their responses. In the event that the school principal from the spring of 1990 was no longer at the school, the next highest administrative official who held a position at the school during the 1989-1990 school year was asked to complete the mail survey or telephone interview. 4.2.5 First Follow-Up Teacher Survey In the NELS:88 first follow-up teacher survey, up to two teachers of each first follow-up sample member were asked to complete a self-administered teacher questionnaire. To maximize the longitudinal comparability of teacher data, NELS:88 first follow-up teachers for each student were selected in the same subject combinations as in the base year: mathematics-English, mathematics-history, science-English, or science-history. Freshened students who were not enrolled in the eighth grade in the base year, and hence had not been assigned a subject combination previously, were assigned the subject combination of their base year \"linked\" partner. In some situations a teacher report was collected in a subject area other than the student's assigned subject combination. If a student were not enrolled in classes in his or her assigned subject area, then a teacher report was collected in another one of the four subject areas. If a student was enrolled only in one of the four subject areas, then only one teacher report was collected for the student. Additionally, the subject area of the student's teacher report was sometimes substituted with another subject area in order to reduce the burden of the teacher survey on teachers who were asked to report on eight or more NELS:88 students. Possible student-teacher subject pairings in the base year and first follow-up were as follows: Data collection for the first follow-up teacher survey occurred in two phases. During the initial data collection effort from January to July 1990, self-administered questionnaires were distributed to teachers at NELS:88 schools. Nonresponding teachers were pursued during the second data collection effort beginning in January of 1991. In the second data collection effort teacher questionnaires were mailed to 2,671 nonresponding teachers, who were instructed to complete the questionnaire with respect to the first follow-up sample member(s) who was enrolled in a particular class the teacher instructed as of spring 1990. No additional follow-up procedures (i.e., telephone interviewing) were undertaken during the second phase of data collection."}, {"section_title": "43", "text": "Same-subject pairings pertain to situations in which either a) different teachers instructed the sample member in the same subject but different courses, or b) the same teacher instructed the sample member in two different courses of the same subject matter. 87 07 NELS:88 Second Follow-Up Final Methodology Report 4.2.6 High School Effectiveness Study: Baseline Data Collection Data collection for the baseline of the High School Effectiveness Study (HSES), an independent component of NELS:88, was conducted concurrently with the NELS:88 first follow-up. The HSES and NELS:88 first follow-up school samples overlapped to a high degree, as did the student samples to a lesser extent. Data collection instruments and procedures for the HSES baseline were almost identical to those used in the NELS:88 first follow-up. In the 247 participating HSES schools, HSES sample members were administered the NELS:88 student questionnaire and cognitive test battery. If HSES students missed their scheduled in-school data collection session, they were surveyed at an off-campus survey session. Unlike the NELS:88 first follow-up, HSES sample members who were no longer attending the HSES school at which they were sampled were not pursued or surveyed; however, enrollment status for these sample members was gathered from their original HSES school. School administrator and teacher data were gathered for HSES students using NELS:88 first follow-up instruments and procedures. A detailed discussion of the data collection procedures for the High School Effectiveness Study is provided in the NELS:88 High School Effectiveness Study: Data File User's Manual."}, {"section_title": "Second Follow-Up Data Collection", "text": "The second follow-up survey collected a third wave of questionnaire and cognitive test data from the eighth-grade cohort of 1988, the majority of whom were high school seniors at the time of data collection. In addition, dropout data were collected, as well as data from students freshened in the first and second follow-ups. As in the base year and first follow-up, contextual data were collected, although with some modification. Rather than collecting two teacher questionnaires for each student, the second follow-up collected at most one teacher report per student. Additionally, teachers were selected only in the areas of mathematics and science; unlike the two prior waves, English and social studies teachers were not surveyed in the 1992 round. The following contextual data were also collected: school transcript data for each sample member; a questionnaire from one parent of each student and dropout; and a questionnaire from the school administrator of each sampled school.\" Self-administered questionnaires remained the principal mode of data collection for all respondent populations. Data collection methods adhered closely to those used in the base year and first follow-up surveys. The design of the second follow-up survey closely resembled that of the first follow-up, including extensive tracing efforts, sample freshening to generate a representative sample of the senior class of 1992, use of both in-school and off-campus survey sessions, and a survey of previously excluded students. The second follow-up survey was executed in three phases which spanned two years. Pre-data collection activities took place during phases 1 and 2, while data collection took place during phase 3. Figure  4-1 summarizes the activities conducted during the three phases of the second follow-up."}, {"section_title": "108", "text": "NELS:88 Second Follow-Up Final Methodology Report Phase 1. Conducted from January to June of 1991, phase I of the second follow-up survey encompassed the pre-data collection activities of tracing sample members to their school of attendance and securing state, district, and school permission to conduct the study. State cooperation with NELS:88 was secured for all fifty states and the District of Columbia. District and school-level cooperation was secured for first follow-up schools with four or more sample members still in attendance in the spring of 1991. Tracing sample members served two purposes: to locate sample members for data collection purposes, and to define the schools to be included in the second follow-up contextual components sample. To maximize the number of students for whom the full complement of contextual data (school administrator and teacher reports) were to be collected, the number of sampled students at each school was determined during tracing. The school sample was then drawn so that the greatest number of students would be included in the school sample. Phase 2. From September to December 1991, pre-data collection activities occurred for all components of the study, and some phase 1 activities continued. District and school-level cooperation were gained for any schools selected for the second follow-up sample for which cooperation was not gained in phase 1. Tracing continued for sample members who were not located during phase 1, and enrollment was verified again for students who were traced to a school which was selected for the second follow-up school sample. Students attending a school not included in the second follow-up school sample and sample members who had left school were also traced again to their school of attendance or to a home address. (For more information about the results of tracing, see chapter IV of the NELS:88 Second Follow-Up: Student Component Data File User's Manual.) Preparation for the collection of contextual data (parent, teacher, school administrator, and academic transcript data) also began in phase 2. Interviewers collected parent address and telephone information for the parent survey. To identify the sample for the teacher survey, interviewers compiled the names of mathematics and science teachers of the student sample members. Course catalogs were collected, and interviewers collected samples of student transcripts to inform data collection and data preparation for the high school transcript component. Phase 3. Phase 3 comprised the main data collection period, from January through June 1992 (although a small number of cases were collected through October 1992). Student questionnaires and cognitive tests were administered to sample members who were currently enrolled in school, and dropout questionnaires and cognitive tests were administered to dropouts, either through an in-school or off-campus group survey session. For the small number of students and dropouts who could not attend an off -campus survey session, telephone interviews were conducted using a version of the student or dropout questionnaire adapted for administration over the telephone. Given the mode of administration, test data were not collected for these sample members.  From January to June 1992, in-school survey sessions were held in all cooperating NELS:88 schools still enrolling second follow-up sample members. Second follow-up data collection procedures were very similar to those used in the first follow-up. Student questionnaires and four cognitive tests in math, science, reading, and social studies were administered in group sessions of approximately nine students during the first data collection at each school, and three students during any second in-school data collection session. Off-campus survey sessions, typically attended by one to three students, were conducted primarily from March to July 1992. Students who were not enrolled in sampled schools, who had missed in-school data collection sessions, or who were enrolled in schools that had refused to participate in the study were invited to off-campus sessions and administered the student questionnaire and cognitive tests. Dropouts were also asked to attend these sessions and were surveyed alongside sample members who were currently enrolled in school. As with in-school survey sessions, off-campus survey sessions in the second follow-up were nearly identical to those in the first follow-up. If a sample member was unable to attend an off -campus group survey session, he or she was surveyed either over the telephone or in person. When the student questionnaire was administered over the telephone, cognitive test data were not collected."}, {"section_title": "Second Follow-Up School Administrator Survey", "text": "In February 1992, school administrator questionnaires were mailed to the principals or headmasters of selected NELS:88 schools with second follow-up sample members still in attendance. Data collection was conducted from February through early July 1992; questionnaires were completed by self-administration and by telephone interview. For any telephone interviews conducted after the end of the 1991-1992 academic year, school principals were asked to refer to the 1991-1992 academic year when answering questions. As in the base year and first follow-up, the school principal or headmaster could delegate all but one of the sections to another knowledgeable school official. Only school principals could complete the fifth section of the questionnaire on school governance and school climate. Because questionnaires from school principals were completed in two different modes of data collection, by self-administration and over the telephone, a number of steps were taken to minimize any mode effects. Telephone interviewers were trained to adapt the questions in a way which made sense when asked over the telephone. If the principal had a copy of the questionnaire, he or she was encouraged to read along in the questionnaire as the interviewer asked the questions over the telephone."}, {"section_title": "Second Follow-Up Teacher Survey", "text": "In the second follow-up teacher survey, one teacher report was collected for each student attending a NELS:88 school who was enrolled in a mathematics or science class. For students enrolled in both a mathematics and a science class, only one teacher report was collected. For these students, the subject area of the second follow-up teacher report was the same as that of the student's base year teacher report. Some second follow-up freshened students, who had no base year subject assignment, were also enrolled in both a mathematics and a science class. For these freshened students, the subject area of the teacher surveyed in the second follow-up was the same as the base year subject area of the student's linked partner in the freshening procedure. The teacher survey was designed to articulate with the student cognitive tests and to minimize the amount of time between the collection of the student and teacher reports. Because students were surveyed at NELS:88 schools from January 1992 through the end of the 1991-1992 academic year, self-administered questionnaires were mailed to teachers in two mailings depending on when the students at the school were 94 i 1 6 surveyed. Teachers at schools at which the students were surveyed before April 1, 1992, were mailed a questionnaire in early February 1992. Teachers at schools at which the students were surveyed on or after April 1, 1992, were mailed a questionnaire in early March 1992. For most students a teacher report was collected from the fall term teacher in the selected subject. However, if the students at a school were surveyed on or after April 1, 1992, then the teacher questionnaire was mailed to the spring term teacher of the selected subject for the student. This design was based on the assumption that early in the spring term, the fall term teacher was the most familiar with and could most fully assess the student.\" After April 1, a teacher report was collected from the spring term teacher because at that time the spring term teacher was more likely to have had sufficient interaction with the student to make a full assessment of the student in the teacher questionnaire, and the fall term teacher might have difficulty recalling a student he or she had not instructed in several months. Interviewing the spring term teacher for students interviewed in school data collection sessions after April 1 also provided better articulation with the student cognitive tests than interviewing the fall term teacher in late spring. Two weeks after the teacher questionnaires were mailed, nonresponding teachers were prompted for the return of the questionnaire with a postcard reminder. Two weeks after the postcard reminder was mailed to teachers, nonresponding teachers were prompted for the return of the questionnaire over the telephone. Teachers who did not respond after the postcard and telephone prompts were interviewed over the telephone. To minimize mode effects between self-administration and telephone administration of the instrument, interviewers were trained to adapt the questions to make sense when read over the telephone. Additionally, teachers were asked to read along in the questionnaire during the telephone interview if they had the copy of the questionnaire."}, {"section_title": "Second Follow-Up Parent Survey", "text": "In the second follow-up, a self-administered, forty-minute questionnaire was mailed to the parent or guardian of selected NELS:88 students in May 1992. Like the base year parent survey, instructions in the questionnaire and accompanying letter directed the parent or guardian who was most knowledgeable about the teenager's current school situation and educational plans to complete the questionnaire. In accordance with these instructions, the respondent was self-selected. Whereas the base year parent survey asked parents to complete the questionnaire near the same time the student was interviewed, the second follow-up instrument included questions about postsecondary educational costs which precluded an exact temporal correspondence between the administration of the two surveys. Because financial aid decisions are frequently not received until late in the spring of the teenager's twelfth-grade year, the parent questionnaires were mailed in May 1992, to ensure that the parents and guardians would be able to answer these questions fully. For parents who completed the interview after the end of the 1991-1992 academic year, the parent questionnaire instructed parents to refer to the spring of 1992 when answering questions about the teenager's school life. The parent instrument was designed as a self-administered questionnaire, but many parents completed the survey over the telephone with an interviewer. To minimize any differences between the two modes of administration, interviewers were trained to adapt the questions to make sense when asked over the telephone. Interviewers also encouraged parents to read along in the questionnaire if they had a copy of the self-administered questionnaire. "}, {"section_title": "Course Offerings", "text": "Course offerings documents were collected from NELS:88 schools in the fall of 1991, for use in transcript coding (see section 4.3.8 below). Additional documents were collected as necessary during transcript collection and processing. The majority of schools provided catalogs with descriptions of the courses offered during the 1991-92 school year. Course offerings documents were also collected from HSES schools."}, {"section_title": "Transcript Component", "text": "In August 1992, transcript survey materials were mailed to the principals of the NELS:88 and non-NELS:88 schools attended or most recently attended by sample members eligible for the survey. (The sample for the transcript component comprised all eligible NELS:88 second follow-up sample members who were: 1) students enrolled in NELS:88 schools; 2) early graduates, regardless of school affiliation; or 3) dropouts [including GED recipients]. Sample members who were ineligible for the base year, first follow-up and second follow-up and were enrolled in the twelfth grade in 1992 were also part of the sample.) Because of the variability in transcript format across schools, explicit instructions for transcript preparation were provided. School staff were asked to retrieve from alternate sources any data elements that were not included on the school's transcripts. Transcript preparers were also asked to note any in-school survey session day transfers on survey documents, to facilitate the pursuit of additional records from transfer schools. Two weeks after survey materials were mailed, nonresponding principals were prompted for the return of transcripts with a postcard reminder. Principals who did not return transcripts within three weeks of the postcard prompt were prompted over the telephone. Telephone prompting of nonresponding principals continued from October 1992 to February 1993. Field visits to schools requesting assistance in the preparation of transcripts were conducted in February and March. Abstraction of student-and course-level data from transcripts began in October 1992 and continued through March 1993. Retrieval of missing critical items from school staff occurred concurrently. Coding of transcript courses began in November 1992, and continued through April 1993. Courses were coded using the course catalog for the school or district, in accordance with the Classification System of Secondary Courses, updated for the 1990 NAEP High School Transcripts Study. When a school or district catalog was unavailable, courses were coded by title alone."}, {"section_title": "High School Effectiveness Study: Followback Data Collection", "text": "Data collection for the followback of the High School Effectiveness Study (HSES) was conducted concurrently with the NELS:88 second follow-up. The HSES and NELS:88 second follow-up school samples overlapped to a high degree, as did the student samples to a lesser extent. Data collection instruments and procedures for the HSES followback were almost identical to those used in the NELS:88 second follow-up. In 246 of the 247 schools participating in the baseline (one HSES school closed between the baseline and the followback), HSES sample members were administered the NELS:88 second follow-up student questionnaire and cognitive test battery. If HSES students missed their scheduled in-school data collection session, they were surveyed at an off -campus survey session. Like the HSES baseline, HSES sample members who were no longer attending the HSES school at which they were sampled were not pursued or surveyed, but their enrollment status was collected from their original HSES school. Parent, school 96 118 NELS:88 Second Follow-Up Final Methodology Report administrator and teacher data were gathered for HSES students using NELS:88 second follow-up instruments and procedures. In the HSES followback, transcripts were collected and processed for all sample members eligible for the baseline or followback. Course offerings documents for the 1991-92 school year were also collected from HSES schools and used in transcript coding. Unlike the NELS:88 second follow-up, school-level and course-level data were also abstracted from the course catalogs and other documents provided by HSES schools. When used with transcript data for HSES sample members, course offerings data facilitate the investigation of coursetaking patterns by student characteristics and the relationship of these patterns to student outcomes. The data also allow for more fine-grained analysis of learning opportunities because the data are informative of all the courses offered at a school during the 91-92 academic year. The following data elements were abstracted from course offerings documents: School-level term system used (quarter, trimester, semester); range of grades in which credits are accrued (grades 9 through 12, or 10 through 12); Carnegie units' in various subjects required for graduation (math, science, social studies, English, vocational education); total Carnegie units required for graduation; high school programs offered (e.g., general, college preparatory, special education); school's modal program; and school's method of computing class rank. Course-level course title and number; duration of course (e.g., quarter, trimester, semester, year); school credits earned for completion of course; Carnegie units earned for completion of course; and a Classification of Secondary School Courses (CSSC) code. A detailed discussion of the data collection procedures for the High School Effectiveness Study is provided in the NELS:88 High School Effectiveness Study: Data File User's Manual."}, {"section_title": "47", "text": "For each school, data entry clerks recorded the number of credits awarded by the school for the successful completion of a one-year academic course taken one period a day, five days a week. This factor, which varied from one to twenty, was used in machine cleaning of the data to standardize school-reported credits to a standard metric, the Carnegie unit. Dividing school-reported credits by the conversion factor yielded credits in Carnegie units. NELS:88 Second Follow-Up Final Methodology Report"}, {"section_title": "V. Data Control, Preparation, and Processing", "text": "Data preparation activities spanned the length of each wave of NELS:88, beginning with tracing and securing school cooperation, through monitoring and machine editing, and ending with the preparation of public-use data files and an electronic codebook (ECB). This chapter uses the second follow-up student component as an example of the procedures used to control, prepare, and process NELS:88 questionnaire data. Procedures were generally consistent across waves and components; however, refer to individual data file user's manuals for additional details about how data processing was conducted for particular components. The construction of the base year through second follow-up combined files and supporting ECBs released in 1995 under the third follow-up is also discussed, and the final section of the chapter describes the confidentiality analysis conducted on the second follow-up data files in order to avoid possible disclosure of respondent or school identities. Similar analyses were conducted in the base year and first follow-up and are described in the NELS:88 Base Year Final Technical Report and the NELS:88 First Follow-up Technical Report, respectively."}, {"section_title": "5.1", "text": ""}, {"section_title": "On-Site Editing and Retrieval", "text": "For student and dropout questionnaires (including the new student supplement), the first data control and preparation activity was editing questionnaires and retrieving missing information. Interviewers conducted on-site editing of the student and dropout questionnaires, giving special attention to the respondents' answers for all critical items. A list of critical items can be found in appendix L in the NELS:88 Second Follow-Up: Student Component User's Manual. If the response to one or more of the critical items was missing, undecipherable, or had multiple categories marked when only one response was permitted, the interviewer privately pointed out the problem to the respondent. If the sample member indicated that he or she had chosen not to answer the question, the interviewer marked a \"no retrieval\" response for the item. The \"no retrieval\" responses were later used during the machine editing process to assign a \"refused\" response to the critical items."}, {"section_title": "5.2", "text": ""}, {"section_title": "Monitoring and Receipt Control", "text": "Once the questionnaires, cognitive tests, and new student supplements were collected, each student and dropout questionnaire was reviewed for completeness and to confirm that the ID numbers were correct. A final disposition code was assigned to each student and dropout indicating whether test data, questionnaire data, or a combination of the two were completed by the sample member. These outcomes were recorded in a microcomputer-based Survey Management System (SMS)."}, {"section_title": "5.3", "text": "In-House Editing and Coding The next step was to edit the confidential locator pages for legibility and remove the pages from the questionnaire. In the student questionnaire respondents were asked to provide the names and locations of the two postsecondary institutions they were most likely to attend after high school. This information was coded using the standard Interagency Postsecondary Education Data System (IPEDS) codes. (IPEDS codes are available only on the privileged use files.) 98 120 NELS:88 Second Follow-Up Final Methodology Report 5.4 Data Capture and Archival Storage Data entry for the student questionnaire and cognitive tests was performed through an optical mark reading procedure by Questar Data Systems, Inc. The new student supplements and dropout questionnaires were not optically scanned but were converted to machine readable form using conventional key-to-disk methods. All cognitive tests were photographed onto microfilm for archival storage."}, {"section_title": "5.5", "text": "Data Processing of the Student Questionnaires In each round of the study, data processing activities began with sample selection and continued through receipt control, machine edit, and the preparation of public and privileged use data files and user documentation. Data processing activities varied little among the base year, first follow-up and second follow-up. This section describes the post-processing that was carried out to prepare the data for final release and concludes with an introduction to the electronic codebooks (ECBs) that have been created for NELS:88 data."}, {"section_title": "Machine Editing", "text": "Conventions for editing, coding, error resolution, and documentation adhered as closely as possible to the procedures and standards previously established for HS&B and NLS-72. Detection of out-of-range codes was completed during scanning or data entry for all questions except those permitting an open-ended response. The scanning contractor converted the student data to machinereadable form and supplied a raw data tape to NORC. Because of their small number, the new student supplements were not scanned, but were data entered. After receipt of all scanned and keyed data, sequenced machine editing and visual inspection of the output began. The tasks performed included: resolving inconsistencies between filter and dependent questions, supplying the appropriate missing data codes for questions left blank, detecting illegal codes and converting them to missing data codes, and investigating inconsistencies or contradictions in the data. Frequencies and crosstabulations for each variable were inspected before and after these steps to verify the accuracy and appropriateness of the automated machine editing processes. Inconsistencies between filter and dependent questions were resolved in the machine editing process. In most instances, dependent questions that conflicted with the skip instructions of a filter question contained data that, although possibly valid, were superfluous. For instance, respondents sometimes indicated \"no\" to a filter question and then continued to answer \"no\" to subsequent dependent items. When a filter question indicated that a subsequent question(s) should have been skipped, the dependent questions were set to the value \"legitimate skip\", with one exception. In the exception, if the dependent questions were answered in a manner that was inconsistent with the filter but consistent across the dependent items, the filter was back edited (changed) to agree with the dependent responses. If a multiple response or no answer was given to a filter question, the question was assigned the appropriate reserved code (see below) and all subsequent questions that might have been skipped were processed as if the respondent should have answered them. The frequency with which responses were recoded to legitimate skip for each skip pattern was closely monitored. Frequency distributions of responses before and after editing were inspected. All filter questions and their respective dependent items were displayed in crosstabulations so that staff could verify the accuracy of the recoding. 121 99 NELS:88 Second Follow -Up Final Methodology Report After improperly answered questions were converted to blanks, the student data were passed through a second step in the editing program that supplied the appropriate reserved codes for blank questions. Where a value was not provided by the respondent, a reserved code fills the field. These reserved codes and their meanings are as follows: When the legitimate response of a variable filled more than one column of space, the right-hand column contained one of the above codes and the remainder of the columns were filled with \"9\"s. Critical items (those deemed most critical to data analyses) followed a somewhat different machine editing process. Data collection procedures instructed field interviewers to mark the retrieval oval beside each critical item in the questionnaire if an attempt was made to retrieve missing or invalid data from a respondent. The edit program then used these fields to set corresponding blank data to \"refused.\" Since their purpose was to determine the correct reserved codes, retrieval variables are not present on the final data file. If a critical item was left blank, was not a legitimate skip, and an attempt was made to retrieve the missing data, the item was coded as \"8\" (missing). If a filter was coded \"7\" (refused), all subsequent questions that might have been skipped were processed as if the respondent should have answered each item. Filters that were coded \"6\" (multiple response) or \"8\" (missing) were handled in the same manner. Items with unusually high nonresponse or multiple responses were checked by verifying the data in the questionnaire (on microfilm for students and dropouts, hardcopy for new student supplements). Finally, while many of the same items appear in both the main student and dropout questionnaires, occasionally the response codes used in the two questionnaires were different. In addition, some of the response scales used were the same as those used in earlier waves and/or HS&B but with the scale reversed. After machine editing was completed, the affected items were recoded. Student questionnaire items were recoded to match comparable items in HS&B and earlier waves of NELS:88. The dropout items were recoded to coincide with the student codes. Because response scales were recoded on questions that may not be strictly compatible, analysts should assess the comparability of questions when comparing NELS:88 second follow-up with earlier NELS:88 waves or HS&B. (The questionnaires that are presented in appendix K of the NELS:88 Second Follow-Up: Student Component User's Manual have been modified to reflect these recodes; these questionnaires should match the data presented in the codebook that appears in appendix J of the same manual but vary somewhat from the optical scan format instrument that was administered to NELS:88 students.) 5.5.2 "}, {"section_title": "Data File Preparation", "text": "The conventions used to assign SAS and SPSS-X variable names are as consistent as possible with HS&B and NLS-72. In those two surveys, variable names were assigned according to the survey wave and the question number. A similar system was developed for NELS:88. For example, BYS56A, is from the base year student survey, question 56, part A. Likewise, F I S7D, is from the first follow-up student survey, question 7 part D, while F2S84C is from the second follow-up student survey, question 84 part C. This code was used only when a critical item was missing and the retrieval oval was checked by the field interviewer, indicating that the respondent refused to answer. Constructed variablesincluding statistical weights, special indicators or flags, and variables that are composites of one or more sourcesare added to the files in order to promote high caliber analyses of the NELS:88 data. Certain items add information from study sources that would otherwise be unavailable to users; some items reference respondent properties to external standards that would be expensive for individual analysts to create; and other items are recodes or combinations of internal questionnaire sources. A number of composites have appeared in earlier rounds and represent a convenience for the analyst, rather than wholly new information. Some of these constructed variables will be used by nearly all users, while others will be appropriate to those seeking insights into distinctive populations, relationships or events. Generally, the names of the base year flags, variables, and weights begin with BY; the first follow-up flags and weights begin with Fl; and the second follow-up names begin with F2. If the variable is a schoollevel variable placed on the student file, the composite variable name begins with G8 (for grade 8 in base year), G10 (for grade 10 in the first follow-up) or G12 (for grade 12 in the second follow-up). A few composite variables that were built in the base year do not begin with the prefix \"BY.\" These are: SEX, RACE, HISP, API, HEARIMP, HANDPAST, BIRTHMO, BIRTHYR. Over the course of the survey even basic demographics such as gender and ethnicity are re-examined and improved when and if new and/or more accurate information becomes available for particular cases (thus there is an F I SEX on the first followup files, an F2SEX on the second follow-up files, etc.). The only reserved code used for all of these specially constructed variables is for missing data. For one-column variables that code is \"8.\" Variables that are greater than one column in length are filled with \"9\"s (i.e., 998) in all but the right-most column. This reserved code is used when the sources for data are missing due to either item nonresponse, nonparticipation in all or part of the components of the study, or when data are missing on one or more external source files. Appendices H in the base year manual, I in the first follow-up manual and H in the second follow-up student manual explain the conditions under which specific composite variables were assigned a missing code."}, {"section_title": "5.6", "text": "The 1995 NELS:88 CD-ROMs: Base Year through Second Follow-Up Data Files and"}, {"section_title": "Electronic Codebook", "text": "For the 1995 release of the base year through second follow-up data on CD-ROM under the third follow-up, datasets with the same unit of analysis that had previously been released as separate files were combined to create files with multiple records per case. The 1995 student-level file, for example, incorporates data from 15 NELS:88 components, including base year, first follow-up, and second follow-up student, parent, teacher, and school (at the level of the student) questionnaire data. The 1995 privileged-and public-use files also contain NELS:88 data never before released on CD. In addition to the base year through second follow-up data files, the 1995 CD-ROMs contain data for respondents to the 1994 third follow-up of NELS:88. Third follow-up data have been integrated with data from the base year through second follow-up for the third follow-up sample. Full documentation of the contents of the CD-ROMs is provided in the NELS:88 User's Guide for the 1995 Electronic Codebook Systems and Base Year through Third Follow-Up Public Use [Privileged Use] Data Files on CD-ROM. The 1995 data files are fully supported by electronic codebook (ECB) systems. While the ECB system is primarily an electronic version of a fully documented survey codebook, it has other important 101 123 NELS:88 Second Follow-Up Final Methodology Report features. The list below summarizes the major options that the ECB software provides to NELS:88 researchers: users can electronically browse a list of all the variables and composites contained on the NELS:88 data files; using key words or variable names/labels, users can electronically search for variables that are relevant to their research questions; the ECB provides an electronic display of the full question text of each variable in the database, along with notes and other pertinent information; the ECB displays the SAS code that was used to create composite variables (if all of the variables that were used to construct the composite are also present on the data file); the ECB includes electronic display of the distribution of raw counts and percentages for each variable in the database; and the ECB permits users to select or \"tag\" variables of interest. Users can subsequently: print a hardcopy codebook that displays the distributions of the tagged variables; generate SAS-PC, SPSS-PC+ or SPSS-for-Windows program code for the tagged variables (that in turn can be used with a user's own SAS or SPSS statistical software); generate a \"tag\" file which will save the set of tags for import in a future application. The NELS:88 ECBs run on IBM-compatible PCS equipped with compact disc (CD-ROM) readers and are available in both DOS and Windows versions. Both the ECB software and the NELS:88 raw data files reside on the CD-ROM."}, {"section_title": "5.7", "text": ""}, {"section_title": "Confidentiality: Protection Against Statistical Disclosure of Respondent Identities", "text": "A confidentiality analysis was conducted in the second follow-up order to avoid possible disclosure of respondent or school identities. Any variable which, by nature, could be used to identify certain individuals or schools must be masked in order to protect the anonymity of the respondent. Procedures for accomplishing this task while maintaining quality of the data are covered in this section."}, {"section_title": "General Strategy", "text": "Disclosure avoidance involves two basic procedures for identification of high-risk variables. First, certain data elements may be identified a priori as posing disclosure risks. Variables that constitute virtually unique data signatures pointing to given individuals or schools (for example, many continuous variables), extreme outliers that may be associated with publicly known characteristics of an institution or individual, and finer-grained versions of school-level variableS that can be linked to universe files all fall within the category of pre-identifiable high-risk variables. Second, other data elements may be identified a posteriori, that is, empirically, as posing a disclosure risk. Disclosure avoidance requires that potentially revealing school-level information from the NELS:88 second follow-up data files be analyzed in conjunction with data available from school universe files. Where school matches permit institutional identities to be deductively disclosed, further modification of school-level, and sometimes student-or teacher-level, variables may be required. This section reports how high-risk variables from NELS:88 were identified, that is, the specification of data elements that, from inspection of response frequencies or on purely a priori grounds, clearly need to be masked or altered if disclosure risks are to be minimized. For the variables that were also included in the universe matches, further abridgements, recategorization, or masking were necessary. These alterations are discussed in section 5.7.2. Preliminary Modifications: Student File. The only modifications to the student file were those alterations that were required as a continuation of confidentiality edits implemented for the base year and first follow-up data and those that resulted from the current, school-based confidentiality analysis. As an example of the first type of alteration, the questionnaire-specific race/ethnicity data and the composite race/ethnicity data for two schools had to be suppressed (set to missing) on the student data file when these schools with unique racial compositions produced matches between NELS:88 base year schools and public school universe files. Since, working backward to the base year school, race-ethnicity information would still be at risk of disclosure in the second follow-up despite the change in schools of the involved individuals between 1988 and 1992, these data elements were suppressed in the second follow-up.' The second type of modification involved making sure the abridgements, recategorizations, and maskings made for confidentiality purposes on school data were carried over to the student records. Preliminary Modifications: School File. One of the most important initial steps in constructing the NELS:88 second follow-up public use school file was to make sure that variable suppressions or recodes used to meet confidentiality requirements in the NELS:88 first follow-up public use school file were carried over. Table 5.7.1-1 shows a list of items, indicated by their questionnaire number, suppressed or recoded in the NELS:88 first follow-up public use School File and their equivalent second follow-up items, also indicated by questionnaire number. All of the items suppressed for the first follow-up public use school file were suppressed for the second follow-up public use file. All of the first follow-up recoded items listed in table 5.7.1-1 were asked in the second follow-up using the same response categories, and recoding for the second follow-up public use file reflect what was done for the first follow-up public use file. In the following section, the analyses and measures undertaken by NORC to assess and eliminate disclosure risk from matching the NELS:88 first follow-up school file with universe files are described."}, {"section_title": "2", "text": "Specific student variables that were suppressed or altered for an extremely small number of schools in order to protect confidentiality of the data were F2RACE1, F2N17, F2N18, F2N19, and G12URBN3. Suppressed or altered parent variables include F2P19, F2P20, F2P21, F2RACE1, F2API, and F2HISP. Step 1. The first step in the disclosure analysis was to assess disclosure risk against the universe file containing both public and private schools. Six variables that were in both the second follow-up NELS:88 school data and the universe file were identified, and categories for the variables were chosen. The selected variables were then categorized as closely as possible across the two files in preparation for the calculation of a distance metric. The distance between schoolsone on the NELS:88 file and the other on the universe filewas measured using a \"code distance\" metric. Variables were included in the code distance measure only if they were not missing on both files. With the code distance measure, results of a code change for confidentiality for a particular school can be readily observed."}, {"section_title": "125", "text": "A number of distance measures were available for each schoolthe school's distance with itself and the school's distances with other schools on the universe file. For each NELS:88 school used in the analysis, the distance measures associated with the school were rank-ordered. The actual code distance values associated with each school are, for the most part, irrelevant for this analysis. The important measure is the relative ranking of the school's distance from itself compared to its distance from other schools. Results. Ten schools in the NELS:88 file were found to be at risk of disclosure, and recoding was implemented to minimize the risk of disclosure. Based on the assessment of the analytic importance of the matching variables, it was decided to recategorize variables in the following order: number of teachers, total 104 126 NELS:88 Second Follow-Up Final Methodology Report school enrollment, percent white, and percent free lunch. Grade span and urbanicity would only be considered if changes to these other variables did not sufficiently reduce disclosure risk for a school. Further, if it was necessary to adjust grade span or ethnicity, the values were set to missing rather than changed. The decision to set variables to missing or recategorize values was the result of a complicated set of considerations in which reduction of the analytic utility of the file was balanced with the efficient reduction of disclosure risk. To preserve the data for analysts, it would be preferable to make values missing. Unfortunately, a greater number of iterative analyses are necessary to determine the effect of making values missing on relative rankings of distance measures. This is not the case when values are changed. In fact, the effect on relative rankings of distance measures can usually be seen quite readily. Because of this, the number of iterative analyses necessary to demonstrate that disclosure risk is safely minimized is reduced considerably. After recoding was performed to eliminate disclosure risk, no schools were found to be at risk for disclosure from the universe file. Method: Step 2. The next step in the disclosure analysis was to assess disclosure risk against the universe file of public schools. The same six variables used in step 1 of the analysis were used in the comparison to the public school universe file. For the variables that were also used in the previous analysis, all categories, recodings, and changes that were necessary to eliminate disclosure risk with respect to the public and private school universe file were carried over into this analysis. Results. When the public school universe file recoding was completed, step 1 was repeated using the newly recoded schools. A few schools turned up as disclosure problems and required further recodes. "}, {"section_title": "NELS:88 Research Bibliography", "text": "The number of published articles, doctoral dissertations, presentations and reports using NELS:88 data continues to grow. The variety of topics addressed ranges from studies of the quality of the middle and high schools attended by 1988 eighth graders who, before school entry, had attended Head Start (Lee & Loeb, 1995), to an examination of how many 1992 high school seniors would have met the new (effective fall 1996) National Collegiate Athletic Association academic eligibility requirements for freshman participation in Division I college varsity sports . Some examples of topics addressed in recent analyses using NELS:88 are listed below. These examples appear under seven broad research rubrics. (See appendix R for a depiction of NELS:88 questionnaire content in relation to each of these seven thematic areas.) These rubrics are: Cognitive growth: achievement gain in math, science, reading and social studies 2. Dropping out of school 3. Equality of educational opportunity: equity, access and choice"}, {"section_title": "4.", "text": "Effects of ability grouping, tracking, and grade retention Parental involvement and home effects 7. Transitions: from eighth grade to high school; from secondary education to postsecondary and the labor market. In addition, two special rubrics have been provided. One special category is for intercohort comparisons that depict trends between the time of NLS-72, HS&B, and NELS:88. The second encompasses crosssectional descriptive analyses of representative samples of eighth, tenth and twelfth-grade studentsa snapshot, as it were, of each cohort, at a point in time (spring 1988, spring 1990, and spring 1992). 1. Cognitive growth: achievement gains in math, science, reading and social studies; --achievement gains between grades 8 and 10, 8 to 12, and 10 to 12 (Scott, Rock, Pollack & Ingels, 1995;Rock, Owings, & Lee, 1994;Hoffer, Rasinski & Moore, 1995;; Madigan, forthcoming); 2. Dropping out of school --high school dropouts Jordan, Lara & McPartland, 1994;Rumberger, 1995; Scott, Rock, Pollack & Ingels, 1995;Kaufman, McMillen & Sweet, 1996;Teachman, Paasch & Carver, 1996)  3. Equality of educational opportunity: equity, access and choice --Equality of opportunity: opportunity to learn (Stevenson, Schiller, & Schneider, 1994;Smith, 1996) --Equality of opportunity: racial/ethnic, language minority, and socioeconomic status subgroup differences (Braddock et al. 1991;Bradby, 1992;Solorzano, 1992;Kerbow & Bernhardt, 1993;Steelman and Powell, 1993;Davis & Jordan, 1994;Kennedy & Park, 1994;Peng & Hill, 1994;Peng & Lee, 1994;Peng & Wright, 1994;Fejgin, 1995;Kao, 1995;Kao & Tienda, 1995;Osbourne, 1995;Kim, forthcoming) --Equality of opportunity: special populations (the gifted; students with disabilities): (Sayler & Brookshire, 1993;Snow & Ennis, 1994;Hodapp & Krasner, 1995;Rossi, Herting & Wolman, forthcoming). --Equality of opportunity: students \"at risk\" and students in urban areas characteristics of and outcomes for (two and four years later) eighth graders with risk factors, Finn, 1993;Green & Scott, 1995); educational conditions in urban schools (Peng, Wang & Walberg, 1992;Lippman, Burns & McArthur, 1996;Gamoran 1996) --Equality of opportunity: gender differences (Catsambis, 1994(Catsambis, , 1995Hedges & Nowell, 1995;Mau, Domnick & Ellsworth, 1995;Lee, Chen & Smerdon, 1996;Burkam, Lee & Smerdon, 1997;LePore and Warren, 1997). --School choice: its impact on students and teachers (Sosniak & Ethington, 1992;Plank, Schiller, Schneider & Coleman, 1993); differential pursuit of opportunities for school choice by various racial/ethnic groups (Schneider, Schiller & Coleman, 1996); 4. Effects of ability grouping, tracking, and grade retention --the impact of tracking and ability grouping (Braddock & Dawkins, 1993;Burks, 1994); --the impact of grade retention (Meisels & Liaw, 1993).\nTus respuestas serin combinadas con las de otros estudiantes, y nunca serail identificadas como tuyas. El prop6sito de este estudio es obtener informacion para mejorar la comprensi6n por parte de los profesores y de los educadores sobre las diversas experiencias que atraviesan los estudiantes de escuela secundaria. Este cuestionario no es una prueba. El Centro necesita tus respuestas, y por eso confia en que contestards cada pregunta honestamente. Puedes dejar sin responder cualquier pregunta que prefieras no contestar. El tiempo que Ileva participar en la presente recolecchin de datos ha sido estimado en un promedio de tres horns (180 minutos), incluyendo una hors para contestar el cuestionario, hors y media para el Test Cognitivo y un maxim\u00b0 de media hors pars la distribucion de materiales y el suministro de instrucciones. Por favor, dirige tus comentarios relacionados con esta Los datos de este cuestionario seran utilizados por educadores y planificadores a nivel federal y estatal a fin de abordar los importantes problems que confrontan las escuelas de la nacion: normas de la educacion, informacion actualizada sobre el desempefio en los programas de estudios, abandono de los estudios, educacion de las personas desaventajadas, necesidades de los estudiantes pertenecientes a minorias linguisticas, incentivos para atraer estudiantes hacia el estudio de las ciencias y las matematicas, asi como las caracteristicas de las escuelas efectivas. En la cubierta de este cuestionario encontrara el nombre de un muchacho(a). Por favor verifique la cubierta para cerciorarse de que ese nombre corresponde al del muchacho(a) por el cual Ud. o su esposo(a) o compafiero(a) son responsables. El cuestionario debera ser completado por el padre o guardian que mss sabe acerca de la situacion escolar y los planes de educacion actuales del estudiante. Si Ud. es la persona indicada, por favor llene el cuestionario y envielo de regreso en el sobre con franqueo pagado que le proporcionamos. Si  Es importante que sepamos quienes son las personas consideradas como los padres o guardianes de los muchachos(as) en este estudio. Por este motivo, en reiteradas ocasiones le pedimos que nos informe sobre su \"ESPOSO(A)/COMPASTERO(A)\". Cada vez que en este cuestionario le preguntemos por su ESPOSO(A) /COMPANERO(A), nos referimos a: 1."}, {"section_title": "School and teacher effects", "text": "--students' instructional experience in mathematics and science (Horn & Hafner, 1992;Hoffer& Moore, 1996); --the comparative effectiveness of magnet schools, Catholic schools, and secular private schools, in increasing the achievement of urban high school students (Gamoran, 1996); 1 2 9 107 NELS:88 Second Follow-Up Final Methodology Report --the relationship between school characteristics and curricula, and student outcomes Smith, 1992, 1995;Finn & Voelkl, 1993;asinski & Pedlow, 1994;Boozer & Rouse, 1995;Voelkl, 1995;Lee, Chen & Smerdon, 1996;Powell, 1996;Lee, Smith & Croninger, forthcoming 1997;Shouse, forthcoming 1997.) --the relationship between teacher characteristics (such as training, race, gender) and student outcomes (Ehrenberg, Goldhaber & Brewer, 1995;Chaney, 1995); 6. Parental involvement and home effects --the effects of parental involvement on student achievement (Horn & West, 1992;Keith et al. 1993;Muller, 1993;Muller & Kerbow, 1993;Keith & Lichtman, 1994;Muller, 1995aMuller, , 1995bSui-Chu & Willms, 1996);. --family structure effects on student outcomes (S.A. Lee 1993;Downey & Powell, 1993;V.E.Lee, Burkam, Zimiles & Ladewski, 1994;Finn & Owings, 1994;Downey, 1995aDowney, , 1995b --family versus school effects on student achievement (Grissmer, Kirby, Berends & Williamson, 1994) 7. Transitions: from eighth grade to high school; from secondary education to postsecondary and the labor market. --the transition from eighth grade to high school Scott, Rock, Pollack & Ingels, 1995); --postsecondary transitions: Sanderson, Rasinski, Dugoni & Taylor, 1996) 8. Intercohort comparisons: --trends in participation in secondary vocational education, 1982education, -1992education, (Tuma, 1996; --trends among high school seniors, 1972-1992 Morgan, 1996); --trends among high school sophomores, 1980; Wang, Schiller & Plank, forthcoming); --trends among high school dropouts, 1982dropouts, and 1992dropouts, (McMillen et al. 1993Kaufman, McMillen & Sweet, 1996); 9. Cross-sectional descriptive summaries: --characteristics of American eighth graders, high school sophomores, and seniors Ingels, Schneider, Scott & Plank, 1995;Green, Dugoni, Ingels & Camburn, 1995) and the schools attended by eighth graders (Hoachlander, 1991). 108   130NELS:88 Second Follow-Up Final Methodology Report A NELS:88 bibliography is maintained on-line on NCES's gopher server, gopher.ed.gov; a jughead search of all gopher menus for \"NELS:88 bibliography\" will reveal its location. There were 289 entries as of March 31, 1996. The bibliography contains the following: name of author(s), publication source, content abstract, and information about page length, number of tables, and number of graphs. Apart from its richness as a source of multilevel longitudinal data NELS:88 has featured a number of innovations that extend its range and power beyond that of prior NCES longitudinal studies of high school students. One such innovation is sample freshening. Although NELS:88 began with a 1988 eighth grade cohort, two and four years later, original sample members were not fully representative of 1990 sophomores or 1992 seniors, since not all students proceed through school in the modal sequence (some are held back, some drop out, some move through high school at an accelerated pace) and since new students enter the system through immigration. Consequently, the student sample was freshened in 1990 to create a valid probability sample of sophomores, and in 1992, to create a valid probability sample of seniors. This was done by identifying 1990 sophomores and 1992 seniors who were not in the 1988 eighth grade sampling frame and giving them a chance of selection into the later rounds. This freshening procedure underwrites valid cross-sectional generalization about eighth graders, sophomores, and seniors, at the three points in time, and permits longitudinal analysis of three distinct panels: 1988 eighth graders, 1990 sophomores, and 1992 seniors. A second major innovation in NELS:88 addresses a significant weighting problem in school-based longitudinal surveys of students. By 1990 the 1988 eighth graders had dispersed to many high schools. The high schools to which eighth graders had dispersed did not constitute a national probability sample of high schools. Three different methodologies for simulating selection probabilities for 1990 high schools were developed and compared, within a probability subsample of the NELS:88 schools. In addition, student samples were augmented and made representative within these same schools, in order to facilitate the study of school effects. A third major innovation in NELS:88 concerns the treatment of excluded students, that is, potential sample members who were declared ineligible because of obstacles to completing the survey forms (for example, severe mental or physical disabilities, inability to complete English language instruments). A subsample of the excluded students was followed, so that eligibility status could be reassessed and eligibility change accommodated (e.g., a student excluded for language reasons in 1988 who subsequently became proficient in English would be drawn into later rounds of the study), so that the biasing impact of exclusion on estimates could be studied, and so that key national statistics (such as cohort dropout rates) could be generated without bias. Other innovations in NELS:88 involve reporting of data, particularly cognitive test scores. NELS:88 and NAEP 1992 twelfth grade mathematics scores were equated. Also, NELS:88 1990 and HS&B 1990 mathematics scores were put on an equivalent scale. NELS:88 reported not only normative scores but criterion-referenced proficiency levels, including scores on the probability of proficiency at a given mastery level that permit analysts to identify where on the growth curve, in terms of behaviorally anchored skills or knowledge, achievement gains took place. One final innovation involving the NELS:88 cognitive assessments was the use of two special strategies to increase accuracy of measurement and avoid floor and ceiling effects: (1) an adaptive multi-form approach (the specific form assigned in 1990 and 1992 depended 131 109 NELS:88 Second Follow-Up Final Methodology Report on the prior round ability estimate [theta] for the math or reading subtest) and 2special vertical scaling procedures that allowed for Bayesian priors on subpopulations for both item parameters and scale scores. It would be sensible to repeat these basic innovations in future longitudinal studies of secondary schooling. However, there are a number of ways that NELS:88 could have been improved, and a number of further innovations that should be considered in undertaking any new NELS-like study."}, {"section_title": "Sampling and Weighting", "text": "There are a number of issues to consider in sample design and weighting. These include: the choice of whether to optimize the longitudinal features of the design, the choice of how to build a design suitable for studying school effects (especially if the starting point is immediately prior to high school), the issue of missed or excluded populations, the need to improve models of unit nonresponse, the need to accommodate missed transfers-in in the weighting scheme, and the desirability of automating the weighting as part of the data analysis system or electronic codebook. A Robust General Purpose Sample Design, Versus a Sample Design Optimized for Measuring Achievement Growth. One basic issue from the outset is sample size (at both the school and student level) and number of measurements to be taken. If one wishes to exploit the longitudinal character of the design, for example, by focusing on a particular set of dependent variables, such as growth curves (here the mean rate of change rather than changes in means and proportions is the important variable), one may not need so large a sample as otherwise, but might benefit from getting more measures per child (for example, by testing students more often). An optimized design can be supported by smaller sample sizes yet produce more precise estimates for a particular design variable of interest. On the other hand, a robust design is particularly suited to a multipurpose study, which must answer a range of questions, sometimes even questions that were unforseen at the design stage. Studies such as NELS:88 have reflected a robust design for this reason. However, the tradeoffs between robustness and optimization must always be reconsidered, each time a new study is to be designed. Sampling: dealing with the middle school to high school transition. The High School and Beyond sophomore cohort was ideally suited for study of school effects in that most 1980 sophomores were in the same schools two years later at the time of the first-follow-up. However, the basic design of NELS:88 was that of a longitudinal study of eighth grade students typically dispersing to new (high) schools. It is possible in such a design to achieve both a student panel for measuring change over time, and, through sample freshening, a representative sample of tenth and twelfth grade students, comparable to the sophomore and senior cohorts of HS&B and NLS-72 seniors. While such a design supplies much information about the individual correlates of student learning, it provides far less basis for answering questions about the internal organization of secondary schools and the way that structural, management and climate characteristics of schools produce differential experiences among both students and teachers, influence student engagement, and shape the school as a workplace for teachers. For three basic reasons, the student-focused design of NELS:88 does not provide a strong basis for addressing high school effectiveness issues. First, neither NELS:88 eighth graders two years later, nor the freshened NELS:88 sophomore cohort, necessarily constitutes a representative sample of their high school's sophomore class. Any given high school may have multiple feeder schools which may have very different student populations; NELS:88 students within the high school may represent only a single eighth grade feeder school. Since NELS:88 eighth graders cannot be presumed to be representative of the high schools they attend, student data, even 110 132 NELS:88 Second Follow-Up Final Methodology Report where NELS:88 eighth grade cohort members are sufficiently numerous, cannot be used to estimate withinschool relationships. While freshening adds students who entered the school from the wider universe of schools, the freshened students represent only the population of sophomores who were not in eighth grade two years before. Second, the resulting student samples, even if they were representative, would be rather small for school effects research. The number of persons sampled per school increases the precision of school-specific estimates (e.g., mean achievement status and mean rate of cognitive growth in a school), with the benefit of adding students depending on the magnitude of variation among students within schools. The average participant cluster size in the NELS:88 base year was 23 students, but the average in the first follow-up was 14 and in the second follow-up 11. In HS&B, reasonable school effects analyses were conducted, but typically cluster sizes were around 30 students. Less than 2 percent (28) of the NELS:88 high school sample had cluster sizes of 30 or higher. Urban students had particularly high dispersion rates and attendant low NELS:88 cluster sizes. A third limitation of the eighth grade cohort sample for high school effects research is that the 1990-1992 school sample was not selected by probability methods. The schools associated with the 1990 first follow-up student sample were selected as a direct consequence of the fact that one or more NELS:88 base year students were attending the school in 1990. The difficulty in creating weights for the 1990 tenth grade schools stemmed from the fact that the probability that a given NELS:88 student selected in 1988 will be attending a given school in 1990 cannot easily be determined. Stated differently, in 1990, schools were not selected with known probabilities from an initial complete sampling frame. Rather, 1990 schools were a set of schools that the initial 1988-selected sample happened to be attending in 1990. The High School Effectiveness Study was designed to enhance the capacity of the NELS:88 data set to study within-school processes. Additional high school sophomores were added within a probability subsample of NELS:88 so that the supplement can provide robust, representative, within-school student samples, while supplying a school-level weight capable of underwriting generalizations to all schools in the United States in the thirty largest Metropolitan Statistical Areas. However, should an eighth-grade starting point be chosen for future high school studies, alternative strategies should be considered also, such as drawing high schools and, simultaneously, selecting an eighth grade school sample that feeds them. Four distinct approaches to generating a representative tenth grade school sample from an eighth grade sample are presented in Spencer, 1987; such approaches are worthy of further investigation. In addition (and regardless of whether the study starts in eighth grade, or high school), if school effects is to be a major focus, it may be sensible to go to somewhat fewer schools but select larger student samples. Though for national statistics, a larger design effect will result, the precision of in-school estimates would be enhanced, if, say, instead of selecting 24 students in 1,052 schools, 32 students were selected in 800 schools. Sampling: Ineligibility and exclusion. Historically, certain groups of students have categorically, or on a case-by-case basis, been excluded from national data collection programs. In particular, students with physical or mental disabilities have had a high rate of exclusion (McGrew, Thurlow, & Spiegel, 1993), as well as students with limited English proficiency. There are various motives for excluding such students, ranging from added cost (for example, lack of resources to provide individual test or questionnaire administrations, multiple shorter testing sessions, translations into Braille or other languages, and so on), to concern about validity of assessment data they might provide (for example, can a test in English be a true test of the knowledge of a student whose English proficiency is severely limited?), to concern about the wellbeing of the child (for whom the task of completing a questionnaire or assessment may be inappropriate or unduly onerous). While circumstances may preclude some students from completing assessments, there may be ways to increase the number of students who can be assessed. In addition, there would seem to be no 133 justification for excluding students from research programs such as NELS:88 simply because they cannot complete an achievement testdata can be collected on these students by other means, including teacher and parent reports and abstraction of school records. ingels (1996) discusses thirteen suggestions for achieving greater inclusiveness of test and questionnaire data from special needs populations. No student should be declared ineligible for a future NELS-like study on the basis of disabilities or limited English proficiency. Sampling and Weighting: Modeling and adjusting for nonresponse. In the NELS:88 base year, at the time of sample selection information was collected about sample members as to whether they were male or female, and whether they were Hispanic, Asian, or other. Additional information was collected using student and.parent questionnaires, but for nonrespondents this information is missing. It is desirable to collect more data at the time of sample selection, data that will support a more sophisticated model of nonresponse, and help provide an improved assessment and adjustment for the impact of nonresponse. Collecting additional data on all selected students from school records at the time of selection will provide richer information on nonrespondents. At minimum, further race data should be collected at the time of sampling (for example, categories such as black, white and American Indian should be used as well as Asian and Hispanic) and further records data such as attendance, test scores or grade point average or class rank, and whether limited in English language proficiency, would be of interest as well. Logistic regression can be used to model the likelihood that a given student will complete the survey; these response propensities can be used to develop adjustments that compensate for the effects of sample attrition. Sampling and weighting: Sample updates and transfers-in prior to Survey Day. Missed transfer students are potentially a problem in the baseline of a school-based longitudinal survey. NELS:88 followed the same basic procedure for dealing with transfer students as did High School and Beyond (HS&B) in 1980. School rosters were submitted and an initial sample dawn in the autumn. To adjust the student sampling frame for student attrition and change, a sample update was conducted seven to ten days prior to the school's scheduled survey session. The NORC survey representative went over the sample list with the school coordinator to ensure that all sampled students were still enrolled and eligible, and that transfers into the schoolthat is, any student who had joined the eighth grade class between the time of original sampling and the updatewere added to a supplementary roster from which additional students would be selected. Given low mortality and dropout rates, one would expect rough parity in gains and losses through transfer, but while about four percent of the NELS:88 eighth grade sample transferred out prior to survey day, but replacement procedures added only around two percent. This experience is not peculiar to NELS:88. For example, for the NAEP Trial State Assessment in 1990, Spencer (1991, p.6) reports that 4.9 percent of students withdrew from the sample but supplemental sampling added only 2.9 percent. Unfortunately, while there can be no error about who has transferred out prior to survey day, there is often inaccuracy in records provided by schools about who has transferred in subsequent to a given date. In future studies, missed transfer students should be accommodated in the weighting. Race/ethnicity, gender, and other basic information should be collected at the time of initial sampling and undercoverage of transfer-ins compensated for by modifying the weights of this group appropriately. Weighting: on-line computation of analysis weights. In the NELS:88 base year, two final (that is, nonresponse-adjusted) weights were created, a student weight and a school weight. For the first follow-up, however, panel weights were required in addition to cross-sectional weights, and four new nonresponseadjusted weights were generated. In the second follow-up, 9 new weights were produced, and in the third follow-up, an additional 11 weights. All told, 26 NELS:88 final weights have been produced, appropriate to a variety of situations. However, even with this number of weights, not all situations of potential analytic interest are covered (for example, there is no panel weight for analyzing change between 1988 to 1992 that is inclusive of the cases for which there is data is 1988 and 1992 but not 1990; there is no 1988 to 1992 parent weight; and there is no weight with a special nonresponse adjustment for questionnaire respondents with missing cognitive test data). There is a tension between the need to cater to the full range of analytic needs, and the desirability of keeping the weights as few and simple as possible, so that they can be used without error or confusion. One way to simplify the use of the weights for the user while providing maximum coverage of situations in which different weights might be required is to incorporate a system of \"weighting on the fly\" in the data analysis or electronic codebook systems. Developing an on-line system for computing panel weights is technically feasible for studies such as NELS:88 and would constitute a major service to data users. Short of this, building a weighting advisory function into the Electronic Codebook would be of utility to analysts."}, {"section_title": "Archival Data: School Records", "text": "High School Transcripts. The immense value of school transcripts as objective, reliable measures of crucial aspects of students' educational experiences is widely recognized. With respect to level of detail, accuracy, and completeness, transcript data are vastly superior to student self-reports of exposure to learning situations.' When coupled with data on students' family backgrounds and demographic characteristics, school environments, and standardized competence and outcome measures, they permit the specification of complex models of educational processes. Moreover, transcript components of longitudinal studies such as HS&B and NELS:88 permit the measurement of high school program and course effects on post-high school outcomes. Transcripts also provide indicator data for measuring national education trends. Of particular interest are changes in course taking and trends associated with grading practices and program placement and participation. NELS:88 and other NCES studies supply archival data on these topics. These studies include the National Longitudinal Study of the High School Class of 1972 (NLS-72), the sophomore cohort component of High School and Beyond (HS&B), and records studies of the high school careers of 1987, 1990, and 1994 graduating seniors conducted as part of the National Assessment of Educational Progress. Some additional, and roughly comparable, secondary transcript studies have been carried out as well.' While the transcript data collection for NELS:88 was extremely successful and valuable, there are a number of ways that future high transcript studies could be improved. Four suggestions are offered below. First, some recent moves toward curriculum integration bring into question many traditional subject classifications and coding schemes and suggest the need to give serious thought to the issue of the way in which future taxonomies may need to be modified. Educational Testing Service collected course completion data in the Study of Academic Prediction and Growth in 1969. Private school students were not included nor was this a national probability sample of public high school graduates; however, the study is thought to give reasonable public school estimates. The Bureau of Labor Statistics National Longitudinal Survey of Labor Force ExperienceYouth Cohort (NLSY79, with sponsorship from the National Center for Research in Vocational Education, collected secondary school academic transcripts in three waves from 1980-83 for its sample of youths who were aged 14-21 in 1979. Transcript studies are planned as part of the new BLS NLSY97 cohort as well. For further information on these studies and on conducting trend analyses with transcript data, see Ingels and Taylor (1995."}, {"section_title": "135", "text": "NELS:88 Second Follow-Up Final Methodology Report Second, in a longitudinal study beginning prior to the senior year, a senior year transcript collection is not enough. It is important to go back at least one more time, say two years later, in order to collect a more complete record for cohort members who fell behind the modal grade progression sequence and did not graduate with the senior class. Certain groups with which there is great policy concernchildren with disabilities, dropouts who return to school, poor academic performerstend not to stay in grade sequence for the four years between eighth and twelfth grade. For example, Ingels (1996) shows that of the five percent of the NELS:88 base year sample initially excluded owing to limited English proficiency or mental or physical disabilities, 37.6 percent had dropped out by 1992, 62.4 percent were still in school, but of the 62.4 percent still in school, 42.4 percent of them had fallen behind grade sequence, that is, were not seniors in 1992. Based on 1987 NAEP data, Hayward and Thorne (1990) report that only 68 percent of disabled (compared to 87 percent of nondisabled) students graduate on time. When NELS:88 data are examined, it appears that of in-school eighth grade cohort members in 1992, the weighted proportion who were classified as seniors was 95 percent (about 1 percent graduated early, about 4 percent were behind). However, if one considers the full eighth grade cohort (including dropouts), the weighted proportion of 1988 eighth graders who were high school seniors four years later was only 80.2 percent. Fewer students are dropping out of school, but students are staying in school longer. Increases in special education and limited English proficient school populations, as well as the success of dropout prevention programs, suggest that this trend will become more, rather than less, pronounced in the next few years. Under these circumstances, longitudinal studies of high school students should not be designed such that they collect the complete high school records only of those students who graduate on time. This design flaw in the HS&B and NELS:88 approach should be corrected by instituting a supplemental transcript data collection at the time of the twoyears-after-high-school follow-up. Third, transcripts for dropouts should be collected as soon as their out-of-school status is determined. The procedure in NELS:88waiting up to three and a half years (spring 1989 to fall 1992) to collect dropout transcriptsled to some loss of data for this group. It would also be sensible to make an earlier start on collecting transcripts of transfer students. Fourth, it is important that measures be taken to facilitate using teacher data in conjunction with transcript data on studies such as NELS:88 by matching and clearly identifying the transcript file courses to which the teacher data refer. Unquestionably valuable though transcript data is, its value is greatly magnified by the capacity to provide linkage to teacher reports of what content was taught and how it was taught. As McDonnell (1995) observes, \"because of significant variation in the breadth and depth of topic coverage, knowing\" (for example) \"that most ninth graders take algebra does not provide adequate information about their actual opportunity to learn algebra content.\" In short, it is highly desirable to include on the teacher file the course codes used in the transcript file. For every student for whom there is both a teacher report and a transcript, there should be a record of the transcript course to which the teacher data refer. Although the NELS:88 teacher questionnaire asked the teacher to write in the name of each class for which class-level data were collected, this information was not coded, owing to resource limitations. Information available on the teacher file (such as subject matter and level, track and achievement level ) underwrites unequivocal identification of the transcript course to which the teacher refers just over 80 percent of the time in subjects such as math and science (see Hoffer & Moore 1996, appendix C). The goal should be a 100 percent match. 114 136 NELS:88 Second Follow-Up Final Methodology Report 6.2.3 Classification Variables and Composites. Classification Variables. Race/ethnicity. Generally respondents were able to successfully use the race/ethnicity categories in NELS:88. A few students of mixed race refused to use a race category, since doing so would have entailed choosing to identify with a single element of their dual heritage. Students may have slightly overreported Pacific Islander and American Indian identities in the base year. There were rare cases of difficulty in interpreting the Asian category because of the inclusion of the Indian subcontinent but exclusion of adjacent areas with cultural and linguistic affinity (e.g., Afghanistan, Iran). Martin, DeMaio and Campanelli (1990), reflecting on racial classifications used in the U.S. Census Bureau between 1850 and 1990, note that although we tend to think of race as a stable, enduring characteristic, \" no single set of racial categories has been used in more than two censuses, and most were used only once.\" Indeed, a number of changes in racial classification categories have been proposed for the 2000 Census, and the Census Bureau is currently conducting cognitive research on this issue. Also, the Office of Management and Budget has put its existing race/ethnicity guidelines under review. One difference between the categories used in HS&B and NELS:88 was that, following a change in Census practice, NELS:88 added the \"other\" category to black and white categories for Hispanics. Some 32 percent of Hispanics in the base year chose the \"other\" option. For future studies it will be important both to reflect changed classifications in the Census categories and those used in federal surveys to which results will be compared, but whenever possible, to do so in ways that permits continued intercohort comparisons, so that trend analyses with earlier NCES studies may be carried out. Students with Disabilities. High School and Beyond collected student self-reports of their disabilities. The information was somewhat inconsistent over time but pointed systematically to the special needs of self-identified handicapped students (Owings and Stocking, 1985). In NELS:88, parents and teachers were asked in the base year about a limited number of disability conditions, and in the 1992 transcript study, information was collected as to whether a student received special education services. (The forthcoming NELS:88 volume by Rossi, Hefting & Wolman should provide interesting comparisons of these sources.) While there is value in posing such questions to teachers, there is an overriding need to go beyond such sources to identify all sample members with an Individualized Education Plan (IEP) for special education services. Each IEP will indicate a disability classification for the studentone of thirteen standard Federal disability categories. These disability categories should be collected consistently across all national data collection programs concerned with students receiving special education services. Since this status can change, IEP disability classification should be collected in each round of a longitudinal study. For students receiving special education services, it would be extremely valuable to pose supplemental questions to their special education teachers. In particular, it would be valuable to know the areas in which the student has IEP goals, how many hours per week of special education and related services the student receives, the special education and related services provided (classroom aide, speech therapy, occupational therapy, etc.), whether primary placement is in a general education classroom and proportion of time spent in general education classrooms, teacher practices used with the student, proportion of the student's IEP goals that have been accomplished during the year, assistive technologies used by the child, and so on. Limited English Proficiency (LEP) and Language Minority (LM). In terms of classification, studies such as NELS:88 have determined language minority status by asking parents about language spoken in the home (also by asking teachers, though this is a much weaker source, as Bradby's analysis [1992] of NELS:88 base year data shows). In terms of English language proficiency, NELS:88 sought to learn whether a student received special services (such as English as a second language, or bilingual education), and in addition to questions directed to the parent and the teacher, asked the student how well she or he could write, speak, 137 115 NELS:88 Second Follow-Up Final Methodology Report read, or understand spoken English. It is important to gather all of these perspectives. However, there are two weaknesses to the approach taken in NELS:88. One weakness is that substantial numbers of LEPs were excluded from the study, on the basis of their inability to complete the instrumentation. Consequently, the study's ability to generalize about this group is severely limited. Another limitation is that definitions of LEP are highly variable from school to school, and in some places depend on parent report, in others on test scores (on various tests, and with various cutoff points for defining proficiency). What is lacking is a single objective measure of English language proficiency across the sample. Perhaps the best way to approach this problem in a future study would be to give all identified LEP students an English language proficiency screener. This would provide a more objective classification scheme and basis for comparison across schools. In addition, by re-administering the screener in future rounds, two further goals would be achieved. First, achievement growth in English proficiency over time could be measured. Second, a cutoff score could be identified that, when achieved, would provide a basis for saying that the student could validly be assessed using the English language cognitive test battery, or complete the English language student questionnaire. Composite Variables. Self Concept. Earlier NCES longitudinal studiesNLS-72, HS&Bemployed scales on two personality attributes, self esteem (a modification of Rosenberg's scale) and locus of control (a short form of Rotter's scale). An attempt was made in NELS:88 to improve these scales, while maintaining comparability to NLS-72 and HS&B, by adding items to achieve higher reliabilities, and effecting some rewording to eliminate response set bias. The dimensionality of the base year self-esteem and locus of control scales is discussed in  This analysis suggests the possibility of some differences in meaning for respondents in different racial subgroups, a subject that is deserving of further investigation. An analysis of the factor structure, reliability and predictive validity of the base year selfesteem and locus of control scales was also undertaken by Freidlin and Salvucci (1995). They suggest that the use of reverse scoring items to avoid response set should be revisited. Also, in the 1990 round, items were added from Marsh's self-concept scales for academic self-concept (math, English), parent relations, and same and opposite sex peer relations (see Marsh, 1994). The potential utility of including academic selfconcept measures in future large-scale studies should be considered. , also uses NELS:88 data, from the base year, to examine problems related to combining responses to single-item self-rating scales, and demonstrates the distinctiveness of affects in specific school subjects.) Education. Educational attainment of the mother and father is a critical measure of the home environment, and a key element in the socioeconomic status variable. As Smith (1995) notes \"education is probably the most frequently used variable in sociology\". Smith adds that education is a central variable in most social science theories, and that it exerts an effect on a wide range of dependent variablesyet, Smith concludes, \"education is not a well-defined and well-measured concept\". NELS:88 has obtained information on highest level of parental education but has not inquired into further detail such as, for postsecondary degrees, institutional quality or field of study. Such further refinement may go beyond what is strictly necessary. However, it should be noted that only one parent responds to the NELS:88 parent questionnairethe self-selected parent most familiar with the child's educational situation. This means that for any two-parent family, one parent's educational attainment has been reported through a proxy. Smith (1985) reports, based on General Social Survey data, that spousal education reports are reasonably accurate. Still, it would be useful to perform more methodological work on spousal reports, both for sociodemographic variables, where there is a single objectively right answer, and for attitudinal variables, where mothers and fathers may differ in their views. A small parent substudy in a field test or main data collection in which interviews are conducted with both parents would be a highly desirable methodological undertaking for this reason. Indeed, there may be substantive as well as methodological reasons for moving beyond the onereporter approach to the American family, reasons grounded in the fact that family structure and parental roles have changed since the NCES longitudinal studies series started in NLS-72. If the basic approach of the HS&B and NELS:88 parent surveys --in which only one person, normally (though not necessarily) the mother, provides child reports from the perspective of the family --has limitations for traditional two-parent families, then the issue of fully capturing key parental and family influences on students becomes even more complex in the light of these recent changes in the American family. With greater female labor force participation, both mothers and fathers have been forced to redefine their familial roles. Family formation and structure have also undergone significant alteration. Both divorce and out-of-wedlock births have increased. In 1960 over 90 percent of children lived with both of their parents while they were growing up, yet currently half of children born to married parents are expected to live with a single parent before reaching adulthood (Bumpass and Sweet, 1989). More and more children live away from their biological fathers (who, however, in some cases continue to have contact with the child and provide financial support, and in other cases do not), but sometimes live in the presence of a stepfather or a cohabiting boyfriend of the mother. Some children live away from both biological parents, with primary care vested in grandparents. To properly capture the complexity and change in the contemporary American family, and especially the role of residential and nonresidential, biological and social, fathers, is an important but difficult task, that might be achieved through a substudy that enlarges the focus of the NELS parent surveys by including a residential and nonresidential father component. Urbanicity. NELS:88 offers both a simple three-part classification into the metropolitan statuses urban, suburban, ruraland the capacity to invoke 1990 Census urbanicity data for the school's zipcode area. Urbanicity classifications have changed over time (for example, when HS&B is compared to NELS:88), not just in respect of changing population densities as measured by the decennial census, but also at times in terms of reference or definition (for example, urbanicity has sometimes meant the metropolitan status of the district in which the school is located, which is a grosser measure than urbanicity for the school building location). Better documentation of definitional differences is needed to ensure that cross-study and cross-cohort comparisons are undertaken properly. Socioeconomic Status. Researchers are not constrained to use the composite provided in NELS:88, since all constituent elements are available to them to use singly or in whatever combination they may choose. The socioeconomic status (SES) composite in NELS:88 largely, but not completely, follows the model of NLS-72 and HS&B. Even in cases where the same data elements are present, however, parent data typically were used in NELS:88, and student data in the earlier studies. In all three studies, the following data were used: father's education level, mother's education level, father's occupation, family income (unadjusted for the size of the household), and household items. However, in NELS:88, the household items from the student questionnaire were used only to substitute for missing parent survey income data; studentreported parental education and occupation also were substituted when these data were missing from the NELS:88 parent survey. In NELS:88, unlike NLS-72 and HS&B, mother's occupation was used in the SES composite as well. In NLS-72 and HS&B, family income data were elicited from students; in NELS:88, family income data were obtained from the parent. As a check on the comparability of SES in HS&B/NELS:88 intercohort comparisons, analysts may wish to review their results when solely student-derived measures, such as student reports on parental education, are substituted for the SES composite. (However, comparisons of HS&B and NELS:88 need to take into account several factors --first, older cohorts are better reporters on parental education and occupation than younger cohorts; and second, there were probably more poor reporters in the NELS:88 base year data set because the study had a substantially higher baseline participation rate and because students who would drop out by sophomore or senior year were still in the sample). Kaufman and Rasinski (Quality of the Responses of Eighth-Grade Students in NELS:88, 1991, pp. [14][15] report that the correlations between the student and the parent responses to father's education level was 0.82 for eighth graders in NELS:88 as contrasted to 0.87 for tenth graders and 0.89 for twelfth graders in HS&B. (Note also that in both HS&B and NELS:88, information on the father's education and occupation usually was reported by the mother, not by the father himself.) The correlation between student reports of the mother's education and parent reports (usually that of the mother herself) was 0.76 in NELS:88, 0.81 for the HS&B sophomore cohort, and 0.85 for high school seniors. In the NELS:88 second follow-up, there is a second version of the SES composite. Because occupational prestige may change over time, the second version incorporates the 1989 revision of Duncan's Socioeconomic Index (SEI), whereas the other version utilizes the original (1961) SEI used in NLS-72, HS&B, and earlier rounds of NELS:88. In analyzing the reliability, predictive validity, and efficiency of the base year SES composite, Freidlin and Salvucci (1995) concluded that a better SES composite could be constructed without the use of occupation, utilizing only father's and mother's education and family income. However, it should also be considered whether more refined coding of occupation, rather than the broad and sometimes misleading general categories (professional, operative, clerical and so on) used in NELS:88 might substantially improve the contribution of the occupational element. A further issue is whether SES should be measured only once. Apart from reliability issues when, e.g., educational attainment questions are re-asked (see Smith, 1995) a larger issue for a longitudinal study is how stable SES is over time, since an individual's educational attainment, occupation, and income are all subject to change. Certainly some of the household items need to be updated (e.g., \"typewriter\"). McNeal (1996) points to a number of limitations in the questionnaire items, consistently used in HS&B and NELS:88, for tapping information about students' employment experience. As noted above, parental occupation could be captured with three-digit Census industry and occupation codes; occupation is a central variable, validating the survey against Census parameters, whereas the current gross categories (clerical, craftsperson, farmer, laborer, manager/administrator, operative, professional, proprietor or owner, protective service, sales, service, technical) submerge much of the meaningful variation in work that detailed occupational coding would reveal. Given the information provided by the study about achievement gains and their relationship to various background and curricular factors, and the general availability of such information on NELS:88 test nonresponders, the possibility of imputing missing test scores should be given serious consideration. It would be especially valuable for longitudinal analysis to be able to impute a missing round of test data when other test data points are available. In terms of future studies, a premium should be placed on achieving the highest possible rate of test completion. Since NAEP provides test data for high school seniors, and response rates drop off in the senior year, it might be sensible to consider gathering test data in the junior year instead. However, the disadvantages of such a strategy would be loss of comparability to NLS-72, HS&B and NELS:88; lack of a cumulative measure of achievement at the end of high school; and lack of ability to cross-walk to NAEP. NELS:88 had high test nonresponse from dropouts. While dropouts as a group are generally less eager test takers than students, higher response rates could have been obtained, if considerably greater resources had been invested in testing this group. To what degree is it worthwhile to disproportionately invest scarce resources in maximizing the test response rate for dropouts? One important use of dropout test scores is to compare the achievement gains of dropouts with those of otherwise similar youths who remained in school. This in effect gives a measure of school effectivenessthe value added by going to school for such a student. Just as it is important, with young children, to assess them both in autumn and spring, so that summer learning effects can be factored out and school effects measured, so too for older students, it is useful to gain a measure of school effects by comparing the cognitive growth of students of similarcharacteristics who are in and are out of school. Given the expenseusually one-on-one personal interviewsinvolved in surveying and testing dropouts, it may be appropriate to try to piggyback other, special surveys onto such efforts. For example, one gap that has been identified in the federal statistical system is that most data collected on teenagers comes from school surveys, and dropouts are missed. Extending longitudinal data on dropouts from surveys such as NELS:88 to include other features of social development and risk and health-related behaviors might be a fruitful area for interagency collaboration. Holistic perspectives on assessment. NELS:88 stressed achievement testing in four subject areas: social studies, mathematics, science and reading. Some information about student behavioral dispositions, such as motivation and ability to relate to others, was collected from teachers. All in all, however, rather limited information was collected concerning the socioemotional development of the student, and the student's approaches to learning. A priority for the future should include developing better measures of student engagement, effort and efficacy. The approach to be taken in the new NCES Early Childhood Longitudinal Studyto assess health and physical, and socioemotional, status and growth, as well as cognitive developmentcould usefully be applied to the high school years. 1 "}, {"section_title": "I", "text": "119 NELS88 Second Follow-Up Final Methodology Report Periodicity of Assessment: Relating Test Results to Instruction. NELS:88 advanced beyond the HS&B methodology by collecting extensive information from teachers about what is taught and how it is taught. However, the NELS:88 biennial assessment design places sharp limits on efforts to estimate the effects of classroom differences on student outcomes (see Hoffer, 1992, p.222). The NELS:88 data do not allow a direct link of instructional variables to achievement growth, since the instructional variables refer to particular one-year or even one-semester classes, while achievement was only measured every two years. Given this incomplete account of the instruction students received over the learning period, causal inferences about the effects of instruction on learning can only weakly be made. This disjuncture between the teacher data and the testing cycle could be corrected in one of three ways. Annual tests along with annual teacher data would be best; next best would be annual tests sandwiched around occasional teacher data; third best would be annual teacher data sandwiched around the two-year-cycled tests. The costs of such a program might be reduced by collecting annual teacher and test data only for a subsample of three or four thousand students. 6.2.5 Contextual Data Classroom Effects: Classrooms as Contextual Data Source Versus Classrooms as Unit of Sampling and Analysis. NELS:88 focuses on classrooms as a context attached to students. Elsewhere in this chapter we argue that classrooms as a context could be better understood in a NELS-type design if testing was annual, at least for a subsample of students. However, many researchers would like to see a focus on classrooms as an independent analytic unit, given the importance of classrooms as sources of student-tostudent differences in opportunities to learn. Information about classrooms is important to understanding how multilevel organizations function. Classroom data can facilitate explorations of within-and betweenclassroom variation in levels of achievement, the processes by which teachers group children within a classroom and the impact of such groupings, and other features of the internal structure of classrooms. Nevertheless, there are both methodological and practical reasons why one might be reluctant to sample whole classrooms. First, it would be very costly to survey all classrooms within a school. While one might sharply curtail the size of the school sample in order to be able to afford to survey intact classrooms across the board, this is not an attractive alternative, and would especially reduce the study's ability to investigate private and other rare school types. Yet the economical alternative say a one-class-per-school designconfounds school-level and classroom-level effects. Moreover, any advantage of initial clustering by classroom would be lost in later waves of data collection, as the sample children scatter across different classrooms in later grades. In high school, with classes reflecting a departmental organization and different choice of course sequences, the multifarious and transitory nature of classrooms introduces a special difficulty in treating the classroom as a sampling unit. Even at the elementary school level, dispersion is a major problem for a longitudinal study, and tends quickly to reduce the value of the classroom as an independent analytical unit. For example, Kerbow (1996) reports that only 15 percent of Chicago elementary schools have stable classrooms where at least 85 percent of the students are the same from year to year, and only 4 percent of the schools have three-fourths or more of their students consistently remaining in their classrooms during a three-year period. Nevertheless, there is a strong argument for combining approaches so that, in a nested substudy, some classroom observational data can be obtained. These observational data can be used to help validate, as well as extend, teacher reports of their time use, instructional practices, and classroom dynamics. While either direct observation or videotaping are possible, videotaping is preferable because of the inter-rater reliability problems associated with classroom observation-based coding. A taped session may be rated multiple times by multiple raters or with multiple objectives in view. Other sorts of complementary substudies may also be built into a NELS-like panel design. Clearly one major focus of surveys like HS&B and NELS:88 is to capture representative data for students and their schools in general. But another possible focus is to conduct nested substudies, perhaps using qualitative methods when appropriate, within the larger sample in which consequential sources of variation in school organization and practice that affect student outcomes are identified and captured. For example, one may identify schools that embody a particular exemplary practice or innovation. These schools might be studied intensively by observational methods, possibly in conjunction with matched schools that lack this organizational characteristic. More needs to be done to exploit the examples of interesting variation in school practice that will appear within a large, representative national school sample. While some kinds of variation can be drawn out of the realized sample, other sorts need to be addressed earlier, at the time of sample selectionin the manner, for example, that NELS:88 provided for oversampling of private schools, with special strata for Catholic, National Association of Independent Schools, and other private schools, or that HS&B created a special oversampling stratum in the school universe for representing alternative schools. Classroom data: opportunity to learn. A major area of inquiry is use of teacher reports to measure instruction, curriculum content, and resources, and, in particular, to relate coverage or \"opportunity to learn\" (OTL) to test results (see Porter, 1991Porter, , 1993Mullins, 1995;Leighton, Mullins, Turnbull, Weiner and Williams, 1995). Some weaknesses have been identified in some of the curriculum measures used in NELS:88 (Burstein et al., 1995). To remedy such shortcomings of the teacher reports on content coverage in their classes, an adaptation of Porter's new scheme for secondary-grade-level OTL (Porter, 1996) would bring substantial improvement. More generally, the point made by Burstein et al. about the need, in collecting teacher data, to build validation studies into large-scale surveys, is important to note. Contextual Data: School and Home Address Mappings to Census Data; School Mappings to District and State Data. It is important to capture the full range of characteristics of geography and setting, of where children live and go to school, that may be hypothesized to affect the different aspects of children's development and school achievement either directly or through their families. While some information about school, community and neighborhood context can be obtained from school administrator and parent questionnaires, other characteristics of the school and geographic context can best be obtained from external sources, and can be made part of the data base without burden to any respondent population. Much of the information obtainable from these external sources may be unknown or not accurately known by parents and school principals, or so detailed and extensive as to be too burdensome to collect from individual respondents. To the extent that there is overlap in external source information with data from the parent and school administrator questionnaires, dual sources provide an indicator of validity, when the two sources converge or when one of the two can be given veridical status. Geographical Context: Labor Markets. It is important to make county identifiers for schools sampled in the study available on restricted use files. Economic characteristics of labor market areas are important to understanding phenomena such as dropping out of school, as well as post-high school status and opportunities. Although labor markets are normally clusters of counties, usually the specific county in which a school is located will be a sufficient basis for analysis. Geographical context: locale of school. neighborhood of student. Neighborhoods, because they are relatively homogeneous, tend to form the most important unit of geographic context, although data are available for larger units (such as states, counties and MSAs) as well. It is difficult to devise sound operational definitions of neighborhoods; however, census-defined units are acceptable proxies (they provide conservative estimates of neighborhood effects, downwardly biasing context effects estimates [Crane 1991;cf. Entwisle 1991, Tienda 1991 Brooks-Gunn, Duncan, Klebanov & Sea land, 1993). Also, based on the Beginning School Study (BSS) in Baltimore, Entwisle, Alexander and Olson (1994) have tentatively identified neighborhood effects working in tandem with school tracking effects to produce a gender gap in mathematics achievement. They hypothesize that neighborhood effects may be stronger for elementary school students than for secondary school students, both because elementary school populations tend to be more homogeneous in terms of family backgrounds, and because neighborhood boundaries typically match elementary school catchment areas. Mappings to Census zipcode or tract (as well as to state or county via FIPS code, or MSA) can be effected at the school level, and at the student home address level, although for confidentiality reasons these linkages can be made available only on privileged use files available through licensure agreements. In NELS:88, school and residential address linkages to Census data at the zipcode level were achieved in piecemeal fashion over time, as various research needs asserted themselves. In a future study, systematic mapping of residential and school locales to (year 2000) decennial Census data should be planned from the outset. Moreover, it should be considered whether the extra cost of obtaining tract rather than zipcode data would be justified in the light of the more specifically targeted information this would provide. The ideal method for linking Census information to a school service area or local community would be to geographically define the boundaries of each school service area and code the Census tracts in each area. The Census data for the tracts in each service area would then be aggregated and attached to the school's privileged use ID. School context: characteristics of schools and school districts. It is desirable to gather school contextual data also at multiple levels, including data about the districts of which individual public schools are part, and where certain policy and resource decisions may be made. At the school level, the Common Core of Data (for public schools) and various commercial school lists provide such information as number of teachers per school, school enrollment, school racial/ethnic distribution, grade span, microcomputer use, and so on. In NELS:88, schools can also be linked to their districts and information provided on school district financial and administrative (as well as population) characteristics through the NCES School District Analysis Book (SDAB). If similar mappings are done with year 2000 Census data, these linkages should be provided for privileged use files of new school surveys as well. 6.2.6 Questionnaire Data: Item Nonresponse Item nonresponse in the NELS:88 second follow-up could have been considerably reduced by following the base year model in which fewer questions were asked, complex skip patterns were avoided, and routing questions were heavily edited by interviewers on-site prior to the end of the survey session. However, given severe time constraints in the length of the survey session, the tradeoff is in number of questions that can be asked. It is always difficult to choose between asking less and having better item response rates, and asking far more, and risking somewhat higher levels of item nonresponse. Computerassisted questionnaire administration would also be a means of ensuring that skip patterns are followed, though this is a far more expensive technology than the group administration of an optically scanned document used in the in-school rounds of NELS:88. Nevertheless, it may be desirable to take special measures to help poor readers, and to plan from the start for interviewer administration. For students with very low reading ability (say the bottom decile) a personal interview should be conducted in order to (a) enhance student comprehension, because listening comprehension is likely to be better for these students than reading comprehension; (b) shift the burden of navigating the skip patterns from the respondent; and (c) to, through the personal relationship with the interviewer, increase student motivation to respond. Although factors in addition to reading level may be at work here, it is illuminating to consider the pattern of weighted item nonresponse in the NELS:88 second follow-up from the perspective of reading level. Mean item nonresponse for students in the lowest reading quartile was 14.7 percent, for students in the middle two quartiles 7.9 percent, and for students in the highest reading test quartile, 5.9 percent. Nonresponse overall was highest for filtered questions and for questions in the last third of the lengthy student questionnaire. For filtered questions, the percent nonresponse on the 1992 questionnaire was 9.45 percent for students in the highest reading quartile, 11.5 percent for students in the middle two quartiles, and 20 percent for students in the lowest reading quartile. For students in the highest reading quartile, nonresponse in the last third of the questionnaire was 11.9 percent, for the middle two quartiles 15.5 percent, for the lowest quartile 25.4 percent. Efforts should be made in the future to ensure that poor readers achieve higher rates of item response. McLaughlin and Cohen (NELS:88 Survey Item Evaluation Report, NCES, forthcoming) provide a measure of item difficulty and investigate whether reading ability contributes to cross-wave convergence of reports in the NELS:88 data set. 6.2.7 Possible Utility of a Guidance Counselor Questionnaire. Another suggestion that might be considered is that of including a guidance counselor questionnaire in a new longitudinal high school study. This is a comparatively low cost option because school counselors are few in number and the questionnaire can be completed in a self-administered format. Nonetheless, much valuable information could be obtained, especially in a longitudinal study that is able to study process and trace eventual outcomes, and which is deeply concerned with issues of school to work transition and the transition from high school to postsecondary education. Counseling is assigned a critical function in providing educational assistance to students in development of college and postsecondary educational plans, in making decisions about entry into the work force, in selecting high school courses (including those course that are most highly related to the workforce or postsecondary plans of the student), and in improving their study skills. Barton (1996) laments the lack of attention, despite its enormous importance, to counseling in the school reform literature. Lack of data may be cause or consequence of that neglect; Barton states that \"little is known about how much time is available for counseling in high school and how that time is spent\". Neither High School and Beyond nor NELS:88 included a guidance counselor questionnaire as part of the high school study. However, the head of guidance was in fact surveyed through a 24-page guidance questionnaire in the Administrator and Teacher Survey (the 1984 add-on to the HS&B second follow-up in which principals, teachers and guidance personnel were included in a probability subsample of the HS&B schools two years after most members of the sophomore cohort had graduated). Information about the counseling process obtained in NELS:88 from students is intriguing but unfortunately the counselor's perspective was not tapped. NELS eighth grade findings on the influence of counselors are summarized in the NCES publication Profile of the American Eighth Grader (Hafner,Ingels,Schneider & Stevenson;. Tenth grade findings are summarized in A Profile of the American High School Sophomore in 1990 (Ingels,Schneider,Scott & Plank;, which suggests that NELS:88 data raise the question \"whether those least prepared to go to college are being effectively counseled\" (p.104). Barton (1996) expands on this question, using the 1992 data for seniors and concludes that the NELS:88 Second Follow-Up data demonstrate that 1992 seniors received little help finding jobs but much help going to college. There are also serious equity issues associated with access to and the direction of advice provided in counseling services to members of different racial/ethnic groups and socioeconomic status groups. Serious consideration should be given to a sophomore and senior (or at least a senior year) counselor questionnaire for any new NCES longitudinal high school cohort."}, {"section_title": "Base Year through Second Follow-Up Cognitive Test Item Files", "text": "The three test item files on the 1996 restricted-use CD, under the subdirectory \\QED_TEST\\TEST, correspond to the three waves of the survey, base year (1988) and first and second follow-up (1990 and 1992). (These files are also available on magnetic media from NCES.) The base year file includes records only for base year sample members who completed a base year student questionnaire; the first and second follow-up files include records for all sample members eligible to complete the cognitive test in that survey wave, including questionnaire nonrespondents. In each of the three waves, subsets of test items were selected from an overall pool for each subject area to make up the test forms administered to survey participants in that year. The overlap among the test forms allowed the development of a common score scale that could measure change over time even though participants answered different assortments of test questions at each administration. The number of test questions on each test form, and the number in the total pool (all questions used in any of the forms) are: Test questions that were used in more than one form or year would not necessarily have been in the same sequence in each test booklet in which they appeared. In order to be able to make comparisons of the same question used in different forms, the test item files \"line up\" the items so each position represents the same test question, regardless of the order in which it appeared in any test form. The Item Response fields are formatted with one position for each unique test item in the total item pool for all four subject areas. Item response codes are the raw (unscored) choices selected by the test takers. The \"# Valid Choices\" column in the item map indicates how many multiple choice response options were presented for each test item. Alphabetic responses (some of the math items had A-B-C-D choices) are converted to the numeric equivalent. Each record in the file contains item responses for only a subset of the items in the total pool. For items without a valid 1-5 response code, the following codes are used to identify the reason for the non-response: blank The sample member did not complete any part of the cognitive test"}, {"section_title": "98", "text": "The test taker had no valid data for this entire subtest."}, {"section_title": "99", "text": "The item did not appear on the test form taken by the student."}, {"section_title": "08", "text": "The item was on the test form, but the test taker skipped it and went on to answer at least one later item (internal omit)."}, {"section_title": "07", "text": "The item was on the test form but the student did not reach it; neither this item nor any later item was answered (trailing omit). Because the order of the item pool in this file does not represent the order in which items were presented on any given test form, codes 07 and 08 are necessary if the user wishes to distinguish between internal and trailing omits. The distinction cannot be made solely on the basis of the item order in the pool without reference to a map of item order in the forms as they were administered."}, {"section_title": "158", "text": "A-1 NELS:88 Second Follow-Up Final Methodology Report Not all of the students with a test record had scorable data for all four subject areas. Because of time constraints or lack of motivation, some of the subtests did not have sufficient numbers of items answered to provide a usable measure of the test taker's ability. Tests were not scored if fewer than 5 items were answered, or if a pattern-marking identification algorithm found evidence of the lack of an honest attempt to answer the questions (for example, responses of 1111111... for all questions in the test). The four \"test present\" indicators on the file mark the presence or absence of each subtest. For subtests that are missing or unscorable, each item in the subtest is coded as \"98\". In the base year, all participants received the same test form. On the basis of their performance at this time, students were assigned reading and math tests of different average difficulty in the first followup in order to increase accuracy of measurement. Similarly, second follow-up reading and math tests were assigned on the basis of performance at first follow-up. There were two levels of the reading test and three levels of the math test in each of the latter two years, resulting in 6 test booklets: Note that the test booklets for the first follow-up were not the same as the second follow-up booklets with the same numbers. For example, 1990 High Level Math was not the same test as 1992 High Level Math. The test item file has codes for the levels of the reading test (1 =low; 2 =high) and the math test (1 =low; 2 =mid; 3 =high) represented in each record. These codes are for the test level within the year of the data. Users who have access to the original test booklets may wish to identify the actual test questions that correspond to the positions in the item pool. Other analyses may simply require knowing the order in which the test items were administered in each form. The item map that follows shows the actual location in the original booklets of each of the re-ordered items in the file. The correct answer key is also included. Test items are in the same position in the response vector for all three waves. This is not the same order in which they appeared in the various forms of the test that were administered. Use the map provided to identify item order on any test form. who have never before appeared on core privileged-use files. Included are Base Year Ineligible (BYI) students who remained ineligible in the first and second follow-ups of NELS:88 and students who were \"freshened\" in the first follow-up but were found to be ineligible and remained ineligible in the second follow-up. The expanded sample is also available separately on magnetic media from NCES; this file includes all composites and weights discussed in this appendix. Since NELS:88 base year and first and second follow-up composites were not constructed for the ineligible members of the expanded sample and are consequently blank on the 1995 BY-F2 student-level file, a number of composites have been specially constructed for use with the expanded sample, including student and school background variables, enrollment and out-of-sequence indicators, a variable indicating reason for ineligibility for the student survey (if applicable), cohort flags and a statistical weight, F2EXPWT, that can be used with both the eighth and tenth grade cohorts. The enrollment status indicators for the expanded sample, FlENREXP and F2ENREXP, include imputed values for eligible and ineligible cases with missing enrollment data. The expanded sample variables, whose names contain an \"X\" or \"EXP\", appear after the F2 teacher variables in the 1996 BY-F3 privileged-use ECB. The expanded sample and accompanying variables allow researchers to in some cases assess or correct for under coverage of the ideal target population due to the application of ineligibility rules that excluded certain cohort members from the study. With this file, researchers can produce corrected estimates for selected characteristics of the eighth grade and sophomore cohorts (for example, dropout rates between grades 8 and 10 and 8 and 12, and between grades 10 and 12), and assess the magnitude of probable bias in selected estimates that employ the eligible (questionnaire) sample. Another purpose of the expanded sample is to provide researchers with information on the ineligible members of the NELS:88 eighth-and tenth-grade cohorts that is not available on any other NELS:88 data file. With the expanded sample and accompanying variables, users can, for example, trace the educational progress (and change in eligibility status) of students who were initially excluded from the 1988 base year survey by such previously unknown characteristics as the reason for their initial exclusion (mentally or physically disabled or severely limited in English proficiency). Expanded sample membership. The expanded sample comprises 21,133 eligible and ineligible members of the NELS:88 eighth grade-and tenth-grade cohorts. Each sample member is an eligible or ineligible member of the 1988 eighth grade cohort and/or an eligible or ineligible member of the 1990 tenthgrade cohort. There is substantial overlap in membership in the eighth-grade and tenth-grade cohorts, since most members of the eighth-grade cohort--students who were enrolled in eighth grade in the spring of 1988-were enrolled in tenth grade in the spring of 1990, the year of the first follow-up of NELS:88 and the defining criterion for membership in the tenth-grade cohort. Reasons for ineligibility. In the base year of NELS:88, students who had a mental or physical disability or difficultly with the English language that would have made participation in a 3-hour survey session unduly difficult were excluded from the study. This amounted to 5.3 percent of the 1987-1988 eighth grade student population. Eligibility rules were modified in the first follow-up to reduce the likelihood of excluding limited English proficiency students from the 1990 tenth-grade cohort and to increase the chances of base year ineligibles entry into the study. With support from the Office of Bilingual Education and Minority Languages Affairs (OBEMLA), the first follow-up student questionnaire was translated into Spanish; because a translation of the cognitive tests was not feasible, students completing the Spanish student questionnaire were not pressed to complete the test component. However, other students whose primary B-1 t66 NELS:88 Second Follow-Up Final Methodology Report language was not Spanish and who were of limited proficiency in English were, as in the base year, excluded from participation in NELS:88 in the first follow-up along with students who had a mental or physical disability that would have prevented them from comfortably completing the NELS:88 student questionnaire and cognitive tests in a 3-hour long survey session. Identifying specific samples. The expanded sample composites include selected characteristics for the students who were excluded from NELS:88 in the base year and first follow-up, as well as for the students included in NELS:88 in the base year and first follow-up. Users can identify eligible and ineligible members of the eighth-and tenth-grade cohorts through the variables G8COHEXP and GIOCOHEXP, respectively. Members of the base year ineligible sample (BYIs) can be identified wing the variable BYIXREAS (values 1-4), which indicates reason for ineligibility in the base year. (A comparable variable does not exist for the base year.) For researchers who are unfamiliar with the base year ineligible study and sample, we encourage you to read the NELS:88 First Follow-Up Student Component Data File User's Manual, sections 1.3.4, 3.4.4, 3.7 and 4.7.4 (Ingels, NCES 1996). These documents discuss how students excluded in the base year and first follow-up entered the study in later waves. Analysis using the expanded sample.. Only the variables (named and described in this appendix) and weight (F2EXPWT on the 1995 and 1996 releases) created for the expanded sample should be used in expanded sample analyses. Expanded sample estimates using student or dropout questionnaire variables will be biased because of the non-random character of missing questionnaire cases. F2EXPWT provides nonresponse adjustments for the expanded sample variables but not for questionnaire variables. The expanded sample weight appearing on the 1995 BY-F2 privileged-use student-level file generalizes to both the population of students who were enrolled in eighth grade in 1988 and the population of students in tenth grade in 1990 regardless of eligibility for NELS:88. In order to account for students who were previously excluded from a particular cohort, select the desired expanded cohort, either eighth-grade (G8COHEXP=1) or tenth-grade (GlOCOEXP=1), and the expanded sample weight (F2EXPWT, which is applicable to either cohort). The difference between estimates derived with the expanded cohort samples and those derived with the eligible NELS:88 samples (identified using the regular NELS:88 cohort identifiers, G8COHORT and G1OCOHRT, which identify only eligible sample members) is the correction factor for the estimate. For information on the statistical properties of F2EXPWT, readers should refer to the NELS:88 Base Year Through Second Follow-Up Sampling Design, Weighting and Estimation Report (Ingels, Scott & Frankel, NCES 1996). Expanded sample composite specifications. Specifications for the expanded sample composites appear below.   For the schools participating in each wave of NELS:88, variables derived from selected 1990 Census items have been created. These variables appear on the BY-F2 restricted-use school file on the 1995 CD-ROM, /NELS92/SCMEG.PRI, and are also available from NCES on magnetic media. The original Census data were aggregated at the zipcode level; data items were extracted from the \"STF3B\" zipcode-level Census files. The Postal Service zipcodes for the NELS:88 schools, which do no/ appear on any NELS:88 files, were used to merge the zipcode-level data with NELS:88 school data, to create school-level Census items. The ideal method for linking Census information to a school service area or local community would be to geographically define the boundaries of each NELS:88 school service area and code the Census tracts in each area. The Census data for the tracts in each service area would then be aggregated and attached to the school's NELS:88 public release ID. Such a precise method of geographically defining school service areas and attaching Census variables to them was undertaken by NCES for U.S. public school districts in collaboration with the Chief State School Officers and the U.S. Bureau of the Census. Their efforts resulted in the School District Data Book (SDDB), a compilation of thousands of 1990 Census data items which is currently available on a set of compact discs Without special funding for a similar effort for NELS:88 schools, which include private schools not included in the SDDB, the selected 1990 Census items for NELS:88 school zipcodes included on the 1995 restricted-use school file provide the next best method for obtaining a limited set of 1990 Census items for NELS:88 school service areas. Types of 1990 Census data available for NELS:88 schools. The primary reason for linking NELS:88 schools to 1990 Census data is to provide researchers with valid and reliable urban/rural distributions at the level of the school service area. In all, some 50 characteristics (including urbanicity) are provided for each set of NELS:88 schools, including: Race (% White, Black, Asian, American Indian, Other); Hispanic origin (% Mexican, Cuban, Puerto Rican, Other Hispanic); Poverty (% Above or Below) status by 12 age categories; Income-to-poverty level ratios Median income (for households in the zipcode) Some items, such as median income and the number of residents or households in each zipcode, have been copied directly from the Census files without modification. Other Census items have been altered in the interest of standardization across zipcodes. The raw counts provided in Census tables have for many variables been used to calculate the proportion of zipcode residents displaying a given attribute. For example, from the raw counts provided in Census tables, the percentage of Black residents has been calculated for each zipcode. Researchers who wish to recalculate raw counts can easily do so, since a variable indicating the number of residents in each zipcode is provided."}, {"section_title": "A Note on Urbanicity", "text": "The Census definition of \"urban\" has been evolving since 1950. Prior to 1950, the definition required that territory, persons or housing units be located in incorporated areas, and this excluded many densely settled areas. Even with special rules that were devised to deal with anomalous situations, many 72 C-1 NELS:88 Second Follow-Up Final Methodology Report large, densely populated areas were excluded from the urban category. Examination of the Census data for NELS:88 schools reveals that \"urbanicity\" is not a single variable comprising mutually exclusive categories where only one category applies to a given area. Rather, urbanicity can vary WITHIN an area. That is, a single zipcode may be characterized as containing a certain percentage of persons residing in urban areas and a certain percentage residing in rural areas. As the Census Bureau states (see 1990 Technical Documentation, p. A-12): The urban and rural classification cuts across the other hierarchies; for example, there is generally both urban and rural territory within both metropolitan and non-metropolitan areas. The four Census-derived urbanicity variables for NELS:88 schools indicate the distribution of zipcode residents (as the percentage of all residents) across four types of areas defined by the Census: Urban, inside an urbanized area Not in an urbanized area Rural non-farm Rural farm NELS:88 School-level Census-derived variables. Variable names in the following list begin with \"BY\", indicating that they apply to NELS:88 base year (1988) schools. Comparable variables are available for 1990 first follow-up and 1992 second follow-up schools. Variable names for these rounds begin with \"F1\" or \"F2\", respectively. Missing data are represented by the NELS:88 missing reserved code (e.g., 8, 99998, etc.). All variables are at the school level and refer to the school's zipcode. The variable name appears in the left column, the variable description in the right column. below sum to 100 percent (plus or minus rounding error). Researchers may wish to collapse poverty and non-poverty percentages and/or age category percentages to arrive at proportions of greatest relevance to the research question under investigation. These variables were calculated from Census table P117: In this and the next set of items (following median household income), 1989 income refers to 1989 income per family member, the average amount of income available to every man, woman and child in a  indicate the percentage of zipcode residents with various ratios of 1989 family income to the appropriate poverty threshold for the family or group. Ratios below 1.00 indicate that a family's or group's income is below the poverty level, while a ratio of 1.00 or greater indicates an income above the poverty level. For example, a ratio between 1.00 and 1.24 indicates that a family's income is somewhere between their poverty threshold and 24 percent above it. That is, if a family's poverty threshold is $10,000, a ratio of 1.00 to 1.24, means their income lies somewhere between $10,000 and $12,400, or between 1.00 X $10,000 and 1.24 X $10,000. to the creation of the privileged use CD-ROM. These data however may be specially requested, under licensing agreement, from NCES. Data elements were extracted from the \"STF3B\" zipcode-level Census files and include percentages of families in poverty, median family income, percent of black, white, and Hispanic males unemployed, percent of births to women under age 20, ratio of single males to single females, and so on. The base year through second follow-up restricted-use school file on the 1995 CD ROM contains five link variables for each NELS:88 school that participated in the BY, Fl or F2 school survey. These variables are also available on separate files --referred to as school link files--on magnetic media from NCES, for use with earlier releases of the NELS:88 data, which do not contain the link variables. Variable names are wave-specific and are listed below in wave order (BY, F1 and F2). (Link variables for a particular wave are blank for all schools that are not part of the responding school sample for that wave.) When merging the school file with external files, the user should select the school sample and linking variable for the survey wave appropriate to his/her analysis. NELS:88 public-use school IDs, 5-digit IDs appearing on all NELS:88 student and school files. These IDs can be used to merge NELS:88 student and school data, and can be used to merge the school link file with the NELS:88 files; a blank school ID indicates that the school was not in the school sample for that wave. CCD school identification number for the NELS:88 school. The first two digits of this ID represent the FIPS state number; the next five digits 3-7constitute the agency (district) ID, unique within states, and the final five digits (8)(9)(10)(11)(12) form the school ID, unique within districts. The first seven digits of the NCES ID, the FIPS state number and the agency ID, can be used to link NELS:88 records with the CCD and SDDB district-level records. The full 12-digit ID can be used to link NELS:88 records with school-level CCD records. NCES ID is blank for all non-public schools, which are not included in the CCD or SDDB datasets. QED school permanent identification number for the NELS:88 school. The QED PIN serves as the link to the NELS:88 QED school files (see appendix E) included on the 1995 restricted-use CD and also available separately from NCES. QED PIN is blank for some NELS:88 schools not included in the QED files. QED state code (equivalent to the FIPS state number) for the NELS:88 school. This variable and O.E. district number (below) are used to merge NELS:88 records with the QED district files. Note that there are no district/diocese records for non-Catholic private schools; QED school type is indicated by the variables BYQEDTYP, F1QEDTYP and F2QEDTYP. The QED state code is blank for some NELS:88 schools not included in the QED files. O.E. district number, used with the QED state code to merge NELS:88 records with the QED district files. The code \"66666\" is used for non-Catholic private schools, which have no district or diocese and do not appear in the QED district files. The O.E. district number is blank for some NELS:88 schools not included in the QED files. It is important to note that the 1995 school file/NELS:88 QED-CCD-SDDB school link file provides only the identification variables or linking mechanisms for merging two or more independent data files and not actual data elements from QED, CCD or SDDB files. To obtain the latter two external datasets, users must contact the distributors of CCD and SDDB data (see below). QED school and district data for the NELS:88 BY, Fl and F2 schools are included on the 1995 restricted-use CD and are also available on magnetic media from NCES, as separate data files not supported by an ECB. See appendix E for complete documentation for the NELS:88 QED files. Linking to QED Files. See appendix E for complete information on the NELS:88 QED school and district files and procedures for merging NELS:88 and QED files. Linking to CCD Files. NCES's Common Core of Data files contain both district-level (referred to as agency-level data) and school-level records for public schools only. Note that as of spring 1995, the CCD CD-ROM release contains records for academic years 1987-1988 through 1992-1993, a set that includes all of the NELS:88 data collection periods (spring 1988, spring 1990 and spring 1992 Merging CCD data with the 1995 NELS:88 BY-F2 school file or the school link file. CCD data may be merged with the NELS:88 files using the CCD school ID (BYNCESID, F1NCESID, F2NCESID) a 12-digit ID with the first 2-digits representing the FIPS state code, the next 5-digits constituting the agency (public district) ID (unique within each state code) and the last 5-digits standing for the school (unique within each agency ID). Users should note that although the CCD school ID is a numeric variable, it appears on both the CCD files and the NELS:88 files in character format. Merge CCD school records from a particular year with the NELS:88 files by the entire 12-digit CCD school ID. The CCD school file and the NELS:88 school sample selected and the ID used in the merge will depend on the survey wave of interest. If, for example, you wished to merge NELS:88 base year data with CCD data , you would use the NELS:88 BY CCD school ID, BYNCESID, and the CCD school file for the 1987-1988 academic year. Merge CCD district records from a particular year with the NELS:88 files by the 7-digit CCD agency ID. The CCD agency ID comprises the first seven digits of the CCD school ID (BYNCESID, F1NCESID or F2NCESID) and consists of the 2-digit FIPS state code and the contiguous 5-digit agency ID. Once again, the CCD district file and the ID used in the merge will depend on the survey wave of interest. Merging the SDDB files with the 1995 NELS:88 BY-F'2 school file or the school link file. The SDDB data files, like the CCD agency-level records, are organized at the level of the public school district. As such, SDDB data can be merged with the NELS:88 files by the CCD agency ID, the first 7-digits of the 12-digit CCD school ID (BYNCESID, F1NCESID or F2NCESID). Merging data from external sources with the student-level file. After merging data from external databases with the 1995 NELS:88 BY-F2 school file or the school link file, the user may merge the resulting school-level file with the NELS:88 student-level file by the school ID for the survey wave of interest--SCH ID (BY), FISCH ID or F2SCH_ID. Prior to performing this merge, it is recommended that the user select the student sample appropriate to his/her analysis. This appendix documents the QED (Quality Education Data of Denver, Colorado) files that are included on the 1995 NELS:88 base year through second follow-up restricted-use CD-ROM and the 1996 base year through third follow-up CD-ROM and are also available on magnetic media from NCES. These files contain characteristics of the public districts, Catholic dioceses and schools of all types that participated in the NELS:88 base year, first follow-up and second follow-up surveys. The QED files include information such as grade span, enrollment size, racial/ethnic and poverty proportions among students, the number of schools in a public district and instructional dollars per pupil. The QED data can be merged with other NELS:88 data files for further investigations of contextual effects in the NELS:88 sample. Since an electronic codebook (ECB) is NOT available for the QED files, this documentation is the primary reference for users who wish to learn about the QED variables and how to merge the QED files with other NELS:88 data. This documentation is organized into five sections. First, the use of the QED files in NELS:88 is briefly described. Modifications made to the original QED records for this release are then discussed. Next, the organization of the NELS:88 QED files on the 1995 CD is explained, followed by instructions for merging the 1995 NELS:88 BY-F2 school file (/NELS92 /SCMEG.PRI) with the QED files. Finally, the original QED documentation for the type of files used in NELS:88 is provided. 1. Use of QED data in NELS:88. The NELS:88 base year school sampling frame was the eighth grade school database compiled by QED. QED collects and sells a broad range of information on all schools in the United States, including private schools. In addition to the research community, the QED client base includes purveyors of educational goods such as textbook publishers and hardware/software vendors. The district/diocesan and school files used in the NELS:88 base year were leased from QED in 1987. In preparation for NELS:88 base year sample selection, the QED frame for eighth grade schools was compared to other school databases and corrected (e.g., any missing records were added; invalid or missing stratification variables that were detected were corrected). In 1989, QED files were leased for the first follow-up, and in 1991 for the second follow-up. In the first and second follow-ups, new QED files were used, not for sampling but instead as sources of contacting and locating information for districts and schools to which selected NELS:88 students had dispersed by 1990 and 1992. (Note that some first and second follow-up schools did not appear on the tenth grade and twelfth grade QED files. In the NELS:88 QED school files, \"dummy\" QED PINs (all beginning with \"9\") have been assigned to these schools but the remainder of the school record is blank. Note also that QED data for a particular school may be available for one survey year but not for another.) QED itself maintains only files with current information; the files used in NELS:88 are no longer available from QED. QED has generously given NCES and NORC permission to release the QED data for NELS:88 schools and the associated districts/dioceses to researchers. 2. Modifications made to the QED records for this release. The original QED records for the subset of NELS:88 schools and districts/dioceses have been altered in several ways. A number of variables have been removed from the records for various reasons. Items containing sensitive information, such as the names of school and district personnel and institutional addresses, have been deleted from school and district/diocese records. QED variables delivered on the NELS:88 data files have also been removed from the QED school records. The NELS:88 releases of the variables were checked for consistency with NELS:88 questionnaire data and cleaned as necessary, and are therefore more accurate than the original QED variables. The QED variable called \"Metro Status\", for example, was cleaned and delivered as the NELS:88 urbanicity variables G8URBAN, G 1 OUFtBN3 and G12URBN3 and is not included on the NELS:88 QED E-1 183 NELS:88 Second Follow-Up Final Methodology Report files. (In general, if a user discovers inconsistencies between similar QED and NELS:88 variables, it is suggested that the user assume that the NELS:88 variable is the more accurate). Other variables on the QED records have been blanked out because the data they contained were obviously incorrect. For example, the variable CAI Units (a count of the PCs available for computer-assisted instruction) appears to be valid in the original Grade 10 QED files but invalid in the Grade 12 files, and has consequently been blanked out on the second follow-up QED files. Finally there are variables that were blank on all of the original QED files and are not included on the NELS:88 QED school and district/diocesan files. Users should check any QED variables that they intend to use in analyses for invalid values and consistency with other QED or NELS:88 variables, since most of the QED variables have not been cleaned. Frequency distributions will reveal any invalid values, and crosstabulations of related variables (such as district and school enrollment) is a useful means to check for inter-item inconsistencies. Users may also wish to check that variables expected to remain constant over time (such as the state codes) are in fact the same on files from different survey waves. 3. Organization of the QED files. All of the files related to QED are contained in the subdirectory \\ QED_TEST\\QED on the 1995 CD-ROM and are repeated on the 1996 CD-ROM covering base year through third follow-up. Each of the files contains only those public districts, Catholic dioceses or schools of all types that are associated with the NELS:88 school sample for the particular wave. Researchers should merge NELS:88 schools in the survey wave of interest (BY, Fl or F2) with the corresponding wave of QED files because school and district/diocesan records may change over time. Some districts may consolidate, new schools may be founded, existing schools dissolved and the values of certain characteristics may fluctuate in different time periods (for example, enrollment, teachers, grades and so forth may change as time passes). The QED files on the 1995 and 1996 NELS:88 restricted-use CDs are:"}, {"section_title": "\\QED_TEST\\QED", "text": ""}, {"section_title": "\\READQED.WP5", "text": "The WordPerfect 5.1 file that documents the QED files and contains the same information as this appendix. "}, {"section_title": "\\QEDLAY.OUT", "text": ""}, {"section_title": "E-2", "text": "As the list above indicates, QED school data and district/diocesan data are in separate files, which are further defined by survey wave. One layout applies to all six data files. This layout supersedes the original file layout provided in section 5 below. Users should expect to find more than one NELS:88 school associated with the same district/diocesan record, especially in large urban areas. Please note that valid data is not present on every QED file for all variables defined by QEDLAY.OUT. For example, PERASIAN (percent Asian) is present on only the first follow-up files; on the base year and second follow-up files the columns occupied by this variable are blank. Also please note this very important change: QEDPIN, which is required to merge the QED files with the NELS:88 base year through second follow-up school file, is an eight-character variable according to the original QED documentation, but appears on the NELS:88 school file and link file and the NELS:88 QED as a seven-character variable. (A leading zero was deleted from the original QED PIN number.). Finally, note that non-Catholic private schools in the QED school files, which have no associated district/diocesan records in the district files, are all coded '66666' in the Office of Education District Number field on the QED school files. 4. Instructions for merging the NELS:88 school file and the QED files. The NELS:88 restricted-use school file is fully described in the ECB guide ( \\DOCU\\ECBGUIDE.WP5) on the 1995 CD; variables on this file appear in the NELS:88 BY-F2 ECB. (The NELS:88 school link file, which contains the link variables listed below and which is described in appendix D, may be used to merge earlier releases of the NELS:88 data with the QED files; the procedures outlined below also apply to merging the link file with the QED files .) The NELS:88 school file may be merged with the QED school files, as well as with the QED district\\diocesan files, as follows:  Finally, it may be possible to merge NELS:88 data files with other external datasets, including other federal datasets not discussed in this guide, using the FIPS codes found on the QED files as a crosswalk between the NELS:88 files and the external files. (\"FIPS\" stands for \"Federal Information Processing Standards\"; FIPS codes are standardized codes defined by the U.S. Department of Commerce, Bureau of Standards). The FIPS state codes (as well as 'alpha' Postal Service state codes) appear both on the NELS:88 BY-F2 restricted-use school file and on the QED files. The FIPS county and MA codes appear in the QED records. (\"MAs\", formerly known as \"MSAs\", are geographical areas with a large population nucleus and adjacent communities that have a high degree of social and economic integration with that nucleus. Metropolitan Statistical Areas (MSAs), Primary Metropolitan Statistical Areas (PMSAs) and Consolidated Metropolitan Statistical Areas (CMSAs) are designated collectively as Metropolitan Areas.)"}, {"section_title": "5.", "text": "Original QED file documentation. The remainder of this document is a replication of the original QED documentation received in 1987 (QEDs \"Type 9\" format was used for NELS:88 in all survey rounds). It is presented in two sections. First, the complete QED record layout for the original QED files is displayed on pages 1 and 2. Note that the same layout (and documentation) is used for QED district and school files in every survey year. (DO NOT USE THE LAYOUT IN THE ORIGINAL QED DOCUMENTATION WITH THE NELS:88 QED FILES; USE QEDLAY.OUT.) A user's guide describing the QED variables follows the original layout, on pages 3 through 10. QED variables included on the NELS:88 QED files are denoted in the layout and documentation by an asterisk. In addition, suggested variable names (the same names used in the NELS:88 QED file layout, QEDLAY.OUT) have been added to the original QED documentation in brackets (\"[ ]\"). Users thus have a crosswalk between the variable names in QEDLAY.OUT and the QED documentation. Users should notice in reading through the documentation that some variables that appear in the district-level records have codes with different meanings than in the school-level records. For example, in Student Enrollment (column 169), code 6 in the district record means \"2,500 -4,999\" but in the school record code 6 means \"1,000 -1,499\". Finally, missing data items or records are blank on the QED files. File Format 9User's Guide 9QED Numbering System Last name is isolated by a comma preceding. If person has suffix, such as \"Jr.\", \"Sr.\", or initials of religious order, such suffix will follow the last name. The true \"last name\" will be preceded by a comma. Prefixed titles, such as \"Mrs.\", Sr.\", and \"Dr\" will not be carried in the name field, but can be generated from the Prefix code carried in Position 338 described below. Exception: If Name Option 2 were used for label selection, then 4-character prefix will be written out in name field and last name will not be preceded by a comma.\nMcMillen, M. Eighth to Tenth Grade Dropouts, 1992; Statistics in Brief series, NCES 92-006. This report presents data from the 1988 National Education Longitudinal Study (NELS:88), which started with an eighth-grade cohort and aimed to provide data on dropout experiences as students made the transition into high school and to examine the contextual school and family factors associated with dropping out. The report explains the parameters of the study, the survey methodology, and the data reliability. The data are presented in the following bar graphs: (1) 8th to 10th grade cohort dropout rates by race/ethnicity and sex; (2) 8th to 10th grade cohort dropout rates by region and metropolitan status; and (3) 8th to 10th grade cohort dropout rates by eighth-grade school (public, Catholic, religious private, and non-religious private). (7 p.).  Owings, J.A., andPeng, S. Transitions Experienced by 1988 Eighth Graders, 1992. NCES 92-023. This brief report presents findings regarding two types of transitions experienced by students as they move between the eighth and 10th grades: continuing or dropping out of school and transferring between sectors. While 98% of public school students remained in public schools, over one-third of Catholic school eighth graders and over 25% of National Association of Independent Schools students transferred to public or other private schools. About 6% of all eighth graders were classified as dropouts by spring of their scheduled 10th-grade year. For most students, the move between eighth and 10th grades involves a change of schools and exposure to new educational settings. These transitions may have an impact on student learning and personal development. Consequently, differences in transition patterns and possible outcomes are of major interest. Data were obtained from the base year and first follow-up surveys of the National Education Longitudinal Study of 1988 (NELS:88), which began in 1988 with a sample of 1,052 schools and 24,599 eighth graders. In the spring of 1990, 17,424 students were studied in the first follow-up to determine their education status and progress, and school, community, and work experiences. Four tables present study data, and five graphs illustrate trends from 1988 to 1990. (13 p.)."}, {"section_title": "N.B.", "text": "If correct prefix codes were not available, records will contain \"0\" or \"Mr.\". As a general rule, do not use \"Mr.\" when printing labels. Orshansky Percentile: File Type \"S\" only (Relative Wealth Indicator is 99 -Orshansky). Percentage of students under the poverty guideline as a percentage of total school-age children in the district.  Record Type 2 = District Record (Includes colleges, main libraries, state departments, and regular districts). If district personnel are provided by name and job code, then all districts data will be replicated in each \"district\" record provided, one per name. 6 = Building Record (Includes branch libraries, schools). Principal or Librarian by Name, if requested, will be carried in the building record."}, {"section_title": "205-214", "text": "Code Key Optional letters/numbers requested by client for identification. If a district were updated in October 1985 and the enrollment and number of students were changed, but the superintendent remained unchanged, the DLC for the superintendent would be the \"old date\" while the DLC for the district would be 8511."}, {"section_title": "248-277", "text": "Location Address (Optional) Present only if different than mailing address.                       As a result of inconsistency resolution nine cases in the data file were coded into this category after the calculation of standar errors/design effects, and one case not in the category was recoded as missing. As a result of inconsistency resolution fourteen cases in the data file moved out of this category after the calculation of standar errors/design effects, and three additional cases in the category were recoded as missing. The effective response rate (weighted unit response times weighted item response) for class rank is 66.4 percent. This is lower than the NCES standard of 70 percent for analytic reports, and suggests that the estimate should be interpreted with caution.                      10th grade school completion rate (for school questionnaire), where at least one student has completed a student questionnaire. 10th grade school questionnaire coverage rate for each student who has completed a student questionnaire. Refers to 10th grade school. The second follow-up (1994) release of the first follow-up student data about the sample numbers of the two releases are in section 3.    In addition to different sample numbers, the same variables from the restricted use files were sometimes suppressed on the public use files. The list below indicates the suppressed variables for each component and wave of NELS:88:"}, {"section_title": "F2-STUDENT", "text": "Classifies the student's first follow-up school type"}, {"section_title": "F2S60B1", "text": "Name and location of first post-secondary school applied to F2S60B2 Name and location of second post-secondary school applied to GI2CTRL2 Classifies the student's second follow-up school type The goal of the study is to provide trend data about critical transitions experienced by young people as they develop, attend school, and embark on their careers. Given the challenge facing America's schools--to educate all our young people for the next decade, regardless of family circumstances--NELS:88 will complement and strengthen state and local efforts by furnishing new information on how school policies, teacher practices, and family involvement affect student educational outcomes (i.e., academic achievement, persistence in school, and participation in postsecondary education). Among the major issues that NELS:88 data will help us address are: the features of effective schools and intervention programs, the factors that promote academic growth over time, the process of dropping out of school, the role of educational institutions in assisting the disadvantaged, the school experience and academic performance of language minority students, and the role of mathematics and science curriculum in American secondary schools. In the Spring of 1988, base year data were collected from over 29,000 eighth grade students attending 1,200 schools across the nation and in Spring of 1990, first follow-up data were collected from over 22,000 tenth grade students attending 1,500 schools across the nation. Having completed the 1990 First Follow-Up Study, NORC is currently preparing for the 1992 Second Follow-Up Study which will survey twelfth grade students. The Second Follow-Up data collection period is scheduled for January through May of 1992. We will be collecting the following data through in-school sessions which will take less than onehalf of a school day: cognitive test batteries for twelfth grade students in reading, mathematics, science and social studies, and student questionnaires. We will also ask parents, school administrators, and eligible teachers to complete a questionnaire and return it to us. In addition, we will also collect student transcripts and information on course offerings and enrollments. The collection of course offerings data is scheduled to precede and be concurrent with the student inschool sessions; transcript and enrollment data requests are currently scheduled to begin in September, 1992. The enclosed NELS:88 overview describes the research objectives of NELS:88 Second Follow-Up."}, {"section_title": "Page Two", "text": "The National Catholic Educational Association (NCEA) reviewed and approved the NELS:88 study and encourages diocesan and school cooperation in this important study. This fall, we will visit your school to schedule a Survey Day at your convenience, request the name of a School Coordinator, identify teachers eligible for the survey, confirm enrollment of NELS:88 sample members, and collect other supporting information. At this time, we will also select additional students to participate in the survey. We expect to add one to two students on average across the 1500 participating schools. The research procedures for the Second Follow-Up have been redesigned in an attempt to reduce the burden placed upon schools and minimize the disruption to your school's operations. We have significantly decreased the length of the school administrator's questionnaire. We have also reduced the length of the teacher questionnaire, decreased the size of the teacher sample, and simplified the procedures for its implementation. Survey Days will be flexibly scheduled to meet your convenience. Procedures for the Second Follow-up were field tested to ensure their maximum efficiency and minimal burden. In addition, we are committed to strictly limiting our tasks for the Second Follow-up to the activities outlined above. An NORC staff member will telephone you within the next few weeks to answer any questions you many have, secure your approval for your school's participation in the study and schedule an appointment to visit the school. If you have further questions concerning the study, please call Gwen Merker collect at (312) 753-7603. The cooperation and support of schools is crucial to the success of this landmark study. We look forward to working with you on the NELS:88 Second Follow-Up. The goal of the study is to better understand the impact of earlier educational experiences on high school performance, to explore more fully the transition from eighth grade to high school, and transitions from high school to adult roles. NELS:88 will help us investigate the features of effective schools and intervention programs, the factors that promote academic growth over time, the process of dropping out of school, the role of educational institutions in assisting the disadvantaged, the school experience and academic performance of language minority students, and the nature of the mathematics and science curriculum in American secondary schools. In the Spring of 1988, base year data were collected from over 29,000 eighth grade students attending 1,200 schools across the nation and in Spring of 1990, first follow-up data were collected from over 22,000 tenth grade students attending 1,500 schools across the nation. Having completed the 1990 First Follow-Up Study, NORC is currently preparing for the 1992 Second Follow-Up Study. In the Second Follow-Up which will last from February through June 1992, we will be collecting data through: cognitive test batteries for twelfth grade students in reading, mathematics, science and social studies; student, dropout, parent, and teacher, school administrator questionnaires; and the collection of student transcripts and information on course offerings and enrollments. (The collection of course offerings data is scheduled to precede and be concurrent with the student inschool sessions; transcript and enrollment data requests are currently scheduled to begin September, 1992.) The enclosed overview describes the research objectives of NELS:88 Second Follow-Up. We request your permission to contact the principals of schools located in your district that contain NELS:88 sample members. A staff member from NORC will contact you within the next few days to answer any questions you may have, learn your response, and ask you to name a member of your administrative staff to serve as the District Coordinator. The District Coordinator will serve as the project liaison, and answer any questions participating schools may have regarding the study. If you have any questions concerning the study, please call Gwen Merker collect at (312) 753-7603 from 9:00 a.m. -5:00 p.m. CST."}, {"section_title": "J-3", "text": "We look forward to working with you on the Second Follow-Up Study. Four years ago, a number of young men and women were selected to participate in the National Education Longitudinal Study of 1988 (NELS:88). You may remember taking part in that study. In the winter and spring of 1992, we will be conducting the second follow-up to the 1988 survey, and we would like you to participate. This study is sponsored by the U.S. Department of Education and is being conducted by the National Opinion Research Center (NORC), a social science research center at the University of Chicago. The purpose of NELS:88 is to provide information that will be used by Congress, researchers, and policymakers to improve the quality of education in America. This winter or spring, a representative from NORC will visit your school and help you fill out a Student Questionnaire and a Cognitive Test. The questionnaire will ask about your plans for the future, family and school life, and school work. The Cognitive Test will cover English, mathematics, science, and social studies. Completing the survey should take less than half of a school day. In addition, one or two of your teachers may be asked to complete a Teacher Questionnaire, which will include questions about your school performance. We will also ask you to sign a transcript release form. School transcripts will tell us what courses you have taken; like all information collected in the study, this information will be kept strictly confidential. An important feature of this study is that it follows the same students as they progress through school and eventually enter the work force and/or pursue higher education. For this reason, we cannot replace you in our sample with anyone else. In order to easily locate you in the future, we will ask for your address and telephone number and those of a relative or close friend. In accordance with professional survey ethics and Federal regulations, we will hold your test scores and responses to the questionnaire in strictest confidence. After you have completed the questionnaire and test, our representative will immediately remove your name from the documents, to protect your privacy. Survey responses will be made public only in statistical form, such as \"70% of twelfth graders reported that they....\" NO ONE from your school will see your answers to the questionnaire, and no one will ever be able to connect your answers with your name. Participation in NELS:88 is voluntary, but, because the study is so important, we hope that all students will want to take part. Your opinions and the other information you provide are very important to us. This is your chance to help improve the quality of education in the United States. We are excited about this study and look forward to meeting you. You will be informed shortly of the date, time, and place of the survey session. We hope that you will feel proud about making this important contribution to education in America. Dear Parent or Guardian: Four years ago, a number of young men and women were scientifically selected to participate in the National Education Longitudinal Study of 1988 (NELS:88). You may remember your teenager's participating in that study. In the winter and spring of 1992, we will be conducting the second follow-up to the 1988 survey, and we would like your permission to survey your son or daughter. The purpose of the survey, which is sponsored by the U.S. Department of Education, is to provide information that will be used by Congress, researchers, and policymakers to improve the quality of education in America. As in the two previous rounds of the study, your son or daughter will be asked to complete a Student Questionnaire and a Cognitive Test. The questionnaire will ask about his or her plans for the future, family and school life, and school work. The Cognitive Test will measure achievement in English, mathematics, science, and social studies. Completing the survey should take less than half of a school day. In addition, one or two of your teenager's teachers may be asked to complete a Teacher Questionnaire, which will include questions about your teenager's school performance. We will also ask your son or daughter to sign a school transcript release form. School transcripts will be used to determine what courses he or she has taken; like all information collected in the study, transcript information will be kept strictly confidential. An important feature of this study is that it follows the same students as they progress through school and eventually enter the work force and/or pursue higher education. For this reason, we cannot replace yo son or daughter in our sample with anyone else. In order to locate our sample members in the future, we will ask your teenager for his or her address and telephone number and those of a relative or close friend. In accordance with professional survey ethics and Federal regulations, we will hold your teenager's test scores and responses to the questionnaire in strictest confidence. As soon as the survey has been completed, your teenager's name and any other identifying data will be immediately and permanently separated from the test and questionnaire. From then on, his or her data will be identified solely by an ID number. Survey responses will be made public only in statistical form, such as \"70% of twelfth graders reported doing at least 4 hours of homework each week.\" Participation is completely voluntary--if for any reason you object to your son or daughter's participation, you may simply deny permission. The vast majority of parents in our previous surveys have allowed and encouraged their teenagers to participate in NELS:88. However, we will need to know whether you will allow your son or daughter to participate in our study. Please take a moment to fill out the form on the reverse side and return it to your teenager's school. If you have any questions about the NELS:88 Second Follow-Up Study or your teenager's participation in the survey, please call John Taylor toll-free at 1-800-726-7202 between 9 AM and 5 PM Central Standard Time, Monday through Friday. We thank you in advance for your cooperation in this important research. PARENT LETTER AND IMPLIED CONSENT FORM January 1992 Dear Parent or Guardian: Four years ago, a number of young men and women were scientifically selected to participate in the National Education Longitudinal Study of 1988 (NELS:88). You may remember your teenager's participating in that study. In the winter and spring of 1992, we will be conducting the second follow-up to the 1988 survey, and we would like your permission to survey your son or daughter. The purpose of the survey, which is sponsored by the U.S. Department of Education, is to provide information that will be used by Congress, researchers, and policymakers to improve the quality of education in America. As in the two previous rounds of the study, your son or daughter will be asked to complete a Student Questionnaire and a Cognitive Test. The questionnaire will ask about his or her plans for the future, family and school life, and school work. The Cognitive Test will measure achievement in English, mathematics, science, and social studies. Completing the survey should take less than half of a school day. In addition, one or two of your teenager's teachers may be asked to complete a Teacher Questionnaire, which will include questions about your teenager's school performance. We will also ask your son or daughter to sign a school transcript release form. School transcripts will be used to determine what courses he or she has taken; like all information collected in the study, transcript information will be kept strictly confidential. An important feature of this study is that it follows the same students as they progress through school and eventually enter the work force and/or pursue higher education. For this reason, we cannot replace your son or daughter in our sample with anyone else. In order to locate our sample members in the future, we will ask your teenager for his or her address and telephone number and those of a relative or close friend. In accordance with professional survey ethics and Federal regulations, we will hold your teenager's test scores and responses to the questionnaire in strictest confidence. As soon as the survey has been completed, your teenager's name and any other identifying data will be immediately and permanently separated from the test and questionnaire. From then on, his or her data will be identified solely by an ID number. Survey responses will be made public only in statistical form, such as \"70% of twelfth graders reported doing at least 4 hours of homework each week.\" The vast majority of parents in our previous surveys have allowed and encouraged their teenagers to participate in NELS:88. Participation is completely voluntary--if for any reason you object to your son or daughter's participation, you may simply deny permission. If you do not want your son or daughter to participate, please fill out the form on the reverse side and return it to your teenager's school. If you have any questions about the NELS:88 Second Follow-Up Study or your teenager's participation in the survey, please call John Taylor toll-free at 1-800-726-7202 between 9 AM and 5 PM Central Standard Time, Monday through Friday. We thank you in advance for your cooperation in this important research. Hace cuatro anos, una cantidad de muchachos y muchachas fueron seleccionados por metodos cientificos para participar en el Estudio Nacional Longitudinal de Educacion de 1988 (NELS:88). Ud. recuerde que su hijo o hija adolescente participo en ese estudio. En el inviemo y primavera de 1992, llevaremos a cabo la segunda continuacion de la encuesta de 1988, y quisieramos solicitarle su permiso para que su hijo o hija responda a la encuesta. El proposito de la encuesta que esta patrocinada por el Departamento de EducaciOn de los Estados Unidos, es proveer informacion que usara el Congreso, asi como tambien investigadores y planificadores, para mejorar la calidad de la educaci6n en los Estados Unidos de America. Tal como lo hicimos en las dos partes anteriores del estudio, a su hijo o hija se le pedird que complete un Cuestionario para Estudiantes y un Test Cognitivo. El cuestionario tendra preguntas acerca de sus planes para el futuro, acerca de su vida familiar y escolar, y de las tareas escolares. El Test Cognitivo medird su capacidad en ingles, matematicas, ciencias y estudios sociales. Para completar la encuesta debera llevarle menos de medio dia de escuela. Ademas, se le pedira a uno o dos de los maestros de su hijo(a) que complete un Cuestionario para Maestros, que va a tener preguntas sobre el desempexio escolar de su hijo(a). Tambien le pediremos a su hijo o hija que firme un permiso para que podamos obtener su certificado de notas. Los certificados de notas se usaran para determinar que cursos ha tornado su hijo(a); al igual que con toda la informacion que se obtiene en este estudio, la informacion de su certificado de notas se mantendra bajo total confidencialidad. Si tiene alguna pregunta acerca de la Segunda Continuacion del Estudio NELS:88 o de la participaci6n de su hijo(a) adolescente en esta encuesta, por favor llame a Amelia Solorio a nuestro numero de telefono sin cargo (\"toll-free\") al 1-800-726-7202, de lunes a viemes, de 9 de la maiiana a 5 de la tarde, Hora Estandar Central. Desde ya le agradecemos su cooperacion en en este importante proyecto de investigacion. Hace cuatro afros, una cantidad de muchachos y muchachas fueron seleccionados por metodos cientificos para participar en el Estudio Nacional Longitudinal de Educaci6n de 1988 (NELS:88). Quizas Ud. recuerde que su hijo o hija adolescente particip6 en ese estudio. En el invierno y primavera de 1992, llevaremos a cabo la segunda continuacion de la encuesta de 1988, y quisieramos solicitarle su permiso para que su hijo o hija responda a la encuesta. El proposito de la encuesta que esta patrocinada por el Departamento de Educacion de los Estados Unidos, es proveer informacion que usard el Congreso, asi como tambien investigadores y planificadores, para mejorar la calidad de la educacion en los Estados Unidos de America. Tal como lo hicimos en las dos panes anteriores del estudio, a su hijo o hija se le pedira que complete un Cuestionario para Estudiantes y un Test Cognitivo. El cuestionario tendra preguntas acerca de sus planes para el futuro, acerca de su vida familiar y escolar, y de las tareas escolares. El Test Cognitivo medira su capacidad en ingles, matematicas, ciencias y estudios sociales. Pam completar la encuesta debera llevarle menos de medio dia de escuela. Ademas, se le pedird a uno o dos de los maestros de su hijo(a) que complete un Cuestionario para Maestros, que va a tener preguntas sobre el desempeno escolar de su hijo(a). Tambien le pediremos a su hijo o hija que fume un permiso para que podamos obtener su certificado de notas. Los certificados de notas se usaran para determiner que cursos ha tornado su hijo(a); al igual que con toda la informacion que se obtiene en este estudio, la informacion de su certificado de notas se mantendra bajo total confidencialidad. Una caracteristica importante de este estudio es que sigue a los mismos estudiantes a medida que avanzan a naves de la escuela y finalmente ingresan a la fuerza de trabajo, o contindan sus estudios luego de la escuela secundaria. Por esta razon, no podemos cambiar a su hijo o hija en nuestra muestra de participantes por alguna otra persona. Para poder encontrar a los miembros de nuestra muestra en el futuro, le vamos a pedir a su hijo o hija adolescente que nos de su direcci6n y niunero de telefono y la de algim pariente o amigo. Siguiendo la etica profesional de encuestas y los reglamentos federales, mantendremos bajo total confidencialided al puntaje que saque en los tests su hijo(a) adolescente y sus respuestas al cuestionario. En cuanto la encuesta haya sido completada, el nombre de su hijo(a) adolescente asi como cualquier otro dato que pueda identificarlo(la) sera separado inmediata y defmitivamente del test y del cuestionario. De ahi en adelante, sus respuestas serail identificadas exclusivamente por un niunero. Las respuestas a la encuesta solo se daran a conocer publicamente en forma de estadisticas, como por ejemplo \"el 70% de los alumnos del 12 \". grado dijeron que cads semana hacen por lo menos 4 horas de tarea para la escuela.\" La gran mayoria de los padres en nuestras encuestas anteriores han permitido y fomentado la participacion de sus hijos adolescentes en NELS:88. Participacion en este estudio es completamente voluntaria--si por cualquier motivo Ud. no esta de acuerdo con que su hijo(a) participe, simplemente puede negar su permiso. Si Ud. no quiere que su hijo(a) participe, por favor complete el formulario que aparece del otro lado y devuelvalo a la escuela de su hijo(a) adolescente."}, {"section_title": "J -12", "text": "Si tiene alguna pregunta acerca de la Segunda Continuacion del Estudio NELS:88 o de la participacion de su hijo(a) adolescente en esta encuesta, por favor llame a Amelia Solorio a nuestro numero de telefono sin cargo (\"toll-free\") al 1-800-726-7202, de lunes a viernes, de 9 de la manana a 5 de la tarde, Hora Estandar Central. Desde ya le agradecemos su cooperacion en en este importante proyecto de investigacion.  August, 1992 Dear Parent: I am writing this letter to urge you to participate in the second follow-up to the National Education Longitudinal Study of 1988 (NELS:88), sponsored by the National Center for Education Statistics in the U.S. Department of Education. The goal of this study is to improve education in America, particularly for students whose native language is not English. Your teenager participated in this study last spring, but in order to understand his or her school experience and educational needs, we need additional information from you. We mailed a questionnaire to you and asked you to fill it out and return it to us; however, we have not yet received it. In the event that you have not received it or no longer have it, I have included another questionnaire for you. Unfortunately, I do not have one in your native language. If you cannot read the English questionnaire, please ask a friend or relative to help you with it. After you fill it out, please send it back to us in the postage-paid envelope. If you have already returned the questionnaire to us, please accept my thanks and disregard this letter. Thank you for your cooperation. Your participation in this important study will help us to work toward a better education for all students. Los datos obtenidos mediante esta encuesta seran utilizados por educadores y planificadores a nivel federal y estatal en el analisis de ciertas cuestiones importantes que interesan a las escuelas de la naci6n, tales como las normas educativas, los procedimientos de seguimiento de los cursos de estudios, el abandono de los estudios, la educacion de grupos marginados, las necesidades de los estudiantes pertenecientes a grupos lingilisticos minoritarios, los incentivos destinados a despertar interes en el estudio de las ciencias y las matermaticas y los rasgos que caracterizan a aquellas escuelas que se destacan por su eficacia."}, {"section_title": "CONFIDENCIALIDAD", "text": "La politica del Centro Nacional de Estadisticas de la Educacion requiere la proteccion de la confidencialidad de la informaci6n proporcionada por las personas que participan voluntariamente en nuestros estudios. Queremos que sepas que: La SecciOn 406 de la Ley sobre Disposiciones Educacionales Genera les (20-USC 1221e-1) y la Ley POblica 100-297 nos autorizan a hacerte las preguntas que figuran en este cuestionario. El tiempo que lleva participar en la presente recoleccion de datos ha sido estimado en un promedio de tres horas (180 minutos), incluyendo una hora para contestar el cuestionario, hora y media para el Test Cognitivo y un maxim\u00b0 de media hora para la distribucion de materiales y el suministro de instrucciones. Escribe el nombre y la direccion de tu padre en los espacios que aparecen a continuacion. Si ademas de padre tienes tutor, escribe el nombre de aquel con quien vivas la mayor parte del tiempo.\nLa politica del Centro Nacional de Estadisticas de la Educaci6n requiere la proteccion de la confidencialidad de la informacion proporcionada por las personas que participan voluntariamente en nuestros estudios. Queremos que sepas que: La Seccien 406 de la Ley sobre Disposiciones Educacionales Genera les (20-USC 1221e-1) y la Ley Publica 100-297 nos autorizan a hacerte las preguntas que figuran en este cuestionario. Se ha estimado que participar en la presente recoleccion de datos toma, en promedio, tres horns (180 minutos), incluyendo una bora para contestar el cuestionario, Nora y media para el Test Cognitivo y un 111117d1110 de media hors para la distribucion de materiales y el suministro de instrucciones. Por favor, dirige tus comentarios relacionados con esta recoleccion de datos, o con cualquiera de sus aspectos, a: U.S. Department of Education, Information Management and Compliance Division, Washington, D.C. 20202-4651 y a Office of Management and Budget, Paperwork Reduction Project, Washington, D.C. 20503. El proposito de este estudio es obtener informaci6n pars mejorar la comprension por parte de educadores y planificadores sobre las diversas experiencias que atraviesan los individuos tanto en la escuela secundaria como en los lugares de trabajo. Este cuestionario no es una prueba. El Centro necesita tus respuestas, y por eso confia en que contestaras cada pregunta conforme a la verdad. Puedes dejar sin responder cualquier pregunta que prefieras no contestar. Por favor, escribe tu nombre, direccion y numero de telefono en letra de imprenta.  Escribe el nombre y la direccion de tu madre en los espacios que aparecen a continuaciOn. Si ademas de tu madre, tienes guardiana, escribe el nombre de aquella con quien vives la mayor parte del tiempo.\nLa politica del Centro Nacional de Estadisticas de la Educacion le exige al Centro proteger la confidencialidad de la informaci6n proporcionada por las personas que participan voluntariamente en nuestros estudios. Queremos que sepas que: 1. La Seccion 406 de la Ley sobre Disposiciones Educativas (20-USC 1221e-1) y la Ley Ptiblica 100-297 nos autorizan a hacerte las preguntas que figuran en este cuestionario."}, {"section_title": "NOMBRE:", "text": "Apellido ;,Rasta que punto estEis de acuerdo con cada una de las afirmaciones que aparecen a continuacion relacionadas con to escuela y con tus profesores actuales?   Programa o curso vocacional en una escuela vocacional de to zona j. Programa para estudiantes superdotados o con talento especial k. Programa especializado (\"magnet\") en una escuela separada, o un programa dentro de una escuela secundaria general Los programas \"Talent Search\" y \"Upward Bound\" son programas que ayudan a los estudiantes de la secundaria con problemas econfimicos a prepararse para entrar a la universidad y a que les vaya bien. Durante tus afios de secundaria, zhas participado alguna vez en estos programas, o en programas similares? (MARCA UNA RESPUESTA) Por favor, marca con un circulo los altos que participaste en \"Talent Search\" y \"Upward Bound\" o en programas similares.    A continuaciOn hay una lista de algunas de las rezones que otras personas dan pars tomar una clase de ciencias. Por favor, categorizalas segtin la importancia que hayan tenido en tu decision de cursar la clase de ciencias que est& tomando en este periodo; marca tus categories desde \"ninguna importancia\" (01) hasta \"mucha importancia\" (OS). Si alguna razor' no corresponde a to situacion, marca solo el casillero que dice \"no corresponde\" para esa razon. a. Me interesan las ciencias b. Me va bien en ciencias c. Necesito cursarla para la universidad o para la escuela comercial/industrial   escribir sobre matematicas9  000011 0 0000 0 0 0000 0 0 0000 0 0 0000 0 0 307.\nApellido Por favor, escribe el nombre, la direccian y el !Amer\u00b0 de telefono de un pariente o de un 0 amigo intimo que no viva contigo, pero que siempre sepa cam\u00b0 encontrarte.\nApellido Por favor, escribe el nombre, la direccion y el ntimero de telefono de tu ex-esposo(a) o de tu esposo(a) actual. A continuacion se enumeran algunos de los motivos que mochas personas clan para 0 abandonar la escuela. i,Cmiles de ellos to parecen iguales o similares a los tuyos? No me llevaba bien con mis maestros Tomando en cuenta los motivos que marcaste en la Pregunta 9A, asi como cualquier otro motivo que puedas haber tenido, fueron los principales motivos por los que abandonaste los estudios en la tilthna escuela a la que fuiste? (ESCRIBELO A CONTINUACION) 10A. Antes de la oltima vez en que abandonaste los estudios, zalguna vez dejaste de ir a la 0 escuela durante nuis de un mes por algtin motivo que no fuera el estar enfermo(a)? (MARCA UNA RESPUESTA) zAproximadamente cuantos dias de clases perdiste durante el aiio escolar de 1990-91? (Si dejaste la escuela durante ese afio, toma en cuenta solamente los dias que perdiste antes de dejarla.) (ESCRIBE EL NUMERO A CONTINUACION)  LCuintas veces to pas6 lo siguiente durante el Ultimo semestre o periodo escolar completo que terminaste en la escuela? a. Llegue tarde a la escuela b. "}, {"section_title": "22C.", "text": "A continuacion hay una lista de algunas de las razones que otras personas dan pars tomar una clase de matematicas. Por favor, categorizalas segtin la importancia que hayan tenido en tu decision de cursar la clase de matematicas que estas tomando en este periodo; marca tus categorias desde \"ninguna importancia\" (01) hasta \"mucha importancia\" (05). Si alguna razon no corresponde a to situacion, marca solo el casillero que dice \"no corresponde\" para esa razon.   (Cont.) CADA SEMANA, zcuanto tiempo le dedicas, dentro y fuera de la escuela, a las tareas que se to asignan, tanto en total como para cada una de las siguientes closes, pars hacer en la casa? Los esfuerzos de algunos estudiantes son premiados por la escuela o la comunidad. Durante la primera mitad del ano escolar, zganaste alguno de los premios mencionados a continuaci6n, o fuiste objeto de alguna distincion por tus esfuerzos o por tu participacion en ciertas actividades? Por favor, marca una respuesta por CADA tipo de deporte/actividad deportiva interescolar en que hayas participado durante el transcurso del ANO ESCOLAR ACTUAL ( \"INTERESCOLAR\" se usa cuando tu escuela compite contra equipos de otras escuelas).  (carrera \"cross-country\", gimnasia, golf, tenis, carreras atleticas, lucha ) \"Cheerleading\", \"pompon\", \"drill team\" Por favor, marca una respuesta por cada actividad en que hayas participado durante el transcurso del ASIO ESCOLAR ACTUAL. En cada linea marca con un circulo el mimero =is alto que corresponds.   Participar en deportes (que no esten patrocinados por tu escuela) 34. Durante el afio escolar, zcuantas horas por dia dedicas GENERALMENTE a jugar juegos de video o de computadora, tales como Nintendo? RESPONDE EN AMBAS COLUMNAS \"A\" I \"B\", A CONT1NUACION.  importancia  importancia   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2  3   1   2   3   1   2   3   1   2   3   1   2   3   32 41.    2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   1   2   1   2   1   2   1   2   1   2   1   2   42 60A. zA cusintas escuelas has solicitado admision? (MARCA UNA RESPUESTA)  Pensando en el futuro, zque posibilidades hay de q u e . . .   piensan trabajar en un empleo regular, de tiempo completo? d. piensan asistir a un programa de dos altos en un \"community college\" o en una escuela tecnica? e. piensan asistir a la universidad por cuatro aims?   Suit de las siguientes afirmaciones describe mejor tu relacion con el padre/la madre del menor de tus nifios? (Si tienes mas de un hijo, por favor contesta pensando en el menor de ellos).  Desde el comienzo de este alio escolar, y mientras to encontrabas dentro del area de to escuela, zcuantas veces (si es que alguna) has estado bajo la influencia de lo siguiente:"}, {"section_title": "20+", "text": ""}, {"section_title": "Ocasiones", "text": "Ocasiones Ocasiones Ocasiones a. alcohol ?. Sin tomar en cuenta el trabajo que haces en tu casa, zalguna vez has trabajado a sueldo? Desde el comienzo del alio escolar, Lculintas veces faltaste a la escuela porque tuviste que cuidar a tu propio hijo(a), o a hermanos menores, o a otros ninos de tu familia menores que tu? En las familias suelen ocurrir muchas cosas que afectan a los jovenes. En los tiltimos dos atios, i,ha ocurrido en to familia alguna de las siguientes cosas?  "}, {"section_title": "Test (SAT)", "text": "Presentar solicitudes a universidades u otras escuelas para despues de la i. Asuntos que to estan preocupando . . . .  LCuantas veces has cambiado de escuela desde el 1 de enero de 1988? NO consideres cambios ocasionados por pasar de grado o porque te pasaste del edificio de una escuela intermedia al edificio de una escuela secundaria o superior en el mismo distrito. Para presentar una solicitud a un \"community/junior college\" de dos ahos ."}, {"section_title": "f.", "text": "Para presentar una solicitud a una escuela vocacional, tecnica, de comercio o negocios g. Para ser aceptado a una universidad de cuatro atios h. Para ser aceptado a un \"community/ junior college\" de dos ailos i. Para ser aceptado a una escuela vocacional, tecnica, de comercio o negocios j. Desde la epoca en que terminaste la escuela superior o secundaria y la actualidad, zte has matriculado o tornado clases en cualquier tipo de escuela, tal como una universidad, una escuela profesional o de posgrado, una escuela o academia militar, una escuela de negocios, una escuela tecnica/vocacional, o en un \"community college\"? (No incluyas  Los datos obtenidos mediante esta encuesta seran utilizados por educadores y planificadores a nivel federal y estatal en el analisis de ciertas cuestiones importantes que interesan a las escuelas de la nacion, tales como las normas educativas, los procedimientos de seguimiento de los cursos de estudios, el abandono de los estudios, la educacien de grupos marginados, las necesidades de los estudiantes pertenecientes a grupos lingiiisticos minoritarios, los incentivos destinados a despertar interes en el estudio de las ciencias y las matematicas y los rasgos que caracterizan a aquellas escuelas que se destacan por su eficacia."}, {"section_title": "20.", "text": "En cuanto a la nItima escuela secundaria o superior a la que asististe, ,cual de las siguientes categorias describe mejor el tipo de programa en el que estabas?  21. zAlguien en to escuela tomb alguna de las siguientes iniciativas la 0 tiltima vez en que dejaste de it a la escuela? Ofrecie enviarme a otra escuela "}, {"section_title": "23.", "text": "Desde que dejaste la escuela, zte has inscrito en alguna institucion 0 educativa como, por ejemplo, una escuela vocacional o de comercio, o una universidad? Escuela tecnica, vocacional o de Si No b. comercio \"Junior/community college\" de dos ailos: Las siguientes preguntas tratan sobre programas alternativos en las escuelas. Los estudiantes que estan en programas alternativos toman cursos o reciben servicios especiales diferentes a los cursos y servicios que obtiene la mayoria de los estudiantes. Un programa de GED es un programa alternativo SOLO SI ofrece cursos y servicios que no estan a la disposicion de la mayoria de los estudiantes. Un programa alternativo puede ofrecerse en una secundaria coman o existir de manera independiente. Ejemplos de programas alternativos son: una escuela dentro de una escuela Ca school-within-a-school\"), programas para padres adolescentes, programa para prevenir el abandono de los estudios, \"street academy\", o programas de regreso a la secundaria."}, {"section_title": "25.", "text": "i,Alguna vez has participado en un programa alternativo? (MARCA UNA RESPUESTA)  En total, Len cudntos programs alternativos has participado? (MARCA UNA RESPUESTA)   Encontrar a la persona con quien desee casarme y ser Tener tiempo libre suficiente para disfrutar de las cosas ;,Haste que grado crees que tu padre y tu madre desean que prosigas tus estudios? (CONTESTA IV. DINERO Y TRABAJO En esta seccion hacemos preguntas sobre los tipos de empleo que has tenido, tus ingresos y horarios de trabajo en cada uno de estos empleos, y sobre la relacion entre to entrenamiento y educacion y tus diferentes empleos. Tus respuestas nos ayudarin a interpretar los resultados de esta encuesta. Durante la tiltima semana, has tornado alguna de las siguientes iniciativas para encontrar un  "}, {"section_title": "45A.", "text": "LCusil de las siguientes categorias describe mejor to empleo u ocupachin actual (o el MIIS reciente, 0 si estds desempleado(a) en la actualidad)? Aunque no estes seguro(a), marca con un circulo la que to parezca mss apropiada. (  Del dinero que gangs en to empleo actual, lcutinto gastos en cads una de las categories que se enumeran a continuation? (Si est& desempleado(a) en la actualidad, responde con relation al ultimo empleo que tuviste)          zQue tan cierta es cads una de las siguientes afirmaciones con respecto a ti y a tus padres o guardianes? a. Mis padres/guardianes confian en que yo haga lo que ellos esperan de mi sin tener que vigilarme e. Para presentar una solicitud a un \"community /junior college\" de dos aims . f. Para presentar una solicitud a una escuela vocacional, tecnica, de comercio o negocios g. Para ser aceptado(a) a una universidad de cuatro altos h. Para ser aceptado(a) a un \"community/ junior college\" de dos altos i. Para ser aceptado(a) a una escuela vocacional, tecnica, de comercio o negocios j. Para sacar buenas notas en la universidad k. Para sacar buenas notas/calificaciones en una escuela vocacional, tecnica, de comercio o negocios Ninguna dificultad Un poco de  Mucha  dificultad   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   1   2   3   61   430 NELS:88 SECOND FOLLOW-UP 0"}, {"section_title": "EQB2111LAUSIDEAEMBIZACION", "text": "Este formulario solicita tu autorizacion firmada para que la tilthna escuela a la que asististe nos entregue una copia de tu certificado de calificaciones de la escuela secundaria o superior. Esta informacion sera utilizada unicamente para los propesitos de esta encuesta. Deseamos agradecerte de antemano tu ayuda y cooperachin."}, {"section_title": "INEQBAIACLQIUDIBETILIJIMBIALEDECAMQ", "text": "Por favor entreguen a NELS:88 SEGUNDO ESTUDIO COMPLEMENTARIO una copia de mi certificado de calificaciones. La informacion debersi incluir mi puntaje en pruebas estsindar (\"standard test scores\"), mis promedios de calificaciones (\"grade point averages\") y mis registros de asistencia. Los datos obtenidos mediante esta encuesta seran utilizados por educadores y planificadores a nivel federal y estatal en el analisis de ciertas cuestiones importantes que interesan a las escuelas nacionales, tales como las normas educativas, los procedimientos de seguimiento de los cursos de estudios, el 'abandono de los estudios, la educacion de grupos marginados, las necesidades de ciertos estudiantes pertenecientes a grupos lingilisticos minoritarios, los incentivos destinados a despertar interes en el estudio de las ciencias y las matematicas y los rasgos que caracterizan a aquellas escuelas que se destacan por su eficacia."}, {"section_title": "2.", "text": "El proposito de estas preguntas es obtener informacion sobre las experiencias que viven los estudiantes durante sus estudios secundarios y mientras deciden a que actividades desean dedicarse una vez que los terminen.\nLa persona con quien esta Ud. casado(a) o con la que vive en una relacion similar al matrimonio, aun cuando el o ella no sea uno de los padres de su muchacho(a). Otro adulto con quien Ud. comparte la responsabilidad hacia su muchacho(a) 4. Si ninguna de las tres afirmaciones anteriores corresponde a su situacion actual, por favor indique NO CORRESPONDE en aquellas preguntas en que se le pide informacien sobre su ESPOSO(A)/COMPASTERO(A). En total, zonintas personas dependen economicamente de Ud. (o de Ud. y de su esposo(a)/companero(a)? Tome en cuenta a todos aquellos que dependen de Ud. o de su esposo(a)/compaftero(a) para satisfacer la mitad o mas de sus necesidades econ6micas. Incluya a las personas que no viven con Ud. y su esposo(a)/compafiero(a), pero no se incluya Ud. ni a su esposo(a)/compaiiero(a). zCwiles de las siguientes personas viven en el mismo hogar que el muchacho(a) cuyo nombre aparece en la cubierta de este cuestionario? Acuerdese de incluirse Ud. tambien. A continuacion en la pregunta 16, describa por favor el empleo actual o mks reciente de su esposo(a)/compafiero(a). Si su esposo(a)/compafiero(a) ha tenido mks de un empleo, por favor describa solamente su empleo principal. "}, {"section_title": "3.", "text": "Puedes dejar sin responder cualquier pregunta que prefieras no contestar; sin embargo, esperamos que contestes tantas preguntas como sea posible."}, {"section_title": "0", "text": "El padre o la madre biologicos o adoptivos, al padrastro o la madrastra, o al padre o la madre de crianza del muchacho(a) cuyo nombre aparece en la cubierta de este cuestionario, con quien Ud. vive en la actualidad."}, {"section_title": "29.", "text": "LCutil fue el ultimo grado al que su muchacho(a) asistio? Si su muchacho(a) esta actualmente inscrito(a) en la escuela, por favor indique el grado en el que esta inscrito(a).  Por favor indique pasta que punto esbi de acuerdo o en desacuerdo con cada una de las siguientes afirmaciones sobre la escuela superior/secundaria de su muchacho(a). Si el/ella ha dejado la secundaria, refierase a la secundaria a la que su muchacho(a) asistid por 'Mims vez.   Desde que comenzo la escuela de su muchacho(a) el otofio pasado (o durante el ultimo afio en que su muchacho(a) estuvo en la escuela), Leonidas veces se ha puesto en contacto la escuela con Ud. o con su esposo(a)/companero(a) en relacion con cada uno de los asuntos siguientes?  Desde que comenzfi la escuela de su muchacho(a) el otoiio pasado (o durante el Ultimo aiio en que su muchacho(a) estuvo en la escuela), zcuantas veces se han puesto en contacto con la escuela Ud. o su En su opinion, zdeberian tener los padres de los estudiantes en la escuela de su muchacho(a) mss influencia, menos influencia, o considers que ya cuentan con la influencia suficiente en relacion con cada uno de los siguientes aspectos: a. Decisiones sobre la manera de gastar los fondos de la escuela   En su familia, lquien toma la mayoria de las decisiones acerca de cada uno de los siguientes asuntos? (Por favor refierase a la pligina 4 para la definicion de esposo(a)/compafiero(a). Si Ud. no tiene esposo(a)/compafiero(a), por favor responda en relacion con Ud. mismo(a) Los cursos que toma mi muchacho(a) Aptitude Battery\" (ASVAB) Presentar solicitudes a universidades u otras escuelas para cuando termine la escuela       ;,Con cuantos de los padres de los muchachos(as) que van a In misma escuela que el suyo(a) habla Ud.  Por favor indique hasta clue punto esta de acuerdo o en desacuerdo con las siguientes afirmaciones sobre su muchacho(a) y sobre los amigos de su muchacho(a).    En el transcurso del alto pasado, Leon que frecuencia hable Ud. con su muchacho(a) sobre la posibilidad de que solicitara su admision a una escuela vocacional/tecnica, a un \"college\" o a una universidad a fin de continuar con su educacion mais ally de la escuela superior/secundaria? Becas y subsidios (\"scholarships\", \"fellowships\" y \"grants\") Han solicitado Ud. o su esposo(a)/compafiero(a) o su muchacho(a) fondos de alguno de los siguientes programas a fin de que les ayuden a pager la educacidn de su muchacho(a) cuando termine la escuela superior/secundaria? Becas y subsidios (\"scholarships\", \"fellowships\" y \"grants\") La siguiente es una lista de programas que otorgan prestamos pars continuar los estudios despues de la escuela superior/secundaria. Para cada programa, por favor indique hasta qui punto esta Ud. informado(a) sobre el mismo.  "}, {"section_title": "93.", "text": "Mientras llenaba este cuestionario, zlo/la ayudo alguien traduciendole algo, aclarindole el significado de las preguntas, o con informaci6n? (MARQUE UNA RESPUESTA) LCtuil es el nivel mss alto de educaciOn que cads uno de ustedes ha alcanzado? (Por favor marque con un circulo tinicamente el nivel Inds itho que Ud. y su esposo(a)/comparlero(a) han alcanzado). Ph.D., M.D., u otro titulo profesional 11 11 102. Nos gustaria saber el ntimero de hermanos y hermanas que tiene su muchacho(a). Por favor tome en cuenta a todos los hermanos, incluyendo los medio hermanos(as), hermanastros y hermanastras, y a los hermanos y hermanas adoptivos, sin importar donde vivan. Hoachlander, E.G. A Profile of Schools Attended by Eighth Graders in 1988, 1991NCES 91-129. As part of the National Education Longitudinal Study of 1988 (NELS:88), this study examined the schools attended by eighth-graders in 1988, the year during which the more than 25,000 eighth-graders of the cohort were first studied. NELS:88 provides information on 802 public schools, 105 Catholic schools, 68 other religious schools, and 60 private, non-religious schools. Throughout the report, the unit of analysis is the school rather than students or teachers. Most of the school data were provided by school administrators. The data are used to develop a profile of the schools attended by eighth-graders, with information about various aspects of the learning environment, school policies and programs, and administrators' assessments of school climate. In 1988, 87.9% of eighth-graders attended public schools, 7.6% attended Catholic schools, 2.9% attended other religious schools, and 1.5% attended private non-religious schools. The study shows that eighth-graders learned under a wide range of different conditions in both public and private schools. Sixty tables are presented, which examine the test achievement of a national probability sample of eighth graders in public and private schools. Statistics were obtained from the base-year student survey of the National Education Longitudinal Study of 1988 (NELS:88). Its purpose is to provide policy-relevant data concerning the effectiveness of schools, curriculum paths, special programs. variations in curriculum content, and/or mode of delivery in bringing about educational growth. The NELS:88 test battery includes four tests: (1) reading comprehension; (2) mathematics; (3) science; and (4) history/citizenship/government. This report is a tabular summary of achievement test scores for approximately 24,000 eighth graders from 1,052 schools. Results are grouped into: student background variables; parental involvement variables; and school characteristics and school climate. Reading and mathematics tables contain, in addition to mean scores, the percentage of each group scoring at each proficiency level and the standard error of the percentage estimate. Effect sizes are included to compare group differences. Technical notes on survey design, response rates, variables in the tables, significance testing, and methods for estimating standard errors and effect sizes follow the tables. (122 p.)."}, {"section_title": "9.", "text": "Horn, L., and Hafner, A. A Profile of American Eighth-Grade Mathematics and Science Instruction, 1992;NCES 92-486. This report profiles the mathematics and science instruction received by eighth graders (11,414 eighth graders had teacher reports in mathematics and 10,686 in science) in public and private schools in 1988. A preface lists highlighted findings, tables, and figures included in the document. The body of the report consists of five chapters. Chapter I discusses the purpose and format of the report and limitations of the study. Chapters II and III examine the relationship of various aspects of mathematics and science instruction to students' socioeconomic status and race-ethnicity and type of school attended. Among the aspects examined were the major topics taught, average class size, hours per week attended, allocation of class time, assigned homework, availability of instructional materials, student attitudes toward mathematics and science, and teacher characteristics and qualifications. Chapter IV examines mathematics and science achievement test scores in relation to the various components of instruction measured in the study. Chapter V provides a descriptive profile of the mathematics curriculum, the science curriculum, teacher characteristics and qualifications, classroom characteristics, school type differences, and students' opportunity to learn based on the findings. Appendices that describe the methodology employed and standard errors of estimates reported in tables and figures in the text are provided. (121 p.). 10. Horn, L., and West, J. A Profile of Parents of Eighth Graders, 1992;NCES 92-488. This report profiles the family characteristics and the level of involvement reported by the parents of 1988 eighth graders, using the base year survey and dropout data from the first follow-up. About 93 percent of the parents of the first year sample were interviewed to provide information about home life and family experiences. This study examined child-directed involvement, including activities such as parent-child discussions and school-directed involvement such as parent-teacher association membership and volunteering in the school. There was some indication that parent involvement was related to whether or not students scored below the basic level in reading or mathematics proficiency, but there was a strong relationship between parent involvement and whether or not a student dropped out of school between the 8th and 10th grades.  Green, P.J. High School Seniors Look to the Future, 1972Statistics in Brief series, NCES 93-473. In light of the many changes of the past 20 years, it may be expected that plans of high school seniors for further education may have also changed, along with the kinds of jobs they expect to have and the things they regard as important. These questions are examined through data from the National Longitudinal Study of 1972 (NLS-72) and the National Education Longitudinal Study in 1988 (NELS:88), the 1992 Second Follow-Up. The proportion of seniors in academic or college preparatory programs was approximately the same in both years, although enrollment in the general track increased and enrollment in vocational education decreased. In 1992, there was little difference between the sexes in high school program placement. In 1992, only 5.3 of students reported that they would not attend some kind of school after high school, but in 1972, 18.9% had reported that they would not continue. Eighty-four percent in 1992 planned to go to college, compared with the 63% who planned to attend in 1972. Differences for females were dramatic, with female seniors in 1992 four times more likely to plan on graduate or professional school as in 1972. Nearly 60% in 1992 planned a professional career, compared with approximately 45% in 1972. Changes in values were most marked among women, who in 1992 espoused values closer to those traditionally held by men. One figure and three tables present data about the two populations. (6 p.) 12. McMillen, M., Hausken, E., Kaufman, P., Ingels, S., Dowd, K., Frankel, M. and Qian, J. Dropping Out of School: 1982, Issue Brief series, 1993NCES 93-901. In recent years, concern over students dropping out of school has increased. A primary focus is the size of the dropout population, a question that has been addressed in two National Center for Education Statistics (NCES) longitudinal studies. Both studies provide the data needed to consider the dropout experiences between the sophomore and senior years of two groups of students a decade apart in time. Over the 10 years between the 1980-82 High School and Beyond survey (HS&B) and the 1990-92 data from the National Education Longitudinal Study of 1988 (NELS:88) (follow-ups), there was a 43 percent reduction in the percent of sophomores who dropped out of school. The NELS:88 rate for the sophomore cohort of 1990 is 6.2 percent. Relative rankings for racial and ethnic groups did not change over the decade, and in both cohorts the dropout rates for Hispanics were higher than those for Whites and Asians. Rates for Blacks were between those of Hispanic Americans and Whites. In both periods, failure in school and dislike for school were major factors leading students to drop out of school. Pregnancy and marriage were important factors influencing females' decisions to leave school early. Three figures illustrate the discussion. (3 p.) P-11 NELS:88 Second Follow-Up Final Methodology Report 13. Rasinski, K.A., Ingels, S.J., Rock, D.A., and Pollack, J. America's High School Sophomores: A Ten Year Comparison, 1980NCES 93-087. This study of high school sophomores in 1980 and 1990 compares the experiences of students in the two cohorts, identifying changes in in-school and out-of-school activities, academic achievement, self-concept, values, plans, and aspirations. Similarities and differences between the two groups are documented using data from the National Education Longitudinal Study of 1988 (NELS:88) and High School and Beyond (HS&B, 1980). HS&B and NELS:88 sophomores are marked by basic demographic differences, including the smaller size of the NELS:88 1990 cohort, reflecting the baby bust of the 1970s, and a higher proportion of racial minority and poverty status sophomores in 1990. NELS:88 sophomores also reflect the influence of various waves of school reform since the late 1970s and early 1980s. Overall, the comparison paints a pictures that is in most respects encouraging in its portrayal of the high school academic orientation and postsecondary expectations of the 1990 sophomore class. Positive changes, however, are typically small or moderate in magnitude. Among the findings are: (1) general and college preparatory program placement has increased, at the expense of vocational program placement; (2) patterns of extracurricular participation changed especially in musical activities (31% in 1980 to 22% in 1990) and in hobby clubs (21% in 1980 to 7% in 1990); (3) changes in sophomores giving high importance to particular life values (e.g., marriage and family 83% rating this as very important in 1980, 72% in 1990); (4) small but statistically significant increase in the number of females aspiring to traditionally male-dominated non-professional occupations (15.6% in 1980 versus 18.% in 1990). Sixteen tables and 13 figures present data from the 2 studies. Three appendixes contain information about the survey sample sizes, standard errors, and other methodological and technical information. Appendix A contains an additional 20 data tables. (Contains 46 references; xiv, 98 p.) 14. Rock, D.A., Owings, J.A., and Lee, R. Changes in Math Proficiency Between Eighth and Tenth Grades. 1994;NCES 93-455. This report in the NCES Statistics in Brief series illustrates use of the NELS:88 dichotomous proficiency scores for conducting achievement gain analysis (see Scott,Rock,Pollack and Ingels [entry 21] for an illustration of an alternative gain analysis strategy, the use of continuous probability of mathematics proficiency scores). The findings presented in this report suggest that course-taking patterns in mathematics between eighth grade and the sophomore year of high school represent an important factor in explaining growth in math proficiency. For example, even after controlling for eighth-grade math proficiency, higher math gains were associated with course-taking patterns that reflected advanced level math courses. The report also suggests that eighth-grade students who have higher aspirations for postsecondary education are also more likely to show positive math gains. (20 p.) P-12"}, {"section_title": "X23", "text": "NELS:88 Second Follow-Up Final Methodology Report 15. Finn, J.D. School Engagement and Students At Risk, 1993;NCES 93-470. To examine the proposition that students who do not remain active participants in class or school may be at risk for school failure, regardless of status characteristics such as ethnicity or family income, two studies of engagement and achievement were conducted. The studies used a nationwide sample of eighth-grade students from the U.S. Department of Education's National Educational Longitudinal Study of 1988 (NELS:88) survey. The first study examined the association of participation in school and classroom activities with academic achievement in 15,737 eighth-graders attending public schools. The study found that participation and academic achievement were positively related, even after controlling for gender, ethnicity, and socioeconomic status. The second study examined behaviors that distinguish students who are at risk, but who are successful in school subjects, from their less successful peers. A sample of 5,945 eighth-graders identified as at risk by virtue of race, home language or socioeconomic status were classified as unsuccessful, passing, or successful, based on reading and mathematics achievement tests. It was found that achievement groups were distinct in terms of variety of classroom participation behaviors, out-of-class participation, and interactions with their parents regarding school. Three major conclusions were drawn from the investigation: (1) behavioral risk factors are indeed related to significant outcomes of schooling; (2) risk behaviors have their roots in the early school years or before; and (3) more attention should be given by educators and researchers to encouraging the potential of \"marginal\" students. Further research is needed to identify manipulable aspects of classroom and school processes that encourage student engagement. Appendices provide details of the measures used in the studies and the standard deviations and correlations of the measures. Contains 91 references. (117p.). This analysis of the effects of vocational education on academic achievement and high school persistence was prepared for the National Assessment of Vocational Education. Data from the NELS:88 high school transcript study were analyzed to assess the influence of vocational programs and vocational courses on gains in tested achievement in mathematics, science and reading. The analysis also addresses the issue of whether, regardless of their effect on achievement gain, vocational programs serve to keep students from dropping out of high school."}, {"section_title": "P-13", "text": "NELS:88 Second Follow-Up Final Methodology Report 17. Ingels, S.J., Schneider, B., Scott, L.A., andPlank, S.B. A Profile of the American High School Sophomore in 1990, 1994;NCES 95-086. This cross-sectional statistical analysis report supplies descriptive analyses of the educational situation of a representative sample of the nation's 1990 sophomores (comprising 1988 eighth-grade cohort members who were in tenth grade in the spring term of 1990 and \"freshened\" sophomores, students new to the sample who were not in the base year sampling frame, either because they were not 1987-88 eighth graders or not in the United States). Chapter 1 provides an in-depth view of tenth-grade learning and achievement in mathematics. Chapter 2 supplies a summary of tenth-grade course-taking patterns and instructional practices in science, reading, social studies, and foreign language. Chapter 3 explores the tenth grader's life outside of school, including the process of educational decision making. Chapter 4 reports on sophomores' plans for the future, including their educational expectations and aspirations. Taken together, these four chapters provide a statistical profile of the American high school sophomore in 1990, which is summarized in Chapter 5. Appendices A and B provide technical notes and tables of standard errors of measurement and sample sizes for all reported population estimates. Appendix C contains further information about NELS:88 in general and the first follow-up in particular. Appendix D presents additional tabulations on reading and social studies achievement. 18. Myers, D., and Heiser, N. Students' School Transition Patterns between Eighth and Tenth Grades Based on NELS:88, 1994;NCES 94-137. Analysis of NELS:88 data makes it possible to explore the relationships between student and family characteristics and the likelihood of shifting among public and private schools as students progress from eighth to tenth grade. This study examines the characteristics of students who switch between sectors (public to private, or private to public) as they move from eighth to tenth grade. Five sets of variables were examined to estimate the association between variations in the students' transition patterns and student and family characteristics: (1) basic student and family background characteristics; (2) the amount of parental involvement in the student's education; (3) the student's academic achievement and educational expectations; (4) the characteristics of the student's school; and (5) parental satisfaction with the student's school. Examination of these characteristics permits four research questions to be addressed: (1) How many students shift between the public and private school sectors? How many students shift from one private school to another?; (2) Who shifts between sectors? Are family background factors, parental involvement, or students' academic achievement or educational expectations associated with variations in transition patterns?: (3) Are school characteristics associated with students' propensity to move between school sectors?: (4) Do parents who are dissatisfied with their children's school shift their children to another type of school? P-14 NELS:88 Second Follow-Up Final Methodology Report 19. Green, P.J., Dugoni, B.L., Ingels, S.J., andCamburn, E. A Profile of the American High School Senior in 1992, NCES, 1995;NCES 94-384. This statistical analysis report examines the background of 1992 high school seniors, the school environment which shaped their senior year experiences, the curriculum in which they were enrolled, their academic achievement, their plans and expectations for the future, and their non-academic experiences during this important period of development. Chapter 1 provides a demographic profile of high school seniors. Chapter 2 depicts their school and peer environment by recording seniors' perceptions of school, of the safety of their school, and of the values of their peers. Chapter 3 describes their course and program enrollments. Chapter 4 examines the tested achievement of 1992 seniors. Chapter 5 describes their shortterm plans--their postsecondary plans, steps they have taken to gain entrance to college, and factors they considered in choosing a postsecondary institution. Chapter 6 reports on seniors' plans and expectations for the future. Finally, chapter 7 describes the senior cohort's experiences outside of school--use of illicit drugs and alcohol, television viewing, jobs, participation in school government, and community volunteer work. Taken together, these seven chapters provide a statistical profile of the American high school senior in 1992. Appendices provide unweighted (sample) Ns and standard errors. 20. Scott, L.A., Rock, D.A., Pollack, J.M., and Ingels, S.J. Two Years Later: Cognitive Gains and School Transilions of NELS:88 Eighth Graders, 1995;NCES 94-436. This statistical analysis report describes the growth in cognitive skills and achievement, and the continuities and discontinuities experienced in school and at home by the NELS:88 eighth grade-cohort during the two years between the study's base year (1988) and first follow-up (1990) surveys. Four distinct topics are addressed, involving both school dropouts and persisters. (1) By 1990, some 1988 eighth graders were dropouts; this report describes their characteristics and the reasons they gave for dropping out of school. (2) This report presents findings on patterns of school transition--changing from a public eighth-grade school to a private high school or vice versa--and the changes in perception of safety and overall learning environment cohort members experienced after moving from a typically more homogeneous middle school environment to a more heterogeneous high school environment. 3Additionally, this report summarizes major changes in home life and family, such as the divorce or remarriage of a parent, that also occurred during cohort members' transition to and/or early years of high school. (4) Finally, this report examines the 1988-90 achievement gain of the eighth-grade cohort, thus addressing several basic questions: How much did students gain in achievement in the two years following eighth grade?; Who gained, in what subjects, and (for mathematics) where or in what way (that is, at what skill or proficiency level)? The qualitative analysis of growth in mathematics achievement illustrates use of the NELS:88 continuous measure of probability of proficiency (see Rock, Owings and Lee [1994, entry 15] for an illustration of gain score analysis using NELS:88 dichotomous mathematics proficiency scores)."}, {"section_title": "P-I5", "text": "5 g 6 NELS:88 Second Follow-Up Final Methodology Report 21. Green, P.J., Dugoni, B.L., and Ingels, S.J. Trends Among High School Seniors, 1972. NCES, 1995NCES 94-380. This statistical analysis report compares the NLS-72 1972, HS&B 1980, and NELS:88 1992 senior cohorts. It supplies a sociodemographic description of the three senior cohorts. The report compares the cohorts' high school program placement, course-taking and achievement, as well as participation in extracurricular activities. It also compares 1972, 1980 and 1992 seniors' plans for the next year, noting the proportions who planned to work full-time in the year following graduation, the type of postsecondary institution seniors planned to attend, college selection, and major field of study. Finally, the report compares the future educational and occupational aspirations of the three senior cohorts. 22. Green, P.J., and Scott, L.A. \"At-Risk\" Eighth Graders Four Years Later, NCES, 1995;NCES 95-736. This publication in the NCES Statistics in Brief series extends to the 1992 second follow-up the analysis of \"at risk\" factors begun by  with the base year data and continued by Scott, Rock, Pollack and Ingels (1995) with the first follow-up data. Approximately 26 percent of eighth grade students had an \"at risk\" characteristic and 20 percent had two or more of these risk factors. Examining the outcomes of at-risk eighth graders four years later (1992), Green and Scott examine both achievement outcomes and social and behavioral outcomes. With respect to achievement, Green and Scott report that (1) approximately one in six adolescents with multiple risk factors were unable to comprehend basic written information, testing below the basic level in reading in 1992. In comparison, only about one in twenty of those with no risk factors were unable to demonstrate basic reading skills. (2) At-risk students were more likely than others in 1992 to test poorly in mathematics. Over half of those with multiple risk factors tested at the basic level, or below, In contrast, only about a fifth of those with no observed risk factors tested at that level. (3) Nearly one-third of students with multiple risk factors could not demonstrate even a \"common knowledge\" of science. Only 12.2 of students with no risk factors failed to demonstrate competence at this basic level. In respect of 1992 social and behavioral outcomes, and 1992 graduation status, Green and Scott report (1) Students who had multiple risk factors in 1992 were no more likely than others to report using illicit drugs (marijuana or alcohol), or to report abusing alcohol than those with no risk factors. (2) Eighth graders who had multiple risk factors in 1988 were more likely than others to have a child in 1992--18.9 percent compared to 5.4 percent. (3) Students with multiple risk factors were more likely than others to report being suspended, and being sent to a juvenile home or detention center.  23. Rock, D.A., and Pollack, J.M. Mathematics Course Taking and Gains in Mathematics Achievement. NCES, 1995;NCES 95-714. This publication in the NCES Statistics in Brief series extends to the 1992 second follow-up the analysis of 1988-1990 test score gains reported in Scott, Rock, Pollack and Ingels (1995). However, instead of self-report data on courses completed, Rock and Pollack utilize the results of the NELS:88 high school transcript study. Rock and Pollack found that when student gains in tested mathematics achievement were cross-classified by grade in school and highest level of mathematics course taken: Slightly over 60 percent of high school students do not go beyond the algebra 2/geometry level of coursework. Approximately 1 out of 9 students take a calculus course while in high school; about 1 out of 4 students, in contrast, never go past algebra in their high school career. Growth in arithmetic, algebra, and geometry achievement appears to be greater in the first two years of high school than in the last two years for almost all course-taking categories. Students who take the more advanced mathematics courses show greater gains, both between 8th and 10th grade, and between 10th and 12th grade. Students who do not take advanced courses make greater gains on test items dealing with computational skills, while students in the advanced courses make larger gains on test items requiring conceptual understanding and problem-solving skills. In fact, for these students, significant growth does not occur until they move into the pre-calculus level of coursework. 24. Hoffer, T.B., Rasinski, K.A., and Moore, W. Social Background Differences in High School Mathematics and Science Coursetaking and Achievement. NCES, 1995;NCES 95-206. This publication in the NCES Statistics in Brief series uses NELS:88 test and transcript data to address two questions: (a) To what extent do students from different social backgrounds differ in the numbers of courses they complete during high school and in their final levels of academic achievement? And (b) Does additional coursework have comparable relationships to measured achievement gains during the high school years for students from different backgrounds. Hoffer, Rasinski and Moore report the following findings: (1) Gender differences in the numbers of science and mathematics courses students complete are not significant. Students from higher socioeconomic families, however, complete more courses in these subjects. (2) The numbers of math and science courses students complete in high school are strongly related to how much their test scores increase from the end of eighth grade to the end of senior year. (3) Additional coursework pays off about equally for all students in terms of increasing achievement gain, regardless of gender, race-ethnicity, and social class. This issue brief uses NELS:88 1992 senior data to examine what proportion of graduates who meet the entrance criteria of highly selective colleges. The authors found that only 5.9 percent of college-bound seniors met the highly selective criteria that included: (a) a high school GPA of 3.5 or higher; (2) a score of 1100 or higher on the SAT; (3) a course-taking pattern that included four English credits, three mathematics credits, three science credits, three social studies credits, and two foreign language credits; (4) positive teacher comments regarding student; and (5) participation in two or more school-related extracurricular activities. After lowering the cutpoints on SAT scores (950), GPA (3.0), English credits (three), social studies (two), and foreign language credits (less than two), the percentage meeting the lower requirements increased the proportion making the reduced cut to 19.5 percent. Alternative completer: The NELS:88 second follow-up distinguished three levels of enrollment status: students enrolled in a regular high school program, dropouts who had enrolled in (or had completed) some alternative (non-diploma) high school equivalency accrediting program (for example, preparation classes for the GED test), and dropouts receiving no alternative instruction. The term \"alternative completer\" was used for dropouts receiving any sort of instruction to prepare them for equivalency certification, and for dropouts who had already received the GED or other equivalency certification. In terms of questionnaire completion, alternative completers were treated in two ways. Dropouts receiving alternative instruction in preparation for possible equivalency certification were administered the dropout questionnaire. Those dropouts who had received the GED or other high school equivalency certification were treated as school completers, and were administered the student questionnaire. Augmentation students: See State augmentation students. Base year ineligible (BYI) study: A NELS:88 First Follow-Up study which sought to locate and survey eligible respondents who were part of the Base Year sample, yet were ineligible to participate in the Base Year due to mental or physical incapacity, language barrier, or other factors. (See entry for \"Followback study of excluded students.\") Bayesian statistics: Bayesian methods incorporate the prior probability distribution with the new evidence collected, as was done in resealing NELS:88 1988 to 1992 test results when the 1992 test data became available. Bias is the difference between the reported value and the true value. Thus the bias of an estimate is the difference between the expected value of a sample estimate and the corresponding true value for the population. Response bias is the difference between respondent reports and their behavior or characteristics. Nonresponse bias is the difference that occurs when respondents differ as a group from nonrespondents on a characteristic being studied. Sample bias is the unequal selection or the omission of members of the population, without appropriate weighting. Related ly, undercoverage bias arises because some portion of the potential sampling frame is missed or excluded, or there are duplicate units. For example, if the school list from which a school sample is drawn is incomplete or inaccurate, school undercoverage may occur. The NELS:88 documentation speaks of excluded students (base year ineligibles) as a coverage problem or as a source of undercoverage bias. This usage is predicated on the premise that the target population was misspecified; the categories of students who were declared ineligible for the study should only, at most, have been excluded from achievement testing. Burden: Formally, this is the aggregate hours realistically required for data providers to participate in a data collection. Burden also has a subjective or psychological dimension: the degree to which providing information is regarded as onerous may depend on the salience to the respondent of the questions that are being posed and on other factors such as competing time demands. BY: NELS:88 Base Year Study conducted in 1988. Carnegie units: A standard of measurement used for secondary education that represents the completion of a course that meets one period per day for one year. Ceiling effect: The result of a cognitive test having insufficient numbers of the more difficult items. In a longitudinal study, ceiling effects in the follow-up testings can cause change scores to be artificially constrained for high ability examinees. More information (that is, smaller error of measurement) is obtained with respect to ability level if high ability individuals receive relatively harder items (and if low ability individuals receive proportionately easier items). The matching of item difficulty to a person's ability level yields increased reliability at the extremes of the score distribution where it is most needed for studies of longitudinal change. That is, the measurement problems related to floor and ceiling effects in combination with regression effects found at the extreme score ranges seriously hamper the accuracy of change measures in longitudinal studies. Hence one strategy employed in NELS:88 to minimize ceiling effects was to develop test forms that are \"adaptive\" to the ability level of the examinee. The multilevel tests used in the first and second follow-ups of NELS:88--with test assignment based on prior test performance--work to minimize the possibility of ceiling effects biasing the estimates of the score gains. (See entry for \"Floor effect.\") Certainty school: A first or second follow-up school attended by four or more NELS:88 sample members, as determined by tracing and data collection efforts. These schools are included in the sample with certainty (probability = 1). All NELS:88 first follow-up sample members in the school at the time of data collection were included in the second follow-up. Closed-ended: A type of question in which the data provider's responses are limited to given alternatives (as opposed to an open-ended question. See entry for \"Open-ended.\") Clustering: A sample selection method in which small geographical areas such as schools (e.g. in NELS:88), school districts, counties, or blocks are selected as an initial stage, with individuals selected in a subsequent step. See entry for \"Primary Sampling Unit\". Cluster size: The number of NELS:88 sample members attending a particular high school. Codebook: A record of each variable being measured, including variable name, columns occupied by each variable in the data matrix, values used to define each variable, unweighted frequencies, unweighted percents, and weighted valid percents. (See entry for \"electronic codebook.\") Cognitive test battery: One of the two parts of the Student Survey (the second part being the student questionnaire). Four achievement areas (mathematics, reading, science, and social studies [history/ citizenship/geography]) were measured. Cohort: A group of individuals who have a statistical factor in common, for example, year of birth or grade in school or year of high school graduation. NELS:88 embraces three overlapping but distinct nationally-representative grade cohorts: 1987-88 eighth graders, 1989-90 high school sophomores, and 1991-92 high school seniors. Composite variables: A composite variable is one that is constructed through either the combination of two or more variables (socioeconomic status, for example) or calculated through the application of a mathematical function to a variable. Also called a \"derived variable\" or \"constructed variable.\" Confidence interval: A sample-based estimate expressed as an interval or range of values within which the true population value is expected to be located (with a specified degree of confidence). Contextual data: In NELS:88, the primary unit of analysis is the student (or dropout), and information from the other study components, referred to as the contextual data, should be viewed as extensions of the student data--for example, as school administrator, teacher, and parent reports on the student's school learning environment or home situation. Core school: School that was selected between Phases 1 and 2 of the Second Follow-Up to receive the full complement (School Administrator, Teacher, Transcript) of study components, and for in-school data collection sessions. Core student: Students who are part of the primary cohort of NELS:88, in contrast to state augmentation or School Effectiveness Study students. The core students include those chosen as eighth graders in the 1988 Base Year Study and those added to the sample through freshening procedures during the First or Second Follow-Up. Core study: The original NELS:88 study, in contrast to the study with additions and follow-up additions like the state augmentation studies and the School Effectiveness Study. Course offerings: School-level summaries of courses offered and of course enrollment levels; while in HS&B course offerings data were collected for all schools, in NELS:88 such data have been collected only for schools in the High School Effectiveness Study. Cross-sectional survey: A cross-sectional design represents events and statuses at a single point in time. For example, a cross-sectional survey may measure the cumulative educational attainment (achievements, attitudes, statuses) of students at a particular stage of schooling (for example, eighth grade, tenth grade, or twelfth grade). In contrast, a longitudinal (or repeated measurement of the same sample units) survey measures the change or growth in educational attainments that occurs over a particular period of schooling. The longitudinal design of NELS:88 generates--by means of sample \"freshening\"three representative cross-sections (eighth graders in 1988, high school sophomores in 1990, seniors in 1992) and permits analysis of individual level change over time through longitudinal analysis and of group level and intercohort change through the cross-sectional comparisons. (See entry for \"Longitudinal or Panel Survey.\") Data element: The most basic unit of information. In data processing it is the fundamental data structure. It is defined by its size (in characters) and data type (e.g. alphanumeric, numeric only, true/false, date) and may include a specific set of values or range of values. Design effect: A measure of sample efficiency. The design effect (DEFF) is the variance of an estimate divided by the variance of the estimate that would have occurred if a sample of the same size had been selected using simple random sampling. Sometimes it is more useful to work with standard errors than with variances. The root design effect (DEFT) expresses the relation between the actual standard error of an estimate and the standard error of the corresponding estimates from a simple random sample."}, {"section_title": "534", "text": "Q-3 NELS:88 Second Follow-Up Final Methodology Report Dropout: The term is used both to describe an eventleaving school before graduating--and a status --an individual who is not in school and is not a graduate at a defined point in time. The \"cohort dropout rate\" in NELS:88 is based on measurement of enrollment status of 1988 eighth graders two and four years later (that is, in the spring term of 1990 and the spring term of 1992) and of 1990 sophomores two years later. A respondent who has not graduated from high school or attained an equivalency certificate and who has not attended high school for 20 consecutive days (not counting any excused absences) is considered to be a dropout. In contrast, transferring schools--for example, from a public to a private schoolis not regarded as a dropout event, nor is delayed graduation (as when a student is continuously enrolled but takes an additional year to complete school). A person who drops out of school may later return and graduate: at the time the person left school initially, he or she is called a \"dropout,\" and at the time the person returns to school, he or she is called a \"stopout.\" Early graduate: A student who graduated from high school in less than the typical amount of time. For example, if a student graduated in December of his/her senior year (when the majority of his/her classmates graduate the following May or June), the student is categorized as an early graduate. In the main study data collection, early graduates were administered a special supplement in the student questionnaire along with the cognitive test battery. Electronic codebook (ECB): While hardcopy codebooks with item stems, response categories, associated response frequency distributions, unweighted percents, and weighted valid percents are contained within the NELS:88 user's manuals, NELS:88 data are also available on CD-ROM in an electronic codebook (ECB) format. Electronic codebooks are menu-driven systems that allows users to perform functions such as the following: (a) search a list of database variables based upon key words or variable names/labels; (b) display weighted and unweighted percentages for each variable in the database; (c) display question text for each variable in the database; (d) select or tag variables for subsequent analysis; (e) generate SAS-PC or SPSS-PC + program code/command statements for subsequently constructing a system file of the selected variables; and (f) generate a codebook of the selected variables. An electronic codebook has been prepared for public and privileged use NELS:88 base year through second follow-up data. ETS: Educational Testing Service. NORC's subcontractor for NELS:88 cognitive test development and evaluation. Expanded Sample: the combined sample of eligible and ineligible NELS:88 sample members, including eighth graders who were excluded from the survey. This sample can be used to make unbiased estimates of national dropout rates. Fl: The NELS:88 first follow-up, conducted in 1990. F2: The NELS:88 second follow-up, conducted in 1992. File: Refers to a data file containing a set of related computerized records. Floor effect: The result of a cognitive test being too difficult for a large number of the examinees, causing the low ability examinees to receive chance scores on the first testing, and on subsequent testings if the test remains too difficult. Floor effects result in an inability to discriminate among low ability individuals at time one or time two, and there will be no reliable discrimination among examinees with respect to amounts of change. A possible solution, utilized in NELS:88, is to develop test forms that are \"adaptive\" to the ability level of the examinee, which tends to minimize the possibility of floor effects biasing the estimates of the score gains. Followback study of excluded students: A continuation in the NELS:88 second follow-up of a special substudy begun in the first follow-up as (see entry for) the base year ineligibles study. Freshening: A NELS:88 sampling procedure by which high school sophomores were added in the first follow-up who were not in the eighth grade in the U.S. two years before. This process was repeated in the second follow-up, adding high school seniors who were not in the eighth grade in the U.S. four years before, and not in the tenth grade in the U.S. two years before. This process ensured that the sample would be representative of the 1992 senior class by allowing 1992 seniors who did not have a chance for selection into the base year (or the first follow-up) sample to have some probability of 1992 selection. GED recipient: A person who has obtained certification of high school equivalency by meeting state requirements and passing an approved exam, which is intended to provide an appraisal of the person's achievement or performance in the broad subject matter areas usually required for high school graduation. (See entry for \"GED test\" and \"Alternative completer.\") GED test: General Educational Development test. A test administered by the American Council on Education as the basis for awarding a high school equivalent certification. HS&B: High School and Beyond. The second in the series of longitudinal education studies sponsored by NCES. The HS&B Base Year study surveyed sophomore and senior students in 1980. IEP: Individualized Education Program in special education for students with a mental or physical disability. IRT: Item Response Theory. A method of estimating achievement level by considering the pattern of right, wrong, and omitted responses on all items administered to an individual student. Rather than merely counting right and wrong responses, the IRT procedure also considers characteristics of each of the test items, such as their difficulty, and the likelihood that they could be guessed correctly by low-ability individuals. IRT scores are less likely than simple number-right or formula scores to be distorted by correct guesses on difficult items if a student's response vector also contains incorrect answers to easier questions. Another attribute of IRT that makes it useful for NELS:88 is the calibration of item parameters for all items administered to all students. This makes it possible to obtain scores on the same scale for students who took harder or easier forms of the test. IRT also permits vertical scaling of the three grade levels (grade 8 in 1988, grade 10 in 1990, grade 12 in 1992). Item nonresponse: The amount of missing information when a valid response to an item or variable was expected. (See entry for \"Unit-nonresponse.\") LEP: Limited English Proficient. A concept developed to assist in identifying those language-minority students (individuals from non-English language backgrounds) who need language assistance services, in their own language or in English, in the schools. (See entries for \"NEP\" and \"LM.\") The Bilingual ) the student comes from an environment where a language other than English is dominant; or c) the student is American Indian or Alaskan Native and comes from an environment where a language other than English has had a significant impact on his/her level of English language proficiency; and 2) has sufficient difficulty speaking, reading, writing, or understanding the English language to deny him or her the opportunity to learn successfully in English-only classrooms. LM: Language Minority. A non, limited or fully English proficient student in whose home a non-English language is typically spoken. Longitudinal or panel survey: In a longitudinal design, similar measurementsof the same sample of individuals, institutions, households or of some other defined unit--are taken at multiple time points. NELS:88 employs a longitudinal design that follows the same individuals over time, and permits the analysis of individual-level change. (See entry for \"Cross-sectional survey.\") Machine editing: Also called forced data cleaning or logical editing. Uses computerized instructions in the data cleaning program that ensure common sense consistency within and across the responses from a data provider. Microdata (microrecords): Observations of individual sample members, such as those contained on the NELS:88 data files. MSA: Metropolitan statistical area. A large population nucleus and the nearby communities which have a high degree of economic and social integration with that nucleus. Each MSA consists of one or more entire counties (or county equivalents) that meet specified standards pertaining to population, commuting ties, and metropolitan character. (However, in New England, towns and cities, rather than counties, are the basic units.) MSAs are designated by the Office of Management and Budget (OMB). An MSA includes a city and, generally, its entire urban area and the remainder of the county or counties in which the urban area is located. A MSA also includes such additional outlying counties which meet specified criteria relating to metropolitan character and level of community of workers into the central city or counties. Multidimensional raking: An adjustment procedure in weighting whereby the sum of the weights for each marginal category of respondents in the follow-up rounds of NELS:88 was made equal to the corresponding sum of the final prior round weights for that group. NAEP: The National Assessment of Educational Progress."}, {"section_title": "NAIS:", "text": "The National Association of Independent Schools. This organization endorsed NELS:88. NAIS schools form a base year school sampling stratum in NELS:88, and NAIS constitutes a category within the restricted use file school control type variable. NCEA: The National Catholic Educational Association. This organization endorsed NELS:88. The study has collected data in 1988, 1990, and 1992 on student's school experiences, as well as background information from school administrators, teachers and parents (in the base year and second follow-up only). The study seeks to learn about students' educational experiences and outcomes from eighth grade through high school and beyond. NEP: No English Proficiency. A student who does not speak English. (See entry for \"LEP.\") New Basics: In its report A Nation At Risk: The Imperative for Educational Reform (1983), the National Commission on Excellence in Education recommended that all high school students \"be required to lay the foundations in the Five New Basics by taking the following curriculum during their four years of high school: (i) 4 years of English; (ii) 3 years of mathematics; (iii) 3 years of science; (iv) 3 years of social studies; and (v) one-half year of computer science.\" A more stringent version of the New Basics was offered by Secretary of Education William Bennett in 1988 (American Education, Making It Work: A Report to the President and the American People), comprising the scheme above, plus a minimum of two years of foreign language. Summary composite variables, reflecting various interpretations of the New Basics, were created for the HS&B and NAEP high school transcript studies; the NELS:88 transcript study provides both HS&B and NAEP equivalent New Basics variables. NLS-72: The National Longitudinal Study of the High School Class of 1972. This project was the first in the series of longitudinal education studies sponsored by NCES. Noncertainty schools: Schools in which fewer than four (three, two or one) NELS:88 students attended. These schools were not subsampled for participation in the School Administrator, Teacher, and Transcript components. Additionally, the survey instruments were not administered in group sessions in the schools, as was done in the certainty schools. Nonresponse: (See entry for \"Item nonresponse\" and \"Unit nonresponse.\") Nonsampling error: An error in sample estimates that cannot be attributed to sampling fluctuations. Such errors may arise from many sources including imperfect implementation of sampling procedures, differential unit or item nonresponse across subgroups, bias in estimation, or errors in observation and recording. NORC: The National Opinion Research Center at The University of Chicago. NORC conducts NELS:88 for the National Center for Education Statistics. NSF: The National Science Foundation, which is one of the sponsors of NELS:88. NSF sponsored several components of NELS:88: 1) additions to the student questionnaire to learn about students' experiences and their exposure to mathematics and science curricula; 2) a survey of mathematics and science teachers to obtain evaluations of their NELS:88 student(s) and to learn about their classroom practices and background preparation for teaching; (3) a base year study of the postsecondary education transcripts of NELS:88 math and science teachers; (4) use of experimental constructed response format math and science achievement test items in the 1992 High School Effectiveness Study schools; and (5) a Q-7 NELS:88 Second Follow -Up Final Methodology Report validity study in a small subset of NELS:88 second follow-up high schools centering on teacher reports of instructional content, strategies and goals. OBEMLA: The Office of Bilingual Education and Minority Languages Affairs, U.S. Department of Education. OBEMLA funded a NELS:88 supplement that inquired into the education experiences of students whose native language is other than English. OMB: The Office of Management and Budget, U.S. Executive Branch. OMB is a federal agency with the responsibility for reviewing all studies funded by executive branch agencies. OMB reviewed, commented on, and approved the NELS:88 questionnaires, as indicated by their approval number and its expiration date in the top right corner of the questionnaire covers. Open-ended: A type of question in which the data provider's responses are not limited to given alternatives. Optical disc: A disc that is read optically (e.g., by laser technology), rather than magnetically. (See entry for \"CD-ROM.\") Optical scanning: A system of recording responses that transfers responses into machine-readable data through optical mark reading. This method of data capture was used for the NELS:88 student questionnaires and cognitive tests, as well as for the parent and teacher questionnaires. (In contrast, responses to certain other questionnaires, such as the school administrator questionnaire, were keyed by using conventional data entry methods.) Out-of-sequence: This term means that a student is not in the grade that he/she would be in if progressing with the majority of the cohort through school. For example, most NELS:88 sample members were in the tenth grade in the 1989-90 school year; one would be described as out-of-sequence if found to be in the eleventh grade in the 1989-90 school year. Parent, NELS-targeted parent/guardian: The NELS:88 Parent Component sought to collect information from parents of eligible student/dropout respondents. It was asked that the parent or guardian who knew most about his or her child's educational experience complete the questionnaire. PIN: Personal Identification Number. A unique number assigned to each district and school. Population: All individuals in the group to which conclusions from a data collection activity are to be applied. Weighted results of NELS:88 data provide estimates for populations and subgroups. Population variance: A measure of dispersion defined as the average of the squared deviations between the observed values of the elements of a population or sample and the population mean of those values. Postsecondary education: The provision of formal instructional programs with a curriculum designed primarily for students who have completed the requirements for a high school diploma or equivalent. This includes programs of an academic, vocational, and continuing professional education purpose, and excludes avocational and adult basic education programs. Poststratification adjustment: A weight adjustment that forces survey estimates to match independent population totals within selected poststrata (adjustment cells). Q-8"}, {"section_title": "539", "text": "NELS:88 Second Follow-Up Final Methodology Report Precision: The difference between a sample-based estimate and its expected value. Precision is measured by the sampling error (or standard error) of an estimate. Primary Sampling Unit (PSU): Unit chosen at the first stage of a cluster sample. In NELS:88, the PSU is the school; in other studies, geographical units such as a county or MSA may serve as the PSU. Probability sample: A sample selected by a method such that each unit has a fixed and determined probability of selection --i.e., each population unit has a known, nonzero chance of being included. QED: Quality Education Data. QED is a commercial firm that publishes national directories of all public and private schools and districts. Its list of schools in the U.S. constituted the sampling frame for the base year, and provided important information on school location, principal's name, minority enrollment, and other characteristics. Range check: A determination of whether responses fall within a predetermined set of acceptable values. Record format: The layout of the information contained in a data record (includes the name, type. and size of each field in the record). Records: A logical grouping of data elements within a file upon which a computer program acts. Reliability: The consistency in results of a test or measurement including the tendency of the test or measurement to produce the same results when applied twice to some entity or attribute believed not to have changed in the interval between measurements. Sample: Subgroup selected from the entire population. Sampling error: The part of the difference between a value for an entire population and an estimate of that value derived from a probability sample that results from observing only a sample of values. Sampling variance: A measure of dispersion of values of a statistic that would occur if the survey were repeated a large number of times using the same sample design, instrument and data collection methodology. The square root of the sampling variance is the standard error. School administrator questionnaire: This questionnaire was to be completed by the principal and/or someone designated by the principal. The questionnaire sought basic information about school policies, number of students in each class, curriculum offered, programs for disadvantaged and disabled students, and other school characteristics. School climate: The social system and culture of the school, including the organizational structure of the school and values and expectations within it. School Coordinator: A person designated in each school to act as a contact person between the school ,'nd NORC. This person assisted with establishing a survey day in the school, and in some cases where the school cluster size was very small, the School Coordinator administered the student instruments. High School Effectiveness Study (HSES): The NELS:88 High School Effectiveness Study (HSES) is a special component of NELS:88 that was designed to estimate school-level characteristics. HSES consists Q-9"}, {"section_title": "540", "text": "NELS:88 Second Follow-Up Final Methodology Report of a sample of 247 urban and suburban tenth grade schools in the 30 largest metropolitan statistical areas (MSAs). For comparison purposes, HSES used eight basic strata defined on the basis of four types of schools (Public, Catholic, NAIS, and Other Private) at two levels of urbanicity (Urban, Suburban). HSES substantially increased cluster sizes and provided in-school representative student samples; selection probabilities were simulated for the schools so that school weights could be generated. This component was continued in the second follow-up, and included student, school administrator, teacher, and parent questionnaires, transcript and course offerings surveys. Standard deviation: The most widely used measure of dispersion of a frequency distribution. It is equal to the positive square root of the population variance. Standard error: The positive square root of the sampling variance. It is a measure of the dispersion of the sampling distribution of a statistic. Standard errors are used to establish confidence intervals for the statistics being analyzed. State augmentation students: In the base year, certain states funded a sample of additional schools in the state to produce a representative sample of schools in the state. In this sense, the state's sample was \"augmented\" to maximize the utility of the NELS:88 data for those states. The students from those base year schools were designated as \"augmentation\" students, and were followed and surveyed in the first follow-up, though the students had dispersed to many tenth-grade schools. In the second follow-up these students were surveyed again. Statistical Significance: The finding. (based on a derived probability, rather than an certitude) that two or more estimates are truly different from one, and not a merely apparent difference reflecting chance variation. Stopout: A student who had one or more occurrences of school non-attendance for 20 or more days (not including any excused absences) who subsequently returned to school. In NELS:88, this term was used for temporary dropouts within a round (e.g., out of school in fall 1989 but back spring 1990, as contrasted to 1990 dropouts who were back in school in spring term of 1992). Stratification: In a stratified sample, the total population is divided into strata or subgroups. Stratification is used to reduce sampling error. In NELS:88, the sampling frame was sorted to create strata or subgroups of schools and schools were selected independently within each stratum. Schools were stratified by superstrata (combinations of school type and geographic reason) and substrata (urban, suburban, rural; high versus low minority public schools). Student questionnaire: One of the two parts of the student survey (the other part is the cognitive test battery). This instrument contained a locator section for tracing sample members for future waves of NELS:88 and a series of questions about courses taken, hours spent on homework, and perceptions of the school and the home environment. Survey day: A day chosen by the school during the data collection period when an NORC interviewer and a clerical assistant (or the School Coordinator in schools with only a small group of sample members) administered the survey to the school's sample of students. The survey day session lasted about three hours for the actual data collection, with about thirty minutes each for preparation and clean-up/preparation of completed materials for mailing. Teacher, questionnaire: Math and science teachers of selected students were asked to complete a teacher questionnaire, which collected data on school and teacher characteristics (including teacher qualifications and experience), evaluations of student performance, and classroom teaching practices. Teacher, NELS-targeted teacher sample: In the base year and first follow-up, two teacher reports were sought for each student, reflecting a combination of two subjects from four subject areas (English, social studies, science, mathematics). In the second follow-up, one teacher report per pupil was sought for those students who were enrolled mathematics, science, or both, in one of the schools designated for school contextual data collection. Teacher transcript study: As a measure of the background and quality of teachers instructing NELS:88 eighth graders, postsecondary transcripts were collected for science and mathematics teachers of base year students. Tracing: The locating (and ascertaining of school enrollment status) of NELS:88 sample members. Sample members were traced at six points in time subsequent to eighth grade: autumn term 1988, autumn term 1989, spring term 1990, autumn term 1990, autumn term 1991, and spring term 1992. Transfer student: A NELS:88 sample member who moved from one school to another after the subsampling of schools between Phase 1 (the tracing of sample members to their school of enrollment) and Phase 2 (the re-verification of sample members' school of enrollment). Unit nonresponse: Failure of a survey unit (for example, at the institutional level, a school, or at the individual level, a respondent, such as a student or a teacher) to cooperate or complete survey instrument. Unit nonresponse may be contrasted to item nonresponse, which is the failure of a participating sample member to give a valid response to a particular question on a survey instrument. Validity: The capacity of an item or measuring instrument to measure what it was designed to measure; stated most often in terms of the correlation between scores in the instrument and measures of performance on some external criterion. Reliability, on the other hand, refers to consistency of measurement over time. (See entry for \"Reliability.\") Variance: See entry for \"Population variance\" and \"Sampling variance.\" Weighted estimates: Estimates from a sample survey in which the sample data are statistically weighted (multiplied) by factors reflecting the sample design. The weights (referred to as sampling weights) are typically equal to the reciprocals of the overall selection probabilities, multiplied by a nonresponse or poststratification adjustment. Thus, for example, the 1,035 completed school administrator questionnaires in the NELS:88 base year represent a population of 38,774 schools. Individual completed cases (that is, base year school administrator questionnaires) may \"represent\" anywhere from a minimum of 1.5 schools to a maximum of 387.3 schools. To take another example, 12,111 base year questionnaire respondents reported themselves to be male, and a slightly greater number (12,244) reported themselves to be female. When these cases are multiplied by the nonresponse-adjusted student weights to yield a weighted percent that reflects the national population of eighth graders, the estimate for males is 50.1 percent of the 1988 eighth-grade cohort while females are estimated to comprise 49.9 percent of the nation's 1988 eighth graders. Q-11"}, {"section_title": "5.42", "text": "Questionnaire data: second follow-up student, dropout, school, parent and teacher. In the extended figure that follows, content areas and corresponding questions in NELS:88 second follow-up questionnaires are displayed. This figure is organized as a matrix with seven policy research categories cross-cutting the five questionnaires. The seven research areas are:  "}]