[{"section_title": "Abstract", "text": "In this work, we consider the problem of predicting the course of a progressive disease, such as cancer or Alzheimer's. Progressive diseases often start with mild symptoms that might precede a diagnosis, and each patient follows their own trajectory. Patient trajectories exhibit wild variability, which can be associated with many factors such as genotype, age, or sex. An additional layer of complexity is that, in real life, the amount and type of data available for each patient can differ significantly. For example, for one patient we might have no prior history, whereas for another patient we might have detailed clinical assessments obtained at multiple prior time-points. This paper presents a probabilistic model that can handle multiple modalities (including images and clinical assessments) and variable patient histories with irregular timings and missing entries, to predict clinical scores at future time-points. We use a sigmoidal function to model latent disease progression, which gives rise to clinical observations in our generative model. We implemented an approximate Bayesian inference strategy on the proposed model to estimate the parameters on data from a large population of subjects. Furthermore, the Bayesian framework enables the model to automatically fine-tune its predictions based on historical observations that might be available on the test subject. We applied our method to a longitudinal Alzheimer's disease dataset with more than 3000 subjects [23] and present a detailed empirical analysis of prediction performance under different scenarios, with comparisons against several benchmarks. We also demonstrate how the proposed model can be interrogated to glean insights about temporal dynamics in Alzheimer's disease."}, {"section_title": "INTRODUCTION", "text": "Many progressive disorders, such as Alzheimer's disease (AD) [3] or cancer [15] , begin with mild symptoms that often precede diagnosis, and follow a patient-specific clinical trajectory that can be influenced by genetic and/or other factors. Therapeutic interventions, if available, are usually more effective in the earliest stages of a progressive disease [1] . Therefore, tracking and predicting disease progression, particularly during the mild stages, is one of the primary objectives of personalized medicine. In this paper, we are motivated by the real-world clinical setting where each individual is at risk and thus monitored for a specific progressive disease, such as AD. Furthermore, we assume that each individual might pay zero, one, or more visits to the clinic. In each clinical visit, various biomarkers or assessments (correlated with the disease and/or its progression) are obtained. Example biomarker modalities include brain MRI scans, PET scans, blood tests, and cognitive test scores. The number and timing of the visits, and the exact types of data collected at each visit can be planned to be standardized, but often vary wildly between patients in practice [4] . An ideal clinical prediction tool should be able to deal with this heterogeneity and compute accurate forecasts for arbitrary time horizons. We present a probabilistic disease progression model that elegantly handles the aforementioned challenges of longitudinal clinical settings: data missingness, variable timing and number of visits, and multi-modal data (i.e., data of different types). The backbone of our model is a latent sigmoidal curve that captures the dynamics of the unobserved pathology, which is reflected in time-varying clinical assessments. Sigmoid curves are conceptually useful abstractions that fit well a wide range of dynamic physical and biological phenomena, including disease progression [11; 27; 25] , which exhibit a floor and ceiling effect. In our framework, the sigmoid allows us to model the temporal correlation in longitudinal measurements and capture the dependence between the different tests and assessments, which are assumed to be generated conditionally independently from the latent state. We implemented an approximate Bayesian inference strategy on the proposed model and applied it to a large-scale longitudinal Alzheimer's disease dataset [23] , a devastating, terminal neurodegenerative disease that affects over 10% of the population older than 65. In our experiments, we considered three target variables, which are widely used cognitive and clinical assessments associated with AD: the Mini Mental State Examination (MMSE) [16] , the Alzheimer's Disease Assessment Scale Cognitive Subscale (ADAS-COG) [5] , and the Clinical Dementia Rating Sum of Boxes (CDR-SB) [22] . We trained and evaluated the proposed model on a longitudinal dataset with more than 3,000 subjects that included healthy controls (cognitively normal elderly individuals), subjects with mild cognitive impairment (MCI, a clinical stage that indicates high risk for dementia), and patients with AD. These clinical classifications are done in part based on the three target biomarkers in our model: MMSE, ADAS-Cog, and CDR-SB. Over the 5+ year follow-up period of the study, many of the subjects transitioned between clinical categories, e.g., from healthy to MCI or from MCI to AD. In fact, predicting these transitions is a significant focus of prior literature.\nYet, the emphasis in prior work is in what might be called static prediction: the target variable is pre-fixed, e.g., [31; 18] . For example, a common objective is to discriminate MCI subjects who progress to AD within some time window, e.g., 2 years. Similar problem setups are popular in cancer research, where a question of interest might be the 5 year survival. This is a binary classification problem. Our objective, on the the other hand, is to model and predict the entire clinical trajectory. Furthermore, we want to achieve this with a model that enables knowledge discovery about the progression of the disease. We provide a detailed analysis of prediction accuracy achieved with the proposed model and alternative benchmark methods under different scenarios that involve varying the past available visits and future time windows. In all our comparisons, the proposed model achieves significantly and substantially better accuracy for all target biomarkers. Furthermore, due to the probabilistic and generative nature of our model, we are able to make certain mechanistic queries to gain further insights about the underlying dynamics. This perspective offers us some new insights. For instance, we provide a quantification of the impact of AD risk factors (such as APOE genotype) on disease progression. The rest of this paper is organized as follows. Section 2 presents the proposed model and inference method. Section 3 describes the data and experimental set-up. Then, we present empirical results in Section 4. Finally, we conclude in Section 5. Figure 1 : Left: Graphical model (Bayesian network) that depicts the assumed statistical dependency structure between random variables (circles) and model parameters (rectangles). We use standard conventions: shaded random variables are assumed to be observed during training, and plates indicate replication with the number of copies listed at the lower left corner. See text for information on variables. Right: Illustration of sigmoids (with two different inflection points) that are assumed to model latent progression curves of two target variables."}, {"section_title": "PROPOSED METHOD", "text": ""}, {"section_title": "Model", "text": "Let us first describe our notation and present our model. Assume we are given n subjects. xi \u2208 R d\u00d71 denotes subject i's d-dimensional attribute vector. In our experiments, this vector contains APOE genotype (encoded as number of E4 alleles, which can be 0, 1 or 2) [7] , education (in years) [12] , sex (0 for female and 1 for male) [9] and two wellestablished neuroanatomical biomarkers of AD computed from a baseline MRI scan (namely total hippocampal [10] and ventricular volume [20] normalized by brain size). The MRI biomarkers capture so-called \"brain reserve\" [26] . Let y\nrepresent the values of the the k'th dynamic (i.e., time-varying) target variable at vi different clinical visits. ti = [ti1, \u00b7 \u00b7 \u00b7 , tiv i ] \u2208 R v i \u00d71 denotes a vector of the age of subject i at these visits. Note that the number and timing of the visits can vary across subjects. In general, we will assume k \u2208 {1, \u00b7 \u00b7 \u00b7 , m}. In our experiments, we consider 3 target variables: MMSE, ADAS-COG or CDRSB and thus m = 3. We use d\nk iv i ] to denote subject i's latent trajectory values associated with the k'th target variable. We assume each d k ij \u2208 [0, 1], with lower values corresponding to milder stages. As we describe below, the target variable, which is a clinical assessment, will be assumed to be a noisy observation of this latent variable. We model the latent trajectory of d k i as a sigmoid function of time (i.e., age), parameterized by a target-and subject-specific inflection point p k i \u2208 R and a subject-specific slope parameter si \u2208 R. Note that we assume that the slopes of the latent sigmoids associated with each target are coupled for each subject, yet the inflection points differ, which correspond to an average lag between the dynamics of target variables. This is consistent with the hypothesized biomarker trajectories of AD [11] . However, it would be easy to relax this assumption by allowing each target variable to have its own slope. We assume the inflection points {p k i } and slopes {si} are random variables drawn from Gaussian priors with means equal to linear functions of subject-specific attributes xi:\nwhere a k \u2208 R is associated with the k'th target (accounting for different time lags between target dynamics), while v, w \u2208 R d\u00d71 , and b, \u03c3p, \u03c3s \u2208 R are general parameters. Here and henceforth N (\u00b5, \u03c3 2 ) denotes a Gaussian with mean \u00b5 and variance \u03c3 2 . Given si and p k i , the latent value d k ij associated with the k'th target is computed by evaluating the sigmoid at tij:\nThe inflection point p k i marks the age at which the rate of change achieves its maximum, which is equal to si/4. Finally, we assume that the target variable value y k ij is a linear function of the latent state d k ij corrupted by additive zero-mean independent Gaussian noise:\nwhere c k , h k , and \u03c3 k \u2208 R are universal (i.e., not subjectspecific) parameters associated with the k'th target variable. We refer to Eq. (3) as an observation model. Fig. 1 depicts the dependency relationship between all variables."}, {"section_title": "Inference", "text": "In this section, we discuss how to train the proposed model and apply it during test time."}, {"section_title": "Training", "text": "Let us use \u0398 to denote the parameter set of our model:\nThe goal of training is to estimate the model parameters \u0398 given data from n subjects: {yi, xi, ti}i=1,...,n. Here,\n\u00d7m denotes m target values of the ith subject for vi visits. We estimate \u0398 via maximizing the likelihood function :\nNote that we use the standard notation of p(y|x) to indicate the probability density function of the random variable Y (evaluated at y) conditioned on the random variable X taking on the value x. Also, parameters not treated as random variables are collected on the right hand side of \";\". Now, let us focus on the likelihood of each subject:\nwith p(si, pi|xi; \u0398) = p(si|xi; \u0398)p(pi|xi; \u0398) due to Eq (1,2). Instead of the computationally challenging Eq (4), we use variational approximation [24] and maximize the expected lower bound objective (ELBO):\nEq(\nwhere q(si; \u03b3i) = N (\u00b5si, \u03c3 2 si ) and q(pi; \u03b3i)) = N (\u00b5pi, \u03a3pi = \u0393 T pi \u0393pi) are proxy distributions that approximate the true posterior distributions p(si|yi, xi; \u0398) and p(pi|yi, xi; \u0398), respectively. Recall that pi is m-dimensional since each target variable is associated with a different inflection point, yet the slope parameter si is shared across targets and thus a scalar. We have used \u03b3i = {\u00b5si, \u03c3si, \u00b5pi, \u0393pi} to collectively denote the proxy parameters. The expectation in the first term is with respect to the proxy distributions and can be approximated via Monte Carlo sampling. Thus: are Monte Carlo samples drawn using the \"re-parameterization trick.\" I.e., s\nare realizations of the auxiliary random variables, independently drawn from zero-mean standard Gaussians, N (0, 1) and N (0, I), respectively. The \"re-parameterization trick\" allows us to differentiate the ELBO (or more accurately, its approximation that uses Eq. 6) with respect to \u03b3i. E.g.:\n, and \u2202s\nDuring training, we use gradient-ascent to iteratively optimize Eq. 5 with respect to \u0398 and the parameters of the proxy distributions: {\u03b3i}. Note the structure of ELBO is flexible: missing target variables are treated by ignoring the corresponding term and the sum is over visits, which can handle irregular timings. Training yields optimal parameters: \u0398 * , and {\u03b3 * i }."}, {"section_title": "Testing", "text": "During test time, we are interested in computing the posterior distribution of yn+1 for a new subject with xn+1 at an arbitrary time-point (age) t. Note that we drop the second sub-script, i.e., j index, of yn+1 to emphasize that we will be computing these posterior probabilities at many different (often future) time-points. There are two types of test subjects: those with no history of visits (scenario 1), and those with at least one prior clinical visit (scenario 2). For scenario 2, we will use {y (n+1)j , t (n+1)j }j=1,...,v n+1 to collectively denote the vn+1 historical observations and their corresponding visit times. Note that we fix \u0398 * to the values obtained from training.\nIn scenario 1, we use Eq. (4) to compute the posterior:\nwhere p(s|xi; \u0398 * ) and p(p k |xi; \u0398 * ) are defined in Eq (1,2). In the second scenario, we will first maximize the ELBO of Equation (5) evaluated for the observations on the new subject {y (n+1)j , t (n+1)j } and attribute vector: xn+1:\nEq (8) is optimized with respect to \u03b3n+1, which yields proxy distributions that can be viewed as approximations:\nNote that these distributions can be regarded as a customization of the priors on s and p given the observed data. We then proceed to use these approximate q distributions in Equation (7), replacing p(s|xi; \u0398 * ) and p(p k |xi; \u0398 * ), to evaluate the posterior distribution for an arbitrary timepoint t conditioned on past observations. During test-time, we often have two distinct objectives: maximizing the posterior distribution or drawing samples from it to estimate the posterior mean and standard deviation. For the maximization problem, we can approximate the integral of Eq (7) via a Monte Carlo strategy by drawing samples from p(s|xi; \u0398 * ) and p(p k |xi; \u0398 * ) (Scenario 1) or the approximate distributions q(sn+1, \u03b3n+1) and q(pn+1, \u03b3n+1) (Scenario 2). Finally, one can use an ancestral sampling strategy to generate samples from the posterior distribution. Here, we first sample sn+1 and pn+1, either from the priors of Eq (1) and (2) (Scenario 1) or customized priors of Eq (9) and (10) (Scenario 2)."}, {"section_title": "EXPERIMENTS", "text": ""}, {"section_title": "Dataset", "text": "We use a dataset of 3,057 subjects (baseline age 73.3 \u00b1 17.2 years) collected by ADNI [23] to empirically validate and demonstrate the proposed model. This dataset contained multiple clinical visits per subject, during which thorough cognitive and symptomatic assessments were conducted. In our experiments, we used MMSE, ADAS-COG and CDR-SB as three target variables. MMSE has a range between 0 (impaired) and 30 (healthy), whereas ADAS-COG takes on values between 0 (healthy) to 70 (severe), and CDR-SB varies from 0 (healthy) to 18 (severe). The first two (MMSE and ADAS-COG) are general cognitive assessments that track and predict dementia, while CDR-SB is a clinical score that measures the severity of dementia-associated symptoms.\nIn ADNI, clinical assessment were done every 6-12 months. The timing of these visits varied and certain subjects missed visits. Furthermore, most subjects dropped out of the study by their 4th planned visit. Hence while the clinical follow-up period spanned over 5 years, each subject had an average of 3.2 visits. In total, there were 9716 time-points in our dataset. The subjects ranged from 55 to 95 years of age and were grouped into three clinical categories: health control (HC), mild cognitive impairment (MCI), and AD patients. These clinical categorizations in part relied on the target variables of interest. Table 1 provides a summary of the different visits and how they breakdown across clinical groups. During the follow-up period, some subjects transitioned between categories, resulting in six types of subjects: stable HC, stable MCI, stable AD, and MCI-to-AD, HC-to-AD, and HC-to-MCI converters. There were also a very small number of subjects who improved in clinical categories (e.g. AD-to-MCI). In addition to the target variables, we utilized individuallevel traits associated with AD: age, APOE genotype (number of E4 alleles) [7] , sex, and education (in years) [9] . We also used baseline brain MRI scans to derive two anatomical biomarkers of AD: total hippocampal and ventricle volume normalized by brain size. These imaging biomarkers were automatically computed with FreeSurfer [8] and quality controlled as previously described [19] . Finally, as we describe below, we considered utilizing the longitudinal imaging biomarkers (hippocampal and ventricle volume) as target variables that were available during training. This is because ADNI is a unique dataset and attempts to acquire brain MRI scans on each subject every 6-12 months. As a result, we have access to these invaluable data. Yet, we emphasize that during test time, we only considered the availability of MMSE, ADAS-COG and CDR-SB on historical visits and did not assume longitudinal neuroimaging data on test subjects."}, {"section_title": "Experimental Setup", "text": ""}, {"section_title": "Benchmark Methods", "text": "In our experiments, we compare the proposed method to the following benchmarks:\n1. Global: A 4-parameter (scale, bias, inflection, and slope) sigmoidal model that was fit on all training data (least-squares)\n2. Sex-specific: Same as above but separate for males and females 3. APOE-specific: Same as above, but separate for three groups defined by APOE-E4 allele count {0, 1, 2}.\n4. Sex-and APOE-specific: Same as above, but separate for each sex and APOE group.\n5. Linear mixed effects (LME) model: A linear regression model with subject-specific attributes (xi) as fixed effects, and time and bias term as a random effects. This LME model, commonly used to capture longitudinal dynamics [17; 4] , allows each subject to deviate from the average trajectory determined by its attributes by shifts in slope and offset.\n6. Subject-specific linear model: Least-squares fit of a linear model on each subject's historical data. When there is only one past visit, we adopt a carry-forward extrapolation.\nBenchmarks 1-5 make use of the training data, whereas benchmark 6 ignores the training data and merely relies on each test subject's own data. While benchmark 1-4 use models that are fixed after training, benchmarks 5 and 6 make adaptations to the model given observations on the test subject. Below, we refer to benchmarks 1-4 as trainingfixed benchmarks. The LME model (benchmark 5) uses test observations to estimate subject-specific deviations from a global linear model. Benchmark 6 fits a line to historical data of the test subject, and is a widely used technique in clinical practice. We did not fit a sigmoid to the subjectspecific data as one would need more than 4 historical timepoints to obtain reliable estimates. For benchmarks 1-4, we also implemented linear versions (i.e. least squares fit of a line), yet the prediction performance was no better than the sigmoidal modes. Therefore, we omitted those results due to space constraints."}, {"section_title": "Evaluation", "text": "For each target variable, we use the mean and standard deviation of the absolute error across test subjects to evaluate the different models. In order to examine the statistical significance of the difference between the proposed method and benchmarks, we used following \"paired permutation\" strategy. For each test subject, we randomly permuted the labels of the prediction models. Note that the random permutation was done at the subject-level, in order to respect the temporal dependency structure in longitudinal assessments. Thus, each randomly shuffled model was used to compute predictions for all time-points of a given subject. For each permutation, we computed the mean absolute error (MAE, average across target variables) of the predictions of each (randomly shuffled) model. Next, we computed and saved the difference between each model's MAE and the proposed model's MAE. After sorting these differences (in descending order) over all permutations, the permutation p-value was computed as the rank of the true difference (i.e. the difference between the MAE of the benchmark model and proposed model without permutation) divided by the number of permutations (10,000) plus 1."}, {"section_title": "Implementation Details", "text": "We implemented the proposed model and inference algorithm in Python 1 , using the Edward library [29] , which is in turn built on TensorFlow [2] . We used a 20-fold crossvalidation strategy in all our experiments. We first partitioned the data into 20 non-overlapping, roughly equallysized sets of subjects. In each of the 20 folds, we reserved one of the partitions as the independent test set. Out of the remaining 19 partitions, one was set aside as a validation set, while the rest were combined into a training set. The training set was used to estimate the model parameters, i.e., \u0398 * , while performance on the validation set was used to select hyper-parameters, such as step size in the optimization and evaluate random initializations. Finally, test performance was computed on the test set. We report results averaged across 20 folds."}, {"section_title": "Prediction Results", "text": "We first show the quantitative prediction results for all the methods and three target variables (MMSE, ADAS-COG, and CDRSB). In the following, we consider several prediction scenarios. In the first prediction scenario, we vary the number of past visits available on the test subjects (i.e., vn+1). In general, we expect this variation to influence the LME and subjectspecific linear model benchmarks (5 and 6), in addition to the proposed model. These methods fine-tune their predictions based on historical observations available on test data. With more test observations, we expect them to achieve better accuracy. All other benchmarks are fixed after training and thus their performance should not improve with increasing number of past observations. In the second scenario, we fix the number of past observations on test subjects and vary the prediction horizon. In general, all models' predictions should be less accurate for more distant future time-points. Finally, we focus on the proposed model and consider training it on longitudinal imaging data available in training. Brain MRI scans are expensive and hard to obtain, so throughout this paper we assumed that each test subject has only a single baseline MRI scan. Yet, the ADNI dataset contains longitudinal imaging data and we were interested in quantifying the effect of using these during training on test-time performance. Figure 2 shows the MMSE, ADAS-COG and CDRSB prediction accuracies (mean and standard deviation of absolute error). We observe that the performance of the trainingfixed benchmarks (1-4) worsen slightly as the number of past visits increases. This is likely because the training data contains more samples at early times (i.e., relatively younger ages), partially because most subjects drop out by their 4th visit. Therefore, a model trained on these data is expected to be less accurate for older ages. The adaptive benchmarks (5-6) and the proposed model, on the other hand, overcome this handicap to achieve better accuracy with more past visits. As we discussed above, this is largely because these techniques exploit test observations to fine-tune their models. The subject-level linear model (benchmark 6), in fact, is an extreme example, where the predictions are computed merely by extrapolating from historical observations without relying on training data. Finally, we note that the proposed model achieves a significantly and substantially better accuracy than all benchmarks (all paired permutation p-values < pmax = 0.04). The subject-specific benchmark (6) exhibits the largest variance implying the quality of performance varies wildly across subjects. Overall, the training-fixed benchmarks perform the worst. In general the proposed model's variance is among the smallest, indicating consistency in prediction accuracy."}, {"section_title": "Varying the Number of Past Visits", "text": ""}, {"section_title": "Varying the Time Horizon", "text": "In order to evaluate how prediction performance changes as a function of the time horizon, we evaluated the methods for different future time-points. In this empirical scenario, we assume that each test subject has 2 past clinical assessments (obtained at baseline and month 6). Our goal is to predict MMSE, ADAS-COG and CDRSB scores at later time-points (starting at 12 months after baseline, up to 36 months). Based on the longitudinal study protocol, we considered 6 month intervals and assigned the actual visits to the closest 6-month bucket. Fig 3 shows prediction accuracies of all considered methods. The proposed method performs significantly (all paired permutation p-values < pmax = 0.03) and substantially better than all other methods, with the difference increasing from the short term (12 months) to long term (36 months). For the benchmark models, prediction accuracy tends to drop more dramatically for longer time horizons. As above, training-fixed benchmarks perform the worst."}, {"section_title": "Training with or without longitudinal MRI scans", "text": "Since longitudinal MRI scans are available for most subjects in our dataset, we considered the use of serial imaging biomarkers in training. Yet, as before, we assume that only the baseline MRI scan is available for testing subjects. Adding a time-varying biomarker is relatively easy in our model, as it involves adding another target variable type. This target variable will have its own inflection point and observation model (Equation 3). Note that in our framework, due to the conditional independence assumptions, inference is robust to the timing and availability of the target variables. During training (i.e., when optimizing the ELBO function), the algorithm simply sums over all available visits and evaluates the function only for observed targets. Fig. 4 shows the performance of our model trained with and without longitudinal MRI scans. We observe that prediction accuracy is consistently better when trained with longitudinal MRI scans, which suggests that we can improve the quality of the model's predictions by incorporating additional time-varying biomarkers."}, {"section_title": "Further Analysis of the Proposed Model", "text": "The proposed model can be viewed as a generative probabilistic model that gives rise to clinical assessments and possibly other time-varying biomarkers. Hence, in addition to computing individual-level predictions, we can probe the trained model to gain further insights about the underly- ing dynamics of the pathology. In this section, we provide examples of such analyses."}, {"section_title": "Inflection Points", "text": "In our model, each target variable is associated with a latent sigmoid curve that captures temporal dynamics. While the slope of these sigmoids are coupled across target variables, their inflection points p k are different. Yet, we emphasize that the inflection points are not assumed to be independent across targets, as they are drawn from a prior distribution shaped by the subject's attributes xi (see Eq. 1). For a given subject, the difference between the inflection points of a pair of target variables reflects the time lag between the corresponding progression curves. After we fit the proposed model on the training data, we draw samples for the unobserved inflection points on test data. We then empirically estimated the prior distribution of p k averaged across subjects via a kernel density estimator (Gaussian kernel with variance = 2.5). Fig. 5 plots the empirical prior distributions for the different target variables and their latent progression curves corresponding to the mean parameter values (for the slope and inflection points) derived from the empirical priors. We notice that the MMSE progression, on average, is earlier than ADAS-COG, with a mean difference of around 3.5 years. ADAS-COG is, in turn, on average, about 11 years earlier than CDR-SB. These results are consistent with the hypothesized trajectories of AD biomarkers [11] , where memory and cognitive scores such as MMSE and ADAS-COG start declining sooner than clinical symptoms."}, {"section_title": "The Impact of APOE, Sex, and Education", "text": "Next, we were interested in inspecting how APOE, sex, and education impact the trajectories MMSE, ADAS-COG and CDRSB. In our model, the parameter vector w determines the mean slope and v affects the mean inflection point of the latent progression curves. Table 2 lists the estimated values in w and v (averaged over the 20 folds) for APOE, sex, and education. We observe that each extra APOE E4 allele copy increases the maximum rate of progression (which is equal to si/4) by an additional 24.5%, yet shifts the inflection forward by 0.11 years. Males, on average, have a maximum rate of progression that is 9.25% more than females, and their inflection points are 0.31 years later. Each additional decade of education, on the other hand, delays the progression curves by 0.44 years, yet the maximum rate of progression increases by an additional 8.1%. "}, {"section_title": "Visualization of Personalized Models", "text": "As we discussed above, the proposed model can adjust its predictions based on available observations on the test data.\nIn this section, we were interested in revealing this personalization effect on subject-specific trajectories. In Figure 6 , we visualized the predicted trajectories for MMSE, ADAS-COG and CDRSB on several representative subjects, under two conditions: no past visits and four past visits. Note that we chose the subjects from 6 sub-groups: stable HC, stable MCI, stable AD, HC-to-MCI converter, MCI-to-AD converter, and HC-to-AD converter. In each sub-group, we selected representative subjects with most time-points. Figure 6 visualizes the ground truth clinical scores, which are marked with x's. Those points that are circled with green are considered observed past points in the second con- Figure 4 : The mean absolute errors with standard derivation of our method on MMSE prediction computed from 20-fold cross-validation with longitudinal MR images in training process and without. We varies the number of past visits from 0 to 4 to evaluate how our methods adapt to use different priors from past visits to improve the performance. dition to compute the adjusted projections (personalized model). We observe that the baseline model predictions (corresponding to no past visit and illustrated in blue) are often much less accurate than the personalized model (red). The baseline model, in general, predicts little change over time, whereas the personalized model offers better projections that can capture significant change."}, {"section_title": "DISCUSSION", "text": "We presented a probabilistic, latent disease progression model for capturing the dynamics of the underlying pathology that is often shaped by risk factors such as genotype. Our work is motived by real-world clinical applications, where irregular visiting patterns, missing variables, and inconsistent multi-modal assessments are ubiquitous. In the proposed framework, we make a distinction between subject-level attributes, which we assume are fixed, and time-varying clinical observations, which can include imaging and cognitive tests, collected over multiple visits. These time-varying variables are modeled to be noisy observations of an idealized latent, sigmoid progression curve that has two parameters: its inflection point and slope. These parameters are in turn, assumed to be functions of the fixed subject attributes. We take a Bayesian approach to fit this model on a training dataset with clinical observations, where the parameters of the latent progression curve is integrated out.\nIn this work, we had two distinct, yet simultaneous goals. Our first goal was practical: to forecast the clinical future of a test subject based on a population model that is customized if we have historical observations from the test subject. Our second goal was \"knowledge discovery:\" we were interested in gaining insights about the underlying dynamics of various clinical assessments and further identifying the impact of risk factors such as genotype. We applied the proposed method on a large dataset of Alzheimer's disease with promising results. In our experiments, we analyzed prediction accuracy for the proposed model and several benchmark methods under different scenarios that included varying the known patient history and prediction horizon. In all our comparisons, the proposed model achieved the best performance. However, we caution the author to treat these results as preliminary. In future work, we are interested in exploring methods that might yield better prediction accuracy. One approach would be to exploit more input variables, such as genome-wide markers and whole-brain images. Such high-dimensional models will likely require additional prior constraints, such as sparsity, to avoid overfitting, as in [32; 30] . Another, closely related framework is multi-task learning, which is suitable for our problem of predicting multiple clinical target variables. Multi-task learning has been applied to predict multiple correlated diseases [21] , integrate data from several sources [28] or modalities [31] . However, in prior works, the target variables are often considered fixed and/or longitudinal observations are ignored. Another direction that will likely yield improved accuracy is to extend our model beyond linearity assumptions. Deep learning techniques, such as reccurent neural networks (RNNs), offer a natural framework for this direction. RNNs have been applied to related problems, such as clinical diagnosis from time-series data [14; 6] , and imputing missing longitudinal variables [13] . The main challenge in these approaches is that they are often data hungry (requiring lots of annotated data to train on) and hard to interpret, which conflicts with our objective to obtain interpretable insights about underlying disease dynamics. Furthermore, RNN models usually assume fixed intervals between time-points -an assumption widely violated in real-life scenarios. In contrast, our Bayesian approach is flexible, assumes no regularity in visit times, does not need a huge amount of data to fit, can seamlessly handle multiple modalities, and, importantly, yields straightforward interpretations."}, {"section_title": "ACKNOWLEDGEMENTS", "text": "This work was supported by National Institutes of Health (NIH) grants R01LM012719, R01AG053949, and 1R21AG050122, and the National Science Foundation NeuroNex Neurotechnology Hub grant 1707312.\nIn our experiments, we employed data downloaded from the longitudinal ADNI study (phases 1, GO, and 2, adni.loni.usc.edu) [23] "}]