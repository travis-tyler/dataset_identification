[{"section_title": "INTRODUCTION", "text": "Studying education policy necessarily includes exploring the context of its elaboration. Researchers pay attention to social, economic, and political contexts in order to enhance their understanding of the policy process. At the same time, researchers increasingly emphasize the importance of a different kind of context-the ideas, discussions, research, and expert advice surrounding and facilitating the processes of policy making (see, e.g., Grek & Ozga, 2010; Tripney, Kenny, & Gough, 2014; Tseng, 2012) . Policies do not simply stem from \"objective\" circumstances; they are \"discursive products\" embedded in wider environments of understanding and meaning making (Kauko, Simola, Varjo, & Kalalahti, 2012; Pashby, 2013) . Kauko et al. (2012) write about \"discursive formations\" or \"problematiques\" that introduce certain political possibilities based on what is defined as a \"problem\" and consequently politicized. They emphasize that \"there is a need to trace genealogies of problems that are specific to a certain discursive field\" (p. 222).\nNational academic discussion constitutes an important discursive context for policies, influencing and being influenced by them. It demonstrates the genesis of thinking and changes of discourse, and consequently, the history of national education policies in their broader sociopolitical context. It outlines the intellectual space within which research and arguably policy making takes place. Thus, education policy scholars investigate the role of theory and research evidence in politics because the \"concepts and arguments developed by researchers play a key role in establishing what is 'in the true' and hence 'real'\" (Bacchi, 2012, p. 6) . Based on these viewpoints, an analysis of the national academic discussion as a distinct, though far from independent, discursive field can shed light on the national body of knowledge in the area studied, highlight and examine the themes that attract most attention, and indicate issues that have been neglected.\nDespite the global reach of the quality of education and its measurement agenda (see, e.g., Lingard, Martino, & Rezai-Rashti, 2013; Valverde, 2014) , the topic has been discussed primarily in the context of the OECD or EU member countries. Little is known about this phenomenon in Russia (the existing publications take other foci; see, e.g., the juxtaposing of the neoliberal concept of quality with national educational settings in Minina (2013) . This article focuses on the academic discussion on quality evaluation in school education in Russian national academic publications. Our interest in evaluation and quality stems from the fact that the two constitute a major policy concern in education across the world, simultaneously acting as powerful steering mechanisms at national and transnational levels (Ozga, Dahler-Larsen, Segerholm, & Simola, 2011; Valverde, 2014) . Tracing the discussion on quality and evaluation in school education in Russian academic sources in the period from 1990 to 2014, this article is guided by the following broad questions: (1) How is quality of education and evaluation of quality discussed in Russian academic literature? Which aspects have received most attention and which ones have been neglected? (2) How has the discussion changed over time? Thus, this article analyzes how the discussion on education quality evaluation in general and certain evaluation mechanisms in particular developed over time, and not on what actually happened in the field (although the discussions arguably facilitated certain developments).\nOur analysis focuses on a context with distinctively different ideological history, administrative practices, and educational research tradition. While rooting our intellectual framework in the (Western) education policy literature that presents quality measurement as a central means of governance at a distance and New Public Management (NPM)-inspired reforms, we remain sensitive to the possibility of other interpretations. Here, our starting point is that (Western) explanations that link the rise of quality control and audit cultures in schools to the ideology of neoliberalism (and by extension, to NPM and governance from a distance) might impoverish the analysis by applying neoliberalism as an encompassing regime of truth (Kipnis, 2008) . As Kipnis (2008) writes, \"The global rise of audit cultures needs to be understood in a broad, anthropological, comparative framework, not one narrowly concerned with a critique of ideas that diffuse from the West\" (p. 286). Concurring with this position, we refrain from making assumptions on the origin of the ideas discussed on the pages of the examined Russian publications, and simultaneously pay attention to the meanings that lie outside the utilized conceptual frame. The article represents the first phase of a research project, which will proceed to the study of national and local level policy documents on quality evaluation in Russia, as well as to interviewing key actors at different levels and conducting ethnographic fieldwork in selected schools, thus enabling us to return to the issue of origin in subsequent work."}, {"section_title": "CONCEPTUALIZATIONS OF EVALUATION AND QUALITY MEASUREMENT AS MECHANISMS OF GOVERNANCE", "text": "Major works in education policy research have recently approached the topic of quality assurance and evaluation from two intertwined theoretical angles: as a tool of governance at a distance and as a manifestation and a means to introduce New Public Management reforms in education and other social spheres (Ferlie, Musselin, & Andresani, 2008; Hood, 1991; Lawn & Grek, 2012; Miller & Rose, 1990 ). Governing at a distance is understood here as a specific mode of governance or \"governmentality\" based on the idea of acting from a center on the habits, desires, and actions of the spatially, culturally or organizationally distant others (Miller & Rose' s concept as described in Rose, O'Malley, & Valverde, 2006, pp. 91-92) . This mode of governance implies that the subjects preserve a significant degree of autonomy and \"voluntarily\" engage in the center-initiated processes that shape their conduct (Miller & Rose, 1990, p.14) . Governing at a distance is capable of imposing the logic of the center over scattered and diverse places and producing a common \"disciplining and enabling space\" (Lawn & Grek, 2012, p. 82) . It is this capacity to create cohesion and commonality amidst diversity that makes this mode of governance suitable for most complex political tasks such as \"creating Europe,\" as powerfully described by Lawn and Grek (2012; also N\u00f3voa & Yariv-Mashal, 2003) . There are several ways in which evaluation and quality assurance procedures contribute to governing at a distance. They set and enforce particular standards against which educational institutions' work is measured, legitimizing reward and punishment by the authorities. Evaluation procedures produce numerical information that is then used for developing governing strategies and programs, as well as for comparison and benchmarking, which have emerged as cordial steering tools (N\u00f3voa & Yariv-Mashal, 2003) . Governing complex spaces and phenomena is now reinterpreted as a problem of data and its proper collection and analysis (Lawn & Grek, 2012, p. 9; Ozga et al., 2011; Rose & Miller, 1992) . The very processes of data production modify behavior of the subjects who produce this data through making them think according to certain norms and pay attention to particular, predetermined aspects of the evaluated phenomena. Data collection redefines practices through the logic of \"what is counted, counts,\" especially when evaluation processes bear high stakes for the evaluated persons and institutions through redistribution of funds or recruitment decisions. Equally, the processes of data collection as mandated by the authorities contribute to building or strengthening hierarchies and unequal power relations between those who assemble the data and those who are acted upon as data (Piattoeva, 2015; Selwyn, Henderson, & Chao, 2015) . Quality assurance procedures increasingly involve self-evaluation practices which, while seemingly permissive and self-initiated, still have to stay in line with the prescribed indicators and central standards, and put emphasis on constant self-regulation and self-improvement (Lawn & Grek, 2012, p. 146 ). Yet another tool is provided by the public nature of evaluation results, which now appear in diverse rankings, ratings, and reports publicized in and often prepared by commercial media for the purpose of modulating everyday decisions and actions of the consumers of educational services. This development can be viewed as empowering a certain privileged category of citizens as political subjects who are expected to influence educational institutions by means of rational and informed consumer choice (for more discussion on media-assisted, data-driven governing from afar, see Piattoeva, 2015) .\nAnother perspective on evaluation and quality assurance as tools of governance is elaborated in the literature that studies NPM reforms in education. NPM is based on the ideal of transplanting market mechanisms, primarily competition, cost-effectiveness, and empowerment of managers, stakeholders and consumers, to the public sector. NPM's \"business approach\" effectively redefines public services as traded commodities, and replaces professional ethics with demand for accountability. The organizations that directly \"serve customers\" are granted greater autonomy to enable a more \"customized\" and efficient service, while authorities steer them through setting targets, defining outcomes rather than inputs, and introducing incentives (for more on NPM see e.g., Diefenbach, 2009; Hood, 1991) .\nPerformance measurement and management play a key role in the NPM approach (cf. \"auditisation variant of NPM\" in Ferlie et al., 2008) . The evaluation data is utilized for performancebased funding and payment schemes, which evoke competition between and within the assessed institutions, and at the same time disguise the cost-reduction measures undertaken by the authorities in their struggle against the so-called inefficiency. The publication of evaluation results serves competition purposes, as well as the objective to increase accountability of educational institutions to their \"stakeholders.\" NPM promotes external evaluation procedures and numerical data as tools of increased transparency and efficiency, and seeks to empower \"customers\" by involving them in the evaluation procedures. We employ the aforementioned conceptualizations as heuristic frames and probe whether Russian academic publications bear the traits of governance at a distance and NPM-related positions in discussing particular forms of quality evaluation through time."}, {"section_title": "QUALITY EVALUATION IN THE SOVIET AND RUSSIAN CONTEXTS", "text": "International sources often depict the Soviet education system as lacking in any quality assurance and evaluation policy. They infer that since there was no standardized achievement testing at either school graduation or university entry, and no systematic feed of school examination results to the Ministry of Education, the authorities lacked a sufficient basis for decision making1 (Bakker, 1999; West & Crighton, 1999) . However, the notion of quality and ideas about its measurement and improvement were not absent from the Soviet education policy discourse, though they appeared in a different guise. Already in the 1940s the government issued decrees \"On the improvement of the quality of teaching in schools\" that introduced compulsory examinations and a five-tier grading system. Another document issued by the ministerial Collegium recommended to \"collect and summarize the best teachers' experience\" (Kukulin, Mayofis, & Safronov, 2015, pp. 643-47) . Notably, the examination and grading reform was accompanied by a decree that condemned the practice of socialist competition in school education and prohibited the evaluation of school or teacher quality based on students' progress in learning (ibid.). By the end of the Soviet period, as both national and international sources suggest, whenever the quality of schools needed to be described, it was usually captured by the numbers of students with high marks (4 and 5), the percentage of students who entered higher education, the number of gold and silver medalists in subject Olympics and the number of students who continued their tertiary education in prestigious higher education institutions (see, e.g., Bakker, 1999, p. 296) . In general, however, Soviet education policies were based on the idea that clearly defined principles (curricular contents, lesson plans, textbooks), sufficient inputs, and well-implemented processes (pedagogies and leadership) would lead to satisfactory education outcomes (West & Crighton, 1999) .\nPublic and professional demands for change in Russian education were voiced already in the 1980s in the spirit of the perestroika movement toward a more democratic society. In 1988, Eduard Dneprov, who later became the first minister of education of post-Soviet Russia, was appointed to lead a newly established collective of like-minded reformer pedagogues under the auspices of the VNIK \"Bazovaia shkola\" (Temporary Scientific Research Collective on the Schools) within the Academy of Pedagogical Sciences. The VNIK participants paved the way for the new thinking, producing a number of central documents that later became the foundation for the post-Soviet educational reforms and new legislation (Kukulin et al., 2015, p. 674; also Long & Long, 1999) .\nAfter the dissolution of the Soviet Union, the new Russian Law on Education from 1992 was formulated in such terms as \"humanization,\" \"differentiation,\" \"democratization,\" and \"pluralization\" (Rust, 1992 , cited in Polyzoi & Dneprov, 2011 . The Law enabled decentralization and shifted particular administrative and fiscal responsibilities to regional and local authorities. The ideal of decentralization also unfolded as support for school-level management, increased school choice for families and introduction of nonstate schools, as well as more freedom to generate school-based curricula in all schools regardless of their status (see, e.g., Long & Long, 1999, p. 83) . Decentralization is often blamed on the harsh financial reality of the early 1990s that simply left central authorities with no choice other than transfer fiscal responsibility onto the regional and municipal shoulders. However, without denying this reality, it is important to bear in mind the new political and pedagogical thinking that motivated the changes.\nFor instance, the reformers promoted the idea that \"educational processes should be governed by those who teach,\" meaning that school-based staff should have a greater say in a wide scope of decisions that concern schoolwork (Long & Long, 1999, p. 88) . In similar vein, the school administration was envisioned as a communal enterprise that should involve students and parents, as well as teachers and representatives of civil society at large. Regionally and locally tailored education was expected to better serve the local needs in the diverse Russian territories. In practice, coupled with underfunding, decentralization led to increasing inequalities between regions and within them (Polyzoi & Dneprov, 2011) . Another major change concerned the overall reinterpretation of education as an education market, leading to partial privatization and commercialization of the school sector (Gounko & Smale, 2007; Silova & Brehm, 2013) .\nThe change of political leadership in 1999 and the rapid recovery of the national economy and finances heralded a new phase in the state policy making, including education reforms. The new National Doctrine for Education (2000), the Concept of Modernization of Russian Education (2001), and the Federal Strategic Program for the Development of Education (2005) stressed the role of education in securing the nation's economic growth, global competitiveness, and human capital development. They also further promoted the introduction of market mechanisms into the education sector and emphasized the importance of efficiency and accountability of education institutions (Gounko & Smale, 2007, pp. 540-541) .\nIt is the modernization reform package of the 2000s that granted the topic of quality of education a dominant position. Several major measures were introduced in the name of quality assurance, including the new state education standards (the part of the curriculum compulsory in all parts of the Russian Federation) and the national tests of educational achievement: the Unified State Exam (USE) executed after the completion of eleven-grade school education, and the State Final Attestation (SFA) undertaken in the last grade of compulsory basic education in grade nine. The State Program for Education Development in 2013-2020 brought a comprehensive system of education evaluation and quality control, composed of state regulation of education activities, assessment of education achievement, procedures of independent quality evaluation, including expert-public accreditation of education programs and self-evaluation of education institutions, and the participation of Russia in international studies (Government of Russia, 2012, p. 218) .\nOf all these, the USE deserves particular mention due to its exceptionally profound influence on the whole education system. Developed as a tool for measuring educational achievement and a means to ensure more equal access to higher education, the USE gradually became a major instrument for measuring overall education quality and ensuring compliance with the official school curricula (Piattoeva, 2015; Tyumeneva, 2013) . It shifted attention to measurable outcomes and efficiency, signaling the introduction of an output-based curriculum in Russia, and facilitated the centralization of school education governance. The standardized examination was implemented at the time of growing dissatisfaction with the decentralization process that went too far and endangered national cohesion, highly polarizing debates on the newly developed school standards. The latter largely concerned the applicability of the competenceand outcome-based approach to education in Russia, as promulgated by the international studies of learning achievements, which Russia 'failed' (see Lenskaya, 2013; Minina, 2014) .\nResearchers note that the national strategy for the modernization of education adopted by the Russian government since the late 1990s conformed to the recommendations of international organizations (primarily, the World Bank and the OECD), whose \"standard package centered around the concepts of cost-effectiveness, market-driven quality control, educational standardization, outcome-based education, decentralization of governance and finance, and privatization of higher education\" (Minina, 2013, p. 21 ; see also Gounko & Smale, 2007; Silova, 2010) . The changes that introduced comprehensive evaluation of quality in education also resemble policy advice from international organizations. Throughout the 1990s, reports by the World Bank and the OECD on Russian education argued for a reform of the examination system, the need for statewide educational statistics, and a transition from direct control to indirect means of ensuring compliance through evaluation and accountability (OECD, 1998; World Bank, 1995) . These changes took place in the context of the newly introduced NPM-inspired forms of state regulation, including steering by results, and these reforms, too, had strong links to loan conditionalities and expert advice provided by international players (see Gusarova & Ovchinnikova, 2014) ."}, {"section_title": "SOURCES AND METHODS OF ANALYSIS", "text": "Several sources were used to identify relevant Russian language academic literature on quality and evaluation in education. First, a search was undertaken within two Russian academic QUALITY OF EDUCATION AND ITS EVALUATION journals in education sciences: (Voprosy obrazovaniia, Educational Studies in its English version) and (Narodnoe obrazovanie, Popular Education). These sources were chosen because they belong to the leading journals in education sciences (along Pedagogika, Obrazovaniye i Nauka and Director Shkoly) and publish regularly on quality and evaluation in education. Our choice of the two aforementioned journals was motivated by an intellectual interest in sources with distinctively different positions and histories. Founded in 1803, Narodnoe obrazovanie is the oldest Russian education journal, and for a long time it served as the official journal for the Ministry of Education. Currently, it seeks to reflect a wide range of views on education, publishing pieces authored by scholars as well as administrators and teachers (Zamost'ianov, 2012) . Voprosy obrazovaniia was established in 2004 by the National Research UniversityHigher School of Economics (HSE), being one of the youngest influential academic journals in education. Although it appears to be more academically oriented, which is arguably the reason for a narrower circle of authors, Voprosy obrazovaniia differs from its \"Western\" counterparts in publishing Russian translations of reports and recommendations produced, for instance, by the OECD and other influential education policy actors (also such individuals as Sir Michael Barber and Eric Hanushek, whose works are a standard reference in the World Bank's and Pearson's policy papers, for instance). In this manner, the journal could be said to channel particular educational ideals without necessarily engaging in their analytical appraisal. By selecting two leading journals with divergent histories, publication policies, and, as it appears, ideological positions, we sought to better capture the breadth of the academic discussion without seeking to compare articles from the two publication venues. As was revealed in the process of data analysis, the circle of authors publishing on quality and evaluation was to a considerable degree similar in the two journals.\nApart from the aforementioned journals, additional publications were found through keyword searches in Google Scholar and the four national databases: eLIBRARY.RU, CyberLeninka, web-portal \"Economika. Sociologia. Management\" and the electronic library of the HSE. Book editions from the 1990s that are by and large not referenced in electronic databases were found by searching the catalogue of the Konstantin Ushinsky Scientific Pedagogical Library in Moscow. A few additional sources were selected from the reference lists of the analyzed publications. Finally, we took into consideration the recommended course literature from two MA-level courses taught at the HSE, \"Measurements and evaluation of quality in education\" and \"National and international programs for evaluating educational achievement.\" These courses are unique in Russian higher education, and the programs in which they are taught are among the very few training specialists in education administration and measurement in education. Hence this course literature can be argued to exert particular influence on future Russian education evaluation professionals.\nThe keywords employed in the publication searches were \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f (otsenka kachestva obrazovaniia; evaluation of educational quality) and \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f (upravlenie kachestvom obrazovaniia; assurance, or management, of educational quality). From the resulting sources, we selected the texts that concerned school education. The selection process resulted in about 160 pieces published between 1990 and 2014. Of these we read 120 relevant articles (which ranged from three to over 20 pages) and 17 books for which full texts were available.\nWe relied on qualitative content analysis in order to construct the analytical categories from our data (see Bryman, 2004, p. 542; Creswell, 2012) . Each source was first examined from the perspective of its key themes; this analysis was followed by identifying key arguments within each key theme. Based on these, five meta-categories were created, each encompassing diverse themes and arguments: quality and evaluation regarding students' learning achievement, quality of teachers' work, quality of school management, quality and its evaluation on the regional and/ or national level, and comparison with other countries, including discussions on international comparative studies. These meta-categories were not mutually exclusive as one article often matched several meta-categories.\nThe sources were then regrouped by publication date in order to see whether there were any thematic similarities within each group and how argumentation changed throughout the years. Due to the scarcity of sources published from 1991 to 1998, these were combined into a single group, and, beginning from 1999, publications were grouped by the year of publication. These initial groups were then reorganized into bigger blocks based on two criteria: proximity in time of publishing and similarity of the discussion foci. This procedure resulted in discerning four periods: from 1990 to 1999, from 2000 to 2004, from 2005 to 2010, and from 2011 onward. Within each period, the academic discussion of quality evaluation concentrated on issues differing from those in the previous or following periods. The thematic differences between the periods are in no way clear-cut. Some strands pervade all periods, while others disappear and reemerge after a while (often connected to the careers of the authors)."}, {"section_title": "RESULTS: SHIFTING FOCI OF RESEARCH ON QUALITY OF EDUCATION", "text": "Overall, the four periods identified in our research capture the dominant themes, which could be titled \"effective management and customization of education \" (1990-1999) , \"the rise of broadscale assessments\" (2000) (2001) (2002) (2003) (2004) , \"systemic approach to quality evaluation\" (2005) (2006) (2007) (2008) (2009) (2010) , and \"towards a more nuanced usage of evaluation data\" (2011-present)."}, {"section_title": "1990-1999: Effective Management and Customization of Education", "text": "The publications of the 1990s discussed quality evaluation primarily at the school level in relation to so-called \"pedagogical management\" (Maiorov, 1998; Potashnik & Moiseev, 1999a , 1999b Simonov, 1995; Tret'iakov, 1997) . The ultimate goal was \"good\" or \"effective\" management of schools, rather than \"quality education\" per se, as the latter was assumed to be essentially different in different schools. Tret'iakov (1997) explains the raising demand for information in the following way:\nThe renewal of the ways in which the schools are managed is connected, first of all, to the development of the system of information-analytical work as the main instrument of management. \u2026 The requirements [to the processes of information production and utilization-authors] increase dramatically in the conditions of democratization of school life. The school leaders' need of information grows, as during transfer to self-regulation the ones who organize the education process seek for new ways to increase the effectiveness of their management activities. (p. 18) The authors suggested that in order to monitor quality school management should develop measurable indicators for the desired outcomes (such as the psychological health of students or the practical relevance of the subjects studied). In fact, \"managing by outcomes\" appeared to be a widely accepted concept (Potashnik & Moiseev, 1999a; Tret'iakov, 1997) , but the concrete definition of the outcomes was still left for the schools to develop. Also, the researchers writing in this period stressed that as the outcomes of diverse, student-centered, and individually tailored education are largely of a qualitative nature (such as the development of personal qualities and attitudes), they are to be assessed and described with qualitative methods (Simonov, 1995; Tatyanchenko & Vorovschikov, 1995) . The assessment of quality was primarily understood as self-assessment (on the level of schools, teachers and students) for immediate feedback and improvement.\nMonitoring quality in schools was also described as a means to meet the expectations of 'customers': \"We should define who the customer of education is, and how education will be used. One should distinguish between the demands for quality of school education that come from students, parents, teachers, job market, society and state\" (Tatianchenko & Vorovshchikov, 1995, p. 9) . Some authors also explicitly connected education to the needs of the economy: \"Education is directly connected to competitiveness. \u2026 Education creates 'human capital,' which in combination with 'material capital' provides for growth in productivity and quality. It has always been true, but it is especially true for the global, technically complex economy\" (p. 46)."}, {"section_title": "2000-2004: The Rise of Broad-Scale Assessments", "text": "The intensification of discussion on quality and its evaluation, particularly around the themes of international studies and the newly introduced Unified State Exam, distinguishes the publications of 2000-04 from the discussions of the preceding period. Russia started participating in international comparative studies of educational achievement as early as the 1990s, with relatively high results in the TIMSS (Trends in International Mathematics and Science Study) undertaken in 1995 and 1999. This, however, attracted little academic attention, and the studies were mentioned only in passing as proof that the quality of education remained high despite the lack of state support. Publications specifically devoted to international studies started to appear at the beginning of the 2000s, when Russia took part in PISA (Programme for International Stu- The articles analyzing international studies in this period were mainly devoted to PISA, pointing to the \"unsatisfactory\" results of Russian students, and explaining differences between Russia and the high-performing countries. The Russian school system was portrayed as being focused on specific knowledge acquisition, while schools in the high-performing (mostly OECD member) countries were described as imparting generic and problem-solving skills. From there, the authors usually continued to discuss how the skills necessary for better results could be achieved. There was also a tendency to value the methodological aspects of international studies and, consequently, to suggest what lessons need to be learned from participation in the studies in terms of both testing techniques and the sociological analysis of education achievement (Kasprzhak, Polivanova, Tsukerman, Mitrofanov, & Sokolova, 2004; Kovaleva, Krasnokutskaia, Krasnyanskaia, & Loginova, 2004) . All in all, a significant number of publications within this period was devoted to testing techniques (Chelyshkova, 2002; Efremova, 2003; Maiorov, 2000) . Surprisingly, these methods were primarily presented as instruments suitable for in-class assessment. At the same time, these publications later contributed to the development of quality evaluation methodology for regional and national level procedures.\nArticles devoted to the USE, which started as a pilot in 2001 and became compulsory throughout Russia in 2009, offered multiple justifications for its introduction (see, e.g., Bolotov, 2004; Efendiev & Reshetnikova, 2004; Kovaleva, 2004; Kuklin, 2004; Smolin, 2004; Zhuravlev, 2004) . They positioned the USE as a strong measure for improving both equality and quality. Through \"objective\" and unified assessment of education achievement in all schools, the USE was said to equalize the chances of school-leavers from all parts of the country to enter higher education, thus improving both geographical and social academic mobility. Moreover, the USE was argued to cut opportunities for corruption in university admissions and to reduce exam stress for school-leavers by offering a single exam for both school graduation and admission to higher education.\nAnother group of authors discussed the role of the USE in standardization: \"The USE content will play (and already plays) the role of a standard\" (Firsov, 2004, p. 193 ; see also Agranovich, 2004, p. 272) . Some suggested that by means of defining and fixing the expected education outcomes through the USE, and then publicizing the results on the school-by-school basis, teachers, school administrations and local and regional authorities would be better motivated to actually follow the state standards in education, and to improve educational materials and teaching qualifications, for example: \"The emergence of a new measurement protected from subjectivity carries a steering effect in itself (effect based on reflexivity, i.e., on the mechanisms of selfevaluation and self-motivation of the participants of the education process,-without an explicit employment of direct regulation from the upper levels of the system)\" (Kuklin, 2004, p. 208) . The statistical data resulting from the USE was viewed by the Russian scholars as enabling \"objective\" and informed policy making across the country, as well as providing an invaluable source of data for education research (see, e.g., Agranovich, 2004; Kuklin, 2004) .\nThe criticisms of the USE mostly related to its actual ability to test educational achievement, the inadequacy of testing as an entrance examination to higher education, the changes that standardized testing might engender in pedagogical practice (such as teaching to the test or the narrowing of curricula), and concerns about increasing stress on students (see, e.g., Bolotov, 2004, pp. 157-160; Firsov, 2004) . It was also argued that the USE might diminish diversity in Russian school education and the opportunities for schools and teachers to tailor their teaching to the students' needs. Some writers suggested that the USE shifted attention from the appropriate organization of the educational process to mere control of its results, and transferred time and other resources from teaching to exam preparation during the last school year (Smolin, 2004; Zhuravlev, 2004) .\nThe discussion on developing diverse quality evaluation techniques in schools, elaborating indicators of quality, and managing by results begun in the 1990s, continued in this period, although its focus started to shift in the direction of using all of these tools for education administration on the regional and national levels (Agranovich, Konstantinovskii, & Loginova, 2003; Kurlov, 2003; Kuznetsov, 2001) . The authors started to criticize the existing data (mainly the census system) as outdated and uninformative, and underscored the necessity to complement it with more comprehensive sources that take account of socioeconomic factors. Gokhberg and Kovaleva (2004) pointed to the importance of the state system of data collection as both a means and a precondition of regulation. They stressed such desired characteristics of data as international comparability and compliance with the \"consolidated recommendations of UNESCO, OECD, and Eurostat on collecting statistical information in education\" (p. 275), and insisted that statistical data must be complemented with sociological surveys, results of school leavers in the state examination, and data from international comparative studies on educational achievement. At the same time, critics pointed to the essential difference between two approaches: quality evaluation and information openness to the public in order to provide the school with information for self-regulation, and quality evaluation to increase state control over schools. They warned that the choice of evaluation instruments determines whether those will be used primarily for support or for control (see Froumin, 2000) ."}, {"section_title": "2005-2010: A Systemic Approach to Quality Evaluation", "text": "The next period, discussions around the USE continued, although now they focused more on the exam as an instrument of quality assurance and an element of a broader national system of evaluation of quality in education (see, e.g., Astapov, Khlopova, & Semenko, 2008; Bolotov, 2007; Kovaleva, 2006; Lebedev, 2009a) . The authors stressed that the main asset of the USE as a measure of national educational quality lies in its ability to provide comparative data. At the same time, they pointed out that as such the USE does not offer any explanations for different learning outcomes and hence needs to be complemented with other, explanatory data to serve administrative purposes. Part of the discussion of whether information on students' educational achievement (including their USE scores) is a proxy for the quality of teachers' and schools' work was related to the introduction of new performance-based payment schemes for teachers (see, e.g., Fomina, 2009; Iamburg, 2008; Il'ina, 2009) .\nThe pervasive characteristic of this period is the systemic approach to evaluation. Numerous publications described cases of municipal and regional quality evaluation systems, (e. g., Agranovich, 2006; Karpushin, Gadzhieva, & Petrogradskih, 2006; Shogenov, 2007) , and others discussed the development of a national quality evaluation system (Bolotov, 2007) . Moreover, there were publications that analyzed systems of quality assurance in foreign countries (Lenskaia, 2008; Valdman, 2009 ). These discussions differed from those of the 1990s in one important way: while the earlier publications viewed quality assurance mostly as a domain of individual schools' decision making, the works of the 2000s addressed it as a matter of national and regional education governance, with comparisons between schools and regions serving as a means to quality evaluation and its enhancement. Hence, external assessment of schools was emphasized at the expense of internal self-evaluation. The objectivity and transparency of evaluation were positioned as its key desirable features.\nThe public control and participation in school governance, discussed in the literature of this period, served either as an addition or as an alternative to the function of state control. In other words, the public was expected to play a greater role in ensuring that schools provide quality education. The proponents of public participation justified it by the necessity to understand customers' needs and cater for them, claiming that only customers can objectively assess the quality of education (e.g., Lebedev, 2009b; Kosaretskii, 2008, p.107) . The key participation mechanisms discussed by the authors were: school boards with public representation, evaluation and approval of school strategic documents by the public, and school websites and selfevaluation reports open to the public (Batrova, 2010; Kosaretskii, 2008) . Publicizing information of the results of diverse contests and rankings of schools (e.g., in national contests among innovative education programs developed by schools on the basis of the new state education standards, or in a regional ranking of schools based on the USE scores of graduates and their admission to prestigious universities) were regarded as a means to provide customers with information for making better choices, and thus to enhance public influence on school quality improvement."}, {"section_title": "2011-2014: Towards a More Nuanced Utilization of Evaluation Data", "text": "In this period, issues of social equality and support to socially disadvantaged schools and students became prominent in the Russian literature on quality evaluation, particularly within the theme of using evaluation data for governance and discussions around the USE. A \"good\" and \"effective\" school came to be defined as the one that helps disadvantaged students, and successfully educates \"weak\" students rather than merely benefits from the existing abilities of highperforming students (Froumin, Pinskaia, & Kosaretskii, 2012; Valdman, 2012) . Some authors also emphasized the importance of understanding the social context for the correct interpretation of school results (Pinskaia, Kosaretskyii & Krutii, 2012) .\nThe discussion about control versus support through evaluation begun in the early 2000s continued in this period. However, support was now envisioned not in terms of providing information for schools' self-management, but as identifying weak or problematic schools in need of help from regional and national authorities:\nThe leaders [among the schools -authors] are self-sufficient educational players, they are not so much in need of additional resources (which, of course, please everyone), they rather need true autonomy, trust and reduction of bureaucratic pressure (amount of control and paperwork for the authorities). \u2026 But the \"weak\" schools need actual assistance. They will hardly manage a difficult situation on their own. This is where we need support programmes-targeted, limited in time, and based on the analysis of the factors that underlie the \"weakness\" of a particular school. (Valdman, 2012, pp. 94-95) The authors criticized the use of the USE data for punishing and rewarding teachers, school principals, and municipal and regional authorities, and argued that this data alone is not sufficient to understand the quality of education (Bochenkov, 2013; Bochenkov & Valdman, 2013; Bolotov & Valdman, 2012; Pinskaia et al., 2012) . Some of these publications focused specifically on erroneous interpretations of the USE data and the correct ways to use it.\nSome publications of this period argued that schools were already overburdened with evaluation procedures (see, e.g., Kokareva, 2014) . Nevertheless, external evaluation, rather than self-evaluation among schools and teachers, was widely regarded by other authors as indispensable for quality assurance. Ivenskikh and Ivenskikh (2011) in the article \"Culture of responsibility as the foundation for creating the system of quality\" pointed out the specific nature of educational service-it is not simply \"consumed,\" but \"coproduced\" by the teacher and student. They claimed that continuous independent evaluation was the key element in developing the \"culture of responsibility\" in students, teachers, parents, and schools as institutions."}, {"section_title": "Summary and Interpretation of the Results", "text": "The literature of the 1990s was concerned with self-evaluation of schools and by schools, assuming them to be self-motivated as well as self-sufficient to explore and consequently, to improve quality. The practice of self-evaluation was explicitly connected to democratization in terms of autonomy and empowerment of school management, as well as individualization expressed as increased concern for the needs of diverse students. The increased autonomy of schools and regions in the 1990s combined with insufficient federal funding for education empowered principals as school managers, giving them significantly more independence as well as new responsibilities and concerns. Hence the literature on school management started to appear, proposing quality improvement methods suitable for diverse schools.\nQuality evaluation was also envisioned in a market-friendly manner and embraced the objective of public accountability interpreted primarily as seeking information on the demands of concrete customers, and feedback for management and teachers to better understand the effects of their decisions and actual work. While authors emphasized the role of school management in understanding customer needs, the decision-making powers remained with the school rather than transferred to the customers, the public or the state. Moreover, whenever indicators of quality were discussed, they often appeared in qualitative, rather than numerical, terms and were expected to arise from school-based development work.\nIn the 2000s, the academic community increasingly started to elaborate on the nationwide tasks that evaluation can and should address. From \"improving the quality/effectiveness of managing schools,\" the academic discourse has swiftly switched to \"managing the quality of education.\" The idea of educational quality as diverse, based on \"customer\" needs, as context-bound and thus undefinable in general terms, was transformed into the concept of quality as captured in statewide standards and reflecting international ideas about what schools should teach (as promoted by international comparative studies). At the same time, discussions on quality assessment and monitoring after the 2000s were still building on what was developed in the 1990s: the ideas that good management (or governance) should be evidence-based, that desired outcomes should be defined in a measurable way and accompanied by a set of indicators, and enthusiasm for new technologies enabling \"objective\" analysis of data and processing of unlimited amounts of information.\nThe main argument proposed in the 2000s was that objective and independent evaluation can ensure greater equality through facilitating access of all school-leavers to higher education, and make the quality of school education more even across the country. Within this logic, evaluation started to be viewed as a steering mechanism that was also connected to incentivizing schools and teachers through performance funding and payment schemes. The availability of comparable data was discussed as beneficial for evidence-based policy making and for the modernization of Russian education (policy) in accordance with international standards.\nThe issue of self-evaluation remained in focus, but as a source of information for actors external to the school, such as in the form of self-evaluation reports publicized on school websites. The instruments and organizational forms of public participation started to resemble the tools of public control over school, and often appeared as a form of activity enforced from the outside independently from the school's position. The tools that produce depersonalized, \"objective,\" often numerical, regional and/or national level data for the state and the public came to be valued over contextualized measurement and school-based indicators.\nThe academic discussion was not devoid of critical voices. These opposed increased state control and regulation through evaluation as threatening diversity, customization of education and school autonomy, all highly valued in the 1990s. While critical voices manifest the diversity of topics and perspectives covered in the Russian academic literature on quality evaluation, some important themes were never brought into the discussion within the limits of our search results. For example, the issues of decreasing trust in schools and teachers, and the apparent shrinking of their autonomy, were not addressed in any critical appraisals of public participation in school governance. Neither did we encounter any thorough analysis of the Soviet experience of education governance or quality assurance and evaluation. Soviet practices were either totally discredited as outdated, or referred to as some \"gold standard\" in education. Similarly, the use of international experience was not thoroughly reflected upon, and we identified no source in Russian that would analyze the formation of quality assurance policies in terms of domestic and foreign influences. From a different angle, critical discussion of foreign practices and norms was usually limited to explanations of contextual factors forming specific Russian educational practices rather than critically examining international recommendations per se. This acceptance of foreign norms was usually justified through the discourse of international competitiveness: if Russia wishes to catch up with the OECD countries economically and scientifically, it has to play by international rules and closely monitor the latest Western trends in education. Finally, the academic sources reviewed offered no analysis of the values and assumptions underlying different systems of evaluation and quality assurance. Such phenomena as customer orientation in education or the pursuit of international competitiveness were described as a context for policies rather than as a value-laden understanding of reality and future goals."}, {"section_title": "DISCUSSION", "text": "An overview of the Russian arguments for evaluation shows their significant resemblance to the New Public Managementand governance at a distance logic. Comparable to the NPM, we can distinguish a clear emphasis on setting targets and defining and measuring outcomes while granting operational autonomy to the schools, empowering consumers and introducing greater accountability of schools to the public, and using performance-based payment schemes to incentivize self-improvement. At the same time, evaluation is assumed to promote a particular \"culture of responsibility\" and govern teachers' as well as students' ways of thinking and acting. Data production mechanisms and publication of evaluation results serve the same ends, also enabling such instruments of governance at a distance as comparisons and benchmarking. It is striking that many Russian authors, particularly recently, approach the tasks of evaluation from a viewpoint that is seemingly identical to the quality of education and its measurement agenda that circulates globally. However, for many of them an important starting point was to enable a firm breakaway from Soviet practices and, lately, to turn Russia into a country with \"modern,\" internationally applied tools of regulation.\nThe democratization of society and the development of a market economy in the 1990s meant that schools were to become accountable to the public, as opposed to the state. Accountability to the state was unimaginable in the political context marked by a strong desire to depoliticize and deideologisize the educational system and to erase the omnipresent authoritarian state reminiscent of the past. The academic discourse on empowering management, self-evaluation and customization appeared in the early 1990s, before the NPM's arrival to the scene as a government technology of the Russian state. Moreover, those seemingly neoliberal, \"NPM-istic\" practices still lacked in two important characteristics central to the neoliberal audit culture-performance measurement as a standardized, numerical procedure, and the practice of external audits. The latter is important to keep in mind since neoliberalism is an ideology of a small but strong state that governs through market mechanisms at a distance (Harvey, 2005) . The authors who wrote in the 1990s appear as antistatist in the sense that they wanted the schools to receive, to a greater or lesser extent, full freedom of operation. However, the ongoing reconsolidation of state power through evaluation (see Piattoeva, 2015) is largely supported in many recent academic discussions that moved from exploring school-level management to evaluation of the national education system as a whole.\nThe controversies apparent in the Russian academic discussion raise the question as to how to understand the political ends and the fundamental values that underlay those practical suggestions. Were the Russian academic community or some of its representatives, exposed to the NPM techniques at a very early stage, converted and began to speak on their behalf even before NPM became an important source of statecraft for the Russian leaders? Alternatively, should the academic debates be interpreted within a different discursive and ideological frame, namely that of democratization and empowerment of the grassroots level regardless of the frequency of such market-oriented terms as customers and consumers, and thus as an intellectual counterreaction to the position of the Soviet state? Overall, what appears as strong elements of the language and tools of NPM cannot necessarily be traced back to that source, underlining, as we already argued in the beginning, the need to avoid a diffusionist mode of thinking that conflates, often erroneously, practical means with the underlying \"regimes of truth\" (see Kipnis, 2008) . There is always a possibility for \"[a] relatively independent inventions of governing practices [that] can be masked by the borrowing of labels and terms to give an \"international\" gloss to what was really being thought locally\" (ibid., p. 285). At the same time, there is a chance that local social and political circumstances help to diffuse particular, travelling technologies of governing without absorbing the ideologies that invented them (ibid.). Otherwise, how else to explain the fact of the strong presence of the theme of equality as an objective of national-level evaluation practices in the Russian academic discourse. The materials analyzed in this article point to the importance of exploring this type of questions in subsequent work. Such research tasks lie at the heart comparative of education as an inquiry into the transfer, translation, and transformation of educational processes."}, {"section_title": "AUTHOR BIOS", "text": "Galina Gurova is a doctoral candidate; her dissertation examines the impact of quality evaluation policies on general education in Russia. School of Education, University of Tampere, Finland.\nDr. Nelli Piattoeva is a university lecturer at the School of Education, University of Tampere, Finland; her research deals with the politics performance measurement in Russian general education.\nProfessor Tuomas Takala specializes in comparative education and education policies in developing countries. School of Education, University of Tampere, Finland."}]