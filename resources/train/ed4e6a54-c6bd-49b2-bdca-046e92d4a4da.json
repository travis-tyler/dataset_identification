[{"section_title": "Abstract", "text": "This paper examines a common form of entry restriction: occupational licensing. The paper studies two questions: first, how occupational licensing laws affect the distribution of quality, and second, how the effects of licensing on quality vary across regions of differing income levels. The paper uses variation in state licensing requirements for teachers and two national datasets on teacher qualifications and student outcomes from 1983-2008. Two measures of quality are used: the qualifications of candidates entering the occupation (input quality) and the quality of service provided (output quality). Results show that more restrictive licensing laws-in the form of certification tests required for initial licensure-may lead some first-year teachers of high input quality to opt out of the occupation.\nIn the sample of teachers who remain in the occupation multiple years, stricter licensing appears to increase input quality at most quantiles of the teacher quality distribution. Output quality, as measured by student test scores, also changes with stricter occupational licensing, revealing a widening of the distribution. For most forms of licensing studied, input and output quality improvements due to stricter licensing requirements occur in high-income rather than low-income school districts."}, {"section_title": "Introduction", "text": "Occupational licensing affects nearly 30% of the US labor force (Kleiner and Krueger 2010) , a larger proportion of workers than are in unions or covered by minimum wage laws, and over 800 occupations are licensed in at least one state (Kleiner 2006) . Doctors, lawyers, teachers, barbers, and, in some states, even interior designers, auctioneers, frog farmers, fortune tellers, and florists, are required to have a license to legally practice. Proponents of licensing argue that these laws decrease informational asymmetries by preventing unqualified candidates from practicing, thus raising the lower tail of the quality distribution, providing a minimum guaranteed level of quality and safety to consumers. 1 Opponents argue that licensing merely secures higher rents for those in the occupation, raising prices and, in particular, harming low-income consumers who may not be able to afford their preferred level of service.\nWhile studies have shown that licensing raises wages, raises prices for consumers, and deters entry, little is known about the effects of licensing laws on the distribution of quality or about how licensing laws differentially affect consumers of low vs high income. Previous empirical studies of the effects of occupational licensing on quality have focused on average quality for the average consumer and most have found that licensing has no significant effect. However, from a public interest standpoint, occupational licensing is intended to eliminate the worst candidates from entering into an occupation (regulating input quality) or to prevent the worst outcomes from occurring (regulating output quality). 2 Therefore, in this paper I argue that effects on average quality may mask important effects of licensing. In particular, licensing may have little effect on average quality but still move the tails of the quality distribution.\nMoreover, price increases from occupational licensing may more negatively impact low-income consumers than high-income consumers. While these features of licensing have been modeled theoretically-Leland (1979) and Arrow (1963) presented models where licensing affects the distribution of quality, and Shapiro (1986) and Friedman and Friedman (1962) highlighted that licensing may differentially affect low vs.\nhigh-income consumers-they have received little empirical attention. This paper is a first attempt to answer these questions empirically.\nI focus on licensing in the market for teachers, using data on 26 years of state requirements for teachers and two national datasets on teacher qualifications and student outcomes. The measures of licensing stringency I employ are indicators for whether a given state in a given year required teachers to pass certain certification tests (basic skills tests, subject tests, and professional knowledge tests) prior 1 Many proponents present consumer safety as an argument for licensing. Ballou and Podgursky (1998) explain, \"The [professional teacher organization] frequently resorts to argument by analogy, comparing teaching to medicine...Doctors put in years of training in medical school and residencies before achieving full professional standing. They must pass rigorous licensing examinations. Why should we expect less of teachers?\" Such arguments are frequently used in other professions as well, such as in the recent Florida case, where interior designers, lobbying against a bill that would have de-regulated their occupation by no longer requiring licenses, argued that the actions of unlicensed designers would lead to furniture in jail cells being used as weapons, hospital fabrics spreading disease, and flammable rugs spreading fires, \"contributing to 88,000 deaths every year\" (Campo-Flores 2011). The interior designer lobby won the debate and the profession remains licensed in Florida. Other proposals in Florida at this same time to deregulate other occupations, such as auctioneers, failed as well.\nto initial licensure. 3 Teacher qualifications are measured by the strength of teacher's undergraduate institution using data on 60,000 teachers in the Schools and Staffing Survey (SASS), serving as a proxy for input quality, or the quality of candidates entering the occupation. Student outcomes are measured by eighth grade math scores from over 300,000 students administered the National Assessment for Education Progress (NAEP) exam, and serve as proxy for output quality, or the quality of the service provided.\nThe teaching profession provides a useful setting for studying the effects of licensing for several reasons.\nFirst, teacher licensing laws have been a major focus of public policy debates in recent years (Mehta 2013; Nadler and Peterson 2009; Weddle 2014) and in the past (Darling-Hammond 1997; Ballou and Podgursky 1998; Gardner 1983) . Second, I observe measures of quality, which is rare in other occupations (Kleiner 2006; Gross 1986 ). Third, the use of licensing test laws varied greatly across states and across time from 1983-2008, allowing for identification of the effects of this particular form of licensing. Fourth, teacher certification tests represent a real obstacle to some candidates. Also, these certification tests must be passed prior to initial licensure for teachers seeking standard certification and, in most states, for teachers seeking alternative certification, making it simple to identify which subgroup of teachers were affected by law changes. 4 Finally, certification test laws are easily quantifiable. Coursework or degree requirements, while potentially more costly to candidates than certification tests, are difficult to translate into a measure of licensing stringency.\nTo estimate the effects of certification test laws on the distribution of quality, I adopt the grouped quantile regression approach of Chetverikov, Larsen, and Palmer (2013) . As demonstrated in Chetverikov, Larsen, and Palmer (2013) , grouped quantile regression is more robust than standard quantile regression in settings where the researcher has micro-level data on outcomes and wishes to measure the effect of a group-level treatment, as in this paper. Under standard difference-in-differences assumptions, this approach provides a consistent estimate of the effect of certification test laws on the distribution of teacher quality within each state. I also employ a difference-in-differences approach to estimate how occupational licensing laws differentially affects average quality in high vs. low-income areas. I compute these effects for measures of input and output quality, and do so both for first-year teachers alone and well as a pooled sample of new and experienced teachers, allowing me to form a synthetic panel that exploits additional variation in state licensing requirements. I find that subject area certification tests for initial licensure lowered the upper tail of the input quality distribution among first-year teachers, suggestive that these licensing requirements may have driven some high-qualified candidates from the occupation. However, when including the sample of 3 In much of the occupational licensing literature (Kleiner 2006) , the term \"licensing\" refers to mandatory requirements that must be met in order to legally practice in the profession, while \"certification\" refers to a qualification that a professional may obtain but which is not required in order to legally practice. Given that in the teaching profession licensing exams are referred to as \"certification\" exams, I use the both terms to refer mandatory requirements. 4 This is not the case with other licensing requirements, such as specific coursework requirements or a requirement to have a master's degree within a certain number of years, which differ by state and by whether or not the teacher was regularly or alternatively certified; in some states, a change in such laws would affect a potential teacher after completing a bachelor's degree, while in others, a change in requirements would affect the candidate midway through an undergraduate program.\nteachers who stayed multiple years in the occupation I find positive effects that are relatively constant across the distribution of quality. I also find that, for first-year teachers, certain certification tests are associated with a decrease in the lower tail and an increase in the upper tail of the distribution of output quality, suggesting that the student test score distribution widens under stricter licensing requirements.\nFor most of the effects I study I find that the estimates are robust to the inclusion of additional controls, including time and experience trends. I also perform an event study that suggests that the primary impact of certification test laws on quality occurs two or more years after the change in certification requirements.\nIn examining how licensing requirements differentially affect areas of high vs. low-income, I find that any positive effects of teacher certification tests accrue primarily to higher-income school districts. This is true for both input and output quality effects for most types of teacher certification tests. Finally, I find some weak evidence that when certification tests are in place, lower-income school districts may substitute away from hiring licensed professionals by instead hiring emergency-certified teachers or increasing class sizes.\nPrevious research has not found positive effects of occupational licensing on average quality in the teaching profession. Kleiner and Petree (1988) ; Goldhaber and Brewer (2000) ; Rockoff, Jacob, Kane, and Staiger (2008) ; Kane, Rockoff, and Staiger (2008) ; and Guryan (2008, 2004) found no relationship between licensing requirements and students' standardized test scores or other measures of teacher quality. Berger and Toma (1994) and Hanushek and Pace (1995) reported negative impacts of licensing. 5 Ballou and Podgursky (1998) presented one reason why average teacher quality may be lower with licensing than without: the costs (monetary or time costs) of licensure may induce those candidates with higher outside opportunities to choose a different career. Wiswall (2007) and Sass (2011) found evidence of this effect for teachers and Ramseyer and Rasmusen (2013) found a similar effect for lawyers.\nStudies have also found non-positive effects of licensing on quality for electricians (Carroll and Gaston 1981) , contractors (Maurizi 1980a) , dentists (Kleiner and Kudrle 2000; Carroll and Gaston 1981) , and physicians (Kugler and Sauer 2005) . To the best of my knowledge, my paper is the first empirical attempt to document the effects of occupational licensing laws on the distribution of quality.\nTwo previous empirical studies touch on the question of how occupational licensing differentially affects high vs. low-income areas, relating to the work of Friedman and Friedman (1962) and the the theoretical model of Shapiro (1986) , which suggested that licensing laws could benefit higher-income consumers at the expense of lower-income consumers. Currie and Hotz (2004) found evidence of this effect, demonstrating that tighter educational requirements for child care professionals led to higher quality for children who received care, but also led to price increases resulting in less children being served. Kleiner (2006) found that more restrictive licensing requirements in dentistry tended to benefit high income states and had no effect on low-income states. 5 Hanushek and Pace (1995) found that state licensing requirements lowered the probability of teachers completing additional training, which can be viewed as another measure of teacher quality.\nSeveral studies have presented evidence of the effects of licensing on entry into the occupation (see Law and Marks 2009; Federman, Harrington, and Krynski 2006) and I do not focus on these effects in this study. Similarly, I do not focus on wage effects, as the non-negative relationship between licensing stringency and wages has been shown in previous work. 6 Maurizi (1980b) and Kleiner and Petree (1988) found that licensing had no impact on the pay of nurses and teachers, respectively. Positive impacts of licensing on wages are found in more recent work, including Guryan (2008), Kleiner (2000) , Kleiner and Kudrle (2000) , Tenn (2001), and Kugler and Sauer (2005) , who found that licensing increased the pay of workers in the educational, medical, and legal professions. Analysis the political economy of occupational licensing is found in Stigler (1971) , Mulligan and Shleifer (2005) , and Kleiner (2013), and evidence on the effects of occupational licensing on industry dynamics and competition is found in Zapletal (2013) .\nThe remainder of the paper proceeds as follows. Section 2 provides a background on the use of teacher certification tests as a form on occupational licensing and provides a description of the state certification requirements data. I also provide a description of the measures I use to proxy for input and output quality. Section 3 explains the empirical approach for measuring effects on the distribution of quality and for estimating effects on high vs. low-income areas. Section 4 presents the main results: distributional and heterogeneous effects of certification tests requirements on input and output quality, as well as an analysis of how low-income school districts may be substituting away from hiring licensed professionals.\nSection 5 presents an event study of the timing of test law changes, and Section 6 concludes.\n2 Background and data on teacher certification laws and quality measures"}, {"section_title": "Teacher certification laws", "text": "Competency tests for teachers were used in many states in the early twentieth century (Rudner 1987) .\nOver time, testing requirements were replaced by educational requirements for prospective teachers, such as a bachelor's degree or specific education coursework. In the late 1970s and early 1980s, states developed a renewed interest in teacher testing, sparked by professional organizations, such as the American Association of Colleges for Teacher Education (AACTE), and by the influential report, \"A Nation at Risk,\" (Gardner 1983 ) commissioned by the Department of Education, which advocated for educational reform, arguing that education professionals too often came from the bottom quartile of high school graduates.\nAs certification tests became more widespread from the 1980s to today, they evolved into three categories: basic skills tests (testing listening, reading, writing, communication, and mathematics), pro-6 Kleiner (2006) pointed out that raising wages may be socially beneficial, as it can provide greater incentive for workers to invest in human capital (such as through additional education or training) because they will be able to reap greater returns from doing so.\nfessional knowledge tests (testing pedagogical skills and knowledge), and subject matter tests (testing specific subjects). 7 Figure 1 displays the proportion of states requiring each type of certification test during the years 1983 to 2010. 8 I manually compiled data on teacher certification test laws from the following teacher certification manuals, which list historical details of certification requirements for each state: AACTE (1990 AACTE ( , 1991 AACTE ( , 1993 AACTE ( -1996 , Boydston (1995 Boydston ( -1999 Boydston ( , 2001 Boydston ( -2010 , Coley and Goertz (1990) , Goddard (1983 Goddard ( -1993 , Goertz (1986 Goertz ( , 1988 , NASDTEC (1991 NASDTEC ( , 1994 NASDTEC ( , 1996 NASDTEC ( , 1996 NASDTEC ( , 2000 NASDTEC ( -2002 , NASDTEC Knowledgebase (2003 Knowledgebase ( -2010 , Neuweiler et al. (1988) , Rudner (1987) . the National Board for Professional Teaching Standards (NBPTS), argued for even stricter certification requirements (NCTAF 1996) . Opponents of this movement argued that increasing the restrictiveness of licensing requirements would only drive away more qualified applicants with higher opportunity costs, inducing them to turn down teaching for alternative careers (Ballou and Podgursky 1998) .\nIn the most recent decade, as seen in Figure 1 , the use of basic skills tests and professional knowledge tests decreased, and the use of subject matter tests increased, in part due to the No Child Left Behind Teacher certification exams do represent a real obstacle to at some candidates, as evidenced by the fact that some students do not pass these exams. The nationwide pass rate was 93% in 2000 and 96% in 2006 (Paige et al. 2002 , Duncan and Ochoa 2002 . However, much lower pass rates were reported in the past. Rudner (1987) , who did not report the overall pass rate, reported that in 1984 the pass rate was 76% for whites and 42% for non-whites on what was then a commonly used basic skills exam. Note that the test could be a costly obstacle to some even if the reported pass rate were 100%, as this pass rate is an equilibrium outcome of test difficulty and candidates' preparation effort. Further evidence that certification tests are a challenge to at least some candidates is found in the fact that test preparation companies offer numerous study products to aid students in preparing for the Praxis exams, the set of exams used by most states today. 1988, 1994, 2000, 2004, and 2008 to a nationally representative sample of teachers. 10 The dataset provides information about the school district in which a teacher is employed, such as the percent of students eligible for free school lunch, which serves to proxy for the 9 Public versions of SASS are available at nces.gov. I use the restricted-use SASS sample, which allows me to link teachers to their undergraduate institution. The restricted-use data is available in a secure fashion to researchers who apply for access through nces.ed.gov/pubsearch/licenses.asp. Note that, in compliance with NCES disclosure requirements, all sample sizes from raw NCES data reported herein are rounded to the nearest 10. 10 These numbers refer to the year the school year ended. I follow the same convention throughout the paper. An additional SASS survey was administered in 1991 but did not contain information on teachers' undergraduate institutions, income level of the district. The data also contains information about individual teachers, such as their years of teaching experience, the state in which they teach, and their undergraduate institution. The undergraduate institution is recorded as a Federal Interagency Committee on Education (FICE) code, which I merge with data on the average SAT score of entering freshmen for the undergraduate institution of the teacher, from a survey conducted by the Higher Education Research Institute (see Astin, Green, Korn, and Maier (1983) and the description in Angrist and Guryan (2008) ). A single observation in the SASS data represents a particular teacher and the selectivity of that teacher's undergraduate institution, which I then link to state certification test laws for initial licensure for the specific year in which the teacher was certified. I then treat this observation as an independent draw from the teacher input quality distribution in a given year and state. 11 (Gross 1986 ). Similar measures of quality to that which I use have been used in Bacolod (2007) , , Hoxby and Leigh (2004) , Figlio (1997) , and Guryan (2008, 2004) . This input quality measure is not meant to capture everything about an individual teacher's qualifications; instead, it is meant to serve as some measure of the impressiveness of a candidate's resume to employers when the candidate enters the job market. It is reasonable to assume that the selectivity of a teacher's undergraduate institution is correlated with the prestige of the teacher's resume."}, {"section_title": "Input and output quality measures", "text": "Summary statistics for the main variables of interest from the SASS dataset are displayed in Table   2 . The mean and standard deviation of the teacher input quality measure are 916 and 107 SAT points, respectively. In the analysis performed below, I standardize this quality measure so it has mean zero and variance one within the sample, meaning all quality results are reported in terms of standard deviations.\nI limit the sample to teachers with less than 12 years of experience. I refer to the years in which the SASS survey was administered as survey years. In the analysis below, I group together teachers whom I observe in the same state and year and of the same experience level, and I refer to this group as a cohort. For example, a teacher who began teaching in the 1992-1993 school year and who was surveyed in 1993-1994 school year would be in the cohort of teachers with two years of experience. I drop cohorts with fewer than ten teachers recorded. Table 2 shows that the number of teachers in a state-year-experience level cohort, described below, ranges from 10 to 113, with a mean of 33. The percent of students in the school district eligible for free lunch is 39% on average. Summary statistics for other covariates from the SASS dataset are reported in Appendix Table 6 .\nTo proxy for output quality I use public school student test scores from the eighth grade math National Assessment of Educational Progress (NAEP) exam from the NCES. 12 The test was administered in 1990, 1992, 1996, 2000, 2003, 2005, and 2007 . The NAEP data contains information on student test scores and other covariates, as well as information on each student's teacher. 13 A single observation in the NAEP data represents a student test score, which I link to state certification test laws for initial licensure for the specific year in which the student's teacher was certified. I then treat this observation as an independent draw from the output quality distribution in a given year and state. 14 Summary statistics are displayed in the lower half of Table 2 . Observe that student scores on the NAEP eighth grade math exam are 262 on average, with a standard deviation of 39. As with input quality, in the analysis below, I standardize these test scores to have mean zero and variance one within the sample, so all results are reported in standard deviation units. As with the SASS survey, I refer to years in which the NAEP test was administered as survey years, and to students being taught by teachers 12 Public versions of NAEP are available at nces.gov. I use the restricted-use NAEP sample, which allows me to link each student to the number of years of experience of the student's teacher. The restricted-use data is available in a secure fashion to researchers who apply for access through nces.ed.gov/pubsearch/licenses.asp. 13 The data does not record raw test scores for students, but rather reports five plausible scores calculated using student responses and item response theory (IRT). As explained in Kolstad (2006), these five scores in the NAEP data represent independent draws from the posterior distribution of scores for students with similar item response patterns and similar observable characteristics. I take the average of the five IRT draws, as in Fryer (2011), and use this to proxy for an output quality draw. See also Jacob (2007) for a discussion. 14 To measure output quality, it would be desirable to translate student test scores into a measure of teacher value-added by aggregating to the teacher level, as in , for example. However, NAEP survey designers claim that the survey is not representative at the teacher level and warn against aggregating to the teacher level (Rogers and Stoeckel 2008) . Also, in many cases very few students assigned to a particular teacher appear in the dataset. Finally, as the data is in the form of a repeated cross-section rather than a panel, no baseline measure of student ability is available, which show greatly increases the explanatory power of teacher value-added measures. Therefore, I focus on the distribution of student test scores rather than teacher value-added, and treat each realization of an NAEP test score as though it were a draw from the output quality distribution.\nof a given experience level as a cohort. For example, students who were tested in 1994 and who were taught by a teacher who began teaching in the school year ending in 1993 would be in the cohort of students taught by teachers with two years of experience. I drop cohorts with fewer than ten students recorded. The number of students in each state-year-experience cohort ranges from 10 to 1,439, with a mean of 203. The NAEP data also contains the percent of students eligible for free lunch, reported in bins rather than as continuous variables. A school is classified as having either 0-5%, 6-10%, 11-25%, 26-50%, 51-75%, or 76-100% of its students qualifying for free lunch, and the distribution (not shown)\nis roughly uniform across quartiles. Summary statistics for other variables from the NAEP dataset are found in Appendix Table 6 .\nIt is impossible to link the SASS and NAEP datasets. This is less problematic in this study than in other contexts, however, because I do not wish o derive a link between input and output quality or to estimate an education production function (Hanushek 1979) . Instead, the focus of this study is simply to determine whether or not teacher certification tests have any detectable effect on the distribution of quality-either for input or output quality-and whether average quality effects differ for high vs. low income areas.\nI use one additional data source in the regressions in Section 4.5 studying the effects of teacher certification laws on pupil to teacher ratios. This dataset comes from the NCES Common Core of Data (CCD) from 1987-2010 and is available publicly on the NCES website. Summary statistics are found in Appendix Table 6 ."}, {"section_title": "Estimating distributional and heterogeneous effects", "text": "In this section I present several approaches to identifying the effect of teacher certification tests on quality.\nEach of these models compares a treatment group (e.g. a state with a certification test requirement) and control group (e.g. a state with no certification test) before and after a change in teacher certification test laws, controlling for state and year fixed effects. I first focus on the case of the input quality distribution. To clarify the estimation approach, I also focus first on first-year teachers and then expand the approach to incorporate other levels of experience. I then explain the approach for estimating the effects on the output quality distribution and then the approach for identifying heterogeneous effects of licensing requirements on quality differing by income level."}, {"section_title": "Estimating distributional effects of teacher licensing requirements", "text": "I focus first on the case of first-year teachers. Recall that the SASS and NAEP were only administered in certain years, and hence records for first-year teachers include only those teachers who began their career during a survey year. Recall also that teacher input quality corresponds to the selectivity of the teacher's undergraduate institution (as measured by the averaged SAT score of entering freshmen). I estimate regressions of the following form: A comparison between two states in two survey years illustrates the interpretation of the model. The control state never adopts a teacher testing law. The treatment state adopts a law in the following survey\nyear. The regression model above will compare input quality in the treatment state before and after to that in the control state before and after. The identifying assumption of this model is that unobserved state-year specific factors (\u03b5(\u03c4, \u03b7 st )) are uncorrelated with the incidence of state certification laws. While it is impossible to rule out all violations of this assumption, one robustness test of (1) can be performed by including state-specific linear time trends, yielding the following model:\nEquation (2) controls for unobserved factors that may affect the quality distribution and that change continuously over time, allowing for a test of the parallel trends assumption required for identification in difference-in-differences models (See Angrist and Pischke 2009). If equation (1) is well identified, one would find similar estimates of the effects of licensing on quality from (1) and from (2).\nThis quantile-based model is a special case of the general grouped instrumental variables quantile regression estimator derived in Chetverikov, Larsen, and Palmer (2013) , which extends the Hausman and Taylor (1981) estimator to quantile regression settings. The regression model in (1) is also a special case of the minimum distance estimator of Chamberlain (1994) and can be estimated using ordinary least squares. Chetverikov, Larsen, and Palmer (2013) demonstrated that the grouped quantile regression approach yields consistent estimates of \u03b4(\u03c4 ) even in settings in which standard quantile regression would be inconsistent. 15 This approach also has the advantage of being simple to implement given that, unlike standard quantile regression, the model is linear and hence state and year effects can be linearly differenced out. 16\nTo incorporate data from other experience cohorts, I modify (1) by writing the \u03c4 th quantile of input quality of teachers in state s who had c years of experience when they were surveyed in survey year t as\nwhere \u03b3 s and \u03bb t are as above, and \u03b1 c represents a cohort fixed effect (the average quality of teachers with c years of experience (1), comparing teachers of the same cohort in different states across survey years. The identifying assumption of this model is that any unobserved shocks affecting the distribution of quality for teachers who in survey year t had been teaching for c years in state s are uncorrelated with state certification laws (i.e. \u03b7 stc must be uncorrelated with Law stc ).\nOne concern with pooling all experience cohorts is that the experienced teachers, for example, those with five years of experience, who are present in survey year t consist of a group which has self-selected to remain in the profession five years. This is not a problem if the experience/cohort effect does not differ by state, because this effect is controlled for by \u03b1 c . However, if the effect of experience on quality differs by state, and if this effect is related to policy changes occurring simultaneously with changes in teacher certification requirements, ordinary least squares estimates of \u03b4 would be biased. One specification check 15 The standard quantile regression model of Koenker and Bassett (1978) solves the following problem for a given \u03c4 :\nwhere q ist represents the individual-level data on teacher i in state s in year t and where \u03c1\u03c4 (\u00b7) is a \"check\" function of Koenker and Bassett (1978) , i.e. \u03c1\u03c4 (x) = (u \u2212 I{x < 0})x. Unlike the grouped quantile approach, standard quantile regression does not allow for additive group-level unobservables (\u03b5(\u03c4, \u03b7st)). 16 I also estimated the standard quantile regression analog of (1) (i.e., assuming \u03b5(\u03c4, \u03b7st) = 0) and found it to be more than 100 times slower than the grouped approach.\nI employ in Section 4 below is to replace \u03b1 c above with state-specific returns to experience, \u03b1 c + \u03b1 s c, similar to the state-specific linear time trends in (2).\nThe model in (1) above can be modified to estimate the effect of teacher certification laws on the distribution of output quality (student test scores from the NAEP) by letting q \u03c4 st be the \u03c4 th quantile of the student test score distribution among students taught by teachers who began teaching in state s and survey year t. Equation (3) is similarly modified, with the q \u03c4 stc being the \u03c4 th quantile of the student test score distribution among students taught by teachers with c years of experience in state s and survey year t. Therefore, for students appearing in the NAEP sample in survey year t taught by cohort c in state s, the certification test law indicators correspond to the year in which the teaching cohort teaching these students would have received initial certification.\nIn the results discussed below in Section 4, some specifications also include an additional vector of state-year observable covariates, X st , including student enrollment; the percent of students eligible for free lunch; the percent minority enrollment; the proportion of the state categorized as suburban, city, or rural; and a quadratic term in the state unemployment rate. Output quality regression models also include the percentage of students who report having an encyclopedia in the home as a proxy for students' educational environment at home."}, {"section_title": "Estimating heterogeneous effects by income", "text": "To estimate the effect of occupational licensing on average quality for school districts of differing income levels, I estimate regressions of quality on an interaction term of test law dummies with the percent of students qualifying for free lunch. These regressions are of the following form:\nwhere q idst is the input quality of teacher i in school district d in state s and survey year t. Lunch dst represents the percent of students in district d, in state s, in survey year t who qualify for free school lunch.\nThus, a higher value of this variable represents a lower income school district. Unlike (1), the regression in (4) is not a model of conditional quantiles, and hence all unobserved heterogeneity is captured in the term \u03bd idst . Thus, ordinary least squares estimation of this model measures the effect of stricter licensing requirements on average quality for areas of differing income. In the case where all experience cohorts are pooled together, I modify (4) to include cohort effects as in (3). The effect of teacher certification laws on the average input quality of teachers found in a school district in which %I of students qualify for free lunch is given by \u03b4 + I\u03c8. The parameter \u03be captures the main effect of the percent of students qualifying for free lunch.\nTo examine heterogeneous effects on output quality, I replace q idst with the NAEP test score of student i in school d in state s in survey year t. 17 In the NAEP datasets, the percentage of students qualifying for free lunch is not recorded as a continuous variable. Instead, discrete data are recorded, classifying the 17 In the NAEP, the percent free lunch variable is recorded at the school level, whereas in the SASS data it is recorded at the district level.\nschool as having either 0-5%, 6-10%, 11-25%, 26-50%, 51-75%, or 76-100% of its students qualifying for free lunch. Therefore, rather than containing an interaction with a single continuous variable, the output quality regression is fully saturated with interactions between law dummies and percentage free lunch dummies:\nwhere p j dst are dummies specifying which of the six free lunch categories contains school d in state s in survey year t. The parameters \u03be j capture the main effect of the percent free lunch variables. A similar modification yields the pooled cohorts specification.\nIt is important to note that if unobserved factors at the group (state-by-year or state-by-year-bycohort) level are correlated with changes in teacher certification testing requirements, each of the approaches described above will yield biased estimates of the effects of testing laws on teacher quality. For example, other education policies may have changed simultaneously with teacher certification requirements. If such policy changes did occur, and these policies are complements with teacher certification testing, the measured effects could simply be interpreted as the total effect of the policy changes rather than the specific portion of the effect attributable to certification tests. If, however, unobserved policy changes and certification testing are substitutes, the estimated effects will be difficult to interpret. While "}, {"section_title": "The effects of licensing on the distribution of input quality", "text": "Before addressing the question of whether stricter occupational licensing laws lead to an increase in the lower tail of the distribution of teacher input quality, I first estimate a regression of average teacher input quality on teacher testing laws. The first three columns of Table 3 display the results of estimating (1), i.e. using first-year teachers only, where the dependent variable is replaced withq st , the mean of input quality in state s in survey year t. Column 1 includes only state and year effects, column 2 adds state-year level demographic controls as explained above, and column 3 adds a state-specific linear time trend. Columns 4-6 repeat the exercise for the pooled sample of teachers. Column 7 adds a term capturing state-specific returns to teacher experience, and column 8 includes both the time trend and the experience trend. Columns 1-3 suggest that none of the test laws have a statistically significant impact on the average input quality of first-year teachers, which is consistent with the results of Angrist and Guryan (2008) .\nHowever, because surveys occurred at 4-6 year intervals, estimation with only first-year teachers does not take advantage of all historical variation in teacher certification test laws. The pooled sample of teachers, on the other hand, uses all teacher cohorts, thus using a larger sample and using variation in certification test laws over the entire period .\nColumn 4 indicates that subject test laws are associated with a statistically significant increase of 0.08 standard deviations in average teacher input quality among the pooled teachers sample. This suggests that, controlling for years of teaching experience, teachers who remain in the occupation multiple years and who were required to pass a subject test prior to initial licensure are of higher quality than those who did not face this requirement. The basic test law and professional knowledge test laws do not have a significant effect. Columns 5-8 indicate that these findings are robust to the inclusion of demographics, time trends, experience trends, or both."}, {"section_title": "Figure 2: Effects of certification test laws on input quality distribution", "text": "Notes: Effects of subject test law, basic skills test law, and professional knowledge test law on quantiles of teacher input quality distribution. Panels on the left display first-year teacher sample and on the right display pooled teacher sample. Robust, pointwise 90% confidence bands are displayed by dashed lines. To examine how teacher certification laws affect the distribution of input quality, I estimate (1) separately for each decile (\u03c4 = 0.1, 0.2, ..., 0.9) of teacher input quality. The results are shown in Figure   2 . Panels (a), (c), and (e) display the effects of subject, basic skills, and professional knowledge test laws at each quantile using the sample of first-year teachers. These regressions include demographic variables and state and year fixed effects, as in columns 2 and 5 of Table 3 . Point-wise 90% confidence intervals are represented in gray. Estimation using the first-year teacher sample demonstrates a generally downward-sloping quality effect for subject and basic skills tests, implying that, among first-year teachers, certification test laws may have a more positive impact on the lower tail than on the upper tail of quality, although at most quantiles the effect is not significant. For subject test laws, the decrease in the upper tail (the 0.8 quantile) is statistically significant. This decrease in the upper tail of qualifications presents some evidence in favor of the hypothesis of Ballou and Podgursky (1998) that occupational licensing can drive away highly qualified candidates. Note that this effect is not possible to detect when looking only at effects on average quality as in Table 3 . "}, {"section_title": "The effects of licensing on the distribution of output quality", "text": "Before estimating the effects of occupational licensing on the distribution of output quality, I first estimate\n(1) with the dependent variable being the average eighth grade math NAEP score within a given group (state-by-year or state-by-year-by-cohort). The results are displayed in Table 4 . For the pooled sample columns, the dependent variable is the mean among students taught by teachers in cohort c in state s in survey year t. Subject test laws appear to have no effect, while basic skills test laws appear to have an effect of about 0.05 standard deviations, but this effect is not robust to the inclusion of time trends.\nProfessional knowledge test laws appear to have a small but imprecisely-measured negative effect. As a useful benchmark, other interventions in education, such as the class size experiments of Krueger (1999), have led to increases in student test scores of approximately 0.2 standard deviations. The effects on the distribution of output quality (NAEP student test scores) are displayed in Figure   3 . As above, these results come from estimating (1) Figure 3 suggests that most of the positive effects of these teacher certification tests accrue to the upper half of the distribution, implying a widening of the student test score distribution.\nWhile is not obvious why this widening would occur, one possibility is these certification tests screen candidates on abilities best suited for providing value to students who perform at or above the mediana question meriting further research. relationship of basic skills test laws on student test scores is less strong than for subject test laws as treated vs. untreated states appear to not be experiencing parallel output quality trends prior to changes in basic skills test laws."}, {"section_title": "Figure 3: Effects of certification test laws on output quality distribution", "text": ""}, {"section_title": "Heterogeneous effects of licensing on input quality for high vs. lowincome areas", "text": "The next question of interest is whether occupational licensing laws differentially affect areas of differing income levels. Shapiro (1986) and Friedman and Friedman (1962) predict that licensing may result in higher quality for high income consumers and lower quality for low income consumers. I test this prediction by estimating (4). The results of this estimation are displayed in Table 5 and Figure 4 . First, Table 5 Panel (f) of Figure 4 demonstrates that professional knowledge test laws have the same relationship as subject test laws, leading to increases in teacher input quality in wealthier areas of approximately 0.07 standard deviations and a decrease of similar magnitude for the lowest income districts. The remaining panels display a similar downward slope but the relationship is imprecisely measured."}, {"section_title": "Heterogeneous effects of licensing on output quality for high vs. lowincome areas", "text": "The effect of licensing on student test scores for areas of differing income levels is displayed in Figure   5 . A table analogous to Table 5 is omitted because the mean value of the percent free lunch variable is not reported in the data; instead, the percent free lunch variable is reported in six bins. 90% confidence intervals are displayed around each estimate, where standard errors are calculated by clustering at the state-year level.\nIn Figure 5 , the first-year teacher sample displays noisily measured effects, while the pooled sample shows stronger patterns. For example, panel (a) does not display a significant effect of subject test laws for the wealthiest schools, and displays a significant negative effect for schools in the second quartile of income (26-50%). In the pooled sample, subject and basic skills test laws are associated with a larger increase in test scores (0.05 standard deviations for subject test laws and 0.15 standard deviations for basic skills test laws) for higher income districts. Appendix Figure 10 focuses on the basic skills test results and demonstrates that they are robust to the inclusion of trends.\nIn Figure 5 , professional knowledge test laws display the opposite effect of basic skills test, with a large and significant decrease of 0.15 standard deviations for the wealthiest districts. While the cause of this opposite effect is unclear, it may be that the pedagogy skills required for these exams are more valuable in low-income areas."}, {"section_title": "Figure 5: Heterogeneous effects of certification test laws on output quality by income", "text": "Notes: Effects of subject test law, basic skills test law, and professional knowledge test law on teacher output quality in areas differing by income, where income is measured by the percent of students eligible for free lunch. Panels on the left display first-year teacher sample and on the right display pooled teacher sample. Robust, pointwise 90% confidence bands are displayed by vertical lines. "}, {"section_title": "Substitution away from licensed professionals", "text": "Given the results from this and the previous section, it is natural to ask how, if at all, licensing induces consumers (in this case, schools and school districts) to substitute away from licensed professionals.\nPrevious studies (e.g. Angrist and Guryan 2008) have demonstrated that more stringent licensing requirements, including teacher certification tests, lead to higher wages. This is as theory would predict:\nlicensing requirements restrict supply and hence increase wages. If it is the case that higher income schools are better equipped than lower income schools to raise wages in response to this restriction of supply, lower income schools might be expected to respond to stricter occupational licensing by substituting away from licensed professionals. Specifically, lower income schools could increase class sizes or hire more emergency-certified teachers, i.e. those who did not have to pass certification tests. For example, Jepsen and Rivkin (2009) found some evidence that lower income schools were less able to retain teachers during supply shortages. The authors studied California's 1996 law to reduce class sizes, finding that the law led to a shortage of teachers. Many teachers left low-income schools to fill coveted vacancies at higher income schools. Below I examine effects on emergency-certified hirings, class sizes, and wages in high vs. low-income areas.\nTo study whether teacher certification tests lead to larger increases in the use of emergency-certified teachers in low-income areas than in high-income areas, I turn again to the SASS survey, which contains an indicator for whether or not a given teacher was emergency certified. Summary statistics for this variable as well as the other variables introduced in this section appear in Appendix Table 6 . I estimate (4) with the dependent variable replaced with the emergency-certified indicator. The results are displayed in the first column of Figure 6 . None of the results are significant, although for basic skills and professional knowledge test laws the point estimates are increasing, consistent with the idea of low-income areas being more likely than high income areas to hire emergency certified teachers in response to stricter occupational licensing.\nI explore changes in class size in the second column of Figure 6 , which displays the results of estimating (4) with the dependent variable replaced by the pupil-to-teacher ratio as recorded in the Common Core of Data (CCD) from the NCES, using all school districts in the database from the years 1988 to 2010. 18\nPanel (b) demonstrates that there is not a significant effect of subject test laws on class size. Panel (d) indicates that there is a significant increase of approximately 0.25 in the student to teacher ratio at the lowest-income school districts, those in which 80% or more qualify for free school lunch. At higherincome schools, a marginally significant decrease in the pupil to teacher ratio of about 0.25 occurs. This is consistent with the hypothesis that occupational licensing may lead to larger class sizes at these schools.\nProfessional knowledge tests, on the other hand, are associated with larger class sizes (an increase of 0.3-0.4 in the student to teacher ratio) at both high and low income schools. skills test laws by approximately 2%. In lower-income schools, those with a higher percentage of students qualifying for free lunch, the estimated increase is not statistically significant. The significant results for basic skills test laws, however, were not robust to the inclusion of state time trends (not shown). The results are difficult to interpret given that Figure 4 panel (d) showed that basic skills test laws did not have a significant effect on teacher qualifications in areas varying by income. Note, however, that these salary regressions use much less variation in licensing regimes, as salary data is only recorded in survey years. In panels (a) and (c), estimates of the effects of subject and professional knowledge test laws are not significant."}, {"section_title": "Event study", "text": "In addition to the robustness checks discussed in the previous sections, namely the inclusion of statespecific time and/or experience trends, I introduce an event study framework to test whether the observed changes in input and output quality occurred after the changes in occupational licensing laws. This event study focuses solely on subject test law changes because, as demonstrated in Table 1, are dummies for year t being 1, 2, 3, or 4 or more years after state s changed its law. If a state never instituted a subject test law, all of the dummies are set to zero. Let the vector of these dummies be given by\nTo estimate the effects of subject test laws on the distribution of teacher input quality in the framework of this event study, I estimate (1) replacing the subject test dummy in the Law st vector with the vector of event dummies, d st . I modify the pooled regression model similarly.\nThe results are displayed in Appendix Figure 11 . I estimate nine regression, one regression for each decile (\u03c4 = 0.1, 0.2, ...0.9), with each decile displayed in its own panel of Appendix Figure 11 . Only the pooled teacher sample results are reported. Thus, the results in Appendix Figure 11 are an event study version of those in panel (b) of Figure 2 . The results demonstrate that in the two years prior to the law change, the effect is zero or insignificant at each quantile of input quality. In the year of the law change and the two years immediately following the change, there is also no significant effect. However, at three years and at four or more years after the law change, there is a significant, positive effect on the distribution at many of the quantiles. This lends support to the evidence from Section 4.1, which suggested that subject test laws raise the distribution of teacher input quality among experienced teachers (demonstrating that the cause-the change in subject test law-appears to occur prior to the effect-the change in the distribution of teacher qualifications). In particular, the main effect of the law change appears to occur several years after the law is first implemented. This phenomenon may arise from Appendix Figure 12 displays the same estimation but for output quality. That is, these results can be compared with those in panel (b) of Figure 3 . Recall that Figure 3 showed a positive impact of 0.05 standard deviations at the 0.9 quantile for the pooled teachers sample, with insignificant results at other quantiles. A similar pattern is seen in Appendix Figure 12 , with the 0.9 quantile, panel (i), demonstrating a marginally significant effect, with the effect arriving at approximately two years after the law change.\nTo apply this event study to the measurement of heterogeneous effects by income, I estimate (4) with the subject test law dummy in the Law st variable replaced by the event dummies, d st , and similarly for the pooled sample model. I interact each of the event dummies with the percent free lunch variable. The results of this estimation for the pooled sample are displayed in Appendix Figure 13 . Once again, at most quantiles, no significant effects are measured prior to or coincident to the law change. Rather, the effects appear to occur four or more years after the change takes place.\nTo examine the timing of the effects of subject test laws on output quality, I estimate (5) including interactions of the percent free lunch dummies with the event study dummies in d st . The results are displayed in Appendix Figure 14 . The effects of the subject law change are larger for the wealthier areas (panels (a) and (b)), and these effects arrive mainly one and two years after the law change took place."}, {"section_title": "Conclusion", "text": "This study used state-level variation in teacher certification testing requirements over the period from 1983 to 2008 to examine how more stringent occupational licensing standards-in the form of teacher certification tests prior to initial licensure-affect the composition of candidates who meet these standards and enter the occupation (input quality), and the distribution of the output in the profession (output quality). I found that subject area certification tests appear to raise the distribution of input quality among teachers who remain in the occupation multiple years, but decrease the upper tail of input quality among first-year teachers. The distribution of output quality appears to widen when certification test laws are in place. I also found that increases in input or output quality due to stricter licensing accrue primarily to high-income areas; low-income areas experience little or no benefit from stricter teacher licensing requirements.\nThe results of this study suggest several avenues for future research. First, the empirical findings can provide guidance for theoretical models of the how teacher certification exams affect outcomes. For example, the results suggest that models of the process through which certification tests screen candidates of different quality levels should take into account candidates' heterogeneity in the costs of passing exams, heterogeneity in outside career options, or heterogeneity in preferences for a teaching career. Given that the effects of licensing differed for teachers who only remained in the profession for a short time period, models should also consider heterogeneity in teachers' propensity to exit the profession. Finally, the results suggest a role for model theoretically the link between the effects of licensing on the quality distribution and the effects of licensing on high vs. low income areas and how schools may compete to attract high-quality teachers.\nAlthough the focus of this study was on the teaching profession, the questions and approaches employed here can play a valuable role in the study of other occupations as well. In particular, the licensing literature to date has focused on the effect of licensing on changes in average levels of quality, while the stated purpose of licensing by many proponents is instead to provide a minimum level of quality that candidates and services must meet. Future research could look for distributional effects in other occupations, especially those in which consumer safety or asymmetric information of professionals vs.\nconsumers is a larger concern, such as medicine or law, to see if licensure laws do in fact prevent the worst candidates from entering the occupation or prevent the worst outcomes from occurring.\nFuture research could also aid in determining the effects of occupational licensing on heterogeneous consumers, examining whether these laws tend to harm low-income consumers relative to high-income consumers. This study sheds some light on this question, as well as on how low-income areas may substitute away from licensed professionals, indicating that policymakers may do well to consider potentially unintended consequences of licensing on low-income areas. However, the question merits further research, again particularly in professions providing services with a greater safety or informational concern, or in occupations in which safety concerns are small, as licensing regulations in these occupations may be more likely to result from professionals' rent-seeking behavior. Figure 14 : Event study: heterogeneous effects of subject test laws on output quality by income Notes: Event study analysis of subject test law on teacher output quality in areas differing by income and using only states which changed from having no subject test law to having a subject test law. Each panel displays the effect for a particular bin of the percent free lunch variable. Within a given panel, the plot corresponds to the effect two years before the subject test law changed, one year before, the year of the change, one year after, etc. The final point corresponds to the effect four or more years after. Robust, pointwise 90% confidence bands are displayed by dashed lines. "}, {"section_title": "A Additional tables and figures", "text": ""}]