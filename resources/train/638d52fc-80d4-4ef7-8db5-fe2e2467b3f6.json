[{"section_title": "", "text": "dulaziz Al-Saud initiated an extensive educational framework incorporating six years of primary school followed by three years each of intermediate and secondary school (Ministry of Education, 2001). By 1951, the country had 226 schools with about 30,000 students. In 1953, the Ministry of Education replaced the Directorate of Education, specifically to improve the school system for male students to meet international standards, although the core of the system was, and still is, religious studies (Al-Sadan, 2000). The General Presidency for Girls' Education was established in 1960, responsible for developing a public education system to enable women to access knowledge and skills to become active members of society. The organization supervised all public girls' schools and education (Al Hakami, 2000). In 2003, the Ministry of Education (2005) assumed responsibility for girls' schools and integrated girls' schools into the public education system. As a consequence, Saudi Arabia has a higher rate of literacy, 85 percent, compared to other Arabic countries, such as Egypt and Algeria, both of which Saudi National Assessment of Educational Progress (SNAEP) ABDULLAH SALEH AL SADAAWI King Saud University ABSTRACT: To provide a universal basic education, Saudi Arabia initially employed a rapid quantitative educational strategy, later developing a qualitative focus to improve standards of education delivery and quality of student outcomes. Despite generous resources provided for education, however, there is no national assessment system to provide statistical evidence on students' learning outcomes. Educators are querying the curricula and quality of delivery for Saudi education, especially following low student performances on the Trends in International Mathematics and Science Study (TIMSS) in 2003 and 2007. There is a growing demand for national assessment standards for all key subject areas to monitor students' learning progress. This study acknowledges extant research on this important topic and offers a strategy of national assessment to guide educational reform. developed their education systems prior to Saudi Arabia (United Nations Development Programme (UNDP), 2009)."}, {"section_title": "Education Resources", "text": "Saudi Arabia has a substantial school system, with over 30,000 schools educating 5 million students (Ministry of Education, 2006). However, there is a vigorous debate regarding the substance of that education. The advocates for the traditional approach, which gives precedence to Arabic values, argue that the Saudi government promotes skills and knowledge acquisition as education for all, providing the citizens with free education from state primary school to public university graduation. Students have monthly remunerations and all study resources (Bahgat, 1999;Rugh, 2002). Over 25 percent, Saudi Riyals (SR) 137 billion (U.S. $35.5 billion.), of the country's 2010 budget was allocated to Education and Manpower Development \"to increase both the quality and quantity of the Kingdom's human resource base among the Saudi Arabia's population, of which two-thirds are under the age of 30\" (U.S.-Saudi Business Council, 2010). Further, overarching educational projects are funded offbudget; for example, the King Abdullah Public Education Development Project received SR 10 billion (U.S. $2.7 billion)."}, {"section_title": "Education Standards", "text": "Nevertheless, critics assert resources are focused on quantitative matters, such as numbers of facilities, teachers, and students, to the detriment of the curricula standards and quality of pedagogy (Abdaljoad, 2005;Al-Ebarahim, 2001;Al-Ghamdi, 2005). Schools' administrations may be compounding elements within the system that are adversely affecting students' learning outcomes. The thrust of resource allocation to date centers on the educational needs of young children, responding to the 3.2 fertility rate (UNDP, 2005) Nevertheless, outcomes from this quantitative approach are mixed, with inadequate schools and facilities to meet the numbers of school-age children. For example, as a temporary measure, the Ministry is renting private residences to use as schools. However, without a national strategy to allow resource flexibility, this makeshift measure has resulted in a profusion of rented premises used for all education purposes, until they now exceed the number of government-owned and appropriately resourced school buildings. In 2006, there were 320 rented schools and 246 government schools in Riyadh alone (Ministry of Education, 2006). Intended for housing, the rented premises are inappropriate for schooling purposes, lacking dedicated and well-equipped classrooms, safety requirements, laboratories, and libraries (Al-Otaibi, 2005;Almegidi, 2004). The Ministry of Education attributes this situation to Saudi's population growth rate, which is relatively high, but does not exceed other Gulf countries that can plan their school resources effectively, such as the U.A.E. (UNDP, 2005). The Ministry of Education, while challenged for accommodation, is improving standards of educational delivery and the quality of outcomes for students. Strategies are being formed to identify optimum paths toward skilled human resources to continue the country's economic and social development. At the time of this study, several key programs are being used to pilot different approaches in different educational areas. Examples of these projects follow, as an indication of the directions the Ministry is pursuing."}, {"section_title": "Saudi Leading Schools Project", "text": "This project is derived from the education system in Victoria, Australia. It was instituted in Saudi Arabia in 2002 as a means to address deficiencies in public schools' responses to individual students' needs. This model is interactive, technical, and incorporates a variety of resources. It accords the school a degree of selfadministration, and provides a flexible curriculum based on openness and partnership with the local community (Ministry of Education, 2005). After six years of implementation in five primary and intermediate schools, the project is still under review."}, {"section_title": "Schools Evaluation Program", "text": "This program is a continuing and comprehensive evaluation process for all aspects of a school, including environment, administration, teachers, and students. It relies upon specific measurement tools and uses quantitative targets (Ministry of Education, 2004). The project is based on educational measurement and quality standards used by the British Office for Standards in Education, the entity that United Kingdom (U.K.) makes responsible for evaluating public schools (Al-Hamed, 2005)."}, {"section_title": "Schools Personnel Evaluation Project", "text": "A project to identify professional standards for teachers, supervisors, and school principals by using objective measurements began with a pilot for a teacher competency assessment in 2001 (Ministry of Education, 2004). The assessment is now one of a suite used for teacher selection, while supervisor and principal competency criteria were being evaluated at that time."}, {"section_title": "Thinking Skills Development Program", "text": "In 2002, a program was implemented to assist students to move from rote learning habits to developing problem solving skills and seeking creative solutions. This entails restructuring the primary school curriculum to introduce interactive class activities, and therefore implement improvements to cognitive skills for educational practitioners. The first phase of the project included a training program for educational leaders and issuing a teacher's guide for the development of thinking skills (Ministry of Education, 2004). However, educators and researchers found that the Ministry's stand-alone projects were not focused on the country's education goals, they lacked integration or communication, and few have reported on their progress or application elsewhere. Further, most of the projects have been curtailed or abandoned during the last few years. For example, the General Project for Curriculum Development commenced in 1999 with a target completion of 2002, yet remained suspended in 2007, and the Saudi Leading Schools Project described above was marginalized after years of teacher training and experiment. Researchers attributed the absence of clarity in education development to two factors; first, there is no consensus of standards in the curricula; and second, an independent office is required to evaluate development projects and to oversee the Ministry of Education's performance (Abdaljoad, 2005;Al-Baadi, 1995;Al-Daoud, 2004;Al-Dossary, 2000;Al Hakami, 2004)."}, {"section_title": "Educational Outcomes", "text": "There is an emerging consensus among educators, researchers, and policymakers that the Saudi education system is not achieving best practices in its provision of facilities, curricula, or teaching standards. Some time ago, the Ministry of Education Report 2000-2004 (2004) stated that the educational challenge facing the country was to prepare students for a competitive workforce; and to achieve this goal, emphasis on teaching quality mathematics, science, and technology was required through the adoption of best practice in teaching and learning methodologies. Traditional teaching practices for some developing countries were based on rote learning in small groups, and the Saudi educational system initially followed this path, adding on curricula in a traditionalist setting. In the developed countries, curricula and teaching standards were adopted earlier, but the traditionalist approach in most developing countries persists. Thus, for the education authorities, there is the grave issue of their inability to develop a comprehensive and reliable school system from the considerable resources devoted to education over the last decades, and this issue is reflected in the uniform substandard results. Administration of a country's judgmental goal, such as preparing future citizens for a future workforce, is not unique to Saudi Arabia, and issues cascading from the aspiration continue to fuel considerable research effort. However, there are fundamental steps to implementation of any program: motivation, goals, resources and, most importantly, standards. The absence of valid and reliable indicators to monitor Saudi educational outcomes over the decades is a substantial disincentive to achievement. Schools' development drifts; a successful school and an unsuccessful school share the same level of resources and general curricula, but neither report against targets. There is little responsibility shown by the entire educational system for the Ministry's goal: preparation of students for a competitive workforce. The TIMSS 2003 assessment, an international test of mathematics and science achievement of students from participating countries, provided an unwelcome result in the ranking of Saudi students. Saudi 8th grade students rank some 34 percent lower (331/500) than the international average in TIMSS mathematics test results, and 20 percent lower (399/500) in science results . For the 2007 tests, Saudi students' mathematics performance did not improve, at 33 percent below average (329/500); however, the science result improved to 19 percent below average (403/500) . Given that education commands about a quarter of the Saudi general budget, this is a serious and unexpected outcome from the international comparison of 8th graders' performances. Informed opinion (Fensham, 1998;Jakwerth, 1999;Kind, 1999) determined that a comprehensive and agreed-upon national assessment system to benchmark results, generate statistical data, and permit adequate comparison is essential to raise standards in curricula and delivery. This study aims to add to debate supporting national assessment standards to drive change and significantly improve performances in the school system. The next section discusses the recognized antecedents of national assessments."}, {"section_title": "National Assessments", "text": "National assessments provide statistical data on benchmarked school student performances to inform policymakers, assist curricula development and delivery, and better manage resources (Smithers, 2004). Versions of national assessments are routinely employed throughout the world, for example, in the U.K., the United States (U.S.), France, Australia, Canada, and Singapore. In England, for example, National Curriculum Tests are applied to all students at the ages of 7, 11, 14, and 16 years in English, mathematics, and science (Jennings, Price, & Pankhurst, 1999). In the U.S., the National Assessment of Educational Progress (NAEP) collects results from a representative sample across the country (NAEP, 2006). In France, there are diagnostic assessments of all students at the upper secondary levels to identify students' needs and address performance issues (Jennings et al., 1999). Australia has a National Assessment Program, Literacy and Numeracy (NAPLAN) benchmark program, which is administered annually to students in grades 3, 5, 7, and 9 (Australia NAPLAN, 2010). In Canada, the Pan-Canadian Assessment Program (Department of Education) was developed to assess students aged 13 to 15 years in their literacy, science, and mathematics knowledge and skills (Canadian Council of Ministers of Education, 2007). Singapore uses the International Primary School Examination (IPSLE), a nation-wide examination held at the end of primary education to assess pupils' suitability for secondary education and placement in appropriate courses to match their learning pace, ability, and inclination. Based on their results, candidates are streamed into four different courses: special, express, normal (academic), and normal (technical) (Singaporean Ministry of Education, 2007). While most of these assessments are not compulsory, other jurisdictions in federal-based countries also have supplementary examinations for local comparisons. For example, in Canada, there are the Ontario District School Board Progress Reports (Ontario Ministry of Education, 2010)."}, {"section_title": "Purpose", "text": "National assessments are implemented by administrators and policymakers for a variety of purposes, which Jennings et al. (1999), themed as follows: \u2022 Formative: measures students' performances for feedback and guidance toward future learning outcomes. \u2022 Diagnostic: to determine students' learning difficulties in order to plan appropriate remedial assistance. \u2022 Summative: to systematically record student performance. \u2022 Evaluative: to assess measures of schools' performances. The benefits to be derived from a coherent testing program are proposed by Greaney and Kellaghan (1996, p. 5-10): 1. Informing policy: provide factual information to assist policymaking, especially data on the quality of students' learning; to make informed decisions on curricula, resources provisions, and teacher training strategies. 2. Monitoring standards: collect regular information on students' performance to assist standards development. 3. Introducing realistic standards: foster a sense of realism about appropriate achievement levels. Unrealistic standards contribute to lower performance levels. 4. Identifying correlation of achievement with outcomes: correlate a range of factors with outcomes to identify strengths and weaknesses in the system. 5. Directing teachers and raising students' performance levels: draw teaching and learning into focus with national assessment to achieve desired outcomes represented in given indicators. 6. Promoting accountability: use assessment to justify resource allocation. 7. Increasing public awareness: publish national assessments to attract considerable media attention, thus heightening public consciousness on educational matters. 8. Informing political debate: direct statistical evidence to issues arising in an educational systemit is more likely to initiate reform. As a guide, the original aims of the U.S. NAEP in the mid-20th century were both political and technical. Termed \"the Nation's Report Card,\" its aims were to track educational reform, educational research, and the war on poverty (Jennings & Renter, 2006). The aims of national assessment in New Zealand's National Educational Monitoring Project differ in that they are explicit: \u2026To get a broad picture of the achievements of representative samples of New Zealand school students at successive points in time so that \u2022 trends in educational performance can be identified and reported; \u2022 good information is available to assist policy makers, curriculum specialists and educators with their planning; \u2022 the public can know about trends in educational achievement (New Zealand Ministry of Education, 2009, webpage)."}, {"section_title": "Capacity to Improve Learning", "text": "National assessment may be viewed as both an instrument for reform and a measure of change. In these guises, assessment methodology is open to public scrutiny from a dual perspective regarding purpose and effectiveness (Whetton, Twist, & Sainsbury, 2000). Initially, all national assessments, whether used for formative or summative purposes, are motivated by a desire to improve an educational system (Shepard, 1991). However, a considerable body of research evidence shows that using national assessments for summative purposes (high-stakes tests) are harmful and have negative effects (Elliott & Fuchs, 1997;Frederiksen, 1994;Shepard, 1991). Moreover, teachers, due to the issue of accountability, tend to tailor their instructions to imitate the format of multiple-choice tests (Baker, 1996;Kane, Khattri, Reeve, & Adamson, 1997). They encourage students to focus on what is tested. Therefore, \"teaching to the test\" is a common practice in schools (Bowers, 1989;Resnick, 1996). Recognizing the negative effects of standardized exams leads to focus on another proposal that can guide an educational system in a positive direction (Jacobson, 1997;Shepard, 1991). Shepard claims that a system of national examinations has high stakes but avoids the issues created by a narrowed curriculum. The United Kingdom Department of Education and Science (1989) recommends that \"the basis of the national assessment system be essentially formative, but designed also to indicate where is a need for more detailed diagnostic assessment\" (Jennings et al., 1999, p. 1). Using a national assessment formatively can serve many purposes; encouraging social comment on the direction of a nation's education focus and administration (Klinger, DeLuca, & Miller, 2008). Educators argue that national assessments will assist in reaching and maintaining higher academic standards than individual establishments are willing to self-impose (Lawton, 1997). Planel, Broadfoot, Osborn, Sharpe, and Ward (2000) argue that a national assessment can be utilized as a case study to demonstrate the fundamental educational and cultural values that underlie an educational system. Assessment results play an essential role in education reform. McKernan (2001) asserted that the educational improvement over the previous decade in the U.S. directly depended on access to high-quality data. None of the accomplishments was possible without sound and objective data to characterize educational progress. This focus in the U.S. on measurement, planning, and feedback was noted in a National Research Council report, where NAEP models for standards-based reporting were widely adopted among U.S. jurisdictions. States also used these results for curricula and standards development (DeVito & Koenig, 2000). In 1996, the U.K. introduced a national curriculum assessment system based on \"attainment targets\" in mathematics, English, and science. The overall target for English was that 80 percent of 11-year-olds achieve level 4 or higher by 2002, compared to 63 percent in 1997. By 1999, 70 percent of students reached the target level (Whetton et al., 2000). Performance measurement and implementing progressive targets enabled the U.K. to make considerable progress on TIMSS 2003 scores in mathematics and science. The result of TIMSS shows that U.K. primary students are among the best performers in mathematics and science, with greater progress in mathematics since TIMSS 1995 than all other contenders, and only two countries scored significantly higher in primary school science. These improvements in performance were achieved throughout the results, for both high and low achievement groups (House of Commons Public Accounts Committee (U.K.), 2009)."}, {"section_title": "Proposed Saudi National Assessment Plan", "text": "To address their differing agendas, nations' assessment of student performances as discussed above fit a continuum of purposes, from national aspirations for future prosperity to a set of targets. At this time, however, the Saudi school system retains traditionalist teaching methodology, characterized as follows: \u2022 A highly centralized system, where the Ministry of Education controls all aspects of public education (curriculum, assessment, teachers, facilities, administration, and extraneous funding) and many of the functions of private schools, \u2022 Curricula which lacks rigor, content, and performance standards, \u2022 Inadequate and uncoordinated data which cannot appropriately inform all levels of decision making, and \u2022 Inadequate professionalism in administration of curricula, assessment, and data gathering. These factors are central to a national assessment strategy for Saudi Arabia. This study offers a proposal which satisfies a strategic view to national assessment, a coherent, comprehensive and phased program supporting a substantive assessment framework. This proposal has a functional aspect which is a national assessment committee; and a policy direction which would take the form of national assessment strategies. The remainder of this study describes both aspects."}, {"section_title": "National Assessment Committees", "text": "The Ministry of Education charged the General Directorate of Evaluation and Educational Quality to develop a plan for national assessment. To provide the resources for developing, implementing, and conduct-ing national assessments, the following committees are required."}, {"section_title": "Steering Committee", "text": "Comprising influential members internal and external to the Ministry of Education, the role of the steering committee is to facilitate the implementation of national assessments for schools, setting goals and establishing adequate resources. An important function of the steering committee is to provide leadership and assign responsibility to organizations and individuals to address administrative and financial obstacles which can destabilize an assessment program. Further, the committee's role includes transparency, providing a public forum for robust debate of proposals, programs, and outcomes. Initially, the steering committee sets an agenda which includes consideration of these factors in consultation with authorities, professional assessors, and community stakeholders: \u2022 Define the justification and the intent of the national student assessments. \u2022 Define the strategy for content, implementation, and staging. \u2022 Determine terms of reference for national assessment: content, data collection, analysis, and reporting procedures. \u2022 Identify and allocate financial resources and define performance levels."}, {"section_title": "Implementation Committee", "text": "Internationally, student assessments are either implemented by central education authorities, especially in federations where there is a division of control; or administered by authorities, using best practice public or private organizations. In Saudi's case, the Director of Evaluation and Educational Quality is responsible for implementing the national assessments. The implementation group's responsibilities include: \u2022 Project management, consultation with the steering committee and stakeholders, and promoting assessment benefits. \u2022 Identifying facilities and equipment sufficient for national assessment data holding. \u2022 Defining the project, target facilities, or regions for the first stage. \u2022 Curricula analysis, assessment design and approval. \u2022 Determining assessment structures relative to schools, teachers, and activities/questionnaires for students. \u2022 Sampling, making amendments, consultations with the steering committee and stakeholders, and issuing final approvals. \u2022 Providing resources and training for districts, administration, and teachers. \u2022 Developing assessment kits, and producing appropriate and sufficient materials, such as teacher training sets, questionnaires, and activity materials. \u2022 Dissemination, application, and collection of assessment materials. \u2022 Processing and analysis, in consultation with steering committee. \u2022 Reporting of data. The implementing group comprises subgroups, involving a technical group for instrument development, sampling, psychometrics, and data processing. The technical subgroup, in particular, requires substantial professional input to ensure best practice standards, materials, and training. While more developed countries' educationalists can access professionals locally, and occasionally internally, developing countries seek assistance from external organizations. For example, the U.A.E. contracted the Australian Council for Educational Research (ACER) to assist its Centre for Educational Testing, Measurement and Evaluation (CETME) in the development of assessments for the 2003 year-5 cohort, focusing on English, mathematics, science, and Arabic. This successful program was extended to year-7 U.A.E. students in 2004 and to year-3 and year-9 students in 2006 (ACER, 2007). However, there is robust debate regarding education authorities undertaking national assessments. Governance is an issue when education authorities audit, or assess, whether self-imposed standards were attained. The bureaucratic processes are not conducive to transparency or adequate consultation with stakeholders. Political influence may occur at any point in the planning or execution of the program (Greaney & Kellaghan, 1996)."}, {"section_title": "National Assessment Strategy", "text": "National education systems differ markedly, due to social, economic, and political factors; consequently, development of national assessment programs vary to meet specific needs. Nevertheless, extant national assessment programs utilize similar frameworks, which is a useful basis for developing a Saudi program respecting Saudi culture and mores. Thus, an assessment program design sponsored by the World Bank (Greaney & Kellaghan, 1996) was the basis for this study's proposal, adapted through reference to subsequent literature, best practice examples from TIMSS, and the specific Saudi environment (see Figure 1, National Assessment Framework for Saudi Schools, page 8)."}, {"section_title": "Assessment Purposes", "text": "As with all complex undertakings, the goal of national assessments should be simple and manageable. Decision making on possibly a broad range of goals should be influenced by the obstacles ahead, such as the construction of appropriate tests, limited capabilities in computer processing, limited expertise to administer assessment materials, limited resources for data analysis, and the need for consultation with stakeholders. A possible mission statement for the program can be derived from the Ministry of Education's vision: national assessment is a valued contribution to raise Saudi schoolchildren's knowledge and skills to an international competitiveness, especially in science and technology, to successfully make their contribution to the country's future development (Al Hakami, Alkalaf, Ayub, & Alalola, 2006). Clarity of purpose facilitates the logistics of the program, thus saving time and resources. The objective should be to monitor Saudi students' achievement in key subject areas and to compare that achievement among Saudi schools as well as internationally. Under these objectives, a cascade of priorities emerges; for instance, comparisons can be made between students' achievement in the targeted subjects, between male and female students or between school districts."}, {"section_title": "Selecting Assessment Subjects", "text": "National assessments gather particular grade year information in three distinct areas: 1) cognitive outcomes, specifically subject matter competence; 2) effective outcomes, that is, attitudes toward the subject; and 3) background variables such as school environment. These are discussed in turn."}, {"section_title": "Cognitive Outcomes", "text": "Generally, national assessment agencies examine students in their first language (literacy), mathematics (numeracy), and science. The attention to literacy and numeracy reflects the importance of these subjects in the provision of a basic education, and then science emerges as an essential subject in the technology age. The countries that have a long experience in national assessments extend the range of subjects to social studies, or extend the domain of the subject matter (such as, in language, by testing students in speaking, listening, writing, and reading). For example, in Alaska, NAEP conducted assessments in reading, mathematics, science, writing, U.S. history, civics, geography, and the arts (Alaskan Department of Education & Early Development, 2007). In this study, in Saudi education, there are four key subjects for the first stages of national assessment development: mathematics, science, religion, and Arabic."}, {"section_title": "Effective Outcomes", "text": "The majority of national and international assessments (such as TIMSS) measure student attitudes towards subjects, influenced by the assumption that attitudes and interests contribute to students' successful learning. Initially, students' attitudes toward subjects, school, and teachers can be measured; however, measuring the variable of attitudes toward teachers may not give valid information, because the traditional relationship between teacher and student might hinder students' responses."}, {"section_title": "Background Variables", "text": "There are many school and nonschool factors that can be studied in relation to students' achievements, such as the type of school building (governmental or rented), class size, and socioeconomic status. "}, {"section_title": "Selecting Survey Populations", "text": "Target populations are usually identified by age, grade level, or both. Choosing a population according to an age factor is disruptive because it requires that students from several grade levels take the test at the same time, and it requires identification of appropriate assessment content for each grade cohort (Greaney & Kellaghan, 1996). In best practice jurisdictions, such as the U.S., the U.K., Australia, and Canada, the grade level is taken into account in defining the population. All countries that conduct national assessments select students in the primary grade years to identify deficiencies at an early point for remedial action. Also, in many countries, national assessments are conducted during the secondary school years, usually at the lower and higher grade levels, to collect indicators regarding students' preparation for life after school. In this study, application of the Saudi assessment program is appropriate for grades 3, 6, 9, and 12, as these years are key stages in public education. However, at the initial stage of assessment development, a focus on the primary level is more useful, proceeding to secondary years' assessment after gaining sufficient skills and experience."}, {"section_title": "Selecting Assessment Subject Standards", "text": "There is increasing pressure on educators to continually raise standards to improve a country's competitive advantage (Whetton, et al., 2000). The formulation of national standards for targeted subjects is essential to establish national assessments. The U.S.  Education, 1998). Two types of standards should be established, content standards and performance standards. Content standards govern the parameters of knowledge, understanding, and skills in a specific content area and performance standards provide performance indicators and concrete examples of skills-based learning specified by the content standard (Hawaii Department of Education, n.d.). The U.S. National Research Council and the international TIMSS are two respected sources which explicate standards, and each jurisdiction initiates or adapts their school subject standards from these and other sources. In this study, these sources are useful guides to establishing standards for other subjects such as language and religion."}, {"section_title": "Constructing Assessment Instruments", "text": "Once assessment standards are established, development of instruments begins. A table of specifications, providing essential information regarding the assessment program, facilitates the test development process. This information is then used to focus and guide the remaining steps in the program (Professional Testing, 2006). The test description may simply indicate the content to be covered; that is, the number and percentage of total items on the test address the particular content area at a specific taxonomic level. It can also include elements such as the overall test length, the test administration time limit, and the item types that are expected to be used (for example, multiple-choice, performance assessment). In some cases, the test description may also specify administration mode (for example, paper-and-pencil, performance-based, computer-based), and scoring procedures and scoring rubrics. Test developers use indicators for levels of cognitive processing that students use in responding to specific items in accord with Bloom's taxonomy; for example, knowledge and application (Krathwohl, 2002). It is critical that the test framework and assessment items include a substantial proportion of items targeted above the knowledge level of cognition. A typical framework is presented as a two-way matrix with the content areas listed in the table rows and the cog-nitive processes in the table columns. The test blueprint is used to guide and target item writing as well as for test form assembly (Professional Testing, 2006). National assessments rely on two forms: multiple choice, where students are required to select an answer from a list of options; and constructed response, where they provide their own answers (United States National Center for Educational Statistics, 2005). However, constructed-response items require qualified scorers, which are not available at this time in Saudi Arabia."}, {"section_title": "Sampling", "text": "To contain costs in gathering and analyzing data for a national assessment program, and to gain greater speed in data analysis and reporting, a representative sample is used (Greaney & Kellaghan, 1996). For this study, the first step is to select a representative sample of schools, data for which are available from the Ministry of Education. Grades 3, 6, 9, and 12, the key years for schooling, are appropriate targets; the technical committee may differ, or stage the selection over a period of time."}, {"section_title": "Review for Best Practice", "text": "While the program is subject to review by the assessment committees throughout, expert opinion is required of the proposed procedures and assessment instruments to confirm relevance to assessment objectives, adequate benchmarks, and efficiency of operation (Greaney & Kellaghan, 1996). A pilot study precedes the program implementation to ensure that items are clear and understandable, and to fulfill statistical requirements such as validity and reliability. As a guide, all U.S. NAEP items are pilot-tested to 500 responses to evaluate performance before operational use (United States National Center for Educational Statistics, 2005). With TIMSS, the review process included several pilots to ensure that the tests represented the curricula of the participating countries and that the items were timely and did not exhibit any bias towards or against particular countries (Martin et al., 1998;Whetton et al., 2000)."}, {"section_title": "Administration", "text": "Substantial logistics are required to conduct a national assessment: gaining agreement with districts and schools to participate; printing, packaging, and distribution of materials; recruiting and training program administrators; supervisory and public relations duties; and processing data (Greaney & Kellaghan, 1996). Involving teachers in conducting tests can reduce administrative costs; it may, however, compromise assessment validity if they do not follow administration procedures adequately. In New Zealand, experienced teachers are selected from a national pool of applicants, attend a week of specialist training, and then work in pairs to conduct the national assessment (New Zealand Ministry of Education, 2008)."}, {"section_title": "Data Analysis", "text": "The data processing consists of collecting, scoring, recording, and entering data, and establishing a database-followed by analysis. This process requires complex data processing capability and software designed to operate on large quantities of data to mentor the quality of data obtained and to ensure the availability of high-quality data for analysis. For this exacting work, TIMSS employed a rigorous quality control to create its international database, producing manuals and software for data entry from its member countries to gain quality, standardized data for the IEA Data Processing Centre each cycle. Quality controls consist of iterative procedures to identify, document, and correct deviations from the international instruments, file structures, and coding schemes (TIMSS, 2001)."}, {"section_title": "Reporting Results", "text": "Assessment results should be reported as soon as possible after data collection. The report should be concise, simply written, and devoid of educational jargon. It should feature simple graphs and bar charts (Greaney & Kellaghan, 1996). The U.S. NAEP reports may serve as models-they include descriptive information about student achievement; evaluative information to support judgments about the adequacy of student performance; and contextual, interpretive information to assist understanding of students' strengths and weaknesses and to gain information relating to policy appli-cations to address systemic shortfalls (Pellegrino, 2000). For NAEP applications, achievement levels are used to report results in terms of students' knowledge and skills (United States National Center for Educational Statistics, 2006). The conclusion is based on clear evidence derived from the data, and the report should document relevant procedures and criteria."}, {"section_title": "Conclusion and Recommendations", "text": "As a matter of urgency, this study stresses the necessity for Saudi Arabia to implement a national assessment program for primary and secondary school students. Recent TIMSS data exposed a fallacious assumption that the extensive resources and policy commitment placed by the government on its educators has not resulted in adequate returns. Investigation shows that an absence of checks and balances in the Saudi educational system has contributed significantly to this situation, and that a national assessment process comprising agreed-upon standards for school districts, individual schools, and students is a prerequisite to reversing the falling competitiveness of the country's graduates and controlling education expenditures. International organizations such as TIMSS assist implementation of such programs, and best practice expertise is readily available from many developed countries and assessment organizations. Only by implementing a rigorous re-education program, based on assessment, can Saudi youth compete in the international labor markets and manage Saudi Arabia's future prosperity."}]