[{"section_title": "Introduction", "text": "Magnetic resonance (MR) imaging plays a crucial role in the detection of pathology, the study of brain organization, and clinical research. Every day, a vast amount of data is produced in clinical settings, preventing the use of manual approaches for data analysis. Consequently, the development of accurate, robust, and reliable segmentation techniques for the automatic extraction of anatomical structures is becoming an important challenge in quantitative MR analysis. In contrast to brain tissue classification where the intensity of the MR signal can be used to segment different tissue types, anatomical segmentation usually requires information derived from the manual segmentations done by experts (i.e., expert priors), since anatomical structures can be composed of several tissue types and distinct anatomical structures can have the same MR signal properties. To overcome this difficulty, several automatic methods of segmentation have been proposed, such as deformable models or region growing (Chupin et al., 2007; Ghanei et al., 1998; Shen et al., 2002) , appearance-based models (Duchesne et al., 2002; Hu and Collins, 2007) , and atlas/template-warping techniques (Aljabar et al., 2009; Barnes et al., 2008; Collins et al., 1995; Fischl et al., 2002; Gousias et al., 2008; Hammers et al., 2007; Heckemann et al., 2006; Rohlfing et al., 2004; Zhou and Rajapakse, 2005) .\nIn template-warping techniques, two main assumptions are made. First, constraints on the shapes of structures are used implicitly because of the one-to-one correspondence between the voxels of the image to be segmented and those of the warped templates. This restriction presents the advantage of forcing the resulting segmentation to have a similar shape to those of expert-labeled structures in the template library. However, according to the regularization used during registration, some details can be lost and local high variability cannot be captured. Second, label fusion techniques usually assign the same weight to all samples during a voting procedure and consider only the absolute number a criterion. This approach is sensitive to registration error, since it does not take into account the relevance of each sample (Lotjonen et al., 2010) . In the present work, we propose a patch-based scheme with a weighted label fusion, where the weight of each sample is only driven by the similarity of intensity between patches (i.e., small subvolumes of the image defined as three-dimensional [3D] cubes). In the proposed method, voxels with similar surrounding neighborhoods are considered to belong to the same structure and thus are used to estimate the final label.\nAs exemplars, patch-based methods are currently the focus of attention of the computer vision community in various domains such as texture synthesis (Efros and Freeman, 2001) , in-painting (Criminisi et al., 2004) , restoration (Buades et al., 2005) , and single-frame super resolution (Protter et al., 2009) . In each of these domains, patch-based methods have been the subject of intensive investigation because they exhibit very high performance despite their simplicity. Inspired by the nonlocal means denoising filter (Buades et al., 2005) , we propose a nonlocal patch-based approach using expert manual segmentations as priors in the context of anatomical segmentation. The nonlocal means filter has two interesting properties that can be exploited to improve segmentation. First, the natural redundancy of information contained in the image can be used to drastically increase the numbers of samples considered during estimation. Second, the local intensity context (i.e., patch) can be used to produce a robust comparison of samples.\nIn this study, we describe a fully automated patch-based method using expert priors (i.e., information derived from manual segmentations) and the different steps required for its utilization. Our method is applied to the HC segmentation of healthy subjects and the lateral ventricle segmentation of patients with Alzheimer's disease (AD). During experiments, the influences of different parameters were studied, and a comparison with two other methods was performed. Finally, we discuss further improvements and questions revealed by this new approach."}, {"section_title": "Materials and Methods", "text": ""}, {"section_title": "Datasets", "text": "Two different datasets were used during the experiments to demonstrate the ability of the proposed method to (1) segment complex anatomical structures, (2) address the high variability of pathological structures, and (3) use multi-site training databases.\nFirst, we used our method to segment the hippocampi of healthy subjects. The HC plays an important role in human memory and orientation. Moreover, HC dysfunction is involved in a variety of diseases, including AD (Jack et al., 2000) , posttraumatic stress disorder (Bremner et al., 1995) , major depression (Bremner et al., 2000) , schizophrenia (Buss et al., 2007; Tanskanen et al., 2005) , and epilepsy (Bernasconi et al., 2003) . This structure is especially difficult to segment because of its small size, high variability, low contrast, and discontinuous boundaries in MR images (Chupin et al., 2007; Siadat et al., 2007) . Finally, the HC is composed of several tissue types, which prevents the use of simple intensity-based techniques.\nSecond, we applied our method to the lateral ventricle segmentation of patients with AD. In such patients, structural variability is increased as a result of the pathology, and this variability represents a challenge for segmentation techniques such as atlas warping. Ventricular volume has been shown to provide a useful marker of neuronal degeneration and thus could be used as an indicator of AD (Nestor et al., 2008) . However, despite the high contrast between tissue and cerebrospinal fluid (CSF), various factors render ventricle segmentation difficult. First, partial volume effects can impact segmentation, especially on MR images with limited resolution (Wang and Doddrell, 2001) . Moreover, the temporal horns and occipital poles of the ventricles can be disconnected from the main body, which affects appearance-based methods and regiongrowing techniques. Finally, the choroid plexus appears with similar intensities to gray matter, which prevents the use of simple threshold-based techniques.\n\u2022 Hippocampus dataset\nThe HC dataset consists of T1-weighted (T1w) MR images (fast field echo, TR = 17 ms, TE = 10 ms, flip angle = 30 \u00b0, 256\u00d7256 matrix, 1 mm in plane resolution, 1 mm thick slices) of 80 subjects randomly extracted from a group of 152 young, healthy individuals acquired on a 1.5T Philips GyroScan imaging system (Philips Medical Systems, Best, The Netherlands) in the context of the International Consortium for Brain Mapping (ICBM) project (Mazziotta et al., 1995) . The local ethics committee approved the study and informed consent was obtained from all participants. The 80 subjects selected comprised 39 males and 41 females of similar ages (mean age: 25.09 \u00b1 4.9 years). The MR images were manually segmented by an expert directly into stereotaxic space. For each subject, the HC label was manually defined using the protocol described by Pruessner et al. (2000) . The resulting segmentations obtained an intraclass reliability coefficient (ICC) of 0.900 for inter-rater reliability (4 raters) and 0.925 for intra-rater reliability (5 repeats).\n\u2022 Ventricle dataset\nThe ventricle dataset consists of T1w MR images (gradient-recalled echo, TR = 22 ms, TE = 10 ms, flip angle = 30 \u00b0, 250 mm field of view, 256\u00d7256 matrix, 110 sagittal partitions 1.5 mm thick, resulting in a voxel size of 0.98\u00d70.98\u00d71.5 mm 3 ) of 80 subjects randomly extracted from a dataset of 271 elderly patients with mild to moderate AD, aged between 50 and 85 years. The images were acquired at 62 different study sites. The manual segmentations were performed on the images in native space. Inter-and intra-rater variability were studied on 10 patients scanned on the same SIEMENS Sonata 1.5T imaging system (Siemens, Erlangen, Germany). The inter-rater variability (3 raters) was estimated to be 0.987, and the intra-rater (10 repeats) variability to be 0.990. This dataset is not publicly available."}, {"section_title": "Method overview", "text": "As in template-warping methods, the proposed patch-based method uses expert manual segmentations as priors in order to achieve the segmentation of anatomical structures. However, our method has two main differences compared with template-warping methods: the scale of the considered objects and the label fusion scheme.\nFirst, while template-warping methods work at the level of anatomical structure, our method handles a finer scale by using patches. Therefore, instead of performing the fusion of nonlinearly deformed template structures, the proposed method achieves the labeling of each voxel individually by comparing its surrounding patch with patches in training subjects in which the labels of the central voxels are known. When the patch under study resembles a patch in the training subjects, their central voxels are considered to belong to the same structure, and this training patch is used to estimate the final label. By this method, several samples from each training subject can be used during the label fusion, enabling a drastic increase in the number of sample patches involved in the label estimation.\nSecond, template-warping methods usually use a majority voting scheme to fuse the labels (Aljabar et al., 2009; Collins and Pruessner, 2010; Heckemann et al., 2006; Rohlfing et al., 2004) that considers the relevance (or weight) of all the samples labeled as similar. In the proposed method, the intensity-based distances between the patch under study and the patches in the training subjects are used to perform a weighted label fusion based on the nonlocal means estimator (Buades et al., 2005) . The term nonlocal indicates that the spatial distance between the patches' centers is not taken into account; thus, the weight of each sample is only driven by the similarity of intensities between patches. In such an approach, the intensity-based distance between patches decreases as the relevance of the considered sample increases.\nIn other words, by taking advantage of the redundancy of information present in the image, the patch-based nonlocal means scheme enables the robust use of a large number of samples during estimation. This number will be significantly more important than the number of training subjects, in contrast to in template-based methods (i.e., where the number of warped subjects dominates). Moreover, contrary to classical majority voting schemes that give the same weight to all the samples, the nonlocal means scheme enables the robust distinction of the most similar samples according to their local context (i.e., their surrounding patches). Finally, in the proposed method, a patch-based weighting is used to perform a pixel-based aggregation of the labels ensuring the independency of the votes."}, {"section_title": "Image preprocessing for library construction", "text": "The first step of the proposed method involves organizing the library of training subjects to be used for patch comparison. During this step, variability caused by image formation is minimized by performing denoising, an inhomogeneity correction, and an intersubject intensity normalization (see Fig. 1 ). Moreover, since the anatomical intersubject regularity will be used to drive the search within the library, the training subjects of the database are linearly transformed into stereotaxic space to ensure a coarse correspondence between the anatomical locations of the images (see Fig. 1 ).\n\u2022 Denoising All images in the database were first denoised with the 3D block-wise nonlocal means filter recently proposed for MR images by Coupe et al. (2008) . To remove the intensity bias introduced by the Rician nature of noise, a Rician adaptation of nonlocal means (WiestDaessle et al., 2008) was also used. The Rician noise level, used as a filtering parameter, was estimated with the object-based method proposed .\n\u2022 Inhomogeneity correction To ensure that each tissue type has the same intensity within a single image, the well-known N3 intensity nonuniformity correction of Sled et al. (1998) was used.\n\u2022 Linear registration to stereotaxic space All the subjects were linearly registered to the MNI-ICBM152 template by using affine registration. For the ventricle dataset, the estimated transformation was applied to the expertbased segmentation using nearest-neighbor interpolation. For the HC dataset, the label interpolation was not performed because the labels are defined in stereotaxic space.\n\u2022 Intensity normalization Finally, the intensities of the images were set in [0-100] and were normalized together by following the method proposed by Nyul and Udupa (2000) . With this method, we ensure that the contrast and luminance of each tissue type are consistent across the training subjects in the database.\nAt the end of this procedure, the images were cropped around the structure of interest to reduce the size of the library (see cropped images in Fig. 1 ). These different preprocessing steps ensure that the tissue intensities are consistent within the images (inhomogeneity correction) and across the subjects of the database (intensity normalization). Finally, the proposed library construction is similar to that used by template-warping techniques. However, while these techniques consider the library at the level of anatomical structure, our approach considers the library at the patch level."}, {"section_title": "Search strategy within the library", "text": "The search within the library is designed to find the most similar patches, but is also constrained in order to avoid useless computations. Therefore, the search process uses different strategies. First, we constrain the segmentation with an initialization mask. Second, we consider the probability that similar patches can be found in similar subjects. Then, we consider that the anatomical intersubject variability in stereotaxic space is limited; thus, we can define a limited search volume around the location under study. Finally, we consider that two similar patches should have similar luminance and contrast."}, {"section_title": "Fig. 1. Preprocessing.", "text": "Preprocessing workflow used for library construction. First, denoising and inhomogeneity correction steps are performed in the subject space. The subjects are then linearly registered to the MNI-ICBM152 Template in MNI space. Finally, an intensity normalization of the different subjects is applied before cropping the images around the structure of interest\nInstead of segmenting the entire image under study, we define an initialization mask around the structure of interest. A number of strategies can be used to propose an accurate initialization, such as matching the best subject (Barnes et al., 2008) followed by a morphological dilation of the mask. In this case, we chose a very fast and simple approach that uses the union of all the expert segmentations in the training database as the initial mask. In this way, we ensure that the structure is completely included in the mask and demonstrate the robustness of our method to coarse initialization (see Fig. 2 )."}, {"section_title": "Fig. 2. Initialization masks.", "text": "Initialization masks used for the hippocampus and ventricle datasets overlaid in blue on one subject.\n\u2022 Subject selection A selection is also performed at the subject level that resembles the selection of best subjects in the label fusion method (Aljabar et al., 2009 ). In our method, we use the sum of the squared difference (SSD) across the initialization mask instead of normalized mutual information over the image, as suggested by Aljabar et al. (2009) . This strategy was chosen because SSD is sensitive to variation in contrast and luminance; thus, we expect to find a greater number of similar patches (in the sense of the L2 norm) in subjects with smaller SSDs. The same N closest subjects are retained during the entire segmentation process (see Fig. 3 where the three closest subjects are displayed).\n\u2022 Search volume definition Initially, the nonlocal means denoising filter was proposed as a weighted average of all the pixels in the image (Buades et al., 2005) . For computational reasons, the entire image cannot be used and the number of pixels involved has to be reduced. As done for denoising (Buades et al., 2005; Coupe et al., 2008) , we use a limited search volume V i , defined as a cube centered on the voxel x i under study. Thus, within each of the N selected subjects, we search for similar patches in a cubic region around the location under study (see Fig. 3 ). This search volume can be viewed as the intersubject variability of the structure of interest in stereotaxic space. This variability can increase for a subject with pathology or according to the structure under consideration.\n\u2022 Patch preselection Finally, as proposed for denoising purposes , we perform a preselection of the patches to be compared in order to reduce the computational time. By using simple statistics such as mean or variance, it is possible to discard a priori the most dissimilar patches. In the proposed approach, we use luminance and contrast criteria to achieve the patch preselection. Based on the first and second terms of the well-known structural similarity measure (SSIM) (Wang et al., 2004) , the preselection procedure can be written as follows: \nwhere \u00b5 represents the means and \u03c3 represents the standard deviations of the patches centered on voxel x i (voxel under consideration) and voxel x s,j at location j in subject s. If the value of ss is greater than a given threshold th, the intensity distance between patches i and j is computed. The threshold th was set to 0.95 for all the experiments. This value was chosen empirically because it provides a good balance between segmentation accuracy and computational time reduction for both structures under study. Patch mean and variance are precomputed as maps of local means and local variances that avoid multiple computations.\nFinally, the proposed search enables only candidates within the most similar training subjects to be considered (SSD-based subject selection), namely, those whose locations are not too far apart in stereotaxic space (search volume) and whose local neighborhoods are similar to the neighborhood of the voxel under study (patch preselection). Hence, the introduction of outliers is limited during the nonlocal patch-based label fusion and the computational burden is drastically reduced."}, {"section_title": "Nonlocal means label fusion", "text": "The proposed label fusion strategy is based on the nonlocal means estimator (Buades et al., 2005) . In such an approach, the intensity-based distance between patches is used to perform a robust weighted average of samples. In our case, the nonlocal means estimator is used to perform the weighted average of the labels.\n\u2022 Nonlocal means estimator For all voxels x i of the image to be segmented, the estimation of the final label is based on a weighted label fusion v(x i ) of all labeled samples inside the search volume V i for the N selected subjects:\nwhere y s,j is the label given by the expert to voxel x s,j at location j in subject s and w(x i , x s,j ) is the weight assigned to y s,j by patch comparison. Depending on the similarity between the patch surrounding x i and that surrounding x s,j , the weight w(x i , x s,j ) is computed as:\nwhere P(x i ) represents the cubic patch centered at x i and ||.|| 2 is the normalized L2 norm (i.e., normalized by the number of elements) computed between each intensity of the elements of the patches P(x i ) and P(x s,j ). As explained in the section on the search strategy (section 2.4), if the structural similarity ss between the patches is less than the threshold th, the weight is not computed and is set directly to zero.\nFinally, by considering the labels y defined in {0,1}, the final label L(x i ) is computed as:\nIn the event that ss is less than th for all patches in the library, -1 is returned to indicate that the selected library does not allow a decision to be made. Note that our method can be also applied to probabilistic labels y defined in [0,1] without any modifications.\nFigure 3 presents an overview of the different steps involved in achieving the segmentation of one voxel x i included in the initialization mask. After the selection of the N most similar subjects in the training library (N = 3 in this example), the patch P(x i ) (in green) is compared with all the patches P(x s,j ) contained in the search volume V i within the N selected subjects. The most similar patches P(x s,j ) (in blue) to the patch P(x i ) obtain the highest weights, as shown in the weight maps. For the 2D slice in this illustration, 12 labeled samples have significant weights in subject s 1 , the two most similar patches are in subject s 2 , and no similar patches are found in subject s 3 .\n\u2022 Local adaptation of h As usual in estimation problems using a robust function, the tuning of the decay parameter h plays a crucial role. When h is very low, only a few samples are taken into account. When h is very high, all samples tend to have the same weight and the estimation is similar to a classical average.\nThe value of h should depend on the distance between the patch under consideration and the library content. In fact, when the library contains patches very similar to the patch under study, h needs to be decreased to drastically reduce the influence of the other patches. However, when no similar patches exist in the library, h has to be increased to relax the selection. To achieve this local adaptation of h automatically, we propose an estimation of h(x i ) based on the minimal distance between P(x i ) and the considered patches P(x s,j ):\nwhere \u03b5 is a small constant to ensure numerical stability in case the patch under consideration is contained in the library. This kind of local adaptation has been similarly used for adaptive MRI denoising by Manj\u00f3n et al. (2010) . Beyond its high denoising performance, the success of the nonlocal means filter is attributable to its algorithmic simplicity. In the proposed segmentation method, we tried to preserve this interesting aspect by keeping the algorithm as simple as possible. However, many improvements on the original nonlocal means denoising filter have been proposed, some of which could be applied to segmentation. The interested reader can find a review of these improvements in (Buades et al., 2010) . For instance, a locally adaptive size of the search volume according to the estimator variance, as suggested by Kervrann and Boulanger (2008) , could avoid useless computation in large constant areas (e.g., CSF in ventricle segmentation)."}, {"section_title": "The method through an example", "text": "In order to provide an intuitive understanding of our method, we examine the spatial distribution of the variables involved in the segmentation process. Here, we present a detailed example of HC segmentation for N = 2 and N = 20, illustrated in Fig. 4: -First, the normalized number of samples (see bottom of Fig. 4) shows that the nonlocal means estimation considers around 500 sample patches on average for each training subject (e.g., 10,000 samples on average for N = 20). Not all the considered samples have significant weights, but this number is significantly higher than N, the number of training subjects, as shown in Fig. 3 . The spatial variation of this number depends on the patch preselection. In fact, since preselection (see Eq. 1) rejects all patches with dissimilar luminance and contrast during the patch comparison, the number of considered samples is lower for the less common patches. Moreover, this average number decreases slightly when N increases because of the introduction of subjects with less similar structural shape, contrast, or luminance in the library (i.e., with lower SSD during subject selection). However, it is interesting to note that similar patches are found in dissimilar subjects, since the average number does not drastically decrease when N increases.\n-The second variable to be studied is the smoothing parameter h(x i ) that represents the minimal distance (see Fig. 4 "}, {"section_title": ") between P(x i ) and all the patches P(x s,j ) considered during patch comparison (see Eq. 5). A high h(x i ) indicates that the closest patch found in the library is not really similar to P(x i", "text": "). In this case, the estimation provided by the nonlocal means estimator is less robust and leads to inaccuracies in segmentation. As shown for N = 2, the areas where h(x i ) is high mainly correspond to false positives and false negatives (see top of Fig. 4 ). When N = 20, the higher number of considered patches enables the procedure to find more similar patches (the minimal distance h(x i ) decreases). Thus, the segmentation is improved, as assessed by kappa index values (see top of Fig. 4 ).\n-The last variable, v(x i ), is the value returned by the nonlocal means estimator (see Eq. 2). This value can be viewed as the probability that a voxel will be included in the structure. In this case, the manual labels y s,j also have to be counted as probabilities. The fast decay of v(x i ) shows that the nonlocal means estimator clearly distinguishes between the structure and the background. As expected, the edges obtain less discriminative values. This can be explained by the higher intra-rater variability on edges within the training database. This aspect is an inherent limitation of all methods that use expert-based manual segmentations as priors."}, {"section_title": "Implementation details", "text": "The proposed method was implemented in MATLAB 7.4.0 using C/MEX code. The experiments were conducted using a single core of an Intel Core 2 Quad Q6600 processor at 2.4 GHz with 4 GB of RAM. The different preprocessing steps needed for library construction were achieved by using tools developed in-house in C. The nonlocal means denoising took around 2 min, and the inhomogeneity correction, around 1 min. The linear registration required less than 2 min, and the normalization, close to 1 min. The execution times given in the results section are the times required only for segmentation, since all the compared methods required these preprocessing steps. As discussed later, many optimizations can be used because each voxel is treated independently, which allows multithreading or GPU-based computation. "}, {"section_title": "Validation framework", "text": "For each dataset, a leave-one-out procedure was performed for the 80 subjects. The kappa index (Dice coefficient or similarity index) (Zijdenbos et al., 1994) was then computed by comparing the expert-based segmentations with those obtained with our method. For two binary segmentations A and B, the kappa index was computed as:\nAs usual in quantitative MR analysis, manual segmentation is considered the gold standard (Pruessner et al., 2000) . For both datasets, the impact of the patch size, search volume size, and number of training subjects was studied. Moreover, the proposed patch-based method was compared for both datasets with an appearance-based approach using level-set shape constraints (Hu and Collins, 2007 ) and a template-based technique inspired by Barnes et al. (2008) that uses ANIMAL (Collins et al., 1995) for the nonlinear registration of the best subject.\nIn the appearance-based method, only one modality was used during the processing. We used the 79 remaining subjects to construct the training dataset involved in the principal component analysis (PCA) computation. Although this number is higher than those proposed by Hu and Collins (2007) (20, 30, 40 , and 60 subjects), we wanted to conduct a fair comparison with our method, since the selection of the N closest subjects in our patch-based method is done within the 79 remaining subjects.\nFor the template-based method inspired by Barnes et al. (2008) , the best subject was selected using the normalized mutual information, as suggested by Aljabar et al. (2009) . This subject was then nonlinearly warped to the subject under study with ANIMAL (Collins et al., 1995) within a multiresolution framework until a resolution of 2 mm. In our validation, the best subject was selected from the 79 remaining subjects during a leave-one-out procedure."}, {"section_title": "Results", "text": "The kappa index values obtained with the initial mask are presented in Fig. 5 . The median kappa index value was 0.44 for the HC dataset and 0.41 for the ventricle dataset, which corresponds to an average percentage of false negatives (i.e., the mean number of voxels included in the mask but not in the manual segmentations) of 71% for the HC dataset and 73% for the ventricle dataset. Note that these results only give a baseline to show that the initial mask does not achieve an accurate segmentation."}, {"section_title": "Impact of the 3D patch size", "text": "First, we studied the impact of patch size on segmentation accuracy. The kappa index results are presented in Fig. 6 for both datasets. The best median kappa index value was obtained with a patch size of 7\u00d77\u00d77 voxels for the HC dataset (\u03ba = 0.882) and 5\u00d75\u00d75 voxels for the ventricle dataset (\u03ba = 0.957). The optimal patch size seems to reflect the complexity of the anatomical structure. The patch size needs to be larger for the HC than for the ventricle, since the intensities of the HC are less discriminative. Figure 7 shows the HC segmentation results for the best, one median, and the worst subject for the different patch sizes studied. These results indicate that the patch size needs to be large enough to capture the local geometry (holes and discontinuities in HC segmentation for a patch size of 3\u00d73\u00d73 voxels). Because of the high contrast between tissues for ventricle segmentation, the size of the patch can be smaller. "}, {"section_title": "Impact of the search volume size", "text": "We also studied the impact of the size of the search volume on segmentation accuracy. The kappa index results are presented in Fig. 8 . The best median kappa index was obtained with a search volume of 9\u00d79\u00d79 voxels for the HC dataset (\u03ba = 0.882) and 15\u00d715\u00d715 voxels for the ventricle dataset (\u03ba = 0.958). The optimal search volume size is related to the anatomical variability of the structure within stereotaxic space. Since the HC is smaller and was segmented in healthy subjects, the variability of this structure is less than that of the ventricles of the subjects with AD; thus, a search volume of 7\u00d77\u00d77 voxels or 9\u00d79\u00d79 voxels provides good results. For the ventricle, the size of the structure and the presence of pathology mean that larger search volumes will give better results. However, the small improvement seen when the search volume increased from 11\u00d711\u00d711 voxels to 15\u00d715\u00d715 voxels may not justify the increase in computational time. Figure 9 presents the ventricle segmentation results for the best, one median, and the worst subject for different search volume sizes. As expected, when the search volume is too small, the anatomical variability of the structure of interest within stereotaxic space can lead to the selection of a subpart of the library that contains insufficient information for finding similar patches. For instance, in Fig. 9 , the holes in the segmentations indicate that no similar patches were found for a search volume of 3\u00d73\u00d73 voxels. Fig. 7 . Impact of the patch size. Hippocampus segmentation for the subjects with the best kappa index (top), a median kappa index (middle), and the worst kappa index (bottom) obtained by our method. These results were obtained using 20 training subjects and a search volume of 9\u00d79\u00d79 voxels. The expert-based segmentations are shown in red, and the segmentations obtained with our method, in green. Fig. 8 . Impact of search volume size. Kappa index distribution for different search volume sizes for both datasets. For the HC dataset, the results were obtained using 20 training subjects and a 3D patch size of 7\u00d77\u00d77 voxels. For the ventricle dataset, the results were obtained using 20 training subjects and a 3D patch size of 5\u00d75\u00d75 voxels."}, {"section_title": "Impact of the number of subjects", "text": "The last important parameter of the proposed method is the number of selected training subjects. During this experiment, segmentation accuracy was studied for 2 to 30 selected training subjects. The results are presented in Figs. 10 and 11. For the HC dataset, the median kappa index value was 0.848 for 2 subjects and 0.884 for 30 subjects. For the ventricle dataset, the median kappa index value was 0.942 for 2 subjects and 0.959 for 30 subjects. As expected, increasing the number of selected training subjects increased the accuracy of the segmentation. Figure 12 presents the HC segmentation results. Holes appeared in the segmentations when data from only two training subjects were used, indicating that no similar patches have been found. This aspect can be moderated by decreasing the threshold of preselection in order to increase the number of patches used during estimation. However, this strategy cannot be more efficient than increasing the number of subjects, since the final decision will be based on patches that are not very similar."}, {"section_title": "Comparison with appearance-based and template-based methods", "text": "Finally, the proposed patch-based method was compared with two other methods. Figure 13 presents the kappa index values obtained for each method applied to both datasets. The results presented for our method were obtained with N = 20. For HC segmentation, the appearancebased method obtained a median kappa index value of 0.800, the best template approach obtained 0.837, and the proposed method obtained 0.882. For ventricle segmentation, the appearance-based method obtained a median kappa index value of 0.788, the best template approach obtained 0.909, and the proposed approach obtained 0.957. The patch-based approach obtained significantly better results compared to the two others methods with a p-value << 0.001 in both cases using Kruskal-Wallis tests. In addition, the appearance-based method was not able to capture the variability of the lateral ventricles in patients with AD. Figures 14 and 15 "}, {"section_title": "Computational time", "text": "The computational time required by the proposed method was proportional to the number of subjects; each subject required around 40 s. This time could be easily reduced with a better initialization mask. Compared with other approaches, the appearance-based method (Hu and Collins, 2007 ) took around 45 s to provide the segmentation of the HC. By contrast, the best template-based approach inspired by Barnes et al. (2008) required around 6 min to achieve the nonlinear registration of the cropped images already linearly registered into stereotaxic space. Although comparing these approaches was difficult because our method was coded in C-MEX for MATLAB and not in C like the other two, these results show that the PCA-based approach was quite fast, though at the expense of accuracy. Finally, methods using nonlinear registration can become quite computationally intensive when several subjects are involved, as noticed in (Aljabar et al., 2009 "}, {"section_title": "Discussion", "text": "We propose a novel patch-based approach to automatically segment anatomical structures using the manual segmentations done by experts as priors. Despite its simplicity, the accuracy of the proposed method has been demonstrated within our validation framework for HC and lateral ventricle segmentation. The highest median kappa index values obtained during experiments were 0.884 for the HC dataset and 0.959 for the ventricle dataset, for N = 30 training subjects. In terms of a two-digit mean kappa index value as is widely used in the literature, our method obtained 0.88 for the HC dataset and 0.95 for the ventricle dataset. Moreover, comparison with an appearance-based (Hu and Collins, 2007 ) and a template-based method (Barnes et al., 2008) highlighted the competitive results obtained by the proposed nonlocal patch-based approach.\nComparing published methods is always difficult because of differences between the databases used for validation, the populations studied, the quality of expert segmentations, and the reported quality metrics. Moreover, the number of labeled samples defining the segmentation (which depends on the ratio between the volume of the structure and the voxel size) (Rohlfing et al., 2004) can impact the similarity measure. Nonetheless, interesting tendencies in method evolution can be extracted by studying published results.\nFor HC segmentation, recently published results (Barnes et al., 2008; Chupin et al., 2007; Morey et al., 2009; Morra et al., 2008; Pohl et al., 2007; van der Lijn et al., 2008) indicated high kappa index values greater than 0.80. The latest published methods based on the nonlinear warping of the best templates and involving a label fusion step (Collins and Pruessner, 2010; Gousias et al., 2008; Lotjonen et al., 2010) obtained kappa index values equal to or greater than 0.88. As discussed by Aljabar et al. (2009) , the accuracy obtained with these techniques reach the limit of the variability of expert human raters. Gousias et al. (2008) reported a mean kappa index of 0.88 with the use of a B-spline-based nonlinear registration on the brain of a 2-year-old. Lotjonen et al. (2010) proposed two intensity-based models to improve label fusion: an extension of the graph-cut-based method described by van der Lijn et al. (2008) and an expectation-maximization (EM) approach. Using nonlinear deformations of the N = 13 closest templates, their graph-cutbased label fusion obtained a kappa index of 0.880 and their EM-based label fusion, a kappa index of 0.885. Obtained by using the ADNI database of healthy subjects and patients with AD, these kappa index values indicate the high performance of these approaches. In our case, only the method proposed by Collins and Pruessner (2010) can be directly compared with our proposed one as they used the same database and the same validation framework. Collins and Pruessner (2010) obtained a median kappa index of 0.886 by nonlinearly registering the N = 11 closest subjects with ANIMAL (Collins et al., 1995) and by fusing the resulting label with a classical majority voting scheme. By comparison, the proposed method offers the main advantages of its simplicity (no nonrigid registration required) and its computational time (40 s vs. 6 min per training subject) for a similar segmentation accuracy (\u03ba = 0.884). As a result of the proposed automatic adaptation of the robust function parameter, our approach can be implemented simply in a fully automatic manner.\nFor ventricle segmentation, the large variety of databases makes comparison with the literature rather difficult. Hu and Collins (2007) used the proposed appearance-based method with a levelset constraint and obtained a mean kappa index of 0.83 for patients with multiple sclerosis. The same method obtained a median kappa index of 0.788 during our comparison using AD patients. This low kappa index might result from the higher variability of lateral ventricles in patients with AD. Schonmeyer (2006) obtained a mean kappa index of 0.90 for subjects with AD by using an object-oriented method, while Aljabar et al. (2009) reported a mean kappa index of 0.912 across a database of 275 healthy subjects. During our method comparison, we obtained a slightly lower kappa index of 0.909 with the best template approach. As previously mentioned for HC segmentation, recent template-warping approaches (Aljabar et al., 2009 ) with a selection strategy for the best subjects have obtained very good results in the literature.\nThe new approach to the label fusion problem introduced by using a patch-based method reveals several questions. First, in this proof of concept, we used linear registration of subjects to save computational time and demonstrate the robustness of the proposed method. However, the complementarity of patch-based weighted label fusion with approaches using nonlinear registration appears to be a natural extension. In this way, the spatial distance between the patches' locations could be used as a shape prior, and the initialization mask could be greatly improved, reducing computational time. This tendency toward using local intensity-based refinement after nonlinear registration seems promising, as shown by van Rikxoort et al. (2010) with local piece-wise atlas fusion and by van der Lijn (2008) and Lotjonen et al. (2010) with graph-cut-based and EM algorithms. Moreover, experiments on a larger diversity of pathologies and anatomical structures should be studied in future applications. The robustness of the proposed parameters in these situations should be also tested.\nFinally, implementation optimization should be investigated. In the literature on nonlocal means denoising, many papers have been proposed on reducing computational time. In our method, a new patch preselection has been proposed and is already included. However, prototype-based (Tibell et al., 2009) or cluster tree-based (Brox et al., 2008) approaches could be faster. In addition, the noniterative nature of the nonlocal means approach is perfectly suited to parallel implementation. Work on parallelization or GPU implementations (Huang et al., 2009; Palhano Xavier de Fontes et al., 2010) has shown a significant reduction in computational time close to real-time processing."}, {"section_title": "Conclusion", "text": "In this paper, we propose a novel patch-based method using expert segmentations as priors to segment anatomical structures. Based on the similarity of intensity content between patches, the new label fusion is achieved by using a nonlocal means estimator. Validation of hippocampus segmentation in healthy subjects and of ventricle segmentation in patients with Alzheimer's disease was performed. In addition, comparison with an appearance-based and a template-based method demonstrated the high performance of our method. During validation, the proposed method obtained a median kappa index value of 0.884 for the HC and 0.959 for the ventricles. The use of a nonlocal means scheme in combination with a method involving nonlinear registration will be the subject of further investigation. Fig. 15 . Method comparison. Three-dimensional ventricle segmentations obtained by the three methods for the subjects with the best kappa index (top), a median kappa index (middle), and the worst kappa index (bottom) obtained by the best template method. The expert-based segmentation is shown in red, the proposed patch-based method in green, the best template method in blue, and the appearance-based method in yellow. Note how the both the appearancebased method and the best template method can cut off the occipital pole of the lateral ventricle. The appearance-based method also cuts off the temporal poles of the lateral ventricle."}]