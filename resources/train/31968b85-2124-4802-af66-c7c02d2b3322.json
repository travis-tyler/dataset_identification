[{"section_title": "Abstract", "text": "We propose a multivariate multilevel model for the analysis of the Italian sample of the TIMSS&PIRLS 2011 Combined International Database on 4th grade students. The multivariate model jointly considers educational achievement on Reading, Mathematics and Science, thus allowing us to test for differential effects of the covariates on the three scores. The multilevel approach allows us to disentangle student and contextual factors affecting achievement, also considering territorial differences in wealth. The proportion of variability at class level is relevant even after controlling for the observed factors. The residual analysis allows us to locate classes with extremely high or low effectiveness."}, {"section_title": "Introduction", "text": "The role of large-scale assessment surveys in the public debate about education has dramatically grown since the mid-1980s. Despite the inevitable criticism, international achievement testing has the merit to display the great variability of the educational systems across the world and to shed light on the process underlying the accumulation of the human capital. As discussed in Rutkowski et al. (2014) , international achievement testing in education has many and ambitious purposes, including the assessment of policies and practices. Indeed, understanding the determinants of achievement in compulsory school is extremely important to design interventions at any level, see among others Reeve and Jang (2006) and the references therein.\nIn this paper we consider the large-scale assessment surveys TIMSS (Trends in International Mathematics and Science Study) and PIRLS (Progress in International Reading Literacy Study). These surveys are generally carried out at different years, but in 2011 for the first time the two cycles coincided, thus providing a sample of students with assessments in Reading, Math and Science. We focus on data for Italy, which represents an interesting case characterized by a relatively homogeneous educational system in a country with marked territorial differences in wealth.\nIn official reports, for any country the outcomes in Reading, Math and Science are analyzed separately by means of multilevel models (Foy and O'Dwyer, 2013) . However, further insights can be obtained by a multivariate multilevel approach, where the three scores are treated as a multivariate outcome measured at student level, with students nested within classes. This approach allows us to estimate the residual correlations between pairs of outcomes at both hierarchical levels, which is important to make a comprehensive picture of student achievement and educational effectiveness. Moreover, a multivariate model enables to test whether the effect of an explanatory variable is identical across outcomes, for example whether the effect of gender is the same for achievement in Reading and Math.\nExploratory analyses show that the three outcomes are highly correlated, in particular at class level. Moreover, the proportion of variability of the outcomes at class level is relevant, thus calling for an analysis of student characteristics, such as gender, family background, and contextual factors, like school resources and wealth of the surrounding area. To this end we exploit the variables included in the TIMSS&PIRLS combined dataset, except for wealth which is measured by the gross value-added at the province level, gathered from an external source. The considered contextual factors are mostly out of the control of school management, thus class level residuals can be interpreted in terms of effectiveness and their analysis gives insights into territorial patterns and it may help to point out anomalous situations.\nEven if the multivariate multilevel model is a well established tool (Yang et al., 2005) , its application to the analysis of large-scale assessment data is novel: therefore, we will emphasize the additional insights given by a multivariate approach and we will discuss several issues arising in the implementation, such as the way of handling the imputed scores (known as plausible values) and the sample weights.\nThe paper is organized as follows. Section 2 describes the TIMSS&PIRLS 2011 Italian dataset and the selected variables. Section 3 outlines the multivariate multilevel model. Section 4 shows the model selection process and reports the main findings. Section 5 provides some concluding remarks and directions for future work."}, {"section_title": "TIMSS&PIRLS 2011: summary of the Italian sample", "text": "The large-scale assessment surveys TIMSS and PIRLS are organized by the International Association for the Evaluation of Educational Achievement (IEA). Specifically, TIMSS is an international assessment of mathematics and science achievements at fourth and eighth grades conducted every four years since 1995, whereas PIRLS provides information on trends in reading literacy achievement of fourth grade students every five years since 2001. In 2011 for the first time the TIMSS and PIRLS cycles coincided, enabling the IEA to release the Combined TIMSS&PIRLS 2011 International Database including fourth grade students responding to both surveys. The data are collected on students selected by a complex multi-stage sampling design (see Section 4.5). Variables are obtained through questionnaires administered to students, their parents, their teachers, and their school principals. We focus on the Italian sample of the TIMSS&PIRLS 2011 combined dataset, which includes 4, 125 students nested in 239 classes, that in turn are nested in 202 schools. Separate achievement scales are produced for Reading, Math, and Science with an international mean of 500 points and a standard deviation of 100 points (Foy, 2013) . For each achievement scale, the TIMSS&PIRLS 2011 database provides five estimates of the student score, known as plausible values. The variability among plausible values encapsulates the uncertainty inherent in the scale estimation process (Mislevy, 1991; Martin and Mullis, 2012) . In Section 3 we will exploit the five plausible values for model fitting; however, for simplicity, in this Section we summarizes the data using a single plausible value (the first one) since this yields accurate enough estimates of aggregate quantities, such as class means (Wu, 2005; Rutkowski et al., 2010) . Table 1 reports sample sizes and summary statistics on achievement for Italy by geographical area, showing a decrease in average scores moving from North to South, whereas the standard deviations among classes have an opposite tendency. The geographical pattern of average scores reflects well known differences in wealth, which we control through the per-capita Gross Value Added (GVA) at market prices in 2010 (Tagliacarne, 2011) . The GVA is measured for each of the 110 Italian provinces, ranging from 55 to 142, with 100 representing the Italian average. Figure 1 shows the patterns at province level of the GVA (left panel) and the average score on Math (right panel, where white areas correspond to provinces without sampled schools). Both quantities tend to decrease from North to South, even if the average score on Math is more irregular.\nThe relationship between Math score and GVA is represented in Figure 2 through a local polynomial smoothing: achievement is positively related to wealth, even if the relationship is weak and it seems to hold only for provinces below the Italian average of 100. Reading and Science have similar relationships, therefore they are not reported.\nIn order to adjust the achievement scores for student and contextual factors, we consider a subset of the variables available in the combined dataset. The choice of this subset is driven by theoretical arguments, exploratory data analysis and previous studies such as the technical Appendix B of the TIMSS&PIRLS 2011 Report (Foy and O'Dwyer, 2013) . Descriptive statistics of the selected covariates are shown in Table 2 . At student level, we include dummy variables for gender (1 if female), pre-school (1 if the student attended at least 3 years) and language spoken at home (1 if not Italian). Furthermore, two home background questionnaire scales from TIMSS&PIRLS 2011 are used to describe the student home environment: Home Resources for Learning and Early Literacy/Numeracy Tasks, described in detail by Martin and Mullis (2013) . In summary, Home Resources for Learning is derived from items on the number of books and study supports available at home and parents' levels of education and occupation; on the other hand, Early Literacy/Numeracy Tasks is the student average score on two scales derived from the parents' responses on how well their child could do some early literacy and numeracy activities when beginning primary school. The last column of Table 2 shows that the background scales have some missing values. At teacher level we consider gender (1 if woman), age group, education (1 if the teacher has a degree) and years of teaching. Class variables are defined as averages of the corresponding student level covariates. At school level, Adequate environment and resources and School is safe and orderly are contextual scales (Martin and Mullis, 2013) , while the other school variables listed in Table 2 are based on the answers of school principals.\nThe number of students of the j-th class is denoted with n j , whereas the total number of students is denoted with N = J j=1 n j . The Italian sample of the TIMSS&PIRLS 2011 Combined Dataset includes N = 4, 125 students nested into J = 239 classes.\nOfficial reports (Foy and O'Dwyer, 2013) consider students as level 1 units and schools as level 2 units. However, in our model the level 2 is represented by classes since several factors act at the class level (e.g. the peer effects), thus merging different classes would obscure some sources of variability. The schools could be considered as a third hierarchical level with their own random effects. However, in the Italian sample only 37 schools out of 202 have more than one class, thus it is not feasible to add school level random effects. Nevertheless, the school characteristics are included in the model as covariates and the correlation between classes of the same school is accounted by robust standard errors for clustered observations (Rabe-Hesketh and Skrondal, 2006) . We specify the following multivariate two-level model for outcome m of student i in class j:\n( 1) where x mij is the vector of student level covariates, w mj is the vector of class level covariates, also including covariates at higher level, e.g. school or province. All the vectors have the outcome index m since they can include outcome-specific covariates, such as the characteristics of the teacher. Student level errors e mij are assumed independent across students, and class level errors u mj are assumed independent across classes. The errors e mij are independent from the errors u mj . In model (1) student level errors e \u2032 ij = (e 1ij , e 2ij , e 3ij ) are assumed to be multivariate normal with zero means and covariance matrix\nwhereas class level errors u \u2032 j = (u 1j , u 2j , u 3j ) are assumed to be multivariate normal with zero means and covariance matrix\nTherefore, the response vector\n\u2032 has residual covariance matrix \u03a3 + T . The class level error u mj represents unobserved factors at class level for outcome m, including the teacher effect. Note that the school level is omitted, thus u mj also accounts for school unobserved factors.\nThe assumptions on the model errors listed above are the standard ones and they can be relaxed in several ways (Grilli and Rampichini, 2014) . In particular, we considered several specifications with heteroscedastic random effects, for example to account for differential variability across geographical areas (Sani and Grilli, 2010) . However, none of the heteroscedastic specifications significantly improved the model fit, which is not surprising in the light of the complexity of the considered model, where the random effects at the class level are characterized by a 3 \u00d7 3 variance-covariance matrix.\nA peculiar heteroscedastic specification that is worth to be mentioned is related to the number of teachers in the class. In fact, the three subjects under consideration may be taught by a single teacher or more teachers. The most frequent situation is a class with a teacher for Reading and another teacher for both Math and Science. The sample correlations between outcomes are slightly higher in classes with a single teacher. This pattern can be accounted by a model with a covariance matrix at the class level depending on the kind of teacher allocation. We tried to estimate separate class level covariance matrices for classes with a single teacher and classes with multiple teachers, but without significant improvements in model fit. Therefore, we proceed the multivariate model with standard assumptions, including a unique class level covariance matrix."}, {"section_title": "Model selection and results", "text": "The analysis is based on the multivariate two-level model of equations (1) to (3). The estimation sample consists of 3,741 students and 237 classes. Indeed, 384 students and 2 classes have been excluded due to missing values in the covariates, see Table 2 . The models are fitted by maximum likelihood. In order to account for the variability induced by plausible values, estimation is performed separately for each of the five plausible values and then the results are combined by using Multiple Imputation (MI) formulas (Rubin, 1987; Schafer, 2003) . The analysis is carried out using the mixed and mi commands of Stata (StataCorp, 2013) .\nIn the following we first show the results from the null model, i.e. without covariates, then we outline the model selection strategy and finally we illustrate the results from the final model."}, {"section_title": "Results from the null model", "text": "In order to explore the correlation structure of the data, we first fit the null model, which has 3 parameters for the means, 6 variance-covariance parameters at student level and 6 variancecovariance parameters at class level. Table 3 summarizes the results of the null model in terms of correlation matrices and between class proportions of variances and covariances after the application of MI formulas. The within class and between class correlation matrices are derived from the corresponding covariance matrices \u03a3 and T of equations (2) and (3), whereas the total correlation matrix is derived from the total covariance matrix \u03a3+T . Table  3 shows that the three scores are highly correlated, in particular at class level.\nThe rightmost matrix in Table 3 reports the percentage of variances and covariances at the class level, namely each element of T is divided by the corresponding element of \u03a3 + T . For example, the percentage of class level variance for Reading is 100 \u00d7\u03c4 2 1 /(\u03c3 2 1 +\u03c4 2 1 ) = 19.8, which is also known as ICC (Intraclass Correlation Coefficient). Note that Reading is the subject with the lowest ICC, maybe because it is most influenced by student background characteristics. The proportion of variability of scores at class level is relevant, thus calling for an analysis of contextual factors. To this end, we select the covariates summarized in Table 2 as explained in the following subsection."}, {"section_title": "Model selection", "text": "The model selection process in principle involves to fit the multivariate multilevel model repeatedly, each time combining the estimates with MI formulas. In order to speed up the selection process, we adopt two simplifications: (i ) the outcomes are analyzed separately with univariate multilevel models, retaining covariates being significant in at least one of the univariate models, and (ii ) estimation is carried out using only the first plausible value. Using a single plausible value gives underestimated standard errors, implying a conservative selection of the covariates.\nIn order to enhance the interpretability of the intercept, we centered continuous covariates at their sample grand means, except for GVA which is centered at 100 (Italian average). As shown in Table 2 , we consider as covariates all the class level means of the student covariates; however, contrary to official reports (Foy and O'Dwyer, 2013), we do not center student level covariates at their class level means. The covariates have been added according to the hierarchy: student, class, school, province. Table 4 reports the models selected at the end of each hierarchical step. All the considered models have 12 variance-covariance parameters: 6 for the within class covariance matrix in equation (2) and 6 for the between class covariance matrix in equation (3). Teacher variables have been added to model M1, but none are significant. Note that models M2 and M3 have the same number of parameters since, after the inclusion of the GVA, the class mean of Early literacy/numeracy tasks is no more significant."}, {"section_title": "Results from the final model", "text": "The results from the final model are obtained by fitting model M3 of Table 4 separately for each plausible value and then combining the estimates through MI formulas. Table 5 reports the estimates of regression coefficients and variance-covariance parameters alongside with robust standard errors. With reference to the considered covariates summarized in Table 2 , all the student level covariates are significant, but the corresponding class means are not. None of the teacher covariates are significant. At school level, the only significant variable is Adequate environment and resources. At province level, the GVA is significant. The last column of Table 5 reports the p-value of the F test for the equality of the regression coefficients across the three outcomes. For example, for the k-th student level covariate the null hypotesis is H 0 : \u03b2 1k = \u03b2 2k = \u03b2 3k . The test, which is feasible only in a multivariate model, is performed with the command mi testtr of Stata, implementing formula (1.17) of Li et al. (1991) . Note that all the contextual covariates have the same effect on the three outcomes, while the student level covariates have different effects, except for pre-school. Also note that, family background covariates have a similar effect on Reading and Science, as opposed to Math, therefore the abilities required for Science seem to be closer to those for Reading than to those for Math. Likely, this is a consequence of the way Science is taught in Italian primary schools.\nThe intercepts in Table 5 represent the average scores for the baseline student: male, language spoken at home is Italian, not attended pre-school, and all the other covariates set at mean values. The performance of the baseline student is beyond the international mean of 500 in all the considered outcomes, though the average score in Math is substantially lower than the average scores in Reading and Science. According to the F test, this difference is significant.\nAll the regression coefficients have the expected signs and are significant for all the considered outcomes, except for being female, which has a negative effect for Math and Science, but no significant effect for Reading. Students from families not speaking Italian at home have a lower performance, especially in Reading and Science. Students who attended pre-school for at least three years have a better performance, with no significant difference among the three outcomes. The two home background questionnaire scales have a positive effect on student achievement. However, Home Resources for Learning (including number of books at home and education level and employment status of parents) has a greater effect on Reading and Science, while Early Literacy/Numeracy Tasks (measuring how well the child could do several early literacy and numeracy activities when beginning primary school) has a stronger effect on Math. Thus, achievements in Reading and Science are more related to cultural and socio-economic factors of the family, while achievement in Math is more related to specific activities in early childhood. At school level, disposing of an Adequate Environment and Resources helps to reach a higher score, with no significant difference across outcomes.\nThe socio-economic context of the province where the school is located is measured by the GVA index. On the basis of the local polynomial smooth of Figure 2 , the effect of the GVA is modelled by a linear spline with a single knot in 100 (the national average). Consistently with the relationship highlighted in the figure, the line for GVA< 100 has a significant positive slope, whereas the line for GVA> 100 is nearly flat and the slope is not significantly different from zero. Therefore, we constrain to zero the slope of the second line of the spline (i.e. GVA> 100), so that wealth affects student achievement only in provinces with GVA below the national average. The effect of the GVA is similar across outcomes and it amounts to about half point in the score for each point in the index. For example, the effect of the GVA on the achievement scores is about \u221222.5 points for the province showing a value of GVA equal to 55 (the lowest value of the index).\nThe proportions of variance explained by the final model with respect to the null model are higher at class level. Indeed, the within-class variances reduce by about 15% for the three outcomes, whereas the between-class variances reduce by 33% for Reading, 20% for Math and 26% for Science. The reduction of the between-class variances is due to the contextual variables at school and province levels and to the compositional effects of student background covariates. Such compositional effects capture cultural and socio-economic factors that are more related to the achievement in Reading, whose class level residual variance shows the greater reduction. Even if the reduction of variances is stronger at the class level, the residual ICC's derived from the estimated variances of Table 5 are quite high, specifically 16.3% for Reading, 27.6% for Math and 26.9% for Science. These values point out the existence of unobserved relevant class level factors. The correlations among outcomes are similar to those observed in the null model, reported in Table 3 . In particular, the estimated correlations among the class level errors of the three outcomes are very high, namely at least 0.93. "}, {"section_title": "Residual analysis", "text": "The level 2 error, or class random effect u mj in model (1) is the contribution of class j to the achievement of students in subject m. This contribution can be interpreted in terms of effectiveness since the model adjusts for differences in student characteristics and contextual factors. Given the high residual correlations among the random effects of the three outcomes (Reading, Math and Science), the residual analysis can focus on a single outcome without any relevant loss of information. In the following, we illustrate the analysis with reference to Math.\nIn principle, the residual analysis could be carried out by combining the results derived from the models fitted on the five plausible values. However, this is not essential since quantities at class level are little affected by the variability induced by the plausible values. Therefore, to simplify the analysis, we consider the level 2 residuals derived from the model fitted on the first plausible value. Once the model has been estimated via maximum likelihood procedures, the level 2 errors u mj are predicted by the level 2 residuals\u00fb mj , obtained as usual by the Empirical Bayes (EB) method (Snijders and Berkhof, 2008) .\nIn order to compare classes in terms of effectiveness, Figure 3 shows a caterpillar plot where EB residuals are reported in increasing order and endowed with 95% confidence intervals defined as \u00b11.96 the comparative standard error. Classes whose confidence interval do not intersect zero have a degree of effectiveness significantly different from the population mean. Specifically, classes with an interval above zero are good since the student average achievement is significantly higher than the level expected on the basis of their covariates. Analogously, classes with an interval below zero are poor. Figure 3 shows that 41 out of 237 classes are good, while 41 are poor.\nThe model accounts for differences in wealth across provinces by means of the GVA index, thus the residuals may reveal further territorial differences not captured by GVA. Table 6 reports the proportions of good and poor classes by geographical area based on level 2 residuals: in North-West good classes prevail on poor classes, while in the Centre the pattern is reversed. This points out a residual territorial effect on mean achievement beyond GVA. This effect can be accounted by geographical dummies in the fixed part of the model, but their coefficients turn out to be not significant. In the two southern areas, the proportions of good and poor schools are higher than in the rest of Italy. This confirms that schools in southern regions have a higher variability in effectiveness, as found by Sani and Grilli (2010) using national standardized test data collected by the Italian Institute for the Evaluation of the Educational System (INVALSI). As mentioned in Section 3, such differential variability could be modelled through heteroscedastic random effects, but in the present application there is no significant improvement in model fit. In order to inspect the distribution of the random effects, EB residuals are standardized with diagnostic standard errors and depicted in the normal probability plot of Figure 4 . Caution is needed since misspecification may be difficult to detect from the residuals (McCulloch and Neuhaus, 2011); anyway, the plot in Figure 4 is reassuring as it does not show serious deviations from normality. In addition, there are only 3 outlying classes, having a standardized residual outside the (\u22123, 3) interval. "}, {"section_title": "A note on sample weights", "text": "In a regression model, weights are needed to obtain unbiased estimates when the sampling is informative, namely the inclusion probabilities are related with the model errors, which is an assumption not directly verifiable. Unfortunately, sample weights inflate the standard errors of the estimators, thus the trade-off between bias and variance should be evaluated case by case. The role of weights is usually assessed by comparing model estimates with and without weights, see among others Rabe-Hesketh and Skrondal (2006) . We checked the effect of including sample weights in the analysis of TIMSS&PIRLS data by fitting univariate multilevel models with and without weights for each score separately.\nThe sampling scheme adopted by TIMSS and PIRLS is a multi-stage design with schools as primary units and classes as secondary units (Martin and Mullis, 2012) . Schools in Italy are stratified according to seven geographic areas (Joncas and Foy, 2013) and, as for the other countries, they are sampled with probability proportional to size, whereas classes are sampled with equal probability from the list of all classes in the school at the target grade. All students in a sampled class are included. At each hierarchical level, the weight is defined as the product of the sampling weight (i.e. the reciprocal of the conditional sampling probability) and the adjustment weight, which accounts for non-participation of sampled units. The overall student weight is obtained by multiplying the weights across the three hierarchical levels (student i, class j, school k): w ijk = w i|jk w j|k w k . In order to perform weighted estimation in multilevel models, the weights must refer to the relevant hierarchical levels (Rabe-Hesketh and Skrondal, 2006) . Therefore, in our two-level model with students nested into classes, we insert both the conditional student weight w i|jk and the unconditional class weight w jk = w j|k w k .\nConsidering the score on Reading, the use of sample weights slightly affects the estimates of the regression coefficients: the signs are unchanged and the average absolute relative variation amounts to 8.7%. However, as expected, the use of sample weights inflates the standard errors for most regression coefficients, with an average absolute relative variation of 7.2%. The ICC reduces from 0.15 to 0.13. Analogous patterns are observed for Math and Science. Overall, we conclude that the use of sample weights do not change the substantial findings of the analysis. Moreover, weighted estimation should be combined with multiple imputation, thus leading to very large standard errors. Therefore, we report the results of unweighted estimation."}, {"section_title": "Final remarks", "text": "We have carried out a secondary data analysis of the Italian sample of the TIMSS&PIRLS 2011 Combined International Database. This database provides an opportunity to perform, for the first time with TIMSS and PIRLS surveys, a joint analysis of achievement in Reading, Math and Science for fourth grade students. The analysis relies on a multivariate multilevel model, thus accounting for both the multivariate nature of the outcome and the hierarchical structure of the data.\nThe additional findings allowed by the multivariate approach are twofold. First, estimating the correlations among the three outcomes, we found that they are high at both student level and class level, even after adjusting for student and contextual factors. The correlations are extremely high at class level, so that in terms of school/class effectiveness the three outcomes are essentially indistinguishable. Second, testing for differential effects of the covariates on the outcomes, we found that females have a lower performance in Math and Science, but not in Reading, and student background covariates have similar effects on Reading and Science, as opposed to Math; on the other hand, contextual covariates have similar effects on the three outcomes.\nA further peculiarity of our analysis lies in the use of the per-capita Gross Value Added at province level (GVA) as an external indicator accounting for territorial differences in wealth. The relationship between student achievement and GVA is well represented through a spline: it is found that student achievement is positively related to wealth for provinces below the national average, with no significant relationship for provinces above the national average. It is worth to note that GVA effectively replaced the dummy variables for the geographical areas, yielding a parsimonious and more interpretable model.\nThe residual analysis allowed us to locate classes with extremely high or low effectiveness. Such classes should be inspected to understand the reasons of the outlying performances and to plan interventions.\nDespite their richness, TIMSS&PIRLS data are collected by a cross-section design, thus preventing to study the dynamic of achievement processes. Indeed, the Italian Institute for the Evaluation of the Educational System (INVALSI) is currently planning longitudinal surveys. Recently, Bartolucci et al. (2011) analysed the longitudinal data gathered by an INVALSI pilot study for the Lombardy region, showing the ability of multilevel latent Markov models to address interesting research questions on achievement progress."}]