[{"section_title": "Abstract", "text": "Marginal model is a popular instrument for studying longitudinal data and cluster data. This paper investigates the estimator of marginal model with subgroup auxiliary information.\nTo marginal model, we propose a new type of auxiliary information, and combine them with the traditional estimating equations of the quadratic inference function (QIF) method based on the generalized method of moments (GMM). Thus obtaining a more efficient estimator.\nThe asymptotic normality and the test statistics of the proposed estimator are established.\nThe theoretical result shows that the estimator with subgroup information is more efficient than the conventional QIF one. Simulation studies are carried out to examine the performance of the proposed method under finite sample. We apply the proposed method to a real data for illustration."}, {"section_title": "Introduction", "text": "Longitudinal data or cluster data exists commonly in many fields, such as biomedical, economics and so on. For longitudinal data, the unknown correlation structure within different measurements of the same subject brings many troubles to the analysis of this type of data.\nIf the within-subject correlation is ignored and all observations are treated independently, the inference result may be inaccurate. As an extension of the generalized linear models (Nelder and Wedderburn, 1972; McCullagh and Nelder, 1989) , Liang and Zeger (1986) proposed a kind of marginal model, which just make model assumption on the conditional expectation and variance of each component of the response given the covariates without considering the correlation structure. And they suggested to use the generalized estimating equations (GEE) method to estimate the parameters involved in this model. The score type estimating equations of the GEE method were obtained based on the working correlation matrix, which refers to the assumed conditional correlation structure among different components of the response vector.\nThe working correlation matrix usually contains an unknown nuisance parameter set which also needs to be estimated during the estimating procedure of GEE method. When the working correlation matrix is misspecified, although the GEE estimator is still consistent, it may suffer from loss of efficiency. Qu et al. (2000) introduced a more efficient estimator obtained by the quadratic inference functions (QIF) method. They approximated the inverse of the working correlation matrix as a linear combination of some known basis matrices and constructed a quadratic inference function based on those matrices. Minimizing this quadratic function, the optimal solution is the QIF estimator. Since the nuisance parameters in working correlation matrix are not included in the quadratic function, the QIF estimator still performs well in efficiency under the misspecified case. QIF method has been widely used in many models. Qu and Li (2006) studied the estimation of varying coefficient model with the QIF method. Li and Yin (2009) applied the QIF method to the accelerated failure time model with multivariate failure time. Li et al. (2016) investigated the QIF estimator of the marginal additive hazards model with cluster failure time.\nRecently, how to apply the information from other sources to improve the efficiency of statistical inference is becoming a research focus, especially for the combination of the individual-level data and the summary-level information which can be obtained from other studies. Auxiliary information method is one popular approach, which stands for the information with specific form provided by other datasets. For example, using covariate-specific disease prevalence information, that is the conditional probability of disease prevalence under different levels of covariate, as auxiliary information, Qin et al. (2015) obtained more efficient estimator to Logistic regression model in case-control studies. Chatterjee et al. (2016) developed the auxiliary information to regression models. They calculated the efficient likelihood estimator of parameter in regression model by incorporating the summary-level information from external big data with the likelihood function and extended their method to the case that the distribution of covariates in the internal data is different from that of the external data. Huang et al. (2016) proposed a double empirical likelihood estimator of the regression parameter in Cox's proportional hazards model which synthesizes the t * -year survival probabilities as auxiliary information. Compared with the conventional partial likelihood estimator, the efficiency of the double empirical likelihood estimator has been improved significantly with the subgroup information.\nIn this paper, to improve the efficiency of parameter estimator in the marginal model, we add a new type of auxiliary information into the procedure of parameter estimation based on the GMM (Hansen, 1982) method. Different from the previous researches about the auxiliary information in regression models, we construct the estimator with auxiliary information from the estimating equations rather than the likelihood function. In addition, previous studies are mainly focus on the one dimensional independent response case, and we explore the multivariate correlated case directly.\nThe rest of the article is organized as follows. In section 2, we introduce the main results in this paper, which includes the marginal model as well as its properties, the proposed auxiliary information and the estimation procedure with auxiliary information by the GMM method. The asymptotic properties of estimator based on the procedures is also presented.\nThe simulation studies are shown in section 3. And we illustrate our proposed procedures with a real data example in section 4. A brief discussion is given in Section 5. And the proofs of the theorems are in the Appendix."}, {"section_title": "Main Results", "text": ""}, {"section_title": "Marginal Model and Auxiliary Information", "text": "In this paper, we just consider the case of longitudinal data, while the estimation procedure of cluster data is similar. For i = 1, \u00b7 \u00b7 \u00b7 , n and j = 1, \u00b7 \u00b7 \u00b7 , q, let\nthe response vector of the ith subject, X T ij = (X ij1 , \u00b7 \u00b7 \u00b7 , X ijp ) be the jth observation of the p-dimensional covariate of the ith subject, thus X i = (X ijk ) represents a q \u00d7 p covariate matrix of the ith subject. Without loss of generality, we assume that observations among different subjects are independent. The marginal model takes the form of\nand \u03b2 is the parameter vector of interest. In addition, \u03c8 is the scalar parameter, h(\u00b7) and v(\u00b7) are known link functions. Qu et al. (2000) proposed to estimate \u03b2 by the QIF method. They expressed the inverse of the working correlation matrix R(\u03b1) as\nT is the nuisance parameter vector and {M 1 , \u00b7 \u00b7 \u00b7 , M L } is a set of known basis matrices. Based on those basis matrices, they obtained the following estimating\nwhere\u03bc i is the partial derivative of \u00b5 i with respect to\nT is the conditional mean vector and A i is a diagonal matrix with each entry as the marginal conditional variance, Var(Y ij |X ij = x ij ). The QIF estimator of \u03b2 is calculated by minimizing the quadratic inference function\nwhere \u03a3 *\nTo marginal model, we suggest a new type of auxiliary information. Let (\u2126 1 , \u00b7 \u00b7 \u00b7 , \u2126 K ) be a partition of \u2126, which is the range space of covariate X. If the conditional expectation of the response in subgroups \u2126 k , k = 1, \u00b7 \u00b7 \u00b7 , K are provided, we could consider them as auxiliary information. In fact, the specific expression of the auxiliary information is\nNow, we change the auxiliary information to the form of estimating equations. By double expectation, \u03c6 k satisfies\nIn the following part, we will incorporate equation (3) into the estimate procedure."}, {"section_title": "GMM Estimator with Auxiliary Information", "text": "Noting (3), we have 1 n\nCombing the estimating equations (4) with (1), we have\n. . .\nwhere\nIt is obvious that the number of estimating equations in (5) is pL+Kq, which is larger than the dimension of parameter vector \u03b2. As it is stated in Hansen (1982) , instead of solving the estimating equations directly, we estimate \u03b2 by minimizing the following quadratic function\nwhere\nWe can obtain the optimal solution of \u03b2 by the Newton-Raphson iterative algorithm."}, {"section_title": "Large sample properties", "text": "We present the large sample properties of the proposed estimation method. Throughout,\nTheorem 1 Under Conditions C1-C5 in the Appendix, we have that\nwhere \u03b2 0 is the true value of parameter vector \u03b2, and the definition of B 1 , B 2 , \u03a3 1 and \u03a3 2 are presented in the Appendix.\nFrom the proof of Theorem1, we have that the asymptotic variance of the QIF estimator\nthe new estimator with auxiliary information is asymptotically more efficient than the QIF one.\nIn order to make the statistical inference on \u03b2 in the marginal model, we construct \u03c7 2 test statistic on the basis of the quadratic inference function. Suppose that the parameter vector could be decomposed as \u03b2 = (\u03b3 T , \u03bb T ) T , where \u03b3 is p 1 dimensional and \u03bb is p \u2212 p 1 dimensional. Suppose that we are interested in the hypothesis test H 0 : \u03b3 = \u03b3 0 , then this hypothesis could be performed based on the following result by treating \u03bb as a nuisance parameter vector.\nT and \u03bb be the GMM estimator of \u03bb with auxiliary information when \u03b3 is fixed at \u03b3 0 . Under Conditions C1-C5 in the Appendix, we have\nThe proof of Theorems 1 and 2 are briefly outlined in the Appendix."}, {"section_title": "Simulation Studies", "text": "In this section, we conduct a series of simulation studies to examine the performance of our\nproposed method under finite sample. We consider the following marginal model,\nwhere \u03b2 1 = 0.5 and\nT is generated from a multivariate normal distribution N 0, \u03a3 1 X , and covariate X 2 is simulated from a Bernoulli distribution taking a value of 0 or 1 with probability 0.5. We obtain the response vector\nT from a multivariate normal distribution with mean vector \u00b5 = (\u00b5 1 , \u00b5 2 , \u00b5 3 )\nT and covariance matrix \u03a3 Y , where \u00b5 j = \u03b2 1 x j1 + \u03b2 2 x 2 , j = 1, 2, 3.\nIn each case, we estimate \u03b2 1 and \u03b2 2 by the QIF and GMM with auxiliary information method, respectively. All simulation results are based on 500 replications, which include the bias (Bias), the standard deviation (SD), the standard error (SE) and the empirical coverage probability (CP).\nIn order to test the influence of the working correlation matrix on the proposed method, we consider two common types of \u03a3 Y and the working correlation matrix, which contains the compound symmetry (CS) structure and the first-order autoregressive correlation (AR (1)) structure. To covariate X 1 , we assume that \u03a3 1 X has CS structure with \u03c1 X = 0.5, i.e., \u03a3 1 X = I 3 + \u03c1 X 1 3 1 T 3 \u2212 I 3 , where I 3 and 1 3 represent the 3 \u00d7 3 identity matrix and 3-vector of ones respectively. The inverse of the working correlation matrix with CS structure can\nand a 1 (\u03b1) = \u03b1/ (4\u03b1 2 \u2212 \u03b1 \u2212 1), \u03b1 is a nuisance parameter and M 1 is a 3 \u00d7 3 matrix with 0 on diagonal as well as 1 off diagonal. Under the AR(1) assumption, the inverse of working correlation can be approximately expressed as R \u22121 (\u03b1) = b 0 (\u03b1)I 3 + b 1 (\u03b1)M 2 by omitting an unimportant matrix with 1 on (0, 0) and (3, 3), and 0 elsewhere. In the above expression,\nand M 2 is a 3 \u00d7 3 matrix with 1 on two main off-diagonals and 0 elsewhere. We then divide all the subjects into two subgroups by the value of covariate X 2 , which have the follow form,\nBy the property of multivariate normal distribution,\nSubstituting \u03b2 2 by its true value, the auxiliary information of the two groups are \u03c6 * 1 = (\u22120.5, \u22120.5, \u22120.5) T and \u03c6 * 2 = (0, 0, 0) T , respectively. Choosing the sample size n = 300, \u03c1 Y = 0.2, 0.5 and 0.8, the simulation results are presented in Table 1 .\nIn Table 1 , \"GMMAI\" represents the estimator obtained by the GMM method with auxiliary information \u03c6 * 1 and \u03c6 * 2 . The results show that both the QIF and GMM incorporated auxiliary information methods perform well: the biases are very small, the SDs are close to the SEs, which are achieved by the asymptotic variance formula, and the CPs generally match the nominal level 95%. The QIF and GMMAI estimators are more efficient when the the working correlation matrix is correctly specified than misspecified. However, the difference is not significate. Furthermore, when incorporated the auxiliary information, the estimators of \u03b2 1 are nearly of the same with the QIF ones as \u03c6 * 1 and \u03c6 * 2 only involve the information about covariate X 2 . Whereas, the results of \u03b2 2 by these two methods are quite different: the SDs of\u03b2 2 by the GMM method with auxiliary information are only about 1/2 to those by the QIF method in all cases, which shows that the efficiency of parameter estimation can be improved largely when considering the auxiliary information. Since whether the correlation matrix is specified correctly has little influence on the estimation results, we just consider the cases with correct specified R(\u03b1) in the following simulation studies. Now, we study the effect of auxiliary information on estimation efficiency in detail. We consider the values of X 1 as well as X 2 when grouping the subjects. The obtained subgroups can be summarized as\nTo estimate the auxiliary information, we calculate the mean of Y in each subgroup, and express the auxiliary information as \u03c6 1 , \u03c6 2 , \u03c6 3 and \u03c6 4 . Once combined \u2126 1 and \u2126 2 , \u2126 3 and \u2126 4 respectively, \u2126 1 \u2212 \u2126 4 will shrink to \u2126 * 1 and \u2126 * 2 . Firstly, we consider a simple case when \u03a3 1 X = I 3 , \u03a3 Y has CS and AR(1) structure with \u03c1 Y = 0.2, 0.5 and 0.8, sample size n = 200 and 500. We estimate the parameters in model (6) by three methods-QIF, GMMAI2 and GMMAI4, where \"GMMAI2\" represents GMM estimator with auxiliary information \u03c6 * 1 \u2212 \u03c6 * 2 and \"GMMAI4\" stands for GMM estimator with subgroup information \u03c6 1 \u2212 \u03c6 4 . The simulation results are shown in Table 2 . The results of GMMAI2 in Table 2 are similar with that in Table 1 , that is only the efficiency of \u03b2 2 can be improved when we incorporate the auxiliary information \u03c6 * 1 \u2212 \u03c6 * 2 . However, when we combine \u03c6 1 \u2212 \u03c6 4 with the estimation procedure, the power of \u03b2 1 is also improved, at the same time, the SD of \u03b2 2 is more smaller than GMMAI2 method. For example, when n = 200 and \u03a3 Y has CS structure with \u03c1 Y = 0.2, the SD of\u03b2 1 by GMMAI4 is only about 1/2 to that by QIF and GMMAI2 methods, and the SD of\u03b2 2 by GMMAI4 method is nearly 1/3 to that by the QIF and the relative efficiency of\u03b2 2 by GMMAI4 is about 1.5 to that by GMMAI2. Once again, these results show that applying auxiliary information effectively can help us improve the efficiency of parameter estimators.\nIn above simulations, we just use the first component of X 1 in making groups. In fact, it is usually very difficult to obtain the information related to all the components of covariate X 1 . Thus, we conduct another simulation study to explore the relationship between \u03c1 X and the extend of improvement in estimation efficiency when the auxiliary information is only related to part components of X 1 . We estimate the parameter in model (6) by QIF, GMMAI2 and GMMAI4 methods, respectively when n = 300, \u03a3 Y has CS structure with \u03c1 Y = 0.5, and \u03a3 1 X has CS and AR(1) structures with \u03c1 X = 0.2, 0.5 and 0.8. Besides of the Bias, SDs, SEs and CPs, we also calculate the relative efficiency (RE) of the estimated coefficients, which represents the variance ratio of the QIF estimator and GMM estimator with subgroup information. The results are summarized in Table 3 . The table shows that the RE of\u03b2 1 by the GMMAI4 method is becoming larger with the increasing of \u03c1 X . In fact, the larger \u03c1 X is, the higher correlation among the components of X 1 is. In this case, even though the auxiliary information only be connected to X 11 , it also involves the information of the other two components in X 1 . Thus, the power of estimator be improved to a larger extend.\nFinally, we study the impact of the auxiliary information on the power of hypothesis about parameters \u03b2 1 and \u03b2 2 in model (6). \u03a3 In order to examine the conclusion in Theorem 2, we plot the QQ-plot of n{Q \u03b2 0 1 ,\u03b2 2 \u2212Q \u03b2 1 ,\u03b2 2 } and n Q \u03b2 1 , \u03b2 0 2 \u2212 Q \u03b2 1 ,\u03b2 2 under \u03b2 0 1 = 0.5 and \u03b2 2 = \u22120.5 by QIF, GMMAI2 and GMMAI4 methods, respectively, which are presented in Figure 1 and 2. In these figures, the sample quantiles show linear relationship with the theoretical ones, which is consistent with the theoretical conclusion in Theorem 2."}, {"section_title": "Real Data Analysis", "text": "As an illustration, we applied the proposed methods to the Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K) database, which contains the gender and longitudinal observations of 21409 children's reading, math and science ability scores at seven time points. Those ability scores were obtained from the Item Response Theory (IRT) study, which can be used to measure a child's underlying ability. We study the influence of reading ability, math ability and gender on children's science ability through the observations measured at Grade 3, 5 and 8. Deleting the subjects with missing data, the sample size is 8591. For the convenience of analysis, we standardize all the ability scores firstly. Letting the science ability score be the response, and gender, reading as well as math ability scores be covariates, which are denoted by Y ij , X i1 (1-male,0-female), X ij2 and X ij3 respectively for i = 1, \u00b7 \u00b7 \u00b7 , 8591; j = 1, 2, 3. By correlation analysis, we found that different components of Y are highly correlated. So we consider the following marginal model,\nTo obtain the auxiliary information, we divide the subjects into subgroups. Here we try three kinds of grouping manners. First of all, we group the data by the value of gender and math ability scores in Grade 3. The subgroups can be written as\nCombing \u2126 In the second case, we separating the subjects into groups by the reading and math ability scores in Grade 3. The corresponding subgroups respectively. Finally, we try to use the reading ability scores in Grade 3 and 8 to make groups. The obtained subgroups take the forms of\nIf we incorporate \u2126 and \u2126 III * 2 . In order to use the proposed method, we randomly sample a subset of sample size 1000 from the original complete data for our analysis, and the left data are used for estimating the auxiliary information. We estimate the parameters in marginal model by QIF, GMMAI2 and GMMAI4 methods under different grouping manners. In each case, \"GMMAI2\" represents the GMM estimator with 2 subgroups information and \"GMMAI4\" stands for GMM estimator with 4 subgroups information. For example, \"GMMAI2(I)\" stands for GMM estimator with auxiliary information provided by subgroups \u2126 * I 1 \u2212 \u2126 * I 2 . The analysis results are presented in Table 5 . The table shows that the estimates of parameters by different methods are very similar. \u03b2 1 are smaller than 0, which indicates that, to children with similar reading and math ability, a girl's science ability is higher than a boy's. As we all known, the development of girl's intelligence is earlier than that of boy's, so this result is reasonable. Moreover, we observe that the estimated coefficients of reading and math ability are larger than 0, which illustrates that these two kinds of ability have positive effects on children's science ability.\nA good reading ability could help children understand new things easily, while outstanding math ability does good to cultivate children's logical thinking ability. So all of them are helpful to promote children's science ability. Finally, the SEs of the estimated parameters obtained by the GMM method with subgroup information are smaller than that by the QIF, which illustrates that the auxiliary information can improve the estimation efficiency. This result is consistent with our theoretical results."}, {"section_title": "Discussion", "text": "In this paper, in order to improve the efficiency of the estimated coefficient in the marginal model, we proposed a kind of GMM procedure with auxiliary information. The asymptotic properties of the proposed estimators have been established. The simulation studies and real data analysis show that our proposed estimators are more efficient than the one obtained by the conventional QIF method. However, we just considered the application of the auxiliary information in marginal model based on a complete data set. It is of interest to explore how to apply the auxiliary information to some more complicated cases, such as the missing data, in further. In addition, we just consider the case that the auxiliary information is consistent with the sample data set we researched. It is meaningful to study how to use the auxiliary information, which is inconsistent with the data set we are interested in."}, {"section_title": "Appendix", "text": "For a vector or matrix v, v denotes the L 2 -norm of v. We impose the following regularity conditions that are needed to establish the asymptotic properties of the estimators.\nThroughout, \" P \u2212\u2192\" represents converge in probability.\nC1. There exists a unique \u03b2 0 in a compact space, which satisfies E {g(\u03b2 0 , X)} = 0.\nT are positive definite and finite.\nC3. Matrix-valued function A(\u03b2) is second continuously differentiable with respect to \u03b2 and is uniformly bounded up to the second order partial derivatives, where A(\u03b2) is a diagonal matrix with each entry as the marginal conditional variance of the response,\nC4. The matrix \u03a3 n (\u03b2) is second continuously differentiable with respect to \u03b2, and there exist a matrix \u03a3(\u03b2) which is continuous and positive definite at \u03b2 0 such that\nwhere V \u03b5,\u03b2 0 is a neighborhood of \u03b2 0 .\nC5. The vector valued function g (n) (\u03b2) is second continuously differentiable with respect to \u03b2, and there exist a matrix g(\u03b2) which is continuous at \u03b2 0 such that\nWe define\nProof of Theorem 1. First, we establish the asymptotic property of the derivative of S (n) (\u03b2) with respect to \u03b2 T , when \u03b2 = \u03b2 0 . From the definition of S (l) n (\u03b2), we have\nThe partial derivative of the mth component of S\nn (\u03b2) with respect to the hth component of \u03b2, \u03b2 h can be decomposed as\nwhere\nFrom the law of large numbers and double expectation, it follows that a n (\u03b2 0 ) = o p (1) and\nas n \u2192 \u221e. By Slutsky's theorem, we have\nwhere B 1 is a pL \u00d7 p matrix, whose the {(l \u2212 1)p + m}th row and hth column takes the form\nThen, we consider the asymptotic property of the derivative of \u2202\u03a8 (n) (\u03b2)/\u2202\u03b2 T , when \u03b2 = \u03b2 0 .\nNote that\nBy Slutsky's theorem, we obtain\nwhere\nand\nCombining (7), (9) and (10), one can show that\nwhere\n, the estimating equation takes the form of\nFrom Slutsky's theorem, we have that U n (\u03b2 0 )\nBy Taylor expansion, we have\nBy the law of large numbers, we obtain\nBy central limit theorem, we observe\nFrom (11) and the sandwich formula, we have\nwhere\nThis completes the proof of Theorem 1.\nProof of Theorem 2. During the proof, we delete the subscript \"GMM\" from \u03b3 GMM for simplicity. Denote\nBy Taylor expansion, we have\nwhere (\u03b3 * , \u03bb * ) is a point on the line segment connecting (\u03b3 0 , \u03bb 0 ) and ( \u03b3, \u03bb), and\nwhere (\u03b3 0 , \u03bb \u2020 ) is a point on the line segment connecting (\u03b3 0 , \u03bb 0 ) and (\u03b3 0 , \u03bb).\nFrom (12) and (13), we have\nBy Taylor expansion, it follows that\nThen,\u03bb\nFrom the proof of Theorem 1, we obtain 1 2\nDividing matrix B into a 2-by-2 block matrix according to the dimensions of \u03b3 and \u03bb, we have \nNoting the conclusion of Theorem 1, one can show that\nThis completes the proof of Theorem 2. Table 3 : Simulation results of model (6) under different \u03c1 X with sample size n = 300. Note: \"I\" represents grouping the subjects by gender and math ability score in Grade 3, \"II\" stands for grouping the subjects by the math and reading ability score in Grade 3 and \"III\" indicates that we dividing the subjects into groups by the reading ability scores in Grade 3 and 8."}]