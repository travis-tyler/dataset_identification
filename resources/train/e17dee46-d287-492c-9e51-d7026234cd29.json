[{"section_title": "Abstract", "text": "The neuroimaging genetic study usually needs to deal with high dimensionality of both brain imaging data and genetic data, so that often resulting in the issue of curse of dimensionality. In this paper, we propose a group sparse reduced rank regression model to take the relations of both the phenotypes and the genotypes for the neuroimaging genetic study. Specifically, we propose designing a graph sparsity constraint as well as a reduced rank constraint to simultaneously conduct subspace learning and feature selection. The group sparsity constraint conducts feature selection to identify genotypes highly related to neuroimaging data, while the reduced rank constraint considers the relations among neuroimaging data to conduct subspace learning in the feature selection model. Furthermore, an alternative optimization algorithm is proposed to solve the resulting objective function and is proved to achieve fast convergence. Experimental results on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset showed that the proposed method has superiority on predicting the phenotype data by the genotype data, than the alternative methods under comparison."}, {"section_title": "Introduction", "text": "In the past decades, the genetic variants have been suspected to associate with development of early and late-onset Alzheimer's Disease (AD). For example, the APOE 4 allele has been observed as the major carrier of cholesterol in the central nervous system compared to other APOE isoform carriers. Specifically, individuals with one or two copies of APOE 4 are more likely to develop late-onset AD [41] . Meanwhile, neuroimaging phenotypes have also been used for studies of genetic variants [25, 31] . Hence, neuroimaging genetic study has become an emergent cross-disciplinary field, where genetic information such as Single Nucleotide Polymorphism (SNP) is combined with neuroimaging data such as structural Magnetic Resonance Imaging (MRI), to analyze both biological and neurobiological systems of the human brain to help with prevention and treatment of AD [31] .\nRecent interest in neuroimaging genetic study is focused on association studies between phenotypes and genotypes. The motivation of the previous studies is that the genetic variants reflect the variability of phenotypes, while phenotypes may increase the power to detect causal variants of genotypes. For example, Brun et al. [5] proposed to select a subset of neuroimaging features by conducting association studies between neuroimaging features of a whole brain and a small number of genetic information, while the studies in [17, 38, 51] focused on selecting a subset of SNPs to conduct association analysis between a limited number of neuroimaging features and all SNPs.\nVounou et al. categorized the existing association studies between phenotypes and genotypes into four classes [36] : 1) Candidate Phenotype-Candidate Gene Association (CP-CGA), e.g., between a brain surrogate and the MECP2 gene [22] ; 2) Candidate Phenotype-Genome-Wide Association (CP-GWA), e.g., between SNPs and a diseaserelated hippocampal MRI-driven measure [17] ; 3) Brain-Wide and Candidate-Gene Association (BW-CGA), e.g., between the gray matter volume in the entire brain and the APOE 4 allele [11] ; and 4) Brain-Wide and Genome-Wide Association (BW-GWA), e.g., between voxel-based neuroimaging phenotypes and SNP genotypes [34, 36] . The differences between the four classes lie in the way that they define the number of phenotypes and genotypes under consideration, i.e., which one is available on either predefined candidates or the whole phenotypes and genotypes. The BW-GWA paradigm is a generation version of other three paradigms. More importantly, the BW-GWA paradigm has the potential benefit of helping to discover important associations between neuroimaging based phenotypic markers and genotypes from a different perspective. For example, by identifying high associations between specific SNPs and brain regions related to AD, information of the specific SNPs can be used to predict the risk of AD much earlier, and even before pathological abnormalities onset. This allows clinicians the time to track the course of AD and find solutions to prevent further degeneration of brain regions.\nIn real applications, a few literature have been designed to conduct the BW-GWA study, i.e., conducting neuroimaging genetic study using all 620, 901 SNPs in the ADNI dataset. Usually, most studies conducted a process of SNP filtering to remove rare genetic variants or variants violating the Hardy-Weinberg Principle, thus resulting in a subset of all the SNPs to conduct neuroimaging genetic study, i.e., the BW-CGA study. For example, the number of the selected SNPs is 437,577 [36] , 437,607 [18] , 448,293 [34] , 501,584 [20] , and 15,788 [2] out of 620,901 SNPs in these different studies. The reasons of using a subset of SNPs rather than all SNPs include the high computational cost of the algorithm, the effectiveness of neuroimaging genetic study, etc. More specifically, in the Region-Of-Interest (ROI) based neuroimaging genetic study, hundreds of the neuroimaging features can easily result in the lack of the ranks of the coefficient matrix to output ineffective performance of neuroimaging genetic study and expensive computation cost. On the other hand, removing irrelevant/redundant SNPs in the BW-CGA study can always output more stable and effective performance of neuroimaging genetic study, compared to the BW-GWA study [17, 20] . Therefore, in this work, we focus on the BW-CGA study, i.e., the neuroimaging genetic study between ROI-based neuroimaging features and a subset of SNPs.\nInspired by recent advancements in neuroinformatics and bioinformatics, machinelearning techniques have been used for imaging-genetic association studies [51] . However, the high dimensionality of neuroimaging phenotypes and genotypes makes the BW-CGA study challenging. In addition, although the phenotypes and the genotypes have been indicated to have strong correlations, not all are equally informative. The BW-CGA study with all phenotypes and the selected genotypes may result in unreliable association models while no appropriate constraints. In this regard, only a few studies have focused on the BW-CGA problem [17, 34] . For example, pairwise univariate analysis (e.g., Pearson correlation) treats the neuroimaging phenotypes and the genetic information as independent and isolated units without taking into account the interacting relationships among them. The earlier methods (e.g., [1, 4, 18] ) used Multi-output Linear Regression (MLR) methods for BW-CGA by estimating the coefficients of the response variables independently. Recent studies in [34, 36] exploited dimensionality reduction techniques for modeling and interpreting associations between phenotypes and genotypes, which limits their power in revealing and interpreting complex imaging-genetic associations. In a nutshell, previous studies mostly consider only inter-relations between genotypes and phenotypes, by ignoring potential informative intra-relations.\nIn this paper, we formulate the BW-CGA study as a regression problem by regarding the genotypes and the phenotypes as regressors and responses, respectively. By finding optimal weight coefficients in a regularized linear regression model, our proposed method may 1) discover the inherent relations in the phenotypes and the genotypes, which are interpretable with the linear feature selection model; and 2) predict phenotypes (e.g., MRI volumes in our work) from a new genotype sample (e.g., SNPs in our work), based on which potential risk of an incidence of a certain disease, such as AD, may be identified. Specifically, we propose a novel sparse regression model to find matrices that transform variables into subspaces by introducing a reduced rank constraint on a weight coefficient matrix. In the resulting subspaces, it is easier to understand relations among variables. The rationale of the reduced rank constraint is that the high-dimensional data have reduced rank structures due to noise and redundancy inherent in data [13, 19, 36, 50] . We also apply a group sparsity constraint (i.e., an 2,1 -norm regularizer [15, 33, 39, 43, 48, 49] ) on each reduced rank matrix, such that highly informative phenotypes and genotypes are selected for the BW-CGA study [38] . The joint use of the reduced rank constraint and the group sparsity in our linear regression model helps select a subset of brain regions and a subset of genotypes, which show high associations in the end. Finally, we conducted experiments on the ADNI cohort to validate our method's effectiveness."}, {"section_title": "Method", "text": ""}, {"section_title": "Sparse reduced rank regression", "text": "By denoting X \u2208 R n\u00d7d and Y \u2208 R n\u00d7c , respectively, as the SNP genotype data and MRI phenotype data, where n, d, and c, indicate the number of the samples, the SNP dimensionality, and the MRI dimensionality, respectively, we assume that there is linear relationships between genotypes and phenotypes as well as there is redundancy in the phenotypes, the group sparsity based multi-output linear regression [14, 54] is formulated as follows\nwhere W \u2208 R d\u00d7c , b \u2208 R c\u00d71 , and e \u2208 R n\u00d71 , respectively, are the coefficient matrix, the bias term, and the column vector with all ones. \u00b7 2 F and \u00b7 2,1 , respectively, indicate the Frobenius norm and 2,1 norm [16, 42, 46, 50] ."}, {"section_title": "Group sparse reduced rank multi-output linear regression", "text": "Equation (1) conducts feature selection on genotypes (i.e., X) and has been used for removing the redundancy of genotypes. However, in multi-output linear regression, both the genotypes (i.e., X) and the phenotypes (i.e., Y) may have noise to add the real ranks of the feature matrix and the response matrix. Moreover, the phenotype Y may also contain redundancy.\nTo solve the first issue, we make the hypothesis of reduced rankness of the MRI phenotypes and the SNP genotypes, as shown in [36] , to change the sparsity regression model in (1) to a sparse reduced rank regression model. Specifically, we assume W = BA T , where B \u2208 R d\u00d7r , A \u2208 R c\u00d7r , r is minimal rank between X and Y, and\nFurther, from the reduced rankness of W (or BA T ), we can derive the following inequalities:\nAccording to (3), we think that the reduced matrix XB \u2208 R n\u00d7r , which is then multiplied with A T to represent the response variables in (2), has less than r latent factors. The assumption of latent factors in either the phenotypes or the genotypes has been also considered in [8, 9, 50, 54] for achieving well-conditioned estimation. Geometrically, B has the effect of transforming X into r-dimensional space, and determining B can be considered as subspace learning by using the correlations among the features, i.e., d SNP genotypes as a group. In the meantime, (4) implies that the rank of the predicted matrix\u0176 \u2208 R n\u00d7c (i.e.,\u0176 = XBA T \u2212 eb T ) is less than r. That is, each c columns of Y can be represented by a linear combination of at most r latent response variables. This considers the correlations among the response variables to conduct subspace learning on Y, based on which we use to predict\u0176. Therefore, the reduced rank constraint on the coefficient matrix has the effect of subspace learning on both the regressor matrix and the response matrix by considering intra-relations in genotypes and phenotypes, separately.\nAs a complex system, the brain regions of the human being usually are related to each other [17, 38] . Moreover, a number of literature have shown that redundant brain regions may affect the performance of neuroimaging analysis. By considering the above observations, we add a group sparsity constraint on Y (i.e., ROIs) to have the our final objective function:\nwhere \u03b1 and \u03b2 are the tuning parameters and I \u2208 R r\u00d7r is an identity matrix. The 2,1 -norm regularizers on BA T and A, respectively, manifest to conduct regressor/response selection on X (i.e., SNP genotypes) and Y (i.e., MRI phenotypes). The orthogonality constraint on A encourages the finding of un-correlated vectors, which can also be regarded as a transformation matrix of subspace learning on Y. Furthermore, the orthogonality constraint A T A = I implies that BA T 2,1 shares the same zero-rows of X with B 2,1 , due to the fact that BA \nClearly, the 2,1 -norm regularizers on B and A penalize coefficients of B and A in a rowwise manner for joint selection or un-selection of the regressors and the response variables. After optimizing (6), elaborated in Section 2.3, we conduct feature selection [24, [42] [43] [44] 53] by discarding the regressors (or the response variables) whose corresponding coefficients in B (or A) are zeros in the rows. More specifically, according to (12) , the sparse rows on A imply that their corresponding columns (i.e., ROIs) of Y will not be selected, while the sparse rows on B imply that their corresponding features (i.e., SNPs) of X will be excluded by the proposed model. This results in the selection of a subset of brain ROIs from Y that is statistically meaningful and associated with a subset of SNPs (i.e., the selected SNPs) from X. By means of our optimization method described below, the reduced rank constraint conducts subspace learning on both X and Y, so that the sequential feature selection is conducted by avoiding noise in the data thus improving performance. In contrast, the group sparsity constraints ensure the reduced rank constraint to explore the reduced rank representations of data on the 'purified data', i.e., the data after removing uninformative ROIs and SNPs by group sparsity constraints. These two steps alternate until the objective function converges. This iterative learning yields optimal results of both feature selection and subspace learning. That is, the selected ROIs are associated with the selected SNPs."}, {"section_title": "Optimization", "text": "This section describes the optimization process of the parameters b, B, and A. Specifically, we iteratively conduct the following three steps until convergence by means of Iteratively Reweighted Least Square (IRLS) [32, 53] "}, {"section_title": "(i) Update b with fixed B and A.", "text": "For fixed B and A, (6) reduces to\nBy setting the derivative of (7) with respect to b to zero, we have:"}, {"section_title": "(ii) Update B with fixed b and A.", "text": "For fixed b, we substitute (8) into (6) by yielding the following:\nBy introducing H = I \u2212 1 n ee T \u2208 R n\u00d7n , we can rewrite (9) as follows:\nSince A is subject to having orthogonal columns, there is a matrix A \u22a5 with orthogonal columns such that (A, A \u22a5 ) is an orthogonal matrix. Thus, we have\nThe second term in (11) does not involve B. For fixed b and A, we substitute (11) into (10) and then obtain:\nBy employing the framework of IRLS to optimize B, we set the derivative of (12) with respect to B to zero and have:\nwhere Q \u2208 R d\u00d7d is a diagonal matrix and its diagonal element q jj = "}, {"section_title": "(iii) Update A with fixed b and B", "text": "For fixed b and B, (6) reduces to\nBased on the framework of IRLS again, we have:\nwhere P \u2208 R c\u00d7c is a diagonal matrix and its diagonal element p jj =\n(15) is a generalized eigenvalue problem, and its global optimal solution is obtained from the nonzero eigenvectors of (Y T HX(X T HX + \u03b1Q) \u22121 X T HY \u2212 \u03b2P).\nWe provide the pseudo algorithm of solving (6) in Algorithm 1. According to [44, 50, 53] , the objective function in (6) monotonically decreases after each iteration."}, {"section_title": "Experimental analysis", "text": "We conducted various experiments on the ADNI dataset ('www.adni-info.org') by comparing our method with the state-of-the-art methods."}, {"section_title": "Data preprocessing", "text": "Both SNP and MRI data used in this work were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc.edu). Please refer to 'www.adni-info.org' for up-to-date information. By following earlier studies [30, 38] , in this work, we used samples of 737 non-Hispanic Caucasian participants, including 171 AD, 362 MCI, and 204 healthy Normal Control (NC), who were also genotyped by ADNI.\nWe downloaded raw Digital Imaging and Communications in Medicine (DICOM) MRI scans from the public ADNI website, and we conducted the image processing of MR images following the same procedures in [45, 52] . Specifically, the MRI scans were processed using a standard protocol, including spatial distortion correction and bias field correction, followed by skull-stripping, cerebellum removal, intensity inhomogeneity correction, segmentation, and registration. Based on the Jacob template [23] , we finally obtained gray matter volume measures of 93 cortical and subcortical regions for each MRI scan to characterize its anatomy [45] .\nWe obtained the genotype data of all non-Hispanic Caucasian participants from the ADNI Phase 1 cohort. ADNI genotyping was performed using the Human610-Quad BeadChip, which includes 620,901 SNPs and copy number variations [40] . The SNP of the APOE 4 variant has been separately genotyped by ADNI, but is not included in the original genotyping chip. In this work, the SNP was added to the final genotype dataset. All subjects were unrelated and further detail of genotypes can be found in [34] . Each of the MRI scans had corresponding genetic data obtained from the ADNI Phase 1 cohort, consisting of 620, 901 SNPs. The SNPs were processed by two steps, i.e., the quality control step and the imputation step [3] . The quality control step included 1) call rate check per subject and per SNP marker; 2) gender check; 3) sibling pair identification; 4) the Hardy-Weinberg equilibrium test; 5) marker removal by the minor allele frequency; and 6) population stratification. The imputation step imputed the incomplete SNPs with the modal value. Finally, we obtained 3996 SNPs, within the boundary of 20K base pairs of the 153 Alzheimer's disease (AD) candidate genes listed on the AlzGene database (http://www.alzgene.org/) as of 4/18/2011. Finally, we obtained 2098 SNPs from 153 genes (boundary: 20KB) using the ANNOVAR annotation. 1 "}, {"section_title": "Competing methods", "text": "In order to validate the effectiveness of the proposed method, we compared our method to the standard regularized Multi-output Linear Regression (MLR) [21] , sparse feature selection with an 2,1 -norm regularizer (L21 for short) [10] , Group sparse Feature Selection (GFS) [38] , sparse Canonical Correlation Analysis (CCA) [25] , and sparse Reduced-Rank Regression (RRR) [36] . The former two are the most widely used methods in both statistical learning and medical image analysis, while the last three are state-of-the-art methods in neuroimaging genetic study. We listed the details of these competing methods as follows:\n-MLR consideres the correlations among the features (i.e., SNPs) but independently considers each of the response variables to conduct the BW-CGA study. -L21 employs a least square loss function in combination with a group sparse regularizer (i.e., an 2,1 -norm regularizer) to consider the correlations among the features. -GFS considers the inter-linked relationship among the genotypes (i.e., the features) without taking correlations among the response variables into account. -CCA conducts feature selection on the response matrix as well as the feature matrix, but does not conduct subspace learning. -RRR conducts subspace learning on both the neuroimaging phenotypes and the genotypes. However, RRR does not explicitly conduct feature selection on the data. -Baseline is a special case of our proposed method. Specifically, Baseline removes the third term (i.e., \u03b2 A 2,1 ) of (6) to only conduct SNP selection. In this way, Baseline does not conduct feature selection on genotype data, thus it may be affected by the irrelevant/redundant SNPs for the BW-CGA study."}, {"section_title": "Experimental setup", "text": "We employed the three-fold cross-validation scheme to evaluate all the methods. Specifically, we partitioned the whole dataset into 3 subsets, where one subset was set as the testing dataset and the left two subsets were set as the training set. Given the training set, we conducted five-fold nested cross-validation to conduct the model selection, which outputted the parameters' combination with the best results of RMSE for the testing datasets. We repeated the whole process of every method ten times, and reported the averaged results of all results within ten times. In model selection, we tuned the parameters of all the methods with the range of {10 \u22125 , ..., 10 5 }, and further varied the rank number r in {2, 4, ..., 20} for our proposed method. Furthermore, we followed the literatures [17, 38] to select the top {20, 40, 60, ..., 180, 200} genotypes to predict the phenotypes in our experiments. We used two evaluation metrics, i.e., Root-Mean-Square Error (RMSE) and 'Frequency' defined as the freqency of the genotypes (or the phenotypes) selected in all the experiments. Usually, the range of 'Frequency' is from 0 to 1. Figure 1 presents the RMSE performance of all the methods considered in this work, with the mean and standard deviation obtained from all the experiments. From Figure 1 , we have the following conclusions."}, {"section_title": "Results", "text": "-All the methods reduced their RMSE results with the increase of the number of the selected genotypes (i.e., SNPs), indicating that the more the genotypes were used, the better the performance for predicting the phenotypes was, with at most top 200 SNPs to be involved. -Our method achieved the best RMSE results, followed by Baseline, RRR, GFS, CCA, L21, and MLR. More specifically, our method on average increased 12.75%, compared to all the competing methods. Moreover, paired-sample t-test (p < 0.05) showed that the p-values between our method and each of the competing methods were less than 0.00001. This demonstrated that our method has statistically significant improvements, than all the competing methods. Furthermore, the stability of our method is the best, showing that our method has superiority on combing a reduced rank constraint with a group sparsity constraint in a framework. -Baseline on average increased 8.26%, than other competing methods. Moreover, pairedsample t-test (at 95% confidence level) showed that the p-values between our method and each of the competing methods were less than 0.001. Hence, Baseline (i.e., our proposed method without conducting ROIs selection) is still better other competing methods, indicating that simultaneously selecting a subset of genotypes and a subset of phenotypes makes sense for conducting neuroimaging genetic study.\nWe presented the 'Frequency' value of the 10 selected SNPs and the 10 selected ROIs by the competing methods along with our method in Figure 2 and also visualized the coefficients of the 10 selected SNPs and the 10 selected ROIs in Figure 3 -PICLAM is a new A\u03b2 toxicity modifier of genes and has been demonstrated to be significantly associated with risk of late-onset AD [29] . Here, our experiments verify that the gene PICALM has biological relations to phenotypes. For example, our method selected SNPs from the PICLAM gene that were the top 10 SNPs, such as 'rs7938033', 'rs11234495', and 'rs10792820', which have been reported to be related to inheritable neuro-developmental disorders [41] . -The APOE-4 variant of the APOE gene has been reported to be responsible for the production of apolipoprotein E [41] . In our experiments, all methods selected the SNP of 'rs429358' as one of the top significant SNPs and our method indicated its strongest association with phenotypes. -SNPs of 'rs7945931' and 'rs2276346' have been shown to have significant effects on the temporal cortex of the gene SORL1, which influences clinical manifestation of AD and is genetically associated with increased risk for late-onset AD [26, 27] .\nThe right sub-figures in Figures 2 and 3 present that the top 10 selected ROIs by our proposed method are parahippocampal gyrus left (para.gy.L), perirhinal cortex left (per.cort.L), temporal pole left (temp.po.L), middle temporal gyrus right (mid.temp.gy.R), amygdala right (amy.R), hippocampal formation right (hip.for.R), middle temporal gyrus left (mid.temp.gy.L), amygdala left (amy.L), inferior temporal gyrus right (inf.temp.gy.R), and hippocampal formation left (hip.for.L). These selected ROIs were known to be highly related to AD or related dementia (e.g., MCI) in previous studies, such as in neuroimaging genetic study [17, 38] , AD classification and regression [35, 45, 47] , and clinical diagnosis [6, 7, 12, 28] . Hence, the ROIs selected by our method could be further incorporated for future clinical analysis. We then interpreted the details on how top selected SNPs (or ROIs) affected the BW-CGA study by reporting a subset of the coefficient matrix of BA T \u2208 R 2098\u00d793 in (6). Specifically, we averaged the absolute value of BA T from all 50 experiments to sort the resulting matrix in a descending order along the rows (or the columns) to obtain the top 10 SNPs (or ROIs). The resulting coefficients, whose rows and columns, respectively, correspond to the top 10 SNPs and the top 10 ROIs in the resulting matrix, are illustrated in Figure 4 to explain the association between the selected SNPs and the selected ROIs. Figure 5 illustrates the top 20 selected ROIs associated with each of the selected SNPs obtained by our proposed method. Figures 4 and 5 manifest that the selected set of SNPs and ROIs are related to AD, which is in accordance with previous state-of-the-art methods [17, 37, 38] . "}, {"section_title": "Effects of the matrix rank r", "text": "We investigated the effect of different numbers of rank r \u2208 {2, ..., 20} in our proposed method by reporting the change of RMSE values in Figure 6 , where the mean and standard deviation of the RMSE were obtained from all 50 experiments. In the figure, each curve represents the change of RMSE with a fixed number of SNPs in predicting the test data, e.g., 'top-200' represents the change of RMSE using top 200 SNPs in predicting the test ROIs.\nFrom Figure 6 , we observed that the best performance of cases with different numbers of SNPs, in predicting test data, was between 8 and 12, which empirically justifies imposing a reduced rank assumption on both neuroimaging phenotypes and genotypes. The reduced rank constraints conducting subspace learning helped find low-dimensional Figure 6 The RMSE of the proposed method with different numbers of ranks using different numbers of SNPs to predict the test data structure of high-dimensional neuroimaging data via relational considerations among the response variables."}, {"section_title": "Conclusion", "text": "We have designed a new group sparse reduced rank regression method to select highly associated phenotypes and genotypes for conducting the BW-CGA study. Experimental results on the ADNI dataset demonstrated that our proposed method outperformed all the competing methods. Despite superior performance of our proposed method over the competing methods, there are still existing limitations, which inspire us to further improve our method for the BW-CGA study in the future work. First, each of the subjects in ADNI has label information, which offers high-level representations of subjects and should thus be informative for improving performance of the BW-CGA study. Hence, we may use this available information to more effectively explore associations between SNPs and ROIs in the future. Second, our proposed method does not consider any natural structures of SNPs (or ROIs). However, SNPs are naturally connected via different pathways, while ROIs have various functional or structural relations to each other [25, 31] . It would be interesting to extend our method to take inter-linked structures, within both SNPs and ROIs, into account for further improving performance of the BW-CGA study in our future work."}]