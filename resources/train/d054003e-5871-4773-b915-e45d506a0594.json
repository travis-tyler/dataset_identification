[{"section_title": "I. INTRODUCTION", "text": "The 2019 novel coronavirus , that originated in Wuhan, China, has been rapidly spreading worldwide, where several cases of pneumonia with an unknown underlying cause were reported. The majority of patients experience mild symptoms including a fever, dry cough, and a sore throat. However, some patients deteriorate to various fatal complications such as pneumonia, Acute Respiratory Distress Syndrome (ARDS), organ failure and even death [1] - [3] .\nStudies regarding which imaging modality to use for COVID-19 patients, compare the advantages of CT vs Chest Xray (CXR), and vise versa [4] , [5] . The decision to use one modality over another depends on the disease phase of the subject and the community norms. In countries where the access to RT-PCR tests is limited, the adopted approach is to encourage patients to approach doctors early. If suspected patients manifest mild symptoms, a CT scan is performed as it's more sensitive to mild pneumonia changes in the lungs than a CXR examination. In contrast, in countries where the directive approach is to instruct patients to present to the hospital only when they experience advanced symptoms, the preferred modality is CXR as it clearly shows abnormalities in the lungs. Another factor that favors the CXR is the high contagion of the COVID-19 virus. The complications related to the patients' transport to the CT suites involve the risks of cross-infections along the transport route, and in the scanning room. Additionally, lack of sterilization equipment in parts of the world strengthens this claim. These complications therefore favor the use of the CXR modality for the identification and followup of COVID-19 patients. Moreover, CXR is very useful for assessing disease progression in hospitalized patients in which the disease state is more likely to be advanced.\nWith the wide and rapid spread of coronavirus, AI has become of significant importance to healthcare specialists in diagnosis and prognosis of COVID-19. AI is actively contributing to the fight against COVID-19 through recent applications [6] . Reviews of AI-empowered publications [7] , [8] show numerous machine learning-based research on segmentations of infected regions in CT scans of COVID-19 patients. However, most CXR publications target the classification task for multiple classes [9] - [12] and provide interpretable and explainable maps using class activation maps (CAM), rather than accurate COVID-19 pneumonia segmentations as provided by CT. Most of these methods were published in the early outbreak of the pandemic, and thus trained solely on a few examples of COVID-19 that were mainly aggregated from publications and radiological websites, and thus not ideal for comparison. In [13] and [14] experiments were conducted to prove that this data selection might cause the network to learn features that are dataset-biased rather than learning diseasespecific characteristics, especially when images of different labels are selected from different databases. As most of the current works focus on the diagnosis of COVID-19, very few works (e.g. [15] , [16] ) target severity assessmen of the disease in CXR. Moreover, to the best of our knowledge, almost no AI-based work studied and validated the follow-up and patient monitoring of COVID-19 patients using chest radiographs.\nIn this work, we evaluate the degree of severity of pneumonia in COVID-19 patients and monitor patients' disease progression over time. Fig. 1 illustrates the overview of the system components as follows: we first detect if pneumonia is present and localize the infected area of the lung (Green color blocks). Then, by combining a lung segmentation step (Black), we can measure the relative area of the lung that is infected. This in turn leads to our ability to assess the severity of the case as well as to monitor patients in time (Yellow): For hospitalized patients that have an extended record of disease, we generate a disease profile over time.\nTo validate our results, we utilize a novel CT-Xray duality (Orange): Using the CT and its accurately defined disease extent, we generate a corresponding synthetic Xray, using a newly developed scheme for Digital Reconstructed Radiograph (DRR) generation. Disease profiles in CT and Xray space Fig. 1 : Overview of the proposed system: Detection and localization models are described in Section III. The methods used for lung segmentation, severity assessment, patient monitoring and CT-DRR duality-based validation are provided in Section IV.\nare extracted and compared. Additional analysis is conducted to show the relationship between CT and Xray in defining disease states. The detection and localization components of the system are detailed in Section III. Generating severity estimates and monitoring in time are presented in Section IV. Experiments and results are presented in Section V, followed by conclusion and discussion in Section VI.\nOur contributions are as follows:\n\u2022 We propose a dual-stage training scheme in the Detection and Localization network, to accurately segment regions in the lungs infected with pneumonia, from inaccurate ground truth (GT) bounding boxes. We exploit the Grad-CAM [17] algorithm to generate segmentation proposals, and use these proposals to learn accurate segmentations that are directly outputted from the model. \u2022 We prove our model's ability, trained on non-COVID-19 pneumonia patients, to generalize the detection, localization, severity scoring, and monitoring of COVID-19 pneumonia cases. \u2022 We introduce a robust lung segmentation method, using unconventional augmentation methods, such as synthetic radiographs of abnormal lungs, gamma correction, and blob implanting. Our proposed augmentations ameliorate the segmentation of pathological lungs. \u2022 We demonstrate the system capability for measuring pneumonia extent in the lungs and for tracking disease progression. \u2022 We present a novel validation strategy for the CXRbased patient disease monitoring, by utilizing CT scans of COVID-19 patients over time, producing corresponding DRRs, and exploring the CT and Xray duality."}, {"section_title": "II. RELATED WORK", "text": "Several studies have been published recently on COVID-19 detection in chest radiographs. Here we review several related works. For an additional review of the field, we refer the reader to an overview paper [7] and the COVID-specific Special Issues of TMI 1 and MedIA 2 .\nIn Wang et al. [9] , the \"COVID-Net\" architecture is presented for COVID-19 detection in CXR. Three datasets, collected from different sources [18] - [20] , were used to train the network to predict three categories: no infection (normal), non-COVID19 infection, and COVID-19 viral infection. They reported a sensitivity of 0.95, 0.94, 0.91 for each class with a test set of 100 normal, 100 non-COVID-19 pneumonia and 100 COVID-19 images, respectively. Apostolopoulos et al. [10] adopted state-of-the-art CNNs that were proposed over the last few years for small medical datasets using transfer learning method. They utilized public datasets of COVID-19 from [21] , [22] for the task of bacterial pneumonia, viral pneumonia of COVID-19, and normal image classification. The authors showed results of 10-fold-cross-validation on two datasets of COVID-19, common bacterial pneumonia (with and without non-COVID-19 patients) and normal cases. Optimal results of sensitivity and specificity greater than 0.96 were obtained with MobileNet v2 network on 224 COVID-19 images. Zhang et al. [11] developed a deep anomaly detection model for the task of COVID-19 vs non-COVID-19 pneumonia classification. They used 100 COVID-19 images from [18] and 1431 additional CXR images confirmed as other pneumonia from the public ChestX-ray14 dataset [23] . They reported AU C of 0.95.\nThe severity scoring has also caught attention in CXR publications lately. Signoroni et al. [15] designed a multipurpose network for COVID-19 pneumonia prediction, lung segmentation and lungs alignment that outputs the severity prediction by dividing the lungs into 6 regions. They utilized annotated 5,000 CXR images from ASST Spedali Civili of Brescia, Italy, in addition to 194 images from the public dataset of [18] . Mean absolute error (MAE) of severity score on a subset of 150 images from the private dataset is 1.8 compared to the gold standard with correlation coefficient of 0.85. The MAE on the 194 images from the public dataset is 2.18. Cohen et al. [16] developed a model to predict COVID-19 pneumonia severity based on CXR: they pre-trained a DenseNet on 18 common radiological findings from multiple public datasets, and then trained a linear regression model on a subset of the COVID-19 dataset, that was scored by three experts to predict the severity scores using different sets of extracted features. The correlation coefficient, R 2 and MAE, on a test set of 50 images are 0.78, 0.58 and 0.78, respectively for the pneumonia extent score, and 0.8, 0.6 and 1.14, respectively for the opacity score (encounters the opacity texture features of consolidation/ground glass).\nIn our work we focus on both COVID-19 detection and severity scoring in CXR, presenting an end-to-end solution for COVID-19 disease management. "}, {"section_title": "III. COVID-19 PNEUMONIA DETECTION AND LOCALIZATION", "text": "In order to assess the severity of pneumonia in COVID-19 patients, the pneumonia region in CXR of positive patients needs to be accurately segmented. In this section we introduce the pneumonia detection and localization network we propose, that entails a two-stage training methodology, to generate finegrained localization maps from coarse ground truth labels."}, {"section_title": "A. Detection and Localization Network", "text": "As Grad-CAM [17] became a useful tool for localizing COVID-19 pneumonia infection in CXR [11] , [12] , this method is generally used when localization GT data is not available and enables only rough localization. Training a network that combines detection and localization allows a more accurate disease extent evaluation.\nWe propose a deep-learning model to predict pneumonia labels and a heatmap simultaneously. An illustration of the proposed network is shown in Fig. 2 . It consists of three components -backbone, classification head and localization head. A detailed description of each component is given in the text below.\nThe backbone network is a 50-layer residual network (ResNet-50) [24] . The network is pre-trained on the ImageNet dataset. As shown in Fig. 2(a) , the images are fed to a convolutional layer with 7 \u00d7 7 kernels and a stride of 2, followed by a 3 \u00d7 3 max-pooling layer with a stride of 2. This is followed by convolution and identity blocks with skip connections. Each convolution block has 3 convolution layers and another convolution layer in the skip connection, and each identity block also has 3 convolution layers.\nThe last dense layer of ResNet-50 is replaced with three consecutive dense layers with 1024, 256 and 1 neurons, respectively. A dropout layer is inserted between the first two dense layers. Finally, a sigmoid activation function is applied, creating the classification head. The output score indicates the probability of the image having pneumonia. The localization head is a feature pyramid-like network [25] . Low resolution features extracted from the final identity block, named Act \u2212 14, are upsampled by a factor of 2 using the nearest neighbor. The upsampled features undergo a 1 \u00d7 1 convolution layer to reduce the channel dimensions. Next, each lateral connection fuses feature maps of the same spatial size from the previous residual block output (Act \u2212 28) by element-wise addition. This process is repeated for the higher resolution features (activation output of the previous identity block: Act \u2212 56). Finally, a 3 \u00d7 3 convolution layer followed by ReLU activation is applied to the last summation and forms the localization output. The last convolution layer formed has 128 feature maps, which allows a prediction of sparse maps and prevents the network from over-fitting the predictions to a rectangular (bounding box) shape. In order to create one heatmap in the inference stage, the maximal value among the 128 output maps is taken for each matching pixel."}, {"section_title": "B. Training Pipeline", "text": "The proposed network is trained using the RSNA Pneumonia Detection Challenge Dataset [20] . Pediatric patients are removed from the dataset to prevent bias due to age. The remaining images in the RSNA dataset are split to three sets: training (9004 images), validation (1126 images) and testing (1124 images). The dataset includes annotation labels of pneumonia/non-pneumonia (in equal amounts) and bounding boxes annotations of the pneumonia regions. The training images are resized to a fixed size of 448 \u00d7 448 pixels. A preprocessing step consisting of a Contrast Limited Histogram Equalization (CLAHE) method is applied to the images before training, followed by normalization according to the mean and standard deviation values of the ImageNet database.\nThe training pipeline consists of two-stages (see Fig. 3 ): in the first stage, we train the network on the training images with the corresponding bounding boxes. Next, we use the trained model to generate accurate segmentation proposals for subset of the training images, and then replace the bounding boxes annotations with the accurate segmentations to train the model again. Fig. 4 compares the produced heatmaps after each training stage, showing the generation of more fine-grained heatmaps after the second stage. The detailed description of the stages is given below:\n1) First Stage: The network is trained on RSNA data, where the GTs in this stage are the labels of pneumonia/nonpneumonia and the corresponding bounding boxes. We denote this detection and localization model as DLN et \u2212 1. Prior to training, a binary image is produced from the bounding boxes, then dilated with a 5 \u00d7 5 kernel and finally smoothed with a Gaussian Blur. This last processing step guarantees an accurate prediction of the bounding box location, and gives a percentage of uncertainty in the edges. The proposed network is trained using the Adam optimizer. The initial learning rate is set to 1e \u2212 4 and decreases by a factor of 0.2 when learning stagnates for 2 epochs. The batch size is set to 8 images and the max number of epochs to 30. The loss is comprised of two parts: (1) classification loss (binary cross entropy) and (2) localization loss (mean squared error). The total loss is a linear combination of the two losses, where the binary cross entropy loss on the prediction and the GT label is denoted by BCE(l pred , l gt ), and the mean squared error by M SE(BB pred , BB gt ). The total loss is described in (1):\nwhere \u03bb is set to 1e\u22125 to scale the localization loss according to the classification loss scale.\n2) Second Stage: The first trained model is exploited to generate a more accurate pneumonia segmentation GT for training the second stage. We will denote this model as DLN et\u22122. This is done using the Grad-CAM [17] algorithm: Two heatmaps are produced, the first generated by backpropagating the gradients from the last convolution layer of the localization head up till the Act \u2212 28 activation layer, and the second up till the Act \u2212 14 activation layer. The heatmaps are then resized to full image size. The two heatmaps are combined to generate one heatmap, whose pixels' class probability is more accurate than each heatmap separately. The two heatmaps are combined by taking the maximum value of matching pixels from both maps. The final heatmap is then smoothed and normalized. To generate the final GT "}, {"section_title": "IV. SEVERITY SCORING AND PATIENT MONITORING", "text": "In this section, we focus on measuring the extent of pneumonia in the lungs of detected positive patients in order to assess the disease severity level. We utilize the severity estimates to monitor patients over time. A novel validation strategy is proposed that uses CT-Xray duality: we perform validations on digitally reconstructed radiographs (DRRs) synthesized from CT scans and compare to the original CT images in monitoring the patients' disease state."}, {"section_title": "A. Lung Segmentation", "text": "To accurately measure the extent of pneumonia in the lungs, we introduce a lung segmentation method for patients with severe opacities and low visibility of the lung fields.\nThe proposed architecture is a modified U-Net [26] in which the pre-trained VGG-19 [27] encoder replaced the contracting path (the encoder) in the U-net, as was introduced by Frid-Adar et al. [28] for segmentation of anatomical structures in chest radiographs. The original model, named LSN et, was trained on the Japanese Society of Radiological Technology (JSRT) dataset with traditional augmentations (zoom, translation, rotation and horizontal flipping). Here, we propose an improved model that is more robust, generalizes on images with severe infections and reduces false detections (LSN et\u2212Aug). The model was improved by challenging the training process with enriched augmented training data. In addition to the original training JSRT dataset, we added images and lung Fig. 6 : Severity score computation -Block diagram: Input image enters the detection network. If the classification score is lower than a pre-determined threshold, the image is classified as negative; otherwise, the image segmentation is outputted from the localization head. At this point, the pneumonia segmentation and the lung segmentation blocks are utilized to compute the \"Pneumonia Ratio\". masks GT from the Montgomery County (MC) -Chest X-ray Database [29] , [30] , the XLSor dataset [31] and 100 images from the NIH dataset that were provided by XLSor authors. The XLSor dataset consists of real and synthetic radiographs: an image-to-image translation module (MUNIT [32] ) is utilized to synthesize radiorealistic abnormal CXRs (synthesized radiographs that appear anatomically realistic) from the source of normal ones, for data augmentation purposes. The lung masks of those synthetic abnormal CXRs are propagated from the segmentation results of their normal counterparts, and then serve as pseudo masks for robust segmentation training. The aim is to construct a large number of abnormal CXR pairs with no human intervention, in order to train a powerful, robust and accurate model for CXR lung segmentation. Fig. 5 shows two examples of normal lung images, the GT segmentation maps, and their corresponding synthesized abnormal CXRs.\nAdditional augmentations are adopted such as gamma correction and blob implanting. The gamma correction simulates Xray images with different intensities from different sources. The blob implanting simulates obstructions in the CXR images, such as tubes, machines and strong infections. The model is trained with Dice loss and optimized using Adam optimizer. The images are resized to 448 \u00d7 448 and normalized by their mean and standard deviation. The output score map is thresholded to generate a binary lung segmentation mask."}, {"section_title": "B. Severity Measurement", "text": "We examine patients that were imaged multiple times during hospitalization. To evaluate the progression of pneumonia, we suggest a \"Pneumonia Ratio\" metric which quantifies the relative area of the segmented pneumonia regions to the total lungs area.\nThe pneumonia ratio is calculated according to both the lung segmentation and the pneumonia segmentation to give a severity measurement of the patient's disease. The lungs are segmented using the lung segmentation module as described above and the segmentation of the suspected pneumonia region is produced, as outlined in V-B, only for patients that were identified with pneumonia by the classification head. The outputted segmentation map is then multiplied by the lung mask to restrict pneumonia detections to the lung area. The area of the lungs (Area lungs ) and the pneumonia segmentation (Area pneumonia ) are calculated according to the total number of pixels involved, and a pneumonia ratio is calculated using the following equation:\nThe system's components and \"Pneumonia Ratio\" calculation steps are shown in Fig. 6 ."}, {"section_title": "C. CT and Xray Duality for Patient Monitoring", "text": "In order to demonstrate the efficacy of our model in performing a follow-up task, we establish a strategy to evaluate the accuracy of disease progression using CXR. Rendering realistic DRRs from serial COVID-19 patients' CT scans is manipulated to validate our method. In particular, the DeepDRR framework [33] , [34] is implemented to generate DRRs from CT. These DRRs are then inputted to our model to calculate the \"Pneumonia Ratio\" following the steps in Fig.  6 . The CXR Pneumonia Ratio is then compared with the CT Pneumonia Ratio, using the the CT disease localization method described in [35] .\nThe system of DRR generation and evaluation is depicted in Fig. 7 and described in detail next:\nDeepDRR. DeepDRR is a machine learning-based method that consists of four modules: (1) material decomposition (air, soft tissue and bones) in CT volumes using a deep segmentation ConvNet, (2) analytic forward projection, (3) scattering estimation in 2D image using a neural networkbased Rayleigh, and (4) noise injection. This framework enables the user to generate synthetic Xray images with different parameter configurations, controlling image size, resolution, spectrum energy level, image view (rotation), noise and scatter control and more. This can be exploited for data augmentation and parameters tuning. The selected parameters set for the generated DRRs in this work include 1024 \u00d7 1024 image size, with 0.168 mm pixel size. The spectrum of a tungsten anode operating at 120 kV with 4.3 mm aluminum is used and a high-dose acquisition is assumed with 10 5 photons per pixel. Posterior-anterior (PA) and anterior-posterior (AP) images are produced for each CT volume.\nChest Body Part Segmentation. A thoracic CT may include scanned objects exterior to the body part such as the bed on which the patient lies. These objects are seen on the generated DRRs, concealing parts of the chest and appearing as undesirable noise. Thus, a pre-processing step is held to keep only the chest parts. First, bit-wise operations are applied to the masks of the decomposed materials: the air mask is inverted using NOT operation, then, OR operation is performed on the inverted air mask, the soft tissue mask and the bones mask. This step creates a mask of the chest part (without the air in lungs) as the bed and other unrelated objects are composed of different materials. To produce a binary mask of the whole chest part including the lungs, a hole-fill algorithm is applied. Finally, the filled mask is multiplied by the CT volume, excluding all the unrelated objects.\nPost-processing. The DRRs are first inverted as they appear dark. They are then converted to 8-bit values. Images that are very bright (with their average intensity value greater than 220) undergo gamma correction with \u03b3 = 0.2. "}, {"section_title": "A. Datasets", "text": "To train our network, the main source of data is the RSNA Pneumonia Detection Challenge [20] , [36] The data is comprised of AP and PA. It includes: 20, 672 radiographs that are labeled with 'Normal' or 'No Lung Opacity / Not Normal' indicating that the image is negative to pneumonia, and 6, 012 which are labeled with suspected pneumonia ('Lung Opacity'). The patients in this study are aged between 1\u2212100;\nIn testing the proposed system, three testing scenarios are used: In what we term Dataset 1, data was set aside from within the RSNA Pneumonia Detection dataset: 562 CXR images from pneumonia patients, and 562 CXR images diagnosed as healthy or with lung pathologies other than pneumonia (total of 1124 images); the number of P A and AP images is 470 and 654, respectively.\nIn a second testing scenario, hereon called Dataset 2, two data sources are merged: The main source of the data is the open source COVID-19 Image Data Collection [18] . The dataset consists of COVID-19 cases (as well as SARS and MERS cases) with annotated CXR and CT images; data is collected from public sources as well as through indirect collection from hospitals and physicians. Till the writing of this paper, the number of CXR images in the dataset is 339, where 287 (from 180 patient) P A and AP images and the rest are lateral view position. To balance the data, we randomly selected, and merged, 287 non-pneumonia images from the RSNA Dataset. Subsets of Dataset 2 include additional GT labels, including lung mask images and severity scoring (will be elaborated in section V-C).\nMotivated by the COVID-Net experiment conducted in [9] , we collected the same dataset and data split for our third testing scenario. The dataset includes a total of 8,066 patient cases who have no pneumonia (i.e., normal), 5,538 patient cases who have non-COVID19 pneumonia, and 358 CXR images from 266 COVID-19 patient cases. Among these, 100 normal, 100 pneumonia, and 100 COVID-19 images were randomly selected for testing (Dataset 3). Detailed description of the data split for all the datasets used in this paper is shown in Table I ."}, {"section_title": "B. COVID-19 Pneumonia Detection", "text": "Several experiments were conducted to evaluate the system detection performance. Table II summarizes pneumonia classification performance over the three datasets defined above in terms of sensitivity (Sens), specificity (Spec), accuracy (ACC) and positive predictive value (P P V ).\nIn the first experiment we evaluate the model performance for both localization and classification on Dataset 1, which does not include COVID-19 patients. Starting with the quality of the pneumonia localization heatmaps (examples over the test set are shown in Fig. 4) , we measure our proposed network localization predictions vs GT labels of bounding boxes using intersection performance metric. For a fair comparison, we generate bounding boxes out of the produced heatmaps by thresholding, and set a tight bounding box around the segmented region. Different threshold values affect the localization performance. The localization performance is assessed by the mean average precision (mAP) at multiple intersection over union (IoU ) thresholds as suggested by the RSNA pneumonia challenge. IoU is calculated using (3):\nWe then threshold the IoU at each threshold from 0.4 to 0.75 with step size 0.05, and count the number of true positive (T P ), false negative (F N ), and false positive (F P ) detections calculated from the comparison of predicted to GT bounding boxes. The precision is then calculated at each threshold t with (4) for each image i:\nThe average precision of a single image is calculated as the mean of the above precision values for all IoU thresholds. The total precision is then defined as the average of precisions of all the images:\nIn order to set a threshold value over the produced heatmaps, which optimize the mAP, we measured the mAP at different values from 0.5 to 0.9. As depicted in Fig. 8a . The optimal threshold value is 0.8 which resulted in mAP of 0.27.\nIn Fig. 9 , we provide examples of bounding box predictions of our network in comparison to the GT bounding boxes from the same test set. The top row shows successful predictions and the bottom row depicts discrepancies between GT and prediction boxes.\nThe pneumonia classification performance is evaluated using pneumonia/non-pneumonia labels of Dataset 1. Fig. 8b shows the Receiver Operating Characteristic (ROC) curve that plots the trade-off between sensitivity and specificity at different thresholds on the test set. The reported Area Under to Curve (AUC) is 0.93. The sensitivity, specificity and ACC at the optimal thershold of 0.62 -which is set at the point that satisfies the minimal Euclidean distance from the point (1, 0) , are 0.87, 0.85 and 0.86, respectively. The Positive predictive value (P P V ), which is the probability that the disease is present when the test is positive is 0.86. In the second experiment, we examine the model's robustness to COVID-19 data by testing on Dataset 2, that includes COVID-19 patients. The reported Area Under to Curve (AUC) for Dataset 2 is 0.94. The sensitivity, specificity, ACC and P P V are 0.86, 0.91, 0.89 and 0.90, respectively, which shows the generalization on COVID-19 patients' data.\nIn the last experiment, we use Dataset 3, which includes pneumonia and COVID-19 patients. For a fair comparison, we trained our network according to the data-split suggested by the authors of [9] , where we merged the non-COVID-19 pneumonia and COVID-19 pneumonia images to one class to fit our proposed network. In this classification task, we achieve a performance of 0.98 AUC, with 0.92 sensitivity and 0.97 specificity. These results are equivalent to state-of-theart performance. We note that the method proposed shows high sensitivity for COVID-19 pneumonia detection, proving its capability to detect COVID-19 pneumonia in addition to non-COVID-19 pneumonia.\nTo summarize, the results in Table II show high performance on non-COVID-19-pneumonia detection (Dataset 1), and an even higher performance on COVID-19-pneumonia detection (Dataset 2), despite the fact that the network was not trained on COVID-19 images. Including COVID-19 images in the training dataset (Dataset 3) yields an even better performance, competitive to the state-of-the-art.\nC. COVID-19 Severity Scoring and Follow-up 1) Lung Segmentation Evaluation: The lung segmentation task is essential in order to calculate an accurate severity score. We present a model for lung segmentation, named LSN et, and suggest an improved model LSN et\u2212Aug, that generalizes on images with severe infections as COVID-19, by using various data augmentation techniques and including abnormal data sources. Evaluation is performed on 210 images provided in Dataset 2. The lung masks of these images were generated using the model from [37] as this achieved the most accurate segmentations. Therefore, we consider Selvan's method as our reference, and compare it to our lung segmentation models. The results are evaluated using the Dice and Jaccard coefficient. Table III shows an improvement in both metrics for lung segmentation after adding the aforementioned augmentations and the datasets during training. III: Lung segmentation results: reported for both Unet based VGG-16 encoder method and the same method with additional abnormal datasets and augmentations. Ground truth masks were generated using [37] ."}, {"section_title": "Method", "text": "Dice Jaccard LSNet 0.89 \u00b1 0.07 0.81 \u00b1 0.10 LSNet-Aug 0.92 \u00b1 0.09 0.86 \u00b1 0.11 2) Quantitative Analysis: Dataset 2 includes a cohort of 94 PA CXR images that are assigned with a severity score of [0/1/2/3/4], indicating the extent of ground glass opacity or consolidation in each lung (right and left lung). Images were labeled by three experts, following a score strategy adapted from [38] . The opacity extent was scored as follows: 0 = no involvement; 1 =< 25% involvement; 2 = 25 \u2212 50% involvement; 3 = 50 \u2212 75% involvement; 4 => 75% involvement. The total extent score in both lungs ranged from 0 to 8. To compare our results to the GT scores, we compute the \"Pneumonia Ratio\" for each lung. We divide the \"Pneumonia Ratio\" into four levels following the same GT criterion, and the total score is summed for both lungs. Fig. 10a shows the predicted severity scores against the GT scores from the 94 patient cohort, with correlation coefficient of the fitted model being 0.83 and R 2 = 0.67. These results surpass the reported severity estimation of [18] , tested on a subset of the same dataset. The confusion matrix in Fig. 10b shows larger confusion between close severity scores such as the low levels [0, 1, 2] . Even though the high severity level images are slightly underestimated, none were scored with a mild condition stage and vice versa. Given the high inter-rater variability, our plots show a satisfactory agreement. Table IV presents 3) Qualitative Analysis: To estimate the progression and severity of pneumonia in COVID-19 patients, we explore the \"Pneumonia Ratio\" for patients from Dataset 2, scanned at multiple time points. We provide a qualitative analysis over time for three selected patients. Fig. 11 shows the CXR scans of these patients, superimposed with red contours indicating the predicted regions of pneumonia. The \"Pneumonia Ratio\" indicates the severity of pneumonia in these patients in percentages out of the lung field, right lung and left lung. In patient 10, the \"Pneumonia Ratio\" shows evidence of disease deterioration over time. In patient 117, we see a substantial increase followed by a period without major change and then another increase in disease severity. In contrast, for patient 171 the ratio indicates recovery from the disease following a substantial infection increase."}, {"section_title": "D. CT-Xray duality for patient monitoring validation", "text": "To further explore the ability of the proposed method to monitor COVID-19 patients, a quantitative analysis following the strategy described in IV-C is performed. The DeepDRR framework is applied to 9 patients with severe disease state. The patients were scanned at Wenzhou hospital in China and were diagnosed with COVID-19 with the RT-PCR test. Each patient had a chest CT scan (slice thickness, {1, 1.5} mm) at one or multiple time points (up to 4).\nAfter generating the DRRs, the proposed method of pneumonia classification and localization is applied (without retraining the model), and the \"Pneumonia Ratio\" is computed for each patient's generated Xray. A ratio of the detected infection in the lungs is also computed from the CT volume, following the method in [35] , [39] . A linear regression model is fitted to the CT and CXR pneumonia ratio values, as shown in Fig. 12 The Correlation coefficient found between the two methods is 0.74 (p < 0.001), where the slope of the line is 0.87 and the intercept with the y-axis is -7.2, thereby indicating overall agreement. Fig. 13 shows the pneumonia ratios that were extracted from the DRRs and the ratios that were computed on CT volumes, for each time point per patient. Our aim is to compare the disease progression trends using the two modalities. We observe that in most of the cases the trend of the regression lines is similar, i.e., when the CXR ratio increases, so does the CT ratio, and vice versa. The agreement of the two lines is quantified as follows: for each time point, if the quotient of the current time point to the previous is greater than one, the sample gets a label of 1; otherwise; 0. Following this definition, we compute an overall accuracy of 0.87. We note Fig. 12 : Linear regression model describing the relationship of the \"Pneumonia Ratio\" from DRRs vs. the ratio that is calculated on CT volume. the differences in ratio values between the CT and CXR computations. These are expected as the former is computed over the 3D volume, and the latter on a 2D image. With the goal to monitor the disease progression, the absolute difference in magnitude is not investigated here. In mild conditions, the CT is more sensitive in detecting penumonia than CXR. This is exemplified in patient #9, where the graph shows a ratio of 0 in CXR (indicating that the patient is negative for pneumonia), whereas the CT shows a positive ratio. Therefore, the \"Pneumonia Ratio\" is more accurate in monitoring patients at an advanced disease stage."}, {"section_title": "VI. DISCUSSION", "text": "Due to the recent outbreak of the COVID-19, there is a need for automatic diagnosis and prognosis of COVID-19 pneumonia infections in CXR images. This includes automatic follow-up of coronavirus patients in order to monitor their condition and the progression of the disease.\nIn this work, we propose an end-to-end solution for COVID-19 pneumonia detection, localization, and severity scoring in CXR. We propose a dual-stage network training to simultaneously detect and localize pneumonia. The training scenario involves learning accurate segmentation from coarse annotations. Finally, we present a novel validation approach to assess disease monitoring based on CT-Xray coupling.\nSeveral other works have attempted to solve the problem of detecting COVID-19 in CXR images [9] - [11] . Most networks were trained and tested on COVID-19 patients with high imbalanced labels from distinct datasets, in addition to testing on small test sets. This raised a concern that the network solutions may be dataset-biased, and not robust as desired [13] , [14] . In order to assure robustness of our solution we took special care to train the network on a single (RSNA) dataset, that includes non-COVID-19 pneumonia. In the inference phase, we tested the method on a larger dataset, including COVID-19 patients from an external public dataset and demonstrated high performance in these cases. Including COVID-19 cases in the training phase significantly improved the network's results and yielded performance values comparable to the state-of-the-art. The segmentation maps provided by our network manifest our model's ability to learn features that are specific to the disease, thereby showing that we are not dataset-biased.\nThe severity of pneumonia is directly associated with its extent in the lungs; thus, an accurate segmentation of the regions infected with pneumonia is necessary. The lack of accurate segmentation in public datasets encouraged us to adopt a two-stage training process. This leverages weak delineations (bounding boxes) to learn segmentation proposals, that in turn, help learn accurate segmentations in the second stage. A measure of the relative pneumonia region to total lung region was found to strongly correlate with the disease severity score estimation. Comparing to [16] , we note that a smaller test set was used, while training on the same source, and including COVID-19 patients in the training process.\nIn [28] it was reported that segmentation was found to be less accurate in pathological lungs. For severe conditions of pneumonia, an improvement in the lung segmentation solutions is therefore crucial. We address this issue with unconventional augmentations in the training procedure, including: synthesizing pathological lungs from normal lung cases and adding blobs to the images along with gamma correction. With this augmentation we were able to improve the segmentation results considerably and overall enhance the network performance. Using the two-stage detection and localization network, along with the augmented lung segmentation model, we note the improvement in the correlation coefficient and R 2 values, as can be seen in Table IV .\nIn order to validate patient-specific disease progression profiles, we would ideally need as GT a disease score per time-point. In this work, we exploit the high sensitivity of CT and utilize available serial CT scans of severe patients to conduct a validation test of patient monitoring in CXR. In order to learn the correspondence of CT and CXR, we would ideally want to have patients scanned simultaneously with CT and CXR. The lack of such duality in hospitals urged us to search for an alternative: we suggest to synthesize Xray (DRR) from CT using the DeepDRR AI-based technique. We use the proposed CT-Xray duality for longitudinal comparison, utilizing a model capable of both assessing and monitoring the disease state and severity of COVID-19 patients from CXR images."}, {"section_title": "VII. CONCLUSION", "text": "This work demonstrates the utility of AI for COVID-19 pneumonia quantification, severity scoring and patient monitoring. The presented model simultaneously detects and localizes the region of pneumonia and assesses its extent in the lungs. We suggest a dual-stage training that leverages the weak annotations of bounding boxes in order to output an accurate segmentation of pneumonia in COVID-19 patients. An improvement of a previous lung segmentation method [28] is presented using unconventional additions that enhance the results of lung segmentation on diseased lungs. The pneumonia and lung segmentation are exploited to quantify a \"Pneumonia Ratio\" which indicates the pneumonia extent in the lungs. Additional exploration in the CT-Xray coupling is presented to validate the capability of our method to monitor patients over time. In conclusion, our proposed solution has the potential to generate quantitative measures for improved diagnosis, facilitation of patient follow-up, and reduction in observerdependent bias to provide overall decision support."}]