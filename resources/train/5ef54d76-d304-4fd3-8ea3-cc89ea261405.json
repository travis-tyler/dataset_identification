[{"section_title": "Abstract", "text": "The paper considers a conformal prediction method for bounded regression task. A predictor was based on the Defensive Forecast algorithm and has been applied for a medical prognostic problem. These empirical results are compared and discussed."}, {"section_title": "Introduction", "text": "The conformal prediction has been applied to regression estimation in [1, 2, 3, 4] , under assumption that label y is approximately linearly dependent on feature vector x. This was also extended for non-linear dependency using a non-linear transformation (kernel mapping) \u03a6 of x into a higher dimensional space -see, for example, [9] .\nIn this paper we consider the non-linear problem of bounded regression. A typical problem that requires a bounded regression is a prediction of examination marks, bounded from 0% to 100% or some problems in medical prognosis that have a range from healthy individuals to patients with a completely developed disease after a time delay. We apply an inductive conformal regression method to this type of problem to make valid regression estimations.\nIn Section 2 we recall key notions of machine learning and conformal prediction. In particular, what functions can be used as non-conformity measures and what changes if we apply conformal prediction in the inductive form of data processing that will be needed further. In Section 3 we describe a non-conformity measure for inductive conformal predictor based on K29 algorithm from [8] , that was initially developed as game-theoretical approach (Defensive Forecast) to regression in bounded intervals. In Section 4 we give an example of application."}, {"section_title": "Machine Learning Background", "text": ""}, {"section_title": "Conformal Classification and Regression", "text": "The core element of a conformal predictor is a Non-Conformity Measure (NCM) that is a function A satisfying the equation (\u03b1 1 ,... ,\u03b1 n ) = A(z 1 ,... ,z n ) =\u21d2 (\u03b1 \u03c0(1) ,... ,\u03b1 \u03c0(n) ) = A(z \u03c0(1) ,...,z \u03c0(n) ).\nNCM can be also undestood as a distance between a set {z 1 ,... ,z n } and one of its elements z i , reflecting a relative strangeness \u03b1 i of the element with respect to the others. The NCM values (non-conformity scores) are converted to p-values by the formula A conformal predictor checks each of a set of hypotheses (possible labels) when presented with a new example and assigns it a p-value (Algorithm 1). Here z 1 ,... ,z n\u22121 are examples with known classification, each z i consists of a feature vector x i \u2208 X and the label y i \u2208 Y , and y is a hypothetical label for a new example with the feature vector x n ."}, {"section_title": "Algorithm 1. A step of conformal prediction", "text": "One of the ways to interpret p-values output by the conformal predictor is to find the prediction set R \u03b3 is a list of labels that are not discarded at a given significance level \u03b3:\nConformal predictors are region predictors: their output is a prediction set R -a list of possible lanbales that are not discarded at a given significance level \u03b3.\nThe prediction set should cover the true label y n with probability at least 1 \u2212 \u03b3, if i.i.d. assumption is true.\nAlternatively the prediction can be done by comparing the different p-values and selecting more likely hypothesis. This makes results of conformal prediction comparable to standard ones if needed."}, {"section_title": "Inductive form of Conformal Prediction", "text": "The approach discussed above is a transductive version of conformal prediction. Inductive conformal predictor was proposed in order to make calculations more computationally efficient. Some previous applications of it can be found in [5, 6] and other works. Usually they use same non-conformity measures as standard (transductive) conformal predictors, but for this work we will need some extension of this.\nThe idea is to use a fixed additional set u 1 ,... ,u h and to define the NCM A(z 1 ,... ,z n ) = (\u03b1 1 ,... ,\u03b1 n ) in such way that\nUsually u 1 ,... ,u h (called proper training set) and z 1 ,... ,z n\u22121 (called calibration set) are taken from the same data set with a random split. This interpretation of the inductive conformal framework is analogous to one given in [7] for inductive probabilistic (Venn) predictor.\nA general scheme of Inductive Conformal Prediction (ICP) can be found in Algorithm 3."}, {"section_title": "Approach for Bounded Regression", "text": "Aim of this section is to present a conformal predictor based on K29 algorithm from the work [8] that develops a game-theoretic approach to machine learning. In principle, details related to this theory are not necessary to understand how the algorithms works and how non-conformity scores are calculated. However, we remind some of them in order to have some intuitive justification for the choice of non-conformity measure."}, {"section_title": "Prediction as a Game", "text": "The Protocol 1 describes a simple form of prediction game with 3 players: Nature, Predictor and Sceptic. Nature generates examples x: say x n on n-th round, Predictor gives a forecast\u0177 n of Nature's move, and once he has done the prediction, Nature announces the real label y n . Sceptic has an initial capital C 0 and bets s n at round n.\nUsually in machine learning the Predictor tries to predict some value given by the nature (such a the new example's label) and his preformance is assessed by a loss function. However Nature does not have any interest to fail Predictor. Therefore game-theoretic approach to prediction usually assumes that Predictor has an antagonist, called Sceptic, whose win is Predictor's loss."}, {"section_title": "Defensive Forecast with Non-conformity Measure", "text": "In [8] , Sceptic has to show in advance his potential reaction as a betting function S n of Predictor's move, so that s n = S n (\u0177 n ).\nPredictor develops the following strategy. After seeing the object x n on round n Predictor has to solve the equation\nAlgorithm 2 follows K29 game protocol for the Defensive Forecast [8] and shows how the non-conformity scores \u03b1 n = |S n (y n )| could be extracted.\nIf Predictor's move (the prediction) is different from Nature's move (the label), then the discrepancy is measured not directly by their difference (as is it usually done in regression), but by the difference of Sceptic's reaction to them. This follows a general idea of game-theoretic probability: an event is rare or strange if someone with reasonable Algorithm 2. K29 algorithm with players' strategies and NCM 1] is either y such that S n (y) = 0 or the sign of S n if it never reaches zero on [\u22121, 1]. NATURE: y n Sceptic's capital:\n, (x n , y n )) = |S n (y n )| end for strategy may make a profit from betting for it. Therefore Sceptic's move showing his betting intention is used to measure the strangeness. If for example S n (y n ) = S n (\u0177 n ) = 0, Sceptic prefers not to play in both cases, then the difference between y n and\u0177 n is not considered as an essential one."}, {"section_title": "Using Defensive Forecast in Inductive Mode", "text": "NCM defined above can be used only in the inductive conformal prediction because otherwise, for transductive conformal predictors, the assumption of exchangeability does not hold: the order of the examples follows the protocol.\nIn the inductive mode of conformal prediction, the data are split into three parts of sizes h (proper training set u 1 ,... ,u h ), m (calibration set z 1 ,... ,z m ) and N \u2212 h \u2212 m (testing set z m+1 ,... ,z N\u2212h ). For an individual testing example the prediction is done as in Algorithm 3.\nThe only examples we deal with are the ones in the calibration or testing set, while proper training set can be considered as a parameter. That way the exchangeability property is satisfied.\nIf the non-conformity measure defined in Section 3.2 is applied in inductive mode, this means that Protocol 1 is run on examples u 1 , u 2 ,... ,u h as usally, but the step n ="}, {"section_title": "Algorithm 3. A step of inductive conformal prediction", "text": "end for h+1 is repeated many times starting from the same point. Each of calibration and testing examples in turn plays the role of x h+1 in Protocol 1 in order to get its non-conformity score. As for the testing examples, each of them is used also with different hypotheses about y n , in this context a Nature's move on the step n may mean a hypothesis about this move."}, {"section_title": "Kernels", "text": "In Algorithm 2 there is a parameter K: a kernel function (or a scalar product) after a feature mapping to a Hilbert space. This is analogous to the well-known kernels [9] K(x, x ) = \u03a6(x) \u00b7 \u03a6(x ) but in K29 the kernels are dependent on y as well as on x. This is useful for bounded regression problem because it allows to consider a nonlinearity in a wider sense: non-linearity in y (labels) as well as labels rather than in x (feature vectors). An example is the polynomial kernel:\nwhere d and e are degrees of non-linearity in x and in y. S n (y) can be represented as \u03a6(x n , y) \u00b7 w n\u22121 where\nplays a role similar to the slope w of separating hyperplane in Support Vector Machines [10] . But in SVM one can find w by solving a quadratic optimization problem, while in K29 calculation of w is separated into n \u2212 1 easy steps of on-line update. Kernels depending on y were also used in a generalized form of SVM for structured output space [11] but in this algorithms optimization problem is even harder than in a standard SVM."}, {"section_title": "Application", "text": ""}, {"section_title": "Data", "text": "In our application, we use the data obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database, ADNI-1 cohort [17] . The database includes more than 800 subjects with up to 5 years annual follow-up with comprehensive clinical, neuropsychological, imaging and laboratory evaluations, performed at the specialized research centers. For the present study, we used 1.5 Tesla 3D T1 magnetic resonance imaging (MRI) brain scans from patients with Alzheimer's Disease (AD), with Mild Cognitive Impairment (MCI) and Healthy Controls (HC), who had long term follow-up information and met the inclusion criteria (see Diagnosis below).\nIn earlier applications of conformal method to other MRI data (see [19] ) the diagnostic was considered as a classification problem, while now we observe the data ordered by these labels reflecting the following disease stages. "}, {"section_title": "Diagnosis", "text": "All AD patients met NINCDS/ADRDA criteria for probable AD, had mild level of dementia, defined as Mini-Mental State Examination (MMSE) score between 20 and 26, Clinical Dementia Rating Scale score of 1.0. Inclusion criteria for MCI were: 1) MMSE score between 24 and 30, 2) memory complaints and objective memory impairment measured by Logical Memory II subscale of the Wechsler Memory Scale (education adjusted), 3) CDR of 0.5, 4) absence of significant levels of impairment in other cognitive domains, 5) preserved activities of daily living, and 6) absence of dementia. MCI converters had to meet the criteria for Alzheimer's disease during at least two sequential evaluations (e.g., at 24 and 36 month follow ups). Controls (general inclusion/exclusion criteria): 1) MMSE scores between 28 and 30, 2) CDR of 0, 3) they did not meet criteria for clinical depression at baseline, MCI or dementia within 3 years of follow-up."}, {"section_title": "Image Post-processing", "text": "Raw 3D T1 MRI data underwent Freesurfer v5.1 (http://surfer.nmr. mgh.harvard.edu) steps for surface-based cortex reconstruction and volumetric segmentation. As a result, 68 measures of brain cortical thickness (32 for each hemisphere) averaged by parcellation as described in [15] and 41 volumetric measurements of subcortical structures (corrected for intracranial volume) acquired for every subject were combined with apoE-allele carrying information, basic clinical evaluations (MMSE and Word-recall) and demographics (age, gender, education). Each example therefore contained 109 brain morphometric measurements combined with 6 non-imaging features. Originally they were serial: same patient can have several measurements at different follow-up timepoints. For each patient, we will use its first (earliest) measurement. The label is based on the current diagnosis at that moment together with information about later dynamics of the disease."}, {"section_title": "Prediction Intervals", "text": "According to the data structure, we consider the following 21 hypotheses related to ADNI.\n-Healthy (y = \u22121); -4.5,4,. . . ,1,0.5 years before Mild Cognitive Impairment (MCI) (y=\u22120.9,...,\u22120.1); -MCI non-converter (y = 0); -MCI converter 4.5,4,. . . ,1,0.5 years before conversion to Dementia (y=0.1,...,0.9); -Dementia (y = +1). In order to apply K29 algorithm we use 109+6 features as vectors x and the stage numbers as their labels y. They are ranging from \u22121 to 1 with step 0.1 as shown in the list above.\nConformal predictor assigns p-value to each hypothesis about the diagnosis. A standard interpretation of conformal prediction is done in terms of intervals. Suppose that for one of examples, each possible y is assigned a p-value by the conformal predictor. Fig. 1 presents a typical individual prediction made for an example. Its true label 0.9 meaning: MCI in 6 months before its conversion to AD.\nExamples of corresponding prediction sets (intervals) are:\n-for the significance level \u03b3 = 10%, R = {y : p(y) > 0.1} = [0.9; 1] that covers the true value with probability at least 90%; -for the significance level \u03b3 = 5%, R = {y : p(y) > 0.05} = [0.6; 1] that covers the true value with probability at least 95%. -for the significance level \u03b3 = 1%, R = {y : p(y) > 0.1} = [0.2; 1] that covers the true value with probability at least 99%;"}, {"section_title": "Accuracy of Two-Class Problems", "text": "In addition to prediction intervals, we can use p-values obtained form a conformal predictor for some two-class problems. The following ones were selected because of their popularity in the literature [13, 14, 16] : These problems can be solved by comparing highest p-values reached on corresponding intervals. For example, if we restrict our interest to the problem (C 1 ) then the interpretation of p-values is following: -a prediction is correct in one of the following cases: The best results are presented in Table 1 .The accuracy is averaged over 50 random splits with ICP parameters h = 500 and m = 100 (see Sec.3.3). We also compare K29 with a simpler approach based on linear regression extended with a T-test feature selection step used in our previous work [19] applied in leave-one-out mode. "}, {"section_title": "Discussion and Conclusions", "text": "This bounded conformal regression method has been applied to a problem of medical prognosis. A development of Alzheimer's disease has several stages before the actual dementia onset. Neurodegeneration usually starts from the entorhinal cortex and hippocampal formation and subsequently spreads thoughout the brain. This pattern is consistent with our results. Thus, the most important features for prediction were volumes of the Left and Right Hippocampi, Left Amygdala, thickness of the Left Entorhinal cortex, apoE-genotype (known genetic biomarker associated with different risks for Alzheimer's disease [18] , and the result of Mini-Mental State Examination (screening tool to assess cognitive functions). We have proposed a conformal predictor based on a new kind of non-conformity measure, based on the ideas of game-theoretic defensive forecasting method, originally developed for a bounded regression. This techniques has some advantages that were discussed in the theoretical part of the paper. The experimental results are especially interesting as an illustration of a generalized kernel technique in the context of bounded regression."}]