[{"section_title": "1", "text": ""}, {"section_title": "Introduction", "text": "This study investigates the impact of teacher characteristics and instructional strategies on the mathematics achievement of students in kindergarten and first grade. Understanding the factors that make some teachers more effective than others is vital to achieving and supporting high quality instruction. Early teaching, in particular, can be crucial to the future academic progress of children, as well as in determining later economic well being and other nonacademic outcomes (Barnett, 1995;Currie & Thomas, 2000;Kilpatrick, Swafford & Findell, 2001;Chetty et al., 2010). Evidence of \"what works\" in elementary mathematics instruction can be obtained from multiple sources: experiments, observations, administrative data, and surveys. This study utilizes survey data and provides a framework to guide the estimation of causal effects in nonexperimental settings. Although experimental evidence of effects is generally considered the gold standard, true educational experiments are rare, centered primarily around interventions, and difficult to impose or implement. In addition, they are generally conducted on a small scale, yielding potentially ambiguous conclusions regarding the effects of scaled-up interventions. Classroom observations provide an in-depth picture of teaching but are costly to conduct on a large scale and can be difficult to parse into identifiable, quantifiable elements of instruction that overcome inter-rater reliability issues. Administrative data are often used to uncover associations between factors like teacher training and student achievement. However, these data contain only the most basic teacher and student characteristics required for reporting and compliance purposes and often suffer from missing, and sometimes inaccurate, data records. Large sample survey data, if representative of the population of interest and sufficiently detailed, can represent an improvement over administrative data. They are less costly to collect than classroom observations on a large scale, and they can provide information on treatments that cannot be investigated through experiments. Much of the body of knowledge on teacher effectiveness consists of estimates derived from survey data, such as National Educational Longitudinal Study (NELS) and Early Childhood Longitudinal Study, Kindergarten Class of 1998-99 (ECLS-K). However, these data have significant limitations, as well. They generally rely on self-reported activities and characteristics and often suffer from item non-response, even when overall survey response rates are high. In addition, sample attrition in longitudinal surveys can pose a threat to representativeness if it is nonrandom. The fundamental disadvantage of survey data with respect to experimental data, however, is that students are not randomly assigned to treatments, rendering causal inference inherently difficult-a disadvantage shared with observational and administrative data. Survey data can compensate for this handicap to varying degrees, however, by providing a rich set of control variables that might reduce omitted variable bias in estimates. This paper tackles the question of how best to use longitudinal survey data to elicit causal inference with respect to teacher-related factors impacting early mathematics achievement in the face of potential threats to validity due to nonrandom assignment to treatment. Researchers have several tools at their disposition to deal with these threats. Methodological decisions can be complex, however, and, as we show, results can be sensitive to the approach selected. As such, it is imperative to understand why inconsistencies occur and which methods are best in a given situation. The goals of this paper are thus twofold: (1) to lay out a careful approach for selecting an appropriate model and estimation method to investigate teacher effects using longitudinal survey data and (2) to apply this approach in answering our specific research question-i.e., the extent to which the observable background characteristics and instructional practices of kindergarten 3 and first grade teachers produce gains in the mathematics achievement of their students. We use data from ECLS-K, a nationally representative sample of kindergarteners followed over time. The data include student assessments in mathematics and reading at each wave as well as detailed information from parents, teachers, and school administrators and are therefore well suited to an investigation of our research question. Through a step-by-step analysis of the data, we select a modeling and estimation strategy. Our findings indicate that teacher certification and courses in methods of teaching mathematics have a slightly negative effect on student achievement in kindergarten, whereas postgraduate education has a positive effect in first grade. Various teaching modalities, such as working with counting manipulatives, using math worksheets, and completing problems on the chalkboard, have positive effects on achievement in kindergarten, and pedagogical practices relating to explaining problem-solving and working on problems from textbooks have positive effects on achievement in first grade. We find that the models and estimators previously employed to estimate teacher characteristic and practice effects using longitudinal survey data likely neglected important features needed to establish causal inference. Importantly, we show that the conclusions drawn depend on the estimation and modeling choices made, underscoring the importance of setting out a clear strategy for choosing among the many possibilities available. This paper is organized as follows. In section 2, we outline a framework for selecting a model and method for estimating teacher effects using longitudinal survey data. Then, in section 3, we review the relevant literature pertaining to our specific research question-i.e., what teacher characteristics and practices affect student achievement in the early grades?-with particular attention to the estimation methods used. Section 4 describes our data, section 5 outlines our methods, section 6 presents and discusses results, and section 7 concludes."}, {"section_title": "Modeling and Estimation Framework", "text": ""}, {"section_title": "Models", "text": "A very general cumulative effects model views current achievement as a function of all relevant current and past inputs, a student specific effect, and a random error term (Hanushek, 1979;Todd & Wolpin, 2003;Harris, Sass, & Semykina, 2010;Guarino, Reckase, & Wooldridge, 2011): (1) where = achievement of child i with teacher j in school s at time t = time-varying education production function relating inputs to achievement = time-varying child, family, and neighborhood inputs for child i in period t = time-varying schooling inputs (such as teaching practices, peer effects, etc.) = time-invariant child effect u ijst = unobserved error term Researchers make several assumptions to render (1) tractable for analysis. As a first step, the function f t is generally assumed to be linear in the parameters. These assumptions yield the linear cumulative effects (LCE) model: Our interest lies primarily in estimating the parameters, which in this case convey the partial effects of teacher characteristics and practices on math achievement. Typically, data on all inputs prior to kindergarten-e.g., preschool or daycare characteristics-are unavailable, and the student effect c i , sometimes thought of as unmeasured innate student ability or motivation, is generally unobservable. To address the lack of prior inputs, it is customary to impose an additional assumption: namely, that the effect of the inputs decays at a geometric rate equal to \u03bb. In terms of the parameters, this assumption requires and for . The geometric decay assumption on the input effects allows one to eliminate the lagged inputs and rewrite equation 2as a geometric distributed lag (GDL) model: 1 (3) A second common restriction is that , indicating that the child-specific effect has the same effect on achievement in every period. Note that under this assumption there is no loss of generality by denoting as 1 in these models if a constant is present in the model. Equation (4) is generally referred to as a dynamic linear model due to the presence of lagged achievement on the right-hand side. Estimation of (4) is generally feasible, as it requires only contemporaneous inputs and a lag of achievement. However, many researchers proceed to subtract prior achievement from both sides of the equation and estimate what is often referred to as a gain score model. This results in the following: Of course, if , then the piece of prior achievement left in the error term with a negative coefficient disappears. If not, it causes an omitted variables problem as well as negative serial correlation. Thus, in choosing this model specification, researchers are essentially assuming that (i.e., that there is no decay in the impact of prior inputs on current achievement) or that the consequences of violating this assumption are unimportant in estimating the parameters of interest. To relate equations (4) and the constrained version (5) directly to our research questions, we now rewrite them under all the assumptions hitherto mentioned using terms specific to our study: , 1 1 2 3 4 , 1 ( 1) where PDG = the set of pedagogical practices used by teacher j TC = the set of background characteristics of teacher j CLASS = a set of classroom characteristics X = a set of child-and family-related control variables \u03c4 j = an unobserved teacher-specific effect \u03b4 s = an unobserved school-specific effect \u03b5 ijst = a random error term In our study, we use data from three time periods. ECLS-K assessed kindergarten and first grade children's achievement in the full sample in the fall of the kindergarten year (t = 0), in the spring of the kindergarten year (t = 1), and in the spring of the first grade year (t = 2). 2 In our modeling, the fall test score in kindergarten is lagged relative to the spring test score. For first grade, the spring kindergarten test score is lagged relative to the spring first grade test score. 3 The characteristics of kindergarten teachers were recorded in the fall, and corrected in the spring if children's teachers changed. Information on teaching practices was recorded in the spring. For first grade teachers, all information was recorded in the spring. 2 A subsample of first grade children was assessed in the fall; we do not use that partial wave. 3 Thus the intervals between current and lagged tests differ across grades. We take this into account by controlling for time elapsed between tests and, in some cases, by interacting lagged achievement with a grade indicator. In these new equations (6) and (7), the composite error term ( ) contains unobserved school and teacher effects as well as the child effect c i and the idiosyncratic term \u03b5 ijst . By including the terms \u03b4 s and \u03c4 j , we allow for the possibility that in our focus on the specific teacher characteristics and pedagogical behaviors contained in PDG and TC, certain teacher and school-level factors that are relevant to predicting achievement may be omitted. 4 It is important to note, however, that \u03b4 s can be explicitly estimated through the inclusion of school dummy variables rather than left as a component of the unobserved error term, whereas fixed teacher effects \u03c4 j -e.g., an unobserved teacher quality component-cannot be estimated separately from the observed teacher variables of interest unless we observe more than one class of students for each teacher. 5 For notational simplicity, we do not include interactions in this model, although in our investigations, we explore the possibility that the effects of teacher characteristics and instructional practices on achievement differ across grades."}, {"section_title": "Estimators", "text": "Several estimation strategies can be applied to models (6) and (7). The estimators associated with these two models-the lag score and the gain score-are outlined below and summarized in Figure 1. Both models can be estimated using either cross-sections of data (i.e., data for each grade separately) or data that are pooled across kindergarten and first grade. If the equations are estimated using cross-sections of data, two primary approaches are possible: ordinary least squares (OLS) estimation and maximum likelihood estimation with random effects assumptions. The OLS estimator will be consistent if student heterogeneity and the other error components are uncorrelated with either the input or output variables. We can 4 In our notation, we impose the simplifying assumptions that the unobserved school and teacher effects are constant across students and over time. 5 In ECLS-K, we have only one classroom per teacher. The possible effects of this limitation are later discussed. relax that assumption with respect to , if need be, by putting in school dummy variables. In Figure 1, this set of choices is represented by the OLS portion of the tree on the left side of the diagram for cross-sectional data. Efficiency gains may be possible using maximum likelihood if we exploit the nested structure of the data (in our case, children within classrooms within schools) and assume that the teacher and school terms ( and ) are normally distributed random effects. Such estimation strategies are often referred to as mixed or hierarchical linear models (HLM). This strategy effectively accounts for correlation among test scores for students with the same teacher and within the same school in the estimation of the pedagogy and teacher effects. Here again, we can treat the school effects as fixed rather than random by including school dummy variables, and use an HLM estimator with just teacher random effects (see the HLM portion of the tree diagram in Figure 1). If the data are pooled across the grades, OLS can still be used on either model (6) or 7under the same independence assumptions as in the cross-section data case (see the right portion of the figure under \"panel\"). However, panel data allow us to make use of approaches that deal with the presence of unobserved student heterogeneity. In the lag score model (6), pooling across grades allows for the elimination of heterogeneity by first differencing and then instrumenting for the endogenous lagged test score gain with the twice-lagged test score. A common estimator that accomplishes this is the generalized method of moments (GMM) approach described in Arellano and Bond (1991), which we will henceforth refer to as AB. This approach not only accounts for unobserved student heterogeneity but also allows us the flexibility of leaving \u03bb unconstrained. However, it relies on the assumptions that the error term in equation 6is serially uncorrelated and that all other inputs satisfy a \"strict exogneity\" assumption-namely, that errors \u03b5 it in one time period are uncorrelated with inputs in all other time periods (Wooldridge, 2002, ch. 10, pp.252-254). In the gain score model (7), in which \u03bb is constrained to equal 1, random effects (RE) or fixed effects (FE) estimators can be used to mitigate problems associated with student heterogeneity. RE assumes the child-specific heterogeneity and the inputs are uncorrelated, strict exogeneity, as well as a particular structure to the error covariance matrix, and may result in efficiency gains over OLS if these assumptions are met (Wooldridge 2002, ch. 10, pp. 252-254). FE estimation relaxes the assumption of zero correlation between heterogeneity and observed right-hand-side variables but maintains strict exogeneity. Note that the strict exogeneity assumption required by RE and FE is violated in model (6) because the lagged test score variable on the right-hand side is a function of the error term in the previous period. Thus, RE and FE estimators will be inconsistent for (6) and will only apply to the gain score model. The modeling and estimation choices that we have described-18 in total and summarized in Figure 1-will be those considered in our study. In section 4, we outline a strategy for selecting the appropriate method. But first, we review prior survey-based research pertaining to our research question with careful attention to the methods chosen in these studies. Divergence of our findings from earlier findings may be traceable, at least in part, to the different choices of methods."}, {"section_title": "Prior survey-based research on the impact of teacher characteristics and teaching practices on student achievement in the early grades", "text": "Although a number of prior studies have used survey data to examine the relationship between student achievement and observable teacher characteristics and practices, using a variety of model specifications and estimation methods (see Wayne and Youngs, 2003, for a review), relatively few have examined these relationships in the context of early elementary mathematics teaching. Rowan, Correnti, and Miller (2002) estimated a gain score model using HLM with both teacher and school random effects to analyze a longitudinal data set on elementary school children across the US in the early 1990s. They found no effect of teacher certification status or subject-matter preparation on achievement growth in mathematics but found a positive relationship between teaching experience and growth for students going from third to sixth grade and a negative relationship between advanced degrees and growth for students in both the early and upper elementary grades. Among a small set of pedagogical practices examined, only time spent on whole class instruction was positively related to mathematics achievement. Other studies focused on links between teacher-reported instructional practices and early mathematics achievement have tended to explore the use of \"reform-based\" or \"standards-based\" practices that emphasize problem solving and inquiry. Le et al. (2006), in a study of third grade students in five districts across the U.S. followed longitudinally for three years estimated a lag score model for achievement using OLS. They found weak and inconsistent relationships between student-centered practices and mathematics achievement. Reform-based practices showed positive effects on measures related to problem solving but negative effects on measures designed to capture a student's grasp on mathematical procedures. Cohen & Hill (2000) also estimated a lag score model using OLS to study links between teacher responses on a survey administered to elementary teachers in California in 1994 and student achievement on the California Learning Assessment System during the same year. They found that teacher-reported frequency of use of reform-based practices was positively related to mathematics test scores among fourth-graders. Hamilton et al. (2003) conducted a meta-analytic synthesis of teacher survey data from grades three through seven at several National Science Foundation-funded Systemic Reform Initiative sites to investigate the effect of reform-based teaching practices on mathematics and science learning. Their results were based on OLS regressions, although it is not clear whether gain or lag scores were used and specifications differed across sites depending on the availability of data. They combined several specific practice items into a \"reform-based\" scale and found small and weak but fairly consistent positive relationships between teachers' use of reform-based practices and student achievement. In addition to the studies cited above, three prior studies estimated the effects of teacher characteristics and instructional practices on the mathematics achievement of early elementary students using ECLS-K. All three relied on a single cross-section of the ECLS-K for the main analysis, with Guarino, Hamilton, Lockwood, and Rathbun (2006) and Bodovski and Farkas (2007) focusing on kindergarten and Parlady and Rumberger (2008) focusing on first grade. All employ HLM estimation. Guarino et al. (2006), using a gain score model, found no evidence of a direct relationship between the background characteristics of teachers and student achievement but found that spending more time on subject was associated with relatively large gains in achievement. They constructed instructional practice scales, combining several practice measures into aggregate indexes using factor analysis. Among the scales designed to capture pedagogical approaches, those describing an emphasis on traditional practices and computation, measurement and advanced topics, advanced numbers and operations, and student-centered instruction (e.g., having students explain how problems were solved) were positively associated with mathematics achievement gains. Bodovski and Farkas (2007) also focused on kindergarten and created instructional practice scales but utilized a lag score model in their analysis. They found that both traditional and interactive approaches, along with practices that focused on advanced counting, practical math and single-digit operations were related to larger gains in achievement. On the other hand, spending additional time on basic numbers and shapes was found to be associated with lower achievement gains. They also mention obtaining similar results from an unreported fixed effects estimation which relies on the pooled kindergarten and first grade data available in the ECLS-K as evidence that their results approximate causal effects. Parlady and Rumberger 2008used a lag score model and focused on first grade rather than kindergarten. They found that the use of math worksheets and calendars raised student mathematics achievement, whereas the use of geometric manipulatives lowered it. They restricted their sample to a 30 percent subsample of students who were tested in the fall of first grade and used the fall exam score as an explanatory variable in the analysis. The relationships found in these survey-based studies cannot be interpreted as causal unless the assumptions underlying the models and estimators used are met. In this paper, we analyze the ECLS-K data using a step-by-step approach to justify our modeling and estimation choices, the goal being to provide estimates with the best claim to causal inference. We then compare our results with those obtained in earlier studies using other methods."}, {"section_title": "Data", "text": "The ECLS-K selected a nationally representative sample of approximately 22,000 children who were enrolled in approximately 1,000 kindergarten programs in the United States, during the 1998-99 school year. The children were selected from both public and private kindergartens offering full-day and part-day programs. The sample consisted of children from different racial-ethnic and socioeconomic backgrounds and included an oversample of Asian children and private school kindergartners. The sample design for the ECLS-K was a dual-frame, multistage sample. First, 100 Primary Sampling Units were selected (PSUs were counties or groups of counties). Schools within the PSUs were then selected; public schools from a public school frame and private schools from a private school frame. In the fall of 1998, approximately 23 kindergartners were selected within each of the sampled schools (Tourangeau et al., 2001). The ECLS-K followed these children at various intervals through eighth grade. Three of the seven available waves of the data are utilized in this study. The first two waves of data were collected in the fall and spring of the 1998-1999 kindergarten year, respectively. The third and fourth waves were collected in the fall and spring of the first grade year, but the third wave (fall of the first grade year) was collected only on a relatively small (30 percent) sub-sample of the children and is therefore not used in this study. For this study, we restrict the data to the fall and spring kindergarten and spring first grade waves. The fifth, sixth, and seventh waves are excluded because they occur after intervals of two or three years-thus the variation in children's learning gains is likely to be only loosely connected to the practices and abilities of contemporaneous teachers. In the three waves selected for the study, we make use of several categories of data-achievement assessments, teacher interviews, and student and family characteristics."}, {"section_title": "Achievement Assessments", "text": "Assessments that included cognitive components were conducted with the sampled children through one-on-one tests administered by trained individuals at each wave. The full achievement assessment used a computer-assisted personal interview and took approximately 50-70 minutes to complete. It included tests of reading and mathematics as well as other components that differed by wave (e.g., general knowledge in the kindergarten wave and science in the third grade). The test was untimed, and the kindergarten test required children to respond verbally or through pointing; no writing was required. Each test was conducted using a two-stage design. The first stage consisted of a routing section that was administered to all students, and the second stage consisted of one of several alternative forms, the choice of which depended on the child's performance on the first stage. Only the assessments in mathematics are utilized in this study. The mathematics assessments had low, middle, and high difficulty second-stage options. The purpose of the adaptive design was to maximize accuracy of measurement and minimize administration time. 6 The content of the mathematics assessments was selected to represent cognitive skills that are typically taught at each stage of development and that are important for the development of later proficiency (Rock & Pollack, 2002). Efforts were made to accommodate children who spoke a language other than English in the kindergarten and first grade assessments. Prior to administering these assessments, a language-screening test-the Oral Language Development Scale (OLDS)-was administered to those children identified from their school records (or by their teacher, if no school records were available) as coming from a home in which the primary language spoken was not English. Children whose performance exceeded an established cut score on the OLDS received the full English direct assessment in mathematics. Students who did not pass the OLDS but who spoke Spanish were given a translated form of the mathematics assessment. Various methods were used to confirm that the psychometric properties of the Spanish mathematics assessment were comparable to those for the English version (Rock & Pollack, 2002 Three types of scores were reported for each test: (1) the number of questions answered correctly on the first-stage routing test, (2) item response theory (IRT) scale scores, and 3standardized (t-scale) scores. The most appropriate of these for the purpose of this study are the IRT scores, because IRT scores are designed to make it possible to calculate scores that can be compared regardless of which second-stage form a child took in the adaptive test. They compensate for the possibility of a low-ability student guessing several items correctly. In addition, they make possible longitudinal measure of gain in achievement over time, even though the tests administered are not identical at each point (Tourangeau et al., 2001)."}, {"section_title": "Teacher-level variables", "text": "Information on the teachers in both kindergarten and first grade was gathered in a set of self-administered paper-and-pencil questionnaires that included questions about their backgrounds and instructional practices. Background characteristics used in this study consisted of indicators for race/ethnicity, teaching experience, certification, educational attainment, and completion of courses in methods of teaching mathematics. 7 Other relevant variables consisted of time spent on preparation, and, most importantly, a set of instructional practices described in the next section."}, {"section_title": "Instructional Practices", "text": "The spring teacher questionnaires include sets of items that address instructional practices in mathematics. The items address a wide range of practices that may occur in classrooms in the early grades and were selected to align with the skills tapped by the ECLS-K achievement assessments. Both the kindergarten and first grade teachers were asked very similar questions regarding their instructional practices; thus we were able to construct nearly identical sets of practices that apply to the two time periods. Specific pedagogical practices are listed as items in the ECLS-K teacher questionnaire under the question: \"How often do children in the class do each of the following math activities?\" The kindergarten teacher questionnaire includes 17 activities representing different pedagogical modalities. The first grade teacher questionnaire included the same items, with very few differences. 8 We code teacher responses on all of these items to reflect days per month. 9 In addition to these items, we include a measure of time spent on mathematics in our analyses. Teachers were asked how often they teach mathematics and how much time they spend on the subject on the days they teach it. We combined the responses to both questions to estimate the total hours per week a teacher reported spending on mathematics. In addition, teachers were asked the extent to which they utilized divided achievement grouping, without special reference to mathematics. This was coded as hours per week the student's spent in such groups."}, {"section_title": "Content Coverage", "text": "In addition to the pedagogical variables, the surveys contain several items relating to content coverage. The stem question is: \"How often is each of the following math skills taught in the class?\" and 29 skill or content areas are then listed. We use these items as control variables to enable us to isolate the effect of pedagogical techniques holding constant content emphases that might align to a greater or lesser degree with the tests. They are recoded in a manner similar solutions\" and \"Do worksheet or workbook page emphasizing routine practice or drill\" to the 17 kindergarten pedagogy questions. 9 We code the response categories for mathematics activities using what is essentially interval midpoint scaling: \"never\" \u2192 0 days per month; \"once a month or less\" \u2192 1 day per month; \"two or three times a month\" \u2192 2.5 days per month; \"once or twice a week\" \u2192 6 days per month; \"three or four times a week\" \u2192 14 days a month; \"daily\" \u2192 20 days per month. The metric assumes a standard of four weeks in a month and five working days per week. to that of the pedagogy variables. 10 Appendix Table 1 displays descriptive statistics for the teacher variables included in the model."}, {"section_title": "Classroom Characteristics", "text": "Teachers were also asked to describe demographic characteristics of their classes. Reported are class size and the percentages of children of different racial-ethnic groups and with disabilities. We include these in our analyses to control for differential teacher responses to variation in classroom composition."}, {"section_title": "Child and Family Variables", "text": "Student-specific variables used in our analyses include the number of days elapsed between tests, indicators for disability status, attending a full day kindergarten, whether the child is repeating kindergarten, and whether the child takes the test in Spanish. In addition, we include several controls that capture socioeconomic status (e.g., parent education and income), family behaviors (e.g., parental involvement, the number of extracurricular activities in which the child engages, how often the child reads, and the number of educational activities in which the child participates in the home), and family structure (e.g., single parent, number of siblings). ECLS-K provides a rich set of such variables, allowing us to capture child effects that are often omitted in administrative data. The full set of these controls and their descriptive statistics are also included in Appendix Table 1."}, {"section_title": "Sample Adjustments", "text": "Although item non-response for the variables in our study is typically low (e.g., around one to two percent for the pedagogy practices, as shown in Appendix Table 2), the combined effect of missing item responses across all variables leads to a sample decrease of more than 60 percent in kindergarten and more than 65 percent in first grade. This drop in the number of observations hinders our ability to estimate the pedagogy and teacher characteristic effects with precision. To counter the loss of information stemming from item non-response, we used Royston's (2004) Stata implementation of chained multiple imputation (Van Buuren, Boshuizen & Knook, 1999) to impute missing values for all variables except student test scores. Forty imputed data sets were produced for each of three types of data-pooled data from both kindergarten and first grade, data from kindergarten only, and data from first grade only. The 40 pooled data sets were each composed of 21,232 student-year observations representing students with test score at all three waves. The separate kindergarten and first grade cross-sectional imputed data sets were composed of 16,356 and 11,780 student observations, respectively, including students with non-missing current and lagged test scores only in the particular grade imputed. Post-imputation estimation was carried out using Stata routines influenced by Carlin, Galati & Royston (2008). Following ECLS-K guidelines, we used sampling weights supplied with the data in the imputation to better approximate the initial population."}, {"section_title": "Methods", "text": "Here we outline a decision-making process to choose among the 18 model/estimation choices described in Section 2 and illustrated in Figure 1. To decide among these alternatives, we undertake a multi-step investigation. Each step pertains to one of the decisions needed: lag score versus gain score, cross-section versus panel, and ultimately choosing an estimator."}, {"section_title": "Gain Score vs. Lag Score", "text": "Deciding between a gain score or lag score model amounts to testing whether the assumption \u03bb=1 in equation 6is justifiable. In addition to merely observing the coefficient of the lagged test score when estimating equation 6, we make use of a test proposed by Harris, Sass, and Semykina (2011). Applied to our problem, this test amounts to testing the joint significance of including a set of variables representing the first lags of all the inputs in the gain score equation 7for first grade. Formally, this is a test of the null hypothesis that . The test is motivated by the idea that the lagged score, with the coefficient constrained to equal one, effectively serves as a sufficient statistic for past inputs. Therefore, if the gain score approach properly controls for past inputs, the included lagged inputs should not be statistically significant. It should be noted, however, that since we observe only two grades, the test of will pertain only to first grade because there are no lags of inputs available for kindergarten."}, {"section_title": "Cross Section vs. Panel", "text": "The decision to use panel data versus separate cross-sections in our analyses is based on three considerations: whether the impact of teacher characteristics and practices changes across grades, whether there are precision gains due to increased sample sizes, and whether there is a need for panel data methods to eliminate time-invariant unobserved child heterogeneity, which may bias estimates of teacher effects related to PDG and TC. To investigate whether the impact of teaching practices varies across grades, we estimate equation (6) or (7) (depending on whether we choose a gain score or a lag score model) using the pooled data and including interactions between a grade dummy and all teacher characteristics and practices. If several characteristics and practices interact significantly with grade, it would indicate that either the interactions should be included in any panel analyses or that crosssectional regressions should be run separately by grade. Possible precision gains from using the panel, due to the increased number of observations, might be a reason to prefer the panel regressions, but such gains are likely to be \uf06c\uf03d\uf031 \uf06c\uf03d\uf031 quite small. As mentioned in the previous section, the grade-specific sample sizes in ECLS-K (N=16,356 for kindergarten and N=11,780 for grade 1) are likely large enough to mitigate concerns over lack of precision. The most important driver of the decision regarding the panel versus the cross-sections is the question of whether unobserved child-specific heterogeneity c i is likely to bias the teacher effect estimates. Only panel data methods (i.e., FE in the gain score model and AB in the lag score model) address this problem by eliminating the effects of heterogeneity. Assessing the influence of heterogeneity is not straightforward and the tools and tests at our disposal provide only suggestive evidence of the extent of the problem. Nevertheless, we can make use of the following set of procedures. A common approach to assessing the influence of unobserved heterogeneity on the effect estimates is to use a Hausman (1978) test in which the coefficients from random and fixed effects estimators are compared, or a related variable addition test suggested by Wooldridge (Wooldridge, 2002, ch.10, p.288-291). 11 It should be noted, however, that in our achievement regression, the RE and FE estimators are consistent only for the gain score model; thus we can seek evidence from these tests only under the assumption that \u03bb=1. Therefore, if our results from step one indicate that the gain score model is not a viable option, these tests cannot be viewed as reliable. Similarly, both estimators require strict exogeneity of the included regressors, and a violation of this assumption limits the reliability of this test. Another approach to assessing the influence of unobserved heterogeneity that is applicable in both the gain score model and the lag score model is to investigate how observable child and family characteristics vary across different levels of exposure to particular teacher characteristic (TC) or teaching practices (PDG). To do so, we adapt the common balance of covariates approach, in which the mean observable characteristics across levels in TC or PDG are compared. First we explore whether the variables in TC or PDG (which we can refer to as \"treatments\") vary with the child-specific observables-prior achievement and the variables contained in X ijst -in the following regression: 12 ,1 Teacher If a test of joint significance of all the right-hand-side variables in (8)-i.e., a test of the null that all \u03b2 and \u03be are zero-does not reject, then there is strong evidence that treatment is unrelated to these observed child characteristics. In this case, we have more confidence that selection on unobservables is also negligible. If instead the test rejects, then we conclude that exposure to treatment differs systematically across child characteristics and, unless we believe that our set of observables is so complete as to eliminate anything that might be left in c i (e.g., individual intelligence or motivation) which is correlated with treatment, we might continue to worry about unobserved heterogeneity. If the test rejects, a possible reason might be that systematic variation of treatment across child and family characteristics is due to the sorting of children with particular characteristics into particular schools. To verify this, we can run the following regression, which includes both the child variables and school dummies, and again test the joint significance of the child variables: ,1 Teacher If the inclusion of school dummies removes the significance of the child variables, then we can assume that treatments are distributed randomly across child characteristics within schools. This would offer evidence that, at least within schools, selection on observables is negligible. If we again rely on the assumption that selection on the unobservables, c i , should be no more threatening than that related to our rich set of observables, then we can argue that panel data methods that remove c i are unnecessary, and that the inclusion of school dummies in either the cross-sectional or panel regressions will suffice to remove this threat. If instead, evidence of unobserved heterogeneity is non-negligible, then the panel will be needed at the cost of requiring the additional assumptions discussed in Section 2 for consistent estimation of the treatment effects."}, {"section_title": "Choosing an Estimator", "text": "The above analyses provide a strategy for choosing between the lag and the gain score model and deciding whether to pool or separate the data across grades. After gathering the information from these analyses, we can substantially narrow down the set of 18 choices illustrated in Figure 1. The gain score/lag score decision, coupled with the cross-section/panel decision will lead to a small number of estimators for further consideration. In addition, the assignment to treatment analysis helps determine whether or not to include school dummies. At this point, if more than one model/estimation method remains viable, we will compare their findings and discuss the similarities and differences found."}, {"section_title": "Results", "text": ""}, {"section_title": "Gain Score vs. Lag Score: Results", "text": "To choose between using the lag score equation (6) or the gain score equation 7we first visually inspect the coefficient on prior test scores in (6) and then apply the test proposed by Harris, Sass, and Semykina (2011). When we use OLS to estimate (6) with the panel, our estimate of is 0.7505 and when we estimate it with the cross-sections, the estimate of is \uf06c \uf06c 0.9070 for kindergarten and 0.6998 for first grade. All three estimates are statistically different from 1, with the p-value equal to 0.0000 in each case for the test of the null hypothesis that \u03bb=1. For the formal test, we estimate equation 7and include the lagged inputs in the first grade specification. We find the lagged inputs to be statistically significant when included in equation 7, with a p-value for the joint test of significance of 0.0005. Given these results, we choose the lag score specification found in equation 6."}, {"section_title": "Cross Section vs. Panel: Results", "text": "To investigate whether teaching practices should be allowed to vary across grades, we estimated equation 6using the pooled data and including interaction terms between the grade dummy and all the teacher practices and characteristics. The results are shown in Table 1. Due to the large number of controls included in the model, we only display those relevant to our research questioni.e., the teaching practices and teacher characteristics. We find significant interactions with grade for a small number of teacher characteristics and teaching practices. Postgraduate education matters more in predicting higher achievement in first grade than in kindergarten. Working with counting manipulatives predicts lower achievement in first grade than in kindergarten-outweighing the positive main effect. Overall, we find that pooling the data and constraining the coefficients to be the same across grades can obscure grade-specific relationships in a sufficient number of instances so as to make it helpful to separate our regressions by grade. To assess whether there is evidence of selection on observables, we estimate equations (8) and (9)-i.e. the treatment regressions. The p-values for the joint F-test for these regressions are presented by grade in Table 2. For equation (8), our results show that for most teaching practices and most teacher characteristics we consider, the child variables are found to be jointly significant, indicating that treatments are not randomly distributed across these observable characteristics. However, once we condition on the school attended by including school dummies in equation 9, the child variables are jointly significant in only one case-having a Hispanic teacher. 13 In effect, all other teacher characteristics and instructional practices appear to be randomly assigned to students with different observable characteristics within schools. This offers evidence that the selection on observables is random within schools. Because of the rich set of observables these data provide, it can be argued that selection on unobservables should also be negligible. Thus, panel data methods that remove child effects (i.e., FE and AB) may be overly cautious-with the first differencing removing too much variation-if we already control for school differences with these data. Using AB instead of a simpler estimator with school dummies will likely increase standard errors due to the lost variation in the data and reduce our ability to detect significant effects. Furthermore, AB requires additional assumptions, such as no serial correlation in equation (6) and strict exogeneity of the other inputs. 14 By eschewing AB, we do not rely on these assumptions to obtain consistent estimates. As a result of these analyses, we narrow down the model/estimation choices in Figure 1 to those that use cross-section data (and thus preserve maximum flexibility) and include school dummies. Note that previous studies relying on HLM techniques (e.g., Guarino et al. 2006, Bodovski & Farkas 2007, Parlady & Rumberger 2008, Rowan, Correnti, & Miller 2002 assumed random school effects, which are uncorrelated with the teacher characteristics and practices experienced by the child, rather than fixed school effects, which do not impose this 13 Further investigation (not shown in a table) revealed that some racial/ethnic matching may take place within schools, which led us to include interactions between teacher and child race categories on our achievement regressions. 14 AB also requires that the coefficient on the lagged dependent variable not be close to one. In that case, it breaks down due to a weak instrument problem. assumption. The above analyses suggest that this assumption is unlikely to hold in ECLS-K, thus leading estimators with random school effects to be inconsistent."}, {"section_title": "Choosing an Estimator: Results", "text": "At this point, the remaining estimation choices among those outlined in Figure 1 are OLS and HLM on the lag score model with school dummy variables. Table 3 presents results for teacher characteristics and teaching practices using these estimators side by side. Certain teacher characteristics and practices-though relatively few-show evidence of producing achievement effects. The two methods produce very similar results. 15 The main difference between the two approaches lies in the computation of the standard errors. We used cluster-robust standard errors at the school level in the OLS regressions, producing standard errors that tended to be slightly more conservative. Teacher characteristics show different effects in kindergarten and first grade as expected due to our previous investigation of interaction terms. In kindergarten, we find evidence that having a teacher who is certified reduces achievement in kindergarten by approximately .43 IRT scale points (a small effect of about 1/25 of a standard deviation 16 ) and that having taken more than two courses in methods of teaching mathematics reduces achievement by a little more than half that amount. In first grade, we find, however, that certification and coursework does not matter one way or the other, but that training in the form of advanced degrees has a positive effect: having a teacher with post-graduate education raise test scores by roughly four IRT scale points-i.e., more than one-third of a standard deviation. The differences in the effects of 15 In fact, the coefficients themselves are more or less identical for OLS and HLM in kindergarten due to the fact that the estimated unexplained variance in achievement due to differences in teachers within schools is very close to zero. In first grade, this variance component is somewhat larger. 16 As shown in Appendix background training and education between kindergarten and first grade-discussed further in the next section-are noteworthy. Small but for the most part strongly significant effects emerged in both grades with respect to teaching practices, and, again, the effects of specific practices differ across grades. In kindergarten, teachers who emphasize the use of counting manipulatives and the chalkboard have a positive impact on achievement. The effects are small-using any of these practices for an additional 10 days per month will raise test scores by less than 1/25 of a standard deviation in IRT scale points. The smaller standard errors in the HLM regression also point to weak evidence that using math worksheets has a small positive effect and using creative movement to teach math has a small negative effect. In first grade, teachers who spend more time engaging students in explaining how a mathematics problem is solved raise test scores by approximately .05 IRT scale points, and the coefficient is highly significant. Although somewhat larger than the other coefficients, it indicates that using this practice an extra 10 days per month will raise achievement by 1/20 of a standard deviation-still a modest effect. A smaller and weakly significant positive effect is detected for doing mathematics problems from a textbook. In addition, the HLM regression provides some evidence that working on problems for which there are several solutions has a positive impact on achievement, a finding that complements the strong finding for explaining math problems."}, {"section_title": "Discussion", "text": "If we assert that the findings are causal, some policy implications emerge. Even though kindergarten and first grade represent closely spaced points on a continuum of early childhood education, we find that few characteristics and practices have a consistent effect in both grades. Our results could be interpreted as suggesting that training and pedagogy that is geared toward analysis or explanation is appropriate for first grade but not necessarily for kindergarten. There are three possible explanations for this. One is that the ECLS tests measure very different constructs in the two grades. However, given that the tests are constructed by the same assessment teams so as to provide a certain amount of continuity, this seems unlikely. Or, secondly, curricular differences across the two grades may be such that they align more with standardized tests in first grade. However, given the large set of content coverage controls in our models, this also seems unlikely. A third explanation, that the cognitive development of a child differs markedly across these two periods of growth, is perhaps more likely. As a corollary to this hypothesis, the negative finding for certification in kindergarten warrants further investigation and suggests either that the approach to mathematics pedagogy in early elementary teacher trainings programs may not be geared toward achieving the kind of learning that can be measured by standardized tests administered at that point in time, or that it is not well aligned with learning development at the kindergarten stage. It is important to note that teacher training programs generally group kindergarten, early elementary, and upper elementary training into the same mathematical content and pedagogy courses. Thus training is not fine-tuned toward specific developmental stages. Our findings with respect to the specific practices suggest that the developmental needs of students change from kindergarten to first grade and may require different teaching techniques. The use of counting manipulatives, although fairly frequently used in both grades, with kindergarten teachers using it an average of 12.5 times per month and first grade teachers using it an average of 11 times a month (see Appendix Table 1), only affected achievement in kindergarten. A possible explanation might be that the usefulness of this type of manipulative in influencing learning reaches a plateau; kinesthetic approaches may prove effective among kindergarteners, whereas first grade students may outgrow their use. Also effective in kindergarten only is the use of chalkboards. Kindergarten teachers report using this practice only 4.7 times per month on average while first grade teachers use it almost twice that amount, suggesting that its relatively non-routine practice in kindergarten produces a helpful boost to achievement. On the other hand, the more verbally-oriented pedagogical technique of asking students to explain how a problem is solved influences achievement for first grade students but not for kindergarten students. It is encouraging to note that this practice is utilized relatively often in first grade (on average, 12.8 times per month in first grade versus 8 times per month in kindergarten). Several explanations might be offered for the small pedagogical effects. First, it is important to acknowledge the limitations of retrospective survey items in accurately capturing the frequency of use. Although some studies have validated survey responses by comparing them with measurements taken during classroom observations (Mayer, 1999;Stipek & Byler, 2004), some measurement error and possibly recall bias may remain. 17 Measurement error, if random, would attenuate coefficients. Another possible explanation is that pedagogical activities as isolated and specific as those we measure may have a small effect on learning and that several \"best practices\" or artful combinations of them are needed to produce substantial learning gains. Finally, it may be the case that it is not so much what a teacher does but how she does it that matters in producing learning. Thus measures of frequency and not quality of teaching modalities do not capture all the essential components of pedagogy. In other words, the effect of an effective kindergarten teacher who completes math problems on a chalkboard might differ from that of an ineffective one who does the same thing. In this sense, it should be acknowledged that despite the steps we have taken to select an estimation strategy, an impediment to claiming that our results are causal remains. The remaining issue is that neither the OLS nor the HLM estimator deals with the possibility that omitted teacher effects, represented in (6) and 7by \u03c4 j are nonrandom. As we have mentioned, one concern might be that high quality teachers tend to use certain teaching techniques but that such techniques, if adopted less skilled teachers, would produce little effect. Or, it is possible the seeming ineffectiveness of particular techniques may be due to inadequate training in those methods. Thus there is a question whether the technique itself or the ability of teachers to properly use the technique matters. Our data follow a single cohort of students and do not provide the type of longitudinal information on their teachers that would permit us to control for time-constant teacher effects. We have no econometric technique at our disposition that allows us to eliminate unobserved teacher effects. We might argue, however, that the inclusion of the extensive set of teacher characteristics, content coverage variables, and school indicators, as well as our practices of interest, substantially narrows the range of what can be attributed to an unobserved teacher effect. Furthermore, in sensitivity analyses 18 in which teacher characteristics are omitted from the model, the practice estimates change very little, suggesting that their use is not driven by training or experience in ways that affect achievement."}, {"section_title": "Sensitivity of Findings to Other Specifications and Estimators", "text": "As mentioned in our review of the literature, prior survey-based studies have tended to use different models and estimators from those selected in our analysis. In order to demonstrate the importance of taking careful steps in selecting the methods used, Table 4 shows the sensitivity of findings to the choice of model and estimator. The table displays results for HLM estimation with random school effects on the kindergarten and first grade cross-sections in the first four columns-analytic approaches that have been more prevalent in the literature than our preferred approaches-and results for the child fixed effects estimator applied to the panel in the last column. The HLM estimation is carried out for both the lag score and the gain score model. Before discussing the differences between these approaches and our preferred approaches, it is interesting to note the differences between the lag and gain score models in the results displayed here in Table 4. Moving to a gain score model has little effect on the magnitude of the estimates for kindergarten but a noticeable effect on those for first grade. Recall that in these data, the coefficient on lambda was fairly close to one for kindergarten and much lower for first grade. In addition, our test of the \u03bb=1 assumption applied only to first grade. Thus it appears that using the gain score model in the ECLS-K data is relatively costless in kindergarten, but these results serve to support our claim that doing so in first grade introduces a noticeable amount of bias. Given this evidence, it seems all the more unlikely that the FE estimator in column five has much insight to offer, since it not only relies on a gain score model but also constrains the coefficients on teacher characteristics and practices to be the same across grades and relies on the strict exogeneity assumption. It is also interesting to note that the FE estimator, having removed a great deal of variation by time-demeaning the data, displays larger standard errors and thus finds no variable to be significant at the .05 level. For instance, the point estimate for the effect of having a teacher with regular certification is of similar or greater magnitude to the others; however the standard error is approximately twice as large. Differences in significance due to large changes in the point estimates (for example, see the coefficient on \"very experienced\"), on the other hand, may be due to bias-for example due to violations of strict exogeneity. Overall, the FE estimator, applied to these data and research questions, offers little in the way of policyrelevant information with regard to our research question. Moving now to a comparison of results from the HLM estimators containing random school effects (i.e., those commonly used in the literature) with those derived from our preferred estimators, shown in Table 3, we find a few similarities but some notable differences. With regard to teacher characteristics, the HLM results from Table 4 generally display coefficients with slightly lower magnitudes for certification and coursework in kindergarten and coefficients with more notably lower magnitudes for postgraduate study in first grade. With regard to instructional practices, the Table 4 HLM estimates diverge from those in Table 3 in several instances. In kindergarten, they show a significant negative effect of counting out loud, the use of geometric manipulatives, engaging in calendar-related activities, whereas these are not significant when school effects are treated as fixed. In addition, although both sets of results display significant coefficients for working with counting manipulatives and completing problems on the chalkboard, the magnitudes differ slightly. In first grade, the magnitude and significance of counting out loud, the use of calendars, and working on problems with several solutions differs across the two sets of results, and the magnitude of the most robust results-that of explaining how problems are solved-is somewhat understated. It is important to reiterate why we might see the differences outlined above. Differences in the conclusions based on different estimators can be driven either by differences in the point estimates or in the standard errors. Of the two HLM approaches, the school random effects specification tends to produce smaller standard errors due to the additional covariance structure imposed on the estimation. However, it is not the case that differences in the conclusions drawn between the two HLM estimators are purely due to smaller standard errors. Rather, it is typically the case that the magnitude of the point estimates changes enough to alter the significance level. Such differences in the point estimates likely occur because estimates with school random effects do not properly control for the sorting of students into different schools, whereas when the random school effects are replaced by fixed effects, this sorting is explicitly accounted for. 19 It is important to note that not only our preferred approaches but also our sensitivity analyses using HLM with random school effects produce some results that differ from the HLM studies in the prior literature and lead to different conclusions, particularly for first grade. This happens despite our attempts to mimic their methods in our sensitivity analyses. In these cases, specification and sample differences account for much of the divergence. It is difficult to compare our findings with those of the two kindergarten studies we cited (Guarino et al., 2006 andBodovski andFarkas, 2007), because the prior studies used instructional practice scales rather than individual practice variables. Both prior studies found that \"traditional approaches\" were positive and significantly related to achievement and thus conflated the effects of some of the variables we use (i.e., worksheets, textbooks, and chalkboard), one of which we find highly significant. However, our findings did not concur with other findings of theirs, such as the positive impact of student centered instruction in Guarino et al. (a scale composed of items such as explaining how mathematics problems are solved, playing games, and using music or creative movement), and interactive instruction in Bodovski and Farkas (a scale composed of items such as explaining how mathematics problems are solved, solving problems in small groups or with a partner, and peer tutoring). The differences between our results and those of Parlady and Rumberger's 2008 study of first grade are more stark and seemingly due to sample differences. The prior study used the 30 percent subsample of first graders who were sampled in the fall as well as the spring and did not impute missing data. Their findings that the use of math worksheets and calendars raise and the use of geometric manipulatives lower first grade achievement are not supported in our study based on the full sample, even when we employ methods that are similar to theirs."}, {"section_title": "Summary and Conclusions", "text": "Survey data on instructional practices, if well designed and carefully analyzed, have the potential to address questions regarding the means by which effective teachers can affect student success. Simple teacher performance studies based on administrative data can be useful in showing that quality matters but have access to very limited information on teachers and provide little insight regarding policy prescriptions needed to improve overall effectiveness. Surveys that use richly detailed survey data to focus on teachers' actions and how they affect student outcomes can hold the key to designing policy instruments, assuming the results they find are causal. A source of concern in non-experimental research on teacher effects, however, is the sensitivity of findings to different modeling and estimation techniques. This paper has outlined a process for selecting an appropriate model and estimation method to investigate teacher effects on student achievement using longitudinal survey data. We applied this process in a series of sequential steps to data from ECLS-K and found little evidence to support many of the modeling and estimation choices heavily relied upon in the literature-for example, models with gain scores or random school effects or models that constrain coefficients to be the same across grades. Our study clearly illustrates how methodological choices can influence results. Although a few of our findings concur with those in prior research, most diverge. Prior studies find little or no relationship between teacher background characteristics and mathematics achievement in either kindergarten or first grade, but we find evidence that teacher certification may slightly lower achievement in kindergarten and that postgraduate education may contribute to relatively substantial achievement gains in first grade. In addition, whereas prior studies claim that studentcentered or interactive pedagogy improves achievement in kindergarten and that worksheets and calendars are important tools in first grade, we find that working with counting manipulatives and completing math problems on the chalkboard improve achievement in kindergarten and that explaining how mathematics problems are solved is important in first grade. Taken as a whole, our findings suggest that there may be important developmental differences in the mathematics learning capabilities of children in kindergarten versus first grade and that training and pedagogy should be structured appropriately. Importantly, there is no finding that holds up under all the many specification and estimation approaches available to researchers-a circumstance that highlights the need to ground the selection of a model and estimation method on sound reasoning. Clearly, it is important that researchers justify their methodological choices through a thorough investigation of related assumptions and sensitivities. The guidelines for empirical investigation in the longitudinal survey data context provided in this study can aid researchers in selecting a credible set of results and advancing causal claims.   11,780 Source: ECLS-K; Standard errors clustered at the school level in parentheses; estimation with 40 imputed data sets *** p<0.01, ** p<0.05, * p<0.1 All specifications include class size, class racial percentages, teacher content practices, family welfare status, prior test score, time between exams, household size, number of siblings, level of parental involvement, how often the child reads, participation in extracurricular activities, number of children's books; indicators for completing the Spanish math exam, student disability, mother's education level, household income level, mother's employment status, single parent family, father absent, pay tuition, child's race, speak non 11,780 21,232 Source: ECLS-K; Standard errors clustered at the school level in parentheses; estimation with 40 imputed data sets *** p<0.01, ** p<0.05, * p<0.1 All specifications include class size, class racial percentages, teacher content practices, family welfare status, prior test score, time between exams, household size, number of siblings, level of parental involvement, how often the child reads, participation in extracurricular activities, number of children's books; indicators for completing the Spanish math exam, student disability, mother's education level, household income level, mother's employment status, single parent family, father absent, pay tuition, child's race, speak non-English in home, repeating kindergarten, attend full day kindergarten Specifications without school dummies also include school level variables: minority percentage, private religious, private non-religious, school enrollment, region, suburban, rural, gang problems, crime problems "}]