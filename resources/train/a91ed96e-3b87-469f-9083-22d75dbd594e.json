[{"section_title": "Abstract", "text": "Abstract. In this paper we propose a novel approach for incorporating measures of spatial uncertainty, which are derived from non-rigid registration, into spatially normalised statistics. Current approaches to spatially normalised statistical analysis use point-estimates of the registration parameters. This is limiting as the registration will rarely be completely accurate, and therefore data smoothing is often used to compensate for the uncertainty of the mapping. We derive localised measurements of spatial uncertainty from a probabilistic registration framework, which provides a principled approach to image smoothing. We evaluate our method using longitudinal deformation features from a set of MR brain images acquired from the Alzheimer's Disease Neuroimaging Initiative. These images are spatially normalised using our probabilistic registration algorithm. The spatially normalised longitudinal features are adaptively smoothed according to the registration uncertainty. The proposed adaptive smoothing shows improved classification results, (84% correct Alzheimer's Disease vs. controls), over either not smoothing (79.6%), or using a Gaussian filter with \u03c3 = 2mm (78.8%)."}, {"section_title": "Introduction", "text": "Alzheimer's disease (AD) is a progressive neurological disease, and the most common to be associated with the symptoms of dementia. The Alzheimer's Disease Neuroimaging Initiative (ADNI) [7] is a large multi-site study whose primary goal is to test whether serial magnetic resonance imaging (MRI) and other biological and imaging markers can be combined to measure the progression of mild cognitive impairment (MCI) and early AD. Determination of sensitive and specific markers of very early AD progression is intended to aid researchers and clinicians to develop new treatments and monitor their effectiveness, as well as lessen the time and cost of clinical trials. ADNI's initial goal was to recruit 800\nThis work was funded by the EPSRC through the LSI DTC adults, ages 55 to 90, to participate in the research, approximately 200 cognitively normal older subjects to be followed for 3 years, 400 people with MCI to be followed for 3 years and 200 people with early AD to be followed for 2 years.\nLongitudinal studies of this scale provide a platform to analyse the progression of the anatomical effects of neurodegenerative diseases. The use of imaging tools on longitudinal data allows quantification of the rate of brain atrophy, e.g. SIENA [11] . Feature maps can be derived from the deformation fields required to warp between follow-up images and baseline scans, providing high-resolution information illustrating the anatomical changes taking place over time [9] . The use of deformation derived features is known as tensor-based morphometry (TBM). A popular feature one can choose to use is the determinant of the Jacobian of the deformation fields, which is interpreted as the local expansion/contraction at a particular location and in the case of longitudinal brain imaging this would describe atrophy. Once these longitudinal features have been created, they need to be spatially normalised to enable comparison. This spatial normalisation is required to be sufficiently accurate to ensure robust inference. Accurate spatial normalisation can be provided using non-rigid registration methods [6] . A drawback in current approaches is that a point-estimate of the registration parameters is used, e.g. in [2] , which assumes that the mapping is exactly correct. This however, in the case of inter-subject brain registration, is highly unlikely. In a recent comparative study of volumetric brain registration algorithms, it was shown that no algorithm was capable of entirely correctly registering large labelled regions [5] . This situation can be improved upon by using a probabilistic registration method, which includes a level of uncertainty on the inferred transformation. The concept of spatial uncertainty in low-level vision has been previously explored [12] . More recently, probabilistic registration methods have been shown to produce a map of registration uncertainty in intra-subject brain registration following tumour resection [8] . However, although their registration model is capable of estimating the weighting between the similarity and regularisation terms, in this work they prefer to use an ad-hoc weighting of these factors. This is probably because their approach employs Markov chain Monte Carlo (MCMC) to infer the registration model parameters, which is particularly computationally expensive. The significance of this weighting is that it will influences both the registration result, and the distribution of the spatial uncertainty.\nIn this work we propose the use of a generic and adaptive approach for probabilistic non-rigid registration to provide a more principled estimate of the spatial uncertainty of a transformation. Based on these estimates, local Gaussian smoothing kernels can be automatically estimated and used to smooth image features over the set of probable locations, rather than just the most likely. This approach is demonstrated using longitudinal data from the ADNI dataset, where Jacobian maps are used as image features. These are spatially normalised using a principled probabilistic approach. This transformed data is adaptively smoothed based on the registration derived uncertainty. Our adaptive approach to image smoothing is compared, and performs favourably to an ad-hoc Gaussian smoothing, or no image smoothing for multi-variate disease state classification."}, {"section_title": "Methods", "text": "Image registration can be described probabilistically using a generative model, where it is assumed that the target image data Y can be generated from a source image X, which is deformed by a transformation, where T(X,w) is the transformed source image, and w parametrises the transformation. The specific form of T used in this implementation is a Free-Form Deformation (FFD) model, where w is the set of control point displacements in each direction.\nAs the model will have residual error throughout the registration process, this error estimate needs to be included. The noise is assumed to have zero mean and be independent and identically distributed (i.i.d.) across image voxels. In this case, the noise is assumed to be normally distributed e \u2248 N (0, \u03c6 \u22121 I), where I represents the matrix identity. The noise distribution is assumed to have global precision (inverse variance) across the image, \u03c6. The generic generative model for registration is therefore given as Y = T(X, w) + e. Using a normally distributed noise model, as we use here, is equivalent to using the sum of squared differences (SSD) as the image similarity term."}, {"section_title": "Priors", "text": "In a probabilistic model for registration, regularisation can be incorporated as a prior on the transformation parameters, which is modelled using a Multivariate Normal Distribution (MVN). The prior on w is described in eq. 1 where \u039b encodes the regularisation as a spatial kernel matrix providing bending energy regularisation. \u03bb is the spatial precision parameter, controlling the level of spatial regularisation. \u03bb is modelled as an unknown parameter, and determined adaptively from the data resulting in an automated approach to regularisation. Where \u03bb is constant, this method of regularisation is seen in other probabilistic approaches to registration [2] . In a related approach in groupwise registration, the covariance matrix of the deformations used to warp a template to a set of observed images is calculated from the data [1] . This provides an alternative principled approach to inferring the covariance between deformation parameters, however the model inference is computationally infeasible on full 3D volumes.\nNon-informative priors on the spatial precision (eq. 2) and noise precision (eq. 3) are specified using Gamma (Ga) distributions, where the subscript 0 denotes initial parameter estimates. We use wide priors over \u03bb and \u03c6 with initial hyperparameter for scale s s 0 = 10 10 , a 0 = 10 10 and shape c 0 = 10 \u221210 , b 0 = 10 \u221210 ."}, {"section_title": "Model Inference", "text": "The model parameters are inferred upon using Variational Bayes [3] which uses an objective function of the Variational Free Energy (VFE). The VFE mea-sures model fit and complexity. Model fit can be approximately considered to be minimising the sum of squared difference, and model complexity as the level of bending energy of the transformation. Using the VB framework, analytic updates are derived for the approximate posterior distributions of the transformation, regularisation and noise parameters, which maximise the VFE. VB uses the mean-field approximation, hence the posterior parameter distribution p(w, \u03bb, \u03c6|Y) is approximated as q(w)q(\u03bb)q(\u03c6). The functional forms of the approximate posterior distributions are constrained to be conjugate to the priors, and are given as: q(w) = M V N (w; \u00b5, \u03a5 ), q(\u03bb) = Ga(\u03bb; s, c) and q(\u03c6) = Ga(\u03c6, a, b) . The hyper-parameter updates (eqs. 4-9) are derived by integrating out the factorised parameters from the log posterior model distribution.\n1\nHere, J is the matrix of first order partial derivatives of the transformation parameters with respect to the transformed image T(X, \u00b5 old ), centred about the previous estimate of the mean \u00b5 old . k is the vector representing the residual image Y\u2212T(X, w). \u00b5 new describes the current estimated transformation parameters, and is dependent on the old estimated values. The approximate posterior covariance matrix of the set of transformation parameters is given by \u03a5 .\u03bb is the expectation of the posterior spatial precision distribution and\u03c6 is the expectation of the estimated noise precision. N c is the number of active control points in the model and N v is the number of active voxels, \u03b1 is the virtual decimation factor which accounts for the correlation in the image noise [4] ."}, {"section_title": "Spatial Uncertainty", "text": "The probabilistic registration method intrinsically provides a measurement of uncertainty on the posterior distribution of the model parameters. This is particularly interesting for the transformation parameters, given by \u03a5 , which has units of mm 2 . The uncertainty of w represents how certain we are that a given point in the source image should be transformed to a particular point in the target image. By accurately estimating \u03a5 , and interpolating the variance and cross-directional covariance across the image, a multivariate normal distribution illustrating the spatial uncertainty can be calculated at each voxel. The spatial uncertainty of a particular control point is governed by 5 factors: -The local image information which is affected by this control point's movement (J T J). -The noise precision: how much the image data is trusted, related to SSD. -The spatial precision: how similar the transformation is to the spatial prior. -The form of the spatial prior, e.g. bending energy, membrane energy.\n-The uncertainty of neighbouring control points.\nThis distribution provides both the magnitude and direction of the uncertainty at a given point. As the uncertainty is dependent on the image information, it is lower across an image boundary than along it. This results in an anisotropic measure of spatial uncertainty, which varies across the image. The scale of uncertainty will also vary across individual registrations. A straightforward approach to compensate for the spatial uncertainty in the mapping of any given voxel is to smooth the data according to the local uncertainty distribution, which is an anisotropic Gaussian kernel. Where the uncertainty of the mapping is high, smoothing the data compensates for this, but still retains potentially discriminating information. We propose this novel method to help reduce the inter-subject variability due to mis-registration of spatially normalised image data."}, {"section_title": "Materials", "text": "Data was provided from the Alzheimer's Disease Neuroimaging Initiative (ADNI) [7] , a large multi-side longitudinal study containing MR imaging data. For this study 125 random control subjects, and AD patients, of both sexes and a range of ages AD (mean age 76.6 std.dev 7.67, 67M, 58F ) and Normal controls (mean age 78.6 std.dev 5.61, 66 M, 59F) were drawn from the database. Pre-processed images which have been corrected for geometric distortions, bias fields and geometric scaling are present on the ADNI website, and were used in this work. Subjects were chosen with at least 2 scans with a minimum interval of 1 year."}, {"section_title": "Experiments", "text": "Tools from the publicly available open-source software library, FSL 4 were used to pre-process the images. To correct for difference in size and location, each of the scans was registered to the MNI 152 template using 9 degrees of freedom. Each scan was also re-sampled to have 1mm isotropic voxels and was processed to remove non-brain tissue. An initial atlas was created by averaging 40 healthy individual control scans after initial affine alignment to the MNI152 template. To create a sharper atlas, each of these scans was then non-rigidly registered to the affine atlas using the probabilistic registration tool with a 5mm knot spacing.\nThe most recent follow-up scan was registered to the baseline scan of each individual using the probabilistic registration tool with a 5mm knot spacing, which yielded individual maps of local atrophy. As the interval between scans varied across subjects, the Jacobian values were linearly scaled to a single year.\nThe probabilistic non-rigid registration algorithm was used to provide accurate spatial normalisation, which allows measurement of spatial uncertainty. Each baseline scan was registered to the atlas, an example is given in figure 2 . Each registration result yields a map of the variance and cross-directional covariance of the transformation parameters. An illustration of the uncertainty in the mapping between an AD subject to the atlas is given in figure 1 . Each individual subject's longitudinal Jacobian map was transformed to the atlas space. It is then adaptively smoothed using a unique 3-D Gaussian kernel for each spatial location derived from the uncertainty of the registration from the baseline to atlas space. As control experiments, we compare this strategy against not smoothing the images, and Gaussian smoothing with \u03c3 = 2mm."}, {"section_title": "Results", "text": "Data decomposition and feature selection was required to provide computationally tractable classification on the 250 spatially normalised and smoothed Jacobian maps, each of which had 2068979 voxels within the anatomical mask. The concatenated data was processed using a principal component analysis (PCA) algorithm to reduce the data dimensionality. The feature maps were masked prior to the PCA using a voxelwise t-test between the two populations with a threshold of p < 0.05 uncorrected. The percentage of voxels within the anatomical atlas region included in the mask was 26.82% for the unsmoothed data, 31.91% for the Gaussian smoothed data and 29.74% for the proposed method. Thresholded z-stat maps of the 3 smoothing methods are presented in figure 3 . The lowest"}, {"section_title": "Registration derived smoothing", "text": "Gaussian smoothing \u03c3 = 2mm\nNo smoothing 30 100 Fig. 3 . Z-stat maps showing the results from an uncorrected, two-tail t-test on the spatially normalised Jacobian maps between AD patients and control subjects. The registration derived smoothing does not blur the boundaries between the ventricles, unlike Gaussian smoothing, and it increases the signal to noise over no smoothing.\nuncorrected p-value observed for the individual methods is 6.8736 \u00d7 10 \u221220 with no smoothing, 1.1289 \u00d7 10 \u221220 for Gaussian smoothing and 1.5601 \u00d7 10 \u221221 when using the proposed adaptive smoothing. In each case the most significant voxel was located in the left hippocampus which is consistent with previous work [6] .\nThe components which explained 99.0% of the sample variance were used to project the data. The projected data were classified using a support vector machine with a radial basis function kernel using \u03c3 RBF = 2. A leave-two-out methodology was used, where an instance of each class was used for testing at each iteration, while the rest of the data were used for training. The average classification results are given in table 1 and show an improvement in the correct classification rate when using the proposed approach. "}, {"section_title": "Conclusions and Future Work", "text": "Adaptive smoothing of spatially normalised image feature data, based on registration derived uncertainty, has been demonstrated to provide an increase in the ability to classify between patients with Alzheimer's Disease and normal controls using longitudinal Jacobian maps as features. Although the uncertainty measurements we derive from the image registration process are only a surrogate indication of the true anatomical uncertainty, we have shown that they still provide useful information for reducing the inter-subject variability due to mis-registration. As the methods presented here are generic, they could be employed in alternative applications, including probabilistic segmentation propagation [10] . Future work includes a more rigorous experimental design and including MCI subjects. Additionally, we will consider the use of the independent uncertainty distribution for each FFD control point, as opposed to the unfactorised estimates used in this work. This may provide more accurate estimates of the spatial uncertainty for use as a smoothing kernel."}]