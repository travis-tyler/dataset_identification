[{"section_title": "Abstract", "text": "Abstract. Segmentation of structural and diffusion MRI (sMRI/dMRI) is usually performed independently in neuroimaging pipelines. However, some brain structures (e.g., globus pallidus, thalamus and its nuclei) can be extracted more accurately by fusing the two modalities. Following the framework of Bayesian segmentation with probabilistic atlases and unsupervised appearance modeling, we present here a novel algorithm to jointly segment multi-modal sMRI/dMRI data. We propose a hierarchical likelihood term for the dMRI defined on the unit ball, which combines the Beta and Dimroth-Scheidegger-Watson distributions to model the data at each voxel. This term is integrated with a mixture of Gaussians for the sMRI data, such that the resulting joint unsupervised likelihood enables the analysis of multi-modal scans acquired with any type of MRI contrast, b-values, or number of directions, which enables wide applicability. We also propose an inference algorithm to estimate the maximuma-posteriori model parameters from input images, and to compute the most likely segmentation. Using a recently published atlas derived from histology, we apply our method to thalamic nuclei segmentation on two datasets: HCP (state of the art) and ADNI (legacy) -producing lower sample sizes than Bayesian segmentation with sMRI alone."}, {"section_title": "Introduction", "text": "Automated segmentation of MRI scans is a prerequisite for most human neuroimaging studies. Most of the algorithms commonly used for this task rely solely on structural MRI (sMRI) scans, and belong to one of three categories: Bayesian segmentation with a probabilistic atlas (e.g., [1, 2] ); multi-atlas segmentation [3] ; and, more recently, convolutional neural networks (e.g., [4] ). Typically, these techniques segment the brain into tissue types (i.e., gray matter, white matter, and cerebrospinal fluid), or into finer anatomical structures (e.g., hippocampus, ventricle). Bayesian methods drive the primary segmentation modules of the most widespread neuroimaging packages, like FreeSurfer [2] , FSL [5] , or SPM [1] .\nThe aforementioned approaches rely mostly on T1 contrast to distinguish between gray and white matter. However, some boundaries between structures are nearly invisible in T1 (and other structural MR contrasts) due to insufficient difference in proton density and relaxation times. This is exacerbated by lower contrast-to-noise ratio in deep-brain structures, due to greater distance from the head coil. Two examples from the state-of-the-art Human Connectome Project (HCP) dataset [6] are shown in Fig. 1 . In the first example, the lateral boundary of the thalamus appears very faint (Fig. 1a) . In the second, the lateral boundary of the globus pallidus is visible thanks to the contrast with the neighboring putamen, but the medial boundary is not (Fig. 1c) .\nThese issues create a need for fusing data from several MR modalities to better delineate structure boundaries. A natural complement to sMRI is diffusion MRI (dMRI), which may help discriminate between certain tissue types, despite its lower resolution. For example, in Fig. 1b , the lateral boundary of the thalamus is clearly discernible in the principal diffusion direction map obtained from dMRI. The diffusion data also complement the T1 scan in the pallidum, which can be delineated by combining contours obtained from the two modalities (medial from dMRI, lateral from sMRI, see Fig. 1d ).\nMost prior work on segmentation of dMRI focuses on delineating white matter structures, using tractography [7, 8, 9] or volumetric segmentation [10, 11] . Tractography has also been used to subdivide subcortical structures (e.g., thalamus [12] , amygdala [13] ) based on long-range connections. Surprisingly, the literature on joint modeling of multimodal sMRI/dMRI is sparse. When sMRI and dMRI are used by the same tool, this is most often done serially, e.g., a segmentation derived from sMRI is used to analyze the dMRI (e.g., to derive priors for Bayesian tractography [9] ). To the best of our knowledge, the only works analyzing sMRI and dMRI simultaneously have been on thalamic nuclei segmentation with random forests [14, 15] . The main concern with such discriminative techniques is their generalization ability to other datasets, which is limited by differences in MRI acquisition. For sMRI segmentation, this problem can be ameliorated with data augmentation and pretraining [4] . However, this is harder to do in dMRI, where acquisition protocols are much less standardized.\nThe ability to generalize across datasets is critical when software is released publicly and few assumptions can be made on the acquisition. In such scenarios, Bayesian segmentation methods that automatically estimate appearance models from input images remain very popular, as they are agnostic to the MRI contrast of the input scan, and thus robust to acquisition differences. These methods are used for tissue segmentation by major neuroimaging packages (e.g., Unified Segmentation [1] in SPM, and FAST [16] in FSL). However, they can be inaccurate when segmenting structures with poor sMRI contrast (see Fig. 1 ).\nHere we propose a sequence-adaptive Bayesian algorithm that uses a probabilistic atlas to segment sMRI and dMRI data simultaneously 5 . This is achieved via a novel dMRI likelihood term, which relies on a hierarchical model for the fractional anisogropy (FA) and principal diffusion orientation. Combined with a Gaussian likelihood for sMRI, this model of image intensities is flexible enough to produce accurate segmentations, while keeping dimensionality low. We also propose a novel inference algorithm to automatically segment scans by fitting the model to multi-modal sMRI/dMRI data. Thanks to unsupervised intensity modeling, applicability across a wide range of acquisition protocols is achieved, which is demonstrated experimentally on two considerably different datasets."}, {"section_title": "Methods", "text": ""}, {"section_title": "Forward probabilistic model", "text": "The graphical model of our framework is shown in Fig. 2a . The observed variables are a bias field corrected (possibly multispectral) sMRI scan S = [s 1 , . . . ,\ndefined at the same voxel coordinates (which might require resampling), and a probabilistic atlas A, which provides the probabilities of observing one of C neuroanatomical classes at every location across a reference spatial coordinate system. The model is governed by three sets of deterministic hyperparameters specified by the user: \u03b3 a , \u03b3 s and \u03b3 d . At the top of the generative model we find the atlas A, along with a set of related parameters \u03b8 a that deform this atlas into the space of the MRI data. These parameters are a sample of a distribution that regularizes the deformation field by penalizing, e.g., its bending energy. The strength of the regularization is controlled by the set of hyperparameterst \u03b3 a . Given the deformed atlas, a labeling (segmentation) L = [l 1 , . . . , l V ], with l v \u2208 {1, . . . , C}, is obtained by independently sampling the categorical distribution defined by the deformed atlas at each voxel location. Given L, the observed sMRI and dMRI data are assumed to be conditionally independent from each other and across voxels. The sMRI data s v at v follows a distribution (typically a Gaussian) whose parameters \u03b8 s c depend on the corresponding label c = l v . Any prior knowledge on these parameters is encoded in their priors, which are governed by hyperparameter vectors {\u03b3 s c }. Similarly, d v is also assumed to be (Fig. 2a) . The joint probability density function (PDF) of the model is therefore:\nwhere"}, {"section_title": "Model instantiation", "text": "Probabilistic atlas: We follow the framework of the thalamic atlas [17] that we use in the experiments in Section 3, in which the atlas is encoded as a tetrahedral mesh. Deforming the mesh is penalized by a regularizer R, weighted by the mesh stiffness \u03bb. The prior is given by (see further details in [18] ):\nwhere\nt is simply the vector of C label probabilities provided by the atlas at voxel v when deformed with parameters \u03b8 a ; Cat[\u00b7] is the categorical distribution; and hyperparameters \u03b3 a comprise just \u03bb, i.e., \u03b3 a = {\u03bb}."}, {"section_title": "Likelihood of sMRI:", "text": "In order to model the sMRI intensities given the segmentation L, we follow the Bayesian brain MR segmentation literature (e.g., [1, 16, 17] ) and use Gaussian intensity distributions, such that \u03b8 s c = {\u00b5 c , \u03a3 c }, i.e., the mean and covariance of the intensities of class c. We place a Normal Inverse Wishart (NIW) distribution on these parameters (i.e., the conjugate prior), with zero degrees of freedom for the covariance, as we found it difficult in practice to inform such parameter a priori. Therefore, we have: \u03b3 s c = {M c , n c }, where M c is the hypermean and n c is the scale. The sMRI likelihood is thus:\nwhere N (\u00b7, \u00b7) is the Gaussian distribution and I is the identity matrix."}, {"section_title": "Likelihood of dMRI:", "text": "We have two requirements for the likelihood function of the dMRI: low demands on gradient directions and b-values to accommodate legacy data; and low number of parameters to facilitate unsupervised clustering (yet sufficient to separate the classes). To satisfy the first requirement, we adopt the diffusion tensor imaging (DTI) model, which can be fit from virtually all available dMRI data. Rather than modeling the tensors directly (e.g., with a Wishart distribution, which we found in pilot experiments to fade too quickly from its mode), we use a hierarchical model (Fig. 2b ) that only considers the FA f v and the principal eigenvector \u03c6 v at each voxel, i.e.,\nAt the first level, we model the FA conditioned on the class, with Beta distributions parameterized by {\u03b1 c , \u03b2 c }. We chose the Beta because it can model location and dispersion of signals defined on the [0,1] interval with two parameters. At the second level, we model the principal eigenvector with the DimrothScheidegger-Watson (DSW) distribution, which is axial (i.e., antipodally symmetric), accommodating the directional invariance of dMRI [19] . This distribution is also rotationally symmetric around a mean direction \u03c8 and its opposite \u2212\u03c8 ( \u03c8 = 1), with a dispersion around the mean parameterized by a concentration \u03ba. It has fewer parameters than other axial distributions, such as the (non rotationally symmetric) Bingham. Its PDF is given by [20] :\nwith domain \u03c6 = 1, and where the partition function is the Kummer function in 3D [20] : Z\u03ba = 1 0 exp(\u03bat 2 )dt. We further assume that the concentration is modulated (multiplied) by the FA. This is a simple yet effective way of modeling the higher directional dispersion in voxels with low FA (e.g., in areas of unrestricted diffusion or fiber crossings), without having to resort to mixtures or additional parameters. The overall model for the dMRI likelihood is thus:\nand the set of parameters is thus:"}, {"section_title": "Segmentation as Bayesian inference", "text": "Within our joint generative model of sMRI and dMRI, we pose segmentation as an optimization problem, seeking to maximize the posterior probability of the labeling, given the known hyperparameters and observed input data:\nwhere we have made the standard approximation that the posterior distribution of the parameters is heavily peaked around point estimates\u03b8 a ,\u03b8 s ,\u03b8 d given by:\nTherefore, we segment a scan by first estimating the parameters with Eq. 7, and then obtaining the (approximate) most likely labeling with Eq. 6. Applying Bayes rule to Eq. 7, marginalizing over the hidden segmentation L, and considering the structure of the model and our design choices, we obtain:\nExpanding and taking logarithm, we obtain the following objective function:\nWe maximize Eq. 8 with a Generalized Expectation Maximization (GEM) algorithm [21] , iterating between expectation (E) and maximization (M) steps:\nIn the E step, we use Jensen's inequality to build a lower bound for the objective function, which touches it at the current value of the parameters:\nwhere {w vc } a soft segmentation according to the current parameter estimates:\n, and\nwhere B is the Beta function.\nM step: In the generalized M step, we seek to improve the lower bound Q in Eq. 9. While optimizing the bound with respect to all parameters simultaneously is difficult, optimizing different subsets each time (coordinate ascent) is feasible. Optimizing \u03b8 a : Fixing all other parameters and switching signs, we obtain:\nThis is a registration problem combining the regularizer R with a data term: the Kullback-Leibler (KL) divergence between the deformed atlas and the current soft segmentation. We solve it numerically with the conjugate gradient method.\nOptimizing {\u00b5 c , \u03a3 c }: Setting derivatives to zero yields a closed-form solution:\nOptimizing {\u03b1 c , \u03b2 c }: Substituting the expression of the Beta distribution into Eq. 9, the problem decouples across classes:\n(14) This is a simple 2D optimization problem, which we solve with conjugate gradient. In the first iteration, we use the method of moments for initialization. Optimizing {\u03c8 c }: This optimization can also be carried out one c at the time: \nwhich we solve with conjugate gradient, initializing \u03ba c = 10 in the first iteration.\nFinal Segmentation: It is straightforward to show that the approximate posterior probability of the segmentation from Eq. 6 factorizes across voxels and is given by p(L|\u03b8\nv,lj , where\u0175 v,lj is obtained by evaluating Eq. 10 at the optimal parameter values\u03b8 a ,\u03b8 s ,\u03b8 d . Therefore, the optimal segmentation can be computed independently at each location v as:\nand the expected value of the volume of class c is given by:\nV v=1\u0175 vc (in voxels). Implementation details: Since GEM only requires improving the bound at each iteration, we follow a schedule in which all the model parameters except for \u03b8 a are updated once in the M step. Since updating \u03b8 a requires solving a more computationally expensive registration problem, we only update \u03b8 a in the M step every five GEM iterations. The method is summarized in Algorithm 1."}, {"section_title": "Algorithm 1 Bayesian segmentation with sMRI and dMRI", "text": "In practice, we also force some parameters {\u03b8 s c } and {\u03b8 d c } to be shared across classes, for increased robustness of the algorithm. For the sMRI parameters ({\u00b5 c , \u03c3 2 c }), we follow [17] and force parameter sharing across: cortex, hippocampus and amygdala; reticular nucleus and white matter; mediodorsal and pulvinar nuclei; rest of thalamic nuclei; and contralateral structures. For the FA, parameters {\u03b1 c , \u03b2 c } are shared across each of the six groups of thalamic nuclei in Table 2 of [17] , and across contralateral structures. The same grouping -but without contralateral constraints -is used for the directional parameters {\u03c8 c , \u03ba c }."}, {"section_title": "Experiments and results", "text": ""}, {"section_title": "Data", "text": "We evaluate our method with a recent probabilistic atlas of 25 thalamic nuclei and surrounding regions derived from histology [17] . The thalamus is an excellent target region, due to its faint lateral boundaries in sMRI (as explained in Section 1), and its set of nuclei with different connectivity. We use two considerably different datasets in evaluation: HCP (state of the art) and ADNI (legacy).\nHCP: Isotropic T1 and dMRI scans from 100 healthy subjects (age 29.1\u00b13.3, 44 males), at 0.7 mm (T1) and 1.25 mm resolution (dMRI). We fit the DTI model to the b=1000 s/mm 2 shell (180 directions) and 12 scans with b=0 (details in [22] ).\nADNI: T1 and dMRI scans from 77 subjects from ADNI2: 39 Alzheimer's disease (AD) and 38 age-matched controls (74.1\u00b18.1 years; 40 females total). T1 resolution: 1.2\u00d71\u00d71 mm (sagittal); dMRI resolution:1.35\u00d71.35\u00d72.7 mm (axial); 5 volumes with b=0, 41 directions (b=1000 s/mm 2 ; details at adni-info.org)."}, {"section_title": "Experimental setup", "text": "We evaluate three competing methods: (i) Segmentation of the whole thalamus with FreeSurfer [2] ; (ii) Segmentation of thalamic nuclei using Bayesian segmentation on T1 only [17] ; and (iii) Segmentation of thalamic nuclei with the full model, including dMRI. We compare these approaches in three experiments: (i) Qualitative assessment of segmentation and tractography in HCP; (ii) Correlation between thalamic and total intracranial volume (ICV) in HCP; and (iii) Ability to discriminate AD and control subjects based on volumes in ADNI.\nThe sMRI and dMRI data are resampled to 0.5 mm isotropic in a bounding box around the thalami (DTI is interpolated in a log-euclidean framework [23] ). We set \u03bb = 0.05 as in [17] , M c to the median T1 intensity in class c according to the main FreeSurfer segmentation, and n c to the volume of the class in mm 3 . Figure 3 shows qualitative results on an HCP subject. FreeSurfer almost completely misses the left pallidum (yellow arrow in the figure) and oversegments the thalami. We test the effects of the latter on tractography by reconstructing the full dMRI data with generalized q-sampling [24] , performing whole-brain tractography, and isolating the tracts that intersect the whole thalami, as automatically segmented by the three competing methods. The FreeSurfer thalamus yields many false positive tracts, mostly due to overlap with the internal capsule (red arrow). Aggregating the nuclei produced by Bayesian segmentation on the T1 produces a more accurate boundary, but still oversegments the anterior thalamus (white arrow), and undersegments the pulvinar nucleus (black arrow). Our multi-modal method yields less false positive tracts, and segments thalamic nuclei that are more homogeneous in terms of diffusion orientation and FA. We also evaluate segmentation performance quantitatively on HCP, in an indirect fashion, by computing the correlation of total thalamic volume obtained by each method (left-right averaged) with the ICV estimated by FreeSurfer; noisy thalamic segmentations are expected to degrade this correlation. Scatter plots and regression lines are shown in Fig. 4 . The FreeSurfer volumes are quite large on average, and their correlation with ICV is \u03c1=0.71. Bayesian segmentation with T1 yields \u03c1=0.68 (not significantly different, with p=0.37 on a two-tailed Steiger test). The proposed algorithm produces fewer outliers than the other two, and yields the highest correlation (\u03c1=0.81), significantly higher than those of FreeSurfer (p=0.006) and T1-only segmentation (p=0.001). Finally, we evaluate the ability of the segmented volumes to classify the ADNI subjects into AD and controls. We use a simple linear discriminant analysis, whose performance is mostly determined by the quality of the volumes. We project the volumes (left-right averaged, corrected for ICV and age) onto the normal to the discriminant hyperplane in a leave-one-out fashion. We use the projections to compute the area under the ROC curve (AUC), accuracy at its elbow, and sample sizes (\u03b1 = 0.05, \u03b2 = 0.2). Results are shown in Table 1 . Our method yields a fair improvement compared with T1-only Bayesian segmentation (increase of 7 points in accuracy and AUC, and reduction of 6 samples). Compared with FreeSurfer, our algorithm reduces the sample size by 60%. "}, {"section_title": "Results", "text": ""}, {"section_title": "Conclusion", "text": "We have presented a Bayesian method for joint segmentation of sMRI and dMRI, which is robust to changes in acquisition platform and protocol -as shown with two substantially different datasets. Compared with Bayesian segmentation using sMRI alone, our method produces more accurate boundaries for subcortical structures, and yields smaller sample sizes in an AD classification task. Future work at the methodological level will follow five main directions: (i) Modeling partial voluming in the dMRI, which may be important for smaller structures; (ii) Exploring other axial PDFs, as well as mixtures; (iii) Placing a prior on the dMRI likelihood parameters, e.g., to utilize prior knowledge on the FA; (iv) Modeling the bias field in the sMRI data, e.g., as in [1] ; and (v) Adding connectivity derived from tractography to the dMRI likelihood, which may be challenging because tractography results depend largely on the MR acquisition.\nWe also plan to manually trace structures some of the HCP and AD data, with three purposes. First, to include white matter bundles in the atlas, as modeling the whole cerebral white matter with a single Beta-DSW is not realistic (not even within a bounding box). Second, to enable direct evaluation of our segmentations. And third, to help us explain discrepancies in AD classification accuracy between our results and those presented in [17] , which may be due to the their larger dataset, their different ADNI sample, or some other factor.\nAs high-resolution dMRI becomes more common in neuroimaging, we believe that segmentation techniques that jointly model gray and white matter with sMRI and dMRI -like the one in this paper -will become increasingly important."}]