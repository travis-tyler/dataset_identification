[{"section_title": "Abstract", "text": "Computational models that forecast the progression of Alzheimer's disease at the patient level are extremely useful tools for identifying high risk cohorts for early intervention and treatment planning. The state-of-the-art work in this area proposes models that forecast by using latent representations extracted from the longitudinal data across multiple modalities, including volumetric information extracted from medical scans and demographic info. These models incorporate the time horizon, which is the amount of time between the last recorded visit and the future visit, by directly concatenating a representation of it to the data latent representation. In this paper, we present a model which generates a sequence of latent representations of the patient status across the time horizon, providing more informative modeling of the temporal relationships between the patient's history and future visits. Our proposed model outperforms the baseline in terms of forecasting accuracy and F1 score with the added benefit of robustly handling mis sing visits."}, {"section_title": "Introduction", "text": "Longitudinal medical datasets commonly contain biomarker information and medical scans spanning multiple years for thousands of patients. Recently, there has been an increased interest in building deep learning models, which have the benefit of being able to extract relevant features from datasets without expert knowledge, to forecast a patient's disease progression. If effective, such models have the potential to become extremely useful tools for identifying high risk cohorts for early intervention and treatment planning.\nClinical Relevance With the increase in the world's aging population, dementia is a critical threat to health around the world. Currently, it is estimated that 24 million people world wide suffer from the condition and this number is projected to double every 20 years Reitz et al. (2011) . Alzheimer's disease is one of the most prevalent forms of dementia. Diagnosis of Alzheimer's takes into account many factors such as performance on cognitive screens, inheritance of high-risk biomarkers, and assessment of MRI scans Neugroschl and Wang (2011) . Deep learning models that can leverage signals from these varying factors in order to accurately forecast the progression of the disease would greatly benefit doctors in identifying patients that are at a high risk of developing Alzheimer's.\nTechnical Significance A wide range of models using deep learning to forecast longitudinal signals have been proposed in the literature. These approaches can be generalized as follows: they project the inputs collected from patient history into a common space using some fully-connected layers and then send the projected representations to a sequence learning model such as an RNN to combine these representations into a single latent representation. The time horizon \u03c4 , which is the interval between the last observed status and the predicted status, is concatenated to this latent representation and sent to a classifier which assigns a disease stage label to the patient, \u03c4 time steps into the future.\nThese techniques do not take advantage of a temporal structure of a patient's historical information. By simply concatenating \u03c4 to the output of the RNN, the models are not taking temporal information into account when forecasting the visit that occurs \u03c4 time steps into the future. In this case, \u03c4 is an additive term which signals the magnitude of the time horizon to the classifier without much of an effect on the overall prediction. Thus, the resulting model is partially agnostic with respect to the temporal correlations that occur across the time horizon. Additionally, with these methods, the irregular time intervals between consecutive visits are not incorporated into the model at any stage in the training process, resulting in models which operate under the assumption that the visits in all sequences are spaced uniformly in time.\nTo address these problems, we propose FLARe: Forecasting by Learning Anticipated Representations, a generative model which naturally incorporates \u03c4 into the prediction pipeline with the ability to \"impute\" representations of missing visits. FLARe draws inspiration from language modeling (LM), which is one of the most widely researched areas in natural language processing. One of the key challenges in LM is to come up with models that can generate sentences or paragraphs of any language. This is typically done by training a model to sequentially generate the next word, given a history of generated words. Such models are trained by optimizing the loss obtained by aggregating the difference between the predicted next word and the actual next word in each sentence in the training data. This approach operates under the assumption the fact that every language has constraints on the ordering of words in a sentence. Rhe model tries to learn what the most probable words are, given the present word, or the history of words.\nIn FLARe, we follow a similar intuition by operating under the assumption that there are constraints on how much the 3D MRI scans and cognitive tests of a given patient can vary within 1 time point -which corresponds to 6 months. It follows from these assumptions that we should be able to train a model that can sequentially predict the feature vector of the patient in the next time step, given his/her feature vector in the present time step as well as the complete history until that point. Furthermore, we can do this by minimizing the loss obtained by aggregating the differences in the predicted and actual values of the next feature vector. As a byproduct of this sequence generation approach, our proposed model can also robustly handle patient trajectories which contain missing visits by 'imputing' their learned representations. All of these factors together give FLARe a heightened ability to model the temporal relationship between a patient's medical history and their future health status, resulting in better disease stage forecasting accuracy.\nWe tested our proposed model on the data of 1652 patients from the publicly available ADNI (Alzheimer's Disease Neuroimaging Initiative) dataset using volumetric information extracted from MRI scans along with demographic information and cognitive test scores as input features. Our results show that our proposed model outperforms baseline models in terms of forecasting performance, while providing more balanced predictions across disease classes. We provide detailed analysis of the performance of our model over different time horizons \u03c4 and time steps T used for forecasting."}, {"section_title": "Related Work", "text": "Disease progression modeling has been an important topic in the field of healthcare analytics. Existing work in this area has been applied towards the development of pharmaceuticals and early prevention and treatment planning. For example, Ito et al. (2010) develop a progression model based on data from literature in order to measure longitudinal changes in cognitive test scores of Alzheimer's patients. De Winter et al. (2006) propose a progression model for Type 2 Diabetes that aims to identify the effects of various treatments on diabetes-related biomarkers. However, these models are traditionally created using domain expert knowledge and are thus limited to their original use cases.\nRecently, there has been increased interest in disease progression modeling in the machine learning community. Such approaches attempt to model the trajectory of the disease using statistical and machine learning techniques on observational data acquired from medical records. A variety of methods have been deployed for the task including Markov Jump Models [Wang et al. (2014) ], Gaussian Processes [Schulam and Arora (2016) ], and Functional Clustering [Yao et al. (2005) ], [Halilaj et al. (2018) ]. Some approaches such as Sukkar et al. (2012) and use models to identify more fine grained trajectory types outside of the standard clinical stages and explore the correlations between multiple longitudinally collected measurements. Zhou et al. (2012) approach the problem by treating it as a multi-task regression, where the objective is to jointly model the trajectory of multiple longitudinal measurements and biomarkers.\nEven more recently, deep learning approaches to the problem have experienced increasing popularity due to their ability to learn features from the dataset without the need for domain knowledge. Fiterau et al. (2017) use hybrid CNN and LSTM layers which leverage information from structured covariates to predict the cartilage degeneration of patients with osteoarthritis, six years into the future. Bhagwat et al. (2018) use a Siamese network to learn a difference representation between two visits in a patient's history in order to classify the patient's trajectory into hierarchically clustered classes. Choi et al. (2016) and Lim and van der Schaar (2018) treat the disease progression as a slowly evolving point process and use temporal deep learning models such as RNNs to jointly model event occurrences and doctor diagnosis."}, {"section_title": "Methodology", "text": ""}, {"section_title": "Model Description", "text": "v L denote the trajectory of a patient where v 1 < v 2 < v 3 < ... < v L and x vt are the input features from some patient at visit t. Note that v 1 , v 2 , . . . v L \u2208 N and do not have to be consecutive. However, we can assume that they are without loss of generality.\nOur goal is to predict the disease stage of the patient at visit v L+\u03c4 where \u03c4 \u2208 N.\nWe let x vt = i vt \u2295s vt \u2295c vt where i vt , s vt , c vt denote volumetric information, demographic information, and cognitive test scores respectively and \u2295 is concatenation.\nFirst, we use a three seperate multilayer perceptrons, \u03c6 i , \u03c6 s , \u03c6 c , one for each category of input features to encode our input features into a common latent space. After we extract the representations, we concatenate them:\nWe do this for all x vt \u2208 X traj resulting in:\nThen, the sequence f v 1 :v L is sent to an RNN which provides hidden layer outputs for each input:\nEach entry is used as input to another MLP, which we refer to as the feature prediction network, \u03c1(.). The purpose of \u03c1(.) is to take the hidden layer output h v L and reconstruct the latent representation of x v L +1 that is generated by \u03c6(.). More generally:\nis the reconstructed latent representation of patient's disease progression at visit v L + 1. We create an auxiliary loss term\n, which is the mean squared error between the reconstructed representations and the learned representations of the visit data that we have available.\nAt this stage, we have dealt with all of the available visit data in the trajectory. If the trajectory only consisted of one visit, say X traj = x v 1 , we would skip the RNN and take the representation f v 1 and send it through \u03c1 resulting in \u03c1(f v 1 ) =f v 1 +1 . Then classif ier(f v 1 +1 ) is the disease progression prediction of the patient at time v 1 + 1. Otherwise, in the general case where we have more than one visit we have this chain of events:\nWe continue iteratively generating the sequence of representations for the datapoints between our last available visit v L and the visit we want to forecast v L + \u03c4 until we reac\u0125 h v L +\u03c4 . Finally, we take classif ier(\u0125 v L +\u03c4 ) to be the disease stage forecast of the patient at time v L + \u03c4 . The disease stage of the patient can be placed in three categories: Cognitively Normal (CN), Mildly Cognitively Impaired (MCI), and Alzheimer's Disease (AD). If the trajectory is not continuous, i.e v 1 , v 2 , ..., v L are not consecutive, we can use \u03c1 to \"impute\" any missing representation. During training, we backpropagate on both cross entropy loss, L class and reconstruction loss L aux . The objective function for a single training batch of N training samples is given in equation (1). The diagrams of FLARe and the baseline model are illustrated in Figure 1 . "}, {"section_title": "Experiments", "text": ""}, {"section_title": "Dataset", "text": "We used the Alzheimer's Disease Neuroimaging Initiative (ADNI) 1 dataset for our experiments. The ADNI dataset contains clinical information and biomarkers taken from from 2104 patients during visits that occur every 6 months spanning over five years. The dataset contains 1907 metrics recorded from the patient during each visit although it is common for many entries to be missing, and the patterns of missingness to be inconsistent across patients.\nIn addition to undergoing a cranial MRI scan, patients have a variety of other metrics recorded during each visit including real-valued bio-markers that measure atrophy, molecular A list of patient IDs we used for training and testing will be made available in our code repository."}, {"section_title": "Experimental Setting", "text": "We shuffled the training data and performed an 80/20 split across 1652 patients. To address the class imbalance within our dataset, we used a weighted Cross Entropy Loss based on the class proportions. A list of hyperparameters we used for both models is available in Appendix B.\nWe chose 697 features from the ADNI dataset. 692 of them were volumetric measures taken from the segmentation of MRI scans, 4 were cognitive test scores, and 3 were demographic information. A detailed list of the features used will be made available in the code repository since the entire list is too long to put in this submission.\nIn order to create more training examples for our model, we generate multiple samples from a given patient trajectory X traj . For example, let\nWe set two sampling parameters: T , which is the number of points used for prediction and \u03c4 , the time horizon. For the ADNI dataset, each unit of \u03c4 is 6 months. For each patient trajectory in a training batch, our model samples data for every possible value T and \u03c4 .\nDoing this exposes our model to more trajectories of varying time horizons and points used for prediction. We split the patients into training and test sets before sampling so that samples generated for one patient will only be encountered in the training set. For our test set, we perform the same augmentation routine on the test sample. Table 1 illustrates the number of patients we used for training and testing, along with the total number of trajectories we sample from each set:"}, {"section_title": "Architecture Selection", "text": "In order to determine the architecture for the initial MLP \u03c6, we chose the architecture that performed the best on disease stage classification. This way, we could ensure that the architecture for \u03c6 is capable of extracting informative representations from the training data. Detailed descriptions of the model architectures will be made available in the code repository."}, {"section_title": "Candidate Models", "text": "We compare the performance of FLARe against the baseline model RNN-Concat, which is a reimplementation of current forecasting models. It concatenates the time horizon \u03c4 to the hidden layer output of the RNN. We keep the model architectures the same between FLARe and RNN-Concat in order to control against the slight performance variations that may occur when implementing different architectures. Table 2 contains the classification accuracy, precision, recall, and F1-scores of the models we tested. We found that FLARe outperforms RNN-Concat across all the evaluation metrics. Additionally, we observe that while the baseline has unbalanced performance across disease stages, often predicting MCI stage patients as AD or NC, our model provides more balance between the classes. A confusion matrices for RNN-Concat and FLARe are provided in Table 3 and Table 4 To analyze our proposed model's change in performance across different levels of data availability and forecasting horizons, we partition the testing set into buckets where each bucket corresponds to an ordered pair (T, \u03c4 ): the number of points used for prediction and the forecasting horizon. In Table 5 , we provide the F1 score of RNN-Concat and FLARe for each bucket. We can make the following observations from the table."}, {"section_title": "Results", "text": ""}, {"section_title": "Accuracy Precision", "text": "\u2022 FLARe is consistently on par or better than RNN-Concat across all buckets of the partitioned test set.\n\u2022 The F1-scores of FLARe improves as the number of available visits increases. This is expected as the model has more data to make a prediction about the future visit representation. "}, {"section_title": "Conclusion", "text": "In this paper, we present a novel approach called FLARe for disease trajectory forecasting using multimodal longitudinal data. FLARe uses a feature prediction module to anticipate the learned representations of the sequence of visits leading up to the future visit, given the representations of the history of visits, instead of directly concatenating some representation of the forecasting horizon \u03c4 to a latent representation of the medical history of the patient. The main reason why FLARe is so effective is because it has the capacity to model a more descriptive temporal relationship between a patient's medical history and their future health status. Also, FLARe has an inherent robustness towards missing data, as it is trained to learn representations that can be used to impute the missing data points. Our performance analysis over the partitioned test set serves to illustrate this point. We observed that generally as the number of visits used for prediction increases, FLARe consistently has a better, or on par, F1 score across all time horizons when compared to the baseline model of RNN-Concat."}]