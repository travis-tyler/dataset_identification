[{"section_title": "", "text": "This paper estimates the short-term, partial-equilibrium impacts of a public-private partnership program for low-cost private secondary schools in Uganda. The public-private partnership program is part of a broader strategy to absorb large increases in secondary enrollment following the introduction of universal secondary education. Under the program, the government offers a per-student subsidy to participating private schools. Program implementation allowed for a randomized phase-in study design to estimate the causal impacts of the program on private school performance. The study finds that the public-private partnership program helped absorb large numbers of eligible students in secondary schools. Student performance in participating private schools was significantly better than in nonparticipating private schools. The study finds that improved student performance is potentially linked to increased input availability, as well as positive selection of government aided students in private schools. Suggestive evidence indicates that this selection most likely occurs on the part of households rather than schools."}, {"section_title": "Introduction", "text": "In the last two decades, many countries in Sub-Saharan Africa have implemented policies-mainly, abolition of user fees-that make access to basic education universal. 1 These policies have led to sudden and massive increases in enrollments that the public education systems are generally not equipped to absorb. Simultaneously, many of the countries are also experiencing a rapid mushrooming of low-cost private schools which are often positioned to serve as an alternative to public schools (Tooley and Dixon 2005) . Against this backdrop lies the question: to what extent can and should governments leverage low-cost private schools to help meet the goals of expanding education access while maintaining (or improving) education quality?\nThis question is now at the center of a debate. On the one side is an argument for an enhanced role of the private sector to facilitate education service delivery (see Pritchett 2013 , Andrabi et al. 2008 , Dixon and Tooley 2005 , Lucas and Mbiti 2012 . It is believed that public provision is characterized by 'ossified' management of inputs and low cognitive achievement (Patrinos et al. 2009 ). Generally, public school administrators have less autonomy in hiring teachers and organizing schools than the private sector does. In comparison, it has been argued that private schools deploy and use teachers more effectively (Andrabi et al 2008 , World Bank, 2009 ). Further, private schools are generally held to a high level of accountability by the parents as a result of the direct financial transactions involved. Schools have to respond to demands of parents and provide high quality services in order to retain students.\nOn the other side of the debate are concerns about private provision as a mechanism that can induce sorting -low-income individuals attending public schools, and high-income individuals attending private institutions -without gains in achievement (McLeod and Urquiola 2013) . Given that the operating model of low-cost private schools involves profit generation while charging low fees, concerns have been expressed about the ability of these schools to offer quality education (Heyneman and Stern 2014) .\nOne popular way to engage the private sector in education delivery is to develop public-private partnerships (PPPs) under which private schools contract with the government to deliver services to lowincome households. This paper exploits a randomized phase-in of a PPP program with low-cost private secondary schools in Uganda to answer some emerging questions as PPPs are rolled out in education and other sectors. We present the effects of the program by comparing outcomes between beneficiary and nonbeneficiary private schools. As such, it is a partial equilibrium analysis, given that the data do not allow us to analyze the effects of the program on public schools under the area of influence of these private schools.\nPPP arrangements provide a unique opportunity to wed the potentially inequality reducing impact of public financing of education to the efficient provision by private schools. Partnering with already-inplace private schools to increase access is cheaper than building new schools or classrooms and training teachers (Barrera-Osorio & Raju 2015; Kim, Alderman & Orazem 1999) . Proponents of PPPs also emphasize their potential effects on public schools through increased competition. 2 In education systems with per-capita funding formulas, the public sector has an incentive to react to this competition (Friedman 1962) . On the other hand some have argued that these partnerships can reduce the government's control on a public service. Increasing the educational choices available to students and their families may increase socioeconomic segregation if better prepared students end up self-selecting into high-quality schools, thus further improving their outcomes. Similarly, if schools are allowed to select students, the market can be segmented with the best schools selecting the best students, as was the case in Chile (MacLeod and Urquiola 1 For instance, see Deininger (2003) ; Bold et al (2010) ; and Lucas and Mbiti (2012) . 2 Hsieh and Urquiola (2006) find no evidence in support of this claim in the context of a very large reform in Chile. 2009 ). PPPs can then lead to poorer or less performing students being left behind in public schools, or lower quality private schools that no longer receive students from better educated and more affluent households.\nA question that has received relatively less attention is the potential impact of PPPs on the low-cost private schools themselves. If, as evidence suggests, low-cost private schools are market-based entities that are meeting an important need in the education sector, then how does the channeling of public financing into these schools impact their effectiveness? It can be argued that PPPs improve the quality of education provided by private schools by increasing the level and stability of resources available to them, particularly in poor credit market contexts (Andrabi et al 2015) . It might also make the distribution of skills and competencies more equitable by making private schools more accessible to low income households. 3 However, there are reasons to be cautious of potential negative effects of PPPs on these schools. PPP arrangements could undermine the efficiency advantages of private schools by introducing additional governance structures. By increasing the number of students and the volume of public monies, PPP programs may dilute the quality of the private school learning environments both by crowding the classroom and crowding out good management.\nDespite an active policy agenda and theoretical interest, the empirical evidence of the causal effects of PPP on private schools is thin. Studies document that PPPs have been successful in increasing access in several countries including Tanzania, Colombia and Pakistan (Alderman, Kim, and Orazem 2003; BarreraOsorio et al 2011; Patrinos et al. 2009 ). Evidence on the impact of such programs on education quality, however, is also only just emerging. Research in Pakistan found some evidence of increased inputsteachers, classrooms and blackboards (Barrera-Osorio and Raju, 2015) . Evaluations of programs in India and Pakistan also point to high cost-benefit ratios from private schools (Muralidharan and Sundararaman 2013; Andrabi et al 2007; Pritchett and Aiyar 2014; Barrera-Osorio et al 2011) . MacLeod and Urquiola (2013), however, find no evidence of an increase in productivity when reviewing these evaluations, as well as programs in Colombia and Chile.\nOur intent-to-treat estimates suggest that schools that participated in the program increased enrollment in eligible, early grades by 35%. Moreover, student performance in participating schools is significantly better. In particular, we find that the set of students exposed to more than a year of the PPP program have test scores in Math, English and Biology that are in the range of 0.07 to 0.16 standard deviations (sd) better than students in non-participating private schools.\nWe examine several likely explanations for this positive impact of the program on student achievement. Crucially, we do not find any adverse impacts on the governance of participating schools even though program schools are more likely to discuss both teacher and head-teacher salaries. We find modest positive changes in availability of school inputs to students (teacher attendance, and science laboratories). We also find significant changes in student composition, suggesting the selection of students from more educationally-favorable backgrounds in participating private schools.\nThe rest of the paper is organized as follows. In section 2 we discuss the context and outline the PPP policy and program; section 3 discusses the empirical strategy and study balance. Section 4 presents our results on enrollment and test scores as well as our exploration of potential mechanisms. Section 5 discusses the results and we conclude in section 6."}, {"section_title": "Context and the PPP program", "text": ""}, {"section_title": "3", "text": "It has been noted that in Uganda affluent households opt out of public schools in favor of the more expensive private schools (Deninger 2003) .\nIn 2007, the Government of Uganda became the first country in Sub-Saharan Africa to introduce and implement the Universal Secondary Education (USE) program, opening the doors of secondary education to its burgeoning population of primary school graduates. 4 Following the adoption of USE, all students who receive an overall aggregate score of 28 or better on the Primary Leaving Examination (PLE) are eligible to attend -at no cost to their families -participating public secondary schools and vocational institutions."}, {"section_title": "5", "text": "The introduction of USE led to large increases in lower secondary school enrollment. For example total enrollment increased by nearly 25% between 2007 (World Bank 2014 . However, this boost to enrollment has not been accompanied by concomitant increases in input levels, straining resources and infrastructure. Large classes -with students-teacher ratios of 60 and above -may lead to poor learning environments. While the number of teachers on government payroll has increased by 14% since 2008, the country needs multiple interventions in order to accommodate rising enrollment and adequately address the problem of a crowded learning environment.\nAt the outset of USE, the government implemented two policies to address short run needs generated by increases in student enrollment. First, the government introduced double shifting in eligible and willing public secondary schools. Secondly, in sub-counties where (i) there were no participating public secondary schools, (ii) those government schools were crowded, or (iii) where the size of the sub-county would involve very long distances to public schools, the government contracted with private schools to provide schooling for USE students. Below, we describe the PPP program.\nThe PPP program was initiated in 2007 under the overall umbrella of the USE policy. Eligibility for this program was defined to include all registered and certified private schools charging 75,000 UGX per term or lower."}, {"section_title": "6", "text": "Under the partnership, private schools apply to the Ministry of Education and Sports (MoES) and must meet a set of certification and quality benchmarks. These include: (i) being registered with the MoES, (ii) have adequate infrastructure, (iii) show demonstrated support from locally elected officials and education officials, (iv) institute a board of governors with government and parental membership and (v) have sufficient certified teaching staff.\nSchools that are enrolled in the partnership enter into a contractual arrangement with the MoES documented by a memorandum of understanding. This contract stipulates that private schools will receive 47,000 UGX per term per student eligible under the USE policy to cover non-boarding fees, and that the school will not charge any other non-boarding fee to the student. Partnering schools become eligible to receive support from the government for USE, including the provision of textbooks and other teaching materials."}, {"section_title": "7", "text": "The program is phased into the entire school over the course of several years, starting with the first lower secondary grade, S1, in the first year, and both adding younger cohorts and supporting each eligible cohort as it progresses through secondary education. Participating schools have control over the student selection process, may enroll as many students as they want, and can continue to enroll non-USE students (private students) for a fee. Participating private schools must institute a board of governors that makes 4 The Government of Uganda (GoU) introduced Universal Primary Education (UPE) in 1997. 5 An aggregate 28 corresponds to an average of a passing grade in each of the four subjects tested: Math, English, Social Studies and Science. 6 At the prevailing exchange rates at the time, this corresponds to about $30 per term for a total annual cost of no more than $90. decisions concerning budgets and expenses. The board of governors is expected to administer the property of the school as well as ensure that the school is operated in such a manner as to ensure the learning and safety of students and staff.\nThe number of participating private schools has steadily grown. As of February 2010, there were 545 participating private schools. This number has grown to 874 schools as of the end of the 2014 school year -an increase of 60% over four years. The percentage of USE students enrolled in private schools has grown from 25% in 2008 to 45% in 2014 (MoES 2015 . Schools that participate in the PPP program in Uganda are typically low-cost private schools. Using baseline data, the average fee charged per term in the study sample was just under 69,000 UGX, or about $27.5 US dollars at prevailing exchange rates. PPP schools are predominantly rural and were often started by local communities or entrepreneurs in response to the lack of government-operated schools in the area. As such, these schools are not the high performing elite schools typically associated with the private school provision in advanced economies or attended by the rich in developing countries.\nGiven the novelty of the program in Uganda, careful research was required to understand if and how much the private sector could support the expansion in access without compromising the quality of education provided to government voucher students. A related objective was determining how government funds are used by private schools in lieu of providing a quality learning environment. If private schools make more efficient allocations of resources, we would expect participation in a PPP program to translate into an increase in learning related inputs. This work sets out to identify the preferences and priorities of school owners and managers as well their actual behavior. In particular, we measure the quality of the inputs that private schools provide including teacher recruitment, competence and effort as well as the presence of important instructional inputs such as science laboratories."}, {"section_title": "Data, Empirical Strategy and Internal Validity", "text": ""}, {"section_title": "a. Randomization", "text": "Implementation of the program allowed a randomized phase-in study design. From the 250 private schools that applied to become part of the program in the 2011 school year and met the criteria for participation described above, 100 schools were selected as study schools."}, {"section_title": "8", "text": "These schools were randomly assigned to one group (50 treatment schools) that implemented the program in 2011 and another group (50 control schools) that were not to be a part of the PPP program in 2011 but were invited to implement the program starting in the 2012 school year.\nThis study design allows us to compare low-cost private schools that were a part of the PPP program in 2011 with a similar set of non-chosen schools in order to estimate the causal effect of the program on private school performance. We estimate the impact of the program on schools' inputs and outcomes (mainly, enrollment); on governance of the school; on students' standardized tests and characteristics. Table 1 summarizes the data collected for the study. Baseline data were collected in December 2010 (prior to the random assignment and prior to the start of the new school year) and, as a result of delays due to end of the year activities, in April 2011 (after start of the program). Information was collected from head teachers, teachers and students. The collection includes interviews of three teachers in each school, randomly selecting an English, Math, and Science teacher. The baseline data are comprised of interviews with 119 and 105 teachers in treatment and control schools, respectively. Up to 20 students per school were also interviewed from each school. Students were randomly selected from Senior 1 and 2 classes. In cases where there were not enough students from these two grades, Senior 3 students were interviewed. In total, 944 and 801 students were selected from treatment and control schools, respectively. Follow-up unannounced surveys were administered at three different points in time (subsequently referred to as checks 1, 2 and 3). Check 1 was administered in July 2011 in 96 schools, during the second school term. Check 2 was administered in September 2011 in 94 schools, during the third term of the school year. Check 3 was administered in 95 schools in February 2012, during the first term of the new school year, prior to the expansion of the program to the control schools. Check 3 also included student interviews with 1,467 and 1,261 students in treatment and control schools, respectively. The variation in number of schools covered in each check is linked to the inability of reach certain schools at certain times of the year. Some common reasons for not reaching schools were weather conditions leading to lack of access or school closure. In addition, some schools closed permanently, an outcome we examine explicitly in the results.\nIn addition to surveys designed by the research team, the study partnered with the Uganda National Examinations Bureau (UNEB) to measure student performance. UNEB conducts an annual standardized assessment in a nationally representative sample of 500 schools called the National Assessment of Progress in Education (NAPE). This mid-year assessment measures student proficiency in English, Mathematics and Biology for a group of 30 randomly selected students in Senior 2. In July 2011 and 2012, UNEB included the list of 100 schools from the study in addition to their national sample and administered the three assessments. In addition, UNEB administered an additional Mathematics test (\"Math independent\"), which the research team adapted from TIMSS, an international test, 9 through discussions with psychometricians in Uganda. The independent test was included to detect real gains in achievement using an alternative to the official test (NAPE), which may be subject to \"teaching to the test\". NAPE data were collected in 2011 for 1,230 students from 48 treatment schools and 1,126 from 45 control schools, and in 2012 for 1,268 students from 48 treatment schools and 990 from 45 control schools."}, {"section_title": "b. Empirical Strategy", "text": "The research team performed the phase-in lottery in December 2010. Treatment is defined as formal notification that the private school is a part of the PPP program. All treatment schools received this notification of acceptance into the PPP program in February 2011 and none of the control schools did. In this respect, compliance to randomized design was close to 100%.\nHowever, actual transfer of resources under the PPP program was slower and compliance was less than perfect. Consequently, we are estimating two models: an intent-to-treat model, ITT (based on the lottery assignment) and an instrumental variable (IV) design that uses actual program implementation, as reported by the schools.\nThe ITT model is based on two main specifications. In the first model, the outcome variable Y of student (grade and gender) i in school s at time t, is regressed against a dummy variable indicating random assignment to treatment (T, 1=treatment; 0=control).\n, , ,\nThe Trends in International Mathematics and Science Study (TIMSS) is a series of international assessments of the mathematics and science knowledge of students around the world. For this research, we used a balanced selection of openly available questions from Grade 4 TIMSS Mathematics tests across specified learning domains.\nOutcome variable Y includes enrollment by grade and by gender, as well as NAPE test results by subject. Enrollment is measured as the total number of students enrolled in a particular grade. Test results are standardized using the mean and standard deviation in the control group. The regression is run at school or student level, according to the outcome measure. X includes a rich list of control variables measured at baseline. These include the number of teachers working in the school, the share of female teachers, the number of permanent teachers, the number of teachers in the classroom at the time of visit, the number of teachers absent, the number of students enrolled, the number of toilets at the school, the availability of electricity, whether or not a library exists, and the existence of a board of governors (BOG)."}, {"section_title": "10", "text": "In analyzing test outcomes, regressions include a rich sets of covariates that help generate greater precision in the estimation and to control for any unbalance across treatment groups. These covariates are average characteristics of students at the school level such as students' age, proportion of males, PLE scores, household size, index of household assets, and mother and father education. Standard errors are clustered at the school level. All regressions include region fixed effects.\nThe second main specification is similar to the first equation. In this second equation, the dependent variable Z includes three families of potential channels of school change.\n, , ,\nThe dependent variable Z includes changes in school inputs (teacher characteristics and school infrastructure), changes in the school governance, and changes in the characteristics of students.\nThe Instrumental Variable design uses reports of schools in Check 2 with respect to program implementation. Compliance to randomized design was close to perfect in that all treatment schools received notification of acceptance into the PPP program in February 2011 and none of control schools did. However, as shown in Figure 1 , 62% of schools treatment schools received government transfers in 2011 and contrary to assignment, around 26% of control schools receive government transfers in 2011."}, {"section_title": "11", "text": "We confirm the data reported by the schools with administrative data; the numbers are very similar to the ones reported by the schools.\nFor this reason, we use the lottery as an instrument for actual receipt of public resources (our measurement of implementation) as a first step:\nwhere I is equal one if the school s receive transfers from the program (and zero otherwise) and then using the predicted implementation in the second step, we estimate , ,\nThe IV estimators scale up the ITT estimators by a factor of (approximately) 2.8 (the inverse of the difference in implementation rates in treatment schools (0.62) and control schools (0.26)). We present the IV estimators for enrollment and test scores.\nThe receipt of government funds by private schools in the control group does not necessarily indicate a link to the PPP program. They might indicate other one-time transfers under other programs or initiatives. Tables 2, 3 and 4 present the balance of the sample at baseline. These three tables present baseline variables at the school, teacher, and student level, respectively. The first column presents the mean and standard deviation of each variable for the control schools, while the second column presents the analogous information for the treatment schools. The third column presents the difference between treatment and control (coefficient ) and standard errors, using the following equation:\nwhere , , is the school, teacher or student attribute in question and , is as above an indicator for assignment to treatment in 2011.\nWe start with the balance of schools characteristics, as reported by the head teachers. Table 2 presents school level variables collected during the head teacher interviews. Panel A presents school characteristics and panel B presents characteristics of teachers and students. Most schools (97%) report having a board of governors (BOG) in place, though 62% of head teachers report the BOG only met once or not at all in the previous six months. On average, BOGs have ten members."}, {"section_title": "c. Internal Validity 10", "text": "In order to maximize sample size, we replace missing values with the average value for the sample and include a dummy variable indicating that imputation."}, {"section_title": "12", "text": "Most schools report access to safe drinking water (90%), while 39% report access to electricity and 44% have a library. On average, schools have 6.39 toilets. Schools have an average of 16 teachers, with treatment schools having a slightly higher proportion of female teachers. On average, teachers in treatment schools were more likely to be present and in the classroom on the day of the visit than those in control schools. Enrollment of students was slightly below 200 students, with no significant difference at baseline between schools. Only two variables-number of female teachers and teacher absenteeism-present statistical differences between control and treatment schools. A joint test for all differences equal to zero cannot be rejected (chi-square = 31.418, p=0.113), as expected from the random assignment at the school level. Table 3 presents the baseline data from teacher interviews. Teachers in these schools are predominantly male (92%) with an average age of 32 years old. About 60% of respondents report being permanent teachers at the school, and the typical respondent has slightly more than 2 years of teaching experience on average. Less than one-third of teachers interviewed had a university degree. The average reported commuting time was 30 minutes. Slightly less than one-quarter of teachers were able to show a lesson plan for the day of the visit. The only significant difference between the study arms was the reported salary, with teachers in treatment schools reporting a higher monthly wage. The joint test shows no significant difference between the two groups (Chi-square = 11.664, p=0.473).\nFinally, Table 4 presents baseline data from students, restricting the sample to S2 students since these students were not treated (directly) at any time during baseline data collection (either in December 2010, before the program; or in April 2011, after the onset of the program). On average, students interviewed were about 16 years old, with the treatment group slightly younger. Slightly more than half of control school students were male (56%) compared with 40% of those in treatment schools. Approximately 5-8% of students report having repeated the current grade; the proportion of students who have ever repeated is much higher at 34 and 26% in control and treatment schools respectively. On average, students reported more than 1 member of the household helped them with homework, and over 70% reported that one parent or grandparent visited the school in the last year. More than half of students in control schools (54%) reported being absent at least 1 day in the previous week, compared with 47% in the treatment schools. Age and gender are the only two characteristics with significant differences between treatment and control. We reject the null hypothesis that jointly, the coefficients are equal to zero. As such, it is critical to control for baseline covariate differences in the estimation of effects below. 13 With respect to the household characteristics of S2 students (Panel B, Table 4), the average size of the household in the control group is 9.5; while the ratio of child to adult was over 1.5. 63% of students in the control group reported their parents being from the same district they currently live. On average, students in the control group were more likely to report that their parents were farmers than in the treatment group, with 63% of mothers and 47% of fathers, compared to 54% and 40% respectively in the treatment group. Students in the control group reported 61% of mothers and 84% of fathers as literate. The index of household services represents a simple additive composite of four variables: roof, toilet, drinking water and electricity. There was no significant difference in reports from the two groups, with an average of 2.17 on the index. Overall, two student attributes (mother and father education) were statistically different between treatment and control. We cannot reject the joint test that all these differences are equal to zero (Chi-square test of 14.033, with a probability of 0.172).\nDespite the inability to reject the null hypothesis of these imbalances being equal to zero, the data show some differences in students and family characteristics between treatment and control schools at baseline. The key difference in baseline student characteristics appears to be that control schools have a higher proportion of repeating students than treatment schools -which creates an imbalance in average age of the student (and possibly gender). It is unclear the direction of the bias that these imbalances can induce for our estimators. On one hand, repeating and older students may perform better in test because either they already took the test or have learned the material before. On the other hand, these students already signal weaker academic performance. As a result, we control for these baseline characteristics in all of the analysis.\nAnother important test of the validity of the experiment pertains to differential attrition. Recall that, at check 3, the number of schools that we were able to visit was 94 (down from 101 schools included in the lottery). We use the school panel structure to test baseline characteristics differ from attritors and nonattritors and, more importantly, if there are differences between attritors across treatment status. Appendix 1 presents the analysis. The first three columns show means of key schools characteristics at baseline of non-attritors and attritors (at check 3) and the differences between treatment and control schools. Only one difference is statistically significant. Columns (4)-(6) present, for non-attritors, the differences between treatment and control status. Again, only one attribute difference is statistically significant. Finally, Columns (7) and (8) present the coefficient results from models that run each baseline characteristic against attrition status, treatment status and the interaction. We show only the coefficient of the attrition status and the interactions. None of the interactions are significant. This analysis suggests that it is unlikely that attrition at the school level can explain the results.\nIn summary, we see this analysis as a validation of the experiment design, despite lack of balance at the student level. The variables at the school level (the level of randomization) and teacher level seem similar across treatment and control group. In any case, we control all the specifications for a rich set of variables at the school and at the student level. Furthermore, attrition is balanced across treatment status."}, {"section_title": "Results", "text": ""}, {"section_title": "a. Enrollment and Test Schools 13", "text": "As a further test, we did the same analysis including only information collected in December 2010. This estimation has about 30% of the sample, and as such, it is noisier that estimations using all S2 students, both in December 2010 and April 2011. However, the results are very similar. The results are available upon request.\nThe first three columns of Table 5 present the intent-to-treat estimates of the impact of the program on total school enrollment, as well as enrollment by grade and by gender. We transformed enrollment data using the formula Log e (Enrrolment+1). We present the regression with a full set of covariates, which include schools characteristics at baseline as well as regional fixed effects. The results are stable to the inclusion of these baseline controls. Each column reports the results corresponding to information collected at Checks 1, 2 and 3.\nWe observe large and significant enrollment effects for lower grades and small and always insignificant impacts for higher grades that were not part of the program. At all Checks, we find an impact between 0.285 and 0.32 for grade 1, which translates to increments of between 33% and 38% in enrollment. At Check 3, in the second year of implementation, we observe effects in enrollment at both grades 1 and 2, of the order of 34% and 58% respectively. In the bottom panel of Table 5 we show that the increase in enrollment is roughly proportionate across genders. If anything, female beneficiaries account for slightly more than half of the students at checks 1 and 2. The last three columns of Table 5 show the IV estimates, which roughly scale up by a factor of 3 the ITT estimates. The same pattern as the ITT estimation is present in the IV model. The most conservative IV estimate (Check 3, point estimate 0.737) suggests an increment that doubles the size of the schools induced to participate in the program by the lottery. Table 6 presents the impact of the program on test scores from NAPE in 2011 and 2012. We include both years of the test given that tested cohorts are variously exposed to the PPP program, with the 2011 cohort potentially exposed for 6 months while the 2012 cohort is exposed for 18 months. We report both on the overall test scores but also on the composition of students, a potential mechanism underlying the observed impacts that we discuss below. Panel A presents student characteristics reported on the day of the test. We tested if there are differences in these characteristics between treatment and control schools. Panel B presents test score results from the three NAPE tests and the independent Math test. Column (1) presents the mean and standard deviation for the control group. Column (2) presents the results of the regression with no controls. Column (3) presents the results of the regression with regional fixed effects, and baseline student characteristics (average at the school level) and school level characteristics. Column (4) presents the IV results, with the full set of controls.\nPanel A shows that, in terms of characteristics of the individuals taking the exam, there are differences in age between treatment and control. However, once the full set of baseline controls and fixed effects are included, there are no differences in student characteristics. Nevertheless, results for the test scores are relatively stable to the inclusion of controls. In general, the test score impacts are positive. The ITT impact for the math independent test is 0.154 sd, and is marginally significant. The IV estimation shows, as expected, larger and highly significant positive effects, in the range of 0.3 and 0.4 sd. NAPE 2012 results are very similar. Our preferred OLS specification, with full baseline controls and region fixed effects, shows positive effects on the test, but only the math independent test is statistically significant, with a point estimate of 0.127 sd. Again, these effects are quite stable to the inclusion of baseline controls. The results from the IV estimations range from 0.28 to 0.4 sd and are significant for all tests. The consistent and stable results for the independent math test are indicative of real learning impacts under the program, as opposed to impacts from teaching to the test etc. It is important to note that full controlled regressions had lower number of observations because of missing information for contemporaneous characteristics. In order to rule out biases due to the sample composition, we restricted all regressions to the sample of the full controlled equation and found similar results (not shown in the table)."}, {"section_title": "b. Mechanisms", "text": "In summary, the PPP program increased private school enrollment significantly at grade 1, and, as the program matured, the increment in enrollment trickled down to grade 2. The increment seems to benefit both girls and boys. Students in treated private schools also scored higher than students in control private schools, in all the tests conducted.\nOne potential explanation for these impacts relates to improved governance within private schools as a result of participation in PPPs. A PPP approach could improve private school governance by increasing the level and stability of resources available. It can also be argued that public funding may in fact empower a broader spectrum of lower-and higher-income parents to exercise greater influence in school matters, since under PPP the purely private \"ownership\" and \"control\" of schooling is radically transformed to a \"contracting out\" model of public education service delivery.\n14 To test these hypotheses, each of the three surveys (Check 1, Check 2 and Check 3) asked questions about the presence of Board of Governors (BOG), frequency of meetings, changes in ownership, and the content of BOG deliberations. Table 7 presents measures of program impact on school governance and accountability from checks 1 to 3. We only present the intent-to-treat estimates that account for regional fixed effects and baseline characteristics of the school. The program does not appear to impact school governance in a systematic way. The likelihood of having a Board of Governors, the frequency of meetings and the attendance rates of members is not impacted. Changes in ownership in the control schools are very small (range 0 to 0.07), with impacts of the program ranging from -0.015 to 0.03, none of them statistically significant. If anything, the program seems to increase discussion of teacher compensation; with positive point estimates for all survey rounds, and with a statically significant coefficient at Check 3 of 0.313. Also, the results suggest that the program induces more discussion of infrastructure at the beginning (Check 1), but then a reduction (Check 3), in favor for teacher compensation. All in all, we read these results as no adverse effects of the program on school governance.\nThe second hypothesis we explore is whether private schools use PPP funds to increase or improve school inputs which could in turn impact student performance. The structure of the program can be expected to directly impact investments in the quantity and quality of school inputs and resources. First, certain investments might be necessary for accommodating additional enrollments. Secondly, private schools might strategically invest in school inputs to create a favorable impression on public officials (who have influence on schools' continued participation in the program), parents and students (especially those that continue to pay fees), and teachers (to maintain motivation in the face of increased class sizes). On the other hand, given that there is limited capacity to enforce expenditure guidelines, the level of per-student subsidy is fairly modest, and some of these institutions are ultimately profit-making entities, input availability perstudent in these private schools might in fact decline with program participation.\nWe explore program impacts on two critical sets of school inputs -teachers and school infrastructure (Table 8 ) -and find that treatment schools had a similar number of teachers, with no systematic changes in teacher composition in terms of the share of female and permanent teachers. However, even though levels remain similar, there appear to be significant differences in the utilization of 14 On the other hand, it is possible that public financing might undermine the superior management of school inputs that underlie the comparative advantage of private schools. Firstly, the establishment of an additional governance structure, a Board of Governors, a requirement for all licensed secondary schools, whose membership includes a number of public officials and where decisions are made by majority vote, could undermine management quality. Secondly, the power and incentive structures of school governance may be fundamentally altered by the infusion of public money and it is conceivable that as a result of PPP private schools become less responsive to the parents, shift the power away from parents to government officials in school management/governance, and (as a result) provide less information to parents. the teacher input. We see that a higher proportion of teachers in treatment schools were present in class, with positive estimates for the three checks, and statistically significant coefficients for the first two checks (0.069 and 0.074 respectively). Likewise, teachers are less likely to be absent at the time of the unannounced school visits. In an environment where teachers typically provide services in several schools, these results are consistent with higher levels of resources in program schools inducing greater teacher commitment to their schools.\nIn terms of school infrastructure, the only discernible impact of the program was on the presence of a science laboratory in schools; with approximately 20% more treatment schools reporting having a science laboratory. There do not appear to be significant differences in other conditions, such as working toilets, class cleanliness, or amount of furniture for students. In light of the intervention, these results seem reasonable. Given the limited transfer, it seems unlikely that schools would be able to invest significantly in school infrastructure. However, it appears that participating private schools are using at least part of the government transfers to adapt existing infrastructure and purchase equipment for school laboratories. The flow of public resources to participating private schools also appears to positively impact the overall likelihood of school survival. 15 These, admittedly marginal, improvements in school stability and availability of school inputs, in terms of teacher effort and science laboratories, could explain part of the observed improvements in student performance.\nThe third hypothesis tested is whether students attending participating private schools are in effect 'different' in a way that would explain the performance differential between treatment and control schools. Given the secure stream of resources, treated schools may choose their students based on specific characteristics. Table 9 presents standard 2 (S2) students' characteristics collected at Check 3. This group of students was the first cohort in the program. Column (1) includes the mean and standard deviation of the control group. Columns (2) and (3) present the results of the regression with and without fixed effects at the district level. Students in treatment schools are younger on average. They also appear more likely to be coming from households that: (i) are more invested in children's schooling (parents reported to be more likely to visit the school), (ii) are smaller; and (iii) with more educated parents (students in treatment schools report a higher education level for their father). Students in the treatment group also have better PLE Scores. We reject the joint null of zero differences in these observable characteristics with a probability of 0.001. More directly capturing differences in unobservables as shown in figure 2, students in the treatment group perform better on the primary leaving exam than students in the control group. We are able to reject the Wilcoxon-Kolmogorov test that the distribution of treatment test scores is drawn from the same distribution as the control group. Overall, it seems that students in treated private schools are different from their peers in control private schools. Specifically, they come from backgrounds that are positively associated with student achievement.\nAnother way to test this hypothesis is to perform a bounding exercise in test outcomes. Following Angrist et al. (2006) , in the absence of student panel data, we use the cohort variation to estimate parametric models in which we impose artificial censoring in the test outcomes. If the positive gains in test scores observed are due to selection of students, control schools would disproportionally have students at the extreme left of the score distribution. We estimate Tobit left-censoring limited models at the 5, 10 and 15"}, {"section_title": "15", "text": "A total of 7 schools closed throughout the entirety of the study, with 2 closing from the treatment group (4% of treatment schools) schools and 5 from control (10% of control schools) and this difference is statistically significant. However, these results need to be interpreted with caution because data limitations prevent us from being definitive about how permanent these school closures were.\npercentiles. Under normality, the estimation is consistent for latent scores of all students. If schools are not choosing particular students, the estimate should be stable to different censoring points, in comparison to the OLS estimator that uses all the variation of the data. Similarly, if treatment schools are choosing students from the extreme right of the test distribution, these schools would have disproportionally more students from the (extreme) right side of the test distribution than control schools. Again, under normality, if schools are not choosing students in this manner, then the estimator should be stable, vis-\u00e0-vis the OLS estimator. We estimate models with data censored from above at the 85, 90 and 95 quintiles. Table 10 presents the results. Column (1) replicates the OLS estimator (presented in Table 6 ). Columns (2)-(4) presents the Tobit point estimates of left-censored estimators, while columns (5)- (7) the right-censored ones. Two patterns emerge from the data: first, the estimators are quite stable for the leftcensored estimators; second, there is a \"J\" shape for the right-censored estimators. At face value, it seems that treated schools are not rejecting the weakest students, but they appear to recruit top students. We take this as suggestive evidence of positive selection into program schools.\nTwo main possibilities may explain these results. With participation in the PPP program, treated private schools might find themselves faced with excess demand -more applications than available seatswhich would make it possible for them to introduce selection criteria for enrollment. Such excess demand is particularly likely to occur if there are few other secondary schools (public or private) present in the community; available public schools are overcrowded and of low-quality; and/or the association of a lowcost private school with public funding is perceived as a positive signal of school quality by parents.\nAnother possibility is that the selection is actually happening on the part of the households. To the extent that (i) the PPP program increases schooling choices for poor households and (ii) households associate these private schools with better quality education, poor households who care more about school quality may choose to enroll their children in treatment schools. Either type of selection -by schools or by households -would present plausible explanations for the observed gains in student performance in PPP schools. While available data do not allow us to be definitive about the underlying causes for better student performance in treatment schools, we weigh the relative evidence surrounding various hypotheses in the discussion below.\nabove. The nature of selection needs to be examined further as it has important implications for the efficacy and effectiveness of the PPP program."}, {"section_title": "c. Discussion", "text": "The explicit objective of the PPP program is to use the private sector to help absorb an increased student population in secondary schools without adversely impacting the quality of education service delivery. Our evaluation of the Uganda PPP program along these dimensions shows that not only does the program help successfully increase student enrollment in private schools, but student performance in participating private schools is actually stronger.\nWe examine the three most likely explanations for this positive impact of the program on student achievement: (i) changes in school management and governance; (ii) changes in school inputs; and (iii) changes in student composition through selection. We find no changes in school governance but modest positive changes in availability of school inputs to students (school stability, teacher presence, and science laboratories). We also find significant changes in student composition suggesting that participating private schools could be systematically selecting students from more educationally-favorable backgrounds.\nOur data are not well suited to reliably establish the key actors driving the observed selection since we do not observe the population of students applying to program and non-program schools. Instead we rely on two strategies that potentially shed more light on this question. First, an exploration of the heterogeneity of program impacts using the data at hand. Second we rely on quantitative and qualitative data from a sub-sample of head teachers about recruitment of new students.\nWe explore the likely nature of the selection observed by testing whether the observed expansion in enrollment or student characteristics varies by attributes associated with a lower cost of school-driven selection. These attributes include (i) number of secondary schools within 10 km (number of competing schools in the market of the school) and (ii) age of the school in years. We argue that these attributes are likely to reduce the cost of selection either through proximity to higher quality students, higher demand for strong reputation signals and well established and arguably better schools (see Melitz (2002)). 16 We run the standard model:\nwhere , captures the heterogeneity attribution (competition or age); and , represents enrollment (by grade) and, for check number 3, school average test results in the PLE. Table 11 shows the results of this exploration. The table only shows the coefficients and . The main effect of the attribute and other controls (region fixed effects) are not shown. Each panel corresponds to each survey round. In panel C, we include a measure of student quality-the school average score on the national primary leaving examination -as the dependent variable.\nThe presence of nearby secondary schools and age of the schools seems to negatively affect changes in student enrollment in treatment schools. All coefficients on the interaction between treatment and the attribution are negative, and all but one estimate is not statistically significant. In short, the higher the number of secondary schools in the vicinity, the lower the number of students that treatment schools can attract. Likewise, the older the treatment school, the lower the growth in student enrollment. These results also hold for the secondary school entrance exam scores measured at Check 3.\nNext, we use a survey of 30 head teachers conducted a year after control schools enter the program. The survey elicited responses both on the composition of applicant pools and the degree of selectivity. The data show firstly that more than two-thirds of applications are publicly funded students. Second, the data show that both in program and non-program schools, the admission rate is very high at 93%. Finally, even though these responses are the most vulnerable to measurement bias, the distribution of quality between admitted students and applicants is very similar, suggesting that schools are not very selective at all.\nFinally we use data from interviews with 11 head teachers and focus groups with 20 parents conducted by one of the authors in December 2014. In response to the question on whether they are selective in admission, 10 of the 11 schools indicated that they admit just about everyone who applies and qualifies for the PPP.\nThe preponderance of evidence suggests that the observed selection is driven by households and not schools. Since this program is effectively an expansion of school choice for budget constrained households, desirable attributes such as proximity to the school potentially underpin the results we obtain 16 We also tested heterogeneity by being founded by a private individual (as opposed to the local public goods that community founded schools may be). The results were very noisy and highly sensitive to the inclusion of controls, presumably due to the fact that the majority of the schools were founded by a private individual. As such, we report only heterogeneity by competition and age. 17 We run the models with and without controls; results are stable to the inclusion of baseline covariants."}, {"section_title": "Conclusion", "text": "In this paper we examine the causal impacts of a PPP program in Uganda, aimed at helping absorb enrollment increases in secondary education, on private school outcomes. We find that the PPP program succeeds in absorbing a considerable number of USE students. Specifically, we find that total enrollment increases by just over 100 students per private school after one year of PPP program participation. Across grades 1 and 2, the average enrollment increment was close to 35%. In addition, the observed expansion in enrollment is evenly distributed between male and female students. Secondly, private schools had similar teacher compositions, with comparable numbers of total, female and permanent teachers, regardless of whether the school received the PPP program or not. However, significantly, more teachers were present in class at the time of visit in PPP schools. We also report a discernible impact of the program on infrastructure: an increase in reported science laboratories in treatment schools.\nIn addition, participation in the PPP program does not appear to change private school governance in any systematic way. The likelihood of having an active Board of Governors, measured by the frequency of meetings and attendance of meetings, does not appear to be affected by inflows of public funding to private schools. While we find the PPP program influences topics discussed at meetings, as far as we can tell, school ownership and control remains unchanged.\nFinally, using data from the Uganda National Examinations post-primary NAPE test results, students in PPP program schools achieve higher scores in all subjects compared to students in non-PPP private schools. In particular, we found a consistent positive statistically significant effect in math, of around 0.16 sd. These results appear to be mainly driven by student selection -given that students in treatment schools are significantly more likely to come from households with better education, more resources, and more involved parents.\nOverall, the results indicate that the PPP program successfully utilizes excess capacity in private schools and enables these schools to operate at a scale that more efficiently utilizes teacher and other instructional inputs. However, the PPP program does lead to positive selection of students in participating private schools, seemingly driven by households rather than schools. C h e c k 1 C h e c k 2 C h e c k 3\nNote. Columns (1) include the mean and SD for each variable for the control group. Columns (2) present the coefficient of the regression of each variable of governance against treatment status. All regression controls for baseline characteristics and fixed effects at the region level.\n25 Note. Columns (1) include the mean and SD for each variable for the control group. Columns (2) present the coefficient of the regression of each variable against treatment status. All regression controls for baseline characteristics and fixed effects at the region level. Note. Column (1) report mean and standard deviation for the control group. Columns (2) and (3) report the estimate of effects of a regression of each outcome variable against the treatment indicator, controlling for regional fixed effects. Standard errors are cluster at the school level. (1), (2), (4) and (5), mean and SD; Columns (3) and (6), difference and SE; Columns (7) and (8) Distribution of PLE Scores -S1/S2 2012"}]