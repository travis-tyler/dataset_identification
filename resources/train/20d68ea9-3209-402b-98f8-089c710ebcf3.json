[{"section_title": "Abstract", "text": "Neuroimaging techniques have greatly enhanced the understanding of neurodiversity (human brain variation across individuals) in both health and disease. The ultimate goal of using brain imaging biomarkers is to perform individualized predictions. Here we proposed a generalized framework that can predict explicit values of the targeted measures by taking advantage of joint information from multiple modalities. This framework also enables whole brain voxel-wise searching by combining multivariate techniques such as ReliefF, clustering, correlation-based feature selection and multiple regression models, which is more flexible and can achieve better prediction performance than alternative atlas-based methods. For 50 healthy controls and 47 schizophrenia patients, three kinds of features derived from resting-state fMRI (fALFF), sMRI (gray matter) and DTI (fractional anisotropy) were extracted and fed into a regression model, achieving high prediction for both cognitive scores (MCCB composite r = 0.7033, MCCB social cognition r = 0.7084) and symptomatic scores (positive and negative syndrome scale [PANSS] positive r = 0.7785, PANSS negative r = 0.7804). Moreover, the brain areas likely responsible for cognitive deficits of schizophrenia, including middle temporal gyrus, dorsolateral prefrontal cortex, striatum, cuneus and cerebellum, were located with different weights, as well as regions predicting PANSS symptoms, including thalamus, striatum and inferior parietal lobule, pinpointing the potential neuromarkers. Finally, compared to a single modality, multimodal combination achieves higher prediction accuracy and enables individualized prediction on multiple clinical measures. There is more work to be done, but the current results highlight the potential utility of multimodal brain imaging biomarkers to eventually inform clinical decision-making."}, {"section_title": "Introduction", "text": "Predictive data mining has become a powerful tool for researchers and clinical practitioners in medicine and neuroscience. It involves building and applying theory and methods that allow for effective creation, evaluation and selection of prediction models (Dumpuri et al., 2010; Oakes et al., 2007; Simpson et al., 2014) . Neuroimaging has greatly enhanced our understanding of the human brain and its variation across individuals (neurodiversity) in health and disease (Edwards et al., 2011; Oto et al., 2011; Wang et al., 2011b; Yan et al., 2013) . However, most criteria that used to assess severity/prognosis of brain disorders are still primarily based on clinical judgment; thus, the subjective factors of the doctors cannot be avoided. In addition, the overlapped cognitive or behavior performance of several mental disorders emphasizes the inadequacy of a diagnosis based purely on symptoms or behaviors alone and highlights the need for objective imaging neuromarkers that can assist the timely diagnosis or treatment. Therefore, using brain-imaging data to identify the neuroanatomical basis of cognitive impairment or symptom changes in brain diseases is an important research topic, since it is helpful for better understanding of the pathophysiology underlying the illness.\nPredictive data mining has become popular in neuroimaging studies in a recent decade, especially for mental disorders research. Recent studies have started to use machine-learning techniques to detect neuroimaging patterns that may predict cognitive or behavioral performance (Aharoni et al., 2013; Eichele et al., 2008; Shen et al., 2014) . And initial brain measures have indicated compelling potential to predict health-related outcomes (Chen et al., 2007; Clark et al., 2014; Gabrieli et al., 2015; Shaffer et al., 2013; Technow et al., 2014; Tsang et al., 2009; Vittengl et al., 2014; Willette et al., 2014) . However, most predictive studies to date have only related variation in baseline brain NeuroImage 145 (2017) [218] [219] [220] [221] [222] [223] [224] [225] [226] [227] [228] [229] measures to variation in subsequent outcomes, which could be described more as post-diction or correlation rather than prediction (Gabrieli et al., 2015; Hutton et al., 2009 ).There are, however, a few examples of studies that are indeed \"predicting\" specific values of the target measures. For example, Wan et al. has proposed an elegant regression model called CORNLIN (Wan et al., 2014) that employs a sparse Bayesian learning algorithm to predict multiple cognitive scores based on 98 structural MRI regions of interests (ROIs) for Alzheimer's disease patients. The polynomial model used in CORNLIN can detect either a nonlinear or linear relationship between brain structure and cognitive decline. Stonnington et al. adopted relevance vector regression (Stonnington et al., 2010) , a sparse kernel method formulated in a Bayesian framework, to predict four sets of cognitive scores using MRI voxel based morphometry measures. Wang et al. (Wang et al., 2011a) and Zhang et al. (Zhang et al., 2012a) employed multi-task learning strategies for selecting biomarkers that could predict multiple clinical scores, e.g., using \u2113 2 -norm coupled with \u2113 1 -norm in regression models or multi-task feature selection coupled with a support vector machine (SVM). Integrating and testing various types of baseline data available, Ye et al. applied sparse logistic regression with stability selection to ADNI (Alzheimer's Disease Neuroimaging Initiative) data for robust feature selection (Ye et al., 2012) , successfully predicted the conversion from MCI to probable AD and identified a small subset of bio-signatures.\nNevertheless, many works were limited to use of a single modality, without using cross information from multiple modalities or were focused on subgroup discrimination (\"classification\") instead of the particular values of the measures (Gabrieli et al., 2015; Leergaard et al., 2012) . In addition, quite often the input feature dimensionality is restricted, e.g. based on ROI features derived from AAL (Anatomical Automatic Labeling) templates, but without performing whole brain voxel-wise searching because of the computational load. Hence, we are motivated to propose a generalized model that is able to predict explicit values of the targeted measures by whole brain voxel-wise searching via cutting-edge machine learning algorithms (Stokes and Visweswaran, 2012; Sun, 2007) and by combining joint information from multiple imaging modalities. Based on this motivation, we could use purely data-driven techniques to estimate the cognitive scores symptom changes or to classify disease subcategories using MRI measures, providing a potentially biologically valid framework for understanding mental illnesses or for even predicting the progression of the disease. This is consistent with the scope of the research domain criteria (RDoC) project proposed by NIMH, which aims to develop new ways of classifying and clarifying the underlying causes of mental disorders based on dimensions of observable behavior and neurobiological measures (Cuthbert and Workgroup, 2014) .\nHere, we aim to achieve two main goals: 1) Design a generalized prediction framework that can be widely employed in future studies. 2) Predict target clinical measures quantitatively and identify relevant neuromarkers that could be biologically meaningful on cognitive decline/functional deficits in schizophrenia (SZ). For real human brain imaging data, we applied the framework to 47 SZ patients and 50 healthy controls (HCs) to estimate their cognitive scores, measured by the \"measurement and treatment research to improve cognition in schizophrenia\" (MATRICS) Consensus Cognitive Battery (MCCB) (August et al., 2011) and the patients' symptom scores, measured by the positive and negative syndrome scale (PANSS) (Kay et al., 1987) , using features extracted from three modalities: fractional amplitude of low frequency fluctuations (fALFF) from resting-state functional MRI, segmented gray matter (GM) from structural MRI and fractional anisotropy (FA) from diffusion MRI.\nNote that we used the same data set as used for (Sui et al., 2015) , however, different than the previous study that investigated the multimodal co-varied networks which were not only significantly correlated with cognitive composite scores, but also showed significant differences between schizophrenia and healthy controls; this study aims to explore an approach to multimodal imaging data that enables detection of neuroimaging patterns as well as the building of a prediction model of target measures, such as cognitive scores or symptom scores. The methods used are quite distinct, the former paper adopted multi-set canonical correlation analysis, a blind source separation approach applied to group level of subjects; while the current work utilized several machine-learning techniques, including feature selection, clustering, regression and cross-validation. Results suggest the proposed prediction framework shows great promise to produce precise and individualized estimates on multiple clinical measures. Hence it's possible to use this tool to estimate the treatment outcome for an individual patient, e.g., remitter or non-remitter, based on observable imaging measures, similar to what did in (van Waarde et al., 2015) , which could enable the clinician to realistically make the personalized medical decision before treating a patient. Therefore, this project will be one of few attempts to meet clinical challenges of making early intervention possible based on fundamental neuroscience."}, {"section_title": "Materials and methods", "text": ""}, {"section_title": "Theory development", "text": "The working flowchart of proposed prediction model is shown in Fig. 1 , which uses three MRI measures as an example; but this surely can be extended to other measures or modalities. The basic idea and justification of each step can be described as follows: First, considering the individuality of the predicted measures (cognition, symptoms), we remove features with very few variability across all training subjects by relative standard deviation thresholding, then based on advanced feature selection method ReliefF (Stokes and Visweswaran, 2012) , we are able to select a set of most relevant features to the predicted measures. Then data-driven spatial clustering was performed to obtain fewer ROI-based features by averaging of the clusters, of which one cluster may consist several parts of the brain regions parcellated by atlas-based template, such AAL template. Note that using brain regions segmented by atlas as features is an alternative in our prediction, whereas, our proposed method is a purely data-driven feature extraction via whole brain voxel-wise searching, and achieves a higher prediction accuracy compared to AAL atlas-based methods, see results and the supplementary file (Supplementary Table S4 ). After this, the ROI-based features of different modalities were combined to take advantage of the multimodal complementary information, and further refined by correlation-based feature selection Fig. 1 . The working flowchart of the proposed prediction framework. Fig. 1 shows working flowchart of the proposed prediction model, in which preprocessing, feature selection (ReliefF), spatial clustering, feature subset selection and regression models are employed. Three MRI measures (fALFF, GM, FA) are combined together to realize the individualized prediction via linear or nonlinear regression analysis.\n(CFS) (Tripoliti et al., 2010) , producing a feature subset before regression. This step is necessary; since spatial clustering and averaging generate ROIs that compared to voxel-wise features indicate decreased relevance to target measure and may contain redundant information. Finally, by cutting-edge multiple regression models, a combination of joint brain feature subsets is formed to best predict the targeted measures. Note that all above mentioned feature selection algorithms (ReliefF, CFS) and regression models can be found in WEKA (Frank et al., 2004) , a powerful data mining software in Java with a collection of machine learning algorithms. We will also release our prediction toolbox in future.\nTo avoid introducing bias into the prediction, rigorous nested crossvalidation was performed. First, we left one subject for testing and used the other 96 subjects for training; then in the training layer, the 96 subjects went through a 10-fold cross-validation in the regression analysis after initial feature selection and the multimodal combination as shown in Fig. 1 . This loop was repeated 97 times to test all the subjects. Each time the results produced the predicted score for the left-out (test) subject, as well as the regression equation and the identified brain regions in each modality. Then, we calculate the accuracy of the resulting prediction and identify the frequently occurring brain regions. Finally, in order to get a single regression equation for the whole MCCB prediction, we also performed a 10-fold prediction using all subjects to illustrate the identified features and regression model, as shown in Fig. 3 . Next we describe the details for each step."}, {"section_title": "Feature preprocessing", "text": "Generally speaking, specific features with only minor variation across all subjects will not be useful for prediction. By setting an appropriate threshold, we eliminate features with low standard deviation (std), which also helps reduce the dimensionality. This step is similar to variance-based thesholding that has been popularly used in DNA methylation pre-processing for dimension reduction (WilhelmBenartzi et al., 2013) . The std. threshold is set as th \u00bc 0:5 \u00c2 std\u00f0target\u00de mean\u00f0target\u00de \u00c2 mean\u00f0all features\u00de where \"target\" denotes the measure to be predicted. The necessity of this step is given in supplementary file, see Table S1 ."}, {"section_title": "Feature selection by regression ReliefF", "text": "After obtaining representative measures from each modality, we will estimate the relevance of each voxel-wise feature to the target measure by ReliefF (Stokes and Visweswaran, 2012) to derive subset of features. For continuous response values here, regression ReliefF is adapted. When processing, assume the input feature matrix X is in dimension of subjects by voxels (N \u00d7 L), ReliefF randomly selects one subject R i and searches for its k nearest neighbor subjects I j (j = 1,2\u2026k) based on L1 distance. For one feature (voxel/attribute) A, if it is desirable for prediction, then a bigger distance between the selected subjectR i and its nearest neighbors I j should correspond to farther values on their predicted measures. For short, ReliefF introduces a kind of probability that the predicted values of two participants are different. This probability can be modeled with the relative distance between the predicted values of two subjects, and then are used to estimate the importance (weight) of each feature for the regression (Robnik-\u0160ikonja and Kononenko, 1997) .\nAssume N dc measures two nearest subjects (e.g.,R i and I j ) have different predictions, N dA [A] [A] were updated m times for all voxels. Finally, the weight for each feature A is defined as:\nWhile, the detailed updates for N dc , N dA(A) and N dA(A)dC , as well as the Pseudo code of RReliefF can be found in (Robnik-\u0160ikonja and Kononenko, 2003) .\nFollowing regression ReliefF, every feature is assigned with a weight value statistically accounts for its relevance to the response values (prediction). By determining a certain output number according to the scree test (Mori et al., 2000) (see more details in the supplementary file Supplementary Fig. S1 ), we can identify the most significant features in the dataset and use them as the representatives of the original voxels."}, {"section_title": "Spatial clustering", "text": "The voxels selected via ReliefF were in general distributed sparsely across the whole brain. Here we employ a 26-connected (3 \u00d7 3 \u00d7 3-1) neighborhood strategy for image dilation (Bazin et al., 2011) , a classic way to find connected voxels in 3D image (Cheng et al., 2009 ). In our case, the voxels selected out by ReliefF is 1, and the other voxels are 0. The 26-connected neighborhood voxels are neighbors to every voxel that touches one of their faces, edges, or corners. These pixels are connected along either one, two, or all three of the primary axes. These new generated voxel clusters can be projected into their corresponding areas on a brain map, enabling a useful visualization of the results. Next, these clusters are treated as the elementary features, and the mean voxel values of each cluster represent the ROI-based feature value."}, {"section_title": "Feature fusion", "text": "Features selected from the above procedures are derived from a single modality, reflecting a view of either brain structure or function (Sui et al., 2012) . By combining features of different modalities together in a joint analysis, potentially important variations or relationship that may only be partially detected by single modality (Sui et al., 2013; Sui et al., 2014) could be revealed, and complementary information may be obtained for better prediction (Arbabshirani et al., 2016; Calhoun and Sui, 2016) . At this step, in order to take advantage of joint information, all ROI-based brain features of 3 modalities were concatenated horizontally, to build a matrix in the dimension of N subjects by (N feat_fMRI + N feat_sMRI + N feat_dMRI ) and then input to the feature subset selection."}, {"section_title": "Feature subset evaluation", "text": "Although voxel-wise features selected by ReliefF are important, after spatial clustering and extract mean of the clusters, some features may have little influence on the predicted attribute. To further remove the redundancy, correlation-based feature selection (CFS) is employed (Tripoliti et al., 2010) . In CFS, the worth of each subset of features is evaluated by considering the individual predictive ability of each feature along with the degree of redundancy between them (Bielza and Larranaga, 2014; Gudmundsson et al., 2012) . Subsets of features that are highly correlated with the predicted measure while having low inter-correlation are preferred (Kohavi and John, 1997) . Such a feature selection can help reduce the size of the resulting knowledge structures based on multimodal features and further yield a concise and refined data set that significantly improves the prediction performance."}, {"section_title": "Regression analysis", "text": "Next, a final regression analysis that quantitatively captures correlations between target measures and selected brain features was implemented. If we have l, p, q number of features derived from fALFF, GM and FA, respectively, then the practical predicted values (not true target value) can be written as:\nTo make a performance comparison between linear and nonlinear regressions, we adopt three models: multiple linear regression, pace regression (linear) and sequential minimal optimization regression (SMOreg) (non-linear), all of which can be called and implemented through WEKA too. The latter two models are briefly introduced as follows."}, {"section_title": "PACE regression", "text": "(Projection Adjustment by Contribution Estimation) has striking advantages over existing techniques for fitting linear models with a strong emphasis on dimensionality determination problem. Compared to classical ordinary least squares estimators that may fail to detect redundancy in a larger feature set, pace regression improves it by evaluating the effect of each variable and using a clustering analysis to improve the statistical basis for estimating their contribution to the overall regressions. Besides, pace regression adopts nonnegative-measure-based minimum distance method for solving the minority cluster problem. It can yield better prediction models with reduced model dimensionality (Meshkin et al., 2009) , especially for high dimensional data. Detailed information can be found in (Wang, 2000) ."}, {"section_title": "Sequential minimal optimization regression", "text": "(SMOreg) is an iterative algorithm (Sch\u00f6lkopf and Smola, 2002) for solving the regression problem using support vector machines (SVM). SMOreg uses the same principles as the SVM for classification, except for applying a nonlinear polynomial kernel k(x i , x j ) = (x i , x j ) p with p = 2 to transfer features into higher dimensional space, to make it possible to perform the linear separation. The goal of SMOreg is to estimate a function that is as \"close\" as possible to target values and as \"flat\" as possible for good generalization. More details together with a pseudo-code can be found in (Li and Jiang, 2006) . As an extension of the SMO algorithm proposed by (Platt, 1999) for SVM classifier design, SMOreg overcomes the issue of an important source of confusion and inefficiency caused by SMO. It globally normalizes all attributes by default (Mohammadi et al., 2013) , with an excellent performance on handling big samples."}, {"section_title": "Human brain data Participants", "text": "Participants included a total of 47 patients with a SCID-P based DSM-IV-TR diagnosis of schizophrenia and 50 age-matched HCs (Table 1) . The study was IRB approved at all participating institutions: the University of New Mexico Hospital and the Albuquerque Veterans Administration Medical Center. Participants were free of any central neurological disorder or significant head trauma and have no current diagnosis of substance abuse (N6 months before enrollment, excluding nicotine). Patients were clinically stable with no recent medication change (N 4 months prior to study enrollment) across the data collection period. HCs and their first-degree relatives had no history of psychiatric disorder."}, {"section_title": "Clinical measures", "text": "To measure the current cognitive functioning, a trained rater administered the MCCB within 1 week of imaging. A composite score was calculated via the MCCB scoring program, which is an equal weighting of seven MCCB domain scores and has been recognized as the optimal primary outcome measure (Burton et al., 2013) . Compared with HCs, SZs achieved significantly lower scores in composite and all domains. Meanwhile, the PANSS was conducted to quantify symptom scores of patients. The negative PANSS scores and the MCCB composite were anticorrelated (R = \u22120.48, p = 0.0008) as expected. No significant correlation was found between MCCB composite and medication dose in SZ."}, {"section_title": "Imaging parameters", "text": "All subjects were scanned by fMRI, sMRI and diffusion magnetic resonance imaging (dMRI), which were collected on a 3-Tesla Siemens Trio scanner with a 12-channel radio frequency coil."}, {"section_title": "fMRI", "text": "Resting-state scans were a minimum of 5 min in duration (152 volumes). Subjects were instructed to keep their eyes open during the scan and stare passively at a presented fixation cross, as this facilitates network delineation compared to eyes-closed conditions and helps ensure that subjects are awake. Data were collected with single-shot full k-space echo-planar imaging with ramp sampling correction using the inter-commissural line (anterior commissure/posterior commissure) as a reference (TR = 2 s, TE = 29 ms, matrix size = 64 \u00d7 64, flip angle = 75\u00b0, slice thickness = 3.5 mm, slice gap = 1.05 mm, field of view (FOV) = 240 mm, matrix size = 64 \u00d7 64, voxel size = 3.75 \u00d7 3.75 \u00d7 4.55 mm 3 )."}, {"section_title": "sMRI", "text": "A multi-echo MPRAGE sequence was used with the following parameters: TR/TE/TI = 2530/[1. 64, 3.5, 5.36, 7.22, 9 .08]/900 ms, flip angle = 7\u00b0, FOV = 256 \u00d7 256 mm, slice thickness = 176 mm, matrix size = 256 \u00d7 256 \u00d7 176, voxel size = 1 \u00d7 1 \u00d7 1 mm, pixel bandwidth = 650 Hz, total scan time = 6 min."}, {"section_title": "dMRI", "text": "Data were collected along the anterior commissure/posterior commissure line throughout the whole brain with the following parameters: FOV = 256 \u00d7 256 mm, slice thickness = 2 mm, number of excitations = 1, TE = 84 ms, TR = 9000 ms. A multiple channel radio frequency coil was used with generalized auto calibrating partially parallel acquisition (\u00d7 2), 35 gradient directions, b = 800 s/mm 2 and 5 measurements with b = 0."}, {"section_title": "fMRI preprocessing", "text": "The SPM8 software package (http://www.fil.ion.ucl.ac.uk/spm/ software/spm8) was employed to perform fMRI preprocessing. Slice timing was performed with the middle slice as the reference frame. Images were realigned using INRI align (Freire et al., 2002 ). The fMRI data were then despiked to mitigate the impact of outliers and spatially normalized into the standard Montreal Neurological Institute space (Friston et al., 1995) with slightly up-sampled to 3 \u00d7 3 \u00d7 3 mm 3 . We further regressed out six motion parameters, white matter (WM) and CSF in de-noising, and the mean frame wise displacements showed no significant group difference (mean of root of mean square frame-toframe head motions assuming 50 mm head radius (Allen et al., 2011) ); HC: 0.224 \u00b1 0.12 mm, SZ: 0.227 \u00b1 0.12 mm, p = 0.91). Finally, data were and slightly subsampled to 3 \u00d7 3 \u00d7 3 mm 3 and spatially smoothed with a Gaussian kernel with full-width half maximum (FWHM) of 8 \u00d7 8 \u00d7 8 mm 3\n. For the rest-fMRI, we extracted the voxelwise fALFF to generate a map for each subject (Calhoun and Allen, 2012) ."}, {"section_title": "dMRI preprocessing", "text": "Data were preprocessed by the FMRIB Software Library (www. fmrib.ox.ac.uk/fsl). All images were registered to the first b = 0 image by the FMRIB linear image registration tool. The preprocessing consisted of the following steps: (a) quality check, any gradient directions with excessive motion or vibration artifacts were identified and removed; (b) motion and eddy current correction; (c) correction of gradient directions for any image rotation done during the previous motion correction step; and (d) calculation of diffusion tensor and scalar measures such as FA, which were then resampled to 3 \u00d7 3 \u00d7 3 mm 3 and smoothed by a Gaussian kernel with FWHM of 8 \u00d7 8 \u00d7 8 mm 3 (Sui et al., 2011) ."}, {"section_title": "sMRI preprocessing", "text": "Data were preprocessed using the SPM8 software package to segment the brain into WM, GM, and cerebral spinal fluid with unmodulated normalized parameters via the unified segmentation method (Ashburner and Friston, 2005) . According to (Radua et al., 2014) , the use of unmodulated GM maps is one of the optimal settings in voxelbased morphometry analysis. Then GM images were then resampled to 3 \u00d7 3 \u00d7 3 mm 3 and smoothed by a Gaussian kernel with FWHM of 8 mm (White et al., 2001) . Subject outliers were detected using a spatial Pearson correlation with the template image to ensure that all subjects were properly segmented (Segall et al., 2009 )."}, {"section_title": "Normalization", "text": "After preprocessing, the 3D brain images of each subject were reshaped into a one-dimensional vector and stacked, forming a matrix (N sbj \u00d7 N voxel ) for each of the three modalities. These three matrices were then normalized to have the same average sum-of-squares (computed across all subjects and all voxels/locus for each modality) to ensure that all modalities had comparable ranges. Since SZ and HC were not perfectly gender matched in the current study, before prediction, the gender was regressed out to remove its potential influence on differences between groups, even though the correlation between gender and the MCCB composite score is not significant (r = 0.17, p N 0.05)."}, {"section_title": "Individualized prediction", "text": "Matrices derived from the above processing could then be treated as the original feature sets, and the corresponding cognitive/symptom scores are treated as the targeted measures; together, they serve as input to the proposed framework. Take fMRI for example, thresholding by standard deviation will prune out almost half of the total number of features, and about thousands of features will be reserved after ReliefF. During spatial clustering, with voxels organized into larger clusters, the number of features will be reduced to dozens. Finally, the features from three modalities are combined into a concatenated feature matrix that is further refined via subset feature selection, resulting in 5-15 brain regions and achieving the final prediction equation by regression analysis. In the experiment, we predicted the MCCB composite score and two domain scores (social cognition and verbal learning) with rigorous crossvalidation, then evaluated PANSS positive and negative scores to verify the validity and reliability of the proposed framework.\nIn order to ensure the validity of the detected features, we performed an unbiased prediction flow based on nested cross-validation (10 fold + leave one out) as shown in Fig. 1 , the correlations and root mean squared errors between the predicted measures and the true values are calculated in both training and testing loops, as shown in supplementary Table S3 . For each modality, we could get a set of ROIs that contribute to regression and occur frequently in all loops. Note that the regression models are different at each loop; in order to get one regression model for the whole prediction, we also performed a prediction of MCCB composite using all subjects with 10 fold cross-validation. In this prediction, although in ReliefF all the training subjects were used, the selected voxel-wise features were not directly input into the pace regression, instead, these voxels were spatially clustered and refined again. Such a flow actually reduced the degree of overfitting in the training. We want to check if the frequently occurred ROI features from unbiased tests are in consistence with what we obtained from the above processing. And as we tested, the results obtained from such a working flow, as shown in Fig. 3 , are quite similar to what we got from the unbiased test, see Results section.\nOn the other hand, the proposed method enables data-driven, voxelwise feature searching. Indeed, using brain regions segmented by an atlas, e.g., AAL, as features can be used as an alternative. For fair comparison, we also added an alternative prediction of MCCB by combining AAL features from GM and fALFF with LASSO (least absolute shrinkage and selection operator), which is a penalized linear regression model popularly used for feature subset selection and making relevant predictions (Tibshirani, 1996; Tibshirani, 2011) . We did not use DTI data since the AAL parcellation is based on gray matter structure, which is not suitable for FA maps representing the white matter tracts. The correlation between predicted values with the ground truth, the root mean squared prediction error (RMSE) as well as the normalized root mean squared prediction error (NRMSE) were calculated for each method using the nested cross-validation (10 fold + leave one out), as listed in Table 3 . It clearly indicates that the proposed method outperformed the others in all perspectives. Table 2 compares the prediction accuracy on MCCB composite values, PANSS positive and negative scores using three regression models based on the proposed feature selection framework (the first 3 columns, ReliefF + CFS + regression). Results showed pace regression outperforms multivariate linear regression and nonlinear regression (SMOreg) in building a prediction model for the MCCB composite, achieving the highest correlation at r = 0.7033, while for PANSS prediction, the nonlinear regression model yields the best results with r N 0.7785 for both positive and negative scores. Since no single regression approach is clearly superior in all cases during prediction process (Langley and Simon, 1995) , we will incorporate all three regression models into the prediction toolbox as options for users in our future work. In addition, to demonstrate the necessity of each feature selection steps, we also added the MCCB/PANSS prediction performance based only on SVOreg without employing different feature selection steps (the 4th column) and without CFS step (ReliefF + SMOreg, the 5th column). It's clear that lacking any of the steps result in lower correlation with ground truth. Specifically, if using only SMOreg without feature selection, tens of thousands of voxels were used to build a regression, resulting in markedly worse estimation. Similarly, without CFS, an essential step to exclude redundant ROI features, correlations between the estimated scores and true MCCB/PANSS scores decrease substantially too. Besides, supplementary Table S1 shows that including a simple step, standard deviation thresholding, the prediction performance will be improved greatly compared to not use it, especially when the predicted target shows adequate individuality; since most of the stationary features across subjects will be removed at first. All above results demonstrated the validity of the proposed method for multiple predicting targets. Table 3 indicates the performance of MCCB prediction using the atlas based features instead of voxel-wise searching, as well as comparison with alternative prediction methods. The fALFF and GM data were segmented into 116 ROIs for each subject based on automated anatomical labeling (AAL) (Natsopoulos et al., 1998) , and then input into 3 regression models similarly as we did in the proposed method. We also added an alternative prediction by combining AAL features with LASSO (least absolute shrinkage and selection operator), which is a penalized linear regression model popularly used for feature subset selection and making relevant predictions (Tibshirani, 1996; Tibshirani, 2011) . We did not use DTI data here since the AAL parcellation is based on gray matter structure, which is not suitable for FA maps representing the white matter tracts. The correlation between predicted values with the ground truth, the root mean squared prediction error (RMSE) as well as the normalized root mean squared prediction error (NRMSE) (https://en.wikipedia.org/ wiki/Root-mean-square_deviation) were calculated for each method using the nested cross-validation (10 fold + leave one out). As listed, the proposed method outperformed all other alternatives, suggesting that the proposed voxel-wise searching enables more flexibility and higher precision than atlas-based features in prediction. Finally, supplementary Table S2 recorded the training and testing results for MCCB composite prediction on both correlations and RMSE mentioned above, which indicated that there is no apparent overfitting in our processing. Fig. 1 , with a correlation coefficient of r = 0.7033. The true MATRICS scores are HC: 50 \u00b1 11 and SZ: 31 \u00b1 16, while RMSE = 11, low enough to separate most of the two groups. As shown in Fig. 2(A) , the predicted score accuracy (measured by 1-|1-predicted value/true value|) is N 75% for 2/3 of the subjects and N90% for 1/3 of the subjects. Fig. 2(B) demonstrates the bootstrapping test result, which was performed 1000 times on all subjects, and the bootstrapped confidence interval was [0.5849, 0.8055] at 95% (Qin et al., 2015) . Connections with a bootstrap ration over 3.0 were considered to be significantly correlated with the cognitive scores. Table 4 lists the anatomical information and the occurring frequency of the identified brain ROI features for MCCB composite prediction in 97 loops. Brodmann areas (BAs) of the fALFF and GM features and the WM tracts (from the John Hopkins Atlas) overlapped with FA maps are listed according to their occurring frequency from high to low. The higher frequency, the more robustness and importance of the brain regions contribute to the prediction. Clearly, the left prefrontal gyrus (BA 6, 8) , middle temporal gyrus (MTG, BA 21 22), visual cortex (BA 18, 19) , inferior parietal lobule (BA 7, 40) and cerebellum are identified as the significant fMRI or sMRI regions contributing to cognitive composite prediction, while for dMRI, parts of superior longitudinal fasciculus, uncinate fasciculus (UF) and inferior longitudinal fasciculus (ILF) seem to play more important roles. Fig. 3 illustrates the identified multimodal ROI features by using all subjects to build a single regression equation. The identified clusters in each modality as well as their weights resulted from the final pace regression model are demonstrated, including six fALFF clusters, four GM clusters and five FA clusters. The anatomical information of these Table 2 demonstrates the necessity of the multi-stage feature selection. The first 3 columns show the performance using the proposed feature selection steps (std thresholding + ReliefF + CFS) with different regression models. In addition, we also added the MCCB/PANSS prediction performance using only SVM-type nonlinear regression models (SMOreg) or support vector regression models (SVR) without different feature selection steps. If only employ SVM-based regression, there are tens of thousands of voxels used to build a regression within each modality, resulting in markedly lower correlations between the estimated scores and true MCCB/PANSS scores. We have added these results to the supplementary file to show the necessity of each step in the workflow. Table S3 , which shows considerable overlaps with the ROIs listed in Table 4 from unbiased testing. More importantly, prediction accuracy is greatly improved by combining three MRI measures (i.e., r = 0.7033 using 3-way fusion compared to r = 0.5677 using only fALFF, r = 0.5678 using only GM and r = 0.3373 using only FA, respectively, as shown in Table 2 ), which is consistent with the known benefits of multimodal fusion (Calhoun and Adali, 2009; Sui et al., 2012) . Besides the MCCB composite, there are 7 specific cognitive domains. The proposed method can actually predict all domains at an accuracy N 0.6, here we chose one domain, social cognition, as an example. Its final correlation with ground truth is r = 0.7084 based on an fMRI-sMRI fusion (r = 0.4966 using only In the reliability test, 1000 bootstrap resamples were performed to estimate the distribution and 95% confidence intervals of correlation coefficients between cognitive score and neuroimaging. fALFF and r = 0.5633 using only GM). The selected fMRI regions included right MTG (BA 20, 21), parahippocampal gyrus and cerebellum, and sMRI regions included striatum, insula (BA 13); inferior parietal lobule (IPL, BA 39) and angular gyrus (BA 40), which are shown in supplementary Table S4 ."}, {"section_title": "Results", "text": ""}, {"section_title": "Impact of feature selection options and method comparison", "text": ""}, {"section_title": "Prediction of cognitive scores", "text": ""}, {"section_title": "Prediction of PANSS scores", "text": "The PANSS is a medical scale used for measuring symptom severity of patients with schizophrenia (Kay et al., 1987) .To evaluate the stability and generality of the proposed framework from another perspective, the PANSS positive and negative scores were also predicted in this project, with r = 0.7785 and r = 0.7804 achieved respectively for all patients, suggesting excellent generalizability of the proposed framework. For both measures, fALFF-GM combination reached the best prediction instead of using three-way fusion (Table 2) . Table 5 provides the identified anatomical labels and occurring frequencies for fALFF and GM. With regard to PANSS positive scores, brain areas including cingulate gyrus, the striatum/thalamus/ parahippocampal gyrus and cerebellum were identified in fALFF, whereas the dorsolateral prefrontal cortex (DLPFC, BA10, 46), inferior parietal lobule (BA 39, 40) and cerebellum were identified in GM. While for PANSS negative scores, the striatum, superior frontal gyrus (BA 6) and cerebellum appear significant in both fALFF and GM."}, {"section_title": "Discussion", "text": "In this study, we proposed a generalized predicting framework that employs advanced data mining strategies to identify potential neuromarkers by whole brain voxel-wise searching, in which multimodal MRI information was combined to predict both cognitive and symptomatic scores. In addition, the important brain regions contributing to the regression model were also identified. Both the MCCB composite and PANSS predictions achieved correlations with ground truth N0.7, and more than 1/3 of the subject samples acquired score estimation with a 90% or higher correlation with true values, which proved the feasibility and the merits of the proposed framework. Note that this prediction framework can easily be generalized to other mental disorders and multiple brain imaging types."}, {"section_title": "Methodological issues", "text": "As a data-driven approach, the proposed method has a strength in searching neuromarkers from whole brain voxels within a short time, while most related studies often adopted predefined brain regions as features, such as those based on 116 AAL templates (Wang et al., 2015) or 244 ROIs (Power et al., 2011) to reduce computational load. Though valuable information would be evident using larger ROIs, such methods do not exclude the possibility that some more focused abnormalities could be missed, as reported (Argyelan et al., 2015) . By contrast, Fig. 3 . Identified brain regions that may serve as neuromarkers. Fig. 3 indicates the identified brain clusters of three MRI measures, with the cluster color reflecting its weight and sign, as well as the corresponding regression equation, in which the ultimate correlation with ground truth is 0.7033. In total, 15 clusters were identified, each of which was assigned a weigh that implied how much they contribute to the predicted measure (MCCB composite score). The brain views are left, top and front for each column, respectively. we adopted several advanced feature selection approaches, including ReliefF and CFS, to mine from tens of thousands of brain voxels efficiently, and the comparisons in Table 3 did show advantages of the proposed method. Compared with the majority of the heuristic feature selection measures (e.g., information gain (Jakulin et al., 2003) , distance measure (Duda et al., 2001) ) that assume the conditional independence of attributes, ReliefF is aware of the contextual information; its computational complexity is polynomial and can correctly estimate data sets with dependent and independent attributes . Regarding parameter tuning, for all feature selection layers, only the ReliefF output needs to be tuned, which can be easily obtained by scree test, see more details in supplementary file. In our case, keeping 2000~5000 voxels after ReliefF is an optimal and reliable choice. Other feature selection stages can be implemented by WEKA with default settings (http:// www.cs.waikato.ac.nz/ml/weka/index.html) (Mark Hall et al., 2009) . And through the contrast tests in Table 2 , we are convinced that each procedure designed for the prediction model adds value in terms of increased performance.\nAnother point worth noting is that multimodal fusion did improve the prediction performance in both cognitive and symptomatic scores; however, fusing as many modalities as possible in the training sample does not necessarily result in the best predicting results (Sui et al., 2014) . To acquire a higher predicting accuracy and make a comparison among combinations of different modalities, we tested all possible modality combinations. As shown in Table 2 , three-way fusion is optimal for MCCB composite prediction, whereas for PANSS, ALFF + GM is the best combination since FA map derives very low prediction. Compared to existing neuroimaging prediction studies that focus on single modality or single machine learning algorithms, like the framework proposed by (Mansson et al., 2015) , which used SVM to predict long-term treatment response of anxiety disorders via fMRI, or the approach described in (Mwangi et al., 2012) , which can predict severity of depression for major depression disorders (MDD) using single MR structural scans, our data-driven framework makes the best use of the multimodal, sparse, precise yet imperative information, which proves to be flexible and fruitful for an informative understanding of brain activity and disorders (Calhoun and Adali, 2009; Sui et al., 2015; Zhang et al., 2012b) ."}, {"section_title": "Identified potential neuromarkers", "text": "As shown in Table 4 , the higher occurring frequency, the greater impact of the brain ROIs contributing to the predicted measure. Note that left middle and superior temporal gyrus (BA 21, 22) have the highest frequency in fMRI and also appears in sMRI. In addition, according to regression equation in Fig. 3 , the lower fALFF and higher GM values in BA 21, the higher cognitive performance. This is consistent with findings in (Choi et al., 2012; Kim et al., 2015) , where SZs showed dominant activities in the superior and MTG compared with HCs in the implicit memory retrieval tests.\nBesides, left middle and medial frontal gyrus occurred in fALFF, which belong to DLPFC and positively correlates with the cognitive scores (Goldberg et al., 2006) . Cognitive disorganization has been suggested as one cause of decreased activation in the prefrontal cortex (Perlstein et al., 2001) , and DLPFC dysfunction has been related to attention deficits of schizophrenia (Boksman et al., 2005) . In addition, abnormal integration of frontal-temporal function, underpinned by a failure of normal cingulate cortical modulation, has also been demonstrated in patients (Fletcher et al., 1999) . The significant brain imaging markers located by our regression model are consistent with the above reports.\nFurthermore, the cuneus (BA 18, 19), which is most known for its involvement in basic visual processing (Delvecchio et al., 2013; Qiu et al., 2011) , also occur in fMRI and sMRI. Since MCCB experiments include visual learning and attention tasks, it makes sense to identify the visual cortex as part of cognition prediction, and many studies have discovered that SZs present visual processing abnormalities in a variety of tasks (Hardoy et al., 2004; Qiu et al., 2011) . Moreover, the similar covariation between fMRI and sMRI suggests a synchronicity and complementary nature between structural and functional changes in cognitive impairment of schizophrenia, which is supported by (Casey et al., 2005; Salgado-Pineda et al., 2004; Schultz et al., 2012) . With regard to WM assessment, we found the FA mainly lies in parts of WM tracts including the superior longitudinal fasciculus (SLF), UF, ILF, and forceps major/minor, similar to (Wu et al., 2015) . Previous results have shown that FA changes in the SLF and SLFt, the major WM connection between the prefrontal and parietal/temporal cortices, relate to verbal working memory performance (Karlsgodt et al., 2008) . (Epstein et al., 2014 ) also found early-onset schizophrenia adolescents exhibit lower FA in left ILF, and the FA values in left ILF predicted worse neurocognitive performance. Similarly, the uncinate fasciculus is suggested as a predictor of conversion from mild cognitive impairment to Alzheimer disease (Hiyoshi-Taniguchi et al., 2015; Serra et al., 2012) . All above reports support our findings that the identified WM tracts are associated with or predictive to cognitive impairment.\nFor MCCB social cognition domain, MTG (BA 20, 21), IPL and precuneus were highly correlated (Supplementary Table S4 ). IPL, particularly angular gyrus, is concerned with language, mathematical operations, perception of emotions and body image (Radua et al., 2010) . Hornak et al. (1996) have reported that damage to the frontal lobes can affect emotional responses to social stimuli and lead to the inability to recognize faces. Furthermore, the striatum and its cortical connections are critical for complex cognition (Radua et al., 2010) , and lesions of it can affect various cognitive control processes (Chudasama and Robbins, 2006) . All of the identified regions are closely related with the measured MCCB domain social cognition.\nWhen it comes to PANSS, related brain regions with great significance were revealed in striatum, DLPFC, IPL and cerebellum ( Table 5 ). Note that the IPL reveals strong involvement in semantic processing, social cognition or theory-of-mind in several meta-analysis reviews (Binder et al., 2009; Mars et al., 2011; Seghier, 2013) . Hazlett, et al. recently reported that larger BA10 volumes in the DLPFC predict less symptom severity (Hazlett et al., 2014) , and Kawada et al. found executive dysfunction scores were correlated with volume reduction in DLPFC in schizophrenia (Kawada et al., 2009) . The role of the cerebellum in schizophrenia has also been highlighted by Andreasen's hypothesis of \"cognitive dysmetria\", which suggests a general dyscoordination of sensorimotor and mental processes (Cerasa et al., 2012; Moulis et al., 2014) . In addition, thalamus, known for their functions in coordinating, planning (Andreasen et al., 1998) and complex cognition (Simpson et al., 2010) , were demonstrated by patients in fMRI. Hence, all of the above brain regions identified in PANSS prediction are closely related to psychotic symptoms in schizophrenia (Makinen et al., 2008; Vohringer et al., 2013) ."}, {"section_title": "Potential limitations and future directions", "text": "There are limitations of this study. First, no clear trend or characteristic was found to suggest which type of regression analysis is optimal, consistent with previous work (Langley and Simon, 1995) . Both linear (multivariate linear regression and pace regression) and non-linear (SMOreg) regression were adapted in our study. Further studies are needed to clarify the utility of potential biomarkers in predicting cognitive/symptom performance identified here, which are closely correlated with cognition deficits in schizophrenia. Similar data from two or more sites are ideal for cross-validation. In addition, modalities adopted here can be extended to other types of data, such as genetic data, electroencephalograph (EEG) and PET, etc. Finally, as a general challenge for studying schizophrenia, most participants were receiving antipsychotic and/or mood stabilizing medication during the scanning course, which could result in both structural and functional brain alterations (Ho et al., 2011; Lui et al., 2010) . Although we have not examined correlations between antipsychotic dose/gender with the identified brain features, the underlying effects of medication on imaging measures have been widely reported on fALFF (Hadley et al., 2014) , DTI (Szeszko et al., 2014) as well as gray matter (Hutcheson et al., 2014) , future studies also need to consider the potential confound of gender effects.\nIn future work, the proposed method can not only be used for cognitive or symptomatic score prediction, but also be feasible to subcategory classification of mental disorders based on various imaging measures or genetic data. Even more, it can be used for treatment prediction, e.g., predicting that a major depression patient will be a remitter, responder or a non-remitter based on MRI scans before his electroconvulsive therapy, similar to what did in (Johnston et al., 2015; van Waarde et al., 2015) , implicating a wide applicability in the neuroimaging field.\nIn summary, we have developed and evaluated a novel, generalized framework that is able to predict explicit values of targeted measures precisely by using multiple imaging modalities and several superior machine learning approaches. In real application, it was applied to a combination of multiple MRI measures to predict both cognitive and symptomatic scores for schizophrenia and healthy controls. By searching the whole brain voxels, the framework not only achieved relatively higher predicting accuracy for multiple measures, but also demonstrated strong robustness to identify potential biomarkers. In brief, the proposed data-driven framework will be very useful for generating quantitative predictive markers, which can help translate neuroimaging observations into treatment decisions for individualized mental disorders, and thus is possible to lead to correct early intervention and better outcomes."}]