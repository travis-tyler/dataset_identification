[{"section_title": "Abstract", "text": "Abstract Recently, transfer learning has been successfully applied in early diagnosis of Alzheimer's Disease (AD) based on multi-domain data. However, most of existing methods only use data from a single auxiliary domain, and thus cannot utilize the intrinsic useful correlation information from multiple domains. Accordingly, in this paper, we consider the joint learning of tasks in multi-auxiliary domains and the target domain, and propose a novel Multi-Domain Transfer Learning (MDTL) framework for early diagnosis of AD. Specifically, the proposed MDTL framework consists of two key components: 1) a multi-domain transfer feature selection (MDTFS) model that selects the most informative feature subset from multi-domain data, and 2) a multidomain transfer classification (MDTC) model that can identify disease status for early AD detection. We evaluate our method on 807 subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database using baseline magnetic resonance imaging (MRI) data. The experimental results show that the proposed MDTL method can effectively utilize multi-auxiliary domain data for improving the learning performance in the target domain, compared with several state-of-the-art methods."}, {"section_title": "Introduction", "text": "Alzheimer's Disease (AD) is characterized by the progressive impairment of neurons and their connections, which leads to the loss of cognitive function and the ultimate death. It is reported that an estimated 700,000 elderly Americans will die with AD, and many of them will die from complications caused by AD in 2014 (Association, A.s 2014). Mild cognitive impairment (MCI) is a prodromal stage of AD, where some MCI patients will convert to AD over time, i.e., progressive MCI (pMCI), and other MCI patients remain stable, i.e., stable MCI (sMCI). Thus, for timely therapy that might be effective to slow the disease progression, it is important for early diagnosis of AD and its early stage (i.e., MCI). For the last decades, neuroimaging has been successfully used to investigate the characteristics of neurodegenerative progression in the spectrum between AD and normal controls (NC). In recent years, magnetic resonance imaging (MRI) data are widely applied to early diagnosis of AD, which can measure the structural brain atrophy (Fan et al. 2008; Misra et al. 2009; Risacher et al. 2009 ). For instance, several studies have shown that AD patients Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc. edu/). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. exhibited significant decrease of gray matter volume (Chao et al. 2010; Chetelat et al. 2005; Guo et al. 2010) .\nRecently, many machine learning methods based on MRI biomarkers have been used for early diagnosis of AD (Cho et al. 2012; Coup\u00e9 et al. 2012; Cuingnet et al. 2011; Eskildsen et al. 2013; Gaser et al. 2013; Li et al. 2014; Liu et al. 2014; Liu et al. 2016a, b; Ota et al. 2014; Wee et al. 2013; Westman et al. 2013; Westman et al. 2012; Zhang et al. 2016) . According to the point of view in the machine learning field, the number of training samples available to build a generalized model is often overwhelmed by the feature dimensionality. In other words, the number of training samples is usually very limited, while the feature dimensionality is very high. This so-called small-sample-size problem has been one of the main challenges in neuroimaging data analysis, which may lead to over-fitting issue (Zhu et al. 2012) . To overcome the small-sample-size problem, feature selection has been commonly used in many neuroimaging based studies (Cheng et al. 2015b; Eskildsen et al. 2013; Jie et al. 2015; Liu et al. 2014; Ye et al. 2012; Zhu et al. 2014) , where various feature selection methods have been developed to select informative feature subset for reducing the feature dimensionality. Especially, in neuroimaging data analysis for disease diagnosis and therapy, features may be corresponding to brain regions. In such a case, feature selection can detect the regions with brain atrophy, thus potentially useful for timely therapy of brain diseases.\nBesides feature selection, many studies have used multimodal data to improve classification performance (Jie et al. 2015; Liu et al. 2014; Ye et al. 2012; Zhang et al. 2012; Zhu et al. 2014) . For example, to enhance the generalization of classifiers, some studies have used multi-task learning for multimodal feature selection (Jie et al. 2015; Liu et al. 2014; Zhang et al. 2012; Zhu et al. 2014) . In all these studies using multimodal data, different biomarkers are regarded as different modalities, and each modality data is regarded as a learning task (Jie et al. 2015; Liu et al. 2014) . On the other hand, several studies have considered each learning approach as a learning task Zhu et al. 2014) . All these studies suggest that the use of multimodal data for multi-task learning of features can significantly improve classification performance and enhance generalization performance of classifiers. However, in the clinical practice of AD/MCI diagnosis, the collection of complete multimodal biomarkers from each subject is expensive and time-consuming; on the other hand, it is relatively easy to get single modality data (e.g., MRI) for different categories of subjects. Therefore, in this paper, we address the latter case to build respective classification models for early diagnosis of AD.\nAccording to the pathology of AD, it is the progressive impairment of neurons, and MCI and advanced AD are thus highly related. In this way, several studies suggested that the learning domain of AD diagnosis is related to the learning domain of MCI diagnosis (Cheng et al. 2015b; Coup\u00e9 et al. 2012; Da et al. 2014; Filipovych et al. 2011; Westman et al. 2013; Young et al. 2013) . Also in machine learning community, transfer learning aims to extract the knowledge from one or more auxiliary domains and applies the extracted knowledge to a target domain (Duan et al. 2012; Pan and Yang 2010; Yang et al. 2007) , where the auxiliary domain is assumed to be related to the target domain. However, in recent years, several transfer learning methods were developed just for AD/MCI diagnosis (Cheng et al. 2015a; Cheng et al. 2015b; Filipovych et al. 2011; Schwartz et al. 2012; Young et al. 2013) . Although these studies suggested that the data from the auxiliary domain can improve the classification performance of target domain, the training data are often from just a single auxiliary domain. Actually, there are multiple auxiliary domain data that can be available in clinical practice. According to the principle of transfer learning, the application of multiple auxiliary domain data could further promote the performance of the target domain.\nIn addition, in our previous works (Cheng et al. 2015a; Cheng et al. 2015b; Cheng et al. 2012) , we mainly consider the prediction of MCI conversion based on a single auxiliary domain data, to construct the respective transfer learning model. Although in our work (Cheng et al. 2015b) we proposed a domain transfer learning method for classification groups such as MCI vs. NC and MCI vs. AD, our proposed method still cannot acquire the deep structured information between the target domain and the auxiliary domain. Furthermore, few studies considered the heterogeneity of MCI to construct semi-supervised classification or regression models (where MCI subjects are regarded as unlabeled samples), which shows that using information of MCI diagnosis can help improve performance of classifying or estimating AD patients from NCs (Cheng et al. 2013; Filipovych et al. 2011; . Inspired by the aforementioned issues and successes, in this paper, we assume that there is underlying relationship between each binary classification problem in the early diagnosis of AD, where each binary classification problem can be regarded as target domain, with the other binary classification problems as auxiliary domains. In Fig. 1 , we illustrate this novel description of relationships between target domain and corresponding multi-auxiliary domains for early diagnosis of AD. Then, those single modal data that contain multiple data categories can be regarded as multiple related-learning-domains.\nIn particular, we develop a novel multi-domain transfer learning (MDTL) method for early diagnosis of AD, where training data from multiple auxiliary domains are jointly learned with the target domain. Specifically, we first develop a multidomain transfer feature selection (MDTFS) model by using the training data from multiple auxiliary domains and target domain to select a subset of discriminative features. Then, we build a multi-domain transfer classifier (MDTC) that can conjointly apply the training data from multi-auxiliary domains and target domain to construct the classifier. The proposed method is evaluated on the baseline Alzheimer's Disease Neuroimaging Initiative (ADNI) database of 807 subjects with MRI data. The experimental results demonstrate that the proposed method can further improve the performance of early diagnosis of AD, compared with several state-of-the-art methods."}, {"section_title": "Materials", "text": ""}, {"section_title": "ADNI Database", "text": "The data used in the preparation of this paper were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc.edu/). ADNI researchers collect, validate and utilize data such as MRI and positron emission tomography (PET) images, genetics, cognitive tests, cerebrospinal fluid (CSF) and blood biomarkers as predictors for Alzheimer's disease. Data from the North American ADNI's study participants, including Alzheimer's disease patients, mild cognitive impairment subjects and elderly controls, are available in this database. In addition, the ADNI was launched in 2003 by the National Institute on Aging (NIA), the National Institute of Biomedical Imaging and Bioengineering (NIBIB), the Food and Drug Administration (FDA), private pharmaceutical companies, and non-profit organizations, as a $60 million, 5-year public-private partnership. The primary goal of ADNI has been to test whether the serial MRI, PET, other biological markers, and clinical and neuropsychological assessments can be combined to measure the progression of MCI and early AD. Determination of sensitive and specific markers of very early AD progression is intended to aid researchers and clinicians to develop new treatments and monitor their effectiveness, as well as lessen the time and cost of clinical trials.\nThe ADNI is the result of efforts of many co-investigators from a broad range of academic institutions and private corporations, and subjects have been recruited from over 50 sites across the U.S. and Canada. The initial goal of ADNI was to recruit 800 adults, aged 55 to 90, to participate in the research approximately 200 cognitively normal older individuals to be followed for 3 years, 400 people with MCI to be followed for 3 years, and 200 people with early AD to be followed for 2 years (see www. adni-info.org for up-to-date information). The research protocol was approved by each local institutional review board, and the written informed consent is obtained from each participant."}, {"section_title": "Subjects", "text": "The ADNI general eligibility criteria are described at www.adniinfo.org. Briefly, subjects are between 55 and 90 years of age, having a study partner able to provide an independent evaluation of functioning. Specific psychoactive medications will be excluded. General inclusion/ exclusion criteria are as follows: 1) healthy subjects: MMSE scores between 24 and 30, a Clinical Dementia Rating (CDR) of 0, non-depressed, non-MCI, and non-demented; 2) MCI subjects: MMSE scores between 24 and 30, a memory complaint, having objective memory loss measured by education adjusted scores on Wechsler Memory Scale Logical Memory II, a CDR of 0.5, absence of significant levels of impairment in other cognitive domains, essentially preserved activities of daily living, and an absence of dementia. MCI is a prodromal stage of AD, where some MCI patients will convert to AD, i.e., progressive MCI (pMCI), and other MCI patients remain stable, i.e., stable MCI (sMCI); and 3) Mild AD: MMSE scores between 20 and 26, CDR of 0.5 or 1.0, and meets the National Institute of Neurological and Communicative Disorders and Stroke and the Alzheimer's Disease and Related Disorders Association (NINCDS/ADRDA) criteria for probable AD.\nIn this work, we focus on using the baseline ADNI database with MRI data. Specifically, the structural MR scans were acquired from 1.5 T scanners. We downloaded raw Digital Imaging and Communications in Medicine (DICOM) MRI scans from the public ADNI website (www.loni.ucla.edu/ADNI), reviewed for quality, and corrected spatial distortion caused by gradient nonlinearity and B 1 field inhomogeneity. More detailed description can be found in ."}, {"section_title": "Method", "text": "In this section, we first briefly introduce our proposed learning method, and then present our proposed multi-modal transfer feature selection (MDTFS) model, as well as an optimization algorithm for solving the proposed objective function. Finally, we elaborate the proposed multi-domain transfer classification (MDTC) model."}, {"section_title": "Overview", "text": "In Fig. 2 Fig. 1 Our proposed relationships between target domain and auxiliary domains main components, i.e., (1) image pre-processing and feature extraction, (2) multi-domain transfer feature selection (MDTFS), and (3) multi-domain transfer classification (MDTC). As shown in Fig. 2 , we first pre-process all MR images, and extract features from MR images as described in the Image Preprocessing and Feature Extraction section below. Then, we select informative features via the proposed MDTFS method. We finally build a multi-domain transfer classifier using both the target domain and multi-auxiliary domains data for the classification of AD and MCI."}, {"section_title": "Image Preprocessing and Feature Extraction", "text": "All MR images were pre-processed by first performing an anterior commissure-posterior commissure (AC-PC) correction using the MIPAV software (CIT 2012). The AC-PC corrected images were resampled to 256 \u00d7 256 \u00d7 256, and the N3 algorithm (Sled et al. 1998 ) was used to correct intensity inhomogeneity. Then, a skull stripping method ) was performed, and the skull stripping results were manually reviewed to ensure cleaning of skull and dura. The cerebellum was removed by first registering the skull-stripped image to a manually-labeled cerebellum template, and then removing all voxels within the labeled cerebellum mask. FAST in FSL (Zhang et al. 2001 ) was then used to segment human brain into three different tissues: grey matter (GM), white matter (WM), and cerebrospinal fluid (CSF). We used HAMMER (Shen and Davatzikos 2002) for registration. After registration, each subject image was labeled using the Jacob template (Kabani et al. 1998 ) with 93 manually-labeled regions-of-interests (ROIs). Then, for each of 93 ROIs, we computed its GM tissue volume as a feature. As a result, for each subject, we have a 93-dimensional feature vector for representing it."}, {"section_title": "Multi-Domain Transfer Feature Selection (MDTFS)", "text": "Unlike previous methods that only considered a single auxiliary domain in model training, in this work, we use samples of target domain as well as multi-auxiliary domains to build a generalized model for feature selection. Hereafter, we denote D as the number of different domains with an index d \u2208 {1, 2, \u22ef , D} throughout the whole paper. Assume that we have one target domain T, with N T samples x T , i and the class labels y T , i , denoted as\n, where x T , i \u2208 R F is the i-th sample with F features, and y T , i \u2208 {+1, \u22121} is its corresponding class label. Also, assume that we have D \u2212 1 auxiliary domains A, with\nA; j and the class labels y\n, where x In this work, we use a traditional multi-task feature selection method (Obozinski et al. 2006 ) to design our model for feature selection, and use all the available domain data from the multi-auxiliary domains as well as the target domain to build a more generalized model. Since they are related between the target domain and each auxiliary domain, we need to utilize the intrinsic useful correlation information from multi-auxiliary domain, and introduce an L 2 -norm regularizer based on weight vectors (i.e.,\u2211\n) for different learning domains, which can capture the correlation information between the target domain and multi-auxiliary domains. To learn the common subset of features from all domains (i.e., target domain and all auxiliary domains), we also introduce an\non the weight matrix W, where w f is the f-th row vector of weight matrix W and is associated with the f-th feature weight across all domains). In addition, to keep the useful decision information of itself, we also use the 'group sparsity' regularization of weight matrix for all domains (i.e.,\ncan be written as follows: \ncan select a discriminative subset of features relevant to self-domain, and\nset of features relevant to all domains. The regularization term\ncan control the similarity of multiple weight vectors between the target domain and each auxiliary domain, thus keeping each weight vector of auxiliary domain close to the target domain (Zhou et al. 2013 ). The column\nA is the d-th auxiliary-domain weight vector, and the column vector w T is the target-domain weight vector. In addition, \u03bb 1 , \u03bb 2 , \u03bb 3 > 0 are the regularization parameters that control the relative contributions of the three regularization terms. By minimizing Eq. (1), we can learn a converged W from the target domain and multi-auxiliary domain. It is worth noting that, because of using 'group sparsity', the elements of the weight matrix W will be zero. For feature selection, we just keep those features with non-zero weights.\nTo solve the optimization problem of Eq.\n(1), we employ an accelerated gradient descent (AGD) method (Chen et al. 2009; Nemirovski 2005) . To be specific, we decompose the objective function of H(W) in Eq. 1 into two parts, i.e., a smooth term S(W) and a non-smooth term G(W), as follows:\nThen, we define the generalized gradient update rule as follows:\nwhere \u2207S(W t ) denotes the gradient of S(W) at the point W t at the t-th iteration, h is a step size,\n) is the matrix inner product, \u2016\u22c5\u2016 F denotes a Frobenius norm for matrix, and tr(\u22c5) denotes a trace of a matrix. According to (Chen et al. 2009 ), the generalized gradient update rule of Eq. (4) can be further decomposed into N separate subproblems with a gradient mapping update approach. We summarize the details of AGD algorithm in Algorithm 1."}, {"section_title": "Multi-Domain Transfer Classification (MDTC)", "text": "After performing MDTFS, we can obtain the most discriminative common features, upon which we will build a multidomain transfer classifier (MDTC) for final classification. (Cheng et al. 2015b ) that only considered a single auxiliary domain in model training of classification. In this work, we will use multi-auxiliary domains for aiding the learning task of target domain. Due to the domain distribution relatedness between the target domain and each auxiliary domain, Yang et al. (Yang et al. 2007) consider that learning a multi-domain transfer classifier f(x) is to learn the Bdelta function \u0394f(x)^between the target and auxiliary classifiers using an objective function similar to SVMs. To combine multi-auxiliary domain classifiers \nThen, we employed the A-SVMs model of Yang et al. (Yang et al. 2007 ) to get the multi-domain transfer classifier, which has the following form: To learn the weight vector u in Eq. 5, we use the following objective function, similar to the SVM (Yang et al. 2007 ):\nwhere l is the l-th sample in the target domain training subset (x l , y l ) \u2208 X T , and \u03b2 l is the slack variable that represents the prediction error of objective function of Eq. 6, thus it can be used for nonlinear classification. The parameter C balances contributions between auxiliary classifier and target-domain training samples. According to (Yang et al. 2007 ), we can solve this objective function in Eq. 6 to obtain the solution for the weight vector u. Then, we can obtain the final solution for f(x). In this study, f A d x \u00f0 \u00de is trained by SVM, and \u0394f(x) is solved by Eq.5 using the method of kernel learning. "}, {"section_title": "Original MR images Image Preprocessing and Feature Extraction", "text": ""}, {"section_title": "Results", "text": "In this section, we first describe experimental settings in our experiments. Then, we show the classification results on the ADNI database by comparing our proposed method with several state-of-the-art methods. In addition, we illustrate the most discriminative brain regions identified by our proposed method."}, {"section_title": "Experimental Settings", "text": "We use the samples of 807 subjects (186 AD, 395 MCI, and 226 NC), for whom the baseline MRI data were all available. It is worth noting that, for all 395 MCI subjects, during the 24-month follow-up period, 167 MCI subjects converted to AD (pMCI for short) and 228 MCI subjects remained stable (sMCI for short). In addition, we consider three binary classification problems, i.e., AD vs. NC classification, MCI vs. NC classification, and pMCI vs. sMCI classification. For our proposed multi-modal transferring method, we explicitly list the target domain and the corresponding auxiliary domains for each classification task in Table 1 .\nIn the experiments, we adopt a 10-fold cross-validation strategy to partition the target domain data into training and testing subsets. In particular, the target domain samples of each classification problem is partitioned into 10 subsets (each subset with a roughly equal size), and then one subset was successively selected as the testing samples and all the remaining subsets were used for training. To avoid the possible bias occurred during sample partitioning, we repeat this process 10 times. We report the average performances in terms of area under the receiver operating characteristic curve (AUC), accuracy (ACC), sensitivity (SEN), and specificity (SPE).\nWe compared the proposed method with a standard SVM (SVM for short), Lasso (Tibshirani 1996) , MTFS , and M2TFS (Jie et al. 2015) . These methods are listed as follows.\n& SVM: training samples only from the target domain, and without any feature selection before classification stage; & Lasso: training samples only from the target domain, and the Lasso method conducted for feature selection before using SVM for classification; & MTFS and M2TFS: training samples from the target and multi-auxiliary domains, and the MTFS and M2TFS methods conducted for feature selection before using the selected classification method in the literatures (Jie et al. 2015; Zhang et al. 2012) .\nThe SVM method is implemented using the LIBSVM toolbox (Chang and Lin 2001) with a linear kernel and a default value for the parameter C. Also, other competing methods with the SVM for classification are implemented using the LIBSVM toolbox, with the same settings of parameters as the SVM method. For the Lasso and MTFS methods, we adopt the SLEP toolbox (Liu et al. 2009 ) to solve the optimization problem. In addition, we employ the accelerated proximal gradient (APG) method in the literature (Chen et al. 2009 ) to solve the optimization problem of M2TFS. There are multiple regularization parameters of these methods (including Lasso, MTFS, M2TFS, and proposed MDTL) to be optimized. All regularization parameters of these methods are chosen from the range of P 1 by a nested 10-fold cross-validation on the training data. In the proposed MDTL frame, the weight v d of auxiliary classifier f A d x \u00f0 \u00de for MDTC is learned within a nested 10-fold cross-validation via a grid search in the range of 0 and 1 at a step size of 0.1, and adopted the SVM based linear kernel for training the target-domain and auxiliary-domain classifiers. Before training models, we normalized features following ."}, {"section_title": "Comparison between MDTL and Other Methods", "text": "To investigate the effectiveness of the proposed method, we compare the proposed method with several state-of-the-art methods. Table 2 shows the classification results achieved by six methods, including SVM (traditional SVM), Lasso, MTFS ), M2TFS (Jie et al. 2015) , and the proposed method (i.e., MDTL and MDTC). In Table 2 , the proposed 'MDTL' method first performs the MDTFS for feature selection and then adopts MDTC for classification, while the 'MDTC' method performs only MDTC for classification. Also, note that each value in Table 2 is the averaged result of the 10-fold cross validation, which was performed for ten different times. In addition, we plot the ROC curves achieved by these six methods in Fig. 3 .\nAs can be seen from Table 2 and Fig. 3 , for three binary classification problems, the proposed MDTL method consistently outperforms SVM, Lasso, MDTC, MTFS and M2TFS in terms of the classification accuracy, sensitivity, and AUC measures. We also perform DeLong's method (DeLong et al. 1988) on the AUC between the proposed method and each of other five competing methods, with the corresponding p-values shown in Table 2 . The DeLong's test is a nonparametric statistical test for comparing AUC between two ROC curves, which can be employed to assess statistical significance by computing z-scores for the AUC estimate (Robin et al. 2011; Sabuncu et al. 2015) . For both AD vs. NC and MCI vs. NC classification tasks, the proposed MDTL method consistently outperforms the competing methods in all classification measures. In pMCI vs. sMCI classification, the proposed MDTL method outperforms the competing methods except for the specificity. Also, in Fig. 3 , we can see from the ROC shown for pMCI vs. sMCI classification, which implies that the MDTL method can achieve better diagnostic performance in recognizing pMCI and sMCI patients than the competing methods. From the results in Table 2 and Fig. 3 , it is clear that the proposed MDTL method can effectively integrate information of target domain and multi-auxiliary domains, which can achieve more significant performance improvement than the methods that use samples only from the target domain for training.\nOn the other hand, in Table 2 and Fig. 3 , the proposed MDTC method consistently outperforms the SVM method in all classification measures for three binary classification problems. Also, there are slight differences of performance between the MDTC and Lasso method for three classification problems. These results imply that, compared with the case of only using SVM for performing classification, using MDTC can also improve the diagnostic performance, similar to the case of using the Lasso method for feature selection. We can see from Table 2 and Fig. 3 , Lasso, MTFS, M2TFS, and MDTL methods also outperform the SVM method in all classification measures for three classification problems, which suggest that using feature selection on the high-dimensional features before performing classification can effectively improve the classification performance. In addition, from Table 2 and Fig. 3 , MTFS, M2TFS, and MDTL methods can achieve better classification performance than the Lasso method, and the MDTL method also outperforms both the MTFS and M2TFS methods. These results also suggest that the inclusion of multi-auxiliary domains can improve the classification performance compared to the case of only using target domain, and that our proposed regularization factor based on multidomain weight vector is more suitable than the manifold regularization factor for the transfer learning problem.\nIn addition, there is an interesting observation from Table 2 and Fig. 3 . Specifically, different from conventional studies Coup\u00e9 et al. 2012; Da et al. 2014; Young et al. 2013 ), using pMCI and sMCI subjects as auxiliary domain can also help improve the performance of AD and NC classification. The main reason for this observation is that we proposed a regularizer (i.e., \u2211\n2 ) in step of MDTFS, which can use the weight vector from each of the multi-auxiliary domains to adjust the weight vector of target domain, and combine L 2 /L 1 -norm and L 1 /L 1 -norm regularizers to select features relevant to all domains (including self-domain), followed by using the MDTC based linear kernel SVM to keep these selected helpful features for classification. Furthermore, our proposed MDTFS model can also keep the target domain as the most important task in classification. Therefore, our proposed MDTL method can effectively use related multi-auxiliary domain data to improve the performance of target learning domain in early diagnosis of AD."}, {"section_title": "Comparison with MDTL and Other Variants", "text": "To investigate the relative contributions of the two components (i.e., MDTC and MDTFS) in our proposed method, we compare our method with its two variant methods. In Table 3 , we give the classification measures by our proposed MDTL method, its variant methods (MDTC and MDTFS), and SVM (as a baseline method). Note that the proposed 'MDTL' method first performs feature selection using MDTFS model and then adopts MDTC for classification (i.e., MDTFS + MDTC, while the 'MDTC' method only performs classification using the proposed MDTC model. The 'MDTFS' method first performs feature selection using MDTFS model and then adopts SVM for classification. In Fig. 4 , we also plot the ROC curves achieved by different methods. In addition, we also report the p-values, which are computed by DeLong's method (DeLong et al. 1988) on the AUC between the proposed method and its two variant methods, as well as baseline method, in Table 3. From  Table 3 to Fig. 4 , we can observe that each component can boost the classification performance compared with SVM method. However, using feature selection method (i.e., MDTFS) can achieve better improvement than the MDTC method for classification. In general, our proposed MDTL method that integrates all the two components together achieves the best performance."}, {"section_title": "Discriminative Brain Regions Detection", "text": "To evaluate the efficacy of our proposed multi-domain transfer feature selection (MDTFS) method in detecting the discriminative brain regions, we compare our proposed MDTFS method with the single-domain based feature selection method (i.e., Lasso) and the commonly used multi-domain based feature selection methods (i.e., MTFS and M2TFS). Table 4 shows the classification performances of four different methods, including Lasso, MTFS , M2TFS (Jie et al. 2015) , and the proposed MDTFS, using classification accuracy, sensitivity, specificity and AUC measures. In addition, we also compute p-values on the AUC between the MDTFS method and other three methods via DeLong's method (DeLong et al. 1988) , as also shown in Table 4 . It is worth noting that, for fair comparison, we use SVM on the target domain in the classification step for our method and competing methods. Also, each value in Table 4 is the averaged result of 10-fold cross-validation strategy in 10 independent runs. As shown in Table 4 , MDTFS, MTFS and M2TFS methods can achieve better classification performance than the Lasso method. The possible Furthermore, we also investigate the most discriminative regions identified by the proposed feature selection method. Since the feature selection in each fold was performed only based on the training set, the selected features could vary across different cross-validations. We thus defined the most discriminative brain regions based on the selected frequency of each region over the cross-validations. In Fig. 5 , for three classification problems, we list all selected brain regions with the highest frequency of occurrence (i.e., each feature and selected across all folds and all runs) by MDTL (i.e., MDTFS + MDTC) on template MR image. As can be seen from Fig. 5 , our proposed MDTL method successfully finds out the most discriminative brain regions (e.g., amygdala, hippocampal formation, entorhinal cortex, temporal pole, uncus, perirhinal cortex, cunecus, and temporal pole) that are known to be related to Alzheimer's disease Eskildsen et al. 2013; Jie et al. 2015; Ye et al. 2012; Zhang et al. 2012; Zhu et al. 2014 )."}, {"section_title": "Discussion", "text": "In this paper, we propose a multi-domain transfer learning (MDTL) method for early diagnosis of AD, in which we combine the data from multi-auxiliary domains and target domain in both feature selection and classification steps. We evaluate the performance of our method on 807 subjects from the publicly available ADNI database and compare our method with the state-of-the-art methods. The experimental results show that the proposed method consistently and substantially improved the performance of early diagnosis of AD."}, {"section_title": "Learning with Multi-Domain Data", "text": "In the field of neuroimaging-based early diagnosis of AD, multimodal biomarker is widely used for the model design of feature selection and classification (Cheng et al. 2015a; Cheng et al. 2015b; Hinrichs et al. 2011; Jie et al. 2015; Liu et al. 2014; Suk et al. 2014; Ye et al. 2012; Zhang et al. 2012; Zhu et al. 2014) , which can achieve better performance than the case of using single-modal biomarker. However, in clinical practice, the collection of multimodal biomarker from subject is expensive and time-consuming, and hence the size of collected complete multimodal biomarker dataset is often small. On the other hand, it is relatively easy to get more single-modal biomarker data (e.g., MRI) that contain different categories of subjects. Because of the characteristic of AD cohorts and the requirement of the clinical diagnosis of AD, these single modal data are classified as multiple learning domains that are related to each other. Some studies also show the effectiveness of transfer learning or semi-supervised learning technique in combining these data from related learning domains Da et al. 2014; Filipovych et al. 2011; Young et al. 2013; . However, auxiliary data from a single related learning domain is often used in the aforementioned studies. In this paper, we developed MDTL method to enhance the generalization and accuracy of To integrate these data with multiple categories of subjects, the transfer learning can be used to build the learning model as done in our previous works (Cheng et al. 2015a; Cheng et al. 2015b; Cheng et al. 2012) . However, in our previous works, we only adopted a single related domain data as auxiliary domain to help design classification model for MCI conversion prediction. For example, in our work (Cheng et al. 2015b) , we gave an explanation that the domain of classifying pMCI and sMCI subjects was related to the domain of classifying AD and NC subjects, but it was only used for MCI (a) AD vs. NC (b) MCI vs. NC (c) pMCI vs. sMCI Fig. 5 The most discriminative brain regions identified by the proposed MDTL method for three classification tasks. Note that different colors indicate different brain regions Table 5 Comparison of our proposed method (MDTL), SDTL1, SDTL2, and Lasso methods in three binary classification problems. The 'SDTL1' is the MDTL method using one auxiliary domain data, which actually is the first one in the auxiliary domains of Table 1 . The 'SDTL2' is the MDTL method using one auxiliary domain data, which is the second one in the auxiliary domains of conversion prediction. According to the pathology of AD and its progression, we extended our previous work (Cheng et al. 2015b) , by assuming that the classification problem in the target domain is related to each classification problem in the auxiliary domains. To validate this assumption, we have listed results of our proposed method (MDTL), as well as SDTL1, SDTL2, and Lasso methods, in Table 5 . For purpose of comparison, we used the Lasso as a baseline method. Also, SDTL1 and SDTL2 methods are the variants of our proposed MDTL method performed on single auxiliary domain and target domain. As we can see from Table 5 , using multiauxiliary domain data in the MDTL method can achieve better performance than using single auxiliary domain data in both SDTL1 and SDTL2 methods, and the baseline method (i.e., Lasso) is inferior to MDTL, SDTL1 and SDTL2 methods. These results make it clear that the use of multi-auxiliary domain can effectively improve the performance of early diagnosis of AD."}, {"section_title": "Multi-Domain Transfer Learning Model", "text": "To effectively integrate the domain knowledge between target domain and multi-auxiliary domain, we introduced the regularizer based on weight vector (i.e., \u2211\n2 ), which can keep the similarity of multi-weight vectors between target domain and each auxiliary domain. In addition, we introduced two regularizations of weight matrix for all domains (i.e., \u2016W\u2016 1 , 1 and \u2016W\u2016 2 , 1 ) simultaneously, which can select a common feature subset relevant to all domains and also keep useful features relevant to self-domain. In this paper, we combined the three regularizers for feature selection from targetdomain and multi-auxiliary-domain data, namely MultiDomain Transfer Feature Selection (MDTFS). To evaluate the efficacy of each regularizer, we performed some experiments for testing the contribution of each regularizer. In Table 6 , we give results of the proposed MDTL method for three classification problems using different setting of regularization parameters.\nIn the MDTFS model, the regularization parameters (i.e., \u03bb 1 , \u03bb 2 , \u03bb 3 ) can control the relative contribution of the three regularizers. In Table 6 , we investigate the contribution of each regularizer by setting the respective parameter to zero. For example, we set the regularization parameter \u03bb 1 to zero (i.e., \u03bb 1 = 0), which is used for evaluating contribution of the first regularizer. As can be seen from Table 6 , combining three regularizers (i.e., \u03bb 1 , \u03bb 2 , \u03bb 3 \u2260 0) can achieve better performance for early diagnosis of AD. Specifically, for three classification problems, the minimum reduction of classification performance is without use of the second regularizer (i.e., \u03bb 2 = 0), while the reduction of classification performance is small compared to the case without using the first regularizer (i.e., \u03bb 1 = 0) and the case without the third regularizer (i.e., \u03bb 3 = 0). These results suggest the importance of selecting the common feature subset relevant to all domains and keeping the similarity of weight vectors between target domain and each auxiliary domain, which also confirms the efficacy of using multi-auxiliary domain data."}, {"section_title": "Strategy for Selecting Feature Subset", "text": "Recently, many studies in early diagnosis of AD focus on designing feature selection methods to overcome the smallsample-size problem in neuroimaging data analysis (Cheng et al. 2015b; Li et al. 2014; Liu et al. 2014; Moradi et al. 2015; Ota et al. 2015; Ye et al. 2012; Zhu et al. 2014) . In this paper, we develop a multi-domain transfer learning (MDTL) method that can simultaneously utilize approaches of related multi-domain data and feature selection to improve generalization ability of classifiers.\nIn the MDTL framework, the multi-domain transfer feature selection (MDTFS) is developed, which can use the optimal weight matrix W to select informative feature subset. Since we use the regularizer of \u2016W\u2016 1 , 1 in the MDTFS step, the selected features from each domain are different. For simplicity, in the current work, we select the same feature subset for each auxiliary domain as the target domain (i.e., Strategy1 in Table 7 ). Actually, we should consider the target domain more than the auxiliary domains in classification task.\nTo validate the above assumption, we also adopt another strategy for selecting feature subset, i.e., keeping just features with non-zero weights from each column weight vector of W for all domains (i.e., Strategy2 in Table 7 ). In Table 7 , we list classification results obtained by two different strategies. As we can see from Table 7 , the MDTL method using Strategy2 for feature subset selection can achieve slight improvement, compared with the case of using Strategy1. Generally, it is believed that using Strategy2 should be more effective than using Strategy1; but, when using the DeLong's test (DeLong et al. 1988) to assess the statistical difference between AUC values of two strategies, we found no statistical difference between these two strategies.\nTo further investigate the difference of using these two strategies, we do a statistical analysis on selected features of each domain. Specifically, we count the number of features selected across all folds and all runs (i.e., a total of 100 times for 10-fold cross-validation with 10 independent runs) on the training set. Then, those features with frequency of 100 (i.e., always selected in all folds and all runs) are regarded as stable features. Accordingly, we compute the average percentage of stable features in the target domain and also those stable features in each auxiliary domain, using MDTL method with the Strategy2 for selecting feature subset. For AD vs. NC, MCI vs. NC and pMCI vs. sMCI classification tasks, their corresponding mean ratios are 83 %, 88 % and 92 %. Similarly, we adopt the Strategy1 to select feature subset, and obtained the results that are slightly inferior to the case of the Strategy2. This implies that the target domain plays a critical role in the classification performance, compared with the auxiliary domain."}, {"section_title": "Comparison with Previous Methods", "text": "To further evaluate the efficacy of our proposed multi-domain transfer learning (MDTL) method for early diagnosis of AD, we list a comparison between the MDTL and some representative state-of-the-art methods in the recent 5 years (Cho et al. 2012; Coup\u00e9 et al. 2012; Cuingnet et al. 2011; Duchesne and Mouiha 2011; Eskildsen et al. 2013; Hu et al. 2016; Khedher et al. 2015; Liu et al. 2014; Moradi et al. 2015; Ota et al. 2015; Westman et al. 2013; Wolz et al. 2011; Zhu et al. 2014) , and show them in Table 8 . Here, we provide two performance measurements (i.e., ACC: Accuracy; and AUC: Area Under the receiver operating characteristic Curve) in Table 8 . Since it is not available the ACC and AUC from the paper of Cuingnet et al. 2011, we just list measurements of sensitivity (SEN) and specificity (SPE). Note that, in Table 8 , for several studies using multimodal biomarker Zhu et al. 2014) , we report their results using only MRI data if available; otherwise, we report their results using multimodal data. Although feature extraction method is different for the comparison methods, this comparison also can show the efficacy of MDTL method at certain level. In most cases, the AUC and ACC of MDTL method are better than those of the comparison methods, indicating that MDTL has better diagnostic performance in early diagnosis of AD. "}, {"section_title": "Limitations", "text": "The current study is limited by several factors. First, our proposed method is based on the single modal (i.e., MRI) biomarker from the ADNI database. In the ADNI database, many subjects also have multimodal biomarkers. Also, many statusunlabeled subjects can be used to extend our current method.\nIn the future work, we will investigate whether adding more auxiliary domain (e.g., multimodal biomarker, and statusunlabeled data) can further improve the performance. Second, considering the small number of training samples, as well as the sensitivity of those very local features (i.e., thickness, and tissue density) to noises as well as errors in processing pipeline (including skull stripping, tissue segmentation, image registration, and regions-of-interest (ROI) labeling), our current study considers only using ROI features, and no surface-based cortical thickness features are extracted and used although some studies already show the sensitivity of cortical thickness in early diagnosis of AD (Cho et al. 2012; Cuingnet et al. 2011; Eskildsen et al. 2013; Querbes et al. 2009; Wee et al. 2013; Wolz et al. 2011 ). In the future work, we will consider extracting cortical thickness features from MR images and combine with volume-based features for early diagnosis of AD.\nFinally, due to the small number of training samples, we adopted only the volume of gray matter (GM) tissue in each ROI as a feature and input the MDTL model for early diagnosis of AD. However, the study of Cuingnet et al. (Cuingnet et al. 2011) showed that other tissue volumetric feature (i.e., white matter (WM) and CSF) also contributed to AD and NC classification. Accordingly, we also used all types of volumetric features (i.e., GM + WM + CSF) to test the classification performance of our proposed MDTL model, by comparison with the MDTL model using only the GM features. In Table 9 , we list their respective ACC and AUC, and further perform the DeLong's test (DeLong et al. 1988) on the AUC to test their statistical difference, with p-values provided. The results in Table 9 suggest that using three types of volumetric features can improve the performance, but the corresponding p-values show no statistical significant improvement by using three types of volumetric features. In future work, we will improve the MDTL model and combine with the improvement of neuroimaging pre-processing pipeline to enhance the final classification results."}, {"section_title": "Conclusion", "text": "In this paper, we propose a novel multi-domain transfer learning (MDTL) method for early diagnosis of AD, which consists of multi-domain transfer feature selection (MDTFS) and multi-domain transfer classifier (MDTC). The main idea of our multi-domain transfer learning based method is to exploit the multi-auxiliary domain data to improve classification performance (e.g., AD vs. NC, MCI vs. NC and pMCI vs. sMCI) in the target domain. Also, we further combine the source data from multi-auxiliary domain and target domain to guide both feature selection and classification steps. We evaluate our method on the baseline ADNI database with MRI data, and the experimental results demonstrate the efficacy of our method by comparison with several state-of-the-art methods."}, {"section_title": "Information Sharing Statement", "text": "The dataset used in this paper are from the Alzheimer's D i s e a s e N e u r o i m a g i n g I n i t i a t i v e (ADNI, RRID:SCR_003007) which are available at http://adni.loni.usc.edu/. Source code and binary programs developed in this paper are available via our website (http://ibrain.nuaa.edu.cn/, RRID:SCR_014691), and also via email, cb729@nuaa.edu.cn."}]