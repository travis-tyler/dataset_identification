[{"section_title": "Abstract", "text": "Abstract-Detection and segmentation of the hippocampal structures in volumetric brain images is a challenging problem in the area of medical imaging. In this paper, we propose a two-stage 3D fully convolutional neural network that efficiently detects and segments the hippocampal structures. In particular, our approach first localizes the hippocampus from the whole volumetric image and obtains a rough segmentation. This initial segmentation can be used an enhancement mask to extract the fine structure of the hippocampus. The proposed method has been evaluated on a public dataset and compared with state-ofthe-art approaches. Results indicate the effectiveness of the proposed method, which yields mean Dice Similarity Coefficients (i.e. DSC) of 0.897 and 0.900 for the left and right hippocampus, respectively. Furthermore, extensive experiments manifest that the proposed enhancement mask layer has remarkable benefits for accelerating training process and obtaining more accurate segmentation results."}, {"section_title": "I. INTRODUCTION", "text": "With pervasive applications of medical imaging, biological structure detection and segmentation have been fundamental and crucial tasks in biomedical imaging research. It extracts different tissues, organs, pathologies and biological structures, to support medical diagnosis surgical planning and treatments. In clinical practice, the detection and segmentation are performed manually by pathologists, which is time-consuming and tedious. The ever-increasing variety of medical images make manual segmentation impracticable in terms of cost and reproducibility. Thus, automatic biomedical detection and segmentation are highly desirable. However, this task is extremely challenging, because of the heterogeneous of biological objects including the large variability in location, size, shape and frequency, and also because of low contrast, noise and other imaging artifacts caused by various medical imaging moralities and techniques. [1] In the past years, substantial progress has been made in biomedical image detection and segmentation with pixelbased methods [2] - [5] and structure-based methods [6] - [9] . In recent years, the fully convolutional networks (FCNs [10] ), * Corresponding author: Wenxi Liu. This work is supported by National Natural Science Foundation of China (NSFC) under grant 61473089 and 61702104 and by Natural Science Foundation of Fujian Province under grant 2016J05155.\nhave been used for biomedical image segmentation, which require little hand-crafted features or prior knowledge. FCNs trained end-to-end have been previously applied to 2D images both in computer vision [11] and microscopy image analysis [12] . These models are trained to predict a segmentation mask, delineating the structures of interest, from the whole image. Ronneberger et al. [12] proposed U-Net, a deep convolutional network that adds skip connections to the symmetric feature maps to perform 2D medical image segmentation. With data augmentation, it achieves significant improvement over previous methods. Recently, this approach was extended to 3D and applied to segmentation of volumetric data acquired from a confocal microscope [13] . With the inspiration of these models, Fausto et al. [1] divided model into stages that learn residuals and as empirically observed improve both results and convergence time. However, due to the heavy computational burden of 3D convolutional operation and a large number of uncertain parameters, it is formidable to devise extremely deeper 3D neural network which inherits more hidden features. Furthermore, with the limitation of hardware devices, the prior methods have to downsample the high resolution medical image before feeding into networks, which gives rise to the loss of segmentation accuracy.\nTo handle the problems mentioned above, we present a novel two-stage 3D fully convolutional neural network, for detecting and segmenting biomedical objects from volumetric medical images, e.g. MRI. Our approach not only reduces the computational burden of 3D FCN, but also preserves the segmentation details. In particular, our model first learns the localization and segmentation context of the biomedical objects from the low resolution input and then integrate it with the original input by an enhancement mask that performs the fine structure segmentation. We experiment the proposed approach on a hippocampus segmentation dataset (ADNI) and achieve state-of-the-art results. Contributions: We present a two-stage 3D fully convolutional neural network that efficiently detects and then segments the hippocampal structure from volumetric brain MR images. Our framework first learns the holistic structural information from the downsampled input image, which localizes the hippocampus, while roughly estimating the segmentation through a proposal network. In the second 978-1-5386-8069-8/18//$31.00 \u00a92018 IEEE Proceeding of the IEEE International Conference on Information and Automation Wuyi Mountain, China, August 2018 Fig. 1 . Our framework consists of two-stage networks. In the first stage, the input data (i.e. the orange cube) is downsampled and fed into a 3D fully convolutional neural network, called Proposal Network which learns a holistic probability map. An enhancement mask will be generated from this probability map. The enhancement mask will be applied to the original data. We will crop a 64 \u00d7 64 \u00d7 64 cube according to hippocampus localization from the enhancement data as the input of Segmentation Network. Hence, the Segmentation network outputs the fine segmentation result of the cropped data.\nstage, we introduce an enhancement mask that integrates the rough segmentation proposal in a segmentation network to perform fine segmentation."}, {"section_title": "II. THE PROPOSED METHOD", "text": "In this paper, we propose a two-stage framework to detect the hippocampus from the volumetric brain images and then apply segmentation to the enhanced original image data through the enhancement mask layer. Our proposed framework can fully exploit the holistic information of the volumetric data and also efficiently perform the segmentation while preserving the fine structure of the hippocampus. Specifically, in the first stage (Proposal Network), the hippocampus is localized from the downsampled input volumetric data while a rough segmentation proposal of the hippocampus is learned with a 3D FCN. In the second stage (Segmentation Network), the original input data is enhanced through the enhancement mask which generates from Proposal Network and then cropped. We will introduce these two stages in the following subsections."}, {"section_title": "A. Proposal Network and Localizing Hippocampus", "text": "In our application, each image consists of several slices with the resolution of 256 \u00d7 256 (pixels) and the numbers of slices range from 166 to 256. Processing the original volumetric data requires a large amount of memory on the runtime. However, the holistic view of the volumetric data provide the crucial context to localize and segment the hippocampus. To fully exploit the holistic information of the input volumetric data, we build up Proposal Network to estimate the segmentation of the hippocampus. The architecture of Proposal Network is an encoder-decoder, which learns a probability map about pixelwise. As shown in Fig.1 , Proposal Network first compress the input data via multiple convolutional layers into feature maps with smaller resolutions, and then perform decompression by upsampling the feature maps layer-by-layer via de-convolution and combining with corresponding compressed feature maps respectively by skipconnection. The output of the network is the response of the segmented hippocampus which performs the pixelwise estimation on whether it belongs to the hippocampus.\nTo learn the holistic information, the original input data X is downsampled to 64 \u00d7 64 \u00d7 128 and fed into Proposal Network F. At the end, the output response map is upsampled to the original size using 3D bilinear interpolation sampling technique. The whole procedure is denoted as F(X) \u2208 R W \u00d7H\u00d7D . Intuitively, in the proposal network, learning the segmentation response from the downsampled low-resolution data actually enlarges the receptive field to cover the entire volumetric image. Although the accuracy of the segmentation at this stage is not satisfactory, the output response provides the crucial context for localizing the hippocampus whose volume is much smaller compared to the whole brain, and the rough segmentation results still make a vital improvement on further image segmentation through the enhancement mask which is generated from itself. Furthermore, since the whole image data is fed into Proposal Network, it makes the detection can be extended to other segmentation problems. Localizing Hippocampus Before the segmentation, we need to localize the hippocampus in advance. In essence, the proposal response F(X) indicates the probability of whether the hippocampus shows up in each voxel. We denote it as L proposal for clarity. The goal is to calculate the central coordinate of the hippocampus from L proposal . Instead of using sliding window or clustering, we accumulate the voxel value of L proposal which is a tensor with the size of W \u00d7 H \u00d7 D along the X, Y, and Z axis respectively. Taking the X axis for instance, the accumulation is computed as follows:\nis larger than a certain threshold , it indicates the occurrence of the hippocampus at the i th slice along the X axis. Empirically, we set as 5 and it can effectively and efficiently filter out the false alarm in L proposal . Hence, we can compute the boundary coordinates by:\nThe central coordinate of localizing the hippocampus is computed:\nare the maximum and minimum coordinates along all axes."}, {"section_title": "B. Enhancement Mask Layer and Segmentation Network", "text": "Enhancement Mask Layer The enhancement mask M is generated from the rough segmentation results of Proposal Network by the following formulation:\nwhere the L proposal contains the holistic and reliable information which regard to the location of the hippocampus, but the details of its 3D structure is blurred due to resizing which needs to be compensated by the original data C original . Both \u03b1, \u03b2 are the parameters which control the influence of the enhancement mask on the original image data. It is obviously that the bigger \u03b1 and smaller \u03b2 will cause a stronger influence of enhancement mask. As for L proposal is 0/1 label value, we set \u03b2 as 1 which respects for that we do not apply any enhance or suppress operation on the original background image data. The value of \u03b1 is relatively flexible, and different \u03b1 value will cause a significant different performance on the segmentation networks. A detail analysis on how to select a suitable \u03b1 value will be shown in next section. Segmentation Network In order to preserve the detailed structure of the hippocampus in segmentation, it is common practice to empirically crop a portion of voxels from the original volumetric image and then infer the segmentation based on this cropped volume. Although such cropping operation keeps the nearing-range context around the hippocampus while reducing the computation burden, it abandons most of the long-range dependent spatial information in the whole brain structure, which bounds the segmentation performance. What's worse, the empirically cropping operation does not guarantee for dealing with the data error caused by medical instrument malfunction, and we have to adapt the crop localization according to different objects which is quietly inconvenient in practice. To introduce the holistic view of the original input data, we need to incorporate the previously inferred enhancement mask M that contains the holistic information with the original data as follows:\nwhere X (X \u2208 R w\u00d7h\u00d7d ) is the enhanced input data that will be fed into the segmentation network and denotes the dot-product operator.\nThen we crop a volume with the size of h \u00d7 w \u00d7 d that covers the target region and centering at V center .\nGiven the estimated location of the hippocampus, we also need to incorporate the holistic information to the cropped data before feeding into the segmentation network. We denote the cropped h \u00d7 w \u00d7 d volume centered at v center of the probability map F(X) as C proposal = Crop(F(X), v center ). We also crop a volume from the exact same region of the original input 3D data X, which is denoted as C original = Crop(X, v center ).\nOn one hand, the proposal serves as the attention mask to enhance the likely regions of the hippocampus localization to guide the segmentation. On the other hand, adding bias to the proposal prevent from the information loss, since it does not completely depress the regions with low responses in proposal. Intuitively, the proposal with low responses may still be part of the hippocampus. The experiments show that the proposal-enhanced data actually boosts the estimation accuracy and speeds up the convergence rate of training the fully convolutional neural network.\nIn the end, the enhanced input X is fed into another network that has the same architecture as the proposal network, to create the fine segmentation result."}, {"section_title": "C. Training Loss", "text": "The network is trained by Dice Loss. The variable Dice Loss D between two binary segmentation volumes P and G is the same as [1] , written as\nwhere the sums run over the N voxels, of the predicted binary segmentation volume p i \u2208 P and the ground truth binary volume g i \u2208 G."}, {"section_title": "III. EXPERIMENTAL A. Datasets", "text": "Described in this section are several experiments conducted to evaluate the performance of our method for hippocampus segmentation using the publicly available ADNI database 1 . The size of the voxels of the image is 1 \u00d7 1 \u00d7 1mm 3 . Each image consists of several slices with the resolution of 256 \u00d7 256 (pixels) and the numbers of slices range from 166 to 256. We utilized 110 normal control subjects, and downloaded their baseline T1-weighted whole brain MRI images along with their hippocampus masks. We train our network using ten-fold cross validations."}, {"section_title": "B. Implementation details", "text": "Proposal Network has the identical structure and parameter settings as Segmentation Network despite the different input image size. Each convolution and de-convolution layer has a 3\u00d73\u00d73 kernel size, and each downsampling and upsampling convolution layer has a 2 \u00d7 2 \u00d7 2 kernel size. At each block of convolutional layer, the output size is half down and the number of output channel is double. At each block of de-convolutional layer, the output size is double and the output channel is half down on the contrary. The input data of Proposal Network is the resized image, while the other is cropped-masked image. The different weight \u03b1 and bias \u03b2 will cause significantly different performance for segmentation network. Empirically, we set \u03b2 as 1 which means the original data will not be suppressed or impressed by \u03b2. In other words, dot production with the mask ranging from zero to one will degrade the data. Our mask will preserve the original object details. The value of \u03b1 determines the influence of the mask which gained from the proposal network. As for that the output of the proposal network is not good enough, the value of \u03b1 should be well designed. In order to explore the optimal weight, we compare different weights in Sec. III-D."}, {"section_title": "C. Evaluations Metric", "text": "To quantitatively evaluate the proposed method, four metrics were used for performance evaluation. The degree of overlap was measured for two ROIs V s and V g , where V s and V g are the sets of object(hippocampus) voxels automatically segmented by the segmentation method and manually segmented by clinical expert, respectively.\n\u2022 Dice similarity coefficient (DSC) is a comprehensive similarity metric that measures the degree of overlap of two ROIs\nwhere | | is the cardinality of a set.\n\u2022 Jaccard similarity coefficient (JSC), which is a statistic used for comparing the similarity and diversity of two ROIs, is described as follows:\nis the ratio between the overlap of two ROIs and the ROI manually segmented by clinical expert, as follows:\nis the ratio between the overlap of two ROIs and the ROI segmented by the segmentation method, as follows:\nA larger value of all the metric mentioned above indicate a better segmentation performance."}, {"section_title": "D. Selecting weights for enhancement mask", "text": "To select optimal value of weights for the mask, we need to analyze the effects of the weight \u03b1 in training and testing in the first place.\nTo do so, we assign different values to \u03b1, i.e., 0, 0.1, 0.3, 1.0. We first evaluate how the weight influences the training process. We illustrate the training loss (i.e. Dice Loss) in the first 250 epochs with different values of \u03b1. According to Fig. 2 , as \u03b1 = 0.1, the training loss drops quickly. With \u03b1 = 0.3 and 1.0, the loss also decreases quickly but their curves are not stable. Comparably, without mask (i.e. \u03b1 = 0), the training appears to be slow. It indicates that using the enhancement mask will easily speed up the training, but it may also have the chance to make the training unstable. Besides, we also evaluate the same models with different \u03b1 in the validation dataset. Their performance is measured using DSC as shown in Fig. 3 . Similar to the observation above, the model with \u03b1 = 0.1 has the optimal performance in testing. With \u03b1 = 0.3 and 1.0, the DSC curves are unstable. To sum up, \u03b1 lets the mask have more impact on the input data, which speeds up the training and enhance the performance of the model. However, too large weights may also cause the overfitting of the trained models. Among these weights, \u03b1 = 0.1 allows the mask to shed some light on the segmentation without jeopardizing the training model. Hence, in the following experiments, we choose \u03b1 = 0.1 as the weight of the enhancement mask."}, {"section_title": "E. Ablation study", "text": "To demonstrate the effect of the mask, we perform comprehensive experiments. First, as shown in Fig. 4 , we compare the DSC for the models with and without enhancement mask after training for 10, 000 iterations and evaluate their segmentation performance every 500 iterations in the validation dataset. It illustrates that the model with mask achieves We evaluate these variants to analyze how the proposal network and the segmentation network affect each other. Observing columns in Tab. I, using better proposal network with the same segmentation network may lead to a boost of the performance, especially combining with better segmentation network. It turns out the proposal indeed makes contributions in the segmentation. Another fact is that the model can achieve satisfactory performance without fully trained proposal network. For instance, after training the proposal network for only 1500 epochs, the model can reach more than 0.86 accuracy in DSC that is comparable to the state-of-the-art approaches. This is another benefit of the enhancement mask, which give our confidence for reducing the training iterations of Proposal Network to less than 1000. Finally, we evaluate the proposal network with the segmentation networks with and without mask in the validation dataset. As we observe in Fig. 5 , the proposal network has only 0.810 accuracy in DSC and the segmentation network without mask gain 0.863. The model with the enhancement mask performs better than them with 0.897. As an example shown in Fig. 6 , the first figure shows the manual labeled hippocampus. The second figure shows the output proposal of the proposal network with the original resolution. It correctly localizes the hippocampus, but it is difficult to discriminate the structural details. The last two figures visualize the hippocampus segmentation with and without mask. As illustrated in the area pointed by the red arrow, the result generated by the model with mask has fewer artifacts and more accurate segmentation in the tail of the hippocampus."}, {"section_title": "F. Quantitative comparison", "text": "In this experiment, we adopt 10-fold cross-validation strategy to evaluate the segmentation of the left and the right hippocampus respectively. For comparison purposes, the conventional patch-based method by non-local weighting (Nonlocal-PBM) [14] , the recently proposed sparse patchbased labeling (Sparse-PBM) [15] and Path-Based Label Fusion (PBLF) [16] are evaluated on the samples collected on ADNI dataset.\nWe compare the proposed model with these methods and evaluate on four metrics as shown in Tab. II. According to the Fig. 6 . Hippocampal detection and segmentation results by our method. first: the manual segmentation hippocampal structure. second: the results of our Proposal Network. third: the segmentation of the hippocampal structure without enhancement mask. fourth: the segmentation of the hippocampal structure with enhancement mask. quantitative comparison, our approach generally outperforms other methods with the obvious advantages in the metrics DSC and JSC."}, {"section_title": "IV. CONCLUSION AND FUTURE WORK", "text": "In this work, we proposed a two-stage hippocampus detection and segmentation framework based on 3D fully convolutional neural network, and we further improve the segmentation performance by introducing an enhancement mask. Our experiments demonstrate that the enhancement mask generated from Proposal Network speeds up the convergence of the training process and achieves significant improvements by concatenating with Segmentation Network. Furthermore, our model can be easily extended to other biological tissue or organ detection and segmentation problems. As the future work, the two-stage neural network can be upgraded to an end-to-end trainable model, and the optimal value of parameters \u03b1 and \u03b2 can also be learned from data."}]