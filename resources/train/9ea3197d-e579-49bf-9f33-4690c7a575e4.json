[{"section_title": "", "text": "Number of teachers and percentage distribution of teachers by teacher status, by sector and selected school and teacher characteristics: 1987-88 2 Number of newly hired, first-time teachers and percentage distribution of newly hired, first-time teachers by previous year's main activity, by sector and selected school and teacher characteristics:   "}, {"section_title": "Introduction", "text": "Determining who is teaching our nation's youth and whether or not there will be enough well-trained teachers to meet the demand during the next decade are matters of utmost importance to educators, parents, policymakers, and others interested in educational issues. During the 1980s, as more children of the \"baby boom\" generation entered the school system and fewer college graduates chose teaching as a career, many feared that there would not be enough teachers for these children and that those who taught would be poorly prepared for their task) Moreover, many worried that students would suffer due to increased class sizes and would be taught by teachers who knew little about their subject matter or pedagogy, resulting in lower student achievement and motivation, and ultimately, in lower intellectual, vocatic sal, and civic abilities.2 These concerns prompted a flurry of studies on the supply and demand of teach( rs confirming that fewer and less qualified college graduates were choosing to teach, and spurred new data collection efforts at the national and state level to better monitor these trends.3 More recent state-level research by Grissmer and Kirby suggests that teacher attrition is actually at its lowest point in years due to a maturing, stable teaching force and a drop in attrition rates among new teachers and women. However, attrition rates still vary among types of teachers, and while a massive shortage may not be likely in the next 10 years, many changes in the teaching force could occur as the current cohort of teachers begins to retire.4 Consequently, continuing efforts are needed to identify and predict changes in the components of teacher supply and demand. The 1987-88 Schools and Staffing Survey (SASS), conducted by the National Center for Education Statistics (NCES), significantly increases the data available on teacher supply and demand. In fact, an entire questionnaire (Teacher Demand and Shortage) was distributed to public districts and private schools to collect information on various aspects of teacher supply and demand. Also, the Teacher Followup Survey (TFS), conducted 1 year after the SASS, focuses on why teachers leave the profession, and permits comparisons between teachers who stay in teaching and those who leave. The purposes of this study were to 1) summarize the important issues related to teacher supply and demand; 2) present descriptive statistics on those aspects of supply and demand that can be addressed with SASS and TFS; and 3) develop and test multivariate models to identify the teacher, school, and district characteristics most closely related to staying in and leaving teaching. The tables with descriptive statistics were designed to help identify variables for the multivariate analysis."}, {"section_title": "Chapter 2 Teacher Supply and Demand", "text": "Estimates of teacher supply and demand have been developed for the nation as a whole, for states, and for smaller entities,6 using different methods, depending upon available data. However, there are overall theoretical models of teacher supply and demand that guide all studies in principle, even though it is not always possible to estimate them with existing data. The Schools and Staffing Survey was developed to collect data on many components of these models. While supply and demand are discussed separately here, they are closely interrelated. The same demographic, policy, social, and economic trends drive not only the components of teacher demandstudent enrollments, class sizes, and teacher attritionbut also the determinants of teacher supplythe number of available continuing and prospective teachers and the attractiveness of teaching jobs. In addition, even though one could theoretically be higher than the other, the numbers of teachers demanded and supplied usually appear to balance out within schools. Shortages or surpluses are not often apparent numerically, because school districts do not allow classes of students to meet without teachers, and they do not assign teachers to classes without students. Instead, accommodations are made in class sizes, offerings, or in the qualifications of teachers hired for the available jobs, which are often used as indicators of shortages or surpluses of teachers."}, {"section_title": "Teacher Supply", "text": "There are four sources of teachers in any given year:7 i) continuing teachers, or stayers (those who are teaching in the same school as the previous year); 2) immigrant teachers, or movers (those who have moved from outside the local hiring level, which, depending on the level of the analysis, could be an academic subject, school, district, state, or nation); 3) new, firsttime teachers (new teacher education graduates or others who have never taught); and 4) reentrants (former teachers who were not teaching in the previous year). Equation (1) expresses the supply of teachers in the year t. T(t) = C(t) + I(t) + N(t) + R(t); ( 1) where: T (t) = Teachers this year, C (t) = Continuing teachers (stayers), I (t) = Immigrants (movers), N(t) = New (first-time) teachers: recent teacher education or other college graduates and others who have never taught, and R(t) = Re-entrants (former teachers). 'This discussion is based on the following sources, which can be consulted for more detailed information: Haggstrom, Darling-Hammond, and Grissmer; and Stephen M. Barro, \"Models for Projecting Teacher Supply, Demand, and Quality: An Assessment of the State of the Art,\" in Teacher Supply, Demand, and Quality: Policy Issues, Models, and Data Bases (Washington, D.C.: National Academy Press, 1992). 7Haggstrom, and Grissmer,[54][55] For this analysis, immigrants (movers' were those who were teaching in a different school the previous year. During the 1987-88 school year, 89 percent of public school teachers were continuing teachers, 6 percent were movers, 2 percent were new teachers, and 3 percent were reentrants (table 1). Among private school teachers, 82 percent were continuing teachers, 8 percent were movers, 6 percent were new teachers, and 5 percent were re-entrants. Continuing and immigrant teachers are drawn from a clearly designated segment of the labor forcethose who are currently teaching. First-time and re-entrant teachers, on the other hand, can come from a number of different sources. For example, in 1987-88, 61 percent of the 63,000 newly hired first-time teachers in the United States attended college the year before, 20 percent worked in non-teaching jobs, and 4 percent were homemakers. The rest were unemployed or in the military or their status was unknown (table 2). Of the 65,000 newly hired re-entrant teachers, 31 percent worked in non-teaching jobs, 26 percent were homemakers, and 12 percent attended college. The rest were unemployed or in the military or their status was unknown (table 3). First-time and re-entrant teachers come from different educational backgrounds as well as different previous activities. For example, 39 percent of re-entrant newly hired public school teachers had a master's degree as their highest degree earned, compared with 8 percent of newly hired first-time public school teachers (table 4). The corresponding percentages for private school teachers were 19 percent and 8 percent. After determining the proportion and training of the current teachers who come from each source, the next step is to determine the proportion from each source who are likely to become teachers in the future. As Barro points out, there are several reasons why information on the source of current teachers is not a sufficient indicator of the potentially available teachers from each source. First, there may have been more applicants than hires from any one source. Second, there may have been potential teachers from each source who did not apply, but might have applied under different conditions (if salaries had been higher, for example). Estimating the number of teachers potentially available from each source requires knowing _he size of the population who could teach (continuing teachers, new teacher education graduates, other qualified college graduates, former teachers, and so on.), the proportion of this population who want to teach, and the proportion who would apply for a teaching position under current conditions.8 SASS and TFS data can be used to estimate the proportion of current teachers who were continuing teachers (stayers) or immigrant teachers (movers) between 1987-88 and 1988-89, and what proportion left teaching (leavers) (table 5). In addition, the Recent College Graduates Study (RCG) can be used to estimate the proportions of recent teacher education and other college graduates who became first-time teachers. Among 1985-86 bachelor's degree recipients, 11 percent were newly qualified teachers, and 61 percent of them taught in 1987 (table 6). However, estimating the proportions of other first-time teachers and of re-entrants from their source populations is not currently possible.9 The rest of this section discusses how information can be used to partially predict the future supply of teachers from the available sources, and presents the limitations of these predictions. 8Stephen M. Barro, The State of the Art in Projecting Teacher Supply and Demand, unpublished report prepared for the NAS Panel on Supply and Demand for Precollege Science and Mathematics Teachers (Washington, D.C.: 3MB Research, Inc., 1986), [46][47][48][49][50][51][52][53]and Grissmer,55.   0.0 6.4 51 years or older -Too few cases for a reliable estimate. *Includes teachers who reported that 1987-88 was the year in which they began their first full-time teaching position at the elementary or secondary level and that teaching at the elementary or secondary level was not their main activity in 1986-87. NOTE: Details may not add to totals due to rounding or cell suppression. SOURCE: U.S. Department of Education, National Center for Education Statistics, Schools and Staffing Survey, 1987-88 (Teacher Questionnaires).     "}, {"section_title": "Continuing Teachers", "text": "Continuing teachers (stayers) provide most of the current teachers in any given year. Of all of the sources, their number is the easiest to predict, because the population from which the supply is drawn (the total number of those teaching in the previous year) is known.10 The proportion of teachers who continue varies from year to year depending on the number of teachers retiring, alternative labor market opportunities for teachers, and other factors) I Nevertheless, TFS data on the proportion of 1987-88 teachers who continued teaching in 1988-89 could be used as a beginning estimate of the rate at which teachers might be expected to continue from year to year."}, {"section_title": "Immigrants", "text": "Nationally, the number of immigrant teachers (movers) can be predicted based on the number of teachers who change schools. The potential population for this group is the same as that for continuing teachersthe total number teaching in the previous year. The proportion of teachers who change schools each year may fluctuate based on factors tl.at may resemble or differ from those that influence whether all teachers continue teaching. The TFS provides data on the proportion of 1987-88 teachers who continued teaching, but were in different schools in 1988-89. However, it is impossible to use this estimate to predict the number of immigrant teachers who might be available to any given school, district, or state. To know the potential supply of movers for any given school, district, or state, a more extensive analysis of the source and destination of movers would be necessary.12 New (First-Time) Teachers: New Teacher Education and Other College Graduates The potential supply of teachers from the population of new teacher education and other college graduates can be predicted with about the same degree of accuracy as the number of continuing teachers. Predicting the potential number of teachers in these two groups requires knowing the number in each group and the proportion who are likely to seek and obtain teaching jobs when they graduate. These data can be obtained from the NCES surveys of recent college I\u00b0Ibid., 29. IlStephen M. Barro, \"Models for Projecting Teacher Supply, Demand, and Quality: An Assessment of the State of the Art,\" chapter 3, 11-12. 12Haggstrom, Darling-Hammond, and Grisstner, 55. graduates, which provide information on the proportion of teacher education and other college graduates who obtained teaching jobs.I3 New (First-Time) Teachers: Past College Graduates Using data on only recent college graduates to predict the potential supply of new teachers would lead to an underestimate.14 Past graduates are a source as well. However, the number of teachers that might be supplied from all past college graduates is much more difficult to predict than the potential numbers of continuing teachers, immigrant teachers, or recent teacher education or college graduates, because past graduates are not located in institutions and we do not know under what conditions they might teach. While recent college graduates are enrolled in college and universities before they graduate and can be surveyed there, the proportion of past college graduates of all ages who might decide to enter teaching are located everywhere, and therefore cannot be estimated without a detailed national survey that identifies all past college graduates and determines who might be likely to teach under what conditions. NCES' Baccalaureate and Beyond Survey will provide information on the rate at which at least a portion of past graduates enter teaching."}, {"section_title": "Re-Entrants", "text": "Similarly, it is difficult to predict the proportion of former teachers who will re-enter teaching. Unless the population of all former teachers could be identified and a sample selected, it would not be possible to determine what proportion of this group would consider returning to teaching and under what circumstances."}, {"section_title": "Demand for New Teachers", "text": "Most of the need for teachers is met by continuing teachers. Following Haggstrom, Darling-Hammond, and Grissmer, the focus here is on the demand for new teachers, which can be expressed as the number of open positions filled with new hires plus the number of open positions that were left unfilled, as indicated by the number of unfilled vacancies, positions filled by a substitute, and/or positions abolished because a suitable candidate could not be found.15 Thus, the demand for new teachers at time t can be expressed by equation 2.16 where: D(t) = New demand, F(t) = Filled positions: number of new hires, and U(t) = Unfilled positions: vacant positions, full -time substitutes, and positions abolished. The number of filled positions represents the \"met demand,\" while the number of unfilled positions is the \"unmet demand.\" Filled positions are easy to spot, and unfilled positions can be estimated by the number of unfilled vacancies, full-time substitutes, and positions abolished; however, the unmet demand is often masked by increasing student/teacher ratios or canceling classes.17 For these reasons, schools and districts cannot always determine the exact number of positions that they could not fill. Nonetheless, theoretically total demand for new teachers consists of both met and unmet demand. Table 7 shows that during 1987-88, approximately 260,000 teaching positions were open in the United States. Overall, 11 percent of them were unfilled (12 percent in public districts and 8 percent in private schools). Several factors may produce a higher or lower total demand for new teachers from one year to the next, including growth or decline in enrollments, growth or decline in student/teacher ratios due to policy changes or shifts in course or staff requirements, and the loss, or attrition, of teachers from the previous year.18 In 1986-87 and1987-88, the student/teacher ratio was about 17 in both public districts and private schools (table 8). The demand for new teachers at time t can also be expressed as shown in equation 3.19 where: D(t) = New demand, G(t) = Changes due to growth or decline in enrollment, the student/teacher ratio, or staff requirements, and L(t) = Loss of teachers due to attrition. ( 3)Population and Policy Changes As Haggstrom, Darling-Hammond, and Grissmer point out, these components of demand are relatively straightforvard to measure, although the prediction of demand is more difficult. Enrollment changes reflect both population and migration shifts, and can be measured within schools and districts and predicted from population censuses and surveys. (Changes in fertility and migration are hard to predict, although the impact of fertility changes can be planned for given the 5-year lag between birth and school entry.) Similarly, changes in student/teacher ratios reflect either state and local mandates of this ratio, local policy changes, or local adjustments to respond to enrollment fluctuations. While the resulting changes can be measured within schools and districts, it is not possible to tell whether changes in this ratio are adjustments to enrollment changes, changes in policy, or both. Thus, it is difficult to predict future student/teacher ratios. Other mandated changes such as increases in high school graduation requirements can also he measured, although they cannot always be directly linked to immediate increases in the demand for teachers.20 \"Ibid.,44;56. I8Ibid.,39;[56][57] equation is a modification of that in Haggstrom,and Grissmer,[56][57] 20Ibid., 39-43.  Table 8-Total number of students and full-time-equivalent (FTE) teachers, student/teacher ratio in 1986-87 and 1987-88, and percentage change between 198647 and 1987-88, by sector, region, and grade level: 1987-88 "}, {"section_title": "2G", "text": "Teacher Attrition A major determinant of new demand is the turnover, or attrition, of teachers. The attrition rate is defined as \"the fraction or percentage of teachers employed in one period who are not employed as teachers in a subsequent period.\"2I This attrition can be caused by teachers leaving teaching altogether (leavers) and by teachers leaving to teach in other schools (movers). The inclusion of movers in the attrition rate depends upon the unit of analysis. For instance, if the analysis is at the state level, movers who just change schools within the state can be seen as continuing teachers and do not count in the state attrition rate. On the: other hand, if the analysis is at the school level, movers who leave to teach in other schools count as part of the school-level attrition rate. However, at every analysis level, it is best to examine the attrition of leavers and movers separately, because movers have different reasons for leaving their schools than do those who are leaving teaching altogether.22 For that reason, movers are sometimes considered continuing teachers. Teacher attrition can be involuntary, such as leaving due to layoffs or death, or voluntary, such as leaving for a different type of job or activity.23 Reasons for voluntary attrition among leavers include going to school, working in another job, raising children, or retiring before the mandatory retirement age. Attrition due to retirement, disability, and death is relatively easy to predict if the ages of current teachers are known, although economic conditions can alter retirement patterns. Attrition due to layoffs and firings is more difficult to predict. Voluntary attrition is particularly difficult to predict, because it depends on a variety of factors such as teachers' personal situations, their working conditions, the economy, and the attractiveness and availability of alternatives to teaching. Moreover, these factors interact. For example, teachers who give birth may not leave at a consistently predictable rate. Whether they continue or leave teaching may depend on their working conditions, their need for income, and the availability of alternative jobs at the time they give birth. By 1988-89, 6 percent of those who were teaching in 1987-88 had left teaching (table 9)."}, {"section_title": "Indicators of Shortages and Surpluses", "text": "Unfilled or abolished positions and the use of substitutes may indicate shortages in the number of available teachers with the desired qualifications, while layoffs may indicate overall surpluses (if they have been precipitated by enrollment declines). However, these measures are not reliable indicators, because unfilled or abolished positions as well as layoffs could be due to budget cuts rather than shortages or surpluses.24 In addition, schools and districts do not always allow vacancies or layoffs to occur, even if there are shortages or surpluses.25 If well-qualified teachers cannot be found to fill certain positions, schools and districts might prefer hiring teachers with less preparation or switching teachers from other fields, rather than leaving the positions unfilled. Thus, the qualifications of teachers for their assignments can be more reliable indicators of shortages or surpluses, and the differences between the qualifications of new hires and other teachers can highlight changes.26 21 Barro,Models for Projecting Teacher Supply,Demand,and Quality, 22lbid., 3-3-3-4. 23Ibid., 3-5-3-7. 24Haggstrom, Darling-Hammond, and Grissmer, 45-47. 25Barro, The State of the Art in Projecting Te6cher Supply and Demand, 20-22; Haggstrom,and Grissmer,44. 26Haggstrom,and Grissmer,[47][48][49][50][51][52]; 71-72.    , 1988-89. 19 Specific indicators might include the percentages of teachers and new hires with standard certificates in the field they teach, the percentages certified in any field and the percentages with standard, probationary, or temporary certification.27 These indicators show the extent to which qualified teachers could be found to fill the positions, how difficult it was to find teachers with standard certification, and to what extent schools granted temporary certificates in order to fill vacancies. Since certification requirements and procedures for probationary and temporary certification vary by state, these indicators must be reported by state. However, if these indicators are also reported by teaching field, they can help pinpoint those areas where efforts should be made to generate a greater supply of teachers. SASS provides data on all these indicators of shortages and surpluses, and some of them are reported by teaching field. In addition to the numbers of filled and unfilled positions reported earlier in the demand section, private schools and public districts report the percentage of new and all teachers with standard credentials in their fields. Teachers also provide detailed information on their qualifications, including the type of certification in the primary and secondary fields in which they were teaching. Tables 10 and 11 show the percentage of teachers who were new hires and the percentage who had standard certificates, by public district and private school characteristics and by state (for public school teachers). Table 12 shows the percentages of public school teachers with various types of credentials in their fields, by teaching level/field and by state.     -3.9 71.8 96.0 0.0 4.0 "}, {"section_title": "3^", "text": ""}, {"section_title": "Human Capital", "text": "Human capital theory maintains that people make systematic assessments of the monetary and nonmonetary benefits associated with different occupations when they make occupationrelated decisions.30 Monetary benefits include income, promotion, medical and other benefits, pension plans, and job security. Nonmonetary benefits include the conditions at work that can make a job more or less desirable, such as the physical environment, the convenience of hours and schedules, relations with co-workers and supervisors, the types of clients (in this case, students) and availability of materials and equipment. In addition, in order to train for a new occupation, there are costs in training and in forgone earnings that must be considered as well. Individuals enter into an occupation or change within or between occupations to maximize the net returns, taking into account both benefits and costs . Three types of human capital accrue by remaining in an occupation, a geographic location, and a firm.3I Occupation-specific human capital consists of the knowledge, skills, and contacts that are relevant to that occupation. The longer one stays in an occupation, the more occupationspecific human capital one accrues from that occupation, and the less applicable the skills are to other occupations. Individuals also acquire generic human capital in jobs that is sometimes applicable to other occupations, although some of these skills are more transferable than others.32 Location-specific human capital refers to the investments one makes to a particular area, such as home ownership, knowledge of an area, and support networks in that city or town.33 Finally, firm-specific human capital refers to the knowledge and seniority one acquires within a specific institution or organization. According to human capital theory, the more occupation-specific, location-specific, and firm-specific human capital teachers have, the lower their probability of attrition.34 Teachers with less human capital have less to lose by starting over in a new occupation or location, while teachers with more human capital in teaching cannot as easily afford to start over. In addition, the costs in forgone earnings while preparing for a non-teaching occupation are greater for older, more experienced teachers who have higher salaries and possibly larger debts than do younger teachers. Therefore, teachers would be expected to be much more likely to leave early in their careers and to be less likely to leave later, unless they are offered a much more attractive package of working conditions and benefits."}, {"section_title": "Uncertainty and Incomplete Information", "text": "A major assumption of human capital theory is that individuals have complete information about salaries, benefits, and working conditions in teaching and in all other occupations when they make occupational and job choices.35 Because this is never true, the role of incomplete information and uncertainty in job decisions cannot be ignored.36 Individuals usually accept jobs without perfect information about the job, and school systems hire individuals without complete information about the teaching abilities of these individuals. There is an initial period of evaluation on the part of teachers and school districts in which the job is compared with the perception of other available jobs and the teachers are compared with other available teachers. As a result of this process, teachers may either stay, leave, or be fired, While this process of evaluation continues throughout a teacher's career, it is more likely to result in either voluntary or involuntary attrition during the first years of teaching. The early voluntary attrition could be caused by more information about alternative jobs, by more experience with the teaching job itself, or both."}, {"section_title": "Life Cycle Considerations", "text": "Changes in family status, residence, and retirement reflect common life cycle patterns that also affect teaching. Marriage, the birth of children, geographical moves, and retirement are all events that are more likely to occur at certain ages. During their 20s and 30s, teachers have a high probability of getting married, having children, and/or moving.37 Many teach .s who marry have children, and some teachers who marry relocate to be near a spouse's job. People of this age group are also likely to move whether or not they are married because they have less location-specific human capital to lose than those who are older. These changes often lead to attrition among teachers because most teachers are women.38 Compared with men, women are more likely to have the responsibility for young children or to move for their spouse's job because they often have less human capital to lose by leaving the labor market or moving. However, both women and men beginning teachers are more likely to move than are mid-career teachers.39 think when they move. Consequently, one might expect greater proportions of movers among teachers than among individuals with other occupations (personal communication to the authors, November 14, 1992). 34Grissmer and Kirby, Teacher Attrition, 12. 35Ibid., 13. 36Ibid., [14][15][16][16][17][18][19]17. 39Ibid.,[18][19] Attrition due to retirement occurs sometime between the minimum retirement age/experience level and the mandatory retirement age.4\u00b0 Teachers decide when to retire by comparing the perceived benefits of continuing to teach with the perceived benefits associated with the amount of pension they will receive and the quality of retirement life."}, {"section_title": "Teacher Attrition Rates", "text": "Human capital accumulation, uncertainty and incomplete information, and life cycle considerations together provide useful explanations for the higher attrition rates among earlyand late-career teachers, and the lower rates for those in mid-career. During the first 10 years of teaching, career and life cycle stages all conspire to produce high attrition rates.41 For example, new teachers are experiencing the working conditions and benefits of teaching and are comparing those conditions and benefits to other teaching and non-teaching joos. They are also evaluating their expectations about teaching. Some expect to stay in teaching, while others see teaching as a stepping stone to other education jobs or other occupations.42 However, all have relatively little human capital invested in teaching and can still afford to enter or train for other occupations. In addition, they have relatively little location-and firm-specific human capital so they can also maximize their benefits by changing schools or districts. New teachers are also likely to be in the most common age range for marriage and having children. These family formation activities often conflict with work, either in time or location, especially for women. In addition, this age group is likely to be geographically mobile. Involuntary attrition is also highest in the early years of teaching,43 with schools evaluating new teachers and firing those who are not performing well. Teachers hired under temporary certification may fail to achieve regular certification. Moreover, reductions in force are more likely to affect new teachers, because they are the most recently hired. All of these reasons also explain why mid-career teachers have lower attrition rates.44 Those who stay past 10 years have made it though the period of teacher evaluation when they might have most easily moved to another occupation. Their human capital in teaching occupation-specific and firm-specific-----has accumulated, so that a switch to another occupation would entail greater costs. In addition, with seniority and earlier job moves, they have most likely found a teaching position that is optimal. Their seniority also protects them from being laid off. Finally, they are less prone to career disruption due to family formation and geographic moves. In all probability they have either already started a family or moved, or they are too invested in their job and location to stop teaching or move in mid-career. The high attrition of late-career teachers is easily explained by retirement and death.45 The specific timing of that retirement, however, is a function of some individual choice as well as the age and experience requirements of their retirement systems. At a given age, some teachers might derive greater benefits from teaching than from retirement, while for others it may be the reverse.  These considerations suggest models for predicting which teachers will leave and when. In addition, they suggest which subgroups of teachers need to be modeled separately. Human capital accumulation, uncertainty and incomplete information, and life cycle considerations all assume choice on the part of teachers and therefore are best suited for explaining voluntary attrition. They are not useful for explaining involuntary attrition such as death, illness, mandatory retirement, and reductions in force. While these involuntary events are related to factors such as teacher age and school policies, the relationship between these factors and the probability of leaving is different for teachers who leave involuntarily than for those who leave voluntarily. Consequently, the attrition of teachers who leave involuntarily should be modeled separately from those who leave voluntarily. Teachers who leave teaching voluntarily might differ in their reasons for leaving, depending on their circumstances. For instance, those who leave for retirement would be reacting to different circumstances than those who leave for other reasons, and the same model would not explain the attrition of both groups. Reasons for leaving may also be different for early-career and mid-career teachers. For instance, those who leave teaching temporarily for family or location reasons might have different characteristics and relationships to teaching than those who leave teaching permanently. Among those who leave permanently, those who leave to pursue higher positions in education may be very different from those who leave for other fields. Thus, various models may be needed to explain the attrition of these diverse groups. Teacher Attrition 1987Attrition -88 to 1988 Based on the theories of attrition discussed previously, this section describes various aspects of teacher attrition between 1987-88 and 1988-89. The tables also provide information on the subgroups of teachers that are later emphasized in the multivariate analysis. As table 9 (Chapter 2) showed, only a small proportion of all teachers left teaching in 1 year: 6 percent between 1987-88 and 1988-89. However, while only 5 percent of public school teachers left teaching, 11 percent of private school teachers left. This finding suggests the need to model attrition patterns separately for public and private school teachers (or at least to distinguish between them in some way). Table 13 indicates that attrition rates between 1987-88 and 1988-89 were slightly different for female and male teachers, with men being slightly less likely to leave (5 percent) than women (6 percent). This table also illustrates the U-shaped curve of attrition by age (teachers aged 36-50 were less likely to leave than were younger or older teachers) and by experience (teachers with 11-25 years of teaching experience were less likely to leave than were teachers with more or less experience). This finding suggests that attrition models must focus on teachers at particular career stages, because teachers in various stages leave teaching at different rates and for a number of reasons. Table 14 shows the percentage distribution of teachers by age, sector, and selected school and teacher characteristics, which can be used to predict the future attrition due to retirement. Among the teachers who left, about one-third of both public and private school teachers left for career reasons (table 15). However, public school teachers were more likely to leave for retirement (28 percent) than were private school teachers (5 percent), while private school teachers were more likely to leave for family/health reasons (30 percent) than were public school teachers (15 percent). About one-fifth of each group left for childrearing purposes, and about 5 percent left involuntarily. Table 16 shows the educational backgrounds of teachers who left for various reasons, and the percentages of teachers who left and stayed who were certified in their main assignment field. Among public school teachers, 98 percent of all 1987-88 teachers who stayed in 1988-89 were certified in their main assignment field, as were 96 percent or more of all teachers who left voluntarily. However, certification among private school teachers ranged from 49 percent for those who left for career reasons to 72 percent for those who left for childrearing. Only 71 percent of those who stayed in teaching were certified in their rain assignment field. Among both public and private school teachers, the educational backgrounds of teachers who stayed and those who left were very similar. However, educational levels varied by reason for leaving. Among public school teachers, those who left for career reasons or retirement were more likely than those who left for childrearing to have a master's degree in education. This may be partly related to age: teachers who leave for childrearing are more likely to be younger and therefore have had less time to earn a master's degree. Table 17 shows that 42 percent of the voluntary, non-retiring leavers planned to return to teaching, and among those who planned to return, 62 percent planned to return the following year. Finally, table 18 shows the range of activities in which teachers who left for reasons other than retirement were engaged. This table shows that 20 percent of public school leavers and 9 percent of private school leavers took non-teaching jobs in education, highlighting the fact that those who leave for career reasons may not be leaving teaching because they do not like education, but because they seek different responsibilities within the education field. Their reasons for leaving teaching might be very different from the 20 percent of public school leavers and 40 percent of private school leavers who found non-education jobs.        Chapter 4 Multivariate Analysis of Teacher Attrition The aim of the multivariate analysis was to identify the characteristics of teachers and their schools and districts that are associated with high attrition. As indicated in the Introduction, these efforts were less successful than originally hoped. This chapter describes in some detail the hypotheses developed, the methodology used, and the results of the analysis. Chapter 5 contains the comments of the reviewers."}, {"section_title": "Hypotheses", "text": "Based on the theory of attrition discussed in the previous chapter, it was hypothesized that the likelihood of leaving would he positively related to the following teacher and school or district characteristics: Teacher characteristics female gender married status children (especially young children) higher degrees (associated with more alternative job opportunities) teaching in fields with more alternative job opportunities (such as math or science) high family income (less need to work) School/district characteristics large class size, high pupil/teacher ratio high percentage of Chapter 1 or free lunch eligible students high minority enrollment urban school location high proportions of teachers in early careers46 It was also hypothesized that the likelihood of leaving would be negatively related to the following teacher and school or district characteristics: Teacher characteristics age years of teaching experience teaching in field best qualified certification in primary assignment field high influence over school policy high control over classroom practices high level of help from others in the school 46Teachers might be more likely to leave schools in which many of the other teachers were in their early careers, either because there would be fewer role models of successful mid-career teachers or because there was a reason that teachers left that school before they reached mid-career. high satisfaction with salary high satisfaction with teaching receiving merit pay or other pay incentives high teaching income large increase in teaching income School/district characteristics large district size47 provision of medical/dental benefits district/private school pension contributions high salary schedule availability of merit pay pay incentives for shortages greater proportion of teachers with higher degrees\" Methodology The dependent variable selected for the analysis was dichotomous with a value of 1 for teachers who left teaching and 0 for teachers who continued teaching. The independent variables were various measures of the teacher, school, and district characteristics listed above that were expected to be related to attrition. Two major sets of models were tested; they differed in the samples selected for analysis and in the specification of the independent variables. Because the dependent variable was dichotomous, logistic regression analysis was used to test the models. The rest of this section describes, for each set of models, the sample used, the specific measures used for the independent variables, and the results of the regression analyses."}, {"section_title": "Initial Modeling Efforts", "text": ""}, {"section_title": "Sample", "text": "The sample chosen first for analysis was the group of teachers thought to be the most sensitive to changes in policy and working conditionsteachers who left voluntarily before retirement for career-related reasons. These included teachers who reported that their main reason for leaving was one of the following: to pursue another career; for better salary or benefits; to take courses to improve career opportunities in the field of education; to take courses to improve career opportunities outside the field of education; to take a sabbatical or other break from teaching; or because they were dissatisfied with teaching as a career. Involuntary leavers (that is, those who listed school staffing action as their main reason for leaving); retirees; and teachers who left for childrearing, health, or family or personal reasons were excluded from the sample. Involuntary leavers were excluded because they had no control over their leaving. In addition, retirees were excluded on the assumption that age would explain so much of the variation for this group that it would be difficult to identify other effects. Teachers who left for family reasons were excluded because such departures are sometimes voluntary and sometimes involuntary, and are caused by different factors than are career-related departures. Finally, public and private school teachers were examined separately, because many believe that each group responds differently to factors such as salary and working conditions, which are thought to affect attrition."}, {"section_title": "Independent Variables", "text": "The independent variables included teacher demographics, education, working conditions, experience, teaching load, and school and district type and policies (salaries, benefits, incentives, and so on). The selection of independent variables was influenced by the purpose of the analysis, which was to test theories about which teachers are most likely to leave. Therefore, variables such as the teacher's response to a question on how long she or he expected to stay in teaching were deliberately avoided. Such variables would likely be very highly correlated with leaving, but including them could easily obscure the effects of other more policy-relevant variables. Two factors possibly related to leaving that were not included were family income and change in teacher income. Since teachers from families with higher family income might be more financially secure, they might be more likely than those from families with lower incomes to leave for career reasons. However, the data on family income were not very reliable, because some teachers included their own income when reporting family income and others did not. Change in teacher income over time might well affect the likelihood of leaving teaching, but the change in only 1 year (all that was available for this analysis) would not be a reliable indicator of earning prospects. The multivariate analysis of teacher attrition involved using multi-level data that are hierarchical in naturethat is, teachers are located within schools, and schools are located within districts. The difficulty with simply attaching data on a teacher's school or district to the teacher with a teacher-level dependent variable is that teacher characteristics vary more among schools than within schools; however, this uneven pattern is not taken into account. In addition, the variation among schools is not modeled correctly when many teachers have the same school characteristics. Although there is a statistical methodhierarchical linear models (HLM)to take care of these problems, HLM cannot be used with the SASS data set because the sample does not contain enough teachers per school (only one or two in the TFS).49 Therefore, it was necessary to use a one-level model, with the teacher as the unit of analysis and school and district characteristics attributed to each teacher. This solution was acceptable because there were so few teachers per school and schools per district that the teacher, school, and district characteristics were almost congruent. Bivariate tables were produced (for public and private school teachers separately) to show the differences between those who were leavers for career reasons and continuing teachers (stayers and movers) for each variable to be used in the regressions (see Appendix table 5).50 Very few statistically significant differences were observed between the two groups. The intercorrelations of the independent variables and the correlations with the dependent variable were examined for possible multicollinearity. Almost all of the correlations were very low. Only the correlation between the percentage of minority teachers and the percentage of minority students was greater than .60, and the correlation was this high only for public school teachers. Table 19 shows the independent variables used in the first set of regressions. The variables are listed by group according to how they were entered into the regression models. Group I 49See Anthony S. Bryk and Stephen W. Raudenbush, Hierarchical Linear Models (Newbury Park, CA: Sage Publications, 1992). \"These tables were produced using REPTAB, a statistical program developed by MPR Associates that estimates standard errors correctly for data from complex samples such as SASS. consists of control/descriptive variables; Group II contains additional teacher and student contextual variables; Group III contains the compensation and benefit variables; and Group IV includes the perception of teaching and certification variables. The \"alternative\" groups show the different ways that the variables were expressed and tested in the regressions. Usually the alternatives consisted of changing the variable from a continuous to a dummy variable or trying different dummy groupings to try to express the variables in the most meaningful way."}, {"section_title": "WESLOG Analysis", "text": "The software used was WESLOG, a logistic regression program that takes into account the complex sampling design of the SASS and TFS surveys.51 WESLOG uses either jackknife or balanced repeated replications (BRR) methods to compute the standard errors. The variables in Group IA were entered first, followed by the variables in Groups IBE, one group at a time. While WESLOG did compute coefficients, standard errors, and Res for these models, it was not able to compute an F value to test the fit of the model for the public school teacher sample because the matrix was singular. The F values of the private school teacher models were computed, but were never significant (they ranged from 1.55 to 2.11), indicating that no coefficients were different from 0. The R2 ranged from .05 to .06 for the various public school teacher models, and from .07 to .11 for the private school teacher models. When the model was tested using the entire Group I modelthat is, with Groups IAE all included simultaneously instead of entered separately as described aboveWESLOG still could not compute an F value for the public school sample due to a singular matrix. For the private school teacher sample, it ended with an \"abnormal termination,\" producing no output. Table 20 shows the WESLOG results for the public school teacher model using all Group I variables together. The odds ratio (0) is shown for each significant independent variable. This ratio indicates the odds of a member of this group leaving teaching compared with a member of the reference group. The analysis showed that, among public school teachers, the odds of a secondary math/computer science teacher leaving teaching were about three times the odds of other secondary school teachers and about twice the odds of elementary school teachers. It also indicated that the odds for teachers with more than one child 6 years or older were about onethird the odds for those with no children, and that the odds for teachers in the south were about twice the odds of teachers in the Northeast. The factors most frequently thought to be associated with career-related attrition, such as experience, education, and gender were not significant. The R2 was .07 for the public school model. Some statisticians believe that the R2 has meaning in logistic regression, but many do not. The authors of both the WESLOG and SAS manuals advocate using the R2 as an indicator of the predictive ability of the model, and they report it (or the R) for that purpose. However, prominent experts in logistic regression, such as Hosmer and Lemeshow, argue that it is not an adequate goodness-of-fit statistic.52 51WESLOG was developed by WESTAT, Inc. See, for example, C.J. Skinner, D. Holt, and T.M.F. Smith, eds., Analysis of Complex Surveys (New York: Wiley, 1989), or E.S. Lee, R.N. Forthofer, and R.J. Lorimer, Analyzing Complex Survey Data (Newbury Park: Sage, 1990), for a discussion of why it is necessary to take into account the complex design of SASS and TFS when conducting statistical analyses. 52D. W. Homer and S. L. Lemeshow, Applied Logistic Regression (Wiley and Sons, 1989), 148-9. Teaching experience 5-14 years full-time experience 0-4 years full-time experience 15+ years full-time experience 0-4 years full-time experience   Some argue that there is no good measure of goodness-of-fit for logistic regression models and that the only way to assess models is to compare them to an equation with only an intercept (that is, with no independent variables), and then judge whether having specific variables in the model increases the log likelihood or not.53 In order to compare models with added variables, the exact same sample size is necessary, which means that only cases with nonmissing values for all the variables in all the models can be included. The -2 (log likelihood) is then compared among models using a chi-square distribution of the difference. One problem, however, is that the -2 (log likelihood) rises with the number of cases and with the improved predictability of the variables. Therefore, the change in this value must be carefully considered. One approach to interpreting the results of logistic regressions is to create a classification table, calculating the probability of leaving teaching for each case and assigning it to leaving if it were greater than 0.50 and to staying in teaching if it were less than 0.50. Then the probability could be compared with the actual value. However, this does not really measure how well the model fits either because \"the expected error rate is a function of the magnitude of the slope, not necessarily the fit of the model.\"54 In addition, this is difficult to do when the dependent variable has a low probability. Consequently, predicting staying would be fairly accurate, but not predicting leaving. One recommendation was that instead of using the odds ratio (eB), which indicates how well a variable did in relation to a reference group, we calculate the \"estimated probability\" of each group by using the Betas and the values of the variables, choosing the value of the variable, multiplying each value by its Beta, and adding them up.55 This is the logit (L) for that group. The estimated probability (P) of that group leaving teaching would then be computed using the following formula: P. eL / (1 + eL). This probability has a confidence interval that can be calculated."}, {"section_title": "SAS Analysis", "text": "To determine whether or not the problems in obtaining an F value were due to using the BRR method with the particular data that were being used or to the specification of the model, the models were tested using SAS, which produces the same coefficients as WESLOG, but computes inaccurate standard errors. This occurs because it assumes a simple random sample and ca .not take into account the complex sample design of SASS and TFS. It was also decided to test the models using SAS as a rough gauge of their usefulness. Although the SAS-generated standard errors would be incorrect, it seemed likely that if very strong (or very weak) relationships were found between the dependent variable arid any of the independent variables, these results would probably hold when the standard errors were computed correctly. The first SAS regressions were run using only the Group I independent variables (Groups Ia-e together). Table 20 compares the SAS and WESLOG results for public school teachers for Group I variables. The coefficients were the same (as they should have been), but the SAScomputed standard errors were not consistently smaller than the WESLOG-computed standard errors as was expected given the clustered sample design. This result suggests that it would not be accurate simply to inflate the SAS-computed standard errors by a design effect to approximate the standard errors that would be generated using the BRR procedure. The major test for goodness-of-fit provided by SAS is the \"Model Chi Square.\"56 It tests the null hypothesis that the coefficients for all terms in the current model except the constant were 0. The Model Chi Square was not significant for the public school teacher model that used all the Group I independent variables. Despite the lack of overall significance for the model, some variables were individually significant. In fact, these variables were very similar (although not exactly identical) to the variables that were statistically significant in the WESLOG analysis, even though the standard errors were computed differently. Therefore, it was concluded that it would be worthwhile continuing to explore the relationship between leaving and other variables using SAS, although definitive results could not be obtained because SAS does not compute the standard errors accurately. The next step was to test additional models using SAS. These models included Group I variables in combination with other groups: Group II; Groups II and III; Groups II, III, and IV; and Group IV. Table 21 lists the variables that proved to be significant for each combination of groups, with public and private school teachers being shown separately. The Model Chi Square was not significant for any of the public school teacher models, but was significant for all the private school models. The private school models (which have greater credibility because the Model Chi Square was significant) suggested that teachers were more likely to leave teaching if they were \"other\" secondary teachers, had a degree higher than a BA/BS, received incentive pay, taught in urban schools, or reported low satisfaction with teaching. These models also suggested that teachers were less likely to leave if they had been teaching fulltime 15 or more years. These results were interesting, and supported some of the hypotheses posed at the beginning of this chapter. However, many variables that were expected to be significant were not. More important is the fact that the analysis could not be completed using WESLOG (because of the singular matrix problem), and therefore the models could not be tested using accurately computed standard errors. Nevertheless, the similarity in the significance of variables using WESLOG and SAS for the model that WESLOG could test suggested that further exploration of the models using SAS would be useful."}, {"section_title": "Additional Efforts", "text": "In consultation with NCES, a second set of models was selected for testing. These models were tested using two different samples of teachers. First, the \"full-sample\" models included all those who were still teaching (stayers and movers) and all voluntary leavers (rather than just leavers for career reasons). The definition of voluntary leavers for this part of the analysis was expanded to include those who were not teaching and who listed their main reason for leaving as childrearing, family/health considerations, or retirement as well as leavers for career reasons. Involuntary leaversthose who listed school staffing action (which could be layoffs or firings) as their main, second, or third reason for leavingwere still excluded from this sample. Second, the \"reduced sample\" included only those who left for career reasons (that is, the same sample used in the first models). 56This tests the difference between the -2 log of the likelihood (the probability of the observed results given the parameter estimates) of a model with only a constant versus -2 log of the likelihood of the current model. The use of the full sample was based on the assumption that trying to predict the attrition of only about 3 percent of the teachers made it difficult to distinguish this group from the others and contributed to the relatively few significant variables. It was hoped that increasing the sample would make leaving a less rare (and, therefore, more predictable) event. However, including all voluntary leavers meant that the analysis would identify only those factors related to leaving that were common to all the subgroups of leavers. The impact of factors that affected only one subgroup would be buried. The specification of the model and that of the sample was changed somewhat. For instance, the number of categories for some of the variables and the total number of variables in the models were reduced to make the analyses clearer. In addition, changes were made to some of the variables, such as squaring the experience variable to make it nonlinear. Table 22 shows the variables tested in the new models. A core set of variables (Group I) was included in every model. The three additional groups were added separately, one group at a time, to the core group. The final model consisted of the core group and any variables that were significant in the separate models. The models were run separately for public and private school teachers and for the full and reduced samples. A second attempt was made to conduct the analysis with correctly computed standard errors. It seemed possible that the abnormal terminations obtained with WESLOG stemmed from using the BRR method with a model containing many dummy variables and a relatively small number of cases in which the dependent variable was 1 (that is, the teacher was a leaver).57 Using the BRR procedure in logistic regression involves taking repeated half samples and performing the regressions on these half samples. When the sample is drawn, half of the cases have their weights doubled, and half are assigned weights of 0. Cases with weights of 0 are essentially \"thrown out.\" It seemed possible that one or more of the half samples might have had perfect correlations among some of the variables, leading to a singular matrix. To get around this problem, Rust suggested that the BRR procedure be continued, but with an alternative set of weights (Fay weights). The Fay weights multiply the original weights by 1.5 or .5 (rather than 2 or 0), and therefore do not invol'. throwing out half the sample. This approach was tried with the second models. Using the Fay weights solved the problem of abnormal terminations of the computer runs, but WESLOG still could not compute the F value for any of the public school teacher models and could do so for only one of the private school teacher models because it again encountered singular matrices. Tables 23 and 24 show the results of testing the full sample and revised independent variables using WESLOG (with Fay weights) and SAS. All the public school teacher models and all but one of the private school models tested with SAS had significant Model Chi Squares. It must be kept in mind, however, that for neither the WESLOG nor SAS models were the standard errors accurately computed. Therefore, this analysis must be considered only exploratory. More variables were significant when tested with WESLOG than with SAS. Some of the findings were counterintuitive. 57Keith Rust: Personal cout-indication with the author, 1992.    The full-sample analysis suggested that public school teachers were more likely to leave teaching if they were male, had 0-3 years of teaching experience, had no children, or reported low satisfaction with teaching. It also indicated that these teachers were less likely to leave if they were older, an older male, minority, never married, teaching in the field for which they were best qualified, special education teachers, or if they reported a low (WESLOG model only) or high amount of help from others or high control in the classroom (WESLOG model only). In the case of private school teachers, the full-sample analysis suggested that teachers were more likely to leave if they were male, had no children, reported high satisfaction with their salary, or reported that physical abuse of teachers was a problem in their school. They were less likely to leave if they were an older male, older (WESLOG model only), never married, had a bachelor's degree in education (WESLOG model only), taught secondary science or elementary school, taught in their best qualified field, or if they reported high control in the classroom (WESLOG model only) or high satisfaction with teaching. Tables 25 and 26 show the WESLOG and SAS models for the reduced sample (that is, for teachers who left teaching only for career-related reasons). Fewer variables were significant, especially in the models tested using SAS. This may explain why relatively few variables were significant when the reduced sample was used for the first WESLOG and SAS models. Because of the methodological difficulties encountered, a draft of this report was submitted to four outside reviewers who are acknowledged experts in the areas of teacher supply and demand, statistics, and logistic regression analysis. They were invited to comment on the conceptual models, the methodology, and the results of the logistic regression analysis. The next chapter summarizes their comments. Table 25-List of significant logistic regression results using WESLOG with reduced sample (leavers for career reasons only) for public and private school teachers: all significant variables from Groups   .00 02 32-51** (always sig) 9-45 (Grps I and IV not sig) NOTE: * probability <.05 **probability <.01 Chapter 5"}, {"section_title": "Reviewers' Comments", "text": "The four outside reviewers' comments covered three broad areas: the general approach taken for this analysis, the specification of the variables used, and the interpretation of the results. Their comments are summarized here. Bonnie S. Billingsley, Ed.D., Associate Professor Virginia Tech, College of Education"}, {"section_title": "General Approach", "text": "It is obvious from the review of theories in Chapter 3 that the authors have a good grasp of the teacher retention literature. They review several different theories and a broad range of variables that influence retention, and rely upon the writings of Grissmer and colleagues extensively, which makes sense given their recent contributions to the knowledge base in this area. The hypotheses posited for the multivariate analysis are consistent with the theories proposed in Chapter 3 and appear to be logical. Many of the variables have been included in previous research studies on attrition/retention and commitment. Some of the hypotheses have strong support based on the theories reviewed and previous research (e.g., age, gender). The first and second models include different samples, recognizing that attrition factors are likely to differ for subgroups of teachers. I would also suggest investigating an \"early career\" model and including a sample of stayers and leavers with less than 10 years of experience (or under a certain age, such as 35), since this is a likely-to-leave group. The proportion of those leaving will also be higher among this group.\nIn summary, I believe that the technical procedures to handle the complex nature of the data are state-of-the-art. My concern with the manuscript lies in the implementation of the logistic regression modeling procedure itself. The discussion of the use of SAS versus WESLOG is sound. Landis et al. discuss this approach of using standard linear modeling software (with weights) in comparison to a procedure that accounts for the complex sample design, and advocate the approach the authors have used as a sound practical procedure.62 Restricting the analysis to voluntary leavers seems sound, with one exception. One aspect of teaching that is attractive to many is the fact that it is a career in which it is relatively easy to regain employment after a move (due to a spouse's relocation, for example). Thus, in a sense, such a move is voluntaryif the teacher were only able to obtain work in a few specific locations, this might well affect the decision of the family to relocate. It might be useful to develop models with and without movers, both for this reason and because at a higher level (e.g., national) movers do not constitute attrition at all. The decision to model public and private teachers separately, rather than just to include sector as an independent variable, may have been a mistake. Differences between public and private attrition rates might be explained by differences in the age and sex distributions of these two groups of teachers, for example, and it would not be possible to discern and establish this confounding relationship with separate models for public and private school teachers. One could learn a lot by discovering which other factors have significant interaction with public/private and also by being able to measure and test the effect of public/private school, controlled for other factors. If there were many interactions, or if different data were available for public versus private teachers (e.g., district level data), then the use of distinct models would be appropriate; however, these issues need to be investigated more fully. This also raises the question about movers between public and private school systems. To what extent do teachers leave public schools to teach in private schools and vice versa? Using multi-level data is not as much of a problem as it appears to be in this report, because the one-level model analysis used takes into account the hierarchical nature of the data. It is true that the models available are more restrictive. One cannot measure interactions between random effects at one level and fixed effects at another level, for example; they must be assumed to be 0. Also, one cannot partition the variance of the random components into, for example, school and teacher components. However, the inference about the parameters in the model will be correct and will not suffer from the problems of incorrect inference that occur if one simply attaches school-level variables to teachers and then analyzes teacher data ignoring the clustering of teachers in schools. The analyses would be equally valid if there were many teachers per school and district, but in that case, an alternative methodology (HLM) would be available.  andNutrition Examination Survey,\" in Vital andHealth Statistics, Series 2, no. 92 (Public Health Service Publication 82-1366, Washington, D.C.: U.S. Government Printing Office, 1982). To illustrate these points, consider a simple HLM: logic (P) = 130 + RiX + E 10 = yoo+ 71oY+ 6 01 = 7o1 + 711Y+ 0; where P is the probability of staying; X is some teacher characteristic; Y is a school characteristic; and c, 8, and 0 are random terms. This model can be expressed as: logit (P) = (yoo + 710Y+ 8)+ (7o\" + y11 Y + e) c 7oo + 701x + 710Y + ylixY + ex + (6+ Provided that 6e2 = 0 and that one is not concerned about establishing the relative magnitude of 672 and 6e2, then this model is reduced to a single (teacher) level model, with the school characteristic Y treated as a teacher-level variable. WESLOG can give correct inference and estimates for the parameters 700, yoi, yip, and yi 1. The weakness of this approach is the reliance for its validity on the assumption that 602 = 0.\nMy comments focus on the logistic regression modeling used in this report. I am not familiar with the WESLOG program, but appreciate the fact that it is trying to incorporate the proper statistical weights into the estimation process. My comments relate to building the logistic regression model with conventional software. I believe that if you were to find a satisfactory model using standard software first, and then refit the final model with WESLOG, the process could be considerably easier and more understandable than it currently is. Also, many of the basic procedures used in building logistic regression models are simply not set up for situations where the statistical weights are unequal for each subject. It would be important to assess the performance of the model with traditional software because it is not possible with the more specialized software. Procedures such as goodness-of-fit testing, analysis of logistic regression diagnostics, and area under ROC curves should not be omitted. All the models are over-parameterized. There are simply too many nonsignificant variables included in each model. This is manifested by the matrix singularities and strange results in the odds ratios and associated confidence intervals. The fact that the models are full of nonsignificant independent variables has led to very unstable results. For example , table 18 demonstrates a very poor model. Notice the very large standard errors associated with the \"less than BA/BS\" category or the large standard error of the \"Black, non-Hispanic\" group relative to the beta in that group. These are indications that the model has fallen apart statistically. It is much better to build smaller models that behave in a stable manner, have statistically significant terms, and fit. My approach would have been to build smaller, significant, and well-fitting models with SAS, and then to refit those models with the WESLOG method incorporating jackknifing or BRR to corroborate the results and better estimate parameters. I would concentrate more on assessing the performance of the models. With modern computer software it is easy to fit models to data. For example, anyone can fit a straight line to a set of X's and Y's, but the straight line is not always appropriate. This has to he checked with logistic regression, as well by computing goodness-of-fit tests and examining diagnostic statistics to see if there are any highly influential or poorly fit covariate patterns. More attention should be paid to these issues.\nThe study involves the binary response variable of teachers who are leavers or stayers. Such studies are modeled using the binomial distribution. The probabilities are functions of linear combinations of teacher and school characteristics. Since some of the characteristics are continuous, the general logistic regression model is appropriate. The classical statistical models involve assumptions that do not reflect the complexity in the SASS and TFS surveys.64 Therefore, they require software that will take into account the complex sampling design. The purpose of the analysis was to assess the impact of possible explanatory variables on the binary response variable. Prentice and Pyke have shown the remarkable fact that in this type of study the estimators of the parameters for the explanatory variables in a logistic regression model are consistent, as is the sample information matrix.65 The PrenticePyke result does assume that the logistic model is correct. However, this has yet to be established in this study. The number of variables should be reduced. Table 18 gives the overall view of the data with all 31 variables included. The improvement in the model is measured by the likelihood ratio test with X231 = 35.33. The next step should be a backwards eliminatior1-of nonsignificant variables. I would recommend deleting some of the nonsignificant variables, and recomputing the model and the x2 goodness-of-fit test. I believe what will happen is that x2 will be only slightly smaller than 35.33, but the degrees of freedom will change from 31 to 9 (4 for child, 4 for secondaiy, and 1 for free lunch). The test will then be very significant. SAS will do this automatically, but all dummy variables in a group should be retained if one is retained. The model can be further simplified by compressing the nonsignificant levels in a group into one level. To check that the deleted variables are really not significant, one can do a forward regression to compute the improvemert with only that group of variables included. Since the significant variables are either categorical or can be converted into such variables I would also suggest categorical modeling. Since the dependent variable has only two responses, CATMOD and LOGIST will yield the same parameter estimates. The advantage of CATMOD is that the output will contain observed and predicted values for each cell.66 SPSSX uses the observed and expected frequencies to compute a Pearson goodness-of-fit test.67 It would help to have a longer period of study to increase the number of leavers. If a 3 -year interval were possible, the total sample would only increase slightly, but the number of leavers would be tripled. "}, {"section_title": "Specification of Variables", "text": "The authors have included the major groups of variables needed to investigate attrition among teachers. There are other variables I would suggest including, but some of these are not in the SASS database. Others are suggested below. The relatively large number of variables and their groupings complicate and confound the analysis. The authors do not provide a rationale for the groupings of variables, and it is not clear why some of the variables are grouped the way they are. For example, the demographic variable groups include variables that are not demographic measures (e.g., subject level taught). Also, the fact that the different groups are entered using a manual stepwise approach implies that the specific composition of the groups influence the various forms (specifications) of the model and consequently influence the statistical results. Perhaps consider reducing the number of variables using either principal components or factor analysis to identify more defensible variable groups. These can be used in the logit analysis as conceptual dimensions thai reflect the meaningful information contained in the entire set of variables. In effect, the conceptual dimension \"indexes\" would reduce the number of variables required in the analysis. In their current form, the models are likely to include too many variables grouped in a questionable manner that confound the analysis through the application of the manual stepwise approach. I would use a conceptual framework for teachers' career decisions based on a review of attrition/retention literature to evaluate the specific independent variables included in the models.58 Professional qualifications. Several variables that relate to teachers' professional qualifications are included in the analysis such as: highest degree earned, whether or not they are teaching in the field for which they are best qualified, whether or not they are certified in their primary assignment field, and teaching experience. Although a variety of other professional qualifications might be considered, they are not available on the SASS database. However, it would be worth considering whether there is a good proxy for \"entry path\" (teachers entering through traditional versus nontraditional routes). Work conditions and work rewards. Prior research suggests that work conditions and rewards are associated with teacher retention. The authors discuss several \"work condition/work reward\" hypotheses. Some of the variables included in this analysis are more \"behavioral\" (e.g., number of students/class, student/teacher r..tio, high minority enrollment, urbanicity, school size, teaching income, merit pay), while others might be considered \"affective reactions\" to the conditions of teaching (e.g., satisfaction with salary, satisfaction with teaching). It seems logical that the behavioral variables might be predictive of the affective measures (e.g., high class sizes predictive of lower job satisfaction). Some of the student variables are likely to be highly correlated (high minority enrollment and free lunch eligible as well as number of students/class and student/teacher ratio). Perhaps high influence over school policy and high control over classroom practices could be combined into one \"control\" variable. Another problem in evaluating these variables is that the reader is not provided with a description of the measures, and no reliability coefficients are given. Section 5 of the questionnaire contains many work-related items. However, I could only guess which items made up job satisfaction. Also, I could not determine whether the variables listed under item 31 (school problems) were included in the analyses. I would use factor or principal components analysis as outlined above to identify defensible work-related variables from those included in the SASS database. I would also include (a) support variable(s) (e.g., administrative, colleague, and parents) in the analyses, given the fact that previous research suggests an association between support and attrition. Other work-related variables of interest include opportunities for professional development, workload, and school climate. I would also consider including grade level in the analyses since a number of researchers have found that grade level taught has been related to attrition, with secondary teachers leaving sooner than elementary teachers.59 Personal factors. Appropriate teacher characteristics (e.g., age, raceethnicity, gender, marital status, children, high family income) have been included in the models. \nThe factors \"high satisfaction with salary\" and especially \"high satisfaction with teaching\" are co-outcomes or at least intervening variables. One cannot change a person's satisfaction with teaching without changing some other factors such as salary or pupil/teacher _atio. Thus, before including such factors in the model, I think that it is necessary to ensure that they capture an important component not reflected in the other variables, and that at least there are some ideas or theories as to what the (unmeasured) underlying factors are. It is not very useful learn that the main reason teachers left teaching was because they did not like it. The idea of considering continuous variables as both continuous and dichotomous is sound. It enhances the ability to detect continuous variables that have threshold or ceiling effects.\nThe use of dummy variables in logistic regression analysis is very important. The 0, 1 coding chosen for the dummy variables is mine if there is an appropriate reference group. An alternative would be to use +1, -1 coding to allow comparison of each region to the national average, rather than to a single reference group. This \"deviation from means\" type of coding is quite useful in some instances, as opposed to the more commonly used \"reference cell\" type of coding used in this report. I would suggest that the scale of an independent variable X be checked before including it in the logistic model as a continuous variable. Inclusion assumes that the logit is linear in X, which may or may not be the case. This assumption must be tested. If it is not true, then the variable can be categorized or transformed to make it more appropriate for inclusion in a logistic regression model. The report mentions that bivariate tests were conducted relating each independent variable to the dependent variable. It is very important that this be done in order to select (from many potential predictor variables) those that are related to the outcome in a crude sense. If a variable is not related to the outcome in this simple screen, it probably will do more harm than good to include it in the model. The P values associated with these bivariate tests should be reported. It is also mentioned that \"the intercorrelations of the independent variables and the correlations with the dependent variable were examined for possible multicollinearity.\" Multicollinearity in logistic regression manifests itself by large regression coefficients, large standard errors associated with these coefficients, and highly variable confidence intervals for odds ratios. Although very useful in multiple linear regression, computing the tolerance or other functions of intercorrelations between the independent variables is not useful with logistic regression.\nThe continuous variables appear to be monotone with respect to the binary response variable. Since retirees are not included in the study, the anticipated U-shaped relationship between leaving and age should have been eliminated."}, {"section_title": "64", "text": ""}, {"section_title": "Interpretation of Results", "text": "Multicollinearity. It was asserted that almost all of the correlations among the independem: variables were \"very low.\" Yet WESLOG could not compute an F value for the public school sample due to a singular matrix. Such singularity generally implies the presence of at least two redundant variables. I suggest that a complete correlation matrix be provided. Further, it would be helpful to evaluate a more comprehensive set of multicollinearity diagnostics such as variance inflation factors, the eigenvalues and eigenvectors of the correlation matrix, or both. The singular matrix generated by WESLOG is a signal that such additional analysis of the specification is appropriate. Goodness-of-fit. The Res do not inspire much confidence as reported. I suggest reevaluating the goodness-of-fit of the models in light of the fact that dichotomous dependent variable models are unlikely to produce Res close to 1. Research by Morrison explains why it is important in interpreting logit models to recognize that the upper bound for R2 is probably significantly less than 1.60 I suggest using Morrison's approach to estimate the upper bound for R2 under the assumption that the predicted probabilities follow a beta distribution. An \"effective\" R2 can be estimated as the ratio of the observed-to-the-upper bound for R2. The observed (empirical) R2 is computed as: (model x2 -2k)/-2L(0), where k is the number of variables omitting the intercept, and L(0) is the maximum log-likelihood including only the intercept. This analysis will add a more meaningful indication of goodness-of-fit to the analysis. Further, I suggest reporting and evaluating the number of correctly classified observations, Interpretation of the estimated coefficients. I suggest reporting and interpreting the I, git regression elasticity coefficients rather than the simple coefficients. Define Prob (Yi = 1) as the probability that teacher i will leave teaching; Zi as the arbitrary index used to ensure that the predicted probabilities reside in the unit interval for all Xs (the vector of explanatory variables); and f(Z) as the value of the logistic density function for each possible value of the Zi index. Thus, the elasticity coefficients can be an estimate for each explanatory variable as follows: I suggest using the mean value of each explanatory variable and the mean predicted probability of membership in class 1.61 The elasticity coefficients are easier to interpret than the current statistics.\nR2 meaning. My experience leads me to endorse the discussion about the inappropriateness of the R2 statistic for logistic regression, and I think that the discussion about this is sound. I also agree that the estimated probability of a group's leaving can be computed using the formula P=e1-/(1+eL). With the variance-covariance matrix, one can derive large-sample confidence intervals for L in each case. Using the fact that P is a monotone function of L, one can derive an asymmetric large-sample confidence interval for P. That is, if the confidence limits for L are Li and Lu, (lower and upper, respectively), then confidence limits for P are eLI / (1 + el-1) and el-u/(1 + el-u), respectively. Statistical significance of the model. If the model lacks significance overall using SAS, then might it not be concluded that none of these variables is worth pursuing further, even though some are individually significant using WESLOG (and SAS)? Otherwise, why worry about the overall test of fit at all? I am very puzzled that with so many significant terms in the model, the overall model fit was not significant. Are the results being interpreted correctly? For instance, in the Private School Groups I, IV example, the overall model was highly significant with p < 0.001 (F=6.55 with 10, 39 degrees of freedom). Alternatively, perhaps this is a result of including so many terms in the model. Did you consider using a stepwise procedure because of the large number of variables involved? I am also somewhat surprised that the results overall are not significant for public schools, yet are for private schools. Presumably the sample sizes are smaller for private schools, and the sizes of the effects of the significant variables do not look very different. I wonder if the weights within each group (public and private) have been scaled so that they have a mean of 1.0 in each case. However, if they have not, I would expect the result to understate significance for private school teachers and overstate it for public school teachers, since my guess is that SASS oversamples private school teachers. (This is indicated by the sample sizes.) Singular matrices. Korn and Graubard discuss the issue of singular matrices in analyzing complex survey data.63 I do not think this is a serious problem here as the approach of using SAS to assess overall model fit, checking against WESLOG results for the comparability of individual parameter significance, is quite sound. Fay weights. The WESLOG results can be corrected by simply multiplying all of the standard error estimates obtained from WESLOG by a factor of 2 (derived from the use ut factors 0.5 and 1.5 in obtaining the Fay weights). This will eliminate some variables from tables 21 and 23 and probably change some **s to *s. It will also make the results of these tables very similar to those in tables 22 and 24, again showing that you could reasonably proceed, on the basis of these analyses, with just using the SAS analyses.\nI object very strongly to the use of R2 as a measure of performance of logistic regression models. It simply does not have the same interpretation as it does for linear regression and is not useful. Some people use the Pearson chi-square or the deviance chi-square to assess fit. This also is an incorrect procedure for the type of data being analyzed here. I would strongly suggest that any models be evaluated with formal goodness-of-fit tests. These are easy to perform with standard statistical packages such as SAS, SYSTAT (LOGIT module), STATA, and others that have the HosmerLemeshow procedure built in. Because WESLOG will not do this, I suggest building and assessing the models first assuming the sample is a simple random one, and then after you are satisfied that you have a good model, refitting the coefficients and standard errors in a manner that accounts for the complex nature of the sample. While the HosmerLemesh, test is not without imperfections, it is the best we have right now, and it will let you know immediately if your model is not reflecting the true outcome experience in the data. The likelihood ratio test is not a measure of fit. It simply tests the significance of terms in a model or between models. There is some discussion about 2 x 2 classification tables. We believe that sun tables are only of limited value if the objective of your model is to make a binary prediction for each subject. The model may have very poor fit and have good classification. First, you need to examine fit. Also, when you place a subject into a 2 x 2 classification table, you are losing a lot of information about that subject's probability of having the outcome. That is, a subject whose probability is .02 is considered the same for purposes of classification as another subject whose probability is .48. Similarly, a subject whose probability is .48 is predicted to have un entirely different outcome than one whose probability is .52. This seems to me to represent a distortion of the meaning of probability. Confidence intervals could be calculated for each subject, but it is not clear what you would do with them. \nThe R2 is not appropriate for logistic models. As noted by Agresti, \"Despite several attempts to define analogs of R2 for models for categorical responses, no proposed measure seems as widely useful as the regression R2.\"68 Agresti proposes a couple of measures that are essentially based on the maximized log likelihood. This study uses the (quite reasonable) approach of reporting the odds ratio. The logit L for a group is really x'B. When the variable is categorical, you can report e3. However, when the variable is continuous, for example, AGE*AGE in table 21, the value reported e3 = 1.00 is the odds for a teacher who is 1-year-old! For a teacher with AGE = 25, the odds is exp (.002 *25 *7,5)= 3.5 # 1.00. The odds can be reported by centering the continuous variables at their mean value. I do not believe that reporting the estimated probabilities P = ex'3/(1 + ex '3) will be very informative. However, it might be worth trying to do so since this is not difficult to calculate.69 The stochastic assumptions for the classical logistic models are not satisfied by complex designs. In particular, the homogeneity of the population clusters will tend to increase the variance of the estimated parameters over the usual asymptotic estimators. It is interesting that this phenomenon did not occur, perhaps indicating that teachers are acting independent of the school effect."}, {"section_title": "Summary", "text": "Overall, the lack of meaningful results are possibly due to several factors, including: 1) the extreme split between leavers and stayers as you suggest; 2) the use of variables that at least appear to be highly correlated; 3) the use of too many dummy variables (it would be Jeferable to use continuous variables); and 4) the possible lack of good work-related measures (e.g., school climate, administrative support, etc.), although it was difficult to evaluate these variables due to insufficient description. Keith Rust, Ph.D., Westat\nThe authors have done a good job of trying to deal with the technical issues involved in using logistic regression with complex survey data. However, I see three major problems. First, logistic regression just does not really explain why teachers leave teaching. The values in tables 22 and 24 are either close to 1 or else are extremely unreliable, as in the case of \"male.\" Second, no consideration has been given to possible interactions among the significant main effects. It seems highly plausible that such interactions might exist and might even substantially increase the explanatory power (fit) of the models. Finally, there is no discussion of the interpretation or plausibility of the final models. What is the overall message? Does it make sense, for example, in table 24 that \"high satisfaction with salary\" has a positive coefficient, indicating that those more satisfied are more likely to leave? The discussion in Chapter 6 (Conclusions) of whether the sample of teachers who leave for career reasons is too small to be systematically different from other teachers gets to the heart of the problem in identifying the characteristics of a relatively rare group. It is unlikely that the 63Edward L. Korn and Barry 1. Graubard, \"Simultaneous Testing of Regression Coefficients With Complex Survey Data: Use of Bonferroni t Statistics,\" The American Statistic/an 44 (1990):270-76. really important variables have been measured. The only real hope lies in looking at two-way and perhaps higher order interactions, which was not done. Stanley Lemeshow, Ph.D., Professor and Chair, Biostatistics and Epidemiology University of Massachusetts, Amherst"}, {"section_title": "Chapter 6 Conclusions", "text": "Previous w -)rk on teacher supply and demand and attrition provided a strong basis for expecting to find a relationship between teacher attrition and various teacher, school, and district characteristics. Despite the extensive data on these characteristics available from SASS, the logistic regression methods used failed to provide evidence of many of the expected relationships. In addition, methodological problems plagued efforts to obtain definitive results. The reviewers, whose comment were summarized in Chapter 5, seemed to agree that our major hypotheses were sound, that the types of variables we included were appropriate, and that logistic regression was an appropriate methodology for testing them. However, they had a number of useful comments on the general approach taken in developing the models tested, the specification of the variables, and the interpretation of the results. They proposed a number of interesting possibilities that merit serious consideration for additional research. This chapter outlines our major conclusions and makes recommendations for additional analysis taking these comments into consideration. 1) The models tested were too large and should be reformulated. Several reviewers believed that we had too many variables and that this was leading to unstable results and possibly causing the problems with singular matrices. Additional analysis with fewer variables might produce more definitive results. Although a much smaller model would be a useful goal, theory suggests that it is important to include variables that measure personal characteristics, qualifications, and working conditions. Selecting only a few variables may be difficult because of the relatively large number of factors that previous research has shown to be related to attrition. One possibility (suggested by Billingsley) would be to use either principal components or factor analysis to identify variable groups. Interactions among the independent variables also need more thorough analysis. 2) A test of the overall fit of the model should be performed. Currently, the only valid test of the overall fit of a logistic regression model is the Hosmer-Lemeshow test. This test is available in SAS 6.07, but not in WESLOG, the logistic regression program we used because it was designed for analyzing data collected in surveys using complex sampling designs. Lemeshow suggested that we fit the model with SAS first, perform the Hosmer-Lemeshow test, and then once we have a model that we like, re-run the model using WESLOG so that the standard errors of the parameters can be computed correctly. 3) The relatively small number of leavers may have contributed to the difficulty in obtaining results. The sample of teachers who left for career reasons may have been too small to be systematically different from all teachers. That is, leaving may have been too rare an event. With only a small percentage of all teachers leaving for career reasons, there may have been too much variation in the rest of the population of teachers to identify systematic differences. For example, even though a certain number of math teachers will leave because of better employment opportunities, most math teachers will not leave. Even if teachers who left had a distinguishing characteristic such as a BA in education, the group of stayers included many with a BA in education. Not only would a statistical test not find the difference significant because of the small sample of leavers, but from a practical standpoint, if the larger group includes all the characteristics that seem to be defining the leavers, then it is not possible to predict which of the teachers with the characteristic are likely to leave. Modeling public and private school teachers together (with sector as a dummy variable) might help solve this problem, because the total number of leavers ....uld be increased. Rust suggested another reason for combining public and private school teachers in one model. He pointed out that differences in attrition rates may be due to differences in the distributions of public and private school teachers by age and sex and that this might not be possible to detect with separate models. Being able to examine public/private school effects controlling for factors such as age and sex would be interesting. 4) The time frame for the analysis may have been too short. The TFS data allow us to measure attrition in only one year. It is possible that this is too short a time period. The leavers may not differ systematically from non-leavers in a given year, but might over a longer time period. In other words, math teachers might have a greater probability than other teachers of leaving teaching at some time, but the probability that a math teacher leaves in a given year may be small. It is almost certainly smaller than the probability of leaving in a five year period. To identify factors related to attrition, it may be necessary to study attrition over periods longer than one year. With the SASS and TFS data, however, the analysis is necessarily limited to oneyear attrition. Despite the lack of definitive findings from the multivariate analysis, this research effort has contributed to our understanding of how the SASS and TFS data can he used to study issues related to teacher supply and demand and what methodological approaches are feasible. NCES will continue to work in this area and will pursue some of the directions suggested in this report.     The precision with which one can use survey results to make inferences to a population depends upon the magnitude of both sampling and nonsampling errors. In large sample surveys, such as the SASS, sampling errors are generally minimal, except when estimates are made for relatively small subpopulations (Native Americans, for example)."}, {"section_title": "Response Rates and Imputation", "text": "Most item-level missing data on the district and school files were imputed using a sequential hot deck procedure that matched the nonrespondent district or school with the most similar respondent in the same stratum. \"Most similar\" was determined on the basis of metropolitan status, percent minority, and enrollment. On the public school file, all missing items were imputed. On the private school file, items 7 and 35 were not imputed. On both the public and private teacher demand and shortage file, items 3, 11, 12, 13, and 28 were not imputed. No imputation was done for either the teacher or administrator files or for the teacher followup. Item nonresponse was treated as missing data in the computation of estimates for tables that include data from either of these files. This is equivalent to assuming equal distributions for both respondents and nonrespondents. Not imputing for item nonresponse when averages are estimated results in bias, and the nature of this bias is unknown. The weighted response rates for the each of the surveys were as follows: "}, {"section_title": "75.9", "text": "The response rates for the items used from the teacher files are listed below. They do not reflect additional response loss due to complete questionnaire refusal. 75The effective response rate shown here is the product of the response rates to the Teacher Survey, which were 86.4 percent (public) and 79.1 percent (private), and the Followup Survey, which were 97.3 percent (public) and 96.0 percent (private). 99.4* Table 16 Certification in main field 99.0 99.4 Table 17 Plans to return to teaching (leavers) 99.4* When might return to teaching (leavers) 98.6* A public school was defined as an institution that provides educational services, has one or more teachers, is located in one or more buildings, receives public funds as primary support, and is operated by an education agency. Prison schools and schools operated by the Department of Defense and the Bureau of Indian Affairs were included. A private school was defined as a school not in the public system that provides instruction for any of grades 1-12 where the instruction was not given exclusively in a private home. To he included in SASS, a school was required to have a minimum school day of 4 hours and a minimum school year of 160 days, and it had to provide instruction to students at or above the first-grade level and not he in a private home. (If it could not he determined that instruction was not in a private home, the school had to have at least 10 students or more than one teacher.) In addition, the school could not offer only adult, night, or specialized courses."}, {"section_title": "Community Type", "text": "Respondents to the School Questionnaire were asked to describe the community that best described the community in which the school was located. They were given ten choices, which were aggregated into four categories as follows: Rural/farming A rural or farming community or an Indian reservation."}, {"section_title": "Small city", "text": "A small city or town of fewer than 50,000 people that was not a suburb of a larger city. A suburb of a medium-sized, large, or very large city, or a military base or station."}, {"section_title": "Suburban", "text": ""}, {"section_title": "Urban School Level", "text": "A medium-sized city (50,000 to 100,000 people), large city (100,00.0 to 500,000 people), or very large city (more than 500,000 people)."}, {"section_title": "Elementary", "text": "A school that had grade 6 or lower, or \"ungraded,\" and no grade higher than the 8th."}, {"section_title": "Secondary", "text": "A school that had no grade lower than the 7th, or \"ungraded,\" and some grade between 7th and 14th."}, {"section_title": "Combined", "text": "A school that had grades higher than the 8th and lower than the 7th."}, {"section_title": "Minority Lnrollment", "text": "Less than 5%, Categories were based on the percentage of the students who were American etc. Indian or Alaskan Native; Asian or Pacific Islander; Hispanic, regardless of race (Mexican, Puerto Rican, Cuban, Central or South American, or other culture or origin); Black (not of Hispanic origin)."}, {"section_title": "Public School District", "text": "A public school district (or Local Education Agency, LEA) was defined as a government agency administratively responsible for providing public elementary and/or secondary instruction and educational suport services. The agency or administrative unit had to operate under a public board of education. Districts that operated only one school and districts that did not operate schools but did hire teachers were included. A district was considered out of scope if it did not employ elementary or secondary teachers."}, {"section_title": "Region", "text": ""}, {"section_title": "Northeast", "text": "Maine, New Hampshire, Vermont, Massachusetts, Rhode Island, Connecticut, New York, New Jersey, Pennsylvania Midwest Ohio, Indiana, Illinois, Michigan, Wisconsin, Minnesota, Iowa, Missouri, North Dakota, South Dakota, Nebraska, Kansas South Delaware, Maryland, District of Columbia, Virginia, West Virginia, North Carolina, South Carolina, Georgia, Florida, Kentucky, Tennessee, Alabama, Mississippi, Arkansas, Louisiana, Oklahoma, Texas West Montana, Idaho, Wyoming, Colorado, New Mexico, Arizona, Utah, Nevada, Washington, Oregon, California, Alaska, Hawaii Teacher For the purposes of SASS, a teacher was any full-or part-time teacher whose primary assignment was to teach in any of grades K-12. Itinerant teachers and long-term substitutes who were filling the role of a regular teacher on an indefinite basis were also included. An itinerant teacher was defined as a teacher who taught at more than one school. Teachers were classified as elementary or secondary on the basis of the grades they taught rather than the schools in which they taught. An elementary school teacher was one who, when asked for the grades taught, checked: Only \"ungraded\" and was designated as an elementary teacher on the list of teachers provided by the school; or 6th grade or lower, or \"ungraded\" and no grade higher than 6th; or 6th grade or lower and 7th grade or higher, and reported a primary assignment of prekindergarten, kindergarten, or general elementary; or 7th and 8th grades only, and a reported primary assignment of prekindergarten, kindergarten, or general elementary; or 6th grade or lower and 7th grade or higher, and reported a primary assignment of special education and was designated as an elementary teacher on the list of teachers provided by the school; or 7th and 8th grades only, and reported a primary assignment of special education and was designated as an elementary teacher on the list of teachers provided by the school. A secondary school teacher was one who, when asked for the grades taught, checked: \"Ungraded\" and was designated as a secondary teacher on the list of teachers provided by the school; or 6th grade or lower anti 7th grade or higher, and reported a primary assignment other than prekindergarten, kindergarten, or general elementary; or 9th grade or higher, or 9th grade or higher and \"ungraded\"; or 7th and 8th grades only, and reported a primary assignment other than prekindergarten, kindergarten, general elementary, or special education; or 7th and 8th grades only, and reported a primary assignment of special education and was designated as a secondary teacher on the list of teachers provided by the school; or 6th grade or sower and 7th grade or higher, or 7th and 8th grades only, and were not categorized above as either elementary or secondary."}, {"section_title": "Comments and More Information", "text": "We are interested in your reaction to the information and analysis presented here and to the content of the questions used to produce these results. We welcome your recommendations for improving our survey work. If you have suggestions or comments or want more information about this report, please contact: "}]