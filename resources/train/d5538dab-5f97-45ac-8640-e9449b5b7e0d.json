[{"section_title": "Abstract", "text": "Many biomedical studies have identified important imaging biomarkers that are associated with both repeated clinical measures and a survival outcome. The functional joint model (FJM) framework, proposed in Li and Luo (2017), investigates the association between repeated clinical measures and survival data, while adjusting for both high-dimensional images and low-dimensional covariates based upon the functional principal component analysis (FPCA).\nIn this paper, we propose a novel algorithm for the estimation of FJM based on the functional partial least squares (FPLS). Our numerical studies demonstrate that, compared to FPCA, the proposed FPLS algorithm can yield more accurate and robust estimation and prediction performance in many important scenarios.\nWe apply the proposed FPLS algorithm to the Alzheimer's Disease Neuroimaging Initiative (ADNI) study. Data used in the preparation of this article were obtained from the ADNI database."}, {"section_title": "Introduction", "text": "Many prospective cohort studies and clinical trials investigating neurodegenerative diseases such Alzheimer's disease (AD) collect repeated measurements of clinical variables, event history and biomedical imaging data. A motivating example is the Alzheimer's Disease Neuroimaging Initiative (ADNI) study. ADNI currently has 4 phases: ADNI1, ADNI-GO, ADNI2 and ADNI3, and the primary goal is to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET) and neuropsychological assessments can be used to measure the progression of AD. Participants were assessed at multiple visits. At each visit, various clinical measures, brain images and neuropsychological assessments were collected. Detailed information about ADNI can be found on the official website \"http://www.adni-info.org\".\nSince mild cognition impairment (MCI) is known as a transitional stage between normal cognition and AD, it is of great interest to predict the progression from MCI to AD. Thus, we selected 236 patients who had been diagnosed with MCI from ADNI1 without missing data in the covariates of interest. The selected patients had at least one Alzheimer's Disease Assessment Scale-Cognitive (ADAS-Cog) score after the baseline measurement. The ADAS-Cog score measures cognition functions and ranges from 0 to 70, with a higher score indicating poorer cognitive function. We consider the AD diagnosis as the survival event of interest.\nAmong the 236 individuals, 92 individuals progressed to AD before the completion of ADNI1 and the remaining 144 individuals did not. Thus, the time of conversion from MCI to AD can be treated as right censored time-to-event data and the censoring is non-informative about the progression to AD. Demographic information of the selected 236 patients and summary statistics of the ADAS-Cog score can be found in the supporting information. Figure 1 displays the average ADAS-Cog score at each follow-up time separately for the MCI and AD group. It can be seen that the ADAS-Cog score increases with time for the AD group, whereas for the MCI group, the trend is not evident. The AD group tends to have higher ADAS-Cog scores, indicating that the ADAS-Cog score may be predictive to the progression of AD. Moreover, a lot of existing work reported the association between brain imaging predictors with the progression of AD. For example, AD and MCI patients were shown to have 27% and 11% smaller hippocampal volumes respectively as compared with normal controls (Du et al., 2001) . Lee et al. (2015) and Kong et al. (2018) both demonstrated the predictive value of the hippocampus surface data to the progression of AD.\n[ Figure 1 about here.] Thus, it is of great interest to examine the association between longitudinal ADAS-Cog scores and the progression of AD while adjusting for high-dimensional imaging predictors. A recent work by Li and Luo (2017) proposed a functional joint model (FJM) for this purpose.\nFJM integrates functional regression models with joint models of longitudinal and timeto-event data. There is a rich literature in both areas. For instance, in the past decades, generalized functional linear models (GFLM) have been widely discussed and applied in various areas including finance, biology and sociology. Please see Cardot et al. (1999 Cardot et al. ( , 2003 , M\u00fcller and Stadtm\u00fcller (2005) and the references therein for an extensive review of GFLM.\nThen, Yao et al. (2005) extended GFLM to longitudinal data, and Lee et al. (2015) and Kong et al. (2018) both extended GFLM to the proportional hazards model. Some of the earliest work on joint models of longitudinal and time to event data is in Tsiatis et al. (1995) and Wulfsohn and Tsiatis (1997) .\nThe major challenge of fitting a functional model, including FJM, is the ultrahigh dimensionality of the functional predictor. A common strategy is to find the \"best\" low-dimensional features that approximate the high-dimensional functional predictor, which is also known as dimension reduction. The functional principal component analysis (FPCA) has been a popular dimension-reduction tool for functional data over decades. See an extensive review and application of FPCA in Besse and Ramsay (1986) , Dalzell (1991), Boente and Fraiman (2000) , James et al. (2000) , Cai and Hall (2006) , M\u00fcller and Yao (2010) , Li and Luo (2017) and the references therein. Based upon the eigen-decomposition of the covariance kernel of the functional data, FPCA finds the low-dimensional space that preserves most of the variation of the functional data; that is, the space spanned by top eigenfunctions. While FPCA serves as a promising tool for exploring functional data, there are two major concerns when it comes to regression. First, as the unknown slope function may not necessarily lie in the space spanned by top eigenfunctions, the estimation and prediction accuracy may suffer if the number of eigenfunctions used for regression is underestimated. Second, it is well known that consistent estimation of eigenvectors is highly challenging in ultrahighdimensional settings (Jung and Marron, 2009) , especially for tail eigenvectors. These two concerns bring up a natural question: if (part of) the unknown slope function lies in the space spanned by some tail eigenfunctions, which cannot be accurately estimated due to the limited sample size, is there an alternative and better approach to estimate the unknown slope function?\nTo address this question, we consider the functional partial least squares (FPLS), first proposed by Preda and Leveder (2005) for functional linear models (FLM). Compared to FPCA, FPLS has two major advantages. First, FPLS does not depend on accurate estimates of eigenfunctions. Second, FPLS incorporates information from the outcome so that the top FPLS basis functions are always the most predictive to the outcome. However, due to its computational and theoretical complexity, FPLS has not gained enough popularity until the recent work by Delaigle and Hall (2012) that proposes a simplified FPLS algorithm for FLM, called alternative PLS (APLS). Through numerical studies, Delaigle and Hall (2012) demonstrates that APLS can capture the interaction between the functional predictor and the outcome using a fewer number of components than FPCA.\nMotivated by the encouraging performance of APLS, in this article, we propose an FPLS algorithm for the estimation and prediction of FJM. Our specific contributions include: (i)\nWe extend APLS to the complex FJM framework in a rigorously mathematical manner;\n(ii) we show by numerical studies that the proposed FPLS algorithm can yield considerably more accurate, robust estimation and prediction results than FPCA in many important scenarios and (iii) unlike the FPCA-based algorithm in Li and Luo (2017) that only handles baseline imaging data, our FPLS algorithm can deal with longitudinal imaging data; this allows to dynamically predict disease progression. The rest of the paper is organized as follows. Section 2 introduces the FPLS algorithm for FJM. Section 3 discusses the details of the implementation of the FPLS algorithm. Section 4 presents a simulation study with ultrahigh-dimensional images in various settings. Section 5 presents a thorough analysis of the selected 236 ADNI patients. Concluding remarks and discussions are presented in Section 6."}, {"section_title": "Methods", "text": "In this section, we first introduce the FJM proposed by Li and Luo (2017) . Then, we review APLS for FLM proposed by Delaigle and Hall (2012) . Next, we extend APLS for FJM."}, {"section_title": "FJM", "text": "For each subject i = 1, . . . , n at visit k = 1, . . . ,\ny ik is the outcome of interest observed at time t ik , z ik is a p z \u00d7 1 vector observed at t ik and \u03c9 i is a p \u03c9 \u00d7 1 vector of time-invariant covariates, which may overlap with z ik . The and censored otherwise. It is assumed throughout the paper that the censoring mechanism is independent of the true event process.\nThe FJM in Li and Luo (2017) consists of a longitudinal model and a survival model. The longitudinal model is given by\nwhere m i (t ik ) is the unobserved true longitudinal trajectory of the i-th subject at t ik , q ik is a subset of z ik , \u03b2 0 is the intercept, \u03b2 1 is a p z \u00d7 1 vectors of regression coefficients, and b 0 (s)\nis the functional parameter that characterizes the association between x i (s) and y ik . We also\nThe survival model is given by\nwhere \u03bb 0 (t) is an unknown baseline hazard function, \u03b3 is a p \u03c9 \u00d7 1 vector of regression coefficients, and b 1 (s) is the functional parameter that characterizes the association between\nx i (s) and the survival outcome. The scalar parameter \u03b1 quantifies the association between the true longitudinal trajectory and the survival process at the same time.\nRemark 1: We discuss our assumptions on FJM (1) and (2). First, the longitudinal marker y ik in (1) is assumed to be normally distributed, which is a standard assumption in the literature. The association between the longitudinal and time-to-event processes is represented by the proportional hazards model (2), in which m i (t) is assumed to be continuous. For definiteness, the conditional hazards function \u03bb i (t|\u03c9 i , x i (s), u i ) is taken to depend linearly on the longitudinal marker through the current m i (t).\nRemark 2: The FJM (1) and (2) can be extended to a more general FJM framework as follows:\nand\nNote that compared with (1), the longitudinal model (3) involves longitudinal imaging data.\nThis extension is appealing in many applications because it allows the dynamic prediction of disease progression. It is worth noting that the FPLS algorithm that will be introduced later can be seamlessly applied to this general FJM framework (3) and (4). But to simplify the notation, we stick to the FJM (1) and (2) in the following sections for illustrating our key ideas."}, {"section_title": "The APLS algorithm", "text": "We review APLS proposed by Delaigle and Hall (2012) for the following FLM:\nwhere is a scalar random variable with E( |x) = 0, a 0 is an intercept, and b(s) is an unknown coefficient function. Let K(\u03c8)(t) = S K(s, t)\u03c8(s)ds be a functional operator where K(s, t) = Cov (x(s), x(t)). The first p APLS basis functions can be constructed as\nCompared to the FPCA basis functions, i.e., the eigenfunctions of K(s, t), the APLS basis functions have two important features. First, the APLS basis functions involve the unknown parameter b(s), indicating that the APLS basis functions incorporate information from both the functional predictor and the outcome. Second, the APLS basis functions are not orthonormal. To see the latter feature clearly, consider an example that\n0 is a sequence of non-increasing eigenvalues and \u03c6 1 (\u00b7), \u03c6 2 (\u00b7), . . . are their corresponding orthonormal eigenfunctions. It can be seen that K(s, t) = Cov(x(s),\nThen, it can be seen that the p-th APLS basis function is given by\nindicating that any two APLS basis functions are not orthogonal to each other.\nAlthough b(s) is unknown, a consistent estimator of K(b) = S K(s, t)b(s)ds is given by\nwhere y = n \u22121 n i=1 y i and x(s) = n \u22121 n i=1 x i (s). Then, we can sequentially estimate all APLS basis functions by using\n2.3 The RAPLS algorithm\nThe APLS algorithm cannot be directly applied to FJM (1) and (2) due to two reasons.\nFirst, it does not adjust for additional scalar covariates. Second, the estimator K(b)(s) in (6) is not a good estimator of K(b)(s) when the the relationship between x(s) and y is nonlinear.\nTo bridge the gap, we first extend the APLS algorithm to the following model:\nwhere \u03b1 is a p z \u00d71 vector of regression coefficients and i is an error term with E( i |x i , z i ) = 0\nIt is assumed that z i includes a constant 1. To estimate b(s) and \u03b1, we develop a residual-based APLS (RAPLS) algorithm. Specifically, model (8) can be rewritten in the following matrix form:\nLet H Z = Z(Z T Z) \u22121 Z T be the orthogonal projection matrix onto the column space of Z and M Z = I n \u2212 H Z , where I n denotes an n \u00d7 n identity matrix. By multiplying both sizes of (9) by M Z , we have\nwhere \u22a5 Z = M Z . Model (10) can be regarded as a special case of model (5) with the response vector Y \u22a5 Z and the functional covariate X \u22a5 Z (s). In this case, we need to introduce a new functional operator as follows:\nThe operator K \u22a5 Z (\u03c8)(t) corrects the correlation between z and x(s). If z and x(s) are independent, then K \u22a5 Z (\u03c8) reduces to K(\u03c8). Therefore, the first p RAPLS basis functions for model (10) are given by\nThen, we can sequentially estimate all RAPLS basis functions by using\nwhere ||a|| 2 = a T a for any column vector a. Therefore, one can estimate b(s) and \u03b1"}, {"section_title": "The FPLS algorithm for FJM", "text": "We develop an FPLS algorithm for the FJM (1) and (2) in an iterative way by integrating RAPLS with the iterative reweighted least squares (IRLS, Green, 1984) . Before discussing the details, we introduce some additional notation. Let y i = (y i1 , . . . , y iK i ) T , z i = (z i1 , . . . , z iK i ) and q i = (q i1 , . . . , q iK i ). We define \u03b4 i = q T i u i + i where i = ( i1 , . . . , iK i ) T . Let 1 K i denote a K i \u00d7 1 vector of ones and \u039b 0 (t) = t 0 \u03bb 0 (u)du denote the cumulative baseline hazard function. Denote \u0398 = {\u03b2 0 , \u03b2 1 , \u03b3, \u03b1, \u03a3 u , \u03c3 2 } and let p 0 and p 1 be the number of RAPLS basis functions used for the estimation of b 0 (s) and b 1 (s), respectively. We further denote\n1,p 1 (s) and \u039b (m) 0,p 0 ,p 1 (\u00b7) as the evaluation of \u0398, b 0 (s), b 1 (s) and \u039b 0 (\u00b7) respectively at the m-th iteration for m 1. In the following discussion, we elaborate on how to obtain\n1,p 1 (s) and \u039b (m) 0,p 0 ,p 1 (\u00b7) given their values at previous iteration for m 1 in three steps.\nStep 1: We first rewrite model (1) as follows:\nIt can be seen that Cov\nto the left on both sides of (11), (11) can be reformulated as an ordinary least squares (OLS) problem, given by\nNote that (12) has the same form as (8), and thus we can calculate the top p 0 RAPLS basis functions for (12). To simplify the notation, we denote these RAPLS basis functions by \u03c8 (m) 1 (s), . . . , \u03c8 (m) p (s). Then, model (1) can be approximated by\nand b 0 (s) can be approximated by p 0 j=1 b 0,j \u03c8 (m) j (s).\nStep 2:\nGiven\n1,p 1 (s) and \u039b (m) 0,p 0 ,p 1 (\u00b7), \u00b5 i still cannot be evaluated because of the unobserved random effects u i in m i (T i ). To deal with this, for any integrable function h(u i ), we define\nas the the posterior expectation of h(u i ) at the m-th iteration. Then, we can evaluate \u00b5 i as:\nFollowing IRLS, for i = 1, . . . , n, we can define the pseudo-response y (m) i for subject i at the m-th iteration as:\nWe provide the details for deriving (14) in the supporting information. Next, we consider the following model:\nNote that (15) has the same form as (8) \nand b 1 (s) can be approximated by p 1 j=1 b 1,j \u03b6 (m) j (s).\nStep 3: Note that FJM (1) and (2) are now, respectively, approximated by the standard joint model with low-dimensional covariates (13) and (16). Due to the unobserved random effects u i , we propose to fit (13) and (16) by the EM algorithm (Dempster et al., 1977) . The details of the EM algorithm are given in the supporting information. Let \u0398 (m+1) p 0 ,p 1 , \u039b \nWith appropriate initial values, the proposed FPLS algorithm for FJM is done by iterating between Steps 1, 2 and 3 until S b\nds is less than a given threshold \u03ba 0 , which is set to be 10 \u22126 in the following numerical studies."}, {"section_title": "Implementation", "text": ""}, {"section_title": "Convergence", "text": "Based on our experience in numerical studies, we make several comments for facilitating the convergence of the proposed FPLS algorithm. Then, by using the CauchySchwarz inequality, it is easy to show that\nwhere x(s) 2 = ( S x 2 (s)ds) 1/2 . This implies that a sensible way to scale x i (s) is\nto multiply x i (s) by a constant such that x i (s) 2 has comparable size to the scalar predictors.\n(iii) As for most iterative algorithms, an appropriate choice of initial values is critical for the convergence of the algorithm. We use the FPCA estimates as the initial values for the proposed FPLS algorithm. The key to finding the FPCA estimates is estimating eigenfunctions. Unlike Li and Luo (2017) , which advocates the fpca.sc function in the refund package (Goldsmith et al., 2018) or fpca.mle and fpca.score functions in the fpca package (Peng and Paul, 2011) in R, we use the method based on the singular value decomposition (SVD) proposed by Zipunnikov et al. (2011) . The reason is that the two R packages advocated by Li and Luo (2017) can be computationally intensive with ultrahigh-dimensional images. For example, to perform FPCA for a data set with 200 subjects, each having a 300 \u00d7 300 image (the simulation study in Section 4), fpca.sc and fpca.mle require at least 60 Gb of RAM memory and take hours to run, whereas the SVD method only requires less than 6 Gb of RAM memory and finishes in seconds.\nOnce eigenfunctions are estimated, one can follow the method in Li and Luo (2017) to obtain the FPCA estimators.\n(iv) We also suggest a step of stochastic approximation to accelerate the convergence.\nSpecifically, instead of using (17) to obtain the updates b\nHere, a (m) is called the step size at the m-th iteration. As demonstrated in Walk (1978) , Yin and Zhu (1990) and the references therein, flexible step sizes can accelerate the convergence of the algorithm as well as stabilize the performance. In our numerical studies, we use a (m) = 1/m.\nTo apply the proposed FPLS algorithm to 2D or 3D images, one can vectorize them in any way since the proposed algorithm is invariant with respect to arbitrary vectorization of the images. In our real data analysis where each image has more than 500,000 voxels, each iteration of the proposed algorithm takes less than 1 minute to run, and the entire algorithm becomes stable in a few steps.\n3.2 Choice of p 0 and p 1 So far we have discussed the algorithm with predetermined p 0 and p 1 . As demonstrated in Li and Luo (2017), changing p 0 and p 1 can have a large effect on the estimation accuracy of the parameters in FJM. Generally, smaller p 0 and p 1 may lead to a larger bias, whereas larger p 0 and p 1 may lead to a larger variance. To balance bias and variance, we use the Bayesian information criterion (BIC) to choose p 0 and p 1 . Specifically, let \u0398 p 0 ,p 1 , b 0,p 0 (s), b 1,p 1 (s) and \u039b 0,p 0 ,p 1 (\u00b7) be the estimates of \u0398, b 0 (s), b 1 (s) and \u039b 0 (\u00b7). Then, the BIC statistic is defined as BIC(p 0 , p 1 ) = log(n)(p 0 + p 1 ) \u2212 2 log(L n,com ( \u0398 p 0 ,p 1 , b 0,p 0 (s), b 1,p 1 (s), \u039b 0,p 0 ,p 1 (\u00b7)))du 1 \u00b7 \u00b7 \u00b7 u n , where L n,com ( \u0398 p 0 ,p 1 , b 0,p 0 (s), b 1,p 1 (s), \u039b 0,p 0 ,p 1 (\u00b7)) is the complete data likelihood, of which the explicit from is given in the supporting information. Numerically, we can use a grid search to find the optimal p 0 and p 1 that minimize BIC(p 0 , p 1 )."}, {"section_title": "Simulation Study", "text": "In this section, we carry out a simulation study to compare the proposed FPLS algorithm with FPCA for FJM (1) and (2). For i = 1, . . . , n, we first independently simulated X i (s) according to the generating process\nwhere eigenimages \u03c6 k (s) are displayed in Fig. 2 and S = [1, 300]\u00d7[1, 300]. These eigenimages can be thought of as 2D greyscale images with pixel intensities on the [0, 1] scale. The black pixels are set to 1 and the white ones are set to 0. We generated Z i from a normal distribution with mean 0 and variance \u03be 2 i2 /9. This indicates that Z i and X i (s) are correlated. We denote N (0, 1) . Then, the true event time T i was generated based on the proportional hazards model as follows:\nNext, we independently generated the censoring time C i from a uniform distribution U (0, c 0 ), where c 0 > 0 controls the censoring rate. Instead of observing both T i and C i , we only observed T i = min(T i , C i ) and \u2206 i = I(T i C i ). Next, the longitudinal follow up time {t ij } j=1,2,3 was simulated from a uniform distribution in (0, T i ), as only the measurements that are collected before the observed survival time can be used to predict the survival event.\nThen, the longitudinal outcome y ij was generated by\n\u223c N (0, 0.4 2 ). We set \u03b2 0 = 0.7, \u03b2 1 = 1, \u03b2 2 = 2, \u03b1 = 2 and \u03b3 = 2, and consider two scenarios of b 0 (s) and b 1 (s):\n[ Figure 2 about here.]\nWe consider n = 200 and 500. The c 0 is selected for each scenario to yield a censoring rate of 60% that mimics our real data analysis. For each pair of n and c 0 , we generated 1000 independent data sets. For simplicity, here we consider the same number of basis functions to estimate b 0 (s) and b 1 (s), i.e., p 0 = p 1 = p. In practice, p 0 and p 1 can be different; this will be considered in the real data analysis in Section 5. The optimal p was then selected by the BIC statistic, given in Section 3.2. For the implementation of both FPLS and FPCA, generated images X i (s)'s were unfolded to obtain vectors of size d = 300 \u00d7 300 = 90000. As mentioned in Section 3.1, our implementation of FPCA is different from that in Li and Luo (2017) , and the FPLS algorithm uses the FPCA estimates as the initial values.\nWe examined the mean squared error (MSE) for both functional parameters according to\nis the FPCA or FPLS estimator of b j (s) for j = 0 and 1. Fig. 3 shows results for scenario (i). In this scenario, both b 0 (s) and b 1 (s) are only informed by the top 5 eigenimages. The weight of the j-th eigenimage, j \u22121.5 , decreases fast as j increases; this further favors FPCA. It can be seen that the proposed FPLS algorithm performs comparably to FPCA: FPLS yields a more accurate estimate of b 0 (s), whereas FPCA performs slightly better in terms of estimating b 1 (s). This is sensible because the IRLS procedure used for the survival model may introduce more error. In scenario (ii) that does not favor FPCA, as shown in Fig. 4 , the proposed FPLS algorithm has considerably higher estimation accuracy than FPCA for both b 0 (s) and b 1 (s). In particular, It can be seen from Fig. 4C that our FPLS algorithm yields accurate estimation of b 0 (s), whereas FPCA yields an MSE over 2. A straightforward calculation yields that S b 2 0 (s)ds = 2.28, indicating that FPCA can barely capture any information from b 0 (s). To see the reason clearly, we first note that b 0 (s) lies in the span of the fifth to the ninth eigenimages. Unfortunately, these eigenimages cannot be consistently estimated in such an ultrahigh-dimensional setting (d n). Thus, BIC tends to select small p (p < 5) for FPCA, indicating that the resulting FPCA estimator is very close to 0. In contrast, since the FPLS basis functions incorporate information from the outcome, which contains information on b 0 (s), the FPLS estimator can still yield an accurate estimate of b 0 (s) regardless of the inconsistent estimates of the eigenimages. In practice, since we never know how the functional predictor informs the outcome, the proposed FPLS algorithm may be a more robust and accurate prediction tool, especially in neuroimaging studies with high-dimensional images and limited sample size.\n[ Figure 3 about here.]\n[ Figure 4 about here.]"}, {"section_title": "Analysis of ADNI Data", "text": "In this section, we jointly model the longitudinal trajectory of ADAS-Cog score and the time of conversion from MCI to AD using the selected 236 subjects. Specifically, we consider\nHere, t ij is the follow-up time for the i-th subject at the j-th visit and y ij is the ADAS-Cog score of the i-th subject at the j-th visit. The scalar covariate vector z i includes gender (1=male; 0=female), handedness (1=right; 0=left), and age at the first MCI diagnosis. The functional predictor x i (s) is the PET imaging data measured on 160 \u00d7 160 \u00d7 96 voxels. PET directly measures the regional use of glucose, which indirectly reflects the brain activity of different brain regions. The PET images we used here underwent four preprocessing steps, which are introduced in detail in the supporting information. We also removed the background regions outside the skull, so around 500,000 voxels remained. The parameter \u03b1 links the two models. If \u03b1 is nonzero, then there may be an unobserved association between the longitudinal and survival outcome. The random intercept u i is assumed to be normally distributed with mean 0 and variance \u03c3 2 u . Given u i , ij follows a normal distribution with mean 0 and variance \u03c3 2 . The implementation of FPCA and FPLS is the same as that in Section 4.\nWe first used cross validation to compare the proposed FPLS algorithm with FPCA in terms of prediction accuracy of the survival time. To examine the predictive value of the longitudinal ADAS-Cog scores, we also predicted the survival time based on the following functional linear Cox regression model (FLCRM, Kong et al., 2018) :\nThe prediction accuracy was examined according to the concordance index (C-index, Harrell et al., 1996) , which can be calculated using the function \"concordance.index()\" in the R package \"survcomp\" (Schroeder et al., 2011) . More specifically, we randomly selected 118 subjects as the training set and the remaining 118 subjects form the test set. We repeated this procedure 100 times. For each method in each replication, we fitted the FJM using the training set with the optimal number of basis functions, i.e. p 0 and p 1 , selected by BIC, and then computed the C-index using the test set. Inspecting Fig. 5A shows that FPLS yields higher prediction accuracy than FPCA. Moreover, both FPLS and FPCA substantially outperform FLCRM, demonstrating that the ADAS-Cog score may be an important predictor of the progression from MCI to AD.\nTo examine the predictive value of PET imaging data, two reduced models are considered.\nThe first reduced model excludes the imaging predictor from the longitudinal model, and the second one excludes the imaging predictor from the survival model, denoted by R1 and R2, respectively. Using the same training and testing data sets, we fitted these two reduced models using our FPLS algorithm with the optimal p 0 or p 1 selected by BIC and calculated the C-index. Fig. 5B shows that two reduced models yield lower prediction accuracy than the FPLS in Fig. 5A , demonstrating the predictive value of the PET imaging data in terms of jointly predicting ADAS-Cog scores and the progression to AD. Moreover, as we aim at predicting the survival outcome, the prediction accuracy suffers more when the imaging predictor is removed from the survival model.\n[ Figure 5 about here.]\nFinally, we considered the complete cohort of 236 subjects to estimate the unknown parameters using our FPLS algorithm. The optimal p 0 and p 1 selected by BIC are 18 and 10, respectively. The estimated \u03b1 is 2.8, indicating that patients with higher ADAS-Cog score may be more likely to progress to AD. Fig. 6 displays the positive regions of the estimates of b 0 (s) and b 1 (s). It can be seen that several functional regions over the brain, such as the hippocampus, frontal lobe and temporal horn of the lateral ventricle are identified to be positively associated with the progression from MCI to AD.\n[ Figure 6 about here.]"}, {"section_title": "Discussions", "text": "In this article, we developed a novel FPLS algorithm for the estimation and prediction of FJM. We examined its performance in simulation studies and an application to ADNI. As shown in the numerical studies, FPLS can yield comparable results to FPCA in the setting that strongly favors FPCA, whereas it yields accurate estimates in the setting where FPCA completely fails. Hence, the proposed FPLS algorithm may be a more robust and powerful prediction tool for FJM than FPCA when massive neuroimaging data are involved.\nIt should be noted, however, that it is very challenging to theoretically derive (asymptotic) confidence intervals of any FPLS based estimators. The reason may be inherent to the key feature of FPLS; that is, the FPLS basis functions depend on the outcome. Consequently, the design matrix in FPLS regressions also involves the error term. Thus, bootstrapping methods have been suggested for constructing confidence intervals of PLS type of estimators (Wold et al., 2001) . Further studies of the inferential problems associated with the proposed FPLS algorithm may be a fruitful area of future research."}, {"section_title": "Acknowledgement", "text": "Dr. Zhu's work was partially supported by NIH grants R01MH086633 and R01MH116527.\nThe content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. Data used in the preparation of this article were obtained from the Alzheimers Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at http://adni.loni.usc.edu/wpcontent/uploads/how to apply/ADNI Acknowledgement List.pdf. "}]