[{"section_title": "List of Tables", "text": ""}, {"section_title": "TIMSS in Brief", "text": "The Trends in International Mathematics and Science Study (TIMSS) 2011 is the fifth such study since this international comparison of student achievement was first conducted in 1995. Developed and implemented at the international level by the International Association for the Evaluation of Educational Achievement (IEA), an international organization of national research institutions and governmental research agencies, TIMSS is used to measure trends in the mathematics and science knowledge and skills of fourth-and eighth-graders. TIMSS is designed to align broadly with mathematics and science curricula in the participating countries. The results, therefore, suggest the degree to which students have learned mathematics and science concepts and skills likely to have been taught in school. TIMSS also collects background information on students, teachers, curricula, and schools to allow cross-national comparisons of educational contexts related to student achievement. In 2011, there were 54 countries 1 and 20 other education systems (including all nine benchmarking states) that participated in TIMSS at the fourth-or eighth-grade level, or both. A detailed treatment of TIMSS 2011 from an international perspective can be found in three reports published by the IEA and available online at http://timssandpirls.bc.edu/timss2011/index.html."}, {"section_title": "\uf06e", "text": "TIMSS 2011 International Results in Mathematics (Mullis, Martin, Foy, & Arora, 2012); 1.4\nThe TIMSS and PIRLS U.S. international data files that are available as part of the international database released by the International Study Center. The U.S.-specific TIMSS data files can be downloaded from http://timssandpirls.bc.edu/timss2011/international-database.html. The U.S.-specific PIRLS data files are available separately and can be downloaded from http://timssandpirls.bc.edu/pirls2011/international-database.html. These data files conform to the international specifications common to the data files from all countries. However, they do not include the U.S.-specific adaptations made to a few questions in the questionnaires or the additional questions added to the school and student questionnaires, such as the question on race/ethnicity added to the student questionnaire. Data for U.S. states are not included in the international data files due to potential confidentiality issues. The TIMSS and PIRLS U.S. national public-use data files that are available through the National Center for Education Statistics. The TIMSS U.S. national dataset can be downloaded from http://nces.ed.gov/timss/datafiles.asp. The PIRLS U.S. national dataset can be downloaded from http://nces.ed.gov/surveys/pirls/datafiles.asp. These U.S. data files include (a) the U.S.-specific adaptations made to questionnaire items and (b) additional questions added to the school and student questionnaires.\nThe TIMSS and PIRLS U.S. national restricted-use data files that are available through the National Center for Education Statistics. Access to these files may be obtained by completing a restricted-use license agreement with NCES. The restricteduse data files are provided only on CD. These data files contain supplemental link files that link TIMSS or PIRLS school ID numbers to the school ID numbers as they appear in the publicly available Common Core of Data (CCD) or the Private School Universe Survey (PSS). In addition, race/ethnicity is provided with all available categories and free or reduced-price lunch is provided as a continuous variable. Because these data can reveal the identities of participating schools, the restricted-use data files are only made available to those who obtain a NCES restricted-use data license. Directions on how to obtain the license can be found at http://nces.ed.gov/pubsearch/licenses.asp. State data are available for each of the benchmarking states via state-specific, restricted-use data files. Access to these files may be obtained by completing a restricted-use license agreement with NCES. These restricted-use data files are provided only on CD. They contain all of the data in the public released national data files plus the supplemental link files that link TIMSS or PIRLS school ID numbers to the school ID numbers as they appear in the publicly available Common Core of Data (CCD) or the Private School Universe Survey (PSS). Because these data can reveal the identities of participating schools, the restricted-use data files are only made available to those who obtain a NCES restricted-use data license. Directions on how to obtain the license can be found at http://nces.ed.gov/pubsearch/licenses.asp. The most comprehensive treatment of the TIMSS and PIRLS international data, and hence of the U.S. international data file, is provided in the various TIMSS 2011 and PIRLS 2011 publications produced by the International Association for the Evaluation of Educational Achievement (IEA), particularly the TIMSS 2011 User Guide for the International Database (Foy, Arora, & Stanco, 2013) and the PIRLS 2011 User Guide for the International Database (Foy & Drucker, 2013). This publication should be seen as the primary reference. The TIMSS and PIRLS 2011 U.S. Technical Report and User Guide draws heavily on the international user's guide for much of its data file-related content. This content is supplemented with detail on those aspects of the TIMSS 2011 and PIRLS 2011 data that were unique to the United States.\nAny incomplete forms generated calls to the schools in question to provide the information or clarification necessary.\nCompleted forms were passed to data entry staff where the information was entered into WinW3S, and a CLF in WinW3S system format was generated.\nThe WinW3S CLF was compared with the original form as a check on the accuracy of data entry.\nQuestionnaires were sealed by students after completion.\nNames of students, teachers and schools were removed by field staff from the assessment booklets, the questionnaires, and all other related materials, and replaced with unique identification numbers. In addition to data collected directly from schools, teachers, and students, additional information was used during the TIMSS and PIRLS sampling, data collection, and weighting processes, and these variables also were considered as part of the review to determine disclosure risk levels. provides demographic information for both public and private schools along with the names of the schools. Thus, there is some possibility that schools at least, and perhaps teachers and students as well, could be identified if comparisons of these data sets with the TIMSS data set allowed the identification of schools. Leaving aside the question of why anyone would want to do this, it might be possible to identify TIMSS and PIRLS schools by taking variables from the TIMSS and PIRLS school data and searching the publicly available data files (QED, CCD, and/or PSS files) for schools with a matching profile. However, because the variables in the TIMSS and PIRLS data files were obtained from responses to the school questionnaire, for the most part, exact profile matches are unlikely. Even then, one would not know for certain whether any of the matched schools were the actual TIMSS and PIRLS schools or whether the match had simply arisen by chance. Nevertheless, school matching analyses were undertaken using probabilistic matching algorithms approved by the Institute of Education Sciences Disclosure Review Board (DRB) for use in disclosure analyses. These algorithms identify schools with some potential for identification. To provide further protection, elements of the data from schools identified as \"disclosure risks\" in this way were perturbed using the procedures approved by the DRB. After perturbation, the data were subjected to another round of analyses to ensure that the potential for identification no longer existed.\nSENWGT is a transformation of TOTWGT that results in a weighted student sample size of 500 in each education system. This weight may be appropriate for cross-\"country\" analyses that require each education system to have the same number of students rather than proportionately more students from larger education systems and fewer from smaller education systems, which is the case if TOTWGT is used.\nHOUWGT, another transformation of TOTWGT, ensures that the weighted sample corresponds to the actual sample size in each education system. This can be important since TOTWGT inflates sample sizes to approximate the population size, and software systems that use the actual sample size to compute significance tests will give misleading results under these conditions. -TOTWGT, SENWGT, and HOUWGT are designed for use in student-level analyses from all student-level files. -SCHWGT is designed for use in school-level analyses where the schools are the units of analysis. -TCHWGT, MATWGT, and SCIWGT are specifically designed for analyses that link teacher background data to student data. -TCHWGT is used for analyses using all teachers. -MATWGT and SCIWGT are used for analyses of mathematics and science teachers, respectively."}, {"section_title": "Overview of the Design and Administration of TIMSS 2011", "text": "The basic parameters of the design and administration of TIMSS and PIRLS 2011 in the United States are outlined below. A more detailed treatment is provided in subsequent chapters of this report. Methods and Procedures in TIMSS and PIRLS 2011 (Martin & Mullis, 2011) contains detail on the international design."}, {"section_title": "Sampling", "text": "Participating countries administered TIMSS and PIRLS to national probability samples of students and schools, and other education systems administered TIMSS and PIRLS to comparably representative samples. At grade 4 countries had the option of participating in both TIMSS and PIRLS and were given options for sampling by the TIMSS and PIRLS International Study Center at Boston College. Several countries choose to administer TIMSS and PIRLS in the same schools and assess the same students in both studies. The United States selected a grade 4 sample of schools and administered TIMSS and PIRLS within the same schools but to different students by selecting classrooms within schools to be assessed in either TIMSS or PIRLS. 2 All education systems were required to draw samples of students who were nearing the end of their fourth year (TIMSS and PIRLS) or eighth year (TIMSS) of formal schooling."}, {"section_title": "Formal schooling was defined as beginning with Level 1 as defined in the International Standard", "text": "Classification of Education-ISCED (UNESCO, 1999). In most education systems, including the United States, these students were in the fourth and eighth grades. The U.S. national sample included both public and private schools, randomly selected and weighted to be representative of the nation. However, the U.S. state samples were representative state samples only of public school students. In total, 369 U.S. schools and 12,569 fourth-grade students, along with 501 schools and 10,477 eighth-grade students, participated in TIMSS 2011 in the national sample. In PIRLS, 370 schools and 12,726 students participated in the national sample. (Counts for schools and students participating in each of the nine benchmarking states can be found in Appendix A.) The following chapters present detailed information on sampling (chapter 2), participation and response rates (chapter 3), administration (chapter 4), and other technical issues."}, {"section_title": "Reporting TIMSS and PIRLS Results", "text": "Achievement results from TIMSS and PIRLS are reported on a scale from 0 to 1,000, with a scale average of 500 and standard deviation of 100. Even though the education systems participating in TIMSS and PIRLS have changed across the assessment rounds from the first administration (TIMSS in 1995 andPIRLS in 2001), comparisons between the 2011 results and prior results are still possible because the achievement scores in each of the assessments are placed on a scale that is not dependent on the list of participating education systems in any particular year. A more detailed explanation of the assessment's equating and scaling can be found in Martin and Mullis (2011). In addition to numerical scale results, TIMSS and PIRLS also include international benchmarks. The international benchmarks provide a way to interpret the scale scores and to understand how students' proficiency in a subject varies along the assessment scale. The benchmarks for both TIMSS and PIRLS describe four levels of student achievement in each subject, based on the kinds of skills and knowledge students at each score cut point would need to successfully answer the items. More information on the development of the benchmarks and the procedures used to set the score cut points can be found in Martin and Mullis (2011)."}, {"section_title": "U.S. International and National Data Files", "text": "Three versions of the U.S. national data are available as follows:"}, {"section_title": "U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide", "text": "\n2.\n\n\n\nrespect to the first sort variable, then within each level of the first sort variable, the second sort variable alternates its sort order, from lowest to highest for the first level of the first sort variable, then from highest to lowest for the second level of the first sort variable, then again from lowest to highest for the third level of the first sort variable, and so on. Each of the variables will alternate the sort order within each level of the preceding sort variable. This means that schools adjacent on the list are not substantially different or at most different by one sorting characteristic.\nThe first school following the sample school was the first substitute, and the first school preceding it was the second substitute. If an original school refused to participate, the first substitute was then contacted. If that school also refused to participate, the second substitute was then contacted. There were several constraints on the assignment of substitutes. One sampled school was not allowed to be a substitute for another, and a given school could not be assigned to be a substitute for more than one sampled school. Furthermore, substitutes were required to be in the explicit stratum as the sampled school. If the sampled school was the first or last school in the stratum, then the second school following or preceding the sampled school was identified as the substitute. If the first substitute school did not have the same implicit stratification values as the sampled school, the first and second substitute were switched. Under these rules, it was possible to identify two substitutes for each sampled school.\n\n\n\nThe school frame used to draw the state samples was identical to the national frame of public schools in those states and grades. 10 However, the North Carolina fourth-grade state school selection differed from that for Florida because North Carolina did not participate in PIRLS. Thus, its fourth-grade sample was completely independent and did not include the schools in the state that were selected for the national sample (overlap schools). In contrast, Florida's fourth-grade state sample and the eighth-grade benchmarking state samples were based on an integrated state and national design in which schools in the state that were selected for the national sample were also selected for the state sample. For each state, tables showing its frame and sample distribution, by each of the stratification variables, are provided in appendix A. The rest of the design was similar to the national design where possible. There were only two explicit strata per state (high/low poverty level), as the other national strata did not apply to state samples. As with the national samples, the frame was implicitly stratified by location, race/ethnicity enrollment, and estimated grade enrollment. In addition, it was also implicitly stratified by state achievement scores. 11 The MOS for each school was the same as in the national design. Substitute schools were assigned using the same procedure. The procedure for selecting classrooms was also the same as in the national design. However, both classes were assigned to the state sample in schools with two or more classes for the fourth-grade North Carolina and eighth-grade benchmarking samples, while the classroom designation was the same as the national design for the fourth-grade Florida sample.\n\nA weighted school response rate of at least 85 percent with replacement (after rounding to nearest whole percent) AND a weighted student response rate (after rounding) of at least 85 percent.\n\n\nIn addition to the 347 participating schools from the original sample, 22 substitute schools also participated for a total of 369 participating schools at the fourth grade in the United States. This gave a weighted (and unweighted) school participation rate after substitution of 84 percent.\n\n\nNon-native-language speakers. Students who were unable to read or speak the language(s) of the test and were unable to overcome the language barrier of the test. Typically, a student who had received less than 1 year of instruction in the language(s) of the test was excluded.\n\nPoverty level. 14 For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for the free or reduced-price lunch (FRPL) program, and a low poverty school is defined as one in which less than 50 percent are eligible; all private schools are treated as low-poverty schools. The following continuous variables were available in the sampling frame for all schools: \uf06e number of grade 4 students enrolled; \uf06e total number of students; and \uf06e percentage of students in five race/ethnicity categories (White, non-Hispanic; Black, non-Hispanic; Hispanic; Asian or Pacific Islander; and American Indian or Alaska Native). 15 An additional continuous variable, the percentage of students eligible to participate in the FRPL, was available only for public schools. \"Poverty level\" variable mentioned among the categorical variable is the recoded version of this continuous variable. For categorical variables, the distribution of frame characteristics for participants was compared with the distribution for all eligible schools. The hypothesis of independence between the characteristic and participation status was tested using a Rao-Scott modified chi-square statistic at the 5 percent level (Rao & Thomas, 2003). For continuous variables, summary means were calculated, and the difference between means was tested using a t test. The statistical significance of differences between participants and the total eligible sample is identical to that which would result from comparing participants and nonparticipants, since all significance tests account for the fact that the participants are a subset of the full sample. The bias and relative bias are also given in each table. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. The relative bias is a measure of the size of the bias compared to the eligible sample estimate. In addition to these tests, logistic regression models were used to provide a multivariate analysis in which the conditional independence of these school characteristics as predictors of participation was examined. It may be that only one or two variables are actually related to participation status. However, if these variables are also related to the other variables examined in the analyses, then other variables, which are not related to participation status, will appear as significant in simple bivariate tables. Dummy variables were created for each component of the categorical variables so that each component was included separately. The last component of each categorical variable is always the reference category and is not included in the model explicitly. The p value of a dummy variable indicates whether there is a significant difference at the 5 percent level from the effect of the (omitted) reference category. It is not possible to include all the frame characteristics in a single model because the five race/ethnicity variables are linearly dependent (i.e., they sum up to 100 percent for every school). Therefore, two models were used. In the first model, four race/ethnicities (Black, non-Hispanic; Hispanic; Asian or Pacific Islander; and American Indian or Alaska Native) were included in the model with percentage White, non-Hispanic as the reference category. In addition, an F test was used to determine whether the parameter estimates of these four characteristics were simultaneously equal to zero. In the second model, the summed percentage of the four race/ethnicities (Black, non-Hispanic; Hispanic; Asian or Pacific Islander; and American Indian or Alaska Native) replaced the four race/ethnicity variables with percentage White, non-Hispanic again as the reference category. All other frame characteristics were included in both models. The logistic regression was performed using WesVar (Westat, 2007) (http://www.westat.com/expertise/information_systems/WesVar/index.cfm) with replicate weights to properly account for the complex sample design. The paired jackknife replication method was used to create the replicate weights (Brick, Morganstein, & Valliant, 2000).\nContinuous variables (TIMSS-4). Summary means for each continuous variable for participating and eligible schools are shown in tables 3-4 through 3-6. Twenty-four of the 399 public schools had a missing value for the free or reduced-price lunch variable; these schools were excluded from the analysis. Participating schools had a higher mean fourth-grade enrollment than the eligible sample (99.3 vs. 94.0, respectively; table 3-4). Participating schools had a lower mean percentage than the eligible sample of Black, non-Hispanic students (13.3 vs. 15.3 percent, respectively; table 3-5). Participating schools had a higher mean percentage than the eligible sample Hispanic students (25.1 vs. 23.5 percent, respectively; table 3-5) and American Indian or Alaska Native students (0.9 vs. 0.8 percent, respectively; table 3-5). There were no statistically significant differences detected between the participating and eligible public schools for the free or reduced-price lunch (table 3-6). However, this must be interpreted with caution because this variable was missing for 24 public schools (see note in table 3-6). 94.0 99.3 5.31 0.056 0.000 NOTE: Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011. Percentage of students eligible for free or reduced-price lunch 48.1 47.2 -0.90 -0.019! 0.170! ! Interpret data with caution. NOTE: Information on percentage of students eligible for free or reduced-price lunch is missing for 24 of the 399 public schools in the original sample and 21 of the 334 public schools that participated. Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\n\nLogistic regression model (TIMSS-4). To examine the joint relationship of various characteristics to school nonresponse, the analysis utilized a logistic regression model with participation status as the binary dependent variable and frame characteristics as predictor variables. Public and private schools were modeled together using the variables available for all schools. Standard errors and tests of hypotheses for the full model parameter estimates are presented in tables 3-7a (with four race/ethnicity variables) and 3-7b (with summed race/ethnicity percentage). Private schools, South region, total school enrollment, fourth-grade enrollment, the percentage of Hispanic students, and the percentage of American Indian or Alaska Native students are significant predictors of school participation in table 3-7a. The negative parameter estimates indicate that, relative to public schools, private schools were somewhat underrepresented among the participating schools, and the total enrollment in participating schools was slightly smaller than in all eligible schools, i.e., the smaller the total enrollment, the more likely a school was to participate. The positive parameter estimates indicate that, relative to schools in the West region, schools in the South region were somewhat overrepresented among the participating schools, and the fourth-grade enrollment, percentage of Hispanic students, and percentage of American Indian or Alaska Native students in participating schools was larger than in all eligible schools. The F test statistic to determine whether the race/ethnicity characteristics are simultaneously equal to 0 was 2.86 with a p value of 0.0023, which indicates a significant relationship detected with participation. Private schools, total school enrollment, and fourth-grade enrollment again are significant predictors of school participation in table 3-7b. This model also shows that the summed race/ethnicity percentage is not significantly related to participation. For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Black includes African American, and Hispanic includes Latino. Racial categories exclude Hispanic origin. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011. For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Summed race/ethnicity percentage includes Black, non-Hispanic; Hispanic; Asian or Pacific Islander; and American Indian or Alaska Native. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\n\n\nContinuous variables (TIMSS-4). Summary means for each continuous variable for participating and eligible schools are shown in tables 3-9 through 3-11. Twenty-four of the 399 public schools had a missing value for the free or reduced-price lunch variable; these schools were excluded from the analysis. Participating schools had a higher mean fourth-grade enrollment than the eligible sample (99.1 vs. 94.0, respectively; table 3-9). Participating schools had a lower mean percentage than the eligible sample of Black, non-Hispanic students (13.4 vs. 15.2 percent, respectively; table 3-10). Participating schools had a higher mean percentage than the eligible sample Hispanic students (25.0 vs. 23.1 percent, respectively; table 3-10) and American Indian or Alaska Native students (1.0 vs. 0.9 percent, respectively; table 3-10). The difference in the fourth-grade enrollment was slightly smaller than that shown in table 3-4, in which only the original sample was considered. The differences in the percentage of students who are Black, non-Hispanic and Hispanic are somewhat smaller than that shown in table 3-5, in which only the original sample was considered. Thus, as in the case with school control, while there is no evidence that the use of substitute schools substantially reduced the potential for bias, as indicated by these variables, it has also not added to it. There was no statistically significant difference detected between the participating and eligible public schools for free or reduced-price lunch (table 3-11). However, this must be interpreted with caution because the variable is missing for 24 schools.   Percentage of students eligible for free or reduced-price lunch 47.9 47.2 -0.70 -0.015 0.217 NOTE: Information on percentage of students eligible for free or reduced-price lunch is missing for 24 of the 399 public schools in the final sample and 22 of the 355 public schools that participated. Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nPrivate schools, total school enrollment, and the percentage of American Indian or Alaska Native students remained significant predictors of school participation in table 3-12a. The negative parameter estimates indicate that, relative to public schools, private schools were somewhat underrepresented among the participating schools, and the total enrollment in participating schools was smaller than in all eligible schools, i.e., the smaller the total enrollment, the more likely a school was to participate. The positive parameter estimates indicate that, the percentage of American Indian or Alaska Native students in participating schools was lower than in all eligible schools. The F test statistic to determine whether the race/ethnicity characteristics are simultaneously equal to 0 was 2.66 with a p value of 0.0042, which indicates a significant relationship detected with participation. Private schools, total school enrollment, and fourth-grade enrollment were also significant predictors of school participation in table 3-12b. This model also shows that the summed race/ethnicity percentage is not significantly related to participation.  For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Summed race/ethnicity percentage includes Black, non-Hispanic; Hispanic; Asian or Pacific Islander; and American Indian or Alaska Native. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nThere were no statistically significant enrollment differences detected between participating and eligible schools (table 3-14). The only remaining significant difference for race/ethnicity was for Black, non-Hispanic students where participating schools had a lower mean percentage than the eligible sample of (13.0 vs. 15.2 percent, respectively; table 3-15). The difference in the percentage of students who are Black, non-Hispanic was somewhat larger than that shown in table 3-10, in which only the original sample was considered. There was no statistically significant difference detected between the participating and eligible public schools for free or reduced-price lunch (table 3-16). However, this must be interpreted with caution because the variable is missing for 24 schools.   Percentage of students eligible for free or reduced-price lunch 47.9 47.6 -0.30 -0.006 0.742 NOTE: Information on percentage of students eligible for free or reduced-price lunch is missing for 24 of the 399 public schools in the final sample and 22 of the 355 public schools that participated. Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school nonresponse adjusted weight. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nFor the final sample of schools in TIMSS-4, five of the six variables remained statistically significant in the bivariate analysis: school control; fourth-grade enrollment; the percentage of Black, non-Hispanic students; the percentage of Hispanic students; and the percentage of American Indian or Alaska Native students. When all of these factors were considered simultaneously in a regression analysis, private schools, total school enrollment and the percentage of American Indian or Alaska Native students remained significant predictors of participation. The second model showed that private schools, total school enrollment, and fourth-grade enrollment were significant predictors of participation (with summed race/ethnicity percentage). For the final sample of schools in TIMSS-4 with school nonresponse adjustments applied to the weights, only two variables were statistically significant in the bivariate analysis: region and the percentage of Black, non-Hispanic students. The multivariate regression analysis cannot be conducted after the school nonresponse adjustments are applied to the weights.\nThese results suggest that there is some potential for nonresponse bias in the U.S. TIMSS-4 original sample based on the characteristics studied. It also suggests that, while there is no evidence that the use of substitute schools reduced the potential for bias, it has not added to it substantially. The application of school nonresponse adjustments substantially reduced the potential for bias.\n48.1 percent, respectively; table 3-21). However, this must be interpreted with caution because this variable was missing for 24 public schools.   \n\nContinuous variables (PIRLS-4). Summary means for each continuous variable for participating and eligible schools are shown in tables 3-24 through 3-26. Twenty-four of the 399 public schools had a missing value for the free or reduced-price lunch variable; these schools were excluded from the analysis. Participating schools had a higher mean fourth-grade enrollment than the eligible sample (99.1 vs. 94.0, respectively; table 3-24). Participating schools had a larger mean percentage than the eligible sample of Hispanic students (24.4 vs. 23.1 percent, respectively; table 3-25). The difference in the fourth-grade enrollment remained the same as shown in table 3-19, in which only the original sample was considered. The differences in the percentage of students who are Hispanic are somewhat larger than that shown in table 3-20, in which only the original sample was considered. Thus, as in the case with school control, while there is no evidence that the use of substitute schools substantially reduced the potential for bias, as indicated by these variables, it has also not substantially added to it. There was no statistically significant difference detected between the participating and eligible public schools for free or reduced-price lunch (table 3-26). However, this must be interpreted with caution because the variable is missing for 24 schools.   \nPrivate schools and fourth-grade enrollment remained significant predictors of school participation in table 3-27a. The negative parameter estimates indicate that, relative to public schools, private schools were somewhat underrepresented among the participating schools. The positive parameter estimates indicate that total enrollment in participating schools was larger than in all eligible schools, i.e., the larger the total enrollment, the more likely a school was to participate. The F test statistic to determine whether the race/ethnicity characteristics are simultaneously equal to 0 was 3.27 with a p value of 0.0006, which indicates a significant relationship detected with participation. Private schools and fourth-grade enrollment remained significant predictor of school participation in table 3-27b. This model also shows that the summed race/ethnicity percentage is not significantly related to participation. For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Black includes African American, and Hispanic includes Latino. Racial categories exclude Hispanic origin. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Progress in International Reading Literacy Study (PIRLS), 2011. For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Summed race/ethnicity percentage includes Black, non-Hispanic; Hispanic; Asian or Pacific Islander; and American Indian or Alaska Native. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Progress in International Reading Literacy Study (PIRLS), 2011.\n\n\n\nThe first step to compute the variance with replication is to calculate the estimate of interest from the full sample as well as each subsample or replicate. The variation between the replicate estimates and the fullsample estimate is then used to estimate the variance for the full sample. Suppose that \u03b8\u02c6 is the full-sample estimate of some population parameter \u03b8. The variance estimator, The JRR algorithm used in 2011 assumes that there are G replicates, each containing two sampled schools selected independently. The element \u03b8\u02c6(g) denotes the estimate using the g-th jackknife replicate. This is computed using all cases except those in the g-th replicate of the sample. For those in the g-th replicate, the replicate weights for all cases associated with one of the randomly selected units of the pair are multiplied by zero, and the replicate weights for the elements associated with the other unit in the replicate are doubled. The computation of the JRR variance for any estimate requires the computation of the statistic 76 times for any given country: once to obtain the estimate for the full sample, and 75 times to obtain the estimate for each of the jackknife replicates ( \u03b8\u02c6(g) ).\nwhere c is the constant appropriate to the replication method (c = 0.05 for U.S. TIMSS and PIRLS). The Satterthwaite's approximation to degrees of freedom for the chi-square statistic to be calculated is Since \u03bd will generally not be an integer, interpolation in standard chi-square tables is required. Finally, the adjusted chi-square statistic is defined as\n\nThe Impact of the Sampling Design on Recruitment Activities The sampling design played an important role in the design of recruitment activities. TIMSS and PIRLS were administered jointly in the same schools at grade 4, therefore the school sample was slightly larger in order to obtain enough students. As a result, 450 schools were sampled in the first instance, along with 450 first substitutes and 450 second substitutes, for a total of 1,350 schools. The school sample design at grade 8 was 600 schools, each with two replacements. The total sample was 1,800 schools, including substitutes. In gaining the cooperation of schools, at each grade level the sampled schools were approached in the first instance. Operationally this meant first informing the districts in which these schools are located and then approaching the schools themselves. If a sampled school refused to participate, the district of the first substitute school was approached and the district-school permission procedure began anew. If the first substitute school refused as well, then the district of the second substitute school was approached and then the second substitute school. The sampling design came into play with the distribution of schools across districts and the consequences that this had for the volume and length of the permission process. With state representatives actively gaining cooperation from the eighth-grade schools (and in some cases the fourth-grade schools) in the original national sample, as well as the benchmarking states, the process was simplified. In fact, only 22 substitute schools were used at grade 4 and only two substitutes were used at grade 8. Thus in both grades, there was an increased original school response rate from previous rounds of TIMSS and PIRLS.\n\n\n\nSampling Classes. WinW3S generated an equal probability sample of two classes (or pseudoclasses) where possible, based on the information in the CLF. If only one grade-appropriate class was available in a school, this class was selected with certainty. At grade 4, up to four classes were sampled and assigned to either TIMSS or PIRLS. The WinW3S sampling software handled the assignment of classes by randomly assigning the first sampled class and alternating assignment of each subsequent sampled class. In grade 8 schools, two classes were sampled unless the school only had one grade 8 class. The TIMSS-NAEP linking study at grade 8 required that one of the sampled classes be designated as the TIMSS-NAEP link class in order to administer a braided booklet of TIMSS and NAEP items. Once the classes were selected, a random number table (0-9) was used to define the TIMSS-NAEP link class. If the number was greater than or equal to 5, the class was designated as the link class. If the number was less than 5, the class was designated as the TIMSS class. The second class was assigned based on the designation of the first class. Once the link class was chosen, \"LK\" was added to the end of the class name to signify that the class was the link class.\nThe response by schools to completing this somewhat formidable task was encouraging, although it required more follow-up than with the simpler Class Listing Form. The return of the STLF forms was tracked and reviewed weekly with the view to initiating reminder calls from field staff to the schools.\nA detailed list of changes made to the questionnaires is provided in appendix G Both the original text from the international version of the questionnaire and the changed text from the U.S. version are shown. Text that has been changed in the U.S. version is underlined in that version. Both international and U.S. questionnaire item numbers, or other location indicators, are provided in each instance. Where appropriate, a crosswalk between the U.S. and international versions of the set of response categories of items is provided in the \"Comments\" column.\n\nTest administrators arrived at the school about an hour before the scheduled assessment to prepare booklets for distribution and take care of other arrangements for the assessment. Following the prescribed international procedures, the test administrator did not open the booklet bundles until 45 minutes before the assessment. At that time, the booklets were assigned to students in the random order established by the IEA sampling software, and labels were placed on the booklets. TIMSS pencils were provided to all students. As required by international rules, simple-function calculators were provided at the eighth-grade level only, and then only at the discretion of the school. Students kept the TIMSS pencils as gifts, but calculators distributed during the assessments were collected with the booklets after the assessment.\n\n\nAn additional measure was taken to reduce further the risk of disclosure of an individual respondent. This measure is referred to as data swapping, a DRB requirement that reduces risk by modifying microdata. In data swapping, a probability sample of records is paired with other records on the file using selected characteristics, and then some identifying variables are swapped between pairs of records (see Kaufman et al., 2005). The sampling rate for TIMSS and PIRLS swapping was designed to protect the confidentiality of the data without affecting the usability of the data set. All questionnaire data (school, teacher, and student) were involved in the swapping. This method is an effective way of keeping as much valuable data as possible while protecting respondent identity. Swapping preserves the univariate frequencies, means, and variances, although it may affect multivariate relationships a little. Pre-and postswapping percentage distributions (unweighted and weighted) and correlations were reviewed to ensure data quality was maintained. Confidentiality analyses of this kind were conducted before the U.S. data files were delivered to the DPC for cleaning, and prior to the IRT scaling and estimation of sampling weights.\n\nteacher was asked to complete a questionnaire for each class taught that contained sampled students. The PIRLS teacher background data files contain one record for each teacher and class combination. Separate TIMSS teacher questionnaires were administered to eighth-grade mathematics and science teachers. The responses of teachers to the mathematics questionnaire are found in the BTM files, and the responses of teachers to the science questionnaire are in the BTS files. Variable names for questions repeated in both questionnaires are the same. Responses to the single questionnaire administered to fourth-grade teachers of TIMSS and PIRLS are found in the ATG files. The seventh and eighth characters (M5 or R3) discern between TIMSS and PIRLS teacher data files. In all of the teacher files each teacher has a unique identification number (IDTEACH) and a link number (IDLINK) specific to the class taught by the teacher and to which the information in the data record corresponds. The IDTEACH and IDLINK combination uniquely identifies, within an education system, a teacher teaching a specific class. For example, students linked to teachers identified by the same IDTEACH but different IDLINK are taught by the same teacher but in different classes. It is important to note that the teachers in question do not constitute a representative sample of teachers in an education system but rather are the teachers who taught a representative sample of students. To reflect this fact, for the most part, the teacher data should be analyzed only in conjunction with the student-teacher linkage data files and weighted with student sampling weights.\n\n\uf06e IDTEACH: a six-digit identification code that uniquely identifies a teacher within a school. \uf06e IDLINK: uniquely identifies the class for which a teacher answered a questionnaire.\n\nExhibit 5-6. Illustrative SAS code for merging U.S. TIMSS eighth-grade student and school data libname bM5 \"C:\\TIMSS2011\\Data\"; data SCHOOL; set bM5.T8_SCHOOL11; proc sort data= SCHOOL; by IDSCHOOL; data STUDENT; set bM5.T8_STUDENT11; proc sort data= STUDENT; by IDSCHOOL; data bM5.MERGE1; merge STUDENT SCHOOL; by IDSCHOOL; run; SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011. This example creates a temporary SAS dataset (SCHOOL) using the permanent school dataset bM5.T8_SCHOOL11. It then sorts the school data by school ID (IDSCHOOL). A similar procedure is used for the student file (STUDENT), which is also sorted by the school ID using the permanent student dataset bM5.T8_STUDENT11. The final dataset is a permanent dataset called bM5.MERGE1 containing the merged file from SCHOOL and STUDENT using IDSCHOOL as the merge variable. The SPSS example shown in exhibit 5-7 works in a similar way. SPSS uses a file containing the school variables (T8_SCHOOL11.SAV) and sorts the cases by IDSCHOOL. The same procedure is used for the student dataset, T8_STUDENT11.SAV. The \"match files\" command merges the two files, and the final, merged output file is saved as MERGE1.SAV. Exhibit 5-7. Illustrative SPSS code for merging U.S. TIMSS eighth-grade student and school data get file = \"C:\\TIMSS2011\\Data\\T8_SCHOOL11.SAV\". sort cases by IDSCHOOL. save outfile = 'C:\\TIMSS2011\\Data\\SCHOOL.SAV'. get file = \"C:\\TIMSS2011\\Data\\T8_STUDENT11.SAV\". sort cases by IDSCHOOL. save outfile = 'C:\\TIMSS2011\\Data\\STUDENT.SAV'. match files / file= 'C:\\TIMSS2011\\Data\\STUDENT.SAV' / table= 'C:\\TIMSS2011\\Data\\SCHOOL.SAV' / by IDSCHOOL. save outfile = \"C:\\TIMSS2011\\Data\\MERGE1.SAV\". SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nIn the SAS example, the program creates a temporary SAS dataset (TEACHER) using the permanent mathematics teacher file, bM5.T8_MTEACHER11. It then sorts the teacher data by the teacher ID (IDTEACH) and the link ID (IDLINK). A similar procedure is used for the student-teacher link file (STDTCH), using the permanent file (bM5.T8_STD_TCH_LINK11) which is also sorted by the teacher ID and the link ID. The weight variable for mathematics teachers (MATWGT) is used as a selection variable because mathematics teachers have been selected. The result is a merged file called bM5.TEACHMRG with disaggregated teacher data. This file is merged with the student file (STUDENT). The final dataset is a permanent dataset called bM5.MERGE2 that contains the merged file from TEACHMRG and STUDENT using IDSTUD as the merge variable. The SPSS student-teacher merge in Exhibit 5-9 uses a file containing the teacher variables (T8_MTEACHER11.SAV) and sorts the cases by IDTEACH and IDLINK. The file is then saved as TEACHER. The same procedure is used for the student-teacher linkage dataset T8_STD_TCH_LINK11.SAV. The \"match files\" command merges the two files by the ID variables IDTEACH and IDLINK, and the merged output file is saved as TEACHMRG. To include the student data, the student file is selected (T8_STUDENT11.SAV), sorted by IDSTUD and saved as STUDENT. This file is merged with TEACHMRG using IDSTUD to create the final file MERGE2.SAV containing both teacher and student variables. Exhibit 5-9. Illustrative SPSS code for merging U.S. TIMSS eighth-grade student and mathematics teacher data get file = \"C:\\TIMSS2011\\Data\\T8_MTEACHER11.SAV\". sort cases by IDTEACH IDLINK . save outfile = 'C:\\TIMSS2011\\Data\\TEACHER.SAV'.. get file = \"C:\\TIMSS2011\\Data\\T8_STD_TCH_LNK11.SAV\". select if MATWGT > 0. sort cases by IDTEACH IDLINK. save outfile= 'C:\\TIMSS2011\\Data\\STDTCH.SAV'.match files / file='C:\\TIMSS2011\\Data\\STDTCH.SAV' / table='C:\\TIMSS2011\\Data\\TEACHER.SAV' / by IDTEACH IDLINK. sort cases by IDSTUD. save outfile = 'C:\\TIMSS2011\\Data\\TEACHMRG.SAV'.. get file = \"C:\\TIMSS2011\\Data\\T8_STUDENT11.SAV\". sort cases by IDSTUD. save outfile= 'C:\\TIMSS2011\\Data\\STUDENT.SAV'. match files / file= 'C:\\TIMSS2011\\Data\\TEACHMRG.SAV' / table= 'C:\\TIMSS2011\\Data\\STUDENT.SAV' / by IDSTUD. save outfile = \"C:\\TIMSS2011\\Data\\MERGE2.SAV\". SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nIn the SPSS example shown in exhibit 5-11 the student and school data are first sorted by IDSCHOOL and then merged. The procedure followed for combining student and teacher data in Exhibit 5-9 is used again. Then the saved student-school and student-teacher files are merged by IDSTUD, and a final dataset MERGEALL.SAV is saved. Exhibit 5-11. Illustrative SPSS code for merging U.S. TIMSS eighth-grade school, mathematics teacher and student data get file = \"C:\\TIMSS2011\\Data\\T8_SCHOOL11.SAV\". sort cases by IDSCHOOL. save outfile = 'C:\\TIMSS2011\\Data\\SCHOOL.SAV'. get file = \"C:\\TIMSS2011\\Data\\T8_STUDENT11.SAV\". sort cases by IDSCHOOL. save outfile = 'C:\\TIMSS2011\\Data\\STUDENT.SAV'. match files / file= 'C:\\TIMSS2011\\Data\\STUDENT.SAV' / table= 'C:\\TIMSS2011\\Data\\SCHOOL.SAV' / by IDSCHOOL. save outfile = \"C:\\TIMSS2011\\Data\\MERGE1.SAV\" . get file = \"C:\\TIMSS2011\\Data\\T8_MTEACHER11.SAV\". sort cases by IDTEACH IDLINK . save outfile = 'C:\\TIMSS2011\\Data\\TEACHER.SAV'. get file = \"C:\\TIMSS2011\\Data\\T8_STD_TCH_LNK11 .SAV\". select if MATWGT > 0 . sort cases by IDTEACH IDLINK. save outfile = 'C:\\TIMSS2011\\Data\\STDTCH.SAV'. match files / file= 'C:\\TIMSS2011\\Data\\STDTCH.SAV' / table= 'C:\\TIMSS2011\\Data\\TEACHER.SAV' / by IDTEACH IDLINK. save outfile = \"C:\\TIMSS2011\\Data\\MERGE2.SAV\". Get file = \"C:\\TIMSS2011\\Data\\MERGE1.SAV\". Sort cases by IDSTUD. save outfile = 'C:\\TIMSS2011\\Data\\MERGE1.SAV'.Get file = \"C:\\TIMSS2011\\Data\\MERGE2.SAV\". Sort cases by IDSTUD. save outfile = 'C:\\TIMSS2011\\Data\\MERGE2'.match files / file= 'C:\\TIMSS2011\\Data\\MERGE2.SAV' / table= 'C:\\TIMSS2011\\Data\\MERGE1.SAV' / by IDSTUD. save outfile = \"C:\\TIMSS2011\\Data\\MERGEALL.SAV\". SOURCE: International Association for the Evaluation of Education Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\n\nExhibit 5-13. Illustrative SPSS code for merging U.S. TIMSS eighth-grade school data with restricted (CCD and PSS) data get file = \"C:\\TIMSS2011\\Data\\T8_RESTRICTED_USE11.SAV\". sort cases by NCESSCH. save outfile = 'C:\\TIMSS2011\\Data\\SCHOOL.SAV'.get file = \"C:\\TIMSS2011\\Data\\CCD.SAV\". sort cases by NCESSCH. save outfile = 'C:\\TIMSS2011\\Data\\CCD.SAV'. match files / file= 'C:\\TIMSS2011\\Data\\CCD.SAV' / table= 'C:\\TIMSS2011\\Data\\SCHOOL.SAV' / by NCESSCH. save outfile = \"C:\\TIMSS2011\\Data\\MERGE1.SAV\". \n\nA-2 8.2 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" All private schools are categorized as \"low.\" For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-3 12.9 9 14.3 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-4 .9 0 0.0 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-5 11.4 8.3 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-6 14.3 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-7 .1 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-8 .4 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-9 12.1 12.1 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-10 .3 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-11 .3 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nA-12  (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international TIMSS rates, whose classroom and student participation rates do include substitute schools in their calculation. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nB-2  (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international TIMSS rates, whose classroom and student participation rates do include substitute schools in their calculation. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nB-3  (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international TIMSS rates, whose classroom and student participation rates do include substitute schools in their calculation. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nB-4  (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international TIMSS rates, whose classroom and student participation rates do include substitute schools in their calculation. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nB-5  (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international PIRLS rates, whose classroom and student participation rates do include substitute schools in their calculation. The exclusion rates for the PIRLS Florida fourth grade sample are presented following Table B (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international TIMSS rates, whose classroom and student participation rates do include substitute schools in their calculation. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nB-7  (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international TIMSS rates, whose classroom and student participation rates do include substitute schools in their calculation. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nB-8  (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international TIMSS rates, whose classroom and student participation rates do include substitute schools in their calculation. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nB-9  (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international TIMSS rates, whose classroom and student participation rates do include substitute schools in their calculation. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\nB-10  (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools because substitute schools do not have an independent probability of selection (National Center for Education Statistics, 2002). However, the participation rates shown in this table are the official international TIMSS rates, whose classroom and student participation rates do include substitute schools in their calculation. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.\n\nn Works with Westat assessment staff to select an assessment date convenient for the school. n Completes a brief School Questionnaire (about the characteristics of the school, its enrollment, resources, policies, and learning environment). n Arranges assessment day space. n Completes Class listing form and Student listing forms and returns these to Westat (via fax, mail, or email). n Ensures parents are notified that their children have been selected for the assessment. n Works with assessment staff to identify students with special education needs. n Meets with students/teachers as necessary to provide information about the study. n Complete Teacher Questionnaires and returns them to the school coordinator prior to assessment day. n Confirms space for assessment is problem-free. n If necessary, helps to ensure all sampled students attend the assessment session. n Collects completed School and Teacher Questionnaires and returns them to assessment staff. n Ensures all sampled students attend the assessment session. n Meets with assessment staff and reviews the assessment. n Receives a $200 check for the school. n Represents other similar U.S. schools. n Receives feedback based on the performance of students in your school that took the TIMSS assessment. n Receives U.S. national report with final results. n Receives a $100 personal check. n Receives U.S. national report with final results. n Represent the United States in the international study.\nFor additional information, go to http://nces.ed.gov/timss. Exhibit D-6. TIMSS eighth-grade summary of activities for school coordinator\nExhibit E-3. PIRLS session script-Continued\nExhibit E-4. TIMSS fourth-grade session script-Continued E-26\nExhibit E-4. TIMSS fourth-grade session script-Continued E-29 \uf026 In Example 1, the question asks, \"Do you go to school?\" Below this question are a \"Yes\" and a \"No.\" Since you all go to school, you should all fill in the oval next to \"Yes.\" Give students time to fill in the circle next to \"Yes\" and make sure they understand how to do it. Once everyone has completed the example, move on to Example 2. Make sure that all students are following along and are looking at Example 2 in their questionnaires. \uf026 Example 2 is another kind of question you will find in this booklet.\nExhibit E-4. TIMSS fourth-grade session script-Continued E-30 \uf026 This question asks \"How often do you do these things?\" Letter (a) says, \"I talk with my friends.\" You are given four choices for how often you do this: Every day or almost every day; Once or twice a week; Once or twice a month; and Never or almost never. \uf026 Fill in the oval below your answer. For example, if you talk to your friends every day or almost every day, fill in the first circle under \"Every day or almost every day.\" Give students time to fill in their answers to all parts of the Example 2 question and make sure they understand how to answer this kind of question. Once everyone has completed the example, move on to Example 3. Make sure that all students are following along and are looking at Example 3 in their questionnaires. \uf026 Example 3 is another kind of question you will find in this booklet.\nExhibit E-5. TIMSS eighth-grade session script-Continued E-42 \uf026 In Example 1, the question asks, \"Do you go to school?\" Below this question are a \"Yes\" and a \"No.\" Since you all go to school, you should all fill in the oval next to \"Yes.\" Give students time to fill in the circle next to \"Yes\" and make sure they understand how to do it. Once everyone has completed the example, move on to Example 2. Make sure that all students are following along and are looking at Example 2 in their questionnaires. \uf026 Example 2 is another kind of question you will find in this booklet. \uf026 This question asks \"How often do you do these things?\" Letter (a) says, \"I talk with my friends.\" You are given four choices for how often you do this: Every day or almost every day; Once or twice a week; Once or twice a month; and Never or almost never. \uf026 Fill in the oval below your answer. For example, if you talk to your friends every day or almost every day, fill in the first circle under \"Every day or almost every day.\" Give students time to fill in their answers to all parts of the Example 2 question and make sure they understand how to answer this kind of question. Once everyone has completed the example, move on to Example 3. Make sure that all students are following along and are looking at Example 3 in their questionnaires. \uf026 Are there any questions before we start? If there are questions try to answer them the best you can. If there are no more questions then record the current time in Cell (13a) of the Test Administration Form and proceed with the administration of the questionnaire.\nExhibit E-6. TIMSS-NAEP link session script-Continued E-51\nExhibit E-6. TIMSS-NAEP link session script-Continued E-55 \uf026 In Example 1, the question asks, \"Do you go to school?\" Below this question are a \"Yes\" and a \"No.\" Since you all go to school, you should all fill in the oval next to \"Yes.\" Give students time to fill in the circle next to \"Yes\" and make sure they understand how to do it. Once everyone has completed the example, move on to Example 2. Make sure that all students are following along and are looking at Example 2 in their questionnaires. \uf026 Example 2 is another kind of question you will find in this booklet. \uf026 This question asks \"How often do you do these things?\" Letter (a) says, \"I talk with my friends.\" You are given four choices for how often you do this: Every day or almost every day; Once or twice a week; Once or twice a month; and Never or almost never. \uf026 Fill in the oval below your answer. For example, if you talk to your friends every day or almost every day, fill in the first circle under \"Every day or almost every day.\" Give students time to fill in their answers to all parts of the Example 2 question and make sure they understand how to answer this kind of question. Once everyone has completed the example, move on to Example 3. Make sure that all students are following along and are looking at Example 3 in their questionnaires. If not all of the students raise their hands, allow for additional time and say: \uf026 You will have more time to continue answering this questionnaire. If you have already finished all the questions, then you can use this time to review your answers. Once you have finished, please close your booklet and read quietly at your desk. Once all students have finished and have closed their booklets record the current time in Cell (13b) of the Test Administration Form. Then say: \uf026 Thank you very much for participating in this study. Your work will help us to learn more about our students and schools. \uf026 Please close your booklets and stay seated. \uf026 Please insert the booklet into the envelope it was in when you received it and seal the envelope closed. Once you have done this, remove the label that contains your name from the envelope. Peel it off and I will collect it. Collect all test booklets and envelopes and keep them secure. Check against the Student Tracking Form to make sure that you have received all of them. Use the sequential number you assigned to the front of the envelope to help in this process."}, {"section_title": "Sampling Schools", "text": "The 2011 TIMSS and PIRLS sample design consisted of the following samples: Each of the first three pairs of samples are described jointly in this chapter because they shared the same sampled schools though they assessed separate classrooms within each school. All of the 2011 TIMSS and PIRLS school samples were drawn for the United States in March 2010. The sample design for the U.S. national school samples were developed to retain most of the properties of the 2007 TIMSS and 2006 PIRLS U.S. school samples, and to follow international requirements as given in Martin and Mullis (2011). The U.S. samples again followed a two-stage sampling process with the first stage a sample of schools, and the second stage a sample of classrooms within schools. All students in sampled classrooms were selected for assessment."}, {"section_title": "U.S. TIMSS and PIRLS Fourth-Grade National Samples", "text": "The 2011 TIMSS and PIRLS national sample design for the fourth grade was similar to the sample design of TIMSS 2007 andPIRLS 2006 in that (a) the student population was defined as the set of all fourthgraders in the United States in both public and private schools, and (b) one or two classrooms were selected for each assessment in each sampled school. However, the 2011 TIMSS and PIRLS national sample design for the fourth grade differed from previous administrations of TIMSS and PIRLS in that there was one joint sample with up to four classrooms selected from each school. Schools in the sample with four or more fourth-grade classes had two classes randomly designated to either TIMSS or PIRLS, and the other two classes designated to the other study. In schools with three fourth-grade classes, two classes were randomly designated to one study, and the remaining class to the other study. In schools with U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide two fourth-grade classes, one class was randomly designated to one study, and the second class to the other study. In small schools with only one fourth-grade class, that class was randomly designated to either the TIMSS or PIRLS study. Thus, under this joint sampling design, the national fourth-grade sample contained \uf06e schools with one classroom designated to TIMSS; \uf06e schools with one classroom designated to PIRLS; and \uf06e schools with two or more classrooms contributing classes to both TIMSS and PIRLS. In total, the 2011 fourth-grade national joint TIMSS-PIRLS school sample consisted of 450 schools containing at least one fourth-grade class. The schools were selected with probability proportionate to the school's estimated grade enrollment of fourth-graders from the 2011 National Assessment of Educational Progress (NAEP) school frame using 2007-08 school data. The overall sample design was intended to approximate a self-weighting sample of students as much as possible in accordance with the international guidelines, with each fourth-grade student in the United States having an equal probability of being selected."}, {"section_title": "U.S. TIMSS Eighth-Grade National and NAEP-TIMSS Eighth-Grade National Linking Study Samples", "text": "The sample design for the eighth-grade national TIMSS assessment was also similar to the sample design of TIMSS 2007 in that the student population is the set of all eighth-graders in the United States in both public and private schools. However, unlike previous cycles where two classes per school were selected, only one class per school was selected in 2011. This was due to a special NAEP-TIMSS linking study that was administered jointly in the same schools and that assessed a second classroom 3 in a separate session from the TIMSS assessment. Thus, the TIMSS 2011 national school sample consisted of 600 schools with at least one eighth-grade class. The schools were selected with probability proportionate to the school's estimated grade enrollment of eighth-graders from the 2011 NAEP school frame using 2007-08 school data. The overall sample design was intended to approximate a self-weighting sample of students as much as possible in accordance with the international guidelines, with each eighth-grade student in the United States having an equal probability of being selected."}, {"section_title": "TIMSS and PIRLS State Samples", "text": "In 2011, a PIRLS public school state sample was drawn for Florida; and a TIMSS public school state sample was drawn for Florida and North Carolina at both fourth-and eighth-grade and for Alabama, California, Colorado, Connecticut, Indiana, Massachusetts, and Minnesota at eighth grade only. The 2011 TIMSS and PIRLS state samples replicated the national sample design, with the following differences: (a) there was only one joint sample at the fourth grade (in Florida), and (b) there was no NAEP-TIMSS linking study at the eighth grade in any of the benchmarking states. The school frame to draw the state samples was identical to the national frame of public schools in those states. The state samples included the schools in each state that were previously selected as part of the TIMSS and PIRLS national samples (these are sometimes referred to as \"overlap\" schools) plus a supplement of schools to reach the internationally set target of 100 assessed classrooms in each state."}, {"section_title": "All Samples", "text": "Schools were explicitly stratified by poverty level, public/private status, and census region. The schools were implicitly stratified by sorting by locale (city, suburb, town and rural), race/ethnicity enrollment (above or below 15 percent Black, Hispanic, Asian and Pacific Islander, 4 and American Indian and Alaska Native), and the estimated grade enrollment within each explicit stratum. A systematic sample was selected independently in each stratum with sampling probabilities proportional to measures of size, (PPS) where the measure of size is the estimated number of students in fourth or eighth grade. There was no oversampling for either grade or study in 2011. Overlap with the 2011 NAEP school sample was minimized even though the TIMSS-PIRLS sample had to be selected before the NAEP sample because of TIMSS-PIRLS scheduling constraints. 5 The overlap between the samples was minimized when the 2011 NAEP sample was selected. The rest of this chapter describes the school samples. Section 2.1 describes the sampling frame-the data sources, data preparation, and the stratification variables. Section 2.2 describes the national school sample "}, {"section_title": "Eighth-Grade Frame", "text": "Any school having an eighth grade as of the school year 2007-08 was included on the TIMSS eighthgrade school sampling frame. Table 2-2 presents frame tabulations of the number of schools by the school grade span (lowest to highest grade level of the school). 19.0 NOTE: Detail may not sum to totals because of rounding. The \"Other\" grade spans includes all additional grade spans. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011."}, {"section_title": "Stratification", "text": "The sample design was a stratified systematic sample within each stratum, with sampling probabilities proportional to size (PPS). Stratification was used for sample efficiency and consistency with previous designs. The explicit strata were formed by the following variables, shown in alphabetical order: \uf06e Census region-Northeast, Midwest, South, and West; \uf06e poverty level 6 -for public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the free or reduced-price lunch program (FRPL), and \"low\" poverty is defined as having less than 50 percent eligible; and \uf06e school type-school is either under public control (operated by publicly elected or appointed officials) or private control (operated by privately elected or appointed officials and derives its major source of funds from private sources). Within each stratum, the frame was implicitly stratified by the following three categorical stratification variables: \uf06e locale-urban-centric locale code, i.e., city, suburb, town, rural; \uf06e race/ethnicity status-student population in the school is \"15 percent or above\" or \"below 15 percent\" Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students; 7 and \uf06e estimated grade enrollment."}, {"section_title": "Fourth-Grade Stratification", "text": "The following tables show the total number and percentage of fourth-grade students and schools in the TIMSS-PIRLS 2011 school frame by census region (table 2-3), poverty level (table 2-4), school type (table 2-5), locale (table 2-6), race/ethnicity status (table 2-7), and by poverty level, school type and region (table 2-8). 6 The sample frame did not contain a direct measure of poverty. No National School Lunch Program (NSLP) data were available for private schools, thus all private schools are treated as low-poverty schools. 7 Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible.  68.0 NOTE: For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011; Progress in International Reading Literacy Study (PIRLS), 2011.   45.6 NOTE: Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011; Progress in International Reading Literacy Study (PIRLS), 2011.  75.5 NOTE: For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.   49.5 NOTE: Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011."}, {"section_title": "14", "text": ""}, {"section_title": "Measure of Size", "text": "The goal for the TIMSS-PIRLS sample was to attain a self-weighting student sample. To achieve this, schools' probability of selection was related to their measure of size (MOS), which is proportional to its share of the target population, that is, the fourth-or eighth-grade enrollments. This method also reduces the chance of selection for smaller schools. This improves cost efficiency by increasing the number of students per school. However, students in schools with enrollments of only a few students would have very large weights if selected. To minimize the impact of these small schools on variances and estimates, the minimum measure of size was set to 5. The following is a summary of the steps for assigning measures of size to the schools on the TIMSS and PIRLS frames. Determine the estimated target population size for the school. This is the estimated enrollment per grade (4 or 8) from the school frame. If the grade 4 or 8 enrollment is not available, it is calculated by dividing the school's total enrollment by the number of grades in the school. "}, {"section_title": "Substitute Schools", "text": "Although efforts were made to secure the participation of all schools selected, it was anticipated at the time of sampling that not all schools would choose to participate. Therefore, as each school was selected for a sample, the two neighboring schools in the sampling frame were designated as substitute schools."}, {"section_title": "Selecting Classrooms", "text": "The final stage of selection was of classrooms within schools. Within each sampled school that agreed to participate in TIMSS and PIRLS at fourth grade, all classrooms in the school were listed on the classroom sampling frame. Within each sampled school that agreed to participate in TIMSS at eighth grade, all mathematics classrooms in the school were listed on the classroom sampling frame. Schools were asked to indicate the names of all classes containing fourth-or eighth-grade students, the number of fourth-or eighth-grade students in the class, and whether it was a \"special class\" in which all or most of the students were learning disabled or classified as having limited English proficiency. Because TIMSS and PIRLS do not provide accommodations, classrooms were excluded from the subsequent classroom sampling if all or most of the students were learning disabled. Classrooms with fewer than 15 students were collapsed into pseudoclassrooms so that each classroom on the school's classroom sampling frame had at least 20 students. 8 An equal probability sample of classrooms or pseudoclassrooms was sampled from the classroom frame for each school. All students in sampled classrooms (pseudoclassrooms) were selected for assessment. Schools in the sample with four or more fourth-grade classes had two classes randomly designated to either TIMSS or PIRLS and the other two designated to the other study. In schools with three fourthgrade classes, two classes were randomly designated to one study, and the remaining class to the other study. In schools with two fourth-grade classes, one class was randomly designated to one study and the second class to the other study. In small schools with only one fourth-grade class, that class was randomly designated to either the TIMSS or PIRLS study. Thus, under this sampling design, the three groups of schools samples are as follows: \uf06e schools with one classroom designated to TIMSS, \uf06e schools with one classroom designated to PIRLS, and \uf06e schools with two or more classrooms contributing classes to both TIMSS and PIRLS. Schools of two or more eighth-grade classes were identified in the sample, and classes in those schools were randomly designated to either TIMSS or the NAEP-TIMSS linking study. Schools with only one eighth-grade class were randomly assigned to either TIMSS or the NAEP-TIMSS linking study."}, {"section_title": "Tabulations Within Subgroups for Frame and Sample", "text": "This section provides an overview of the frame and sample for the explicit and implicit strata used in the sample process. The PPS sampling and stratification worked effectively: the sample percentage of schools is close to the measure-of-size percentage of the frame for all the implicit strata. For these strata-defining subgroups, tables 2-15 through 2-26 present the following summary tabulations in these subgroups: \uf06e Total measure of size. This is the summation of ij MOS over the subgroup. Note that this is larger than the national population student size because the minimum ij MOS is set to 5 for small schools; and \uf06e Sample size. This is the final realized sample size of schools in the subgroup for the U.S. TIMSS-PIRLS fourth-or eighth-grade samples."}, {"section_title": "Fourth-Grade Tabulations", "text": "This section provides an overview of the fourth-grade frame and sample distribution by each of the stratification variables. Each table shows the total number and percentage of fourth-grade students in the sampling frame (data shown in tables 2-15 through 2-20) and the total number and percentage of schools U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide in the TIMSS-PIRLS school sample. 9 By each stratification variable, the tables are Census region (table 2-15), poverty level (table 2-16), school type (table 2-17), locale (table 2-18), race/ethnicity status   (table 2-19), and by poverty level, school type, and region (table 2-20).  .4 NOTE: Measure of size is the estimated number of students enrolled in the target grade with a minimum of 5 students per school. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011; Progress in International Reading Literacy Study (PIRLS), 2011. 9 The measure of size (MOS) defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These are consistently larger than the estimated student sample size (reported in tables 2.1-2.14), which is the estimate of the number of students in the sampled schools and have no minimum per school.  22.2 NOTE: For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Measure of size is the estimated number of students enrolled in the target grade with a minimum of 5 students per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011; Progress in International Reading Literacy Study (PIRLS), 2011. Measure of size is the estimated number of students enrolled in the target grade with a minimum of 5 students per school. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011; Progress in International Reading Literacy Study (PIRLS), 2011.  Measure of size is the estimated number of students enrolled in the target grade with a minimum of 5 students per school. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011.  22.2 NOTE: For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Measure of size is the estimated number of students enrolled in the target grade with a minimum of 5 students per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011. .0 NOTE: Measure of size is the estimated number of students enrolled in the target grade with a minimum of 5 students per school. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011."}, {"section_title": "School Selection for the Integrated Design", "text": "The state samples for Alabama, California, Colorado, Connecticut, Florida, Indiana, Massachusetts, and Minnesota, and North Carolina at eighth-grade used an integrated design. As mentioned above, the fourth-grade sample in North Carolina differed in that it was independent. The integrated design included the schools in each state that were previously selected as part of the TIMSS and PIRLS national samples plus a supplement of schools to reach the international target of 100 assessed classrooms. The target was in terms of the number of classrooms rather than schools because with the integration of the national design there were a varying number of national sample schools per state. For the eighth-grade samples, one class was selected for TIMSS and one for the NAEP-TIMSS linking study in each school. Thus, only one classroom from each of the national schools was included in the state assessment. The supplemental grade 8 sample of schools selected for each state followed the normal TIMSS procedure of selecting two classes per school. The additional number of schools needed in each state is then ([100 -# national public schools] / 2) plus an additional five schools per state to account for ineligible schools. The supplemental fourth-grade Florida sample followed the TIMSS-PIRLS procedure of selecting four classes per school, so an additional 20 supplemental schools were selected to account for schools with fewer than four classrooms. The integrated sample was selected using a version of the Keyfitz procedure (Keyfitz, 1951); Chowdhury, Chu, & Kaufman, (2001) have described the implementation of the procedure. The method is generally used to minimize overlap between one or more surveys, but it can also be used to maximize overlap by ordering the rows in descending order of the response load indicator. By following the process outlined in table 2 of the Chowdhury, Chu, and Kaufman paper, the rows in the table can be thought of as a hierarchy of selection preference, where the top row maximizes the probability and the bottom row minimizes it. This property allowed us to maximize the overlap with the TIMSS national sample (in fact, select all national schools) while minimizing the overlap with the NAEP state operational public school sample or \"Alpha sample.\" 12 By maximizing the overlap with the national sample, the assessed classrooms can be included in both studies with proper probabilities. This minimization was undertaken to reduce the burden for schools selected in the NAEP Alpha sample and to improve response rates. This was accomplished by partitioning the frame into the following three groups shown in order, as in table 2 of the paper. The three groups were as follows: \uf06e schools selected for the TIMSS national sample (including schools also selected for the NAEP Alpha sample); \uf06e schools not selected for either the TIMSS national sample or the NAEP Alpha sample; and \uf06e schools selected for the NAEP Alpha sample and not for the TIMSS national sample. With this design, the method guarantees all schools in group 1 will be selected with certainty since the probability of being selected for the integrated sample is always larger than being selected for the national sample and since more schools were selected in each state sample (the national schools plus a state supplement) than in the national sample with the frames being identical. The method minimized the overlap with schools in group 3 (NAEP Alpha sample) and selected the majority of the state supplement from schools in group 2. Table 2-27 presents the composition of the state integrated sample by sample type and state. See appendix A for the tables of the frame and sample distribution by each of the stratification variables for each state sample. "}, {"section_title": "School Selection for the North Carolina Fourth-Grade Design", "text": "Ideally, the objective for the North Carolina state samples was that they would not include the schools that were previously selected as part of the TIMSS national sample. By again following the Keyfitz procedure outlined in table 2 of Chowdhury, Chu, and Kaufman (2001), the procedure allowed us to minimize the overlap with the TIMSS national and NAEP Alpha (public school) samples. By minimizing the overlap with the national sample, the assessed classrooms can be included in only one study with proper probabilities. This was accomplished by partitioning the frame into the following three groups shown in order as in table 2 of the paper. The four groups were as follows: \uf06e schools not selected for either the TIMSS national or NAEP Alpha samples; \uf06e schools selected for the NAEP Alpha sample and not the TIMSS national sample; U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide \uf06e schools selected for the TIMSS national sample and not the NAEP Alpha sample; and \uf06e schools selected for the TIMSS national sample and the NAEP Alpha sample. With this design, the method accomplished the goal of selecting all the state sample from group 1 and none from the other groups. For the schools in groups 3 and 4, this was due to the sum of the school's probabilities of being selected for the state sample and the national sample was always less than one. In that case, their conditional probabilities are zero."}, {"section_title": "3.", "text": "\nLogically not applicable. The respondent answered a preceding filter question in a way that made the following dependent questions not applicable to him or her.\nRetrieve the relevant variables from the student-teacher linkage data files, including plausible values of achievement, classification variables, identification variables (IDCNTRY, IDSTUD, IDTEACH, and IDLINK), sampling (JKZONE and JKREP) and weighting (MATWGT, SCIWGT, or TCHWGT) variables, and any other variables used in the selection of cases."}, {"section_title": "Participation Rates and Nonresponse Bias", "text": "To minimize the potential for response biases, IEA developed participation or response rate standards that apply to all participating education systems and govern whether or not data are included in the TIMSS and PIRLS 2011 international datasets and the way in which aggregate statistics are presented in the international reports. These standards were set using composites of participation rates at the school, classroom, and student levels, and were calculated with and without the inclusion of substitute schools that were selected to replace schools refusing to participate. The standards take the following two forms, distinguished primarily by whether or not meeting the school participation rate of 85 percent requires the counting of substitute schools: Category 1: Met requirements. Participants that meet all of the following conditions are considered to have fulfilled the IEA requirements: Obtain an unweighted school response rate of at least 85 percent without replacement (rounded to nearest whole percent) AND an unweighted student response rate (after rounding) of at least 85 percent OR A weighted school response rate of at least 85 percent without replacement (rounded to nearest whole percent) AND a weighted student response rate (after rounding) of at least 85 percent OR The product of the (unrounded) weighted school response rate without replacement and the (unrounded) weighted student response rate of at least 75 percent (after rounding to the nearest whole percent). Participants in this category appear in the tables and figures in international reports without annotation, and are ordered by achievement score. Category 2: Met requirements after substitutes. In the case of participants not meeting the category 1 requirements, but who had a weighted school response rate of at least 50 percent without replacement (after rounding to the nearest percent) AND HAD EITHER:"}, {"section_title": "OR", "text": "The product of the (unrounded) weighted school response rate with replacement and the (unrounded) weighted student response rate of at least 75 percent (after rounding to the nearest whole percent). Those participants able to satisfy only the category 2 standard are included in the tables and figures as well but are annotated to indicate their response rate status. Category 3: Unacceptable sampling response rate even when replacement schools are included. Participants that could provide documentation to show that they complied with TIMSS and PIRLS sampling procedures and requirements but did not meet the requirements for Category 1 or Category 2 were be placed in Category 3. Participants in this category appeared in a separate section of the achievement tables, below the other participants, in international reports. These countries were presented in alphabetical order."}, {"section_title": "TIMSS and PIRLS Participation Rates of U.S. Schools, Classrooms, and Students", "text": "The raw numbers on which the various participation rates are based, along with the participation rates themselves, are shown in table 3-1 separately for the TIMSS fourth-grade and eighth-grade national samples and table 3-2 for the PIRLS national sample. Participation rates for the state samples are shown in appendix B. To explain how to interpret these participation rates, subsections 3.1.1 through 3.1.3 describe a complete interpretation of the TIMSS fourth-grade numbers. The participation rates for TIMSS eighth-grade, PIRLS, and all the state samples can be interpreted in the same way.  Students in participating  schools  Sampled  14,205  11,864  Excluded  839  398  Withdrawn  185  302  Eligible  13,181  11,164  Absent  612  687  Assessed 12,569 10,477 95 95 94 NOTE: NCES standards (Standard 1-3-8) indicate that participation rates should be calculated without including substitute schools since substitute schools do not have an independent probability of selection (National Center for Education Statistics 2002). However, the participation rates shown in this table are those reported by TIMSS and do include substitute schools in the calculations. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011. "}, {"section_title": "Interpreting School Participation Rates (TIMSS Fourth Grade Example)", "text": "The fourth-grade school sample consisted of 450 schools and was designed to yield a representative school sample for TIMSS and PIRLS, as both assessments were administered within the same schools . Thirteen ineligible schools were identified on the basis that they served special student populations or had closed or altered their grade makeup since the sampling frame was developed. This left 437 eligible schools, of which 347 agreed to participate. The fourth-grade school participation rate before substitution was 79 percent (unweighted). The analogous weighted school participation rate was also 79 percent."}, {"section_title": "Interpreting Classroom Participation Rates (TIMSS Fourth Grade Example)", "text": "In accord with the international requirements, schools agreeing to participate were asked to list their fourth-grade mathematics classes as the basis for sampling at the classroom level. Schools appeared to be able to identify classes in this way without any problems. A total of 1,674 mathematics classrooms were identified as a result. At this time, schools were given the opportunity to identify special classes-classes containing all, or a majority of, students with intellectual and/or functional disabilities, or students who were non-native-language speakers. While these classes were regarded as eligible, the students as a group were treated as excluded since, in the opinion of the school, their disabilities or language capabilities would render meaningless their performance on the assessment. A total of 72 classrooms were excluded in this way. This left a pool of 1,602 eligible classrooms from which the sample was drawn. While the students in these excluded classrooms did not figure in the participation rate calculations, they did count in the population coverage calculations, and this is reflected in the higher exclusion rate for the U.S. In the international report the U.S. is annotated to reflect this fact. Classrooms with fewer than 15 students were collapsed into pseudoclassrooms prior to sampling so that each eligible classroom in a school had at least 20 students. Two classrooms (pseudoclassrooms) were selected per school where possible. In schools where there was only one classroom, this classroom was selected with certainty. Some 623 classrooms were selected as a result of this process, and all participated in TIMSS. Weighted and unweighted classroom participation rates were 100 percent. Subsequently, schools were asked to list the students in each of the 623 sampled classrooms at the fourth grade, along with the teachers who taught mathematics and science to these students. At this time, schools were given the opportunity to identify particular students not suited to take the test because of functional and/or intellectual disabilities and/or because they were non-native language speakers (students with disabilities or non-native-language speakers who had been mainstreamed; see definitions in section 3.3)."}, {"section_title": "Interpreting Student Participation Rates (TIMSS Fourth Grade Example)", "text": "A total of 14,205 fourth-grade students were listed as being in these classrooms. (In mixed-grade classrooms only students in the target population were considered.) At the outset, 839 of these were excluded because of functional/intellectual disabilities or because they were non-native language speakers. Additionally, in the months between the listing of students and the time of the assessment, 185 students were classified as withdrawn, as they were no longer in the school/classroom at the time of the assessment. As a consequence, 13,181 students were considered eligible to take the assessment. On the day of the assessment some 612 students were absent, leaving 12,569 students who completed a TIMSS 2011 assessment booklet. Participation rates are calculated on the number of eligible students (13,181). Since 12,569 of the 13,181 eligible students were assessed, the weighted (and unweighted) student participation rate was 95 percent."}, {"section_title": "Combined Participation Rates", "text": "The combined school, classroom, and student weighted participation rate standard of 75 percent used by TIMSS and PIRLS in situations in which it was necessary to recruit substitute schools was met for all grade samples in TIMSS and PIRLS 2011. Both the weighted and unweighted product of the separate participation rates for TIMSS at grade 4 was 80 percent (82 percent for both TIMSS at grade 8 and PIRLS). The application of international guidelines means, however, that U.S. statistics describing fourthgrade students in TIMSS and PIRLS are annotated in international reports to indicate that coverage of the defined student population was less than the IEA standard of 95 percent and that participation rates were met only after substitute schools were included."}, {"section_title": "Participation Rates for All Countries", "text": "For comparable fourth-and eighth-grade school, classroom, and student participation rates in other nations in TIMSS, see exhibits C-2. through C-9 in appendix C of  and, for PIRLS see exhibits C-2. through C-9 in appendix C of ."}, {"section_title": "Exclusions", "text": "The national defined target population is described in Sample Design in TIMSS and PIRLS (Joncas & Foy, 2013). All schools and students excluded from this population are referred to as the \"excluded population.\" Exclusions could occur at the school level, with entire schools being excluded, or within schools, with specific students or entire classrooms excluded. TIMSS 2011 and PIRLS 2011 did not provide accommodations for students with disabilities or students who were unable to read or speak the language of the test."}, {"section_title": "School Exclusions", "text": "Countries could exclude schools that \uf06e were geographically inaccessible; \uf06e were of extremely small size; \uf06e offered a curriculum or school structure radically different from the mainstream educational system; or \uf06e provided instruction only to students in the excluded categories defined under \"withinschool exclusions,\" such as schools for the blind."}, {"section_title": "Within-School Exclusions", "text": "Countries were asked to adapt the following international within-school exclusion rules to define excluded students: Students with intellectual disabilities. Students who, in the professional opinion of the school principal or other qualified staff members, were considered to be intellectually disabled or who had been tested psychologically as such. This included students who were emotionally or mentally unable to follow even the general instructions of the test. Students were not to be excluded solely because of poor academic performance or normal disciplinary problems. Students with functional disabilities. Students who were permanently physically disabled in such a way that they could not perform in the TIMSS or PIRLS testing situation. Functionally disabled students who were able to respond were included in the testing."}, {"section_title": "Exclusions in the U.S. National Samples", "text": "As noted earlier, schools were given the opportunity to exclude any special classes among the total number of classes in the fourth or eighth grade. These classes were made up largely of students with functional or intellectual disabilities or students who were non-native-language speakers, as defined above. Classes identified in this way were excluded from the class sampling procedure. Subsequently, schools were given the opportunity to exclude students from the sampled classes-essentially, students with functional or intellectual disabilities, or non-native-language speaking students in the United States who had been mainstreamed. These procedures resulted in a (weighted) student exclusion rate of 7.0 percent in the fourth grade for TIMSS, 7.3 percent for PIRLS, and 7.2 percent for TIMSS in the eighth grade, based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (93 percent for TIMSS at both fourth and eighth grade and PIRLS) as acceptable though falling below the desired range of 95 percent or better. The tabulations shown in the international reports show the United States annotated to indicate this fact. Exclusion information for the state samples can be found on appendix B."}, {"section_title": "Nonresponse Bias Analysis", "text": "The National Center for Education Statistics (NCES) standards for assessment surveys stipulate that a nonresponse bias analysis is required at any stage of data collection with a weighted unit response rate of less than 85 percent (without substitution) at both grades. Because the U.S. TIMSS and PIRLS 2011 weighted school response rates at grade 4 are below 85 percent, NCES required an investigation into the potential magnitude of nonresponse bias at the school level in the U.S. samples, which is the focus of this section. Neither the U.S. TIMSS grade 8 nor any of the benchmarking states required a nonresponse bias analysis be performed because their weighted school and student participation rates were above 85 percent."}, {"section_title": "Methodology", "text": "To measure the potential nonresponse bias at the school level, the characteristics of participating schools were compared to those of the total eligible sample of schools. The alternative of comparing participants to nonparticipants, while resulting in the same tests of significance, makes it more difficult to judge the potential for bias. This analysis is similar to other NCES nonresponse bias studies on the 2003 TIMSS (Ferraro & Van de Kerckhove, 2006). The analysis for each sample (TIMSS Grade 4 and PIRLS Grade 4) was conducted in three parts as follows: Analysis of original respondent sample: The distribution for TIMSS of the responding (participating) original school sample (N = 347) was compared with that of the total eligible original school sample (N = 437). The distribution for PIRLS of the responding (participating) original school sample (N = 349) was compared with that of the total eligible original school sample (N = 437). The original sample is the sample before substitution. In each sample, schools were weighted by their school base weights that did not include a nonresponse adjustment factor. The base weight for each original school was the reciprocal of its selection probability."}, {"section_title": "Analysis of respondent sample with substitutes (final sample):", "text": "The distribution for TIMSS of the responding (participating) sample with substitutes (N = 369), was compared to the total eligible final sample (N = 437). The distribution for PIRLS of the responding (participating) sample with substitutes (N = 370), was compared to the total eligible final sample (N = 437). The final sample is the sample after substitution. Again, school base weights were used for both the eligible sample and the participating schools. The base weight for each substitute school was set to the base weight of the original school that it replaced."}, {"section_title": "Analysis of the nonresponse adjusted sample with substitutes:", "text": "As done in the second analysis, the same sets of schools were compared (i.e., N = 369 vs. N = 437 for TIMSS, N = 370 vs. N = 437 for PIRLS), but, this time, when analyzing the responding schools alone, school nonresponse adjustments were applied to the weights. The international weighting procedures created a nonresponse adjustment class 13 for each explicit stratum. For U.S. TIMSS grade 4, or \"TIMSS-4,\" and U.S. PIRLS grade 4, or \"PIRLS-4,\" 12 explicit strata were formed by poverty level, school control, and Census region, thus forming 12 adjustment classes. The first analysis indicates the potential for nonresponse bias that was introduced through school nonresponse. The second analysis suggests the remaining potential for nonresponse bias after the mitigating effects of substitution have been accounted for. The third analysis indicates the potential for bias after accounting for the mitigating effects of both substitution and nonresponse weight adjustments. Both the second and third analyses, however, may provide an overly optimistic scenario because even though substitution and nonresponse adjustments may correct somewhat for deficiencies in the few characteristics examined here, there is no guarantee that they are equally as effective for other characteristics, and in particular for student achievement. To compare participants and the total eligible sample, the sample of schools was matched to the sample frame to compare as many characteristics as possible that might provide information about the presence of nonresponse bias. Since the analyses involve both participating and nonparticipating schools, they are based, out of necessity, on data from the sampling frame as TIMSS and PIRLS data are not available for nonparticipating schools. Comparing frame characteristics for participants and the total eligible sample is not an ideal measure of nonresponse bias if the characteristics are unrelated or weakly related to more substantive items in the survey; however, this is often the only approach available. Frame characteristics for public schools were taken from the 2007-08 Common Core of Data (CCD) and, for private schools, from the 2007-08 Private School Survey (PSS). The following categorical variables were available in the sampling frame for all schools: School control. Indicates whether the school is under public control (operated by publicly elected or appointed officials) or private control (operated by privately elected or appointed officials and derives its major source of funds from private sources); Community type. The location of a school relative to populous areas, i.e., city, suburban, town, rural; Region. Census region (see section 3.5 for state listing); and"}, {"section_title": "Results for Original Respondent Sample-TIMSS Fourth Grade", "text": "This section presents the results of the nonresponse bias analysis, based exclusively on the original sample of 437 eligible U.S. schools for TIMSS-4 (section 3.4.6 presents the results for PIRLS). The distribution of the responding original school sample was compared with that of the total eligible original school sample using base weights in each case. All original schools in the sample that declined to participate in the survey were treated as nonparticipants regardless of whether they were substituted by a substitute school. The weighted and unweighted response rates were 79 percent, with 347 out of 437 eligible schools participating. See table 3-1 for details on the TIMSS-4 school participation rates."}, {"section_title": "Categorical variables (TIMSS-4)", "text": ". The distribution of participating and eligible schools in the U.S. TIMSS-4 sample by the four characteristics is shown in table 3-3. Based on these analyses, the chi-square statistics for school control and community type are significant and suggests that there is evidence of relationships with participating in the assessment. In particular, public schools were overrepresented U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide among participating schools (96.3 vs. 91.3 percent, respectively), and private schools were underrepresented among participating schools (3.7 vs. 8.7 percent, respectively). Similarly, schools in cities were underrepresented among participating schools relative to eligible schools (26.8 vs. 30.2 percent, respectively), while schools in rural areas were overrepresented among participating schools (24.2 vs. 22.6 percent, respectively). There are no statistically significant relationships between participation status and any of the other characteristics shown in table 3-3. .9 -0.18 -0.003 NOTE: For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011."}, {"section_title": "Results for Respondent Sample With Substitutes (Final Sample) -TIMSS Fourth Grade", "text": "This section presents the nonresponse bias analysis based on the final sample of 437 eligible schools for "}, {"section_title": "52", "text": "(96.2 vs. 91.3 percent, respectively), and private schools were underrepresented among participating schools (3.8 vs. 8.7 percent, respectively). These differences were slightly smaller than that shown in table 3-3, in which only the original sample was considered. Thus while there is no evidence that the use of substitute schools eliminated the potential for bias, as indicated by this variable, it certainly has also not added to it. There are no statistically significant relationships detected between participation status and the other characteristics shown in table 3-8. For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011."}, {"section_title": "Logistic regression model (TIMSS-4).", "text": "To examine the joint relationship of various characteristics to school nonresponse, the analysis utilized a logistic regression model with participation status as the binary dependent variable and frame characteristics as predictor variables. Six schools were excluded from the analysis due to missing information for race/ethnicity and total school enrollment."}, {"section_title": "Results for Nonresponse-Adjusted Sample With Substitutes (Nonresponse-Adjusted Sample)-TIMSS Fourth Grade", "text": "This section presents the nonresponse bias analysis based on the final sample of 437 eligible schools for TIMSS-4. The distribution of the responding sample, including participating substitutes, was compared to the total eligible final sample, just like the previous section. However, in this section, school base weights were used for the eligible sample of schools, whereas nonresponse-adjusted weights were used for the participating schools. Only eligible original schools that refused and were not successfully replaced by a substitute were treated as nonparticipants. All other eligible original sample schools were treated as participating.  For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school nonresponse adjusted weight. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), 2011."}, {"section_title": "Categorical variables (TIMSS-4).", "text": ""}, {"section_title": "Continuous variables (TIMSS-4)", "text": ". Summary means for each continuous variable for participating and eligible schools are shown in tables 3-14 through 3-16. Twenty-four of the 399 public schools had a missing value for the free or reduced-price lunch variable; these schools were excluded from the analysis."}, {"section_title": "Summary-TIMSS Fourth Grade", "text": "The results of the fourth-grade analyses are summarized in table 3-17. Native students were significant predictors of participation. The second model showed that private schools, total school enrollment, and fourth-grade enrollment were significant predictors of participation (with summed race/ethnicity percentage)."}, {"section_title": "Results for Original Respondent Sample-PIRLS Fourth Grade", "text": "This section presents the results of the nonresponse bias analysis, based exclusively on the original sample of 437 eligible U.S. schools for PIRLS-4. The distribution of the responding original school sample was compared with that of the total eligible original school sample using base weights in each case. All original schools in the sample that declined to participate in the survey were treated as nonparticipants regardless of whether they were substituted by a substitute school. The weighted and unweighted response rates were 80 percent, with 349 out of 437 eligible schools participating. See  1.20 0.020 NOTE: For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Educational Achievement (IEA) Progress in International Reading Literacy Study (PIRLS), 2011. Continuous variables (PIRLS-4). Summary means for each continuous variable for participating and eligible schools are shown in tables 3-19 through 3-21. Twenty-four of the 399 public schools had a missing value for the free or reduced-price lunch variable; these schools were excluded from the analysis. Participating schools had a higher mean fourth-grade enrollment than the eligible sample (99.1 vs. 94.0, respectively; table 3-19). There were no statistically significant differences detected between the participating and eligible public schools for race/ethnicity (table 3-20). Participating schools had a lower mean percentage than the eligible sample of students eligible for free or reduced-price lunch (46.6 vs."}, {"section_title": "Logistic regression model (PIRLS-4).", "text": "To examine the joint relationship of various characteristics to school nonresponse, the analysis utilized a logistic regression model with participation status as the binary dependent variable and frame characteristics as predictor variables. Public and private schools were modeled together using the variables available for all schools. Standard errors and tests of hypotheses for the full model parameter estimates are presented in tables 3-22a (with four race/ethnicity variables) and 3-22b (with summed race/ethnicity percentage). Private schools, high poverty schools, total school enrollment, and fourth-grade enrollment are significant predictors of school participation in table 3-22a. The negative parameter estimates indicate that, relative to public and low-poverty schools, private and high poverty schools, respectively, were somewhat underrepresented among the participating schools, and the total enrollment in participating schools was smaller than in all eligible schools (i.e., the smaller the total enrollment, the more likely a school was to participate). The positive parameter estimates indicate that the fourth-grade enrollment in participating schools was larger than in all eligible schools. The F test statistic to determine whether the race/ethnicity characteristics are simultaneously equal to 0 was 3.69 with a p value of 0.0002, which indicates a significant relationship detected with participation.  For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing.) Summed race/ethnicity percentage includes Black, non-Hispanic; Hispanic; Asian or Pacific Islander; and American Indian or Alaska Native. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Progress in International Reading Literacy Study (PIRLS), 2011.\nTo examine the joint relationship of various characteristics to school nonresponse, the analysis utilized a logistic regression model with participation status as the binary dependent variable and frame characteristics as predictor variables. Six schools were excluded from the analysis due to missing information for race/ethnicity and total school enrollment."}, {"section_title": "Results for Respondent Sample With Substitutes (Final Sample)-PIRLS Fourth Grade", "text": "This section presents the nonresponse bias analysis based on the final sample of 437 eligible schools for PIRLS-4. The distribution of the responding sample, including participating substitutes, was compared to the total eligible final sample. School base weights were used for both the eligible sample and the participating schools. Only eligible original schools that refused and were not successfully replaced by a substitute were treated as nonparticipants. All other eligible original sample schools were treated as participating. Through the use of substitutes, the weighted and unweighted school response rates for PIRLS-4 were 85 percent, with 370 out of 437 schools participating."}, {"section_title": "Categorical variables (PIRLS-4)", "text": ". The distribution of participating and eligible schools by the four characteristics is shown in table 3-23. Only school control was found to be statistically significant among the categorical variables. In particular, public schools were overrepresented among participating schools U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide (94.9 vs. 91.3 percent, respectively), and private schools were underrepresented among participating schools (5.1 vs. 8.7 percent, respectively). These differences were slightly larger than that shown in table 3-18, in which only the original sample was considered. Thus while there is no evidence that the use of substitute schools eliminated the potential for bias, as indicated by this variable, it certainly has also not substantially added to it. There are no statistically significant relationships detected between participation status and the other characteristics shown in table 3-23. For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Progress in International Reading Literacy Study (PIRLS), 2011.\n. The distribution of participating and eligible schools by the four characteristics is shown in table 3-28. No variables were found to be statistically significant among the categorical variables. For public schools, a high poverty school is defined as one in which 50 percent or more of the students are eligible for participation in the free or reduced-price lunch (FRPL) program, and low poverty is defined as having less than 50 percent eligible. All private schools are treated as low-poverty schools. For definitions of these urban-centric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Region is the Census region of the country (see section 3.5 for state listing). Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school nonresponse adjusted weight. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Progress in International Reading Literacy Study (PIRLS), 2011."}, {"section_title": "Participating", "text": "(percent) (N = 328) Percentage of students eligible for free or reduced-price lunch 47.9 46.7 -1.20 -0.025 0.059 NOTE: Information on percentage of students eligible for free or reduced-price lunch is missing for 24 of the 399 public schools in the final sample and 23 of the 351 public schools that participated. Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school base weights that did not include a nonresponse adjustment factor. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Progress in International Reading Literacy Study (PIRLS), 2011."}, {"section_title": "Results for Nonresponse-Adjusted Sample With Substitutes (Nonresponse-Adjusted Sample)-PIRLS Fourth Grade", "text": "This section presents the nonresponse bias analysis based on the final sample of 437 eligible schools for PIRLS-4. The distribution of the responding sample, including participating substitutes, was compared to the total eligible final sample just like the previous section. However, in this section, school base weights were used for the eligible sample of schools, whereas nonresponse-adjusted weights were used for the participating schools. Only eligible original schools that refused and were not successfully replaced by a substitute were treated as nonparticipants. All other eligible original sample schools were treated as participating."}, {"section_title": "Continuous variables (PIRLS-4)", "text": ". Summary means for each continuous variable for participating and eligible schools are shown in tables 3-29 through 3-31. Twenty-four of the 399 public schools had a missing value for the free or reduced-price lunch variable; these schools were excluded from the analysis. There were no statistically significant differences detected between participating and eligible schools for enrollment (table 3-29) or race/ethnicity (table 3-30). There was also no statistically significant difference detected between the participating and eligible public schools for free or reduced-price lunch (table 3-31). However, this must be interpreted with caution because the variable is missing for 24 schools.   (percent) (N = 328) Percentage of students eligible for free or reduced-price lunch 47.9 47.4 -0.50 -0.010 0.468 NOTE: Information on percentage of students eligible for free or reduced-price lunch is missing for 24 of the 399 public schools in the final sample and 23 of the 351 public schools that participated. Eligible schools contained at least one fourth-grade class. Participating schools agreed to have their students assessed. The bias is the difference between the respective estimates for the participants and the eligible sample. The relative bias is calculated as the bias divided by the estimate from the eligible sample. Schools were weighted by their school nonresponse adjusted weight. SOURCE: International Association for the Evaluation of Education Achievement (IEA), Progress in International Reading Literacy Study (PIRLS), 2011."}, {"section_title": "Summary-PIRLS Fourth Grade", "text": "The results of the grade 4 analyses are summarized in table 3-32. When all of these factors were considered simultaneously in a regression analysis, private schools and fourth-grade enrollment remained significant predictors of participation in both models (tables 3-27a and 3-27b, with summed race/ethnicity percentage). For the final sample of schools in PIRLS-4 with school nonresponse adjustments applied to the weights, no variables were statistically significant in the bivariate analysis: The multivariate regression analysis cannot be conducted after the school nonresponse adjustments are applied to the weights. These results suggest that there is some potential for nonresponse bias in the U.S. PIRLS-4 original sample based on the characteristics studied. It also suggests that, while there is no evidence that the use of substitute schools reduced the potential for bias, it has not added to it substantially. The application of school nonresponse adjustments completely reduced the potential for bias, based on the characteristics studied."}, {"section_title": "Conclusions", "text": "The investigation into nonresponse bias at the school level for U.S. 2011 TIMSS sample for grade 4 and the PIRLS sample for grade 4 has shown that there was no statistically significant relationship detected between participation status and the majority of school characteristics that are available for analysis. It also suggests that, while there is no evidence that the use of substitute schools reduced the potential for bias, it has not added to it substantially. The application of school nonresponse adjustments substantially reduced the potential for bias. However, the results do indicate some potential for bias in the data arising from school control, enrollment, and regional differences in participation, along with the fact that schools with higher percentages of minority students were less likely to participate. "}, {"section_title": "Technical Notes", "text": ""}, {"section_title": "Description of Variables", "text": "Frame characteristics for public schools were taken from the 2007-08 Common Core of Data (CCD) and, for private schools, from the 2007-08 Private School Survey (PSS). Race/ethnicity. Students' race/ethnicity was obtained through student responses to a two-part question. Students were asked first whether they were Hispanic or Latino and then asked whether they were members of the following racial groups: American Indian/Alaska Native; Asian; Black or African American; Native Hawaiian or other Pacific Islander; or White. Multiple responses to the race classification question were allowed. Community type. Community type was derived from the locale variable based on how the school is situated in a particular location relative to populous areas, based on the school's address. City consists of territory inside an urbanized area and inside a principal city with population of 250,000 or more, territory inside an urbanized area and inside a principal city with population less than 250,000 and greater than or equal to 100,000, and territory inside an urbanized area and inside a principal city with population less than 100,000. Suburb consists of territory outside a principal city and inside an urbanized area with population of 250,000 or more, territory outside a principal city and inside an urbanized area with population less than 250,000 and greater than or equal to 100,000, and territory outside a principal city and inside an urbanized area with population less than 100,000. Town consists of territory inside an urban cluster that is less than or equal to 10 miles from an urbanized area, territory inside an urban cluster that is more than 10 miles and less than or equal to 35 miles from an urbanized area, and territory inside an urban cluster that is more than 35 miles of an urbanized area. Rural consists of Census-defined rural territory that is less than or equal to 5 miles from an urbanized area, as well as rural territory that is less than or equal to 2.5 miles from an urban cluster, Census-defined rural territory that is more than 5 miles but less than or equal to 25 miles from an urbanized area, as well as rural territory that is more than 2.5 miles but less than or equal to 10 U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide miles from an urban cluster, and Census-defined rural territory that is more than 25 miles from an urbanized area and is also more than 10 miles from an urban cluster. Poverty level in public schools. The measure of school poverty is based on the percentage of students eligible for FRPL. Schools were classified as \"low poverty\" if less than 50 percent of the students were eligible for FRPL and as \"high poverty\" if 50 percent or more of the students were eligible. In the interest of retaining all of the schools and students in these analyses, private schools were assumed to be lowpoverty schools-that is, they were assumed to be schools in which less than 50 percent of students were eligible for FRPL."}, {"section_title": "Region", "text": ""}, {"section_title": "Statistical Procedures", "text": "Weighting. Before the data are analyzed, responses from the groups of students assessed are assigned sampling weights to ensure that their representation in TIMSS and PIRLS 2011 results matches their actual percentage of the school population in the grade assessed. Responses from the groups of students were assigned sampling weights to adjust for over-or underrepresentation during the sampling of a particular group. The use of sampling weights is necessary for the computation of sound, nationally representative estimates. The weight assigned to a student's responses is U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide the inverse of the probability that the student would be selected for the sample. When responses are weighted, none are discarded, and each contributes to the results for the total number of students represented by the individual student assessed. Weighting also adjusts for various situations (such as school and student nonresponse) because data cannot be assumed to be randomly missing. The internationally defined weighting specifications require that each assessed student's sampling weight should be the product of (1) the inverse of the school's probability of selection, (2) an adjustment for school-level nonresponse, (3) the inverse of the classroom's probability of selection, and (4) an adjustment for student-level nonresponse. In the analyses in this report, sometimes the appropriate weight (base weight) includes only the components of the reciprocals of the respective selection probabilities. This is the case when estimates are made based on the entire sample. In other cases nonresponse adjustments, as computed by the International Study Center, are also applied. In each case the text and tables make clear which of these weighting procedures has been applied. Whereas for substantive analyses using the TIMSS and PIRLS data, one would normally apply the nonresponse adjustments when analyzing the data from the respondents in the sample, this is not always when the case when carrying out analyses of potential nonresponse bias analyses. Sampling errors. Sampling errors occur when the discrepancy between a population characteristic and the sample estimate arises because not all members of the reference population are sampled for the survey. The size of the sample relative to the population and the variability of the population characteristics both influence the magnitude of sampling error. The particular sample of students in fourth and eighth grade from the 2010-11 school year was just one of many possible samples that could have been selected. Therefore, estimates produced from the TIMSS and PIRLS sample may differ from estimates that would have been produced had another student sample been drawn. This type of variability is called sampling error because it arises from using a sample of students in fourth or eighth grade, rather than all students in the grade in that year. The standard error is a measure of the variability due to sampling when estimating a statistic, and is often included in reports containing estimates from survey data. The approach used for calculating sampling variances was the jackknife repeated replication (JRR). This report does not show estimates of standard errors for each estimate. Rather the effects of sampling error are reflected in the test statistics (for t tests and chi-square tests, and t test used in logistic regression analyses) that are presented for each analysis. These are described below."}, {"section_title": "Tests of Significance", "text": "Comparisons made in the text of this report have been tested for statistical significance. For example, when comparing results obtained from the full sample for a given grade, with those obtained only from the responding sample units, tests of statistical significance were used to establish whether or not the observed differences are statistically significant.  (Westat, 2007). Two kinds of statistical tests are included in the report: t tests and chi-square tests. In addition, logistic regression analyses were conducted."}, {"section_title": "Use of t Tests", "text": "The t test was used for testing for the hypothesis that no difference exists between the means of continuous variables for two groups (namely, the full sample and the responding sample). Suppose that A x and B x are the means for two groups that are being compared and ( ) is the standard error of the difference between the means, which accounts for the complex survey design. Then the t test is defined as This statistic is then compared to the critical values of the appropriate student t-distribution to determine whether the difference is statistically significant. The appropriate number of degrees of freedom for the distribution is given by the number of primary sampling units in the design (in this case the number of schools), minus the number of sampling strata. Note that this procedure took account of the fact that the two samples in question were not independent samples, but in fact the responding sample was a subsample of the full sample. This effect was accounted for in calculating the standard error of the difference. Note also that, in those cases where both samples were weighted just using base weights, the test is exactly equivalent to testing that the mean of the respondents was equal to the mean of the nonrespondents. Consider for example the data in table 3-4. The first row shows that the weighted mean total school enrollment for the full eligible sample of grade 4 schools is 561.3. For the subsample of schools that participated, the corresponding mean is 570.1, resulting in a difference of 8.74. The standard error of this estimated difference, calculated so as to reflect the dependency between these two samples, and the complex sample design, is 6.65 (not shown in table). This gives rise to a t-statistic of 1.31 (not shown in Report and User's Guide  table), and using 75 degrees of freedom (the appropriate figure for the TIMSS and PIRLS design), the resulting significance (or p value) is 0.193. This last figure appears in the table."}, {"section_title": "U.S. TIMSS and PIRLS 2011 Technical", "text": "The t test was also used in the logistic regression for testing for the hypothesis for whether each estimated parameter estimate is significantly different from 0. Then the t test is defined as where k b is a parameter estimate and ( ) is the replication variance estimate for that parameter. This statistic is then compared to the critical values of the appropriate student t-distribution, as described above, to determine whether the difference is statistically significant. The appropriate number of degrees of freedom for the distribution is again given by the number of primary sampling units in the design (in this case the number of schools), minus the number of sampling strata."}, {"section_title": "Chi-square Tests", "text": "Chi-square tests are used for testing whether two distributions of a given categorical variable are different, conducted in a way that reflects the impact of the complex sample design on sampling variance. In this instance one distribution is for the full sample and one for the responding sample. Suppose that the categorical variable in question has c levels, cross-tabulated producing weighted proportions p. The usual Pearson chi-square statistic is calculated as ( ) where j denotes the categories of the categorical variable, i indexes the samples (full sample and respondents), and n indicates the overall sample size. This statistic is not suitable for use directly in a statistical test with these data, for two reasons. First, the fact that the respondents are a subset of the full sample violates the standard assumptions for a chi-square test of this kind. Second, this statistic does not account for the complex sample design used to collect the data. Thus the Pearson chi-square statistic is modified appropriately to account for the impact of these two features. The resulting test statistic is referred to as the Rao-Scott Adjusted chi-square statistic. It is sometimes also referred to as the Satterthwaite-adjusted chi-square statistic. The number of degrees of U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide freedom for the chi-square test, normally given as (c -1), where c is the number of categories of the categorical variable for each distribution, is also modified on account of the complex design. The modified test statistic is then compared to the chi-square distribution with the appropriate number of degrees of freedom, to determine whether the difference in the two distributions is statistically significant. For a detailed description of the technique, see Rao and Scott (1984) or Rao and Thomas (2003). The first step in the calculation of the Satterthwaite-adjusted chi-square statistic is to form the following vector: An rc x 1 vector made up of the products of the marginal proportions is defined as For each replicate, an rc x rc matrix is calculated whose ij-th element is made up of ( )( ), where y ig and y jg are the i-th and j-th elements of Y calculated for the g-th replicate and y i and y j are the corresponding full-sample values. The ij-th element of the estimated covariance matrix for Y, B = cov(Y), is calculated using the following formula:"}, {"section_title": "Logistic Regression Models", "text": "Let p i denote the probability that the i-th sampled school will participate. Under the logistic regression model, the log odds of response propensity (expressed in terms of the logarithm of p i /(1-p i )), is assumed to have the following linear form: where X 1i , X 2i ..., X pi are p auxiliary variables associated with the i-th sampled school, and \u03b2 0 , \u03b2 \u03b2 1 , ..., p are coefficients to be estimated. Asymptotic assumptions are used to develop statistical tests to determine which, if any, of the coefficients are significantly different from zero. In the analyses in this report the standard procedures for carrying out logistic regression analyses have been modified both to incorporate the sampling weights in the estimation of the coefficients and to reflect the effect of the complex sample design on the variance-covariance matrix of the coefficients. The Newton-Raphson algorithm is used to iteratively solve for parameter solutions in the logistic and ( ) H \u03b2 evaluated at b t , the value of the estimate b at step t. The general approach is to approximate the sample log-likelihood at the desired estimate, , at step t in the iterative process near the point b t by a second-order Taylor series expansion: , assuming H t has an inverse. Given an initial value for t = 0, the set of iteration equations is solved for 1 b , 1 b is used to solve for 2 b , and so on, until the convergence criterion is satisfied. The ( ) \u03b2 se is calculated using JRR and repeating the procedure for each replicate."}, {"section_title": "4.", "text": "\nNot reached (only used in the achievement files). This code indicates those items not reached by the students due to a lack of time. SAS and SPSS control code for all the data files include the code for handling/converting missing data.\nMerge the teacher background data files with the student-teacher linkage data files using the variables IDCNTRY, IDTEACH, and IDLINK."}, {"section_title": "Survey Operations", "text": "This chapter describes data collection and related activities for TIMSS and PIRLS 2011 in the United States. These activities included recruitment of schools for the national and state samples; sampling of students within schools; development of the instruments used; field operations undertaken to administer the assessment; post assessment activities associated with scoring and data entry; and several activities associated with the preparation of the data to meet international standards."}, {"section_title": "Recruiting Districts and Schools", "text": "The established protocol for seeking the participation of schools in studies such as TIMSS and PIRLS, where participation is voluntary, is to (1) notify state education authorities of the intention to approach schools within their jurisdiction, (2) inform authorities at the district level that schools within their districts are being sampled, and (3) contact the sampled schools. Participation may be refused at any of these levels, so several considerations were important in this context, specifically the need to establish the value of participation; establish the timing of the assessment window in conjunction with mandatory federal, state, and local assessments; and address concerns about the burden on schools. Private schools were contacted directly. In the case of Catholic schools, the diocese was informed and schools were then contacted. Non-religious affiliated private schools were contacted directly. The recruitment for TIMSS and PIRLS, particularly at grade 8, benefitted from increased involvement at the state level. The inclusion of a TIMSS-NAEP linking study at grade 8 allowed NAEP State Coordinators within each state to secure participation of sampled public schools in their states."}, {"section_title": "Timing of Recruitment Activities", "text": "Assessment dates needed to be established early in the school year in which the assessment was to take place or, better still, toward the end of the previous school year. In total, the recruitment phase for TIMSS and PIRLS 2011 extended from April 2010 through May 2011, as indicated in exhibit 1-1 in chapter 1. States were contacted toward the end of April 2010. Following this, contact with districts began in May 2010 and continued through the summer. Schools were contacted beginning in June 2010 and activities continued through March 2011."}, {"section_title": "Contacting States", "text": "The chief state school officer and state assessment director in each of the 50 states and the District of Columbia were contacted beginning in April 2010. Each person received a combined TIMSS-PIRLS package that included an NCES cover letter, instructions on how to obtain the sampled schools in the state, a brochure describing the study, a timeline of activities, a summary of activities for the school coordinator, and a sheet of frequently asked questions. A copy of the letter sent to states is provided as exhibit C-1 in appendix C. Several items of TIMSS and PIRLS information materials (exhibits D-1 through D-8 in appendix C) were included with the letter. Similar packages were supplied to NAEP State Coordinators (NSCs), and NCES and Westat held a series of webinars to explain TIMSS at grade 8 and the processes used to report participation and to answer questions about the study. In many cases, NSCs created personalized contact letters for districts and "}, {"section_title": "Contacting Districts", "text": "After informing the states, similar packages of advance materials were sent to the superintendent and the assessment director of each district (or diocese) containing sampled schools. A copy of the letter sent to districts is provided as exhibit C-2 in appendix C. Several items of TIMSS and PIRLS information materials (exhibits D-1 through D-8 in appendix D) and a list of sampled schools were included with the letter. During this time, if a sampled school in a cooperating district refused to participate and was judged to be a firm refusal, a similar district package was sent out to the district of the first substitute school linked to the sampled school. A parallel procedure was adopted with the second substitute district and school in those cases where a first substitute school refused to participate."}, {"section_title": "Follow-up Contact", "text": "In each case field staff made follow-up calls to district contacts after a few days to discuss the study and answer questions. Additionally, 57 school districts required a formal application process and school board approval. However, given that many of these were in states with eighth-grade sampled schools, thus states were contacting the districts and schools, these requirements were waived. Only 16 applications had to be formally processed.\nAfter a few days, each school was contacted by a field staff member to discuss the school's participation in TIMSS. In-person visits were made in a small number of schools where efforts to secure participation proved difficult. "}, {"section_title": "Special security requirements.", "text": "As a matter of course, each TIMSS field staff member had a current FBI clearance and fingerprints on file. In most instances this satisfied school security requirements. However, a number of districts required that additional procedures be met before allowing staff to enter schools. For example, New York City required staff to obtain additional, local fingerprinting at a local office in New York City. Additionally, for each school in New York City, Westat was also required to complete a special form with signatures from both the principal and the district superintendent. In Florida, several districts required additional fingerprinting and a local security check (Miami-Dade County required the completion of an Affidavit of Good Moral Character). In many cases, field staff working in these districts had these clearances on file from their recent NAEP work."}, {"section_title": "Contacting Schools", "text": "After district approval was secured, schools were contacted with an initial school information packet. Private schools and some parochial schools not linked with a diocese were contacted directly. Each school information package was sent on a flow basis governed by receipt of district approval. A copy of the cover letter included in the school package is shown as exhibit C-3 in appendix C. Copies of items of TIMSS and PIRLS information materials (exhibits D-1 through D-8 in appendix D) were included with the letter."}, {"section_title": "Informational Materials and Gifts", "text": "Since the initial contact with states, districts, and schools was by mail, particular attention was paid to developing materials that would promote the value of participation and assure all concerned that the burden on schools would be minimal. These materials included the following: After the assessment, schools and school coordinators were paid incentives of $200 and $100, respectively. Students each received a clock-compass carabiner. Some additional documents were used to maintain contact with schools throughout the year and to inform school coordinators of coming TIMSS and PIRLS activities; see, for example, the sheet describing school coordinator responsibilities (exhibit D-2 in appendix D). Schools were sent a holiday card toward the end of 2010, and at various points school coordinators were sent informational materials to prepare them for upcoming TIMSS and PIRLS tasks. Drafts of parent approval letters, forms, and fact sheets were supplied to those schools indicating that parent approval was required. Details on the parent approval materials is provided in exhibits C-6 through C-14 in appendix C and discussed further below. meeting weekly with the field manager by conference call to discuss progress."}, {"section_title": "Gaining Cooperation Recruiters (GCRs)", "text": ""}, {"section_title": "Training Field Staff", "text": "A recruitment training workshop for field staff was held at Westat on June 6, 2010. A Gaining Cooperation Manual was assembled and sent to GCRs 5 days prior to training. GCRs were asked to complete 4 hours of home study before training. The training was delivered as distance training through a webinar with the field manager and project director. All of the materials that would be sent to district and school contacts in the recruitment package were provided and explained. A subsequent discussion ensured that all field staff engaged in the recruitment of districts and schools understood the mission of TIMSS and PIRLS, the materials used in the United States, and the importance of satisfactory participation rates. and avoiding refusals. Participants were invited to share successful strategies and techniques in past recruitment experiences. Also, approaches that might be used with schools for refusal conversion were introduced and practiced. To reinforce these presentations and discussions, several role-playing exercises were performed after the training session. The final activity was the completion of a hands-on tutorial of the TIMSS and PIRLS Field Management System (FMS). Each GCR had a laptop workstation connected to the FMS and a set of small exercises to complete on dummy case data in the system."}, {"section_title": "Monitoring the Recruiting Progress", "text": "Progress in recruiting districts and schools was monitored on a daily basis through the TIMSS and PIRLS Field Management System (FMS). GCRs were required to update the FMS for each contact made with districts or schools using an electronic record of calls that included updating the disposition code for the district/school in question. The disposition code indicated whether the district or school was pending, refusing, or cooperating. Using these status codes, the Westat home office tracked the progress of recruitment and generated daily reports. These daily reports enabled the operations of recruitment (and eventually assessments) to be closely monitored. NAEP State Coordinators used a special template similar to the FMS to monitor the recruitment status of eighth-grade public schools in their states."}, {"section_title": "Difficulties in Gaining Cooperation", "text": "The principal reasons given by both districts and schools for refusing to participate included, in approximate order of priority, the following: \uf06e Conflict with mandatory federal, state, and/or local assessments whose outcomes had direct implications for districts, schools, teachers and students; \uf06e The related matter of the burden that additional testing placed on students at the cost of instructional time; and \uf06e The limited return on the school's investment of time since they would not receive much usable information on the school, and none on particular students."}, {"section_title": "Sampling Students Within Schools", "text": "Students in participating schools were sampled in a two-stage process. In the first stage, schools were asked to provide lists of fourth-grade classrooms or eighth-grade mathematics classrooms that indicated the number of students in each class. An equal probability sample of two classrooms (or pseudoclassrooms) was identified from the classrooms listed for each school. In the second stage all students in sampled classrooms (or pseudoclassrooms) were selected for assessment. These procedures are standardized internationally and embodied in software made available to each country. The software was developed by the IEA Data Processing Center (DPC) and is known as WinW3S (IEA DPC, 2010). The WinW3S system provides for forms generation, data entry, class sampling, student sampling, student-teacher linkages, the random assignment of assessment booklets to students, the production of various survey tracking forms, and the printing of labels for test instruments and questionnaires. Westat home office staff attended a training session using WinW3S and conducted a 2-day training for the data entry staff to introduce them to the software and familiarize them with the listing forms and the procedures for entering data."}, {"section_title": "Obtaining Class Lists From Schools", "text": "A Class Listing Form (CLF) was sent to the school coordinator. The CLF was used to create a list of the eligible classes, some attributes of each class, and the names of the teacher(s) teaching each class. An example Class Listing Form for grade 4 is reproduced in exhibit 4-1. A similar form for grade 8 is shown in exhibit 4-2. The information relating to school ID and school name, the name of the school coordinator, and the grade level in question was filled before the form was dispatched. Schools were asked to complete the remaining information for each eligible fourth-grade class or eighth-grade mathematics class in the school. At grade 4, the form asked for the reading, math, and science teachers to be listed in addition to the class information. In grade 8, only the mathematics teachers were listed for each class. The CLFs were sent via FedEx in a packet to each designated school coordinator and contained a customized cover letter, the school's CLF, and a school coordinator handbook for TIMSS-PIRLS or TIMSS (based on the grade). This packet was followed by an email with an encrypted CLF attachment that was password protected. Emails were sent to schools for which email addresses were available. All schools received a hard copy. The first wave of emails was sent January 27, 2011 (grade 4 CLFs); the second wave was sent February 1, 2011 (grade 8 CLFs). Processing the Class Listing Forms. Receipt of the CLF was tracked using a ledger that included the return status of each form and detailed any anomalies. The status of schools was reviewed weekly. As CLFs were returned, they were processed as follows: \uf06e The forms were reviewed for clarity and completeness."}, {"section_title": "Identifying Students and Their Teachers", "text": "With the classes identified, a Student-Teacher Linkage Form (STLF) was generated for each of the sampled classes in TIMSS and a Student Listing Form (SLF) was created for sampled classes in PIRLS. These forms were created by the WinW3S software and output in Excel using information from the CLF. An example of an STLF and SLF containing fictitious information is provided in exhibits 4-3 and 4-4, for TIMSS and PIRLS respectively. The upper part of the form containing the school ID, school name, class ID, school coordinator name, and grade was completed using information from the Class Listing Form. The remainder of the form was to be completed by the school, beginning with a listing of the names of the students in the named class. Schools were then asked to work across the form line-by-line to add the information relating to each student and to the mathematics and science teacher(s) of each student. Copies of the forms describing each of the sampled classes, along with instructions and examples, were sent to each school coordinator."}, {"section_title": "Student Tracking Forms (STF)", "text": "Information from the STLF was entered into the WinW3S system, which generated a Student Tracking Form (STF) for each class. The Student Tracking Form was designed to provide test administrators with student IDs, student identifiers in the form of date of birth and sex, the booklet assignment to each student, and the means to record the completion of the assessment and associated questionnaire. The student names or IDs shown in the first column of the form were removed following the assessment and retained by the school to ensure confidentiality. An example of a STF containing fictitious information is provided in exhibit 4-5."}, {"section_title": "Teacher Tracking Form (TTF)", "text": "A Teacher Tracking Form was also generated from information provided on the STLF. This form enabled test administrators to record the participation of teachers and to ensure that each teacher received the correct teacher questionnaire. Teacher names provided in the TTF were removed following the assessment and retained by the school to ensure confidentiality. The student questionnaire was grade-specific and bound into the assessment booklet with the assessment items for the particular grade. The school questionnaire was designed as an online instrument to be completed by the school principal. In the case of the teacher questionnaires, these were also developed as online instruments. A single fourth-grade online teacher questionnaire was designed for both TIMSS and PIRLS to be completed by the reading and/or mathematics and/or science teachers of the students in the sampled classrooms. Separate questionnaires were provided for the TIMSS mathematics teachers and science teachers of the students in the sampled eighth-grade classrooms. The international versions of the "}, {"section_title": "Assessment Frameworks", "text": "For both TIMSS and PIRLS 2011, the test development effort began with a revision of the frameworks used to guide the construction of the previous TIMSS 2007 and PIRLS 2006 assessments (Mullis et al., 2005;Mullis et al., 2006). The frameworks were updated to reflect changes in the curriculum and instruction of participating countries (Mullis et al., 2009). Extensive input from experts in mathematics and science education, reading education, assessment, and curriculum, and representatives from national educational centers around the world contributed to the final shape of the frameworks. Maintaining the ability to measure change over time was an important factor in revising the frameworks."}, {"section_title": "Content and Cognitive Domains", "text": "The TIMSS mathematics and science assessments were designed along two dimensions: (1) the topics or content that students are expected to learn and (2) the cognitive skills students are expected to have "}, {"section_title": "Background Questionnaires", "text": "As in prior administrations, TIMSS and PIRLS 2011 included self-administered questionnaires for principals, teachers, and students. "}, {"section_title": "U.S. Adaptations to the Assessment Items and Questionnaires", "text": "Source versions of all instruments (assessment booklets, questionnaires, and manuals) were prepared by the IEA in English and translated by the participating countries into the primary language or languages of U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide instruction in each country. In addition, it was sometimes necessary to adapt the instruments to better fit language usage, even in countries that use English as the primary language of instruction. Other adaptations to fit national education characteristics were sometimes required as well. All adaptations were reviewed and approved by the IEA to ensure they did not change the substance or intent of the question or answer choices."}, {"section_title": "U.S. Adaptations to the Assessment Items", "text": "As in previous cycles of TIMSS and PIRLS, the U.S. adaptations to the international instruments were minimal and designed to make the assessment more readable to U.S. students without changing the essence of the assessment item. For example, at times names of individuals were changed to more familiar forms (for example, \"Ahmed\" to \"Andrew\"), nouns with British origins were changed to their U.S. equivalent (for example, \"cinema\" to \"movie theater\"), Imperial English spellings were changed to American English (for example, \"organisation\" to \"organization, \"programme\" to \"program\"), and some changes to the text of instructions were also made to better mirror the administration procedures in the United States."}, {"section_title": "U.S. Adaptations to the School, Teacher, and Student Questionnaires", "text": "Adaptations made to the school, teacher, and student questionnaires were of the following five main types: \uf06e changes to general instructions made in the interests of enhancing clarity; \uf06e changes designed to make question text more readable to U.S. students, similar to those made to the assessment items as described above; \uf06e changes to response alternatives where the international response set did not adequately reflect the U.S. context; \uf06e additional questionnaire items included to address particular issues of national interest; and \uf06e International items that were omitted from the U.S. questionnaires because they violated the federal Pupil Privacy Rights Act (for example, questions on bullying and violence in the school)."}, {"section_title": "Translation and Verification of Instruments", "text": "Each country prepared translations of the instruments according to translation guidelines established by the IEA. Since the international versions of the instruments are produced in English, the U.S. did not need to engage in the full-fledged translation required of many nations. However, the adaptations made to the U.S. instruments required verification by the IEA to ensure their suitability for the current cycle of TIMSS and, if trend items, their continuity with previous cycles. Further details on the translation process can be found in Martin and Mullis (2011)."}, {"section_title": "Production of Assessment Booklets and Questionnaires", "text": "On receiving IEA approval of the adaptations, Pearson Educational Measurement applied the adaptations to the international questionnaires and item blocks and then assembled the final assessment booklets. Quality control procedures for this process included a review of each adaptation made to the questionnaires and item blocks as well as a full review of the assembled instruments in a final layout proof. In mid-December 2010, electronic files were sent to the IEA Data Processing Center (DPC) for verification of the national changes and to the TIMSS & PIRLS International Study Center for layout verifications. The student assessment booklets and student questionnaires were printed in scannable form. The teacher and school paper and pencil versions of the questionnaires were printed in non-scannable form. A similar procedure was applied to the online school and teacher questionnaires. Adaptations were made to the online instruments using software provided by the IEA DPC. A set of output files was produced for each questionnaire, and these were uploaded to a secure sever and verified by the DPC."}, {"section_title": "Scannable Document Preparation and Printing", "text": "The student test assessment and student questionnaire were printed as scannable documents combined into 14 single booklets. Document production was divided into two phases. The preparation phase included the mockup and design of forms, typesetting, composition, and editing for text accuracy and process ability. The production phase included final platemaking, printing, binding, and any finishing procedures (counting, wrapping, etc.) that were required prior to packaging and distribution. After a form was created, it was thoroughly inspected for grammar, spelling, and punctuation to ensure that it matched the approved electronic files. Subsequently, copies of these proofs were subject to a technical review of \"scan ability,\" oval placement, and spine code assignment. Immediately after printing, sample documents were selected from predetermined locations throughout the print run for testing. Before shipping, a sample from each carton of multipage documents was inspected to ensure that the pages of the booklets were in the correct sequence. After binding, all documents were boxed to assure that material quality was maintained during transit."}, {"section_title": "Preparation and Printing of Non-Scannable Documents", "text": "The teacher and school questionnaires were produced as non-scannable documents. In a first stage proofs of each document were reviewed against the original electronic files. Once accuracy was certified, printing was initiated. During this process staff checked a 10 percent sample of the printed form against the approved document to ensure that accuracy was maintained throughout the printing process."}, {"section_title": "Online Questionnaires", "text": "Once verified, each questionnaire was loaded to an NCES server and thoroughly tested by NCES and Westat to ensure that responses were being captured correctly and that the instruments were functioning properly."}, {"section_title": "Field Operations", "text": "The activities discussed here refer to those associated with the administration of the assessments in participating schools. In the United States the administration of the assessments was carried out by U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide professional staff trained according to the international guidelines. School personnel were asked only to assist with listings of students, the identification of school space for the assessment, and the specification of parental consent procedures needed for sampled students. Field operations centered on three main tasks: recruiting and training of field staff; scheduling the assessments; and administration of the assessments within the schools. Many of the gaining cooperation staff working on the recruitment of districts and schools were retained for the assessment phase of the study.  "}, {"section_title": "Responsibilities of Field Managers, Test Administrators and Assistant Administrators", "text": ""}, {"section_title": "Scheduling Assessments", "text": "The 1,240 schools taking part in TIMSS and PIRLS 2011 were dispersed across the country, although with concentrations in the more populous states and cities. Scheduling assessment dates for these schools required the optimization of school preferences for a particular date with the assessment date preferences of nearby schools and the location of field staff in an effort to keep travel and related expenses to a minimum. The basic approach adopted involved the geographic mapping of schools and assignment of a preliminary date, along with the location of field staff. This formed the foundation for discussions with schools, and the assignment of schools to field staff. In essence, geographical clusters of schools were assigned assessment dates clustered in time insofar as this was possible. "}, {"section_title": "Mapping Schools", "text": "In a second step a geographic map of participating grade 4 and grade 8 schools was developed based on the addresses of the schools. The map allowed the ready identification of obvious clusters of schools in large metropolitan areas and also allowed for identification of less concentrated clusters in broader geographical areas as well as isolated schools. To establish optimal work areas for assessment administrators, geographic clusters of schools were defined in an iterative process that took into account the location of field staff and their caseload. A total of 134 work areas of varying size were identified in this way."}, {"section_title": "Assigning Tentative Assessment Dates", "text": "The provisional assessment dates were then mapped to the schools in each cluster and represented in a spreadsheet. Within clusters, assessment dates were balanced against the location of schools in relation to one another. With some minor modifications to work areas, schools in relatively close proximity were assigned to provisional assessment weeks. This process identified smaller clusters of schools that could be assessed within a week without undue travel and related expenses. For the most part, assessments were scheduled on Tuesday through Thursday, leaving Monday and Friday as travel days. "}, {"section_title": "Negotiating Final Assessment Dates", "text": ""}, {"section_title": "Troubleshooting", "text": "Fifteen of the test administrators and 42 assistant administrators were recruited as regional troubleshooters who would be available to cover last-minute changes in assessment dates, staff illnesses, and the like. Each of these staff also had their own assignments, essentially schools that did not easily fit into an identified work area or assessment date window."}, {"section_title": "The Assessment and Related Activities", "text": "Field staff engaged in a number of activities in advance of the actual assessment. These included \uf06e working with the school coordinator to gain the permission of parents and students, if this was required by the school; \uf06e making arrangements with the school for the assessment sessions; and \uf06e obtaining the materials to be used in the assessment.  Passive consent. The school was required to ask parents for permission for the child to participate but permission would be assumed unless there was a formal objection; and \uf06e Active consent. The school was required to ask parents for permission for the child to participate and the child could not participate until the parents provided formal approval."}, {"section_title": "Recruiting Parents and Students", "text": "A majority of schools (956) opted for parent notification. Nearly 400 schools used passive consent and a further 50 used active consent. To assist schools in this task the school coordinator was provided with three draft letters to parents, one for each of the three forms of parent permission. These letters could be edited as appropriate and sent out on school stationery. Consent forms to accompany the passive and active consent letters were also provided along with an information sheet describing TIMSS. English and Spanish versions of each of these documents were made available to the schools. Copies of these materials as they apply to fourthgrade students and eighth-grade students are provided as exhibits C-6 through C-8 in appendix C. The eighth-grade materials were essentially the same. On assessment day each test administrator, accompanied by an assistant administrator, arrived at the school with all of the materials needed for the assessment. One session box of materials was provided for each of the sampled classes. Each session box contained the estimated number of student assessment booklets required, plus three unassigned booklets to accommodate any changes in class enrollments."}, {"section_title": "Organizing the Assessment Session at the School", "text": "Upon arrival, the test administrator met with the school coordinator to make any updates to the Student Tracking Form that would affect the preparation of student materials (for example, the addition of new students, the withdrawal of listed students from the school or class, or a change in exclusion status of a sampled student)."}, {"section_title": "Administering the Assessment", "text": "Assessments were administered by reading verbatim from a standardized script according to the instructions in the TIMSS & PIRLS Test Administrator Manual. A copy of each of the sessions scripts are provided in appendix E. The script began with a brief introduction to the study. The assessment booklets, each in a security envelope, then were distributed. The students were instructed to remove their booklet from the envelope, and the general instructions and instructions for Part 1 were read. Following this, the students were instructed to begin Part 1 of the assessment. After 36/45 minutes (grade 4/grade 8), a short break was provided. After the break, the instructions for Part 2 were read and students were instructed to begin Part 2 of the assessment. After the allotted 36/45 minutes for this part of the assessment, students were instructed to stop work, and a longer break was provided. Following the break, the student questionnaire was administered; it was not time-limited but was typically completed in about 30 minutes."}, {"section_title": "Postassessment Activities", "text": "Following the assessment, test administrators instructed the students remove an identifying label from the cover of the booklet, place the booklets in the security envelope, and seal it. The students handed their booklets to the administrator, received their gift, and were dismissed.  "}, {"section_title": "Receipt Control System Specification", "text": "Two systems were used to monitor the receipt and processing of materials after the assessments-the System was used to track the documents through every processing step, thus enabling project staff to easily locate materials for a particular school."}, {"section_title": "Booklet Accountability", "text": "Prior to the distribution of materials, all assessment instruments were organized into bundles and scanned to a file that was used to control distribution to field staff or a particular school. This assignment was recorded in the Materials Distribution System. When the return shipments were received, a manual count was made to ensure that all booklets from the original bundle were there. The assessment booklets were submitted for scanning and key entry, and unused booklets were batched and the booklet identification barcode scanned. This file and the processed documents file were compared to the original bundle security file created before distribution. A list of unmatched booklet identification numbers was printed in a report used to confirm any nonreceipt of individual booklets. After the batches of documents had successfully passed the coding and editing process, they were sent to the warehouse for storage. The storage locations of all documents were recorded on the inventory control system, which permits the rapid retrieval of any document, should it be necessary. Unused materials were U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide sent to temporary storage until the study was completed and the data files accepted by the Westat home office, at which time the extra inventory was destroyed."}, {"section_title": "Scoring the Assessment Items", "text": "The TIMSS and PIRLS assessment items included both multiple-choice and constructed-response items. Scoring rubrics developed internationally following the field tests of the assessment items were available to guide the scoring of each constructed-response item. In the United States, the scoring of the openended student responses according to these rubrics was the responsibility of Pearson."}, {"section_title": "Training", "text": "Two subject-specific scoring directors participated in the TIMSS training sessions sponsored by IEA, and an additional scoring director participated in the PIRLS training sessions. Materials from these sessions along with additional materials constructed specifically for this purpose were used to train team leaders and supervisors. There were 10 scoring supervisors for TIMSS. All were hired based on their experience with similar mathematics and science scoring projects. Pearson hired 78 scorers for TIMSS organized into 12 teams, with 6 to 8 scorers per team. For PIRLS, two scoring supervisors were hired along with 18 scorers organized into two teams of 9. Training activities for the scorers followed the same routine, with supervisors leading each small team reading the item prompt; reading the rubric or scoring guide aloud; reading aloud each of the anchor papers and explaining the reasoning behind the score; allowing the scorers time to complete the practice papers; reviewing each of the practice papers; and opening individual scoring on the electronic Performance Evaluation Network (ePEN). Training on and scoring of the items was completed one at a time, with the exception of the linked items, which were scored together."}, {"section_title": "Scoring", "text": "Each team worked on different items. Scorers were able to view only the one active item that they were assigned by their supervisors and were not able to score other items from any other team. The exception was with the linked items from the \"themed\" blocks. In this situation a question or questions required reference to a previous answer. For instance, question 4 in the block may have required data or the answer U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide from questions 1 and 2 in order to answer the question. In this situation, the ePEN setup was designed so that the scorer had access to screens with all of the pertinent responses, again only as assigned by the supervisor. The answers could not be submitted to ePEN until all questions from the set were scored to make sure that the scorer had all the needed information to score all related items. Scoring quality was monitored continuously. The ePEN system allowed inter-rater reliability reports to be run almost as soon as scoring began. Another monitoring method used was back-reading of already scored responses. This allowed the scoring supervisor to look at responses by category. The scoring supervisor also could review responses either by scorer or by score point agreements or splits. Scoring supervisors checked completion statistics as well."}, {"section_title": "Cross-Country Scoring Reliability Study", "text": "In international assessments, it is also important to gather information about how reliably the scoring was conducted from country to country so that valid international comparisons can be made of students' achievement. To document the reliability of constructed-response scoring across both TIMSS and PIRLS countries, a cross-country scoring reliability study was conducted. Responses to TIMSS and PIRLS items from Southern Hemisphere countries were sent to the Northern Hemisphere countries for scoring. After the scoring of the U.S. responses for an item with their team, two scorers then completed scoring of the international responses that were preloaded on desktop computers. After training and successfully scoring a portion of the 2011 responses, select scorers were asked to score all the responses for an item. While the individuals making up the pairs varied, no scorer worked on items that he or she had not been trained to score. A qualification set of 50 responses for each selected trend item for both TIMSS and PIRLS (or item part) was assigned to each scorer. After 25 responses were scored per item (item part), the trend reliability between the trend item was evaluated. The goal was to have between 85 percent to 100 percent agreement among scorers. If agreement for any item was below 85 percent for a particular scorer, retraining was required for the corresponding scorer and item. The scorer was then required to score the entire qualification set of 50 responses, rescoring the initial set of 25. If the scorer's agreement level reached 85 percent then the scorer began scoring 2011 student responses and the trend reliability set of responses."}, {"section_title": "Trend Scoring", "text": "A total number of responses (200) were divided equally by the number of scorers who were assigned to the item block. The main trend reliability scoring process took place in parallel with the main study scoring for TIMSS and PIRLS 2011."}, {"section_title": "Scanning the Student Questionnaire Responses", "text": "Responses to the TIMSS and PIRLS student questionnaire items were scanned with optical-scanning equipment that also captured images of the constructed-response items and intelligent character recognition (ICR) fields. The data values captured from booklets and questionnaires were coded as numeric data. Unmarked fields were coded as blanks and the editing staff was alerted to missing or encoded critical data. The images of constructed-response items were saved as a digitized computer file. In addition to capturing the student responses, the barcode identification numbers used to maintain process control were decoded and transcribed to the TIMSS and PIRLS computerized data file. ICR was used to read various hand and machine printing on the assessment booklets and student questionnaires. Image clips of the fields on the booklet covers were displayed to online editing staff for verification. Image clips were also taken for the open-ended items to be used for scoring."}, {"section_title": "Key-Entry of Teacher and School Questionnaire Responses", "text": "For school and teacher questionnaires received as hard copy, the questionnaire data were entered directly into the online questionnaire for that school or teacher."}, {"section_title": "Data Validation", "text": "Student booklets. Each data set produced by the scanning system was validated for type and range of response. The data-entry and resolution system used was able to simultaneously process a variety of materials from all age groups, subject areas, and assessment booklets as the materials were submitted to the system from scannable media. The data records in the scan file were organized in the same order in which the paper materials were processed by the scanner. As the program processed each record within a batch from the scan file, it wrote the edited and reformatted data records to the pre-edit file and recorded all errors on the edit file. The program generated an online edit file of the data problems and resolution guidelines. Image clips requiring edits were routed to online editing stations for the imaged scanned documents. All data values that were out of range were read \"as is\" but were flagged as suspect. All data fields that were read as asterisks (*) were recorded on the online edit file. Since the asterisk code indicated a doubleresponse, these items were identified for possible resolution by editing staff. Each field was validated for range response and any values outside of the specified range. Corrections were made immediately. The system employed an edit/verify system, which meant two different people viewed the same suspect data and operated on it separately. The verifier made sure the two responses (one from either the entry operator or the ICR engine) were the same before the system accepted the item as being correct. If it could not be determined, it was escalated to a supervisor. When the edit process produced an error-free file, the booklet ID number was posted to the TIMSS and PIRLS tracking file by grade and school. This permitted staff to monitor the TIMSS and PIRLS processing effort by accurately measuring the number of documents processed. The posting of booklet IDs also ensured that a booklet ID was not processed more than once."}, {"section_title": "File Creation and Consistency Checks", "text": "In a final step the data from the assessment score files were merged with the student scanned data. At this time, final output files were produced for each file type. The final files were checked to ensure the data were in the correct format. In earlier editing functions, data were checked for completeness and compliance with codebook specifications. In addition, a check was performed to verify correct linking and matching of student, teacher, and school data files. Student and teacher files were loaded in the WinDem software such that all data from the assessments and questionnaires were available in the format required by IEA."}, {"section_title": "Data Preparation", "text": "As noted in the previous section, the data collected for TIMSS and PIRLS 2011 were entered into data files according to a common international format, as specified in the WinDEM data entry software. The software facilitated the checking and correction of data by providing various data consistency checks The data files in this format were sent to the IEA Data Processing Center (DPC), where they were subjected to an extensive series of data cleaning and consistency checks. The overriding concern of these checks was to ensure that all information in the database conformed to the internationally defined data structure, national adaptations to questionnaires were reflected appropriately in the codebooks and documentation, and all variables used for international comparisons were comparable across countries."}, {"section_title": "International Data Cleaning Procedures", "text": "The DPC was responsible for checking the data files from each country, applying standard cleaning rules to verify the accuracy and consistency of the data, and documenting electronically any deviations from the international file structure. Queries arising during this process were addressed to national centers, and this process was repeated as necessary to ensure the data were consistent and comparable within and between countries. Following this cleaning step, countries were provided national univariate and reliability statistics along with data almanacs containing international univariate statistics and item statistics. This allowed countries to examine their data with those of other participating nations. Once any problems arising from this U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide examination were resolved, sampling weights produced by Statistics Canada and IRT-scaled student proficiency scores in mathematics and science were added to the file. Detailed information on the entire data entry and cleaning process can be found in Martin and Mullis (2011). All students, teachers, and schools participating in TIMSS and PIRLS 2011 do so with the assurance that their identities will not be disclosed. Confidentiality procedures in place included the following: \uf06e All employees with access to the data signed affidavits of data confidentiality."}, {"section_title": "Data Confidentiality Safeguards", "text": ""}, {"section_title": "The Estimation of TIMSS and PIRLS Student Proficiencies", "text": "All cycles of TIMSS and PIRLS used item response theory (IRT) methods to produce score scales that summarized the achievement results. With this method, the performance of a sample of students in a subject area or sub-area could be summarized on a single scale or a series of scales, even when different students had been administered different items. IRT scaling provides estimates of item parameters (for example, item difficulty and item discrimination) that define the relationship between the item and the underlying variable measured by the test. Parameters of the IRT model are estimated for each test item, with an overall scale being established as well as scales for each content area and cognitive domain specified in the assessment framework. To allow for the calculation of trends in achievement, comparisons of scores across the five TIMSS assessments conducted in 1995, 1999, 2003, 2007, and "}, {"section_title": "Plausible Values", "text": "During the scaling phase, plausible values were used to characterize scale scores for students participating in the assessment. To keep student burden to a minimum while ensuring content coverage, TIMSS and PIRLS administered a limited number of assessment items to each student-too few to produce accurate scale scores for each student. To account for this, TIMSS and PIRLS generated five possible scale scores for each student, each representing a random selection from the distribution of scale scores of students with similar backgrounds who answered the assessment items the same way. This approach to the estimation of scale scores ensures that the estimates of the average performance of student populations and the estimates of variability in those estimates are more accurate than those determined through traditional procedures, which estimate a single score for each student. An accessible treatment of the derivation and use of plausible values can be found in Beaton and Gonz\u00e1lez (1995). A more technical treatment can be found in Methods and Procedures in TIMSS and PIRLS 2011 (Martin & Mullis, 2011).\nAs noted earlier, the assessment design was based on Balanced Incomplete Block (BIB) spiraling of assessment items to increase content-area coverage without a concomitant increase in the assessment time demanded of students. Each student completed only a subset of the total pool of assessment items, with the resulting data containing missing values for other items in the pool but not in the subset administered to the student. The trade-off for increased coverage through BIB spiraling is increased measurement error in the scores available for each student. This is accommodated through the estimation of (five) plausible values for each student rather than a single (unreliable) point estimate.  (Foy, Arora, & Stanco, 2013;Foy & Drucker, 2013). See also work by Stapleton (2006Stapleton ( , 2008, which suggests procedures that can be used to generate appropriate standard errors for statistics generated by structural equation modeling techniques."}, {"section_title": "International Benchmarks", "text": "International achievement benchmarks were developed to provide a concrete interpretation of what the scores on the TIMSS mathematics and science achievement scales and on the PIRLS reading scales mean. "}, {"section_title": "The Estimation of Sampling Weights", "text": "Because of the complex sampling design used in TIMSS and PIRLS, students were assigned sampling weights. In general the sampling weight assigned to a student is the inverse of the probability that the student would be selected for the sample. When responses are weighted, each contributes to the results for the total number of students represented by the individual student assessed. Weighting also adjusts for school and student nonresponse. The internationally defined weighting specifications for TIMSS and PIRLS require that each assessed student's sampling weight should be the product of "}, {"section_title": "5.", "text": "\nIf student background variables also are needed, merge the student background data files with the merged student-teacher data files from the previous step using the variables IDCNTRY and IDSTUD. One further point to note: fourth-grade teachers were given a single questionnaire with mathematics and science sections or a reading section as pertinent to PIRLS. If a teacher taught only mathematics or only science to the TIMSS fourth-graders, that teacher would complete only one of these sections. In frequency distributions of the variables in these sections, teachers who did not answer the questions for this reason are shown as \"not administered.\""}, {"section_title": "The TIMSS and PIRLS 2011 Data for the United States and Benchmarking States", "text": "The TIMSS and PIRLS 2011 international databases contain student achievement data as well as student, teacher, school, and curricular background data for 54 countries and 11 other education systems for TIMSS, and 40 countries and 12 other education systems for PIRLS 2011. These databases provide comparable data across education systems on detailed measures of student achievement in mathematics and science for TIMSS participating education systems 16 detailed measures of achievement in reading for PIRLS participants; information on educational practices and student outcomes; links between student achievement and background information from students, teachers, school principals, and curriculum experts; and achievement scales on a metric that is common to all cycles of TIMSS and PIRLS respectively, allowing for the analysis of trends."}, {"section_title": "U.S. International, National, and State Benchmarking Data Files", "text": "The TIMSS and PIRLS 2011 national data for the United States exist in the following three forms: \uf06e U.S. international data files, which are part of the TIMSS and PIRLS international database and are directly comparable to that of other nations. As such these files allow for comparisons of the United States with any of the other education systems participating (except participating U.S. states) in TIMSS and/or PIRLS in virtually all respects. These files are available from the TIMSS and PIRLS International Study Center as SAS export files or SPSS \".sav\" files through http://timssandpirls.bc.edu/timss2011/international-database.html (TIMSS) or http://timssandpirls.bc.edu/pirls2011/international-database.html (PIRLS). Note that these data files do not include the U.S.-specific adaptations made to a few questions in the questionnaires or the additional questions added to the school and student questionnaires, such as the question on race/ethnicity added to the student questionnaire. Data for U.S. states are not included in the international data files due to potential confidentiality issues. \uf06e U.S. national public-use data files, which include the U.S.-specific adaptations that are not part of the U.S. international data files. These adaptations affect only a few variables and take the form of some elaboration of international response alternatives in a few items and the addition of questions to each of the questionnaires. These additional questions are described in section 5.9.2 of this report.  (Foy, Arora, & Stanco, 2013) and the PIRLS 2011 User Guide for the International Database (Foy & Drucker, 2013). These are the most comprehensive and detailed references for the TIMSS and PIRLS 2011 data and should be seen as the primary reference. \uf06e U.S. national restricted-use data files, which can only be obtained by completing a restricted-use license agreement with NCES. The restricted-use data files are provided only on CD. These datasets contain the supplemental link files that link TIMSS or PIRLS school ID numbers to the school ID numbers as they appear in the publicly available Common Core of Data (CCD) or the Private School Universe Survey (PSS). In addition, race/ethnicity is provided with all available categories and free or reduced price lunch is provided as a continuous variable. Because these data can reveal the identities of participating schools, the restricted-use data files are only made available to those who obtain a NCES restricted-use data license. Directions on how to obtain the license can be found at http://nces.ed.gov/pubsearch/licenses.asp. Data for the nine states that participated in TIMSS and/or PIRLS are provided in one format: \uf06e State restricted-use data files, which can only be obtained by completing a restricted-use license agreement with NCES. The restricted-use data files are provided only on CD. Like the U.S. national restricted-use data files, these datasets contain the supplemental link files that link TIMSS or PIRLS school ID numbers to the school ID numbers as they appear in the publicly available Common Core of Data (CCD) or the Private School Universe Survey (PSS). In addition, the state data files also contain the state-level data parallel to the U.S. national public-use files. Because these data can reveal the identities of participating schools, the restricted-use data files are only made available to those who obtain a NCES restricted-use data license. Directions on how to obtain the license can be found at http://nces.ed.gov/pubsearch/licenses.asp. The discussion that follows is designed to provide the following: "}, {"section_title": "TIMSS and PIRLS Data Files", "text": "The following five basic types of data files are available for each education system in both the TIMSS and PIRLS international datasets: \uf06e achievement files containing item response data and scale scores for the TIMSS or PIRLS assessment; \uf06e background files with information from students, from their mathematics and science teachers in TIMSS or their reading teachers in PIRLS, and from the principals of their schools; \uf06e student-teacher linkage files that contain the information needed to link data on students to that of their teachers; \uf06e constructed-response scoring reliability files providing data on the reliability of scoring for this type of item; and \uf06e curriculum data files that contain the responses of countries or participating education systems to the curriculum questionnaires. The following discussion focuses on the first three categories of files as these are the ones most likely to be used in data analyses by most users. For the remaining two categories of files, the reader is referred to the TIMSS 2011 User Guide for the International Database (Foy, Arora, & Stanco, 2013) or the PIRLS 2011 User Guide for the International Database (Foy & Drucker, 2013)."}, {"section_title": "Data File Naming Convention for TIMSS/PIRLS", "text": "The file names of the data files consist of an eight-character string followed by a three-character file extension using the conventions listed below. These conventions are illustrated by reference to the SPSS file containing the fourth-grade school background data for the United States (ACGUSAM5.sav) and govern both TIMSS and PIRLS data file nomenclature. The first character of the file name indicates grade level (ACGUSAM5).  "}, {"section_title": "TIMSS and PIRLS Achievement Data Files and Variable Names", "text": "The data files containing the IRT-scaled achievement scores for overall mathematics and science, the several mathematics and science content domains, and the three mathematics and science cognitive domains are identified by the first three characters in the file name. A set of five plausible values characterizes each of these achievement scores. Files beginning with ASA are fourth-grade achievement score files, and those beginning with BSA are eighth-grade achievement score files. For analytic convenience, these same achievement scores are also provided as an addition to the student background data files. The achievement score variable names are based on an eight-character string defined below. In exhibit 5-3 these conventions are illustrated by reference to the first plausible value for each of the total, content domain, and cognitive domain achievement scales at each grade level. For example, ASMMAT01 is the first plausible value for the fourth-grade mathematics total score. Again, ASSSCI02 is the second plausible value for the total science score, ASSEAR03 is the third plausible value for the content domain \"Earth science,\" and ASRLIT05 is the fifth plausible value for domain \"Reading for Literacy Experience .\""}, {"section_title": "First character of the variable name:", "text": "Exhibit 5-3 shows the nomenclature for identifying the various total, content domain, and cognitive domain achievement scale score variables, each of which is represented by five plausible values."}, {"section_title": "TIMSS and PIRLS Benchmark Achievement Variables", "text": "The TIMSS and PIRLS achievement files also contain a set of variables indicating which international benchmark the students reached. For TIMSS, the overall mathematics and science scales at both grades have five plausible values for each of the four benchmark levels defined ( advanced, high, intermediate, low). For PIRLS, a similar set of plausible values is provided for the overall reading scale. The international benchmark variables follow the achievement score variable naming convention but substitute the letters \"IBM\" in the fourth through sixth positions of the variable name. Thus, ASMIBM01, ASMIBM02, ASMIBM03, ASMIBM04, and ASMIBM05 are the five benchmark variables describing the fourth-grade overall mathematics score. Similarly, BSMIBM01 through BSMIBM05 describe the eighth-grade overall mathematics score and BSSIBM01 through BSSIBM05 describe the eighth-grade overall science score. Details for TIMSS are provided in Foy, Arora and Stanco (2013, pp. 86-87) and for PIRLS in Foy and Drucker (2013, pp. 86-87). "}, {"section_title": "TIMSS and PIRLS Background Questionnaire Data Files", "text": "Student, teacher, and school files contain the responses to the questions contained in the respective background questionnaires administered in TIMSS 2011 or PIRLS 2011, along with a fourth file used to link the student and teacher background data appropriately when student and teacher files are merged."}, {"section_title": "TIMSS and PIRLS Student Background Data Files (ASG/BSG)", "text": "The student background data files contain students' responses to questions in the student questionnaire along with students' mathematics and science achievement scores (as plausible values). At the fourth grade, there was a single version of the student questionnaire for TIMSS and PIRLS. However, internationally there were two versions of the student questionnaire at the eighth grade: a version for education systems in which science is taught as an integrated subject (general science version), and another version for education systems in which the sciences (biology or life science, physics, chemistry, and Earth science) are taught separately. For eighth-grade students who were administered the general science version, as was the case for the United States and benchmarking U.S. states, questions that appeared only in the separate science version were coded as \"not administered.\" For students in those education systems assigned the separate science versions, questions asked only in the general science version were coded as \"not administered.\" The student background data files also contain a number of identification variables, tracking variables, sampling and weighting variables, and derived variables that were used to produce some of the exhibits in the international reports."}, {"section_title": "TIMSS and PIRLS Teacher Background Data Files (ATG/BTM/BTS)", "text": "The mathematics and science teachers of the students sampled for TIMSS 2011 were administered at least one questionnaire for each TIMSS class taught. The teacher background data files contain one record for each of the classes taught. If teachers taught more than one class, they were expected to complete only one set of general background questions (part A), irrespective of the number of classes taught, and a separate part B (class-specific questions) for each class they taught. Teachers of PIRLS classes were administered a single teacher background questionnaire that had questions about their background and their teaching practices in the classes of sampled students. Each"}, {"section_title": "TIMSS and PIRLS School Background Data Files (ACG/BCG)", "text": "The school background data files contain the responses of school principals to questions about school policy, resources, and environment asked in the school questionnaire. That file also contains a series of identification variables, link variables, and sampling variables. The school data files can be merged with the student data files by using the education system and school identification variables. Details of the merging procedure using the SPSS-linked IEA International Database (IDB) Analyzer or using SAS programs for TIMSS are described in the TIMSS 2011 User Guide for the International Database (Foy, Arora, & Stanco, 2013) and for PIRLS these details are provided in the PIRLS 2011 User Guide for the International Database (Foy & Drucker, 2013)."}, {"section_title": "TIMSS and PIRLS Student-Teacher Linkage Data Files (AST/BST)", "text": "The TIMSS and PIRLS 2011 student-teacher linkage data files contain information required to link the student and teacher data files. These files contain one entry per student-teacher linkage combination in the data. For instance, if three teachers are linked to a student, there are three entries in the file corresponding to that student. The sole purpose of the student-teacher linkage data files is to link teacher-level data with student-level data to perform appropriate student-level analyses where teacher characteristics are disaggregated over students."}, {"section_title": "TIMSS and PIRLS Curriculum Questionnaire Data Files", "text": "In addition to the background questionnaires, TIMSS and PIRLS also provides data on the curriculum of the participating education systems. For TIMSS there is a separate file for each grade, while for PIRLS there is a single file."}, {"section_title": "Variable Naming Convention for Background Variables", "text": "The background variable naming convention is based on a seven-or eight-character string defined below. These conventions are illustrated by reference to an item in the fourth-grade school questionnaire. This item asks principals to report the population size of the community in which the school is located. For PIRLS, the curriculum questionnaire uses a different variable naming convention. The first three characters are \"GEN\" for general questions, or \"REA\" for questions relating to reading instruction. The remaining characters are defined by the sequential location of the questions in the questionnaire (Foy & Drucker, 2013)."}, {"section_title": "Summary Indices and Derived Variables", "text": "The TIMSS and PIRLS questionnaires often devote several questions to a single construct. In these cases, responses to the individual items were combined to create a derived variable. A TIMSS or PIRLS index is a special type of derived variable that assigns students to one of three levels-high, medium, or low-on the basis of their responses to the component variables. These variables are described in detail in Supplement 3 of the PIRLS 2011 User Guide for the International Database (Foy & Drucker, 2013) and in Supplement 3 of the TIMSS 2011 User Guide for the International Database (Foy, Arora, & Stanco, 2013)."}, {"section_title": "Sampling and Weighting Variables", "text": "Several sampling and weighting variables are included in the TIMSS and PIRLS data files. They are listed and described below in conjunction with a discussion of how and when these weights are used. Because TIMSS and PIRLS use a complex sampling design, sampling weights need to be used to generate accurate population estimates. The sampling weights account for the sample design, any stratification or disproportional sampling of subgroups, and also include adjustments for nonresponse (see Joncas & Foy, 2012). As noted, the sample of students is not a simple random sample and, as a consequence, students in the sample do not have an equal probability of selection. Sampling weights adjust for this unequal probability and, in so doing, provide for statistical estimates reflective of the student population from which the sample was drawn. Sampling weights also include adjustments for school and student nonresponse. All TIMSS and PIRLS analyses require the application of sampling weights. Provisions for weighting data are a standard feature of virtually all software likely to be used in analyses. The sampling weights included in the TIMSS and PIRLS 2011 data files are described in exhibit 5-4. TOTWGT sums to the student population size in each education system and is appropriate for \"within-country\" 19 analyses and \"cross-country\" analyses where the analyses are conducted \"country-by-country\" and compared."}, {"section_title": "Structure and Design Variables in TIMSS and PIRLS 2011 Data Files", "text": "The TIMSS and PIRLS 2011 data files also contain unique numerical identification variables for each respondent along with sample design information."}, {"section_title": "Identification Variables", "text": "In all TIMSS and PIRLS data files, identification variables are included to label countries, students, teachers, or schools. These variables also are used to link cases between the different data file types. The identification variables are the same across PIRLS and TIMSS, have the prefix \"ID,\" and are described below. \uf06e IDCNTRY: a five-digit country identification code based on the ISO 3166 classification. \uf06e IDPOP: identifies the target grade; \"1\" for the fourth grade and \"2\" for the eighth grade. \uf06e IDGRADE: identifies the target grade of the participating students; \"4\" and \"8\" for most countries. \uf06e IDSCHOOL: a four-digit identification code that uniquely identifies the participating schools within each country but are not unique across countries. \uf06e IDCLASS: a six-digit identification code that uniquely identifies the sampled classrooms within a country. \uf06e IDSTUD: an eight-digit identification code that uniquely identifies each sampled student in a country. \uf06e IDBOOK: identifies the specific assessment booklet that was administered to each student. \uf06e IDSTRATE & IDSTRATI: identification variables generated by the school sampling process. IDSTRATE identifies the explicit strata and IDSTRATI the implicit strata from which the participating schools were sampled."}, {"section_title": "Tracking Variables", "text": "Information about students, teachers, and schools provided by the survey tracking forms described earlier is stored in the tracking variables. These variables have the prefix \"IT.\" All tracking variables are included in the student background data files. ITLANG is included in the student achievement and student background data files. "}, {"section_title": "TIMSS and PIRLS 2011 Codebook Files", "text": "All information related to the structure of the TIMSS and PIRLS 2011 data files, as well as the source, format, descriptive labels, and response option codes for all variables, is contained in codebook files. Each data file type in the database is accompanied by a codebook file, with the exception of the curriculum data files. These files are available from the TIMSS and PIRLS International Study Center website at http://timssandpirls.bc.edu/timss2011/international-database.html. "}, {"section_title": "The U.S. National and State Benchmarking Data Files", "text": ""}, {"section_title": "Background Questionnaire Items With U.S. Adaptations to Response Alternatives", "text": "As the description of U.S. national adaptations in appendix F makes clear, there were a number of relatively minor changes to the wording of the international item stems and response alternatives in the questionnaires. Most of these adaptations do not require comment, as they are identical in format between the international and U.S. versions of the questionnaires (for example, they contain simple wording changes). In some cases, however, the adaptations resulted in item response formats not immediately comparable between the international and national versions of the questionnaires. As indicated in appendix F, there are instances in which the international and U.S. versions of variables have different sets of response codes; \"highest level of formal education\" in the teacher questionnaire is one example. This means that, for these items, the data will not be identical in international and U.S. versions of the data files. Using the same example, \"highest level of formal education\" will have six response categories in the U.S. international file and seven categories in the U.S. national file. 20 However, as indicated in appendix F crosswalks between international and U.S. versions of these questions allow for the conversion of the U.S. response codes to the international format."}, {"section_title": "U.S.-Specific Variables", "text": "U.S.-specific items were added to the student, teacher, and school questionnaires. Six questions were added to the student questionnaires: 1. a two-part question designed to measure the student's race/ethnicity; 2. a question that asked for language other than English spoken at home; 3. a 3-part question asking about place of birth and parents place of birth; 4. a question about additional activities outside of school; 5. a question asking about number of days absent; and 6. a two-part question that asked students to indicate whether they had repeated a grade in elementary and/or middle/junior high school (grade 8 student questionnaire only). One question was added to the grade 8 teacher questionnaires that asked teachers to identify the title of the mathematics or science course being taught to the students being assessed. Three questions were added to the school questionnaire: 1. the percentage of students in the school eligible for free or reduced-price lunch; 2. the percentage of students in the school who are English language learners; and 3. a specification of the type of school."}, {"section_title": "Race/Ethnicity (TIMSS 4 & 8/PIRLS Student Questionnaire)", "text": "Students' race/ethnicity was obtained through student responses to a two-part question in the student questionnaire. Students were asked first whether they were Hispanic or Latino and then whether they were members of the following five racial groups: (1) American Indian or Alaska Native; (2) Asian; (3) Black or African American; (4) Native Hawaiian or other Pacific Islander; or (5) White. Multiple responses to the second of these questions were allowed. 21 A composite variable with six categories was constructed in which results are shown separately for (1) Hispanics of any race; (2) Blacks; (3) Whites; (4) Asians; and (5) Multiracial. The sixth category was labeled as \"Other\" and consisted of the small numbers of students indicating that they were American Indian, Alaska Native, Native Hawaiian, or other Pacific Islander. 22"}, {"section_title": "Language Other Than English Spoken at Home (TIMSS 4 & 8/PIRLS Student Questionnaire)", "text": "This item extended the international question about how often students spoke English at home to ask those who indicated that they did not always speak English if they spoke Spanish or another language. 23"}, {"section_title": "Repeating a Grade (TIMSS 8 Student Questionnaire)", "text": "Students were asked whether they had ever repeated a grade in either \"elementary school\" and/or \"middle or junior high school.\" The response alternatives were \"yes\" or \"no\" in each case."}, {"section_title": "Additional Outside Activities (TIMSS 4/PIRLS Student Questionnaire)", "text": "The measure of outside of school activities was collected using a prompt with 4 yes/no questions. The prompt states, \"The following questions ask about the activities you do outside of school. The yes/no questions were as follows: "}, {"section_title": "Country of Mother/Father/Student (TIMSS 4/PIRLS Student Questionnaire)", "text": "Grade 4 students, in both TIMSS and PIRLS, were asked about the location of their birth and about the location of their parents or legal guardians birth using three yes/no questions. These questions were as follows: A "}, {"section_title": "Poverty Level in Public Schools (Percentage of Students Eligible for Free or Reduced-Price Lunch) (TIMSS 4 & 8/PIRLS School Questionnaire)", "text": "The measure of poverty level in public schools was obtained from principals' responses to the school questionnaire. The question asked the principal to report, as of approximately October 2010, the percentage of students at the school eligible to receive free or reduced-price lunch through the National School Lunch Program. Responses were grouped into five categories: (1) less than 10 percent, (2) 10 to 24.9 percent, (3) 25 to 49.9 percent, (4) 50 to 74.9 percent, and (5) 75 percent or more. 24 Missing data on this variable were replaced with measures taken from the Common Core of Data. The effect of this replacement on the confidentiality of the data was examined as part of the confidentiality analyses described earlier."}, {"section_title": "Limited-English Proficient (LEP)/English Language Learners (ELL) (TIMSS 4 & 8/PIRLS School Questionnaire)", "text": "Principals were asked to report the percentage of such students and were provided with the following 8 response categories: 0 percent; 1-5 percent; 6-10 percent; 11-25 percent; 26-50 percent; 51-75 percent; 76-90 percent; and over 90 percent."}, {"section_title": "Type of School (TIMSS 4 & 8/PIRLS School Questionnaire)", "text": "Principals were asked to identify their schools using one of the following 10 response categories: (1) regular public school; (2) regular public school with magnet program; (3) magnet school or school with special program; (4) special education; (5) alternative curriculum; (6) vocational; (7) charter school; 8independent private school; (9) religiously affiliated private school; or (10) other school."}, {"section_title": "Missing Data", "text": "Data derived from the student, school and teacher questionnaires and from the student assessments contain missing data in varying amounts. Four sources of missing data are identified: 1. Not administered. The respondent was not administered the actual item. He or she had no chance to read and answer the question."}, {"section_title": "2.", "text": "Omitted. The respondent had a chance to answer the question but did not do so. This code also was used for responses that were not interpretable.\nRetrieve the relevant variables from the teacher background data files, including analysis variables, classification variables, identification variables (IDCNTRY, IDTEACH, and IDLINK), and any other variables used in the selection of cases."}, {"section_title": "Imputation", "text": "No imputation for missing values was undertaken. However, missing data on the measure of school poverty (proportion of students eligible for free or reduced-price lunch) reported by schools was replaced as described above."}, {"section_title": "Data Files Available From the Website of the National Center for Education Statistics", "text": "The data files containing the U.S. national data for TIMSS can be downloaded from the NCES website at http://nces.ed.gov/timss/datafiles.asp. The data files containing the U.S. national data for PIRLS can be downloaded from the NCES website at http://nces.ed.gov/surveys/pirls/datafiles.asp. These national files are in ASCII format and are named as indicated in exhibit 5-5. SAS and SPSS codes for reading these data files can also be downloaded from the NCES website. 25 Exhibit "}, {"section_title": "5.11", "text": ""}, {"section_title": "Merging TIMSS/PIRLS 2011 Data Files", "text": "In preparing TIMSS 2011 or PIRLS 2011 data for analysis it may be necessary to merge two (or more) of the data files named in exhibit 5-5. Not every analysis will require merging of files, however. For example, analyses looking at the relationship between student background and achievement can be done using the student background file alone. However, analyses that wish to examine the relationships between school and/or teacher and/or student characteristics and student achievement will require that files be merged. Standard merging procedures as implemented in SPSS, SAS or Stata can be applied. Examples are provided below along with illustrative SAS and SPSS code. (These various merges are facilitated for SPSS users who choose to work with the IEA International Database Analyzer [IEA IDB Analyzer] described below.) The merging procedures illustrated below follow the same pattern as previous TIMSS studies (see Foy et al., 2013) and are illustrated with TIMSS Grade 8 data. The user will need to replace file names in order to run the merges for TIMSS Grade 4 or PIRLS."}, {"section_title": "Merging Student and School Data", "text": "If the intent is to disaggregate school data across students the school-level data are merged to the student file using IDSCHOOL. The disaggregated data can be analyzed at the student level using the student-level weight TOTWGT. Exhibits 5-6 and 5-7 provide examples of how to merge the student and school data using SAS and SPSS. Additional examples are provided in chapters 2 and 3 in the TIMSS 2011 User Guide for the International Database (Foy et al., 2013; available at http://timssandpirls.bc.edu/timss2011/international-database.html) and PIRLS 2011 User Guide for the International Database (Foy et. al., 2013; available at http://timssandpirls.bc.edu/pirls2011/internationaldatabase.html)."}, {"section_title": "Merging TIMSS or PIRLS 2011 Data With Restricted-Use Data", "text": "Users who have been granted a license to use the restricted-use TIMSS or PIRLS 2011 data will receive a restricted-use CD-ROM which contains an additional link file that provides a way to merge TIMSS or PIRLS data with school data from the Common Core of Data (CCD) and the Private School Survey (PSS). The NCESSCH (the NCES unique public school identification code) from the TIMSS or PIRLS file is used to merge with NCESSCH from the CCD file. The PPIN (the private school's unique identification number) from the TIMSS or PIRLS file is used to merge with the PPIN from the PSS file. Illustrative SAS and SPSS code is provided in Exhibits 5-12 and 5-13. The code in question provides for a link between the TIMSS school data and the CCD/PSS data by school. Further merging to other TIMSS files (student, school, teacher) can be conducted using the IDSCHOOL for merging as has been shown in earlier examples."}, {"section_title": "Some Notes on Analyzing the TIMSS and PIRLS 2011 Data", "text": "The design of TIMSS and PIRLS raises three special considerations for the analysis of TIMSS and PIRLS data. First, the assessment design necessitates the use of five plausible values rather than a single score for each of the various measures of mathematics, science, and reading achievement. Second, since the sampling design is not a simple random sample in which each student had an equal probability of selection, sampling weights need to be applied to generate unbiased estimates of population parameters. Third, the complex sampling design also means that the calculation of the standard errors of the various statistics generated requires special procedures."}, {"section_title": "The IEA International Database (IDB) Analyzer and International Data Explorer (IDE)", "text": "As described in section 5.12.2, the IDB Analyzer was developed by the IEA Data Processing and Research Center (IEA DPC) as a plug-in for SPSS and can only be used in conjunction with SPSS. It is not a stand-alone analysis system. The IDB Analyzer enables users to combine SPSS data files and conduct analyses using SPSS without actually writing programming code. The IDB Analyzer generates SPSS syntax that takes into account information from the sampling design in the computation of statistics and their standard errors. In addition, the generated SPSS syntax makes appropriate use of plausible values for calculating estimates of achievement scores and their standard errors, combining both sampling variance and imputation variance. "}, {"section_title": "Special Considerations in Using the Teacher Data", "text": "The teachers in the TIMSS and PIRLS 2011 international databases are the teachers of nationally representative samples of students and are not representative samples of teachers in the participating countries. As a result, analyses with teacher data should be made with students as the units of analysis and reported in terms of students who are taught by teachers with a particular attribute. When analyzing teacher data, it is first necessary to link the students to their respective teachers. The student-teacher linkage data files (AST/BST) were created for this purpose. Since student achievement scores (plausible values), jackknife replication information, and teacher weighting variables are found in the student-teacher linkage data files, it is only necessary to merge the teacher background data files with the student-teacher linkage data files. For analyses linking teacher variables to student background U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide variables, it is also necessary to merge the student background data files with the teacher background data files after having been combined with the student-teacher linkage data files. In general, to perform analyses using the teacher background data files, follow the steps below."}, {"section_title": "1.", "text": "Identify the variables of interest in the teacher background data files and note any specific national adaptations to the variables.\nIdentify the variables of interest in the school and student background data files and note any specific national adaptations to the variables. .9 NOTE: Detail may not sum to totals because of rounding. For public schools, \"high\" poverty is defined as having 50 percent or more of the students eligible for participation in the National School Lunch Program (NSLP), and \"low\" poverty is defined as having less than 50 percent eligible. Because no NSLP data were available for private schools, all private schools are categorized as \"low.\" For definitions of these urbancentric locales, see http://nces.ed.gov/surveys/urbaned/definitions.asp. Race/ethnicity status refers to the percentage of Black, Hispanic, Asian and Pacific Islander, and American Indian and Alaska Native students. Black includes African American and Hispanic includes Latino. Racial categories exclude Hispanic origin. Asian and Pacific Islander are combined into a single category due to the fact that that the frame was developed using the previous NCES guidelines for combining Asian and Pacific Islanders, while the U.S. national report was developed under new guidelines that call for reporting out Asian separately when possible. The measure of size is defined as the estimated number of students enrolled in the target grade with a minimum of 5 students per school. These differ slightly from the estimated student sample size reported in Joncas 2012 (Exhibit 1 and 2), which reports the estimate of the number of students in the sampled schools with no minimum per school. SOURCE: International Association for the Evaluation of Educational Achievement (IEA), Trends in International Mathematics and Science Study (TIMSS), Progress in International Reading Literacy Study (PIRLS), 2011."}, {"section_title": "Special Considerations in Using the School Data", "text": "In general, to perform analyses using the school background data files, follow the steps below."}, {"section_title": "Exclusions in the Alabama TIMSS grade 8 sample", "text": "The Alabama TIMSS eighth grade sample had a (weighted) student exclusion rate of 4.6 percent based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (95.4 percent) as acceptable."}, {"section_title": "Exclusions in the California TIMSS grade 8 sample", "text": "The California TIMSS eighth grade sample had a (weighted) student exclusion rate of 5.6 percent based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (94.4 percent) as acceptable though falling below the desired range of 95 percent or better. The tabulations shown in the international reports show California annotated to indicate this fact."}, {"section_title": "Exclusions in the Colorado TIMSS grade 8 sample", "text": "The Colorado TIMSS eighth grade sample had a (weighted) student exclusion rate of 4.1 percent based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (95.9 percent) as acceptable."}, {"section_title": "Exclusions in the Connecticut TIMSS grade 8 sample", "text": "The Connecticut TIMSS eighth grade sample had a (weighted) student exclusion rate of 8.5 percent based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (91.5 percent) as acceptable though falling below the desired range of 95 percent or better. The tabulations shown in the international reports show Connecticut annotated to indicate this fact."}, {"section_title": "Exclusions in the Florida TIMSS and PIRLS grade 4 samples and TIMSS grade 8 sample", "text": "Florida had a (weighted) student exclusion rate of 12.1 percent in the fourth-grade for TIMSS, 12.9 percent for PIRLS, and 6.9 percent for TIMSS in the eighth-grade, based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (87.9 percent for both TIMSS, 87.1 percent for PIRLS at fourth grade and 93.1 percent for eighth grade) as acceptable though falling below the desired range of 95 percent or better. The tabulations shown in the international reports show the Florida annotated to indicate this fact."}, {"section_title": "Exclusions in the Indiana TIMSS grade 8 sample", "text": "The Indiana TIMSS eighth grade sample had a (weighted) student exclusion rate of 6.3 percent based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (93.7 percent) as acceptable though falling below the desired range of 95 percent or better. The tabulations shown in the international reports show Indiana annotated to indicate this fact."}, {"section_title": "Exclusions in the Massachusetts TIMSS grade 8 sample", "text": "The Massachusetts TIMSS eighth grade sample had a (weighted) student exclusion rate of 7.9 percent based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (92.1 percent) as acceptable though falling below the desired range of 95 percent or better. The tabulations shown in the international reports show Massachusetts annotated to indicate this fact."}, {"section_title": "Exclusions in the Minnesota TIMSS grade 8 sample", "text": "The Minnesota TIMSS eighth grade sample had a (weighted) student exclusion rate of 4.3 percent based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (95.7 percent) as acceptable."}, {"section_title": "Exclusions in the North Carolina TIMSS grades 4 and 8 samples", "text": "North Carolina had a (weighted) student exclusion rate of 10.1 percent in the fourth-grade for TIMSS and 11.4 percent for TIMSS in the eighth-grade, based on the combination of whole-class and within-class exclusions. IEA standards define this degree of coverage of the national target population (89.9 percent for both TIMSS at fourth grade and 88.6 percent for eighth-grade) as acceptable though falling below the desired range of 95 percent or better. The tabulations shown in the international reports show North Carolina annotated to indicate this fact. The United States will be participating in two important international studies in 2011 to help benchmark student performance in the United States compared to that in other countries around the world. Some schools in your state have been randomly selected to participate in these studies in the spring of 2011. I am writing to ask your agency to support the participation of schools in your state in these two studies: the Trends in International Mathematics and Science Study (TIMSS) 2011 and the Progress in International Reading Literacy Study (PIRLS) 2011. TIMSS is administered every four years in more than 60 countries and provides important information for internationally benchmarking U.S. performance in mathematics and science at the fourth-and eighth-grade levels against top countries around the world. PIRLS is administered every five years in more than 50 countries and provides similarly important international benchmarking information in fourth-grade reading. TIMSS, PIRLS, and the process for participating schools are described in more detail in materials enclosed with this letter. The studies are sponsored in the United States by the National Center for Education Statistics in the U.S. Department of Education and are conducted by Westat of Rockville, MD. The U.S. Office of Management and Budget has approved the data collection under OMB # 1850-0645 v5. While participation in this study is entirely voluntary, we ask your agency to support participation on the part of schools in your state so that the United States has a representative sample of schools across the country. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section153). By law, the data provided by your schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Reports of the findings from the assessments will not identify participating districts, schools, students, or individual staff. Individual responses will be combined with those from other participants to produce summary statistics and reports. Within the next few weeks, a representative of Westat will contact sampled school districts and schools to discuss conducting data collection. In the meantime, if you have questions about the study, please do not hesitate to call [insert name of contact] at 1-888-369-5033 or send an email to TIMSS-PIRLS@westat.com. You may also get more information about these studies by contacting Dr. Patrick Gonzales at NCES at (415) 920-9229 or visiting the TIMSS and PIRLS websites at: http://nces.ed.gov/timss/ http://nces.ed.gov/surveys/pirls/. Thank you for your time and support. TIMSS and PIRLS are important elements in the U.S. effort to benchmark the performance and progress of our education system against international standards. The United States will be participating in two important international studies in 2011 to help benchmark student performance in the United States against that in other countries around the world: the Trends in International Mathematics and Science Study (TIMSS) 2011 and the Progress in International Reading Literacy Study (PIRLS) 2011. We are contacting you because one or more schools in your diocese have been randomly selected to represent the United States in these studies in the spring of 2011. TIMSS is administered every four years in more than 60 countries and provides important information for internationally benchmarking U.S. performance in mathematics and science at the fourth-and eighthgrade against top countries around the world. PIRLS is administered every five years in more than 50 countries and provides similarly important international benchmarking information in fourth-grade reading. We ask your agency to support the participation of schools in your diocese in the TIMSS and PIRLS studies as these assessments are vital in understanding how the knowledge and skills of U.S. students compare with those of their peers in other countries. Schools that participate in the TIMSS and PIRLS studies will be partially compensated for their time and efforts: participating schools will receive $200, their school-level coordinator will receive $100, and each student that takes the assessment will receive a small gift. Materials enclosed with this letter describe TIMSS and PIRLS and the process for participating schools in more detail. Both assessments are sponsored by the U.S. Department of Education's National Center for Education Statistics and are conducted by Westat, a research organization based in the Washington D.C. area. The U.S. Office of Management and Budget has approved this data collection under OMB #1850-0645 v5. While participation in this study is entirely voluntary, we ask your agency to support the participation of schools in your diocese that the United States has a representative sample of schools across the country. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by your schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). We will disclose the names of schools in each district only to the governing district for each school, and we ask that each district maintain the confidentiality of the sampled schools in the TIMSS and PIRLS studies. Reports of the findings from these assessments will not identify participating districts, schools, students, or individual staff. Individual responses will be combined with those from other participants to produce summary statistics and reports."}, {"section_title": "U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide C-3", "text": "If you have any questions, please do not hesitate to call the TIMSS and PIRLS Home Office at 1-888-369-5033 or send an email to TIMSS-PIRLS@westat.com. You may also get more information about these studies by contacting Dr. Patrick Gonzales at NCES at (415) 920-9229 or visiting the TIMSS and PIRLS websites at: http://nces.ed.gov/timss/ and http://nces.ed.gov/surveys/pirls/. Thank you for your time and support. TIMSS and PIRLS are important elements in the U.S. effort to benchmark the performance and progress of our education system against international standards. TIMSS provides important international benchmarking information in fourth-and eighth-grade mathematics and science. We are notifying you now because one or more schools in your district have been randomly selected to take part in the TIMSS study in the spring of 2011. We ask your agency to support the participation of schools in your district in the TIMSS assessment as it is vital to understanding how the knowledge and skills of U.S. students compare to those of their peers in other countries. Schools that participate in TIMSS will be compensated for their time and efforts. Participating schools will receive $200, their school-level coordinator will receive $100, and each student that takes the assessment will receive a small gift. Materials enclosed with this letter describe TIMSS and the process for participating schools in more detail. TIMSS is sponsored by the U.S. Department of Education's National Center for Education Statistics and is conducted by Westat, a research organization based in the Washington D.C. area. The U.S. Office of Management and Budget has approved the data collection under OMB #1850-0645 v5. While participation in this study is entirely voluntary, we ask your agency to support the participation of schools in your district so that the United States has a representative sample of schools across the country. Within the next few days, a representative of Westat will contact the following school or schools in your district that have been selected for the assessment: [LIST SAMPLED SCHOOLS HERE\u2026] NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by your schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). We will disclose the names of schools in each district only to the governing district for each school, and we ask that each district maintain the confidentiality of the sampled schools in the TIMSS study. Reports of the findings from the assessment will not identify participating districts, schools, students, or individual staff. Individual responses will be combined with those from other participants to produce summary statistics and reports. If you have any questions, please do not hesitate to call the TIMSS Home Office at 1-888-369-5033 or send an email to TIMSS-PIRLS@westat.com. You may also get more information about these studies by contacting Dr. Patrick Gonzales at NCES at (415) 920-9229 or visiting the TIMSS website at: http://nces.ed.gov/timss/. Thank you for your time and support. TIMSS is an important element in the U.S. effort to benchmark the performance and progress of our education system against international standards. The United States will be participating in two important international studies in 2011 to help benchmark student performance in the United States against that in other countries around the world: the Trends in International Mathematics and Science Study (TIMSS) 2011 and the Progress in International Reading Literacy Study (PIRLS) 2011. We are contacting you because your school has been selected to represent the United States in the TIMSS and PIRLS international studies in the spring of 2011. TIMSS is administered every four years in more than 60 countries and provides important information for internationally benchmarking U.S. performance in mathematics and science at the fourth-and eighthgrade levels against top countries around the world. PIRLS is administered every five years in more than 50 countries and provides similarly important international benchmarking information in fourth-grade reading. I encourage your school's participation in the TIMSS and PIRLS assessments as they are vital to understanding how the knowledge and skills of U.S. students compare with those of their peers in other countries. Schools that participate in the TIMSS and PIRLS studies will be compensated in part for their time and efforts: participating schools will receive $200, their school-level coordinator will receive $100, and each student that takes the assessment will receive a small gift. Materials enclosed with this letter describe TIMSS and PIRLS and the process for participating schools in more detail. Both assessments are sponsored in the United States by the U.S. Department of Education's National Center for Education Statistics and are conducted by Westat of Rockville, MD. The U.S. Office of Management and Budget has approved the data collection under OMB #1850-0645 v5. We hope you will participate in this study so that the United States has a representative sample of schools across the country; however, participation in this study is entirely voluntary. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by your schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). We will only disclose the names of schools in each district to the governing district for each school, and we have asked that each district maintain the confidentiality of the sampled schools in the TIMSS and PIRLS study. Reports of the findings from these assessments will not identify participating districts, schools, students, or individual staff. Individual responses will be combined with those from other participants to produce summary statistics and reports. Within the next few days, a representative of Westat will call you to discuss your participation in the assessment. In the meantime, if you have any questions about the TIMSS and PIRLS study or your school's participation, please feel free to call 1-888-369-5033 or send an email to TIMSS-PIRLS@westat.com. You may also get more information about these studies by contacting Dr. Patrick Gonzales at NCES at (415) 920-9229 or visiting the TIMSS and PIRLS websites at: http://nces.ed.gov/timss/ and http://nces.ed.gov/surveys/pirls/."}, {"section_title": "U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide C-7", "text": "Thank you for your time and support. TIMSS and PIRLS are important elements in the U.S. effort to benchmark the performance and progress of our education system against international standards. I am writing to inform you about the upcoming Trends in International Mathematics and Science Study (TIMSS) 2011, in which the United States will participate along with more than 60 other countries. TIMSS provides important international benchmarking information in fourth-and eighth-grade mathematics and science. We are notifying you now because your school has been randomly selected to take part in the TIMSS study in the spring of 2011. I encourage your school's participation in the TIMSS assessment as it is vital in understanding how the knowledge and skills of U.S. students compare with those of their peers in other countries. Schools that participate in TIMSS will be compensated in part for their time and efforts: participating schools will receive $200, their school-level coordinator will receive $100, and each student that takes the assessment will receive a small gift Materials enclosed with this letter describe TIMSS and the process for participating schools in more detail. Both assessments are sponsored in the United States by the U.S. Department of Education's National Center for Education Statistics and are conducted by Westat of Rockville, MD. The U.S. Office of Management and Budget has approved the data collection under OMB # 1850-0645 v5. We hope you will participate in this study so that the United States has a representative sample of schools across the country; however, participation in this study is entirely voluntary. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by your schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). We will only disclose the names of schools in each district to the governing district for each school, and we have asked that each district maintain the confidentiality of the sampled schools in the TIMSS study. Reports of the findings from the assessment will not identify participating districts, schools, students, or individual staff. Individual responses will be combined with those from other participants to produce summary statistics and reports. Within the next few days, a representative of Westat will call you to discuss your participation in TIMSS. In the meantime, if you have any questions about the TIMSS or your school's participation, please feel free to call 1-888-369-5033 or send an email to TIMSS-PIRLS@westat.com. You may also get more information about these studies by contacting Dr. Patrick Gonzales at NCES at (415) 920-9229 or visiting the TIMSS website at: http://nces.ed.gov/timss/. Thank you for your time and support. TIMSS is an element in the U.S. effort to benchmark the performance and progress of our education system against international standards. Our school has accepted an invitation from the National Center for Education Statistics (NCES), U.S. Department of Education, to participate in an important international study of student learning. This study is called TIMSS for short; the full name is the Trends in International Mathematics and Science Study. TIMSS looks at student mathematics and science achievement in schools around the world and documents worldwide trends in student knowledge of mathematics and science since 1995. The enclosed summary sheet provides some background to TIMSS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. {Insert number} of our 4th -grade classes will take part. {This/One of these} is your child's class. {This class/These two classes}, along with some {500} other classes of 4th graders nationwide, will contribute to this picture of what U.S. 4th graders know about mathematics and science, and how they compare with 4th graders worldwide. To have an accurate picture of what U.S. 4th graders can do, it is important that each student selected take part in the study. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is kept completely confidential, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Thank you for taking the time to think about this. We wish you all the best. Nuestra escuela ha aceptado una invitaci\u00f3n del Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s) del Departamento de Educaci\u00f3n de Estados Unidos para participar en un importante estudio internacional sobre el aprendizaje estudiantil. El nombre corto de este estudio es TIMSS; abreviaci\u00f3n de Estudio Internacional Sobre las Tendencias en Matem\u00e1ticas y Ciencias. Desde 1995 TIMSS ha observado los logros de los estudiantes en matem\u00e1ticas y ciencias en las escuelas del mundo y ha documentado las tendencias mundiales en el conocimiento estudiantil de matem\u00e1ticas y ciencias. El resumen adjunto ofrece informaci\u00f3n de trasfondo de TIMSS, explica lo que implica la participaci\u00f3n en el estudio para cada estudiante seleccionado e incluye un n\u00famero de tel\u00e9fono y un correo electr\u00f3nico de contacto donde usted podr\u00e1 encontrar respuestas a cualquier pregunta que tenga. {Insert number} de nuestras clases de cuarto grado participar\u00e1n. {Esta/Una de estas} es la clase de su hijo. {Esta clase/Estas dos clases}, junto con otras {500} clases de estudiantes de cuarto grado en todo el pa\u00eds, contribuir\u00e1n a mostrar lo que saben los estudiantes de cuarto grado en Estados Unidos sobre matem\u00e1ticas y ciencias, y c\u00f3mo se comparan con estudiantes de cuarto grado alrededor del mundo. Para tener una imagen precisa de lo que los estudiantes de cuarto grado en Estados Unidos pueden hacer, es importante que cada estudiante seleccionado participe en el estudio. Lo invito a que apoye este esfuerzo animando a su hijo a participar; sin embargo, la participaci\u00f3n en este estudio es completamente voluntaria. Las experiencias anteriores parecen indicar que los estudiantes disfrutan de su participaci\u00f3n. Adem\u00e1s, los estudiantes que participen recibir\u00e1n un peque\u00f1o regalo que creemos les gustar\u00e1. Toda la informaci\u00f3n que se re\u00fana es completamente confidencial, como lo exige la ley. NCES est\u00e1 autorizado a realizar este estudio de acuerdo con la Ley de reforma de ciencias de la educaci\u00f3n de 2002 (Ley p\u00fablica 107-279, secci\u00f3n 153). Por ley, la informaci\u00f3n dada por las escuelas, empleados y estudiantes solamente se puede utilizar con fines estad\u00edsticos y no se puede dar a conocer ni utilizar de una manera que permita la identificaci\u00f3n de personas para otros fines (Ley p\u00fablica 107-279, secci\u00f3n 183 y t\u00edtulo V, subt\u00edtulo A de la Ley de gobierno electr\u00f3nico de 2002 (Ley p\u00fablica 107-347)). En los informes nunca se identifica ni a los estudiantes ni a las escuelas. Todas las estad\u00edsticas publicadas se refieren a Estados Unidos en conjunto. Gracias por tomarse el tiempo de considerar este estudio. Reciba nuestros mejores deseos. Our school has accepted an invitation from the National Center for Education Statistics (NCES), U.S. Department of Education, to participate in an important international study of student learning. This study is called TIMSS for short; the full name is the Trends in International Mathematics and Science Study. TIMSS looks at student mathematics and science achievement in schools around the world and documents worldwide trends in student knowledge of mathematics and science since 1995. The enclosed summary sheet provides some background to TIMSS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. {Insert number} of our 4th-grade classes will take part. {This/One of these} is your child's class. {This class/These two classes}, along with some {500} other classes of 4th graders nationwide, will contribute to this picture of what U.S. 4th graders know about mathematics and science, and how they compare with 4th graders worldwide. To have an accurate picture of what U.S. 4th graders can do, it is important that each student selected take part in the study. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is kept completely confidential, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. If you have any objection to your child joining in the TIMSS activities please let us know by completing the attached form ('Being Part of TIMSS') and returning it to the school. Thank you for taking the time to think about this. We wish you all the best. "}, {"section_title": "Being Part of TIMSS", "text": "We would like very much to have your child take part in the TIMSS project along with his/her classmates. Student participation in TIMSS is critical to the success of the study and, ultimately, to the nation's interests in improving mathematics and science education. Your child will be included in TIMSS unless you indicate otherwise. If you do not want your child to participate, please check the \"No\" box below, sign the form and send it back to the school. The school will make arrangements for your child to undertake some other activities during the time that the other students are involved with TIMSS. No, I do not want my child to take part in the study. Child's Name: _____________________________________________________ Nuestra escuela ha aceptado una invitaci\u00f3n del Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s) del Departamento de Educaci\u00f3n de Estados Unidos para participar en un importante estudio internacional sobre el aprendizaje estudiantil. El nombre corto de este estudio es TIMSS; abreviaci\u00f3n de Estudio Internacional Sobre las Tendencias en Matem\u00e1ticas y Ciencias. Desde 1995 TIMSS ha observado los logros de los estudiantes en matem\u00e1ticas y ciencias en las escuelas del mundo y ha documentado las tendencias mundiales en el conocimiento estudiantil de matem\u00e1ticas y ciencias. El resumen adjunto ofrece informaci\u00f3n de trasfondo de TIMSS, explica lo que implica la participaci\u00f3n en el estudio para cada estudiante seleccionado e incluye un n\u00famero de tel\u00e9fono y un correo electr\u00f3nico de contacto donde usted podr\u00e1 encontrar respuestas a cualquier pregunta que tenga. {Insert number} de nuestras clases de cuarto grado participar\u00e1n. {Esta/Una de estas} es la clase de su hijo. {Esta clase/Estas dos clases}, junto con otras {500} clases de estudiantes de cuarto grado en todo el pa\u00eds, contribuir\u00e1n a mostrar lo que saben los estudiantes de cuarto grado en Estados Unidos sobre matem\u00e1ticas y ciencias, y c\u00f3mo se comparan con estudiantes de cuarto grado alrededor del mundo. Para tener una imagen precisa de lo que los estudiantes de cuarto grado en Estados Unidos pueden hacer, es importante que cada estudiante seleccionado participe en el estudio. Lo invito a que apoye este esfuerzo animando a su hijo a participar; sin embargo, la participaci\u00f3n en este estudio es completamente voluntaria. Las experiencias anteriores parecen indicar que los estudiantes disfrutan de su participaci\u00f3n. Adem\u00e1s, los estudiantes que participen recibir\u00e1n un peque\u00f1o regalo que creemos les gustar\u00e1. Toda la informaci\u00f3n que se re\u00fana es completamente confidencial, como lo exige la ley. NCES est\u00e1 autorizado a realizar este estudio de acuerdo con la Ley de reforma de ciencias de la educaci\u00f3n de 2002 (Ley p\u00fablica 107-279, secci\u00f3n 153). Por ley, la informaci\u00f3n dada por las escuelas, empleados y estudiantes solamente se puede utilizar con fines estad\u00edsticos y no se puede dar a conocer ni utilizar de una manera que permita la identificaci\u00f3n de personas para otros fines (Ley p\u00fablica 107-279, secci\u00f3n 183 y t\u00edtulo V, subt\u00edtulo A de la Ley de gobierno electr\u00f3nico de 2002 (Ley p\u00fablica 107-347)). En los informes nunca se identifica ni a los estudiantes ni a las escuelas. Todas las estad\u00edsticas publicadas se refieren a Estados Unidos en conjunto. Si tiene alguna objeci\u00f3n en que su hijo participe en las actividades de TIMSS, por favor h\u00e1ganoslo saber al completar el formulario adjunto ('Participaci\u00f3n en TIMSS') y enviarlo a la escuela lo antes posible. Gracias por tomarse el tiempo de considerar este estudio. Reciba nuestros mejores deseos. \nWe need your consent. We would like very much to have your child take part in the TIMSS project along with his/her classmates. Student participation in TIMSS is critical to the success of the study and, ultimately, to the nation's interests in improving mathematics and science education. Please check the \"Yes\" box below if you give your consent, or check the \"No\" box if you do not consent. If you do not want your child to participate, the school will make arrangements for your child to undertake some other activities during the time that the other students are involved with TIMSS. After making your selection, please sign the form and send it back to the school by {Insert date at least 2 days prior to assessment date}. Nuestra escuela ha aceptado una invitaci\u00f3n del Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s) del Departamento de Educaci\u00f3n de Estados Unidos para participar en un importante estudio internacional sobre el aprendizaje estudiantil. El nombre corto de este estudio es TIMSS; abreviaci\u00f3n de Estudio Internacional Sobre las Tendencias en Matem\u00e1ticas y Ciencias. Desde 1995 TIMSS ha observado los logros de los estudiantes en matem\u00e1ticas y ciencias en las escuelas del mundo y ha documentado las tendencias mundiales en el conocimiento estudiantil de matem\u00e1ticas y ciencias. El resumen adjunto ofrece informaci\u00f3n de trasfondo de TIMSS, explica lo que implica la participaci\u00f3n en el estudio para cada estudiante seleccionado e incluye un n\u00famero de tel\u00e9fono y un correo electr\u00f3nico de contacto donde usted podr\u00e1 encontrar respuestas a cualquier pregunta que tenga. {Insert number} de nuestras clases de cuarto grado participar\u00e1n. {Esta/Una de estas} es la clase de su hijo. {Esta clase/Estas dos clases}, junto con otras {500} clases de estudiantes de cuarto grado en todo el pa\u00eds, contribuir\u00e1n a mostrar lo que saben los estudiantes de cuarto grado en Estados Unidos sobre matem\u00e1ticas y ciencias, y c\u00f3mo se comparan con estudiantes de cuarto grado alrededor del mundo. Para tener una imagen precisa de lo que los estudiantes de cuarto grado en Estados Unidos pueden hacer, es importante que cada estudiante seleccionado participe en el estudio. Lo invito a que apoye este esfuerzo animando a su hijo a participar; sin embargo, la participaci\u00f3n en este estudio es completamente voluntaria. Las experiencias anteriores parecen indicar que los estudiantes disfrutan de su participaci\u00f3n. Adem\u00e1s, los estudiantes que participen recibir\u00e1n un peque\u00f1o regalo que creemos les gustar\u00e1. Toda la informaci\u00f3n que se re\u00fana es completamente confidencial, como lo exige la ley. NCES est\u00e1 autorizado a realizar este estudio de acuerdo con la Ley de reforma de ciencias de la educaci\u00f3n de 2002 (Ley p\u00fablica 107-279, secci\u00f3n 153). Por ley, la informaci\u00f3n dada por las escuelas, empleados y estudiantes solamente se puede utilizar con fines estad\u00edsticos y no se puede dar a conocer ni utilizar de una manera que permita la identificaci\u00f3n de personas para otros fines (Ley p\u00fablica 107-279, secci\u00f3n 183 y t\u00edtulo V, subt\u00edtulo A de la Ley de gobierno electr\u00f3nico de 2002 (Ley p\u00fablica 107-347)). En los informes nunca se identifica ni a los estudiantes ni a las escuelas. Todas las estad\u00edsticas publicadas se refieren a Estados Unidos en conjunto. Antes de que podamos permitirle al ni\u00f1o participar en las actividades de TIMSS, debemos tener su autorizaci\u00f3n por escrito. Puede dej\u00e1rnoslo saber completando el formulario que se adjunta (\u00b4Participaci\u00f3n en TIMSS\u00b4) y envi\u00e1ndolo a la escuela antes de {Insert date at least 2 days prior to assessment date}. Gracias por tomarse el tiempo de considerar este estudio. Reciba nuestros mejores deseos. "}, {"section_title": "Participaci\u00f3n en TIMSS", "text": "Nos encantar\u00eda que su hijo participara en el proyecto TIMSS junto con sus compa\u00f1eros de clase. La participaci\u00f3n de los estudiantes en TIMSS es sumamente importante para el \u00e9xito del estudio y en \u00faltima instancia para los intereses del pa\u00eds de mejorar la educaci\u00f3n en matem\u00e1ticas y ciencias. Su hijo ser\u00e1 inclu\u00eddo en TIMSS a menos que usted indique lo contrario. Si no desea que su hijo participe, por favor marque la casilla \"No\" a continuaci\u00f3n, firme el formulario y env\u00edelo a la escuela. La escuela se asegurar\u00e1 que su hijo realice otra actividad en el tiempo en que los dem\u00e1s estudiantes est\u00e9n participando en TIMSS. No, no deseo que mi hijo participe en el estudio. Our school has accepted an invitation from the National Center for Education Statistics (NCES), U.S. Department of Education, to participate in an important international study of student learning. This study is called TIMSS for short; the full name is the Trends in International Mathematics and Science Study. TIMSS looks at student mathematics and science achievement in schools around the world and documents worldwide trends in student knowledge of mathematics and science since 1995. The enclosed summary sheet provides some background to TIMSS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. {Insert number} of our 4th-grade classes will take part. {This/One of these} is your child's class. {This class/These two classes}, along with some {500} other classes of 4th graders nationwide, will contribute to this picture of what U.S. 4th graders know about mathematics and science, and how they compare with 4th graders worldwide. To have an accurate picture of what U.S. 4th graders can do, it is important that each student selected take part in the study. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part. And participating students will receive a small gift, which we think they will like. All of the information collected is kept completely confidential, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Before we can allow your child to join in the TIMSS activities we must have your written consent. You can let us know by completing the attached form ('Being Part of TIMSS') and returning it to the school by {Insert date at least 2 days prior to assessment date}. Thank you for taking the time to think about this. We wish you all the best. \nNecesitamos su autorizaci\u00f3n. Nos encantar\u00eda que su hijo participara en el proyecto TIMSS junto con sus compa\u00f1eros de clase. La participaci\u00f3n de los estudiantes en TIMSS es sumamente importante para el \u00e9xito del estudio y en \u00faltima instancia para los intereses del pa\u00eds de mejorar la educaci\u00f3n en matem\u00e1ticas y ciencias. Por favor marque \"S\u00ed\" a continuaci\u00f3n si da su autorizaci\u00f3n, o marque \"No\" si no la da. Si usted no desea que su hijo participe, la escuela se asegurar\u00e1 que su hijo realice otra actividad en el tiempo en que los dem\u00e1s estudiantes est\u00e9n participando en TIMSS. Despu\u00e9s de marcar su elecci\u00f3n, por favor firme el formulario y env\u00edelo a la escuela antes de {Insert date at least 2 days prior to assessment date}. "}, {"section_title": "Facts About TIMSS for Parents", "text": "In April and May of this year, your child's school will join schools across the U.S. and around the world taking part in TIMSS, the Trends in International Mathematics and Science Study. The schools were selected randomly to represent the nation's schools, and within each school, 4th-grade students were selected randomly to represent the nation's 4th graders. Your child is among the 4th graders selected from this school to take part in TIMSS."}, {"section_title": "What is TIMSS?", "text": "TIMSS is an international assessment that measures student learning in mathematics and science. Periodically (1995,2003,2007, and now 2011) TIMSS documents worldwide trends in the knowledge of 4th graders. The National Center for Education Statistics within the U.S. Department of Education sponsors U.S. participation in TIMSS. Along with more than 60 other nations, we will take part in the 2011 cycle just as we did in 1995, 2003, and 2007. Participation in this study is voluntary."}, {"section_title": "What is involved?", "text": "From April through May 2011, TIMSS staff will visit the school and administer an assessment that contains mathematics and science items. The assessment runs for 70 minutes with breaks between sections. Students will also receive a background questionnaire, which takes 20 to 30 minutes to complete.\nFrom April through May 2011, PIRLS staff will visit the school and administer an assessment that contains reading items. The assessment runs for 70 minutes with breaks between sections. Students will also receive a background questionnaire, which takes 20 to 30 minutes to complete."}, {"section_title": "What are the benefits?", "text": "The nation as a whole benefits from the contribution your child's school makes to the national picture of what our 4th graders know about mathematics and science, and how they compare with 4th graders worldwide Schools benefit too since we provide each school with a report about how it did in the assessment. Last, and certainly not least, students receive a small gift that we believe they will like.\nThe nation as a whole benefits from the contribution your child's school makes to the national picture of the reading achievement of our 4th graders, and how they compare with 4th graders worldwide. Schools benefit too since we provide each school with a report about how it did in the assessment. Last, and certainly not least, students receive a small gift that we believe they will like."}, {"section_title": "Who administers TIMSS?", "text": "The entire assessment is administered by trained staff from Westat, a research organization under contract to the U.S. Department of Education's National Center for Education Statistics. All of the information collected is kept completely confidential, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Where can I find out more about TIMSS? There is a lot of information available through the TIMSS website at http://nces.ed.gov/timss/ or http://timss.bc.edu/. Or, if you would like to contact a TIMSS staff member directly, please feel free to call the TIMSS hotline at 1 (888) 369-5033 or email us at TIMSS-PIRLS@westat.com."}, {"section_title": "U.S. TIMSS and PIRLS 2011 Technical Report and User's Guide C-20", "text": "Main study's 'Facts About TIMSS for Parents' -Grade 4"}, {"section_title": "Informaci\u00f3n sobre TIMSS para los padres", "text": "En abril y mayo de este a\u00f1o, la escuela de su ni\u00f1o participar\u00e1 junto con otras escuelas de Estados Unidos y de todo el mundo en el Estudio Internacional Sobre las Tendencias en Matem\u00e1ticas y Ciencias, TIMSS, por sus siglas en ingl\u00e9s. Las escuelas fueron seleccionadas al azar para representar a las escuelas de nuestro pa\u00eds, y dentro de cada escuela, se seleccionaron al azar a estudiantes de cuarto grado para representar a los estudiantes de cuarto grado del pa\u00eds. Su ni\u00f1o es uno de los estudiantes de cuarto grado seleccionados de esta escuela para participar en TIMSS."}, {"section_title": "\u00bfQu\u00e9 es TIMSS?", "text": "TIMSS es una evaluaci\u00f3n internacional que mide el aprendizaje de los estudiantes en matem\u00e1ticas y ciencias. TIMSS documenta peri\u00f3dicamente (1995,2003,2007  El pa\u00eds en conjunto se beneficia de la contribuci\u00f3n que la escuela del ni\u00f1o hace para crear una imagen del pa\u00eds sobre lo que los estudiantes de cuarto grado saben de matem\u00e1ticas y ciencias y c\u00f3mo se comparan con los estudiantes de cuarto grado a nivel mundial. Las escuelas tambi\u00e9n se benefician ya que a cada una le damos un informe sobre cu\u00e1l fue su desempe\u00f1o en la prueba. Finalmente, los estudiantes reciben un peque\u00f1o regalo que creemos les gustar\u00e1.\nTIMSS es una evaluaci\u00f3n internacional que mide el aprendizaje de los estudiantes en matem\u00e1ticas y ciencias. Cada cuatro a\u00f1os, desde 1995, TIMSS documenta en todo el mundo las tendencias en el conocimiento de los estudiantes de 8\u00ba grado. El Centro Nacional para Estad\u00edsticas de la Educaci\u00f3n dentro del Departamento de Educaci\u00f3n de Estados Unidos auspicia la participaci\u00f3n de Estados Unidos en TIMSS. Junto con m\u00e1s de otras 60 naciones, Estados Unidos participar\u00e1 en el ciclo 2011 tal como lo hicimos en 1995, 1999, 2003, y 2007. La participaci\u00f3n en este estudio es voluntaria."}, {"section_title": "\u00bfQui\u00e9n administra TIMSS?", "text": "La totalidad de la evaluaci\u00f3n la administra personal capacitado de Westat, una compa\u00f1\u00eda de estudios de investigaci\u00f3n que tiene un contrato con el Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n del Departamento de Educaci\u00f3n de Estados Unidos. Our school has accepted an invitation from the National Center for Education Statistics (NCES), U.S. Department of Education, to participate in an important international study of student learning. This study is called PIRLS for short; the full name is the Progress in International Reading Literacy Study. PIRLS looks at student reading achievement in schools around the world and, every five years since 2001, documents worldwide trends in reading literacy. The enclosed summary sheet provides some background to PIRLS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. {Insert number} of our 4th-grade classes will take part in PIRLS. {This/One of these} is your child's class. {This class/These classes}, along with some {500} other classes of 4th graders nationwide, will contribute to this picture of the reading achievement of U.S. 4th graders, and how they compare with 4th graders worldwide. To have an accurate picture of what U.S. 4th graders can do, it is important that each student selected take part in the study. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is kept completely confidential, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Thank you for taking the time to think about this. We wish you all the best. Nuestra escuela ha aceptado una invitaci\u00f3n del Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s) del Departamento de Educaci\u00f3n de Estados Unidos para participar en un importante estudio internacional sobre el aprendizaje estudiantil. El nombre corto de este estudio es PIRLS; abreviaci\u00f3n de Estudio Internacional Sobre el Progreso en el Aprendizaje de la Lectura. Desde 2001 PIRLS ha observado los logros de los estudiantes en lectura en las escuelas del mundo y cada cinco a\u00f1os documenta las tendencias mundiales en el aprendizaje de la lectura. El resumen adjunto ofrece informaci\u00f3n de trasfondo de PIRLS, explica lo que implica la participaci\u00f3n en el estudio para cada estudiante seleccionado e incluye un n\u00famero de tel\u00e9fono y un correo electr\u00f3nico de contacto donde usted podr\u00e1 encontrar respuestas a cualquier pregunta que tenga. {Insert number} de nuestras clases de cuarto grado participar\u00e1n. {Esta/Una de estas} es la clase de su hijo. {Esta clase/Estas dos clases}, junto con otras {500} clases de estudiantes de cuarto grado en todo el pa\u00eds, contribuir\u00e1n a mostrar los logros en lectura de los estudiantes de cuarto grado en Estados Unidos, y c\u00f3mo se comparan con estudiantes de cuarto grado alrededor del mundo. Para tener una imagen precisa de lo que los estudiantes de cuarto grado en Estados Unidos pueden hacer, es importante que cada estudiante seleccionado participe en el estudio. Lo invito a que apoye este esfuerzo animando a su hijo a participar; sin embargo, la participaci\u00f3n en este estudio es completamente voluntaria. Las experiencias anteriores parecen indicar que los estudiantes disfrutan de su participaci\u00f3n. Adem\u00e1s, los estudiantes que participen recibir\u00e1n un peque\u00f1o regalo que creemos les gustar\u00e1. Toda la informaci\u00f3n que se re\u00fana es completamente confidencial, como lo exige la ley. NCES est\u00e1 autorizado a realizar este estudio de acuerdo con la Ley de reforma de ciencias de la educaci\u00f3n de 2002 (Ley p\u00fablica 107-279, secci\u00f3n 153). Por ley, la informaci\u00f3n dada por las escuelas, empleados y estudiantes solamente se puede utilizar con fines estad\u00edsticos y no se puede dar a conocer ni utilizar de una manera que permita la identificaci\u00f3n de personas para otros fines (Ley p\u00fablica 107-279, secci\u00f3n 183 y t\u00edtulo V, subt\u00edtulo A de la Ley de gobierno electr\u00f3nico de 2002 (Ley p\u00fablica 107-347)). En los informes nunca se identifica ni a los estudiantes ni a las escuelas. Todas las estad\u00edsticas publicadas se refieren a Estados Unidos en conjunto. Gracias por tomarse el tiempo de considerar este estudio. Reciba nuestros mejores deseos. Our school has accepted an invitation from the National Center for Education Statistics (NCES), U.S. Department of Education, to participate in an important international study of student learning. This study is called PIRLS for short; the full name is the Progress in International Reading Literacy Study. PILRS looks at student reading achievement in schools around the world and, every five years since 2001, documents worldwide trends in reading literacy. The enclosed summary sheet provides some background to PIRLS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. {Insert number} of our 4th-grade classes will take part. {This/One of these} is your child's class. {This class/These classes}, along with some {500} other classes of 4th graders nationwide, will contribute to this picture of the reading achievement of U.S. 4th graders, and how they compare with 4th graders worldwide. To have an accurate picture of what U.S. 4th graders can do, it is important that each student selected take part in the study. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is kept completely confidential, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. If you have any objection to your child joining in the PIRLS activities please let us know by completing the attached form ('Being Part of PIRLS') and returning it to the school. Thank you for taking the time to think about this. We wish you all the best.\nToda la evaluaci\u00f3n es administrada por personal capacitado de Westat, una  the characteristics of the school; its enrollment, resources, policies, and learning environment). is problem-free. n If necessary, helps to ensure all sampled n Represents other similar U.S. schools. n Receives feedback based on the n Arranges assessment day space. students attend the assessment session. performance of students in your school that took the TIMSS/PIRLS assessment. n Receives U.S. national report with final results."}, {"section_title": "Enclosures:", "text": "Facts About PIRLS for Parents "}, {"section_title": "Being Part of PIRLS", "text": "We would like very much to have your child take part in the PIRLS project along with his/her classmates. Student participation in PIRLS is critical to the success of the study and, ultimately, to the nation's interests in improving reading education. Your child will be included in PIRLS unless you indicate otherwise. If you do not want your child to participate in PIRLS, please check the \"No\" box below, sign the form, and send it back to the school. The school will make arrangements for your child to undertake some other activities during the time that the other students are involved with PIRLS. No, I do not want my child to take part in the study. Child's Name: _____________________________________________________ Nuestra escuela ha aceptado una invitaci\u00f3n del Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s) del Departamento de Educaci\u00f3n de Estados Unidos para participar en un importante estudio internacional sobre el aprendizaje estudiantil. El nombre corto de este estudio es PIRLS; abreviaci\u00f3n de Estudio Internacional Sobre el Progreso en el Aprendizaje de la Lectura. Desde 2001 PIRLS ha observado los logros de los estudiantes en lectura en las escuelas del mundo y cada cinco a\u00f1os documenta las tendencias mundiales en el aprendizaje de la lectura. El resumen adjunto ofrece informaci\u00f3n de trasfondo de PIRLS, explica lo que implica la participaci\u00f3n en el estudio para cada estudiante seleccionado e incluye un n\u00famero de tel\u00e9fono y un correo electr\u00f3nico de contacto donde usted podr\u00e1 encontrar respuestas a cualquier pregunta que tenga. {Insert number} de nuestras clases de cuarto grado participar\u00e1n. {Esta/Una de estas} es la clase de su hijo. {Esta clase/Estas dos clases}, junto con otras {500} clases de estudiantes de cuarto grado en todo el pa\u00eds, contribuir\u00e1n a mostrar los logros en lectura de los estudiantes de cuarto grado en Estados Unidos, y c\u00f3mo se comparan con estudiantes de cuarto grado alrededor del mundo. Para tener una imagen precisa de lo que los estudiantes de cuarto grado en Estados Unidos pueden hacer, es importante que cada estudiante seleccionado participe en el estudio. Lo invito a que apoye este esfuerzo animando a su hijo a participar; sin embargo, la participaci\u00f3n en este estudio es completamente voluntaria. Las experiencias anteriores parecen indicar que los estudiantes disfrutan de su participaci\u00f3n. Adem\u00e1s, los estudiantes que participen recibir\u00e1n un peque\u00f1o regalo que creemos les gustar\u00e1. Toda la informaci\u00f3n que se re\u00fana es completamente confidencial, como lo exige la ley. NCES est\u00e1 autorizado a realizar este estudio de acuerdo con la Ley de reforma de ciencias de la educaci\u00f3n de 2002 (Ley p\u00fablica 107-279, secci\u00f3n 153). Por ley, la informaci\u00f3n dada por las escuelas, empleados y estudiantes solamente se puede utilizar con fines estad\u00edsticos y no se puede dar a conocer ni utilizar de una manera que permita la identificaci\u00f3n de personas para otros fines (Ley p\u00fablica 107-279, secci\u00f3n 183 y t\u00edtulo V, subt\u00edtulo A de la Ley de gobierno electr\u00f3nico de 2002 (Ley p\u00fablica 107-347)). En los informes nunca se identifica ni a los estudiantes ni a las escuelas. Todas las estad\u00edsticas publicadas se refieren a Estados Unidos en conjunto. Si tiene alguna objeci\u00f3n en que su hijo participe en las actividades de PIRLS, por favor h\u00e1ganoslo saber al completar el formulario adjunto ('Participaci\u00f3n en PIRLS') y enviarlo a la escuela lo antes posible. Gracias por tomarse el tiempo de considerar este estudio. Reciba nuestros mejores deseos. \nWe need your consent. We would like very much to have your child take part in the PIRLS project along with his/her classmates. Student participation in PIRLS is critical to the success of the study and, ultimately, to the nation's interests in improving reading education. Please check the \"Yes\" box below if you give your consent, or check the \"No\" box if you do not consent. If you do not want your child to participate, the school will make arrangements for your child to undertake some other activities during the time that the other students are involved with PIRLS. After making your selection, please sign the form and send it back to the school by {Insert date at least 2 days prior to assessment date}. Nuestra escuela ha aceptado una invitaci\u00f3n del Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s) del Departamento de Educaci\u00f3n de Estados Unidos para participar en un importante estudio internacional sobre el aprendizaje estudiantil. El nombre corto de este estudio es PIRLS; abreviaci\u00f3n de Estudio Internacional Sobre el Progreso en el Aprendizaje de la Lectura. Desde 2001 PIRLS ha observado los logros de los estudiantes en lectura en las escuelas del mundo y cada cinco a\u00f1os documenta las tendencias mundiales en el aprendizaje de la lectura. El resumen adjunto ofrece informaci\u00f3n de trasfondo de PIRLS, explica lo que implica la participaci\u00f3n en el estudio para cada estudiante seleccionado e incluye un n\u00famero de tel\u00e9fono y un correo electr\u00f3nico de contacto donde usted podr\u00e1 encontrar respuestas a cualquier pregunta que tenga. {Insert number} de nuestras clases de cuarto grado participar\u00e1n. {Esta/Una de estas} es la clase de su hijo. {Esta clase/Estas dos clases}, junto con otras {500} clases de estudiantes de cuarto grado en todo el pa\u00eds, contribuir\u00e1n a mostrar los logros en lectura de los estudiantes de cuarto grado en Estados Unidos, y c\u00f3mo se comparan con estudiantes de cuarto grado alrededor del mundo. Para tener una imagen precisa de lo que los estudiantes de cuarto grado en Estados Unidos pueden hacer, es importante que cada estudiante seleccionado participe en el estudio. Lo invito a que apoye este esfuerzo animando a su hijo a participar; sin embargo, la participaci\u00f3n en este estudio es completamente voluntaria. Las experiencias anteriores parecen indicar que los estudiantes disfrutan de su participaci\u00f3n. Adem\u00e1s, los estudiantes que participen recibir\u00e1n un peque\u00f1o regalo que creemos les gustar\u00e1. Toda la informaci\u00f3n que se re\u00fana es completamente confidencial, como lo exige la ley. NCES est\u00e1 autorizado a realizar este estudio de acuerdo con la Ley de reforma de ciencias de la educaci\u00f3n de 2002 (Ley p\u00fablica 107-279, secci\u00f3n 153). Por ley, la informaci\u00f3n dada por las escuelas, empleados y estudiantes solamente se puede utilizar con fines estad\u00edsticos y no se puede dar a conocer ni utilizar de una manera que permita la identificaci\u00f3n de personas para otros fines (Ley p\u00fablica 107-279, secci\u00f3n 183 y t\u00edtulo V, subt\u00edtulo A de la Ley de gobierno electr\u00f3nico de 2002 (Ley p\u00fablica 107-347)). En los informes nunca se identifica ni a los estudiantes ni a las escuelas. Todas las estad\u00edsticas publicadas se refieren a Estados Unidos en conjunto. Antes de que podamos permitirle al ni\u00f1o participar en las actividades de PIRLS, debemos tener su autorizaci\u00f3n por escrito. Puede dej\u00e1rnoslo saber completando el formulario que se adjunta ('Participaci\u00f3n en PIRLS') y envi\u00e1ndolo a la escuela. Gracias por tomarse el tiempo de considerar este estudio. Reciba nuestros mejores deseos. "}, {"section_title": "Participaci\u00f3n en PIRLS", "text": "Nos encantar\u00eda que su hijo participara en el proyecto PIRLS junto con sus compa\u00f1eros de clase. La participaci\u00f3n de los estudiantes en PIRLS es sumamente importante para el \u00e9xito del estudio y en \u00faltima instancia para los intereses del pa\u00eds de mejorar la educaci\u00f3n en lectura. Su hijo ser\u00e1 inclu\u00eddo en PIRLS a menos que usted indique lo contrario. Si no desea que su hijo participe, por favor marque la casilla \"No\" a continuaci\u00f3n, firme el formulario y env\u00edelo a la escuela. La escuela se asegurar\u00e1 que su hijo realice otra actividad en el tiempo en que los dem\u00e1s estudiantes est\u00e9n participando en PIRLS. No, no deseo que mi hijo participe en el estudio. Our school has accepted an invitation from the National Center for Education Statistics (NCES), U.S. Department of Education, to participate in an important international study of student learning. This study is called PIRLS for short; the full name is the Progress in International Reading Literacy Study. PIRLS looks at student reading achievement in schools around the world and, every five years since 2001, documents worldwide trends in reading literacy. The enclosed summary sheet provides some background to PIRLS, explains what is involved for each student selected to participate in the study, and gives a contact phone number and email address where you can find answers to any questions you might have. {Insert number} of our 4th-grade classes will take part. {This/One of these} is your child's class. {This class/These two classes}, along with some {500} other classes of 4th graders nationwide, will contribute to this picture of the reading achievement of U.S. 4th graders, and how they compare with 4th graders worldwide. To have an accurate picture of what U.S. 4th graders can do, it is important that each student selected take part in the study. I urge you to support this effort by encouraging your child to take part; however, participation in this study is entirely voluntary. Previous experience suggests that students actually enjoy taking part, and participating students will receive a small gift, which we think they will like. All of the information collected is kept completely confidential, as required by law. NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. Before we can allow your child to join in the PIRLS activities we must have your written consent. You can let us know by completing the attached form ('Being Part of PIRLS') and returning it to the school. Thank you for taking the time to think about this. We wish you all the best. \nNecesitamos su autorizaci\u00f3n. Nos encantar\u00eda que su hijo participara en el proyecto PIRLS junto con sus compa\u00f1eros de clase. La participaci\u00f3n de los estudiantes en PIRLS es sumamente importante para el \u00e9xito del estudio y en \u00faltima instancia para los intereses del pa\u00eds de mejorar la educaci\u00f3n en lectura. Por favor marque \"S\u00ed\" a continuaci\u00f3n si da su autorizaci\u00f3n, o marque \"No\" si no la da. Si usted no desea que su hijo participe, la escuela se asegurar\u00e1 que su hijo realice otra actividad en el tiempo en que los dem\u00e1s estudiantes est\u00e9n participando en PIRLS. Despu\u00e9s de marcar su elecci\u00f3n, por favor firme el formulario y env\u00edelo a la escuela antes de {Insert date at least 2 days prior to assessment date}. "}, {"section_title": "Facts About PIRLS for Parents", "text": "In April and May of this year, your child's school will join schools across the U.S. and around the world taking part in PIRLS, the Progress in International Reading Literacy Study. The schools in the United States were selected randomly to represent our nation's schools, and within each school, 4th-grade students were selected randomly to represent the nation's 4th graders. Your child is among the 4th graders selected from this school to take part in PIRLS."}, {"section_title": "What is PIRLS?", "text": "PIRLS is an international assessment that measures student achievement in reading. Periodically (2001,2006, and now 2011) PIRLS documents worldwide trends in the knowledge of 4th graders. The National Center for Education Statistics within the U.S. Department of Education sponsors U.S. participation in PIRLS. Along with more than 50 other nations, we will take part in the 2011 cycle just as we did in 2001 and 2006. Participation in this study is voluntary.\nThe Progress in International Reading Literacy Study (PIRLS) is an international assessment and research project designed to measure both trends in fourthgrade students' reading literacy achievement as well as school and teacher practices related to reading instruction. PIRLS 2011 is the third such study in the PIRLS series of internationally comparative reading studies carried out in countries around the world every 5 years. In PIRLS 2011, students from more than 50 countries, including the United States, will participate. "}, {"section_title": "Who administers PIRLS?", "text": "The entire assessment is administered by trained staff from Westat, a research organization under contract to the U.S. Department of Education's National Center for Education Statistics. Where can I find out more about PIRLS? There is a lot of information available through the PIRLS website at http://nces.ed.gov/surveys/PIRLS. Or, if you would like to contact a PIRLS staff member directly, please feel free to call the PIRLS hotline at 1 (888) 369-5033 or email us at TIMSS-PIRLS@westat.com. "}, {"section_title": "Informaci\u00f3n sobre PIRLS para los padres", "text": "En abril y mayo de este a\u00f1o, la escuela de su ni\u00f1o participar\u00e1 junto con otras escuelas de Estados Unidos y de todo el mundo en el Estudio Internacional Sobre el Progreso en el Aprendizaje de la Lectura, PIRLS, por sus siglas en ingl\u00e9s. Las escuelas fueron seleccionadas al azar para representar a las escuelas de nuestro pa\u00eds, y dentro de cada escuela, se seleccionaron al azar a estudiantes de cuarto grado para representar a los estudiantes de cuarto grado del pa\u00eds. Su ni\u00f1o es uno de los estudiantes de cuarto grado seleccionados de esta escuela para participar en PIRLS."}, {"section_title": "\u00bfQu\u00e9 es PIRLS?", "text": "PIRLS es una evaluaci\u00f3n internacional que mide el aprendizaje de los estudiantes en lectura. PIRLS documenta peri\u00f3dicamente (2001,2006 y ahora en 2011) las tendencias mundiales en el conocimiento de los estudiantes de cuarto grado. El Centro Nacional de Estad\u00edsticas de la Educaci\u00f3n dentro del Departamento de Educaci\u00f3n de Estados Unidos patrocina la participaci\u00f3n de Estados Unidos en PIRLS. Junto con m\u00e1s de 50 pa\u00edses, participaremos en el ciclo del 2011 tal como lo hicimos en el 2001 y en el 2006. La participaci\u00f3n en este estudio es voluntaria."}, {"section_title": "\u00bfQu\u00e9 implica?", "text": "Desde abril hasta mayo de 2011, el personal de PIRLS visitar\u00e1 la escuela y administrar\u00e1 una evaluaci\u00f3n que contiene temas de lectura. La evaluaci\u00f3n dura 70 minutos y tiene descansos entre las secciones. A los estudiantes tambi\u00e9n se les dar\u00e1 un cuestionario sobre informaci\u00f3n general, que toma de 20 a 30 minutos para responder.\nDesde abril hasta mayo de 2011, el personal de TIMSS visitar\u00e1 la escuela y administrar\u00e1 una evaluaci\u00f3n que contiene preguntas de matem\u00e1ticas y ciencias. La evaluaci\u00f3n dura 90 minutos con descansos entre las secciones. A los estudiantes tambi\u00e9n se les har\u00e1n algunas preguntas acerca de s\u00ed mismos y de sus experiencias educativas en un cuestionario que tomar\u00e1 20 a 30 minutos para llenar."}, {"section_title": "\u00bfCu\u00e1les son los beneficios?", "text": "El pa\u00eds en conjunto se beneficia de la contribuci\u00f3n que la escuela del ni\u00f1o hace para crear una imagen del pa\u00eds sobre lo que los estudiantes de cuarto grado saben de lectura y c\u00f3mo se comparan con los estudiantes de cuarto grado a nivel mundial. Las escuelas tambi\u00e9n se benefician ya que a cada una le damos un informe sobre cu\u00e1l fue su desempe\u00f1o en la prueba. Finalmente, los estudiantes reciben un peque\u00f1o regalo que creemos les gustar\u00e1.\nToda la naci\u00f3n se beneficia de la contribuci\u00f3n que la escuela de su hijo(a) hace a la descripci\u00f3n nacional de lo que nuestros estudiantes de 8\u00ba grado saben acerca de matem\u00e1ticas y ciencias, y como se comparan con los estudiantes de 8\u00ba grado de todo el mundo. La escuela tambi\u00e9n se beneficia, ya que a cada escuela le proporcionamos un informe acerca de c\u00f3mo les fue en la evaluaci\u00f3n. Finalmente, y ciertamente no menos importante, los estudiantes reciben un peque\u00f1o regalo que creemos que a ellos les gustar\u00e1."}, {"section_title": "\u00bfQui\u00e9n administra PIRLS?", "text": "La totalidad de la evaluaci\u00f3n la administra personal capacitado de Westat, una  Dear Parent or Guardian, Our school has accepted an invitation to participate in an important assessment that will allow us to compare the mathematics and science performance of students in our state to students worldwide. The Trends in International Mathematics and Science Study (TIMSS) is conducted by the National Center for Education Statistics (NCES) within the U.S. Department of Education. TIMSS has documented student achievement worldwide in mathematics and science every four years since 1995, and this year a special study will be conducted to link TIMSS and the National Assessment of Educational Progress (NAEP). NAEP is also conducted by NCES and is the largest continuing and nationally representative assessment of what our nation's students can do in key subject areas such as mathematics, reading, science, and writing. Some students may be answering some NAEP questions during the TIMSS assessment. To access released NAEP questions, please visit the NAEP Questions Tool at http://nces.ed.gov/nationsreportcard/itmrlsx/default.aspx. The enclosed summary sheet provides some background to TIMSS, explains what is involved for each student selected to participate, and gives a contact phone number and e-mail address where you can find answers to any questions you might have. (Insert number) of our 8 th -grade classes will take part in TIMSS on (insert assessment date). (This/One of these) is your child's class. (This class/These two classes), along with some 1,200 other classes of 8 th -graders nationwide, will contribute to an understanding of what U.S. 8 th -graders know about mathematics and science and how they compare with 8 th -graders worldwide. It is important that each student selected participates in the assessment to provide the most accurate report of what our students know and can do. The results are completely confidential, and your child's grade will not be affected. Your child may be excused from participation for any reason, is not required to finish the assessment, and may skip any test question. While TIMSS is voluntary, the results from this assessment will inform improvements in education and will allow states to compare their educational achievement in mathematics and science internationally. Your child will represent many other students, so participation is very important. However, if you do not want your child to participate, please notify me in writing by (date). NCES is authorized to conduct this study under the Education Sciences Reform Act of 2002 Section 9543). Under that law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 9573 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Students and schools are never identified in any reports. All reported statistics refer to the United States as a whole. We are excited that our school will be participating in TIMSS, and we are pleased that your child has been selected. We know that (school name)'s students will help us to show what our nation's students know and can do. Sincerely, Nuestra escuela ha aceptado una invitaci\u00f3n para participar en una importante evaluaci\u00f3n que nos permitir\u00e1 comparar el desempe\u00f1o de los estudiantes de nuestro estado con estudiantes de todo el mundo en matem\u00e1ticas y ciencias. El Estudio de las Tendencias Internacionales de Matem\u00e1tica y Ciencias (TIMSS, por sus siglas en ingl\u00e9s) lo lleva a cabo el Centro Nacional para Estad\u00edsticas de la Educaci\u00f3n (NCES, por sus siglas en ingl\u00e9s) dentro del Departamento de Educaci\u00f3n de Estados Unidos. TIMSS ha documentado los logros de los estudiantes en matem\u00e1ticas y ciencias en todo el mundo cada cuatro a\u00f1os desde 1995, y este a\u00f1o se llevar\u00e1 a cabo un estudio especial para relacionar TIMSS y la Evaluaci\u00f3n Nacional de Progreso Educativo (NAEP, por sus siglas en ingl\u00e9s). NAEP tambi\u00e9n la lleva a cabo NCES y es la evaluaci\u00f3n continua y nacionalmente representativa m\u00e1s grande que muestra lo que los estudiantes en toda la naci\u00f3n saben y pueden hacer en el \u00e1rea de las materias fundamentales como matem\u00e1ticas, lectura, ciencias y escritura. Algunos estudiantes responder\u00e1n algunas preguntas de NAEP durante la evaluaci\u00f3n de TIMSS. Para ver las preguntas publicadas de NAEP, por favor visite NAEP \"Questions Tool\" en http://nces.ed.gov/nationsreportcard/itmrlsx. La hoja de resumen que se adjunta proporciona alguna informaci\u00f3n sobre TIMSS, explica lo que implica participar para cada estudiante seleccionado para participar y da un n\u00famero de tel\u00e9fono de contacto y una direcci\u00f3n de correo electr\u00f3nico (e-mail) donde usted puede encontrar respuestas a cualquier pregunta que tenga. (Insert number) de nuestras clases de 8\u00ba grado participar\u00e1n en la evaluaci\u00f3n de TIMSS el (insert assessment date). (Esta/Una de estas) es la clase de su hijo(a). (Esta clase/Estas dos clases), junto con otras 1,200 clases de estudiantes de 8\u00ba grado en toda la naci\u00f3n, contribuir\u00e1(n) a una comprensi\u00f3n de lo que los estudiantes de 8\u00ba grado en Estados Unidos saben acerca de matem\u00e1ticas y ciencias y c\u00f3mo se comparan con los estudiantes de 8\u00ba grado de todo el mundo. Es importante que cada estudiante seleccionado participe en la evaluaci\u00f3n para proporcionar el informe m\u00e1s preciso posible de lo que los estudiantes saben y pueden hacer. Los resultados son completamente confidenciales, y no afectar\u00e1n las notas de su hijo(a). Su hijo(a) puede ser excusado(a) de participar por cualquier motivo, no est\u00e1 obligado(a) a terminar la evaluaci\u00f3n y puede dejar de responder cualquier pregunta de la prueba. Aunque TIMSS es voluntaria, los resultados de esta evaluaci\u00f3n se tendr\u00e1n en cuenta en el momento de efectuar mejoras en la educaci\u00f3n y les permitir\u00e1n a los estados comparar sus logros educativos en matem\u00e1ticas y ciencias internacionalmente. Su hijo(a) representar\u00e1 a muchos otros estudiantes, de manera que la participaci\u00f3n es muy importante. Sin embargo, si usted no quiere que su hijo(a) participe, por favor notif\u00edqueme por escrito antes del (date). NCES est\u00e1 autorizado bajo la Ley de Reforma de Ciencias de la Educaci\u00f3n de 2002 (Ley P\u00fablica 107-279, Secci\u00f3n 9543) para llevar a cabo este estudio. Bajo esa ley, la informaci\u00f3n proporcionada por las escuelas, el personal y los estudiantes se puede usar solamente para prop\u00f3sitos estad\u00edsticos y no se puede publicar o usar de manera que pueda identificar a alguien para cualquier otro prop\u00f3sito (Ley P\u00fablica 107-279, Secci\u00f3n 9573 y T\u00edtulo V, subt\u00edtulo A de la Ley de Gobierno Electr\u00f3nico de 2002 (Ley P\u00fablica 107-347)). Los estudiantes y las escuelas nunca se identifican en ning\u00fan informe. Todas las estad\u00edsticas que se informan se refieren a Estados Unidos en conjunto. Estamos muy entusiasmados de que nuestra escuela participe en TIMSS y nos agrada que su hijo(a) haya sido seleccionado(a). Sabemos que los estudiantes de (school name) nos ayudar\u00e1n a mostrar lo que los estudiantes de nuestra naci\u00f3n saben y pueden hacer. Atentamente, Director(a) Se adjunta documento Informaci\u00f3n para los padres acerca de TIMSS"}, {"section_title": "Informaci\u00f3n para los padres acerca de TIMSS", "text": "En abril y mayo de este a\u00f1o, la escuela de su hijo(a) se unir\u00e1 a otras escuelas en todo Estados Unidos y alrededor del mundo al tomar parte en TIMSS, el Estudio de las Tendencias Internacionales de Matem\u00e1tica y Ciencias. Las escuelas fueron seleccionadas al azar para representar a las escuelas de la naci\u00f3n, y dentro de cada escuela se seleccionaron estudiantes de 8\u00ba grado al azar para representar a los estudiantes de 8\u00ba grado de la naci\u00f3n. Su hijo(a) est\u00e1 dentro de los estudiantes de 8\u00ba grado seleccionados en esta escuela para participar en TIMSS."}, {"section_title": "School coordinator", "text": "n Receives a $100 personal check. n Works with Westat assessment staff to select n Completes Class Listing Form and Student n Collects completed School and Teacher an assessment date convenient for the school. Listing Forms and returns these to Westat (via fax, mail, or email). Questionnaires and returns them to assessment staff. n Receives U.S. national report with final results. n Ensures parents are notified that their children n Ensures all sampled students attend the have been selected for the assessment. assessment session. n Works with assessment staff to identify n Meets with assessment staff and reviews the assessment. students with special education needs. n Meets with students/teachers as necessary to provide information about the study."}, {"section_title": "Teachers of n Represent the United States -", "text": "n Complete Teacher Questionnaires and returns sampled classes them to the school coordinator prior in the international study. to assessment day."}, {"section_title": "Students", "text": "-n Students of the selected classes attend n Receive a small thank-you gift. the assessment session and complete the assessment and Student Questionnaire. n Represent other U.S. students like themselves and contribute to the profile of what American students know.\nWestat assessment staff (contracted by the U.S. department of Education's National Center for Education Statistics to conduct the study and support participating schools) n Work with the school to set an assessment date. n Help school coordinator with assessment details. n Protect school and student confidentiality. n Call the school coordinator to discuss assessment day space and student participation. n Select classroom sample and notify school of selected classes. n Provide School and Teacher Questionnaires to the school coordinator for distribution. n Students of the selected classes attend the assessment session and complete the assessment and Student Questionnaire. n Conduct assessment from start to finish. n furnish all the assessment materials, pencils, and test booklets. n Conduct a brief followup interview with the school coordinator at the end of the assessment. n Maintain security of all materials. n Receive a small thank-you gift. n Represent the United States in the international study. -D-9"}, {"section_title": "Westat assessment staff", "text": "(contracted by the U.S. Department of Education's National Center for Education Statistics to conduct the study and support participating schools) n Work with the school to set an assessment date. n Help school coordinator with assessment details. n Protect school and student confidentiality. n Call the school coordinator to discuss assess ment day space and student participation. n Select classroom sample and notify school of selected classes. n Provide School and Teacher Questionnaires to the school coordinator for distribution. n Conduct assessment from start to finish. n Furnish all the assessment materials, pencils, and test booklets. n Conduct a brief followup interview with the school coordinator at the end of the assessment. n Maintain security of all materials. -For additional information, go to http://nces.ed.gov/timss and http://nces.ed.gov/surveys/PIRLS. "}, {"section_title": "Summary of Activities for School Coordinators", "text": "\nGrade 8 What will be asked of the school coordinator? Upon the school's agreement to participate, Westat staff will work with the school coordinator to: \uf06e Schedule the assessment. A Westat staff member will contact the school coordinator to schedule a convenient date between April 4 and May 27, 2011. The coordinator will need to arrange the use of each selected class' classroom or an alternative quiet space for the assessment. \uf06e Review parent notification procedures. If your school requires parental permission to conduct the assessment(s), the Westat staff member will review these procedures with the school coordinator. \uf06e Provide a list of eighth-grade mathematics classes. The school coordinator will receive instructions for preparing and submitting a list of eighth-grade mathematics classes. Classes from the list will be selected randomly to participate. \uf06e Provide a student listing for each selected class. All student names will be kept confidential and will never be linked to assessment booklets or results. Individual student responses or scores are NEVER reported or distributed. Closer to the assessment date, the school coordinator will be asked to: \uf06e Work with a Westat staff member to identify those students with special needs or limited English proficiency that preclude them from participating in the assessment. \uf06e Notify parents, teachers, and students. Once the classes and students have been selected, a Westat staff member will work with the school coordinator on procedures for notifying parents, teachers, and students of the study and the benefits of participating. \uf06e Receive the School and Teacher Questionnaires. The school coordinator will be mailed the School and Teacher Questionnaires and asked to distribute them to the school principal and teachers of the selected classes. The school coordinator should also retrieve the questionnaires and return them to the Westat staff member on assessment day. \uf06e Confirm the assessment information. At least 2 weeks before the assessment, a Westat staff member will contact the school coordinator to confirm the date and location of the assessment. On assessment day, the school coordinator will be asked to: \uf06e Ensure that all students in the selected classes attend the assessment session. While it is not necessary for the school coordinator to be present during the session, the school coordinator should be available before the assessment to help locate selected students and ensure participation. It is very important that student attendance rates be as high as possible to avoid the need for a makeup session. A graphic timeline of activities is also available for your convenience. TIMSS is an international assessment designed to measure trends in mathematics and science achievement of U.S. eighth-grade students. It provides a benchmark for how U.S. eighth-grade students perform relative to their peers in other countries. TIMSS also collects data from principals and teachers about school conditions and practices that relate to student achievement. TIMSS was first administered in 1995 and is in its fifth cycle. In 2011, more than 60 countries will participate in TIMSS."}, {"section_title": "Grade 4", "text": "What will be asked of the school coordinator? Upon the school's agreement to participate, Westat staff will work with the school coordinator to: \uf06e Schedule the assessment. A Westat staff member will contact the school coordinator to schedule a convenient date between April 4 and May 27, 2011. The coordinator will need to arrange the use of each selected class' classroom or an alternative quiet space for the assessment. \uf06e Review parent notification procedures. If your school requires parental permission to conduct the assessment(s), the Westat staff member will review these procedures with the school coordinator. \uf06e Provide a list of fourth-grade classes. The school coordinator will receive instructions for preparing and submitting a list of fourth-grade classes. Classes from the list will be selected randomly to participate. \uf06e Provide a student listing for each selected class. All student names will be kept confidential and will never be linked to assessment booklets or results. Individual student responses or scores are NEVER reported or distributed. Closer to the assessment date, the school coordinator will be asked to: \uf06e Work with a Westat staff member to identify those students with special needs or limited English proficiency that preclude them from participating in the assessment. \uf06e Notify parents, teachers, and students. Once the classes and students have been selected, a Westat staff member will work with the school coordinator on procedures for notifying parents, teachers, and students of the study and the benefits of participating. \uf06e Receive the School and Teacher Questionnaires. The school coordinator will be mailed the School and Teacher Questionnaires and asked to distribute them to the school principal and teachers of the selected classes. The school coordinator should also retrieve the questionnaires and return them to the Westat staff member on assessment day. \uf06e Confirm the assessment information. At least 2 weeks before the assessment, a Westat staff member will contact the school coordinator to confirm the date and location of the assessment. On assessment day, the school coordinator will be asked to: \uf06e Ensure that all students in the selected classes attend the assessment session. While it is not necessary for the school coordinator to be present during the session, the school coordinator should be available before the assessment to help locate selected students and ensure participation. It is very important that student attendance rates be as high as possible to avoid the need for a makeup session. A graphic timeline of activities is also available for your convenience. Please feel free to contact the U.S. TIMSS-PIRLS Home Office with any questions via email at TIMSS-PIRLS@westat.com or by calling The data from the assessment will be used to evaluate how the knowledge and skills of U.S. students compare to those of their peers in other participating countries. By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Reports of the findings from the assessment will not identify participating districts, schools, students, or individual staff. Individual responses will be combined with those from other participants to produce summary statistics and reports."}, {"section_title": "Are schools required by federal law to participate?", "text": "No. School participation is voluntary. However, we hope you will participate in this study so that students like those in your school are accurately and fairly represented.\nNo. School participation is voluntary. However, we hope you will participate in this study so that students like those in your school are accurately and fairly represented."}, {"section_title": "What do school staff and students do?", "text": "\uf06e Schools are asked to designate a School Coordinator to assist Westat staff members with in-school arrangements. \uf06e The school principal or lead administrator will receive a School Questionnaire to complete. The questionnaire, which asks about the school environment and structure, takes about 20 minutes to complete. \uf06e Teachers of the sampled fourth-grade classes will receive Teacher Questionnaires to complete. These questionnaires focus on the nature of implemented curricula, instructional practices, and attitudes toward reading, mathematics, and science. They take about 30 minutes to complete. \uf06e Students will attend the assessment session (2\u00bd hours in length) and will be asked to complete the assessment booklet and questionnaire. Those who do will receive a small gift as a thank-you. \u2022 Focusing on and retrieving explicitly stated information; \u2022 Making straightforward inferences; \u2022 Interpreting and integrating ideas and information; and \n\uf06e Schools are asked to designate a School Coordinator to assist Westat staff members with in-school arrangements. \uf06e The school principal or lead administrator will receive a School Questionnaire to complete. The questionnaire, which asks about the school environment and structure, takes about 20 minutes to complete. \uf06e Teachers of the sampled eighth-grade classes will receive Teacher Questionnaires to complete. These questionnaires focus on the nature of implemented curricula, instructional practices, and attitudes toward mathematics and science. They take about 30 minutes to complete. \uf06e Students will attend the assessment session (2\u00bd hours in length) and will be asked to complete the assessment booklet and questionnaire. Those who do will receive a small gift as a thank-you. For questions about TIMSS 2011, contact the TIMSS Information Hotline at 1-888-369-5033 or email TIMSS-PIRLS@westat.com. In the packet are the [Student Teacher Linkage/Student Listing] Forms. There is one form for each selected class. On each form we need you to list the students in the sampled class and each student's gender and date of birth. If any of the sampled students have special needs and should be excluded, please put the appropriate exclusion code in the Exclusion Status column."}, {"section_title": "Why is PIRLS important?", "text": "PIRLS provides a unique opportunity to compare the reading knowledge and skills of U.S. fourthgraders with their peers in countries around the world. PIRLS complements what we learn from national assessments by identifying the strengths and weaknesses of students in reading relative to students around the world. The results inform national discussions about U.S. education performance and practice within the wider context of international competitiveness. Moreover, by participating in PIRLS 2011, the United States will obtain data about changes in children's reading achievement over the past 10 years, including valuable information about changes in reading instruction, how those changes relate to students' performance in reading, and about home, school, and classroom influences on reading achievement."}, {"section_title": "What type of reading assessment is PIRLS?", "text": "PIRLS is designed to reflect the reading curriculum used in participating countries. PIRLS asks students to read two texts, either two literary texts (narrative fiction, generally drawn from children's books), two informational texts (typically excerpts from biographies, step-by-step instructions, or scientific or non-fictional materials), or one of each type. It then asks students about a dozen questionsboth multiple-choice and open-ended \"constructed response\" questions-about the texts. These questions may range from identifying the place, time, and actions of the main characters or events to interpreting how characters might feel, why events occurred, or what the passage means overall (e.g., does the story teach a lesson?). Examples of released PIRLS test items can be viewed at http://nces.ed.gov/pubs2008/2008017_2.pdf."}, {"section_title": "Key findings from PIRLS 2006", "text": "\u2022 In PIRLS 2006, the average U.S. 4th grader's reading literacy score 540was above the PIRLS scale average of 500 but below that of 4th-graders in 7 of the other 39 participating countries and 3 of the 5 participating Canadian provinces. PIRLS is also meant to study home and school factors associated with children's reading literacy by the fourth grade. To that end, PIRLS will also administer questionnaires to students, their teachers, and the principals of their schools. The questions are designed to measure key aspects of students' home and school environments. In this way, PIRLS provides each country with a rich source of information on the factors influencing reading literacy."}, {"section_title": "D-7", "text": "Exhibit D-4. PIRLS study brochure-Continued  n Identifies a school coordinator. The school coordinator works with Westat assessment staff to plan for the assessment."}, {"section_title": "Why was my school selected for participation?", "text": "Schools of varying demographics and locations were randomly selected so that the overall U.S. sample is representative of the overall U.S. school population. The random selection process is important for ensuring that a country's sample accurately reflects its schools and, therefore, can fairly be compared with samples of schools from other countries."}, {"section_title": "Will all our eighth-graders be asked to participate?", "text": "It depends on the number of eighth-grade classrooms in the school. In schools with only one or two eighth-grade classrooms, all students will be asked to participate. In schools with more than two eighthgrade classrooms, only students in two randomly selected classrooms will be asked to participate. In addition, some students with special needs or limited English proficiency may be excused from the assessment."}, {"section_title": "Who conducts the assessment?", "text": "The entire assessment process will be undertaken by trained staff from Westat, a research organization under contract to the U.S. Department of Education's National Center for Education Statistics (NCES). NCES conducts this study under authorization in the Education Sciences Reform Act of 2002 (Public Law 107-279, Section 153). The U.S. Office of Management and Budget has approved the data collection under OMB # 1850-0645."}, {"section_title": "Do teachers need to help administer the assessment?", "text": "No. Westat staff will visit the school on the day of the assessment, bringing with them all the materials required, and they will handle the entire administration of the assessment."}, {"section_title": "When will the assessment be conducted?", "text": "The assessment will be conducted between April 4 and May 27, 2011. Westat will work with schools to identify an assessment date convenient for the school in that time period. Where will the assessment be conducted? The assessment will be conducted in the schools that are selected to participate."}, {"section_title": "How long does the assessment take?", "text": "The assessment session is approximately 2 \u00bd hours and includes the administration of the assessment, a brief questionnaire that students complete about themselves, and two breaks. The questionnaire takes approximately 30 minutes to complete."}, {"section_title": "What will happen with the collected data?", "text": "The data from the assessment will be used to evaluate how the knowledge and skills of U.S. students compare to those of their peers in other participating countries. By law, the data provided by schools, staff, and students may be used only for statistical purposes and may not be disclosed, or used, in identifiable form for any other purpose (Public Law 107-279, Section 183 and Title V, subtitle A of the E-Government Act of 2002 (P.L. 107-347)). Reports of the findings from the assessment will not identify participating districts, schools, students, or individual staff. Individual responses will be combined with those from other participants to produce summary statistics and reports."}, {"section_title": "IF THIS IS A TIMSS SCHOOL:", "text": "We also need you to list each sampled student's math and science teachers in the appropriate columns. "}, {"section_title": "Do you have any questions about this form?", "text": ""}, {"section_title": "General Directions", "text": "\uf026 In this test, you will read stories or articles and answer questions about what you have read. You may find some parts easy and you may find some parts difficult. \uf026 You will be asked to answer different types of questions. Some of the questions will be followed by four choices. You will choose the best answer and fill in the oval next to that answer. Example 1 shows this type of question.\n\uf026 In this test, you will answer questions in mathematics and science. You may find some questions easy, and you may find some questions difficult. Try to answer all questions, the difficult ones as well as the easy ones. Begin timing the 36 minutes for Part 1. Record the current time in Cell (10a) of the Test Administration Form.\n\uf026 In this test, you will answer questions in mathematics and science. You may find some questions easy, and you may find some questions difficult. Try to answer all questions, the difficult ones as well as the easy ones. Begin timing the 45 minutes for Part 1. Record the current time in Cell (10a) of the Test Administration Form."}, {"section_title": "\uf026", "text": "The oval next to \"7 days\" is filled in because there are 7 days in a week. Make sure all students begin working on the correct part of the booklet. Students assigned the PIRLS Reader and Booklet R should be reading the first story in the PIRLS Reader. Please make sure that students with Booklets 5, 6, and 10 pull out the leaflet that accompanies their booklet and use it to answer the questions in the first section of their test booklet. All other students should begin reading the story/article in the first section of the test booklet. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. After 35 minutes have passed, say the following: \uf026 You have 5 minutes left to work on this part of your booklet. Make sure you try to finish answering all of the questions in the first part of your booklet before the break. After the last 5 minutes have passed, say: \uf026 Your time is up. Please close your booklets, and put your pencils down. Do not write anything more. We will now take a [insert amount of time (up to 30 minutes) that is adequate for your students] break. Record the current time in Cell (10b) of the PIRLS Test Administration Form.\nWe will now take a short break. Afterwards, I will ask you to answer a short questionnaire. (Please be back on time.) If the room will be left unattended during the break, collect the booklets in the envelopes from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets and envelopes after the break, just like you did at the beginning of the testing session, making sure each student receives the same test booklet he/she was working on during the testing session. If the Student Questionnaire is going to be administered at a later time, say: \uf026 Please insert the booklet into the envelope it was in when you received it. \uf6b9 Make sure all the students are in the class; all are seated quietly, and have a pencil. When ready, say: \uf026 Now you will complete a short questionnaire. Turn to the colored divider page in your booklet. Do not begin the questionnaire until I tell you to do so. Make sure that all students are following along and are looking at Example 1 in their questionnaires.\nIn Example 1, the question asks, \"Do you go to school?\" Below this question are a \"Yes\" and a \"No.\" Since you all go to school, you should all fill in the oval next to \"Yes.\" Give students time to fill in the oval next to \"Yes\" and make sure they understand how to do it. Once everyone has completed the example, move on to Example 2. Make sure that all students are following along and are looking at Example 2 in their questionnaires. \uf026 Example 2 is another kind of question you will find in this booklet. \uf026 This question asks \"How often do you do these things?\" Letter (a) says, \"I talk with my friends.\" You are given four choices for how often you do this: Every day or almost every day; Once or twice a week; Once or twice a month; and Never or almost never. \uf026 Fill in the oval below your answer. For example, if you talk to your friends every day or almost every day, fill in the first oval under \"Every day or almost every day.\" Give students time to fill in their answers to all parts of the Example 2 question and make sure they understand how to answer this kind of question. Once everyone has completed the example, move on to Example 3. Make sure that all students are following along and are looking at Example 3 in their questionnaires. \uf026 Example 3 is another kind of question you will find in this booklet. \uf026 Example 3 says, \"What do you think? Tell how much you agree with these statements.\" Letter (a) says, \"Watching movies is fun.\" You are given four choices for how much you agree with the statement: Agree a lot, Agree a little, Disagree a little, or Disagree a lot. \uf026 Fill in the oval below your answer. For example, if you really agree a lot with that, fill in the first oval under \"Agree a lot.\" If you really disagree a lot, fill in the oval under \"Disagree a lot.\" Give students time to fill in their answers to all parts of the Example 3 question and make sure they understand how to answer this kind of question. Then continue reading the final directions: \uf026 Are there any questions before we start? If there are questions try to answer them the best you can. If there are no more questions then record the current time in Cell (13a) of the PIRLS Test Administration Form and proceed with the administration of the questionnaire.\nTurn the page to the first question and begin answering this questionnaire. You will have 30 minutes to answer these questions. After 30 minutes are up, say: Collect all test booklets and envelopes and keep them secure. Check against the Student Tracking Form to make sure that you have received all of them. Use the sequential number you assigned to the front of the envelope to help in this process. Thank you again for your help in conducting this important international study.\nMake sure all students begin working on the correct part of the booklet. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. 10 minutes before the testing session ends, say the following: \uf026 You have 10 minutes left before the break. Make sure you try to finish answering all of the questions in the first part of your booklet before the break. After the last 10 minutes have passed, say: \uf026 Your time is up. Please close your booklets, and put your pencils down. Do not write anything more. We will now take a short break. Record the current time in Cell (10b) of the Test Administration Form.\nWe will now take a short break. Afterwards, I will ask you to answer a short questionnaire. (Please be back on time.) If the room will be left unattended during the break, collect the booklets in the envelopes from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets and envelopes after the break, just like you did at the beginning of the testing session, making sure each student receives the same test booklet he/she was working on during the testing session. If the Student Questionnaire is going to be administered at a later time, say: \uf026 Please insert the booklet into the envelope it was in when you received it. Make sure all the students are in the class are all seated quietly and have a pencil. When ready, say: \uf026 Now you will complete a short questionnaire. Turn to the colored divider page in your booklet. Do not begin the questionnaire until I tell you to do so.\nThe directions are printed at the beginning of your questionnaire. I will also read them to you. It is important that you follow the directions very carefully so that you understand how to mark your answers. Now open the questionnaire and turn to the first page titled \"Directions.\" Make sure that the students have their questionnaires open to the Directions page before proceeding. \uf026 Example 1 is one kind of question you will find in this booklet. Make sure that all students are following along and are looking at Example 1 in their questionnaires.\nMake sure all students begin working on the correct part of the booklet. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. 10 minutes before the testing session ends, say the following: \uf026 You have 10 minutes left before the break. Make sure you try to finish answering all of the questions in the first part of your booklet before the break. After the last 10 minutes have passed, say: \uf026 Your time is up. Please close your booklets, and put your pencils down. Do not write anything more. We will now take a short break. Record the current time in Cell (10b) of the Test Administration Form.\nWe will now take a short break. Afterwards, I will ask you to answer a short questionnaire. (Please be back on time.) If the room will be left unattended during the break, collect the booklets in the envelopes from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets and envelopes after the break, just like you did at the beginning of the testing session, making sure each student receives the same test booklet he/she was working on during the testing session. If the Student Questionnaire is going to be administered at a later time, say: \uf026 Please insert the booklet into the envelope it was in when you received it. If yes, then continue. If not, find out why and proceed as described before. \uf026 Example 1 is one kind of question you will find in this booklet. Make sure that all students are following along and are looking at Example 1 in their questionnaires.\nTurn the page to the first question and begin answering this questionnaire. You will have 30 minutes to answer these questions. If not all of the students raise their hands, allow for additional time and say: \uf026 You will have more time to continue answering this questionnaire. If you have already finished all the questions, then you can use this time to review your answers. Once you have finished, please close your booklet and read quietly at your desk. Once all students have finished and have closed their booklets record the current time in Cell (13b) of the Test Administration Form. Then say: \uf026 Thank you very much for participating in this study. Your work will help us to learn more about our students and schools. \uf026 Please close your booklets and stay seated. \uf026 Please insert the booklet into the envelope it was in when you received it and seal the envelope closed. Once you have done this, remove the label that contains your name from the envelope. Peel it off and I will collect it. Collect all test booklets and envelopes and keep them secure. Check against the Student Tracking Form to make sure that you have received all of them. Use the sequential number you assigned to the front of the envelope to help in this process. Thank you again for your help in conducting this important international study. General Directions \uf026 In this test, you will answer questions in mathematics and science. You may find some questions easy, and you may find some questions difficult. Try to answer all questions, the difficult ones as well as the easy ones. Begin timing the 47 minutes for Part 1. Record the current time in Cell (10a) of the Test Administration Form.\nMake sure all students begin working on the correct part of the booklet. Remember that you are not allowed to help the students with the test except if they are confused about items involving currency. Refer to your Student Questionnaire Guide for responses to questions about dollars and cents and Zeds. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. Also, you should be monitoring the students to make sure those students that are restricted from using a calculator in the NAEP items are not using one. 10 minutes before the testing session ends, say the following: \uf026 You have 10 minutes left before the break. Make sure you try to finish answering all of the questions in the first part of your booklet before the break. After the last 10 minutes have passed, say: \uf026 Your time is up. Please close your booklets, and put your pencils down. Do not write anything more. We will now take a short break. Record the current time in Cell (10b) of the Test Administration Form."}, {"section_title": "Break", "text": "If the room will be left unattended during the break, collect the booklets from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets after the break, just like you did at the beginning of the testing session, making sure each student receives the same test booklet he/she was working on during the first half of the testing session.\nIf the room will be left unattended during the break, collect the booklets from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets after the break, just like you did at the beginning of the testing session, making sure each student receives the same test booklet he/she was working on during the first half of the testing session.\nIf the room will be left unattended during the break, collect the booklets from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets after the break, just like you did at the beginning of the testing session, making sure each student receives the same test booklet he/she was working on during the first half of the testing session. \nIf the room will be left unattended during the break, collect the booklets from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets after the break, just like you did at the beginning of the testing session, making sure each student receives the same test booklet he/she was working on during the first half of the testing session."}, {"section_title": "Part Two", "text": "Record the current time in Cell (11a) of the PIRLS Test Administration Form. Make sure all the students are seated. When the students are seated and quiet redistribute the test booklets, if necessary. Then, say the following: Begin timing the 40 minutes for the second part of the session. Record the current time in Cell (12a) of the PIRLS Test Administration Form. Make sure all students begin working on the correct part of the booklet. Students assigned the PIRLS Reader and Booklet R should be reading the second story in the PIRLS Reader. Please make sure that students with Booklets 5, 6, and 10 pull out the leaflet that accompanies their booklet and use it to answer the questions in the second section of their test booklet. All other students should begin reading the story/article in the second section of the test booklet. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. If a student is finished early, make sure that he or she has a book to read. After 35 minutes have passed, say the following: If the Student Questionnaire is going to be administered now, say:"}, {"section_title": "Instructions for Part 2", "text": "Record the current time in Cell (11a) of the Test Administration Form. Make sure all the students are seated. When the students are seated and quiet redistribute the test booklets, if necessary. Then, say the following: Begin timing the 36 minutes for the second part of the session. Record the current time in Cell (12a) of the Test Administration Form. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. If a student is finished early, make sure that he or she has a book to read. 10 minutes before the testing session ends, say the following: If the Student Questionnaire is going to be administered now, say:\nRecord the current time in Cell (11a) of the Test Administration Form. Make sure all the students are seated. When the students are seated and quiet redistribute the test booklets, if necessary. Then, say the following: Begin timing the 45 minutes for the second part of the session. Record the current time in Cell (12a) of the Test Administration Form. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. If a student is finished early, make sure that he or she has either a book to read or an activities sheet to work on. 10 minutes before the testing session ends, say the following: Collect the calculators. Make sure you account for all the calculators that you distributed. If the Student Questionnaire is going to be administered now, say:\nRecord the current time in Cell (11a) of the Test Administration Form. Make sure all the students are seated. When the students are seated and quiet redistribute the test booklets, if necessary. Then, say the following: Begin timing the 45 minutes for the second part of the session. Record the current time in Cell (12a) of the Test Administration Form. Remember that you are not allowed to help the students with the test. While the students are working, you should move around the room to see that students are working on the correct section of their booklets. If a student is finished early, make sure that he or she has either a book to read or an activities sheet to work on. 10 minutes before the testing session ends, say the following: After the last 10 minutes have passed, say: \uf026 Your time is up. Please close your booklets, and put your pencils down. Do not write anything more. Record the current time in Cell (12b) of the Test Administration Form, then say: \uf026 Thank you for your work. I'm now going to collect all of your extra materials. You will need to keep your pencil and test booklet. If you have a packet of materials, make sure to place the materials back in the bag. Please place any calculators or extra materials in the upper right corner of your desk and I will come around and collect them. Collect the calculators and manipulatives. Make sure you account for all items that you distributed. If the Student Questionnaire is going to be administered now, say: \uf026 We will now take a short break. Afterwards, I will ask you to answer a short questionnaire. (Please be back on time.) If the room will be left unattended during the break, collect the booklets in the envelopes from the students one by one. Keep the booklets secure during the break time. You will then redistribute the booklets and envelopes after the break, just like you did at the beginning of the testing session, making sure each student receives the same test booklet he/she was working on during the testing session. If the Student Questionnaire is going to be administered at a later time, say: \uf026 Please insert the booklet into the envelope it was in when you received it. If yes, then continue. If not, find out why and proceed as described before. \uf026 Example 1 is one kind of question you will find in this booklet. Make sure that all students are following along and are looking at Example 1 in their questionnaires."}]