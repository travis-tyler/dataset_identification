[{"section_title": "INTRODUCTION", "text": "Background, Problem, and Objectives"}, {"section_title": "Wetlands in Michigan", "text": "It has been estimated that Michigan once had 11.2 million acres of wetlands. However, a United States Fish and Wildlife Service study estimated that only 3.2 million acres remain (Michigan Department of Natural Resources, 1982). Of those remaining wetlands, coastal wetlands in Michigan account only for 48,000 acres (U.S. Commerce, 1994). The encroachment and habitat destruction on coastal wetlands are particularly due to agriculture, recreational, urban and industrial development (U.S. Environmental Protection Agency, 1995). The transformation of wetlands to dry lands has provided considerable benefits to the human economy. The natural benefits ( e.g., pollution control, flood control, erosion control) of coastal wetlands, however, have been destroyed (U.S. Department of Commerce, 1994) Biological Survey in 1987, was developed to map areas of high biodiversity using geographical information systems (GIS) and remote sensing technology (Scott et. al, 1993). Though the GAP Analysis program will provide useful information to the State of Michigan, it is not designed specifically for the monitoring of coastal zone habitats."}, {"section_title": "Department of", "text": "\n"}, {"section_title": "Uniqueness of C-CAP in the Great Lakes Region", "text": "The National Oceanic and Atmospheric Administration (NOAA) recognized the problem of limited data for the coastal wetland regions of the United States by developing the Coastal Change Analysis Program (C-CAP) (Kiraly et al., 1990). The C-CAP Program developed a protocol to establish guidelines to help researchers quantitatively monitor changes that are occurring in coastal regions on a 1 to 5 year cycle (Dobson et. al, 1995). This program primarily uses Landsat Thematic Mapper satellite digital imagery to monitor land covers in coastal regions. While the C-CAP protocol has been applied to the East and West coasts of the United States, it has not been applied to the Great Lakes region. Harris (1994) describes the East coast wetlands as being influenced largely by the low topographic relief of the region which allows for the formation of larger coastal wetlands, while the West coast of the United States is characterized by high topographic relief which allows for the formation of small, narrow coastal wetlands. In both of these areas, the wetlands are influenced highly by predictable tides (U.S. Environmental Protection Agency, 1995). The Great Lakes coastal wetlands are unique to the marine environments in that they are storm-driven ecosystems. They are shaped by waves, wind tides, and long and short-term water level fluctuations (U.S. Environmental Protection Agency, 1995). Additionally, the coastal wetlands are highly influenced by variable water levels that subject the wetlands to alternating inundation and exposure (U.S. Commerce, 1994). Coastal wetland vegetation varies with the water level fluctuations. In times when the water is low, emergent vegetation dominate, while when water levels are high, planktonic or floating leafed systems dominate (Price, Padding, and Knapton, 1992)."}, {"section_title": "Problem Statement", "text": "Currently, the State of Michigan does not have a program specifically designed for the monitoring of its coastal wetlands and near uplands on the Great Lakes. Limited research has been done on the monitoring of change in the coastal zones of this region (i.e., Williams and Lyon, 1991;Lyon and Greene, 1992). In many of the previous studies, a majority of the wetland data were gathered either from aerial photographs or from the U.S. Fish and Wildlife Service, National Wetlands Inventory (NWI) maps. The NWI data are considered highly accurate, but are updated only on a ten to fifteen year cycle (Dobson et al., 1995). An additional drawback to the NWI maps is that they fail to classify upland land cover. Land cover changes in the near uplands of a wetland ecosystem can have measurable effects on a wetland habitat. It is critical to monitor the uplands, as well as the habitats, because knowledge of the upland cover can provide a significant information to the type of stress that may be affecting the coastal wetlands (Klemas et al., 1993). To protect those remaining coastal wetlands in Michigan, a monitoring program is needed to evaluate the changes in wetland habitats and near upland land covers in coastal regions on a cycle less than the NWI. This program must allow for an accurate, rapid, and cost-effective acquisition of regional scale data. The C-CAP protocol has been designed for all coastal wetland regions of the United States, however it has not been evaluated on Michigan coastal wetlands. In addition, the protocol provides explanations for accepted image processing and change detection techniques. Unfortunately, many of these techniques have not been applied to or have not been well documented in a Great Lakes coastal region."}, {"section_title": "Purpose and Objective of Research", "text": "The purpose of this research was to evaluate the effectiveness of the established NOAA Coastal Change Analysis Program (C-CAP): Guidance for Regional Implementation protocol to serve as a monitoring program for Michigan's freshwater Great Lakes coastal wetlands (Dobson et al., 1995). To accomplish this, four components of the C-CAP protocol were investigated in a Great Lake freshwater environment; (1) suitable methodology to classify land cover in the Great Lakes coastal region, (2) suitable change detection logic, (3) accuracy assessment, and (4) source of digital data. The objective of this study was not to develop new classification and change detection processes, but to use accepted developed technologies to examine their effectiveness in a Great Lake freshwater ecosystem."}, {"section_title": "Site for Evaluation of C-CAP Protocol: Fish Point", "text": "The following section describes the specific site for the evaluation of the C-CAP protocol. This area was chosen because it is indicative of the general study region. The Fish Point, USGS 7.5' quadrangle was chosen for the specific study  portion of the quadrangle. Two townships, Akron and Wisner, are represented in this study area. The upland land cover of the study site is dominated by cultivated land. Small plots of deciduous forest, farmsteads, and managed grasslands are scattered across the uplands. The coastline land cover includes emergent grasses, submergent rooted vascular, shrub scrub wetlands, deciduous forests, and small linear sand dunes. The northwest portion of the study region is dominated by water. Although there are scattered farmsteads across the study area, this study location has no large urban developments. A network of man-made drains and ditches complements a network of predominately regularly spaced unpaved roads."}, {"section_title": "Components of the C-CAP Protocol Evaluated", "text": "(1) Suitable Classification Logic Management of the Great Lakes diverse coastal ecosystems relies on the ability to produce an accurate classification of the area of interest. In the 1993 C-CAP protocol, an overall classification accuracy of 90% for individual image classifications was required. Work by Jensen et al. (1993) and Althausen (1994) recommended that the accuracy should be lowered to 85. The April 1995 C-CAP protocol, however, states that classification methods often neglect the fuzzy nature of the wetland habitats. Given this limitation, Dobson et al. (1995) state that it is not feasible to provide a uniform quantitative value for every C-CAP regional database. To provide information on the effectiveness of the protocol in the Great Lakes region, a quantitative accuracy value for the classification must be provided. This study considered an overall classification accuracy of 85% or greater as \"suitable.\" To obtain this accuracy I evaluated unsupervised classification logic of a single date satellite scene as a means of extracting informational classes from digital satellite data. Criteria for Effectiveness and Hypotheses. The C-CAP protocol requires the final outputs of the data analysis to show \"from-to\" land cover changes. To identify land covers on satellite data, a classification methodology is required. Dobson et al. (1995) stated that the primary reason for using classification algorithms was to reduce human interaction with the data and improve classification consistency. The C-CAP protocol allows the analyst classifying the data to choose the appropriate classification algorithm. Therefore, a wide variety of algorithms can be applied to the satellite data. For a classification algorithm to be considered effective, it must allow for the accurate identification of each C-CAP required land cover class. To evaluate the effectiveness of the unsupervised classification logic in a Great Lakes freshwater ecosystem, two hypotheses were formulated: Hypothesis 1. Single scene, unsupervised classification logic can be used to produce an overall classification accuracy of 85% or greater in a Great Lakes coastal ecosystem. Hypothesis 2. Single scene, unsupervised classification logic can be used to identify each informational class to an accuracy of 85% or greater in a Great Lakes coastal region. (2) Suitable Change Detection Logic The C-CAP protocol allows for many different techniques to observe change. One main requirement, however, is that the technique must allow for the identification of \"from-to\" land cover changes (Dobson et al., 1995;Jensen et al., 1993). Althausen (1994) stated that an optimum change detection methodology has not been identified for the C-CAP program. Therefore, this part of the research evaluated the use of a binary change mask in conjunction with post-classification logic to serve as an optimum change detection methodology. Three methods of producing a change mask were investigated: (1) simple image differencing of a selected band, (2) selected principal components analysis (PCA), and (3) differencing of a normalized difference vegetation index (NDVI). The April 1995 C-CAP protocol does not provide an accepted change detection accuracy, but Jensen et al. (1993) and Althausen (1994) recommend that a change accuracy should be 75% or greater. This research considered an overall change accuracy of 75% or greater as acceptable. In this research an assumption was made that a change has occurred only when an informational class changed to a different informational class. To evaluate the effectiveness of a binary mask in identifying areas of relative spectral change between two images, two hypotheses were posed and were stated as: Hypothesis 3. Simple image differencing, selected PCA, and NDVI differencing methods of producing a change image in a Great Lakes coastal ecosystem provide the same results. Hypothesis 4. The use of a binary mask in conjunction with post classification logic can produce a land cover change product in a Great Lakes ecosystem with an overall accuracy greater than 75 percent. (3) Accuracy Assessment An accuracy assessment value of a land cover product from digital satellite data is an important and essential descriptor to the correctness of the derived classification data. There are many different techniques and methodologies available to determine the accuracy of a single classified scene (Congalton, 1991;Khorram et al., 1994). However, limited research has been conducted on the assessment of the accuracy of a change detection product (Jensen et al., 1993). This part of the research evaluated the use of a stratified random 3 x 3 pixel cluster desi gn to assess the accuracy of the individual classified scenes. To assess the accuracy of the derived land cover change detection product, a multinomial sampling approach in conjunction with a stratified random 3 x 3 pixel cluster desi gn was evaluated as described by Khorram et al. (1994). To evaluate the effectiveness of a stratified random cluster desi gn on a single classified product and a change product, two hypotheses were posed and were stated as: Hypothesis 5. The stratified random 3 x 3 cluster design will allow for each informational class to be represented in a single scene accuracy assessment. Hypothesis 6. Using a multinomial sampling approach with a stratified random 3 x 3 cluster design will allow for each informational class change to be represented in the change accuracy assessment."}, {"section_title": "( 4) Digital Data Source", "text": "The recommended data source for the C-CAP program is the Landsat Thematic Mapper (TM) data (Dobson et al., 1995). The TM data were first acquired aboard the Landsat-4 satellite in 1982. The spatial resolution of reflected bands are 30 meters. The TM data are the \"data-of -choice\" for the C-CAP protocol, but other sources of digital satellite data may be incorporated (Dobson et al., 1995). Examples of other satellite digital data include SPOT and Landsat Multispectral Scanner (MSS). Unfortunately, very few studies have evaluated the feasibility of using MSS data when applying the C-CAP protocol. When comparing MSS data to the TM data, the MSS data has coarser spatial resolution (79 meters) and a limited spectral resolution (four bands). The advantages of the MSS data, however, are that the acquisition of the data started in 1972 and the data are less expensive. Therefore, this part of the research evaluated the effectiveness of the MSS data compared to the TM data when applied to the C-CAP protocol in a Great Lakes ecosystem. If proven effective, the MSS data would allow for an additional 10 years to be monitored. To evaluate the effectiveness of the MSS data to be used in the C-CAP protocol, one hypothesis was proposed and was stated as: Hypothesis 7. The spatial resolution of the MSS data will allow for the required C-CAP informational classes to be classified in a Great Lakes ecosystem to an overall accuracy equal to the TM data classifications."}, {"section_title": "CHAPTER II LITERATURE REVIEW", "text": ""}, {"section_title": "Remote Sensing and Wetland Inventory", "text": "Satellite imagery has been widely used to detect change in various environments. Some of the previous change detection studies involved forest defoliation, urban sprawl, and vegetation stress (i.e., Muchoney and Haack, 1994;Jensen, Hodgson, and Christensen, 1986;Chavez and MacKinnon, 1994). Until recently, however, very few studies have applied satellite change detection to wetland ecosystems (Howarth and Wickware, 1981). The need to fmd an efficient method to inventory wetlands has led to the use of digital remote sensing to reduce costs, produce consistent results, and obtain accurate information on wetland changes. In 1979, the National Wetlands Inventory (NWI) tested the capabilities of Landsat MSS data to map Alaska's wetlands. The test results showed that Landsat MSS data could not accurately classify wetlands with a reasonable degree of accuracy. NWI is currently testing the Landsat Thematic Mapper (TM) data for wetland delineation. The only results to date are that TM data can not be used to produce maps to NWI standards (Pywell and Wilen, 1991 ). A study by the Ducks Unlimited, however, used Landsat TM data and found that satellite data could be used to classify and inventory wetlands (Jacobson, 1987). Ducks Unlimited, Inc. (DUI) and Ducks Unlimited Canada (DUC) have been developed in response to the loss of waterfowl habitat in the United States and Canada. Their main goals are to protect and manage waterfowl habitat. Ducks Unlimited (DU) is developing an inventory of wetland ecosystems to protect waterfowl habitats. The Habitat Inventory and Evaluation Program (IIlEP) within the DU has adopted Landsat Thematic Mapper (TM) data as its main source of information for monitoring. The TM data were determined to be the most economical and adequate data source to meet the DU criteria for habitat mapping and monitoring. The spatial, spectral, and temporal resolution of the Landsat TM data allowed for the identification of wetlands two acres or larger, for the identification of basins within 100 feet of their actual locations, and for the detection of seasonal and yearly changes in waterfowl habitats."}, {"section_title": "Advantages of Satellite Imagery", "text": "The use of satellite imagery has many advantages over conventional aerial photographs in monitoring coastal wetlands. While aerial photographs are more appropriate for small areas, satellite data are better suited for large areas because of the reduced costs (Jacobson, 1987). Other advantages of satellite data over aerial photographs include: increased spectral resolution, increased temporal resolution (a single area has the chance to be imaged every 16 days), greater classification consistency, and synopticity (Klemas et al., 1987;Jensen et al., 1993)."}, {"section_title": "Remote Sensing of Coastal Wetlands in the Great Lakes Region", "text": "Great Lakes wetlands have been identified as important ecosystems. Researches have incorporated remote sensing to monitor the coastal wetlands distributions to try to understand the forces responsible for their changes. Currently, Geographic Information Systems (GIS) have become an essential tool in anal yz ing these changes. By reviewing the periodical literature available, it has been observed that a majority of the data used in GIS has come from aerial photographs. It has also been observed that few studies have been conducted that have used satellite data for monitoring of Great Lakes coastal wetlands. Dahl, Young, and Caldwell ( 1996) used maps produced from aerial photographs and a Geographic Information System (GIS) to monitor inland wetland and coastal wetland changes in the Great Lakes watersheds. The purpose of the study was to help understand wetland changes by observing relationships between aquatic, wetland, and upland ecosystems. The first phase of the study has been completed in Lake Superior's watershed. Dahl, Young, and Caldwell (1996) stated that it was too time consuming and expensive to inventory the entire watershed, so a sample scheme was employed as a cost effective alternative. Ten percent of the drainage area was sampled with 434 four-square-mile plots. One goal of the project was to identify wetlands that were most susceptible to conversion to another land use/cover class. The researcher observed that the use of a GIS in wetland monitoring allowed for a greater understanding of the spatial patterns of wetland loss in the region's landscape. Williams and Lyon (1991) used a raster based Geographic Information System (GIS) to examine historical wetland changes on the St. Mary's River in Michigan. To build the database, seven dates of aerial photographs were interpreted and digitized. The database was used to determine the past, present, and potential sources of change in the wetlands. In addition, Lyon and Green (1992) interpreted aerial photographs to measure historical extents of coastal wetlands on Lake Erie in Monroe County, Michigan. The objectives of the study were to quantify changes in wetlands and to evaluate the causes for those changes. Also, Lyon and Green developed a model to estimate wetland areas based on water levels. McNaim, Protz, and Duke (1993) observed the effects of spatial resolution on the classification of coastal wetland changes in James Bay, Ontario. They used MEIS-II imagery and resampled it to simulate SPOT panchromatic, SPOT multispectral, Landsat TM, Landsat MSS, and NOAA A VHRR spatial resolutions. Each of the simulated data sets was used in a maximum likelihood unsupervised and a supervised classification. The results of the each method were compared. The results of the study suggested that the use of satellite images, such as SPOT and Landsat TM, could be used to observe change in coastal wetlands. Based on the results of the study, the McNaim, Protz, and Duke (1993) stated that spatial resolution of the data set was strongly dependent on the ecotype being observed. Also, the pixel resolution was strongly dependent on the area covered by each class and on the microtopographic variations within classes. Finally, McNaim, Protz, and Duke (1993) observed that the supervised classification logic could spectrally separate more coastal zone classes than the unsupervised classification logic."}, {"section_title": "C-CAP Program", "text": "NOAA has reacted to the wetland habitat problem in the United States by initiating the C-CAP program, which is part of the Estuarine Habitat Program of NOAA's Coastal Ocean Program (COP). The C-CAP program involves an inventory of coastal wetlands and near uplands, and monitoring changes in the habitats on a one-to-five year cycle using Landsat TM data. (Dobson et al., 1995;Dobson and Bright, 1991 ). In areas where noticeable changes are occurring or where some environmental stress is being applied ( e.g., oil spill), the monitoring can occur over an even shorter interval (Jensen et al., 1993)."}, {"section_title": "Standardization", "text": "The main goal of the C-CAP protocol is to develop a standardized and reliable database of coastal regions across the United States (Dobson et al., 1995;Klemas et al., 1993). To accomplish this goal, a standardized protocol is being designed using (1) digital remote sensing, (2) in situ measurements and global positioning system (GPS), and (3) ancillary data (Dobson et al., 1995). Although the C-CAP protocol has many emphases, three topics allow for regional and nation-wide consistency. These topics include a standardized land cover classification system, C-CAP accepted change detection algorithms, and quality assurance and control."}, {"section_title": "Land Cover Classification", "text": "The C-CAP land cover classification system is a hierarchical system that includes three level I superclasses: upland, wetland, and water and submerged land (Klemas et al., 1993). Each of these superclasses is broken down into subclasses. The classification system was devised specifically for the use of satellite imagery. The system was also designed, however, to be compatible with other classification systems (e.g., Cowardin et al., 1979, andAnderson et al., 1979). Some modifications had to be made to the Anderson et al. (1979) classification system because it stressed land use classes. For example, level two of the Urban or Built-Up Land class of Anderson et al. (1979) classification system contained subclasses that could not be extracted from satellite data (i.e., Residential, Industrial and Commercial Complexes, and Industrial). Therefore, the C-CAP classification system stresses land cover instead ofland use."}, {"section_title": "Classification Accuracy", "text": "The C-CAP protocol reqmres change detection algorithms capable of extracting \"from-to\" information from the satellite imagery. The \"from-to\" data are required by C-CAP to be available for integration into a GIS and for the production of maps and tabular summaries (Dobsen et al., 1995). The accepted list of change detection algorithms is not exhaustive. Because the protocol adopted digital data, specifically TM, new techniques in processing can be easily incorporated into the protocol (Dobson et al., 1995;Klemas et al., 1993;Jensen et al., 1993). In the 1993 C-CAP protocol draft, a classification accuracy of 90% for individual image classifications and 85% for the land cover change data was required. Work by Jensen et al. (1993) and Althausen (1994) recommended that the accuracies be lowered to 85% and 80% respectively. However, the April 1995 C-CAP protocol states that the classification methods often neglect the fuzzy nature of the wetland habitats. Given this limitation, it is not feasible to provide a uniform accuracy for every C-CAP regional database (Dobson et al., 1995). The 1995 protocol does describe a process called \"blind-field testing.\" This process requires independent field researchers to complete the field mapping before they see the individual classification maps and change detection maps, thereby reducing the amount of bias introduced into the accuracy assessments (Dobson et al., 1995). The independently produced maps can be compared to the digitally produced maps to provide an accuracy assessment."}, {"section_title": "Evaluations of the C-CAP Protocol", "text": "To evaluate the protocol, several study areas have been established across the nation. The C-CAP prototype was conducted by Dobson and Bright, researchers at the Oak Ridge National Laboratory, in the Chesapeake Bay region (Dobson and Bright, 1991). The analysis incorporated four MSS scenes. Dobson and Bright used a supervised, maximum-likelihood classification logic to extract informational classes from the satellite data. Training samples for the classification process were developed by on-screen digitizing and each class' statistical signature was evaluated interactively (Dobson and Bright, 1991;Dobson et. al., 1995). A Geographic Information System (GIS) was used to produce the change maps. The results of this study served as the basis for the draft C-CAP protocol (Dobson et. al., 1995). The next phase of evaluations of the C-CAP protocol incorporated Landsat TM data. Again, Dobson and Bright (1992) evaluated the C-CAP protocol in the Chesapeake Bay area, however, Landsat TM data was used. The objective of the study was to evaluate the use of a binary change mask in a multiple-date change detection process. The binary change mask was produced from an algebraic overlay of two individual bands from both dates of imagery. In this study, the 1988 image was used as the base scene and the entire image was classified using supervised classification logic. The binary mask was overlain onto the 1984 scene to isolate the pixels that have changed between the two dates of imagery. The pixels of change were then classified using supervised classification logic. This method proved successful because it reduced the errors of omission and commission and provided \"from-to\" change class information. Jensen et. al. (1993) evaluated the change detection protocol in South Carolina using TM data. The study evaluated the C-CAP classification system, image classification procedures, and change detection algorithms. The C-CAP classification system was satisfactory, but adjustments were recommended for some classes. Difficulties were encountered in distinguishing between developed/bare soil, cultivated land, and herbaceous land cover. The recommendation was to prioritize the land cover classes according to their importance in the C-CAP protocol. To classify the images, Jensen et .. al. (1993) used an unsupervised \"clusterbusting\" technique accompanied by a majority threshold filter. Clusterbusting is a process by which mixed clusters from the unsupervised classification process are re-clustered to isolate individual clusters. Finally, the best change detection procedure included the images to be classified independently, applying a majority threshold filter, and then applying post classification change detection logic. Jensen et. al. (1993) suggested using more than one scene per year to discriminate between classes, especially those associated with cropland covers. While, there have been evaluations of the protocol in marine environments, there have been no evaluations in the Great Lakes region (Worthy, 1996). Worthy ( 1996) stated that the next step for the C-CAP program is to evaluate the protocol in a Great Lakes coastal environment."}, {"section_title": "CHAPTER III STUDY REGION", "text": ""}, {"section_title": "Geographic Description of the Saginaw Bay Region", "text": "To gain a better understanding of the specific study site, a general description of the study region will be provided. This section provides information on the physiography, climate, soils, and vegetation of the Saginaw Bay region.  Resources, 1988). This is one important reason why the Saginaw Bay region was chosen for the study.   Resources, 1988;Mettert, 1986)."}, {"section_title": "The Saginaw Bay Watershed", "text": ""}, {"section_title": "Physiography and Drainage", "text": "Glacial landforms from the Wisconsin glacial period 12,000 years ago dominate the region's landscape (Dorr and Eschman, 1970). As glacial ice melted, a series of landforms were left behind. Topographic features such as terminal moraines, outwash plains, and lake plains were formed at this time (Mettert, 1986). Much of the region's coast can be described as flat. These areas are the former bed of Glacial Lake Saginaw (Dorr and Eschman, 1970 (Gabler, Sager, and Wise, 1991). The controlling factors for the climate in this region are cyclonic storms along the polar front, the prevailing westerlies, and continentality (Gabler, Sager, and Wise, 1991). Though inland from the effects of a large marine water body, the Great Lakes can still have a measurable effect on this region's climate (Eichenlaub, 1979 months of the year with a yearly average of 36.5 inches (Mettert, 1986).  (Mettert, 1986). The Essexville-Aquents-Tappan Association is most closely associated with the coastal wetlands of the bay. This association is typically found with ponding water and is most commonly found on lake margins, beaches, till plains, and lake plains (Mettert, 1986). These soils, developed by glacial lake sediments, are very fertile and highly suitable for agricultural development (Michigan Department of Natural Resources, 1988)."}, {"section_title": "Vegetation", "text": "The coastal zones of the Saginaw Bay region are composed of a linear series of beaches which parallel the present shoreline and are characterized by three environmental types: nearshore emergent marshes, beach ridges, and landward of the beach ridges. A description will be given for each of the environmental types to provide a better understanding of the coastal regions of the study area. "}, {"section_title": "CHAPTER IV METHODOLOGY Introduction", "text": "When research involves the use of satellite digital imagery, there are many steps that must be completed and followed in sequence to make the analysis accurate. The C-CAP protocol, however, does allow for a variety of processes to be used. This section describes the steps and processes in detail that were applied in the research."}, {"section_title": "Data Acquisition", "text": "The first step in this research was to collect data. Three main data sources were needed to complete this study. The following sections provide general descriptions of the data sources and their purpose in the analysis. For a change detection analysis, collecting satellite data that are near-anniversary is very important. Near-anniversary data are defmed as all data being collected near the same time of the year. Having near-anniversary data minimizes the differences introduced by sun angles and other environmental factors ( e.g., soil moisture). Also, the impact of the system factors may be minimized by choosing appropriate satellite data (Singh, 1989). System factors include detector calibration, atmospheric conditions, and sun angles (Jensen, 1986). The goal of the data acquisition was to collect data for the study area that minimizes the factors that result in these errors."}, {"section_title": "Digital Satellite Data", "text": "Two sources of digital data were acquired for the digital processing analysis:  (Lillesand and Kiefer, 1994;Jensen, 1986). The spectral, spatial, temporal and radiometric resolutions of the TM sensor are listed in Table 1. The TM data were used to produce land cover maps of the study area."}, {"section_title": "Multispectral Scanner", "text": "Two MSS system corrected scenes dated June 1, 1992 (ID#85301415394, path 20, row 30) and June 11, 1984 (ID#85010215442, path 20, row 30) were purchased from the EROS Data Center on 8mm data cartridges. The coverage area for each MSS Landsat scene is approximately 185 x 185-KM (Lillesand and Kiefer, 1994;Jensen, 1986). Both scenes contained less than 10% cloud cover and the study area extent was cloud free. A description of the MSS sensor characteristics are provided in Table 1. The MSS data were used to produce land cover classifications for the study area."}, {"section_title": "Aerial Photographs", "text": "Aerial photographs were purchased from the United States Department of Agriculture, Agriculture Stabilization and Conservation Service of Tuscola County for the purpose of accuracy assessments and ground truth data. These color photographs were taken at a scale of 1: 660 and were distributed on 35mm color slides. Two dates of slides were purchased: July 1992, and July 1984. For the 1992 date, 38 slides were needed to cover the entire Fish Point quadrangle study area, while 31 slides were needed for the 1984 date. The slides were digitally scanned to a minimum mapping unit of 1.5 meters."}, {"section_title": "Paper Maps", "text": "The Fish Point 1: 24,000 (7.5') topographic quadrangle and the Fish Point National Wetlands Inventory (NWI) 1: 24,000 (7.5') quadrangle were purchased from the United States Geological Service (USGS). The topographic sheet served as a base map to rectify the satellite images to the Universal Transverse Coordinate System (UTM). The NWI map was used as a reference to help identify wetland classes on the digital imagery. "}, {"section_title": "Data Preprocessing", "text": "Invariably, collecting all the data sets with the same variables or influencing factors (e.g., sun angle and atmospheric characteristics) is unlikely. Many factors may inhibit the acquisition of appropriate data. The presence of clouds over the study area at the near-anniversary date will make it impossible to use the scene. Most often, because of uncontrollable environmental factors, a multitemporal change detection analysis will not include data with identical variables. As a result, the multitemporal data sets should be normalized to minimize the atmospheric differences, sun angles, and detector calibrations (Jensen, Rutchey, and Narumalani, 1995)."}, {"section_title": "Normalization", "text": "Normalization is the process of reducing the variation between two images. Jensen et al. (1995) notes that the ability to detect change depends on the brightness values and actual surface conditions. Therefore, variations between the images must be minimized to justify that changes in the brightness values of objects on the image represent actual changes in these objects on the ground (Jensen, Rutchey, and Narumalani, 1995). In this study, empirical scene normalization was used to normalize the variation between data sets. This technique was used to match detector calibrations, sun angles, atmospheric conditions, and other scene variables to a reference data set. The process of empirical scene normalization does not correct these problems. Rather, the procedure tries to predict the brightness value of an object as if it were acquired under the same conditions as the reference scene (Jensen, Rutchey, and Narumalani, 1995). Image normalization was achieved by applying a regression equation to each scene. The regression is run against the reference scene. For this research the 1992 scenes for both TM and MSS data were used as the reference scenes. To perform image normalization, \"normalization targets\" (NTs) were collected from the study data sets (Schott, Salvaggio, and Volchok, 1988;Jensen, Rutchey, and Narumalani, 1995). Normalization targets are the objects on the scenes that should have constant reflectance ( e.g., water bodies, bare soil, concrete). The brightness values of these objects should not change from year to year. Therefore, the differences in brightness values of the NTs in the scenes can be attributed to detector calibration, atmospheric conditions, and sun angles (Jensen, 1986). Normalization targets should be objects that can be found easily on all scenes. The brightness values of the targets on the image being normalized are regressed against the brightness values of the same objects on the reference scene (Schott, Salvaggio, and Volchok, 1988). This process was executed on each band in the data set used in the analysis. The result of the regression analysis was a \"model that contained an additive component that corrected for the differences in atmospheric path radiance, and a multiplication term that corrected for the differences in detector calibration, sun angle, Earth/sun distance, atmospheric attenuatives, and phase angle between dates\" (Jensen, Rutchey, and Narumalani, 1995, p. 202). The equations and scatterplots of the reference objects for the sub-scene TM data sets used in this study are shown in Fi gur e 3. Dry areas, such as large unpaved parking lots and bare agricultural fields, were used for the high brightness value normalization targets (NTs ). Great care went into identifying agricultural fields that were absent of vegetation. In early June, some crops may be just breaking the surface of the soil. Though the small crops may not be easily identified on the image, the presence of vegetation may still provide significant changes in reflectance values. Therefore, it was necessary to identify these pixel areas on aerial photographs to insure that they were absent of vegetation. Only one NT was the result of bare agricultural fields. The low brightness value normalization targets were the result of deep, sediment-free water pixels in the Saginaw Bay. These targets were easily identified on the reference image (1992), but it was very difficult to identify the exact location of these pixels on the 1984 scene because of the lack of reference points in the bay. The MSS data were normalized using the same procedure, but only two pure dry soil pixels could be identified. The equation used for the MSS normalization can be seen in Fi gur e 4. It must be noted that Figure 3 only shows the results of five models because the 1984 TM data set did not contain band one, and band 6 (thermal) was not incorporated into the analysis. Also, the MSS 1992 data set did not contain band four. Therefore, the results of only three models are shown in   "}, {"section_title": "Image Rectification", "text": "The accuracy of a multitemporal change detection product is heavily dependent on the accuracy of the geometric registration of the data sets (Jensen et al., 1993;Dobson et al., 1995). For this reason, errors must be minimized in the rectification process. There are two general types of image rectification: image-to map and image-to-image. Image-to-map rectification registers an image to a planimetric surface, while image-to-image registration is a process by which two images are arranged to make similar objects on both scenes appear in the same place on the registered images (Jensen, 1986). Image-to-image registration is used when geometric precision is not needed. In the case of a change detection problem, multitemporal images must be registered using both of these methods."}, {"section_title": "Image-to-map registration", "text": "For both the TM and MS S data, the 1992 data sets were rectified to the Universal Transverse Mercator, NAD 27 projection using image-to-map rectification. In ERDAS 7.5 ground control points (GCPs) were used to match the image coordinates of an object to map coordinates (VGA ERDAS, 1989). The accuracy of the rectification procedure was assessed by applying a root mean square error algorithm (RMSE) to each of the GCPs. Jensen et al.(1993) recommended a RMSE of less than \u00b1 1.0 pixel. However, the C-CAP protocol is more stringent by requiring a RMSE of \u00b1 0.5 pixel (Dobson et al., 1995). For the 1992 TM data set 20 GCPs were identified on the image and on the topographic sheet. A first-order linear transformation was applied with an overall X and-Y RMSE threshold of 0.5 pixels. The 0.5 pixel threshold was not met until 5 GCPs that contributed greatest to the RMSE were deleted. These 5 GCPs were needed to be removed to meet the required RMSE. The overall RMSE for the GCPs was 0.4387 (13.2 m). The MSS data set was registered in the same manner as above to the Fish Point 7.5' topographic sheet. Twenty-three original GCPs were selected. The 0.5 overall RMSE threshold was not reached until 9 GCPs were deleted. The final overall RMSE obtained was 0.41355 (33.9 m). The final step in the image registration was a process known as image resampling. This process takes the GCPs generated from the previous step and produces an empty grid system. This grid system is then filled using the values from the original data set. The decision on a resampling technique is an important consideration when approaching a change detection problem. A nearest-neighbor resampling algorithm was used in this research because it retained the original digital numbers (DN) when applying them to the new transformation grid system (Rutchey and Vilcheck, 1994). The TM data sets were resampled to 30 meters while the MSS data were resampled to 82 meters."}, {"section_title": "Image-to-Image Registration", "text": "Both of the 1984 data sets (TM and MSS) were registered to the 1992 data sets using ERDAS 7.5. Again, the 0.5 RMSE threshold was pursued. It must be understood that all geometric errors that exist in the base image will be passed on to the second image (Choung, 1992). If the RMSE is greater than \u00b1 1.0 pixel after the geometric transformation, error will undoubtedly be introduced into the change detection process. In this case, change may be detected because of the displacement of an object between the two scenes providing a false indication of change. An error of\u00b1 1.0 pixel on a TM data scene can result in a displacement of\u00b1 30 meters. The TM 1984 scene was registered to the TM 1992 base image using a first order linear transformation. Thirty-two GCPs were identified, but six points had to be deleted to meet the 0.5 RMSE threshold. The final overall RMSE for the TM 1984 transformation was 0.3992 (11.9 m). The 1984 MSS scene was registered to the 1992 MSS scene using the same procedure as above. Twenty-eight GCPs were identified, but the 0.5 RMSE threshold was not obtained until eight points contributing the greatest error were removed leaving an overall RMSE of 0.3952 (32.4 m). As in the image-to-map transformations, the nearest-neighbor resampling algorithm was applied."}, {"section_title": "Binary Mask Production", "text": "To help reduce the amount of error due to misclassification, a process using a binary mask can be applied and is highly recommended by the C-CAP protocol (Dobson et al., 1995). This process involves producing a binary mask that isolates only the pixels of change between the two dates of imagery. Therefore, classification is only undertaken on the pixels which have significantly changed ( Figure 5). In theory, this process has a potential to be superior to other methods, but the most difficult process in this methodology is the production of an accurate change mask.  Figure 5. Using a Binary Mask and Classified Base Image to Classify a Second Data Set. In this research, three change images were calculated using three different methods. Each method was qualitatively examined for its effectiveness in detecting change and the most effective one was used for the final analysis. The following section will provide a description of each method."}, {"section_title": "Simple Image Differencing", "text": "Image differencing is a change detection algorithm that is accomplished by subtracting one image from another (Singh, 1989). The subtraction process produces positive and negative values that correspond to changes in the relative radiance of objects between the two images. A subtraction value of zero ( or near zero) in the normalized change images indicates an absence of change in relative radiance values. Mathematically, Jensen (1986)  xi/ = pixel value for band k, i and j are line and row numbers in band k ti = pixel value for the first date t2 = pixel value for the second date The differencing process produces a difference distribution for each band which is distributed approximately Gaussian in nature (Jensen, 1986;Singh, 1989). In this distribution, pixels showing change are grouped in the tails, while pixels showing no change are distributed around the mean (Singh, 1989). The normal distribution of the data allows the analyst to break up the scene into change and no-change classes. To identify the change in the land covers for the TM data sets, the near infrared band was used for both dates. It was believed that the near-infrared bands would show the best contrast between the uplands and inundated lowlands. Also, the near-infrared bands are less influenced by atmospheric variation (Green, Kempka, and Lackey, 1994). Thus, the differences between the two data sets should be more closely related to differences in land cover than subtle changes in atmospheric conditions. Band 3, instead of band 4, was chosen from both MSS data sets to be used in simple image differencing process because of the missing band 4 from the 1992 MSS data set. Chavez and MacKinnon (1994) found that the differencing of the red bands proved to be better than near-infrared bands and NDVI. The study by Chavez and MacKinnon (1994), however, was conducted in an arid to semi-arid environment, very different from the Saginaw Bay, Michigan study environment.\nThe image diffrencing technique, though the least complex of the three methods, produced satisfactory results for the TM data sets. The difference image in Figure 8 had an average change brightness value (BV) of 0.28. An average near zero indicated that the normalization process was successful. This would confirm the assumption that a majority of the image would belong to the no-change category. It must be understood, however, that a statistical average can be significantly influenced by BV outliers. The minimum and maximum for the TM change data set were -93 and 104 respectively. The majority of the change image is a medium gray tone. This is the result of linear contrast scaling of the image using the minimum and maximum values as lower and upper limits. Therefore, values of zero or near zero would be displayed in a medium gray tone. The dark tones (black) are relative negative changes. That is, the negative brightness values are pixels that had a higher BV in the 1984 scene than in the 1992 scene. The negative value pixels were most closely associated with the inland land covers, specifically cropland. After further investigation, these areas were identified as winter wheat. It is common to find wheat in this region planted for two purposes; planted for a cash crop, and for soil conservation practices (Roget, 1996). Unfortunately, the use of remote sensing alone can not identify land uses. Because of the inability to separate the uses of the wheat, the wheat cover was considered as a managed grassland in the C-CAP classification scheme (Dobson et al., 1995). The brighter tones of gray are areas that have undergone positive relative brightness value changes. In this case, the brightness value for the 1984 pixel was less than that of the 1992 pixel. The majority of the positive relative change pixels are again associated with the upland managed grasslands (wheat). There were some positive changes, however, along the coastline. This is because the increased amounts of exposed emergent wetlands on the coastline. Generally, the differencing of the near-infrared TM band 4 detected relative change, though this technique was very sensitive to differing amounts of cropland vegetation present between the two dates. Figure 9 shows the data distribution of the difference change image in a histogram. The distribution of the data is not normal because the second mode in the -25 to -10 BV region. Therefore, the standard deviation method of determining the change threshold was not appropriate. were 89 and 56 respectively, the output DN on the change image would be 30 (i.e., (89 * 0.754374) + (56 * -0.666445). This would be 3 DNs lower than the simple image difference method output of 33 using the same input DNs (i.e., 89-56 = 33). The PCA method produced similar results to the simple image differencing method. Similarly, the PCA method was sensitive to apparent upland cropland changes caused by the acquisition of satellite data at different stages of cropland growth. Therefore, this method failed to isolate the areas that would be the most probable for an informational class change. Instead, it identified many areas that were undergoing subtle \"within\" class changes. A \"within\" class change is described as a change pixel that is identified by the change image as having a high relative change, but when that pixel is classified into an informational class it remains the same (Pilon, Bullock, and Adeniyi, 1988). This concept is not examined in the C-CAP protocol.\nThe simple image differencing of the MSS band 3 produced the change image in Figure 11. This normally distributed change image had an average BV of 0.28 and a minimum and maximum BV of -33 and 47 respectively ( Figure 12). This method produced similar results to the TM data, in that upland cropland pixels were identified as having higher relative changes. Using band 3, however, failed to indicate strong relative changes on the coastline. This is primarily because the combination of the spectral resolution of band 3 and the low spatial resolution of the MSS data."}, {"section_title": "Selected Principal Components Analysis {PCA)", "text": "Principal component analysis (PCA) is a multivariate analysis or mathematical transformation used to reduce the number of components that account for most of the variance in a multispectral image (Singh, 1989). The mathematical transformation generates new images, referred to as components or eigenimages, which are uncorrelated linear combinations of the original image. PCA allows the analyst to generate new images ( eigenimages) that have no mathematical correlation with one another (Chavez and Kwarteng, 1989). When using PCA for change detection, the assumption must be made that multitemporal data sets are highly correlated and that PCA can be utilized to show differences between two images (Muchoney and Haack, 1994). Instead of merging all the bands from both dates of data into a single data set, the selective PCA method only uses two images or bands as input. Information that is similar between the two images is mapped to the first eigenimage (to a single component). The remaining eigenimage contains the information that is different between the two images. Chavez and MacKinnon (1994) feel that using only two single-band images as input makes interpretation much easier and more straightforward. There are benefits in using PCA over image differencing. The most important factor is that PCA technique does not require the multitemporal data sets to be normalized or radiometrically calibrated. The PCA procedure will automatically eliminate most image-wide, low frequency differences between the two images. Image-wide, low frequency differences between two images are associated with atmospheric conditions and sensor calibrations (Chavez and Kwarteng, 1989). This research used the same bands as in image differencing method (TM band 4 and MSS band 3) to isolate changes in the TM and MSS data using selected principal components. Because the selected principal components method automatically reduces system calibration variations and atmospheric variations between multitemporal datasets, the original (non-normalized) datasets were used."}, {"section_title": "Differencing of NDVI", "text": "The normalized difference vegetation index (NDVI) is a mathematical function that incorporates the red and infra-red bands to generate information on \" gr eenness\" of vegetation (Lillesand and Keifer, 1994). The formula is stated as: Similar to the image diffrencing process, this method uses cell-by-cell subtraction of the input bands. However, the NDVI formula is applied to each date before the subtraction process. Chavez and Mackinnon (1994) found that the NDVI differencing method tended to detect minimal differences in areas that were sparsely vegetated. They felt that little change was detected because the soil that supports the vegetation reflects highly in the red and near-infrared bands. Moreover, vegetation tends to reflect highly in both bands. Therefore, when vegetation gr ows there will still be minimal differences in values between the two dates. This method was applied to the TM data, but was not suitable for the MSS data because of the missing band 4 in the 1992 data set."}, {"section_title": "Image Thresholding", "text": "The thresholding process is the most critical step in producing a binary change image. Singh (1989) describes this process in which brightness values considered as change are coded as one and brightness values of no-change are coded zero. It is assumed that only a small portion of the image will have changed. Therefore, when a histogram of the change image is produced, the change areas will appear in the tails of the distribution, while the no-change pixels will be grouped around the mean ( Figure   6). The resulting image serves as a binary mask that can be applied to a classified image to give further information on the distribution of change. In this study the change image was used to direct the classification process only to pixels of change. The most difficult part of image thresholding is deciding where to place the thresholds. There are many methods used to determine the ideal threshold. For example, Muchoney and Haack ( 1994) used a trial and error approach based on standard deviations away from the mean. They graphed the results of the trials by assessing the accuracy of each different standard deviation detecting change. This technique is obviously very labor-intensive. Singh (1989) suggests applying a density slicing technique if one is interested in defining multiple thresholds. The best thresholding level, recommended by Singh, should be associated with prior knowledge of the study area. Houhoulis and Michener (1996) used a process similar to Muchoney and Haack by incorporating standard deviations as thresholds. The thresholds, however, were adjusted based on visual inspection of the images. To develop thresholds, this research used the approach incorporated by Houhoulis and Michener (1996). Thresholds were developed by producing a histogram of the change image and then calculating the mean and standard deviation of the total image. This method was used only on data sets that appeared to be normally distributed. The standard deviation method is not suitable for bimodal distributions. The standard deviation threshold was adjusted based on visual inspection of the change on the image.  "}, {"section_title": "Unsupervised Classification", "text": "The primary reason for using digital image classification algorithms is to reduce the human interaction in the classification process and increase the consistency of the classification (Dobson et al., 1995). This research used unsupervised classification logic to extract informational classes from the digital data sets. This process allowed the computer algorithm to examine the unknown pixels in the image and group them based upon the number of statistical clusters in the image (Lillesand and Kiefer, 1994). The ISODATA classification algorithm from TNTmips software was used to generate the spectral clusters (TNTmips, 1996). In this research, the binary mask, post-classification technique was employed. Therefore, it was only necessary to classify one entire scene for each data type (TM and MSS). The remaining scene would only have a classification applied to those pixels that have been identified as change from the binary mask. The entire 1992 TM scene was subjected to \u2022the ISODATA classifier which resulted in the formation of 130 original clusters. After the clusters were generated, it was necessary to attach informational classes from the C-CAP classification system to each cluster (Dobson et al., 1995). A listing of the required C-CAP land cover classification scheme used in the study is in Table 2 (Klemas et al., 1993). To help identify the clusters, a combination of three methods were applied. The methods included analyzing the locations of pixels in each generated cluster in relationship to geographic locations (using the ERDAS CLASSOVER module), identifying each cluster's statistics in relationship to their positions in feature space, and analyzing the dendrogram of the aggregation clusters (Hodgson and Plews, 1989). To provide additional information to correctly identify the clusters, ancillary data was incorporated into the analysis (e.g., soil survey, and National Wetlands Inventory maps (NWI) ). This information provided clues to the land cover classes in the study area. The NWI maps provide a detailed overview of the existing wetlands in the area based on the NWI classification system. It was assumed that the spatial pattern of classes on the NWI map were very similar to those on the classified images even though the classifications were of different years. In the case when mixed clusters were produced from the unsupervised classification, a process known as \"cluster-busting\" was applied (Jensen et al., 1993). For the 1992 TM classification 28 of the 130 clusters generated were observed as being mixed. The \"cluster-busting\" process involved isolating the mixed clusters then applying an unsupervised classification to those clusters. This process would again generate clusters for which information classes must be attached. After four iterations, a total of 186 clusters were generated. The 186 clusters were then recoded using the IDRISI ASSIGN module to correspond to the class values in the C-CAP classification scheme (Table 2). Table 2 Required C-CAP Coastal Land Cover Classification Classes (Dobson et al., 1995;Klemas et al., 1993) Class Value Class Name Therefore, it was believed by the researcher that a better discrimination between classes would be obtained by including band four into the classification. After the completion of three iterations of \"cluster-busting\", a total of 194 clusters were produced. These clusters were then recoded to correspond similarly to the informational classes in Table 2. The second TM scene (1984 change pixels only) was classified using the same procedure as above. The ISODATA clustering algorithm produced 84 clusters and after three iterations of \"cluster-busting\" a total of 113 clusters were generated. The 1992 MSS observed change data set was grouped into 65 clusters and after two iterations a total of 73 clusters were produced."}, {"section_title": "Post-classification Comparison and Change Representation", "text": "A post-classification change detection method incorporated the output of the image classification step. This process uses two classified images and compares them on a cell-by-cell basis using a GIS \"matrix\" algorithm (Jensen, 1986;Jensen et al., 1993;Dobson et al., 1995). The post classification algorithm is ideal because the C-CAP program requires a map that can show \"from-to\" classes (Dobson et al., 1995). There are some limitations, however, to the post-classification change detection method. The accuracy of the change detection product is directly related to the accuracy of the individual classifications. The accuracy of the change detection product will be similar to multiplying the accuracy of each individual classification if each map is statistically independent of the other (Singh, 1989;Khorram et al., 1994). For example, multiplying classification accuracies of 0.90 x 0.90 will theoretically result in an overall change accuracy near 81 percent. In reality, a strong dependency exists between two land cover maps of the same area, even when they are of two different dates. The MATRIX module ofERDAS 7.5 was used to produce the final \"from-to\" change maps after the individual classifications were complete,.   "}, {"section_title": "13", "text": "Accuracy Assessment of Individual Classified Scenes Since the satellite images are considered historical data (1984 and 1992), it is impossible to use in situ measurements as the only source of ground truth. Therefore, 3 5 mm slides in combination with limited site visits were used as ground truth. Evaluations of land use and land cover classification accuracy have been heavily studied (Fitzpatrick-Lins, 1981;Dicks, and Lo, 1990;Congalton, 1988;Congalton, Oderwald, and Mead, 1983). Tue main components of an accuracy assessment include (1) sampling with a particular scheme (e.g., simple random), 2generating an appropriate number of sample sites, (3) generating error matrices, and 4calculating statistics based on the error matrices. Therefore, the overall assumption in an accuracy assessment is that the error matrix represents the area mapped from the remotely sensed data (Congalton, 1988). This assumption relies heavily on the components and schemes used to generate the error matrix. If the matrix can not be assumed to be representative of the mapped area, then the results of the accuracy assessment will be invalid (Congalton, 1988). Moreover, the accuracy assessment scheme applied to a particular area can be influenced by different variables ( e.g., size of the study area, homogeneity of the land cover, purpose of the map). Tue universal sampling scheme and appropriate technique for determining the number of sampling sites for remotely sensed data has still not been found. Many studies, however, have focused on accuracy assessment methodologies (Congalton, 1988;Dicks and Lo, 1990;Fitpatrick-Lins, 1981;Warren et al., 1990). In the following section a description of the techniques used to address the above four components of a single scene accuracy assessment will be provided."}, {"section_title": "Sampling Strategy and Sampling Size", "text": "The sampling strategy was designed to meet the following objectives: (a) to determine if the total accuracy of the land cover classification meets C-CAP expectations, (b) to adequately sample all informational classes on the land cover map generated from the remotely sensed data, and ( c) to incorporate techniques recommended by the C-CAP protocol. Given these goals and the recommendations of Congalton (1988) and Khorram et al. (1994), this study used a stratified random sampling design. Although a simple random design has been found to be more statistically valid, the nature of the land cover and the purpose of the study does not allow for this scheme. Coastal wetland identification is the priority of the accuracy assessment, though it occupies a small portion the total study area, and is thus deemed important for representation in the accuracy assessment. A random design may not adequately sample the smaller informational classes. Hay (1979) suggests that there must be at least 50 samples taken for each informational class in the land cover classification. A binomial probability formula was used to determine the number of samples that must be taken to statistically achieve the accepted accuracy percentage. This formula helped determine the number of sample points and is written as: where pis the expected accuracy percentage, q is 100 -p, and Eis the allowable error (Jensen, 1986). Using the binomial formula above with an expected C-CAP accuracy of 85% and an allowable error of 5%, a minimum of 204 samples was needed. Therefore, the goal of the sampling scheme was to collect greater than 204 total samples for the entire classified scene and to attempt to collect a minimum of 50 samples for each class. A stratified random sampling scheme was applied to ensure that each informational class was represented. Each informational class produced from the remotely sensed data was isolated and random coordinates were then generated within it. The RANDOM module in ldrisi was used to generate the random sample points. The coordinates of the random sample points were located on the classified satellite image and were used only if a 3 x 3 group of homogeneous pixels were present. The 3 x 3 pixel cluster is used to ensure that the sampling plots were completely within the sample spot on the image, which can be affected by misregistration (Khorram, 1994;Martin, 1989). Also, the minimum 3 x 3 pixel cluster size may r\ufffdduce the amount of error due to edge effects or mixed pixels. The random generated sample points were then identified on the digitally scanned photographs and an informational class was given to each point. If the class could not be identified using aerial photographs, then site visits were made to help determine the land cover. A confusion matrix was used to organize the informational class identified from the reference data and the classified scenes. A simplified example of a confusion matrix is shown in Table 5. The results of the accuracy assessment were tabulated in a confusion matrix."}, {"section_title": "Classification", "text": "The confusion matrix was used to calculate a series of descriptive and statistical techniques. The simplest descriptive statistic calculated was the overall accuracy of the classification (Congalton, 1991). This was computed by dividing the total correct (sum of the diagonals) by the total number of the pixels in the error matrix (Table 5) ( Congalton and Mead, 1986). Also, errors of omission (producer's error) and commission (user's accuracy) were calculated. Errors of omission are calculated by dividing the total number of correct pixels in a category by the total number of reference pixels for that category (column totals). Errors of commission are calculated by the total number of correct pixels in a category divided by the total number of pixels that were classified in that category (row totals) (Table 5) (Congalton, 1991;Choung, 1992;Lillesand and Keifer, 1994). Jensen (1986) notes that the overall classification accuracy is useful, but that it fails to report how confident the overall accuracy is statistically greater than the expected 85% accuracy. To calculate this, 95% confidence intervals are produced by using the following formula (Harris, 1994;Jensen, 1986). p = p~ -\u2713 [ 1.645 (p~)(q~)/n + 50 /n] where p = the accuracy of the 95% lower confidence level p~ = the expression in percent of number of correct pixels divided by the total number of samples q~= 100-p~ n = number of samples To determine if the overall accuracy of the sample matrix in Table 5 is statistically greater than 85%, the p value can be calculated using the above formula. The results of this calculation was a p value of 84%, thus the overall expected map accuracy of 85% is not met at the lower 95% confidence level. This statistical test was applied to all confusion matrices. The producer's and the user's accuracy were tested In the same manner as above. As stated in the objective of the research, goals of the classification were to identify each informational class with an accuracy of 85% or greater. The following two-tailed formula provided by Janssen and van der Wel (1994) was used to test if each class exceeded the 85% lower confidence level. In this research the 95% level of significance was used. The primary disadvantage of using the overall accuracy statistic in an accuracy assessment is that it does not incorporate or account for the errors of omission and commission (Dicks and Lo, 1990). To incorporate the off-diagonals, a discrete multivariate technique called KAPP A was applied. The KAPP A coefficient provides an additional measurement of agreement or accuracy (Congalton, 1988). The KAPPA coefficient provides a measure of difference between the observed agreement between two maps and the agreement that is contributed by chance (Congalton, 1991;Dicks and Lo, 1990). To estimate KAPPA a KHAT statistic was computed. The formula is where r is the number of rows in the matrix, N is the total number of observations, x;; is the number of observations in row i and column i, X;+ and X+; are marginal totals of row i and column i (Congalton, 1991). The KAPPA statistic for the example matrix in figure 5 is 84 percent. An alternate expression of the calculation of KAPPA is: where Po is the observed accuracy, and Pe is the expected accuracy (Congalton, 1991;Foody, 1992)."}, {"section_title": "Change Accuracy Assessment", "text": "As with the single classified image map, the accuracy of the change product is a critical component of the C-CAP protocol or any change detection project. Therefore, it might be assumed that change detection accuracy would be heavily studied. This is not the case, however, and Jensen et al. (1993) noted that little work has been done with change detection accuracy. In many studies, change is assessed in the same manner as the single image accuracy assessment using binomial distributions. In this case, change is assessed by a two-by-two matrix. However to accurately assess all errors of omission (inferring no-change when actual change existed) and errors of commission (inferring change when there was actual no change) the probability distribution must change from a binomial to multinomial (Khorram et al., 1994). Khorram et al. (1994) described six types of errors that are possible in a change detection product. The six components are shown in Table 6 Khorram et al. ( 1994) suggested that not only these six components of the change product be assessed, but every class combination accuracy be evaluated. It was concluded that it would not be feasible to statistically generate the appropriate number of sample points to sample all possible land cover change combinations for this research. Therefore, this research used and evaluated the six component change accuracy assessment. An example of the error matrix used in the study is in Table 6. The change detection sampling strategy recommended by the C-CAP protocol is a stratified random design (Khorram et al., 1994;Dobson et al., 1995). In this research, the study region was divided into two groups: predicted change and predicted no change. The strata were produced by talcing the diagonals on the cross-tabulation matrix and assigning them to predicted no-change while assigning the off-diagonals to the areas of predicted change. Since the focus of the accuracy assessment was only on the six components, there was not a need to stratify the sampling based on Table 6 Six Components of Change Used in the Change Accuracy Assessment Shown in a Change Matrix individual change classes. Therefore, two individual accuracy assessments were undertaken for each scene: an accuracy assessment for the predicted change, and another for the predicated no-change. In both cases, there were three elements of the matrix estimated (Khorram et al., 1994). Components 1, 3 and 5 were estimated for the predicted no-change and 2, 4, and 6 were estimated for the predicted change."}, {"section_title": "Sampling Strategy and Sample Size", "text": "To determine the sample size required for simultaneous confidence intervals for the two stratum, a multinomial distribution formula given by Khorram et al. (1994) was used and is state as: where pis the probability of occurrence of each category and 8 is the half width of the confidence interval. It is recommended by Khorram et al. (1994) to use a probability of 0.5 because at this probability the sample size is the largest. Using this formula it was determined that the minimum number of samples needed would be 150 using the probability of each category as 0.5, the level of significance set at 0.05, and a half width confidence interval at 0.10. Therefore, for each stratum (predicted change and no-change), 150 sample points were randomly generated using the ID RISI RANDOM module (Idrisi for Windows, 1995). A 3 x 3 minimum cluster size recommended by Jensen et al. (1993) was implemented similar to the single scene accuracy assessment. The random generated coordinates were located on the \"from-to\" change image and if a homogenous 3 x 3 cluster of cells did not exist, the sample cluster was not used in the accuracy assessment. The random coordinates were generated until a total of 150 homogenous cluster samples were identified. Once the clusters were identified on the change image, the same sample locations were located on the 1984 and 1992 aerial photographs. The two observed class combinations from both data sources (aerial photographs and \"from-to\" change image) were compared and the results were tallied in the change matrix in the appropriate locations (refer to Table 6). This process was used for both of the change and no-change strata, and for both of the TM and MSS change images"}, {"section_title": "Calculation of Change Accuracy", "text": "The calculation of accuracy statistics from the change matrix was completed using the same procedures used in the single scene accuracy assessment. These statistics included the overall accuracy, user's and producer's accuracy, and KAPPA statistics of agreement. To incorporate the irregular matrix, however, components 1 and 3 were grouped for the correct no-change cell, and components 2 and 6 were grouped for the correct change cell (refer back to Table 6)."}, {"section_title": "CHAPTER V RESULTS", "text": ""}, {"section_title": "Introduction", "text": "This chapter describes the results of this study.  Figure 7 shows TM band 3 of the subset study area for both dates (1992 and 1984).\nBecause the 1992 data set did not contain band 4, the NOVI differencing method could not be applied. The results of the \u2022 simple image differencing and selected PCA are provided in the following section."}, {"section_title": "MSS Data Source", "text": "The coordinates of the subset region for both dates of MSS data were 288,173mE, 4,847,267mN for the upper-left extents, while the lower-right extents were 298,763mE, 4,847,267mN. The total area for the MSS data study region was 150.9 km. 2 \u2022 Figure 7 shows band 3 for both dates of MSS imagery for the study area. "}, {"section_title": "Production of Change Images Introduction", "text": "A binary mask was produced to isolate change pixels between the two dates of imagery. Three techniques were evaluated to produce this mask: differencing of near-infrared bands, selected PCA of the near-infrared bands, and differencing of NDVI images. It must be understood that this study region's upland land cover is predominately cropland. In early to mid June, however, very little cropland vegetation is present. The 1992 data set was collected 10 days earlier than the 1984 anniversary date of June 1. Through visual inspection of the digital scenes, it was apparent that the 1984 data set had more cropland present because data were acquired later in the growing season. This would falsely indicate a change in cropland land cover. The C-CAP protocol states that if land is in the state of being tilled it is considered cropland, but the protocol does not mention differences caused by slight differences in the dates of data acquisition. Therefore, for the data used in the study, the technique chosen to identify changes had to limit the detection of change in areas where vegetation differences are caused by the 10 day difference in anniversary data."}, {"section_title": "TM Data Results", "text": "The near-infrared band 4 was chosen for the image differencing and selected PCA change detection methods because through visual inspection the near-infrared band allowed for best overall detection of the coastal and the upland vegetation change. The following section describes the results of the three binary change methods when applied to the TM data."}, {"section_title": "NDVI Differencing", "text": "The NDVI differencing method produced the best results of the three change image methods. Statistically, the NDVI change image had an average BV of 0.01 and a minimum and maximum BV of-0.84 and 0.87 respectively. The standard deviation for the change image was 0.14. This method was the least sensitive to the ''within\" class changes in upland cropland land covers (Figure 8). The change image BV s were normally distributed (Figure 9). When comparing the NDVI change image to the other two method products (Figure 8), the NDVI difference image shows the change in the wheat plots in the upland area of the study region more clearly. The bright and dark cropland plots Also, the relative positive changes (light tones) on coastline are more distinct (refer to Figure 8). Because this method produced the best results by reducing the within class changes in the upland areas and by identifying coastal wetland differences, it was decided by the researcher to use it for the source to produce the binary change and no change image. This study only incorporated one change image (i.e., NDVI differencing) into the binary mask, post-classification portion on the analysis. To produce a binary change image a series of standard deviation thresholds were evaluated interactively (1, 1.3, 1.5, 1.8, and 2.0) using the NDVI change image, however the threshold values of\u00b1 1.3 standard deviation were chosen to be the most effective. The \u00b1 1.3 thresholds visually appeared to be the most accurate in differentiating known change and no-change areas on aerial photographs. The \u00b1 1.3 standard deviation binary change image is shown in Figure 10.  MSS Data 1.8 SD Threshold Figure 10. Binary Change Images Produced by Thresholding the Change Images. The areas in black are pixels that have been predicted to be changed in the study area. For the TM binary change image a total of 1316.7 hectares are included in the change class, while the MSS binary image has 1105.3 hectares."}, {"section_title": "MSS Data Results", "text": ""}, {"section_title": "Selected PCA", "text": "The selected PCA of the MSS band 3 produced results similar to the simple image differencing method (Figure 11 ). This method was highly sensitive to the differences in the amounts of cropland vegetation present in the two dates of imagery. The normally distributed change image had a minimum and maximum BV of -22 and 44 respectively, and had an average BV value of 6. As in the TM selected PCA, the MSS change image BV range was lower ( Figure 12). The lower range was the result of the weights applied from the linear transformation of the second eigenvector. Simple Image Differencing Selected PCA Both change methods led to similar results, but both techniques were extremely sensitive to changes in the inland cropland area. The selected PCA change product was chosen to produce the binary change and no-change image because the BV distribution appeared to be more evenly distributed on either side of the mean. A threshold value of\u00b1 1.8 standard deviations was used to produce the binary change f mask. This threshold was chosen after several thresholds were interactively compared to known changes identified from the aerial photographs. A higher threshold standard deviation was needed to isolate only the higher relative change pixels. The higher threshold was also needed to filter out many of the within class changes in the upland cropland areas. Tue binary image produced from the thresholding process is in Figure   10. Simple Image Differencing Selected PCA Figure 12. Histograms of the Two Change Images Produced From the MSS Data Sources."}, {"section_title": "Classification of TM Data", "text": "Both TM sub-scenes were classified usmg an ISODATA unsupervised classification algorithm. This process resulted in the formation of eleven informational classes from the C-CAP classification scheme for the 1984 sub-scene and ten for the 1992 sub-scene (  (Figure 13). Table 7 C-CAP Land Cover Informational Classes Extracted From the TM Sub-Scenes Using Unsupervised Classification Logic (Dobson et al., 1995) C- CAP Land Cover Class TM 1992TM 1984 Hectares % Hectares %  The second problem was the differentiation between the Woody Land -Deciduous Forest (1.411) and the Grassland -Managed (1.32) classes. As mentioned earlier, wheat in the Saginaw Bay region is planted for management practices and for a cash crop (Roget, 1996). Using strictly remote sensing, the two previous uses of wheat cannot be separated. Therefore, under C-CAP classification guidelines, the wheat cover was treated as a managed grassland (Dobson et al., 1995). Unlike other surrounding cropland vegetation, wheat was highly visible in the spring data acquisition date. Unfortunately, deciduous trees and wheat had similar spectral response patterns for both dates of TM data sets at this time period. The means and standard deviations for both classes were similar in all five bands, although the band 5 provided the best separation. The final problem encountered was the lack of homogeneity in the land covers of the study region. This resulted in many mixed pixels which were commonly located on or near the network of unpaved roads and water drains. Potentially, the mixture of bare dirt roads, open water, emergent grasses on the banks of drains, and parts of agricultural fields may contribute to a single 30 x 30 meter TM pixel BV. Therefore, the spatial resolution of the TM sensor made it difficult to classify the small linear land cover classes ( e.g., interdunal wetlands, roads, and drains)."}, {"section_title": "Classification ofMSS Data", "text": "The ISO DA TA unsupervised classification algorithm allowed for the extraction of nine C-CAP informational classes from both dates of MSS imagery (Table 8). As with the TM classification, Cultivated  dominated the upland extents, while Water (3.1) (Saginaw Bay) dominated the lowland portion of the study area ( Figure 14). The three main problems in the TM data classification were also present in the MSS classification. The limited spectral and spatial resolution of the MSS data enhanced these problems. The coarser resolution of the MSS data did not allow for many of the linear coastal wetlands to be detected. Many of these wetlands were not identified or extracted because of mixed pixel effects."}, {"section_title": "TM Data Classification Accuracy", "text": "The overall classification accuracy for both dates of TM data did not meet the recommended classification accuracy stated by Jensen et al., (1993). The 1992 data set had an overall classification accuracy of 80.79% and a lower 95% confidence level of 77.22% using 354 sample clusters. For the 1984 classified scene 306 sample clusters were generated, which resulted in an overall accuracy of 81.04% and 77.20% at the lower 95% confidence level. Both classifications had a KAPPA coefficient of 78 percent. Table 8 C-CAP Land Cover Informational Classes Extracted From the MSS Sub-Scenes Using Unsupervised Classification Logic (Dobson et al., 1995) C- CAP Land Cover Class MSS 1992MSS 1984 Hectares % Hectares %  lower 95% confidence level, with an accuracy of 97%. Unfortunately, a limited number of samples were generated for this class. For the user's accuracy, the Palustrine Emergent (2.8) and Water (3.1) classes exceeded the 85% mark with an accuracy of 89% and 98% respectively. Only the Water (3.1) class exceeded the 85% mark at the 95% lower confidence level ( Table 9 and Table 10). For the 1984 classified scene, fewer than half of the informational classes were classified with an accuracy of 85% or greater. The Palustrine Emergent (2.8) class had a producer's accuracy of 87% and a user's accuracy of 89 percent. Class Water (3.1) had producer's accuracy of 94% and a user's accuracy of 100 percent. This was the only class in the 1984 scene to exceed the 85% mark at the lower 95% confidence level. The Cropland (1.23) class had a user's accuracy of 88%, but the producer's accuracy fell short of the 85% mark with an accuracy of 64 percent. Classes Dead Scrub/Shrub Wetland (2.913) and Upland Scrub/Shrub Forest (1.412) exceeded the 85% mark, but the statistics were based on limited samples. The confusion matrices in Table 9   .., = \" :i \" ..  . .   ... = .. ...  ... .."}, {"section_title": "C. C.", "text": "; foliated at the time of data acquisition, so the sensor was affected little by the wet soil beneath the canopy. Without the effects of the moisture, the patches of tag alder had spectral response patterns similar to a stand of upland deciduous trees. The overall accuracy of 1992 and 1984 classifications were similar, an indication that the binary mask method used to determine change areas was somewhat successful."}, {"section_title": "MSS Data Classification Accuracy", "text": "Both dates ofMSS data failed to meet the required 85% overall accuracy. The 1992 data set had an overall classification accuracy of 74% and a 95% lower confidence level accuracy of 69.2 ( Table 11). The 1984 classified scene had an overall accuracy of 77.7% and a 95% lower level accuracy of 73 percent (Table 12). The KAPPA coefficient for the 1992 and 1984 classified scenes were 69.4% and 73.7% respectively. The lower overall accuracy of the 1992 scene was the result of the binary change mask produced using the selected PCA method and the thresholding process. The selected PCA method failed to indicate changes in some of the coastal zones. Also, the thresholding of the change image was too conservative. Thus, some areas of change were not classified on the 1992 scene. The 1992 scene had only two individual informational classes classified to an accuracy of at least 85 percent. Class Water (3.1) had a producer's accuracy of 95% and a user's accuracy of 91 percent. The producer's accuracy of the Water (3.1) class was significant at the 95% level of significance. The second class that met the Table 11 Confusion Matrix Generated From the Classification of the 1992 MSS Sub-Scene Data Set    ..       Table 12 Confusion Matrix Generated From the Classification of the 1984 MSS Sub-Scene Data Set  "}, {"section_title": "00", "text": "...   .. ... ., . .."}, {"section_title": "88.13", "text": "accuracy requirement was Cropland (1.23). The user's accuracy was 85%, however the producer's accuracy was 54 percent. The 1984 scene only contained two classes that were classified to the required accuracy of 85 percent. Class Water (3.1) had a producer's accuracy of94% while class Water (3.1) had a producer's accuracy of 94% while the user's accuracy was 91 percent. Surprisingly, the Managed Grassland (1.32) class had a producer's accuracy of 91 %, yet still the user's accuracy failed to meet the C-CAP requirements. Unfortunately, neither of the two class accuracies were significant at the 95% level. The classification process for the MSS data had similar problems to the TM classification. The confusion between the classes Scrub/Shrub Wetland (2.912), Upland Forest (1.411), and Managed Grassland (1.32) was still present. The spatial resolution of the MSS data did not allow for the detection of the small linear coastal wetlands. Mixed pixels were also a problem."}, {"section_title": "TM Change Detection and Accuracy Assessment", "text": "The TM informational class change map was produced usmg a cross tabulation algorithm, and the resultant map was recoded to correspond to the values in the change look-up table in Table 13. Area statistics for the final recoded change map were tabulated in a change matrix which organized the changes between the 1984 and 1992 data sets (Table 14). The main diagonal of the matrix represents areas that have not changed between the two dates, while the off-diagonal are areas that have changed. A total of 713. 5 hectares of land cover have changed to another informational class. The largest change existed between the upland classes Managed Grassland (1.32) and Cropland (1.23). The largest lowland cover change existed between the classes Palustrine Wetland (2.8) and Scrub/Shrub Wetlands (2.912). Also, Table 13 Look-Up .. .c: .,, .. .,,"}, {"section_title": "C", "text": ".. This change was found most commonly near the shoreline. The changes may be the result of different water levels for the two dates of imagery. Higher water levels in ...  .., = ., .."}, {"section_title": "t:11)", "text": ".. = .. .. = .. To assess the accuracy of the change map, the predicted change and predicted no-change components of the map were extracted. Using the multinomial probability formula, a total of 150 sample clusters were needed to meet the 95% level of significance for each of the two strata. The predicted no-change stratus of the image contained the largest area of the two. After generating hundreds of random sample points, a total of 132 homogenous 3 x 3 clusters were identified for the change accuracy assessment. A total of 42 sample clusters were identified for the predicted change stratus. The information from the sample clusters for both strata were entered into an accuracy change matrix in Table 15. When merged, the total number of sample clusters located for the change accuracy assessment was 174. This was well below the statistically needed 300 sample points. The overall change accuracy was above the 75% expected accuracy at 88.5 percent. At the lower 95% confidence level, the change image still exceeded the expected accuracy with 84.l % mark. However, the KAPPA statistic fell below the expected mark with a 70.8% accuracy. This was heavily influenced by the 73.9% producer's accuracy.   .. .. -0 s -.... .....        stratus, most of the upland changes were between the Cropland (1.23) and Managed Grassland (1.32) classes, while the lowland changes were primarily between the Palustrine Emergent (2.8) and Scrub/Shrub Wetland (2.912) classes. Therefore, because of the small aerial extents of the lowland changes, the upland classes were represented more in the change accuracy assessment. \" \" .. "}, {"section_title": "Suitable Classification Logic", "text": "In the following discussion of the classification logic, the assumption was made that the sampling methods used to generate the classification statistics were appropriate. Therefore, this section will not discuss the problems met when applying the accuracy assessments. The final problem met was the difficulty in identifying the Cropland (1.23) class. The June acquisition date was not opportune for the classification of this class. It was observed that very little cropland vegetation was present in early June. Therefore, this class was only able to be classified with the aid of ancillary data. The spatial pattern characteristics of each C-CAP informational class had an obvious effect on the ability to correctly identify each land cover class. The larger homogeneous classes (i.e., Water, Cropland) were generally identified to a higher correct percentage than the more fragmented classes (i.e., Scrub/Shrub Wetlands). This can easily be explained by the varying amounts of mixed pixels and edge effects present in homogeneous and fragmented land covers. Highly fragmented land covers will contain more transition zones that will undoubtedly introduce error into the identification of land cover classes. Therefore, the size of a land cover class had a significant effect on the accuracy of the identification of that information class. To solve some of these problems, the incorporation of multitemporal data could be used in the classification process. This would take advantage of the phenological differences in the vegetation. provide the same results) was rejected and it was determined that the NDVI differencing method produced superior results to the other two methods. The acquisition of the data used in this study made it difficult to determine areas of informational class changes. Thus, many of the relative changes identified by the change images were caused by the slight differences in cropland growth between the two dates of satellite imagery. The simple image differencing and selected PCA methods were both highly sensitive to these cropland changes. The NDVI differencing method, however, neglected to identify these changes in the upland regions. In the lowlands, all three methods produced similar results, but the NDVI differencing method was more sensitive to changes in the Palustrine Emergent (2.8) class. The NDVI differencing method was proven to be most feasible for this study because it reduced many of the changes in cropland land covers due to different dates of data acquisition. Many of the relative \"within\" class changes were reduced because the NDVI ratio included two spectral bands into the production of the change image. This is different than the other two methods analyzed in that one spectral band was used to produce the change images. Therefore, the NDVI ratio was able to incorporate more spectral information into the change image. The red TM band was highly sensitive to the bare soil in the inland regions of the study area. Therefore, bare soil was given a higher digital number (DN) even when small amounts of vegetation were present. This is different than what Chavez and Mackinnon (1994) stated, in that the red TM band vegetation has high reflectance values. The near-IR band was sensitive to vegetation. Thus, healthy vegetation would be given a higher digital number. Theoretically, it was possible to have a cropland pixel on TM band 3 with a high DN because of the cropland soil reflectance, and have a high DN on TM band 4 because of the vegetation present. Given this situation, the result of the NDVI ration would be a low value. This was the general case for both dates of imagery for the inland cropland areas. When the two change images were subtracted ( NDVI -1984 NDVn, the result was low values for the cropland areas on the change image. Thus, minimal differences in the cropland vegetation present were reduced. The differences in the amount of cropland vegetation present between both dates of imagery introduced unwanted environmental characteristics into the study. Ideally, the cropland changes would be reduced by acquiring satellite data when cropland vegetation is more mature (later in the growing season). An additional problem observed was that the study site chosen was predominately covered with natural land covers. Thus, the results are unknown for these three methods when applied to a high and low developed land cover in the Great Lakes region. It may be possible to combine the results of two or more methods to produce acceptable results. This would allow the analyst to observe the results of multiple methods and extract the portions of the change images that produced superior results."}, {"section_title": "Discussion of Hypothesis 4", "text": "Hypothesis 4 (The use of a binary mask in conjunction with post-classification logic can produce a land cover change product in a Great Lakes ecosystem with an overall accuracy greater than 75 percent) for both data sources (TM and MSS) failed to be rejected. Again, for this discussion, an assumption was made that the accuracy assessment used to produce the overall accuracy percentage was indicative of the true accuracy of the change product. This was not necessarily the case in this research. The problems encountered in the change accuracy assessment will be discussed later in the chapter. The overall accuracy for the TM data change product was 88.5% and 84.1 % at the lower 95% confidence level. Thus, the expected overall accuracy of 75% was achieved. The KAPPA coefficient of 70.8%, however, fell below the accepted accuracy mark. The overall change accuracy for the MSS product was 94.63% and 89 .92% at the lower 95% confidence interval. The incorporation of a binary mask into the post-classification methodology proved to be a valuable method in reducing falsely identified \"from-to\" change. Using strictly post-classification change detection logic in the region may introduce unwanted error into the change detection product. Because of the mixed pixels on and near the edges of linear features, the classification process for two different dates of imagery may result in different informational classes for the same object even if that object has not undergone change. Classifying only one entire scene and then classifying only the areas on the second scene that have undergone change significantly reduce these errors. Great care, however, must go into the classification of the first scene. The classification accuracy of the second scene is highly dependent on the accuracy of the first classified scene. In addition to the classification process, much effort must be spent on identifying the appropriate change mask. Every environment differs, therefore, a single binary change mask methodology may not be appropriate for all situations. It may be possible to use two or more binary mask production methodologies in one study area to produce a relative binary change mask. For this study, only one methodology was chosen to produce a binary change mask. It may have been beneficial, however, to merge the results of the NDVI and the simple image differencing results to take advantage of the sensitivity of each method in different environments (e.g., coastal zones, and uplands)."}, {"section_title": "Accuracy Assessment", "text": "The methodology used in this research to assess the accuracy of single scene classifications and the \"from-to\" change products contained some problems caused by the physical characteristics of the land cover in the study region. The problems met are discussed below."}, {"section_title": "Discussion of Hypothesis 5", "text": "Hypothesis 5 (The stratified random 3 x 3 cluster design will allow for each informational class to be represented in a single scene accuracy assessment) was partly supported for the four single scene accuracy assessments. The 3 x 3 cluster size was not suitable for the small linear wetlands on the coastline. Therefore, there was little representation of the small wetland extents in the accuracy assessments. Many of the Palustrine Emergent (2.8) wetlands that formed between beach ridges were not represented in the accuracy assessments. In most cases the linear wetlands were approximately 2 to 3 pixels wide. However, the probability of random sample points falling within a 3 x 3 cluster in these wetlands was minimal even with stratification. The accuracy assessments of the four classified scenes were heavily influenced by the large extent, homogenous classes (Palustrine Emergent (2.8), Water (3.1), Managed Grasslands (1.32) ). Therefore, it was relatively simple to generate 3 x 3 clusters for these homogeneous classes. The binomial probability formula required a total of 204 sample clusters to be generated for each classified scene to statistically achieve an accuracy of 85 percent. This requirement was obtained for all four classified scenes. The recommendation by Hay (1979) to collect a minimum of 50 samples for each information class could not be met for all classes. In this region it may be beneficial to reduce the cluster size to 2 x 2 pixels. This will allow for more of the linear wetlands and the smaller extent classes in this region (e.g., Dead Scrub/Shrub Wetlands (2.913), Drains) to be represented in the accuracy assessments. Reducing the pixel cluster size, however, may introduce error due to edge effects or misregistration. These errors could be reduced by increasing the positional accuracy requirement in the registration process. Reducing the cluster size will not only allow for the larger homogenous areas to be sampled, but will allow also for the near edges of homogenous areas and smaller isolated groups of pixels to be incorporated into the error assessment. This may provide a more truthful estimate of the overall accuracy of the classified scenes."}, {"section_title": "Discussion of Hypothesis 6", "text": "Hypothesis 6 (Using a multinomial sampling approach with a stratified random 3 x 3 cluster design will allow for each informational class change to be represented in the change accuracy assessment) could not be accepted for both data sources. Khorram et al. (1994) suggested that each informational class change be represented in the change matrix. However, it was deemed impractical to statistically sample each possible land cover change. The TM data was classified into 11 C-CAP informational classes. Therefore, each stratum (i.e., change and no-change) would have 14,641 possible land cover class combinations. To produce the change matrix, individual class changes were not sampled, rather the six components of land cover change were sampled (refer to Table 6). The final change product was stratified into predicted change and predicted no-change regions. Using the multinomial distribution formula, a minimum of 150 sample clusters were needed for each stratus. For the TM change map 132 3 x 3 sample clusters were identified on the predicted no-change stratus, while the predicted change stratus was sampled with 42 clusters. The MSS predicted no-change stratus was represented by 116 cluster samples, while 33 clusters were identified on the predicted change stratus. The requirement of a 150 sample clusters for each predicted stratus was not met for both data sources. Similar to the single scene accuracy assessment, the change accuracy assessment was heavily influenced by the larger contiguous classes (e.g., Water (3.1)). It was much easier to identify 3 x 3 sample clusters on the predicted no-change stratus, moreover, the 3 .1 Water class dominated this portion of the assessment. The lowest accuracy of the Water (3 .1) class on either of the two individual classified TM scenes was 90.9 percent. Therefore, the Water (3.1) informational class tended to bias the estimate towards a higher overall change accuracy. The 3 x 3 cluster size inhibited the predicted change areas of the change product to be represented equally in the accuracy assessment. This stratus was dominated by the changes in the upland land covers (i.e., Managed Grassland). A majority of the wetland changes on the change maps were too small to be sampled with a 3 x 3 cluster. Therefore, the wetland changes were not well represented because of the inability to locate contiguous 3 x 3 cells. This problem was enhanced on the MSS change product due to the data's spatial resolution. The incorporation of a 2 x 2 cluster size may help include some of the smaller change areas into the accuracy assessment. However, with a smaller cluster size the potential for error is even greater than that for a single scene accuracy assessment. The change product is the result of the comparison of two different classified satellite scenes, thus errors in the registration process will be compounded. Therefore, the image rectification and registration process becomes an increasingly important step in the reduction of positional error in a change detection process. sets. Therefore, increased number of mixed pixels in the MSS data sets resulted in lower overall classification accuracy."}, {"section_title": "Observations", "text": "When comparing both the TM and MSS classified products to the NWI map, it was apparent that strong similarities existed in the wetland extents between the two data sources. The satellite data-derived maps, however, provided more information within polygons than the NWI map. For example, when the northeastern portion of the study area is compared between the two data sources (Figure 15) it is apparent that the satellite data provided much more \"within\" polygon (groups of homogeneous pixels) information. The NWI map classified the entire polygon as PEMh (Palustrine Emergent Permanent), however the TM and MSS data produced maps were able to provide information on the smaller wetland classes within the larger groups of pixels. In this example, the satellite data derived maps provide information on aerial extents of three additional land cover classes (Water (3.1), Scrub/Shrub Wetland (2.912), and Dead Scrub/Shrub Wetland (2.913) ). The satellite data derived maps provide more information on the changes within many of the larger wetland areas. This information may be critical to wetland monitoring in that subtle changes in a wetland ecosystem may be an indicator to potential problems. If a researcher was relying strictly on the presented NWI map for wetland data, important information my be overlooked.  Figure 15. Comparison of the Classified TM and MSS Data Sets lo the NWI Map. Finally, in both accuracy assessments (single scene and change) it was observed that overall change statistics were not necessarily representative of the entire accuracy of the product. By using the user's, producer's, and KAPPA statistics, more detailed information of the product's accuracy was provided. However, if additional statistics, such as KAPP A, are going to be introduced into the C-CAP protocol, an accepted threshold accuracy should be developed. modifications. It is believed that the following recommendations will improve C-CAP methodologies when applied to a Great Lake ecosystem, and thus allow for more accurate data to be collected."}, {"section_title": "Component 1: Suitable Classification Logic", "text": "The C-CAP protocol allows for many different classification methodologies. Therefore, this study evaluated the use of a single scene, unsupervised classification logic to extract informational classes from the satellite imagery. The overall and individual class accuracy of 85% was not obtained for all scenes classified using this methodology. These results suggest that the classification logic implemented had some difficulties differentiating informational classes in the study region. The highest single scene accuracy obtained was 81 % for the 1984 TM data set. It was concluded that the unsupervised classification logic was not completely at fault for the failure to reach the C-CAP required overall classification accuracy mark of 85 percent. Additional problems were identified as the result of the single scene data sources. To increase the accuracy of classification process in a Great Lakes ecosystem, the following recommendations are provided: 1. To decrease the confusion between the upland and lowland informational classes, multitemporal (two or more) scenes should be incorporated for each date analyzed. 2. Satellite data should be collected in early May (leaf-off) and mid July (leaf on) to allow for better separation of lowland and upland classes. This will also allow for cropland classes to be observed. 3. Single scene, unsupervised classification logic was evaluated in this research, but there are many other accepted classification methodologies available. It is recommended that other methodologies be evaluated with the use of single scene digital satellite data. This will help determine if the single scene data or the classification methodology is at fault for the inability to differentiate C-CAP informational classes in this region."}, {"section_title": "Component 2: Suitable Change Detection Logic", "text": "The use of a binary mask in conjunction with post-classification logic proved to be successful in isolating change between two classified scenes. Because of the many linear features in the study region, the use of a binary mask in isolating change areas reduced the possibility of change error due to misclassification of mixed pixels. Also, it was observed that the NDVI differencing method in producing a change image detected changes between the two dates of imagery more correctly in the vegetated areas of the study region than the simple image differencing and selected PCA methods. To increase the accuracy of the change detection product in the Great Lakes region, the following recommendations are provided: 1. The method used to produce a binary change mask should be determined based on the ability of the method to observe change in the data acquired. The use of multiple methods to produce a change image is recommended, thus it may be possible to take advantage of the strengths of the various methods in different environments. 2. The calculation of threshold values should be done interactively to identify the \"boundaries\" between change and no-change areas of the change image. Applying a threshold and then comparing the results to known changes on aerial photographs and on the satellite images is highly recommended."}, {"section_title": "Component 3: Accuracy Assessment", "text": "The study site in the Saginaw Bay region is commonly associated with many small extent wetlands and many linear features. Thus, the recommended stratified 3 x 3 clustered accuracy assessment by Khorram et al. (1994) and Jensen et al. (1994) provided unsatisfactory results. The 3 x 3 cluster size failed to allow the representation of all informational classes in the single scene accuracy assessment. Also, the cluster size was too large for many of the wetland changes to be represented in the change accuracy assessment. Therefore, to allow for the representation of all classes in a accuracy assessment in Saginaw Bay study region, the following recommendations are provided: 1. Reducing the minimum cluster size from a 3 x 3 matrix of pixels to a 2 x 2 matrix will allow for smaller extent groups of pixels to be incorporated into the accuracy assessment. This will allow more wetland changes to be represented in the change accuracy assessment. 2. Decreasing the minimum cluster size to a 2 x 2 matrix of pixels in the accuracy assessment will increase the chance for errors due to misregistration and edge effects. Thus, the C-CAP allowable image-to-map and image-to-image registration error requirement should be more stringent by requiring a positional accuracy threshold less than 0.5 pixels (e.g., 0.35 pixels). 3. Calculating user's, producer's, KAPPA, and 95% confidence statistics in addition to the overall accuracy will provide the user of the classified and change satellite data with a more detailed description of the products accuracy."}, {"section_title": "Component 4: Source of Digital Data", "text": "The results of comparing the MSS and TM data products indicated that the MSS spatial resolution was too coarse to allow for the identification of small linear coastal wetlands in the study region. The inability to detect essential C-CAP informational classes heavily deterred the practical applications of the MSS data in the Saginaw Bay region."}, {"section_title": "Results Related to Similar Studies", "text": "The results observed from this study are similar to some of the studies described in Chapter II. Unfortunately, the applications of the C-CAP protocol in the previous studies can not be directly related to this study because of the lack of observations of the protocol in the Great Lakes region. Many of the classification problems met in this research were also recognized by Jensen et. al. (1993). The confusion involving bare soil and built-up features was common. Similarly, it was observed in this research that it may be beneficial to incorporate more than one scene per year to help more accurately classify cropland covers and to discriminate between upland and lowland C-CAP classes. The results of the feasibility of using Landsat MSS data in the Fish Point study area were closely related to the findings by McNaim, Protz, and Duke (1993). It was observed in this research that the spatial resolution of the MSS data were too coarse to detect smaller wetland areas. It was observed that the TM data allowed for more detailed change information to be identified. Similarly, McNaim, Protz, and Duke (1993) suggested that Landsat TM could be used to detect changes in most land covers in coastal regions."}, {"section_title": "C-CAP Protocol as a Monitoring Program for Michigan", "text": "The Great Lakes coastal zones of Michigan are undergoing many changes. The coastlines are seen for their aesthetic beauty, productivity, and potential commercialism, and thus are being developed at increasing rates. The increased development and use of the land in the coastal zones of the Great Lakes is applying direct and indirect stress on coastal ecosystems. To effectively manage the remaining Great Lakes coastal wetlands, a monitoring program must be implemented to generate data that can be used by policy makers to make wiser decisions. This research indicates that the Coastal Change Analysis Program (C-CAP) can be applied to a Great Lake ecosystem with some modifications. For future studies, it is suggested that the recommendations provided in this paper be evaluated in both developed and non-developed Great Lakes coastal zones. With increased amounts of high resolution satellite digital data available today and becoming available in the near future, it suggested that other data sources be incorporated into the analysis. The merging of higher spatial resolution data with the TM data may allow for better delineation and separation of C-CAP classes. An example of this may be merging TM data with India's IRS lC data. Finally, the C-CAP protocol fails to mention the possibility of radar data being incorporated into analysis. The merging of radar data with TM data may allow for more accurate delineation of C-CAP classes due to the texture information within the data."}]